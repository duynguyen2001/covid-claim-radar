<?xml version="1.0" encoding="utf-8"?>
<LCTL_TEXT>
	<DOC id="L0C04ATA6">
		<TEXT>
			<SEG end_char="21" id="L0C04ATA6-0" start_char="0">
				<ORIGINAL_TEXT>Is COVIDE19 weakening?</ORIGINAL_TEXT>
				<TOKEN end_char="1" id="token-0-0" start_char="0">Is</TOKEN>
				<TOKEN end_char="10" id="token-0-1" start_char="3">COVIDE19</TOKEN>
				<TOKEN end_char="20" id="token-0-2" start_char="12">weakening</TOKEN>
				<TOKEN end_char="21" id="token-0-3" start_char="21">?</TOKEN>
			</SEG>
			<SEG end_char="112" id="L0C04ATA6-1" start_char="23">
				<ORIGINAL_TEXT>According to some doctors and hospital managers, the strength of the virus has diminished.</ORIGINAL_TEXT>
				<TOKEN end_char="31" id="token-1-0" start_char="23">According</TOKEN>
				<TOKEN end_char="34" id="token-1-1" start_char="33">to</TOKEN>
				<TOKEN end_char="39" id="token-1-2" start_char="36">some</TOKEN>
				<TOKEN end_char="47" id="token-1-3" start_char="41">doctors</TOKEN>
				<TOKEN end_char="51" id="token-1-4" start_char="49">and</TOKEN>
				<TOKEN end_char="60" id="token-1-5" start_char="53">hospital</TOKEN>
				<TOKEN end_char="69" id="token-1-6" start_char="62">managers</TOKEN>
				<TOKEN end_char="70" id="token-1-7" start_char="70">,</TOKEN>
				<TOKEN end_char="74" id="token-1-8" start_char="72">the</TOKEN>
				<TOKEN end_char="83" id="token-1-9" start_char="76">strength</TOKEN>
				<TOKEN end_char="86" id="token-1-10" start_char="85">of</TOKEN>
				<TOKEN end_char="90" id="token-1-11" start_char="88">the</TOKEN>
				<TOKEN end_char="96" id="token-1-12" start_char="92">virus</TOKEN>
				<TOKEN end_char="100" id="token-1-13" start_char="98">has</TOKEN>
				<TOKEN end_char="111" id="token-1-14" start_char="102">diminished</TOKEN>
				<TOKEN end_char="112" id="token-1-15" start_char="112">.</TOKEN>
			</SEG>
			<SEG end_char="237" id="L0C04ATA6-2" start_char="114">
				<ORIGINAL_TEXT>Over the last few weeks, the authorities have been warning us that coronavirus is still with us and that care must be taken.</ORIGINAL_TEXT>
				<TOKEN end_char="117" id="token-2-0" start_char="114">Over</TOKEN>
				<TOKEN end_char="121" id="token-2-1" start_char="119">the</TOKEN>
				<TOKEN end_char="126" id="token-2-2" start_char="123">last</TOKEN>
				<TOKEN end_char="130" id="token-2-3" start_char="128">few</TOKEN>
				<TOKEN end_char="136" id="token-2-4" start_char="132">weeks</TOKEN>
				<TOKEN end_char="137" id="token-2-5" start_char="137">,</TOKEN>
				<TOKEN end_char="141" id="token-2-6" start_char="139">the</TOKEN>
				<TOKEN end_char="153" id="token-2-7" start_char="143">authorities</TOKEN>
				<TOKEN end_char="158" id="token-2-8" start_char="155">have</TOKEN>
				<TOKEN end_char="163" id="token-2-9" start_char="160">been</TOKEN>
				<TOKEN end_char="171" id="token-2-10" start_char="165">warning</TOKEN>
				<TOKEN end_char="174" id="token-2-11" start_char="173">us</TOKEN>
				<TOKEN end_char="179" id="token-2-12" start_char="176">that</TOKEN>
				<TOKEN end_char="191" id="token-2-13" start_char="181">coronavirus</TOKEN>
				<TOKEN end_char="194" id="token-2-14" start_char="193">is</TOKEN>
				<TOKEN end_char="200" id="token-2-15" start_char="196">still</TOKEN>
				<TOKEN end_char="205" id="token-2-16" start_char="202">with</TOKEN>
				<TOKEN end_char="208" id="token-2-17" start_char="207">us</TOKEN>
				<TOKEN end_char="212" id="token-2-18" start_char="210">and</TOKEN>
				<TOKEN end_char="217" id="token-2-19" start_char="214">that</TOKEN>
				<TOKEN end_char="222" id="token-2-20" start_char="219">care</TOKEN>
				<TOKEN end_char="227" id="token-2-21" start_char="224">must</TOKEN>
				<TOKEN end_char="230" id="token-2-22" start_char="229">be</TOKEN>
				<TOKEN end_char="236" id="token-2-23" start_char="232">taken</TOKEN>
				<TOKEN end_char="237" id="token-2-24" start_char="237">.</TOKEN>
			</SEG>
			<SEG end_char="420" id="L0C04ATA6-3" start_char="239">
				<ORIGINAL_TEXT>To be sure, precautions must be maintained, even if what some researchers claim is true: that the virus is losing strength and is not as virulent as at the beginning of the pandemic.</ORIGINAL_TEXT>
				<TOKEN end_char="240" id="token-3-0" start_char="239">To</TOKEN>
				<TOKEN end_char="243" id="token-3-1" start_char="242">be</TOKEN>
				<TOKEN end_char="248" id="token-3-2" start_char="245">sure</TOKEN>
				<TOKEN end_char="249" id="token-3-3" start_char="249">,</TOKEN>
				<TOKEN end_char="261" id="token-3-4" start_char="251">precautions</TOKEN>
				<TOKEN end_char="266" id="token-3-5" start_char="263">must</TOKEN>
				<TOKEN end_char="269" id="token-3-6" start_char="268">be</TOKEN>
				<TOKEN end_char="280" id="token-3-7" start_char="271">maintained</TOKEN>
				<TOKEN end_char="281" id="token-3-8" start_char="281">,</TOKEN>
				<TOKEN end_char="286" id="token-3-9" start_char="283">even</TOKEN>
				<TOKEN end_char="289" id="token-3-10" start_char="288">if</TOKEN>
				<TOKEN end_char="294" id="token-3-11" start_char="291">what</TOKEN>
				<TOKEN end_char="299" id="token-3-12" start_char="296">some</TOKEN>
				<TOKEN end_char="311" id="token-3-13" start_char="301">researchers</TOKEN>
				<TOKEN end_char="317" id="token-3-14" start_char="313">claim</TOKEN>
				<TOKEN end_char="320" id="token-3-15" start_char="319">is</TOKEN>
				<TOKEN end_char="325" id="token-3-16" start_char="322">true</TOKEN>
				<TOKEN end_char="326" id="token-3-17" start_char="326">:</TOKEN>
				<TOKEN end_char="331" id="token-3-18" start_char="328">that</TOKEN>
				<TOKEN end_char="335" id="token-3-19" start_char="333">the</TOKEN>
				<TOKEN end_char="341" id="token-3-20" start_char="337">virus</TOKEN>
				<TOKEN end_char="344" id="token-3-21" start_char="343">is</TOKEN>
				<TOKEN end_char="351" id="token-3-22" start_char="346">losing</TOKEN>
				<TOKEN end_char="360" id="token-3-23" start_char="353">strength</TOKEN>
				<TOKEN end_char="364" id="token-3-24" start_char="362">and</TOKEN>
				<TOKEN end_char="367" id="token-3-25" start_char="366">is</TOKEN>
				<TOKEN end_char="371" id="token-3-26" start_char="369">not</TOKEN>
				<TOKEN end_char="374" id="token-3-27" start_char="373">as</TOKEN>
				<TOKEN end_char="383" id="token-3-28" start_char="376">virulent</TOKEN>
				<TOKEN end_char="386" id="token-3-29" start_char="385">as</TOKEN>
				<TOKEN end_char="389" id="token-3-30" start_char="388">at</TOKEN>
				<TOKEN end_char="393" id="token-3-31" start_char="391">the</TOKEN>
				<TOKEN end_char="403" id="token-3-32" start_char="395">beginning</TOKEN>
				<TOKEN end_char="406" id="token-3-33" start_char="405">of</TOKEN>
				<TOKEN end_char="410" id="token-3-34" start_char="408">the</TOKEN>
				<TOKEN end_char="419" id="token-3-35" start_char="412">pandemic</TOKEN>
				<TOKEN end_char="420" id="token-3-36" start_char="420">.</TOKEN>
			</SEG>
			<SEG end_char="635" id="L0C04ATA6-4" start_char="422">
				<ORIGINAL_TEXT>That is what Sara Lumbreras, a researcher at the Institute of Technology Research (IIT), is trying to uncover, saying that &quot;current cases of coronavirus may be lighter, but there are several possible explanations.&quot;</ORIGINAL_TEXT>
				<TOKEN end_char="425" id="token-4-0" start_char="422">That</TOKEN>
				<TOKEN end_char="428" id="token-4-1" start_char="427">is</TOKEN>
				<TOKEN end_char="433" id="token-4-2" start_char="430">what</TOKEN>
				<TOKEN end_char="438" id="token-4-3" start_char="435">Sara</TOKEN>
				<TOKEN end_char="448" id="token-4-4" start_char="440">Lumbreras</TOKEN>
				<TOKEN end_char="449" id="token-4-5" start_char="449">,</TOKEN>
				<TOKEN end_char="451" id="token-4-6" start_char="451">a</TOKEN>
				<TOKEN end_char="462" id="token-4-7" start_char="453">researcher</TOKEN>
				<TOKEN end_char="465" id="token-4-8" start_char="464">at</TOKEN>
				<TOKEN end_char="469" id="token-4-9" start_char="467">the</TOKEN>
				<TOKEN end_char="479" id="token-4-10" start_char="471">Institute</TOKEN>
				<TOKEN end_char="482" id="token-4-11" start_char="481">of</TOKEN>
				<TOKEN end_char="493" id="token-4-12" start_char="484">Technology</TOKEN>
				<TOKEN end_char="502" id="token-4-13" start_char="495">Research</TOKEN>
				<TOKEN end_char="504" id="token-4-14" start_char="504">(</TOKEN>
				<TOKEN end_char="507" id="token-4-15" start_char="505">IIT</TOKEN>
				<TOKEN end_char="509" id="token-4-16" start_char="508">),</TOKEN>
				<TOKEN end_char="512" id="token-4-17" start_char="511">is</TOKEN>
				<TOKEN end_char="519" id="token-4-18" start_char="514">trying</TOKEN>
				<TOKEN end_char="522" id="token-4-19" start_char="521">to</TOKEN>
				<TOKEN end_char="530" id="token-4-20" start_char="524">uncover</TOKEN>
				<TOKEN end_char="531" id="token-4-21" start_char="531">,</TOKEN>
				<TOKEN end_char="538" id="token-4-22" start_char="533">saying</TOKEN>
				<TOKEN end_char="543" id="token-4-23" start_char="540">that</TOKEN>
				<TOKEN end_char="545" id="token-4-24" start_char="545">&quot;</TOKEN>
				<TOKEN end_char="552" id="token-4-25" start_char="546">current</TOKEN>
				<TOKEN end_char="558" id="token-4-26" start_char="554">cases</TOKEN>
				<TOKEN end_char="561" id="token-4-27" start_char="560">of</TOKEN>
				<TOKEN end_char="573" id="token-4-28" start_char="563">coronavirus</TOKEN>
				<TOKEN end_char="577" id="token-4-29" start_char="575">may</TOKEN>
				<TOKEN end_char="580" id="token-4-30" start_char="579">be</TOKEN>
				<TOKEN end_char="588" id="token-4-31" start_char="582">lighter</TOKEN>
				<TOKEN end_char="589" id="token-4-32" start_char="589">,</TOKEN>
				<TOKEN end_char="593" id="token-4-33" start_char="591">but</TOKEN>
				<TOKEN end_char="599" id="token-4-34" start_char="595">there</TOKEN>
				<TOKEN end_char="603" id="token-4-35" start_char="601">are</TOKEN>
				<TOKEN end_char="611" id="token-4-36" start_char="605">several</TOKEN>
				<TOKEN end_char="620" id="token-4-37" start_char="613">possible</TOKEN>
				<TOKEN end_char="633" id="token-4-38" start_char="622">explanations</TOKEN>
				<TOKEN end_char="635" id="token-4-39" start_char="634">.&quot;</TOKEN>
			</SEG>
			<SEG end_char="661" id="L0C04ATA6-5" start_char="637">
				<ORIGINAL_TEXT>What could be the causes?</ORIGINAL_TEXT>
				<TOKEN end_char="640" id="token-5-0" start_char="637">What</TOKEN>
				<TOKEN end_char="646" id="token-5-1" start_char="642">could</TOKEN>
				<TOKEN end_char="649" id="token-5-2" start_char="648">be</TOKEN>
				<TOKEN end_char="653" id="token-5-3" start_char="651">the</TOKEN>
				<TOKEN end_char="660" id="token-5-4" start_char="655">causes</TOKEN>
				<TOKEN end_char="661" id="token-5-5" start_char="661">?</TOKEN>
			</SEG>
			<SEG end_char="855" id="L0C04ATA6-6" start_char="663">
				<ORIGINAL_TEXT>According to some doctors and hospital managers, the strength of the virus has been attenuated, either by the effect of ultraviolet radiation or by the existence of more benign mutated strains.</ORIGINAL_TEXT>
				<TOKEN end_char="671" id="token-6-0" start_char="663">According</TOKEN>
				<TOKEN end_char="674" id="token-6-1" start_char="673">to</TOKEN>
				<TOKEN end_char="679" id="token-6-2" start_char="676">some</TOKEN>
				<TOKEN end_char="687" id="token-6-3" start_char="681">doctors</TOKEN>
				<TOKEN end_char="691" id="token-6-4" start_char="689">and</TOKEN>
				<TOKEN end_char="700" id="token-6-5" start_char="693">hospital</TOKEN>
				<TOKEN end_char="709" id="token-6-6" start_char="702">managers</TOKEN>
				<TOKEN end_char="710" id="token-6-7" start_char="710">,</TOKEN>
				<TOKEN end_char="714" id="token-6-8" start_char="712">the</TOKEN>
				<TOKEN end_char="723" id="token-6-9" start_char="716">strength</TOKEN>
				<TOKEN end_char="726" id="token-6-10" start_char="725">of</TOKEN>
				<TOKEN end_char="730" id="token-6-11" start_char="728">the</TOKEN>
				<TOKEN end_char="736" id="token-6-12" start_char="732">virus</TOKEN>
				<TOKEN end_char="740" id="token-6-13" start_char="738">has</TOKEN>
				<TOKEN end_char="745" id="token-6-14" start_char="742">been</TOKEN>
				<TOKEN end_char="756" id="token-6-15" start_char="747">attenuated</TOKEN>
				<TOKEN end_char="757" id="token-6-16" start_char="757">,</TOKEN>
				<TOKEN end_char="764" id="token-6-17" start_char="759">either</TOKEN>
				<TOKEN end_char="767" id="token-6-18" start_char="766">by</TOKEN>
				<TOKEN end_char="771" id="token-6-19" start_char="769">the</TOKEN>
				<TOKEN end_char="778" id="token-6-20" start_char="773">effect</TOKEN>
				<TOKEN end_char="781" id="token-6-21" start_char="780">of</TOKEN>
				<TOKEN end_char="793" id="token-6-22" start_char="783">ultraviolet</TOKEN>
				<TOKEN end_char="803" id="token-6-23" start_char="795">radiation</TOKEN>
				<TOKEN end_char="806" id="token-6-24" start_char="805">or</TOKEN>
				<TOKEN end_char="809" id="token-6-25" start_char="808">by</TOKEN>
				<TOKEN end_char="813" id="token-6-26" start_char="811">the</TOKEN>
				<TOKEN end_char="823" id="token-6-27" start_char="815">existence</TOKEN>
				<TOKEN end_char="826" id="token-6-28" start_char="825">of</TOKEN>
				<TOKEN end_char="831" id="token-6-29" start_char="828">more</TOKEN>
				<TOKEN end_char="838" id="token-6-30" start_char="833">benign</TOKEN>
				<TOKEN end_char="846" id="token-6-31" start_char="840">mutated</TOKEN>
				<TOKEN end_char="854" id="token-6-32" start_char="848">strains</TOKEN>
				<TOKEN end_char="855" id="token-6-33" start_char="855">.</TOKEN>
			</SEG>
			<SEG end_char="954" id="L0C04ATA6-7" start_char="857">
				<ORIGINAL_TEXT>But Lumbreras emphasizes that, for the time being, the evidence supporting these views is limited.</ORIGINAL_TEXT>
				<TOKEN end_char="859" id="token-7-0" start_char="857">But</TOKEN>
				<TOKEN end_char="869" id="token-7-1" start_char="861">Lumbreras</TOKEN>
				<TOKEN end_char="880" id="token-7-2" start_char="871">emphasizes</TOKEN>
				<TOKEN end_char="885" id="token-7-3" start_char="882">that</TOKEN>
				<TOKEN end_char="886" id="token-7-4" start_char="886">,</TOKEN>
				<TOKEN end_char="890" id="token-7-5" start_char="888">for</TOKEN>
				<TOKEN end_char="894" id="token-7-6" start_char="892">the</TOKEN>
				<TOKEN end_char="899" id="token-7-7" start_char="896">time</TOKEN>
				<TOKEN end_char="905" id="token-7-8" start_char="901">being</TOKEN>
				<TOKEN end_char="906" id="token-7-9" start_char="906">,</TOKEN>
				<TOKEN end_char="910" id="token-7-10" start_char="908">the</TOKEN>
				<TOKEN end_char="919" id="token-7-11" start_char="912">evidence</TOKEN>
				<TOKEN end_char="930" id="token-7-12" start_char="921">supporting</TOKEN>
				<TOKEN end_char="936" id="token-7-13" start_char="932">these</TOKEN>
				<TOKEN end_char="942" id="token-7-14" start_char="938">views</TOKEN>
				<TOKEN end_char="945" id="token-7-15" start_char="944">is</TOKEN>
				<TOKEN end_char="953" id="token-7-16" start_char="947">limited</TOKEN>
				<TOKEN end_char="954" id="token-7-17" start_char="954">.</TOKEN>
			</SEG>
			<SEG end_char="1171" id="L0C04ATA6-8" start_char="956">
				<ORIGINAL_TEXT>Our working group has attempted to confirm or disprove the weakening hypothesis with the statistics published so far: the low quality of the available data timidly points to the weakening without conclusive evidence.</ORIGINAL_TEXT>
				<TOKEN end_char="958" id="token-8-0" start_char="956">Our</TOKEN>
				<TOKEN end_char="966" id="token-8-1" start_char="960">working</TOKEN>
				<TOKEN end_char="972" id="token-8-2" start_char="968">group</TOKEN>
				<TOKEN end_char="976" id="token-8-3" start_char="974">has</TOKEN>
				<TOKEN end_char="986" id="token-8-4" start_char="978">attempted</TOKEN>
				<TOKEN end_char="989" id="token-8-5" start_char="988">to</TOKEN>
				<TOKEN end_char="997" id="token-8-6" start_char="991">confirm</TOKEN>
				<TOKEN end_char="1000" id="token-8-7" start_char="999">or</TOKEN>
				<TOKEN end_char="1009" id="token-8-8" start_char="1002">disprove</TOKEN>
				<TOKEN end_char="1013" id="token-8-9" start_char="1011">the</TOKEN>
				<TOKEN end_char="1023" id="token-8-10" start_char="1015">weakening</TOKEN>
				<TOKEN end_char="1034" id="token-8-11" start_char="1025">hypothesis</TOKEN>
				<TOKEN end_char="1039" id="token-8-12" start_char="1036">with</TOKEN>
				<TOKEN end_char="1043" id="token-8-13" start_char="1041">the</TOKEN>
				<TOKEN end_char="1054" id="token-8-14" start_char="1045">statistics</TOKEN>
				<TOKEN end_char="1064" id="token-8-15" start_char="1056">published</TOKEN>
				<TOKEN end_char="1067" id="token-8-16" start_char="1066">so</TOKEN>
				<TOKEN end_char="1071" id="token-8-17" start_char="1069">far</TOKEN>
				<TOKEN end_char="1072" id="token-8-18" start_char="1072">:</TOKEN>
				<TOKEN end_char="1076" id="token-8-19" start_char="1074">the</TOKEN>
				<TOKEN end_char="1080" id="token-8-20" start_char="1078">low</TOKEN>
				<TOKEN end_char="1088" id="token-8-21" start_char="1082">quality</TOKEN>
				<TOKEN end_char="1091" id="token-8-22" start_char="1090">of</TOKEN>
				<TOKEN end_char="1095" id="token-8-23" start_char="1093">the</TOKEN>
				<TOKEN end_char="1105" id="token-8-24" start_char="1097">available</TOKEN>
				<TOKEN end_char="1110" id="token-8-25" start_char="1107">data</TOKEN>
				<TOKEN end_char="1118" id="token-8-26" start_char="1112">timidly</TOKEN>
				<TOKEN end_char="1125" id="token-8-27" start_char="1120">points</TOKEN>
				<TOKEN end_char="1128" id="token-8-28" start_char="1127">to</TOKEN>
				<TOKEN end_char="1132" id="token-8-29" start_char="1130">the</TOKEN>
				<TOKEN end_char="1142" id="token-8-30" start_char="1134">weakening</TOKEN>
				<TOKEN end_char="1150" id="token-8-31" start_char="1144">without</TOKEN>
				<TOKEN end_char="1161" id="token-8-32" start_char="1152">conclusive</TOKEN>
				<TOKEN end_char="1170" id="token-8-33" start_char="1163">evidence</TOKEN>
				<TOKEN end_char="1171" id="token-8-34" start_char="1171">.</TOKEN>
			</SEG>
			<SEG end_char="1245" id="L0C04ATA6-9" start_char="1173">
				<ORIGINAL_TEXT>Exploring this hypothesis is key to the importance of its implications. &quot;</ORIGINAL_TEXT>
				<TOKEN end_char="1181" id="token-9-0" start_char="1173">Exploring</TOKEN>
				<TOKEN end_char="1186" id="token-9-1" start_char="1183">this</TOKEN>
				<TOKEN end_char="1197" id="token-9-2" start_char="1188">hypothesis</TOKEN>
				<TOKEN end_char="1200" id="token-9-3" start_char="1199">is</TOKEN>
				<TOKEN end_char="1204" id="token-9-4" start_char="1202">key</TOKEN>
				<TOKEN end_char="1207" id="token-9-5" start_char="1206">to</TOKEN>
				<TOKEN end_char="1211" id="token-9-6" start_char="1209">the</TOKEN>
				<TOKEN end_char="1222" id="token-9-7" start_char="1213">importance</TOKEN>
				<TOKEN end_char="1225" id="token-9-8" start_char="1224">of</TOKEN>
				<TOKEN end_char="1229" id="token-9-9" start_char="1227">its</TOKEN>
				<TOKEN end_char="1242" id="token-9-10" start_char="1231">implications</TOKEN>
				<TOKEN end_char="1243" id="token-9-11" start_char="1243">.</TOKEN>
				<TOKEN end_char="1245" id="token-9-12" start_char="1245">&quot;</TOKEN>
			</SEG>
			<SEG end_char="1477" id="L0C04ATA6-10" start_char="1247">
				<ORIGINAL_TEXT>For the IIT researcher, a possible weakening could be due to the impact of heat and ultraviolet radiation, or the virus is mutating, although &quot;more sequencing studies are needed to confirm what evolution the virus is experiencing.&quot;</ORIGINAL_TEXT>
				<TOKEN end_char="1249" id="token-10-0" start_char="1247">For</TOKEN>
				<TOKEN end_char="1253" id="token-10-1" start_char="1251">the</TOKEN>
				<TOKEN end_char="1257" id="token-10-2" start_char="1255">IIT</TOKEN>
				<TOKEN end_char="1268" id="token-10-3" start_char="1259">researcher</TOKEN>
				<TOKEN end_char="1269" id="token-10-4" start_char="1269">,</TOKEN>
				<TOKEN end_char="1271" id="token-10-5" start_char="1271">a</TOKEN>
				<TOKEN end_char="1280" id="token-10-6" start_char="1273">possible</TOKEN>
				<TOKEN end_char="1290" id="token-10-7" start_char="1282">weakening</TOKEN>
				<TOKEN end_char="1296" id="token-10-8" start_char="1292">could</TOKEN>
				<TOKEN end_char="1299" id="token-10-9" start_char="1298">be</TOKEN>
				<TOKEN end_char="1303" id="token-10-10" start_char="1301">due</TOKEN>
				<TOKEN end_char="1306" id="token-10-11" start_char="1305">to</TOKEN>
				<TOKEN end_char="1310" id="token-10-12" start_char="1308">the</TOKEN>
				<TOKEN end_char="1317" id="token-10-13" start_char="1312">impact</TOKEN>
				<TOKEN end_char="1320" id="token-10-14" start_char="1319">of</TOKEN>
				<TOKEN end_char="1325" id="token-10-15" start_char="1322">heat</TOKEN>
				<TOKEN end_char="1329" id="token-10-16" start_char="1327">and</TOKEN>
				<TOKEN end_char="1341" id="token-10-17" start_char="1331">ultraviolet</TOKEN>
				<TOKEN end_char="1351" id="token-10-18" start_char="1343">radiation</TOKEN>
				<TOKEN end_char="1352" id="token-10-19" start_char="1352">,</TOKEN>
				<TOKEN end_char="1355" id="token-10-20" start_char="1354">or</TOKEN>
				<TOKEN end_char="1359" id="token-10-21" start_char="1357">the</TOKEN>
				<TOKEN end_char="1365" id="token-10-22" start_char="1361">virus</TOKEN>
				<TOKEN end_char="1368" id="token-10-23" start_char="1367">is</TOKEN>
				<TOKEN end_char="1377" id="token-10-24" start_char="1370">mutating</TOKEN>
				<TOKEN end_char="1378" id="token-10-25" start_char="1378">,</TOKEN>
				<TOKEN end_char="1387" id="token-10-26" start_char="1380">although</TOKEN>
				<TOKEN end_char="1389" id="token-10-27" start_char="1389">&quot;</TOKEN>
				<TOKEN end_char="1393" id="token-10-28" start_char="1390">more</TOKEN>
				<TOKEN end_char="1404" id="token-10-29" start_char="1395">sequencing</TOKEN>
				<TOKEN end_char="1412" id="token-10-30" start_char="1406">studies</TOKEN>
				<TOKEN end_char="1416" id="token-10-31" start_char="1414">are</TOKEN>
				<TOKEN end_char="1423" id="token-10-32" start_char="1418">needed</TOKEN>
				<TOKEN end_char="1426" id="token-10-33" start_char="1425">to</TOKEN>
				<TOKEN end_char="1434" id="token-10-34" start_char="1428">confirm</TOKEN>
				<TOKEN end_char="1439" id="token-10-35" start_char="1436">what</TOKEN>
				<TOKEN end_char="1449" id="token-10-36" start_char="1441">evolution</TOKEN>
				<TOKEN end_char="1453" id="token-10-37" start_char="1451">the</TOKEN>
				<TOKEN end_char="1459" id="token-10-38" start_char="1455">virus</TOKEN>
				<TOKEN end_char="1462" id="token-10-39" start_char="1461">is</TOKEN>
				<TOKEN end_char="1475" id="token-10-40" start_char="1464">experiencing</TOKEN>
				<TOKEN end_char="1477" id="token-10-41" start_char="1476">.&quot;</TOKEN>
			</SEG>
			<SEG end_char="1750" id="L0C04ATA6-11" start_char="1479">
				<ORIGINAL_TEXT>Lumbreras recalls that the weakening could be due simply to the fact that the population that has been affected is now stronger (for example, that outbreaks are concentrated in young working-age individuals who have returned to their daily activities to a greater extent).</ORIGINAL_TEXT>
				<TOKEN end_char="1487" id="token-11-0" start_char="1479">Lumbreras</TOKEN>
				<TOKEN end_char="1495" id="token-11-1" start_char="1489">recalls</TOKEN>
				<TOKEN end_char="1500" id="token-11-2" start_char="1497">that</TOKEN>
				<TOKEN end_char="1504" id="token-11-3" start_char="1502">the</TOKEN>
				<TOKEN end_char="1514" id="token-11-4" start_char="1506">weakening</TOKEN>
				<TOKEN end_char="1520" id="token-11-5" start_char="1516">could</TOKEN>
				<TOKEN end_char="1523" id="token-11-6" start_char="1522">be</TOKEN>
				<TOKEN end_char="1527" id="token-11-7" start_char="1525">due</TOKEN>
				<TOKEN end_char="1534" id="token-11-8" start_char="1529">simply</TOKEN>
				<TOKEN end_char="1537" id="token-11-9" start_char="1536">to</TOKEN>
				<TOKEN end_char="1541" id="token-11-10" start_char="1539">the</TOKEN>
				<TOKEN end_char="1546" id="token-11-11" start_char="1543">fact</TOKEN>
				<TOKEN end_char="1551" id="token-11-12" start_char="1548">that</TOKEN>
				<TOKEN end_char="1555" id="token-11-13" start_char="1553">the</TOKEN>
				<TOKEN end_char="1566" id="token-11-14" start_char="1557">population</TOKEN>
				<TOKEN end_char="1571" id="token-11-15" start_char="1568">that</TOKEN>
				<TOKEN end_char="1575" id="token-11-16" start_char="1573">has</TOKEN>
				<TOKEN end_char="1580" id="token-11-17" start_char="1577">been</TOKEN>
				<TOKEN end_char="1589" id="token-11-18" start_char="1582">affected</TOKEN>
				<TOKEN end_char="1592" id="token-11-19" start_char="1591">is</TOKEN>
				<TOKEN end_char="1596" id="token-11-20" start_char="1594">now</TOKEN>
				<TOKEN end_char="1605" id="token-11-21" start_char="1598">stronger</TOKEN>
				<TOKEN end_char="1607" id="token-11-22" start_char="1607">(</TOKEN>
				<TOKEN end_char="1610" id="token-11-23" start_char="1608">for</TOKEN>
				<TOKEN end_char="1618" id="token-11-24" start_char="1612">example</TOKEN>
				<TOKEN end_char="1619" id="token-11-25" start_char="1619">,</TOKEN>
				<TOKEN end_char="1624" id="token-11-26" start_char="1621">that</TOKEN>
				<TOKEN end_char="1634" id="token-11-27" start_char="1626">outbreaks</TOKEN>
				<TOKEN end_char="1638" id="token-11-28" start_char="1636">are</TOKEN>
				<TOKEN end_char="1651" id="token-11-29" start_char="1640">concentrated</TOKEN>
				<TOKEN end_char="1654" id="token-11-30" start_char="1653">in</TOKEN>
				<TOKEN end_char="1660" id="token-11-31" start_char="1656">young</TOKEN>
				<TOKEN end_char="1668" id="token-11-32" start_char="1662">working</TOKEN>
				<TOKEN end_char="1669" id="token-11-33" start_char="1669">-</TOKEN>
				<TOKEN end_char="1672" id="token-11-34" start_char="1670">age</TOKEN>
				<TOKEN end_char="1684" id="token-11-35" start_char="1674">individuals</TOKEN>
				<TOKEN end_char="1688" id="token-11-36" start_char="1686">who</TOKEN>
				<TOKEN end_char="1693" id="token-11-37" start_char="1690">have</TOKEN>
				<TOKEN end_char="1702" id="token-11-38" start_char="1695">returned</TOKEN>
				<TOKEN end_char="1705" id="token-11-39" start_char="1704">to</TOKEN>
				<TOKEN end_char="1711" id="token-11-40" start_char="1707">their</TOKEN>
				<TOKEN end_char="1717" id="token-11-41" start_char="1713">daily</TOKEN>
				<TOKEN end_char="1728" id="token-11-42" start_char="1719">activities</TOKEN>
				<TOKEN end_char="1731" id="token-11-43" start_char="1730">to</TOKEN>
				<TOKEN end_char="1733" id="token-11-44" start_char="1733">a</TOKEN>
				<TOKEN end_char="1741" id="token-11-45" start_char="1735">greater</TOKEN>
				<TOKEN end_char="1748" id="token-11-46" start_char="1743">extent</TOKEN>
				<TOKEN end_char="1750" id="token-11-47" start_char="1749">).</TOKEN>
			</SEG>
			<SEG end_char="1853" id="L0C04ATA6-12" start_char="1752">
				<ORIGINAL_TEXT>In addition, &quot;we now understand the disease better and begin to treat it sooner,&quot; says the researcher.</ORIGINAL_TEXT>
				<TOKEN end_char="1753" id="token-12-0" start_char="1752">In</TOKEN>
				<TOKEN end_char="1762" id="token-12-1" start_char="1755">addition</TOKEN>
				<TOKEN end_char="1763" id="token-12-2" start_char="1763">,</TOKEN>
				<TOKEN end_char="1765" id="token-12-3" start_char="1765">&quot;</TOKEN>
				<TOKEN end_char="1767" id="token-12-4" start_char="1766">we</TOKEN>
				<TOKEN end_char="1771" id="token-12-5" start_char="1769">now</TOKEN>
				<TOKEN end_char="1782" id="token-12-6" start_char="1773">understand</TOKEN>
				<TOKEN end_char="1786" id="token-12-7" start_char="1784">the</TOKEN>
				<TOKEN end_char="1794" id="token-12-8" start_char="1788">disease</TOKEN>
				<TOKEN end_char="1801" id="token-12-9" start_char="1796">better</TOKEN>
				<TOKEN end_char="1805" id="token-12-10" start_char="1803">and</TOKEN>
				<TOKEN end_char="1811" id="token-12-11" start_char="1807">begin</TOKEN>
				<TOKEN end_char="1814" id="token-12-12" start_char="1813">to</TOKEN>
				<TOKEN end_char="1820" id="token-12-13" start_char="1816">treat</TOKEN>
				<TOKEN end_char="1823" id="token-12-14" start_char="1822">it</TOKEN>
				<TOKEN end_char="1830" id="token-12-15" start_char="1825">sooner</TOKEN>
				<TOKEN end_char="1832" id="token-12-16" start_char="1831">,&quot;</TOKEN>
				<TOKEN end_char="1837" id="token-12-17" start_char="1834">says</TOKEN>
				<TOKEN end_char="1841" id="token-12-18" start_char="1839">the</TOKEN>
				<TOKEN end_char="1852" id="token-12-19" start_char="1843">researcher</TOKEN>
				<TOKEN end_char="1853" id="token-12-20" start_char="1853">.</TOKEN>
			</SEG>
			<SEG end_char="1953" id="L0C04ATA6-13" start_char="1855">
				<ORIGINAL_TEXT>Finally, containment could have limited not only the number of infections, but also their severity.</ORIGINAL_TEXT>
				<TOKEN end_char="1861" id="token-13-0" start_char="1855">Finally</TOKEN>
				<TOKEN end_char="1862" id="token-13-1" start_char="1862">,</TOKEN>
				<TOKEN end_char="1874" id="token-13-2" start_char="1864">containment</TOKEN>
				<TOKEN end_char="1880" id="token-13-3" start_char="1876">could</TOKEN>
				<TOKEN end_char="1885" id="token-13-4" start_char="1882">have</TOKEN>
				<TOKEN end_char="1893" id="token-13-5" start_char="1887">limited</TOKEN>
				<TOKEN end_char="1897" id="token-13-6" start_char="1895">not</TOKEN>
				<TOKEN end_char="1902" id="token-13-7" start_char="1899">only</TOKEN>
				<TOKEN end_char="1906" id="token-13-8" start_char="1904">the</TOKEN>
				<TOKEN end_char="1913" id="token-13-9" start_char="1908">number</TOKEN>
				<TOKEN end_char="1916" id="token-13-10" start_char="1915">of</TOKEN>
				<TOKEN end_char="1927" id="token-13-11" start_char="1918">infections</TOKEN>
				<TOKEN end_char="1928" id="token-13-12" start_char="1928">,</TOKEN>
				<TOKEN end_char="1932" id="token-13-13" start_char="1930">but</TOKEN>
				<TOKEN end_char="1937" id="token-13-14" start_char="1934">also</TOKEN>
				<TOKEN end_char="1943" id="token-13-15" start_char="1939">their</TOKEN>
				<TOKEN end_char="1952" id="token-13-16" start_char="1945">severity</TOKEN>
				<TOKEN end_char="1953" id="token-13-17" start_char="1953">.</TOKEN>
			</SEG>
			<SEG end_char="2076" id="L0C04ATA6-14" start_char="1955">
				<ORIGINAL_TEXT>This would be the case if the intensity of symptoms depends on viral load, and viral load is limited by social distancing.</ORIGINAL_TEXT>
				<TOKEN end_char="1958" id="token-14-0" start_char="1955">This</TOKEN>
				<TOKEN end_char="1964" id="token-14-1" start_char="1960">would</TOKEN>
				<TOKEN end_char="1967" id="token-14-2" start_char="1966">be</TOKEN>
				<TOKEN end_char="1971" id="token-14-3" start_char="1969">the</TOKEN>
				<TOKEN end_char="1976" id="token-14-4" start_char="1973">case</TOKEN>
				<TOKEN end_char="1979" id="token-14-5" start_char="1978">if</TOKEN>
				<TOKEN end_char="1983" id="token-14-6" start_char="1981">the</TOKEN>
				<TOKEN end_char="1993" id="token-14-7" start_char="1985">intensity</TOKEN>
				<TOKEN end_char="1996" id="token-14-8" start_char="1995">of</TOKEN>
				<TOKEN end_char="2005" id="token-14-9" start_char="1998">symptoms</TOKEN>
				<TOKEN end_char="2013" id="token-14-10" start_char="2007">depends</TOKEN>
				<TOKEN end_char="2016" id="token-14-11" start_char="2015">on</TOKEN>
				<TOKEN end_char="2022" id="token-14-12" start_char="2018">viral</TOKEN>
				<TOKEN end_char="2027" id="token-14-13" start_char="2024">load</TOKEN>
				<TOKEN end_char="2028" id="token-14-14" start_char="2028">,</TOKEN>
				<TOKEN end_char="2032" id="token-14-15" start_char="2030">and</TOKEN>
				<TOKEN end_char="2038" id="token-14-16" start_char="2034">viral</TOKEN>
				<TOKEN end_char="2043" id="token-14-17" start_char="2040">load</TOKEN>
				<TOKEN end_char="2046" id="token-14-18" start_char="2045">is</TOKEN>
				<TOKEN end_char="2054" id="token-14-19" start_char="2048">limited</TOKEN>
				<TOKEN end_char="2057" id="token-14-20" start_char="2056">by</TOKEN>
				<TOKEN end_char="2064" id="token-14-21" start_char="2059">social</TOKEN>
				<TOKEN end_char="2075" id="token-14-22" start_char="2066">distancing</TOKEN>
				<TOKEN end_char="2076" id="token-14-23" start_char="2076">.</TOKEN>
			</SEG>
			<SEG end_char="2364" id="L0C04ATA6-15" start_char="2078">
				<ORIGINAL_TEXT>Indeed, the researcher recalls that all of this &quot;does not change the fact that we should continue to maintain that social distancing and that masquerades or hand hygiene remain a key part of our routines&quot; and calls for more research and transparent data on the evolution of the pandemic.</ORIGINAL_TEXT>
				<TOKEN end_char="2083" id="token-15-0" start_char="2078">Indeed</TOKEN>
				<TOKEN end_char="2084" id="token-15-1" start_char="2084">,</TOKEN>
				<TOKEN end_char="2088" id="token-15-2" start_char="2086">the</TOKEN>
				<TOKEN end_char="2099" id="token-15-3" start_char="2090">researcher</TOKEN>
				<TOKEN end_char="2107" id="token-15-4" start_char="2101">recalls</TOKEN>
				<TOKEN end_char="2112" id="token-15-5" start_char="2109">that</TOKEN>
				<TOKEN end_char="2116" id="token-15-6" start_char="2114">all</TOKEN>
				<TOKEN end_char="2119" id="token-15-7" start_char="2118">of</TOKEN>
				<TOKEN end_char="2124" id="token-15-8" start_char="2121">this</TOKEN>
				<TOKEN end_char="2126" id="token-15-9" start_char="2126">&quot;</TOKEN>
				<TOKEN end_char="2130" id="token-15-10" start_char="2127">does</TOKEN>
				<TOKEN end_char="2134" id="token-15-11" start_char="2132">not</TOKEN>
				<TOKEN end_char="2141" id="token-15-12" start_char="2136">change</TOKEN>
				<TOKEN end_char="2145" id="token-15-13" start_char="2143">the</TOKEN>
				<TOKEN end_char="2150" id="token-15-14" start_char="2147">fact</TOKEN>
				<TOKEN end_char="2155" id="token-15-15" start_char="2152">that</TOKEN>
				<TOKEN end_char="2158" id="token-15-16" start_char="2157">we</TOKEN>
				<TOKEN end_char="2165" id="token-15-17" start_char="2160">should</TOKEN>
				<TOKEN end_char="2174" id="token-15-18" start_char="2167">continue</TOKEN>
				<TOKEN end_char="2177" id="token-15-19" start_char="2176">to</TOKEN>
				<TOKEN end_char="2186" id="token-15-20" start_char="2179">maintain</TOKEN>
				<TOKEN end_char="2191" id="token-15-21" start_char="2188">that</TOKEN>
				<TOKEN end_char="2198" id="token-15-22" start_char="2193">social</TOKEN>
				<TOKEN end_char="2209" id="token-15-23" start_char="2200">distancing</TOKEN>
				<TOKEN end_char="2213" id="token-15-24" start_char="2211">and</TOKEN>
				<TOKEN end_char="2218" id="token-15-25" start_char="2215">that</TOKEN>
				<TOKEN end_char="2230" id="token-15-26" start_char="2220">masquerades</TOKEN>
				<TOKEN end_char="2233" id="token-15-27" start_char="2232">or</TOKEN>
				<TOKEN end_char="2238" id="token-15-28" start_char="2235">hand</TOKEN>
				<TOKEN end_char="2246" id="token-15-29" start_char="2240">hygiene</TOKEN>
				<TOKEN end_char="2253" id="token-15-30" start_char="2248">remain</TOKEN>
				<TOKEN end_char="2255" id="token-15-31" start_char="2255">a</TOKEN>
				<TOKEN end_char="2259" id="token-15-32" start_char="2257">key</TOKEN>
				<TOKEN end_char="2264" id="token-15-33" start_char="2261">part</TOKEN>
				<TOKEN end_char="2267" id="token-15-34" start_char="2266">of</TOKEN>
				<TOKEN end_char="2271" id="token-15-35" start_char="2269">our</TOKEN>
				<TOKEN end_char="2280" id="token-15-36" start_char="2273">routines</TOKEN>
				<TOKEN end_char="2281" id="token-15-37" start_char="2281">&quot;</TOKEN>
				<TOKEN end_char="2285" id="token-15-38" start_char="2283">and</TOKEN>
				<TOKEN end_char="2291" id="token-15-39" start_char="2287">calls</TOKEN>
				<TOKEN end_char="2295" id="token-15-40" start_char="2293">for</TOKEN>
				<TOKEN end_char="2300" id="token-15-41" start_char="2297">more</TOKEN>
				<TOKEN end_char="2309" id="token-15-42" start_char="2302">research</TOKEN>
				<TOKEN end_char="2313" id="token-15-43" start_char="2311">and</TOKEN>
				<TOKEN end_char="2325" id="token-15-44" start_char="2315">transparent</TOKEN>
				<TOKEN end_char="2330" id="token-15-45" start_char="2327">data</TOKEN>
				<TOKEN end_char="2333" id="token-15-46" start_char="2332">on</TOKEN>
				<TOKEN end_char="2337" id="token-15-47" start_char="2335">the</TOKEN>
				<TOKEN end_char="2347" id="token-15-48" start_char="2339">evolution</TOKEN>
				<TOKEN end_char="2350" id="token-15-49" start_char="2349">of</TOKEN>
				<TOKEN end_char="2354" id="token-15-50" start_char="2352">the</TOKEN>
				<TOKEN end_char="2363" id="token-15-51" start_char="2356">pandemic</TOKEN>
				<TOKEN end_char="2364" id="token-15-52" start_char="2364">.</TOKEN>
			</SEG>
		</TEXT>
	</DOC>
</LCTL_TEXT>

<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CA6M" lang="spa" raw_text_char_length="5307" raw_text_md5="96e7dfb8cde68728ab52128ee6a3a62d" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="86" id="segment-0" start_char="1">
<ORIGINAL_TEXT>In search for origin, no sample of COVID-19 was kept at Wuhan lab, WHO researchers say</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">In</TOKEN>
<TOKEN end_char="9" id="token-0-1" morph="none" pos="word" start_char="4">search</TOKEN>
<TOKEN end_char="13" id="token-0-2" morph="none" pos="word" start_char="11">for</TOKEN>
<TOKEN end_char="20" id="token-0-3" morph="none" pos="word" start_char="15">origin</TOKEN>
<TOKEN end_char="21" id="token-0-4" morph="none" pos="punct" start_char="21">,</TOKEN>
<TOKEN end_char="24" id="token-0-5" morph="none" pos="word" start_char="23">no</TOKEN>
<TOKEN end_char="31" id="token-0-6" morph="none" pos="word" start_char="26">sample</TOKEN>
<TOKEN end_char="34" id="token-0-7" morph="none" pos="word" start_char="33">of</TOKEN>
<TOKEN end_char="43" id="token-0-8" morph="none" pos="unknown" start_char="36">COVID-19</TOKEN>
<TOKEN end_char="47" id="token-0-9" morph="none" pos="word" start_char="45">was</TOKEN>
<TOKEN end_char="52" id="token-0-10" morph="none" pos="word" start_char="49">kept</TOKEN>
<TOKEN end_char="55" id="token-0-11" morph="none" pos="word" start_char="54">at</TOKEN>
<TOKEN end_char="61" id="token-0-12" morph="none" pos="word" start_char="57">Wuhan</TOKEN>
<TOKEN end_char="65" id="token-0-13" morph="none" pos="word" start_char="63">lab</TOKEN>
<TOKEN end_char="66" id="token-0-14" morph="none" pos="punct" start_char="66">,</TOKEN>
<TOKEN end_char="70" id="token-0-15" morph="none" pos="word" start_char="68">WHO</TOKEN>
<TOKEN end_char="82" id="token-0-16" morph="none" pos="word" start_char="72">researchers</TOKEN>
<TOKEN end_char="86" id="token-0-17" morph="none" pos="word" start_char="84">say</TOKEN>
</SEG>
<SEG end_char="370" id="segment-1" start_char="90">
<ORIGINAL_TEXT>WUHAN, China (AP) — The coronavirus most likely first appeared in humans after jumping from an animal, a team of international and Chinese scientists looking for the origins of COVID-19 said Tuesday, saying an alternate theory that the virus leaked from a Chinese lab was unlikely.</ORIGINAL_TEXT>
<TOKEN end_char="94" id="token-1-0" morph="none" pos="word" start_char="90">WUHAN</TOKEN>
<TOKEN end_char="95" id="token-1-1" morph="none" pos="punct" start_char="95">,</TOKEN>
<TOKEN end_char="101" id="token-1-2" morph="none" pos="word" start_char="97">China</TOKEN>
<TOKEN end_char="103" id="token-1-3" morph="none" pos="punct" start_char="103">(</TOKEN>
<TOKEN end_char="105" id="token-1-4" morph="none" pos="word" start_char="104">AP</TOKEN>
<TOKEN end_char="106" id="token-1-5" morph="none" pos="punct" start_char="106">)</TOKEN>
<TOKEN end_char="108" id="token-1-6" morph="none" pos="punct" start_char="108">—</TOKEN>
<TOKEN end_char="112" id="token-1-7" morph="none" pos="word" start_char="110">The</TOKEN>
<TOKEN end_char="124" id="token-1-8" morph="none" pos="word" start_char="114">coronavirus</TOKEN>
<TOKEN end_char="129" id="token-1-9" morph="none" pos="word" start_char="126">most</TOKEN>
<TOKEN end_char="136" id="token-1-10" morph="none" pos="word" start_char="131">likely</TOKEN>
<TOKEN end_char="142" id="token-1-11" morph="none" pos="word" start_char="138">first</TOKEN>
<TOKEN end_char="151" id="token-1-12" morph="none" pos="word" start_char="144">appeared</TOKEN>
<TOKEN end_char="154" id="token-1-13" morph="none" pos="word" start_char="153">in</TOKEN>
<TOKEN end_char="161" id="token-1-14" morph="none" pos="word" start_char="156">humans</TOKEN>
<TOKEN end_char="167" id="token-1-15" morph="none" pos="word" start_char="163">after</TOKEN>
<TOKEN end_char="175" id="token-1-16" morph="none" pos="word" start_char="169">jumping</TOKEN>
<TOKEN end_char="180" id="token-1-17" morph="none" pos="word" start_char="177">from</TOKEN>
<TOKEN end_char="183" id="token-1-18" morph="none" pos="word" start_char="182">an</TOKEN>
<TOKEN end_char="190" id="token-1-19" morph="none" pos="word" start_char="185">animal</TOKEN>
<TOKEN end_char="191" id="token-1-20" morph="none" pos="punct" start_char="191">,</TOKEN>
<TOKEN end_char="193" id="token-1-21" morph="none" pos="word" start_char="193">a</TOKEN>
<TOKEN end_char="198" id="token-1-22" morph="none" pos="word" start_char="195">team</TOKEN>
<TOKEN end_char="201" id="token-1-23" morph="none" pos="word" start_char="200">of</TOKEN>
<TOKEN end_char="215" id="token-1-24" morph="none" pos="word" start_char="203">international</TOKEN>
<TOKEN end_char="219" id="token-1-25" morph="none" pos="word" start_char="217">and</TOKEN>
<TOKEN end_char="227" id="token-1-26" morph="none" pos="word" start_char="221">Chinese</TOKEN>
<TOKEN end_char="238" id="token-1-27" morph="none" pos="word" start_char="229">scientists</TOKEN>
<TOKEN end_char="246" id="token-1-28" morph="none" pos="word" start_char="240">looking</TOKEN>
<TOKEN end_char="250" id="token-1-29" morph="none" pos="word" start_char="248">for</TOKEN>
<TOKEN end_char="254" id="token-1-30" morph="none" pos="word" start_char="252">the</TOKEN>
<TOKEN end_char="262" id="token-1-31" morph="none" pos="word" start_char="256">origins</TOKEN>
<TOKEN end_char="265" id="token-1-32" morph="none" pos="word" start_char="264">of</TOKEN>
<TOKEN end_char="274" id="token-1-33" morph="none" pos="unknown" start_char="267">COVID-19</TOKEN>
<TOKEN end_char="279" id="token-1-34" morph="none" pos="word" start_char="276">said</TOKEN>
<TOKEN end_char="287" id="token-1-35" morph="none" pos="word" start_char="281">Tuesday</TOKEN>
<TOKEN end_char="288" id="token-1-36" morph="none" pos="punct" start_char="288">,</TOKEN>
<TOKEN end_char="295" id="token-1-37" morph="none" pos="word" start_char="290">saying</TOKEN>
<TOKEN end_char="298" id="token-1-38" morph="none" pos="word" start_char="297">an</TOKEN>
<TOKEN end_char="308" id="token-1-39" morph="none" pos="word" start_char="300">alternate</TOKEN>
<TOKEN end_char="315" id="token-1-40" morph="none" pos="word" start_char="310">theory</TOKEN>
<TOKEN end_char="320" id="token-1-41" morph="none" pos="word" start_char="317">that</TOKEN>
<TOKEN end_char="324" id="token-1-42" morph="none" pos="word" start_char="322">the</TOKEN>
<TOKEN end_char="330" id="token-1-43" morph="none" pos="word" start_char="326">virus</TOKEN>
<TOKEN end_char="337" id="token-1-44" morph="none" pos="word" start_char="332">leaked</TOKEN>
<TOKEN end_char="342" id="token-1-45" morph="none" pos="word" start_char="339">from</TOKEN>
<TOKEN end_char="344" id="token-1-46" morph="none" pos="word" start_char="344">a</TOKEN>
<TOKEN end_char="352" id="token-1-47" morph="none" pos="word" start_char="346">Chinese</TOKEN>
<TOKEN end_char="356" id="token-1-48" morph="none" pos="word" start_char="354">lab</TOKEN>
<TOKEN end_char="360" id="token-1-49" morph="none" pos="word" start_char="358">was</TOKEN>
<TOKEN end_char="369" id="token-1-50" morph="none" pos="word" start_char="362">unlikely</TOKEN>
<TOKEN end_char="370" id="token-1-51" morph="none" pos="punct" start_char="370">.</TOKEN>
</SEG>
<SEG end_char="656" id="segment-2" start_char="373">
<ORIGINAL_TEXT>A closely watched visit by World Health Organization experts to Wuhan — the Chinese city where the first coronavirus cases were discovered — did not dramatically change the current understanding of the early days of the pandemic, said Peter Ben Embarek, the leader of the WHO mission.</ORIGINAL_TEXT>
<TOKEN end_char="373" id="token-2-0" morph="none" pos="word" start_char="373">A</TOKEN>
<TOKEN end_char="381" id="token-2-1" morph="none" pos="word" start_char="375">closely</TOKEN>
<TOKEN end_char="389" id="token-2-2" morph="none" pos="word" start_char="383">watched</TOKEN>
<TOKEN end_char="395" id="token-2-3" morph="none" pos="word" start_char="391">visit</TOKEN>
<TOKEN end_char="398" id="token-2-4" morph="none" pos="word" start_char="397">by</TOKEN>
<TOKEN end_char="404" id="token-2-5" morph="none" pos="word" start_char="400">World</TOKEN>
<TOKEN end_char="411" id="token-2-6" morph="none" pos="word" start_char="406">Health</TOKEN>
<TOKEN end_char="424" id="token-2-7" morph="none" pos="word" start_char="413">Organization</TOKEN>
<TOKEN end_char="432" id="token-2-8" morph="none" pos="word" start_char="426">experts</TOKEN>
<TOKEN end_char="435" id="token-2-9" morph="none" pos="word" start_char="434">to</TOKEN>
<TOKEN end_char="441" id="token-2-10" morph="none" pos="word" start_char="437">Wuhan</TOKEN>
<TOKEN end_char="443" id="token-2-11" morph="none" pos="punct" start_char="443">—</TOKEN>
<TOKEN end_char="447" id="token-2-12" morph="none" pos="word" start_char="445">the</TOKEN>
<TOKEN end_char="455" id="token-2-13" morph="none" pos="word" start_char="449">Chinese</TOKEN>
<TOKEN end_char="460" id="token-2-14" morph="none" pos="word" start_char="457">city</TOKEN>
<TOKEN end_char="466" id="token-2-15" morph="none" pos="word" start_char="462">where</TOKEN>
<TOKEN end_char="470" id="token-2-16" morph="none" pos="word" start_char="468">the</TOKEN>
<TOKEN end_char="476" id="token-2-17" morph="none" pos="word" start_char="472">first</TOKEN>
<TOKEN end_char="488" id="token-2-18" morph="none" pos="word" start_char="478">coronavirus</TOKEN>
<TOKEN end_char="494" id="token-2-19" morph="none" pos="word" start_char="490">cases</TOKEN>
<TOKEN end_char="499" id="token-2-20" morph="none" pos="word" start_char="496">were</TOKEN>
<TOKEN end_char="510" id="token-2-21" morph="none" pos="word" start_char="501">discovered</TOKEN>
<TOKEN end_char="512" id="token-2-22" morph="none" pos="punct" start_char="512">—</TOKEN>
<TOKEN end_char="516" id="token-2-23" morph="none" pos="word" start_char="514">did</TOKEN>
<TOKEN end_char="520" id="token-2-24" morph="none" pos="word" start_char="518">not</TOKEN>
<TOKEN end_char="533" id="token-2-25" morph="none" pos="word" start_char="522">dramatically</TOKEN>
<TOKEN end_char="540" id="token-2-26" morph="none" pos="word" start_char="535">change</TOKEN>
<TOKEN end_char="544" id="token-2-27" morph="none" pos="word" start_char="542">the</TOKEN>
<TOKEN end_char="552" id="token-2-28" morph="none" pos="word" start_char="546">current</TOKEN>
<TOKEN end_char="566" id="token-2-29" morph="none" pos="word" start_char="554">understanding</TOKEN>
<TOKEN end_char="569" id="token-2-30" morph="none" pos="word" start_char="568">of</TOKEN>
<TOKEN end_char="573" id="token-2-31" morph="none" pos="word" start_char="571">the</TOKEN>
<TOKEN end_char="579" id="token-2-32" morph="none" pos="word" start_char="575">early</TOKEN>
<TOKEN end_char="584" id="token-2-33" morph="none" pos="word" start_char="581">days</TOKEN>
<TOKEN end_char="587" id="token-2-34" morph="none" pos="word" start_char="586">of</TOKEN>
<TOKEN end_char="591" id="token-2-35" morph="none" pos="word" start_char="589">the</TOKEN>
<TOKEN end_char="600" id="token-2-36" morph="none" pos="word" start_char="593">pandemic</TOKEN>
<TOKEN end_char="601" id="token-2-37" morph="none" pos="punct" start_char="601">,</TOKEN>
<TOKEN end_char="606" id="token-2-38" morph="none" pos="word" start_char="603">said</TOKEN>
<TOKEN end_char="612" id="token-2-39" morph="none" pos="word" start_char="608">Peter</TOKEN>
<TOKEN end_char="616" id="token-2-40" morph="none" pos="word" start_char="614">Ben</TOKEN>
<TOKEN end_char="624" id="token-2-41" morph="none" pos="word" start_char="618">Embarek</TOKEN>
<TOKEN end_char="625" id="token-2-42" morph="none" pos="punct" start_char="625">,</TOKEN>
<TOKEN end_char="629" id="token-2-43" morph="none" pos="word" start_char="627">the</TOKEN>
<TOKEN end_char="636" id="token-2-44" morph="none" pos="word" start_char="631">leader</TOKEN>
<TOKEN end_char="639" id="token-2-45" morph="none" pos="word" start_char="638">of</TOKEN>
<TOKEN end_char="643" id="token-2-46" morph="none" pos="word" start_char="641">the</TOKEN>
<TOKEN end_char="647" id="token-2-47" morph="none" pos="word" start_char="645">WHO</TOKEN>
<TOKEN end_char="655" id="token-2-48" morph="none" pos="word" start_char="649">mission</TOKEN>
<TOKEN end_char="656" id="token-2-49" morph="none" pos="punct" start_char="656">.</TOKEN>
</SEG>
<SEG end_char="781" id="segment-3" start_char="659">
<ORIGINAL_TEXT>But it did "add details to that story," he said at a news conference as the group wrapped up a four-week visit to the city.</ORIGINAL_TEXT>
<TOKEN end_char="661" id="token-3-0" morph="none" pos="word" start_char="659">But</TOKEN>
<TOKEN end_char="664" id="token-3-1" morph="none" pos="word" start_char="663">it</TOKEN>
<TOKEN end_char="668" id="token-3-2" morph="none" pos="word" start_char="666">did</TOKEN>
<TOKEN end_char="670" id="token-3-3" morph="none" pos="punct" start_char="670">"</TOKEN>
<TOKEN end_char="673" id="token-3-4" morph="none" pos="word" start_char="671">add</TOKEN>
<TOKEN end_char="681" id="token-3-5" morph="none" pos="word" start_char="675">details</TOKEN>
<TOKEN end_char="684" id="token-3-6" morph="none" pos="word" start_char="683">to</TOKEN>
<TOKEN end_char="689" id="token-3-7" morph="none" pos="word" start_char="686">that</TOKEN>
<TOKEN end_char="695" id="token-3-8" morph="none" pos="word" start_char="691">story</TOKEN>
<TOKEN end_char="697" id="token-3-9" morph="none" pos="punct" start_char="696">,"</TOKEN>
<TOKEN end_char="700" id="token-3-10" morph="none" pos="word" start_char="699">he</TOKEN>
<TOKEN end_char="705" id="token-3-11" morph="none" pos="word" start_char="702">said</TOKEN>
<TOKEN end_char="708" id="token-3-12" morph="none" pos="word" start_char="707">at</TOKEN>
<TOKEN end_char="710" id="token-3-13" morph="none" pos="word" start_char="710">a</TOKEN>
<TOKEN end_char="715" id="token-3-14" morph="none" pos="word" start_char="712">news</TOKEN>
<TOKEN end_char="726" id="token-3-15" morph="none" pos="word" start_char="717">conference</TOKEN>
<TOKEN end_char="729" id="token-3-16" morph="none" pos="word" start_char="728">as</TOKEN>
<TOKEN end_char="733" id="token-3-17" morph="none" pos="word" start_char="731">the</TOKEN>
<TOKEN end_char="739" id="token-3-18" morph="none" pos="word" start_char="735">group</TOKEN>
<TOKEN end_char="747" id="token-3-19" morph="none" pos="word" start_char="741">wrapped</TOKEN>
<TOKEN end_char="750" id="token-3-20" morph="none" pos="word" start_char="749">up</TOKEN>
<TOKEN end_char="752" id="token-3-21" morph="none" pos="word" start_char="752">a</TOKEN>
<TOKEN end_char="762" id="token-3-22" morph="none" pos="unknown" start_char="754">four-week</TOKEN>
<TOKEN end_char="768" id="token-3-23" morph="none" pos="word" start_char="764">visit</TOKEN>
<TOKEN end_char="771" id="token-3-24" morph="none" pos="word" start_char="770">to</TOKEN>
<TOKEN end_char="775" id="token-3-25" morph="none" pos="word" start_char="773">the</TOKEN>
<TOKEN end_char="780" id="token-3-26" morph="none" pos="word" start_char="777">city</TOKEN>
<TOKEN end_char="781" id="token-3-27" morph="none" pos="punct" start_char="781">.</TOKEN>
</SEG>
<SEG end_char="1007" id="segment-4" start_char="784">
<ORIGINAL_TEXT>And it allowed the joint Chinese-WHO team to further explore the lab leak theory — which former U.S. President Donald Trump and officials from his administration had put forward without evidence — and decide it was unlikely.</ORIGINAL_TEXT>
<TOKEN end_char="786" id="token-4-0" morph="none" pos="word" start_char="784">And</TOKEN>
<TOKEN end_char="789" id="token-4-1" morph="none" pos="word" start_char="788">it</TOKEN>
<TOKEN end_char="797" id="token-4-2" morph="none" pos="word" start_char="791">allowed</TOKEN>
<TOKEN end_char="801" id="token-4-3" morph="none" pos="word" start_char="799">the</TOKEN>
<TOKEN end_char="807" id="token-4-4" morph="none" pos="word" start_char="803">joint</TOKEN>
<TOKEN end_char="819" id="token-4-5" morph="none" pos="unknown" start_char="809">Chinese-WHO</TOKEN>
<TOKEN end_char="824" id="token-4-6" morph="none" pos="word" start_char="821">team</TOKEN>
<TOKEN end_char="827" id="token-4-7" morph="none" pos="word" start_char="826">to</TOKEN>
<TOKEN end_char="835" id="token-4-8" morph="none" pos="word" start_char="829">further</TOKEN>
<TOKEN end_char="843" id="token-4-9" morph="none" pos="word" start_char="837">explore</TOKEN>
<TOKEN end_char="847" id="token-4-10" morph="none" pos="word" start_char="845">the</TOKEN>
<TOKEN end_char="851" id="token-4-11" morph="none" pos="word" start_char="849">lab</TOKEN>
<TOKEN end_char="856" id="token-4-12" morph="none" pos="word" start_char="853">leak</TOKEN>
<TOKEN end_char="863" id="token-4-13" morph="none" pos="word" start_char="858">theory</TOKEN>
<TOKEN end_char="865" id="token-4-14" morph="none" pos="punct" start_char="865">—</TOKEN>
<TOKEN end_char="871" id="token-4-15" morph="none" pos="word" start_char="867">which</TOKEN>
<TOKEN end_char="878" id="token-4-16" morph="none" pos="word" start_char="873">former</TOKEN>
<TOKEN end_char="882" id="token-4-17" morph="none" pos="unknown" start_char="880">U.S</TOKEN>
<TOKEN end_char="883" id="token-4-18" morph="none" pos="punct" start_char="883">.</TOKEN>
<TOKEN end_char="893" id="token-4-19" morph="none" pos="word" start_char="885">President</TOKEN>
<TOKEN end_char="900" id="token-4-20" morph="none" pos="word" start_char="895">Donald</TOKEN>
<TOKEN end_char="906" id="token-4-21" morph="none" pos="word" start_char="902">Trump</TOKEN>
<TOKEN end_char="910" id="token-4-22" morph="none" pos="word" start_char="908">and</TOKEN>
<TOKEN end_char="920" id="token-4-23" morph="none" pos="word" start_char="912">officials</TOKEN>
<TOKEN end_char="925" id="token-4-24" morph="none" pos="word" start_char="922">from</TOKEN>
<TOKEN end_char="929" id="token-4-25" morph="none" pos="word" start_char="927">his</TOKEN>
<TOKEN end_char="944" id="token-4-26" morph="none" pos="word" start_char="931">administration</TOKEN>
<TOKEN end_char="948" id="token-4-27" morph="none" pos="word" start_char="946">had</TOKEN>
<TOKEN end_char="952" id="token-4-28" morph="none" pos="word" start_char="950">put</TOKEN>
<TOKEN end_char="960" id="token-4-29" morph="none" pos="word" start_char="954">forward</TOKEN>
<TOKEN end_char="968" id="token-4-30" morph="none" pos="word" start_char="962">without</TOKEN>
<TOKEN end_char="977" id="token-4-31" morph="none" pos="word" start_char="970">evidence</TOKEN>
<TOKEN end_char="979" id="token-4-32" morph="none" pos="punct" start_char="979">—</TOKEN>
<TOKEN end_char="983" id="token-4-33" morph="none" pos="word" start_char="981">and</TOKEN>
<TOKEN end_char="990" id="token-4-34" morph="none" pos="word" start_char="985">decide</TOKEN>
<TOKEN end_char="993" id="token-4-35" morph="none" pos="word" start_char="992">it</TOKEN>
<TOKEN end_char="997" id="token-4-36" morph="none" pos="word" start_char="995">was</TOKEN>
<TOKEN end_char="1006" id="token-4-37" morph="none" pos="word" start_char="999">unlikely</TOKEN>
<TOKEN end_char="1007" id="token-4-38" morph="none" pos="punct" start_char="1007">.</TOKEN>
</SEG>
<SEG end_char="1198" id="segment-5" start_char="1009">
<ORIGINAL_TEXT>The Wuhan Institute of Virology is home to many different virus samples, leading to allegations that it may have been the source of the original outbreak, whether on purpose or accidentally.</ORIGINAL_TEXT>
<TOKEN end_char="1011" id="token-5-0" morph="none" pos="word" start_char="1009">The</TOKEN>
<TOKEN end_char="1017" id="token-5-1" morph="none" pos="word" start_char="1013">Wuhan</TOKEN>
<TOKEN end_char="1027" id="token-5-2" morph="none" pos="word" start_char="1019">Institute</TOKEN>
<TOKEN end_char="1030" id="token-5-3" morph="none" pos="word" start_char="1029">of</TOKEN>
<TOKEN end_char="1039" id="token-5-4" morph="none" pos="word" start_char="1032">Virology</TOKEN>
<TOKEN end_char="1042" id="token-5-5" morph="none" pos="word" start_char="1041">is</TOKEN>
<TOKEN end_char="1047" id="token-5-6" morph="none" pos="word" start_char="1044">home</TOKEN>
<TOKEN end_char="1050" id="token-5-7" morph="none" pos="word" start_char="1049">to</TOKEN>
<TOKEN end_char="1055" id="token-5-8" morph="none" pos="word" start_char="1052">many</TOKEN>
<TOKEN end_char="1065" id="token-5-9" morph="none" pos="word" start_char="1057">different</TOKEN>
<TOKEN end_char="1071" id="token-5-10" morph="none" pos="word" start_char="1067">virus</TOKEN>
<TOKEN end_char="1079" id="token-5-11" morph="none" pos="word" start_char="1073">samples</TOKEN>
<TOKEN end_char="1080" id="token-5-12" morph="none" pos="punct" start_char="1080">,</TOKEN>
<TOKEN end_char="1088" id="token-5-13" morph="none" pos="word" start_char="1082">leading</TOKEN>
<TOKEN end_char="1091" id="token-5-14" morph="none" pos="word" start_char="1090">to</TOKEN>
<TOKEN end_char="1103" id="token-5-15" morph="none" pos="word" start_char="1093">allegations</TOKEN>
<TOKEN end_char="1108" id="token-5-16" morph="none" pos="word" start_char="1105">that</TOKEN>
<TOKEN end_char="1111" id="token-5-17" morph="none" pos="word" start_char="1110">it</TOKEN>
<TOKEN end_char="1115" id="token-5-18" morph="none" pos="word" start_char="1113">may</TOKEN>
<TOKEN end_char="1120" id="token-5-19" morph="none" pos="word" start_char="1117">have</TOKEN>
<TOKEN end_char="1125" id="token-5-20" morph="none" pos="word" start_char="1122">been</TOKEN>
<TOKEN end_char="1129" id="token-5-21" morph="none" pos="word" start_char="1127">the</TOKEN>
<TOKEN end_char="1136" id="token-5-22" morph="none" pos="word" start_char="1131">source</TOKEN>
<TOKEN end_char="1139" id="token-5-23" morph="none" pos="word" start_char="1138">of</TOKEN>
<TOKEN end_char="1143" id="token-5-24" morph="none" pos="word" start_char="1141">the</TOKEN>
<TOKEN end_char="1152" id="token-5-25" morph="none" pos="word" start_char="1145">original</TOKEN>
<TOKEN end_char="1161" id="token-5-26" morph="none" pos="word" start_char="1154">outbreak</TOKEN>
<TOKEN end_char="1162" id="token-5-27" morph="none" pos="punct" start_char="1162">,</TOKEN>
<TOKEN end_char="1170" id="token-5-28" morph="none" pos="word" start_char="1164">whether</TOKEN>
<TOKEN end_char="1173" id="token-5-29" morph="none" pos="word" start_char="1172">on</TOKEN>
<TOKEN end_char="1181" id="token-5-30" morph="none" pos="word" start_char="1175">purpose</TOKEN>
<TOKEN end_char="1184" id="token-5-31" morph="none" pos="word" start_char="1183">or</TOKEN>
<TOKEN end_char="1197" id="token-5-32" morph="none" pos="word" start_char="1186">accidentally</TOKEN>
<TOKEN end_char="1198" id="token-5-33" morph="none" pos="punct" start_char="1198">.</TOKEN>
</SEG>
<SEG end_char="1384" id="segment-6" start_char="1201">
<ORIGINAL_TEXT>Embarek, a WHO food safety and animal disease expert, said experts now consider the possibility of such a leak so improbable that it will not be suggested as an avenue of future study.</ORIGINAL_TEXT>
<TOKEN end_char="1207" id="token-6-0" morph="none" pos="word" start_char="1201">Embarek</TOKEN>
<TOKEN end_char="1208" id="token-6-1" morph="none" pos="punct" start_char="1208">,</TOKEN>
<TOKEN end_char="1210" id="token-6-2" morph="none" pos="word" start_char="1210">a</TOKEN>
<TOKEN end_char="1214" id="token-6-3" morph="none" pos="word" start_char="1212">WHO</TOKEN>
<TOKEN end_char="1219" id="token-6-4" morph="none" pos="word" start_char="1216">food</TOKEN>
<TOKEN end_char="1226" id="token-6-5" morph="none" pos="word" start_char="1221">safety</TOKEN>
<TOKEN end_char="1230" id="token-6-6" morph="none" pos="word" start_char="1228">and</TOKEN>
<TOKEN end_char="1237" id="token-6-7" morph="none" pos="word" start_char="1232">animal</TOKEN>
<TOKEN end_char="1245" id="token-6-8" morph="none" pos="word" start_char="1239">disease</TOKEN>
<TOKEN end_char="1252" id="token-6-9" morph="none" pos="word" start_char="1247">expert</TOKEN>
<TOKEN end_char="1253" id="token-6-10" morph="none" pos="punct" start_char="1253">,</TOKEN>
<TOKEN end_char="1258" id="token-6-11" morph="none" pos="word" start_char="1255">said</TOKEN>
<TOKEN end_char="1266" id="token-6-12" morph="none" pos="word" start_char="1260">experts</TOKEN>
<TOKEN end_char="1270" id="token-6-13" morph="none" pos="word" start_char="1268">now</TOKEN>
<TOKEN end_char="1279" id="token-6-14" morph="none" pos="word" start_char="1272">consider</TOKEN>
<TOKEN end_char="1283" id="token-6-15" morph="none" pos="word" start_char="1281">the</TOKEN>
<TOKEN end_char="1295" id="token-6-16" morph="none" pos="word" start_char="1285">possibility</TOKEN>
<TOKEN end_char="1298" id="token-6-17" morph="none" pos="word" start_char="1297">of</TOKEN>
<TOKEN end_char="1303" id="token-6-18" morph="none" pos="word" start_char="1300">such</TOKEN>
<TOKEN end_char="1305" id="token-6-19" morph="none" pos="word" start_char="1305">a</TOKEN>
<TOKEN end_char="1310" id="token-6-20" morph="none" pos="word" start_char="1307">leak</TOKEN>
<TOKEN end_char="1313" id="token-6-21" morph="none" pos="word" start_char="1312">so</TOKEN>
<TOKEN end_char="1324" id="token-6-22" morph="none" pos="word" start_char="1315">improbable</TOKEN>
<TOKEN end_char="1329" id="token-6-23" morph="none" pos="word" start_char="1326">that</TOKEN>
<TOKEN end_char="1332" id="token-6-24" morph="none" pos="word" start_char="1331">it</TOKEN>
<TOKEN end_char="1337" id="token-6-25" morph="none" pos="word" start_char="1334">will</TOKEN>
<TOKEN end_char="1341" id="token-6-26" morph="none" pos="word" start_char="1339">not</TOKEN>
<TOKEN end_char="1344" id="token-6-27" morph="none" pos="word" start_char="1343">be</TOKEN>
<TOKEN end_char="1354" id="token-6-28" morph="none" pos="word" start_char="1346">suggested</TOKEN>
<TOKEN end_char="1357" id="token-6-29" morph="none" pos="word" start_char="1356">as</TOKEN>
<TOKEN end_char="1360" id="token-6-30" morph="none" pos="word" start_char="1359">an</TOKEN>
<TOKEN end_char="1367" id="token-6-31" morph="none" pos="word" start_char="1362">avenue</TOKEN>
<TOKEN end_char="1370" id="token-6-32" morph="none" pos="word" start_char="1369">of</TOKEN>
<TOKEN end_char="1377" id="token-6-33" morph="none" pos="word" start_char="1372">future</TOKEN>
<TOKEN end_char="1383" id="token-6-34" morph="none" pos="word" start_char="1379">study</TOKEN>
<TOKEN end_char="1384" id="token-6-35" morph="none" pos="punct" start_char="1384">.</TOKEN>
</SEG>
<SEG end_char="1556" id="segment-7" start_char="1386">
<ORIGINAL_TEXT>But another team member, Danish scientist Thea Koelsen Fischer, told reporters that team members could not rule out the possibility of further investigation and new leads.</ORIGINAL_TEXT>
<TOKEN end_char="1388" id="token-7-0" morph="none" pos="word" start_char="1386">But</TOKEN>
<TOKEN end_char="1396" id="token-7-1" morph="none" pos="word" start_char="1390">another</TOKEN>
<TOKEN end_char="1401" id="token-7-2" morph="none" pos="word" start_char="1398">team</TOKEN>
<TOKEN end_char="1408" id="token-7-3" morph="none" pos="word" start_char="1403">member</TOKEN>
<TOKEN end_char="1409" id="token-7-4" morph="none" pos="punct" start_char="1409">,</TOKEN>
<TOKEN end_char="1416" id="token-7-5" morph="none" pos="word" start_char="1411">Danish</TOKEN>
<TOKEN end_char="1426" id="token-7-6" morph="none" pos="word" start_char="1418">scientist</TOKEN>
<TOKEN end_char="1431" id="token-7-7" morph="none" pos="word" start_char="1428">Thea</TOKEN>
<TOKEN end_char="1439" id="token-7-8" morph="none" pos="word" start_char="1433">Koelsen</TOKEN>
<TOKEN end_char="1447" id="token-7-9" morph="none" pos="word" start_char="1441">Fischer</TOKEN>
<TOKEN end_char="1448" id="token-7-10" morph="none" pos="punct" start_char="1448">,</TOKEN>
<TOKEN end_char="1453" id="token-7-11" morph="none" pos="word" start_char="1450">told</TOKEN>
<TOKEN end_char="1463" id="token-7-12" morph="none" pos="word" start_char="1455">reporters</TOKEN>
<TOKEN end_char="1468" id="token-7-13" morph="none" pos="word" start_char="1465">that</TOKEN>
<TOKEN end_char="1473" id="token-7-14" morph="none" pos="word" start_char="1470">team</TOKEN>
<TOKEN end_char="1481" id="token-7-15" morph="none" pos="word" start_char="1475">members</TOKEN>
<TOKEN end_char="1487" id="token-7-16" morph="none" pos="word" start_char="1483">could</TOKEN>
<TOKEN end_char="1491" id="token-7-17" morph="none" pos="word" start_char="1489">not</TOKEN>
<TOKEN end_char="1496" id="token-7-18" morph="none" pos="word" start_char="1493">rule</TOKEN>
<TOKEN end_char="1500" id="token-7-19" morph="none" pos="word" start_char="1498">out</TOKEN>
<TOKEN end_char="1504" id="token-7-20" morph="none" pos="word" start_char="1502">the</TOKEN>
<TOKEN end_char="1516" id="token-7-21" morph="none" pos="word" start_char="1506">possibility</TOKEN>
<TOKEN end_char="1519" id="token-7-22" morph="none" pos="word" start_char="1518">of</TOKEN>
<TOKEN end_char="1527" id="token-7-23" morph="none" pos="word" start_char="1521">further</TOKEN>
<TOKEN end_char="1541" id="token-7-24" morph="none" pos="word" start_char="1529">investigation</TOKEN>
<TOKEN end_char="1545" id="token-7-25" morph="none" pos="word" start_char="1543">and</TOKEN>
<TOKEN end_char="1549" id="token-7-26" morph="none" pos="word" start_char="1547">new</TOKEN>
<TOKEN end_char="1555" id="token-7-27" morph="none" pos="word" start_char="1551">leads</TOKEN>
<TOKEN end_char="1556" id="token-7-28" morph="none" pos="punct" start_char="1556">.</TOKEN>
</SEG>
<SEG end_char="1652" id="segment-8" start_char="1559">
<ORIGINAL_TEXT>China had already strongly rejected the possibility of a leak and has promoted other theories.</ORIGINAL_TEXT>
<TOKEN end_char="1563" id="token-8-0" morph="none" pos="word" start_char="1559">China</TOKEN>
<TOKEN end_char="1567" id="token-8-1" morph="none" pos="word" start_char="1565">had</TOKEN>
<TOKEN end_char="1575" id="token-8-2" morph="none" pos="word" start_char="1569">already</TOKEN>
<TOKEN end_char="1584" id="token-8-3" morph="none" pos="word" start_char="1577">strongly</TOKEN>
<TOKEN end_char="1593" id="token-8-4" morph="none" pos="word" start_char="1586">rejected</TOKEN>
<TOKEN end_char="1597" id="token-8-5" morph="none" pos="word" start_char="1595">the</TOKEN>
<TOKEN end_char="1609" id="token-8-6" morph="none" pos="word" start_char="1599">possibility</TOKEN>
<TOKEN end_char="1612" id="token-8-7" morph="none" pos="word" start_char="1611">of</TOKEN>
<TOKEN end_char="1614" id="token-8-8" morph="none" pos="word" start_char="1614">a</TOKEN>
<TOKEN end_char="1619" id="token-8-9" morph="none" pos="word" start_char="1616">leak</TOKEN>
<TOKEN end_char="1623" id="token-8-10" morph="none" pos="word" start_char="1621">and</TOKEN>
<TOKEN end_char="1627" id="token-8-11" morph="none" pos="word" start_char="1625">has</TOKEN>
<TOKEN end_char="1636" id="token-8-12" morph="none" pos="word" start_char="1629">promoted</TOKEN>
<TOKEN end_char="1642" id="token-8-13" morph="none" pos="word" start_char="1638">other</TOKEN>
<TOKEN end_char="1651" id="token-8-14" morph="none" pos="word" start_char="1644">theories</TOKEN>
<TOKEN end_char="1652" id="token-8-15" morph="none" pos="punct" start_char="1652">.</TOKEN>
</SEG>
<SEG end_char="1837" id="segment-9" start_char="1654">
<ORIGINAL_TEXT>The Chinese and foreign experts considered several ideas for how the disease first ended up in humans, leading to a pandemic that has now killed more than 2.3 million people worldwide.</ORIGINAL_TEXT>
<TOKEN end_char="1656" id="token-9-0" morph="none" pos="word" start_char="1654">The</TOKEN>
<TOKEN end_char="1664" id="token-9-1" morph="none" pos="word" start_char="1658">Chinese</TOKEN>
<TOKEN end_char="1668" id="token-9-2" morph="none" pos="word" start_char="1666">and</TOKEN>
<TOKEN end_char="1676" id="token-9-3" morph="none" pos="word" start_char="1670">foreign</TOKEN>
<TOKEN end_char="1684" id="token-9-4" morph="none" pos="word" start_char="1678">experts</TOKEN>
<TOKEN end_char="1695" id="token-9-5" morph="none" pos="word" start_char="1686">considered</TOKEN>
<TOKEN end_char="1703" id="token-9-6" morph="none" pos="word" start_char="1697">several</TOKEN>
<TOKEN end_char="1709" id="token-9-7" morph="none" pos="word" start_char="1705">ideas</TOKEN>
<TOKEN end_char="1713" id="token-9-8" morph="none" pos="word" start_char="1711">for</TOKEN>
<TOKEN end_char="1717" id="token-9-9" morph="none" pos="word" start_char="1715">how</TOKEN>
<TOKEN end_char="1721" id="token-9-10" morph="none" pos="word" start_char="1719">the</TOKEN>
<TOKEN end_char="1729" id="token-9-11" morph="none" pos="word" start_char="1723">disease</TOKEN>
<TOKEN end_char="1735" id="token-9-12" morph="none" pos="word" start_char="1731">first</TOKEN>
<TOKEN end_char="1741" id="token-9-13" morph="none" pos="word" start_char="1737">ended</TOKEN>
<TOKEN end_char="1744" id="token-9-14" morph="none" pos="word" start_char="1743">up</TOKEN>
<TOKEN end_char="1747" id="token-9-15" morph="none" pos="word" start_char="1746">in</TOKEN>
<TOKEN end_char="1754" id="token-9-16" morph="none" pos="word" start_char="1749">humans</TOKEN>
<TOKEN end_char="1755" id="token-9-17" morph="none" pos="punct" start_char="1755">,</TOKEN>
<TOKEN end_char="1763" id="token-9-18" morph="none" pos="word" start_char="1757">leading</TOKEN>
<TOKEN end_char="1766" id="token-9-19" morph="none" pos="word" start_char="1765">to</TOKEN>
<TOKEN end_char="1768" id="token-9-20" morph="none" pos="word" start_char="1768">a</TOKEN>
<TOKEN end_char="1777" id="token-9-21" morph="none" pos="word" start_char="1770">pandemic</TOKEN>
<TOKEN end_char="1782" id="token-9-22" morph="none" pos="word" start_char="1779">that</TOKEN>
<TOKEN end_char="1786" id="token-9-23" morph="none" pos="word" start_char="1784">has</TOKEN>
<TOKEN end_char="1790" id="token-9-24" morph="none" pos="word" start_char="1788">now</TOKEN>
<TOKEN end_char="1797" id="token-9-25" morph="none" pos="word" start_char="1792">killed</TOKEN>
<TOKEN end_char="1802" id="token-9-26" morph="none" pos="word" start_char="1799">more</TOKEN>
<TOKEN end_char="1807" id="token-9-27" morph="none" pos="word" start_char="1804">than</TOKEN>
<TOKEN end_char="1811" id="token-9-28" morph="none" pos="word" start_char="1809">2.3</TOKEN>
<TOKEN end_char="1819" id="token-9-29" morph="none" pos="word" start_char="1813">million</TOKEN>
<TOKEN end_char="1826" id="token-9-30" morph="none" pos="word" start_char="1821">people</TOKEN>
<TOKEN end_char="1836" id="token-9-31" morph="none" pos="word" start_char="1828">worldwide</TOKEN>
<TOKEN end_char="1837" id="token-9-32" morph="none" pos="punct" start_char="1837">.</TOKEN>
</SEG>
<SEG end_char="2020" id="segment-10" start_char="1840">
<ORIGINAL_TEXT>Embarek said the initial findings suggest the most likely pathway the virus followed was from a bat to another animal and then to humans, adding that would require further research.</ORIGINAL_TEXT>
<TOKEN end_char="1846" id="token-10-0" morph="none" pos="word" start_char="1840">Embarek</TOKEN>
<TOKEN end_char="1851" id="token-10-1" morph="none" pos="word" start_char="1848">said</TOKEN>
<TOKEN end_char="1855" id="token-10-2" morph="none" pos="word" start_char="1853">the</TOKEN>
<TOKEN end_char="1863" id="token-10-3" morph="none" pos="word" start_char="1857">initial</TOKEN>
<TOKEN end_char="1872" id="token-10-4" morph="none" pos="word" start_char="1865">findings</TOKEN>
<TOKEN end_char="1880" id="token-10-5" morph="none" pos="word" start_char="1874">suggest</TOKEN>
<TOKEN end_char="1884" id="token-10-6" morph="none" pos="word" start_char="1882">the</TOKEN>
<TOKEN end_char="1889" id="token-10-7" morph="none" pos="word" start_char="1886">most</TOKEN>
<TOKEN end_char="1896" id="token-10-8" morph="none" pos="word" start_char="1891">likely</TOKEN>
<TOKEN end_char="1904" id="token-10-9" morph="none" pos="word" start_char="1898">pathway</TOKEN>
<TOKEN end_char="1908" id="token-10-10" morph="none" pos="word" start_char="1906">the</TOKEN>
<TOKEN end_char="1914" id="token-10-11" morph="none" pos="word" start_char="1910">virus</TOKEN>
<TOKEN end_char="1923" id="token-10-12" morph="none" pos="word" start_char="1916">followed</TOKEN>
<TOKEN end_char="1927" id="token-10-13" morph="none" pos="word" start_char="1925">was</TOKEN>
<TOKEN end_char="1932" id="token-10-14" morph="none" pos="word" start_char="1929">from</TOKEN>
<TOKEN end_char="1934" id="token-10-15" morph="none" pos="word" start_char="1934">a</TOKEN>
<TOKEN end_char="1938" id="token-10-16" morph="none" pos="word" start_char="1936">bat</TOKEN>
<TOKEN end_char="1941" id="token-10-17" morph="none" pos="word" start_char="1940">to</TOKEN>
<TOKEN end_char="1949" id="token-10-18" morph="none" pos="word" start_char="1943">another</TOKEN>
<TOKEN end_char="1956" id="token-10-19" morph="none" pos="word" start_char="1951">animal</TOKEN>
<TOKEN end_char="1960" id="token-10-20" morph="none" pos="word" start_char="1958">and</TOKEN>
<TOKEN end_char="1965" id="token-10-21" morph="none" pos="word" start_char="1962">then</TOKEN>
<TOKEN end_char="1968" id="token-10-22" morph="none" pos="word" start_char="1967">to</TOKEN>
<TOKEN end_char="1975" id="token-10-23" morph="none" pos="word" start_char="1970">humans</TOKEN>
<TOKEN end_char="1976" id="token-10-24" morph="none" pos="punct" start_char="1976">,</TOKEN>
<TOKEN end_char="1983" id="token-10-25" morph="none" pos="word" start_char="1978">adding</TOKEN>
<TOKEN end_char="1988" id="token-10-26" morph="none" pos="word" start_char="1985">that</TOKEN>
<TOKEN end_char="1994" id="token-10-27" morph="none" pos="word" start_char="1990">would</TOKEN>
<TOKEN end_char="2002" id="token-10-28" morph="none" pos="word" start_char="1996">require</TOKEN>
<TOKEN end_char="2010" id="token-10-29" morph="none" pos="word" start_char="2004">further</TOKEN>
<TOKEN end_char="2019" id="token-10-30" morph="none" pos="word" start_char="2012">research</TOKEN>
<TOKEN end_char="2020" id="token-10-31" morph="none" pos="punct" start_char="2020">.</TOKEN>
</SEG>
<SEG end_char="2182" id="segment-11" start_char="2023">
<ORIGINAL_TEXT>"The findings suggest that the laboratory incidents hypothesis is extremely unlikely to explain the introduction of the virus to the human population," he said.</ORIGINAL_TEXT>
<TOKEN end_char="2023" id="token-11-0" morph="none" pos="punct" start_char="2023">"</TOKEN>
<TOKEN end_char="2026" id="token-11-1" morph="none" pos="word" start_char="2024">The</TOKEN>
<TOKEN end_char="2035" id="token-11-2" morph="none" pos="word" start_char="2028">findings</TOKEN>
<TOKEN end_char="2043" id="token-11-3" morph="none" pos="word" start_char="2037">suggest</TOKEN>
<TOKEN end_char="2048" id="token-11-4" morph="none" pos="word" start_char="2045">that</TOKEN>
<TOKEN end_char="2052" id="token-11-5" morph="none" pos="word" start_char="2050">the</TOKEN>
<TOKEN end_char="2063" id="token-11-6" morph="none" pos="word" start_char="2054">laboratory</TOKEN>
<TOKEN end_char="2073" id="token-11-7" morph="none" pos="word" start_char="2065">incidents</TOKEN>
<TOKEN end_char="2084" id="token-11-8" morph="none" pos="word" start_char="2075">hypothesis</TOKEN>
<TOKEN end_char="2087" id="token-11-9" morph="none" pos="word" start_char="2086">is</TOKEN>
<TOKEN end_char="2097" id="token-11-10" morph="none" pos="word" start_char="2089">extremely</TOKEN>
<TOKEN end_char="2106" id="token-11-11" morph="none" pos="word" start_char="2099">unlikely</TOKEN>
<TOKEN end_char="2109" id="token-11-12" morph="none" pos="word" start_char="2108">to</TOKEN>
<TOKEN end_char="2117" id="token-11-13" morph="none" pos="word" start_char="2111">explain</TOKEN>
<TOKEN end_char="2121" id="token-11-14" morph="none" pos="word" start_char="2119">the</TOKEN>
<TOKEN end_char="2134" id="token-11-15" morph="none" pos="word" start_char="2123">introduction</TOKEN>
<TOKEN end_char="2137" id="token-11-16" morph="none" pos="word" start_char="2136">of</TOKEN>
<TOKEN end_char="2141" id="token-11-17" morph="none" pos="word" start_char="2139">the</TOKEN>
<TOKEN end_char="2147" id="token-11-18" morph="none" pos="word" start_char="2143">virus</TOKEN>
<TOKEN end_char="2150" id="token-11-19" morph="none" pos="word" start_char="2149">to</TOKEN>
<TOKEN end_char="2154" id="token-11-20" morph="none" pos="word" start_char="2152">the</TOKEN>
<TOKEN end_char="2160" id="token-11-21" morph="none" pos="word" start_char="2156">human</TOKEN>
<TOKEN end_char="2171" id="token-11-22" morph="none" pos="word" start_char="2162">population</TOKEN>
<TOKEN end_char="2173" id="token-11-23" morph="none" pos="punct" start_char="2172">,"</TOKEN>
<TOKEN end_char="2176" id="token-11-24" morph="none" pos="word" start_char="2175">he</TOKEN>
<TOKEN end_char="2181" id="token-11-25" morph="none" pos="word" start_char="2178">said</TOKEN>
<TOKEN end_char="2182" id="token-11-26" morph="none" pos="punct" start_char="2182">.</TOKEN>
</SEG>
<SEG end_char="2372" id="segment-12" start_char="2185">
<ORIGINAL_TEXT>Asked why, Embarek said accidental releases are extremely rare and that the team’s review of the Wuhan institute’s lab operations indicated it would be hard for anything to escape from it.</ORIGINAL_TEXT>
<TOKEN end_char="2189" id="token-12-0" morph="none" pos="word" start_char="2185">Asked</TOKEN>
<TOKEN end_char="2193" id="token-12-1" morph="none" pos="word" start_char="2191">why</TOKEN>
<TOKEN end_char="2194" id="token-12-2" morph="none" pos="punct" start_char="2194">,</TOKEN>
<TOKEN end_char="2202" id="token-12-3" morph="none" pos="word" start_char="2196">Embarek</TOKEN>
<TOKEN end_char="2207" id="token-12-4" morph="none" pos="word" start_char="2204">said</TOKEN>
<TOKEN end_char="2218" id="token-12-5" morph="none" pos="word" start_char="2209">accidental</TOKEN>
<TOKEN end_char="2227" id="token-12-6" morph="none" pos="word" start_char="2220">releases</TOKEN>
<TOKEN end_char="2231" id="token-12-7" morph="none" pos="word" start_char="2229">are</TOKEN>
<TOKEN end_char="2241" id="token-12-8" morph="none" pos="word" start_char="2233">extremely</TOKEN>
<TOKEN end_char="2246" id="token-12-9" morph="none" pos="word" start_char="2243">rare</TOKEN>
<TOKEN end_char="2250" id="token-12-10" morph="none" pos="word" start_char="2248">and</TOKEN>
<TOKEN end_char="2255" id="token-12-11" morph="none" pos="word" start_char="2252">that</TOKEN>
<TOKEN end_char="2259" id="token-12-12" morph="none" pos="word" start_char="2257">the</TOKEN>
<TOKEN end_char="2266" id="token-12-13" morph="none" pos="word" start_char="2261">team’s</TOKEN>
<TOKEN end_char="2273" id="token-12-14" morph="none" pos="word" start_char="2268">review</TOKEN>
<TOKEN end_char="2276" id="token-12-15" morph="none" pos="word" start_char="2275">of</TOKEN>
<TOKEN end_char="2280" id="token-12-16" morph="none" pos="word" start_char="2278">the</TOKEN>
<TOKEN end_char="2286" id="token-12-17" morph="none" pos="word" start_char="2282">Wuhan</TOKEN>
<TOKEN end_char="2298" id="token-12-18" morph="none" pos="word" start_char="2288">institute’s</TOKEN>
<TOKEN end_char="2302" id="token-12-19" morph="none" pos="word" start_char="2300">lab</TOKEN>
<TOKEN end_char="2313" id="token-12-20" morph="none" pos="word" start_char="2304">operations</TOKEN>
<TOKEN end_char="2323" id="token-12-21" morph="none" pos="word" start_char="2315">indicated</TOKEN>
<TOKEN end_char="2326" id="token-12-22" morph="none" pos="word" start_char="2325">it</TOKEN>
<TOKEN end_char="2332" id="token-12-23" morph="none" pos="word" start_char="2328">would</TOKEN>
<TOKEN end_char="2335" id="token-12-24" morph="none" pos="word" start_char="2334">be</TOKEN>
<TOKEN end_char="2340" id="token-12-25" morph="none" pos="word" start_char="2337">hard</TOKEN>
<TOKEN end_char="2344" id="token-12-26" morph="none" pos="word" start_char="2342">for</TOKEN>
<TOKEN end_char="2353" id="token-12-27" morph="none" pos="word" start_char="2346">anything</TOKEN>
<TOKEN end_char="2356" id="token-12-28" morph="none" pos="word" start_char="2355">to</TOKEN>
<TOKEN end_char="2363" id="token-12-29" morph="none" pos="word" start_char="2358">escape</TOKEN>
<TOKEN end_char="2368" id="token-12-30" morph="none" pos="word" start_char="2365">from</TOKEN>
<TOKEN end_char="2371" id="token-12-31" morph="none" pos="word" start_char="2370">it</TOKEN>
<TOKEN end_char="2372" id="token-12-32" morph="none" pos="punct" start_char="2372">.</TOKEN>
</SEG>
<SEG end_char="2469" id="segment-13" start_char="2375">
<ORIGINAL_TEXT>He also noted that there were no reports of this virus in any lab anywhere before the pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="2376" id="token-13-0" morph="none" pos="word" start_char="2375">He</TOKEN>
<TOKEN end_char="2381" id="token-13-1" morph="none" pos="word" start_char="2378">also</TOKEN>
<TOKEN end_char="2387" id="token-13-2" morph="none" pos="word" start_char="2383">noted</TOKEN>
<TOKEN end_char="2392" id="token-13-3" morph="none" pos="word" start_char="2389">that</TOKEN>
<TOKEN end_char="2398" id="token-13-4" morph="none" pos="word" start_char="2394">there</TOKEN>
<TOKEN end_char="2403" id="token-13-5" morph="none" pos="word" start_char="2400">were</TOKEN>
<TOKEN end_char="2406" id="token-13-6" morph="none" pos="word" start_char="2405">no</TOKEN>
<TOKEN end_char="2414" id="token-13-7" morph="none" pos="word" start_char="2408">reports</TOKEN>
<TOKEN end_char="2417" id="token-13-8" morph="none" pos="word" start_char="2416">of</TOKEN>
<TOKEN end_char="2422" id="token-13-9" morph="none" pos="word" start_char="2419">this</TOKEN>
<TOKEN end_char="2428" id="token-13-10" morph="none" pos="word" start_char="2424">virus</TOKEN>
<TOKEN end_char="2431" id="token-13-11" morph="none" pos="word" start_char="2430">in</TOKEN>
<TOKEN end_char="2435" id="token-13-12" morph="none" pos="word" start_char="2433">any</TOKEN>
<TOKEN end_char="2439" id="token-13-13" morph="none" pos="word" start_char="2437">lab</TOKEN>
<TOKEN end_char="2448" id="token-13-14" morph="none" pos="word" start_char="2441">anywhere</TOKEN>
<TOKEN end_char="2455" id="token-13-15" morph="none" pos="word" start_char="2450">before</TOKEN>
<TOKEN end_char="2459" id="token-13-16" morph="none" pos="word" start_char="2457">the</TOKEN>
<TOKEN end_char="2468" id="token-13-17" morph="none" pos="word" start_char="2461">pandemic</TOKEN>
<TOKEN end_char="2469" id="token-13-18" morph="none" pos="punct" start_char="2469">.</TOKEN>
</SEG>
<SEG end_char="2593" id="segment-14" start_char="2471">
<ORIGINAL_TEXT>Liang Wannian, the head of the Chinese side, also emphasized that, saying there was no sample of it in the Wuhan institute.</ORIGINAL_TEXT>
<TOKEN end_char="2475" id="token-14-0" morph="none" pos="word" start_char="2471">Liang</TOKEN>
<TOKEN end_char="2483" id="token-14-1" morph="none" pos="word" start_char="2477">Wannian</TOKEN>
<TOKEN end_char="2484" id="token-14-2" morph="none" pos="punct" start_char="2484">,</TOKEN>
<TOKEN end_char="2488" id="token-14-3" morph="none" pos="word" start_char="2486">the</TOKEN>
<TOKEN end_char="2493" id="token-14-4" morph="none" pos="word" start_char="2490">head</TOKEN>
<TOKEN end_char="2496" id="token-14-5" morph="none" pos="word" start_char="2495">of</TOKEN>
<TOKEN end_char="2500" id="token-14-6" morph="none" pos="word" start_char="2498">the</TOKEN>
<TOKEN end_char="2508" id="token-14-7" morph="none" pos="word" start_char="2502">Chinese</TOKEN>
<TOKEN end_char="2513" id="token-14-8" morph="none" pos="word" start_char="2510">side</TOKEN>
<TOKEN end_char="2514" id="token-14-9" morph="none" pos="punct" start_char="2514">,</TOKEN>
<TOKEN end_char="2519" id="token-14-10" morph="none" pos="word" start_char="2516">also</TOKEN>
<TOKEN end_char="2530" id="token-14-11" morph="none" pos="word" start_char="2521">emphasized</TOKEN>
<TOKEN end_char="2535" id="token-14-12" morph="none" pos="word" start_char="2532">that</TOKEN>
<TOKEN end_char="2536" id="token-14-13" morph="none" pos="punct" start_char="2536">,</TOKEN>
<TOKEN end_char="2543" id="token-14-14" morph="none" pos="word" start_char="2538">saying</TOKEN>
<TOKEN end_char="2549" id="token-14-15" morph="none" pos="word" start_char="2545">there</TOKEN>
<TOKEN end_char="2553" id="token-14-16" morph="none" pos="word" start_char="2551">was</TOKEN>
<TOKEN end_char="2556" id="token-14-17" morph="none" pos="word" start_char="2555">no</TOKEN>
<TOKEN end_char="2563" id="token-14-18" morph="none" pos="word" start_char="2558">sample</TOKEN>
<TOKEN end_char="2566" id="token-14-19" morph="none" pos="word" start_char="2565">of</TOKEN>
<TOKEN end_char="2569" id="token-14-20" morph="none" pos="word" start_char="2568">it</TOKEN>
<TOKEN end_char="2572" id="token-14-21" morph="none" pos="word" start_char="2571">in</TOKEN>
<TOKEN end_char="2576" id="token-14-22" morph="none" pos="word" start_char="2574">the</TOKEN>
<TOKEN end_char="2582" id="token-14-23" morph="none" pos="word" start_char="2578">Wuhan</TOKEN>
<TOKEN end_char="2592" id="token-14-24" morph="none" pos="word" start_char="2584">institute</TOKEN>
<TOKEN end_char="2593" id="token-14-25" morph="none" pos="punct" start_char="2593">.</TOKEN>
</SEG>
<SEG end_char="2812" id="segment-15" start_char="2596">
<ORIGINAL_TEXT>The mission was intended to be an initial step in the process of understanding the origins of the virus, which scientists have posited may have passed to humans through a wild animal, such as a pangolin or bamboo rat.</ORIGINAL_TEXT>
<TOKEN end_char="2598" id="token-15-0" morph="none" pos="word" start_char="2596">The</TOKEN>
<TOKEN end_char="2606" id="token-15-1" morph="none" pos="word" start_char="2600">mission</TOKEN>
<TOKEN end_char="2610" id="token-15-2" morph="none" pos="word" start_char="2608">was</TOKEN>
<TOKEN end_char="2619" id="token-15-3" morph="none" pos="word" start_char="2612">intended</TOKEN>
<TOKEN end_char="2622" id="token-15-4" morph="none" pos="word" start_char="2621">to</TOKEN>
<TOKEN end_char="2625" id="token-15-5" morph="none" pos="word" start_char="2624">be</TOKEN>
<TOKEN end_char="2628" id="token-15-6" morph="none" pos="word" start_char="2627">an</TOKEN>
<TOKEN end_char="2636" id="token-15-7" morph="none" pos="word" start_char="2630">initial</TOKEN>
<TOKEN end_char="2641" id="token-15-8" morph="none" pos="word" start_char="2638">step</TOKEN>
<TOKEN end_char="2644" id="token-15-9" morph="none" pos="word" start_char="2643">in</TOKEN>
<TOKEN end_char="2648" id="token-15-10" morph="none" pos="word" start_char="2646">the</TOKEN>
<TOKEN end_char="2656" id="token-15-11" morph="none" pos="word" start_char="2650">process</TOKEN>
<TOKEN end_char="2659" id="token-15-12" morph="none" pos="word" start_char="2658">of</TOKEN>
<TOKEN end_char="2673" id="token-15-13" morph="none" pos="word" start_char="2661">understanding</TOKEN>
<TOKEN end_char="2677" id="token-15-14" morph="none" pos="word" start_char="2675">the</TOKEN>
<TOKEN end_char="2685" id="token-15-15" morph="none" pos="word" start_char="2679">origins</TOKEN>
<TOKEN end_char="2688" id="token-15-16" morph="none" pos="word" start_char="2687">of</TOKEN>
<TOKEN end_char="2692" id="token-15-17" morph="none" pos="word" start_char="2690">the</TOKEN>
<TOKEN end_char="2698" id="token-15-18" morph="none" pos="word" start_char="2694">virus</TOKEN>
<TOKEN end_char="2699" id="token-15-19" morph="none" pos="punct" start_char="2699">,</TOKEN>
<TOKEN end_char="2705" id="token-15-20" morph="none" pos="word" start_char="2701">which</TOKEN>
<TOKEN end_char="2716" id="token-15-21" morph="none" pos="word" start_char="2707">scientists</TOKEN>
<TOKEN end_char="2721" id="token-15-22" morph="none" pos="word" start_char="2718">have</TOKEN>
<TOKEN end_char="2729" id="token-15-23" morph="none" pos="word" start_char="2723">posited</TOKEN>
<TOKEN end_char="2733" id="token-15-24" morph="none" pos="word" start_char="2731">may</TOKEN>
<TOKEN end_char="2738" id="token-15-25" morph="none" pos="word" start_char="2735">have</TOKEN>
<TOKEN end_char="2745" id="token-15-26" morph="none" pos="word" start_char="2740">passed</TOKEN>
<TOKEN end_char="2748" id="token-15-27" morph="none" pos="word" start_char="2747">to</TOKEN>
<TOKEN end_char="2755" id="token-15-28" morph="none" pos="word" start_char="2750">humans</TOKEN>
<TOKEN end_char="2763" id="token-15-29" morph="none" pos="word" start_char="2757">through</TOKEN>
<TOKEN end_char="2765" id="token-15-30" morph="none" pos="word" start_char="2765">a</TOKEN>
<TOKEN end_char="2770" id="token-15-31" morph="none" pos="word" start_char="2767">wild</TOKEN>
<TOKEN end_char="2777" id="token-15-32" morph="none" pos="word" start_char="2772">animal</TOKEN>
<TOKEN end_char="2778" id="token-15-33" morph="none" pos="punct" start_char="2778">,</TOKEN>
<TOKEN end_char="2783" id="token-15-34" morph="none" pos="word" start_char="2780">such</TOKEN>
<TOKEN end_char="2786" id="token-15-35" morph="none" pos="word" start_char="2785">as</TOKEN>
<TOKEN end_char="2788" id="token-15-36" morph="none" pos="word" start_char="2788">a</TOKEN>
<TOKEN end_char="2797" id="token-15-37" morph="none" pos="word" start_char="2790">pangolin</TOKEN>
<TOKEN end_char="2800" id="token-15-38" morph="none" pos="word" start_char="2799">or</TOKEN>
<TOKEN end_char="2807" id="token-15-39" morph="none" pos="word" start_char="2802">bamboo</TOKEN>
<TOKEN end_char="2811" id="token-15-40" morph="none" pos="word" start_char="2809">rat</TOKEN>
<TOKEN end_char="2812" id="token-15-41" morph="none" pos="punct" start_char="2812">.</TOKEN>
</SEG>
<SEG end_char="2937" id="segment-16" start_char="2814">
<ORIGINAL_TEXT>Transmission directly from bats to humans or through the trade in frozen food products are also possibilities, Embarek said.</ORIGINAL_TEXT>
<TOKEN end_char="2825" id="token-16-0" morph="none" pos="word" start_char="2814">Transmission</TOKEN>
<TOKEN end_char="2834" id="token-16-1" morph="none" pos="word" start_char="2827">directly</TOKEN>
<TOKEN end_char="2839" id="token-16-2" morph="none" pos="word" start_char="2836">from</TOKEN>
<TOKEN end_char="2844" id="token-16-3" morph="none" pos="word" start_char="2841">bats</TOKEN>
<TOKEN end_char="2847" id="token-16-4" morph="none" pos="word" start_char="2846">to</TOKEN>
<TOKEN end_char="2854" id="token-16-5" morph="none" pos="word" start_char="2849">humans</TOKEN>
<TOKEN end_char="2857" id="token-16-6" morph="none" pos="word" start_char="2856">or</TOKEN>
<TOKEN end_char="2865" id="token-16-7" morph="none" pos="word" start_char="2859">through</TOKEN>
<TOKEN end_char="2869" id="token-16-8" morph="none" pos="word" start_char="2867">the</TOKEN>
<TOKEN end_char="2875" id="token-16-9" morph="none" pos="word" start_char="2871">trade</TOKEN>
<TOKEN end_char="2878" id="token-16-10" morph="none" pos="word" start_char="2877">in</TOKEN>
<TOKEN end_char="2885" id="token-16-11" morph="none" pos="word" start_char="2880">frozen</TOKEN>
<TOKEN end_char="2890" id="token-16-12" morph="none" pos="word" start_char="2887">food</TOKEN>
<TOKEN end_char="2899" id="token-16-13" morph="none" pos="word" start_char="2892">products</TOKEN>
<TOKEN end_char="2903" id="token-16-14" morph="none" pos="word" start_char="2901">are</TOKEN>
<TOKEN end_char="2908" id="token-16-15" morph="none" pos="word" start_char="2905">also</TOKEN>
<TOKEN end_char="2922" id="token-16-16" morph="none" pos="word" start_char="2910">possibilities</TOKEN>
<TOKEN end_char="2923" id="token-16-17" morph="none" pos="punct" start_char="2923">,</TOKEN>
<TOKEN end_char="2931" id="token-16-18" morph="none" pos="word" start_char="2925">Embarek</TOKEN>
<TOKEN end_char="2936" id="token-16-19" morph="none" pos="word" start_char="2933">said</TOKEN>
<TOKEN end_char="2937" id="token-16-20" morph="none" pos="punct" start_char="2937">.</TOKEN>
</SEG>
<SEG end_char="3095" id="segment-17" start_char="2940">
<ORIGINAL_TEXT>The WHO team’s visit is politically sensitive for Beijing, which is concerned about being blamed for alleged missteps in its early response to the outbreak.</ORIGINAL_TEXT>
<TOKEN end_char="2942" id="token-17-0" morph="none" pos="word" start_char="2940">The</TOKEN>
<TOKEN end_char="2946" id="token-17-1" morph="none" pos="word" start_char="2944">WHO</TOKEN>
<TOKEN end_char="2953" id="token-17-2" morph="none" pos="word" start_char="2948">team’s</TOKEN>
<TOKEN end_char="2959" id="token-17-3" morph="none" pos="word" start_char="2955">visit</TOKEN>
<TOKEN end_char="2962" id="token-17-4" morph="none" pos="word" start_char="2961">is</TOKEN>
<TOKEN end_char="2974" id="token-17-5" morph="none" pos="word" start_char="2964">politically</TOKEN>
<TOKEN end_char="2984" id="token-17-6" morph="none" pos="word" start_char="2976">sensitive</TOKEN>
<TOKEN end_char="2988" id="token-17-7" morph="none" pos="word" start_char="2986">for</TOKEN>
<TOKEN end_char="2996" id="token-17-8" morph="none" pos="word" start_char="2990">Beijing</TOKEN>
<TOKEN end_char="2997" id="token-17-9" morph="none" pos="punct" start_char="2997">,</TOKEN>
<TOKEN end_char="3003" id="token-17-10" morph="none" pos="word" start_char="2999">which</TOKEN>
<TOKEN end_char="3006" id="token-17-11" morph="none" pos="word" start_char="3005">is</TOKEN>
<TOKEN end_char="3016" id="token-17-12" morph="none" pos="word" start_char="3008">concerned</TOKEN>
<TOKEN end_char="3022" id="token-17-13" morph="none" pos="word" start_char="3018">about</TOKEN>
<TOKEN end_char="3028" id="token-17-14" morph="none" pos="word" start_char="3024">being</TOKEN>
<TOKEN end_char="3035" id="token-17-15" morph="none" pos="word" start_char="3030">blamed</TOKEN>
<TOKEN end_char="3039" id="token-17-16" morph="none" pos="word" start_char="3037">for</TOKEN>
<TOKEN end_char="3047" id="token-17-17" morph="none" pos="word" start_char="3041">alleged</TOKEN>
<TOKEN end_char="3056" id="token-17-18" morph="none" pos="word" start_char="3049">missteps</TOKEN>
<TOKEN end_char="3059" id="token-17-19" morph="none" pos="word" start_char="3058">in</TOKEN>
<TOKEN end_char="3063" id="token-17-20" morph="none" pos="word" start_char="3061">its</TOKEN>
<TOKEN end_char="3069" id="token-17-21" morph="none" pos="word" start_char="3065">early</TOKEN>
<TOKEN end_char="3078" id="token-17-22" morph="none" pos="word" start_char="3071">response</TOKEN>
<TOKEN end_char="3081" id="token-17-23" morph="none" pos="word" start_char="3080">to</TOKEN>
<TOKEN end_char="3085" id="token-17-24" morph="none" pos="word" start_char="3083">the</TOKEN>
<TOKEN end_char="3094" id="token-17-25" morph="none" pos="word" start_char="3087">outbreak</TOKEN>
<TOKEN end_char="3095" id="token-17-26" morph="none" pos="punct" start_char="3095">.</TOKEN>
</SEG>
<SEG end_char="3244" id="segment-18" start_char="3097">
<ORIGINAL_TEXT>An AP investigation has found that the Chinese government put limits on research into the outbreak and ordered scientists not to speak to reporters.</ORIGINAL_TEXT>
<TOKEN end_char="3098" id="token-18-0" morph="none" pos="word" start_char="3097">An</TOKEN>
<TOKEN end_char="3101" id="token-18-1" morph="none" pos="word" start_char="3100">AP</TOKEN>
<TOKEN end_char="3115" id="token-18-2" morph="none" pos="word" start_char="3103">investigation</TOKEN>
<TOKEN end_char="3119" id="token-18-3" morph="none" pos="word" start_char="3117">has</TOKEN>
<TOKEN end_char="3125" id="token-18-4" morph="none" pos="word" start_char="3121">found</TOKEN>
<TOKEN end_char="3130" id="token-18-5" morph="none" pos="word" start_char="3127">that</TOKEN>
<TOKEN end_char="3134" id="token-18-6" morph="none" pos="word" start_char="3132">the</TOKEN>
<TOKEN end_char="3142" id="token-18-7" morph="none" pos="word" start_char="3136">Chinese</TOKEN>
<TOKEN end_char="3153" id="token-18-8" morph="none" pos="word" start_char="3144">government</TOKEN>
<TOKEN end_char="3157" id="token-18-9" morph="none" pos="word" start_char="3155">put</TOKEN>
<TOKEN end_char="3164" id="token-18-10" morph="none" pos="word" start_char="3159">limits</TOKEN>
<TOKEN end_char="3167" id="token-18-11" morph="none" pos="word" start_char="3166">on</TOKEN>
<TOKEN end_char="3176" id="token-18-12" morph="none" pos="word" start_char="3169">research</TOKEN>
<TOKEN end_char="3181" id="token-18-13" morph="none" pos="word" start_char="3178">into</TOKEN>
<TOKEN end_char="3185" id="token-18-14" morph="none" pos="word" start_char="3183">the</TOKEN>
<TOKEN end_char="3194" id="token-18-15" morph="none" pos="word" start_char="3187">outbreak</TOKEN>
<TOKEN end_char="3198" id="token-18-16" morph="none" pos="word" start_char="3196">and</TOKEN>
<TOKEN end_char="3206" id="token-18-17" morph="none" pos="word" start_char="3200">ordered</TOKEN>
<TOKEN end_char="3217" id="token-18-18" morph="none" pos="word" start_char="3208">scientists</TOKEN>
<TOKEN end_char="3221" id="token-18-19" morph="none" pos="word" start_char="3219">not</TOKEN>
<TOKEN end_char="3224" id="token-18-20" morph="none" pos="word" start_char="3223">to</TOKEN>
<TOKEN end_char="3230" id="token-18-21" morph="none" pos="word" start_char="3226">speak</TOKEN>
<TOKEN end_char="3233" id="token-18-22" morph="none" pos="word" start_char="3232">to</TOKEN>
<TOKEN end_char="3243" id="token-18-23" morph="none" pos="word" start_char="3235">reporters</TOKEN>
<TOKEN end_char="3244" id="token-18-24" morph="none" pos="punct" start_char="3244">.</TOKEN>
</SEG>
<SEG end_char="3508" id="segment-19" start_char="3247">
<ORIGINAL_TEXT>Still, one member of the WHO team, British-born zoologist Peter Daszak, told The Associated Press last week that they enjoyed a greater level of openness than they had anticipated, and that they were granted full access to all sites and personnel they requested.</ORIGINAL_TEXT>
<TOKEN end_char="3251" id="token-19-0" morph="none" pos="word" start_char="3247">Still</TOKEN>
<TOKEN end_char="3252" id="token-19-1" morph="none" pos="punct" start_char="3252">,</TOKEN>
<TOKEN end_char="3256" id="token-19-2" morph="none" pos="word" start_char="3254">one</TOKEN>
<TOKEN end_char="3263" id="token-19-3" morph="none" pos="word" start_char="3258">member</TOKEN>
<TOKEN end_char="3266" id="token-19-4" morph="none" pos="word" start_char="3265">of</TOKEN>
<TOKEN end_char="3270" id="token-19-5" morph="none" pos="word" start_char="3268">the</TOKEN>
<TOKEN end_char="3274" id="token-19-6" morph="none" pos="word" start_char="3272">WHO</TOKEN>
<TOKEN end_char="3279" id="token-19-7" morph="none" pos="word" start_char="3276">team</TOKEN>
<TOKEN end_char="3280" id="token-19-8" morph="none" pos="punct" start_char="3280">,</TOKEN>
<TOKEN end_char="3293" id="token-19-9" morph="none" pos="unknown" start_char="3282">British-born</TOKEN>
<TOKEN end_char="3303" id="token-19-10" morph="none" pos="word" start_char="3295">zoologist</TOKEN>
<TOKEN end_char="3309" id="token-19-11" morph="none" pos="word" start_char="3305">Peter</TOKEN>
<TOKEN end_char="3316" id="token-19-12" morph="none" pos="word" start_char="3311">Daszak</TOKEN>
<TOKEN end_char="3317" id="token-19-13" morph="none" pos="punct" start_char="3317">,</TOKEN>
<TOKEN end_char="3322" id="token-19-14" morph="none" pos="word" start_char="3319">told</TOKEN>
<TOKEN end_char="3326" id="token-19-15" morph="none" pos="word" start_char="3324">The</TOKEN>
<TOKEN end_char="3337" id="token-19-16" morph="none" pos="word" start_char="3328">Associated</TOKEN>
<TOKEN end_char="3343" id="token-19-17" morph="none" pos="word" start_char="3339">Press</TOKEN>
<TOKEN end_char="3348" id="token-19-18" morph="none" pos="word" start_char="3345">last</TOKEN>
<TOKEN end_char="3353" id="token-19-19" morph="none" pos="word" start_char="3350">week</TOKEN>
<TOKEN end_char="3358" id="token-19-20" morph="none" pos="word" start_char="3355">that</TOKEN>
<TOKEN end_char="3363" id="token-19-21" morph="none" pos="word" start_char="3360">they</TOKEN>
<TOKEN end_char="3371" id="token-19-22" morph="none" pos="word" start_char="3365">enjoyed</TOKEN>
<TOKEN end_char="3373" id="token-19-23" morph="none" pos="word" start_char="3373">a</TOKEN>
<TOKEN end_char="3381" id="token-19-24" morph="none" pos="word" start_char="3375">greater</TOKEN>
<TOKEN end_char="3387" id="token-19-25" morph="none" pos="word" start_char="3383">level</TOKEN>
<TOKEN end_char="3390" id="token-19-26" morph="none" pos="word" start_char="3389">of</TOKEN>
<TOKEN end_char="3399" id="token-19-27" morph="none" pos="word" start_char="3392">openness</TOKEN>
<TOKEN end_char="3404" id="token-19-28" morph="none" pos="word" start_char="3401">than</TOKEN>
<TOKEN end_char="3409" id="token-19-29" morph="none" pos="word" start_char="3406">they</TOKEN>
<TOKEN end_char="3413" id="token-19-30" morph="none" pos="word" start_char="3411">had</TOKEN>
<TOKEN end_char="3425" id="token-19-31" morph="none" pos="word" start_char="3415">anticipated</TOKEN>
<TOKEN end_char="3426" id="token-19-32" morph="none" pos="punct" start_char="3426">,</TOKEN>
<TOKEN end_char="3430" id="token-19-33" morph="none" pos="word" start_char="3428">and</TOKEN>
<TOKEN end_char="3435" id="token-19-34" morph="none" pos="word" start_char="3432">that</TOKEN>
<TOKEN end_char="3440" id="token-19-35" morph="none" pos="word" start_char="3437">they</TOKEN>
<TOKEN end_char="3445" id="token-19-36" morph="none" pos="word" start_char="3442">were</TOKEN>
<TOKEN end_char="3453" id="token-19-37" morph="none" pos="word" start_char="3447">granted</TOKEN>
<TOKEN end_char="3458" id="token-19-38" morph="none" pos="word" start_char="3455">full</TOKEN>
<TOKEN end_char="3465" id="token-19-39" morph="none" pos="word" start_char="3460">access</TOKEN>
<TOKEN end_char="3468" id="token-19-40" morph="none" pos="word" start_char="3467">to</TOKEN>
<TOKEN end_char="3472" id="token-19-41" morph="none" pos="word" start_char="3470">all</TOKEN>
<TOKEN end_char="3478" id="token-19-42" morph="none" pos="word" start_char="3474">sites</TOKEN>
<TOKEN end_char="3482" id="token-19-43" morph="none" pos="word" start_char="3480">and</TOKEN>
<TOKEN end_char="3492" id="token-19-44" morph="none" pos="word" start_char="3484">personnel</TOKEN>
<TOKEN end_char="3497" id="token-19-45" morph="none" pos="word" start_char="3494">they</TOKEN>
<TOKEN end_char="3507" id="token-19-46" morph="none" pos="word" start_char="3499">requested</TOKEN>
<TOKEN end_char="3508" id="token-19-47" morph="none" pos="punct" start_char="3508">.</TOKEN>
</SEG>
<SEG end_char="3636" id="segment-20" start_char="3511">
<ORIGINAL_TEXT>Koelsen Fischer said she did not get to see the raw data and had to rely on an analysis of the data that was presented to her.</ORIGINAL_TEXT>
<TOKEN end_char="3517" id="token-20-0" morph="none" pos="word" start_char="3511">Koelsen</TOKEN>
<TOKEN end_char="3525" id="token-20-1" morph="none" pos="word" start_char="3519">Fischer</TOKEN>
<TOKEN end_char="3530" id="token-20-2" morph="none" pos="word" start_char="3527">said</TOKEN>
<TOKEN end_char="3534" id="token-20-3" morph="none" pos="word" start_char="3532">she</TOKEN>
<TOKEN end_char="3538" id="token-20-4" morph="none" pos="word" start_char="3536">did</TOKEN>
<TOKEN end_char="3542" id="token-20-5" morph="none" pos="word" start_char="3540">not</TOKEN>
<TOKEN end_char="3546" id="token-20-6" morph="none" pos="word" start_char="3544">get</TOKEN>
<TOKEN end_char="3549" id="token-20-7" morph="none" pos="word" start_char="3548">to</TOKEN>
<TOKEN end_char="3553" id="token-20-8" morph="none" pos="word" start_char="3551">see</TOKEN>
<TOKEN end_char="3557" id="token-20-9" morph="none" pos="word" start_char="3555">the</TOKEN>
<TOKEN end_char="3561" id="token-20-10" morph="none" pos="word" start_char="3559">raw</TOKEN>
<TOKEN end_char="3566" id="token-20-11" morph="none" pos="word" start_char="3563">data</TOKEN>
<TOKEN end_char="3570" id="token-20-12" morph="none" pos="word" start_char="3568">and</TOKEN>
<TOKEN end_char="3574" id="token-20-13" morph="none" pos="word" start_char="3572">had</TOKEN>
<TOKEN end_char="3577" id="token-20-14" morph="none" pos="word" start_char="3576">to</TOKEN>
<TOKEN end_char="3582" id="token-20-15" morph="none" pos="word" start_char="3579">rely</TOKEN>
<TOKEN end_char="3585" id="token-20-16" morph="none" pos="word" start_char="3584">on</TOKEN>
<TOKEN end_char="3588" id="token-20-17" morph="none" pos="word" start_char="3587">an</TOKEN>
<TOKEN end_char="3597" id="token-20-18" morph="none" pos="word" start_char="3590">analysis</TOKEN>
<TOKEN end_char="3600" id="token-20-19" morph="none" pos="word" start_char="3599">of</TOKEN>
<TOKEN end_char="3604" id="token-20-20" morph="none" pos="word" start_char="3602">the</TOKEN>
<TOKEN end_char="3609" id="token-20-21" morph="none" pos="word" start_char="3606">data</TOKEN>
<TOKEN end_char="3614" id="token-20-22" morph="none" pos="word" start_char="3611">that</TOKEN>
<TOKEN end_char="3618" id="token-20-23" morph="none" pos="word" start_char="3616">was</TOKEN>
<TOKEN end_char="3628" id="token-20-24" morph="none" pos="word" start_char="3620">presented</TOKEN>
<TOKEN end_char="3631" id="token-20-25" morph="none" pos="word" start_char="3630">to</TOKEN>
<TOKEN end_char="3635" id="token-20-26" morph="none" pos="word" start_char="3633">her</TOKEN>
<TOKEN end_char="3636" id="token-20-27" morph="none" pos="punct" start_char="3636">.</TOKEN>
</SEG>
<SEG end_char="3687" id="segment-21" start_char="3638">
<ORIGINAL_TEXT>But she said that would be true in most countries.</ORIGINAL_TEXT>
<TOKEN end_char="3640" id="token-21-0" morph="none" pos="word" start_char="3638">But</TOKEN>
<TOKEN end_char="3644" id="token-21-1" morph="none" pos="word" start_char="3642">she</TOKEN>
<TOKEN end_char="3649" id="token-21-2" morph="none" pos="word" start_char="3646">said</TOKEN>
<TOKEN end_char="3654" id="token-21-3" morph="none" pos="word" start_char="3651">that</TOKEN>
<TOKEN end_char="3660" id="token-21-4" morph="none" pos="word" start_char="3656">would</TOKEN>
<TOKEN end_char="3663" id="token-21-5" morph="none" pos="word" start_char="3662">be</TOKEN>
<TOKEN end_char="3668" id="token-21-6" morph="none" pos="word" start_char="3665">true</TOKEN>
<TOKEN end_char="3671" id="token-21-7" morph="none" pos="word" start_char="3670">in</TOKEN>
<TOKEN end_char="3676" id="token-21-8" morph="none" pos="word" start_char="3673">most</TOKEN>
<TOKEN end_char="3686" id="token-21-9" morph="none" pos="word" start_char="3678">countries</TOKEN>
<TOKEN end_char="3687" id="token-21-10" morph="none" pos="punct" start_char="3687">.</TOKEN>
</SEG>
<SEG end_char="3760" id="segment-22" start_char="3690">
<ORIGINAL_TEXT>The team — which includes experts from 10 countries who arrived on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="3692" id="token-22-0" morph="none" pos="word" start_char="3690">The</TOKEN>
<TOKEN end_char="3697" id="token-22-1" morph="none" pos="word" start_char="3694">team</TOKEN>
<TOKEN end_char="3699" id="token-22-2" morph="none" pos="punct" start_char="3699">—</TOKEN>
<TOKEN end_char="3705" id="token-22-3" morph="none" pos="word" start_char="3701">which</TOKEN>
<TOKEN end_char="3714" id="token-22-4" morph="none" pos="word" start_char="3707">includes</TOKEN>
<TOKEN end_char="3722" id="token-22-5" morph="none" pos="word" start_char="3716">experts</TOKEN>
<TOKEN end_char="3727" id="token-22-6" morph="none" pos="word" start_char="3724">from</TOKEN>
<TOKEN end_char="3730" id="token-22-7" morph="none" pos="word" start_char="3729">10</TOKEN>
<TOKEN end_char="3740" id="token-22-8" morph="none" pos="word" start_char="3732">countries</TOKEN>
<TOKEN end_char="3744" id="token-22-9" morph="none" pos="word" start_char="3742">who</TOKEN>
<TOKEN end_char="3752" id="token-22-10" morph="none" pos="word" start_char="3746">arrived</TOKEN>
<TOKEN end_char="3755" id="token-22-11" morph="none" pos="word" start_char="3754">on</TOKEN>
<TOKEN end_char="3759" id="token-22-12" morph="none" pos="word" start_char="3757">Jan</TOKEN>
<TOKEN end_char="3760" id="token-22-13" morph="none" pos="punct" start_char="3760">.</TOKEN>
</SEG>
<SEG end_char="3852" id="segment-23" start_char="3762">
<ORIGINAL_TEXT>14 — visited the Huanan Seafood Market, the site of an early cluster of cases in late 2019.</ORIGINAL_TEXT>
<TOKEN end_char="3763" id="token-23-0" morph="none" pos="word" start_char="3762">14</TOKEN>
<TOKEN end_char="3765" id="token-23-1" morph="none" pos="punct" start_char="3765">—</TOKEN>
<TOKEN end_char="3773" id="token-23-2" morph="none" pos="word" start_char="3767">visited</TOKEN>
<TOKEN end_char="3777" id="token-23-3" morph="none" pos="word" start_char="3775">the</TOKEN>
<TOKEN end_char="3784" id="token-23-4" morph="none" pos="word" start_char="3779">Huanan</TOKEN>
<TOKEN end_char="3792" id="token-23-5" morph="none" pos="word" start_char="3786">Seafood</TOKEN>
<TOKEN end_char="3799" id="token-23-6" morph="none" pos="word" start_char="3794">Market</TOKEN>
<TOKEN end_char="3800" id="token-23-7" morph="none" pos="punct" start_char="3800">,</TOKEN>
<TOKEN end_char="3804" id="token-23-8" morph="none" pos="word" start_char="3802">the</TOKEN>
<TOKEN end_char="3809" id="token-23-9" morph="none" pos="word" start_char="3806">site</TOKEN>
<TOKEN end_char="3812" id="token-23-10" morph="none" pos="word" start_char="3811">of</TOKEN>
<TOKEN end_char="3815" id="token-23-11" morph="none" pos="word" start_char="3814">an</TOKEN>
<TOKEN end_char="3821" id="token-23-12" morph="none" pos="word" start_char="3817">early</TOKEN>
<TOKEN end_char="3829" id="token-23-13" morph="none" pos="word" start_char="3823">cluster</TOKEN>
<TOKEN end_char="3832" id="token-23-14" morph="none" pos="word" start_char="3831">of</TOKEN>
<TOKEN end_char="3838" id="token-23-15" morph="none" pos="word" start_char="3834">cases</TOKEN>
<TOKEN end_char="3841" id="token-23-16" morph="none" pos="word" start_char="3840">in</TOKEN>
<TOKEN end_char="3846" id="token-23-17" morph="none" pos="word" start_char="3843">late</TOKEN>
<TOKEN end_char="3851" id="token-23-18" morph="none" pos="word" start_char="3848">2019</TOKEN>
<TOKEN end_char="3852" id="token-23-19" morph="none" pos="punct" start_char="3852">.</TOKEN>
</SEG>
<SEG end_char="4036" id="segment-24" start_char="3855">
<ORIGINAL_TEXT>Marion Koopmans, a Dutch virologist on the team, said that some animals at the market were susceptible or suspected to be susceptible to the virus, including rabbits and bamboo rats.</ORIGINAL_TEXT>
<TOKEN end_char="3860" id="token-24-0" morph="none" pos="word" start_char="3855">Marion</TOKEN>
<TOKEN end_char="3869" id="token-24-1" morph="none" pos="word" start_char="3862">Koopmans</TOKEN>
<TOKEN end_char="3870" id="token-24-2" morph="none" pos="punct" start_char="3870">,</TOKEN>
<TOKEN end_char="3872" id="token-24-3" morph="none" pos="word" start_char="3872">a</TOKEN>
<TOKEN end_char="3878" id="token-24-4" morph="none" pos="word" start_char="3874">Dutch</TOKEN>
<TOKEN end_char="3889" id="token-24-5" morph="none" pos="word" start_char="3880">virologist</TOKEN>
<TOKEN end_char="3892" id="token-24-6" morph="none" pos="word" start_char="3891">on</TOKEN>
<TOKEN end_char="3896" id="token-24-7" morph="none" pos="word" start_char="3894">the</TOKEN>
<TOKEN end_char="3901" id="token-24-8" morph="none" pos="word" start_char="3898">team</TOKEN>
<TOKEN end_char="3902" id="token-24-9" morph="none" pos="punct" start_char="3902">,</TOKEN>
<TOKEN end_char="3907" id="token-24-10" morph="none" pos="word" start_char="3904">said</TOKEN>
<TOKEN end_char="3912" id="token-24-11" morph="none" pos="word" start_char="3909">that</TOKEN>
<TOKEN end_char="3917" id="token-24-12" morph="none" pos="word" start_char="3914">some</TOKEN>
<TOKEN end_char="3925" id="token-24-13" morph="none" pos="word" start_char="3919">animals</TOKEN>
<TOKEN end_char="3928" id="token-24-14" morph="none" pos="word" start_char="3927">at</TOKEN>
<TOKEN end_char="3932" id="token-24-15" morph="none" pos="word" start_char="3930">the</TOKEN>
<TOKEN end_char="3939" id="token-24-16" morph="none" pos="word" start_char="3934">market</TOKEN>
<TOKEN end_char="3944" id="token-24-17" morph="none" pos="word" start_char="3941">were</TOKEN>
<TOKEN end_char="3956" id="token-24-18" morph="none" pos="word" start_char="3946">susceptible</TOKEN>
<TOKEN end_char="3959" id="token-24-19" morph="none" pos="word" start_char="3958">or</TOKEN>
<TOKEN end_char="3969" id="token-24-20" morph="none" pos="word" start_char="3961">suspected</TOKEN>
<TOKEN end_char="3972" id="token-24-21" morph="none" pos="word" start_char="3971">to</TOKEN>
<TOKEN end_char="3975" id="token-24-22" morph="none" pos="word" start_char="3974">be</TOKEN>
<TOKEN end_char="3987" id="token-24-23" morph="none" pos="word" start_char="3977">susceptible</TOKEN>
<TOKEN end_char="3990" id="token-24-24" morph="none" pos="word" start_char="3989">to</TOKEN>
<TOKEN end_char="3994" id="token-24-25" morph="none" pos="word" start_char="3992">the</TOKEN>
<TOKEN end_char="4000" id="token-24-26" morph="none" pos="word" start_char="3996">virus</TOKEN>
<TOKEN end_char="4001" id="token-24-27" morph="none" pos="punct" start_char="4001">,</TOKEN>
<TOKEN end_char="4011" id="token-24-28" morph="none" pos="word" start_char="4003">including</TOKEN>
<TOKEN end_char="4019" id="token-24-29" morph="none" pos="word" start_char="4013">rabbits</TOKEN>
<TOKEN end_char="4023" id="token-24-30" morph="none" pos="word" start_char="4021">and</TOKEN>
<TOKEN end_char="4030" id="token-24-31" morph="none" pos="word" start_char="4025">bamboo</TOKEN>
<TOKEN end_char="4035" id="token-24-32" morph="none" pos="word" start_char="4032">rats</TOKEN>
<TOKEN end_char="4036" id="token-24-33" morph="none" pos="punct" start_char="4036">.</TOKEN>
</SEG>
<SEG end_char="4188" id="segment-25" start_char="4038">
<ORIGINAL_TEXT>And some could be traced to farms or traders in regions that are home to the bats that carry the closest related virus to the one that causes COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="4040" id="token-25-0" morph="none" pos="word" start_char="4038">And</TOKEN>
<TOKEN end_char="4045" id="token-25-1" morph="none" pos="word" start_char="4042">some</TOKEN>
<TOKEN end_char="4051" id="token-25-2" morph="none" pos="word" start_char="4047">could</TOKEN>
<TOKEN end_char="4054" id="token-25-3" morph="none" pos="word" start_char="4053">be</TOKEN>
<TOKEN end_char="4061" id="token-25-4" morph="none" pos="word" start_char="4056">traced</TOKEN>
<TOKEN end_char="4064" id="token-25-5" morph="none" pos="word" start_char="4063">to</TOKEN>
<TOKEN end_char="4070" id="token-25-6" morph="none" pos="word" start_char="4066">farms</TOKEN>
<TOKEN end_char="4073" id="token-25-7" morph="none" pos="word" start_char="4072">or</TOKEN>
<TOKEN end_char="4081" id="token-25-8" morph="none" pos="word" start_char="4075">traders</TOKEN>
<TOKEN end_char="4084" id="token-25-9" morph="none" pos="word" start_char="4083">in</TOKEN>
<TOKEN end_char="4092" id="token-25-10" morph="none" pos="word" start_char="4086">regions</TOKEN>
<TOKEN end_char="4097" id="token-25-11" morph="none" pos="word" start_char="4094">that</TOKEN>
<TOKEN end_char="4101" id="token-25-12" morph="none" pos="word" start_char="4099">are</TOKEN>
<TOKEN end_char="4106" id="token-25-13" morph="none" pos="word" start_char="4103">home</TOKEN>
<TOKEN end_char="4109" id="token-25-14" morph="none" pos="word" start_char="4108">to</TOKEN>
<TOKEN end_char="4113" id="token-25-15" morph="none" pos="word" start_char="4111">the</TOKEN>
<TOKEN end_char="4118" id="token-25-16" morph="none" pos="word" start_char="4115">bats</TOKEN>
<TOKEN end_char="4123" id="token-25-17" morph="none" pos="word" start_char="4120">that</TOKEN>
<TOKEN end_char="4129" id="token-25-18" morph="none" pos="word" start_char="4125">carry</TOKEN>
<TOKEN end_char="4133" id="token-25-19" morph="none" pos="word" start_char="4131">the</TOKEN>
<TOKEN end_char="4141" id="token-25-20" morph="none" pos="word" start_char="4135">closest</TOKEN>
<TOKEN end_char="4149" id="token-25-21" morph="none" pos="word" start_char="4143">related</TOKEN>
<TOKEN end_char="4155" id="token-25-22" morph="none" pos="word" start_char="4151">virus</TOKEN>
<TOKEN end_char="4158" id="token-25-23" morph="none" pos="word" start_char="4157">to</TOKEN>
<TOKEN end_char="4162" id="token-25-24" morph="none" pos="word" start_char="4160">the</TOKEN>
<TOKEN end_char="4166" id="token-25-25" morph="none" pos="word" start_char="4164">one</TOKEN>
<TOKEN end_char="4171" id="token-25-26" morph="none" pos="word" start_char="4168">that</TOKEN>
<TOKEN end_char="4178" id="token-25-27" morph="none" pos="word" start_char="4173">causes</TOKEN>
<TOKEN end_char="4187" id="token-25-28" morph="none" pos="unknown" start_char="4180">COVID-19</TOKEN>
<TOKEN end_char="4188" id="token-25-29" morph="none" pos="punct" start_char="4188">.</TOKEN>
</SEG>
<SEG end_char="4252" id="segment-26" start_char="4191">
<ORIGINAL_TEXT>She said the next step would be to look more closely at farms.</ORIGINAL_TEXT>
<TOKEN end_char="4193" id="token-26-0" morph="none" pos="word" start_char="4191">She</TOKEN>
<TOKEN end_char="4198" id="token-26-1" morph="none" pos="word" start_char="4195">said</TOKEN>
<TOKEN end_char="4202" id="token-26-2" morph="none" pos="word" start_char="4200">the</TOKEN>
<TOKEN end_char="4207" id="token-26-3" morph="none" pos="word" start_char="4204">next</TOKEN>
<TOKEN end_char="4212" id="token-26-4" morph="none" pos="word" start_char="4209">step</TOKEN>
<TOKEN end_char="4218" id="token-26-5" morph="none" pos="word" start_char="4214">would</TOKEN>
<TOKEN end_char="4221" id="token-26-6" morph="none" pos="word" start_char="4220">be</TOKEN>
<TOKEN end_char="4224" id="token-26-7" morph="none" pos="word" start_char="4223">to</TOKEN>
<TOKEN end_char="4229" id="token-26-8" morph="none" pos="word" start_char="4226">look</TOKEN>
<TOKEN end_char="4234" id="token-26-9" morph="none" pos="word" start_char="4231">more</TOKEN>
<TOKEN end_char="4242" id="token-26-10" morph="none" pos="word" start_char="4236">closely</TOKEN>
<TOKEN end_char="4245" id="token-26-11" morph="none" pos="word" start_char="4244">at</TOKEN>
<TOKEN end_char="4251" id="token-26-12" morph="none" pos="word" start_char="4247">farms</TOKEN>
<TOKEN end_char="4252" id="token-26-13" morph="none" pos="punct" start_char="4252">.</TOKEN>
</SEG>
<SEG end_char="4446" id="segment-27" start_char="4255">
<ORIGINAL_TEXT>Liang, the head of the Chinese team, said the virus also appeared to have been spreading in parts of the city other than the market, so it remains possible that the virus originated elsewhere.</ORIGINAL_TEXT>
<TOKEN end_char="4259" id="token-27-0" morph="none" pos="word" start_char="4255">Liang</TOKEN>
<TOKEN end_char="4260" id="token-27-1" morph="none" pos="punct" start_char="4260">,</TOKEN>
<TOKEN end_char="4264" id="token-27-2" morph="none" pos="word" start_char="4262">the</TOKEN>
<TOKEN end_char="4269" id="token-27-3" morph="none" pos="word" start_char="4266">head</TOKEN>
<TOKEN end_char="4272" id="token-27-4" morph="none" pos="word" start_char="4271">of</TOKEN>
<TOKEN end_char="4276" id="token-27-5" morph="none" pos="word" start_char="4274">the</TOKEN>
<TOKEN end_char="4284" id="token-27-6" morph="none" pos="word" start_char="4278">Chinese</TOKEN>
<TOKEN end_char="4289" id="token-27-7" morph="none" pos="word" start_char="4286">team</TOKEN>
<TOKEN end_char="4290" id="token-27-8" morph="none" pos="punct" start_char="4290">,</TOKEN>
<TOKEN end_char="4295" id="token-27-9" morph="none" pos="word" start_char="4292">said</TOKEN>
<TOKEN end_char="4299" id="token-27-10" morph="none" pos="word" start_char="4297">the</TOKEN>
<TOKEN end_char="4305" id="token-27-11" morph="none" pos="word" start_char="4301">virus</TOKEN>
<TOKEN end_char="4310" id="token-27-12" morph="none" pos="word" start_char="4307">also</TOKEN>
<TOKEN end_char="4319" id="token-27-13" morph="none" pos="word" start_char="4312">appeared</TOKEN>
<TOKEN end_char="4322" id="token-27-14" morph="none" pos="word" start_char="4321">to</TOKEN>
<TOKEN end_char="4327" id="token-27-15" morph="none" pos="word" start_char="4324">have</TOKEN>
<TOKEN end_char="4332" id="token-27-16" morph="none" pos="word" start_char="4329">been</TOKEN>
<TOKEN end_char="4342" id="token-27-17" morph="none" pos="word" start_char="4334">spreading</TOKEN>
<TOKEN end_char="4345" id="token-27-18" morph="none" pos="word" start_char="4344">in</TOKEN>
<TOKEN end_char="4351" id="token-27-19" morph="none" pos="word" start_char="4347">parts</TOKEN>
<TOKEN end_char="4354" id="token-27-20" morph="none" pos="word" start_char="4353">of</TOKEN>
<TOKEN end_char="4358" id="token-27-21" morph="none" pos="word" start_char="4356">the</TOKEN>
<TOKEN end_char="4363" id="token-27-22" morph="none" pos="word" start_char="4360">city</TOKEN>
<TOKEN end_char="4369" id="token-27-23" morph="none" pos="word" start_char="4365">other</TOKEN>
<TOKEN end_char="4374" id="token-27-24" morph="none" pos="word" start_char="4371">than</TOKEN>
<TOKEN end_char="4378" id="token-27-25" morph="none" pos="word" start_char="4376">the</TOKEN>
<TOKEN end_char="4385" id="token-27-26" morph="none" pos="word" start_char="4380">market</TOKEN>
<TOKEN end_char="4386" id="token-27-27" morph="none" pos="punct" start_char="4386">,</TOKEN>
<TOKEN end_char="4389" id="token-27-28" morph="none" pos="word" start_char="4388">so</TOKEN>
<TOKEN end_char="4392" id="token-27-29" morph="none" pos="word" start_char="4391">it</TOKEN>
<TOKEN end_char="4400" id="token-27-30" morph="none" pos="word" start_char="4394">remains</TOKEN>
<TOKEN end_char="4409" id="token-27-31" morph="none" pos="word" start_char="4402">possible</TOKEN>
<TOKEN end_char="4414" id="token-27-32" morph="none" pos="word" start_char="4411">that</TOKEN>
<TOKEN end_char="4418" id="token-27-33" morph="none" pos="word" start_char="4416">the</TOKEN>
<TOKEN end_char="4424" id="token-27-34" morph="none" pos="word" start_char="4420">virus</TOKEN>
<TOKEN end_char="4435" id="token-27-35" morph="none" pos="word" start_char="4426">originated</TOKEN>
<TOKEN end_char="4445" id="token-27-36" morph="none" pos="word" start_char="4437">elsewhere</TOKEN>
<TOKEN end_char="4446" id="token-27-37" morph="none" pos="punct" start_char="4446">.</TOKEN>
</SEG>
<SEG end_char="4587" id="segment-28" start_char="4449">
<ORIGINAL_TEXT>The team found no evidence that the disease was spreading widely any earlier than the initial outbreak in the second half of December 2019.</ORIGINAL_TEXT>
<TOKEN end_char="4451" id="token-28-0" morph="none" pos="word" start_char="4449">The</TOKEN>
<TOKEN end_char="4456" id="token-28-1" morph="none" pos="word" start_char="4453">team</TOKEN>
<TOKEN end_char="4462" id="token-28-2" morph="none" pos="word" start_char="4458">found</TOKEN>
<TOKEN end_char="4465" id="token-28-3" morph="none" pos="word" start_char="4464">no</TOKEN>
<TOKEN end_char="4474" id="token-28-4" morph="none" pos="word" start_char="4467">evidence</TOKEN>
<TOKEN end_char="4479" id="token-28-5" morph="none" pos="word" start_char="4476">that</TOKEN>
<TOKEN end_char="4483" id="token-28-6" morph="none" pos="word" start_char="4481">the</TOKEN>
<TOKEN end_char="4491" id="token-28-7" morph="none" pos="word" start_char="4485">disease</TOKEN>
<TOKEN end_char="4495" id="token-28-8" morph="none" pos="word" start_char="4493">was</TOKEN>
<TOKEN end_char="4505" id="token-28-9" morph="none" pos="word" start_char="4497">spreading</TOKEN>
<TOKEN end_char="4512" id="token-28-10" morph="none" pos="word" start_char="4507">widely</TOKEN>
<TOKEN end_char="4516" id="token-28-11" morph="none" pos="word" start_char="4514">any</TOKEN>
<TOKEN end_char="4524" id="token-28-12" morph="none" pos="word" start_char="4518">earlier</TOKEN>
<TOKEN end_char="4529" id="token-28-13" morph="none" pos="word" start_char="4526">than</TOKEN>
<TOKEN end_char="4533" id="token-28-14" morph="none" pos="word" start_char="4531">the</TOKEN>
<TOKEN end_char="4541" id="token-28-15" morph="none" pos="word" start_char="4535">initial</TOKEN>
<TOKEN end_char="4550" id="token-28-16" morph="none" pos="word" start_char="4543">outbreak</TOKEN>
<TOKEN end_char="4553" id="token-28-17" morph="none" pos="word" start_char="4552">in</TOKEN>
<TOKEN end_char="4557" id="token-28-18" morph="none" pos="word" start_char="4555">the</TOKEN>
<TOKEN end_char="4564" id="token-28-19" morph="none" pos="word" start_char="4559">second</TOKEN>
<TOKEN end_char="4569" id="token-28-20" morph="none" pos="word" start_char="4566">half</TOKEN>
<TOKEN end_char="4572" id="token-28-21" morph="none" pos="word" start_char="4571">of</TOKEN>
<TOKEN end_char="4581" id="token-28-22" morph="none" pos="word" start_char="4574">December</TOKEN>
<TOKEN end_char="4586" id="token-28-23" morph="none" pos="word" start_char="4583">2019</TOKEN>
<TOKEN end_char="4587" id="token-28-24" morph="none" pos="punct" start_char="4587">.</TOKEN>
</SEG>
<SEG end_char="4762" id="segment-29" start_char="4590">
<ORIGINAL_TEXT>"We haven’t been able to fully do the research, but there is no indication there were clusters before what we saw happen in the later part of December in Wuhan," Liang said.</ORIGINAL_TEXT>
<TOKEN end_char="4590" id="token-29-0" morph="none" pos="punct" start_char="4590">"</TOKEN>
<TOKEN end_char="4592" id="token-29-1" morph="none" pos="word" start_char="4591">We</TOKEN>
<TOKEN end_char="4600" id="token-29-2" morph="none" pos="word" start_char="4594">haven’t</TOKEN>
<TOKEN end_char="4605" id="token-29-3" morph="none" pos="word" start_char="4602">been</TOKEN>
<TOKEN end_char="4610" id="token-29-4" morph="none" pos="word" start_char="4607">able</TOKEN>
<TOKEN end_char="4613" id="token-29-5" morph="none" pos="word" start_char="4612">to</TOKEN>
<TOKEN end_char="4619" id="token-29-6" morph="none" pos="word" start_char="4615">fully</TOKEN>
<TOKEN end_char="4622" id="token-29-7" morph="none" pos="word" start_char="4621">do</TOKEN>
<TOKEN end_char="4626" id="token-29-8" morph="none" pos="word" start_char="4624">the</TOKEN>
<TOKEN end_char="4635" id="token-29-9" morph="none" pos="word" start_char="4628">research</TOKEN>
<TOKEN end_char="4636" id="token-29-10" morph="none" pos="punct" start_char="4636">,</TOKEN>
<TOKEN end_char="4640" id="token-29-11" morph="none" pos="word" start_char="4638">but</TOKEN>
<TOKEN end_char="4646" id="token-29-12" morph="none" pos="word" start_char="4642">there</TOKEN>
<TOKEN end_char="4649" id="token-29-13" morph="none" pos="word" start_char="4648">is</TOKEN>
<TOKEN end_char="4652" id="token-29-14" morph="none" pos="word" start_char="4651">no</TOKEN>
<TOKEN end_char="4663" id="token-29-15" morph="none" pos="word" start_char="4654">indication</TOKEN>
<TOKEN end_char="4669" id="token-29-16" morph="none" pos="word" start_char="4665">there</TOKEN>
<TOKEN end_char="4674" id="token-29-17" morph="none" pos="word" start_char="4671">were</TOKEN>
<TOKEN end_char="4683" id="token-29-18" morph="none" pos="word" start_char="4676">clusters</TOKEN>
<TOKEN end_char="4690" id="token-29-19" morph="none" pos="word" start_char="4685">before</TOKEN>
<TOKEN end_char="4695" id="token-29-20" morph="none" pos="word" start_char="4692">what</TOKEN>
<TOKEN end_char="4698" id="token-29-21" morph="none" pos="word" start_char="4697">we</TOKEN>
<TOKEN end_char="4702" id="token-29-22" morph="none" pos="word" start_char="4700">saw</TOKEN>
<TOKEN end_char="4709" id="token-29-23" morph="none" pos="word" start_char="4704">happen</TOKEN>
<TOKEN end_char="4712" id="token-29-24" morph="none" pos="word" start_char="4711">in</TOKEN>
<TOKEN end_char="4716" id="token-29-25" morph="none" pos="word" start_char="4714">the</TOKEN>
<TOKEN end_char="4722" id="token-29-26" morph="none" pos="word" start_char="4718">later</TOKEN>
<TOKEN end_char="4727" id="token-29-27" morph="none" pos="word" start_char="4724">part</TOKEN>
<TOKEN end_char="4730" id="token-29-28" morph="none" pos="word" start_char="4729">of</TOKEN>
<TOKEN end_char="4739" id="token-29-29" morph="none" pos="word" start_char="4732">December</TOKEN>
<TOKEN end_char="4742" id="token-29-30" morph="none" pos="word" start_char="4741">in</TOKEN>
<TOKEN end_char="4748" id="token-29-31" morph="none" pos="word" start_char="4744">Wuhan</TOKEN>
<TOKEN end_char="4750" id="token-29-32" morph="none" pos="punct" start_char="4749">,"</TOKEN>
<TOKEN end_char="4756" id="token-29-33" morph="none" pos="word" start_char="4752">Liang</TOKEN>
<TOKEN end_char="4761" id="token-29-34" morph="none" pos="word" start_char="4758">said</TOKEN>
<TOKEN end_char="4762" id="token-29-35" morph="none" pos="punct" start_char="4762">.</TOKEN>
</SEG>
<SEG end_char="4815" id="segment-30" start_char="4765">
<ORIGINAL_TEXT>The visit by the WHO team took months to negotiate.</ORIGINAL_TEXT>
<TOKEN end_char="4767" id="token-30-0" morph="none" pos="word" start_char="4765">The</TOKEN>
<TOKEN end_char="4773" id="token-30-1" morph="none" pos="word" start_char="4769">visit</TOKEN>
<TOKEN end_char="4776" id="token-30-2" morph="none" pos="word" start_char="4775">by</TOKEN>
<TOKEN end_char="4780" id="token-30-3" morph="none" pos="word" start_char="4778">the</TOKEN>
<TOKEN end_char="4784" id="token-30-4" morph="none" pos="word" start_char="4782">WHO</TOKEN>
<TOKEN end_char="4789" id="token-30-5" morph="none" pos="word" start_char="4786">team</TOKEN>
<TOKEN end_char="4794" id="token-30-6" morph="none" pos="word" start_char="4791">took</TOKEN>
<TOKEN end_char="4801" id="token-30-7" morph="none" pos="word" start_char="4796">months</TOKEN>
<TOKEN end_char="4804" id="token-30-8" morph="none" pos="word" start_char="4803">to</TOKEN>
<TOKEN end_char="4814" id="token-30-9" morph="none" pos="word" start_char="4806">negotiate</TOKEN>
<TOKEN end_char="4815" id="token-30-10" morph="none" pos="punct" start_char="4815">.</TOKEN>
</SEG>
<SEG end_char="5004" id="segment-31" start_char="4817">
<ORIGINAL_TEXT>China only agreed to it amid international pressure at the WHO’s World Health Assembly meeting last May, and Beijing has continued to resist calls for a strictly independent investigation.</ORIGINAL_TEXT>
<TOKEN end_char="4821" id="token-31-0" morph="none" pos="word" start_char="4817">China</TOKEN>
<TOKEN end_char="4826" id="token-31-1" morph="none" pos="word" start_char="4823">only</TOKEN>
<TOKEN end_char="4833" id="token-31-2" morph="none" pos="word" start_char="4828">agreed</TOKEN>
<TOKEN end_char="4836" id="token-31-3" morph="none" pos="word" start_char="4835">to</TOKEN>
<TOKEN end_char="4839" id="token-31-4" morph="none" pos="word" start_char="4838">it</TOKEN>
<TOKEN end_char="4844" id="token-31-5" morph="none" pos="word" start_char="4841">amid</TOKEN>
<TOKEN end_char="4858" id="token-31-6" morph="none" pos="word" start_char="4846">international</TOKEN>
<TOKEN end_char="4867" id="token-31-7" morph="none" pos="word" start_char="4860">pressure</TOKEN>
<TOKEN end_char="4870" id="token-31-8" morph="none" pos="word" start_char="4869">at</TOKEN>
<TOKEN end_char="4874" id="token-31-9" morph="none" pos="word" start_char="4872">the</TOKEN>
<TOKEN end_char="4880" id="token-31-10" morph="none" pos="word" start_char="4876">WHO’s</TOKEN>
<TOKEN end_char="4886" id="token-31-11" morph="none" pos="word" start_char="4882">World</TOKEN>
<TOKEN end_char="4893" id="token-31-12" morph="none" pos="word" start_char="4888">Health</TOKEN>
<TOKEN end_char="4902" id="token-31-13" morph="none" pos="word" start_char="4895">Assembly</TOKEN>
<TOKEN end_char="4910" id="token-31-14" morph="none" pos="word" start_char="4904">meeting</TOKEN>
<TOKEN end_char="4915" id="token-31-15" morph="none" pos="word" start_char="4912">last</TOKEN>
<TOKEN end_char="4919" id="token-31-16" morph="none" pos="word" start_char="4917">May</TOKEN>
<TOKEN end_char="4920" id="token-31-17" morph="none" pos="punct" start_char="4920">,</TOKEN>
<TOKEN end_char="4924" id="token-31-18" morph="none" pos="word" start_char="4922">and</TOKEN>
<TOKEN end_char="4932" id="token-31-19" morph="none" pos="word" start_char="4926">Beijing</TOKEN>
<TOKEN end_char="4936" id="token-31-20" morph="none" pos="word" start_char="4934">has</TOKEN>
<TOKEN end_char="4946" id="token-31-21" morph="none" pos="word" start_char="4938">continued</TOKEN>
<TOKEN end_char="4949" id="token-31-22" morph="none" pos="word" start_char="4948">to</TOKEN>
<TOKEN end_char="4956" id="token-31-23" morph="none" pos="word" start_char="4951">resist</TOKEN>
<TOKEN end_char="4962" id="token-31-24" morph="none" pos="word" start_char="4958">calls</TOKEN>
<TOKEN end_char="4966" id="token-31-25" morph="none" pos="word" start_char="4964">for</TOKEN>
<TOKEN end_char="4968" id="token-31-26" morph="none" pos="word" start_char="4968">a</TOKEN>
<TOKEN end_char="4977" id="token-31-27" morph="none" pos="word" start_char="4970">strictly</TOKEN>
<TOKEN end_char="4989" id="token-31-28" morph="none" pos="word" start_char="4979">independent</TOKEN>
<TOKEN end_char="5003" id="token-31-29" morph="none" pos="word" start_char="4991">investigation</TOKEN>
<TOKEN end_char="5004" id="token-31-30" morph="none" pos="punct" start_char="5004">.</TOKEN>
</SEG>
<SEG end_char="5176" id="segment-32" start_char="5007">
<ORIGINAL_TEXT>While China has weathered some localized resurgences of infection since getting the outbreak under control last year, life in Wuhan itself has largely returned to normal.</ORIGINAL_TEXT>
<TOKEN end_char="5011" id="token-32-0" morph="none" pos="word" start_char="5007">While</TOKEN>
<TOKEN end_char="5017" id="token-32-1" morph="none" pos="word" start_char="5013">China</TOKEN>
<TOKEN end_char="5021" id="token-32-2" morph="none" pos="word" start_char="5019">has</TOKEN>
<TOKEN end_char="5031" id="token-32-3" morph="none" pos="word" start_char="5023">weathered</TOKEN>
<TOKEN end_char="5036" id="token-32-4" morph="none" pos="word" start_char="5033">some</TOKEN>
<TOKEN end_char="5046" id="token-32-5" morph="none" pos="word" start_char="5038">localized</TOKEN>
<TOKEN end_char="5058" id="token-32-6" morph="none" pos="word" start_char="5048">resurgences</TOKEN>
<TOKEN end_char="5061" id="token-32-7" morph="none" pos="word" start_char="5060">of</TOKEN>
<TOKEN end_char="5071" id="token-32-8" morph="none" pos="word" start_char="5063">infection</TOKEN>
<TOKEN end_char="5077" id="token-32-9" morph="none" pos="word" start_char="5073">since</TOKEN>
<TOKEN end_char="5085" id="token-32-10" morph="none" pos="word" start_char="5079">getting</TOKEN>
<TOKEN end_char="5089" id="token-32-11" morph="none" pos="word" start_char="5087">the</TOKEN>
<TOKEN end_char="5098" id="token-32-12" morph="none" pos="word" start_char="5091">outbreak</TOKEN>
<TOKEN end_char="5104" id="token-32-13" morph="none" pos="word" start_char="5100">under</TOKEN>
<TOKEN end_char="5112" id="token-32-14" morph="none" pos="word" start_char="5106">control</TOKEN>
<TOKEN end_char="5117" id="token-32-15" morph="none" pos="word" start_char="5114">last</TOKEN>
<TOKEN end_char="5122" id="token-32-16" morph="none" pos="word" start_char="5119">year</TOKEN>
<TOKEN end_char="5123" id="token-32-17" morph="none" pos="punct" start_char="5123">,</TOKEN>
<TOKEN end_char="5128" id="token-32-18" morph="none" pos="word" start_char="5125">life</TOKEN>
<TOKEN end_char="5131" id="token-32-19" morph="none" pos="word" start_char="5130">in</TOKEN>
<TOKEN end_char="5137" id="token-32-20" morph="none" pos="word" start_char="5133">Wuhan</TOKEN>
<TOKEN end_char="5144" id="token-32-21" morph="none" pos="word" start_char="5139">itself</TOKEN>
<TOKEN end_char="5148" id="token-32-22" morph="none" pos="word" start_char="5146">has</TOKEN>
<TOKEN end_char="5156" id="token-32-23" morph="none" pos="word" start_char="5150">largely</TOKEN>
<TOKEN end_char="5165" id="token-32-24" morph="none" pos="word" start_char="5158">returned</TOKEN>
<TOKEN end_char="5168" id="token-32-25" morph="none" pos="word" start_char="5167">to</TOKEN>
<TOKEN end_char="5175" id="token-32-26" morph="none" pos="word" start_char="5170">normal</TOKEN>
<TOKEN end_char="5176" id="token-32-27" morph="none" pos="punct" start_char="5176">.</TOKEN>
</SEG>
<SEG end_char="5238" id="segment-33" start_char="5179">
<ORIGINAL_TEXT>Associated Press writers Ken Moritsugu in Beijing and Jan M.</ORIGINAL_TEXT>
<TOKEN end_char="5188" id="token-33-0" morph="none" pos="word" start_char="5179">Associated</TOKEN>
<TOKEN end_char="5194" id="token-33-1" morph="none" pos="word" start_char="5190">Press</TOKEN>
<TOKEN end_char="5202" id="token-33-2" morph="none" pos="word" start_char="5196">writers</TOKEN>
<TOKEN end_char="5206" id="token-33-3" morph="none" pos="word" start_char="5204">Ken</TOKEN>
<TOKEN end_char="5216" id="token-33-4" morph="none" pos="word" start_char="5208">Moritsugu</TOKEN>
<TOKEN end_char="5219" id="token-33-5" morph="none" pos="word" start_char="5218">in</TOKEN>
<TOKEN end_char="5227" id="token-33-6" morph="none" pos="word" start_char="5221">Beijing</TOKEN>
<TOKEN end_char="5231" id="token-33-7" morph="none" pos="word" start_char="5229">and</TOKEN>
<TOKEN end_char="5235" id="token-33-8" morph="none" pos="word" start_char="5233">Jan</TOKEN>
<TOKEN end_char="5237" id="token-33-9" morph="none" pos="word" start_char="5237">M</TOKEN>
<TOKEN end_char="5238" id="token-33-10" morph="none" pos="punct" start_char="5238">.</TOKEN>
</SEG>
<SEG end_char="5296" id="segment-34" start_char="5240">
<ORIGINAL_TEXT>Olsen in Copenhagen, Denmark, contributed to this report.</ORIGINAL_TEXT>
<TOKEN end_char="5244" id="token-34-0" morph="none" pos="word" start_char="5240">Olsen</TOKEN>
<TOKEN end_char="5247" id="token-34-1" morph="none" pos="word" start_char="5246">in</TOKEN>
<TOKEN end_char="5258" id="token-34-2" morph="none" pos="word" start_char="5249">Copenhagen</TOKEN>
<TOKEN end_char="5259" id="token-34-3" morph="none" pos="punct" start_char="5259">,</TOKEN>
<TOKEN end_char="5267" id="token-34-4" morph="none" pos="word" start_char="5261">Denmark</TOKEN>
<TOKEN end_char="5268" id="token-34-5" morph="none" pos="punct" start_char="5268">,</TOKEN>
<TOKEN end_char="5280" id="token-34-6" morph="none" pos="word" start_char="5270">contributed</TOKEN>
<TOKEN end_char="5283" id="token-34-7" morph="none" pos="word" start_char="5282">to</TOKEN>
<TOKEN end_char="5288" id="token-34-8" morph="none" pos="word" start_char="5285">this</TOKEN>
<TOKEN end_char="5295" id="token-34-9" morph="none" pos="word" start_char="5290">report</TOKEN>
<TOKEN end_char="5296" id="token-34-10" morph="none" pos="punct" start_char="5296">.</TOKEN>
</SEG>
<SEG end_char="5303" id="segment-35" start_char="5299">
<ORIGINAL_TEXT>Video</ORIGINAL_TEXT>
<TOKEN end_char="5303" id="token-35-0" morph="none" pos="word" start_char="5299">Video</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
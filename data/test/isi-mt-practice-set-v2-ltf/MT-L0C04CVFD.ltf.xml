<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CVFD" lang="spa" raw_text_char_length="14531" raw_text_md5="87f5ade207e10e8b7fcba46caf01e7b9" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="50" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Why France is hiding a cheap and tested virus cure</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">Why</TOKEN>
<TOKEN end_char="10" id="token-0-1" morph="none" pos="word" start_char="5">France</TOKEN>
<TOKEN end_char="13" id="token-0-2" morph="none" pos="word" start_char="12">is</TOKEN>
<TOKEN end_char="20" id="token-0-3" morph="none" pos="word" start_char="15">hiding</TOKEN>
<TOKEN end_char="22" id="token-0-4" morph="none" pos="word" start_char="22">a</TOKEN>
<TOKEN end_char="28" id="token-0-5" morph="none" pos="word" start_char="24">cheap</TOKEN>
<TOKEN end_char="32" id="token-0-6" morph="none" pos="word" start_char="30">and</TOKEN>
<TOKEN end_char="39" id="token-0-7" morph="none" pos="word" start_char="34">tested</TOKEN>
<TOKEN end_char="45" id="token-0-8" morph="none" pos="word" start_char="41">virus</TOKEN>
<TOKEN end_char="50" id="token-0-9" morph="none" pos="word" start_char="47">cure</TOKEN>
</SEG>
<SEG end_char="266" id="segment-1" start_char="56">
<ORIGINAL_TEXT>Islam Times - What’s going on in the fifth largest economy in the world arguably points to a major collusion scandal in which the French government is helping Big Pharma to profit from the expansion of Covid-19.</ORIGINAL_TEXT>
<TOKEN end_char="60" id="token-1-0" morph="none" pos="word" start_char="56">Islam</TOKEN>
<TOKEN end_char="66" id="token-1-1" morph="none" pos="word" start_char="62">Times</TOKEN>
<TOKEN end_char="68" id="token-1-2" morph="none" pos="punct" start_char="68">-</TOKEN>
<TOKEN end_char="75" id="token-1-3" morph="none" pos="word" start_char="70">What’s</TOKEN>
<TOKEN end_char="81" id="token-1-4" morph="none" pos="word" start_char="77">going</TOKEN>
<TOKEN end_char="84" id="token-1-5" morph="none" pos="word" start_char="83">on</TOKEN>
<TOKEN end_char="87" id="token-1-6" morph="none" pos="word" start_char="86">in</TOKEN>
<TOKEN end_char="91" id="token-1-7" morph="none" pos="word" start_char="89">the</TOKEN>
<TOKEN end_char="97" id="token-1-8" morph="none" pos="word" start_char="93">fifth</TOKEN>
<TOKEN end_char="105" id="token-1-9" morph="none" pos="word" start_char="99">largest</TOKEN>
<TOKEN end_char="113" id="token-1-10" morph="none" pos="word" start_char="107">economy</TOKEN>
<TOKEN end_char="116" id="token-1-11" morph="none" pos="word" start_char="115">in</TOKEN>
<TOKEN end_char="120" id="token-1-12" morph="none" pos="word" start_char="118">the</TOKEN>
<TOKEN end_char="126" id="token-1-13" morph="none" pos="word" start_char="122">world</TOKEN>
<TOKEN end_char="135" id="token-1-14" morph="none" pos="word" start_char="128">arguably</TOKEN>
<TOKEN end_char="142" id="token-1-15" morph="none" pos="word" start_char="137">points</TOKEN>
<TOKEN end_char="145" id="token-1-16" morph="none" pos="word" start_char="144">to</TOKEN>
<TOKEN end_char="147" id="token-1-17" morph="none" pos="word" start_char="147">a</TOKEN>
<TOKEN end_char="153" id="token-1-18" morph="none" pos="word" start_char="149">major</TOKEN>
<TOKEN end_char="163" id="token-1-19" morph="none" pos="word" start_char="155">collusion</TOKEN>
<TOKEN end_char="171" id="token-1-20" morph="none" pos="word" start_char="165">scandal</TOKEN>
<TOKEN end_char="174" id="token-1-21" morph="none" pos="word" start_char="173">in</TOKEN>
<TOKEN end_char="180" id="token-1-22" morph="none" pos="word" start_char="176">which</TOKEN>
<TOKEN end_char="184" id="token-1-23" morph="none" pos="word" start_char="182">the</TOKEN>
<TOKEN end_char="191" id="token-1-24" morph="none" pos="word" start_char="186">French</TOKEN>
<TOKEN end_char="202" id="token-1-25" morph="none" pos="word" start_char="193">government</TOKEN>
<TOKEN end_char="205" id="token-1-26" morph="none" pos="word" start_char="204">is</TOKEN>
<TOKEN end_char="213" id="token-1-27" morph="none" pos="word" start_char="207">helping</TOKEN>
<TOKEN end_char="217" id="token-1-28" morph="none" pos="word" start_char="215">Big</TOKEN>
<TOKEN end_char="224" id="token-1-29" morph="none" pos="word" start_char="219">Pharma</TOKEN>
<TOKEN end_char="227" id="token-1-30" morph="none" pos="word" start_char="226">to</TOKEN>
<TOKEN end_char="234" id="token-1-31" morph="none" pos="word" start_char="229">profit</TOKEN>
<TOKEN end_char="239" id="token-1-32" morph="none" pos="word" start_char="236">from</TOKEN>
<TOKEN end_char="243" id="token-1-33" morph="none" pos="word" start_char="241">the</TOKEN>
<TOKEN end_char="253" id="token-1-34" morph="none" pos="word" start_char="245">expansion</TOKEN>
<TOKEN end_char="256" id="token-1-35" morph="none" pos="word" start_char="255">of</TOKEN>
<TOKEN end_char="265" id="token-1-36" morph="none" pos="unknown" start_char="258">Covid-19</TOKEN>
<TOKEN end_char="266" id="token-1-37" morph="none" pos="punct" start_char="266">.</TOKEN>
</SEG>
<SEG end_char="324" id="segment-2" start_char="268">
<ORIGINAL_TEXT>Informed French citizens are absolutely furious about it.</ORIGINAL_TEXT>
<TOKEN end_char="275" id="token-2-0" morph="none" pos="word" start_char="268">Informed</TOKEN>
<TOKEN end_char="282" id="token-2-1" morph="none" pos="word" start_char="277">French</TOKEN>
<TOKEN end_char="291" id="token-2-2" morph="none" pos="word" start_char="284">citizens</TOKEN>
<TOKEN end_char="295" id="token-2-3" morph="none" pos="word" start_char="293">are</TOKEN>
<TOKEN end_char="306" id="token-2-4" morph="none" pos="word" start_char="297">absolutely</TOKEN>
<TOKEN end_char="314" id="token-2-5" morph="none" pos="word" start_char="308">furious</TOKEN>
<TOKEN end_char="320" id="token-2-6" morph="none" pos="word" start_char="316">about</TOKEN>
<TOKEN end_char="323" id="token-2-7" morph="none" pos="word" start_char="322">it</TOKEN>
<TOKEN end_char="324" id="token-2-8" morph="none" pos="punct" start_char="324">.</TOKEN>
</SEG>
<SEG end_char="636" id="segment-3" start_char="328">
<ORIGINAL_TEXT>My initial question to a serious, unimpeachable Paris source, jurist Valerie Bugault, was about the liaisons dangereuses between Macronism and Big Pharma and especially about the mysterious "disappearance" – more likely outright theft – of all the stocks of chloroquine in possession of the French government.</ORIGINAL_TEXT>
<TOKEN end_char="329" id="token-3-0" morph="none" pos="word" start_char="328">My</TOKEN>
<TOKEN end_char="337" id="token-3-1" morph="none" pos="word" start_char="331">initial</TOKEN>
<TOKEN end_char="346" id="token-3-2" morph="none" pos="word" start_char="339">question</TOKEN>
<TOKEN end_char="349" id="token-3-3" morph="none" pos="word" start_char="348">to</TOKEN>
<TOKEN end_char="351" id="token-3-4" morph="none" pos="word" start_char="351">a</TOKEN>
<TOKEN end_char="359" id="token-3-5" morph="none" pos="word" start_char="353">serious</TOKEN>
<TOKEN end_char="360" id="token-3-6" morph="none" pos="punct" start_char="360">,</TOKEN>
<TOKEN end_char="374" id="token-3-7" morph="none" pos="word" start_char="362">unimpeachable</TOKEN>
<TOKEN end_char="380" id="token-3-8" morph="none" pos="word" start_char="376">Paris</TOKEN>
<TOKEN end_char="387" id="token-3-9" morph="none" pos="word" start_char="382">source</TOKEN>
<TOKEN end_char="388" id="token-3-10" morph="none" pos="punct" start_char="388">,</TOKEN>
<TOKEN end_char="395" id="token-3-11" morph="none" pos="word" start_char="390">jurist</TOKEN>
<TOKEN end_char="403" id="token-3-12" morph="none" pos="word" start_char="397">Valerie</TOKEN>
<TOKEN end_char="411" id="token-3-13" morph="none" pos="word" start_char="405">Bugault</TOKEN>
<TOKEN end_char="412" id="token-3-14" morph="none" pos="punct" start_char="412">,</TOKEN>
<TOKEN end_char="416" id="token-3-15" morph="none" pos="word" start_char="414">was</TOKEN>
<TOKEN end_char="422" id="token-3-16" morph="none" pos="word" start_char="418">about</TOKEN>
<TOKEN end_char="426" id="token-3-17" morph="none" pos="word" start_char="424">the</TOKEN>
<TOKEN end_char="435" id="token-3-18" morph="none" pos="word" start_char="428">liaisons</TOKEN>
<TOKEN end_char="447" id="token-3-19" morph="none" pos="word" start_char="437">dangereuses</TOKEN>
<TOKEN end_char="455" id="token-3-20" morph="none" pos="word" start_char="449">between</TOKEN>
<TOKEN end_char="465" id="token-3-21" morph="none" pos="word" start_char="457">Macronism</TOKEN>
<TOKEN end_char="469" id="token-3-22" morph="none" pos="word" start_char="467">and</TOKEN>
<TOKEN end_char="473" id="token-3-23" morph="none" pos="word" start_char="471">Big</TOKEN>
<TOKEN end_char="480" id="token-3-24" morph="none" pos="word" start_char="475">Pharma</TOKEN>
<TOKEN end_char="484" id="token-3-25" morph="none" pos="word" start_char="482">and</TOKEN>
<TOKEN end_char="495" id="token-3-26" morph="none" pos="word" start_char="486">especially</TOKEN>
<TOKEN end_char="501" id="token-3-27" morph="none" pos="word" start_char="497">about</TOKEN>
<TOKEN end_char="505" id="token-3-28" morph="none" pos="word" start_char="503">the</TOKEN>
<TOKEN end_char="516" id="token-3-29" morph="none" pos="word" start_char="507">mysterious</TOKEN>
<TOKEN end_char="518" id="token-3-30" morph="none" pos="punct" start_char="518">"</TOKEN>
<TOKEN end_char="531" id="token-3-31" morph="none" pos="word" start_char="519">disappearance</TOKEN>
<TOKEN end_char="532" id="token-3-32" morph="none" pos="punct" start_char="532">"</TOKEN>
<TOKEN end_char="534" id="token-3-33" morph="none" pos="punct" start_char="534">–</TOKEN>
<TOKEN end_char="539" id="token-3-34" morph="none" pos="word" start_char="536">more</TOKEN>
<TOKEN end_char="546" id="token-3-35" morph="none" pos="word" start_char="541">likely</TOKEN>
<TOKEN end_char="555" id="token-3-36" morph="none" pos="word" start_char="548">outright</TOKEN>
<TOKEN end_char="561" id="token-3-37" morph="none" pos="word" start_char="557">theft</TOKEN>
<TOKEN end_char="563" id="token-3-38" morph="none" pos="punct" start_char="563">–</TOKEN>
<TOKEN end_char="566" id="token-3-39" morph="none" pos="word" start_char="565">of</TOKEN>
<TOKEN end_char="570" id="token-3-40" morph="none" pos="word" start_char="568">all</TOKEN>
<TOKEN end_char="574" id="token-3-41" morph="none" pos="word" start_char="572">the</TOKEN>
<TOKEN end_char="581" id="token-3-42" morph="none" pos="word" start_char="576">stocks</TOKEN>
<TOKEN end_char="584" id="token-3-43" morph="none" pos="word" start_char="583">of</TOKEN>
<TOKEN end_char="596" id="token-3-44" morph="none" pos="word" start_char="586">chloroquine</TOKEN>
<TOKEN end_char="599" id="token-3-45" morph="none" pos="word" start_char="598">in</TOKEN>
<TOKEN end_char="610" id="token-3-46" morph="none" pos="word" start_char="601">possession</TOKEN>
<TOKEN end_char="613" id="token-3-47" morph="none" pos="word" start_char="612">of</TOKEN>
<TOKEN end_char="617" id="token-3-48" morph="none" pos="word" start_char="615">the</TOKEN>
<TOKEN end_char="624" id="token-3-49" morph="none" pos="word" start_char="619">French</TOKEN>
<TOKEN end_char="635" id="token-3-50" morph="none" pos="word" start_char="626">government</TOKEN>
<TOKEN end_char="636" id="token-3-51" morph="none" pos="punct" start_char="636">.</TOKEN>
</SEG>
<SEG end_char="874" id="segment-4" start_char="639">
<ORIGINAL_TEXT>Respected Professor Christian Perronne talked about the theft live in one of France’s 24/7 info channels: "The central pharmacy for the hospitals announced today that they were facing a total rupture of stocks, that they were pillaged."</ORIGINAL_TEXT>
<TOKEN end_char="647" id="token-4-0" morph="none" pos="word" start_char="639">Respected</TOKEN>
<TOKEN end_char="657" id="token-4-1" morph="none" pos="word" start_char="649">Professor</TOKEN>
<TOKEN end_char="667" id="token-4-2" morph="none" pos="word" start_char="659">Christian</TOKEN>
<TOKEN end_char="676" id="token-4-3" morph="none" pos="word" start_char="669">Perronne</TOKEN>
<TOKEN end_char="683" id="token-4-4" morph="none" pos="word" start_char="678">talked</TOKEN>
<TOKEN end_char="689" id="token-4-5" morph="none" pos="word" start_char="685">about</TOKEN>
<TOKEN end_char="693" id="token-4-6" morph="none" pos="word" start_char="691">the</TOKEN>
<TOKEN end_char="699" id="token-4-7" morph="none" pos="word" start_char="695">theft</TOKEN>
<TOKEN end_char="704" id="token-4-8" morph="none" pos="word" start_char="701">live</TOKEN>
<TOKEN end_char="707" id="token-4-9" morph="none" pos="word" start_char="706">in</TOKEN>
<TOKEN end_char="711" id="token-4-10" morph="none" pos="word" start_char="709">one</TOKEN>
<TOKEN end_char="714" id="token-4-11" morph="none" pos="word" start_char="713">of</TOKEN>
<TOKEN end_char="723" id="token-4-12" morph="none" pos="word" start_char="716">France’s</TOKEN>
<TOKEN end_char="728" id="token-4-13" morph="none" pos="unknown" start_char="725">24/7</TOKEN>
<TOKEN end_char="733" id="token-4-14" morph="none" pos="word" start_char="730">info</TOKEN>
<TOKEN end_char="742" id="token-4-15" morph="none" pos="word" start_char="735">channels</TOKEN>
<TOKEN end_char="743" id="token-4-16" morph="none" pos="punct" start_char="743">:</TOKEN>
<TOKEN end_char="745" id="token-4-17" morph="none" pos="punct" start_char="745">"</TOKEN>
<TOKEN end_char="748" id="token-4-18" morph="none" pos="word" start_char="746">The</TOKEN>
<TOKEN end_char="756" id="token-4-19" morph="none" pos="word" start_char="750">central</TOKEN>
<TOKEN end_char="765" id="token-4-20" morph="none" pos="word" start_char="758">pharmacy</TOKEN>
<TOKEN end_char="769" id="token-4-21" morph="none" pos="word" start_char="767">for</TOKEN>
<TOKEN end_char="773" id="token-4-22" morph="none" pos="word" start_char="771">the</TOKEN>
<TOKEN end_char="783" id="token-4-23" morph="none" pos="word" start_char="775">hospitals</TOKEN>
<TOKEN end_char="793" id="token-4-24" morph="none" pos="word" start_char="785">announced</TOKEN>
<TOKEN end_char="799" id="token-4-25" morph="none" pos="word" start_char="795">today</TOKEN>
<TOKEN end_char="804" id="token-4-26" morph="none" pos="word" start_char="801">that</TOKEN>
<TOKEN end_char="809" id="token-4-27" morph="none" pos="word" start_char="806">they</TOKEN>
<TOKEN end_char="814" id="token-4-28" morph="none" pos="word" start_char="811">were</TOKEN>
<TOKEN end_char="821" id="token-4-29" morph="none" pos="word" start_char="816">facing</TOKEN>
<TOKEN end_char="823" id="token-4-30" morph="none" pos="word" start_char="823">a</TOKEN>
<TOKEN end_char="829" id="token-4-31" morph="none" pos="word" start_char="825">total</TOKEN>
<TOKEN end_char="837" id="token-4-32" morph="none" pos="word" start_char="831">rupture</TOKEN>
<TOKEN end_char="840" id="token-4-33" morph="none" pos="word" start_char="839">of</TOKEN>
<TOKEN end_char="847" id="token-4-34" morph="none" pos="word" start_char="842">stocks</TOKEN>
<TOKEN end_char="848" id="token-4-35" morph="none" pos="punct" start_char="848">,</TOKEN>
<TOKEN end_char="853" id="token-4-36" morph="none" pos="word" start_char="850">that</TOKEN>
<TOKEN end_char="858" id="token-4-37" morph="none" pos="word" start_char="855">they</TOKEN>
<TOKEN end_char="863" id="token-4-38" morph="none" pos="word" start_char="860">were</TOKEN>
<TOKEN end_char="872" id="token-4-39" morph="none" pos="word" start_char="865">pillaged</TOKEN>
<TOKEN end_char="874" id="token-4-40" morph="none" pos="punct" start_char="873">."</TOKEN>
</SEG>
<SEG end_char="1042" id="segment-5" start_char="877">
<ORIGINAL_TEXT>With input from another, anonymous source, it’s now possible to establish a timeline that puts in much-needed perspective the recent actions of the French government.</ORIGINAL_TEXT>
<TOKEN end_char="880" id="token-5-0" morph="none" pos="word" start_char="877">With</TOKEN>
<TOKEN end_char="886" id="token-5-1" morph="none" pos="word" start_char="882">input</TOKEN>
<TOKEN end_char="891" id="token-5-2" morph="none" pos="word" start_char="888">from</TOKEN>
<TOKEN end_char="899" id="token-5-3" morph="none" pos="word" start_char="893">another</TOKEN>
<TOKEN end_char="900" id="token-5-4" morph="none" pos="punct" start_char="900">,</TOKEN>
<TOKEN end_char="910" id="token-5-5" morph="none" pos="word" start_char="902">anonymous</TOKEN>
<TOKEN end_char="917" id="token-5-6" morph="none" pos="word" start_char="912">source</TOKEN>
<TOKEN end_char="918" id="token-5-7" morph="none" pos="punct" start_char="918">,</TOKEN>
<TOKEN end_char="923" id="token-5-8" morph="none" pos="word" start_char="920">it’s</TOKEN>
<TOKEN end_char="927" id="token-5-9" morph="none" pos="word" start_char="925">now</TOKEN>
<TOKEN end_char="936" id="token-5-10" morph="none" pos="word" start_char="929">possible</TOKEN>
<TOKEN end_char="939" id="token-5-11" morph="none" pos="word" start_char="938">to</TOKEN>
<TOKEN end_char="949" id="token-5-12" morph="none" pos="word" start_char="941">establish</TOKEN>
<TOKEN end_char="951" id="token-5-13" morph="none" pos="word" start_char="951">a</TOKEN>
<TOKEN end_char="960" id="token-5-14" morph="none" pos="word" start_char="953">timeline</TOKEN>
<TOKEN end_char="965" id="token-5-15" morph="none" pos="word" start_char="962">that</TOKEN>
<TOKEN end_char="970" id="token-5-16" morph="none" pos="word" start_char="967">puts</TOKEN>
<TOKEN end_char="973" id="token-5-17" morph="none" pos="word" start_char="972">in</TOKEN>
<TOKEN end_char="985" id="token-5-18" morph="none" pos="unknown" start_char="975">much-needed</TOKEN>
<TOKEN end_char="997" id="token-5-19" morph="none" pos="word" start_char="987">perspective</TOKEN>
<TOKEN end_char="1001" id="token-5-20" morph="none" pos="word" start_char="999">the</TOKEN>
<TOKEN end_char="1008" id="token-5-21" morph="none" pos="word" start_char="1003">recent</TOKEN>
<TOKEN end_char="1016" id="token-5-22" morph="none" pos="word" start_char="1010">actions</TOKEN>
<TOKEN end_char="1019" id="token-5-23" morph="none" pos="word" start_char="1018">of</TOKEN>
<TOKEN end_char="1023" id="token-5-24" morph="none" pos="word" start_char="1021">the</TOKEN>
<TOKEN end_char="1030" id="token-5-25" morph="none" pos="word" start_char="1025">French</TOKEN>
<TOKEN end_char="1041" id="token-5-26" morph="none" pos="word" start_char="1032">government</TOKEN>
<TOKEN end_char="1042" id="token-5-27" morph="none" pos="punct" start_char="1042">.</TOKEN>
</SEG>
<SEG end_char="1268" id="segment-6" start_char="1045">
<ORIGINAL_TEXT>Let’s start with Yves Levy, who was the head of INSERM – the French National Institute of Health and Medical Research – from 2014 to 2018, when he was appointed as extraordinary state councilor for the Macron administration.</ORIGINAL_TEXT>
<TOKEN end_char="1049" id="token-6-0" morph="none" pos="word" start_char="1045">Let’s</TOKEN>
<TOKEN end_char="1055" id="token-6-1" morph="none" pos="word" start_char="1051">start</TOKEN>
<TOKEN end_char="1060" id="token-6-2" morph="none" pos="word" start_char="1057">with</TOKEN>
<TOKEN end_char="1065" id="token-6-3" morph="none" pos="word" start_char="1062">Yves</TOKEN>
<TOKEN end_char="1070" id="token-6-4" morph="none" pos="word" start_char="1067">Levy</TOKEN>
<TOKEN end_char="1071" id="token-6-5" morph="none" pos="punct" start_char="1071">,</TOKEN>
<TOKEN end_char="1075" id="token-6-6" morph="none" pos="word" start_char="1073">who</TOKEN>
<TOKEN end_char="1079" id="token-6-7" morph="none" pos="word" start_char="1077">was</TOKEN>
<TOKEN end_char="1083" id="token-6-8" morph="none" pos="word" start_char="1081">the</TOKEN>
<TOKEN end_char="1088" id="token-6-9" morph="none" pos="word" start_char="1085">head</TOKEN>
<TOKEN end_char="1091" id="token-6-10" morph="none" pos="word" start_char="1090">of</TOKEN>
<TOKEN end_char="1098" id="token-6-11" morph="none" pos="word" start_char="1093">INSERM</TOKEN>
<TOKEN end_char="1100" id="token-6-12" morph="none" pos="punct" start_char="1100">–</TOKEN>
<TOKEN end_char="1104" id="token-6-13" morph="none" pos="word" start_char="1102">the</TOKEN>
<TOKEN end_char="1111" id="token-6-14" morph="none" pos="word" start_char="1106">French</TOKEN>
<TOKEN end_char="1120" id="token-6-15" morph="none" pos="word" start_char="1113">National</TOKEN>
<TOKEN end_char="1130" id="token-6-16" morph="none" pos="word" start_char="1122">Institute</TOKEN>
<TOKEN end_char="1133" id="token-6-17" morph="none" pos="word" start_char="1132">of</TOKEN>
<TOKEN end_char="1140" id="token-6-18" morph="none" pos="word" start_char="1135">Health</TOKEN>
<TOKEN end_char="1144" id="token-6-19" morph="none" pos="word" start_char="1142">and</TOKEN>
<TOKEN end_char="1152" id="token-6-20" morph="none" pos="word" start_char="1146">Medical</TOKEN>
<TOKEN end_char="1161" id="token-6-21" morph="none" pos="word" start_char="1154">Research</TOKEN>
<TOKEN end_char="1163" id="token-6-22" morph="none" pos="punct" start_char="1163">–</TOKEN>
<TOKEN end_char="1168" id="token-6-23" morph="none" pos="word" start_char="1165">from</TOKEN>
<TOKEN end_char="1173" id="token-6-24" morph="none" pos="word" start_char="1170">2014</TOKEN>
<TOKEN end_char="1176" id="token-6-25" morph="none" pos="word" start_char="1175">to</TOKEN>
<TOKEN end_char="1181" id="token-6-26" morph="none" pos="word" start_char="1178">2018</TOKEN>
<TOKEN end_char="1182" id="token-6-27" morph="none" pos="punct" start_char="1182">,</TOKEN>
<TOKEN end_char="1187" id="token-6-28" morph="none" pos="word" start_char="1184">when</TOKEN>
<TOKEN end_char="1190" id="token-6-29" morph="none" pos="word" start_char="1189">he</TOKEN>
<TOKEN end_char="1194" id="token-6-30" morph="none" pos="word" start_char="1192">was</TOKEN>
<TOKEN end_char="1204" id="token-6-31" morph="none" pos="word" start_char="1196">appointed</TOKEN>
<TOKEN end_char="1207" id="token-6-32" morph="none" pos="word" start_char="1206">as</TOKEN>
<TOKEN end_char="1221" id="token-6-33" morph="none" pos="word" start_char="1209">extraordinary</TOKEN>
<TOKEN end_char="1227" id="token-6-34" morph="none" pos="word" start_char="1223">state</TOKEN>
<TOKEN end_char="1237" id="token-6-35" morph="none" pos="word" start_char="1229">councilor</TOKEN>
<TOKEN end_char="1241" id="token-6-36" morph="none" pos="word" start_char="1239">for</TOKEN>
<TOKEN end_char="1245" id="token-6-37" morph="none" pos="word" start_char="1243">the</TOKEN>
<TOKEN end_char="1252" id="token-6-38" morph="none" pos="word" start_char="1247">Macron</TOKEN>
<TOKEN end_char="1267" id="token-6-39" morph="none" pos="word" start_char="1254">administration</TOKEN>
<TOKEN end_char="1268" id="token-6-40" morph="none" pos="punct" start_char="1268">.</TOKEN>
</SEG>
<SEG end_char="1319" id="segment-7" start_char="1270">
<ORIGINAL_TEXT>Only 12 people in France have reached this status.</ORIGINAL_TEXT>
<TOKEN end_char="1273" id="token-7-0" morph="none" pos="word" start_char="1270">Only</TOKEN>
<TOKEN end_char="1276" id="token-7-1" morph="none" pos="word" start_char="1275">12</TOKEN>
<TOKEN end_char="1283" id="token-7-2" morph="none" pos="word" start_char="1278">people</TOKEN>
<TOKEN end_char="1286" id="token-7-3" morph="none" pos="word" start_char="1285">in</TOKEN>
<TOKEN end_char="1293" id="token-7-4" morph="none" pos="word" start_char="1288">France</TOKEN>
<TOKEN end_char="1298" id="token-7-5" morph="none" pos="word" start_char="1295">have</TOKEN>
<TOKEN end_char="1306" id="token-7-6" morph="none" pos="word" start_char="1300">reached</TOKEN>
<TOKEN end_char="1311" id="token-7-7" morph="none" pos="word" start_char="1308">this</TOKEN>
<TOKEN end_char="1318" id="token-7-8" morph="none" pos="word" start_char="1313">status</TOKEN>
<TOKEN end_char="1319" id="token-7-9" morph="none" pos="punct" start_char="1319">.</TOKEN>
</SEG>
<SEG end_char="1407" id="segment-8" start_char="1322">
<ORIGINAL_TEXT>Levy is married to Agnes Buzy, who until recently was minister of health under Macron.</ORIGINAL_TEXT>
<TOKEN end_char="1325" id="token-8-0" morph="none" pos="word" start_char="1322">Levy</TOKEN>
<TOKEN end_char="1328" id="token-8-1" morph="none" pos="word" start_char="1327">is</TOKEN>
<TOKEN end_char="1336" id="token-8-2" morph="none" pos="word" start_char="1330">married</TOKEN>
<TOKEN end_char="1339" id="token-8-3" morph="none" pos="word" start_char="1338">to</TOKEN>
<TOKEN end_char="1345" id="token-8-4" morph="none" pos="word" start_char="1341">Agnes</TOKEN>
<TOKEN end_char="1350" id="token-8-5" morph="none" pos="word" start_char="1347">Buzy</TOKEN>
<TOKEN end_char="1351" id="token-8-6" morph="none" pos="punct" start_char="1351">,</TOKEN>
<TOKEN end_char="1355" id="token-8-7" morph="none" pos="word" start_char="1353">who</TOKEN>
<TOKEN end_char="1361" id="token-8-8" morph="none" pos="word" start_char="1357">until</TOKEN>
<TOKEN end_char="1370" id="token-8-9" morph="none" pos="word" start_char="1363">recently</TOKEN>
<TOKEN end_char="1374" id="token-8-10" morph="none" pos="word" start_char="1372">was</TOKEN>
<TOKEN end_char="1383" id="token-8-11" morph="none" pos="word" start_char="1376">minister</TOKEN>
<TOKEN end_char="1386" id="token-8-12" morph="none" pos="word" start_char="1385">of</TOKEN>
<TOKEN end_char="1393" id="token-8-13" morph="none" pos="word" start_char="1388">health</TOKEN>
<TOKEN end_char="1399" id="token-8-14" morph="none" pos="word" start_char="1395">under</TOKEN>
<TOKEN end_char="1406" id="token-8-15" morph="none" pos="word" start_char="1401">Macron</TOKEN>
<TOKEN end_char="1407" id="token-8-16" morph="none" pos="punct" start_char="1407">.</TOKEN>
</SEG>
<SEG end_char="1650" id="segment-9" start_char="1409">
<ORIGINAL_TEXT>Buzy was essentially presented with an "offer you can’t refuse" by Macron’s party to leave the ministry – in the middle of the coronavirus crisis – and run for Mayor of Paris, where she was mercilessly trounced in the first round on March 16.</ORIGINAL_TEXT>
<TOKEN end_char="1412" id="token-9-0" morph="none" pos="word" start_char="1409">Buzy</TOKEN>
<TOKEN end_char="1416" id="token-9-1" morph="none" pos="word" start_char="1414">was</TOKEN>
<TOKEN end_char="1428" id="token-9-2" morph="none" pos="word" start_char="1418">essentially</TOKEN>
<TOKEN end_char="1438" id="token-9-3" morph="none" pos="word" start_char="1430">presented</TOKEN>
<TOKEN end_char="1443" id="token-9-4" morph="none" pos="word" start_char="1440">with</TOKEN>
<TOKEN end_char="1446" id="token-9-5" morph="none" pos="word" start_char="1445">an</TOKEN>
<TOKEN end_char="1448" id="token-9-6" morph="none" pos="punct" start_char="1448">"</TOKEN>
<TOKEN end_char="1453" id="token-9-7" morph="none" pos="word" start_char="1449">offer</TOKEN>
<TOKEN end_char="1457" id="token-9-8" morph="none" pos="word" start_char="1455">you</TOKEN>
<TOKEN end_char="1463" id="token-9-9" morph="none" pos="word" start_char="1459">can’t</TOKEN>
<TOKEN end_char="1470" id="token-9-10" morph="none" pos="word" start_char="1465">refuse</TOKEN>
<TOKEN end_char="1471" id="token-9-11" morph="none" pos="punct" start_char="1471">"</TOKEN>
<TOKEN end_char="1474" id="token-9-12" morph="none" pos="word" start_char="1473">by</TOKEN>
<TOKEN end_char="1483" id="token-9-13" morph="none" pos="word" start_char="1476">Macron’s</TOKEN>
<TOKEN end_char="1489" id="token-9-14" morph="none" pos="word" start_char="1485">party</TOKEN>
<TOKEN end_char="1492" id="token-9-15" morph="none" pos="word" start_char="1491">to</TOKEN>
<TOKEN end_char="1498" id="token-9-16" morph="none" pos="word" start_char="1494">leave</TOKEN>
<TOKEN end_char="1502" id="token-9-17" morph="none" pos="word" start_char="1500">the</TOKEN>
<TOKEN end_char="1511" id="token-9-18" morph="none" pos="word" start_char="1504">ministry</TOKEN>
<TOKEN end_char="1513" id="token-9-19" morph="none" pos="punct" start_char="1513">–</TOKEN>
<TOKEN end_char="1516" id="token-9-20" morph="none" pos="word" start_char="1515">in</TOKEN>
<TOKEN end_char="1520" id="token-9-21" morph="none" pos="word" start_char="1518">the</TOKEN>
<TOKEN end_char="1527" id="token-9-22" morph="none" pos="word" start_char="1522">middle</TOKEN>
<TOKEN end_char="1530" id="token-9-23" morph="none" pos="word" start_char="1529">of</TOKEN>
<TOKEN end_char="1534" id="token-9-24" morph="none" pos="word" start_char="1532">the</TOKEN>
<TOKEN end_char="1546" id="token-9-25" morph="none" pos="word" start_char="1536">coronavirus</TOKEN>
<TOKEN end_char="1553" id="token-9-26" morph="none" pos="word" start_char="1548">crisis</TOKEN>
<TOKEN end_char="1555" id="token-9-27" morph="none" pos="punct" start_char="1555">–</TOKEN>
<TOKEN end_char="1559" id="token-9-28" morph="none" pos="word" start_char="1557">and</TOKEN>
<TOKEN end_char="1563" id="token-9-29" morph="none" pos="word" start_char="1561">run</TOKEN>
<TOKEN end_char="1567" id="token-9-30" morph="none" pos="word" start_char="1565">for</TOKEN>
<TOKEN end_char="1573" id="token-9-31" morph="none" pos="word" start_char="1569">Mayor</TOKEN>
<TOKEN end_char="1576" id="token-9-32" morph="none" pos="word" start_char="1575">of</TOKEN>
<TOKEN end_char="1582" id="token-9-33" morph="none" pos="word" start_char="1578">Paris</TOKEN>
<TOKEN end_char="1583" id="token-9-34" morph="none" pos="punct" start_char="1583">,</TOKEN>
<TOKEN end_char="1589" id="token-9-35" morph="none" pos="word" start_char="1585">where</TOKEN>
<TOKEN end_char="1593" id="token-9-36" morph="none" pos="word" start_char="1591">she</TOKEN>
<TOKEN end_char="1597" id="token-9-37" morph="none" pos="word" start_char="1595">was</TOKEN>
<TOKEN end_char="1609" id="token-9-38" morph="none" pos="word" start_char="1599">mercilessly</TOKEN>
<TOKEN end_char="1618" id="token-9-39" morph="none" pos="word" start_char="1611">trounced</TOKEN>
<TOKEN end_char="1621" id="token-9-40" morph="none" pos="word" start_char="1620">in</TOKEN>
<TOKEN end_char="1625" id="token-9-41" morph="none" pos="word" start_char="1623">the</TOKEN>
<TOKEN end_char="1631" id="token-9-42" morph="none" pos="word" start_char="1627">first</TOKEN>
<TOKEN end_char="1637" id="token-9-43" morph="none" pos="word" start_char="1633">round</TOKEN>
<TOKEN end_char="1640" id="token-9-44" morph="none" pos="word" start_char="1639">on</TOKEN>
<TOKEN end_char="1646" id="token-9-45" morph="none" pos="word" start_char="1642">March</TOKEN>
<TOKEN end_char="1649" id="token-9-46" morph="none" pos="word" start_char="1648">16</TOKEN>
<TOKEN end_char="1650" id="token-9-47" morph="none" pos="punct" start_char="1650">.</TOKEN>
</SEG>
<SEG end_char="1792" id="segment-10" start_char="1653">
<ORIGINAL_TEXT>Levy has a vicious running feud with Professor Didier Raoult – prolific and often-cited Marseille-based specialist in communicable diseases.</ORIGINAL_TEXT>
<TOKEN end_char="1656" id="token-10-0" morph="none" pos="word" start_char="1653">Levy</TOKEN>
<TOKEN end_char="1660" id="token-10-1" morph="none" pos="word" start_char="1658">has</TOKEN>
<TOKEN end_char="1662" id="token-10-2" morph="none" pos="word" start_char="1662">a</TOKEN>
<TOKEN end_char="1670" id="token-10-3" morph="none" pos="word" start_char="1664">vicious</TOKEN>
<TOKEN end_char="1678" id="token-10-4" morph="none" pos="word" start_char="1672">running</TOKEN>
<TOKEN end_char="1683" id="token-10-5" morph="none" pos="word" start_char="1680">feud</TOKEN>
<TOKEN end_char="1688" id="token-10-6" morph="none" pos="word" start_char="1685">with</TOKEN>
<TOKEN end_char="1698" id="token-10-7" morph="none" pos="word" start_char="1690">Professor</TOKEN>
<TOKEN end_char="1705" id="token-10-8" morph="none" pos="word" start_char="1700">Didier</TOKEN>
<TOKEN end_char="1712" id="token-10-9" morph="none" pos="word" start_char="1707">Raoult</TOKEN>
<TOKEN end_char="1714" id="token-10-10" morph="none" pos="punct" start_char="1714">–</TOKEN>
<TOKEN end_char="1723" id="token-10-11" morph="none" pos="word" start_char="1716">prolific</TOKEN>
<TOKEN end_char="1727" id="token-10-12" morph="none" pos="word" start_char="1725">and</TOKEN>
<TOKEN end_char="1739" id="token-10-13" morph="none" pos="unknown" start_char="1729">often-cited</TOKEN>
<TOKEN end_char="1755" id="token-10-14" morph="none" pos="unknown" start_char="1741">Marseille-based</TOKEN>
<TOKEN end_char="1766" id="token-10-15" morph="none" pos="word" start_char="1757">specialist</TOKEN>
<TOKEN end_char="1769" id="token-10-16" morph="none" pos="word" start_char="1768">in</TOKEN>
<TOKEN end_char="1782" id="token-10-17" morph="none" pos="word" start_char="1771">communicable</TOKEN>
<TOKEN end_char="1791" id="token-10-18" morph="none" pos="word" start_char="1784">diseases</TOKEN>
<TOKEN end_char="1792" id="token-10-19" morph="none" pos="punct" start_char="1792">.</TOKEN>
</SEG>
<SEG end_char="1919" id="segment-11" start_char="1794">
<ORIGINAL_TEXT>Levy withheld the INSERM label from the world-renowned IHU (Hospital-University Institute) research center directed by Raoult.</ORIGINAL_TEXT>
<TOKEN end_char="1797" id="token-11-0" morph="none" pos="word" start_char="1794">Levy</TOKEN>
<TOKEN end_char="1806" id="token-11-1" morph="none" pos="word" start_char="1799">withheld</TOKEN>
<TOKEN end_char="1810" id="token-11-2" morph="none" pos="word" start_char="1808">the</TOKEN>
<TOKEN end_char="1817" id="token-11-3" morph="none" pos="word" start_char="1812">INSERM</TOKEN>
<TOKEN end_char="1823" id="token-11-4" morph="none" pos="word" start_char="1819">label</TOKEN>
<TOKEN end_char="1828" id="token-11-5" morph="none" pos="word" start_char="1825">from</TOKEN>
<TOKEN end_char="1832" id="token-11-6" morph="none" pos="word" start_char="1830">the</TOKEN>
<TOKEN end_char="1847" id="token-11-7" morph="none" pos="unknown" start_char="1834">world-renowned</TOKEN>
<TOKEN end_char="1851" id="token-11-8" morph="none" pos="word" start_char="1849">IHU</TOKEN>
<TOKEN end_char="1853" id="token-11-9" morph="none" pos="punct" start_char="1853">(</TOKEN>
<TOKEN end_char="1872" id="token-11-10" morph="none" pos="unknown" start_char="1854">Hospital-University</TOKEN>
<TOKEN end_char="1882" id="token-11-11" morph="none" pos="word" start_char="1874">Institute</TOKEN>
<TOKEN end_char="1883" id="token-11-12" morph="none" pos="punct" start_char="1883">)</TOKEN>
<TOKEN end_char="1892" id="token-11-13" morph="none" pos="word" start_char="1885">research</TOKEN>
<TOKEN end_char="1899" id="token-11-14" morph="none" pos="word" start_char="1894">center</TOKEN>
<TOKEN end_char="1908" id="token-11-15" morph="none" pos="word" start_char="1901">directed</TOKEN>
<TOKEN end_char="1911" id="token-11-16" morph="none" pos="word" start_char="1910">by</TOKEN>
<TOKEN end_char="1918" id="token-11-17" morph="none" pos="word" start_char="1913">Raoult</TOKEN>
<TOKEN end_char="1919" id="token-11-18" morph="none" pos="punct" start_char="1919">.</TOKEN>
</SEG>
<SEG end_char="2050" id="segment-12" start_char="1922">
<ORIGINAL_TEXT>In practice, in October 2019, Levy revoked the status of "foundation" of the different IHUs so he could take over their research.</ORIGINAL_TEXT>
<TOKEN end_char="1923" id="token-12-0" morph="none" pos="word" start_char="1922">In</TOKEN>
<TOKEN end_char="1932" id="token-12-1" morph="none" pos="word" start_char="1925">practice</TOKEN>
<TOKEN end_char="1933" id="token-12-2" morph="none" pos="punct" start_char="1933">,</TOKEN>
<TOKEN end_char="1936" id="token-12-3" morph="none" pos="word" start_char="1935">in</TOKEN>
<TOKEN end_char="1944" id="token-12-4" morph="none" pos="word" start_char="1938">October</TOKEN>
<TOKEN end_char="1949" id="token-12-5" morph="none" pos="word" start_char="1946">2019</TOKEN>
<TOKEN end_char="1950" id="token-12-6" morph="none" pos="punct" start_char="1950">,</TOKEN>
<TOKEN end_char="1955" id="token-12-7" morph="none" pos="word" start_char="1952">Levy</TOKEN>
<TOKEN end_char="1963" id="token-12-8" morph="none" pos="word" start_char="1957">revoked</TOKEN>
<TOKEN end_char="1967" id="token-12-9" morph="none" pos="word" start_char="1965">the</TOKEN>
<TOKEN end_char="1974" id="token-12-10" morph="none" pos="word" start_char="1969">status</TOKEN>
<TOKEN end_char="1977" id="token-12-11" morph="none" pos="word" start_char="1976">of</TOKEN>
<TOKEN end_char="1979" id="token-12-12" morph="none" pos="punct" start_char="1979">"</TOKEN>
<TOKEN end_char="1989" id="token-12-13" morph="none" pos="word" start_char="1980">foundation</TOKEN>
<TOKEN end_char="1990" id="token-12-14" morph="none" pos="punct" start_char="1990">"</TOKEN>
<TOKEN end_char="1993" id="token-12-15" morph="none" pos="word" start_char="1992">of</TOKEN>
<TOKEN end_char="1997" id="token-12-16" morph="none" pos="word" start_char="1995">the</TOKEN>
<TOKEN end_char="2007" id="token-12-17" morph="none" pos="word" start_char="1999">different</TOKEN>
<TOKEN end_char="2012" id="token-12-18" morph="none" pos="word" start_char="2009">IHUs</TOKEN>
<TOKEN end_char="2015" id="token-12-19" morph="none" pos="word" start_char="2014">so</TOKEN>
<TOKEN end_char="2018" id="token-12-20" morph="none" pos="word" start_char="2017">he</TOKEN>
<TOKEN end_char="2024" id="token-12-21" morph="none" pos="word" start_char="2020">could</TOKEN>
<TOKEN end_char="2029" id="token-12-22" morph="none" pos="word" start_char="2026">take</TOKEN>
<TOKEN end_char="2034" id="token-12-23" morph="none" pos="word" start_char="2031">over</TOKEN>
<TOKEN end_char="2040" id="token-12-24" morph="none" pos="word" start_char="2036">their</TOKEN>
<TOKEN end_char="2049" id="token-12-25" morph="none" pos="word" start_char="2042">research</TOKEN>
<TOKEN end_char="2050" id="token-12-26" morph="none" pos="punct" start_char="2050">.</TOKEN>
</SEG>
<SEG end_char="2198" id="segment-13" start_char="2053">
<ORIGINAL_TEXT>Raoult was part of a clinical trial that in which hydroxychloroquine and azithromycin healed 90% of Covid-19 cases if they were tested very early.</ORIGINAL_TEXT>
<TOKEN end_char="2058" id="token-13-0" morph="none" pos="word" start_char="2053">Raoult</TOKEN>
<TOKEN end_char="2062" id="token-13-1" morph="none" pos="word" start_char="2060">was</TOKEN>
<TOKEN end_char="2067" id="token-13-2" morph="none" pos="word" start_char="2064">part</TOKEN>
<TOKEN end_char="2070" id="token-13-3" morph="none" pos="word" start_char="2069">of</TOKEN>
<TOKEN end_char="2072" id="token-13-4" morph="none" pos="word" start_char="2072">a</TOKEN>
<TOKEN end_char="2081" id="token-13-5" morph="none" pos="word" start_char="2074">clinical</TOKEN>
<TOKEN end_char="2087" id="token-13-6" morph="none" pos="word" start_char="2083">trial</TOKEN>
<TOKEN end_char="2092" id="token-13-7" morph="none" pos="word" start_char="2089">that</TOKEN>
<TOKEN end_char="2095" id="token-13-8" morph="none" pos="word" start_char="2094">in</TOKEN>
<TOKEN end_char="2101" id="token-13-9" morph="none" pos="word" start_char="2097">which</TOKEN>
<TOKEN end_char="2120" id="token-13-10" morph="none" pos="word" start_char="2103">hydroxychloroquine</TOKEN>
<TOKEN end_char="2124" id="token-13-11" morph="none" pos="word" start_char="2122">and</TOKEN>
<TOKEN end_char="2137" id="token-13-12" morph="none" pos="word" start_char="2126">azithromycin</TOKEN>
<TOKEN end_char="2144" id="token-13-13" morph="none" pos="word" start_char="2139">healed</TOKEN>
<TOKEN end_char="2147" id="token-13-14" morph="none" pos="word" start_char="2146">90</TOKEN>
<TOKEN end_char="2148" id="token-13-15" morph="none" pos="punct" start_char="2148">%</TOKEN>
<TOKEN end_char="2151" id="token-13-16" morph="none" pos="word" start_char="2150">of</TOKEN>
<TOKEN end_char="2160" id="token-13-17" morph="none" pos="unknown" start_char="2153">Covid-19</TOKEN>
<TOKEN end_char="2166" id="token-13-18" morph="none" pos="word" start_char="2162">cases</TOKEN>
<TOKEN end_char="2169" id="token-13-19" morph="none" pos="word" start_char="2168">if</TOKEN>
<TOKEN end_char="2174" id="token-13-20" morph="none" pos="word" start_char="2171">they</TOKEN>
<TOKEN end_char="2179" id="token-13-21" morph="none" pos="word" start_char="2176">were</TOKEN>
<TOKEN end_char="2186" id="token-13-22" morph="none" pos="word" start_char="2181">tested</TOKEN>
<TOKEN end_char="2191" id="token-13-23" morph="none" pos="word" start_char="2188">very</TOKEN>
<TOKEN end_char="2197" id="token-13-24" morph="none" pos="word" start_char="2193">early</TOKEN>
<TOKEN end_char="2198" id="token-13-25" morph="none" pos="punct" start_char="2198">.</TOKEN>
</SEG>
<SEG end_char="2280" id="segment-14" start_char="2200">
<ORIGINAL_TEXT>(Early, massive testing is at the heart of the successful South Korean strategy.)</ORIGINAL_TEXT>
<TOKEN end_char="2200" id="token-14-0" morph="none" pos="punct" start_char="2200">(</TOKEN>
<TOKEN end_char="2205" id="token-14-1" morph="none" pos="word" start_char="2201">Early</TOKEN>
<TOKEN end_char="2206" id="token-14-2" morph="none" pos="punct" start_char="2206">,</TOKEN>
<TOKEN end_char="2214" id="token-14-3" morph="none" pos="word" start_char="2208">massive</TOKEN>
<TOKEN end_char="2222" id="token-14-4" morph="none" pos="word" start_char="2216">testing</TOKEN>
<TOKEN end_char="2225" id="token-14-5" morph="none" pos="word" start_char="2224">is</TOKEN>
<TOKEN end_char="2228" id="token-14-6" morph="none" pos="word" start_char="2227">at</TOKEN>
<TOKEN end_char="2232" id="token-14-7" morph="none" pos="word" start_char="2230">the</TOKEN>
<TOKEN end_char="2238" id="token-14-8" morph="none" pos="word" start_char="2234">heart</TOKEN>
<TOKEN end_char="2241" id="token-14-9" morph="none" pos="word" start_char="2240">of</TOKEN>
<TOKEN end_char="2245" id="token-14-10" morph="none" pos="word" start_char="2243">the</TOKEN>
<TOKEN end_char="2256" id="token-14-11" morph="none" pos="word" start_char="2247">successful</TOKEN>
<TOKEN end_char="2262" id="token-14-12" morph="none" pos="word" start_char="2258">South</TOKEN>
<TOKEN end_char="2269" id="token-14-13" morph="none" pos="word" start_char="2264">Korean</TOKEN>
<TOKEN end_char="2278" id="token-14-14" morph="none" pos="word" start_char="2271">strategy</TOKEN>
<TOKEN end_char="2280" id="token-14-15" morph="none" pos="punct" start_char="2279">.)</TOKEN>
</SEG>
<SEG end_char="2423" id="segment-15" start_char="2283">
<ORIGINAL_TEXT>Raoult is opposed to the total lockdown of sane individuals and possible carriers – which he considers "medieval," in an anachronistic sense.</ORIGINAL_TEXT>
<TOKEN end_char="2288" id="token-15-0" morph="none" pos="word" start_char="2283">Raoult</TOKEN>
<TOKEN end_char="2291" id="token-15-1" morph="none" pos="word" start_char="2290">is</TOKEN>
<TOKEN end_char="2299" id="token-15-2" morph="none" pos="word" start_char="2293">opposed</TOKEN>
<TOKEN end_char="2302" id="token-15-3" morph="none" pos="word" start_char="2301">to</TOKEN>
<TOKEN end_char="2306" id="token-15-4" morph="none" pos="word" start_char="2304">the</TOKEN>
<TOKEN end_char="2312" id="token-15-5" morph="none" pos="word" start_char="2308">total</TOKEN>
<TOKEN end_char="2321" id="token-15-6" morph="none" pos="word" start_char="2314">lockdown</TOKEN>
<TOKEN end_char="2324" id="token-15-7" morph="none" pos="word" start_char="2323">of</TOKEN>
<TOKEN end_char="2329" id="token-15-8" morph="none" pos="word" start_char="2326">sane</TOKEN>
<TOKEN end_char="2341" id="token-15-9" morph="none" pos="word" start_char="2331">individuals</TOKEN>
<TOKEN end_char="2345" id="token-15-10" morph="none" pos="word" start_char="2343">and</TOKEN>
<TOKEN end_char="2354" id="token-15-11" morph="none" pos="word" start_char="2347">possible</TOKEN>
<TOKEN end_char="2363" id="token-15-12" morph="none" pos="word" start_char="2356">carriers</TOKEN>
<TOKEN end_char="2365" id="token-15-13" morph="none" pos="punct" start_char="2365">–</TOKEN>
<TOKEN end_char="2371" id="token-15-14" morph="none" pos="word" start_char="2367">which</TOKEN>
<TOKEN end_char="2374" id="token-15-15" morph="none" pos="word" start_char="2373">he</TOKEN>
<TOKEN end_char="2384" id="token-15-16" morph="none" pos="word" start_char="2376">considers</TOKEN>
<TOKEN end_char="2386" id="token-15-17" morph="none" pos="punct" start_char="2386">"</TOKEN>
<TOKEN end_char="2394" id="token-15-18" morph="none" pos="word" start_char="2387">medieval</TOKEN>
<TOKEN end_char="2396" id="token-15-19" morph="none" pos="punct" start_char="2395">,"</TOKEN>
<TOKEN end_char="2399" id="token-15-20" morph="none" pos="word" start_char="2398">in</TOKEN>
<TOKEN end_char="2402" id="token-15-21" morph="none" pos="word" start_char="2401">an</TOKEN>
<TOKEN end_char="2416" id="token-15-22" morph="none" pos="word" start_char="2404">anachronistic</TOKEN>
<TOKEN end_char="2422" id="token-15-23" morph="none" pos="word" start_char="2418">sense</TOKEN>
<TOKEN end_char="2423" id="token-15-24" morph="none" pos="punct" start_char="2423">.</TOKEN>
</SEG>
<SEG end_char="2580" id="segment-16" start_char="2425">
<ORIGINAL_TEXT>He’s in favor of massive testing (which, besides South Korea, was successful in Singapore, Taiwan and Vietnam) and a fast treatment with hydroxychloroquine.</ORIGINAL_TEXT>
<TOKEN end_char="2428" id="token-16-0" morph="none" pos="word" start_char="2425">He’s</TOKEN>
<TOKEN end_char="2431" id="token-16-1" morph="none" pos="word" start_char="2430">in</TOKEN>
<TOKEN end_char="2437" id="token-16-2" morph="none" pos="word" start_char="2433">favor</TOKEN>
<TOKEN end_char="2440" id="token-16-3" morph="none" pos="word" start_char="2439">of</TOKEN>
<TOKEN end_char="2448" id="token-16-4" morph="none" pos="word" start_char="2442">massive</TOKEN>
<TOKEN end_char="2456" id="token-16-5" morph="none" pos="word" start_char="2450">testing</TOKEN>
<TOKEN end_char="2458" id="token-16-6" morph="none" pos="punct" start_char="2458">(</TOKEN>
<TOKEN end_char="2463" id="token-16-7" morph="none" pos="word" start_char="2459">which</TOKEN>
<TOKEN end_char="2464" id="token-16-8" morph="none" pos="punct" start_char="2464">,</TOKEN>
<TOKEN end_char="2472" id="token-16-9" morph="none" pos="word" start_char="2466">besides</TOKEN>
<TOKEN end_char="2478" id="token-16-10" morph="none" pos="word" start_char="2474">South</TOKEN>
<TOKEN end_char="2484" id="token-16-11" morph="none" pos="word" start_char="2480">Korea</TOKEN>
<TOKEN end_char="2485" id="token-16-12" morph="none" pos="punct" start_char="2485">,</TOKEN>
<TOKEN end_char="2489" id="token-16-13" morph="none" pos="word" start_char="2487">was</TOKEN>
<TOKEN end_char="2500" id="token-16-14" morph="none" pos="word" start_char="2491">successful</TOKEN>
<TOKEN end_char="2503" id="token-16-15" morph="none" pos="word" start_char="2502">in</TOKEN>
<TOKEN end_char="2513" id="token-16-16" morph="none" pos="word" start_char="2505">Singapore</TOKEN>
<TOKEN end_char="2514" id="token-16-17" morph="none" pos="punct" start_char="2514">,</TOKEN>
<TOKEN end_char="2521" id="token-16-18" morph="none" pos="word" start_char="2516">Taiwan</TOKEN>
<TOKEN end_char="2525" id="token-16-19" morph="none" pos="word" start_char="2523">and</TOKEN>
<TOKEN end_char="2533" id="token-16-20" morph="none" pos="word" start_char="2527">Vietnam</TOKEN>
<TOKEN end_char="2534" id="token-16-21" morph="none" pos="punct" start_char="2534">)</TOKEN>
<TOKEN end_char="2538" id="token-16-22" morph="none" pos="word" start_char="2536">and</TOKEN>
<TOKEN end_char="2540" id="token-16-23" morph="none" pos="word" start_char="2540">a</TOKEN>
<TOKEN end_char="2545" id="token-16-24" morph="none" pos="word" start_char="2542">fast</TOKEN>
<TOKEN end_char="2555" id="token-16-25" morph="none" pos="word" start_char="2547">treatment</TOKEN>
<TOKEN end_char="2560" id="token-16-26" morph="none" pos="word" start_char="2557">with</TOKEN>
<TOKEN end_char="2579" id="token-16-27" morph="none" pos="word" start_char="2562">hydroxychloroquine</TOKEN>
<TOKEN end_char="2580" id="token-16-28" morph="none" pos="punct" start_char="2580">.</TOKEN>
</SEG>
<SEG end_char="2630" id="segment-17" start_char="2582">
<ORIGINAL_TEXT>Only contaminated individuals should be confined.</ORIGINAL_TEXT>
<TOKEN end_char="2585" id="token-17-0" morph="none" pos="word" start_char="2582">Only</TOKEN>
<TOKEN end_char="2598" id="token-17-1" morph="none" pos="word" start_char="2587">contaminated</TOKEN>
<TOKEN end_char="2610" id="token-17-2" morph="none" pos="word" start_char="2600">individuals</TOKEN>
<TOKEN end_char="2617" id="token-17-3" morph="none" pos="word" start_char="2612">should</TOKEN>
<TOKEN end_char="2620" id="token-17-4" morph="none" pos="word" start_char="2619">be</TOKEN>
<TOKEN end_char="2629" id="token-17-5" morph="none" pos="word" start_char="2622">confined</TOKEN>
<TOKEN end_char="2630" id="token-17-6" morph="none" pos="punct" start_char="2630">.</TOKEN>
</SEG>
<SEG end_char="2673" id="segment-18" start_char="2633">
<ORIGINAL_TEXT>Chloroquine costs one euro for ten pills.</ORIGINAL_TEXT>
<TOKEN end_char="2643" id="token-18-0" morph="none" pos="word" start_char="2633">Chloroquine</TOKEN>
<TOKEN end_char="2649" id="token-18-1" morph="none" pos="word" start_char="2645">costs</TOKEN>
<TOKEN end_char="2653" id="token-18-2" morph="none" pos="word" start_char="2651">one</TOKEN>
<TOKEN end_char="2658" id="token-18-3" morph="none" pos="word" start_char="2655">euro</TOKEN>
<TOKEN end_char="2662" id="token-18-4" morph="none" pos="word" start_char="2660">for</TOKEN>
<TOKEN end_char="2666" id="token-18-5" morph="none" pos="word" start_char="2664">ten</TOKEN>
<TOKEN end_char="2672" id="token-18-6" morph="none" pos="word" start_char="2668">pills</TOKEN>
<TOKEN end_char="2673" id="token-18-7" morph="none" pos="punct" start_char="2673">.</TOKEN>
<TRANSLATED_TEXT>Cloroquin koster 1 euro for 10 piller.</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="2836" id="segment-19" start_char="2675">
<ORIGINAL_TEXT>And there’s the rub: Big Pharma – which, crucially, finances INSERM, and includes "national champion" Sanofi – would rather go for a way more profitable solution.</ORIGINAL_TEXT>
<TOKEN end_char="2677" id="token-19-0" morph="none" pos="word" start_char="2675">And</TOKEN>
<TOKEN end_char="2685" id="token-19-1" morph="none" pos="word" start_char="2679">there’s</TOKEN>
<TOKEN end_char="2689" id="token-19-2" morph="none" pos="word" start_char="2687">the</TOKEN>
<TOKEN end_char="2693" id="token-19-3" morph="none" pos="word" start_char="2691">rub</TOKEN>
<TOKEN end_char="2694" id="token-19-4" morph="none" pos="punct" start_char="2694">:</TOKEN>
<TOKEN end_char="2698" id="token-19-5" morph="none" pos="word" start_char="2696">Big</TOKEN>
<TOKEN end_char="2705" id="token-19-6" morph="none" pos="word" start_char="2700">Pharma</TOKEN>
<TOKEN end_char="2707" id="token-19-7" morph="none" pos="punct" start_char="2707">–</TOKEN>
<TOKEN end_char="2713" id="token-19-8" morph="none" pos="word" start_char="2709">which</TOKEN>
<TOKEN end_char="2714" id="token-19-9" morph="none" pos="punct" start_char="2714">,</TOKEN>
<TOKEN end_char="2724" id="token-19-10" morph="none" pos="word" start_char="2716">crucially</TOKEN>
<TOKEN end_char="2725" id="token-19-11" morph="none" pos="punct" start_char="2725">,</TOKEN>
<TOKEN end_char="2734" id="token-19-12" morph="none" pos="word" start_char="2727">finances</TOKEN>
<TOKEN end_char="2741" id="token-19-13" morph="none" pos="word" start_char="2736">INSERM</TOKEN>
<TOKEN end_char="2742" id="token-19-14" morph="none" pos="punct" start_char="2742">,</TOKEN>
<TOKEN end_char="2746" id="token-19-15" morph="none" pos="word" start_char="2744">and</TOKEN>
<TOKEN end_char="2755" id="token-19-16" morph="none" pos="word" start_char="2748">includes</TOKEN>
<TOKEN end_char="2757" id="token-19-17" morph="none" pos="punct" start_char="2757">"</TOKEN>
<TOKEN end_char="2765" id="token-19-18" morph="none" pos="word" start_char="2758">national</TOKEN>
<TOKEN end_char="2774" id="token-19-19" morph="none" pos="word" start_char="2767">champion</TOKEN>
<TOKEN end_char="2775" id="token-19-20" morph="none" pos="punct" start_char="2775">"</TOKEN>
<TOKEN end_char="2782" id="token-19-21" morph="none" pos="word" start_char="2777">Sanofi</TOKEN>
<TOKEN end_char="2784" id="token-19-22" morph="none" pos="punct" start_char="2784">–</TOKEN>
<TOKEN end_char="2790" id="token-19-23" morph="none" pos="word" start_char="2786">would</TOKEN>
<TOKEN end_char="2797" id="token-19-24" morph="none" pos="word" start_char="2792">rather</TOKEN>
<TOKEN end_char="2800" id="token-19-25" morph="none" pos="word" start_char="2799">go</TOKEN>
<TOKEN end_char="2804" id="token-19-26" morph="none" pos="word" start_char="2802">for</TOKEN>
<TOKEN end_char="2806" id="token-19-27" morph="none" pos="word" start_char="2806">a</TOKEN>
<TOKEN end_char="2810" id="token-19-28" morph="none" pos="word" start_char="2808">way</TOKEN>
<TOKEN end_char="2815" id="token-19-29" morph="none" pos="word" start_char="2812">more</TOKEN>
<TOKEN end_char="2826" id="token-19-30" morph="none" pos="word" start_char="2817">profitable</TOKEN>
<TOKEN end_char="2835" id="token-19-31" morph="none" pos="word" start_char="2828">solution</TOKEN>
<TOKEN end_char="2836" id="token-19-32" morph="none" pos="punct" start_char="2836">.</TOKEN>
</SEG>
<SEG end_char="2979" id="segment-20" start_char="2838">
<ORIGINAL_TEXT>Sanofi for the moment says it is "actively preparing" to produce chloroquine, but that may take "weeks," and there’s no mention about pricing.</ORIGINAL_TEXT>
<TOKEN end_char="2843" id="token-20-0" morph="none" pos="word" start_char="2838">Sanofi</TOKEN>
<TOKEN end_char="2847" id="token-20-1" morph="none" pos="word" start_char="2845">for</TOKEN>
<TOKEN end_char="2851" id="token-20-2" morph="none" pos="word" start_char="2849">the</TOKEN>
<TOKEN end_char="2858" id="token-20-3" morph="none" pos="word" start_char="2853">moment</TOKEN>
<TOKEN end_char="2863" id="token-20-4" morph="none" pos="word" start_char="2860">says</TOKEN>
<TOKEN end_char="2866" id="token-20-5" morph="none" pos="word" start_char="2865">it</TOKEN>
<TOKEN end_char="2869" id="token-20-6" morph="none" pos="word" start_char="2868">is</TOKEN>
<TOKEN end_char="2871" id="token-20-7" morph="none" pos="punct" start_char="2871">"</TOKEN>
<TOKEN end_char="2879" id="token-20-8" morph="none" pos="word" start_char="2872">actively</TOKEN>
<TOKEN end_char="2889" id="token-20-9" morph="none" pos="word" start_char="2881">preparing</TOKEN>
<TOKEN end_char="2890" id="token-20-10" morph="none" pos="punct" start_char="2890">"</TOKEN>
<TOKEN end_char="2893" id="token-20-11" morph="none" pos="word" start_char="2892">to</TOKEN>
<TOKEN end_char="2901" id="token-20-12" morph="none" pos="word" start_char="2895">produce</TOKEN>
<TOKEN end_char="2913" id="token-20-13" morph="none" pos="word" start_char="2903">chloroquine</TOKEN>
<TOKEN end_char="2914" id="token-20-14" morph="none" pos="punct" start_char="2914">,</TOKEN>
<TOKEN end_char="2918" id="token-20-15" morph="none" pos="word" start_char="2916">but</TOKEN>
<TOKEN end_char="2923" id="token-20-16" morph="none" pos="word" start_char="2920">that</TOKEN>
<TOKEN end_char="2927" id="token-20-17" morph="none" pos="word" start_char="2925">may</TOKEN>
<TOKEN end_char="2932" id="token-20-18" morph="none" pos="word" start_char="2929">take</TOKEN>
<TOKEN end_char="2934" id="token-20-19" morph="none" pos="punct" start_char="2934">"</TOKEN>
<TOKEN end_char="2939" id="token-20-20" morph="none" pos="word" start_char="2935">weeks</TOKEN>
<TOKEN end_char="2941" id="token-20-21" morph="none" pos="punct" start_char="2940">,"</TOKEN>
<TOKEN end_char="2945" id="token-20-22" morph="none" pos="word" start_char="2943">and</TOKEN>
<TOKEN end_char="2953" id="token-20-23" morph="none" pos="word" start_char="2947">there’s</TOKEN>
<TOKEN end_char="2956" id="token-20-24" morph="none" pos="word" start_char="2955">no</TOKEN>
<TOKEN end_char="2964" id="token-20-25" morph="none" pos="word" start_char="2958">mention</TOKEN>
<TOKEN end_char="2970" id="token-20-26" morph="none" pos="word" start_char="2966">about</TOKEN>
<TOKEN end_char="2978" id="token-20-27" morph="none" pos="word" start_char="2972">pricing</TOKEN>
<TOKEN end_char="2979" id="token-20-28" morph="none" pos="punct" start_char="2979">.</TOKEN>
</SEG>
<SEG end_char="3009" id="segment-21" start_char="2982">
<ORIGINAL_TEXT>A minister fleeing a tsunami</ORIGINAL_TEXT>
<TOKEN end_char="2982" id="token-21-0" morph="none" pos="word" start_char="2982">A</TOKEN>
<TOKEN end_char="2991" id="token-21-1" morph="none" pos="word" start_char="2984">minister</TOKEN>
<TOKEN end_char="2999" id="token-21-2" morph="none" pos="word" start_char="2993">fleeing</TOKEN>
<TOKEN end_char="3001" id="token-21-3" morph="none" pos="word" start_char="3001">a</TOKEN>
<TOKEN end_char="3009" id="token-21-4" morph="none" pos="word" start_char="3003">tsunami</TOKEN>
</SEG>
<SEG end_char="3031" id="segment-22" start_char="3012">
<ORIGINAL_TEXT>Here’s the timeline:</ORIGINAL_TEXT>
<TOKEN end_char="3017" id="token-22-0" morph="none" pos="word" start_char="3012">Here’s</TOKEN>
<TOKEN end_char="3021" id="token-22-1" morph="none" pos="word" start_char="3019">the</TOKEN>
<TOKEN end_char="3030" id="token-22-2" morph="none" pos="word" start_char="3023">timeline</TOKEN>
<TOKEN end_char="3031" id="token-22-3" morph="none" pos="punct" start_char="3031">:</TOKEN>
</SEG>
<SEG end_char="3187" id="segment-23" start_char="3034">
<ORIGINAL_TEXT>On January 13, Agnes Buzyn, still France’s Health Minister, classifies chloroquine as a "poisonous substance," from now on only available by prescription.</ORIGINAL_TEXT>
<TOKEN end_char="3035" id="token-23-0" morph="none" pos="word" start_char="3034">On</TOKEN>
<TOKEN end_char="3043" id="token-23-1" morph="none" pos="word" start_char="3037">January</TOKEN>
<TOKEN end_char="3046" id="token-23-2" morph="none" pos="word" start_char="3045">13</TOKEN>
<TOKEN end_char="3047" id="token-23-3" morph="none" pos="punct" start_char="3047">,</TOKEN>
<TOKEN end_char="3053" id="token-23-4" morph="none" pos="word" start_char="3049">Agnes</TOKEN>
<TOKEN end_char="3059" id="token-23-5" morph="none" pos="word" start_char="3055">Buzyn</TOKEN>
<TOKEN end_char="3060" id="token-23-6" morph="none" pos="punct" start_char="3060">,</TOKEN>
<TOKEN end_char="3066" id="token-23-7" morph="none" pos="word" start_char="3062">still</TOKEN>
<TOKEN end_char="3075" id="token-23-8" morph="none" pos="word" start_char="3068">France’s</TOKEN>
<TOKEN end_char="3082" id="token-23-9" morph="none" pos="word" start_char="3077">Health</TOKEN>
<TOKEN end_char="3091" id="token-23-10" morph="none" pos="word" start_char="3084">Minister</TOKEN>
<TOKEN end_char="3092" id="token-23-11" morph="none" pos="punct" start_char="3092">,</TOKEN>
<TOKEN end_char="3103" id="token-23-12" morph="none" pos="word" start_char="3094">classifies</TOKEN>
<TOKEN end_char="3115" id="token-23-13" morph="none" pos="word" start_char="3105">chloroquine</TOKEN>
<TOKEN end_char="3118" id="token-23-14" morph="none" pos="word" start_char="3117">as</TOKEN>
<TOKEN end_char="3120" id="token-23-15" morph="none" pos="word" start_char="3120">a</TOKEN>
<TOKEN end_char="3122" id="token-23-16" morph="none" pos="punct" start_char="3122">"</TOKEN>
<TOKEN end_char="3131" id="token-23-17" morph="none" pos="word" start_char="3123">poisonous</TOKEN>
<TOKEN end_char="3141" id="token-23-18" morph="none" pos="word" start_char="3133">substance</TOKEN>
<TOKEN end_char="3143" id="token-23-19" morph="none" pos="punct" start_char="3142">,"</TOKEN>
<TOKEN end_char="3148" id="token-23-20" morph="none" pos="word" start_char="3145">from</TOKEN>
<TOKEN end_char="3152" id="token-23-21" morph="none" pos="word" start_char="3150">now</TOKEN>
<TOKEN end_char="3155" id="token-23-22" morph="none" pos="word" start_char="3154">on</TOKEN>
<TOKEN end_char="3160" id="token-23-23" morph="none" pos="word" start_char="3157">only</TOKEN>
<TOKEN end_char="3170" id="token-23-24" morph="none" pos="word" start_char="3162">available</TOKEN>
<TOKEN end_char="3173" id="token-23-25" morph="none" pos="word" start_char="3172">by</TOKEN>
<TOKEN end_char="3186" id="token-23-26" morph="none" pos="word" start_char="3175">prescription</TOKEN>
<TOKEN end_char="3187" id="token-23-27" morph="none" pos="punct" start_char="3187">.</TOKEN>
</SEG>
<SEG end_char="3286" id="segment-24" start_char="3189">
<ORIGINAL_TEXT>An astonishing move, considering that it has been sold off the shelf in France for half a century.</ORIGINAL_TEXT>
<TOKEN end_char="3190" id="token-24-0" morph="none" pos="word" start_char="3189">An</TOKEN>
<TOKEN end_char="3202" id="token-24-1" morph="none" pos="word" start_char="3192">astonishing</TOKEN>
<TOKEN end_char="3207" id="token-24-2" morph="none" pos="word" start_char="3204">move</TOKEN>
<TOKEN end_char="3208" id="token-24-3" morph="none" pos="punct" start_char="3208">,</TOKEN>
<TOKEN end_char="3220" id="token-24-4" morph="none" pos="word" start_char="3210">considering</TOKEN>
<TOKEN end_char="3225" id="token-24-5" morph="none" pos="word" start_char="3222">that</TOKEN>
<TOKEN end_char="3228" id="token-24-6" morph="none" pos="word" start_char="3227">it</TOKEN>
<TOKEN end_char="3232" id="token-24-7" morph="none" pos="word" start_char="3230">has</TOKEN>
<TOKEN end_char="3237" id="token-24-8" morph="none" pos="word" start_char="3234">been</TOKEN>
<TOKEN end_char="3242" id="token-24-9" morph="none" pos="word" start_char="3239">sold</TOKEN>
<TOKEN end_char="3246" id="token-24-10" morph="none" pos="word" start_char="3244">off</TOKEN>
<TOKEN end_char="3250" id="token-24-11" morph="none" pos="word" start_char="3248">the</TOKEN>
<TOKEN end_char="3256" id="token-24-12" morph="none" pos="word" start_char="3252">shelf</TOKEN>
<TOKEN end_char="3259" id="token-24-13" morph="none" pos="word" start_char="3258">in</TOKEN>
<TOKEN end_char="3266" id="token-24-14" morph="none" pos="word" start_char="3261">France</TOKEN>
<TOKEN end_char="3270" id="token-24-15" morph="none" pos="word" start_char="3268">for</TOKEN>
<TOKEN end_char="3275" id="token-24-16" morph="none" pos="word" start_char="3272">half</TOKEN>
<TOKEN end_char="3277" id="token-24-17" morph="none" pos="word" start_char="3277">a</TOKEN>
<TOKEN end_char="3285" id="token-24-18" morph="none" pos="word" start_char="3279">century</TOKEN>
<TOKEN end_char="3286" id="token-24-19" morph="none" pos="punct" start_char="3286">.</TOKEN>
</SEG>
<SEG end_char="3349" id="segment-25" start_char="3289">
<ORIGINAL_TEXT>On March 16, the Macron government orders a partial lockdown.</ORIGINAL_TEXT>
<TOKEN end_char="3290" id="token-25-0" morph="none" pos="word" start_char="3289">On</TOKEN>
<TOKEN end_char="3296" id="token-25-1" morph="none" pos="word" start_char="3292">March</TOKEN>
<TOKEN end_char="3299" id="token-25-2" morph="none" pos="word" start_char="3298">16</TOKEN>
<TOKEN end_char="3300" id="token-25-3" morph="none" pos="punct" start_char="3300">,</TOKEN>
<TOKEN end_char="3304" id="token-25-4" morph="none" pos="word" start_char="3302">the</TOKEN>
<TOKEN end_char="3311" id="token-25-5" morph="none" pos="word" start_char="3306">Macron</TOKEN>
<TOKEN end_char="3322" id="token-25-6" morph="none" pos="word" start_char="3313">government</TOKEN>
<TOKEN end_char="3329" id="token-25-7" morph="none" pos="word" start_char="3324">orders</TOKEN>
<TOKEN end_char="3331" id="token-25-8" morph="none" pos="word" start_char="3331">a</TOKEN>
<TOKEN end_char="3339" id="token-25-9" morph="none" pos="word" start_char="3333">partial</TOKEN>
<TOKEN end_char="3348" id="token-25-10" morph="none" pos="word" start_char="3341">lockdown</TOKEN>
<TOKEN end_char="3349" id="token-25-11" morph="none" pos="punct" start_char="3349">.</TOKEN>
</SEG>
<SEG end_char="3387" id="segment-26" start_char="3351">
<ORIGINAL_TEXT>There’s not a peep about chloroquine.</ORIGINAL_TEXT>
<TOKEN end_char="3357" id="token-26-0" morph="none" pos="word" start_char="3351">There’s</TOKEN>
<TOKEN end_char="3361" id="token-26-1" morph="none" pos="word" start_char="3359">not</TOKEN>
<TOKEN end_char="3363" id="token-26-2" morph="none" pos="word" start_char="3363">a</TOKEN>
<TOKEN end_char="3368" id="token-26-3" morph="none" pos="word" start_char="3365">peep</TOKEN>
<TOKEN end_char="3374" id="token-26-4" morph="none" pos="word" start_char="3370">about</TOKEN>
<TOKEN end_char="3386" id="token-26-5" morph="none" pos="word" start_char="3376">chloroquine</TOKEN>
<TOKEN end_char="3387" id="token-26-6" morph="none" pos="punct" start_char="3387">.</TOKEN>
</SEG>
<SEG end_char="3522" id="segment-27" start_char="3389">
<ORIGINAL_TEXT>Police initially are not required to wear masks; most have been stolen anyway, and there are not enough masks even for health workers.</ORIGINAL_TEXT>
<TOKEN end_char="3394" id="token-27-0" morph="none" pos="word" start_char="3389">Police</TOKEN>
<TOKEN end_char="3404" id="token-27-1" morph="none" pos="word" start_char="3396">initially</TOKEN>
<TOKEN end_char="3408" id="token-27-2" morph="none" pos="word" start_char="3406">are</TOKEN>
<TOKEN end_char="3412" id="token-27-3" morph="none" pos="word" start_char="3410">not</TOKEN>
<TOKEN end_char="3421" id="token-27-4" morph="none" pos="word" start_char="3414">required</TOKEN>
<TOKEN end_char="3424" id="token-27-5" morph="none" pos="word" start_char="3423">to</TOKEN>
<TOKEN end_char="3429" id="token-27-6" morph="none" pos="word" start_char="3426">wear</TOKEN>
<TOKEN end_char="3435" id="token-27-7" morph="none" pos="word" start_char="3431">masks</TOKEN>
<TOKEN end_char="3436" id="token-27-8" morph="none" pos="punct" start_char="3436">;</TOKEN>
<TOKEN end_char="3441" id="token-27-9" morph="none" pos="word" start_char="3438">most</TOKEN>
<TOKEN end_char="3446" id="token-27-10" morph="none" pos="word" start_char="3443">have</TOKEN>
<TOKEN end_char="3451" id="token-27-11" morph="none" pos="word" start_char="3448">been</TOKEN>
<TOKEN end_char="3458" id="token-27-12" morph="none" pos="word" start_char="3453">stolen</TOKEN>
<TOKEN end_char="3465" id="token-27-13" morph="none" pos="word" start_char="3460">anyway</TOKEN>
<TOKEN end_char="3466" id="token-27-14" morph="none" pos="punct" start_char="3466">,</TOKEN>
<TOKEN end_char="3470" id="token-27-15" morph="none" pos="word" start_char="3468">and</TOKEN>
<TOKEN end_char="3476" id="token-27-16" morph="none" pos="word" start_char="3472">there</TOKEN>
<TOKEN end_char="3480" id="token-27-17" morph="none" pos="word" start_char="3478">are</TOKEN>
<TOKEN end_char="3484" id="token-27-18" morph="none" pos="word" start_char="3482">not</TOKEN>
<TOKEN end_char="3491" id="token-27-19" morph="none" pos="word" start_char="3486">enough</TOKEN>
<TOKEN end_char="3497" id="token-27-20" morph="none" pos="word" start_char="3493">masks</TOKEN>
<TOKEN end_char="3502" id="token-27-21" morph="none" pos="word" start_char="3499">even</TOKEN>
<TOKEN end_char="3506" id="token-27-22" morph="none" pos="word" start_char="3504">for</TOKEN>
<TOKEN end_char="3513" id="token-27-23" morph="none" pos="word" start_char="3508">health</TOKEN>
<TOKEN end_char="3521" id="token-27-24" morph="none" pos="word" start_char="3515">workers</TOKEN>
<TOKEN end_char="3522" id="token-27-25" morph="none" pos="punct" start_char="3522">.</TOKEN>
</SEG>
<SEG end_char="3652" id="segment-28" start_char="3524">
<ORIGINAL_TEXT>In 2011 France had nearly 1.5 billion masks: 800 million surgical masks and 600 million masks for health professionals generally.</ORIGINAL_TEXT>
<TOKEN end_char="3525" id="token-28-0" morph="none" pos="word" start_char="3524">In</TOKEN>
<TOKEN end_char="3530" id="token-28-1" morph="none" pos="word" start_char="3527">2011</TOKEN>
<TOKEN end_char="3537" id="token-28-2" morph="none" pos="word" start_char="3532">France</TOKEN>
<TOKEN end_char="3541" id="token-28-3" morph="none" pos="word" start_char="3539">had</TOKEN>
<TOKEN end_char="3548" id="token-28-4" morph="none" pos="word" start_char="3543">nearly</TOKEN>
<TOKEN end_char="3552" id="token-28-5" morph="none" pos="word" start_char="3550">1.5</TOKEN>
<TOKEN end_char="3560" id="token-28-6" morph="none" pos="word" start_char="3554">billion</TOKEN>
<TOKEN end_char="3566" id="token-28-7" morph="none" pos="word" start_char="3562">masks</TOKEN>
<TOKEN end_char="3567" id="token-28-8" morph="none" pos="punct" start_char="3567">:</TOKEN>
<TOKEN end_char="3571" id="token-28-9" morph="none" pos="word" start_char="3569">800</TOKEN>
<TOKEN end_char="3579" id="token-28-10" morph="none" pos="word" start_char="3573">million</TOKEN>
<TOKEN end_char="3588" id="token-28-11" morph="none" pos="word" start_char="3581">surgical</TOKEN>
<TOKEN end_char="3594" id="token-28-12" morph="none" pos="word" start_char="3590">masks</TOKEN>
<TOKEN end_char="3598" id="token-28-13" morph="none" pos="word" start_char="3596">and</TOKEN>
<TOKEN end_char="3602" id="token-28-14" morph="none" pos="word" start_char="3600">600</TOKEN>
<TOKEN end_char="3610" id="token-28-15" morph="none" pos="word" start_char="3604">million</TOKEN>
<TOKEN end_char="3616" id="token-28-16" morph="none" pos="word" start_char="3612">masks</TOKEN>
<TOKEN end_char="3620" id="token-28-17" morph="none" pos="word" start_char="3618">for</TOKEN>
<TOKEN end_char="3627" id="token-28-18" morph="none" pos="word" start_char="3622">health</TOKEN>
<TOKEN end_char="3641" id="token-28-19" morph="none" pos="word" start_char="3629">professionals</TOKEN>
<TOKEN end_char="3651" id="token-28-20" morph="none" pos="word" start_char="3643">generally</TOKEN>
<TOKEN end_char="3652" id="token-28-21" morph="none" pos="punct" start_char="3652">.</TOKEN>
</SEG>
<SEG end_char="3892" id="segment-29" start_char="3655">
<ORIGINAL_TEXT>But then, over the years, the strategic stocks were not renewed, to please the EU and to apply the Maastricht criteria, which limited membership in the Growth and Stability Pact to countries whose budget deficits did not exceed 3% of GDP.</ORIGINAL_TEXT>
<TOKEN end_char="3657" id="token-29-0" morph="none" pos="word" start_char="3655">But</TOKEN>
<TOKEN end_char="3662" id="token-29-1" morph="none" pos="word" start_char="3659">then</TOKEN>
<TOKEN end_char="3663" id="token-29-2" morph="none" pos="punct" start_char="3663">,</TOKEN>
<TOKEN end_char="3668" id="token-29-3" morph="none" pos="word" start_char="3665">over</TOKEN>
<TOKEN end_char="3672" id="token-29-4" morph="none" pos="word" start_char="3670">the</TOKEN>
<TOKEN end_char="3678" id="token-29-5" morph="none" pos="word" start_char="3674">years</TOKEN>
<TOKEN end_char="3679" id="token-29-6" morph="none" pos="punct" start_char="3679">,</TOKEN>
<TOKEN end_char="3683" id="token-29-7" morph="none" pos="word" start_char="3681">the</TOKEN>
<TOKEN end_char="3693" id="token-29-8" morph="none" pos="word" start_char="3685">strategic</TOKEN>
<TOKEN end_char="3700" id="token-29-9" morph="none" pos="word" start_char="3695">stocks</TOKEN>
<TOKEN end_char="3705" id="token-29-10" morph="none" pos="word" start_char="3702">were</TOKEN>
<TOKEN end_char="3709" id="token-29-11" morph="none" pos="word" start_char="3707">not</TOKEN>
<TOKEN end_char="3717" id="token-29-12" morph="none" pos="word" start_char="3711">renewed</TOKEN>
<TOKEN end_char="3718" id="token-29-13" morph="none" pos="punct" start_char="3718">,</TOKEN>
<TOKEN end_char="3721" id="token-29-14" morph="none" pos="word" start_char="3720">to</TOKEN>
<TOKEN end_char="3728" id="token-29-15" morph="none" pos="word" start_char="3723">please</TOKEN>
<TOKEN end_char="3732" id="token-29-16" morph="none" pos="word" start_char="3730">the</TOKEN>
<TOKEN end_char="3735" id="token-29-17" morph="none" pos="word" start_char="3734">EU</TOKEN>
<TOKEN end_char="3739" id="token-29-18" morph="none" pos="word" start_char="3737">and</TOKEN>
<TOKEN end_char="3742" id="token-29-19" morph="none" pos="word" start_char="3741">to</TOKEN>
<TOKEN end_char="3748" id="token-29-20" morph="none" pos="word" start_char="3744">apply</TOKEN>
<TOKEN end_char="3752" id="token-29-21" morph="none" pos="word" start_char="3750">the</TOKEN>
<TOKEN end_char="3763" id="token-29-22" morph="none" pos="word" start_char="3754">Maastricht</TOKEN>
<TOKEN end_char="3772" id="token-29-23" morph="none" pos="word" start_char="3765">criteria</TOKEN>
<TOKEN end_char="3773" id="token-29-24" morph="none" pos="punct" start_char="3773">,</TOKEN>
<TOKEN end_char="3779" id="token-29-25" morph="none" pos="word" start_char="3775">which</TOKEN>
<TOKEN end_char="3787" id="token-29-26" morph="none" pos="word" start_char="3781">limited</TOKEN>
<TOKEN end_char="3798" id="token-29-27" morph="none" pos="word" start_char="3789">membership</TOKEN>
<TOKEN end_char="3801" id="token-29-28" morph="none" pos="word" start_char="3800">in</TOKEN>
<TOKEN end_char="3805" id="token-29-29" morph="none" pos="word" start_char="3803">the</TOKEN>
<TOKEN end_char="3812" id="token-29-30" morph="none" pos="word" start_char="3807">Growth</TOKEN>
<TOKEN end_char="3816" id="token-29-31" morph="none" pos="word" start_char="3814">and</TOKEN>
<TOKEN end_char="3826" id="token-29-32" morph="none" pos="word" start_char="3818">Stability</TOKEN>
<TOKEN end_char="3831" id="token-29-33" morph="none" pos="word" start_char="3828">Pact</TOKEN>
<TOKEN end_char="3834" id="token-29-34" morph="none" pos="word" start_char="3833">to</TOKEN>
<TOKEN end_char="3844" id="token-29-35" morph="none" pos="word" start_char="3836">countries</TOKEN>
<TOKEN end_char="3850" id="token-29-36" morph="none" pos="word" start_char="3846">whose</TOKEN>
<TOKEN end_char="3857" id="token-29-37" morph="none" pos="word" start_char="3852">budget</TOKEN>
<TOKEN end_char="3866" id="token-29-38" morph="none" pos="word" start_char="3859">deficits</TOKEN>
<TOKEN end_char="3870" id="token-29-39" morph="none" pos="word" start_char="3868">did</TOKEN>
<TOKEN end_char="3874" id="token-29-40" morph="none" pos="word" start_char="3872">not</TOKEN>
<TOKEN end_char="3881" id="token-29-41" morph="none" pos="word" start_char="3876">exceed</TOKEN>
<TOKEN end_char="3883" id="token-29-42" morph="none" pos="word" start_char="3883">3</TOKEN>
<TOKEN end_char="3884" id="token-29-43" morph="none" pos="punct" start_char="3884">%</TOKEN>
<TOKEN end_char="3887" id="token-29-44" morph="none" pos="word" start_char="3886">of</TOKEN>
<TOKEN end_char="3891" id="token-29-45" morph="none" pos="word" start_char="3889">GDP</TOKEN>
<TOKEN end_char="3892" id="token-29-46" morph="none" pos="punct" start_char="3892">.</TOKEN>
</SEG>
<SEG end_char="4000" id="segment-30" start_char="3894">
<ORIGINAL_TEXT>One of those in charge at the time was Jerome Salomon, now a scientific counselor to the Macron government.</ORIGINAL_TEXT>
<TOKEN end_char="3896" id="token-30-0" morph="none" pos="word" start_char="3894">One</TOKEN>
<TOKEN end_char="3899" id="token-30-1" morph="none" pos="word" start_char="3898">of</TOKEN>
<TOKEN end_char="3905" id="token-30-2" morph="none" pos="word" start_char="3901">those</TOKEN>
<TOKEN end_char="3908" id="token-30-3" morph="none" pos="word" start_char="3907">in</TOKEN>
<TOKEN end_char="3915" id="token-30-4" morph="none" pos="word" start_char="3910">charge</TOKEN>
<TOKEN end_char="3918" id="token-30-5" morph="none" pos="word" start_char="3917">at</TOKEN>
<TOKEN end_char="3922" id="token-30-6" morph="none" pos="word" start_char="3920">the</TOKEN>
<TOKEN end_char="3927" id="token-30-7" morph="none" pos="word" start_char="3924">time</TOKEN>
<TOKEN end_char="3931" id="token-30-8" morph="none" pos="word" start_char="3929">was</TOKEN>
<TOKEN end_char="3938" id="token-30-9" morph="none" pos="word" start_char="3933">Jerome</TOKEN>
<TOKEN end_char="3946" id="token-30-10" morph="none" pos="word" start_char="3940">Salomon</TOKEN>
<TOKEN end_char="3947" id="token-30-11" morph="none" pos="punct" start_char="3947">,</TOKEN>
<TOKEN end_char="3951" id="token-30-12" morph="none" pos="word" start_char="3949">now</TOKEN>
<TOKEN end_char="3953" id="token-30-13" morph="none" pos="word" start_char="3953">a</TOKEN>
<TOKEN end_char="3964" id="token-30-14" morph="none" pos="word" start_char="3955">scientific</TOKEN>
<TOKEN end_char="3974" id="token-30-15" morph="none" pos="word" start_char="3966">counselor</TOKEN>
<TOKEN end_char="3977" id="token-30-16" morph="none" pos="word" start_char="3976">to</TOKEN>
<TOKEN end_char="3981" id="token-30-17" morph="none" pos="word" start_char="3979">the</TOKEN>
<TOKEN end_char="3988" id="token-30-18" morph="none" pos="word" start_char="3983">Macron</TOKEN>
<TOKEN end_char="3999" id="token-30-19" morph="none" pos="word" start_char="3990">government</TOKEN>
<TOKEN end_char="4000" id="token-30-20" morph="none" pos="punct" start_char="4000">.</TOKEN>
</SEG>
<SEG end_char="4147" id="segment-31" start_char="4003">
<ORIGINAL_TEXT>On March 17, Agnes Buzyn says she has learned the spread of Covid-19 will be a major tsunami, for which the French health system has no solution.</ORIGINAL_TEXT>
<TOKEN end_char="4004" id="token-31-0" morph="none" pos="word" start_char="4003">On</TOKEN>
<TOKEN end_char="4010" id="token-31-1" morph="none" pos="word" start_char="4006">March</TOKEN>
<TOKEN end_char="4013" id="token-31-2" morph="none" pos="word" start_char="4012">17</TOKEN>
<TOKEN end_char="4014" id="token-31-3" morph="none" pos="punct" start_char="4014">,</TOKEN>
<TOKEN end_char="4020" id="token-31-4" morph="none" pos="word" start_char="4016">Agnes</TOKEN>
<TOKEN end_char="4026" id="token-31-5" morph="none" pos="word" start_char="4022">Buzyn</TOKEN>
<TOKEN end_char="4031" id="token-31-6" morph="none" pos="word" start_char="4028">says</TOKEN>
<TOKEN end_char="4035" id="token-31-7" morph="none" pos="word" start_char="4033">she</TOKEN>
<TOKEN end_char="4039" id="token-31-8" morph="none" pos="word" start_char="4037">has</TOKEN>
<TOKEN end_char="4047" id="token-31-9" morph="none" pos="word" start_char="4041">learned</TOKEN>
<TOKEN end_char="4051" id="token-31-10" morph="none" pos="word" start_char="4049">the</TOKEN>
<TOKEN end_char="4058" id="token-31-11" morph="none" pos="word" start_char="4053">spread</TOKEN>
<TOKEN end_char="4061" id="token-31-12" morph="none" pos="word" start_char="4060">of</TOKEN>
<TOKEN end_char="4070" id="token-31-13" morph="none" pos="unknown" start_char="4063">Covid-19</TOKEN>
<TOKEN end_char="4075" id="token-31-14" morph="none" pos="word" start_char="4072">will</TOKEN>
<TOKEN end_char="4078" id="token-31-15" morph="none" pos="word" start_char="4077">be</TOKEN>
<TOKEN end_char="4080" id="token-31-16" morph="none" pos="word" start_char="4080">a</TOKEN>
<TOKEN end_char="4086" id="token-31-17" morph="none" pos="word" start_char="4082">major</TOKEN>
<TOKEN end_char="4094" id="token-31-18" morph="none" pos="word" start_char="4088">tsunami</TOKEN>
<TOKEN end_char="4095" id="token-31-19" morph="none" pos="punct" start_char="4095">,</TOKEN>
<TOKEN end_char="4099" id="token-31-20" morph="none" pos="word" start_char="4097">for</TOKEN>
<TOKEN end_char="4105" id="token-31-21" morph="none" pos="word" start_char="4101">which</TOKEN>
<TOKEN end_char="4109" id="token-31-22" morph="none" pos="word" start_char="4107">the</TOKEN>
<TOKEN end_char="4116" id="token-31-23" morph="none" pos="word" start_char="4111">French</TOKEN>
<TOKEN end_char="4123" id="token-31-24" morph="none" pos="word" start_char="4118">health</TOKEN>
<TOKEN end_char="4130" id="token-31-25" morph="none" pos="word" start_char="4125">system</TOKEN>
<TOKEN end_char="4134" id="token-31-26" morph="none" pos="word" start_char="4132">has</TOKEN>
<TOKEN end_char="4137" id="token-31-27" morph="none" pos="word" start_char="4136">no</TOKEN>
<TOKEN end_char="4146" id="token-31-28" morph="none" pos="word" start_char="4139">solution</TOKEN>
<TOKEN end_char="4147" id="token-31-29" morph="none" pos="punct" start_char="4147">.</TOKEN>
</SEG>
<SEG end_char="4291" id="segment-32" start_char="4149">
<ORIGINAL_TEXT>She also says it had been her understanding that the Paris mayoral election "would not take place" and that it was, ultimately, "a masquerade."</ORIGINAL_TEXT>
<TOKEN end_char="4151" id="token-32-0" morph="none" pos="word" start_char="4149">She</TOKEN>
<TOKEN end_char="4156" id="token-32-1" morph="none" pos="word" start_char="4153">also</TOKEN>
<TOKEN end_char="4161" id="token-32-2" morph="none" pos="word" start_char="4158">says</TOKEN>
<TOKEN end_char="4164" id="token-32-3" morph="none" pos="word" start_char="4163">it</TOKEN>
<TOKEN end_char="4168" id="token-32-4" morph="none" pos="word" start_char="4166">had</TOKEN>
<TOKEN end_char="4173" id="token-32-5" morph="none" pos="word" start_char="4170">been</TOKEN>
<TOKEN end_char="4177" id="token-32-6" morph="none" pos="word" start_char="4175">her</TOKEN>
<TOKEN end_char="4191" id="token-32-7" morph="none" pos="word" start_char="4179">understanding</TOKEN>
<TOKEN end_char="4196" id="token-32-8" morph="none" pos="word" start_char="4193">that</TOKEN>
<TOKEN end_char="4200" id="token-32-9" morph="none" pos="word" start_char="4198">the</TOKEN>
<TOKEN end_char="4206" id="token-32-10" morph="none" pos="word" start_char="4202">Paris</TOKEN>
<TOKEN end_char="4214" id="token-32-11" morph="none" pos="word" start_char="4208">mayoral</TOKEN>
<TOKEN end_char="4223" id="token-32-12" morph="none" pos="word" start_char="4216">election</TOKEN>
<TOKEN end_char="4225" id="token-32-13" morph="none" pos="punct" start_char="4225">"</TOKEN>
<TOKEN end_char="4230" id="token-32-14" morph="none" pos="word" start_char="4226">would</TOKEN>
<TOKEN end_char="4234" id="token-32-15" morph="none" pos="word" start_char="4232">not</TOKEN>
<TOKEN end_char="4239" id="token-32-16" morph="none" pos="word" start_char="4236">take</TOKEN>
<TOKEN end_char="4245" id="token-32-17" morph="none" pos="word" start_char="4241">place</TOKEN>
<TOKEN end_char="4246" id="token-32-18" morph="none" pos="punct" start_char="4246">"</TOKEN>
<TOKEN end_char="4250" id="token-32-19" morph="none" pos="word" start_char="4248">and</TOKEN>
<TOKEN end_char="4255" id="token-32-20" morph="none" pos="word" start_char="4252">that</TOKEN>
<TOKEN end_char="4258" id="token-32-21" morph="none" pos="word" start_char="4257">it</TOKEN>
<TOKEN end_char="4262" id="token-32-22" morph="none" pos="word" start_char="4260">was</TOKEN>
<TOKEN end_char="4263" id="token-32-23" morph="none" pos="punct" start_char="4263">,</TOKEN>
<TOKEN end_char="4274" id="token-32-24" morph="none" pos="word" start_char="4265">ultimately</TOKEN>
<TOKEN end_char="4275" id="token-32-25" morph="none" pos="punct" start_char="4275">,</TOKEN>
<TOKEN end_char="4277" id="token-32-26" morph="none" pos="punct" start_char="4277">"</TOKEN>
<TOKEN end_char="4278" id="token-32-27" morph="none" pos="word" start_char="4278">a</TOKEN>
<TOKEN end_char="4289" id="token-32-28" morph="none" pos="word" start_char="4280">masquerade</TOKEN>
<TOKEN end_char="4291" id="token-32-29" morph="none" pos="punct" start_char="4290">."</TOKEN>
</SEG>
<SEG end_char="4470" id="segment-33" start_char="4294">
<ORIGINAL_TEXT>What she does not say is that she didn’t go public at the time she was running because the whole political focus by the Macron political machine was on winning the "masquerade."</ORIGINAL_TEXT>
<TOKEN end_char="4297" id="token-33-0" morph="none" pos="word" start_char="4294">What</TOKEN>
<TOKEN end_char="4301" id="token-33-1" morph="none" pos="word" start_char="4299">she</TOKEN>
<TOKEN end_char="4306" id="token-33-2" morph="none" pos="word" start_char="4303">does</TOKEN>
<TOKEN end_char="4310" id="token-33-3" morph="none" pos="word" start_char="4308">not</TOKEN>
<TOKEN end_char="4314" id="token-33-4" morph="none" pos="word" start_char="4312">say</TOKEN>
<TOKEN end_char="4317" id="token-33-5" morph="none" pos="word" start_char="4316">is</TOKEN>
<TOKEN end_char="4322" id="token-33-6" morph="none" pos="word" start_char="4319">that</TOKEN>
<TOKEN end_char="4326" id="token-33-7" morph="none" pos="word" start_char="4324">she</TOKEN>
<TOKEN end_char="4333" id="token-33-8" morph="none" pos="word" start_char="4328">didn’t</TOKEN>
<TOKEN end_char="4336" id="token-33-9" morph="none" pos="word" start_char="4335">go</TOKEN>
<TOKEN end_char="4343" id="token-33-10" morph="none" pos="word" start_char="4338">public</TOKEN>
<TOKEN end_char="4346" id="token-33-11" morph="none" pos="word" start_char="4345">at</TOKEN>
<TOKEN end_char="4350" id="token-33-12" morph="none" pos="word" start_char="4348">the</TOKEN>
<TOKEN end_char="4355" id="token-33-13" morph="none" pos="word" start_char="4352">time</TOKEN>
<TOKEN end_char="4359" id="token-33-14" morph="none" pos="word" start_char="4357">she</TOKEN>
<TOKEN end_char="4363" id="token-33-15" morph="none" pos="word" start_char="4361">was</TOKEN>
<TOKEN end_char="4371" id="token-33-16" morph="none" pos="word" start_char="4365">running</TOKEN>
<TOKEN end_char="4379" id="token-33-17" morph="none" pos="word" start_char="4373">because</TOKEN>
<TOKEN end_char="4383" id="token-33-18" morph="none" pos="word" start_char="4381">the</TOKEN>
<TOKEN end_char="4389" id="token-33-19" morph="none" pos="word" start_char="4385">whole</TOKEN>
<TOKEN end_char="4399" id="token-33-20" morph="none" pos="word" start_char="4391">political</TOKEN>
<TOKEN end_char="4405" id="token-33-21" morph="none" pos="word" start_char="4401">focus</TOKEN>
<TOKEN end_char="4408" id="token-33-22" morph="none" pos="word" start_char="4407">by</TOKEN>
<TOKEN end_char="4412" id="token-33-23" morph="none" pos="word" start_char="4410">the</TOKEN>
<TOKEN end_char="4419" id="token-33-24" morph="none" pos="word" start_char="4414">Macron</TOKEN>
<TOKEN end_char="4429" id="token-33-25" morph="none" pos="word" start_char="4421">political</TOKEN>
<TOKEN end_char="4437" id="token-33-26" morph="none" pos="word" start_char="4431">machine</TOKEN>
<TOKEN end_char="4441" id="token-33-27" morph="none" pos="word" start_char="4439">was</TOKEN>
<TOKEN end_char="4444" id="token-33-28" morph="none" pos="word" start_char="4443">on</TOKEN>
<TOKEN end_char="4452" id="token-33-29" morph="none" pos="word" start_char="4446">winning</TOKEN>
<TOKEN end_char="4456" id="token-33-30" morph="none" pos="word" start_char="4454">the</TOKEN>
<TOKEN end_char="4458" id="token-33-31" morph="none" pos="punct" start_char="4458">"</TOKEN>
<TOKEN end_char="4468" id="token-33-32" morph="none" pos="word" start_char="4459">masquerade</TOKEN>
<TOKEN end_char="4470" id="token-33-33" morph="none" pos="punct" start_char="4469">."</TOKEN>
</SEG>
<SEG end_char="4544" id="segment-34" start_char="4472">
<ORIGINAL_TEXT>The first round of the election meant nothing, as Covid-19 was advancing.</ORIGINAL_TEXT>
<TOKEN end_char="4474" id="token-34-0" morph="none" pos="word" start_char="4472">The</TOKEN>
<TOKEN end_char="4480" id="token-34-1" morph="none" pos="word" start_char="4476">first</TOKEN>
<TOKEN end_char="4486" id="token-34-2" morph="none" pos="word" start_char="4482">round</TOKEN>
<TOKEN end_char="4489" id="token-34-3" morph="none" pos="word" start_char="4488">of</TOKEN>
<TOKEN end_char="4493" id="token-34-4" morph="none" pos="word" start_char="4491">the</TOKEN>
<TOKEN end_char="4502" id="token-34-5" morph="none" pos="word" start_char="4495">election</TOKEN>
<TOKEN end_char="4508" id="token-34-6" morph="none" pos="word" start_char="4504">meant</TOKEN>
<TOKEN end_char="4516" id="token-34-7" morph="none" pos="word" start_char="4510">nothing</TOKEN>
<TOKEN end_char="4517" id="token-34-8" morph="none" pos="punct" start_char="4517">,</TOKEN>
<TOKEN end_char="4520" id="token-34-9" morph="none" pos="word" start_char="4519">as</TOKEN>
<TOKEN end_char="4529" id="token-34-10" morph="none" pos="unknown" start_char="4522">Covid-19</TOKEN>
<TOKEN end_char="4533" id="token-34-11" morph="none" pos="word" start_char="4531">was</TOKEN>
<TOKEN end_char="4543" id="token-34-12" morph="none" pos="word" start_char="4535">advancing</TOKEN>
<TOKEN end_char="4544" id="token-34-13" morph="none" pos="punct" start_char="4544">.</TOKEN>
</SEG>
<SEG end_char="4589" id="segment-35" start_char="4546">
<ORIGINAL_TEXT>The second round was postponed indefinitely.</ORIGINAL_TEXT>
<TOKEN end_char="4548" id="token-35-0" morph="none" pos="word" start_char="4546">The</TOKEN>
<TOKEN end_char="4555" id="token-35-1" morph="none" pos="word" start_char="4550">second</TOKEN>
<TOKEN end_char="4561" id="token-35-2" morph="none" pos="word" start_char="4557">round</TOKEN>
<TOKEN end_char="4565" id="token-35-3" morph="none" pos="word" start_char="4563">was</TOKEN>
<TOKEN end_char="4575" id="token-35-4" morph="none" pos="word" start_char="4567">postponed</TOKEN>
<TOKEN end_char="4588" id="token-35-5" morph="none" pos="word" start_char="4577">indefinitely</TOKEN>
<TOKEN end_char="4589" id="token-35-6" morph="none" pos="punct" start_char="4589">.</TOKEN>
</SEG>
<SEG end_char="4646" id="segment-36" start_char="4591">
<ORIGINAL_TEXT>She had to know about the impending healthcare disaster.</ORIGINAL_TEXT>
<TOKEN end_char="4593" id="token-36-0" morph="none" pos="word" start_char="4591">She</TOKEN>
<TOKEN end_char="4597" id="token-36-1" morph="none" pos="word" start_char="4595">had</TOKEN>
<TOKEN end_char="4600" id="token-36-2" morph="none" pos="word" start_char="4599">to</TOKEN>
<TOKEN end_char="4605" id="token-36-3" morph="none" pos="word" start_char="4602">know</TOKEN>
<TOKEN end_char="4611" id="token-36-4" morph="none" pos="word" start_char="4607">about</TOKEN>
<TOKEN end_char="4615" id="token-36-5" morph="none" pos="word" start_char="4613">the</TOKEN>
<TOKEN end_char="4625" id="token-36-6" morph="none" pos="word" start_char="4617">impending</TOKEN>
<TOKEN end_char="4636" id="token-36-7" morph="none" pos="word" start_char="4627">healthcare</TOKEN>
<TOKEN end_char="4645" id="token-36-8" morph="none" pos="word" start_char="4638">disaster</TOKEN>
<TOKEN end_char="4646" id="token-36-9" morph="none" pos="punct" start_char="4646">.</TOKEN>
</SEG>
<SEG end_char="4728" id="segment-37" start_char="4648">
<ORIGINAL_TEXT>But as a candidate of the Macron machine she did not go public in timely fashion.</ORIGINAL_TEXT>
<TOKEN end_char="4650" id="token-37-0" morph="none" pos="word" start_char="4648">But</TOKEN>
<TOKEN end_char="4653" id="token-37-1" morph="none" pos="word" start_char="4652">as</TOKEN>
<TOKEN end_char="4655" id="token-37-2" morph="none" pos="word" start_char="4655">a</TOKEN>
<TOKEN end_char="4665" id="token-37-3" morph="none" pos="word" start_char="4657">candidate</TOKEN>
<TOKEN end_char="4668" id="token-37-4" morph="none" pos="word" start_char="4667">of</TOKEN>
<TOKEN end_char="4672" id="token-37-5" morph="none" pos="word" start_char="4670">the</TOKEN>
<TOKEN end_char="4679" id="token-37-6" morph="none" pos="word" start_char="4674">Macron</TOKEN>
<TOKEN end_char="4687" id="token-37-7" morph="none" pos="word" start_char="4681">machine</TOKEN>
<TOKEN end_char="4691" id="token-37-8" morph="none" pos="word" start_char="4689">she</TOKEN>
<TOKEN end_char="4695" id="token-37-9" morph="none" pos="word" start_char="4693">did</TOKEN>
<TOKEN end_char="4699" id="token-37-10" morph="none" pos="word" start_char="4697">not</TOKEN>
<TOKEN end_char="4702" id="token-37-11" morph="none" pos="word" start_char="4701">go</TOKEN>
<TOKEN end_char="4709" id="token-37-12" morph="none" pos="word" start_char="4704">public</TOKEN>
<TOKEN end_char="4712" id="token-37-13" morph="none" pos="word" start_char="4711">in</TOKEN>
<TOKEN end_char="4719" id="token-37-14" morph="none" pos="word" start_char="4714">timely</TOKEN>
<TOKEN end_char="4727" id="token-37-15" morph="none" pos="word" start_char="4721">fashion</TOKEN>
<TOKEN end_char="4728" id="token-37-16" morph="none" pos="punct" start_char="4728">.</TOKEN>
</SEG>
<SEG end_char="4750" id="segment-38" start_char="4731">
<ORIGINAL_TEXT>In quick succession:</ORIGINAL_TEXT>
<TOKEN end_char="4732" id="token-38-0" morph="none" pos="word" start_char="4731">In</TOKEN>
<TOKEN end_char="4738" id="token-38-1" morph="none" pos="word" start_char="4734">quick</TOKEN>
<TOKEN end_char="4749" id="token-38-2" morph="none" pos="word" start_char="4740">succession</TOKEN>
<TOKEN end_char="4750" id="token-38-3" morph="none" pos="punct" start_char="4750">:</TOKEN>
<TRANSLATED_TEXT>In rasch opvolging:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="4858" id="segment-39" start_char="4753">
<ORIGINAL_TEXT>The Macron government refuses to apply mass testing, as practiced with success in South Korea and Germany.</ORIGINAL_TEXT>
<TOKEN end_char="4755" id="token-39-0" morph="none" pos="word" start_char="4753">The</TOKEN>
<TOKEN end_char="4762" id="token-39-1" morph="none" pos="word" start_char="4757">Macron</TOKEN>
<TOKEN end_char="4773" id="token-39-2" morph="none" pos="word" start_char="4764">government</TOKEN>
<TOKEN end_char="4781" id="token-39-3" morph="none" pos="word" start_char="4775">refuses</TOKEN>
<TOKEN end_char="4784" id="token-39-4" morph="none" pos="word" start_char="4783">to</TOKEN>
<TOKEN end_char="4790" id="token-39-5" morph="none" pos="word" start_char="4786">apply</TOKEN>
<TOKEN end_char="4795" id="token-39-6" morph="none" pos="word" start_char="4792">mass</TOKEN>
<TOKEN end_char="4803" id="token-39-7" morph="none" pos="word" start_char="4797">testing</TOKEN>
<TOKEN end_char="4804" id="token-39-8" morph="none" pos="punct" start_char="4804">,</TOKEN>
<TOKEN end_char="4807" id="token-39-9" morph="none" pos="word" start_char="4806">as</TOKEN>
<TOKEN end_char="4817" id="token-39-10" morph="none" pos="word" start_char="4809">practiced</TOKEN>
<TOKEN end_char="4822" id="token-39-11" morph="none" pos="word" start_char="4819">with</TOKEN>
<TOKEN end_char="4830" id="token-39-12" morph="none" pos="word" start_char="4824">success</TOKEN>
<TOKEN end_char="4833" id="token-39-13" morph="none" pos="word" start_char="4832">in</TOKEN>
<TOKEN end_char="4839" id="token-39-14" morph="none" pos="word" start_char="4835">South</TOKEN>
<TOKEN end_char="4845" id="token-39-15" morph="none" pos="word" start_char="4841">Korea</TOKEN>
<TOKEN end_char="4849" id="token-39-16" morph="none" pos="word" start_char="4847">and</TOKEN>
<TOKEN end_char="4857" id="token-39-17" morph="none" pos="word" start_char="4851">Germany</TOKEN>
<TOKEN end_char="4858" id="token-39-18" morph="none" pos="punct" start_char="4858">.</TOKEN>
</SEG>
<SEG end_char="4977" id="segment-40" start_char="4861">
<ORIGINAL_TEXT>Le Monde and the French state health agency characterize Raoult’s research as fake news, before issuing a retraction.</ORIGINAL_TEXT>
<TOKEN end_char="4862" id="token-40-0" morph="none" pos="word" start_char="4861">Le</TOKEN>
<TOKEN end_char="4868" id="token-40-1" morph="none" pos="word" start_char="4864">Monde</TOKEN>
<TOKEN end_char="4872" id="token-40-2" morph="none" pos="word" start_char="4870">and</TOKEN>
<TOKEN end_char="4876" id="token-40-3" morph="none" pos="word" start_char="4874">the</TOKEN>
<TOKEN end_char="4883" id="token-40-4" morph="none" pos="word" start_char="4878">French</TOKEN>
<TOKEN end_char="4889" id="token-40-5" morph="none" pos="word" start_char="4885">state</TOKEN>
<TOKEN end_char="4896" id="token-40-6" morph="none" pos="word" start_char="4891">health</TOKEN>
<TOKEN end_char="4903" id="token-40-7" morph="none" pos="word" start_char="4898">agency</TOKEN>
<TOKEN end_char="4916" id="token-40-8" morph="none" pos="word" start_char="4905">characterize</TOKEN>
<TOKEN end_char="4925" id="token-40-9" morph="none" pos="word" start_char="4918">Raoult’s</TOKEN>
<TOKEN end_char="4934" id="token-40-10" morph="none" pos="word" start_char="4927">research</TOKEN>
<TOKEN end_char="4937" id="token-40-11" morph="none" pos="word" start_char="4936">as</TOKEN>
<TOKEN end_char="4942" id="token-40-12" morph="none" pos="word" start_char="4939">fake</TOKEN>
<TOKEN end_char="4947" id="token-40-13" morph="none" pos="word" start_char="4944">news</TOKEN>
<TOKEN end_char="4948" id="token-40-14" morph="none" pos="punct" start_char="4948">,</TOKEN>
<TOKEN end_char="4955" id="token-40-15" morph="none" pos="word" start_char="4950">before</TOKEN>
<TOKEN end_char="4963" id="token-40-16" morph="none" pos="word" start_char="4957">issuing</TOKEN>
<TOKEN end_char="4965" id="token-40-17" morph="none" pos="word" start_char="4965">a</TOKEN>
<TOKEN end_char="4976" id="token-40-18" morph="none" pos="word" start_char="4967">retraction</TOKEN>
<TOKEN end_char="4977" id="token-40-19" morph="none" pos="punct" start_char="4977">.</TOKEN>
</SEG>
<SEG end_char="5111" id="segment-41" start_char="4980">
<ORIGINAL_TEXT>Professor Perrone reveals on the 24/7 LCI news channel that the stock of chloroquine at the French central pharmacy has been stolen.</ORIGINAL_TEXT>
<TOKEN end_char="4988" id="token-41-0" morph="none" pos="word" start_char="4980">Professor</TOKEN>
<TOKEN end_char="4996" id="token-41-1" morph="none" pos="word" start_char="4990">Perrone</TOKEN>
<TOKEN end_char="5004" id="token-41-2" morph="none" pos="word" start_char="4998">reveals</TOKEN>
<TOKEN end_char="5007" id="token-41-3" morph="none" pos="word" start_char="5006">on</TOKEN>
<TOKEN end_char="5011" id="token-41-4" morph="none" pos="word" start_char="5009">the</TOKEN>
<TOKEN end_char="5016" id="token-41-5" morph="none" pos="unknown" start_char="5013">24/7</TOKEN>
<TOKEN end_char="5020" id="token-41-6" morph="none" pos="word" start_char="5018">LCI</TOKEN>
<TOKEN end_char="5025" id="token-41-7" morph="none" pos="word" start_char="5022">news</TOKEN>
<TOKEN end_char="5033" id="token-41-8" morph="none" pos="word" start_char="5027">channel</TOKEN>
<TOKEN end_char="5038" id="token-41-9" morph="none" pos="word" start_char="5035">that</TOKEN>
<TOKEN end_char="5042" id="token-41-10" morph="none" pos="word" start_char="5040">the</TOKEN>
<TOKEN end_char="5048" id="token-41-11" morph="none" pos="word" start_char="5044">stock</TOKEN>
<TOKEN end_char="5051" id="token-41-12" morph="none" pos="word" start_char="5050">of</TOKEN>
<TOKEN end_char="5063" id="token-41-13" morph="none" pos="word" start_char="5053">chloroquine</TOKEN>
<TOKEN end_char="5066" id="token-41-14" morph="none" pos="word" start_char="5065">at</TOKEN>
<TOKEN end_char="5070" id="token-41-15" morph="none" pos="word" start_char="5068">the</TOKEN>
<TOKEN end_char="5077" id="token-41-16" morph="none" pos="word" start_char="5072">French</TOKEN>
<TOKEN end_char="5085" id="token-41-17" morph="none" pos="word" start_char="5079">central</TOKEN>
<TOKEN end_char="5094" id="token-41-18" morph="none" pos="word" start_char="5087">pharmacy</TOKEN>
<TOKEN end_char="5098" id="token-41-19" morph="none" pos="word" start_char="5096">has</TOKEN>
<TOKEN end_char="5103" id="token-41-20" morph="none" pos="word" start_char="5100">been</TOKEN>
<TOKEN end_char="5110" id="token-41-21" morph="none" pos="word" start_char="5105">stolen</TOKEN>
<TOKEN end_char="5111" id="token-41-22" morph="none" pos="punct" start_char="5111">.</TOKEN>
</SEG>
<SEG end_char="5215" id="segment-42" start_char="5114">
<ORIGINAL_TEXT>Thanks to a tweet by Elon Musk, President Trump says chloroquine should be available to all Americans.</ORIGINAL_TEXT>
<TOKEN end_char="5119" id="token-42-0" morph="none" pos="word" start_char="5114">Thanks</TOKEN>
<TOKEN end_char="5122" id="token-42-1" morph="none" pos="word" start_char="5121">to</TOKEN>
<TOKEN end_char="5124" id="token-42-2" morph="none" pos="word" start_char="5124">a</TOKEN>
<TOKEN end_char="5130" id="token-42-3" morph="none" pos="word" start_char="5126">tweet</TOKEN>
<TOKEN end_char="5133" id="token-42-4" morph="none" pos="word" start_char="5132">by</TOKEN>
<TOKEN end_char="5138" id="token-42-5" morph="none" pos="word" start_char="5135">Elon</TOKEN>
<TOKEN end_char="5143" id="token-42-6" morph="none" pos="word" start_char="5140">Musk</TOKEN>
<TOKEN end_char="5144" id="token-42-7" morph="none" pos="punct" start_char="5144">,</TOKEN>
<TOKEN end_char="5154" id="token-42-8" morph="none" pos="word" start_char="5146">President</TOKEN>
<TOKEN end_char="5160" id="token-42-9" morph="none" pos="word" start_char="5156">Trump</TOKEN>
<TOKEN end_char="5165" id="token-42-10" morph="none" pos="word" start_char="5162">says</TOKEN>
<TOKEN end_char="5177" id="token-42-11" morph="none" pos="word" start_char="5167">chloroquine</TOKEN>
<TOKEN end_char="5184" id="token-42-12" morph="none" pos="word" start_char="5179">should</TOKEN>
<TOKEN end_char="5187" id="token-42-13" morph="none" pos="word" start_char="5186">be</TOKEN>
<TOKEN end_char="5197" id="token-42-14" morph="none" pos="word" start_char="5189">available</TOKEN>
<TOKEN end_char="5200" id="token-42-15" morph="none" pos="word" start_char="5199">to</TOKEN>
<TOKEN end_char="5204" id="token-42-16" morph="none" pos="word" start_char="5202">all</TOKEN>
<TOKEN end_char="5214" id="token-42-17" morph="none" pos="word" start_char="5206">Americans</TOKEN>
<TOKEN end_char="5215" id="token-42-18" morph="none" pos="punct" start_char="5215">.</TOKEN>
</SEG>
<SEG end_char="5378" id="segment-43" start_char="5217">
<ORIGINAL_TEXT>Sufferers of lupus and rheumatoid arthritis, who already have supply problems with the only drug that offers them relief, set social media afire with their panic.</ORIGINAL_TEXT>
<TOKEN end_char="5225" id="token-43-0" morph="none" pos="word" start_char="5217">Sufferers</TOKEN>
<TOKEN end_char="5228" id="token-43-1" morph="none" pos="word" start_char="5227">of</TOKEN>
<TOKEN end_char="5234" id="token-43-2" morph="none" pos="word" start_char="5230">lupus</TOKEN>
<TOKEN end_char="5238" id="token-43-3" morph="none" pos="word" start_char="5236">and</TOKEN>
<TOKEN end_char="5249" id="token-43-4" morph="none" pos="word" start_char="5240">rheumatoid</TOKEN>
<TOKEN end_char="5259" id="token-43-5" morph="none" pos="word" start_char="5251">arthritis</TOKEN>
<TOKEN end_char="5260" id="token-43-6" morph="none" pos="punct" start_char="5260">,</TOKEN>
<TOKEN end_char="5264" id="token-43-7" morph="none" pos="word" start_char="5262">who</TOKEN>
<TOKEN end_char="5272" id="token-43-8" morph="none" pos="word" start_char="5266">already</TOKEN>
<TOKEN end_char="5277" id="token-43-9" morph="none" pos="word" start_char="5274">have</TOKEN>
<TOKEN end_char="5284" id="token-43-10" morph="none" pos="word" start_char="5279">supply</TOKEN>
<TOKEN end_char="5293" id="token-43-11" morph="none" pos="word" start_char="5286">problems</TOKEN>
<TOKEN end_char="5298" id="token-43-12" morph="none" pos="word" start_char="5295">with</TOKEN>
<TOKEN end_char="5302" id="token-43-13" morph="none" pos="word" start_char="5300">the</TOKEN>
<TOKEN end_char="5307" id="token-43-14" morph="none" pos="word" start_char="5304">only</TOKEN>
<TOKEN end_char="5312" id="token-43-15" morph="none" pos="word" start_char="5309">drug</TOKEN>
<TOKEN end_char="5317" id="token-43-16" morph="none" pos="word" start_char="5314">that</TOKEN>
<TOKEN end_char="5324" id="token-43-17" morph="none" pos="word" start_char="5319">offers</TOKEN>
<TOKEN end_char="5329" id="token-43-18" morph="none" pos="word" start_char="5326">them</TOKEN>
<TOKEN end_char="5336" id="token-43-19" morph="none" pos="word" start_char="5331">relief</TOKEN>
<TOKEN end_char="5337" id="token-43-20" morph="none" pos="punct" start_char="5337">,</TOKEN>
<TOKEN end_char="5341" id="token-43-21" morph="none" pos="word" start_char="5339">set</TOKEN>
<TOKEN end_char="5348" id="token-43-22" morph="none" pos="word" start_char="5343">social</TOKEN>
<TOKEN end_char="5354" id="token-43-23" morph="none" pos="word" start_char="5350">media</TOKEN>
<TOKEN end_char="5360" id="token-43-24" morph="none" pos="word" start_char="5356">afire</TOKEN>
<TOKEN end_char="5365" id="token-43-25" morph="none" pos="word" start_char="5362">with</TOKEN>
<TOKEN end_char="5371" id="token-43-26" morph="none" pos="word" start_char="5367">their</TOKEN>
<TOKEN end_char="5377" id="token-43-27" morph="none" pos="word" start_char="5373">panic</TOKEN>
<TOKEN end_char="5378" id="token-43-28" morph="none" pos="punct" start_char="5378">.</TOKEN>
</SEG>
<SEG end_char="5594" id="segment-44" start_char="5381">
<ORIGINAL_TEXT>US doctors and other medical professionals take to hoarding the medicine for the use of themselves and those close to them, faking prescriptions to indicate they are for patients with lupus or rheumatoid arthritis.</ORIGINAL_TEXT>
<TOKEN end_char="5382" id="token-44-0" morph="none" pos="word" start_char="5381">US</TOKEN>
<TOKEN end_char="5390" id="token-44-1" morph="none" pos="word" start_char="5384">doctors</TOKEN>
<TOKEN end_char="5394" id="token-44-2" morph="none" pos="word" start_char="5392">and</TOKEN>
<TOKEN end_char="5400" id="token-44-3" morph="none" pos="word" start_char="5396">other</TOKEN>
<TOKEN end_char="5408" id="token-44-4" morph="none" pos="word" start_char="5402">medical</TOKEN>
<TOKEN end_char="5422" id="token-44-5" morph="none" pos="word" start_char="5410">professionals</TOKEN>
<TOKEN end_char="5427" id="token-44-6" morph="none" pos="word" start_char="5424">take</TOKEN>
<TOKEN end_char="5430" id="token-44-7" morph="none" pos="word" start_char="5429">to</TOKEN>
<TOKEN end_char="5439" id="token-44-8" morph="none" pos="word" start_char="5432">hoarding</TOKEN>
<TOKEN end_char="5443" id="token-44-9" morph="none" pos="word" start_char="5441">the</TOKEN>
<TOKEN end_char="5452" id="token-44-10" morph="none" pos="word" start_char="5445">medicine</TOKEN>
<TOKEN end_char="5456" id="token-44-11" morph="none" pos="word" start_char="5454">for</TOKEN>
<TOKEN end_char="5460" id="token-44-12" morph="none" pos="word" start_char="5458">the</TOKEN>
<TOKEN end_char="5464" id="token-44-13" morph="none" pos="word" start_char="5462">use</TOKEN>
<TOKEN end_char="5467" id="token-44-14" morph="none" pos="word" start_char="5466">of</TOKEN>
<TOKEN end_char="5478" id="token-44-15" morph="none" pos="word" start_char="5469">themselves</TOKEN>
<TOKEN end_char="5482" id="token-44-16" morph="none" pos="word" start_char="5480">and</TOKEN>
<TOKEN end_char="5488" id="token-44-17" morph="none" pos="word" start_char="5484">those</TOKEN>
<TOKEN end_char="5494" id="token-44-18" morph="none" pos="word" start_char="5490">close</TOKEN>
<TOKEN end_char="5497" id="token-44-19" morph="none" pos="word" start_char="5496">to</TOKEN>
<TOKEN end_char="5502" id="token-44-20" morph="none" pos="word" start_char="5499">them</TOKEN>
<TOKEN end_char="5503" id="token-44-21" morph="none" pos="punct" start_char="5503">,</TOKEN>
<TOKEN end_char="5510" id="token-44-22" morph="none" pos="word" start_char="5505">faking</TOKEN>
<TOKEN end_char="5524" id="token-44-23" morph="none" pos="word" start_char="5512">prescriptions</TOKEN>
<TOKEN end_char="5527" id="token-44-24" morph="none" pos="word" start_char="5526">to</TOKEN>
<TOKEN end_char="5536" id="token-44-25" morph="none" pos="word" start_char="5529">indicate</TOKEN>
<TOKEN end_char="5541" id="token-44-26" morph="none" pos="word" start_char="5538">they</TOKEN>
<TOKEN end_char="5545" id="token-44-27" morph="none" pos="word" start_char="5543">are</TOKEN>
<TOKEN end_char="5549" id="token-44-28" morph="none" pos="word" start_char="5547">for</TOKEN>
<TOKEN end_char="5558" id="token-44-29" morph="none" pos="word" start_char="5551">patients</TOKEN>
<TOKEN end_char="5563" id="token-44-30" morph="none" pos="word" start_char="5560">with</TOKEN>
<TOKEN end_char="5569" id="token-44-31" morph="none" pos="word" start_char="5565">lupus</TOKEN>
<TOKEN end_char="5572" id="token-44-32" morph="none" pos="word" start_char="5571">or</TOKEN>
<TOKEN end_char="5583" id="token-44-33" morph="none" pos="word" start_char="5574">rheumatoid</TOKEN>
<TOKEN end_char="5593" id="token-44-34" morph="none" pos="word" start_char="5585">arthritis</TOKEN>
<TOKEN end_char="5594" id="token-44-35" morph="none" pos="punct" start_char="5594">.</TOKEN>
</SEG>
<SEG end_char="5660" id="segment-45" start_char="5597">
<ORIGINAL_TEXT>Morocco buys the stock of chloroquine from Sanofi in Casablanca.</ORIGINAL_TEXT>
<TOKEN end_char="5603" id="token-45-0" morph="none" pos="word" start_char="5597">Morocco</TOKEN>
<TOKEN end_char="5608" id="token-45-1" morph="none" pos="word" start_char="5605">buys</TOKEN>
<TOKEN end_char="5612" id="token-45-2" morph="none" pos="word" start_char="5610">the</TOKEN>
<TOKEN end_char="5618" id="token-45-3" morph="none" pos="word" start_char="5614">stock</TOKEN>
<TOKEN end_char="5621" id="token-45-4" morph="none" pos="word" start_char="5620">of</TOKEN>
<TOKEN end_char="5633" id="token-45-5" morph="none" pos="word" start_char="5623">chloroquine</TOKEN>
<TOKEN end_char="5638" id="token-45-6" morph="none" pos="word" start_char="5635">from</TOKEN>
<TOKEN end_char="5645" id="token-45-7" morph="none" pos="word" start_char="5640">Sanofi</TOKEN>
<TOKEN end_char="5648" id="token-45-8" morph="none" pos="word" start_char="5647">in</TOKEN>
<TOKEN end_char="5659" id="token-45-9" morph="none" pos="word" start_char="5650">Casablanca</TOKEN>
<TOKEN end_char="5660" id="token-45-10" morph="none" pos="punct" start_char="5660">.</TOKEN>
</SEG>
<SEG end_char="5741" id="segment-46" start_char="5663">
<ORIGINAL_TEXT>Pakistan decides to increase its production of chloroquine to be sent to China.</ORIGINAL_TEXT>
<TOKEN end_char="5670" id="token-46-0" morph="none" pos="word" start_char="5663">Pakistan</TOKEN>
<TOKEN end_char="5678" id="token-46-1" morph="none" pos="word" start_char="5672">decides</TOKEN>
<TOKEN end_char="5681" id="token-46-2" morph="none" pos="word" start_char="5680">to</TOKEN>
<TOKEN end_char="5690" id="token-46-3" morph="none" pos="word" start_char="5683">increase</TOKEN>
<TOKEN end_char="5694" id="token-46-4" morph="none" pos="word" start_char="5692">its</TOKEN>
<TOKEN end_char="5705" id="token-46-5" morph="none" pos="word" start_char="5696">production</TOKEN>
<TOKEN end_char="5708" id="token-46-6" morph="none" pos="word" start_char="5707">of</TOKEN>
<TOKEN end_char="5720" id="token-46-7" morph="none" pos="word" start_char="5710">chloroquine</TOKEN>
<TOKEN end_char="5723" id="token-46-8" morph="none" pos="word" start_char="5722">to</TOKEN>
<TOKEN end_char="5726" id="token-46-9" morph="none" pos="word" start_char="5725">be</TOKEN>
<TOKEN end_char="5731" id="token-46-10" morph="none" pos="word" start_char="5728">sent</TOKEN>
<TOKEN end_char="5734" id="token-46-11" morph="none" pos="word" start_char="5733">to</TOKEN>
<TOKEN end_char="5740" id="token-46-12" morph="none" pos="word" start_char="5736">China</TOKEN>
<TOKEN end_char="5741" id="token-46-13" morph="none" pos="punct" start_char="5741">.</TOKEN>
</SEG>
<SEG end_char="5898" id="segment-47" start_char="5744">
<ORIGINAL_TEXT>Switzerland discards the total lockdown of its population; goes for mass testing and fast treatment; and accuses France of practicing "spectacle politics."</ORIGINAL_TEXT>
<TOKEN end_char="5754" id="token-47-0" morph="none" pos="word" start_char="5744">Switzerland</TOKEN>
<TOKEN end_char="5763" id="token-47-1" morph="none" pos="word" start_char="5756">discards</TOKEN>
<TOKEN end_char="5767" id="token-47-2" morph="none" pos="word" start_char="5765">the</TOKEN>
<TOKEN end_char="5773" id="token-47-3" morph="none" pos="word" start_char="5769">total</TOKEN>
<TOKEN end_char="5782" id="token-47-4" morph="none" pos="word" start_char="5775">lockdown</TOKEN>
<TOKEN end_char="5785" id="token-47-5" morph="none" pos="word" start_char="5784">of</TOKEN>
<TOKEN end_char="5789" id="token-47-6" morph="none" pos="word" start_char="5787">its</TOKEN>
<TOKEN end_char="5800" id="token-47-7" morph="none" pos="word" start_char="5791">population</TOKEN>
<TOKEN end_char="5801" id="token-47-8" morph="none" pos="punct" start_char="5801">;</TOKEN>
<TOKEN end_char="5806" id="token-47-9" morph="none" pos="word" start_char="5803">goes</TOKEN>
<TOKEN end_char="5810" id="token-47-10" morph="none" pos="word" start_char="5808">for</TOKEN>
<TOKEN end_char="5815" id="token-47-11" morph="none" pos="word" start_char="5812">mass</TOKEN>
<TOKEN end_char="5823" id="token-47-12" morph="none" pos="word" start_char="5817">testing</TOKEN>
<TOKEN end_char="5827" id="token-47-13" morph="none" pos="word" start_char="5825">and</TOKEN>
<TOKEN end_char="5832" id="token-47-14" morph="none" pos="word" start_char="5829">fast</TOKEN>
<TOKEN end_char="5842" id="token-47-15" morph="none" pos="word" start_char="5834">treatment</TOKEN>
<TOKEN end_char="5843" id="token-47-16" morph="none" pos="punct" start_char="5843">;</TOKEN>
<TOKEN end_char="5847" id="token-47-17" morph="none" pos="word" start_char="5845">and</TOKEN>
<TOKEN end_char="5855" id="token-47-18" morph="none" pos="word" start_char="5849">accuses</TOKEN>
<TOKEN end_char="5862" id="token-47-19" morph="none" pos="word" start_char="5857">France</TOKEN>
<TOKEN end_char="5865" id="token-47-20" morph="none" pos="word" start_char="5864">of</TOKEN>
<TOKEN end_char="5876" id="token-47-21" morph="none" pos="word" start_char="5867">practicing</TOKEN>
<TOKEN end_char="5878" id="token-47-22" morph="none" pos="punct" start_char="5878">"</TOKEN>
<TOKEN end_char="5887" id="token-47-23" morph="none" pos="word" start_char="5879">spectacle</TOKEN>
<TOKEN end_char="5896" id="token-47-24" morph="none" pos="word" start_char="5889">politics</TOKEN>
<TOKEN end_char="5898" id="token-47-25" morph="none" pos="punct" start_char="5897">."</TOKEN>
</SEG>
<SEG end_char="6085" id="segment-48" start_char="5901">
<ORIGINAL_TEXT>Christian Estrosi, the mayor of Nice, having had himself treated with chloroquine, without any government input, directly calls Sanofi so they may deliver chloroquine to Nice hospitals.</ORIGINAL_TEXT>
<TOKEN end_char="5909" id="token-48-0" morph="none" pos="word" start_char="5901">Christian</TOKEN>
<TOKEN end_char="5917" id="token-48-1" morph="none" pos="word" start_char="5911">Estrosi</TOKEN>
<TOKEN end_char="5918" id="token-48-2" morph="none" pos="punct" start_char="5918">,</TOKEN>
<TOKEN end_char="5922" id="token-48-3" morph="none" pos="word" start_char="5920">the</TOKEN>
<TOKEN end_char="5928" id="token-48-4" morph="none" pos="word" start_char="5924">mayor</TOKEN>
<TOKEN end_char="5931" id="token-48-5" morph="none" pos="word" start_char="5930">of</TOKEN>
<TOKEN end_char="5936" id="token-48-6" morph="none" pos="word" start_char="5933">Nice</TOKEN>
<TOKEN end_char="5937" id="token-48-7" morph="none" pos="punct" start_char="5937">,</TOKEN>
<TOKEN end_char="5944" id="token-48-8" morph="none" pos="word" start_char="5939">having</TOKEN>
<TOKEN end_char="5948" id="token-48-9" morph="none" pos="word" start_char="5946">had</TOKEN>
<TOKEN end_char="5956" id="token-48-10" morph="none" pos="word" start_char="5950">himself</TOKEN>
<TOKEN end_char="5964" id="token-48-11" morph="none" pos="word" start_char="5958">treated</TOKEN>
<TOKEN end_char="5969" id="token-48-12" morph="none" pos="word" start_char="5966">with</TOKEN>
<TOKEN end_char="5981" id="token-48-13" morph="none" pos="word" start_char="5971">chloroquine</TOKEN>
<TOKEN end_char="5982" id="token-48-14" morph="none" pos="punct" start_char="5982">,</TOKEN>
<TOKEN end_char="5990" id="token-48-15" morph="none" pos="word" start_char="5984">without</TOKEN>
<TOKEN end_char="5994" id="token-48-16" morph="none" pos="word" start_char="5992">any</TOKEN>
<TOKEN end_char="6005" id="token-48-17" morph="none" pos="word" start_char="5996">government</TOKEN>
<TOKEN end_char="6011" id="token-48-18" morph="none" pos="word" start_char="6007">input</TOKEN>
<TOKEN end_char="6012" id="token-48-19" morph="none" pos="punct" start_char="6012">,</TOKEN>
<TOKEN end_char="6021" id="token-48-20" morph="none" pos="word" start_char="6014">directly</TOKEN>
<TOKEN end_char="6027" id="token-48-21" morph="none" pos="word" start_char="6023">calls</TOKEN>
<TOKEN end_char="6034" id="token-48-22" morph="none" pos="word" start_char="6029">Sanofi</TOKEN>
<TOKEN end_char="6037" id="token-48-23" morph="none" pos="word" start_char="6036">so</TOKEN>
<TOKEN end_char="6042" id="token-48-24" morph="none" pos="word" start_char="6039">they</TOKEN>
<TOKEN end_char="6046" id="token-48-25" morph="none" pos="word" start_char="6044">may</TOKEN>
<TOKEN end_char="6054" id="token-48-26" morph="none" pos="word" start_char="6048">deliver</TOKEN>
<TOKEN end_char="6066" id="token-48-27" morph="none" pos="word" start_char="6056">chloroquine</TOKEN>
<TOKEN end_char="6069" id="token-48-28" morph="none" pos="word" start_char="6068">to</TOKEN>
<TOKEN end_char="6074" id="token-48-29" morph="none" pos="word" start_char="6071">Nice</TOKEN>
<TOKEN end_char="6084" id="token-48-30" morph="none" pos="word" start_char="6076">hospitals</TOKEN>
<TOKEN end_char="6085" id="token-48-31" morph="none" pos="punct" start_char="6085">.</TOKEN>
</SEG>
<SEG end_char="6298" id="segment-49" start_char="6088">
<ORIGINAL_TEXT>Because of Raoult’s research, a large-scale chloroquine test finally starts in France, under the – predictable – direction of INSERM, which wants to "remake the experiments in other independent medical centers."</ORIGINAL_TEXT>
<TOKEN end_char="6094" id="token-49-0" morph="none" pos="word" start_char="6088">Because</TOKEN>
<TOKEN end_char="6097" id="token-49-1" morph="none" pos="word" start_char="6096">of</TOKEN>
<TOKEN end_char="6106" id="token-49-2" morph="none" pos="word" start_char="6099">Raoult’s</TOKEN>
<TOKEN end_char="6115" id="token-49-3" morph="none" pos="word" start_char="6108">research</TOKEN>
<TOKEN end_char="6116" id="token-49-4" morph="none" pos="punct" start_char="6116">,</TOKEN>
<TOKEN end_char="6118" id="token-49-5" morph="none" pos="word" start_char="6118">a</TOKEN>
<TOKEN end_char="6130" id="token-49-6" morph="none" pos="unknown" start_char="6120">large-scale</TOKEN>
<TOKEN end_char="6142" id="token-49-7" morph="none" pos="word" start_char="6132">chloroquine</TOKEN>
<TOKEN end_char="6147" id="token-49-8" morph="none" pos="word" start_char="6144">test</TOKEN>
<TOKEN end_char="6155" id="token-49-9" morph="none" pos="word" start_char="6149">finally</TOKEN>
<TOKEN end_char="6162" id="token-49-10" morph="none" pos="word" start_char="6157">starts</TOKEN>
<TOKEN end_char="6165" id="token-49-11" morph="none" pos="word" start_char="6164">in</TOKEN>
<TOKEN end_char="6172" id="token-49-12" morph="none" pos="word" start_char="6167">France</TOKEN>
<TOKEN end_char="6173" id="token-49-13" morph="none" pos="punct" start_char="6173">,</TOKEN>
<TOKEN end_char="6179" id="token-49-14" morph="none" pos="word" start_char="6175">under</TOKEN>
<TOKEN end_char="6183" id="token-49-15" morph="none" pos="word" start_char="6181">the</TOKEN>
<TOKEN end_char="6185" id="token-49-16" morph="none" pos="punct" start_char="6185">–</TOKEN>
<TOKEN end_char="6197" id="token-49-17" morph="none" pos="word" start_char="6187">predictable</TOKEN>
<TOKEN end_char="6199" id="token-49-18" morph="none" pos="punct" start_char="6199">–</TOKEN>
<TOKEN end_char="6209" id="token-49-19" morph="none" pos="word" start_char="6201">direction</TOKEN>
<TOKEN end_char="6212" id="token-49-20" morph="none" pos="word" start_char="6211">of</TOKEN>
<TOKEN end_char="6219" id="token-49-21" morph="none" pos="word" start_char="6214">INSERM</TOKEN>
<TOKEN end_char="6220" id="token-49-22" morph="none" pos="punct" start_char="6220">,</TOKEN>
<TOKEN end_char="6226" id="token-49-23" morph="none" pos="word" start_char="6222">which</TOKEN>
<TOKEN end_char="6232" id="token-49-24" morph="none" pos="word" start_char="6228">wants</TOKEN>
<TOKEN end_char="6235" id="token-49-25" morph="none" pos="word" start_char="6234">to</TOKEN>
<TOKEN end_char="6237" id="token-49-26" morph="none" pos="punct" start_char="6237">"</TOKEN>
<TOKEN end_char="6243" id="token-49-27" morph="none" pos="word" start_char="6238">remake</TOKEN>
<TOKEN end_char="6247" id="token-49-28" morph="none" pos="word" start_char="6245">the</TOKEN>
<TOKEN end_char="6259" id="token-49-29" morph="none" pos="word" start_char="6249">experiments</TOKEN>
<TOKEN end_char="6262" id="token-49-30" morph="none" pos="word" start_char="6261">in</TOKEN>
<TOKEN end_char="6268" id="token-49-31" morph="none" pos="word" start_char="6264">other</TOKEN>
<TOKEN end_char="6280" id="token-49-32" morph="none" pos="word" start_char="6270">independent</TOKEN>
<TOKEN end_char="6288" id="token-49-33" morph="none" pos="word" start_char="6282">medical</TOKEN>
<TOKEN end_char="6296" id="token-49-34" morph="none" pos="word" start_char="6290">centers</TOKEN>
<TOKEN end_char="6298" id="token-49-35" morph="none" pos="punct" start_char="6297">."</TOKEN>
</SEG>
<SEG end_char="6452" id="segment-50" start_char="6300">
<ORIGINAL_TEXT>This will take at least an extra six weeks – as the Elysee Palace’s scientific council now mulls the extension of France’s total lockdown to … six weeks.</ORIGINAL_TEXT>
<TOKEN end_char="6303" id="token-50-0" morph="none" pos="word" start_char="6300">This</TOKEN>
<TOKEN end_char="6308" id="token-50-1" morph="none" pos="word" start_char="6305">will</TOKEN>
<TOKEN end_char="6313" id="token-50-2" morph="none" pos="word" start_char="6310">take</TOKEN>
<TOKEN end_char="6316" id="token-50-3" morph="none" pos="word" start_char="6315">at</TOKEN>
<TOKEN end_char="6322" id="token-50-4" morph="none" pos="word" start_char="6318">least</TOKEN>
<TOKEN end_char="6325" id="token-50-5" morph="none" pos="word" start_char="6324">an</TOKEN>
<TOKEN end_char="6331" id="token-50-6" morph="none" pos="word" start_char="6327">extra</TOKEN>
<TOKEN end_char="6335" id="token-50-7" morph="none" pos="word" start_char="6333">six</TOKEN>
<TOKEN end_char="6341" id="token-50-8" morph="none" pos="word" start_char="6337">weeks</TOKEN>
<TOKEN end_char="6343" id="token-50-9" morph="none" pos="punct" start_char="6343">–</TOKEN>
<TOKEN end_char="6346" id="token-50-10" morph="none" pos="word" start_char="6345">as</TOKEN>
<TOKEN end_char="6350" id="token-50-11" morph="none" pos="word" start_char="6348">the</TOKEN>
<TOKEN end_char="6357" id="token-50-12" morph="none" pos="word" start_char="6352">Elysee</TOKEN>
<TOKEN end_char="6366" id="token-50-13" morph="none" pos="word" start_char="6359">Palace’s</TOKEN>
<TOKEN end_char="6377" id="token-50-14" morph="none" pos="word" start_char="6368">scientific</TOKEN>
<TOKEN end_char="6385" id="token-50-15" morph="none" pos="word" start_char="6379">council</TOKEN>
<TOKEN end_char="6389" id="token-50-16" morph="none" pos="word" start_char="6387">now</TOKEN>
<TOKEN end_char="6395" id="token-50-17" morph="none" pos="word" start_char="6391">mulls</TOKEN>
<TOKEN end_char="6399" id="token-50-18" morph="none" pos="word" start_char="6397">the</TOKEN>
<TOKEN end_char="6409" id="token-50-19" morph="none" pos="word" start_char="6401">extension</TOKEN>
<TOKEN end_char="6412" id="token-50-20" morph="none" pos="word" start_char="6411">of</TOKEN>
<TOKEN end_char="6421" id="token-50-21" morph="none" pos="word" start_char="6414">France’s</TOKEN>
<TOKEN end_char="6427" id="token-50-22" morph="none" pos="word" start_char="6423">total</TOKEN>
<TOKEN end_char="6436" id="token-50-23" morph="none" pos="word" start_char="6429">lockdown</TOKEN>
<TOKEN end_char="6439" id="token-50-24" morph="none" pos="word" start_char="6438">to</TOKEN>
<TOKEN end_char="6441" id="token-50-25" morph="none" pos="punct" start_char="6441">…</TOKEN>
<TOKEN end_char="6445" id="token-50-26" morph="none" pos="word" start_char="6443">six</TOKEN>
<TOKEN end_char="6451" id="token-50-27" morph="none" pos="word" start_char="6447">weeks</TOKEN>
<TOKEN end_char="6452" id="token-50-28" morph="none" pos="punct" start_char="6452">.</TOKEN>
</SEG>
<SEG end_char="6608" id="segment-51" start_char="6455">
<ORIGINAL_TEXT>If joint use of hydroxychloroquine and azithromycin proves definitely effective among the most gravely ill, quarantines may be reduced in select clusters.</ORIGINAL_TEXT>
<TOKEN end_char="6456" id="token-51-0" morph="none" pos="word" start_char="6455">If</TOKEN>
<TOKEN end_char="6462" id="token-51-1" morph="none" pos="word" start_char="6458">joint</TOKEN>
<TOKEN end_char="6466" id="token-51-2" morph="none" pos="word" start_char="6464">use</TOKEN>
<TOKEN end_char="6469" id="token-51-3" morph="none" pos="word" start_char="6468">of</TOKEN>
<TOKEN end_char="6488" id="token-51-4" morph="none" pos="word" start_char="6471">hydroxychloroquine</TOKEN>
<TOKEN end_char="6492" id="token-51-5" morph="none" pos="word" start_char="6490">and</TOKEN>
<TOKEN end_char="6505" id="token-51-6" morph="none" pos="word" start_char="6494">azithromycin</TOKEN>
<TOKEN end_char="6512" id="token-51-7" morph="none" pos="word" start_char="6507">proves</TOKEN>
<TOKEN end_char="6523" id="token-51-8" morph="none" pos="word" start_char="6514">definitely</TOKEN>
<TOKEN end_char="6533" id="token-51-9" morph="none" pos="word" start_char="6525">effective</TOKEN>
<TOKEN end_char="6539" id="token-51-10" morph="none" pos="word" start_char="6535">among</TOKEN>
<TOKEN end_char="6543" id="token-51-11" morph="none" pos="word" start_char="6541">the</TOKEN>
<TOKEN end_char="6548" id="token-51-12" morph="none" pos="word" start_char="6545">most</TOKEN>
<TOKEN end_char="6556" id="token-51-13" morph="none" pos="word" start_char="6550">gravely</TOKEN>
<TOKEN end_char="6560" id="token-51-14" morph="none" pos="word" start_char="6558">ill</TOKEN>
<TOKEN end_char="6561" id="token-51-15" morph="none" pos="punct" start_char="6561">,</TOKEN>
<TOKEN end_char="6573" id="token-51-16" morph="none" pos="word" start_char="6563">quarantines</TOKEN>
<TOKEN end_char="6577" id="token-51-17" morph="none" pos="word" start_char="6575">may</TOKEN>
<TOKEN end_char="6580" id="token-51-18" morph="none" pos="word" start_char="6579">be</TOKEN>
<TOKEN end_char="6588" id="token-51-19" morph="none" pos="word" start_char="6582">reduced</TOKEN>
<TOKEN end_char="6591" id="token-51-20" morph="none" pos="word" start_char="6590">in</TOKEN>
<TOKEN end_char="6598" id="token-51-21" morph="none" pos="word" start_char="6593">select</TOKEN>
<TOKEN end_char="6607" id="token-51-22" morph="none" pos="word" start_char="6600">clusters</TOKEN>
<TOKEN end_char="6608" id="token-51-23" morph="none" pos="punct" start_char="6608">.</TOKEN>
</SEG>
<SEG end_char="6701" id="segment-52" start_char="6611">
<ORIGINAL_TEXT>The only French company that still manufactures chloroquine is under judicial intervention.</ORIGINAL_TEXT>
<TOKEN end_char="6613" id="token-52-0" morph="none" pos="word" start_char="6611">The</TOKEN>
<TOKEN end_char="6618" id="token-52-1" morph="none" pos="word" start_char="6615">only</TOKEN>
<TOKEN end_char="6625" id="token-52-2" morph="none" pos="word" start_char="6620">French</TOKEN>
<TOKEN end_char="6633" id="token-52-3" morph="none" pos="word" start_char="6627">company</TOKEN>
<TOKEN end_char="6638" id="token-52-4" morph="none" pos="word" start_char="6635">that</TOKEN>
<TOKEN end_char="6644" id="token-52-5" morph="none" pos="word" start_char="6640">still</TOKEN>
<TOKEN end_char="6657" id="token-52-6" morph="none" pos="word" start_char="6646">manufactures</TOKEN>
<TOKEN end_char="6669" id="token-52-7" morph="none" pos="word" start_char="6659">chloroquine</TOKEN>
<TOKEN end_char="6672" id="token-52-8" morph="none" pos="word" start_char="6671">is</TOKEN>
<TOKEN end_char="6678" id="token-52-9" morph="none" pos="word" start_char="6674">under</TOKEN>
<TOKEN end_char="6687" id="token-52-10" morph="none" pos="word" start_char="6680">judicial</TOKEN>
<TOKEN end_char="6700" id="token-52-11" morph="none" pos="word" start_char="6689">intervention</TOKEN>
<TOKEN end_char="6701" id="token-52-12" morph="none" pos="punct" start_char="6701">.</TOKEN>
</SEG>
<SEG end_char="6769" id="segment-53" start_char="6703">
<ORIGINAL_TEXT>That puts the chloroquine hoarding and theft into full perspective.</ORIGINAL_TEXT>
<TOKEN end_char="6706" id="token-53-0" morph="none" pos="word" start_char="6703">That</TOKEN>
<TOKEN end_char="6711" id="token-53-1" morph="none" pos="word" start_char="6708">puts</TOKEN>
<TOKEN end_char="6715" id="token-53-2" morph="none" pos="word" start_char="6713">the</TOKEN>
<TOKEN end_char="6727" id="token-53-3" morph="none" pos="word" start_char="6717">chloroquine</TOKEN>
<TOKEN end_char="6736" id="token-53-4" morph="none" pos="word" start_char="6729">hoarding</TOKEN>
<TOKEN end_char="6740" id="token-53-5" morph="none" pos="word" start_char="6738">and</TOKEN>
<TOKEN end_char="6746" id="token-53-6" morph="none" pos="word" start_char="6742">theft</TOKEN>
<TOKEN end_char="6751" id="token-53-7" morph="none" pos="word" start_char="6748">into</TOKEN>
<TOKEN end_char="6756" id="token-53-8" morph="none" pos="word" start_char="6753">full</TOKEN>
<TOKEN end_char="6768" id="token-53-9" morph="none" pos="word" start_char="6758">perspective</TOKEN>
<TOKEN end_char="6769" id="token-53-10" morph="none" pos="punct" start_char="6769">.</TOKEN>
</SEG>
<SEG end_char="6901" id="segment-54" start_char="6771">
<ORIGINAL_TEXT>It will take time for these stocks to be replenished, thus allowing Big Pharma the leeway to have what it wants: a costly solution.</ORIGINAL_TEXT>
<TOKEN end_char="6772" id="token-54-0" morph="none" pos="word" start_char="6771">It</TOKEN>
<TOKEN end_char="6777" id="token-54-1" morph="none" pos="word" start_char="6774">will</TOKEN>
<TOKEN end_char="6782" id="token-54-2" morph="none" pos="word" start_char="6779">take</TOKEN>
<TOKEN end_char="6787" id="token-54-3" morph="none" pos="word" start_char="6784">time</TOKEN>
<TOKEN end_char="6791" id="token-54-4" morph="none" pos="word" start_char="6789">for</TOKEN>
<TOKEN end_char="6797" id="token-54-5" morph="none" pos="word" start_char="6793">these</TOKEN>
<TOKEN end_char="6804" id="token-54-6" morph="none" pos="word" start_char="6799">stocks</TOKEN>
<TOKEN end_char="6807" id="token-54-7" morph="none" pos="word" start_char="6806">to</TOKEN>
<TOKEN end_char="6810" id="token-54-8" morph="none" pos="word" start_char="6809">be</TOKEN>
<TOKEN end_char="6822" id="token-54-9" morph="none" pos="word" start_char="6812">replenished</TOKEN>
<TOKEN end_char="6823" id="token-54-10" morph="none" pos="punct" start_char="6823">,</TOKEN>
<TOKEN end_char="6828" id="token-54-11" morph="none" pos="word" start_char="6825">thus</TOKEN>
<TOKEN end_char="6837" id="token-54-12" morph="none" pos="word" start_char="6830">allowing</TOKEN>
<TOKEN end_char="6841" id="token-54-13" morph="none" pos="word" start_char="6839">Big</TOKEN>
<TOKEN end_char="6848" id="token-54-14" morph="none" pos="word" start_char="6843">Pharma</TOKEN>
<TOKEN end_char="6852" id="token-54-15" morph="none" pos="word" start_char="6850">the</TOKEN>
<TOKEN end_char="6859" id="token-54-16" morph="none" pos="word" start_char="6854">leeway</TOKEN>
<TOKEN end_char="6862" id="token-54-17" morph="none" pos="word" start_char="6861">to</TOKEN>
<TOKEN end_char="6867" id="token-54-18" morph="none" pos="word" start_char="6864">have</TOKEN>
<TOKEN end_char="6872" id="token-54-19" morph="none" pos="word" start_char="6869">what</TOKEN>
<TOKEN end_char="6875" id="token-54-20" morph="none" pos="word" start_char="6874">it</TOKEN>
<TOKEN end_char="6881" id="token-54-21" morph="none" pos="word" start_char="6877">wants</TOKEN>
<TOKEN end_char="6882" id="token-54-22" morph="none" pos="punct" start_char="6882">:</TOKEN>
<TOKEN end_char="6884" id="token-54-23" morph="none" pos="word" start_char="6884">a</TOKEN>
<TOKEN end_char="6891" id="token-54-24" morph="none" pos="word" start_char="6886">costly</TOKEN>
<TOKEN end_char="6900" id="token-54-25" morph="none" pos="word" start_char="6893">solution</TOKEN>
<TOKEN end_char="6901" id="token-54-26" morph="none" pos="punct" start_char="6901">.</TOKEN>
</SEG>
<SEG end_char="6980" id="segment-55" start_char="6904">
<ORIGINAL_TEXT>It appears the perpetrators of the chloroquine theft were very well informed.</ORIGINAL_TEXT>
<TOKEN end_char="6905" id="token-55-0" morph="none" pos="word" start_char="6904">It</TOKEN>
<TOKEN end_char="6913" id="token-55-1" morph="none" pos="word" start_char="6907">appears</TOKEN>
<TOKEN end_char="6917" id="token-55-2" morph="none" pos="word" start_char="6915">the</TOKEN>
<TOKEN end_char="6930" id="token-55-3" morph="none" pos="word" start_char="6919">perpetrators</TOKEN>
<TOKEN end_char="6933" id="token-55-4" morph="none" pos="word" start_char="6932">of</TOKEN>
<TOKEN end_char="6937" id="token-55-5" morph="none" pos="word" start_char="6935">the</TOKEN>
<TOKEN end_char="6949" id="token-55-6" morph="none" pos="word" start_char="6939">chloroquine</TOKEN>
<TOKEN end_char="6955" id="token-55-7" morph="none" pos="word" start_char="6951">theft</TOKEN>
<TOKEN end_char="6960" id="token-55-8" morph="none" pos="word" start_char="6957">were</TOKEN>
<TOKEN end_char="6965" id="token-55-9" morph="none" pos="word" start_char="6962">very</TOKEN>
<TOKEN end_char="6970" id="token-55-10" morph="none" pos="word" start_char="6967">well</TOKEN>
<TOKEN end_char="6979" id="token-55-11" morph="none" pos="word" start_char="6972">informed</TOKEN>
<TOKEN end_char="6980" id="token-55-12" morph="none" pos="punct" start_char="6980">.</TOKEN>
</SEG>
<SEG end_char="6995" id="segment-56" start_char="6983">
<ORIGINAL_TEXT>Bagged nurses</ORIGINAL_TEXT>
<TOKEN end_char="6988" id="token-56-0" morph="none" pos="word" start_char="6983">Bagged</TOKEN>
<TOKEN end_char="6995" id="token-56-1" morph="none" pos="word" start_char="6990">nurses</TOKEN>
<TRANSLATED_TEXT>Krankenverpleegkundige</TRANSLATED_TEXT><DETECTED_LANGUAGE>da</DETECTED_LANGUAGE></SEG>
<SEG end_char="7158" id="segment-57" start_char="6998">
<ORIGINAL_TEXT>This chain of events, astonishing for a highly developed G-7 nation proud of its health service, is part of a long, painful process embedded in neoliberal dogma.</ORIGINAL_TEXT>
<TOKEN end_char="7001" id="token-57-0" morph="none" pos="word" start_char="6998">This</TOKEN>
<TOKEN end_char="7007" id="token-57-1" morph="none" pos="word" start_char="7003">chain</TOKEN>
<TOKEN end_char="7010" id="token-57-2" morph="none" pos="word" start_char="7009">of</TOKEN>
<TOKEN end_char="7017" id="token-57-3" morph="none" pos="word" start_char="7012">events</TOKEN>
<TOKEN end_char="7018" id="token-57-4" morph="none" pos="punct" start_char="7018">,</TOKEN>
<TOKEN end_char="7030" id="token-57-5" morph="none" pos="word" start_char="7020">astonishing</TOKEN>
<TOKEN end_char="7034" id="token-57-6" morph="none" pos="word" start_char="7032">for</TOKEN>
<TOKEN end_char="7036" id="token-57-7" morph="none" pos="word" start_char="7036">a</TOKEN>
<TOKEN end_char="7043" id="token-57-8" morph="none" pos="word" start_char="7038">highly</TOKEN>
<TOKEN end_char="7053" id="token-57-9" morph="none" pos="word" start_char="7045">developed</TOKEN>
<TOKEN end_char="7057" id="token-57-10" morph="none" pos="unknown" start_char="7055">G-7</TOKEN>
<TOKEN end_char="7064" id="token-57-11" morph="none" pos="word" start_char="7059">nation</TOKEN>
<TOKEN end_char="7070" id="token-57-12" morph="none" pos="word" start_char="7066">proud</TOKEN>
<TOKEN end_char="7073" id="token-57-13" morph="none" pos="word" start_char="7072">of</TOKEN>
<TOKEN end_char="7077" id="token-57-14" morph="none" pos="word" start_char="7075">its</TOKEN>
<TOKEN end_char="7084" id="token-57-15" morph="none" pos="word" start_char="7079">health</TOKEN>
<TOKEN end_char="7092" id="token-57-16" morph="none" pos="word" start_char="7086">service</TOKEN>
<TOKEN end_char="7093" id="token-57-17" morph="none" pos="punct" start_char="7093">,</TOKEN>
<TOKEN end_char="7096" id="token-57-18" morph="none" pos="word" start_char="7095">is</TOKEN>
<TOKEN end_char="7101" id="token-57-19" morph="none" pos="word" start_char="7098">part</TOKEN>
<TOKEN end_char="7104" id="token-57-20" morph="none" pos="word" start_char="7103">of</TOKEN>
<TOKEN end_char="7106" id="token-57-21" morph="none" pos="word" start_char="7106">a</TOKEN>
<TOKEN end_char="7111" id="token-57-22" morph="none" pos="word" start_char="7108">long</TOKEN>
<TOKEN end_char="7112" id="token-57-23" morph="none" pos="punct" start_char="7112">,</TOKEN>
<TOKEN end_char="7120" id="token-57-24" morph="none" pos="word" start_char="7114">painful</TOKEN>
<TOKEN end_char="7128" id="token-57-25" morph="none" pos="word" start_char="7122">process</TOKEN>
<TOKEN end_char="7137" id="token-57-26" morph="none" pos="word" start_char="7130">embedded</TOKEN>
<TOKEN end_char="7140" id="token-57-27" morph="none" pos="word" start_char="7139">in</TOKEN>
<TOKEN end_char="7151" id="token-57-28" morph="none" pos="word" start_char="7142">neoliberal</TOKEN>
<TOKEN end_char="7157" id="token-57-29" morph="none" pos="word" start_char="7153">dogma</TOKEN>
<TOKEN end_char="7158" id="token-57-30" morph="none" pos="punct" start_char="7158">.</TOKEN>
</SEG>
<SEG end_char="7266" id="segment-58" start_char="7160">
<ORIGINAL_TEXT>EU-driven austerity mixed with the profit motive resulted in a very lax attitude towards the health system.</ORIGINAL_TEXT>
<TOKEN end_char="7168" id="token-58-0" morph="none" pos="unknown" start_char="7160">EU-driven</TOKEN>
<TOKEN end_char="7178" id="token-58-1" morph="none" pos="word" start_char="7170">austerity</TOKEN>
<TOKEN end_char="7184" id="token-58-2" morph="none" pos="word" start_char="7180">mixed</TOKEN>
<TOKEN end_char="7189" id="token-58-3" morph="none" pos="word" start_char="7186">with</TOKEN>
<TOKEN end_char="7193" id="token-58-4" morph="none" pos="word" start_char="7191">the</TOKEN>
<TOKEN end_char="7200" id="token-58-5" morph="none" pos="word" start_char="7195">profit</TOKEN>
<TOKEN end_char="7207" id="token-58-6" morph="none" pos="word" start_char="7202">motive</TOKEN>
<TOKEN end_char="7216" id="token-58-7" morph="none" pos="word" start_char="7209">resulted</TOKEN>
<TOKEN end_char="7219" id="token-58-8" morph="none" pos="word" start_char="7218">in</TOKEN>
<TOKEN end_char="7221" id="token-58-9" morph="none" pos="word" start_char="7221">a</TOKEN>
<TOKEN end_char="7226" id="token-58-10" morph="none" pos="word" start_char="7223">very</TOKEN>
<TOKEN end_char="7230" id="token-58-11" morph="none" pos="word" start_char="7228">lax</TOKEN>
<TOKEN end_char="7239" id="token-58-12" morph="none" pos="word" start_char="7232">attitude</TOKEN>
<TOKEN end_char="7247" id="token-58-13" morph="none" pos="word" start_char="7241">towards</TOKEN>
<TOKEN end_char="7251" id="token-58-14" morph="none" pos="word" start_char="7249">the</TOKEN>
<TOKEN end_char="7258" id="token-58-15" morph="none" pos="word" start_char="7253">health</TOKEN>
<TOKEN end_char="7265" id="token-58-16" morph="none" pos="word" start_char="7260">system</TOKEN>
<TOKEN end_char="7266" id="token-58-17" morph="none" pos="punct" start_char="7266">.</TOKEN>
</SEG>
<SEG end_char="7526" id="segment-59" start_char="7269">
<ORIGINAL_TEXT>As Bugault told me, "test kits – very few in number – were always available but mostly for a small group connected to the French government [ former officials of the Ministry of Finance, CEOs of large corporations, oligarchs, media and entertainment moguls].</ORIGINAL_TEXT>
<TOKEN end_char="7270" id="token-59-0" morph="none" pos="word" start_char="7269">As</TOKEN>
<TOKEN end_char="7278" id="token-59-1" morph="none" pos="word" start_char="7272">Bugault</TOKEN>
<TOKEN end_char="7283" id="token-59-2" morph="none" pos="word" start_char="7280">told</TOKEN>
<TOKEN end_char="7286" id="token-59-3" morph="none" pos="word" start_char="7285">me</TOKEN>
<TOKEN end_char="7287" id="token-59-4" morph="none" pos="punct" start_char="7287">,</TOKEN>
<TOKEN end_char="7289" id="token-59-5" morph="none" pos="punct" start_char="7289">"</TOKEN>
<TOKEN end_char="7293" id="token-59-6" morph="none" pos="word" start_char="7290">test</TOKEN>
<TOKEN end_char="7298" id="token-59-7" morph="none" pos="word" start_char="7295">kits</TOKEN>
<TOKEN end_char="7300" id="token-59-8" morph="none" pos="punct" start_char="7300">–</TOKEN>
<TOKEN end_char="7305" id="token-59-9" morph="none" pos="word" start_char="7302">very</TOKEN>
<TOKEN end_char="7309" id="token-59-10" morph="none" pos="word" start_char="7307">few</TOKEN>
<TOKEN end_char="7312" id="token-59-11" morph="none" pos="word" start_char="7311">in</TOKEN>
<TOKEN end_char="7319" id="token-59-12" morph="none" pos="word" start_char="7314">number</TOKEN>
<TOKEN end_char="7321" id="token-59-13" morph="none" pos="punct" start_char="7321">–</TOKEN>
<TOKEN end_char="7326" id="token-59-14" morph="none" pos="word" start_char="7323">were</TOKEN>
<TOKEN end_char="7333" id="token-59-15" morph="none" pos="word" start_char="7328">always</TOKEN>
<TOKEN end_char="7343" id="token-59-16" morph="none" pos="word" start_char="7335">available</TOKEN>
<TOKEN end_char="7347" id="token-59-17" morph="none" pos="word" start_char="7345">but</TOKEN>
<TOKEN end_char="7354" id="token-59-18" morph="none" pos="word" start_char="7349">mostly</TOKEN>
<TOKEN end_char="7358" id="token-59-19" morph="none" pos="word" start_char="7356">for</TOKEN>
<TOKEN end_char="7360" id="token-59-20" morph="none" pos="word" start_char="7360">a</TOKEN>
<TOKEN end_char="7366" id="token-59-21" morph="none" pos="word" start_char="7362">small</TOKEN>
<TOKEN end_char="7372" id="token-59-22" morph="none" pos="word" start_char="7368">group</TOKEN>
<TOKEN end_char="7382" id="token-59-23" morph="none" pos="word" start_char="7374">connected</TOKEN>
<TOKEN end_char="7385" id="token-59-24" morph="none" pos="word" start_char="7384">to</TOKEN>
<TOKEN end_char="7389" id="token-59-25" morph="none" pos="word" start_char="7387">the</TOKEN>
<TOKEN end_char="7396" id="token-59-26" morph="none" pos="word" start_char="7391">French</TOKEN>
<TOKEN end_char="7407" id="token-59-27" morph="none" pos="word" start_char="7398">government</TOKEN>
<TOKEN end_char="7409" id="token-59-28" morph="none" pos="punct" start_char="7409">[</TOKEN>
<TOKEN end_char="7416" id="token-59-29" morph="none" pos="word" start_char="7411">former</TOKEN>
<TOKEN end_char="7426" id="token-59-30" morph="none" pos="word" start_char="7418">officials</TOKEN>
<TOKEN end_char="7429" id="token-59-31" morph="none" pos="word" start_char="7428">of</TOKEN>
<TOKEN end_char="7433" id="token-59-32" morph="none" pos="word" start_char="7431">the</TOKEN>
<TOKEN end_char="7442" id="token-59-33" morph="none" pos="word" start_char="7435">Ministry</TOKEN>
<TOKEN end_char="7445" id="token-59-34" morph="none" pos="word" start_char="7444">of</TOKEN>
<TOKEN end_char="7453" id="token-59-35" morph="none" pos="word" start_char="7447">Finance</TOKEN>
<TOKEN end_char="7454" id="token-59-36" morph="none" pos="punct" start_char="7454">,</TOKEN>
<TOKEN end_char="7459" id="token-59-37" morph="none" pos="word" start_char="7456">CEOs</TOKEN>
<TOKEN end_char="7462" id="token-59-38" morph="none" pos="word" start_char="7461">of</TOKEN>
<TOKEN end_char="7468" id="token-59-39" morph="none" pos="word" start_char="7464">large</TOKEN>
<TOKEN end_char="7481" id="token-59-40" morph="none" pos="word" start_char="7470">corporations</TOKEN>
<TOKEN end_char="7482" id="token-59-41" morph="none" pos="punct" start_char="7482">,</TOKEN>
<TOKEN end_char="7492" id="token-59-42" morph="none" pos="word" start_char="7484">oligarchs</TOKEN>
<TOKEN end_char="7493" id="token-59-43" morph="none" pos="punct" start_char="7493">,</TOKEN>
<TOKEN end_char="7499" id="token-59-44" morph="none" pos="word" start_char="7495">media</TOKEN>
<TOKEN end_char="7503" id="token-59-45" morph="none" pos="word" start_char="7501">and</TOKEN>
<TOKEN end_char="7517" id="token-59-46" morph="none" pos="word" start_char="7505">entertainment</TOKEN>
<TOKEN end_char="7524" id="token-59-47" morph="none" pos="word" start_char="7519">moguls</TOKEN>
<TOKEN end_char="7526" id="token-59-48" morph="none" pos="punct" start_char="7525">].</TOKEN>
</SEG>
<SEG end_char="7626" id="segment-60" start_char="7528">
<ORIGINAL_TEXT>Same for chloroquine, which this government did everything to make inaccessible for the population.</ORIGINAL_TEXT>
<TOKEN end_char="7531" id="token-60-0" morph="none" pos="word" start_char="7528">Same</TOKEN>
<TOKEN end_char="7535" id="token-60-1" morph="none" pos="word" start_char="7533">for</TOKEN>
<TOKEN end_char="7547" id="token-60-2" morph="none" pos="word" start_char="7537">chloroquine</TOKEN>
<TOKEN end_char="7548" id="token-60-3" morph="none" pos="punct" start_char="7548">,</TOKEN>
<TOKEN end_char="7554" id="token-60-4" morph="none" pos="word" start_char="7550">which</TOKEN>
<TOKEN end_char="7559" id="token-60-5" morph="none" pos="word" start_char="7556">this</TOKEN>
<TOKEN end_char="7570" id="token-60-6" morph="none" pos="word" start_char="7561">government</TOKEN>
<TOKEN end_char="7574" id="token-60-7" morph="none" pos="word" start_char="7572">did</TOKEN>
<TOKEN end_char="7585" id="token-60-8" morph="none" pos="word" start_char="7576">everything</TOKEN>
<TOKEN end_char="7588" id="token-60-9" morph="none" pos="word" start_char="7587">to</TOKEN>
<TOKEN end_char="7593" id="token-60-10" morph="none" pos="word" start_char="7590">make</TOKEN>
<TOKEN end_char="7606" id="token-60-11" morph="none" pos="word" start_char="7595">inaccessible</TOKEN>
<TOKEN end_char="7610" id="token-60-12" morph="none" pos="word" start_char="7608">for</TOKEN>
<TOKEN end_char="7614" id="token-60-13" morph="none" pos="word" start_char="7612">the</TOKEN>
<TOKEN end_char="7625" id="token-60-14" morph="none" pos="word" start_char="7616">population</TOKEN>
<TOKEN end_char="7626" id="token-60-15" morph="none" pos="punct" start_char="7626">.</TOKEN>
</SEG>
<SEG end_char="7742" id="segment-61" start_char="7629">
<ORIGINAL_TEXT>They did not make life easy for Professor Raoult – he received death threats and was intimidated by ‘journalists.’</ORIGINAL_TEXT>
<TOKEN end_char="7632" id="token-61-0" morph="none" pos="word" start_char="7629">They</TOKEN>
<TOKEN end_char="7636" id="token-61-1" morph="none" pos="word" start_char="7634">did</TOKEN>
<TOKEN end_char="7640" id="token-61-2" morph="none" pos="word" start_char="7638">not</TOKEN>
<TOKEN end_char="7645" id="token-61-3" morph="none" pos="word" start_char="7642">make</TOKEN>
<TOKEN end_char="7650" id="token-61-4" morph="none" pos="word" start_char="7647">life</TOKEN>
<TOKEN end_char="7655" id="token-61-5" morph="none" pos="word" start_char="7652">easy</TOKEN>
<TOKEN end_char="7659" id="token-61-6" morph="none" pos="word" start_char="7657">for</TOKEN>
<TOKEN end_char="7669" id="token-61-7" morph="none" pos="word" start_char="7661">Professor</TOKEN>
<TOKEN end_char="7676" id="token-61-8" morph="none" pos="word" start_char="7671">Raoult</TOKEN>
<TOKEN end_char="7678" id="token-61-9" morph="none" pos="punct" start_char="7678">–</TOKEN>
<TOKEN end_char="7681" id="token-61-10" morph="none" pos="word" start_char="7680">he</TOKEN>
<TOKEN end_char="7690" id="token-61-11" morph="none" pos="word" start_char="7683">received</TOKEN>
<TOKEN end_char="7696" id="token-61-12" morph="none" pos="word" start_char="7692">death</TOKEN>
<TOKEN end_char="7704" id="token-61-13" morph="none" pos="word" start_char="7698">threats</TOKEN>
<TOKEN end_char="7708" id="token-61-14" morph="none" pos="word" start_char="7706">and</TOKEN>
<TOKEN end_char="7712" id="token-61-15" morph="none" pos="word" start_char="7710">was</TOKEN>
<TOKEN end_char="7724" id="token-61-16" morph="none" pos="word" start_char="7714">intimidated</TOKEN>
<TOKEN end_char="7727" id="token-61-17" morph="none" pos="word" start_char="7726">by</TOKEN>
<TOKEN end_char="7729" id="token-61-18" morph="none" pos="punct" start_char="7729">‘</TOKEN>
<TOKEN end_char="7740" id="token-61-19" morph="none" pos="word" start_char="7730">journalists</TOKEN>
<TOKEN end_char="7742" id="token-61-20" morph="none" pos="punct" start_char="7741">.’</TOKEN>
</SEG>
<SEG end_char="7782" id="segment-62" start_char="7745">
<ORIGINAL_TEXT>And they did not protect vital stocks.</ORIGINAL_TEXT>
<TOKEN end_char="7747" id="token-62-0" morph="none" pos="word" start_char="7745">And</TOKEN>
<TOKEN end_char="7752" id="token-62-1" morph="none" pos="word" start_char="7749">they</TOKEN>
<TOKEN end_char="7756" id="token-62-2" morph="none" pos="word" start_char="7754">did</TOKEN>
<TOKEN end_char="7760" id="token-62-3" morph="none" pos="word" start_char="7758">not</TOKEN>
<TOKEN end_char="7768" id="token-62-4" morph="none" pos="word" start_char="7762">protect</TOKEN>
<TOKEN end_char="7774" id="token-62-5" morph="none" pos="word" start_char="7770">vital</TOKEN>
<TOKEN end_char="7781" id="token-62-6" morph="none" pos="word" start_char="7776">stocks</TOKEN>
<TOKEN end_char="7782" id="token-62-7" morph="none" pos="punct" start_char="7782">.</TOKEN>
</SEG>
<SEG end_char="7933" id="segment-63" start_char="7784">
<ORIGINAL_TEXT>Still under the Hollande government, there was a conscious liquidation of the stock of masks – which had existed in large quantities in all hospitals.</ORIGINAL_TEXT>
<TOKEN end_char="7788" id="token-63-0" morph="none" pos="word" start_char="7784">Still</TOKEN>
<TOKEN end_char="7794" id="token-63-1" morph="none" pos="word" start_char="7790">under</TOKEN>
<TOKEN end_char="7798" id="token-63-2" morph="none" pos="word" start_char="7796">the</TOKEN>
<TOKEN end_char="7807" id="token-63-3" morph="none" pos="word" start_char="7800">Hollande</TOKEN>
<TOKEN end_char="7818" id="token-63-4" morph="none" pos="word" start_char="7809">government</TOKEN>
<TOKEN end_char="7819" id="token-63-5" morph="none" pos="punct" start_char="7819">,</TOKEN>
<TOKEN end_char="7825" id="token-63-6" morph="none" pos="word" start_char="7821">there</TOKEN>
<TOKEN end_char="7829" id="token-63-7" morph="none" pos="word" start_char="7827">was</TOKEN>
<TOKEN end_char="7831" id="token-63-8" morph="none" pos="word" start_char="7831">a</TOKEN>
<TOKEN end_char="7841" id="token-63-9" morph="none" pos="word" start_char="7833">conscious</TOKEN>
<TOKEN end_char="7853" id="token-63-10" morph="none" pos="word" start_char="7843">liquidation</TOKEN>
<TOKEN end_char="7856" id="token-63-11" morph="none" pos="word" start_char="7855">of</TOKEN>
<TOKEN end_char="7860" id="token-63-12" morph="none" pos="word" start_char="7858">the</TOKEN>
<TOKEN end_char="7866" id="token-63-13" morph="none" pos="word" start_char="7862">stock</TOKEN>
<TOKEN end_char="7869" id="token-63-14" morph="none" pos="word" start_char="7868">of</TOKEN>
<TOKEN end_char="7875" id="token-63-15" morph="none" pos="word" start_char="7871">masks</TOKEN>
<TOKEN end_char="7877" id="token-63-16" morph="none" pos="punct" start_char="7877">–</TOKEN>
<TOKEN end_char="7883" id="token-63-17" morph="none" pos="word" start_char="7879">which</TOKEN>
<TOKEN end_char="7887" id="token-63-18" morph="none" pos="word" start_char="7885">had</TOKEN>
<TOKEN end_char="7895" id="token-63-19" morph="none" pos="word" start_char="7889">existed</TOKEN>
<TOKEN end_char="7898" id="token-63-20" morph="none" pos="word" start_char="7897">in</TOKEN>
<TOKEN end_char="7904" id="token-63-21" morph="none" pos="word" start_char="7900">large</TOKEN>
<TOKEN end_char="7915" id="token-63-22" morph="none" pos="word" start_char="7906">quantities</TOKEN>
<TOKEN end_char="7918" id="token-63-23" morph="none" pos="word" start_char="7917">in</TOKEN>
<TOKEN end_char="7922" id="token-63-24" morph="none" pos="word" start_char="7920">all</TOKEN>
<TOKEN end_char="7932" id="token-63-25" morph="none" pos="word" start_char="7924">hospitals</TOKEN>
<TOKEN end_char="7933" id="token-63-26" morph="none" pos="punct" start_char="7933">.</TOKEN>
</SEG>
<SEG end_char="8033" id="segment-64" start_char="7935">
<ORIGINAL_TEXT>Not to mention that the suppression of hospital beds and hospital means accelerated under Sarkozy."</ORIGINAL_TEXT>
<TOKEN end_char="7937" id="token-64-0" morph="none" pos="word" start_char="7935">Not</TOKEN>
<TOKEN end_char="7940" id="token-64-1" morph="none" pos="word" start_char="7939">to</TOKEN>
<TOKEN end_char="7948" id="token-64-2" morph="none" pos="word" start_char="7942">mention</TOKEN>
<TOKEN end_char="7953" id="token-64-3" morph="none" pos="word" start_char="7950">that</TOKEN>
<TOKEN end_char="7957" id="token-64-4" morph="none" pos="word" start_char="7955">the</TOKEN>
<TOKEN end_char="7969" id="token-64-5" morph="none" pos="word" start_char="7959">suppression</TOKEN>
<TOKEN end_char="7972" id="token-64-6" morph="none" pos="word" start_char="7971">of</TOKEN>
<TOKEN end_char="7981" id="token-64-7" morph="none" pos="word" start_char="7974">hospital</TOKEN>
<TOKEN end_char="7986" id="token-64-8" morph="none" pos="word" start_char="7983">beds</TOKEN>
<TOKEN end_char="7990" id="token-64-9" morph="none" pos="word" start_char="7988">and</TOKEN>
<TOKEN end_char="7999" id="token-64-10" morph="none" pos="word" start_char="7992">hospital</TOKEN>
<TOKEN end_char="8005" id="token-64-11" morph="none" pos="word" start_char="8001">means</TOKEN>
<TOKEN end_char="8017" id="token-64-12" morph="none" pos="word" start_char="8007">accelerated</TOKEN>
<TOKEN end_char="8023" id="token-64-13" morph="none" pos="word" start_char="8019">under</TOKEN>
<TOKEN end_char="8031" id="token-64-14" morph="none" pos="word" start_char="8025">Sarkozy</TOKEN>
<TOKEN end_char="8033" id="token-64-15" morph="none" pos="punct" start_char="8032">."</TOKEN>
</SEG>
<SEG end_char="8168" id="segment-65" start_char="8036">
<ORIGINAL_TEXT>This ties in with anguished reports by French citizens of nurses now having to use trash bags due to the lack of proper medical gear.</ORIGINAL_TEXT>
<TOKEN end_char="8039" id="token-65-0" morph="none" pos="word" start_char="8036">This</TOKEN>
<TOKEN end_char="8044" id="token-65-1" morph="none" pos="word" start_char="8041">ties</TOKEN>
<TOKEN end_char="8047" id="token-65-2" morph="none" pos="word" start_char="8046">in</TOKEN>
<TOKEN end_char="8052" id="token-65-3" morph="none" pos="word" start_char="8049">with</TOKEN>
<TOKEN end_char="8062" id="token-65-4" morph="none" pos="word" start_char="8054">anguished</TOKEN>
<TOKEN end_char="8070" id="token-65-5" morph="none" pos="word" start_char="8064">reports</TOKEN>
<TOKEN end_char="8073" id="token-65-6" morph="none" pos="word" start_char="8072">by</TOKEN>
<TOKEN end_char="8080" id="token-65-7" morph="none" pos="word" start_char="8075">French</TOKEN>
<TOKEN end_char="8089" id="token-65-8" morph="none" pos="word" start_char="8082">citizens</TOKEN>
<TOKEN end_char="8092" id="token-65-9" morph="none" pos="word" start_char="8091">of</TOKEN>
<TOKEN end_char="8099" id="token-65-10" morph="none" pos="word" start_char="8094">nurses</TOKEN>
<TOKEN end_char="8103" id="token-65-11" morph="none" pos="word" start_char="8101">now</TOKEN>
<TOKEN end_char="8110" id="token-65-12" morph="none" pos="word" start_char="8105">having</TOKEN>
<TOKEN end_char="8113" id="token-65-13" morph="none" pos="word" start_char="8112">to</TOKEN>
<TOKEN end_char="8117" id="token-65-14" morph="none" pos="word" start_char="8115">use</TOKEN>
<TOKEN end_char="8123" id="token-65-15" morph="none" pos="word" start_char="8119">trash</TOKEN>
<TOKEN end_char="8128" id="token-65-16" morph="none" pos="word" start_char="8125">bags</TOKEN>
<TOKEN end_char="8132" id="token-65-17" morph="none" pos="word" start_char="8130">due</TOKEN>
<TOKEN end_char="8135" id="token-65-18" morph="none" pos="word" start_char="8134">to</TOKEN>
<TOKEN end_char="8139" id="token-65-19" morph="none" pos="word" start_char="8137">the</TOKEN>
<TOKEN end_char="8144" id="token-65-20" morph="none" pos="word" start_char="8141">lack</TOKEN>
<TOKEN end_char="8147" id="token-65-21" morph="none" pos="word" start_char="8146">of</TOKEN>
<TOKEN end_char="8154" id="token-65-22" morph="none" pos="word" start_char="8149">proper</TOKEN>
<TOKEN end_char="8162" id="token-65-23" morph="none" pos="word" start_char="8156">medical</TOKEN>
<TOKEN end_char="8167" id="token-65-24" morph="none" pos="word" start_char="8164">gear</TOKEN>
<TOKEN end_char="8168" id="token-65-25" morph="none" pos="punct" start_char="8168">.</TOKEN>
</SEG>
<SEG end_char="8522" id="segment-66" start_char="8171">
<ORIGINAL_TEXT>At the same time, in another astonishing development, the French state refuses to requisition private hospitals and clinics – which are practically empty at this stage – even as the president of their own association, Lamine Garbi, has pleaded for such a public service initiative: "I solemnly demand that we are requisitioned to help public hospitals.</ORIGINAL_TEXT>
<TOKEN end_char="8172" id="token-66-0" morph="none" pos="word" start_char="8171">At</TOKEN>
<TOKEN end_char="8176" id="token-66-1" morph="none" pos="word" start_char="8174">the</TOKEN>
<TOKEN end_char="8181" id="token-66-2" morph="none" pos="word" start_char="8178">same</TOKEN>
<TOKEN end_char="8186" id="token-66-3" morph="none" pos="word" start_char="8183">time</TOKEN>
<TOKEN end_char="8187" id="token-66-4" morph="none" pos="punct" start_char="8187">,</TOKEN>
<TOKEN end_char="8190" id="token-66-5" morph="none" pos="word" start_char="8189">in</TOKEN>
<TOKEN end_char="8198" id="token-66-6" morph="none" pos="word" start_char="8192">another</TOKEN>
<TOKEN end_char="8210" id="token-66-7" morph="none" pos="word" start_char="8200">astonishing</TOKEN>
<TOKEN end_char="8222" id="token-66-8" morph="none" pos="word" start_char="8212">development</TOKEN>
<TOKEN end_char="8223" id="token-66-9" morph="none" pos="punct" start_char="8223">,</TOKEN>
<TOKEN end_char="8227" id="token-66-10" morph="none" pos="word" start_char="8225">the</TOKEN>
<TOKEN end_char="8234" id="token-66-11" morph="none" pos="word" start_char="8229">French</TOKEN>
<TOKEN end_char="8240" id="token-66-12" morph="none" pos="word" start_char="8236">state</TOKEN>
<TOKEN end_char="8248" id="token-66-13" morph="none" pos="word" start_char="8242">refuses</TOKEN>
<TOKEN end_char="8251" id="token-66-14" morph="none" pos="word" start_char="8250">to</TOKEN>
<TOKEN end_char="8263" id="token-66-15" morph="none" pos="word" start_char="8253">requisition</TOKEN>
<TOKEN end_char="8271" id="token-66-16" morph="none" pos="word" start_char="8265">private</TOKEN>
<TOKEN end_char="8281" id="token-66-17" morph="none" pos="word" start_char="8273">hospitals</TOKEN>
<TOKEN end_char="8285" id="token-66-18" morph="none" pos="word" start_char="8283">and</TOKEN>
<TOKEN end_char="8293" id="token-66-19" morph="none" pos="word" start_char="8287">clinics</TOKEN>
<TOKEN end_char="8295" id="token-66-20" morph="none" pos="punct" start_char="8295">–</TOKEN>
<TOKEN end_char="8301" id="token-66-21" morph="none" pos="word" start_char="8297">which</TOKEN>
<TOKEN end_char="8305" id="token-66-22" morph="none" pos="word" start_char="8303">are</TOKEN>
<TOKEN end_char="8317" id="token-66-23" morph="none" pos="word" start_char="8307">practically</TOKEN>
<TOKEN end_char="8323" id="token-66-24" morph="none" pos="word" start_char="8319">empty</TOKEN>
<TOKEN end_char="8326" id="token-66-25" morph="none" pos="word" start_char="8325">at</TOKEN>
<TOKEN end_char="8331" id="token-66-26" morph="none" pos="word" start_char="8328">this</TOKEN>
<TOKEN end_char="8337" id="token-66-27" morph="none" pos="word" start_char="8333">stage</TOKEN>
<TOKEN end_char="8339" id="token-66-28" morph="none" pos="punct" start_char="8339">–</TOKEN>
<TOKEN end_char="8344" id="token-66-29" morph="none" pos="word" start_char="8341">even</TOKEN>
<TOKEN end_char="8347" id="token-66-30" morph="none" pos="word" start_char="8346">as</TOKEN>
<TOKEN end_char="8351" id="token-66-31" morph="none" pos="word" start_char="8349">the</TOKEN>
<TOKEN end_char="8361" id="token-66-32" morph="none" pos="word" start_char="8353">president</TOKEN>
<TOKEN end_char="8364" id="token-66-33" morph="none" pos="word" start_char="8363">of</TOKEN>
<TOKEN end_char="8370" id="token-66-34" morph="none" pos="word" start_char="8366">their</TOKEN>
<TOKEN end_char="8374" id="token-66-35" morph="none" pos="word" start_char="8372">own</TOKEN>
<TOKEN end_char="8386" id="token-66-36" morph="none" pos="word" start_char="8376">association</TOKEN>
<TOKEN end_char="8387" id="token-66-37" morph="none" pos="punct" start_char="8387">,</TOKEN>
<TOKEN end_char="8394" id="token-66-38" morph="none" pos="word" start_char="8389">Lamine</TOKEN>
<TOKEN end_char="8400" id="token-66-39" morph="none" pos="word" start_char="8396">Garbi</TOKEN>
<TOKEN end_char="8401" id="token-66-40" morph="none" pos="punct" start_char="8401">,</TOKEN>
<TOKEN end_char="8405" id="token-66-41" morph="none" pos="word" start_char="8403">has</TOKEN>
<TOKEN end_char="8413" id="token-66-42" morph="none" pos="word" start_char="8407">pleaded</TOKEN>
<TOKEN end_char="8417" id="token-66-43" morph="none" pos="word" start_char="8415">for</TOKEN>
<TOKEN end_char="8422" id="token-66-44" morph="none" pos="word" start_char="8419">such</TOKEN>
<TOKEN end_char="8424" id="token-66-45" morph="none" pos="word" start_char="8424">a</TOKEN>
<TOKEN end_char="8431" id="token-66-46" morph="none" pos="word" start_char="8426">public</TOKEN>
<TOKEN end_char="8439" id="token-66-47" morph="none" pos="word" start_char="8433">service</TOKEN>
<TOKEN end_char="8450" id="token-66-48" morph="none" pos="word" start_char="8441">initiative</TOKEN>
<TOKEN end_char="8451" id="token-66-49" morph="none" pos="punct" start_char="8451">:</TOKEN>
<TOKEN end_char="8453" id="token-66-50" morph="none" pos="punct" start_char="8453">"</TOKEN>
<TOKEN end_char="8454" id="token-66-51" morph="none" pos="word" start_char="8454">I</TOKEN>
<TOKEN end_char="8463" id="token-66-52" morph="none" pos="word" start_char="8456">solemnly</TOKEN>
<TOKEN end_char="8470" id="token-66-53" morph="none" pos="word" start_char="8465">demand</TOKEN>
<TOKEN end_char="8475" id="token-66-54" morph="none" pos="word" start_char="8472">that</TOKEN>
<TOKEN end_char="8478" id="token-66-55" morph="none" pos="word" start_char="8477">we</TOKEN>
<TOKEN end_char="8482" id="token-66-56" morph="none" pos="word" start_char="8480">are</TOKEN>
<TOKEN end_char="8496" id="token-66-57" morph="none" pos="word" start_char="8484">requisitioned</TOKEN>
<TOKEN end_char="8499" id="token-66-58" morph="none" pos="word" start_char="8498">to</TOKEN>
<TOKEN end_char="8504" id="token-66-59" morph="none" pos="word" start_char="8501">help</TOKEN>
<TOKEN end_char="8511" id="token-66-60" morph="none" pos="word" start_char="8506">public</TOKEN>
<TOKEN end_char="8521" id="token-66-61" morph="none" pos="word" start_char="8513">hospitals</TOKEN>
<TOKEN end_char="8522" id="token-66-62" morph="none" pos="punct" start_char="8522">.</TOKEN>
</SEG>
<SEG end_char="8551" id="segment-67" start_char="8524">
<ORIGINAL_TEXT>Our facilities are prepared.</ORIGINAL_TEXT>
<TOKEN end_char="8526" id="token-67-0" morph="none" pos="word" start_char="8524">Our</TOKEN>
<TOKEN end_char="8537" id="token-67-1" morph="none" pos="word" start_char="8528">facilities</TOKEN>
<TOKEN end_char="8541" id="token-67-2" morph="none" pos="word" start_char="8539">are</TOKEN>
<TOKEN end_char="8550" id="token-67-3" morph="none" pos="word" start_char="8543">prepared</TOKEN>
<TOKEN end_char="8551" id="token-67-4" morph="none" pos="punct" start_char="8551">.</TOKEN>
</SEG>
<SEG end_char="8619" id="segment-68" start_char="8553">
<ORIGINAL_TEXT>The wave that surprised the east of France must teach us a lesson."</ORIGINAL_TEXT>
<TOKEN end_char="8555" id="token-68-0" morph="none" pos="word" start_char="8553">The</TOKEN>
<TOKEN end_char="8560" id="token-68-1" morph="none" pos="word" start_char="8557">wave</TOKEN>
<TOKEN end_char="8565" id="token-68-2" morph="none" pos="word" start_char="8562">that</TOKEN>
<TOKEN end_char="8575" id="token-68-3" morph="none" pos="word" start_char="8567">surprised</TOKEN>
<TOKEN end_char="8579" id="token-68-4" morph="none" pos="word" start_char="8577">the</TOKEN>
<TOKEN end_char="8584" id="token-68-5" morph="none" pos="word" start_char="8581">east</TOKEN>
<TOKEN end_char="8587" id="token-68-6" morph="none" pos="word" start_char="8586">of</TOKEN>
<TOKEN end_char="8594" id="token-68-7" morph="none" pos="word" start_char="8589">France</TOKEN>
<TOKEN end_char="8599" id="token-68-8" morph="none" pos="word" start_char="8596">must</TOKEN>
<TOKEN end_char="8605" id="token-68-9" morph="none" pos="word" start_char="8601">teach</TOKEN>
<TOKEN end_char="8608" id="token-68-10" morph="none" pos="word" start_char="8607">us</TOKEN>
<TOKEN end_char="8610" id="token-68-11" morph="none" pos="word" start_char="8610">a</TOKEN>
<TOKEN end_char="8617" id="token-68-12" morph="none" pos="word" start_char="8612">lesson</TOKEN>
<TOKEN end_char="8619" id="token-68-13" morph="none" pos="punct" start_char="8618">."</TOKEN>
</SEG>
<SEG end_char="8902" id="segment-69" start_char="8622">
<ORIGINAL_TEXT>Bugault reconfirms the health situation in France "is very serious and will become even worse due to these political decisions – absence of masks, political refusal to massively test people, refusal of free access to chloroquine – in a context of supreme distress at the hospitals.</ORIGINAL_TEXT>
<TOKEN end_char="8628" id="token-69-0" morph="none" pos="word" start_char="8622">Bugault</TOKEN>
<TOKEN end_char="8639" id="token-69-1" morph="none" pos="word" start_char="8630">reconfirms</TOKEN>
<TOKEN end_char="8643" id="token-69-2" morph="none" pos="word" start_char="8641">the</TOKEN>
<TOKEN end_char="8650" id="token-69-3" morph="none" pos="word" start_char="8645">health</TOKEN>
<TOKEN end_char="8660" id="token-69-4" morph="none" pos="word" start_char="8652">situation</TOKEN>
<TOKEN end_char="8663" id="token-69-5" morph="none" pos="word" start_char="8662">in</TOKEN>
<TOKEN end_char="8670" id="token-69-6" morph="none" pos="word" start_char="8665">France</TOKEN>
<TOKEN end_char="8672" id="token-69-7" morph="none" pos="punct" start_char="8672">"</TOKEN>
<TOKEN end_char="8674" id="token-69-8" morph="none" pos="word" start_char="8673">is</TOKEN>
<TOKEN end_char="8679" id="token-69-9" morph="none" pos="word" start_char="8676">very</TOKEN>
<TOKEN end_char="8687" id="token-69-10" morph="none" pos="word" start_char="8681">serious</TOKEN>
<TOKEN end_char="8691" id="token-69-11" morph="none" pos="word" start_char="8689">and</TOKEN>
<TOKEN end_char="8696" id="token-69-12" morph="none" pos="word" start_char="8693">will</TOKEN>
<TOKEN end_char="8703" id="token-69-13" morph="none" pos="word" start_char="8698">become</TOKEN>
<TOKEN end_char="8708" id="token-69-14" morph="none" pos="word" start_char="8705">even</TOKEN>
<TOKEN end_char="8714" id="token-69-15" morph="none" pos="word" start_char="8710">worse</TOKEN>
<TOKEN end_char="8718" id="token-69-16" morph="none" pos="word" start_char="8716">due</TOKEN>
<TOKEN end_char="8721" id="token-69-17" morph="none" pos="word" start_char="8720">to</TOKEN>
<TOKEN end_char="8727" id="token-69-18" morph="none" pos="word" start_char="8723">these</TOKEN>
<TOKEN end_char="8737" id="token-69-19" morph="none" pos="word" start_char="8729">political</TOKEN>
<TOKEN end_char="8747" id="token-69-20" morph="none" pos="word" start_char="8739">decisions</TOKEN>
<TOKEN end_char="8749" id="token-69-21" morph="none" pos="punct" start_char="8749">–</TOKEN>
<TOKEN end_char="8757" id="token-69-22" morph="none" pos="word" start_char="8751">absence</TOKEN>
<TOKEN end_char="8760" id="token-69-23" morph="none" pos="word" start_char="8759">of</TOKEN>
<TOKEN end_char="8766" id="token-69-24" morph="none" pos="word" start_char="8762">masks</TOKEN>
<TOKEN end_char="8767" id="token-69-25" morph="none" pos="punct" start_char="8767">,</TOKEN>
<TOKEN end_char="8777" id="token-69-26" morph="none" pos="word" start_char="8769">political</TOKEN>
<TOKEN end_char="8785" id="token-69-27" morph="none" pos="word" start_char="8779">refusal</TOKEN>
<TOKEN end_char="8788" id="token-69-28" morph="none" pos="word" start_char="8787">to</TOKEN>
<TOKEN end_char="8798" id="token-69-29" morph="none" pos="word" start_char="8790">massively</TOKEN>
<TOKEN end_char="8803" id="token-69-30" morph="none" pos="word" start_char="8800">test</TOKEN>
<TOKEN end_char="8810" id="token-69-31" morph="none" pos="word" start_char="8805">people</TOKEN>
<TOKEN end_char="8811" id="token-69-32" morph="none" pos="punct" start_char="8811">,</TOKEN>
<TOKEN end_char="8819" id="token-69-33" morph="none" pos="word" start_char="8813">refusal</TOKEN>
<TOKEN end_char="8822" id="token-69-34" morph="none" pos="word" start_char="8821">of</TOKEN>
<TOKEN end_char="8827" id="token-69-35" morph="none" pos="word" start_char="8824">free</TOKEN>
<TOKEN end_char="8834" id="token-69-36" morph="none" pos="word" start_char="8829">access</TOKEN>
<TOKEN end_char="8837" id="token-69-37" morph="none" pos="word" start_char="8836">to</TOKEN>
<TOKEN end_char="8849" id="token-69-38" morph="none" pos="word" start_char="8839">chloroquine</TOKEN>
<TOKEN end_char="8851" id="token-69-39" morph="none" pos="punct" start_char="8851">–</TOKEN>
<TOKEN end_char="8854" id="token-69-40" morph="none" pos="word" start_char="8853">in</TOKEN>
<TOKEN end_char="8856" id="token-69-41" morph="none" pos="word" start_char="8856">a</TOKEN>
<TOKEN end_char="8864" id="token-69-42" morph="none" pos="word" start_char="8858">context</TOKEN>
<TOKEN end_char="8867" id="token-69-43" morph="none" pos="word" start_char="8866">of</TOKEN>
<TOKEN end_char="8875" id="token-69-44" morph="none" pos="word" start_char="8869">supreme</TOKEN>
<TOKEN end_char="8884" id="token-69-45" morph="none" pos="word" start_char="8877">distress</TOKEN>
<TOKEN end_char="8887" id="token-69-46" morph="none" pos="word" start_char="8886">at</TOKEN>
<TOKEN end_char="8891" id="token-69-47" morph="none" pos="word" start_char="8889">the</TOKEN>
<TOKEN end_char="8901" id="token-69-48" morph="none" pos="word" start_char="8893">hospitals</TOKEN>
<TOKEN end_char="8902" id="token-69-49" morph="none" pos="punct" start_char="8902">.</TOKEN>
</SEG>
<SEG end_char="8952" id="segment-70" start_char="8904">
<ORIGINAL_TEXT>This will last and destitution will be the norm."</ORIGINAL_TEXT>
<TOKEN end_char="8907" id="token-70-0" morph="none" pos="word" start_char="8904">This</TOKEN>
<TOKEN end_char="8912" id="token-70-1" morph="none" pos="word" start_char="8909">will</TOKEN>
<TOKEN end_char="8917" id="token-70-2" morph="none" pos="word" start_char="8914">last</TOKEN>
<TOKEN end_char="8921" id="token-70-3" morph="none" pos="word" start_char="8919">and</TOKEN>
<TOKEN end_char="8933" id="token-70-4" morph="none" pos="word" start_char="8923">destitution</TOKEN>
<TOKEN end_char="8938" id="token-70-5" morph="none" pos="word" start_char="8935">will</TOKEN>
<TOKEN end_char="8941" id="token-70-6" morph="none" pos="word" start_char="8940">be</TOKEN>
<TOKEN end_char="8945" id="token-70-7" morph="none" pos="word" start_char="8943">the</TOKEN>
<TOKEN end_char="8950" id="token-70-8" morph="none" pos="word" start_char="8947">norm</TOKEN>
<TOKEN end_char="8952" id="token-70-9" morph="none" pos="punct" start_char="8951">."</TOKEN>
</SEG>
<SEG end_char="8976" id="segment-71" start_char="8955">
<ORIGINAL_TEXT>Professor vs president</ORIGINAL_TEXT>
<TOKEN end_char="8963" id="token-71-0" morph="none" pos="word" start_char="8955">Professor</TOKEN>
<TOKEN end_char="8966" id="token-71-1" morph="none" pos="word" start_char="8965">vs</TOKEN>
<TOKEN end_char="8976" id="token-71-2" morph="none" pos="word" start_char="8968">president</TOKEN>
<TRANSLATED_TEXT>Professor vs President</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="9137" id="segment-72" start_char="8979">
<ORIGINAL_TEXT>In an explosive development on Tuesday, Raoult said he’s not participating in Macron’s scientific council anymore, even though he’s not quitting it altogether.</ORIGINAL_TEXT>
<TOKEN end_char="8980" id="token-72-0" morph="none" pos="word" start_char="8979">In</TOKEN>
<TOKEN end_char="8983" id="token-72-1" morph="none" pos="word" start_char="8982">an</TOKEN>
<TOKEN end_char="8993" id="token-72-2" morph="none" pos="word" start_char="8985">explosive</TOKEN>
<TOKEN end_char="9005" id="token-72-3" morph="none" pos="word" start_char="8995">development</TOKEN>
<TOKEN end_char="9008" id="token-72-4" morph="none" pos="word" start_char="9007">on</TOKEN>
<TOKEN end_char="9016" id="token-72-5" morph="none" pos="word" start_char="9010">Tuesday</TOKEN>
<TOKEN end_char="9017" id="token-72-6" morph="none" pos="punct" start_char="9017">,</TOKEN>
<TOKEN end_char="9024" id="token-72-7" morph="none" pos="word" start_char="9019">Raoult</TOKEN>
<TOKEN end_char="9029" id="token-72-8" morph="none" pos="word" start_char="9026">said</TOKEN>
<TOKEN end_char="9034" id="token-72-9" morph="none" pos="word" start_char="9031">he’s</TOKEN>
<TOKEN end_char="9038" id="token-72-10" morph="none" pos="word" start_char="9036">not</TOKEN>
<TOKEN end_char="9052" id="token-72-11" morph="none" pos="word" start_char="9040">participating</TOKEN>
<TOKEN end_char="9055" id="token-72-12" morph="none" pos="word" start_char="9054">in</TOKEN>
<TOKEN end_char="9064" id="token-72-13" morph="none" pos="word" start_char="9057">Macron’s</TOKEN>
<TOKEN end_char="9075" id="token-72-14" morph="none" pos="word" start_char="9066">scientific</TOKEN>
<TOKEN end_char="9083" id="token-72-15" morph="none" pos="word" start_char="9077">council</TOKEN>
<TOKEN end_char="9091" id="token-72-16" morph="none" pos="word" start_char="9085">anymore</TOKEN>
<TOKEN end_char="9092" id="token-72-17" morph="none" pos="punct" start_char="9092">,</TOKEN>
<TOKEN end_char="9097" id="token-72-18" morph="none" pos="word" start_char="9094">even</TOKEN>
<TOKEN end_char="9104" id="token-72-19" morph="none" pos="word" start_char="9099">though</TOKEN>
<TOKEN end_char="9109" id="token-72-20" morph="none" pos="word" start_char="9106">he’s</TOKEN>
<TOKEN end_char="9113" id="token-72-21" morph="none" pos="word" start_char="9111">not</TOKEN>
<TOKEN end_char="9122" id="token-72-22" morph="none" pos="word" start_char="9115">quitting</TOKEN>
<TOKEN end_char="9125" id="token-72-23" morph="none" pos="word" start_char="9124">it</TOKEN>
<TOKEN end_char="9136" id="token-72-24" morph="none" pos="word" start_char="9127">altogether</TOKEN>
<TOKEN end_char="9137" id="token-72-25" morph="none" pos="punct" start_char="9137">.</TOKEN>
</SEG>
<SEG end_char="9286" id="segment-73" start_char="9139">
<ORIGINAL_TEXT>Raoult once again insists on massive testing on a national scale to detect suspected cases, and then isolate and treat patients who tested positive.</ORIGINAL_TEXT>
<TOKEN end_char="9144" id="token-73-0" morph="none" pos="word" start_char="9139">Raoult</TOKEN>
<TOKEN end_char="9149" id="token-73-1" morph="none" pos="word" start_char="9146">once</TOKEN>
<TOKEN end_char="9155" id="token-73-2" morph="none" pos="word" start_char="9151">again</TOKEN>
<TOKEN end_char="9163" id="token-73-3" morph="none" pos="word" start_char="9157">insists</TOKEN>
<TOKEN end_char="9166" id="token-73-4" morph="none" pos="word" start_char="9165">on</TOKEN>
<TOKEN end_char="9174" id="token-73-5" morph="none" pos="word" start_char="9168">massive</TOKEN>
<TOKEN end_char="9182" id="token-73-6" morph="none" pos="word" start_char="9176">testing</TOKEN>
<TOKEN end_char="9185" id="token-73-7" morph="none" pos="word" start_char="9184">on</TOKEN>
<TOKEN end_char="9187" id="token-73-8" morph="none" pos="word" start_char="9187">a</TOKEN>
<TOKEN end_char="9196" id="token-73-9" morph="none" pos="word" start_char="9189">national</TOKEN>
<TOKEN end_char="9202" id="token-73-10" morph="none" pos="word" start_char="9198">scale</TOKEN>
<TOKEN end_char="9205" id="token-73-11" morph="none" pos="word" start_char="9204">to</TOKEN>
<TOKEN end_char="9212" id="token-73-12" morph="none" pos="word" start_char="9207">detect</TOKEN>
<TOKEN end_char="9222" id="token-73-13" morph="none" pos="word" start_char="9214">suspected</TOKEN>
<TOKEN end_char="9228" id="token-73-14" morph="none" pos="word" start_char="9224">cases</TOKEN>
<TOKEN end_char="9229" id="token-73-15" morph="none" pos="punct" start_char="9229">,</TOKEN>
<TOKEN end_char="9233" id="token-73-16" morph="none" pos="word" start_char="9231">and</TOKEN>
<TOKEN end_char="9238" id="token-73-17" morph="none" pos="word" start_char="9235">then</TOKEN>
<TOKEN end_char="9246" id="token-73-18" morph="none" pos="word" start_char="9240">isolate</TOKEN>
<TOKEN end_char="9250" id="token-73-19" morph="none" pos="word" start_char="9248">and</TOKEN>
<TOKEN end_char="9256" id="token-73-20" morph="none" pos="word" start_char="9252">treat</TOKEN>
<TOKEN end_char="9265" id="token-73-21" morph="none" pos="word" start_char="9258">patients</TOKEN>
<TOKEN end_char="9269" id="token-73-22" morph="none" pos="word" start_char="9267">who</TOKEN>
<TOKEN end_char="9276" id="token-73-23" morph="none" pos="word" start_char="9271">tested</TOKEN>
<TOKEN end_char="9285" id="token-73-24" morph="none" pos="word" start_char="9278">positive</TOKEN>
<TOKEN end_char="9286" id="token-73-25" morph="none" pos="punct" start_char="9286">.</TOKEN>
</SEG>
<SEG end_char="9325" id="segment-74" start_char="9288">
<ORIGINAL_TEXT>In a nutshell: the South Korean model.</ORIGINAL_TEXT>
<TOKEN end_char="9289" id="token-74-0" morph="none" pos="word" start_char="9288">In</TOKEN>
<TOKEN end_char="9291" id="token-74-1" morph="none" pos="word" start_char="9291">a</TOKEN>
<TOKEN end_char="9300" id="token-74-2" morph="none" pos="word" start_char="9293">nutshell</TOKEN>
<TOKEN end_char="9301" id="token-74-3" morph="none" pos="punct" start_char="9301">:</TOKEN>
<TOKEN end_char="9305" id="token-74-4" morph="none" pos="word" start_char="9303">the</TOKEN>
<TOKEN end_char="9311" id="token-74-5" morph="none" pos="word" start_char="9307">South</TOKEN>
<TOKEN end_char="9318" id="token-74-6" morph="none" pos="word" start_char="9313">Korean</TOKEN>
<TOKEN end_char="9324" id="token-74-7" morph="none" pos="word" start_char="9320">model</TOKEN>
<TOKEN end_char="9325" id="token-74-8" morph="none" pos="punct" start_char="9325">.</TOKEN>
</SEG>
<SEG end_char="9447" id="segment-75" start_char="9328">
<ORIGINAL_TEXT>That’s exactly what is expected from the IHU in Marseille, where hundreds of residents continue to queue up for testing.</ORIGINAL_TEXT>
<TOKEN end_char="9333" id="token-75-0" morph="none" pos="word" start_char="9328">That’s</TOKEN>
<TOKEN end_char="9341" id="token-75-1" morph="none" pos="word" start_char="9335">exactly</TOKEN>
<TOKEN end_char="9346" id="token-75-2" morph="none" pos="word" start_char="9343">what</TOKEN>
<TOKEN end_char="9349" id="token-75-3" morph="none" pos="word" start_char="9348">is</TOKEN>
<TOKEN end_char="9358" id="token-75-4" morph="none" pos="word" start_char="9351">expected</TOKEN>
<TOKEN end_char="9363" id="token-75-5" morph="none" pos="word" start_char="9360">from</TOKEN>
<TOKEN end_char="9367" id="token-75-6" morph="none" pos="word" start_char="9365">the</TOKEN>
<TOKEN end_char="9371" id="token-75-7" morph="none" pos="word" start_char="9369">IHU</TOKEN>
<TOKEN end_char="9374" id="token-75-8" morph="none" pos="word" start_char="9373">in</TOKEN>
<TOKEN end_char="9384" id="token-75-9" morph="none" pos="word" start_char="9376">Marseille</TOKEN>
<TOKEN end_char="9385" id="token-75-10" morph="none" pos="punct" start_char="9385">,</TOKEN>
<TOKEN end_char="9391" id="token-75-11" morph="none" pos="word" start_char="9387">where</TOKEN>
<TOKEN end_char="9400" id="token-75-12" morph="none" pos="word" start_char="9393">hundreds</TOKEN>
<TOKEN end_char="9403" id="token-75-13" morph="none" pos="word" start_char="9402">of</TOKEN>
<TOKEN end_char="9413" id="token-75-14" morph="none" pos="word" start_char="9405">residents</TOKEN>
<TOKEN end_char="9422" id="token-75-15" morph="none" pos="word" start_char="9415">continue</TOKEN>
<TOKEN end_char="9425" id="token-75-16" morph="none" pos="word" start_char="9424">to</TOKEN>
<TOKEN end_char="9431" id="token-75-17" morph="none" pos="word" start_char="9427">queue</TOKEN>
<TOKEN end_char="9434" id="token-75-18" morph="none" pos="word" start_char="9433">up</TOKEN>
<TOKEN end_char="9438" id="token-75-19" morph="none" pos="word" start_char="9436">for</TOKEN>
<TOKEN end_char="9446" id="token-75-20" morph="none" pos="word" start_char="9440">testing</TOKEN>
<TOKEN end_char="9447" id="token-75-21" morph="none" pos="punct" start_char="9447">.</TOKEN>
</SEG>
<SEG end_char="9667" id="segment-76" start_char="9449">
<ORIGINAL_TEXT>And that ties in with the conclusions by a top Chinese expert on Covid-19, Zhang Nanshan, who says that treatment with chloroquine phospate had a "positive impact," with patients testing negative after around four days.</ORIGINAL_TEXT>
<TOKEN end_char="9451" id="token-76-0" morph="none" pos="word" start_char="9449">And</TOKEN>
<TOKEN end_char="9456" id="token-76-1" morph="none" pos="word" start_char="9453">that</TOKEN>
<TOKEN end_char="9461" id="token-76-2" morph="none" pos="word" start_char="9458">ties</TOKEN>
<TOKEN end_char="9464" id="token-76-3" morph="none" pos="word" start_char="9463">in</TOKEN>
<TOKEN end_char="9469" id="token-76-4" morph="none" pos="word" start_char="9466">with</TOKEN>
<TOKEN end_char="9473" id="token-76-5" morph="none" pos="word" start_char="9471">the</TOKEN>
<TOKEN end_char="9485" id="token-76-6" morph="none" pos="word" start_char="9475">conclusions</TOKEN>
<TOKEN end_char="9488" id="token-76-7" morph="none" pos="word" start_char="9487">by</TOKEN>
<TOKEN end_char="9490" id="token-76-8" morph="none" pos="word" start_char="9490">a</TOKEN>
<TOKEN end_char="9494" id="token-76-9" morph="none" pos="word" start_char="9492">top</TOKEN>
<TOKEN end_char="9502" id="token-76-10" morph="none" pos="word" start_char="9496">Chinese</TOKEN>
<TOKEN end_char="9509" id="token-76-11" morph="none" pos="word" start_char="9504">expert</TOKEN>
<TOKEN end_char="9512" id="token-76-12" morph="none" pos="word" start_char="9511">on</TOKEN>
<TOKEN end_char="9521" id="token-76-13" morph="none" pos="unknown" start_char="9514">Covid-19</TOKEN>
<TOKEN end_char="9522" id="token-76-14" morph="none" pos="punct" start_char="9522">,</TOKEN>
<TOKEN end_char="9528" id="token-76-15" morph="none" pos="word" start_char="9524">Zhang</TOKEN>
<TOKEN end_char="9536" id="token-76-16" morph="none" pos="word" start_char="9530">Nanshan</TOKEN>
<TOKEN end_char="9537" id="token-76-17" morph="none" pos="punct" start_char="9537">,</TOKEN>
<TOKEN end_char="9541" id="token-76-18" morph="none" pos="word" start_char="9539">who</TOKEN>
<TOKEN end_char="9546" id="token-76-19" morph="none" pos="word" start_char="9543">says</TOKEN>
<TOKEN end_char="9551" id="token-76-20" morph="none" pos="word" start_char="9548">that</TOKEN>
<TOKEN end_char="9561" id="token-76-21" morph="none" pos="word" start_char="9553">treatment</TOKEN>
<TOKEN end_char="9566" id="token-76-22" morph="none" pos="word" start_char="9563">with</TOKEN>
<TOKEN end_char="9578" id="token-76-23" morph="none" pos="word" start_char="9568">chloroquine</TOKEN>
<TOKEN end_char="9587" id="token-76-24" morph="none" pos="word" start_char="9580">phospate</TOKEN>
<TOKEN end_char="9591" id="token-76-25" morph="none" pos="word" start_char="9589">had</TOKEN>
<TOKEN end_char="9593" id="token-76-26" morph="none" pos="word" start_char="9593">a</TOKEN>
<TOKEN end_char="9595" id="token-76-27" morph="none" pos="punct" start_char="9595">"</TOKEN>
<TOKEN end_char="9603" id="token-76-28" morph="none" pos="word" start_char="9596">positive</TOKEN>
<TOKEN end_char="9610" id="token-76-29" morph="none" pos="word" start_char="9605">impact</TOKEN>
<TOKEN end_char="9612" id="token-76-30" morph="none" pos="punct" start_char="9611">,"</TOKEN>
<TOKEN end_char="9617" id="token-76-31" morph="none" pos="word" start_char="9614">with</TOKEN>
<TOKEN end_char="9626" id="token-76-32" morph="none" pos="word" start_char="9619">patients</TOKEN>
<TOKEN end_char="9634" id="token-76-33" morph="none" pos="word" start_char="9628">testing</TOKEN>
<TOKEN end_char="9643" id="token-76-34" morph="none" pos="word" start_char="9636">negative</TOKEN>
<TOKEN end_char="9649" id="token-76-35" morph="none" pos="word" start_char="9645">after</TOKEN>
<TOKEN end_char="9656" id="token-76-36" morph="none" pos="word" start_char="9651">around</TOKEN>
<TOKEN end_char="9661" id="token-76-37" morph="none" pos="word" start_char="9658">four</TOKEN>
<TOKEN end_char="9666" id="token-76-38" morph="none" pos="word" start_char="9663">days</TOKEN>
<TOKEN end_char="9667" id="token-76-39" morph="none" pos="punct" start_char="9667">.</TOKEN>
</SEG>
<SEG end_char="9851" id="segment-77" start_char="9670">
<ORIGINAL_TEXT>The key point has been stressed by Raoult: Use chloroquine in very special circumstances, for people tested very early, when the disease is not advanced yet, and only in these cases.</ORIGINAL_TEXT>
<TOKEN end_char="9672" id="token-77-0" morph="none" pos="word" start_char="9670">The</TOKEN>
<TOKEN end_char="9676" id="token-77-1" morph="none" pos="word" start_char="9674">key</TOKEN>
<TOKEN end_char="9682" id="token-77-2" morph="none" pos="word" start_char="9678">point</TOKEN>
<TOKEN end_char="9686" id="token-77-3" morph="none" pos="word" start_char="9684">has</TOKEN>
<TOKEN end_char="9691" id="token-77-4" morph="none" pos="word" start_char="9688">been</TOKEN>
<TOKEN end_char="9700" id="token-77-5" morph="none" pos="word" start_char="9693">stressed</TOKEN>
<TOKEN end_char="9703" id="token-77-6" morph="none" pos="word" start_char="9702">by</TOKEN>
<TOKEN end_char="9710" id="token-77-7" morph="none" pos="word" start_char="9705">Raoult</TOKEN>
<TOKEN end_char="9711" id="token-77-8" morph="none" pos="punct" start_char="9711">:</TOKEN>
<TOKEN end_char="9715" id="token-77-9" morph="none" pos="word" start_char="9713">Use</TOKEN>
<TOKEN end_char="9727" id="token-77-10" morph="none" pos="word" start_char="9717">chloroquine</TOKEN>
<TOKEN end_char="9730" id="token-77-11" morph="none" pos="word" start_char="9729">in</TOKEN>
<TOKEN end_char="9735" id="token-77-12" morph="none" pos="word" start_char="9732">very</TOKEN>
<TOKEN end_char="9743" id="token-77-13" morph="none" pos="word" start_char="9737">special</TOKEN>
<TOKEN end_char="9757" id="token-77-14" morph="none" pos="word" start_char="9745">circumstances</TOKEN>
<TOKEN end_char="9758" id="token-77-15" morph="none" pos="punct" start_char="9758">,</TOKEN>
<TOKEN end_char="9762" id="token-77-16" morph="none" pos="word" start_char="9760">for</TOKEN>
<TOKEN end_char="9769" id="token-77-17" morph="none" pos="word" start_char="9764">people</TOKEN>
<TOKEN end_char="9776" id="token-77-18" morph="none" pos="word" start_char="9771">tested</TOKEN>
<TOKEN end_char="9781" id="token-77-19" morph="none" pos="word" start_char="9778">very</TOKEN>
<TOKEN end_char="9787" id="token-77-20" morph="none" pos="word" start_char="9783">early</TOKEN>
<TOKEN end_char="9788" id="token-77-21" morph="none" pos="punct" start_char="9788">,</TOKEN>
<TOKEN end_char="9793" id="token-77-22" morph="none" pos="word" start_char="9790">when</TOKEN>
<TOKEN end_char="9797" id="token-77-23" morph="none" pos="word" start_char="9795">the</TOKEN>
<TOKEN end_char="9805" id="token-77-24" morph="none" pos="word" start_char="9799">disease</TOKEN>
<TOKEN end_char="9808" id="token-77-25" morph="none" pos="word" start_char="9807">is</TOKEN>
<TOKEN end_char="9812" id="token-77-26" morph="none" pos="word" start_char="9810">not</TOKEN>
<TOKEN end_char="9821" id="token-77-27" morph="none" pos="word" start_char="9814">advanced</TOKEN>
<TOKEN end_char="9825" id="token-77-28" morph="none" pos="word" start_char="9823">yet</TOKEN>
<TOKEN end_char="9826" id="token-77-29" morph="none" pos="punct" start_char="9826">,</TOKEN>
<TOKEN end_char="9830" id="token-77-30" morph="none" pos="word" start_char="9828">and</TOKEN>
<TOKEN end_char="9835" id="token-77-31" morph="none" pos="word" start_char="9832">only</TOKEN>
<TOKEN end_char="9838" id="token-77-32" morph="none" pos="word" start_char="9837">in</TOKEN>
<TOKEN end_char="9844" id="token-77-33" morph="none" pos="word" start_char="9840">these</TOKEN>
<TOKEN end_char="9850" id="token-77-34" morph="none" pos="word" start_char="9846">cases</TOKEN>
<TOKEN end_char="9851" id="token-77-35" morph="none" pos="punct" start_char="9851">.</TOKEN>
</SEG>
<SEG end_char="9897" id="segment-78" start_char="9853">
<ORIGINAL_TEXT>He’s not advocating chloroquine for everyone.</ORIGINAL_TEXT>
<TOKEN end_char="9856" id="token-78-0" morph="none" pos="word" start_char="9853">He’s</TOKEN>
<TOKEN end_char="9860" id="token-78-1" morph="none" pos="word" start_char="9858">not</TOKEN>
<TOKEN end_char="9871" id="token-78-2" morph="none" pos="word" start_char="9862">advocating</TOKEN>
<TOKEN end_char="9883" id="token-78-3" morph="none" pos="word" start_char="9873">chloroquine</TOKEN>
<TOKEN end_char="9887" id="token-78-4" morph="none" pos="word" start_char="9885">for</TOKEN>
<TOKEN end_char="9896" id="token-78-5" morph="none" pos="word" start_char="9889">everyone</TOKEN>
<TOKEN end_char="9897" id="token-78-6" morph="none" pos="punct" start_char="9897">.</TOKEN>
</SEG>
<SEG end_char="9968" id="segment-79" start_char="9899">
<ORIGINAL_TEXT>It’s exactly what the Chinese did, along with their use of Interferon.</ORIGINAL_TEXT>
<TOKEN end_char="9902" id="token-79-0" morph="none" pos="word" start_char="9899">It’s</TOKEN>
<TOKEN end_char="9910" id="token-79-1" morph="none" pos="word" start_char="9904">exactly</TOKEN>
<TOKEN end_char="9915" id="token-79-2" morph="none" pos="word" start_char="9912">what</TOKEN>
<TOKEN end_char="9919" id="token-79-3" morph="none" pos="word" start_char="9917">the</TOKEN>
<TOKEN end_char="9927" id="token-79-4" morph="none" pos="word" start_char="9921">Chinese</TOKEN>
<TOKEN end_char="9931" id="token-79-5" morph="none" pos="word" start_char="9929">did</TOKEN>
<TOKEN end_char="9932" id="token-79-6" morph="none" pos="punct" start_char="9932">,</TOKEN>
<TOKEN end_char="9938" id="token-79-7" morph="none" pos="word" start_char="9934">along</TOKEN>
<TOKEN end_char="9943" id="token-79-8" morph="none" pos="word" start_char="9940">with</TOKEN>
<TOKEN end_char="9949" id="token-79-9" morph="none" pos="word" start_char="9945">their</TOKEN>
<TOKEN end_char="9953" id="token-79-10" morph="none" pos="word" start_char="9951">use</TOKEN>
<TOKEN end_char="9956" id="token-79-11" morph="none" pos="word" start_char="9955">of</TOKEN>
<TOKEN end_char="9967" id="token-79-12" morph="none" pos="word" start_char="9958">Interferon</TOKEN>
<TOKEN end_char="9968" id="token-79-13" morph="none" pos="punct" start_char="9968">.</TOKEN>
</SEG>
<SEG end_char="10192" id="segment-80" start_char="9971">
<ORIGINAL_TEXT>For years, Raoult has been pleading for a drastic revision of health economic models, so the treatments, cure and therapies created mostly during the 20th century, are considered a patrimony in the service of all humanity.</ORIGINAL_TEXT>
<TOKEN end_char="9973" id="token-80-0" morph="none" pos="word" start_char="9971">For</TOKEN>
<TOKEN end_char="9979" id="token-80-1" morph="none" pos="word" start_char="9975">years</TOKEN>
<TOKEN end_char="9980" id="token-80-2" morph="none" pos="punct" start_char="9980">,</TOKEN>
<TOKEN end_char="9987" id="token-80-3" morph="none" pos="word" start_char="9982">Raoult</TOKEN>
<TOKEN end_char="9991" id="token-80-4" morph="none" pos="word" start_char="9989">has</TOKEN>
<TOKEN end_char="9996" id="token-80-5" morph="none" pos="word" start_char="9993">been</TOKEN>
<TOKEN end_char="10005" id="token-80-6" morph="none" pos="word" start_char="9998">pleading</TOKEN>
<TOKEN end_char="10009" id="token-80-7" morph="none" pos="word" start_char="10007">for</TOKEN>
<TOKEN end_char="10011" id="token-80-8" morph="none" pos="word" start_char="10011">a</TOKEN>
<TOKEN end_char="10019" id="token-80-9" morph="none" pos="word" start_char="10013">drastic</TOKEN>
<TOKEN end_char="10028" id="token-80-10" morph="none" pos="word" start_char="10021">revision</TOKEN>
<TOKEN end_char="10031" id="token-80-11" morph="none" pos="word" start_char="10030">of</TOKEN>
<TOKEN end_char="10038" id="token-80-12" morph="none" pos="word" start_char="10033">health</TOKEN>
<TOKEN end_char="10047" id="token-80-13" morph="none" pos="word" start_char="10040">economic</TOKEN>
<TOKEN end_char="10054" id="token-80-14" morph="none" pos="word" start_char="10049">models</TOKEN>
<TOKEN end_char="10055" id="token-80-15" morph="none" pos="punct" start_char="10055">,</TOKEN>
<TOKEN end_char="10058" id="token-80-16" morph="none" pos="word" start_char="10057">so</TOKEN>
<TOKEN end_char="10062" id="token-80-17" morph="none" pos="word" start_char="10060">the</TOKEN>
<TOKEN end_char="10073" id="token-80-18" morph="none" pos="word" start_char="10064">treatments</TOKEN>
<TOKEN end_char="10074" id="token-80-19" morph="none" pos="punct" start_char="10074">,</TOKEN>
<TOKEN end_char="10079" id="token-80-20" morph="none" pos="word" start_char="10076">cure</TOKEN>
<TOKEN end_char="10083" id="token-80-21" morph="none" pos="word" start_char="10081">and</TOKEN>
<TOKEN end_char="10093" id="token-80-22" morph="none" pos="word" start_char="10085">therapies</TOKEN>
<TOKEN end_char="10101" id="token-80-23" morph="none" pos="word" start_char="10095">created</TOKEN>
<TOKEN end_char="10108" id="token-80-24" morph="none" pos="word" start_char="10103">mostly</TOKEN>
<TOKEN end_char="10115" id="token-80-25" morph="none" pos="word" start_char="10110">during</TOKEN>
<TOKEN end_char="10119" id="token-80-26" morph="none" pos="word" start_char="10117">the</TOKEN>
<TOKEN end_char="10124" id="token-80-27" morph="none" pos="word" start_char="10121">20th</TOKEN>
<TOKEN end_char="10132" id="token-80-28" morph="none" pos="word" start_char="10126">century</TOKEN>
<TOKEN end_char="10133" id="token-80-29" morph="none" pos="punct" start_char="10133">,</TOKEN>
<TOKEN end_char="10137" id="token-80-30" morph="none" pos="word" start_char="10135">are</TOKEN>
<TOKEN end_char="10148" id="token-80-31" morph="none" pos="word" start_char="10139">considered</TOKEN>
<TOKEN end_char="10150" id="token-80-32" morph="none" pos="word" start_char="10150">a</TOKEN>
<TOKEN end_char="10160" id="token-80-33" morph="none" pos="word" start_char="10152">patrimony</TOKEN>
<TOKEN end_char="10163" id="token-80-34" morph="none" pos="word" start_char="10162">in</TOKEN>
<TOKEN end_char="10167" id="token-80-35" morph="none" pos="word" start_char="10165">the</TOKEN>
<TOKEN end_char="10175" id="token-80-36" morph="none" pos="word" start_char="10169">service</TOKEN>
<TOKEN end_char="10178" id="token-80-37" morph="none" pos="word" start_char="10177">of</TOKEN>
<TOKEN end_char="10182" id="token-80-38" morph="none" pos="word" start_char="10180">all</TOKEN>
<TOKEN end_char="10191" id="token-80-39" morph="none" pos="word" start_char="10184">humanity</TOKEN>
<TOKEN end_char="10192" id="token-80-40" morph="none" pos="punct" start_char="10192">.</TOKEN>
</SEG>
<SEG end_char="10301" id="segment-81" start_char="10194">
<ORIGINAL_TEXT>"That’s not the case", he says, "because we abandon medicine that is not profitable, even if it’s effective.</ORIGINAL_TEXT>
<TOKEN end_char="10194" id="token-81-0" morph="none" pos="punct" start_char="10194">"</TOKEN>
<TOKEN end_char="10200" id="token-81-1" morph="none" pos="word" start_char="10195">That’s</TOKEN>
<TOKEN end_char="10204" id="token-81-2" morph="none" pos="word" start_char="10202">not</TOKEN>
<TOKEN end_char="10208" id="token-81-3" morph="none" pos="word" start_char="10206">the</TOKEN>
<TOKEN end_char="10213" id="token-81-4" morph="none" pos="word" start_char="10210">case</TOKEN>
<TOKEN end_char="10215" id="token-81-5" morph="none" pos="punct" start_char="10214">",</TOKEN>
<TOKEN end_char="10218" id="token-81-6" morph="none" pos="word" start_char="10217">he</TOKEN>
<TOKEN end_char="10223" id="token-81-7" morph="none" pos="word" start_char="10220">says</TOKEN>
<TOKEN end_char="10224" id="token-81-8" morph="none" pos="punct" start_char="10224">,</TOKEN>
<TOKEN end_char="10226" id="token-81-9" morph="none" pos="punct" start_char="10226">"</TOKEN>
<TOKEN end_char="10233" id="token-81-10" morph="none" pos="word" start_char="10227">because</TOKEN>
<TOKEN end_char="10236" id="token-81-11" morph="none" pos="word" start_char="10235">we</TOKEN>
<TOKEN end_char="10244" id="token-81-12" morph="none" pos="word" start_char="10238">abandon</TOKEN>
<TOKEN end_char="10253" id="token-81-13" morph="none" pos="word" start_char="10246">medicine</TOKEN>
<TOKEN end_char="10258" id="token-81-14" morph="none" pos="word" start_char="10255">that</TOKEN>
<TOKEN end_char="10261" id="token-81-15" morph="none" pos="word" start_char="10260">is</TOKEN>
<TOKEN end_char="10265" id="token-81-16" morph="none" pos="word" start_char="10263">not</TOKEN>
<TOKEN end_char="10276" id="token-81-17" morph="none" pos="word" start_char="10267">profitable</TOKEN>
<TOKEN end_char="10277" id="token-81-18" morph="none" pos="punct" start_char="10277">,</TOKEN>
<TOKEN end_char="10282" id="token-81-19" morph="none" pos="word" start_char="10279">even</TOKEN>
<TOKEN end_char="10285" id="token-81-20" morph="none" pos="word" start_char="10284">if</TOKEN>
<TOKEN end_char="10290" id="token-81-21" morph="none" pos="word" start_char="10287">it’s</TOKEN>
<TOKEN end_char="10300" id="token-81-22" morph="none" pos="word" start_char="10292">effective</TOKEN>
<TOKEN end_char="10301" id="token-81-23" morph="none" pos="punct" start_char="10301">.</TOKEN>
</SEG>
<SEG end_char="10365" id="segment-82" start_char="10303">
<ORIGINAL_TEXT>That’s why almost no antibiotics are manufactured in the West."</ORIGINAL_TEXT>
<TOKEN end_char="10308" id="token-82-0" morph="none" pos="word" start_char="10303">That’s</TOKEN>
<TOKEN end_char="10312" id="token-82-1" morph="none" pos="word" start_char="10310">why</TOKEN>
<TOKEN end_char="10319" id="token-82-2" morph="none" pos="word" start_char="10314">almost</TOKEN>
<TOKEN end_char="10322" id="token-82-3" morph="none" pos="word" start_char="10321">no</TOKEN>
<TOKEN end_char="10334" id="token-82-4" morph="none" pos="word" start_char="10324">antibiotics</TOKEN>
<TOKEN end_char="10338" id="token-82-5" morph="none" pos="word" start_char="10336">are</TOKEN>
<TOKEN end_char="10351" id="token-82-6" morph="none" pos="word" start_char="10340">manufactured</TOKEN>
<TOKEN end_char="10354" id="token-82-7" morph="none" pos="word" start_char="10353">in</TOKEN>
<TOKEN end_char="10358" id="token-82-8" morph="none" pos="word" start_char="10356">the</TOKEN>
<TOKEN end_char="10363" id="token-82-9" morph="none" pos="word" start_char="10360">West</TOKEN>
<TOKEN end_char="10365" id="token-82-10" morph="none" pos="punct" start_char="10364">."</TOKEN>
</SEG>
<SEG end_char="10500" id="segment-83" start_char="10368">
<ORIGINAL_TEXT>On Tuesday, the French Health Ministry officially prohibited the utilization of treatment based on chloroquine recommended by Raoult.</ORIGINAL_TEXT>
<TOKEN end_char="10369" id="token-83-0" morph="none" pos="word" start_char="10368">On</TOKEN>
<TOKEN end_char="10377" id="token-83-1" morph="none" pos="word" start_char="10371">Tuesday</TOKEN>
<TOKEN end_char="10378" id="token-83-2" morph="none" pos="punct" start_char="10378">,</TOKEN>
<TOKEN end_char="10382" id="token-83-3" morph="none" pos="word" start_char="10380">the</TOKEN>
<TOKEN end_char="10389" id="token-83-4" morph="none" pos="word" start_char="10384">French</TOKEN>
<TOKEN end_char="10396" id="token-83-5" morph="none" pos="word" start_char="10391">Health</TOKEN>
<TOKEN end_char="10405" id="token-83-6" morph="none" pos="word" start_char="10398">Ministry</TOKEN>
<TOKEN end_char="10416" id="token-83-7" morph="none" pos="word" start_char="10407">officially</TOKEN>
<TOKEN end_char="10427" id="token-83-8" morph="none" pos="word" start_char="10418">prohibited</TOKEN>
<TOKEN end_char="10431" id="token-83-9" morph="none" pos="word" start_char="10429">the</TOKEN>
<TOKEN end_char="10443" id="token-83-10" morph="none" pos="word" start_char="10433">utilization</TOKEN>
<TOKEN end_char="10446" id="token-83-11" morph="none" pos="word" start_char="10445">of</TOKEN>
<TOKEN end_char="10456" id="token-83-12" morph="none" pos="word" start_char="10448">treatment</TOKEN>
<TOKEN end_char="10462" id="token-83-13" morph="none" pos="word" start_char="10458">based</TOKEN>
<TOKEN end_char="10465" id="token-83-14" morph="none" pos="word" start_char="10464">on</TOKEN>
<TOKEN end_char="10477" id="token-83-15" morph="none" pos="word" start_char="10467">chloroquine</TOKEN>
<TOKEN end_char="10489" id="token-83-16" morph="none" pos="word" start_char="10479">recommended</TOKEN>
<TOKEN end_char="10492" id="token-83-17" morph="none" pos="word" start_char="10491">by</TOKEN>
<TOKEN end_char="10499" id="token-83-18" morph="none" pos="word" start_char="10494">Raoult</TOKEN>
<TOKEN end_char="10500" id="token-83-19" morph="none" pos="punct" start_char="10500">.</TOKEN>
</SEG>
<SEG end_char="10608" id="segment-84" start_char="10502">
<ORIGINAL_TEXT>In fact the treatment is only allowed for terminal Covid-19 patients, with no other possibility of healing.</ORIGINAL_TEXT>
<TOKEN end_char="10503" id="token-84-0" morph="none" pos="word" start_char="10502">In</TOKEN>
<TOKEN end_char="10508" id="token-84-1" morph="none" pos="word" start_char="10505">fact</TOKEN>
<TOKEN end_char="10512" id="token-84-2" morph="none" pos="word" start_char="10510">the</TOKEN>
<TOKEN end_char="10522" id="token-84-3" morph="none" pos="word" start_char="10514">treatment</TOKEN>
<TOKEN end_char="10525" id="token-84-4" morph="none" pos="word" start_char="10524">is</TOKEN>
<TOKEN end_char="10530" id="token-84-5" morph="none" pos="word" start_char="10527">only</TOKEN>
<TOKEN end_char="10538" id="token-84-6" morph="none" pos="word" start_char="10532">allowed</TOKEN>
<TOKEN end_char="10542" id="token-84-7" morph="none" pos="word" start_char="10540">for</TOKEN>
<TOKEN end_char="10551" id="token-84-8" morph="none" pos="word" start_char="10544">terminal</TOKEN>
<TOKEN end_char="10560" id="token-84-9" morph="none" pos="unknown" start_char="10553">Covid-19</TOKEN>
<TOKEN end_char="10569" id="token-84-10" morph="none" pos="word" start_char="10562">patients</TOKEN>
<TOKEN end_char="10570" id="token-84-11" morph="none" pos="punct" start_char="10570">,</TOKEN>
<TOKEN end_char="10575" id="token-84-12" morph="none" pos="word" start_char="10572">with</TOKEN>
<TOKEN end_char="10578" id="token-84-13" morph="none" pos="word" start_char="10577">no</TOKEN>
<TOKEN end_char="10584" id="token-84-14" morph="none" pos="word" start_char="10580">other</TOKEN>
<TOKEN end_char="10596" id="token-84-15" morph="none" pos="word" start_char="10586">possibility</TOKEN>
<TOKEN end_char="10599" id="token-84-16" morph="none" pos="word" start_char="10598">of</TOKEN>
<TOKEN end_char="10607" id="token-84-17" morph="none" pos="word" start_char="10601">healing</TOKEN>
<TOKEN end_char="10608" id="token-84-18" morph="none" pos="punct" start_char="10608">.</TOKEN>
</SEG>
<SEG end_char="10771" id="segment-85" start_char="10610">
<ORIGINAL_TEXT>This cannot but expose the Macron government to more accusations of at least inefficiency – added to the absence of masks, tests, contact tracing and ventilators.</ORIGINAL_TEXT>
<TOKEN end_char="10613" id="token-85-0" morph="none" pos="word" start_char="10610">This</TOKEN>
<TOKEN end_char="10620" id="token-85-1" morph="none" pos="word" start_char="10615">cannot</TOKEN>
<TOKEN end_char="10624" id="token-85-2" morph="none" pos="word" start_char="10622">but</TOKEN>
<TOKEN end_char="10631" id="token-85-3" morph="none" pos="word" start_char="10626">expose</TOKEN>
<TOKEN end_char="10635" id="token-85-4" morph="none" pos="word" start_char="10633">the</TOKEN>
<TOKEN end_char="10642" id="token-85-5" morph="none" pos="word" start_char="10637">Macron</TOKEN>
<TOKEN end_char="10653" id="token-85-6" morph="none" pos="word" start_char="10644">government</TOKEN>
<TOKEN end_char="10656" id="token-85-7" morph="none" pos="word" start_char="10655">to</TOKEN>
<TOKEN end_char="10661" id="token-85-8" morph="none" pos="word" start_char="10658">more</TOKEN>
<TOKEN end_char="10673" id="token-85-9" morph="none" pos="word" start_char="10663">accusations</TOKEN>
<TOKEN end_char="10676" id="token-85-10" morph="none" pos="word" start_char="10675">of</TOKEN>
<TOKEN end_char="10679" id="token-85-11" morph="none" pos="word" start_char="10678">at</TOKEN>
<TOKEN end_char="10685" id="token-85-12" morph="none" pos="word" start_char="10681">least</TOKEN>
<TOKEN end_char="10698" id="token-85-13" morph="none" pos="word" start_char="10687">inefficiency</TOKEN>
<TOKEN end_char="10700" id="token-85-14" morph="none" pos="punct" start_char="10700">–</TOKEN>
<TOKEN end_char="10706" id="token-85-15" morph="none" pos="word" start_char="10702">added</TOKEN>
<TOKEN end_char="10709" id="token-85-16" morph="none" pos="word" start_char="10708">to</TOKEN>
<TOKEN end_char="10713" id="token-85-17" morph="none" pos="word" start_char="10711">the</TOKEN>
<TOKEN end_char="10721" id="token-85-18" morph="none" pos="word" start_char="10715">absence</TOKEN>
<TOKEN end_char="10724" id="token-85-19" morph="none" pos="word" start_char="10723">of</TOKEN>
<TOKEN end_char="10730" id="token-85-20" morph="none" pos="word" start_char="10726">masks</TOKEN>
<TOKEN end_char="10731" id="token-85-21" morph="none" pos="punct" start_char="10731">,</TOKEN>
<TOKEN end_char="10737" id="token-85-22" morph="none" pos="word" start_char="10733">tests</TOKEN>
<TOKEN end_char="10738" id="token-85-23" morph="none" pos="punct" start_char="10738">,</TOKEN>
<TOKEN end_char="10746" id="token-85-24" morph="none" pos="word" start_char="10740">contact</TOKEN>
<TOKEN end_char="10754" id="token-85-25" morph="none" pos="word" start_char="10748">tracing</TOKEN>
<TOKEN end_char="10758" id="token-85-26" morph="none" pos="word" start_char="10756">and</TOKEN>
<TOKEN end_char="10770" id="token-85-27" morph="none" pos="word" start_char="10760">ventilators</TOKEN>
<TOKEN end_char="10771" id="token-85-28" morph="none" pos="punct" start_char="10771">.</TOKEN>
</SEG>
<SEG end_char="10990" id="segment-86" start_char="10774">
<ORIGINAL_TEXT>On Wednesday, commenting on the new government guidelines, Raoult said, "When damage to the lungs is too important, and patients arrive for reanimation, they practically do not harbor viruses in their bodies any more.</ORIGINAL_TEXT>
<TOKEN end_char="10775" id="token-86-0" morph="none" pos="word" start_char="10774">On</TOKEN>
<TOKEN end_char="10785" id="token-86-1" morph="none" pos="word" start_char="10777">Wednesday</TOKEN>
<TOKEN end_char="10786" id="token-86-2" morph="none" pos="punct" start_char="10786">,</TOKEN>
<TOKEN end_char="10797" id="token-86-3" morph="none" pos="word" start_char="10788">commenting</TOKEN>
<TOKEN end_char="10800" id="token-86-4" morph="none" pos="word" start_char="10799">on</TOKEN>
<TOKEN end_char="10804" id="token-86-5" morph="none" pos="word" start_char="10802">the</TOKEN>
<TOKEN end_char="10808" id="token-86-6" morph="none" pos="word" start_char="10806">new</TOKEN>
<TOKEN end_char="10819" id="token-86-7" morph="none" pos="word" start_char="10810">government</TOKEN>
<TOKEN end_char="10830" id="token-86-8" morph="none" pos="word" start_char="10821">guidelines</TOKEN>
<TOKEN end_char="10831" id="token-86-9" morph="none" pos="punct" start_char="10831">,</TOKEN>
<TOKEN end_char="10838" id="token-86-10" morph="none" pos="word" start_char="10833">Raoult</TOKEN>
<TOKEN end_char="10843" id="token-86-11" morph="none" pos="word" start_char="10840">said</TOKEN>
<TOKEN end_char="10844" id="token-86-12" morph="none" pos="punct" start_char="10844">,</TOKEN>
<TOKEN end_char="10846" id="token-86-13" morph="none" pos="punct" start_char="10846">"</TOKEN>
<TOKEN end_char="10850" id="token-86-14" morph="none" pos="word" start_char="10847">When</TOKEN>
<TOKEN end_char="10857" id="token-86-15" morph="none" pos="word" start_char="10852">damage</TOKEN>
<TOKEN end_char="10860" id="token-86-16" morph="none" pos="word" start_char="10859">to</TOKEN>
<TOKEN end_char="10864" id="token-86-17" morph="none" pos="word" start_char="10862">the</TOKEN>
<TOKEN end_char="10870" id="token-86-18" morph="none" pos="word" start_char="10866">lungs</TOKEN>
<TOKEN end_char="10873" id="token-86-19" morph="none" pos="word" start_char="10872">is</TOKEN>
<TOKEN end_char="10877" id="token-86-20" morph="none" pos="word" start_char="10875">too</TOKEN>
<TOKEN end_char="10887" id="token-86-21" morph="none" pos="word" start_char="10879">important</TOKEN>
<TOKEN end_char="10888" id="token-86-22" morph="none" pos="punct" start_char="10888">,</TOKEN>
<TOKEN end_char="10892" id="token-86-23" morph="none" pos="word" start_char="10890">and</TOKEN>
<TOKEN end_char="10901" id="token-86-24" morph="none" pos="word" start_char="10894">patients</TOKEN>
<TOKEN end_char="10908" id="token-86-25" morph="none" pos="word" start_char="10903">arrive</TOKEN>
<TOKEN end_char="10912" id="token-86-26" morph="none" pos="word" start_char="10910">for</TOKEN>
<TOKEN end_char="10924" id="token-86-27" morph="none" pos="word" start_char="10914">reanimation</TOKEN>
<TOKEN end_char="10925" id="token-86-28" morph="none" pos="punct" start_char="10925">,</TOKEN>
<TOKEN end_char="10930" id="token-86-29" morph="none" pos="word" start_char="10927">they</TOKEN>
<TOKEN end_char="10942" id="token-86-30" morph="none" pos="word" start_char="10932">practically</TOKEN>
<TOKEN end_char="10945" id="token-86-31" morph="none" pos="word" start_char="10944">do</TOKEN>
<TOKEN end_char="10949" id="token-86-32" morph="none" pos="word" start_char="10947">not</TOKEN>
<TOKEN end_char="10956" id="token-86-33" morph="none" pos="word" start_char="10951">harbor</TOKEN>
<TOKEN end_char="10964" id="token-86-34" morph="none" pos="word" start_char="10958">viruses</TOKEN>
<TOKEN end_char="10967" id="token-86-35" morph="none" pos="word" start_char="10966">in</TOKEN>
<TOKEN end_char="10973" id="token-86-36" morph="none" pos="word" start_char="10969">their</TOKEN>
<TOKEN end_char="10980" id="token-86-37" morph="none" pos="word" start_char="10975">bodies</TOKEN>
<TOKEN end_char="10984" id="token-86-38" morph="none" pos="word" start_char="10982">any</TOKEN>
<TOKEN end_char="10989" id="token-86-39" morph="none" pos="word" start_char="10986">more</TOKEN>
<TOKEN end_char="10990" id="token-86-40" morph="none" pos="punct" start_char="10990">.</TOKEN>
</SEG>
<SEG end_char="11036" id="segment-87" start_char="10992">
<ORIGINAL_TEXT>It’s too late to treat them with chloroquine.</ORIGINAL_TEXT>
<TOKEN end_char="10995" id="token-87-0" morph="none" pos="word" start_char="10992">It’s</TOKEN>
<TOKEN end_char="10999" id="token-87-1" morph="none" pos="word" start_char="10997">too</TOKEN>
<TOKEN end_char="11004" id="token-87-2" morph="none" pos="word" start_char="11001">late</TOKEN>
<TOKEN end_char="11007" id="token-87-3" morph="none" pos="word" start_char="11006">to</TOKEN>
<TOKEN end_char="11013" id="token-87-4" morph="none" pos="word" start_char="11009">treat</TOKEN>
<TOKEN end_char="11018" id="token-87-5" morph="none" pos="word" start_char="11015">them</TOKEN>
<TOKEN end_char="11023" id="token-87-6" morph="none" pos="word" start_char="11020">with</TOKEN>
<TOKEN end_char="11035" id="token-87-7" morph="none" pos="word" start_char="11025">chloroquine</TOKEN>
<TOKEN end_char="11036" id="token-87-8" morph="none" pos="punct" start_char="11036">.</TOKEN>
</SEG>
<SEG end_char="11186" id="segment-88" start_char="11038">
<ORIGINAL_TEXT>Are these the only cases – the very serious cases – that will be treated with chloroquine under the new directive by [French Health Minister] Veran?"</ORIGINAL_TEXT>
<TOKEN end_char="11040" id="token-88-0" morph="none" pos="word" start_char="11038">Are</TOKEN>
<TOKEN end_char="11046" id="token-88-1" morph="none" pos="word" start_char="11042">these</TOKEN>
<TOKEN end_char="11050" id="token-88-2" morph="none" pos="word" start_char="11048">the</TOKEN>
<TOKEN end_char="11055" id="token-88-3" morph="none" pos="word" start_char="11052">only</TOKEN>
<TOKEN end_char="11061" id="token-88-4" morph="none" pos="word" start_char="11057">cases</TOKEN>
<TOKEN end_char="11063" id="token-88-5" morph="none" pos="punct" start_char="11063">–</TOKEN>
<TOKEN end_char="11067" id="token-88-6" morph="none" pos="word" start_char="11065">the</TOKEN>
<TOKEN end_char="11072" id="token-88-7" morph="none" pos="word" start_char="11069">very</TOKEN>
<TOKEN end_char="11080" id="token-88-8" morph="none" pos="word" start_char="11074">serious</TOKEN>
<TOKEN end_char="11086" id="token-88-9" morph="none" pos="word" start_char="11082">cases</TOKEN>
<TOKEN end_char="11088" id="token-88-10" morph="none" pos="punct" start_char="11088">–</TOKEN>
<TOKEN end_char="11093" id="token-88-11" morph="none" pos="word" start_char="11090">that</TOKEN>
<TOKEN end_char="11098" id="token-88-12" morph="none" pos="word" start_char="11095">will</TOKEN>
<TOKEN end_char="11101" id="token-88-13" morph="none" pos="word" start_char="11100">be</TOKEN>
<TOKEN end_char="11109" id="token-88-14" morph="none" pos="word" start_char="11103">treated</TOKEN>
<TOKEN end_char="11114" id="token-88-15" morph="none" pos="word" start_char="11111">with</TOKEN>
<TOKEN end_char="11126" id="token-88-16" morph="none" pos="word" start_char="11116">chloroquine</TOKEN>
<TOKEN end_char="11132" id="token-88-17" morph="none" pos="word" start_char="11128">under</TOKEN>
<TOKEN end_char="11136" id="token-88-18" morph="none" pos="word" start_char="11134">the</TOKEN>
<TOKEN end_char="11140" id="token-88-19" morph="none" pos="word" start_char="11138">new</TOKEN>
<TOKEN end_char="11150" id="token-88-20" morph="none" pos="word" start_char="11142">directive</TOKEN>
<TOKEN end_char="11153" id="token-88-21" morph="none" pos="word" start_char="11152">by</TOKEN>
<TOKEN end_char="11155" id="token-88-22" morph="none" pos="punct" start_char="11155">[</TOKEN>
<TOKEN end_char="11161" id="token-88-23" morph="none" pos="word" start_char="11156">French</TOKEN>
<TOKEN end_char="11168" id="token-88-24" morph="none" pos="word" start_char="11163">Health</TOKEN>
<TOKEN end_char="11177" id="token-88-25" morph="none" pos="word" start_char="11170">Minister</TOKEN>
<TOKEN end_char="11178" id="token-88-26" morph="none" pos="punct" start_char="11178">]</TOKEN>
<TOKEN end_char="11184" id="token-88-27" morph="none" pos="word" start_char="11180">Veran</TOKEN>
<TOKEN end_char="11186" id="token-88-28" morph="none" pos="punct" start_char="11185">?"</TOKEN>
</SEG>
<SEG end_char="11304" id="segment-89" start_char="11188">
<ORIGINAL_TEXT>If so, he added ironically, "then they will be able to say with scientific certainty that chloroquine does not work."</ORIGINAL_TEXT>
<TOKEN end_char="11189" id="token-89-0" morph="none" pos="word" start_char="11188">If</TOKEN>
<TOKEN end_char="11192" id="token-89-1" morph="none" pos="word" start_char="11191">so</TOKEN>
<TOKEN end_char="11193" id="token-89-2" morph="none" pos="punct" start_char="11193">,</TOKEN>
<TOKEN end_char="11196" id="token-89-3" morph="none" pos="word" start_char="11195">he</TOKEN>
<TOKEN end_char="11202" id="token-89-4" morph="none" pos="word" start_char="11198">added</TOKEN>
<TOKEN end_char="11213" id="token-89-5" morph="none" pos="word" start_char="11204">ironically</TOKEN>
<TOKEN end_char="11214" id="token-89-6" morph="none" pos="punct" start_char="11214">,</TOKEN>
<TOKEN end_char="11216" id="token-89-7" morph="none" pos="punct" start_char="11216">"</TOKEN>
<TOKEN end_char="11220" id="token-89-8" morph="none" pos="word" start_char="11217">then</TOKEN>
<TOKEN end_char="11225" id="token-89-9" morph="none" pos="word" start_char="11222">they</TOKEN>
<TOKEN end_char="11230" id="token-89-10" morph="none" pos="word" start_char="11227">will</TOKEN>
<TOKEN end_char="11233" id="token-89-11" morph="none" pos="word" start_char="11232">be</TOKEN>
<TOKEN end_char="11238" id="token-89-12" morph="none" pos="word" start_char="11235">able</TOKEN>
<TOKEN end_char="11241" id="token-89-13" morph="none" pos="word" start_char="11240">to</TOKEN>
<TOKEN end_char="11245" id="token-89-14" morph="none" pos="word" start_char="11243">say</TOKEN>
<TOKEN end_char="11250" id="token-89-15" morph="none" pos="word" start_char="11247">with</TOKEN>
<TOKEN end_char="11261" id="token-89-16" morph="none" pos="word" start_char="11252">scientific</TOKEN>
<TOKEN end_char="11271" id="token-89-17" morph="none" pos="word" start_char="11263">certainty</TOKEN>
<TOKEN end_char="11276" id="token-89-18" morph="none" pos="word" start_char="11273">that</TOKEN>
<TOKEN end_char="11288" id="token-89-19" morph="none" pos="word" start_char="11278">chloroquine</TOKEN>
<TOKEN end_char="11293" id="token-89-20" morph="none" pos="word" start_char="11290">does</TOKEN>
<TOKEN end_char="11297" id="token-89-21" morph="none" pos="word" start_char="11295">not</TOKEN>
<TOKEN end_char="11302" id="token-89-22" morph="none" pos="word" start_char="11299">work</TOKEN>
<TOKEN end_char="11304" id="token-89-23" morph="none" pos="punct" start_char="11303">."</TOKEN>
</SEG>
<SEG end_char="11504" id="segment-90" start_char="11307">
<ORIGINAL_TEXT>Raoult was unavailable for comment on Western news media articles citing Chinese test results that would suggest he is wrong about the efficacy of chloroquine in dealing with mild cases of Covid-19.</ORIGINAL_TEXT>
<TOKEN end_char="11312" id="token-90-0" morph="none" pos="word" start_char="11307">Raoult</TOKEN>
<TOKEN end_char="11316" id="token-90-1" morph="none" pos="word" start_char="11314">was</TOKEN>
<TOKEN end_char="11328" id="token-90-2" morph="none" pos="word" start_char="11318">unavailable</TOKEN>
<TOKEN end_char="11332" id="token-90-3" morph="none" pos="word" start_char="11330">for</TOKEN>
<TOKEN end_char="11340" id="token-90-4" morph="none" pos="word" start_char="11334">comment</TOKEN>
<TOKEN end_char="11343" id="token-90-5" morph="none" pos="word" start_char="11342">on</TOKEN>
<TOKEN end_char="11351" id="token-90-6" morph="none" pos="word" start_char="11345">Western</TOKEN>
<TOKEN end_char="11356" id="token-90-7" morph="none" pos="word" start_char="11353">news</TOKEN>
<TOKEN end_char="11362" id="token-90-8" morph="none" pos="word" start_char="11358">media</TOKEN>
<TOKEN end_char="11371" id="token-90-9" morph="none" pos="word" start_char="11364">articles</TOKEN>
<TOKEN end_char="11378" id="token-90-10" morph="none" pos="word" start_char="11373">citing</TOKEN>
<TOKEN end_char="11386" id="token-90-11" morph="none" pos="word" start_char="11380">Chinese</TOKEN>
<TOKEN end_char="11391" id="token-90-12" morph="none" pos="word" start_char="11388">test</TOKEN>
<TOKEN end_char="11399" id="token-90-13" morph="none" pos="word" start_char="11393">results</TOKEN>
<TOKEN end_char="11404" id="token-90-14" morph="none" pos="word" start_char="11401">that</TOKEN>
<TOKEN end_char="11410" id="token-90-15" morph="none" pos="word" start_char="11406">would</TOKEN>
<TOKEN end_char="11418" id="token-90-16" morph="none" pos="word" start_char="11412">suggest</TOKEN>
<TOKEN end_char="11421" id="token-90-17" morph="none" pos="word" start_char="11420">he</TOKEN>
<TOKEN end_char="11424" id="token-90-18" morph="none" pos="word" start_char="11423">is</TOKEN>
<TOKEN end_char="11430" id="token-90-19" morph="none" pos="word" start_char="11426">wrong</TOKEN>
<TOKEN end_char="11436" id="token-90-20" morph="none" pos="word" start_char="11432">about</TOKEN>
<TOKEN end_char="11440" id="token-90-21" morph="none" pos="word" start_char="11438">the</TOKEN>
<TOKEN end_char="11449" id="token-90-22" morph="none" pos="word" start_char="11442">efficacy</TOKEN>
<TOKEN end_char="11452" id="token-90-23" morph="none" pos="word" start_char="11451">of</TOKEN>
<TOKEN end_char="11464" id="token-90-24" morph="none" pos="word" start_char="11454">chloroquine</TOKEN>
<TOKEN end_char="11467" id="token-90-25" morph="none" pos="word" start_char="11466">in</TOKEN>
<TOKEN end_char="11475" id="token-90-26" morph="none" pos="word" start_char="11469">dealing</TOKEN>
<TOKEN end_char="11480" id="token-90-27" morph="none" pos="word" start_char="11477">with</TOKEN>
<TOKEN end_char="11485" id="token-90-28" morph="none" pos="word" start_char="11482">mild</TOKEN>
<TOKEN end_char="11491" id="token-90-29" morph="none" pos="word" start_char="11487">cases</TOKEN>
<TOKEN end_char="11494" id="token-90-30" morph="none" pos="word" start_char="11493">of</TOKEN>
<TOKEN end_char="11503" id="token-90-31" morph="none" pos="unknown" start_char="11496">Covid-19</TOKEN>
<TOKEN end_char="11504" id="token-90-32" morph="none" pos="punct" start_char="11504">.</TOKEN>
</SEG>
<SEG end_char="11567" id="segment-91" start_char="11507">
<ORIGINAL_TEXT>Staffers pointed instead to his comments in the IHU bulletin.</ORIGINAL_TEXT>
<TOKEN end_char="11514" id="token-91-0" morph="none" pos="word" start_char="11507">Staffers</TOKEN>
<TOKEN end_char="11522" id="token-91-1" morph="none" pos="word" start_char="11516">pointed</TOKEN>
<TOKEN end_char="11530" id="token-91-2" morph="none" pos="word" start_char="11524">instead</TOKEN>
<TOKEN end_char="11533" id="token-91-3" morph="none" pos="word" start_char="11532">to</TOKEN>
<TOKEN end_char="11537" id="token-91-4" morph="none" pos="word" start_char="11535">his</TOKEN>
<TOKEN end_char="11546" id="token-91-5" morph="none" pos="word" start_char="11539">comments</TOKEN>
<TOKEN end_char="11549" id="token-91-6" morph="none" pos="word" start_char="11548">in</TOKEN>
<TOKEN end_char="11553" id="token-91-7" morph="none" pos="word" start_char="11551">the</TOKEN>
<TOKEN end_char="11557" id="token-91-8" morph="none" pos="word" start_char="11555">IHU</TOKEN>
<TOKEN end_char="11566" id="token-91-9" morph="none" pos="word" start_char="11559">bulletin</TOKEN>
<TOKEN end_char="11567" id="token-91-10" morph="none" pos="punct" start_char="11567">.</TOKEN>
</SEG>
<SEG end_char="11664" id="segment-92" start_char="11569">
<ORIGINAL_TEXT>There Raoult says it’s "insulting" to ask if we can trust the Chinese on the use of chloroquine.</ORIGINAL_TEXT>
<TOKEN end_char="11573" id="token-92-0" morph="none" pos="word" start_char="11569">There</TOKEN>
<TOKEN end_char="11580" id="token-92-1" morph="none" pos="word" start_char="11575">Raoult</TOKEN>
<TOKEN end_char="11585" id="token-92-2" morph="none" pos="word" start_char="11582">says</TOKEN>
<TOKEN end_char="11590" id="token-92-3" morph="none" pos="word" start_char="11587">it’s</TOKEN>
<TOKEN end_char="11592" id="token-92-4" morph="none" pos="punct" start_char="11592">"</TOKEN>
<TOKEN end_char="11601" id="token-92-5" morph="none" pos="word" start_char="11593">insulting</TOKEN>
<TOKEN end_char="11602" id="token-92-6" morph="none" pos="punct" start_char="11602">"</TOKEN>
<TOKEN end_char="11605" id="token-92-7" morph="none" pos="word" start_char="11604">to</TOKEN>
<TOKEN end_char="11609" id="token-92-8" morph="none" pos="word" start_char="11607">ask</TOKEN>
<TOKEN end_char="11612" id="token-92-9" morph="none" pos="word" start_char="11611">if</TOKEN>
<TOKEN end_char="11615" id="token-92-10" morph="none" pos="word" start_char="11614">we</TOKEN>
<TOKEN end_char="11619" id="token-92-11" morph="none" pos="word" start_char="11617">can</TOKEN>
<TOKEN end_char="11625" id="token-92-12" morph="none" pos="word" start_char="11621">trust</TOKEN>
<TOKEN end_char="11629" id="token-92-13" morph="none" pos="word" start_char="11627">the</TOKEN>
<TOKEN end_char="11637" id="token-92-14" morph="none" pos="word" start_char="11631">Chinese</TOKEN>
<TOKEN end_char="11640" id="token-92-15" morph="none" pos="word" start_char="11639">on</TOKEN>
<TOKEN end_char="11644" id="token-92-16" morph="none" pos="word" start_char="11642">the</TOKEN>
<TOKEN end_char="11648" id="token-92-17" morph="none" pos="word" start_char="11646">use</TOKEN>
<TOKEN end_char="11651" id="token-92-18" morph="none" pos="word" start_char="11650">of</TOKEN>
<TOKEN end_char="11663" id="token-92-19" morph="none" pos="word" start_char="11653">chloroquine</TOKEN>
<TOKEN end_char="11664" id="token-92-20" morph="none" pos="punct" start_char="11664">.</TOKEN>
</SEG>
<SEG end_char="11808" id="segment-93" start_char="11666">
<ORIGINAL_TEXT>"If this was an American disease, and the president of the United States said, ‘We need to treat patients with that,’ nobody would discuss it."</ORIGINAL_TEXT>
<TOKEN end_char="11666" id="token-93-0" morph="none" pos="punct" start_char="11666">"</TOKEN>
<TOKEN end_char="11668" id="token-93-1" morph="none" pos="word" start_char="11667">If</TOKEN>
<TOKEN end_char="11673" id="token-93-2" morph="none" pos="word" start_char="11670">this</TOKEN>
<TOKEN end_char="11677" id="token-93-3" morph="none" pos="word" start_char="11675">was</TOKEN>
<TOKEN end_char="11680" id="token-93-4" morph="none" pos="word" start_char="11679">an</TOKEN>
<TOKEN end_char="11689" id="token-93-5" morph="none" pos="word" start_char="11682">American</TOKEN>
<TOKEN end_char="11697" id="token-93-6" morph="none" pos="word" start_char="11691">disease</TOKEN>
<TOKEN end_char="11698" id="token-93-7" morph="none" pos="punct" start_char="11698">,</TOKEN>
<TOKEN end_char="11702" id="token-93-8" morph="none" pos="word" start_char="11700">and</TOKEN>
<TOKEN end_char="11706" id="token-93-9" morph="none" pos="word" start_char="11704">the</TOKEN>
<TOKEN end_char="11716" id="token-93-10" morph="none" pos="word" start_char="11708">president</TOKEN>
<TOKEN end_char="11719" id="token-93-11" morph="none" pos="word" start_char="11718">of</TOKEN>
<TOKEN end_char="11723" id="token-93-12" morph="none" pos="word" start_char="11721">the</TOKEN>
<TOKEN end_char="11730" id="token-93-13" morph="none" pos="word" start_char="11725">United</TOKEN>
<TOKEN end_char="11737" id="token-93-14" morph="none" pos="word" start_char="11732">States</TOKEN>
<TOKEN end_char="11742" id="token-93-15" morph="none" pos="word" start_char="11739">said</TOKEN>
<TOKEN end_char="11743" id="token-93-16" morph="none" pos="punct" start_char="11743">,</TOKEN>
<TOKEN end_char="11745" id="token-93-17" morph="none" pos="punct" start_char="11745">‘</TOKEN>
<TOKEN end_char="11747" id="token-93-18" morph="none" pos="word" start_char="11746">We</TOKEN>
<TOKEN end_char="11752" id="token-93-19" morph="none" pos="word" start_char="11749">need</TOKEN>
<TOKEN end_char="11755" id="token-93-20" morph="none" pos="word" start_char="11754">to</TOKEN>
<TOKEN end_char="11761" id="token-93-21" morph="none" pos="word" start_char="11757">treat</TOKEN>
<TOKEN end_char="11770" id="token-93-22" morph="none" pos="word" start_char="11763">patients</TOKEN>
<TOKEN end_char="11775" id="token-93-23" morph="none" pos="word" start_char="11772">with</TOKEN>
<TOKEN end_char="11780" id="token-93-24" morph="none" pos="word" start_char="11777">that</TOKEN>
<TOKEN end_char="11782" id="token-93-25" morph="none" pos="punct" start_char="11781">,’</TOKEN>
<TOKEN end_char="11789" id="token-93-26" morph="none" pos="word" start_char="11784">nobody</TOKEN>
<TOKEN end_char="11795" id="token-93-27" morph="none" pos="word" start_char="11791">would</TOKEN>
<TOKEN end_char="11803" id="token-93-28" morph="none" pos="word" start_char="11797">discuss</TOKEN>
<TOKEN end_char="11806" id="token-93-29" morph="none" pos="word" start_char="11805">it</TOKEN>
<TOKEN end_char="11808" id="token-93-30" morph="none" pos="punct" start_char="11807">."</TOKEN>
</SEG>
<SEG end_char="11994" id="segment-94" start_char="11811">
<ORIGINAL_TEXT>In China, he adds, there were "enough elements so the Chinese government and all Chinese experts who know coronaviruses took an official position that ‘we must treat with chloroquine.’</ORIGINAL_TEXT>
<TOKEN end_char="11812" id="token-94-0" morph="none" pos="word" start_char="11811">In</TOKEN>
<TOKEN end_char="11818" id="token-94-1" morph="none" pos="word" start_char="11814">China</TOKEN>
<TOKEN end_char="11819" id="token-94-2" morph="none" pos="punct" start_char="11819">,</TOKEN>
<TOKEN end_char="11822" id="token-94-3" morph="none" pos="word" start_char="11821">he</TOKEN>
<TOKEN end_char="11827" id="token-94-4" morph="none" pos="word" start_char="11824">adds</TOKEN>
<TOKEN end_char="11828" id="token-94-5" morph="none" pos="punct" start_char="11828">,</TOKEN>
<TOKEN end_char="11834" id="token-94-6" morph="none" pos="word" start_char="11830">there</TOKEN>
<TOKEN end_char="11839" id="token-94-7" morph="none" pos="word" start_char="11836">were</TOKEN>
<TOKEN end_char="11841" id="token-94-8" morph="none" pos="punct" start_char="11841">"</TOKEN>
<TOKEN end_char="11847" id="token-94-9" morph="none" pos="word" start_char="11842">enough</TOKEN>
<TOKEN end_char="11856" id="token-94-10" morph="none" pos="word" start_char="11849">elements</TOKEN>
<TOKEN end_char="11859" id="token-94-11" morph="none" pos="word" start_char="11858">so</TOKEN>
<TOKEN end_char="11863" id="token-94-12" morph="none" pos="word" start_char="11861">the</TOKEN>
<TOKEN end_char="11871" id="token-94-13" morph="none" pos="word" start_char="11865">Chinese</TOKEN>
<TOKEN end_char="11882" id="token-94-14" morph="none" pos="word" start_char="11873">government</TOKEN>
<TOKEN end_char="11886" id="token-94-15" morph="none" pos="word" start_char="11884">and</TOKEN>
<TOKEN end_char="11890" id="token-94-16" morph="none" pos="word" start_char="11888">all</TOKEN>
<TOKEN end_char="11898" id="token-94-17" morph="none" pos="word" start_char="11892">Chinese</TOKEN>
<TOKEN end_char="11906" id="token-94-18" morph="none" pos="word" start_char="11900">experts</TOKEN>
<TOKEN end_char="11910" id="token-94-19" morph="none" pos="word" start_char="11908">who</TOKEN>
<TOKEN end_char="11915" id="token-94-20" morph="none" pos="word" start_char="11912">know</TOKEN>
<TOKEN end_char="11929" id="token-94-21" morph="none" pos="word" start_char="11917">coronaviruses</TOKEN>
<TOKEN end_char="11934" id="token-94-22" morph="none" pos="word" start_char="11931">took</TOKEN>
<TOKEN end_char="11937" id="token-94-23" morph="none" pos="word" start_char="11936">an</TOKEN>
<TOKEN end_char="11946" id="token-94-24" morph="none" pos="word" start_char="11939">official</TOKEN>
<TOKEN end_char="11955" id="token-94-25" morph="none" pos="word" start_char="11948">position</TOKEN>
<TOKEN end_char="11960" id="token-94-26" morph="none" pos="word" start_char="11957">that</TOKEN>
<TOKEN end_char="11962" id="token-94-27" morph="none" pos="punct" start_char="11962">‘</TOKEN>
<TOKEN end_char="11964" id="token-94-28" morph="none" pos="word" start_char="11963">we</TOKEN>
<TOKEN end_char="11969" id="token-94-29" morph="none" pos="word" start_char="11966">must</TOKEN>
<TOKEN end_char="11975" id="token-94-30" morph="none" pos="word" start_char="11971">treat</TOKEN>
<TOKEN end_char="11980" id="token-94-31" morph="none" pos="word" start_char="11977">with</TOKEN>
<TOKEN end_char="11992" id="token-94-32" morph="none" pos="word" start_char="11982">chloroquine</TOKEN>
<TOKEN end_char="11994" id="token-94-33" morph="none" pos="punct" start_char="11993">.’</TOKEN>
</SEG>
<SEG end_char="12178" id="segment-95" start_char="11996">
<ORIGINAL_TEXT>Between the moment when we have the first results and an accepted international publication, there is no credible alternative among people who are the most knowledgeable in the world.</ORIGINAL_TEXT>
<TOKEN end_char="12002" id="token-95-0" morph="none" pos="word" start_char="11996">Between</TOKEN>
<TOKEN end_char="12006" id="token-95-1" morph="none" pos="word" start_char="12004">the</TOKEN>
<TOKEN end_char="12013" id="token-95-2" morph="none" pos="word" start_char="12008">moment</TOKEN>
<TOKEN end_char="12018" id="token-95-3" morph="none" pos="word" start_char="12015">when</TOKEN>
<TOKEN end_char="12021" id="token-95-4" morph="none" pos="word" start_char="12020">we</TOKEN>
<TOKEN end_char="12026" id="token-95-5" morph="none" pos="word" start_char="12023">have</TOKEN>
<TOKEN end_char="12030" id="token-95-6" morph="none" pos="word" start_char="12028">the</TOKEN>
<TOKEN end_char="12036" id="token-95-7" morph="none" pos="word" start_char="12032">first</TOKEN>
<TOKEN end_char="12044" id="token-95-8" morph="none" pos="word" start_char="12038">results</TOKEN>
<TOKEN end_char="12048" id="token-95-9" morph="none" pos="word" start_char="12046">and</TOKEN>
<TOKEN end_char="12051" id="token-95-10" morph="none" pos="word" start_char="12050">an</TOKEN>
<TOKEN end_char="12060" id="token-95-11" morph="none" pos="word" start_char="12053">accepted</TOKEN>
<TOKEN end_char="12074" id="token-95-12" morph="none" pos="word" start_char="12062">international</TOKEN>
<TOKEN end_char="12086" id="token-95-13" morph="none" pos="word" start_char="12076">publication</TOKEN>
<TOKEN end_char="12087" id="token-95-14" morph="none" pos="punct" start_char="12087">,</TOKEN>
<TOKEN end_char="12093" id="token-95-15" morph="none" pos="word" start_char="12089">there</TOKEN>
<TOKEN end_char="12096" id="token-95-16" morph="none" pos="word" start_char="12095">is</TOKEN>
<TOKEN end_char="12099" id="token-95-17" morph="none" pos="word" start_char="12098">no</TOKEN>
<TOKEN end_char="12108" id="token-95-18" morph="none" pos="word" start_char="12101">credible</TOKEN>
<TOKEN end_char="12120" id="token-95-19" morph="none" pos="word" start_char="12110">alternative</TOKEN>
<TOKEN end_char="12126" id="token-95-20" morph="none" pos="word" start_char="12122">among</TOKEN>
<TOKEN end_char="12133" id="token-95-21" morph="none" pos="word" start_char="12128">people</TOKEN>
<TOKEN end_char="12137" id="token-95-22" morph="none" pos="word" start_char="12135">who</TOKEN>
<TOKEN end_char="12141" id="token-95-23" morph="none" pos="word" start_char="12139">are</TOKEN>
<TOKEN end_char="12145" id="token-95-24" morph="none" pos="word" start_char="12143">the</TOKEN>
<TOKEN end_char="12150" id="token-95-25" morph="none" pos="word" start_char="12147">most</TOKEN>
<TOKEN end_char="12164" id="token-95-26" morph="none" pos="word" start_char="12152">knowledgeable</TOKEN>
<TOKEN end_char="12167" id="token-95-27" morph="none" pos="word" start_char="12166">in</TOKEN>
<TOKEN end_char="12171" id="token-95-28" morph="none" pos="word" start_char="12169">the</TOKEN>
<TOKEN end_char="12177" id="token-95-29" morph="none" pos="word" start_char="12173">world</TOKEN>
<TOKEN end_char="12178" id="token-95-30" morph="none" pos="punct" start_char="12178">.</TOKEN>
</SEG>
<SEG end_char="12236" id="segment-96" start_char="12180">
<ORIGINAL_TEXT>They took this measure in the interest of public health."</ORIGINAL_TEXT>
<TOKEN end_char="12183" id="token-96-0" morph="none" pos="word" start_char="12180">They</TOKEN>
<TOKEN end_char="12188" id="token-96-1" morph="none" pos="word" start_char="12185">took</TOKEN>
<TOKEN end_char="12193" id="token-96-2" morph="none" pos="word" start_char="12190">this</TOKEN>
<TOKEN end_char="12201" id="token-96-3" morph="none" pos="word" start_char="12195">measure</TOKEN>
<TOKEN end_char="12204" id="token-96-4" morph="none" pos="word" start_char="12203">in</TOKEN>
<TOKEN end_char="12208" id="token-96-5" morph="none" pos="word" start_char="12206">the</TOKEN>
<TOKEN end_char="12217" id="token-96-6" morph="none" pos="word" start_char="12210">interest</TOKEN>
<TOKEN end_char="12220" id="token-96-7" morph="none" pos="word" start_char="12219">of</TOKEN>
<TOKEN end_char="12227" id="token-96-8" morph="none" pos="word" start_char="12222">public</TOKEN>
<TOKEN end_char="12234" id="token-96-9" morph="none" pos="word" start_char="12229">health</TOKEN>
<TOKEN end_char="12236" id="token-96-10" morph="none" pos="punct" start_char="12235">."</TOKEN>
</SEG>
<SEG end_char="12310" id="segment-97" start_char="12239">
<ORIGINAL_TEXT>Crucially: if he had coronavirus, Raoult says he would take chloroquine.</ORIGINAL_TEXT>
<TOKEN end_char="12247" id="token-97-0" morph="none" pos="word" start_char="12239">Crucially</TOKEN>
<TOKEN end_char="12248" id="token-97-1" morph="none" pos="punct" start_char="12248">:</TOKEN>
<TOKEN end_char="12251" id="token-97-2" morph="none" pos="word" start_char="12250">if</TOKEN>
<TOKEN end_char="12254" id="token-97-3" morph="none" pos="word" start_char="12253">he</TOKEN>
<TOKEN end_char="12258" id="token-97-4" morph="none" pos="word" start_char="12256">had</TOKEN>
<TOKEN end_char="12270" id="token-97-5" morph="none" pos="word" start_char="12260">coronavirus</TOKEN>
<TOKEN end_char="12271" id="token-97-6" morph="none" pos="punct" start_char="12271">,</TOKEN>
<TOKEN end_char="12278" id="token-97-7" morph="none" pos="word" start_char="12273">Raoult</TOKEN>
<TOKEN end_char="12283" id="token-97-8" morph="none" pos="word" start_char="12280">says</TOKEN>
<TOKEN end_char="12286" id="token-97-9" morph="none" pos="word" start_char="12285">he</TOKEN>
<TOKEN end_char="12292" id="token-97-10" morph="none" pos="word" start_char="12288">would</TOKEN>
<TOKEN end_char="12297" id="token-97-11" morph="none" pos="word" start_char="12294">take</TOKEN>
<TOKEN end_char="12309" id="token-97-12" morph="none" pos="word" start_char="12299">chloroquine</TOKEN>
<TOKEN end_char="12310" id="token-97-13" morph="none" pos="punct" start_char="12310">.</TOKEN>
</SEG>
<SEG end_char="12416" id="segment-98" start_char="12312">
<ORIGINAL_TEXT>Since Raoult is rated by his peers as the number one world expert in communicable diseases, way above Dr.</ORIGINAL_TEXT>
<TOKEN end_char="12316" id="token-98-0" morph="none" pos="word" start_char="12312">Since</TOKEN>
<TOKEN end_char="12323" id="token-98-1" morph="none" pos="word" start_char="12318">Raoult</TOKEN>
<TOKEN end_char="12326" id="token-98-2" morph="none" pos="word" start_char="12325">is</TOKEN>
<TOKEN end_char="12332" id="token-98-3" morph="none" pos="word" start_char="12328">rated</TOKEN>
<TOKEN end_char="12335" id="token-98-4" morph="none" pos="word" start_char="12334">by</TOKEN>
<TOKEN end_char="12339" id="token-98-5" morph="none" pos="word" start_char="12337">his</TOKEN>
<TOKEN end_char="12345" id="token-98-6" morph="none" pos="word" start_char="12341">peers</TOKEN>
<TOKEN end_char="12348" id="token-98-7" morph="none" pos="word" start_char="12347">as</TOKEN>
<TOKEN end_char="12352" id="token-98-8" morph="none" pos="word" start_char="12350">the</TOKEN>
<TOKEN end_char="12359" id="token-98-9" morph="none" pos="word" start_char="12354">number</TOKEN>
<TOKEN end_char="12363" id="token-98-10" morph="none" pos="word" start_char="12361">one</TOKEN>
<TOKEN end_char="12369" id="token-98-11" morph="none" pos="word" start_char="12365">world</TOKEN>
<TOKEN end_char="12376" id="token-98-12" morph="none" pos="word" start_char="12371">expert</TOKEN>
<TOKEN end_char="12379" id="token-98-13" morph="none" pos="word" start_char="12378">in</TOKEN>
<TOKEN end_char="12392" id="token-98-14" morph="none" pos="word" start_char="12381">communicable</TOKEN>
<TOKEN end_char="12401" id="token-98-15" morph="none" pos="word" start_char="12394">diseases</TOKEN>
<TOKEN end_char="12402" id="token-98-16" morph="none" pos="punct" start_char="12402">,</TOKEN>
<TOKEN end_char="12406" id="token-98-17" morph="none" pos="word" start_char="12404">way</TOKEN>
<TOKEN end_char="12412" id="token-98-18" morph="none" pos="word" start_char="12408">above</TOKEN>
<TOKEN end_char="12415" id="token-98-19" morph="none" pos="word" start_char="12414">Dr</TOKEN>
<TOKEN end_char="12416" id="token-98-20" morph="none" pos="punct" start_char="12416">.</TOKEN>
</SEG>
<SEG end_char="12499" id="segment-99" start_char="12418">
<ORIGINAL_TEXT>Anthony Fauci in the US, I would say the new reports represent Big Pharma talking.</ORIGINAL_TEXT>
<TOKEN end_char="12424" id="token-99-0" morph="none" pos="word" start_char="12418">Anthony</TOKEN>
<TOKEN end_char="12430" id="token-99-1" morph="none" pos="word" start_char="12426">Fauci</TOKEN>
<TOKEN end_char="12433" id="token-99-2" morph="none" pos="word" start_char="12432">in</TOKEN>
<TOKEN end_char="12437" id="token-99-3" morph="none" pos="word" start_char="12435">the</TOKEN>
<TOKEN end_char="12440" id="token-99-4" morph="none" pos="word" start_char="12439">US</TOKEN>
<TOKEN end_char="12441" id="token-99-5" morph="none" pos="punct" start_char="12441">,</TOKEN>
<TOKEN end_char="12443" id="token-99-6" morph="none" pos="word" start_char="12443">I</TOKEN>
<TOKEN end_char="12449" id="token-99-7" morph="none" pos="word" start_char="12445">would</TOKEN>
<TOKEN end_char="12453" id="token-99-8" morph="none" pos="word" start_char="12451">say</TOKEN>
<TOKEN end_char="12457" id="token-99-9" morph="none" pos="word" start_char="12455">the</TOKEN>
<TOKEN end_char="12461" id="token-99-10" morph="none" pos="word" start_char="12459">new</TOKEN>
<TOKEN end_char="12469" id="token-99-11" morph="none" pos="word" start_char="12463">reports</TOKEN>
<TOKEN end_char="12479" id="token-99-12" morph="none" pos="word" start_char="12471">represent</TOKEN>
<TOKEN end_char="12483" id="token-99-13" morph="none" pos="word" start_char="12481">Big</TOKEN>
<TOKEN end_char="12490" id="token-99-14" morph="none" pos="word" start_char="12485">Pharma</TOKEN>
<TOKEN end_char="12498" id="token-99-15" morph="none" pos="word" start_char="12492">talking</TOKEN>
<TOKEN end_char="12499" id="token-99-16" morph="none" pos="punct" start_char="12499">.</TOKEN>
</SEG>
<SEG end_char="12644" id="segment-100" start_char="12502">
<ORIGINAL_TEXT>Raoult has been mercilessly savaged and demonized by French corporate media that are controlled by a few oligarchs closely linked to Macronism.</ORIGINAL_TEXT>
<TOKEN end_char="12507" id="token-100-0" morph="none" pos="word" start_char="12502">Raoult</TOKEN>
<TOKEN end_char="12511" id="token-100-1" morph="none" pos="word" start_char="12509">has</TOKEN>
<TOKEN end_char="12516" id="token-100-2" morph="none" pos="word" start_char="12513">been</TOKEN>
<TOKEN end_char="12528" id="token-100-3" morph="none" pos="word" start_char="12518">mercilessly</TOKEN>
<TOKEN end_char="12536" id="token-100-4" morph="none" pos="word" start_char="12530">savaged</TOKEN>
<TOKEN end_char="12540" id="token-100-5" morph="none" pos="word" start_char="12538">and</TOKEN>
<TOKEN end_char="12550" id="token-100-6" morph="none" pos="word" start_char="12542">demonized</TOKEN>
<TOKEN end_char="12553" id="token-100-7" morph="none" pos="word" start_char="12552">by</TOKEN>
<TOKEN end_char="12560" id="token-100-8" morph="none" pos="word" start_char="12555">French</TOKEN>
<TOKEN end_char="12570" id="token-100-9" morph="none" pos="word" start_char="12562">corporate</TOKEN>
<TOKEN end_char="12576" id="token-100-10" morph="none" pos="word" start_char="12572">media</TOKEN>
<TOKEN end_char="12581" id="token-100-11" morph="none" pos="word" start_char="12578">that</TOKEN>
<TOKEN end_char="12585" id="token-100-12" morph="none" pos="word" start_char="12583">are</TOKEN>
<TOKEN end_char="12596" id="token-100-13" morph="none" pos="word" start_char="12587">controlled</TOKEN>
<TOKEN end_char="12599" id="token-100-14" morph="none" pos="word" start_char="12598">by</TOKEN>
<TOKEN end_char="12601" id="token-100-15" morph="none" pos="word" start_char="12601">a</TOKEN>
<TOKEN end_char="12605" id="token-100-16" morph="none" pos="word" start_char="12603">few</TOKEN>
<TOKEN end_char="12615" id="token-100-17" morph="none" pos="word" start_char="12607">oligarchs</TOKEN>
<TOKEN end_char="12623" id="token-100-18" morph="none" pos="word" start_char="12617">closely</TOKEN>
<TOKEN end_char="12630" id="token-100-19" morph="none" pos="word" start_char="12625">linked</TOKEN>
<TOKEN end_char="12633" id="token-100-20" morph="none" pos="word" start_char="12632">to</TOKEN>
<TOKEN end_char="12643" id="token-100-21" morph="none" pos="word" start_char="12635">Macronism</TOKEN>
<TOKEN end_char="12644" id="token-100-22" morph="none" pos="punct" start_char="12644">.</TOKEN>
</SEG>
<SEG end_char="12979" id="segment-101" start_char="12646">
<ORIGINAL_TEXT>Not by accident the demonization has reached gilets jaunes (yellow vest) levels, especially because of the extremely popular hashtag #IlsSavaient ("They knew"), with which the yellow vests stress that French elites have "managed" the Covid-19 crisis by protecting themselves while leaving the population defenseless against the virus.</ORIGINAL_TEXT>
<TOKEN end_char="12648" id="token-101-0" morph="none" pos="word" start_char="12646">Not</TOKEN>
<TOKEN end_char="12651" id="token-101-1" morph="none" pos="word" start_char="12650">by</TOKEN>
<TOKEN end_char="12660" id="token-101-2" morph="none" pos="word" start_char="12653">accident</TOKEN>
<TOKEN end_char="12664" id="token-101-3" morph="none" pos="word" start_char="12662">the</TOKEN>
<TOKEN end_char="12677" id="token-101-4" morph="none" pos="word" start_char="12666">demonization</TOKEN>
<TOKEN end_char="12681" id="token-101-5" morph="none" pos="word" start_char="12679">has</TOKEN>
<TOKEN end_char="12689" id="token-101-6" morph="none" pos="word" start_char="12683">reached</TOKEN>
<TOKEN end_char="12696" id="token-101-7" morph="none" pos="word" start_char="12691">gilets</TOKEN>
<TOKEN end_char="12703" id="token-101-8" morph="none" pos="word" start_char="12698">jaunes</TOKEN>
<TOKEN end_char="12705" id="token-101-9" morph="none" pos="punct" start_char="12705">(</TOKEN>
<TOKEN end_char="12711" id="token-101-10" morph="none" pos="word" start_char="12706">yellow</TOKEN>
<TOKEN end_char="12716" id="token-101-11" morph="none" pos="word" start_char="12713">vest</TOKEN>
<TOKEN end_char="12717" id="token-101-12" morph="none" pos="punct" start_char="12717">)</TOKEN>
<TOKEN end_char="12724" id="token-101-13" morph="none" pos="word" start_char="12719">levels</TOKEN>
<TOKEN end_char="12725" id="token-101-14" morph="none" pos="punct" start_char="12725">,</TOKEN>
<TOKEN end_char="12736" id="token-101-15" morph="none" pos="word" start_char="12727">especially</TOKEN>
<TOKEN end_char="12744" id="token-101-16" morph="none" pos="word" start_char="12738">because</TOKEN>
<TOKEN end_char="12747" id="token-101-17" morph="none" pos="word" start_char="12746">of</TOKEN>
<TOKEN end_char="12751" id="token-101-18" morph="none" pos="word" start_char="12749">the</TOKEN>
<TOKEN end_char="12761" id="token-101-19" morph="none" pos="word" start_char="12753">extremely</TOKEN>
<TOKEN end_char="12769" id="token-101-20" morph="none" pos="word" start_char="12763">popular</TOKEN>
<TOKEN end_char="12777" id="token-101-21" morph="none" pos="word" start_char="12771">hashtag</TOKEN>
<TOKEN end_char="12790" id="token-101-22" morph="none" pos="tag" start_char="12779">#IlsSavaient</TOKEN>
<TOKEN end_char="12793" id="token-101-23" morph="none" pos="punct" start_char="12792">("</TOKEN>
<TOKEN end_char="12797" id="token-101-24" morph="none" pos="word" start_char="12794">They</TOKEN>
<TOKEN end_char="12802" id="token-101-25" morph="none" pos="word" start_char="12799">knew</TOKEN>
<TOKEN end_char="12805" id="token-101-26" morph="none" pos="punct" start_char="12803">"),</TOKEN>
<TOKEN end_char="12810" id="token-101-27" morph="none" pos="word" start_char="12807">with</TOKEN>
<TOKEN end_char="12816" id="token-101-28" morph="none" pos="word" start_char="12812">which</TOKEN>
<TOKEN end_char="12820" id="token-101-29" morph="none" pos="word" start_char="12818">the</TOKEN>
<TOKEN end_char="12827" id="token-101-30" morph="none" pos="word" start_char="12822">yellow</TOKEN>
<TOKEN end_char="12833" id="token-101-31" morph="none" pos="word" start_char="12829">vests</TOKEN>
<TOKEN end_char="12840" id="token-101-32" morph="none" pos="word" start_char="12835">stress</TOKEN>
<TOKEN end_char="12845" id="token-101-33" morph="none" pos="word" start_char="12842">that</TOKEN>
<TOKEN end_char="12852" id="token-101-34" morph="none" pos="word" start_char="12847">French</TOKEN>
<TOKEN end_char="12859" id="token-101-35" morph="none" pos="word" start_char="12854">elites</TOKEN>
<TOKEN end_char="12864" id="token-101-36" morph="none" pos="word" start_char="12861">have</TOKEN>
<TOKEN end_char="12866" id="token-101-37" morph="none" pos="punct" start_char="12866">"</TOKEN>
<TOKEN end_char="12873" id="token-101-38" morph="none" pos="word" start_char="12867">managed</TOKEN>
<TOKEN end_char="12874" id="token-101-39" morph="none" pos="punct" start_char="12874">"</TOKEN>
<TOKEN end_char="12878" id="token-101-40" morph="none" pos="word" start_char="12876">the</TOKEN>
<TOKEN end_char="12887" id="token-101-41" morph="none" pos="unknown" start_char="12880">Covid-19</TOKEN>
<TOKEN end_char="12894" id="token-101-42" morph="none" pos="word" start_char="12889">crisis</TOKEN>
<TOKEN end_char="12897" id="token-101-43" morph="none" pos="word" start_char="12896">by</TOKEN>
<TOKEN end_char="12908" id="token-101-44" morph="none" pos="word" start_char="12899">protecting</TOKEN>
<TOKEN end_char="12919" id="token-101-45" morph="none" pos="word" start_char="12910">themselves</TOKEN>
<TOKEN end_char="12925" id="token-101-46" morph="none" pos="word" start_char="12921">while</TOKEN>
<TOKEN end_char="12933" id="token-101-47" morph="none" pos="word" start_char="12927">leaving</TOKEN>
<TOKEN end_char="12937" id="token-101-48" morph="none" pos="word" start_char="12935">the</TOKEN>
<TOKEN end_char="12948" id="token-101-49" morph="none" pos="word" start_char="12939">population</TOKEN>
<TOKEN end_char="12960" id="token-101-50" morph="none" pos="word" start_char="12950">defenseless</TOKEN>
<TOKEN end_char="12968" id="token-101-51" morph="none" pos="word" start_char="12962">against</TOKEN>
<TOKEN end_char="12972" id="token-101-52" morph="none" pos="word" start_char="12970">the</TOKEN>
<TOKEN end_char="12978" id="token-101-53" morph="none" pos="word" start_char="12974">virus</TOKEN>
<TOKEN end_char="12979" id="token-101-54" morph="none" pos="punct" start_char="12979">.</TOKEN>
</SEG>
<SEG end_char="13306" id="segment-102" start_char="12982">
<ORIGINAL_TEXT>That ties in with the controversial analysis by crack philosopher Giorgio Agamben in a column published a month ago, where he was already arguing that Covid-19 clearly shows that the state of exception – similar to a state of emergency but with differences important to philosophers – has become fully normalized in the West.</ORIGINAL_TEXT>
<TOKEN end_char="12985" id="token-102-0" morph="none" pos="word" start_char="12982">That</TOKEN>
<TOKEN end_char="12990" id="token-102-1" morph="none" pos="word" start_char="12987">ties</TOKEN>
<TOKEN end_char="12993" id="token-102-2" morph="none" pos="word" start_char="12992">in</TOKEN>
<TOKEN end_char="12998" id="token-102-3" morph="none" pos="word" start_char="12995">with</TOKEN>
<TOKEN end_char="13002" id="token-102-4" morph="none" pos="word" start_char="13000">the</TOKEN>
<TOKEN end_char="13016" id="token-102-5" morph="none" pos="word" start_char="13004">controversial</TOKEN>
<TOKEN end_char="13025" id="token-102-6" morph="none" pos="word" start_char="13018">analysis</TOKEN>
<TOKEN end_char="13028" id="token-102-7" morph="none" pos="word" start_char="13027">by</TOKEN>
<TOKEN end_char="13034" id="token-102-8" morph="none" pos="word" start_char="13030">crack</TOKEN>
<TOKEN end_char="13046" id="token-102-9" morph="none" pos="word" start_char="13036">philosopher</TOKEN>
<TOKEN end_char="13054" id="token-102-10" morph="none" pos="word" start_char="13048">Giorgio</TOKEN>
<TOKEN end_char="13062" id="token-102-11" morph="none" pos="word" start_char="13056">Agamben</TOKEN>
<TOKEN end_char="13065" id="token-102-12" morph="none" pos="word" start_char="13064">in</TOKEN>
<TOKEN end_char="13067" id="token-102-13" morph="none" pos="word" start_char="13067">a</TOKEN>
<TOKEN end_char="13074" id="token-102-14" morph="none" pos="word" start_char="13069">column</TOKEN>
<TOKEN end_char="13084" id="token-102-15" morph="none" pos="word" start_char="13076">published</TOKEN>
<TOKEN end_char="13086" id="token-102-16" morph="none" pos="word" start_char="13086">a</TOKEN>
<TOKEN end_char="13092" id="token-102-17" morph="none" pos="word" start_char="13088">month</TOKEN>
<TOKEN end_char="13096" id="token-102-18" morph="none" pos="word" start_char="13094">ago</TOKEN>
<TOKEN end_char="13097" id="token-102-19" morph="none" pos="punct" start_char="13097">,</TOKEN>
<TOKEN end_char="13103" id="token-102-20" morph="none" pos="word" start_char="13099">where</TOKEN>
<TOKEN end_char="13106" id="token-102-21" morph="none" pos="word" start_char="13105">he</TOKEN>
<TOKEN end_char="13110" id="token-102-22" morph="none" pos="word" start_char="13108">was</TOKEN>
<TOKEN end_char="13118" id="token-102-23" morph="none" pos="word" start_char="13112">already</TOKEN>
<TOKEN end_char="13126" id="token-102-24" morph="none" pos="word" start_char="13120">arguing</TOKEN>
<TOKEN end_char="13131" id="token-102-25" morph="none" pos="word" start_char="13128">that</TOKEN>
<TOKEN end_char="13140" id="token-102-26" morph="none" pos="unknown" start_char="13133">Covid-19</TOKEN>
<TOKEN end_char="13148" id="token-102-27" morph="none" pos="word" start_char="13142">clearly</TOKEN>
<TOKEN end_char="13154" id="token-102-28" morph="none" pos="word" start_char="13150">shows</TOKEN>
<TOKEN end_char="13159" id="token-102-29" morph="none" pos="word" start_char="13156">that</TOKEN>
<TOKEN end_char="13163" id="token-102-30" morph="none" pos="word" start_char="13161">the</TOKEN>
<TOKEN end_char="13169" id="token-102-31" morph="none" pos="word" start_char="13165">state</TOKEN>
<TOKEN end_char="13172" id="token-102-32" morph="none" pos="word" start_char="13171">of</TOKEN>
<TOKEN end_char="13182" id="token-102-33" morph="none" pos="word" start_char="13174">exception</TOKEN>
<TOKEN end_char="13184" id="token-102-34" morph="none" pos="punct" start_char="13184">–</TOKEN>
<TOKEN end_char="13192" id="token-102-35" morph="none" pos="word" start_char="13186">similar</TOKEN>
<TOKEN end_char="13195" id="token-102-36" morph="none" pos="word" start_char="13194">to</TOKEN>
<TOKEN end_char="13197" id="token-102-37" morph="none" pos="word" start_char="13197">a</TOKEN>
<TOKEN end_char="13203" id="token-102-38" morph="none" pos="word" start_char="13199">state</TOKEN>
<TOKEN end_char="13206" id="token-102-39" morph="none" pos="word" start_char="13205">of</TOKEN>
<TOKEN end_char="13216" id="token-102-40" morph="none" pos="word" start_char="13208">emergency</TOKEN>
<TOKEN end_char="13220" id="token-102-41" morph="none" pos="word" start_char="13218">but</TOKEN>
<TOKEN end_char="13225" id="token-102-42" morph="none" pos="word" start_char="13222">with</TOKEN>
<TOKEN end_char="13237" id="token-102-43" morph="none" pos="word" start_char="13227">differences</TOKEN>
<TOKEN end_char="13247" id="token-102-44" morph="none" pos="word" start_char="13239">important</TOKEN>
<TOKEN end_char="13250" id="token-102-45" morph="none" pos="word" start_char="13249">to</TOKEN>
<TOKEN end_char="13263" id="token-102-46" morph="none" pos="word" start_char="13252">philosophers</TOKEN>
<TOKEN end_char="13265" id="token-102-47" morph="none" pos="punct" start_char="13265">–</TOKEN>
<TOKEN end_char="13269" id="token-102-48" morph="none" pos="word" start_char="13267">has</TOKEN>
<TOKEN end_char="13276" id="token-102-49" morph="none" pos="word" start_char="13271">become</TOKEN>
<TOKEN end_char="13282" id="token-102-50" morph="none" pos="word" start_char="13278">fully</TOKEN>
<TOKEN end_char="13293" id="token-102-51" morph="none" pos="word" start_char="13284">normalized</TOKEN>
<TOKEN end_char="13296" id="token-102-52" morph="none" pos="word" start_char="13295">in</TOKEN>
<TOKEN end_char="13300" id="token-102-53" morph="none" pos="word" start_char="13298">the</TOKEN>
<TOKEN end_char="13305" id="token-102-54" morph="none" pos="word" start_char="13302">West</TOKEN>
<TOKEN end_char="13306" id="token-102-55" morph="none" pos="punct" start_char="13306">.</TOKEN>
</SEG>
<SEG end_char="13456" id="segment-103" start_char="13309">
<ORIGINAL_TEXT>Agamben was speaking not as a doctor or a virologist but as a master thinker, following in the steps of Foucault, Walter Benjamin and Hannah Arendt.</ORIGINAL_TEXT>
<TOKEN end_char="13315" id="token-103-0" morph="none" pos="word" start_char="13309">Agamben</TOKEN>
<TOKEN end_char="13319" id="token-103-1" morph="none" pos="word" start_char="13317">was</TOKEN>
<TOKEN end_char="13328" id="token-103-2" morph="none" pos="word" start_char="13321">speaking</TOKEN>
<TOKEN end_char="13332" id="token-103-3" morph="none" pos="word" start_char="13330">not</TOKEN>
<TOKEN end_char="13335" id="token-103-4" morph="none" pos="word" start_char="13334">as</TOKEN>
<TOKEN end_char="13337" id="token-103-5" morph="none" pos="word" start_char="13337">a</TOKEN>
<TOKEN end_char="13344" id="token-103-6" morph="none" pos="word" start_char="13339">doctor</TOKEN>
<TOKEN end_char="13347" id="token-103-7" morph="none" pos="word" start_char="13346">or</TOKEN>
<TOKEN end_char="13349" id="token-103-8" morph="none" pos="word" start_char="13349">a</TOKEN>
<TOKEN end_char="13360" id="token-103-9" morph="none" pos="word" start_char="13351">virologist</TOKEN>
<TOKEN end_char="13364" id="token-103-10" morph="none" pos="word" start_char="13362">but</TOKEN>
<TOKEN end_char="13367" id="token-103-11" morph="none" pos="word" start_char="13366">as</TOKEN>
<TOKEN end_char="13369" id="token-103-12" morph="none" pos="word" start_char="13369">a</TOKEN>
<TOKEN end_char="13376" id="token-103-13" morph="none" pos="word" start_char="13371">master</TOKEN>
<TOKEN end_char="13384" id="token-103-14" morph="none" pos="word" start_char="13378">thinker</TOKEN>
<TOKEN end_char="13385" id="token-103-15" morph="none" pos="punct" start_char="13385">,</TOKEN>
<TOKEN end_char="13395" id="token-103-16" morph="none" pos="word" start_char="13387">following</TOKEN>
<TOKEN end_char="13398" id="token-103-17" morph="none" pos="word" start_char="13397">in</TOKEN>
<TOKEN end_char="13402" id="token-103-18" morph="none" pos="word" start_char="13400">the</TOKEN>
<TOKEN end_char="13408" id="token-103-19" morph="none" pos="word" start_char="13404">steps</TOKEN>
<TOKEN end_char="13411" id="token-103-20" morph="none" pos="word" start_char="13410">of</TOKEN>
<TOKEN end_char="13420" id="token-103-21" morph="none" pos="word" start_char="13413">Foucault</TOKEN>
<TOKEN end_char="13421" id="token-103-22" morph="none" pos="punct" start_char="13421">,</TOKEN>
<TOKEN end_char="13428" id="token-103-23" morph="none" pos="word" start_char="13423">Walter</TOKEN>
<TOKEN end_char="13437" id="token-103-24" morph="none" pos="word" start_char="13430">Benjamin</TOKEN>
<TOKEN end_char="13441" id="token-103-25" morph="none" pos="word" start_char="13439">and</TOKEN>
<TOKEN end_char="13448" id="token-103-26" morph="none" pos="word" start_char="13443">Hannah</TOKEN>
<TOKEN end_char="13455" id="token-103-27" morph="none" pos="word" start_char="13450">Arendt</TOKEN>
<TOKEN end_char="13456" id="token-103-28" morph="none" pos="punct" start_char="13456">.</TOKEN>
</SEG>
<SEG end_char="13822" id="segment-104" start_char="13458">
<ORIGINAL_TEXT>Noting how a latent state of fear has metastasized into a state of collective panic, for which Covid-19 "offers once again the ideal pretext," he described how, "in a perverse vicious circle, the limitation of freedom imposed by governments is accepted in the name of a desire for security that was induced by the same governments that now intervene to satisfy it."</ORIGINAL_TEXT>
<TOKEN end_char="13463" id="token-104-0" morph="none" pos="word" start_char="13458">Noting</TOKEN>
<TOKEN end_char="13467" id="token-104-1" morph="none" pos="word" start_char="13465">how</TOKEN>
<TOKEN end_char="13469" id="token-104-2" morph="none" pos="word" start_char="13469">a</TOKEN>
<TOKEN end_char="13476" id="token-104-3" morph="none" pos="word" start_char="13471">latent</TOKEN>
<TOKEN end_char="13482" id="token-104-4" morph="none" pos="word" start_char="13478">state</TOKEN>
<TOKEN end_char="13485" id="token-104-5" morph="none" pos="word" start_char="13484">of</TOKEN>
<TOKEN end_char="13490" id="token-104-6" morph="none" pos="word" start_char="13487">fear</TOKEN>
<TOKEN end_char="13494" id="token-104-7" morph="none" pos="word" start_char="13492">has</TOKEN>
<TOKEN end_char="13507" id="token-104-8" morph="none" pos="word" start_char="13496">metastasized</TOKEN>
<TOKEN end_char="13512" id="token-104-9" morph="none" pos="word" start_char="13509">into</TOKEN>
<TOKEN end_char="13514" id="token-104-10" morph="none" pos="word" start_char="13514">a</TOKEN>
<TOKEN end_char="13520" id="token-104-11" morph="none" pos="word" start_char="13516">state</TOKEN>
<TOKEN end_char="13523" id="token-104-12" morph="none" pos="word" start_char="13522">of</TOKEN>
<TOKEN end_char="13534" id="token-104-13" morph="none" pos="word" start_char="13525">collective</TOKEN>
<TOKEN end_char="13540" id="token-104-14" morph="none" pos="word" start_char="13536">panic</TOKEN>
<TOKEN end_char="13541" id="token-104-15" morph="none" pos="punct" start_char="13541">,</TOKEN>
<TOKEN end_char="13545" id="token-104-16" morph="none" pos="word" start_char="13543">for</TOKEN>
<TOKEN end_char="13551" id="token-104-17" morph="none" pos="word" start_char="13547">which</TOKEN>
<TOKEN end_char="13560" id="token-104-18" morph="none" pos="unknown" start_char="13553">Covid-19</TOKEN>
<TOKEN end_char="13562" id="token-104-19" morph="none" pos="punct" start_char="13562">"</TOKEN>
<TOKEN end_char="13568" id="token-104-20" morph="none" pos="word" start_char="13563">offers</TOKEN>
<TOKEN end_char="13573" id="token-104-21" morph="none" pos="word" start_char="13570">once</TOKEN>
<TOKEN end_char="13579" id="token-104-22" morph="none" pos="word" start_char="13575">again</TOKEN>
<TOKEN end_char="13583" id="token-104-23" morph="none" pos="word" start_char="13581">the</TOKEN>
<TOKEN end_char="13589" id="token-104-24" morph="none" pos="word" start_char="13585">ideal</TOKEN>
<TOKEN end_char="13597" id="token-104-25" morph="none" pos="word" start_char="13591">pretext</TOKEN>
<TOKEN end_char="13599" id="token-104-26" morph="none" pos="punct" start_char="13598">,"</TOKEN>
<TOKEN end_char="13602" id="token-104-27" morph="none" pos="word" start_char="13601">he</TOKEN>
<TOKEN end_char="13612" id="token-104-28" morph="none" pos="word" start_char="13604">described</TOKEN>
<TOKEN end_char="13616" id="token-104-29" morph="none" pos="word" start_char="13614">how</TOKEN>
<TOKEN end_char="13617" id="token-104-30" morph="none" pos="punct" start_char="13617">,</TOKEN>
<TOKEN end_char="13619" id="token-104-31" morph="none" pos="punct" start_char="13619">"</TOKEN>
<TOKEN end_char="13621" id="token-104-32" morph="none" pos="word" start_char="13620">in</TOKEN>
<TOKEN end_char="13623" id="token-104-33" morph="none" pos="word" start_char="13623">a</TOKEN>
<TOKEN end_char="13632" id="token-104-34" morph="none" pos="word" start_char="13625">perverse</TOKEN>
<TOKEN end_char="13640" id="token-104-35" morph="none" pos="word" start_char="13634">vicious</TOKEN>
<TOKEN end_char="13647" id="token-104-36" morph="none" pos="word" start_char="13642">circle</TOKEN>
<TOKEN end_char="13648" id="token-104-37" morph="none" pos="punct" start_char="13648">,</TOKEN>
<TOKEN end_char="13652" id="token-104-38" morph="none" pos="word" start_char="13650">the</TOKEN>
<TOKEN end_char="13663" id="token-104-39" morph="none" pos="word" start_char="13654">limitation</TOKEN>
<TOKEN end_char="13666" id="token-104-40" morph="none" pos="word" start_char="13665">of</TOKEN>
<TOKEN end_char="13674" id="token-104-41" morph="none" pos="word" start_char="13668">freedom</TOKEN>
<TOKEN end_char="13682" id="token-104-42" morph="none" pos="word" start_char="13676">imposed</TOKEN>
<TOKEN end_char="13685" id="token-104-43" morph="none" pos="word" start_char="13684">by</TOKEN>
<TOKEN end_char="13697" id="token-104-44" morph="none" pos="word" start_char="13687">governments</TOKEN>
<TOKEN end_char="13700" id="token-104-45" morph="none" pos="word" start_char="13699">is</TOKEN>
<TOKEN end_char="13709" id="token-104-46" morph="none" pos="word" start_char="13702">accepted</TOKEN>
<TOKEN end_char="13712" id="token-104-47" morph="none" pos="word" start_char="13711">in</TOKEN>
<TOKEN end_char="13716" id="token-104-48" morph="none" pos="word" start_char="13714">the</TOKEN>
<TOKEN end_char="13721" id="token-104-49" morph="none" pos="word" start_char="13718">name</TOKEN>
<TOKEN end_char="13724" id="token-104-50" morph="none" pos="word" start_char="13723">of</TOKEN>
<TOKEN end_char="13726" id="token-104-51" morph="none" pos="word" start_char="13726">a</TOKEN>
<TOKEN end_char="13733" id="token-104-52" morph="none" pos="word" start_char="13728">desire</TOKEN>
<TOKEN end_char="13737" id="token-104-53" morph="none" pos="word" start_char="13735">for</TOKEN>
<TOKEN end_char="13746" id="token-104-54" morph="none" pos="word" start_char="13739">security</TOKEN>
<TOKEN end_char="13751" id="token-104-55" morph="none" pos="word" start_char="13748">that</TOKEN>
<TOKEN end_char="13755" id="token-104-56" morph="none" pos="word" start_char="13753">was</TOKEN>
<TOKEN end_char="13763" id="token-104-57" morph="none" pos="word" start_char="13757">induced</TOKEN>
<TOKEN end_char="13766" id="token-104-58" morph="none" pos="word" start_char="13765">by</TOKEN>
<TOKEN end_char="13770" id="token-104-59" morph="none" pos="word" start_char="13768">the</TOKEN>
<TOKEN end_char="13775" id="token-104-60" morph="none" pos="word" start_char="13772">same</TOKEN>
<TOKEN end_char="13787" id="token-104-61" morph="none" pos="word" start_char="13777">governments</TOKEN>
<TOKEN end_char="13792" id="token-104-62" morph="none" pos="word" start_char="13789">that</TOKEN>
<TOKEN end_char="13796" id="token-104-63" morph="none" pos="word" start_char="13794">now</TOKEN>
<TOKEN end_char="13806" id="token-104-64" morph="none" pos="word" start_char="13798">intervene</TOKEN>
<TOKEN end_char="13809" id="token-104-65" morph="none" pos="word" start_char="13808">to</TOKEN>
<TOKEN end_char="13817" id="token-104-66" morph="none" pos="word" start_char="13811">satisfy</TOKEN>
<TOKEN end_char="13820" id="token-104-67" morph="none" pos="word" start_char="13819">it</TOKEN>
<TOKEN end_char="13822" id="token-104-68" morph="none" pos="punct" start_char="13821">."</TOKEN>
</SEG>
<SEG end_char="13959" id="segment-105" start_char="13825">
<ORIGINAL_TEXT>There was no state of collective panic in South Korea, Singapore, Taiwan and Vietnam – to mention four Asian examples outside of China.</ORIGINAL_TEXT>
<TOKEN end_char="13829" id="token-105-0" morph="none" pos="word" start_char="13825">There</TOKEN>
<TOKEN end_char="13833" id="token-105-1" morph="none" pos="word" start_char="13831">was</TOKEN>
<TOKEN end_char="13836" id="token-105-2" morph="none" pos="word" start_char="13835">no</TOKEN>
<TOKEN end_char="13842" id="token-105-3" morph="none" pos="word" start_char="13838">state</TOKEN>
<TOKEN end_char="13845" id="token-105-4" morph="none" pos="word" start_char="13844">of</TOKEN>
<TOKEN end_char="13856" id="token-105-5" morph="none" pos="word" start_char="13847">collective</TOKEN>
<TOKEN end_char="13862" id="token-105-6" morph="none" pos="word" start_char="13858">panic</TOKEN>
<TOKEN end_char="13865" id="token-105-7" morph="none" pos="word" start_char="13864">in</TOKEN>
<TOKEN end_char="13871" id="token-105-8" morph="none" pos="word" start_char="13867">South</TOKEN>
<TOKEN end_char="13877" id="token-105-9" morph="none" pos="word" start_char="13873">Korea</TOKEN>
<TOKEN end_char="13878" id="token-105-10" morph="none" pos="punct" start_char="13878">,</TOKEN>
<TOKEN end_char="13888" id="token-105-11" morph="none" pos="word" start_char="13880">Singapore</TOKEN>
<TOKEN end_char="13889" id="token-105-12" morph="none" pos="punct" start_char="13889">,</TOKEN>
<TOKEN end_char="13896" id="token-105-13" morph="none" pos="word" start_char="13891">Taiwan</TOKEN>
<TOKEN end_char="13900" id="token-105-14" morph="none" pos="word" start_char="13898">and</TOKEN>
<TOKEN end_char="13908" id="token-105-15" morph="none" pos="word" start_char="13902">Vietnam</TOKEN>
<TOKEN end_char="13910" id="token-105-16" morph="none" pos="punct" start_char="13910">–</TOKEN>
<TOKEN end_char="13913" id="token-105-17" morph="none" pos="word" start_char="13912">to</TOKEN>
<TOKEN end_char="13921" id="token-105-18" morph="none" pos="word" start_char="13915">mention</TOKEN>
<TOKEN end_char="13926" id="token-105-19" morph="none" pos="word" start_char="13923">four</TOKEN>
<TOKEN end_char="13932" id="token-105-20" morph="none" pos="word" start_char="13928">Asian</TOKEN>
<TOKEN end_char="13941" id="token-105-21" morph="none" pos="word" start_char="13934">examples</TOKEN>
<TOKEN end_char="13949" id="token-105-22" morph="none" pos="word" start_char="13943">outside</TOKEN>
<TOKEN end_char="13952" id="token-105-23" morph="none" pos="word" start_char="13951">of</TOKEN>
<TOKEN end_char="13958" id="token-105-24" morph="none" pos="word" start_char="13954">China</TOKEN>
<TOKEN end_char="13959" id="token-105-25" morph="none" pos="punct" start_char="13959">.</TOKEN>
</SEG>
<SEG end_char="14058" id="segment-106" start_char="13961">
<ORIGINAL_TEXT>A dogged combination of mass testing and contact tracing was applied with immense professionalism.</ORIGINAL_TEXT>
<TOKEN end_char="13961" id="token-106-0" morph="none" pos="word" start_char="13961">A</TOKEN>
<TOKEN end_char="13968" id="token-106-1" morph="none" pos="word" start_char="13963">dogged</TOKEN>
<TOKEN end_char="13980" id="token-106-2" morph="none" pos="word" start_char="13970">combination</TOKEN>
<TOKEN end_char="13983" id="token-106-3" morph="none" pos="word" start_char="13982">of</TOKEN>
<TOKEN end_char="13988" id="token-106-4" morph="none" pos="word" start_char="13985">mass</TOKEN>
<TOKEN end_char="13996" id="token-106-5" morph="none" pos="word" start_char="13990">testing</TOKEN>
<TOKEN end_char="14000" id="token-106-6" morph="none" pos="word" start_char="13998">and</TOKEN>
<TOKEN end_char="14008" id="token-106-7" morph="none" pos="word" start_char="14002">contact</TOKEN>
<TOKEN end_char="14016" id="token-106-8" morph="none" pos="word" start_char="14010">tracing</TOKEN>
<TOKEN end_char="14020" id="token-106-9" morph="none" pos="word" start_char="14018">was</TOKEN>
<TOKEN end_char="14028" id="token-106-10" morph="none" pos="word" start_char="14022">applied</TOKEN>
<TOKEN end_char="14033" id="token-106-11" morph="none" pos="word" start_char="14030">with</TOKEN>
<TOKEN end_char="14041" id="token-106-12" morph="none" pos="word" start_char="14035">immense</TOKEN>
<TOKEN end_char="14057" id="token-106-13" morph="none" pos="word" start_char="14043">professionalism</TOKEN>
<TOKEN end_char="14058" id="token-106-14" morph="none" pos="punct" start_char="14058">.</TOKEN>
</SEG>
<SEG end_char="14069" id="segment-107" start_char="14060">
<ORIGINAL_TEXT>It worked.</ORIGINAL_TEXT>
<TOKEN end_char="14061" id="token-107-0" morph="none" pos="word" start_char="14060">It</TOKEN>
<TOKEN end_char="14068" id="token-107-1" morph="none" pos="word" start_char="14063">worked</TOKEN>
<TOKEN end_char="14069" id="token-107-2" morph="none" pos="punct" start_char="14069">.</TOKEN>
</SEG>
<SEG end_char="14120" id="segment-108" start_char="14071">
<ORIGINAL_TEXT>In the Chinese case, with the help of chloroquine.</ORIGINAL_TEXT>
<TOKEN end_char="14072" id="token-108-0" morph="none" pos="word" start_char="14071">In</TOKEN>
<TOKEN end_char="14076" id="token-108-1" morph="none" pos="word" start_char="14074">the</TOKEN>
<TOKEN end_char="14084" id="token-108-2" morph="none" pos="word" start_char="14078">Chinese</TOKEN>
<TOKEN end_char="14089" id="token-108-3" morph="none" pos="word" start_char="14086">case</TOKEN>
<TOKEN end_char="14090" id="token-108-4" morph="none" pos="punct" start_char="14090">,</TOKEN>
<TOKEN end_char="14095" id="token-108-5" morph="none" pos="word" start_char="14092">with</TOKEN>
<TOKEN end_char="14099" id="token-108-6" morph="none" pos="word" start_char="14097">the</TOKEN>
<TOKEN end_char="14104" id="token-108-7" morph="none" pos="word" start_char="14101">help</TOKEN>
<TOKEN end_char="14107" id="token-108-8" morph="none" pos="word" start_char="14106">of</TOKEN>
<TOKEN end_char="14119" id="token-108-9" morph="none" pos="word" start_char="14109">chloroquine</TOKEN>
<TOKEN end_char="14120" id="token-108-10" morph="none" pos="punct" start_char="14120">.</TOKEN>
</SEG>
<SEG end_char="14204" id="segment-109" start_char="14122">
<ORIGINAL_TEXT>And in all Asian cases, without a murky profit motive to the benefit of Big Pharma.</ORIGINAL_TEXT>
<TOKEN end_char="14124" id="token-109-0" morph="none" pos="word" start_char="14122">And</TOKEN>
<TOKEN end_char="14127" id="token-109-1" morph="none" pos="word" start_char="14126">in</TOKEN>
<TOKEN end_char="14131" id="token-109-2" morph="none" pos="word" start_char="14129">all</TOKEN>
<TOKEN end_char="14137" id="token-109-3" morph="none" pos="word" start_char="14133">Asian</TOKEN>
<TOKEN end_char="14143" id="token-109-4" morph="none" pos="word" start_char="14139">cases</TOKEN>
<TOKEN end_char="14144" id="token-109-5" morph="none" pos="punct" start_char="14144">,</TOKEN>
<TOKEN end_char="14152" id="token-109-6" morph="none" pos="word" start_char="14146">without</TOKEN>
<TOKEN end_char="14154" id="token-109-7" morph="none" pos="word" start_char="14154">a</TOKEN>
<TOKEN end_char="14160" id="token-109-8" morph="none" pos="word" start_char="14156">murky</TOKEN>
<TOKEN end_char="14167" id="token-109-9" morph="none" pos="word" start_char="14162">profit</TOKEN>
<TOKEN end_char="14174" id="token-109-10" morph="none" pos="word" start_char="14169">motive</TOKEN>
<TOKEN end_char="14177" id="token-109-11" morph="none" pos="word" start_char="14176">to</TOKEN>
<TOKEN end_char="14181" id="token-109-12" morph="none" pos="word" start_char="14179">the</TOKEN>
<TOKEN end_char="14189" id="token-109-13" morph="none" pos="word" start_char="14183">benefit</TOKEN>
<TOKEN end_char="14192" id="token-109-14" morph="none" pos="word" start_char="14191">of</TOKEN>
<TOKEN end_char="14196" id="token-109-15" morph="none" pos="word" start_char="14194">Big</TOKEN>
<TOKEN end_char="14203" id="token-109-16" morph="none" pos="word" start_char="14198">Pharma</TOKEN>
<TOKEN end_char="14204" id="token-109-17" morph="none" pos="punct" start_char="14204">.</TOKEN>
</SEG>
<SEG end_char="14412" id="segment-110" start_char="14207">
<ORIGINAL_TEXT>There hasn’t yet appeared the smoking gun that proves the Macron system not only is incompetent to deal with Covid-19 but also is dragging the process so Big Pharma can come up with a miracle vaccine, fast.</ORIGINAL_TEXT>
<TOKEN end_char="14211" id="token-110-0" morph="none" pos="word" start_char="14207">There</TOKEN>
<TOKEN end_char="14218" id="token-110-1" morph="none" pos="word" start_char="14213">hasn’t</TOKEN>
<TOKEN end_char="14222" id="token-110-2" morph="none" pos="word" start_char="14220">yet</TOKEN>
<TOKEN end_char="14231" id="token-110-3" morph="none" pos="word" start_char="14224">appeared</TOKEN>
<TOKEN end_char="14235" id="token-110-4" morph="none" pos="word" start_char="14233">the</TOKEN>
<TOKEN end_char="14243" id="token-110-5" morph="none" pos="word" start_char="14237">smoking</TOKEN>
<TOKEN end_char="14247" id="token-110-6" morph="none" pos="word" start_char="14245">gun</TOKEN>
<TOKEN end_char="14252" id="token-110-7" morph="none" pos="word" start_char="14249">that</TOKEN>
<TOKEN end_char="14259" id="token-110-8" morph="none" pos="word" start_char="14254">proves</TOKEN>
<TOKEN end_char="14263" id="token-110-9" morph="none" pos="word" start_char="14261">the</TOKEN>
<TOKEN end_char="14270" id="token-110-10" morph="none" pos="word" start_char="14265">Macron</TOKEN>
<TOKEN end_char="14277" id="token-110-11" morph="none" pos="word" start_char="14272">system</TOKEN>
<TOKEN end_char="14281" id="token-110-12" morph="none" pos="word" start_char="14279">not</TOKEN>
<TOKEN end_char="14286" id="token-110-13" morph="none" pos="word" start_char="14283">only</TOKEN>
<TOKEN end_char="14289" id="token-110-14" morph="none" pos="word" start_char="14288">is</TOKEN>
<TOKEN end_char="14301" id="token-110-15" morph="none" pos="word" start_char="14291">incompetent</TOKEN>
<TOKEN end_char="14304" id="token-110-16" morph="none" pos="word" start_char="14303">to</TOKEN>
<TOKEN end_char="14309" id="token-110-17" morph="none" pos="word" start_char="14306">deal</TOKEN>
<TOKEN end_char="14314" id="token-110-18" morph="none" pos="word" start_char="14311">with</TOKEN>
<TOKEN end_char="14323" id="token-110-19" morph="none" pos="unknown" start_char="14316">Covid-19</TOKEN>
<TOKEN end_char="14327" id="token-110-20" morph="none" pos="word" start_char="14325">but</TOKEN>
<TOKEN end_char="14332" id="token-110-21" morph="none" pos="word" start_char="14329">also</TOKEN>
<TOKEN end_char="14335" id="token-110-22" morph="none" pos="word" start_char="14334">is</TOKEN>
<TOKEN end_char="14344" id="token-110-23" morph="none" pos="word" start_char="14337">dragging</TOKEN>
<TOKEN end_char="14348" id="token-110-24" morph="none" pos="word" start_char="14346">the</TOKEN>
<TOKEN end_char="14356" id="token-110-25" morph="none" pos="word" start_char="14350">process</TOKEN>
<TOKEN end_char="14359" id="token-110-26" morph="none" pos="word" start_char="14358">so</TOKEN>
<TOKEN end_char="14363" id="token-110-27" morph="none" pos="word" start_char="14361">Big</TOKEN>
<TOKEN end_char="14370" id="token-110-28" morph="none" pos="word" start_char="14365">Pharma</TOKEN>
<TOKEN end_char="14374" id="token-110-29" morph="none" pos="word" start_char="14372">can</TOKEN>
<TOKEN end_char="14379" id="token-110-30" morph="none" pos="word" start_char="14376">come</TOKEN>
<TOKEN end_char="14382" id="token-110-31" morph="none" pos="word" start_char="14381">up</TOKEN>
<TOKEN end_char="14387" id="token-110-32" morph="none" pos="word" start_char="14384">with</TOKEN>
<TOKEN end_char="14389" id="token-110-33" morph="none" pos="word" start_char="14389">a</TOKEN>
<TOKEN end_char="14397" id="token-110-34" morph="none" pos="word" start_char="14391">miracle</TOKEN>
<TOKEN end_char="14405" id="token-110-35" morph="none" pos="word" start_char="14399">vaccine</TOKEN>
<TOKEN end_char="14406" id="token-110-36" morph="none" pos="punct" start_char="14406">,</TOKEN>
<TOKEN end_char="14411" id="token-110-37" morph="none" pos="word" start_char="14408">fast</TOKEN>
<TOKEN end_char="14412" id="token-110-38" morph="none" pos="punct" start_char="14412">.</TOKEN>
</SEG>
<SEG end_char="14527" id="segment-111" start_char="14414">
<ORIGINAL_TEXT>But the pattern to discourage chloroquine is more than laid out above – in parallel to the demonization of Raoult.</ORIGINAL_TEXT>
<TOKEN end_char="14416" id="token-111-0" morph="none" pos="word" start_char="14414">But</TOKEN>
<TOKEN end_char="14420" id="token-111-1" morph="none" pos="word" start_char="14418">the</TOKEN>
<TOKEN end_char="14428" id="token-111-2" morph="none" pos="word" start_char="14422">pattern</TOKEN>
<TOKEN end_char="14431" id="token-111-3" morph="none" pos="word" start_char="14430">to</TOKEN>
<TOKEN end_char="14442" id="token-111-4" morph="none" pos="word" start_char="14433">discourage</TOKEN>
<TOKEN end_char="14454" id="token-111-5" morph="none" pos="word" start_char="14444">chloroquine</TOKEN>
<TOKEN end_char="14457" id="token-111-6" morph="none" pos="word" start_char="14456">is</TOKEN>
<TOKEN end_char="14462" id="token-111-7" morph="none" pos="word" start_char="14459">more</TOKEN>
<TOKEN end_char="14467" id="token-111-8" morph="none" pos="word" start_char="14464">than</TOKEN>
<TOKEN end_char="14472" id="token-111-9" morph="none" pos="word" start_char="14469">laid</TOKEN>
<TOKEN end_char="14476" id="token-111-10" morph="none" pos="word" start_char="14474">out</TOKEN>
<TOKEN end_char="14482" id="token-111-11" morph="none" pos="word" start_char="14478">above</TOKEN>
<TOKEN end_char="14484" id="token-111-12" morph="none" pos="punct" start_char="14484">–</TOKEN>
<TOKEN end_char="14487" id="token-111-13" morph="none" pos="word" start_char="14486">in</TOKEN>
<TOKEN end_char="14496" id="token-111-14" morph="none" pos="word" start_char="14489">parallel</TOKEN>
<TOKEN end_char="14499" id="token-111-15" morph="none" pos="word" start_char="14498">to</TOKEN>
<TOKEN end_char="14503" id="token-111-16" morph="none" pos="word" start_char="14501">the</TOKEN>
<TOKEN end_char="14516" id="token-111-17" morph="none" pos="word" start_char="14505">demonization</TOKEN>
<TOKEN end_char="14519" id="token-111-18" morph="none" pos="word" start_char="14518">of</TOKEN>
<TOKEN end_char="14526" id="token-111-19" morph="none" pos="word" start_char="14521">Raoult</TOKEN>
<TOKEN end_char="14527" id="token-111-20" morph="none" pos="punct" start_char="14527">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
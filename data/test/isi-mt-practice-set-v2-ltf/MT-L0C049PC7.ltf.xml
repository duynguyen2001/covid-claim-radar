<LCTL_TEXT lang="ukr">
<DOC grammar="none" id="L0C049PC7" lang="ukr" raw_text_char_length="6802" raw_text_md5="2b356d67c7704ce2368ccea4fb91dc79" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="69" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Debunked: This image doesn't show 'extent of corpse burning in Wuhan'</ORIGINAL_TEXT>
<TOKEN end_char="8" id="token-0-0" morph="none" pos="word" start_char="1">Debunked</TOKEN>
<TOKEN end_char="9" id="token-0-1" morph="none" pos="punct" start_char="9">:</TOKEN>
<TOKEN end_char="14" id="token-0-2" morph="none" pos="word" start_char="11">This</TOKEN>
<TOKEN end_char="20" id="token-0-3" morph="none" pos="word" start_char="16">image</TOKEN>
<TOKEN end_char="28" id="token-0-4" morph="none" pos="word" start_char="22">doesn't</TOKEN>
<TOKEN end_char="33" id="token-0-5" morph="none" pos="word" start_char="30">show</TOKEN>
<TOKEN end_char="35" id="token-0-6" morph="none" pos="punct" start_char="35">'</TOKEN>
<TOKEN end_char="41" id="token-0-7" morph="none" pos="word" start_char="36">extent</TOKEN>
<TOKEN end_char="44" id="token-0-8" morph="none" pos="word" start_char="43">of</TOKEN>
<TOKEN end_char="51" id="token-0-9" morph="none" pos="word" start_char="46">corpse</TOKEN>
<TOKEN end_char="59" id="token-0-10" morph="none" pos="word" start_char="53">burning</TOKEN>
<TOKEN end_char="62" id="token-0-11" morph="none" pos="word" start_char="61">in</TOKEN>
<TOKEN end_char="68" id="token-0-12" morph="none" pos="word" start_char="64">Wuhan</TOKEN>
<TOKEN end_char="69" id="token-0-13" morph="none" pos="punct" start_char="69">'</TOKEN>
</SEG>
<SEG end_char="142" id="segment-1" start_char="73">
<ORIGINAL_TEXT>Sulphur dioxyde levels forecast for Wuhan and Chongqing on February 12</ORIGINAL_TEXT>
<TOKEN end_char="79" id="token-1-0" morph="none" pos="word" start_char="73">Sulphur</TOKEN>
<TOKEN end_char="87" id="token-1-1" morph="none" pos="word" start_char="81">dioxyde</TOKEN>
<TOKEN end_char="94" id="token-1-2" morph="none" pos="word" start_char="89">levels</TOKEN>
<TOKEN end_char="103" id="token-1-3" morph="none" pos="word" start_char="96">forecast</TOKEN>
<TOKEN end_char="107" id="token-1-4" morph="none" pos="word" start_char="105">for</TOKEN>
<TOKEN end_char="113" id="token-1-5" morph="none" pos="word" start_char="109">Wuhan</TOKEN>
<TOKEN end_char="117" id="token-1-6" morph="none" pos="word" start_char="115">and</TOKEN>
<TOKEN end_char="127" id="token-1-7" morph="none" pos="word" start_char="119">Chongqing</TOKEN>
<TOKEN end_char="130" id="token-1-8" morph="none" pos="word" start_char="129">on</TOKEN>
<TOKEN end_char="139" id="token-1-9" morph="none" pos="word" start_char="132">February</TOKEN>
<TOKEN end_char="142" id="token-1-10" morph="none" pos="word" start_char="141">12</TOKEN>
</SEG>
<SEG end_char="371" id="segment-2" start_char="146">
<ORIGINAL_TEXT>In the midst of what the World Health Organisation calls an "infodemic" of fake news around the COVID-19 coronavirus outbreak, British tabloid newspapers published images they suggested was evidence of corpse burning in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="147" id="token-2-0" morph="none" pos="word" start_char="146">In</TOKEN>
<TOKEN end_char="151" id="token-2-1" morph="none" pos="word" start_char="149">the</TOKEN>
<TOKEN end_char="157" id="token-2-2" morph="none" pos="word" start_char="153">midst</TOKEN>
<TOKEN end_char="160" id="token-2-3" morph="none" pos="word" start_char="159">of</TOKEN>
<TOKEN end_char="165" id="token-2-4" morph="none" pos="word" start_char="162">what</TOKEN>
<TOKEN end_char="169" id="token-2-5" morph="none" pos="word" start_char="167">the</TOKEN>
<TOKEN end_char="175" id="token-2-6" morph="none" pos="word" start_char="171">World</TOKEN>
<TOKEN end_char="182" id="token-2-7" morph="none" pos="word" start_char="177">Health</TOKEN>
<TOKEN end_char="195" id="token-2-8" morph="none" pos="word" start_char="184">Organisation</TOKEN>
<TOKEN end_char="201" id="token-2-9" morph="none" pos="word" start_char="197">calls</TOKEN>
<TOKEN end_char="204" id="token-2-10" morph="none" pos="word" start_char="203">an</TOKEN>
<TOKEN end_char="206" id="token-2-11" morph="none" pos="punct" start_char="206">"</TOKEN>
<TOKEN end_char="215" id="token-2-12" morph="none" pos="word" start_char="207">infodemic</TOKEN>
<TOKEN end_char="216" id="token-2-13" morph="none" pos="punct" start_char="216">"</TOKEN>
<TOKEN end_char="219" id="token-2-14" morph="none" pos="word" start_char="218">of</TOKEN>
<TOKEN end_char="224" id="token-2-15" morph="none" pos="word" start_char="221">fake</TOKEN>
<TOKEN end_char="229" id="token-2-16" morph="none" pos="word" start_char="226">news</TOKEN>
<TOKEN end_char="236" id="token-2-17" morph="none" pos="word" start_char="231">around</TOKEN>
<TOKEN end_char="240" id="token-2-18" morph="none" pos="word" start_char="238">the</TOKEN>
<TOKEN end_char="249" id="token-2-19" morph="none" pos="unknown" start_char="242">COVID-19</TOKEN>
<TOKEN end_char="261" id="token-2-20" morph="none" pos="word" start_char="251">coronavirus</TOKEN>
<TOKEN end_char="270" id="token-2-21" morph="none" pos="word" start_char="263">outbreak</TOKEN>
<TOKEN end_char="271" id="token-2-22" morph="none" pos="punct" start_char="271">,</TOKEN>
<TOKEN end_char="279" id="token-2-23" morph="none" pos="word" start_char="273">British</TOKEN>
<TOKEN end_char="287" id="token-2-24" morph="none" pos="word" start_char="281">tabloid</TOKEN>
<TOKEN end_char="298" id="token-2-25" morph="none" pos="word" start_char="289">newspapers</TOKEN>
<TOKEN end_char="308" id="token-2-26" morph="none" pos="word" start_char="300">published</TOKEN>
<TOKEN end_char="315" id="token-2-27" morph="none" pos="word" start_char="310">images</TOKEN>
<TOKEN end_char="320" id="token-2-28" morph="none" pos="word" start_char="317">they</TOKEN>
<TOKEN end_char="330" id="token-2-29" morph="none" pos="word" start_char="322">suggested</TOKEN>
<TOKEN end_char="334" id="token-2-30" morph="none" pos="word" start_char="332">was</TOKEN>
<TOKEN end_char="343" id="token-2-31" morph="none" pos="word" start_char="336">evidence</TOKEN>
<TOKEN end_char="346" id="token-2-32" morph="none" pos="word" start_char="345">of</TOKEN>
<TOKEN end_char="353" id="token-2-33" morph="none" pos="word" start_char="348">corpse</TOKEN>
<TOKEN end_char="361" id="token-2-34" morph="none" pos="word" start_char="355">burning</TOKEN>
<TOKEN end_char="364" id="token-2-35" morph="none" pos="word" start_char="363">in</TOKEN>
<TOKEN end_char="370" id="token-2-36" morph="none" pos="word" start_char="366">Wuhan</TOKEN>
<TOKEN end_char="371" id="token-2-37" morph="none" pos="punct" start_char="371">.</TOKEN>
</SEG>
<SEG end_char="591" id="segment-3" start_char="374">
<ORIGINAL_TEXT>Although the conditional tense was used, they inferred "satellite images" from the windy.com showed high levels of sulphur dioxide (SO2) in Wuhan and Chongqing, both cities quarantined at the epicentre of the outbreak.</ORIGINAL_TEXT>
<TOKEN end_char="381" id="token-3-0" morph="none" pos="word" start_char="374">Although</TOKEN>
<TOKEN end_char="385" id="token-3-1" morph="none" pos="word" start_char="383">the</TOKEN>
<TOKEN end_char="397" id="token-3-2" morph="none" pos="word" start_char="387">conditional</TOKEN>
<TOKEN end_char="403" id="token-3-3" morph="none" pos="word" start_char="399">tense</TOKEN>
<TOKEN end_char="407" id="token-3-4" morph="none" pos="word" start_char="405">was</TOKEN>
<TOKEN end_char="412" id="token-3-5" morph="none" pos="word" start_char="409">used</TOKEN>
<TOKEN end_char="413" id="token-3-6" morph="none" pos="punct" start_char="413">,</TOKEN>
<TOKEN end_char="418" id="token-3-7" morph="none" pos="word" start_char="415">they</TOKEN>
<TOKEN end_char="427" id="token-3-8" morph="none" pos="word" start_char="420">inferred</TOKEN>
<TOKEN end_char="429" id="token-3-9" morph="none" pos="punct" start_char="429">"</TOKEN>
<TOKEN end_char="438" id="token-3-10" morph="none" pos="word" start_char="430">satellite</TOKEN>
<TOKEN end_char="445" id="token-3-11" morph="none" pos="word" start_char="440">images</TOKEN>
<TOKEN end_char="446" id="token-3-12" morph="none" pos="punct" start_char="446">"</TOKEN>
<TOKEN end_char="451" id="token-3-13" morph="none" pos="word" start_char="448">from</TOKEN>
<TOKEN end_char="455" id="token-3-14" morph="none" pos="word" start_char="453">the</TOKEN>
<TOKEN end_char="465" id="token-3-15" morph="none" pos="unknown" start_char="457">windy.com</TOKEN>
<TOKEN end_char="472" id="token-3-16" morph="none" pos="word" start_char="467">showed</TOKEN>
<TOKEN end_char="477" id="token-3-17" morph="none" pos="word" start_char="474">high</TOKEN>
<TOKEN end_char="484" id="token-3-18" morph="none" pos="word" start_char="479">levels</TOKEN>
<TOKEN end_char="487" id="token-3-19" morph="none" pos="word" start_char="486">of</TOKEN>
<TOKEN end_char="495" id="token-3-20" morph="none" pos="word" start_char="489">sulphur</TOKEN>
<TOKEN end_char="503" id="token-3-21" morph="none" pos="word" start_char="497">dioxide</TOKEN>
<TOKEN end_char="505" id="token-3-22" morph="none" pos="punct" start_char="505">(</TOKEN>
<TOKEN end_char="508" id="token-3-23" morph="none" pos="word" start_char="506">SO2</TOKEN>
<TOKEN end_char="509" id="token-3-24" morph="none" pos="punct" start_char="509">)</TOKEN>
<TOKEN end_char="512" id="token-3-25" morph="none" pos="word" start_char="511">in</TOKEN>
<TOKEN end_char="518" id="token-3-26" morph="none" pos="word" start_char="514">Wuhan</TOKEN>
<TOKEN end_char="522" id="token-3-27" morph="none" pos="word" start_char="520">and</TOKEN>
<TOKEN end_char="532" id="token-3-28" morph="none" pos="word" start_char="524">Chongqing</TOKEN>
<TOKEN end_char="533" id="token-3-29" morph="none" pos="punct" start_char="533">,</TOKEN>
<TOKEN end_char="538" id="token-3-30" morph="none" pos="word" start_char="535">both</TOKEN>
<TOKEN end_char="545" id="token-3-31" morph="none" pos="word" start_char="540">cities</TOKEN>
<TOKEN end_char="557" id="token-3-32" morph="none" pos="word" start_char="547">quarantined</TOKEN>
<TOKEN end_char="560" id="token-3-33" morph="none" pos="word" start_char="559">at</TOKEN>
<TOKEN end_char="564" id="token-3-34" morph="none" pos="word" start_char="562">the</TOKEN>
<TOKEN end_char="574" id="token-3-35" morph="none" pos="word" start_char="566">epicentre</TOKEN>
<TOKEN end_char="577" id="token-3-36" morph="none" pos="word" start_char="576">of</TOKEN>
<TOKEN end_char="581" id="token-3-37" morph="none" pos="word" start_char="579">the</TOKEN>
<TOKEN end_char="590" id="token-3-38" morph="none" pos="word" start_char="583">outbreak</TOKEN>
<TOKEN end_char="591" id="token-3-39" morph="none" pos="punct" start_char="591">.</TOKEN>
</SEG>
<SEG end_char="669" id="segment-4" start_char="594">
<ORIGINAL_TEXT>The Sun newspaper ran a story suggesting Beijing was "burning the evidence".</ORIGINAL_TEXT>
<TOKEN end_char="596" id="token-4-0" morph="none" pos="word" start_char="594">The</TOKEN>
<TOKEN end_char="600" id="token-4-1" morph="none" pos="word" start_char="598">Sun</TOKEN>
<TOKEN end_char="610" id="token-4-2" morph="none" pos="word" start_char="602">newspaper</TOKEN>
<TOKEN end_char="614" id="token-4-3" morph="none" pos="word" start_char="612">ran</TOKEN>
<TOKEN end_char="616" id="token-4-4" morph="none" pos="word" start_char="616">a</TOKEN>
<TOKEN end_char="622" id="token-4-5" morph="none" pos="word" start_char="618">story</TOKEN>
<TOKEN end_char="633" id="token-4-6" morph="none" pos="word" start_char="624">suggesting</TOKEN>
<TOKEN end_char="641" id="token-4-7" morph="none" pos="word" start_char="635">Beijing</TOKEN>
<TOKEN end_char="645" id="token-4-8" morph="none" pos="word" start_char="643">was</TOKEN>
<TOKEN end_char="647" id="token-4-9" morph="none" pos="punct" start_char="647">"</TOKEN>
<TOKEN end_char="654" id="token-4-10" morph="none" pos="word" start_char="648">burning</TOKEN>
<TOKEN end_char="658" id="token-4-11" morph="none" pos="word" start_char="656">the</TOKEN>
<TOKEN end_char="667" id="token-4-12" morph="none" pos="word" start_char="660">evidence</TOKEN>
<TOKEN end_char="669" id="token-4-13" morph="none" pos="punct" start_char="668">".</TOKEN>
</SEG>
<SEG end_char="806" id="segment-5" start_char="671">
<ORIGINAL_TEXT>The headline read: with China accused of major coronavirus cover-up as chilling satellite pics 'show extent of corpse burning in Wuhan’.</ORIGINAL_TEXT>
<TOKEN end_char="673" id="token-5-0" morph="none" pos="word" start_char="671">The</TOKEN>
<TOKEN end_char="682" id="token-5-1" morph="none" pos="word" start_char="675">headline</TOKEN>
<TOKEN end_char="687" id="token-5-2" morph="none" pos="word" start_char="684">read</TOKEN>
<TOKEN end_char="688" id="token-5-3" morph="none" pos="punct" start_char="688">:</TOKEN>
<TOKEN end_char="693" id="token-5-4" morph="none" pos="word" start_char="690">with</TOKEN>
<TOKEN end_char="699" id="token-5-5" morph="none" pos="word" start_char="695">China</TOKEN>
<TOKEN end_char="707" id="token-5-6" morph="none" pos="word" start_char="701">accused</TOKEN>
<TOKEN end_char="710" id="token-5-7" morph="none" pos="word" start_char="709">of</TOKEN>
<TOKEN end_char="716" id="token-5-8" morph="none" pos="word" start_char="712">major</TOKEN>
<TOKEN end_char="728" id="token-5-9" morph="none" pos="word" start_char="718">coronavirus</TOKEN>
<TOKEN end_char="737" id="token-5-10" morph="none" pos="unknown" start_char="730">cover-up</TOKEN>
<TOKEN end_char="740" id="token-5-11" morph="none" pos="word" start_char="739">as</TOKEN>
<TOKEN end_char="749" id="token-5-12" morph="none" pos="word" start_char="742">chilling</TOKEN>
<TOKEN end_char="759" id="token-5-13" morph="none" pos="word" start_char="751">satellite</TOKEN>
<TOKEN end_char="764" id="token-5-14" morph="none" pos="word" start_char="761">pics</TOKEN>
<TOKEN end_char="766" id="token-5-15" morph="none" pos="punct" start_char="766">'</TOKEN>
<TOKEN end_char="770" id="token-5-16" morph="none" pos="word" start_char="767">show</TOKEN>
<TOKEN end_char="777" id="token-5-17" morph="none" pos="word" start_char="772">extent</TOKEN>
<TOKEN end_char="780" id="token-5-18" morph="none" pos="word" start_char="779">of</TOKEN>
<TOKEN end_char="787" id="token-5-19" morph="none" pos="word" start_char="782">corpse</TOKEN>
<TOKEN end_char="795" id="token-5-20" morph="none" pos="word" start_char="789">burning</TOKEN>
<TOKEN end_char="798" id="token-5-21" morph="none" pos="word" start_char="797">in</TOKEN>
<TOKEN end_char="804" id="token-5-22" morph="none" pos="word" start_char="800">Wuhan</TOKEN>
<TOKEN end_char="806" id="token-5-23" morph="none" pos="punct" start_char="805">’.</TOKEN>
</SEG>
<SEG end_char="846" id="segment-6" start_char="809">
<ORIGINAL_TEXT>The Daily Mirror used a question mark.</ORIGINAL_TEXT>
<TOKEN end_char="811" id="token-6-0" morph="none" pos="word" start_char="809">The</TOKEN>
<TOKEN end_char="817" id="token-6-1" morph="none" pos="word" start_char="813">Daily</TOKEN>
<TOKEN end_char="824" id="token-6-2" morph="none" pos="word" start_char="819">Mirror</TOKEN>
<TOKEN end_char="829" id="token-6-3" morph="none" pos="word" start_char="826">used</TOKEN>
<TOKEN end_char="831" id="token-6-4" morph="none" pos="word" start_char="831">a</TOKEN>
<TOKEN end_char="840" id="token-6-5" morph="none" pos="word" start_char="833">question</TOKEN>
<TOKEN end_char="845" id="token-6-6" morph="none" pos="word" start_char="842">mark</TOKEN>
<TOKEN end_char="846" id="token-6-7" morph="none" pos="punct" start_char="846">.</TOKEN>
</SEG>
<SEG end_char="965" id="segment-7" start_char="849">
<ORIGINAL_TEXT>But both suggested that these high levels of SO2 could have come from an unusual crematorium activity in both cities.</ORIGINAL_TEXT>
<TOKEN end_char="851" id="token-7-0" morph="none" pos="word" start_char="849">But</TOKEN>
<TOKEN end_char="856" id="token-7-1" morph="none" pos="word" start_char="853">both</TOKEN>
<TOKEN end_char="866" id="token-7-2" morph="none" pos="word" start_char="858">suggested</TOKEN>
<TOKEN end_char="871" id="token-7-3" morph="none" pos="word" start_char="868">that</TOKEN>
<TOKEN end_char="877" id="token-7-4" morph="none" pos="word" start_char="873">these</TOKEN>
<TOKEN end_char="882" id="token-7-5" morph="none" pos="word" start_char="879">high</TOKEN>
<TOKEN end_char="889" id="token-7-6" morph="none" pos="word" start_char="884">levels</TOKEN>
<TOKEN end_char="892" id="token-7-7" morph="none" pos="word" start_char="891">of</TOKEN>
<TOKEN end_char="896" id="token-7-8" morph="none" pos="word" start_char="894">SO2</TOKEN>
<TOKEN end_char="902" id="token-7-9" morph="none" pos="word" start_char="898">could</TOKEN>
<TOKEN end_char="907" id="token-7-10" morph="none" pos="word" start_char="904">have</TOKEN>
<TOKEN end_char="912" id="token-7-11" morph="none" pos="word" start_char="909">come</TOKEN>
<TOKEN end_char="917" id="token-7-12" morph="none" pos="word" start_char="914">from</TOKEN>
<TOKEN end_char="920" id="token-7-13" morph="none" pos="word" start_char="919">an</TOKEN>
<TOKEN end_char="928" id="token-7-14" morph="none" pos="word" start_char="922">unusual</TOKEN>
<TOKEN end_char="940" id="token-7-15" morph="none" pos="word" start_char="930">crematorium</TOKEN>
<TOKEN end_char="949" id="token-7-16" morph="none" pos="word" start_char="942">activity</TOKEN>
<TOKEN end_char="952" id="token-7-17" morph="none" pos="word" start_char="951">in</TOKEN>
<TOKEN end_char="957" id="token-7-18" morph="none" pos="word" start_char="954">both</TOKEN>
<TOKEN end_char="964" id="token-7-19" morph="none" pos="word" start_char="959">cities</TOKEN>
<TOKEN end_char="965" id="token-7-20" morph="none" pos="punct" start_char="965">.</TOKEN>
</SEG>
<SEG end_char="992" id="segment-8" start_char="967">
<ORIGINAL_TEXT>Other media followed suit.</ORIGINAL_TEXT>
<TOKEN end_char="971" id="token-8-0" morph="none" pos="word" start_char="967">Other</TOKEN>
<TOKEN end_char="977" id="token-8-1" morph="none" pos="word" start_char="973">media</TOKEN>
<TOKEN end_char="986" id="token-8-2" morph="none" pos="word" start_char="979">followed</TOKEN>
<TOKEN end_char="991" id="token-8-3" morph="none" pos="word" start_char="988">suit</TOKEN>
<TOKEN end_char="992" id="token-8-4" morph="none" pos="punct" start_char="992">.</TOKEN>
</SEG>
<SEG end_char="1107" id="segment-9" start_char="995">
<ORIGINAL_TEXT>The claim pushed China's air quality office to issue a statement via China's Ministry of Ecology and Environment.</ORIGINAL_TEXT>
<TOKEN end_char="997" id="token-9-0" morph="none" pos="word" start_char="995">The</TOKEN>
<TOKEN end_char="1003" id="token-9-1" morph="none" pos="word" start_char="999">claim</TOKEN>
<TOKEN end_char="1010" id="token-9-2" morph="none" pos="word" start_char="1005">pushed</TOKEN>
<TOKEN end_char="1018" id="token-9-3" morph="none" pos="word" start_char="1012">China's</TOKEN>
<TOKEN end_char="1022" id="token-9-4" morph="none" pos="word" start_char="1020">air</TOKEN>
<TOKEN end_char="1030" id="token-9-5" morph="none" pos="word" start_char="1024">quality</TOKEN>
<TOKEN end_char="1037" id="token-9-6" morph="none" pos="word" start_char="1032">office</TOKEN>
<TOKEN end_char="1040" id="token-9-7" morph="none" pos="word" start_char="1039">to</TOKEN>
<TOKEN end_char="1046" id="token-9-8" morph="none" pos="word" start_char="1042">issue</TOKEN>
<TOKEN end_char="1048" id="token-9-9" morph="none" pos="word" start_char="1048">a</TOKEN>
<TOKEN end_char="1058" id="token-9-10" morph="none" pos="word" start_char="1050">statement</TOKEN>
<TOKEN end_char="1062" id="token-9-11" morph="none" pos="word" start_char="1060">via</TOKEN>
<TOKEN end_char="1070" id="token-9-12" morph="none" pos="word" start_char="1064">China's</TOKEN>
<TOKEN end_char="1079" id="token-9-13" morph="none" pos="word" start_char="1072">Ministry</TOKEN>
<TOKEN end_char="1082" id="token-9-14" morph="none" pos="word" start_char="1081">of</TOKEN>
<TOKEN end_char="1090" id="token-9-15" morph="none" pos="word" start_char="1084">Ecology</TOKEN>
<TOKEN end_char="1094" id="token-9-16" morph="none" pos="word" start_char="1092">and</TOKEN>
<TOKEN end_char="1106" id="token-9-17" morph="none" pos="word" start_char="1096">Environment</TOKEN>
<TOKEN end_char="1107" id="token-9-18" morph="none" pos="punct" start_char="1107">.</TOKEN>
</SEG>
<SEG end_char="1265" id="segment-10" start_char="1110">
<ORIGINAL_TEXT>It said: "After careful confirmation, we found that the SO2 rise published by windy.com was a 'serious distortion' and its statistics could not be trusted."</ORIGINAL_TEXT>
<TOKEN end_char="1111" id="token-10-0" morph="none" pos="word" start_char="1110">It</TOKEN>
<TOKEN end_char="1116" id="token-10-1" morph="none" pos="word" start_char="1113">said</TOKEN>
<TOKEN end_char="1117" id="token-10-2" morph="none" pos="punct" start_char="1117">:</TOKEN>
<TOKEN end_char="1119" id="token-10-3" morph="none" pos="punct" start_char="1119">"</TOKEN>
<TOKEN end_char="1124" id="token-10-4" morph="none" pos="word" start_char="1120">After</TOKEN>
<TOKEN end_char="1132" id="token-10-5" morph="none" pos="word" start_char="1126">careful</TOKEN>
<TOKEN end_char="1145" id="token-10-6" morph="none" pos="word" start_char="1134">confirmation</TOKEN>
<TOKEN end_char="1146" id="token-10-7" morph="none" pos="punct" start_char="1146">,</TOKEN>
<TOKEN end_char="1149" id="token-10-8" morph="none" pos="word" start_char="1148">we</TOKEN>
<TOKEN end_char="1155" id="token-10-9" morph="none" pos="word" start_char="1151">found</TOKEN>
<TOKEN end_char="1160" id="token-10-10" morph="none" pos="word" start_char="1157">that</TOKEN>
<TOKEN end_char="1164" id="token-10-11" morph="none" pos="word" start_char="1162">the</TOKEN>
<TOKEN end_char="1168" id="token-10-12" morph="none" pos="word" start_char="1166">SO2</TOKEN>
<TOKEN end_char="1173" id="token-10-13" morph="none" pos="word" start_char="1170">rise</TOKEN>
<TOKEN end_char="1183" id="token-10-14" morph="none" pos="word" start_char="1175">published</TOKEN>
<TOKEN end_char="1186" id="token-10-15" morph="none" pos="word" start_char="1185">by</TOKEN>
<TOKEN end_char="1196" id="token-10-16" morph="none" pos="unknown" start_char="1188">windy.com</TOKEN>
<TOKEN end_char="1200" id="token-10-17" morph="none" pos="word" start_char="1198">was</TOKEN>
<TOKEN end_char="1202" id="token-10-18" morph="none" pos="word" start_char="1202">a</TOKEN>
<TOKEN end_char="1204" id="token-10-19" morph="none" pos="punct" start_char="1204">'</TOKEN>
<TOKEN end_char="1211" id="token-10-20" morph="none" pos="word" start_char="1205">serious</TOKEN>
<TOKEN end_char="1222" id="token-10-21" morph="none" pos="word" start_char="1213">distortion</TOKEN>
<TOKEN end_char="1223" id="token-10-22" morph="none" pos="punct" start_char="1223">'</TOKEN>
<TOKEN end_char="1227" id="token-10-23" morph="none" pos="word" start_char="1225">and</TOKEN>
<TOKEN end_char="1231" id="token-10-24" morph="none" pos="word" start_char="1229">its</TOKEN>
<TOKEN end_char="1242" id="token-10-25" morph="none" pos="word" start_char="1233">statistics</TOKEN>
<TOKEN end_char="1248" id="token-10-26" morph="none" pos="word" start_char="1244">could</TOKEN>
<TOKEN end_char="1252" id="token-10-27" morph="none" pos="word" start_char="1250">not</TOKEN>
<TOKEN end_char="1255" id="token-10-28" morph="none" pos="word" start_char="1254">be</TOKEN>
<TOKEN end_char="1263" id="token-10-29" morph="none" pos="word" start_char="1257">trusted</TOKEN>
<TOKEN end_char="1265" id="token-10-30" morph="none" pos="punct" start_char="1264">."</TOKEN>
</SEG>
<SEG end_char="1404" id="segment-11" start_char="1268">
<ORIGINAL_TEXT>According to their data, a concentration of between 4 and 8 μg/m3 was recorded on Sunday and not 1,300 μg/m3 as shown by the application.</ORIGINAL_TEXT>
<TOKEN end_char="1276" id="token-11-0" morph="none" pos="word" start_char="1268">According</TOKEN>
<TOKEN end_char="1279" id="token-11-1" morph="none" pos="word" start_char="1278">to</TOKEN>
<TOKEN end_char="1285" id="token-11-2" morph="none" pos="word" start_char="1281">their</TOKEN>
<TOKEN end_char="1290" id="token-11-3" morph="none" pos="word" start_char="1287">data</TOKEN>
<TOKEN end_char="1291" id="token-11-4" morph="none" pos="punct" start_char="1291">,</TOKEN>
<TOKEN end_char="1293" id="token-11-5" morph="none" pos="word" start_char="1293">a</TOKEN>
<TOKEN end_char="1307" id="token-11-6" morph="none" pos="word" start_char="1295">concentration</TOKEN>
<TOKEN end_char="1310" id="token-11-7" morph="none" pos="word" start_char="1309">of</TOKEN>
<TOKEN end_char="1318" id="token-11-8" morph="none" pos="word" start_char="1312">between</TOKEN>
<TOKEN end_char="1320" id="token-11-9" morph="none" pos="word" start_char="1320">4</TOKEN>
<TOKEN end_char="1324" id="token-11-10" morph="none" pos="word" start_char="1322">and</TOKEN>
<TOKEN end_char="1326" id="token-11-11" morph="none" pos="word" start_char="1326">8</TOKEN>
<TOKEN end_char="1332" id="token-11-12" morph="none" pos="unknown" start_char="1328">μg/m3</TOKEN>
<TOKEN end_char="1336" id="token-11-13" morph="none" pos="word" start_char="1334">was</TOKEN>
<TOKEN end_char="1345" id="token-11-14" morph="none" pos="word" start_char="1338">recorded</TOKEN>
<TOKEN end_char="1348" id="token-11-15" morph="none" pos="word" start_char="1347">on</TOKEN>
<TOKEN end_char="1355" id="token-11-16" morph="none" pos="word" start_char="1350">Sunday</TOKEN>
<TOKEN end_char="1359" id="token-11-17" morph="none" pos="word" start_char="1357">and</TOKEN>
<TOKEN end_char="1363" id="token-11-18" morph="none" pos="word" start_char="1361">not</TOKEN>
<TOKEN end_char="1369" id="token-11-19" morph="none" pos="unknown" start_char="1365">1,300</TOKEN>
<TOKEN end_char="1375" id="token-11-20" morph="none" pos="unknown" start_char="1371">μg/m3</TOKEN>
<TOKEN end_char="1378" id="token-11-21" morph="none" pos="word" start_char="1377">as</TOKEN>
<TOKEN end_char="1384" id="token-11-22" morph="none" pos="word" start_char="1380">shown</TOKEN>
<TOKEN end_char="1387" id="token-11-23" morph="none" pos="word" start_char="1386">by</TOKEN>
<TOKEN end_char="1391" id="token-11-24" morph="none" pos="word" start_char="1389">the</TOKEN>
<TOKEN end_char="1403" id="token-11-25" morph="none" pos="word" start_char="1393">application</TOKEN>
<TOKEN end_char="1404" id="token-11-26" morph="none" pos="punct" start_char="1404">.</TOKEN>
</SEG>
<SEG end_char="1452" id="segment-12" start_char="1407">
<ORIGINAL_TEXT>Where did the sulphur dioxide claim come from?</ORIGINAL_TEXT>
<TOKEN end_char="1411" id="token-12-0" morph="none" pos="word" start_char="1407">Where</TOKEN>
<TOKEN end_char="1415" id="token-12-1" morph="none" pos="word" start_char="1413">did</TOKEN>
<TOKEN end_char="1419" id="token-12-2" morph="none" pos="word" start_char="1417">the</TOKEN>
<TOKEN end_char="1427" id="token-12-3" morph="none" pos="word" start_char="1421">sulphur</TOKEN>
<TOKEN end_char="1435" id="token-12-4" morph="none" pos="word" start_char="1429">dioxide</TOKEN>
<TOKEN end_char="1441" id="token-12-5" morph="none" pos="word" start_char="1437">claim</TOKEN>
<TOKEN end_char="1446" id="token-12-6" morph="none" pos="word" start_char="1443">come</TOKEN>
<TOKEN end_char="1451" id="token-12-7" morph="none" pos="word" start_char="1448">from</TOKEN>
<TOKEN end_char="1452" id="token-12-8" morph="none" pos="punct" start_char="1452">?</TOKEN>
</SEG>
<SEG end_char="1608" id="segment-13" start_char="1456">
<ORIGINAL_TEXT>A tweet from Twitter account @inteldotwav, with just over 16,000 followers, posted a thread including what looked like an impressive image on February 8.</ORIGINAL_TEXT>
<TOKEN end_char="1456" id="token-13-0" morph="none" pos="word" start_char="1456">A</TOKEN>
<TOKEN end_char="1462" id="token-13-1" morph="none" pos="word" start_char="1458">tweet</TOKEN>
<TOKEN end_char="1467" id="token-13-2" morph="none" pos="word" start_char="1464">from</TOKEN>
<TOKEN end_char="1475" id="token-13-3" morph="none" pos="word" start_char="1469">Twitter</TOKEN>
<TOKEN end_char="1483" id="token-13-4" morph="none" pos="word" start_char="1477">account</TOKEN>
<TOKEN end_char="1497" id="token-13-5" morph="none" pos="tag" start_char="1485">@inteldotwav,</TOKEN>
<TOKEN end_char="1502" id="token-13-6" morph="none" pos="word" start_char="1499">with</TOKEN>
<TOKEN end_char="1507" id="token-13-7" morph="none" pos="word" start_char="1504">just</TOKEN>
<TOKEN end_char="1512" id="token-13-8" morph="none" pos="word" start_char="1509">over</TOKEN>
<TOKEN end_char="1519" id="token-13-9" morph="none" pos="unknown" start_char="1514">16,000</TOKEN>
<TOKEN end_char="1529" id="token-13-10" morph="none" pos="word" start_char="1521">followers</TOKEN>
<TOKEN end_char="1530" id="token-13-11" morph="none" pos="punct" start_char="1530">,</TOKEN>
<TOKEN end_char="1537" id="token-13-12" morph="none" pos="word" start_char="1532">posted</TOKEN>
<TOKEN end_char="1539" id="token-13-13" morph="none" pos="word" start_char="1539">a</TOKEN>
<TOKEN end_char="1546" id="token-13-14" morph="none" pos="word" start_char="1541">thread</TOKEN>
<TOKEN end_char="1556" id="token-13-15" morph="none" pos="word" start_char="1548">including</TOKEN>
<TOKEN end_char="1561" id="token-13-16" morph="none" pos="word" start_char="1558">what</TOKEN>
<TOKEN end_char="1568" id="token-13-17" morph="none" pos="word" start_char="1563">looked</TOKEN>
<TOKEN end_char="1573" id="token-13-18" morph="none" pos="word" start_char="1570">like</TOKEN>
<TOKEN end_char="1576" id="token-13-19" morph="none" pos="word" start_char="1575">an</TOKEN>
<TOKEN end_char="1587" id="token-13-20" morph="none" pos="word" start_char="1578">impressive</TOKEN>
<TOKEN end_char="1593" id="token-13-21" morph="none" pos="word" start_char="1589">image</TOKEN>
<TOKEN end_char="1596" id="token-13-22" morph="none" pos="word" start_char="1595">on</TOKEN>
<TOKEN end_char="1605" id="token-13-23" morph="none" pos="word" start_char="1598">February</TOKEN>
<TOKEN end_char="1607" id="token-13-24" morph="none" pos="word" start_char="1607">8</TOKEN>
<TOKEN end_char="1608" id="token-13-25" morph="none" pos="punct" start_char="1608">.</TOKEN>
</SEG>
<SEG end_char="1685" id="segment-14" start_char="1611">
<ORIGINAL_TEXT>It claimed to show dangerously high levels of SO2 near Wuhan and Chongqing.</ORIGINAL_TEXT>
<TOKEN end_char="1612" id="token-14-0" morph="none" pos="word" start_char="1611">It</TOKEN>
<TOKEN end_char="1620" id="token-14-1" morph="none" pos="word" start_char="1614">claimed</TOKEN>
<TOKEN end_char="1623" id="token-14-2" morph="none" pos="word" start_char="1622">to</TOKEN>
<TOKEN end_char="1628" id="token-14-3" morph="none" pos="word" start_char="1625">show</TOKEN>
<TOKEN end_char="1640" id="token-14-4" morph="none" pos="word" start_char="1630">dangerously</TOKEN>
<TOKEN end_char="1645" id="token-14-5" morph="none" pos="word" start_char="1642">high</TOKEN>
<TOKEN end_char="1652" id="token-14-6" morph="none" pos="word" start_char="1647">levels</TOKEN>
<TOKEN end_char="1655" id="token-14-7" morph="none" pos="word" start_char="1654">of</TOKEN>
<TOKEN end_char="1659" id="token-14-8" morph="none" pos="word" start_char="1657">SO2</TOKEN>
<TOKEN end_char="1664" id="token-14-9" morph="none" pos="word" start_char="1661">near</TOKEN>
<TOKEN end_char="1670" id="token-14-10" morph="none" pos="word" start_char="1666">Wuhan</TOKEN>
<TOKEN end_char="1674" id="token-14-11" morph="none" pos="word" start_char="1672">and</TOKEN>
<TOKEN end_char="1684" id="token-14-12" morph="none" pos="word" start_char="1676">Chongqing</TOKEN>
<TOKEN end_char="1685" id="token-14-13" morph="none" pos="punct" start_char="1685">.</TOKEN>
</SEG>
<SEG end_char="1791" id="segment-15" start_char="1688">
<ORIGINAL_TEXT>The person behind the tweet left interpretation of what the high levels of SO2 meant open to the reader,</ORIGINAL_TEXT>
<TOKEN end_char="1690" id="token-15-0" morph="none" pos="word" start_char="1688">The</TOKEN>
<TOKEN end_char="1697" id="token-15-1" morph="none" pos="word" start_char="1692">person</TOKEN>
<TOKEN end_char="1704" id="token-15-2" morph="none" pos="word" start_char="1699">behind</TOKEN>
<TOKEN end_char="1708" id="token-15-3" morph="none" pos="word" start_char="1706">the</TOKEN>
<TOKEN end_char="1714" id="token-15-4" morph="none" pos="word" start_char="1710">tweet</TOKEN>
<TOKEN end_char="1719" id="token-15-5" morph="none" pos="word" start_char="1716">left</TOKEN>
<TOKEN end_char="1734" id="token-15-6" morph="none" pos="word" start_char="1721">interpretation</TOKEN>
<TOKEN end_char="1737" id="token-15-7" morph="none" pos="word" start_char="1736">of</TOKEN>
<TOKEN end_char="1742" id="token-15-8" morph="none" pos="word" start_char="1739">what</TOKEN>
<TOKEN end_char="1746" id="token-15-9" morph="none" pos="word" start_char="1744">the</TOKEN>
<TOKEN end_char="1751" id="token-15-10" morph="none" pos="word" start_char="1748">high</TOKEN>
<TOKEN end_char="1758" id="token-15-11" morph="none" pos="word" start_char="1753">levels</TOKEN>
<TOKEN end_char="1761" id="token-15-12" morph="none" pos="word" start_char="1760">of</TOKEN>
<TOKEN end_char="1765" id="token-15-13" morph="none" pos="word" start_char="1763">SO2</TOKEN>
<TOKEN end_char="1771" id="token-15-14" morph="none" pos="word" start_char="1767">meant</TOKEN>
<TOKEN end_char="1776" id="token-15-15" morph="none" pos="word" start_char="1773">open</TOKEN>
<TOKEN end_char="1779" id="token-15-16" morph="none" pos="word" start_char="1778">to</TOKEN>
<TOKEN end_char="1783" id="token-15-17" morph="none" pos="word" start_char="1781">the</TOKEN>
<TOKEN end_char="1790" id="token-15-18" morph="none" pos="word" start_char="1785">reader</TOKEN>
<TOKEN end_char="1791" id="token-15-19" morph="none" pos="punct" start_char="1791">,</TOKEN>
</SEG>
<SEG end_char="2101" id="segment-16" start_char="1794">
<ORIGINAL_TEXT>It was suggested it could be a power plant, burning garbage or animal carcasses, and "the third and most morbid: that bodies are being burned on the outskirts of the city, that the numbers of victims are much higher than what the Chinese Communist Party is reporting, and that things are really, really bad."</ORIGINAL_TEXT>
<TOKEN end_char="1795" id="token-16-0" morph="none" pos="word" start_char="1794">It</TOKEN>
<TOKEN end_char="1799" id="token-16-1" morph="none" pos="word" start_char="1797">was</TOKEN>
<TOKEN end_char="1809" id="token-16-2" morph="none" pos="word" start_char="1801">suggested</TOKEN>
<TOKEN end_char="1812" id="token-16-3" morph="none" pos="word" start_char="1811">it</TOKEN>
<TOKEN end_char="1818" id="token-16-4" morph="none" pos="word" start_char="1814">could</TOKEN>
<TOKEN end_char="1821" id="token-16-5" morph="none" pos="word" start_char="1820">be</TOKEN>
<TOKEN end_char="1823" id="token-16-6" morph="none" pos="word" start_char="1823">a</TOKEN>
<TOKEN end_char="1829" id="token-16-7" morph="none" pos="word" start_char="1825">power</TOKEN>
<TOKEN end_char="1835" id="token-16-8" morph="none" pos="word" start_char="1831">plant</TOKEN>
<TOKEN end_char="1836" id="token-16-9" morph="none" pos="punct" start_char="1836">,</TOKEN>
<TOKEN end_char="1844" id="token-16-10" morph="none" pos="word" start_char="1838">burning</TOKEN>
<TOKEN end_char="1852" id="token-16-11" morph="none" pos="word" start_char="1846">garbage</TOKEN>
<TOKEN end_char="1855" id="token-16-12" morph="none" pos="word" start_char="1854">or</TOKEN>
<TOKEN end_char="1862" id="token-16-13" morph="none" pos="word" start_char="1857">animal</TOKEN>
<TOKEN end_char="1872" id="token-16-14" morph="none" pos="word" start_char="1864">carcasses</TOKEN>
<TOKEN end_char="1873" id="token-16-15" morph="none" pos="punct" start_char="1873">,</TOKEN>
<TOKEN end_char="1877" id="token-16-16" morph="none" pos="word" start_char="1875">and</TOKEN>
<TOKEN end_char="1879" id="token-16-17" morph="none" pos="punct" start_char="1879">"</TOKEN>
<TOKEN end_char="1882" id="token-16-18" morph="none" pos="word" start_char="1880">the</TOKEN>
<TOKEN end_char="1888" id="token-16-19" morph="none" pos="word" start_char="1884">third</TOKEN>
<TOKEN end_char="1892" id="token-16-20" morph="none" pos="word" start_char="1890">and</TOKEN>
<TOKEN end_char="1897" id="token-16-21" morph="none" pos="word" start_char="1894">most</TOKEN>
<TOKEN end_char="1904" id="token-16-22" morph="none" pos="word" start_char="1899">morbid</TOKEN>
<TOKEN end_char="1905" id="token-16-23" morph="none" pos="punct" start_char="1905">:</TOKEN>
<TOKEN end_char="1910" id="token-16-24" morph="none" pos="word" start_char="1907">that</TOKEN>
<TOKEN end_char="1917" id="token-16-25" morph="none" pos="word" start_char="1912">bodies</TOKEN>
<TOKEN end_char="1921" id="token-16-26" morph="none" pos="word" start_char="1919">are</TOKEN>
<TOKEN end_char="1927" id="token-16-27" morph="none" pos="word" start_char="1923">being</TOKEN>
<TOKEN end_char="1934" id="token-16-28" morph="none" pos="word" start_char="1929">burned</TOKEN>
<TOKEN end_char="1937" id="token-16-29" morph="none" pos="word" start_char="1936">on</TOKEN>
<TOKEN end_char="1941" id="token-16-30" morph="none" pos="word" start_char="1939">the</TOKEN>
<TOKEN end_char="1951" id="token-16-31" morph="none" pos="word" start_char="1943">outskirts</TOKEN>
<TOKEN end_char="1954" id="token-16-32" morph="none" pos="word" start_char="1953">of</TOKEN>
<TOKEN end_char="1958" id="token-16-33" morph="none" pos="word" start_char="1956">the</TOKEN>
<TOKEN end_char="1963" id="token-16-34" morph="none" pos="word" start_char="1960">city</TOKEN>
<TOKEN end_char="1964" id="token-16-35" morph="none" pos="punct" start_char="1964">,</TOKEN>
<TOKEN end_char="1969" id="token-16-36" morph="none" pos="word" start_char="1966">that</TOKEN>
<TOKEN end_char="1973" id="token-16-37" morph="none" pos="word" start_char="1971">the</TOKEN>
<TOKEN end_char="1981" id="token-16-38" morph="none" pos="word" start_char="1975">numbers</TOKEN>
<TOKEN end_char="1984" id="token-16-39" morph="none" pos="word" start_char="1983">of</TOKEN>
<TOKEN end_char="1992" id="token-16-40" morph="none" pos="word" start_char="1986">victims</TOKEN>
<TOKEN end_char="1996" id="token-16-41" morph="none" pos="word" start_char="1994">are</TOKEN>
<TOKEN end_char="2001" id="token-16-42" morph="none" pos="word" start_char="1998">much</TOKEN>
<TOKEN end_char="2008" id="token-16-43" morph="none" pos="word" start_char="2003">higher</TOKEN>
<TOKEN end_char="2013" id="token-16-44" morph="none" pos="word" start_char="2010">than</TOKEN>
<TOKEN end_char="2018" id="token-16-45" morph="none" pos="word" start_char="2015">what</TOKEN>
<TOKEN end_char="2022" id="token-16-46" morph="none" pos="word" start_char="2020">the</TOKEN>
<TOKEN end_char="2030" id="token-16-47" morph="none" pos="word" start_char="2024">Chinese</TOKEN>
<TOKEN end_char="2040" id="token-16-48" morph="none" pos="word" start_char="2032">Communist</TOKEN>
<TOKEN end_char="2046" id="token-16-49" morph="none" pos="word" start_char="2042">Party</TOKEN>
<TOKEN end_char="2049" id="token-16-50" morph="none" pos="word" start_char="2048">is</TOKEN>
<TOKEN end_char="2059" id="token-16-51" morph="none" pos="word" start_char="2051">reporting</TOKEN>
<TOKEN end_char="2060" id="token-16-52" morph="none" pos="punct" start_char="2060">,</TOKEN>
<TOKEN end_char="2064" id="token-16-53" morph="none" pos="word" start_char="2062">and</TOKEN>
<TOKEN end_char="2069" id="token-16-54" morph="none" pos="word" start_char="2066">that</TOKEN>
<TOKEN end_char="2076" id="token-16-55" morph="none" pos="word" start_char="2071">things</TOKEN>
<TOKEN end_char="2080" id="token-16-56" morph="none" pos="word" start_char="2078">are</TOKEN>
<TOKEN end_char="2087" id="token-16-57" morph="none" pos="word" start_char="2082">really</TOKEN>
<TOKEN end_char="2088" id="token-16-58" morph="none" pos="punct" start_char="2088">,</TOKEN>
<TOKEN end_char="2095" id="token-16-59" morph="none" pos="word" start_char="2090">really</TOKEN>
<TOKEN end_char="2099" id="token-16-60" morph="none" pos="word" start_char="2097">bad</TOKEN>
<TOKEN end_char="2101" id="token-16-61" morph="none" pos="punct" start_char="2100">."</TOKEN>
</SEG>
<SEG end_char="2202" id="segment-17" start_char="2104">
<ORIGINAL_TEXT>The tweeter confirmed he saw the rumours on the internet and decided to do his own "investigation".</ORIGINAL_TEXT>
<TOKEN end_char="2106" id="token-17-0" morph="none" pos="word" start_char="2104">The</TOKEN>
<TOKEN end_char="2114" id="token-17-1" morph="none" pos="word" start_char="2108">tweeter</TOKEN>
<TOKEN end_char="2124" id="token-17-2" morph="none" pos="word" start_char="2116">confirmed</TOKEN>
<TOKEN end_char="2127" id="token-17-3" morph="none" pos="word" start_char="2126">he</TOKEN>
<TOKEN end_char="2131" id="token-17-4" morph="none" pos="word" start_char="2129">saw</TOKEN>
<TOKEN end_char="2135" id="token-17-5" morph="none" pos="word" start_char="2133">the</TOKEN>
<TOKEN end_char="2143" id="token-17-6" morph="none" pos="word" start_char="2137">rumours</TOKEN>
<TOKEN end_char="2146" id="token-17-7" morph="none" pos="word" start_char="2145">on</TOKEN>
<TOKEN end_char="2150" id="token-17-8" morph="none" pos="word" start_char="2148">the</TOKEN>
<TOKEN end_char="2159" id="token-17-9" morph="none" pos="word" start_char="2152">internet</TOKEN>
<TOKEN end_char="2163" id="token-17-10" morph="none" pos="word" start_char="2161">and</TOKEN>
<TOKEN end_char="2171" id="token-17-11" morph="none" pos="word" start_char="2165">decided</TOKEN>
<TOKEN end_char="2174" id="token-17-12" morph="none" pos="word" start_char="2173">to</TOKEN>
<TOKEN end_char="2177" id="token-17-13" morph="none" pos="word" start_char="2176">do</TOKEN>
<TOKEN end_char="2181" id="token-17-14" morph="none" pos="word" start_char="2179">his</TOKEN>
<TOKEN end_char="2185" id="token-17-15" morph="none" pos="word" start_char="2183">own</TOKEN>
<TOKEN end_char="2187" id="token-17-16" morph="none" pos="punct" start_char="2187">"</TOKEN>
<TOKEN end_char="2200" id="token-17-17" morph="none" pos="word" start_char="2188">investigation</TOKEN>
<TOKEN end_char="2202" id="token-17-18" morph="none" pos="punct" start_char="2201">".</TOKEN>
</SEG>
<SEG end_char="2247" id="segment-18" start_char="2204">
<ORIGINAL_TEXT>However, his method proved to be misleading.</ORIGINAL_TEXT>
<TOKEN end_char="2210" id="token-18-0" morph="none" pos="word" start_char="2204">However</TOKEN>
<TOKEN end_char="2211" id="token-18-1" morph="none" pos="punct" start_char="2211">,</TOKEN>
<TOKEN end_char="2215" id="token-18-2" morph="none" pos="word" start_char="2213">his</TOKEN>
<TOKEN end_char="2222" id="token-18-3" morph="none" pos="word" start_char="2217">method</TOKEN>
<TOKEN end_char="2229" id="token-18-4" morph="none" pos="word" start_char="2224">proved</TOKEN>
<TOKEN end_char="2232" id="token-18-5" morph="none" pos="word" start_char="2231">to</TOKEN>
<TOKEN end_char="2235" id="token-18-6" morph="none" pos="word" start_char="2234">be</TOKEN>
<TOKEN end_char="2246" id="token-18-7" morph="none" pos="word" start_char="2237">misleading</TOKEN>
<TOKEN end_char="2247" id="token-18-8" morph="none" pos="punct" start_char="2247">.</TOKEN>
</SEG>
<SEG end_char="2500" id="segment-19" start_char="2250">
<ORIGINAL_TEXT>In recent days, some media have reported that Wuhan's crematoria are operating 24/7 based on an interview with an employee, interviewed reportedly obtained by The Epoch Times, a conservative and anti-communist media of the Chinese community in the US.</ORIGINAL_TEXT>
<TOKEN end_char="2251" id="token-19-0" morph="none" pos="word" start_char="2250">In</TOKEN>
<TOKEN end_char="2258" id="token-19-1" morph="none" pos="word" start_char="2253">recent</TOKEN>
<TOKEN end_char="2263" id="token-19-2" morph="none" pos="word" start_char="2260">days</TOKEN>
<TOKEN end_char="2264" id="token-19-3" morph="none" pos="punct" start_char="2264">,</TOKEN>
<TOKEN end_char="2269" id="token-19-4" morph="none" pos="word" start_char="2266">some</TOKEN>
<TOKEN end_char="2275" id="token-19-5" morph="none" pos="word" start_char="2271">media</TOKEN>
<TOKEN end_char="2280" id="token-19-6" morph="none" pos="word" start_char="2277">have</TOKEN>
<TOKEN end_char="2289" id="token-19-7" morph="none" pos="word" start_char="2282">reported</TOKEN>
<TOKEN end_char="2294" id="token-19-8" morph="none" pos="word" start_char="2291">that</TOKEN>
<TOKEN end_char="2302" id="token-19-9" morph="none" pos="word" start_char="2296">Wuhan's</TOKEN>
<TOKEN end_char="2313" id="token-19-10" morph="none" pos="word" start_char="2304">crematoria</TOKEN>
<TOKEN end_char="2317" id="token-19-11" morph="none" pos="word" start_char="2315">are</TOKEN>
<TOKEN end_char="2327" id="token-19-12" morph="none" pos="word" start_char="2319">operating</TOKEN>
<TOKEN end_char="2332" id="token-19-13" morph="none" pos="unknown" start_char="2329">24/7</TOKEN>
<TOKEN end_char="2338" id="token-19-14" morph="none" pos="word" start_char="2334">based</TOKEN>
<TOKEN end_char="2341" id="token-19-15" morph="none" pos="word" start_char="2340">on</TOKEN>
<TOKEN end_char="2344" id="token-19-16" morph="none" pos="word" start_char="2343">an</TOKEN>
<TOKEN end_char="2354" id="token-19-17" morph="none" pos="word" start_char="2346">interview</TOKEN>
<TOKEN end_char="2359" id="token-19-18" morph="none" pos="word" start_char="2356">with</TOKEN>
<TOKEN end_char="2362" id="token-19-19" morph="none" pos="word" start_char="2361">an</TOKEN>
<TOKEN end_char="2371" id="token-19-20" morph="none" pos="word" start_char="2364">employee</TOKEN>
<TOKEN end_char="2372" id="token-19-21" morph="none" pos="punct" start_char="2372">,</TOKEN>
<TOKEN end_char="2384" id="token-19-22" morph="none" pos="word" start_char="2374">interviewed</TOKEN>
<TOKEN end_char="2395" id="token-19-23" morph="none" pos="word" start_char="2386">reportedly</TOKEN>
<TOKEN end_char="2404" id="token-19-24" morph="none" pos="word" start_char="2397">obtained</TOKEN>
<TOKEN end_char="2407" id="token-19-25" morph="none" pos="word" start_char="2406">by</TOKEN>
<TOKEN end_char="2411" id="token-19-26" morph="none" pos="word" start_char="2409">The</TOKEN>
<TOKEN end_char="2417" id="token-19-27" morph="none" pos="word" start_char="2413">Epoch</TOKEN>
<TOKEN end_char="2423" id="token-19-28" morph="none" pos="word" start_char="2419">Times</TOKEN>
<TOKEN end_char="2424" id="token-19-29" morph="none" pos="punct" start_char="2424">,</TOKEN>
<TOKEN end_char="2426" id="token-19-30" morph="none" pos="word" start_char="2426">a</TOKEN>
<TOKEN end_char="2439" id="token-19-31" morph="none" pos="word" start_char="2428">conservative</TOKEN>
<TOKEN end_char="2443" id="token-19-32" morph="none" pos="word" start_char="2441">and</TOKEN>
<TOKEN end_char="2458" id="token-19-33" morph="none" pos="unknown" start_char="2445">anti-communist</TOKEN>
<TOKEN end_char="2464" id="token-19-34" morph="none" pos="word" start_char="2460">media</TOKEN>
<TOKEN end_char="2467" id="token-19-35" morph="none" pos="word" start_char="2466">of</TOKEN>
<TOKEN end_char="2471" id="token-19-36" morph="none" pos="word" start_char="2469">the</TOKEN>
<TOKEN end_char="2479" id="token-19-37" morph="none" pos="word" start_char="2473">Chinese</TOKEN>
<TOKEN end_char="2489" id="token-19-38" morph="none" pos="word" start_char="2481">community</TOKEN>
<TOKEN end_char="2492" id="token-19-39" morph="none" pos="word" start_char="2491">in</TOKEN>
<TOKEN end_char="2496" id="token-19-40" morph="none" pos="word" start_char="2494">the</TOKEN>
<TOKEN end_char="2499" id="token-19-41" morph="none" pos="word" start_char="2498">US</TOKEN>
<TOKEN end_char="2500" id="token-19-42" morph="none" pos="punct" start_char="2500">.</TOKEN>
</SEG>
<SEG end_char="2583" id="segment-20" start_char="2502">
<ORIGINAL_TEXT>Other experts outside China also question the accuracy of the official death toll.</ORIGINAL_TEXT>
<TOKEN end_char="2506" id="token-20-0" morph="none" pos="word" start_char="2502">Other</TOKEN>
<TOKEN end_char="2514" id="token-20-1" morph="none" pos="word" start_char="2508">experts</TOKEN>
<TOKEN end_char="2522" id="token-20-2" morph="none" pos="word" start_char="2516">outside</TOKEN>
<TOKEN end_char="2528" id="token-20-3" morph="none" pos="word" start_char="2524">China</TOKEN>
<TOKEN end_char="2533" id="token-20-4" morph="none" pos="word" start_char="2530">also</TOKEN>
<TOKEN end_char="2542" id="token-20-5" morph="none" pos="word" start_char="2535">question</TOKEN>
<TOKEN end_char="2546" id="token-20-6" morph="none" pos="word" start_char="2544">the</TOKEN>
<TOKEN end_char="2555" id="token-20-7" morph="none" pos="word" start_char="2548">accuracy</TOKEN>
<TOKEN end_char="2558" id="token-20-8" morph="none" pos="word" start_char="2557">of</TOKEN>
<TOKEN end_char="2562" id="token-20-9" morph="none" pos="word" start_char="2560">the</TOKEN>
<TOKEN end_char="2571" id="token-20-10" morph="none" pos="word" start_char="2564">official</TOKEN>
<TOKEN end_char="2577" id="token-20-11" morph="none" pos="word" start_char="2573">death</TOKEN>
<TOKEN end_char="2582" id="token-20-12" morph="none" pos="word" start_char="2579">toll</TOKEN>
<TOKEN end_char="2583" id="token-20-13" morph="none" pos="punct" start_char="2583">.</TOKEN>
</SEG>
<SEG end_char="2605" id="segment-21" start_char="2586">
<ORIGINAL_TEXT>So what's the truth?</ORIGINAL_TEXT>
<TOKEN end_char="2587" id="token-21-0" morph="none" pos="word" start_char="2586">So</TOKEN>
<TOKEN end_char="2594" id="token-21-1" morph="none" pos="word" start_char="2589">what's</TOKEN>
<TOKEN end_char="2598" id="token-21-2" morph="none" pos="word" start_char="2596">the</TOKEN>
<TOKEN end_char="2604" id="token-21-3" morph="none" pos="word" start_char="2600">truth</TOKEN>
<TOKEN end_char="2605" id="token-21-4" morph="none" pos="punct" start_char="2605">?</TOKEN>
</SEG>
<SEG end_char="2692" id="segment-22" start_char="2609">
<ORIGINAL_TEXT>It is true that data on windy.com shows extremely high levels of SO2 in both cities.</ORIGINAL_TEXT>
<TOKEN end_char="2610" id="token-22-0" morph="none" pos="word" start_char="2609">It</TOKEN>
<TOKEN end_char="2613" id="token-22-1" morph="none" pos="word" start_char="2612">is</TOKEN>
<TOKEN end_char="2618" id="token-22-2" morph="none" pos="word" start_char="2615">true</TOKEN>
<TOKEN end_char="2623" id="token-22-3" morph="none" pos="word" start_char="2620">that</TOKEN>
<TOKEN end_char="2628" id="token-22-4" morph="none" pos="word" start_char="2625">data</TOKEN>
<TOKEN end_char="2631" id="token-22-5" morph="none" pos="word" start_char="2630">on</TOKEN>
<TOKEN end_char="2641" id="token-22-6" morph="none" pos="unknown" start_char="2633">windy.com</TOKEN>
<TOKEN end_char="2647" id="token-22-7" morph="none" pos="word" start_char="2643">shows</TOKEN>
<TOKEN end_char="2657" id="token-22-8" morph="none" pos="word" start_char="2649">extremely</TOKEN>
<TOKEN end_char="2662" id="token-22-9" morph="none" pos="word" start_char="2659">high</TOKEN>
<TOKEN end_char="2669" id="token-22-10" morph="none" pos="word" start_char="2664">levels</TOKEN>
<TOKEN end_char="2672" id="token-22-11" morph="none" pos="word" start_char="2671">of</TOKEN>
<TOKEN end_char="2676" id="token-22-12" morph="none" pos="word" start_char="2674">SO2</TOKEN>
<TOKEN end_char="2679" id="token-22-13" morph="none" pos="word" start_char="2678">in</TOKEN>
<TOKEN end_char="2684" id="token-22-14" morph="none" pos="word" start_char="2681">both</TOKEN>
<TOKEN end_char="2691" id="token-22-15" morph="none" pos="word" start_char="2686">cities</TOKEN>
<TOKEN end_char="2692" id="token-22-16" morph="none" pos="punct" start_char="2692">.</TOKEN>
</SEG>
<SEG end_char="2815" id="segment-23" start_char="2695">
<ORIGINAL_TEXT>But little or nothing allows us to establish a relationship with the alleged unbridled activity at the city's crematoria.</ORIGINAL_TEXT>
<TOKEN end_char="2697" id="token-23-0" morph="none" pos="word" start_char="2695">But</TOKEN>
<TOKEN end_char="2704" id="token-23-1" morph="none" pos="word" start_char="2699">little</TOKEN>
<TOKEN end_char="2707" id="token-23-2" morph="none" pos="word" start_char="2706">or</TOKEN>
<TOKEN end_char="2715" id="token-23-3" morph="none" pos="word" start_char="2709">nothing</TOKEN>
<TOKEN end_char="2722" id="token-23-4" morph="none" pos="word" start_char="2717">allows</TOKEN>
<TOKEN end_char="2725" id="token-23-5" morph="none" pos="word" start_char="2724">us</TOKEN>
<TOKEN end_char="2728" id="token-23-6" morph="none" pos="word" start_char="2727">to</TOKEN>
<TOKEN end_char="2738" id="token-23-7" morph="none" pos="word" start_char="2730">establish</TOKEN>
<TOKEN end_char="2740" id="token-23-8" morph="none" pos="word" start_char="2740">a</TOKEN>
<TOKEN end_char="2753" id="token-23-9" morph="none" pos="word" start_char="2742">relationship</TOKEN>
<TOKEN end_char="2758" id="token-23-10" morph="none" pos="word" start_char="2755">with</TOKEN>
<TOKEN end_char="2762" id="token-23-11" morph="none" pos="word" start_char="2760">the</TOKEN>
<TOKEN end_char="2770" id="token-23-12" morph="none" pos="word" start_char="2764">alleged</TOKEN>
<TOKEN end_char="2780" id="token-23-13" morph="none" pos="word" start_char="2772">unbridled</TOKEN>
<TOKEN end_char="2789" id="token-23-14" morph="none" pos="word" start_char="2782">activity</TOKEN>
<TOKEN end_char="2792" id="token-23-15" morph="none" pos="word" start_char="2791">at</TOKEN>
<TOKEN end_char="2796" id="token-23-16" morph="none" pos="word" start_char="2794">the</TOKEN>
<TOKEN end_char="2803" id="token-23-17" morph="none" pos="word" start_char="2798">city's</TOKEN>
<TOKEN end_char="2814" id="token-23-18" morph="none" pos="word" start_char="2805">crematoria</TOKEN>
<TOKEN end_char="2815" id="token-23-19" morph="none" pos="punct" start_char="2815">.</TOKEN>
</SEG>
<SEG end_char="2866" id="segment-24" start_char="2818">
<ORIGINAL_TEXT>Sulfur dioxide is naturally emitted by volcanoes.</ORIGINAL_TEXT>
<TOKEN end_char="2823" id="token-24-0" morph="none" pos="word" start_char="2818">Sulfur</TOKEN>
<TOKEN end_char="2831" id="token-24-1" morph="none" pos="word" start_char="2825">dioxide</TOKEN>
<TOKEN end_char="2834" id="token-24-2" morph="none" pos="word" start_char="2833">is</TOKEN>
<TOKEN end_char="2844" id="token-24-3" morph="none" pos="word" start_char="2836">naturally</TOKEN>
<TOKEN end_char="2852" id="token-24-4" morph="none" pos="word" start_char="2846">emitted</TOKEN>
<TOKEN end_char="2855" id="token-24-5" morph="none" pos="word" start_char="2854">by</TOKEN>
<TOKEN end_char="2865" id="token-24-6" morph="none" pos="word" start_char="2857">volcanoes</TOKEN>
<TOKEN end_char="2866" id="token-24-7" morph="none" pos="punct" start_char="2866">.</TOKEN>
</SEG>
<SEG end_char="3117" id="segment-25" start_char="2868">
<ORIGINAL_TEXT>According to the WHO, the main human source of SO2 emissions is the combustion of sulphur-containing fossils used for domestic heating, electricity generation and motor vehicles as well as the burning of waste and the decomposition of organic matter.</ORIGINAL_TEXT>
<TOKEN end_char="2876" id="token-25-0" morph="none" pos="word" start_char="2868">According</TOKEN>
<TOKEN end_char="2879" id="token-25-1" morph="none" pos="word" start_char="2878">to</TOKEN>
<TOKEN end_char="2883" id="token-25-2" morph="none" pos="word" start_char="2881">the</TOKEN>
<TOKEN end_char="2887" id="token-25-3" morph="none" pos="word" start_char="2885">WHO</TOKEN>
<TOKEN end_char="2888" id="token-25-4" morph="none" pos="punct" start_char="2888">,</TOKEN>
<TOKEN end_char="2892" id="token-25-5" morph="none" pos="word" start_char="2890">the</TOKEN>
<TOKEN end_char="2897" id="token-25-6" morph="none" pos="word" start_char="2894">main</TOKEN>
<TOKEN end_char="2903" id="token-25-7" morph="none" pos="word" start_char="2899">human</TOKEN>
<TOKEN end_char="2910" id="token-25-8" morph="none" pos="word" start_char="2905">source</TOKEN>
<TOKEN end_char="2913" id="token-25-9" morph="none" pos="word" start_char="2912">of</TOKEN>
<TOKEN end_char="2917" id="token-25-10" morph="none" pos="word" start_char="2915">SO2</TOKEN>
<TOKEN end_char="2927" id="token-25-11" morph="none" pos="word" start_char="2919">emissions</TOKEN>
<TOKEN end_char="2930" id="token-25-12" morph="none" pos="word" start_char="2929">is</TOKEN>
<TOKEN end_char="2934" id="token-25-13" morph="none" pos="word" start_char="2932">the</TOKEN>
<TOKEN end_char="2945" id="token-25-14" morph="none" pos="word" start_char="2936">combustion</TOKEN>
<TOKEN end_char="2948" id="token-25-15" morph="none" pos="word" start_char="2947">of</TOKEN>
<TOKEN end_char="2967" id="token-25-16" morph="none" pos="unknown" start_char="2950">sulphur-containing</TOKEN>
<TOKEN end_char="2975" id="token-25-17" morph="none" pos="word" start_char="2969">fossils</TOKEN>
<TOKEN end_char="2980" id="token-25-18" morph="none" pos="word" start_char="2977">used</TOKEN>
<TOKEN end_char="2984" id="token-25-19" morph="none" pos="word" start_char="2982">for</TOKEN>
<TOKEN end_char="2993" id="token-25-20" morph="none" pos="word" start_char="2986">domestic</TOKEN>
<TOKEN end_char="3001" id="token-25-21" morph="none" pos="word" start_char="2995">heating</TOKEN>
<TOKEN end_char="3002" id="token-25-22" morph="none" pos="punct" start_char="3002">,</TOKEN>
<TOKEN end_char="3014" id="token-25-23" morph="none" pos="word" start_char="3004">electricity</TOKEN>
<TOKEN end_char="3025" id="token-25-24" morph="none" pos="word" start_char="3016">generation</TOKEN>
<TOKEN end_char="3029" id="token-25-25" morph="none" pos="word" start_char="3027">and</TOKEN>
<TOKEN end_char="3035" id="token-25-26" morph="none" pos="word" start_char="3031">motor</TOKEN>
<TOKEN end_char="3044" id="token-25-27" morph="none" pos="word" start_char="3037">vehicles</TOKEN>
<TOKEN end_char="3047" id="token-25-28" morph="none" pos="word" start_char="3046">as</TOKEN>
<TOKEN end_char="3052" id="token-25-29" morph="none" pos="word" start_char="3049">well</TOKEN>
<TOKEN end_char="3055" id="token-25-30" morph="none" pos="word" start_char="3054">as</TOKEN>
<TOKEN end_char="3059" id="token-25-31" morph="none" pos="word" start_char="3057">the</TOKEN>
<TOKEN end_char="3067" id="token-25-32" morph="none" pos="word" start_char="3061">burning</TOKEN>
<TOKEN end_char="3070" id="token-25-33" morph="none" pos="word" start_char="3069">of</TOKEN>
<TOKEN end_char="3076" id="token-25-34" morph="none" pos="word" start_char="3072">waste</TOKEN>
<TOKEN end_char="3080" id="token-25-35" morph="none" pos="word" start_char="3078">and</TOKEN>
<TOKEN end_char="3084" id="token-25-36" morph="none" pos="word" start_char="3082">the</TOKEN>
<TOKEN end_char="3098" id="token-25-37" morph="none" pos="word" start_char="3086">decomposition</TOKEN>
<TOKEN end_char="3101" id="token-25-38" morph="none" pos="word" start_char="3100">of</TOKEN>
<TOKEN end_char="3109" id="token-25-39" morph="none" pos="word" start_char="3103">organic</TOKEN>
<TOKEN end_char="3116" id="token-25-40" morph="none" pos="word" start_char="3111">matter</TOKEN>
<TOKEN end_char="3117" id="token-25-41" morph="none" pos="punct" start_char="3117">.</TOKEN>
</SEG>
<SEG end_char="3173" id="segment-26" start_char="3120">
<ORIGINAL_TEXT>Models used for forecasts are not "satellite measures"</ORIGINAL_TEXT>
<TOKEN end_char="3125" id="token-26-0" morph="none" pos="word" start_char="3120">Models</TOKEN>
<TOKEN end_char="3130" id="token-26-1" morph="none" pos="word" start_char="3127">used</TOKEN>
<TOKEN end_char="3134" id="token-26-2" morph="none" pos="word" start_char="3132">for</TOKEN>
<TOKEN end_char="3144" id="token-26-3" morph="none" pos="word" start_char="3136">forecasts</TOKEN>
<TOKEN end_char="3148" id="token-26-4" morph="none" pos="word" start_char="3146">are</TOKEN>
<TOKEN end_char="3152" id="token-26-5" morph="none" pos="word" start_char="3150">not</TOKEN>
<TOKEN end_char="3154" id="token-26-6" morph="none" pos="punct" start_char="3154">"</TOKEN>
<TOKEN end_char="3163" id="token-26-7" morph="none" pos="word" start_char="3155">satellite</TOKEN>
<TOKEN end_char="3172" id="token-26-8" morph="none" pos="word" start_char="3165">measures</TOKEN>
<TOKEN end_char="3173" id="token-26-9" morph="none" pos="punct" start_char="3173">"</TOKEN>
</SEG>
<SEG end_char="3288" id="segment-27" start_char="3177">
<ORIGINAL_TEXT>The data on windy.com is not based on satellite images, as claimed by the Sun tabloid newspaper in its headline.</ORIGINAL_TEXT>
<TOKEN end_char="3179" id="token-27-0" morph="none" pos="word" start_char="3177">The</TOKEN>
<TOKEN end_char="3184" id="token-27-1" morph="none" pos="word" start_char="3181">data</TOKEN>
<TOKEN end_char="3187" id="token-27-2" morph="none" pos="word" start_char="3186">on</TOKEN>
<TOKEN end_char="3197" id="token-27-3" morph="none" pos="unknown" start_char="3189">windy.com</TOKEN>
<TOKEN end_char="3200" id="token-27-4" morph="none" pos="word" start_char="3199">is</TOKEN>
<TOKEN end_char="3204" id="token-27-5" morph="none" pos="word" start_char="3202">not</TOKEN>
<TOKEN end_char="3210" id="token-27-6" morph="none" pos="word" start_char="3206">based</TOKEN>
<TOKEN end_char="3213" id="token-27-7" morph="none" pos="word" start_char="3212">on</TOKEN>
<TOKEN end_char="3223" id="token-27-8" morph="none" pos="word" start_char="3215">satellite</TOKEN>
<TOKEN end_char="3230" id="token-27-9" morph="none" pos="word" start_char="3225">images</TOKEN>
<TOKEN end_char="3231" id="token-27-10" morph="none" pos="punct" start_char="3231">,</TOKEN>
<TOKEN end_char="3234" id="token-27-11" morph="none" pos="word" start_char="3233">as</TOKEN>
<TOKEN end_char="3242" id="token-27-12" morph="none" pos="word" start_char="3236">claimed</TOKEN>
<TOKEN end_char="3245" id="token-27-13" morph="none" pos="word" start_char="3244">by</TOKEN>
<TOKEN end_char="3249" id="token-27-14" morph="none" pos="word" start_char="3247">the</TOKEN>
<TOKEN end_char="3253" id="token-27-15" morph="none" pos="word" start_char="3251">Sun</TOKEN>
<TOKEN end_char="3261" id="token-27-16" morph="none" pos="word" start_char="3255">tabloid</TOKEN>
<TOKEN end_char="3271" id="token-27-17" morph="none" pos="word" start_char="3263">newspaper</TOKEN>
<TOKEN end_char="3274" id="token-27-18" morph="none" pos="word" start_char="3273">in</TOKEN>
<TOKEN end_char="3278" id="token-27-19" morph="none" pos="word" start_char="3276">its</TOKEN>
<TOKEN end_char="3287" id="token-27-20" morph="none" pos="word" start_char="3280">headline</TOKEN>
<TOKEN end_char="3288" id="token-27-21" morph="none" pos="punct" start_char="3288">.</TOKEN>
</SEG>
<SEG end_char="3459" id="segment-28" start_char="3291">
<ORIGINAL_TEXT>Instead, they are based upon forecasts based on NASA's GEOS-5 model, which, according to the US agency itself, often give significantly higher results than observations.</ORIGINAL_TEXT>
<TOKEN end_char="3297" id="token-28-0" morph="none" pos="word" start_char="3291">Instead</TOKEN>
<TOKEN end_char="3298" id="token-28-1" morph="none" pos="punct" start_char="3298">,</TOKEN>
<TOKEN end_char="3303" id="token-28-2" morph="none" pos="word" start_char="3300">they</TOKEN>
<TOKEN end_char="3307" id="token-28-3" morph="none" pos="word" start_char="3305">are</TOKEN>
<TOKEN end_char="3313" id="token-28-4" morph="none" pos="word" start_char="3309">based</TOKEN>
<TOKEN end_char="3318" id="token-28-5" morph="none" pos="word" start_char="3315">upon</TOKEN>
<TOKEN end_char="3328" id="token-28-6" morph="none" pos="word" start_char="3320">forecasts</TOKEN>
<TOKEN end_char="3334" id="token-28-7" morph="none" pos="word" start_char="3330">based</TOKEN>
<TOKEN end_char="3337" id="token-28-8" morph="none" pos="word" start_char="3336">on</TOKEN>
<TOKEN end_char="3344" id="token-28-9" morph="none" pos="word" start_char="3339">NASA's</TOKEN>
<TOKEN end_char="3351" id="token-28-10" morph="none" pos="unknown" start_char="3346">GEOS-5</TOKEN>
<TOKEN end_char="3357" id="token-28-11" morph="none" pos="word" start_char="3353">model</TOKEN>
<TOKEN end_char="3358" id="token-28-12" morph="none" pos="punct" start_char="3358">,</TOKEN>
<TOKEN end_char="3364" id="token-28-13" morph="none" pos="word" start_char="3360">which</TOKEN>
<TOKEN end_char="3365" id="token-28-14" morph="none" pos="punct" start_char="3365">,</TOKEN>
<TOKEN end_char="3375" id="token-28-15" morph="none" pos="word" start_char="3367">according</TOKEN>
<TOKEN end_char="3378" id="token-28-16" morph="none" pos="word" start_char="3377">to</TOKEN>
<TOKEN end_char="3382" id="token-28-17" morph="none" pos="word" start_char="3380">the</TOKEN>
<TOKEN end_char="3385" id="token-28-18" morph="none" pos="word" start_char="3384">US</TOKEN>
<TOKEN end_char="3392" id="token-28-19" morph="none" pos="word" start_char="3387">agency</TOKEN>
<TOKEN end_char="3399" id="token-28-20" morph="none" pos="word" start_char="3394">itself</TOKEN>
<TOKEN end_char="3400" id="token-28-21" morph="none" pos="punct" start_char="3400">,</TOKEN>
<TOKEN end_char="3406" id="token-28-22" morph="none" pos="word" start_char="3402">often</TOKEN>
<TOKEN end_char="3411" id="token-28-23" morph="none" pos="word" start_char="3408">give</TOKEN>
<TOKEN end_char="3425" id="token-28-24" morph="none" pos="word" start_char="3413">significantly</TOKEN>
<TOKEN end_char="3432" id="token-28-25" morph="none" pos="word" start_char="3427">higher</TOKEN>
<TOKEN end_char="3440" id="token-28-26" morph="none" pos="word" start_char="3434">results</TOKEN>
<TOKEN end_char="3445" id="token-28-27" morph="none" pos="word" start_char="3442">than</TOKEN>
<TOKEN end_char="3458" id="token-28-28" morph="none" pos="word" start_char="3447">observations</TOKEN>
<TOKEN end_char="3459" id="token-28-29" morph="none" pos="punct" start_char="3459">.</TOKEN>
</SEG>
<SEG end_char="3539" id="segment-29" start_char="3462">
<ORIGINAL_TEXT>The models are not updated to take into account episodes like the coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="3464" id="token-29-0" morph="none" pos="word" start_char="3462">The</TOKEN>
<TOKEN end_char="3471" id="token-29-1" morph="none" pos="word" start_char="3466">models</TOKEN>
<TOKEN end_char="3475" id="token-29-2" morph="none" pos="word" start_char="3473">are</TOKEN>
<TOKEN end_char="3479" id="token-29-3" morph="none" pos="word" start_char="3477">not</TOKEN>
<TOKEN end_char="3487" id="token-29-4" morph="none" pos="word" start_char="3481">updated</TOKEN>
<TOKEN end_char="3490" id="token-29-5" morph="none" pos="word" start_char="3489">to</TOKEN>
<TOKEN end_char="3495" id="token-29-6" morph="none" pos="word" start_char="3492">take</TOKEN>
<TOKEN end_char="3500" id="token-29-7" morph="none" pos="word" start_char="3497">into</TOKEN>
<TOKEN end_char="3508" id="token-29-8" morph="none" pos="word" start_char="3502">account</TOKEN>
<TOKEN end_char="3517" id="token-29-9" morph="none" pos="word" start_char="3510">episodes</TOKEN>
<TOKEN end_char="3522" id="token-29-10" morph="none" pos="word" start_char="3519">like</TOKEN>
<TOKEN end_char="3526" id="token-29-11" morph="none" pos="word" start_char="3524">the</TOKEN>
<TOKEN end_char="3538" id="token-29-12" morph="none" pos="word" start_char="3528">coronavirus</TOKEN>
<TOKEN end_char="3539" id="token-29-13" morph="none" pos="punct" start_char="3539">.</TOKEN>
</SEG>
<SEG end_char="3667" id="segment-30" start_char="3541">
<ORIGINAL_TEXT>They're based on "emissions inventories", for example, the probability of pollution levels based on known sources of emissions.</ORIGINAL_TEXT>
<TOKEN end_char="3547" id="token-30-0" morph="none" pos="word" start_char="3541">They're</TOKEN>
<TOKEN end_char="3553" id="token-30-1" morph="none" pos="word" start_char="3549">based</TOKEN>
<TOKEN end_char="3556" id="token-30-2" morph="none" pos="word" start_char="3555">on</TOKEN>
<TOKEN end_char="3558" id="token-30-3" morph="none" pos="punct" start_char="3558">"</TOKEN>
<TOKEN end_char="3567" id="token-30-4" morph="none" pos="word" start_char="3559">emissions</TOKEN>
<TOKEN end_char="3579" id="token-30-5" morph="none" pos="word" start_char="3569">inventories</TOKEN>
<TOKEN end_char="3581" id="token-30-6" morph="none" pos="punct" start_char="3580">",</TOKEN>
<TOKEN end_char="3585" id="token-30-7" morph="none" pos="word" start_char="3583">for</TOKEN>
<TOKEN end_char="3593" id="token-30-8" morph="none" pos="word" start_char="3587">example</TOKEN>
<TOKEN end_char="3594" id="token-30-9" morph="none" pos="punct" start_char="3594">,</TOKEN>
<TOKEN end_char="3598" id="token-30-10" morph="none" pos="word" start_char="3596">the</TOKEN>
<TOKEN end_char="3610" id="token-30-11" morph="none" pos="word" start_char="3600">probability</TOKEN>
<TOKEN end_char="3613" id="token-30-12" morph="none" pos="word" start_char="3612">of</TOKEN>
<TOKEN end_char="3623" id="token-30-13" morph="none" pos="word" start_char="3615">pollution</TOKEN>
<TOKEN end_char="3630" id="token-30-14" morph="none" pos="word" start_char="3625">levels</TOKEN>
<TOKEN end_char="3636" id="token-30-15" morph="none" pos="word" start_char="3632">based</TOKEN>
<TOKEN end_char="3639" id="token-30-16" morph="none" pos="word" start_char="3638">on</TOKEN>
<TOKEN end_char="3645" id="token-30-17" morph="none" pos="word" start_char="3641">known</TOKEN>
<TOKEN end_char="3653" id="token-30-18" morph="none" pos="word" start_char="3647">sources</TOKEN>
<TOKEN end_char="3656" id="token-30-19" morph="none" pos="word" start_char="3655">of</TOKEN>
<TOKEN end_char="3666" id="token-30-20" morph="none" pos="word" start_char="3658">emissions</TOKEN>
<TOKEN end_char="3667" id="token-30-21" morph="none" pos="punct" start_char="3667">.</TOKEN>
</SEG>
<SEG end_char="3828" id="segment-31" start_char="3670">
<ORIGINAL_TEXT>They take into account the usual sources of emissions of an area: factories, power and heating plants, and cross-references them with meteorological variables.</ORIGINAL_TEXT>
<TOKEN end_char="3673" id="token-31-0" morph="none" pos="word" start_char="3670">They</TOKEN>
<TOKEN end_char="3678" id="token-31-1" morph="none" pos="word" start_char="3675">take</TOKEN>
<TOKEN end_char="3683" id="token-31-2" morph="none" pos="word" start_char="3680">into</TOKEN>
<TOKEN end_char="3691" id="token-31-3" morph="none" pos="word" start_char="3685">account</TOKEN>
<TOKEN end_char="3695" id="token-31-4" morph="none" pos="word" start_char="3693">the</TOKEN>
<TOKEN end_char="3701" id="token-31-5" morph="none" pos="word" start_char="3697">usual</TOKEN>
<TOKEN end_char="3709" id="token-31-6" morph="none" pos="word" start_char="3703">sources</TOKEN>
<TOKEN end_char="3712" id="token-31-7" morph="none" pos="word" start_char="3711">of</TOKEN>
<TOKEN end_char="3722" id="token-31-8" morph="none" pos="word" start_char="3714">emissions</TOKEN>
<TOKEN end_char="3725" id="token-31-9" morph="none" pos="word" start_char="3724">of</TOKEN>
<TOKEN end_char="3728" id="token-31-10" morph="none" pos="word" start_char="3727">an</TOKEN>
<TOKEN end_char="3733" id="token-31-11" morph="none" pos="word" start_char="3730">area</TOKEN>
<TOKEN end_char="3734" id="token-31-12" morph="none" pos="punct" start_char="3734">:</TOKEN>
<TOKEN end_char="3744" id="token-31-13" morph="none" pos="word" start_char="3736">factories</TOKEN>
<TOKEN end_char="3745" id="token-31-14" morph="none" pos="punct" start_char="3745">,</TOKEN>
<TOKEN end_char="3751" id="token-31-15" morph="none" pos="word" start_char="3747">power</TOKEN>
<TOKEN end_char="3755" id="token-31-16" morph="none" pos="word" start_char="3753">and</TOKEN>
<TOKEN end_char="3763" id="token-31-17" morph="none" pos="word" start_char="3757">heating</TOKEN>
<TOKEN end_char="3770" id="token-31-18" morph="none" pos="word" start_char="3765">plants</TOKEN>
<TOKEN end_char="3771" id="token-31-19" morph="none" pos="punct" start_char="3771">,</TOKEN>
<TOKEN end_char="3775" id="token-31-20" morph="none" pos="word" start_char="3773">and</TOKEN>
<TOKEN end_char="3792" id="token-31-21" morph="none" pos="unknown" start_char="3777">cross-references</TOKEN>
<TOKEN end_char="3797" id="token-31-22" morph="none" pos="word" start_char="3794">them</TOKEN>
<TOKEN end_char="3802" id="token-31-23" morph="none" pos="word" start_char="3799">with</TOKEN>
<TOKEN end_char="3817" id="token-31-24" morph="none" pos="word" start_char="3804">meteorological</TOKEN>
<TOKEN end_char="3827" id="token-31-25" morph="none" pos="word" start_char="3819">variables</TOKEN>
<TOKEN end_char="3828" id="token-31-26" morph="none" pos="punct" start_char="3828">.</TOKEN>
</SEG>
<SEG end_char="3927" id="segment-32" start_char="3830">
<ORIGINAL_TEXT>In other words, NASA would have had to introduce a "burning human bodies in crematoria" parameter.</ORIGINAL_TEXT>
<TOKEN end_char="3831" id="token-32-0" morph="none" pos="word" start_char="3830">In</TOKEN>
<TOKEN end_char="3837" id="token-32-1" morph="none" pos="word" start_char="3833">other</TOKEN>
<TOKEN end_char="3843" id="token-32-2" morph="none" pos="word" start_char="3839">words</TOKEN>
<TOKEN end_char="3844" id="token-32-3" morph="none" pos="punct" start_char="3844">,</TOKEN>
<TOKEN end_char="3849" id="token-32-4" morph="none" pos="word" start_char="3846">NASA</TOKEN>
<TOKEN end_char="3855" id="token-32-5" morph="none" pos="word" start_char="3851">would</TOKEN>
<TOKEN end_char="3860" id="token-32-6" morph="none" pos="word" start_char="3857">have</TOKEN>
<TOKEN end_char="3864" id="token-32-7" morph="none" pos="word" start_char="3862">had</TOKEN>
<TOKEN end_char="3867" id="token-32-8" morph="none" pos="word" start_char="3866">to</TOKEN>
<TOKEN end_char="3877" id="token-32-9" morph="none" pos="word" start_char="3869">introduce</TOKEN>
<TOKEN end_char="3879" id="token-32-10" morph="none" pos="word" start_char="3879">a</TOKEN>
<TOKEN end_char="3881" id="token-32-11" morph="none" pos="punct" start_char="3881">"</TOKEN>
<TOKEN end_char="3888" id="token-32-12" morph="none" pos="word" start_char="3882">burning</TOKEN>
<TOKEN end_char="3894" id="token-32-13" morph="none" pos="word" start_char="3890">human</TOKEN>
<TOKEN end_char="3901" id="token-32-14" morph="none" pos="word" start_char="3896">bodies</TOKEN>
<TOKEN end_char="3904" id="token-32-15" morph="none" pos="word" start_char="3903">in</TOKEN>
<TOKEN end_char="3915" id="token-32-16" morph="none" pos="word" start_char="3906">crematoria</TOKEN>
<TOKEN end_char="3916" id="token-32-17" morph="none" pos="punct" start_char="3916">"</TOKEN>
<TOKEN end_char="3926" id="token-32-18" morph="none" pos="word" start_char="3918">parameter</TOKEN>
<TOKEN end_char="3927" id="token-32-19" morph="none" pos="punct" start_char="3927">.</TOKEN>
</SEG>
<SEG end_char="3950" id="segment-33" start_char="3929">
<ORIGINAL_TEXT>This is very unlikely.</ORIGINAL_TEXT>
<TOKEN end_char="3932" id="token-33-0" morph="none" pos="word" start_char="3929">This</TOKEN>
<TOKEN end_char="3935" id="token-33-1" morph="none" pos="word" start_char="3934">is</TOKEN>
<TOKEN end_char="3940" id="token-33-2" morph="none" pos="word" start_char="3937">very</TOKEN>
<TOKEN end_char="3949" id="token-33-3" morph="none" pos="word" start_char="3942">unlikely</TOKEN>
<TOKEN end_char="3950" id="token-33-4" morph="none" pos="punct" start_char="3950">.</TOKEN>
</SEG>
<SEG end_char="4017" id="segment-34" start_char="3953">
<ORIGINAL_TEXT>NASA has not responded to Euronews' requests for comment on this.</ORIGINAL_TEXT>
<TOKEN end_char="3956" id="token-34-0" morph="none" pos="word" start_char="3953">NASA</TOKEN>
<TOKEN end_char="3960" id="token-34-1" morph="none" pos="word" start_char="3958">has</TOKEN>
<TOKEN end_char="3964" id="token-34-2" morph="none" pos="word" start_char="3962">not</TOKEN>
<TOKEN end_char="3974" id="token-34-3" morph="none" pos="word" start_char="3966">responded</TOKEN>
<TOKEN end_char="3977" id="token-34-4" morph="none" pos="word" start_char="3976">to</TOKEN>
<TOKEN end_char="3986" id="token-34-5" morph="none" pos="word" start_char="3979">Euronews</TOKEN>
<TOKEN end_char="3987" id="token-34-6" morph="none" pos="punct" start_char="3987">'</TOKEN>
<TOKEN end_char="3996" id="token-34-7" morph="none" pos="word" start_char="3989">requests</TOKEN>
<TOKEN end_char="4000" id="token-34-8" morph="none" pos="word" start_char="3998">for</TOKEN>
<TOKEN end_char="4008" id="token-34-9" morph="none" pos="word" start_char="4002">comment</TOKEN>
<TOKEN end_char="4011" id="token-34-10" morph="none" pos="word" start_char="4010">on</TOKEN>
<TOKEN end_char="4016" id="token-34-11" morph="none" pos="word" start_char="4013">this</TOKEN>
<TOKEN end_char="4017" id="token-34-12" morph="none" pos="punct" start_char="4017">.</TOKEN>
</SEG>
<SEG end_char="4178" id="segment-35" start_char="4020">
<ORIGINAL_TEXT>This type of forecast uses satellite data, but, in general, satellites are not able to detect small sources of sulphur dioxide such as factories or crematoria.</ORIGINAL_TEXT>
<TOKEN end_char="4023" id="token-35-0" morph="none" pos="word" start_char="4020">This</TOKEN>
<TOKEN end_char="4028" id="token-35-1" morph="none" pos="word" start_char="4025">type</TOKEN>
<TOKEN end_char="4031" id="token-35-2" morph="none" pos="word" start_char="4030">of</TOKEN>
<TOKEN end_char="4040" id="token-35-3" morph="none" pos="word" start_char="4033">forecast</TOKEN>
<TOKEN end_char="4045" id="token-35-4" morph="none" pos="word" start_char="4042">uses</TOKEN>
<TOKEN end_char="4055" id="token-35-5" morph="none" pos="word" start_char="4047">satellite</TOKEN>
<TOKEN end_char="4060" id="token-35-6" morph="none" pos="word" start_char="4057">data</TOKEN>
<TOKEN end_char="4061" id="token-35-7" morph="none" pos="punct" start_char="4061">,</TOKEN>
<TOKEN end_char="4065" id="token-35-8" morph="none" pos="word" start_char="4063">but</TOKEN>
<TOKEN end_char="4066" id="token-35-9" morph="none" pos="punct" start_char="4066">,</TOKEN>
<TOKEN end_char="4069" id="token-35-10" morph="none" pos="word" start_char="4068">in</TOKEN>
<TOKEN end_char="4077" id="token-35-11" morph="none" pos="word" start_char="4071">general</TOKEN>
<TOKEN end_char="4078" id="token-35-12" morph="none" pos="punct" start_char="4078">,</TOKEN>
<TOKEN end_char="4089" id="token-35-13" morph="none" pos="word" start_char="4080">satellites</TOKEN>
<TOKEN end_char="4093" id="token-35-14" morph="none" pos="word" start_char="4091">are</TOKEN>
<TOKEN end_char="4097" id="token-35-15" morph="none" pos="word" start_char="4095">not</TOKEN>
<TOKEN end_char="4102" id="token-35-16" morph="none" pos="word" start_char="4099">able</TOKEN>
<TOKEN end_char="4105" id="token-35-17" morph="none" pos="word" start_char="4104">to</TOKEN>
<TOKEN end_char="4112" id="token-35-18" morph="none" pos="word" start_char="4107">detect</TOKEN>
<TOKEN end_char="4118" id="token-35-19" morph="none" pos="word" start_char="4114">small</TOKEN>
<TOKEN end_char="4126" id="token-35-20" morph="none" pos="word" start_char="4120">sources</TOKEN>
<TOKEN end_char="4129" id="token-35-21" morph="none" pos="word" start_char="4128">of</TOKEN>
<TOKEN end_char="4137" id="token-35-22" morph="none" pos="word" start_char="4131">sulphur</TOKEN>
<TOKEN end_char="4145" id="token-35-23" morph="none" pos="word" start_char="4139">dioxide</TOKEN>
<TOKEN end_char="4150" id="token-35-24" morph="none" pos="word" start_char="4147">such</TOKEN>
<TOKEN end_char="4153" id="token-35-25" morph="none" pos="word" start_char="4152">as</TOKEN>
<TOKEN end_char="4163" id="token-35-26" morph="none" pos="word" start_char="4155">factories</TOKEN>
<TOKEN end_char="4166" id="token-35-27" morph="none" pos="word" start_char="4165">or</TOKEN>
<TOKEN end_char="4177" id="token-35-28" morph="none" pos="word" start_char="4168">crematoria</TOKEN>
<TOKEN end_char="4178" id="token-35-29" morph="none" pos="punct" start_char="4178">.</TOKEN>
</SEG>
<SEG end_char="4256" id="segment-36" start_char="4180">
<ORIGINAL_TEXT>They do accurately measure more intense phenomena such as volcanic eruptions.</ORIGINAL_TEXT>
<TOKEN end_char="4183" id="token-36-0" morph="none" pos="word" start_char="4180">They</TOKEN>
<TOKEN end_char="4186" id="token-36-1" morph="none" pos="word" start_char="4185">do</TOKEN>
<TOKEN end_char="4197" id="token-36-2" morph="none" pos="word" start_char="4188">accurately</TOKEN>
<TOKEN end_char="4205" id="token-36-3" morph="none" pos="word" start_char="4199">measure</TOKEN>
<TOKEN end_char="4210" id="token-36-4" morph="none" pos="word" start_char="4207">more</TOKEN>
<TOKEN end_char="4218" id="token-36-5" morph="none" pos="word" start_char="4212">intense</TOKEN>
<TOKEN end_char="4228" id="token-36-6" morph="none" pos="word" start_char="4220">phenomena</TOKEN>
<TOKEN end_char="4233" id="token-36-7" morph="none" pos="word" start_char="4230">such</TOKEN>
<TOKEN end_char="4236" id="token-36-8" morph="none" pos="word" start_char="4235">as</TOKEN>
<TOKEN end_char="4245" id="token-36-9" morph="none" pos="word" start_char="4238">volcanic</TOKEN>
<TOKEN end_char="4255" id="token-36-10" morph="none" pos="word" start_char="4247">eruptions</TOKEN>
<TOKEN end_char="4256" id="token-36-11" morph="none" pos="punct" start_char="4256">.</TOKEN>
</SEG>
<SEG end_char="4371" id="segment-37" start_char="4259">
<ORIGINAL_TEXT>So, if there were an intense, unusual emissions activity due to crematoria, it wouldn't be shown on these models.</ORIGINAL_TEXT>
<TOKEN end_char="4260" id="token-37-0" morph="none" pos="word" start_char="4259">So</TOKEN>
<TOKEN end_char="4261" id="token-37-1" morph="none" pos="punct" start_char="4261">,</TOKEN>
<TOKEN end_char="4264" id="token-37-2" morph="none" pos="word" start_char="4263">if</TOKEN>
<TOKEN end_char="4270" id="token-37-3" morph="none" pos="word" start_char="4266">there</TOKEN>
<TOKEN end_char="4275" id="token-37-4" morph="none" pos="word" start_char="4272">were</TOKEN>
<TOKEN end_char="4278" id="token-37-5" morph="none" pos="word" start_char="4277">an</TOKEN>
<TOKEN end_char="4286" id="token-37-6" morph="none" pos="word" start_char="4280">intense</TOKEN>
<TOKEN end_char="4287" id="token-37-7" morph="none" pos="punct" start_char="4287">,</TOKEN>
<TOKEN end_char="4295" id="token-37-8" morph="none" pos="word" start_char="4289">unusual</TOKEN>
<TOKEN end_char="4305" id="token-37-9" morph="none" pos="word" start_char="4297">emissions</TOKEN>
<TOKEN end_char="4314" id="token-37-10" morph="none" pos="word" start_char="4307">activity</TOKEN>
<TOKEN end_char="4318" id="token-37-11" morph="none" pos="word" start_char="4316">due</TOKEN>
<TOKEN end_char="4321" id="token-37-12" morph="none" pos="word" start_char="4320">to</TOKEN>
<TOKEN end_char="4332" id="token-37-13" morph="none" pos="word" start_char="4323">crematoria</TOKEN>
<TOKEN end_char="4333" id="token-37-14" morph="none" pos="punct" start_char="4333">,</TOKEN>
<TOKEN end_char="4336" id="token-37-15" morph="none" pos="word" start_char="4335">it</TOKEN>
<TOKEN end_char="4345" id="token-37-16" morph="none" pos="word" start_char="4338">wouldn't</TOKEN>
<TOKEN end_char="4348" id="token-37-17" morph="none" pos="word" start_char="4347">be</TOKEN>
<TOKEN end_char="4354" id="token-37-18" morph="none" pos="word" start_char="4350">shown</TOKEN>
<TOKEN end_char="4357" id="token-37-19" morph="none" pos="word" start_char="4356">on</TOKEN>
<TOKEN end_char="4363" id="token-37-20" morph="none" pos="word" start_char="4359">these</TOKEN>
<TOKEN end_char="4370" id="token-37-21" morph="none" pos="word" start_char="4365">models</TOKEN>
<TOKEN end_char="4371" id="token-37-22" morph="none" pos="punct" start_char="4371">.</TOKEN>
</SEG>
<SEG end_char="4444" id="segment-38" start_char="4374">
<ORIGINAL_TEXT>Wuhan and Chongqing always have high levels of SO2 using the NASA model</ORIGINAL_TEXT>
<TOKEN end_char="4378" id="token-38-0" morph="none" pos="word" start_char="4374">Wuhan</TOKEN>
<TOKEN end_char="4382" id="token-38-1" morph="none" pos="word" start_char="4380">and</TOKEN>
<TOKEN end_char="4392" id="token-38-2" morph="none" pos="word" start_char="4384">Chongqing</TOKEN>
<TOKEN end_char="4399" id="token-38-3" morph="none" pos="word" start_char="4394">always</TOKEN>
<TOKEN end_char="4404" id="token-38-4" morph="none" pos="word" start_char="4401">have</TOKEN>
<TOKEN end_char="4409" id="token-38-5" morph="none" pos="word" start_char="4406">high</TOKEN>
<TOKEN end_char="4416" id="token-38-6" morph="none" pos="word" start_char="4411">levels</TOKEN>
<TOKEN end_char="4419" id="token-38-7" morph="none" pos="word" start_char="4418">of</TOKEN>
<TOKEN end_char="4423" id="token-38-8" morph="none" pos="word" start_char="4421">SO2</TOKEN>
<TOKEN end_char="4429" id="token-38-9" morph="none" pos="word" start_char="4425">using</TOKEN>
<TOKEN end_char="4433" id="token-38-10" morph="none" pos="word" start_char="4431">the</TOKEN>
<TOKEN end_char="4438" id="token-38-11" morph="none" pos="word" start_char="4435">NASA</TOKEN>
<TOKEN end_char="4444" id="token-38-12" morph="none" pos="word" start_char="4440">model</TOKEN>
</SEG>
<SEG end_char="4512" id="segment-39" start_char="4448">
<ORIGINAL_TEXT>The earth.nullschool application uses the same GEOS-5 NASA model.</ORIGINAL_TEXT>
<TOKEN end_char="4450" id="token-39-0" morph="none" pos="word" start_char="4448">The</TOKEN>
<TOKEN end_char="4467" id="token-39-1" morph="none" pos="unknown" start_char="4452">earth.nullschool</TOKEN>
<TOKEN end_char="4479" id="token-39-2" morph="none" pos="word" start_char="4469">application</TOKEN>
<TOKEN end_char="4484" id="token-39-3" morph="none" pos="word" start_char="4481">uses</TOKEN>
<TOKEN end_char="4488" id="token-39-4" morph="none" pos="word" start_char="4486">the</TOKEN>
<TOKEN end_char="4493" id="token-39-5" morph="none" pos="word" start_char="4490">same</TOKEN>
<TOKEN end_char="4500" id="token-39-6" morph="none" pos="unknown" start_char="4495">GEOS-5</TOKEN>
<TOKEN end_char="4505" id="token-39-7" morph="none" pos="word" start_char="4502">NASA</TOKEN>
<TOKEN end_char="4511" id="token-39-8" morph="none" pos="word" start_char="4507">model</TOKEN>
<TOKEN end_char="4512" id="token-39-9" morph="none" pos="punct" start_char="4512">.</TOKEN>
</SEG>
<SEG end_char="4552" id="segment-40" start_char="4514">
<ORIGINAL_TEXT>But it also has an archive of measures.</ORIGINAL_TEXT>
<TOKEN end_char="4516" id="token-40-0" morph="none" pos="word" start_char="4514">But</TOKEN>
<TOKEN end_char="4519" id="token-40-1" morph="none" pos="word" start_char="4518">it</TOKEN>
<TOKEN end_char="4524" id="token-40-2" morph="none" pos="word" start_char="4521">also</TOKEN>
<TOKEN end_char="4528" id="token-40-3" morph="none" pos="word" start_char="4526">has</TOKEN>
<TOKEN end_char="4531" id="token-40-4" morph="none" pos="word" start_char="4530">an</TOKEN>
<TOKEN end_char="4539" id="token-40-5" morph="none" pos="word" start_char="4533">archive</TOKEN>
<TOKEN end_char="4542" id="token-40-6" morph="none" pos="word" start_char="4541">of</TOKEN>
<TOKEN end_char="4551" id="token-40-7" morph="none" pos="word" start_char="4544">measures</TOKEN>
<TOKEN end_char="4552" id="token-40-8" morph="none" pos="punct" start_char="4552">.</TOKEN>
</SEG>
<SEG end_char="4729" id="segment-41" start_char="4554">
<ORIGINAL_TEXT>At random, we went to February 14, 2019 - long before the world knew about the existence of a new type of coronavirus - and obtained even more impressive values of 1,583 µg/m3.</ORIGINAL_TEXT>
<TOKEN end_char="4555" id="token-41-0" morph="none" pos="word" start_char="4554">At</TOKEN>
<TOKEN end_char="4562" id="token-41-1" morph="none" pos="word" start_char="4557">random</TOKEN>
<TOKEN end_char="4563" id="token-41-2" morph="none" pos="punct" start_char="4563">,</TOKEN>
<TOKEN end_char="4566" id="token-41-3" morph="none" pos="word" start_char="4565">we</TOKEN>
<TOKEN end_char="4571" id="token-41-4" morph="none" pos="word" start_char="4568">went</TOKEN>
<TOKEN end_char="4574" id="token-41-5" morph="none" pos="word" start_char="4573">to</TOKEN>
<TOKEN end_char="4583" id="token-41-6" morph="none" pos="word" start_char="4576">February</TOKEN>
<TOKEN end_char="4586" id="token-41-7" morph="none" pos="word" start_char="4585">14</TOKEN>
<TOKEN end_char="4587" id="token-41-8" morph="none" pos="punct" start_char="4587">,</TOKEN>
<TOKEN end_char="4592" id="token-41-9" morph="none" pos="word" start_char="4589">2019</TOKEN>
<TOKEN end_char="4594" id="token-41-10" morph="none" pos="punct" start_char="4594">-</TOKEN>
<TOKEN end_char="4599" id="token-41-11" morph="none" pos="word" start_char="4596">long</TOKEN>
<TOKEN end_char="4606" id="token-41-12" morph="none" pos="word" start_char="4601">before</TOKEN>
<TOKEN end_char="4610" id="token-41-13" morph="none" pos="word" start_char="4608">the</TOKEN>
<TOKEN end_char="4616" id="token-41-14" morph="none" pos="word" start_char="4612">world</TOKEN>
<TOKEN end_char="4621" id="token-41-15" morph="none" pos="word" start_char="4618">knew</TOKEN>
<TOKEN end_char="4627" id="token-41-16" morph="none" pos="word" start_char="4623">about</TOKEN>
<TOKEN end_char="4631" id="token-41-17" morph="none" pos="word" start_char="4629">the</TOKEN>
<TOKEN end_char="4641" id="token-41-18" morph="none" pos="word" start_char="4633">existence</TOKEN>
<TOKEN end_char="4644" id="token-41-19" morph="none" pos="word" start_char="4643">of</TOKEN>
<TOKEN end_char="4646" id="token-41-20" morph="none" pos="word" start_char="4646">a</TOKEN>
<TOKEN end_char="4650" id="token-41-21" morph="none" pos="word" start_char="4648">new</TOKEN>
<TOKEN end_char="4655" id="token-41-22" morph="none" pos="word" start_char="4652">type</TOKEN>
<TOKEN end_char="4658" id="token-41-23" morph="none" pos="word" start_char="4657">of</TOKEN>
<TOKEN end_char="4670" id="token-41-24" morph="none" pos="word" start_char="4660">coronavirus</TOKEN>
<TOKEN end_char="4672" id="token-41-25" morph="none" pos="punct" start_char="4672">-</TOKEN>
<TOKEN end_char="4676" id="token-41-26" morph="none" pos="word" start_char="4674">and</TOKEN>
<TOKEN end_char="4685" id="token-41-27" morph="none" pos="word" start_char="4678">obtained</TOKEN>
<TOKEN end_char="4690" id="token-41-28" morph="none" pos="word" start_char="4687">even</TOKEN>
<TOKEN end_char="4695" id="token-41-29" morph="none" pos="word" start_char="4692">more</TOKEN>
<TOKEN end_char="4706" id="token-41-30" morph="none" pos="word" start_char="4697">impressive</TOKEN>
<TOKEN end_char="4713" id="token-41-31" morph="none" pos="word" start_char="4708">values</TOKEN>
<TOKEN end_char="4716" id="token-41-32" morph="none" pos="word" start_char="4715">of</TOKEN>
<TOKEN end_char="4722" id="token-41-33" morph="none" pos="unknown" start_char="4718">1,583</TOKEN>
<TOKEN end_char="4728" id="token-41-34" morph="none" pos="unknown" start_char="4724">µg/m3</TOKEN>
<TOKEN end_char="4729" id="token-41-35" morph="none" pos="punct" start_char="4729">.</TOKEN>
</SEG>
<SEG end_char="4788" id="segment-42" start_char="4732">
<ORIGINAL_TEXT>The values change depending on where we place the cursor.</ORIGINAL_TEXT>
<TOKEN end_char="4734" id="token-42-0" morph="none" pos="word" start_char="4732">The</TOKEN>
<TOKEN end_char="4741" id="token-42-1" morph="none" pos="word" start_char="4736">values</TOKEN>
<TOKEN end_char="4748" id="token-42-2" morph="none" pos="word" start_char="4743">change</TOKEN>
<TOKEN end_char="4758" id="token-42-3" morph="none" pos="word" start_char="4750">depending</TOKEN>
<TOKEN end_char="4761" id="token-42-4" morph="none" pos="word" start_char="4760">on</TOKEN>
<TOKEN end_char="4767" id="token-42-5" morph="none" pos="word" start_char="4763">where</TOKEN>
<TOKEN end_char="4770" id="token-42-6" morph="none" pos="word" start_char="4769">we</TOKEN>
<TOKEN end_char="4776" id="token-42-7" morph="none" pos="word" start_char="4772">place</TOKEN>
<TOKEN end_char="4780" id="token-42-8" morph="none" pos="word" start_char="4778">the</TOKEN>
<TOKEN end_char="4787" id="token-42-9" morph="none" pos="word" start_char="4782">cursor</TOKEN>
<TOKEN end_char="4788" id="token-42-10" morph="none" pos="punct" start_char="4788">.</TOKEN>
</SEG>
<SEG end_char="4877" id="segment-43" start_char="4791">
<ORIGINAL_TEXT>Screenshot of the SO2 levels for Wuhan for February 14 2019 with levels of 1.583 µg/m3.</ORIGINAL_TEXT>
<TOKEN end_char="4800" id="token-43-0" morph="none" pos="word" start_char="4791">Screenshot</TOKEN>
<TOKEN end_char="4803" id="token-43-1" morph="none" pos="word" start_char="4802">of</TOKEN>
<TOKEN end_char="4807" id="token-43-2" morph="none" pos="word" start_char="4805">the</TOKEN>
<TOKEN end_char="4811" id="token-43-3" morph="none" pos="word" start_char="4809">SO2</TOKEN>
<TOKEN end_char="4818" id="token-43-4" morph="none" pos="word" start_char="4813">levels</TOKEN>
<TOKEN end_char="4822" id="token-43-5" morph="none" pos="word" start_char="4820">for</TOKEN>
<TOKEN end_char="4828" id="token-43-6" morph="none" pos="word" start_char="4824">Wuhan</TOKEN>
<TOKEN end_char="4832" id="token-43-7" morph="none" pos="word" start_char="4830">for</TOKEN>
<TOKEN end_char="4841" id="token-43-8" morph="none" pos="word" start_char="4834">February</TOKEN>
<TOKEN end_char="4844" id="token-43-9" morph="none" pos="word" start_char="4843">14</TOKEN>
<TOKEN end_char="4849" id="token-43-10" morph="none" pos="word" start_char="4846">2019</TOKEN>
<TOKEN end_char="4854" id="token-43-11" morph="none" pos="word" start_char="4851">with</TOKEN>
<TOKEN end_char="4861" id="token-43-12" morph="none" pos="word" start_char="4856">levels</TOKEN>
<TOKEN end_char="4864" id="token-43-13" morph="none" pos="word" start_char="4863">of</TOKEN>
<TOKEN end_char="4870" id="token-43-14" morph="none" pos="word" start_char="4866">1.583</TOKEN>
<TOKEN end_char="4876" id="token-43-15" morph="none" pos="unknown" start_char="4872">µg/m3</TOKEN>
<TOKEN end_char="4877" id="token-43-16" morph="none" pos="punct" start_char="4877">.</TOKEN>
</SEG>
<SEG end_char="4988" id="segment-44" start_char="4881">
<ORIGINAL_TEXT>The same goes for Chongqing, where, at random, we get levels of over 1,000 μg/m3 last year, or even in 2018.</ORIGINAL_TEXT>
<TOKEN end_char="4883" id="token-44-0" morph="none" pos="word" start_char="4881">The</TOKEN>
<TOKEN end_char="4888" id="token-44-1" morph="none" pos="word" start_char="4885">same</TOKEN>
<TOKEN end_char="4893" id="token-44-2" morph="none" pos="word" start_char="4890">goes</TOKEN>
<TOKEN end_char="4897" id="token-44-3" morph="none" pos="word" start_char="4895">for</TOKEN>
<TOKEN end_char="4907" id="token-44-4" morph="none" pos="word" start_char="4899">Chongqing</TOKEN>
<TOKEN end_char="4908" id="token-44-5" morph="none" pos="punct" start_char="4908">,</TOKEN>
<TOKEN end_char="4914" id="token-44-6" morph="none" pos="word" start_char="4910">where</TOKEN>
<TOKEN end_char="4915" id="token-44-7" morph="none" pos="punct" start_char="4915">,</TOKEN>
<TOKEN end_char="4918" id="token-44-8" morph="none" pos="word" start_char="4917">at</TOKEN>
<TOKEN end_char="4925" id="token-44-9" morph="none" pos="word" start_char="4920">random</TOKEN>
<TOKEN end_char="4926" id="token-44-10" morph="none" pos="punct" start_char="4926">,</TOKEN>
<TOKEN end_char="4929" id="token-44-11" morph="none" pos="word" start_char="4928">we</TOKEN>
<TOKEN end_char="4933" id="token-44-12" morph="none" pos="word" start_char="4931">get</TOKEN>
<TOKEN end_char="4940" id="token-44-13" morph="none" pos="word" start_char="4935">levels</TOKEN>
<TOKEN end_char="4943" id="token-44-14" morph="none" pos="word" start_char="4942">of</TOKEN>
<TOKEN end_char="4948" id="token-44-15" morph="none" pos="word" start_char="4945">over</TOKEN>
<TOKEN end_char="4954" id="token-44-16" morph="none" pos="unknown" start_char="4950">1,000</TOKEN>
<TOKEN end_char="4960" id="token-44-17" morph="none" pos="unknown" start_char="4956">μg/m3</TOKEN>
<TOKEN end_char="4965" id="token-44-18" morph="none" pos="word" start_char="4962">last</TOKEN>
<TOKEN end_char="4970" id="token-44-19" morph="none" pos="word" start_char="4967">year</TOKEN>
<TOKEN end_char="4971" id="token-44-20" morph="none" pos="punct" start_char="4971">,</TOKEN>
<TOKEN end_char="4974" id="token-44-21" morph="none" pos="word" start_char="4973">or</TOKEN>
<TOKEN end_char="4979" id="token-44-22" morph="none" pos="word" start_char="4976">even</TOKEN>
<TOKEN end_char="4982" id="token-44-23" morph="none" pos="word" start_char="4981">in</TOKEN>
<TOKEN end_char="4987" id="token-44-24" morph="none" pos="word" start_char="4984">2018</TOKEN>
<TOKEN end_char="4988" id="token-44-25" morph="none" pos="punct" start_char="4988">.</TOKEN>
</SEG>
<SEG end_char="5238" id="segment-45" start_char="4991">
<ORIGINAL_TEXT>This means the "forecasts" of these platforms are an interesting and useful indicator, and, certainly, Chongqing and Wuhan suffer from poor air quality, but this is approximative data to be taken into perspective, not a scientific measure or proof.</ORIGINAL_TEXT>
<TOKEN end_char="4994" id="token-45-0" morph="none" pos="word" start_char="4991">This</TOKEN>
<TOKEN end_char="5000" id="token-45-1" morph="none" pos="word" start_char="4996">means</TOKEN>
<TOKEN end_char="5004" id="token-45-2" morph="none" pos="word" start_char="5002">the</TOKEN>
<TOKEN end_char="5006" id="token-45-3" morph="none" pos="punct" start_char="5006">"</TOKEN>
<TOKEN end_char="5015" id="token-45-4" morph="none" pos="word" start_char="5007">forecasts</TOKEN>
<TOKEN end_char="5016" id="token-45-5" morph="none" pos="punct" start_char="5016">"</TOKEN>
<TOKEN end_char="5019" id="token-45-6" morph="none" pos="word" start_char="5018">of</TOKEN>
<TOKEN end_char="5025" id="token-45-7" morph="none" pos="word" start_char="5021">these</TOKEN>
<TOKEN end_char="5035" id="token-45-8" morph="none" pos="word" start_char="5027">platforms</TOKEN>
<TOKEN end_char="5039" id="token-45-9" morph="none" pos="word" start_char="5037">are</TOKEN>
<TOKEN end_char="5042" id="token-45-10" morph="none" pos="word" start_char="5041">an</TOKEN>
<TOKEN end_char="5054" id="token-45-11" morph="none" pos="word" start_char="5044">interesting</TOKEN>
<TOKEN end_char="5058" id="token-45-12" morph="none" pos="word" start_char="5056">and</TOKEN>
<TOKEN end_char="5065" id="token-45-13" morph="none" pos="word" start_char="5060">useful</TOKEN>
<TOKEN end_char="5075" id="token-45-14" morph="none" pos="word" start_char="5067">indicator</TOKEN>
<TOKEN end_char="5076" id="token-45-15" morph="none" pos="punct" start_char="5076">,</TOKEN>
<TOKEN end_char="5080" id="token-45-16" morph="none" pos="word" start_char="5078">and</TOKEN>
<TOKEN end_char="5081" id="token-45-17" morph="none" pos="punct" start_char="5081">,</TOKEN>
<TOKEN end_char="5091" id="token-45-18" morph="none" pos="word" start_char="5083">certainly</TOKEN>
<TOKEN end_char="5092" id="token-45-19" morph="none" pos="punct" start_char="5092">,</TOKEN>
<TOKEN end_char="5102" id="token-45-20" morph="none" pos="word" start_char="5094">Chongqing</TOKEN>
<TOKEN end_char="5106" id="token-45-21" morph="none" pos="word" start_char="5104">and</TOKEN>
<TOKEN end_char="5112" id="token-45-22" morph="none" pos="word" start_char="5108">Wuhan</TOKEN>
<TOKEN end_char="5119" id="token-45-23" morph="none" pos="word" start_char="5114">suffer</TOKEN>
<TOKEN end_char="5124" id="token-45-24" morph="none" pos="word" start_char="5121">from</TOKEN>
<TOKEN end_char="5129" id="token-45-25" morph="none" pos="word" start_char="5126">poor</TOKEN>
<TOKEN end_char="5133" id="token-45-26" morph="none" pos="word" start_char="5131">air</TOKEN>
<TOKEN end_char="5141" id="token-45-27" morph="none" pos="word" start_char="5135">quality</TOKEN>
<TOKEN end_char="5142" id="token-45-28" morph="none" pos="punct" start_char="5142">,</TOKEN>
<TOKEN end_char="5146" id="token-45-29" morph="none" pos="word" start_char="5144">but</TOKEN>
<TOKEN end_char="5151" id="token-45-30" morph="none" pos="word" start_char="5148">this</TOKEN>
<TOKEN end_char="5154" id="token-45-31" morph="none" pos="word" start_char="5153">is</TOKEN>
<TOKEN end_char="5168" id="token-45-32" morph="none" pos="word" start_char="5156">approximative</TOKEN>
<TOKEN end_char="5173" id="token-45-33" morph="none" pos="word" start_char="5170">data</TOKEN>
<TOKEN end_char="5176" id="token-45-34" morph="none" pos="word" start_char="5175">to</TOKEN>
<TOKEN end_char="5179" id="token-45-35" morph="none" pos="word" start_char="5178">be</TOKEN>
<TOKEN end_char="5185" id="token-45-36" morph="none" pos="word" start_char="5181">taken</TOKEN>
<TOKEN end_char="5190" id="token-45-37" morph="none" pos="word" start_char="5187">into</TOKEN>
<TOKEN end_char="5202" id="token-45-38" morph="none" pos="word" start_char="5192">perspective</TOKEN>
<TOKEN end_char="5203" id="token-45-39" morph="none" pos="punct" start_char="5203">,</TOKEN>
<TOKEN end_char="5207" id="token-45-40" morph="none" pos="word" start_char="5205">not</TOKEN>
<TOKEN end_char="5209" id="token-45-41" morph="none" pos="word" start_char="5209">a</TOKEN>
<TOKEN end_char="5220" id="token-45-42" morph="none" pos="word" start_char="5211">scientific</TOKEN>
<TOKEN end_char="5228" id="token-45-43" morph="none" pos="word" start_char="5222">measure</TOKEN>
<TOKEN end_char="5231" id="token-45-44" morph="none" pos="word" start_char="5230">or</TOKEN>
<TOKEN end_char="5237" id="token-45-45" morph="none" pos="word" start_char="5233">proof</TOKEN>
<TOKEN end_char="5238" id="token-45-46" morph="none" pos="punct" start_char="5238">.</TOKEN>
</SEG>
<SEG end_char="5430" id="segment-46" start_char="5241">
<ORIGINAL_TEXT>An Italian chemistry professor has made a rough calculation for the website open.online, and he estimates that to get to those levels of SO2 Wuhan would have to burn about 30 million bodies.</ORIGINAL_TEXT>
<TOKEN end_char="5242" id="token-46-0" morph="none" pos="word" start_char="5241">An</TOKEN>
<TOKEN end_char="5250" id="token-46-1" morph="none" pos="word" start_char="5244">Italian</TOKEN>
<TOKEN end_char="5260" id="token-46-2" morph="none" pos="word" start_char="5252">chemistry</TOKEN>
<TOKEN end_char="5270" id="token-46-3" morph="none" pos="word" start_char="5262">professor</TOKEN>
<TOKEN end_char="5274" id="token-46-4" morph="none" pos="word" start_char="5272">has</TOKEN>
<TOKEN end_char="5279" id="token-46-5" morph="none" pos="word" start_char="5276">made</TOKEN>
<TOKEN end_char="5281" id="token-46-6" morph="none" pos="word" start_char="5281">a</TOKEN>
<TOKEN end_char="5287" id="token-46-7" morph="none" pos="word" start_char="5283">rough</TOKEN>
<TOKEN end_char="5299" id="token-46-8" morph="none" pos="word" start_char="5289">calculation</TOKEN>
<TOKEN end_char="5303" id="token-46-9" morph="none" pos="word" start_char="5301">for</TOKEN>
<TOKEN end_char="5307" id="token-46-10" morph="none" pos="word" start_char="5305">the</TOKEN>
<TOKEN end_char="5315" id="token-46-11" morph="none" pos="word" start_char="5309">website</TOKEN>
<TOKEN end_char="5327" id="token-46-12" morph="none" pos="unknown" start_char="5317">open.online</TOKEN>
<TOKEN end_char="5328" id="token-46-13" morph="none" pos="punct" start_char="5328">,</TOKEN>
<TOKEN end_char="5332" id="token-46-14" morph="none" pos="word" start_char="5330">and</TOKEN>
<TOKEN end_char="5335" id="token-46-15" morph="none" pos="word" start_char="5334">he</TOKEN>
<TOKEN end_char="5345" id="token-46-16" morph="none" pos="word" start_char="5337">estimates</TOKEN>
<TOKEN end_char="5350" id="token-46-17" morph="none" pos="word" start_char="5347">that</TOKEN>
<TOKEN end_char="5353" id="token-46-18" morph="none" pos="word" start_char="5352">to</TOKEN>
<TOKEN end_char="5357" id="token-46-19" morph="none" pos="word" start_char="5355">get</TOKEN>
<TOKEN end_char="5360" id="token-46-20" morph="none" pos="word" start_char="5359">to</TOKEN>
<TOKEN end_char="5366" id="token-46-21" morph="none" pos="word" start_char="5362">those</TOKEN>
<TOKEN end_char="5373" id="token-46-22" morph="none" pos="word" start_char="5368">levels</TOKEN>
<TOKEN end_char="5376" id="token-46-23" morph="none" pos="word" start_char="5375">of</TOKEN>
<TOKEN end_char="5380" id="token-46-24" morph="none" pos="word" start_char="5378">SO2</TOKEN>
<TOKEN end_char="5386" id="token-46-25" morph="none" pos="word" start_char="5382">Wuhan</TOKEN>
<TOKEN end_char="5392" id="token-46-26" morph="none" pos="word" start_char="5388">would</TOKEN>
<TOKEN end_char="5397" id="token-46-27" morph="none" pos="word" start_char="5394">have</TOKEN>
<TOKEN end_char="5400" id="token-46-28" morph="none" pos="word" start_char="5399">to</TOKEN>
<TOKEN end_char="5405" id="token-46-29" morph="none" pos="word" start_char="5402">burn</TOKEN>
<TOKEN end_char="5411" id="token-46-30" morph="none" pos="word" start_char="5407">about</TOKEN>
<TOKEN end_char="5414" id="token-46-31" morph="none" pos="word" start_char="5413">30</TOKEN>
<TOKEN end_char="5422" id="token-46-32" morph="none" pos="word" start_char="5416">million</TOKEN>
<TOKEN end_char="5429" id="token-46-33" morph="none" pos="word" start_char="5424">bodies</TOKEN>
<TOKEN end_char="5430" id="token-46-34" morph="none" pos="punct" start_char="5430">.</TOKEN>
</SEG>
<SEG end_char="5465" id="segment-47" start_char="5432">
<ORIGINAL_TEXT>That's unlikely, to say the least.</ORIGINAL_TEXT>
<TOKEN end_char="5437" id="token-47-0" morph="none" pos="word" start_char="5432">That's</TOKEN>
<TOKEN end_char="5446" id="token-47-1" morph="none" pos="word" start_char="5439">unlikely</TOKEN>
<TOKEN end_char="5447" id="token-47-2" morph="none" pos="punct" start_char="5447">,</TOKEN>
<TOKEN end_char="5450" id="token-47-3" morph="none" pos="word" start_char="5449">to</TOKEN>
<TOKEN end_char="5454" id="token-47-4" morph="none" pos="word" start_char="5452">say</TOKEN>
<TOKEN end_char="5458" id="token-47-5" morph="none" pos="word" start_char="5456">the</TOKEN>
<TOKEN end_char="5464" id="token-47-6" morph="none" pos="word" start_char="5460">least</TOKEN>
<TOKEN end_char="5465" id="token-47-7" morph="none" pos="punct" start_char="5465">.</TOKEN>
</SEG>
<SEG end_char="5503" id="segment-48" start_char="5468">
<ORIGINAL_TEXT>Factories and atmospheric conditions</ORIGINAL_TEXT>
<TOKEN end_char="5476" id="token-48-0" morph="none" pos="word" start_char="5468">Factories</TOKEN>
<TOKEN end_char="5480" id="token-48-1" morph="none" pos="word" start_char="5478">and</TOKEN>
<TOKEN end_char="5492" id="token-48-2" morph="none" pos="word" start_char="5482">atmospheric</TOKEN>
<TOKEN end_char="5503" id="token-48-3" morph="none" pos="word" start_char="5494">conditions</TOKEN>
</SEG>
<SEG end_char="5643" id="segment-49" start_char="5507">
<ORIGINAL_TEXT>Experts consulted by Euronews believe that the levels observed are not particularly alarming in one of the world's most polluted country.</ORIGINAL_TEXT>
<TOKEN end_char="5513" id="token-49-0" morph="none" pos="word" start_char="5507">Experts</TOKEN>
<TOKEN end_char="5523" id="token-49-1" morph="none" pos="word" start_char="5515">consulted</TOKEN>
<TOKEN end_char="5526" id="token-49-2" morph="none" pos="word" start_char="5525">by</TOKEN>
<TOKEN end_char="5535" id="token-49-3" morph="none" pos="word" start_char="5528">Euronews</TOKEN>
<TOKEN end_char="5543" id="token-49-4" morph="none" pos="word" start_char="5537">believe</TOKEN>
<TOKEN end_char="5548" id="token-49-5" morph="none" pos="word" start_char="5545">that</TOKEN>
<TOKEN end_char="5552" id="token-49-6" morph="none" pos="word" start_char="5550">the</TOKEN>
<TOKEN end_char="5559" id="token-49-7" morph="none" pos="word" start_char="5554">levels</TOKEN>
<TOKEN end_char="5568" id="token-49-8" morph="none" pos="word" start_char="5561">observed</TOKEN>
<TOKEN end_char="5572" id="token-49-9" morph="none" pos="word" start_char="5570">are</TOKEN>
<TOKEN end_char="5576" id="token-49-10" morph="none" pos="word" start_char="5574">not</TOKEN>
<TOKEN end_char="5589" id="token-49-11" morph="none" pos="word" start_char="5578">particularly</TOKEN>
<TOKEN end_char="5598" id="token-49-12" morph="none" pos="word" start_char="5591">alarming</TOKEN>
<TOKEN end_char="5601" id="token-49-13" morph="none" pos="word" start_char="5600">in</TOKEN>
<TOKEN end_char="5605" id="token-49-14" morph="none" pos="word" start_char="5603">one</TOKEN>
<TOKEN end_char="5608" id="token-49-15" morph="none" pos="word" start_char="5607">of</TOKEN>
<TOKEN end_char="5612" id="token-49-16" morph="none" pos="word" start_char="5610">the</TOKEN>
<TOKEN end_char="5620" id="token-49-17" morph="none" pos="word" start_char="5614">world's</TOKEN>
<TOKEN end_char="5625" id="token-49-18" morph="none" pos="word" start_char="5622">most</TOKEN>
<TOKEN end_char="5634" id="token-49-19" morph="none" pos="word" start_char="5627">polluted</TOKEN>
<TOKEN end_char="5642" id="token-49-20" morph="none" pos="word" start_char="5636">country</TOKEN>
<TOKEN end_char="5643" id="token-49-21" morph="none" pos="punct" start_char="5643">.</TOKEN>
</SEG>
<SEG end_char="5742" id="segment-50" start_char="5646">
<ORIGINAL_TEXT>They say that high concentrations in a particular place may be related to atmospheric conditions.</ORIGINAL_TEXT>
<TOKEN end_char="5649" id="token-50-0" morph="none" pos="word" start_char="5646">They</TOKEN>
<TOKEN end_char="5653" id="token-50-1" morph="none" pos="word" start_char="5651">say</TOKEN>
<TOKEN end_char="5658" id="token-50-2" morph="none" pos="word" start_char="5655">that</TOKEN>
<TOKEN end_char="5663" id="token-50-3" morph="none" pos="word" start_char="5660">high</TOKEN>
<TOKEN end_char="5678" id="token-50-4" morph="none" pos="word" start_char="5665">concentrations</TOKEN>
<TOKEN end_char="5681" id="token-50-5" morph="none" pos="word" start_char="5680">in</TOKEN>
<TOKEN end_char="5683" id="token-50-6" morph="none" pos="word" start_char="5683">a</TOKEN>
<TOKEN end_char="5694" id="token-50-7" morph="none" pos="word" start_char="5685">particular</TOKEN>
<TOKEN end_char="5700" id="token-50-8" morph="none" pos="word" start_char="5696">place</TOKEN>
<TOKEN end_char="5704" id="token-50-9" morph="none" pos="word" start_char="5702">may</TOKEN>
<TOKEN end_char="5707" id="token-50-10" morph="none" pos="word" start_char="5706">be</TOKEN>
<TOKEN end_char="5715" id="token-50-11" morph="none" pos="word" start_char="5709">related</TOKEN>
<TOKEN end_char="5718" id="token-50-12" morph="none" pos="word" start_char="5717">to</TOKEN>
<TOKEN end_char="5730" id="token-50-13" morph="none" pos="word" start_char="5720">atmospheric</TOKEN>
<TOKEN end_char="5741" id="token-50-14" morph="none" pos="word" start_char="5732">conditions</TOKEN>
<TOKEN end_char="5742" id="token-50-15" morph="none" pos="punct" start_char="5742">.</TOKEN>
</SEG>
<SEG end_char="5913" id="segment-51" start_char="5744">
<ORIGINAL_TEXT>Indeed, last weekend in Wuhan it was cold, about 4-5 degrees — increasing the probability of people using heating — and not very windy, which can increase concentrations.</ORIGINAL_TEXT>
<TOKEN end_char="5749" id="token-51-0" morph="none" pos="word" start_char="5744">Indeed</TOKEN>
<TOKEN end_char="5750" id="token-51-1" morph="none" pos="punct" start_char="5750">,</TOKEN>
<TOKEN end_char="5755" id="token-51-2" morph="none" pos="word" start_char="5752">last</TOKEN>
<TOKEN end_char="5763" id="token-51-3" morph="none" pos="word" start_char="5757">weekend</TOKEN>
<TOKEN end_char="5766" id="token-51-4" morph="none" pos="word" start_char="5765">in</TOKEN>
<TOKEN end_char="5772" id="token-51-5" morph="none" pos="word" start_char="5768">Wuhan</TOKEN>
<TOKEN end_char="5775" id="token-51-6" morph="none" pos="word" start_char="5774">it</TOKEN>
<TOKEN end_char="5779" id="token-51-7" morph="none" pos="word" start_char="5777">was</TOKEN>
<TOKEN end_char="5784" id="token-51-8" morph="none" pos="word" start_char="5781">cold</TOKEN>
<TOKEN end_char="5785" id="token-51-9" morph="none" pos="punct" start_char="5785">,</TOKEN>
<TOKEN end_char="5791" id="token-51-10" morph="none" pos="word" start_char="5787">about</TOKEN>
<TOKEN end_char="5795" id="token-51-11" morph="none" pos="unknown" start_char="5793">4-5</TOKEN>
<TOKEN end_char="5803" id="token-51-12" morph="none" pos="word" start_char="5797">degrees</TOKEN>
<TOKEN end_char="5805" id="token-51-13" morph="none" pos="punct" start_char="5805">—</TOKEN>
<TOKEN end_char="5816" id="token-51-14" morph="none" pos="word" start_char="5807">increasing</TOKEN>
<TOKEN end_char="5820" id="token-51-15" morph="none" pos="word" start_char="5818">the</TOKEN>
<TOKEN end_char="5832" id="token-51-16" morph="none" pos="word" start_char="5822">probability</TOKEN>
<TOKEN end_char="5835" id="token-51-17" morph="none" pos="word" start_char="5834">of</TOKEN>
<TOKEN end_char="5842" id="token-51-18" morph="none" pos="word" start_char="5837">people</TOKEN>
<TOKEN end_char="5848" id="token-51-19" morph="none" pos="word" start_char="5844">using</TOKEN>
<TOKEN end_char="5856" id="token-51-20" morph="none" pos="word" start_char="5850">heating</TOKEN>
<TOKEN end_char="5858" id="token-51-21" morph="none" pos="punct" start_char="5858">—</TOKEN>
<TOKEN end_char="5862" id="token-51-22" morph="none" pos="word" start_char="5860">and</TOKEN>
<TOKEN end_char="5866" id="token-51-23" morph="none" pos="word" start_char="5864">not</TOKEN>
<TOKEN end_char="5871" id="token-51-24" morph="none" pos="word" start_char="5868">very</TOKEN>
<TOKEN end_char="5877" id="token-51-25" morph="none" pos="word" start_char="5873">windy</TOKEN>
<TOKEN end_char="5878" id="token-51-26" morph="none" pos="punct" start_char="5878">,</TOKEN>
<TOKEN end_char="5884" id="token-51-27" morph="none" pos="word" start_char="5880">which</TOKEN>
<TOKEN end_char="5888" id="token-51-28" morph="none" pos="word" start_char="5886">can</TOKEN>
<TOKEN end_char="5897" id="token-51-29" morph="none" pos="word" start_char="5890">increase</TOKEN>
<TOKEN end_char="5912" id="token-51-30" morph="none" pos="word" start_char="5899">concentrations</TOKEN>
<TOKEN end_char="5913" id="token-51-31" morph="none" pos="punct" start_char="5913">.</TOKEN>
</SEG>
<SEG end_char="6128" id="segment-52" start_char="5916">
<ORIGINAL_TEXT>East of Wuhan, where the large cloud of SO2 was shown, there is a large coal-fired power plant that is identified in NASA's catalogue of sources of sulphur dioxide emissions, as researcher Iolanda Ialongo told us.</ORIGINAL_TEXT>
<TOKEN end_char="5919" id="token-52-0" morph="none" pos="word" start_char="5916">East</TOKEN>
<TOKEN end_char="5922" id="token-52-1" morph="none" pos="word" start_char="5921">of</TOKEN>
<TOKEN end_char="5928" id="token-52-2" morph="none" pos="word" start_char="5924">Wuhan</TOKEN>
<TOKEN end_char="5929" id="token-52-3" morph="none" pos="punct" start_char="5929">,</TOKEN>
<TOKEN end_char="5935" id="token-52-4" morph="none" pos="word" start_char="5931">where</TOKEN>
<TOKEN end_char="5939" id="token-52-5" morph="none" pos="word" start_char="5937">the</TOKEN>
<TOKEN end_char="5945" id="token-52-6" morph="none" pos="word" start_char="5941">large</TOKEN>
<TOKEN end_char="5951" id="token-52-7" morph="none" pos="word" start_char="5947">cloud</TOKEN>
<TOKEN end_char="5954" id="token-52-8" morph="none" pos="word" start_char="5953">of</TOKEN>
<TOKEN end_char="5958" id="token-52-9" morph="none" pos="word" start_char="5956">SO2</TOKEN>
<TOKEN end_char="5962" id="token-52-10" morph="none" pos="word" start_char="5960">was</TOKEN>
<TOKEN end_char="5968" id="token-52-11" morph="none" pos="word" start_char="5964">shown</TOKEN>
<TOKEN end_char="5969" id="token-52-12" morph="none" pos="punct" start_char="5969">,</TOKEN>
<TOKEN end_char="5975" id="token-52-13" morph="none" pos="word" start_char="5971">there</TOKEN>
<TOKEN end_char="5978" id="token-52-14" morph="none" pos="word" start_char="5977">is</TOKEN>
<TOKEN end_char="5980" id="token-52-15" morph="none" pos="word" start_char="5980">a</TOKEN>
<TOKEN end_char="5986" id="token-52-16" morph="none" pos="word" start_char="5982">large</TOKEN>
<TOKEN end_char="5997" id="token-52-17" morph="none" pos="unknown" start_char="5988">coal-fired</TOKEN>
<TOKEN end_char="6003" id="token-52-18" morph="none" pos="word" start_char="5999">power</TOKEN>
<TOKEN end_char="6009" id="token-52-19" morph="none" pos="word" start_char="6005">plant</TOKEN>
<TOKEN end_char="6014" id="token-52-20" morph="none" pos="word" start_char="6011">that</TOKEN>
<TOKEN end_char="6017" id="token-52-21" morph="none" pos="word" start_char="6016">is</TOKEN>
<TOKEN end_char="6028" id="token-52-22" morph="none" pos="word" start_char="6019">identified</TOKEN>
<TOKEN end_char="6031" id="token-52-23" morph="none" pos="word" start_char="6030">in</TOKEN>
<TOKEN end_char="6038" id="token-52-24" morph="none" pos="word" start_char="6033">NASA's</TOKEN>
<TOKEN end_char="6048" id="token-52-25" morph="none" pos="word" start_char="6040">catalogue</TOKEN>
<TOKEN end_char="6051" id="token-52-26" morph="none" pos="word" start_char="6050">of</TOKEN>
<TOKEN end_char="6059" id="token-52-27" morph="none" pos="word" start_char="6053">sources</TOKEN>
<TOKEN end_char="6062" id="token-52-28" morph="none" pos="word" start_char="6061">of</TOKEN>
<TOKEN end_char="6070" id="token-52-29" morph="none" pos="word" start_char="6064">sulphur</TOKEN>
<TOKEN end_char="6078" id="token-52-30" morph="none" pos="word" start_char="6072">dioxide</TOKEN>
<TOKEN end_char="6088" id="token-52-31" morph="none" pos="word" start_char="6080">emissions</TOKEN>
<TOKEN end_char="6089" id="token-52-32" morph="none" pos="punct" start_char="6089">,</TOKEN>
<TOKEN end_char="6092" id="token-52-33" morph="none" pos="word" start_char="6091">as</TOKEN>
<TOKEN end_char="6103" id="token-52-34" morph="none" pos="word" start_char="6094">researcher</TOKEN>
<TOKEN end_char="6111" id="token-52-35" morph="none" pos="word" start_char="6105">Iolanda</TOKEN>
<TOKEN end_char="6119" id="token-52-36" morph="none" pos="word" start_char="6113">Ialongo</TOKEN>
<TOKEN end_char="6124" id="token-52-37" morph="none" pos="word" start_char="6121">told</TOKEN>
<TOKEN end_char="6127" id="token-52-38" morph="none" pos="word" start_char="6126">us</TOKEN>
<TOKEN end_char="6128" id="token-52-39" morph="none" pos="punct" start_char="6128">.</TOKEN>
</SEG>
<SEG end_char="6360" id="segment-53" start_char="6132">
<ORIGINAL_TEXT>Anu-Maija Sundström, an air quality expert from the Finnish Meteorological Institute, pointed out that at a quick glance, neither the air quality indices nor the SILAM model showed anything exceptional in the SO2 levels of Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="6140" id="token-53-0" morph="none" pos="unknown" start_char="6132">Anu-Maija</TOKEN>
<TOKEN end_char="6150" id="token-53-1" morph="none" pos="word" start_char="6142">Sundström</TOKEN>
<TOKEN end_char="6151" id="token-53-2" morph="none" pos="punct" start_char="6151">,</TOKEN>
<TOKEN end_char="6154" id="token-53-3" morph="none" pos="word" start_char="6153">an</TOKEN>
<TOKEN end_char="6158" id="token-53-4" morph="none" pos="word" start_char="6156">air</TOKEN>
<TOKEN end_char="6166" id="token-53-5" morph="none" pos="word" start_char="6160">quality</TOKEN>
<TOKEN end_char="6173" id="token-53-6" morph="none" pos="word" start_char="6168">expert</TOKEN>
<TOKEN end_char="6178" id="token-53-7" morph="none" pos="word" start_char="6175">from</TOKEN>
<TOKEN end_char="6182" id="token-53-8" morph="none" pos="word" start_char="6180">the</TOKEN>
<TOKEN end_char="6190" id="token-53-9" morph="none" pos="word" start_char="6184">Finnish</TOKEN>
<TOKEN end_char="6205" id="token-53-10" morph="none" pos="word" start_char="6192">Meteorological</TOKEN>
<TOKEN end_char="6215" id="token-53-11" morph="none" pos="word" start_char="6207">Institute</TOKEN>
<TOKEN end_char="6216" id="token-53-12" morph="none" pos="punct" start_char="6216">,</TOKEN>
<TOKEN end_char="6224" id="token-53-13" morph="none" pos="word" start_char="6218">pointed</TOKEN>
<TOKEN end_char="6228" id="token-53-14" morph="none" pos="word" start_char="6226">out</TOKEN>
<TOKEN end_char="6233" id="token-53-15" morph="none" pos="word" start_char="6230">that</TOKEN>
<TOKEN end_char="6236" id="token-53-16" morph="none" pos="word" start_char="6235">at</TOKEN>
<TOKEN end_char="6238" id="token-53-17" morph="none" pos="word" start_char="6238">a</TOKEN>
<TOKEN end_char="6244" id="token-53-18" morph="none" pos="word" start_char="6240">quick</TOKEN>
<TOKEN end_char="6251" id="token-53-19" morph="none" pos="word" start_char="6246">glance</TOKEN>
<TOKEN end_char="6252" id="token-53-20" morph="none" pos="punct" start_char="6252">,</TOKEN>
<TOKEN end_char="6260" id="token-53-21" morph="none" pos="word" start_char="6254">neither</TOKEN>
<TOKEN end_char="6264" id="token-53-22" morph="none" pos="word" start_char="6262">the</TOKEN>
<TOKEN end_char="6268" id="token-53-23" morph="none" pos="word" start_char="6266">air</TOKEN>
<TOKEN end_char="6276" id="token-53-24" morph="none" pos="word" start_char="6270">quality</TOKEN>
<TOKEN end_char="6284" id="token-53-25" morph="none" pos="word" start_char="6278">indices</TOKEN>
<TOKEN end_char="6288" id="token-53-26" morph="none" pos="word" start_char="6286">nor</TOKEN>
<TOKEN end_char="6292" id="token-53-27" morph="none" pos="word" start_char="6290">the</TOKEN>
<TOKEN end_char="6298" id="token-53-28" morph="none" pos="word" start_char="6294">SILAM</TOKEN>
<TOKEN end_char="6304" id="token-53-29" morph="none" pos="word" start_char="6300">model</TOKEN>
<TOKEN end_char="6311" id="token-53-30" morph="none" pos="word" start_char="6306">showed</TOKEN>
<TOKEN end_char="6320" id="token-53-31" morph="none" pos="word" start_char="6313">anything</TOKEN>
<TOKEN end_char="6332" id="token-53-32" morph="none" pos="word" start_char="6322">exceptional</TOKEN>
<TOKEN end_char="6335" id="token-53-33" morph="none" pos="word" start_char="6334">in</TOKEN>
<TOKEN end_char="6339" id="token-53-34" morph="none" pos="word" start_char="6337">the</TOKEN>
<TOKEN end_char="6343" id="token-53-35" morph="none" pos="word" start_char="6341">SO2</TOKEN>
<TOKEN end_char="6350" id="token-53-36" morph="none" pos="word" start_char="6345">levels</TOKEN>
<TOKEN end_char="6353" id="token-53-37" morph="none" pos="word" start_char="6352">of</TOKEN>
<TOKEN end_char="6359" id="token-53-38" morph="none" pos="word" start_char="6355">Wuhan</TOKEN>
<TOKEN end_char="6360" id="token-53-39" morph="none" pos="punct" start_char="6360">.</TOKEN>
</SEG>
<SEG end_char="6518" id="segment-54" start_char="6363">
<ORIGINAL_TEXT>In short, this looks like just another more example of the difficulty of separating rumours and misinformation in a subject as sensitive as the coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="6364" id="token-54-0" morph="none" pos="word" start_char="6363">In</TOKEN>
<TOKEN end_char="6370" id="token-54-1" morph="none" pos="word" start_char="6366">short</TOKEN>
<TOKEN end_char="6371" id="token-54-2" morph="none" pos="punct" start_char="6371">,</TOKEN>
<TOKEN end_char="6376" id="token-54-3" morph="none" pos="word" start_char="6373">this</TOKEN>
<TOKEN end_char="6382" id="token-54-4" morph="none" pos="word" start_char="6378">looks</TOKEN>
<TOKEN end_char="6387" id="token-54-5" morph="none" pos="word" start_char="6384">like</TOKEN>
<TOKEN end_char="6392" id="token-54-6" morph="none" pos="word" start_char="6389">just</TOKEN>
<TOKEN end_char="6400" id="token-54-7" morph="none" pos="word" start_char="6394">another</TOKEN>
<TOKEN end_char="6405" id="token-54-8" morph="none" pos="word" start_char="6402">more</TOKEN>
<TOKEN end_char="6413" id="token-54-9" morph="none" pos="word" start_char="6407">example</TOKEN>
<TOKEN end_char="6416" id="token-54-10" morph="none" pos="word" start_char="6415">of</TOKEN>
<TOKEN end_char="6420" id="token-54-11" morph="none" pos="word" start_char="6418">the</TOKEN>
<TOKEN end_char="6431" id="token-54-12" morph="none" pos="word" start_char="6422">difficulty</TOKEN>
<TOKEN end_char="6434" id="token-54-13" morph="none" pos="word" start_char="6433">of</TOKEN>
<TOKEN end_char="6445" id="token-54-14" morph="none" pos="word" start_char="6436">separating</TOKEN>
<TOKEN end_char="6453" id="token-54-15" morph="none" pos="word" start_char="6447">rumours</TOKEN>
<TOKEN end_char="6457" id="token-54-16" morph="none" pos="word" start_char="6455">and</TOKEN>
<TOKEN end_char="6472" id="token-54-17" morph="none" pos="word" start_char="6459">misinformation</TOKEN>
<TOKEN end_char="6475" id="token-54-18" morph="none" pos="word" start_char="6474">in</TOKEN>
<TOKEN end_char="6477" id="token-54-19" morph="none" pos="word" start_char="6477">a</TOKEN>
<TOKEN end_char="6485" id="token-54-20" morph="none" pos="word" start_char="6479">subject</TOKEN>
<TOKEN end_char="6488" id="token-54-21" morph="none" pos="word" start_char="6487">as</TOKEN>
<TOKEN end_char="6498" id="token-54-22" morph="none" pos="word" start_char="6490">sensitive</TOKEN>
<TOKEN end_char="6501" id="token-54-23" morph="none" pos="word" start_char="6500">as</TOKEN>
<TOKEN end_char="6505" id="token-54-24" morph="none" pos="word" start_char="6503">the</TOKEN>
<TOKEN end_char="6517" id="token-54-25" morph="none" pos="word" start_char="6507">coronavirus</TOKEN>
<TOKEN end_char="6518" id="token-54-26" morph="none" pos="punct" start_char="6518">.</TOKEN>
</SEG>
<SEG end_char="6636" id="segment-55" start_char="6520">
<ORIGINAL_TEXT>Many take advantage of the traditional opacity of the Chinese authorities to multiply the most gruesome speculations.</ORIGINAL_TEXT>
<TOKEN end_char="6523" id="token-55-0" morph="none" pos="word" start_char="6520">Many</TOKEN>
<TOKEN end_char="6528" id="token-55-1" morph="none" pos="word" start_char="6525">take</TOKEN>
<TOKEN end_char="6538" id="token-55-2" morph="none" pos="word" start_char="6530">advantage</TOKEN>
<TOKEN end_char="6541" id="token-55-3" morph="none" pos="word" start_char="6540">of</TOKEN>
<TOKEN end_char="6545" id="token-55-4" morph="none" pos="word" start_char="6543">the</TOKEN>
<TOKEN end_char="6557" id="token-55-5" morph="none" pos="word" start_char="6547">traditional</TOKEN>
<TOKEN end_char="6565" id="token-55-6" morph="none" pos="word" start_char="6559">opacity</TOKEN>
<TOKEN end_char="6568" id="token-55-7" morph="none" pos="word" start_char="6567">of</TOKEN>
<TOKEN end_char="6572" id="token-55-8" morph="none" pos="word" start_char="6570">the</TOKEN>
<TOKEN end_char="6580" id="token-55-9" morph="none" pos="word" start_char="6574">Chinese</TOKEN>
<TOKEN end_char="6592" id="token-55-10" morph="none" pos="word" start_char="6582">authorities</TOKEN>
<TOKEN end_char="6595" id="token-55-11" morph="none" pos="word" start_char="6594">to</TOKEN>
<TOKEN end_char="6604" id="token-55-12" morph="none" pos="word" start_char="6597">multiply</TOKEN>
<TOKEN end_char="6608" id="token-55-13" morph="none" pos="word" start_char="6606">the</TOKEN>
<TOKEN end_char="6613" id="token-55-14" morph="none" pos="word" start_char="6610">most</TOKEN>
<TOKEN end_char="6622" id="token-55-15" morph="none" pos="word" start_char="6615">gruesome</TOKEN>
<TOKEN end_char="6635" id="token-55-16" morph="none" pos="word" start_char="6624">speculations</TOKEN>
<TOKEN end_char="6636" id="token-55-17" morph="none" pos="punct" start_char="6636">.</TOKEN>
</SEG>
<SEG end_char="6798" id="segment-56" start_char="6639">
<ORIGINAL_TEXT>The World Health Organization itself or the major social networks and Internet platforms have created special pages to try to stop false rumours about COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="6641" id="token-56-0" morph="none" pos="word" start_char="6639">The</TOKEN>
<TOKEN end_char="6647" id="token-56-1" morph="none" pos="word" start_char="6643">World</TOKEN>
<TOKEN end_char="6654" id="token-56-2" morph="none" pos="word" start_char="6649">Health</TOKEN>
<TOKEN end_char="6667" id="token-56-3" morph="none" pos="word" start_char="6656">Organization</TOKEN>
<TOKEN end_char="6674" id="token-56-4" morph="none" pos="word" start_char="6669">itself</TOKEN>
<TOKEN end_char="6677" id="token-56-5" morph="none" pos="word" start_char="6676">or</TOKEN>
<TOKEN end_char="6681" id="token-56-6" morph="none" pos="word" start_char="6679">the</TOKEN>
<TOKEN end_char="6687" id="token-56-7" morph="none" pos="word" start_char="6683">major</TOKEN>
<TOKEN end_char="6694" id="token-56-8" morph="none" pos="word" start_char="6689">social</TOKEN>
<TOKEN end_char="6703" id="token-56-9" morph="none" pos="word" start_char="6696">networks</TOKEN>
<TOKEN end_char="6707" id="token-56-10" morph="none" pos="word" start_char="6705">and</TOKEN>
<TOKEN end_char="6716" id="token-56-11" morph="none" pos="word" start_char="6709">Internet</TOKEN>
<TOKEN end_char="6726" id="token-56-12" morph="none" pos="word" start_char="6718">platforms</TOKEN>
<TOKEN end_char="6731" id="token-56-13" morph="none" pos="word" start_char="6728">have</TOKEN>
<TOKEN end_char="6739" id="token-56-14" morph="none" pos="word" start_char="6733">created</TOKEN>
<TOKEN end_char="6747" id="token-56-15" morph="none" pos="word" start_char="6741">special</TOKEN>
<TOKEN end_char="6753" id="token-56-16" morph="none" pos="word" start_char="6749">pages</TOKEN>
<TOKEN end_char="6756" id="token-56-17" morph="none" pos="word" start_char="6755">to</TOKEN>
<TOKEN end_char="6760" id="token-56-18" morph="none" pos="word" start_char="6758">try</TOKEN>
<TOKEN end_char="6763" id="token-56-19" morph="none" pos="word" start_char="6762">to</TOKEN>
<TOKEN end_char="6768" id="token-56-20" morph="none" pos="word" start_char="6765">stop</TOKEN>
<TOKEN end_char="6774" id="token-56-21" morph="none" pos="word" start_char="6770">false</TOKEN>
<TOKEN end_char="6782" id="token-56-22" morph="none" pos="word" start_char="6776">rumours</TOKEN>
<TOKEN end_char="6788" id="token-56-23" morph="none" pos="word" start_char="6784">about</TOKEN>
<TOKEN end_char="6797" id="token-56-24" morph="none" pos="unknown" start_char="6790">COVID-19</TOKEN>
<TOKEN end_char="6798" id="token-56-25" morph="none" pos="punct" start_char="6798">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
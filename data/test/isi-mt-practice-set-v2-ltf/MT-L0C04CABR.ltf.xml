<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CABR" lang="spa" raw_text_char_length="9705" raw_text_md5="68cb80409f5ee8368842c016846501fb" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="122" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Suspicions mount that the coronavirus was spreading in China and Europe as early as October, following a WHO investigation</ORIGINAL_TEXT>
<TOKEN end_char="10" id="token-0-0" morph="none" pos="word" start_char="1">Suspicions</TOKEN>
<TOKEN end_char="16" id="token-0-1" morph="none" pos="word" start_char="12">mount</TOKEN>
<TOKEN end_char="21" id="token-0-2" morph="none" pos="word" start_char="18">that</TOKEN>
<TOKEN end_char="25" id="token-0-3" morph="none" pos="word" start_char="23">the</TOKEN>
<TOKEN end_char="37" id="token-0-4" morph="none" pos="word" start_char="27">coronavirus</TOKEN>
<TOKEN end_char="41" id="token-0-5" morph="none" pos="word" start_char="39">was</TOKEN>
<TOKEN end_char="51" id="token-0-6" morph="none" pos="word" start_char="43">spreading</TOKEN>
<TOKEN end_char="54" id="token-0-7" morph="none" pos="word" start_char="53">in</TOKEN>
<TOKEN end_char="60" id="token-0-8" morph="none" pos="word" start_char="56">China</TOKEN>
<TOKEN end_char="64" id="token-0-9" morph="none" pos="word" start_char="62">and</TOKEN>
<TOKEN end_char="71" id="token-0-10" morph="none" pos="word" start_char="66">Europe</TOKEN>
<TOKEN end_char="74" id="token-0-11" morph="none" pos="word" start_char="73">as</TOKEN>
<TOKEN end_char="80" id="token-0-12" morph="none" pos="word" start_char="76">early</TOKEN>
<TOKEN end_char="83" id="token-0-13" morph="none" pos="word" start_char="82">as</TOKEN>
<TOKEN end_char="91" id="token-0-14" morph="none" pos="word" start_char="85">October</TOKEN>
<TOKEN end_char="92" id="token-0-15" morph="none" pos="punct" start_char="92">,</TOKEN>
<TOKEN end_char="102" id="token-0-16" morph="none" pos="word" start_char="94">following</TOKEN>
<TOKEN end_char="104" id="token-0-17" morph="none" pos="word" start_char="104">a</TOKEN>
<TOKEN end_char="108" id="token-0-18" morph="none" pos="word" start_char="106">WHO</TOKEN>
<TOKEN end_char="122" id="token-0-19" morph="none" pos="word" start_char="110">investigation</TOKEN>
</SEG>
<SEG end_char="314" id="segment-1" start_char="127">
<ORIGINAL_TEXT>A worker in protective coverings directs members of the World Health Organization (WHO) team on their arrival at the airport in Wuhan in central China's Hubei province on January 14, 2021.</ORIGINAL_TEXT>
<TOKEN end_char="127" id="token-1-0" morph="none" pos="word" start_char="127">A</TOKEN>
<TOKEN end_char="134" id="token-1-1" morph="none" pos="word" start_char="129">worker</TOKEN>
<TOKEN end_char="137" id="token-1-2" morph="none" pos="word" start_char="136">in</TOKEN>
<TOKEN end_char="148" id="token-1-3" morph="none" pos="word" start_char="139">protective</TOKEN>
<TOKEN end_char="158" id="token-1-4" morph="none" pos="word" start_char="150">coverings</TOKEN>
<TOKEN end_char="166" id="token-1-5" morph="none" pos="word" start_char="160">directs</TOKEN>
<TOKEN end_char="174" id="token-1-6" morph="none" pos="word" start_char="168">members</TOKEN>
<TOKEN end_char="177" id="token-1-7" morph="none" pos="word" start_char="176">of</TOKEN>
<TOKEN end_char="181" id="token-1-8" morph="none" pos="word" start_char="179">the</TOKEN>
<TOKEN end_char="187" id="token-1-9" morph="none" pos="word" start_char="183">World</TOKEN>
<TOKEN end_char="194" id="token-1-10" morph="none" pos="word" start_char="189">Health</TOKEN>
<TOKEN end_char="207" id="token-1-11" morph="none" pos="word" start_char="196">Organization</TOKEN>
<TOKEN end_char="209" id="token-1-12" morph="none" pos="punct" start_char="209">(</TOKEN>
<TOKEN end_char="212" id="token-1-13" morph="none" pos="word" start_char="210">WHO</TOKEN>
<TOKEN end_char="213" id="token-1-14" morph="none" pos="punct" start_char="213">)</TOKEN>
<TOKEN end_char="218" id="token-1-15" morph="none" pos="word" start_char="215">team</TOKEN>
<TOKEN end_char="221" id="token-1-16" morph="none" pos="word" start_char="220">on</TOKEN>
<TOKEN end_char="227" id="token-1-17" morph="none" pos="word" start_char="223">their</TOKEN>
<TOKEN end_char="235" id="token-1-18" morph="none" pos="word" start_char="229">arrival</TOKEN>
<TOKEN end_char="238" id="token-1-19" morph="none" pos="word" start_char="237">at</TOKEN>
<TOKEN end_char="242" id="token-1-20" morph="none" pos="word" start_char="240">the</TOKEN>
<TOKEN end_char="250" id="token-1-21" morph="none" pos="word" start_char="244">airport</TOKEN>
<TOKEN end_char="253" id="token-1-22" morph="none" pos="word" start_char="252">in</TOKEN>
<TOKEN end_char="259" id="token-1-23" morph="none" pos="word" start_char="255">Wuhan</TOKEN>
<TOKEN end_char="262" id="token-1-24" morph="none" pos="word" start_char="261">in</TOKEN>
<TOKEN end_char="270" id="token-1-25" morph="none" pos="word" start_char="264">central</TOKEN>
<TOKEN end_char="278" id="token-1-26" morph="none" pos="word" start_char="272">China's</TOKEN>
<TOKEN end_char="284" id="token-1-27" morph="none" pos="word" start_char="280">Hubei</TOKEN>
<TOKEN end_char="293" id="token-1-28" morph="none" pos="word" start_char="286">province</TOKEN>
<TOKEN end_char="296" id="token-1-29" morph="none" pos="word" start_char="295">on</TOKEN>
<TOKEN end_char="304" id="token-1-30" morph="none" pos="word" start_char="298">January</TOKEN>
<TOKEN end_char="307" id="token-1-31" morph="none" pos="word" start_char="306">14</TOKEN>
<TOKEN end_char="308" id="token-1-32" morph="none" pos="punct" start_char="308">,</TOKEN>
<TOKEN end_char="313" id="token-1-33" morph="none" pos="word" start_char="310">2021</TOKEN>
<TOKEN end_char="314" id="token-1-34" morph="none" pos="punct" start_char="314">.</TOKEN>
</SEG>
<SEG end_char="336" id="segment-2" start_char="317">
<ORIGINAL_TEXT>AP Photo/Ng Han Guan</ORIGINAL_TEXT>
<TOKEN end_char="318" id="token-2-0" morph="none" pos="word" start_char="317">AP</TOKEN>
<TOKEN end_char="327" id="token-2-1" morph="none" pos="unknown" start_char="320">Photo/Ng</TOKEN>
<TOKEN end_char="331" id="token-2-2" morph="none" pos="word" start_char="329">Han</TOKEN>
<TOKEN end_char="336" id="token-2-3" morph="none" pos="word" start_char="333">Guan</TOKEN>
<TRANSLATED_TEXT>AP Photo / Ng Han Guan</TRANSLATED_TEXT><DETECTED_LANGUAGE>tl</DETECTED_LANGUAGE></SEG>
<SEG end_char="437" id="segment-3" start_char="341">
<ORIGINAL_TEXT>Experts from the WHO and China conducted an investigation into the coronavirus' origins in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="347" id="token-3-0" morph="none" pos="word" start_char="341">Experts</TOKEN>
<TOKEN end_char="352" id="token-3-1" morph="none" pos="word" start_char="349">from</TOKEN>
<TOKEN end_char="356" id="token-3-2" morph="none" pos="word" start_char="354">the</TOKEN>
<TOKEN end_char="360" id="token-3-3" morph="none" pos="word" start_char="358">WHO</TOKEN>
<TOKEN end_char="364" id="token-3-4" morph="none" pos="word" start_char="362">and</TOKEN>
<TOKEN end_char="370" id="token-3-5" morph="none" pos="word" start_char="366">China</TOKEN>
<TOKEN end_char="380" id="token-3-6" morph="none" pos="word" start_char="372">conducted</TOKEN>
<TOKEN end_char="383" id="token-3-7" morph="none" pos="word" start_char="382">an</TOKEN>
<TOKEN end_char="397" id="token-3-8" morph="none" pos="word" start_char="385">investigation</TOKEN>
<TOKEN end_char="402" id="token-3-9" morph="none" pos="word" start_char="399">into</TOKEN>
<TOKEN end_char="406" id="token-3-10" morph="none" pos="word" start_char="404">the</TOKEN>
<TOKEN end_char="418" id="token-3-11" morph="none" pos="word" start_char="408">coronavirus</TOKEN>
<TOKEN end_char="419" id="token-3-12" morph="none" pos="punct" start_char="419">'</TOKEN>
<TOKEN end_char="427" id="token-3-13" morph="none" pos="word" start_char="421">origins</TOKEN>
<TOKEN end_char="430" id="token-3-14" morph="none" pos="word" start_char="429">in</TOKEN>
<TOKEN end_char="436" id="token-3-15" morph="none" pos="word" start_char="432">Wuhan</TOKEN>
<TOKEN end_char="437" id="token-3-16" morph="none" pos="punct" start_char="437">.</TOKEN>
</SEG>
<SEG end_char="601" id="segment-4" start_char="441">
<ORIGINAL_TEXT>The investigation bolstered findings from studies that suggested the virus was circulating in China and Europe months before officials confirmed the first cases.</ORIGINAL_TEXT>
<TOKEN end_char="443" id="token-4-0" morph="none" pos="word" start_char="441">The</TOKEN>
<TOKEN end_char="457" id="token-4-1" morph="none" pos="word" start_char="445">investigation</TOKEN>
<TOKEN end_char="467" id="token-4-2" morph="none" pos="word" start_char="459">bolstered</TOKEN>
<TOKEN end_char="476" id="token-4-3" morph="none" pos="word" start_char="469">findings</TOKEN>
<TOKEN end_char="481" id="token-4-4" morph="none" pos="word" start_char="478">from</TOKEN>
<TOKEN end_char="489" id="token-4-5" morph="none" pos="word" start_char="483">studies</TOKEN>
<TOKEN end_char="494" id="token-4-6" morph="none" pos="word" start_char="491">that</TOKEN>
<TOKEN end_char="504" id="token-4-7" morph="none" pos="word" start_char="496">suggested</TOKEN>
<TOKEN end_char="508" id="token-4-8" morph="none" pos="word" start_char="506">the</TOKEN>
<TOKEN end_char="514" id="token-4-9" morph="none" pos="word" start_char="510">virus</TOKEN>
<TOKEN end_char="518" id="token-4-10" morph="none" pos="word" start_char="516">was</TOKEN>
<TOKEN end_char="530" id="token-4-11" morph="none" pos="word" start_char="520">circulating</TOKEN>
<TOKEN end_char="533" id="token-4-12" morph="none" pos="word" start_char="532">in</TOKEN>
<TOKEN end_char="539" id="token-4-13" morph="none" pos="word" start_char="535">China</TOKEN>
<TOKEN end_char="543" id="token-4-14" morph="none" pos="word" start_char="541">and</TOKEN>
<TOKEN end_char="550" id="token-4-15" morph="none" pos="word" start_char="545">Europe</TOKEN>
<TOKEN end_char="557" id="token-4-16" morph="none" pos="word" start_char="552">months</TOKEN>
<TOKEN end_char="564" id="token-4-17" morph="none" pos="word" start_char="559">before</TOKEN>
<TOKEN end_char="574" id="token-4-18" morph="none" pos="word" start_char="566">officials</TOKEN>
<TOKEN end_char="584" id="token-4-19" morph="none" pos="word" start_char="576">confirmed</TOKEN>
<TOKEN end_char="588" id="token-4-20" morph="none" pos="word" start_char="586">the</TOKEN>
<TOKEN end_char="594" id="token-4-21" morph="none" pos="word" start_char="590">first</TOKEN>
<TOKEN end_char="600" id="token-4-22" morph="none" pos="word" start_char="596">cases</TOKEN>
<TOKEN end_char="601" id="token-4-23" morph="none" pos="punct" start_char="601">.</TOKEN>
</SEG>
<SEG end_char="691" id="segment-5" start_char="605">
<ORIGINAL_TEXT>One study found that some people in the US had coronavirus antibodies in December 2019.</ORIGINAL_TEXT>
<TOKEN end_char="607" id="token-5-0" morph="none" pos="word" start_char="605">One</TOKEN>
<TOKEN end_char="613" id="token-5-1" morph="none" pos="word" start_char="609">study</TOKEN>
<TOKEN end_char="619" id="token-5-2" morph="none" pos="word" start_char="615">found</TOKEN>
<TOKEN end_char="624" id="token-5-3" morph="none" pos="word" start_char="621">that</TOKEN>
<TOKEN end_char="629" id="token-5-4" morph="none" pos="word" start_char="626">some</TOKEN>
<TOKEN end_char="636" id="token-5-5" morph="none" pos="word" start_char="631">people</TOKEN>
<TOKEN end_char="639" id="token-5-6" morph="none" pos="word" start_char="638">in</TOKEN>
<TOKEN end_char="643" id="token-5-7" morph="none" pos="word" start_char="641">the</TOKEN>
<TOKEN end_char="646" id="token-5-8" morph="none" pos="word" start_char="645">US</TOKEN>
<TOKEN end_char="650" id="token-5-9" morph="none" pos="word" start_char="648">had</TOKEN>
<TOKEN end_char="662" id="token-5-10" morph="none" pos="word" start_char="652">coronavirus</TOKEN>
<TOKEN end_char="673" id="token-5-11" morph="none" pos="word" start_char="664">antibodies</TOKEN>
<TOKEN end_char="676" id="token-5-12" morph="none" pos="word" start_char="675">in</TOKEN>
<TOKEN end_char="685" id="token-5-13" morph="none" pos="word" start_char="678">December</TOKEN>
<TOKEN end_char="690" id="token-5-14" morph="none" pos="word" start_char="687">2019</TOKEN>
<TOKEN end_char="691" id="token-5-15" morph="none" pos="punct" start_char="691">.</TOKEN>
</SEG>
<SEG end_char="745" id="segment-6" start_char="695">
<ORIGINAL_TEXT>Visit Business Insider's homepage for more stories.</ORIGINAL_TEXT>
<TOKEN end_char="699" id="token-6-0" morph="none" pos="word" start_char="695">Visit</TOKEN>
<TOKEN end_char="708" id="token-6-1" morph="none" pos="word" start_char="701">Business</TOKEN>
<TOKEN end_char="718" id="token-6-2" morph="none" pos="word" start_char="710">Insider's</TOKEN>
<TOKEN end_char="727" id="token-6-3" morph="none" pos="word" start_char="720">homepage</TOKEN>
<TOKEN end_char="731" id="token-6-4" morph="none" pos="word" start_char="729">for</TOKEN>
<TOKEN end_char="736" id="token-6-5" morph="none" pos="word" start_char="733">more</TOKEN>
<TOKEN end_char="744" id="token-6-6" morph="none" pos="word" start_char="738">stories</TOKEN>
<TOKEN end_char="745" id="token-6-7" morph="none" pos="punct" start_char="745">.</TOKEN>
</SEG>
<SEG end_char="912" id="segment-7" start_char="750">
<ORIGINAL_TEXT>A growing body of evidence suggests the coronavirus was spreading globally months before the first cases in a Wuhan market captured global attention last December.</ORIGINAL_TEXT>
<TOKEN end_char="750" id="token-7-0" morph="none" pos="word" start_char="750">A</TOKEN>
<TOKEN end_char="758" id="token-7-1" morph="none" pos="word" start_char="752">growing</TOKEN>
<TOKEN end_char="763" id="token-7-2" morph="none" pos="word" start_char="760">body</TOKEN>
<TOKEN end_char="766" id="token-7-3" morph="none" pos="word" start_char="765">of</TOKEN>
<TOKEN end_char="775" id="token-7-4" morph="none" pos="word" start_char="768">evidence</TOKEN>
<TOKEN end_char="784" id="token-7-5" morph="none" pos="word" start_char="777">suggests</TOKEN>
<TOKEN end_char="788" id="token-7-6" morph="none" pos="word" start_char="786">the</TOKEN>
<TOKEN end_char="800" id="token-7-7" morph="none" pos="word" start_char="790">coronavirus</TOKEN>
<TOKEN end_char="804" id="token-7-8" morph="none" pos="word" start_char="802">was</TOKEN>
<TOKEN end_char="814" id="token-7-9" morph="none" pos="word" start_char="806">spreading</TOKEN>
<TOKEN end_char="823" id="token-7-10" morph="none" pos="word" start_char="816">globally</TOKEN>
<TOKEN end_char="830" id="token-7-11" morph="none" pos="word" start_char="825">months</TOKEN>
<TOKEN end_char="837" id="token-7-12" morph="none" pos="word" start_char="832">before</TOKEN>
<TOKEN end_char="841" id="token-7-13" morph="none" pos="word" start_char="839">the</TOKEN>
<TOKEN end_char="847" id="token-7-14" morph="none" pos="word" start_char="843">first</TOKEN>
<TOKEN end_char="853" id="token-7-15" morph="none" pos="word" start_char="849">cases</TOKEN>
<TOKEN end_char="856" id="token-7-16" morph="none" pos="word" start_char="855">in</TOKEN>
<TOKEN end_char="858" id="token-7-17" morph="none" pos="word" start_char="858">a</TOKEN>
<TOKEN end_char="864" id="token-7-18" morph="none" pos="word" start_char="860">Wuhan</TOKEN>
<TOKEN end_char="871" id="token-7-19" morph="none" pos="word" start_char="866">market</TOKEN>
<TOKEN end_char="880" id="token-7-20" morph="none" pos="word" start_char="873">captured</TOKEN>
<TOKEN end_char="887" id="token-7-21" morph="none" pos="word" start_char="882">global</TOKEN>
<TOKEN end_char="897" id="token-7-22" morph="none" pos="word" start_char="889">attention</TOKEN>
<TOKEN end_char="902" id="token-7-23" morph="none" pos="word" start_char="899">last</TOKEN>
<TOKEN end_char="911" id="token-7-24" morph="none" pos="word" start_char="904">December</TOKEN>
<TOKEN end_char="912" id="token-7-25" morph="none" pos="punct" start_char="912">.</TOKEN>
</SEG>
<SEG end_char="1057" id="segment-8" start_char="915">
<ORIGINAL_TEXT>The World Health Organization sent an international team to China in January to investigate the virus' origins and when it started circulating.</ORIGINAL_TEXT>
<TOKEN end_char="917" id="token-8-0" morph="none" pos="word" start_char="915">The</TOKEN>
<TOKEN end_char="923" id="token-8-1" morph="none" pos="word" start_char="919">World</TOKEN>
<TOKEN end_char="930" id="token-8-2" morph="none" pos="word" start_char="925">Health</TOKEN>
<TOKEN end_char="943" id="token-8-3" morph="none" pos="word" start_char="932">Organization</TOKEN>
<TOKEN end_char="948" id="token-8-4" morph="none" pos="word" start_char="945">sent</TOKEN>
<TOKEN end_char="951" id="token-8-5" morph="none" pos="word" start_char="950">an</TOKEN>
<TOKEN end_char="965" id="token-8-6" morph="none" pos="word" start_char="953">international</TOKEN>
<TOKEN end_char="970" id="token-8-7" morph="none" pos="word" start_char="967">team</TOKEN>
<TOKEN end_char="973" id="token-8-8" morph="none" pos="word" start_char="972">to</TOKEN>
<TOKEN end_char="979" id="token-8-9" morph="none" pos="word" start_char="975">China</TOKEN>
<TOKEN end_char="982" id="token-8-10" morph="none" pos="word" start_char="981">in</TOKEN>
<TOKEN end_char="990" id="token-8-11" morph="none" pos="word" start_char="984">January</TOKEN>
<TOKEN end_char="993" id="token-8-12" morph="none" pos="word" start_char="992">to</TOKEN>
<TOKEN end_char="1005" id="token-8-13" morph="none" pos="word" start_char="995">investigate</TOKEN>
<TOKEN end_char="1009" id="token-8-14" morph="none" pos="word" start_char="1007">the</TOKEN>
<TOKEN end_char="1015" id="token-8-15" morph="none" pos="word" start_char="1011">virus</TOKEN>
<TOKEN end_char="1016" id="token-8-16" morph="none" pos="punct" start_char="1016">'</TOKEN>
<TOKEN end_char="1024" id="token-8-17" morph="none" pos="word" start_char="1018">origins</TOKEN>
<TOKEN end_char="1028" id="token-8-18" morph="none" pos="word" start_char="1026">and</TOKEN>
<TOKEN end_char="1033" id="token-8-19" morph="none" pos="word" start_char="1030">when</TOKEN>
<TOKEN end_char="1036" id="token-8-20" morph="none" pos="word" start_char="1035">it</TOKEN>
<TOKEN end_char="1044" id="token-8-21" morph="none" pos="word" start_char="1038">started</TOKEN>
<TOKEN end_char="1056" id="token-8-22" morph="none" pos="word" start_char="1046">circulating</TOKEN>
<TOKEN end_char="1057" id="token-8-23" morph="none" pos="punct" start_char="1057">.</TOKEN>
</SEG>
<SEG end_char="1191" id="segment-9" start_char="1060">
<ORIGINAL_TEXT>The team assessed medical records from more than 230 clinics across Hubei — the province where Wuhan is located — to look for clues.</ORIGINAL_TEXT>
<TOKEN end_char="1062" id="token-9-0" morph="none" pos="word" start_char="1060">The</TOKEN>
<TOKEN end_char="1067" id="token-9-1" morph="none" pos="word" start_char="1064">team</TOKEN>
<TOKEN end_char="1076" id="token-9-2" morph="none" pos="word" start_char="1069">assessed</TOKEN>
<TOKEN end_char="1084" id="token-9-3" morph="none" pos="word" start_char="1078">medical</TOKEN>
<TOKEN end_char="1092" id="token-9-4" morph="none" pos="word" start_char="1086">records</TOKEN>
<TOKEN end_char="1097" id="token-9-5" morph="none" pos="word" start_char="1094">from</TOKEN>
<TOKEN end_char="1102" id="token-9-6" morph="none" pos="word" start_char="1099">more</TOKEN>
<TOKEN end_char="1107" id="token-9-7" morph="none" pos="word" start_char="1104">than</TOKEN>
<TOKEN end_char="1111" id="token-9-8" morph="none" pos="word" start_char="1109">230</TOKEN>
<TOKEN end_char="1119" id="token-9-9" morph="none" pos="word" start_char="1113">clinics</TOKEN>
<TOKEN end_char="1126" id="token-9-10" morph="none" pos="word" start_char="1121">across</TOKEN>
<TOKEN end_char="1132" id="token-9-11" morph="none" pos="word" start_char="1128">Hubei</TOKEN>
<TOKEN end_char="1134" id="token-9-12" morph="none" pos="punct" start_char="1134">—</TOKEN>
<TOKEN end_char="1138" id="token-9-13" morph="none" pos="word" start_char="1136">the</TOKEN>
<TOKEN end_char="1147" id="token-9-14" morph="none" pos="word" start_char="1140">province</TOKEN>
<TOKEN end_char="1153" id="token-9-15" morph="none" pos="word" start_char="1149">where</TOKEN>
<TOKEN end_char="1159" id="token-9-16" morph="none" pos="word" start_char="1155">Wuhan</TOKEN>
<TOKEN end_char="1162" id="token-9-17" morph="none" pos="word" start_char="1161">is</TOKEN>
<TOKEN end_char="1170" id="token-9-18" morph="none" pos="word" start_char="1164">located</TOKEN>
<TOKEN end_char="1172" id="token-9-19" morph="none" pos="punct" start_char="1172">—</TOKEN>
<TOKEN end_char="1175" id="token-9-20" morph="none" pos="word" start_char="1174">to</TOKEN>
<TOKEN end_char="1180" id="token-9-21" morph="none" pos="word" start_char="1177">look</TOKEN>
<TOKEN end_char="1184" id="token-9-22" morph="none" pos="word" start_char="1182">for</TOKEN>
<TOKEN end_char="1190" id="token-9-23" morph="none" pos="word" start_char="1186">clues</TOKEN>
<TOKEN end_char="1191" id="token-9-24" morph="none" pos="punct" start_char="1191">.</TOKEN>
</SEG>
<SEG end_char="1365" id="segment-10" start_char="1193">
<ORIGINAL_TEXT>More than 90 patients in the province were hospitalized with pneumonia or coronavirus-like symptoms in October and November 2019, the Wall Street Journal reported Wednesday.</ORIGINAL_TEXT>
<TOKEN end_char="1196" id="token-10-0" morph="none" pos="word" start_char="1193">More</TOKEN>
<TOKEN end_char="1201" id="token-10-1" morph="none" pos="word" start_char="1198">than</TOKEN>
<TOKEN end_char="1204" id="token-10-2" morph="none" pos="word" start_char="1203">90</TOKEN>
<TOKEN end_char="1213" id="token-10-3" morph="none" pos="word" start_char="1206">patients</TOKEN>
<TOKEN end_char="1216" id="token-10-4" morph="none" pos="word" start_char="1215">in</TOKEN>
<TOKEN end_char="1220" id="token-10-5" morph="none" pos="word" start_char="1218">the</TOKEN>
<TOKEN end_char="1229" id="token-10-6" morph="none" pos="word" start_char="1222">province</TOKEN>
<TOKEN end_char="1234" id="token-10-7" morph="none" pos="word" start_char="1231">were</TOKEN>
<TOKEN end_char="1247" id="token-10-8" morph="none" pos="word" start_char="1236">hospitalized</TOKEN>
<TOKEN end_char="1252" id="token-10-9" morph="none" pos="word" start_char="1249">with</TOKEN>
<TOKEN end_char="1262" id="token-10-10" morph="none" pos="word" start_char="1254">pneumonia</TOKEN>
<TOKEN end_char="1265" id="token-10-11" morph="none" pos="word" start_char="1264">or</TOKEN>
<TOKEN end_char="1282" id="token-10-12" morph="none" pos="unknown" start_char="1267">coronavirus-like</TOKEN>
<TOKEN end_char="1291" id="token-10-13" morph="none" pos="word" start_char="1284">symptoms</TOKEN>
<TOKEN end_char="1294" id="token-10-14" morph="none" pos="word" start_char="1293">in</TOKEN>
<TOKEN end_char="1302" id="token-10-15" morph="none" pos="word" start_char="1296">October</TOKEN>
<TOKEN end_char="1306" id="token-10-16" morph="none" pos="word" start_char="1304">and</TOKEN>
<TOKEN end_char="1315" id="token-10-17" morph="none" pos="word" start_char="1308">November</TOKEN>
<TOKEN end_char="1320" id="token-10-18" morph="none" pos="word" start_char="1317">2019</TOKEN>
<TOKEN end_char="1321" id="token-10-19" morph="none" pos="punct" start_char="1321">,</TOKEN>
<TOKEN end_char="1325" id="token-10-20" morph="none" pos="word" start_char="1323">the</TOKEN>
<TOKEN end_char="1330" id="token-10-21" morph="none" pos="word" start_char="1327">Wall</TOKEN>
<TOKEN end_char="1337" id="token-10-22" morph="none" pos="word" start_char="1332">Street</TOKEN>
<TOKEN end_char="1345" id="token-10-23" morph="none" pos="word" start_char="1339">Journal</TOKEN>
<TOKEN end_char="1354" id="token-10-24" morph="none" pos="word" start_char="1347">reported</TOKEN>
<TOKEN end_char="1364" id="token-10-25" morph="none" pos="word" start_char="1356">Wednesday</TOKEN>
<TOKEN end_char="1365" id="token-10-26" morph="none" pos="punct" start_char="1365">.</TOKEN>
</SEG>
<SEG end_char="1500" id="segment-11" start_char="1368">
<ORIGINAL_TEXT>This finding lends credence to other research from China that shows people were getting sick in Wuhan in November and early December.</ORIGINAL_TEXT>
<TOKEN end_char="1371" id="token-11-0" morph="none" pos="word" start_char="1368">This</TOKEN>
<TOKEN end_char="1379" id="token-11-1" morph="none" pos="word" start_char="1373">finding</TOKEN>
<TOKEN end_char="1385" id="token-11-2" morph="none" pos="word" start_char="1381">lends</TOKEN>
<TOKEN end_char="1394" id="token-11-3" morph="none" pos="word" start_char="1387">credence</TOKEN>
<TOKEN end_char="1397" id="token-11-4" morph="none" pos="word" start_char="1396">to</TOKEN>
<TOKEN end_char="1403" id="token-11-5" morph="none" pos="word" start_char="1399">other</TOKEN>
<TOKEN end_char="1412" id="token-11-6" morph="none" pos="word" start_char="1405">research</TOKEN>
<TOKEN end_char="1417" id="token-11-7" morph="none" pos="word" start_char="1414">from</TOKEN>
<TOKEN end_char="1423" id="token-11-8" morph="none" pos="word" start_char="1419">China</TOKEN>
<TOKEN end_char="1428" id="token-11-9" morph="none" pos="word" start_char="1425">that</TOKEN>
<TOKEN end_char="1434" id="token-11-10" morph="none" pos="word" start_char="1430">shows</TOKEN>
<TOKEN end_char="1441" id="token-11-11" morph="none" pos="word" start_char="1436">people</TOKEN>
<TOKEN end_char="1446" id="token-11-12" morph="none" pos="word" start_char="1443">were</TOKEN>
<TOKEN end_char="1454" id="token-11-13" morph="none" pos="word" start_char="1448">getting</TOKEN>
<TOKEN end_char="1459" id="token-11-14" morph="none" pos="word" start_char="1456">sick</TOKEN>
<TOKEN end_char="1462" id="token-11-15" morph="none" pos="word" start_char="1461">in</TOKEN>
<TOKEN end_char="1468" id="token-11-16" morph="none" pos="word" start_char="1464">Wuhan</TOKEN>
<TOKEN end_char="1471" id="token-11-17" morph="none" pos="word" start_char="1470">in</TOKEN>
<TOKEN end_char="1480" id="token-11-18" morph="none" pos="word" start_char="1473">November</TOKEN>
<TOKEN end_char="1484" id="token-11-19" morph="none" pos="word" start_char="1482">and</TOKEN>
<TOKEN end_char="1490" id="token-11-20" morph="none" pos="word" start_char="1486">early</TOKEN>
<TOKEN end_char="1499" id="token-11-21" morph="none" pos="word" start_char="1492">December</TOKEN>
<TOKEN end_char="1500" id="token-11-22" morph="none" pos="punct" start_char="1500">.</TOKEN>
</SEG>
<SEG end_char="1694" id="segment-12" start_char="1502">
<ORIGINAL_TEXT>One analysis, based on satellite images of Wuhan hospitals and online searches for COVID-19 symptoms in the area, suggested the virus may have started circulating there as early as late summer.</ORIGINAL_TEXT>
<TOKEN end_char="1504" id="token-12-0" morph="none" pos="word" start_char="1502">One</TOKEN>
<TOKEN end_char="1513" id="token-12-1" morph="none" pos="word" start_char="1506">analysis</TOKEN>
<TOKEN end_char="1514" id="token-12-2" morph="none" pos="punct" start_char="1514">,</TOKEN>
<TOKEN end_char="1520" id="token-12-3" morph="none" pos="word" start_char="1516">based</TOKEN>
<TOKEN end_char="1523" id="token-12-4" morph="none" pos="word" start_char="1522">on</TOKEN>
<TOKEN end_char="1533" id="token-12-5" morph="none" pos="word" start_char="1525">satellite</TOKEN>
<TOKEN end_char="1540" id="token-12-6" morph="none" pos="word" start_char="1535">images</TOKEN>
<TOKEN end_char="1543" id="token-12-7" morph="none" pos="word" start_char="1542">of</TOKEN>
<TOKEN end_char="1549" id="token-12-8" morph="none" pos="word" start_char="1545">Wuhan</TOKEN>
<TOKEN end_char="1559" id="token-12-9" morph="none" pos="word" start_char="1551">hospitals</TOKEN>
<TOKEN end_char="1563" id="token-12-10" morph="none" pos="word" start_char="1561">and</TOKEN>
<TOKEN end_char="1570" id="token-12-11" morph="none" pos="word" start_char="1565">online</TOKEN>
<TOKEN end_char="1579" id="token-12-12" morph="none" pos="word" start_char="1572">searches</TOKEN>
<TOKEN end_char="1583" id="token-12-13" morph="none" pos="word" start_char="1581">for</TOKEN>
<TOKEN end_char="1592" id="token-12-14" morph="none" pos="unknown" start_char="1585">COVID-19</TOKEN>
<TOKEN end_char="1601" id="token-12-15" morph="none" pos="word" start_char="1594">symptoms</TOKEN>
<TOKEN end_char="1604" id="token-12-16" morph="none" pos="word" start_char="1603">in</TOKEN>
<TOKEN end_char="1608" id="token-12-17" morph="none" pos="word" start_char="1606">the</TOKEN>
<TOKEN end_char="1613" id="token-12-18" morph="none" pos="word" start_char="1610">area</TOKEN>
<TOKEN end_char="1614" id="token-12-19" morph="none" pos="punct" start_char="1614">,</TOKEN>
<TOKEN end_char="1624" id="token-12-20" morph="none" pos="word" start_char="1616">suggested</TOKEN>
<TOKEN end_char="1628" id="token-12-21" morph="none" pos="word" start_char="1626">the</TOKEN>
<TOKEN end_char="1634" id="token-12-22" morph="none" pos="word" start_char="1630">virus</TOKEN>
<TOKEN end_char="1638" id="token-12-23" morph="none" pos="word" start_char="1636">may</TOKEN>
<TOKEN end_char="1643" id="token-12-24" morph="none" pos="word" start_char="1640">have</TOKEN>
<TOKEN end_char="1651" id="token-12-25" morph="none" pos="word" start_char="1645">started</TOKEN>
<TOKEN end_char="1663" id="token-12-26" morph="none" pos="word" start_char="1653">circulating</TOKEN>
<TOKEN end_char="1669" id="token-12-27" morph="none" pos="word" start_char="1665">there</TOKEN>
<TOKEN end_char="1672" id="token-12-28" morph="none" pos="word" start_char="1671">as</TOKEN>
<TOKEN end_char="1678" id="token-12-29" morph="none" pos="word" start_char="1674">early</TOKEN>
<TOKEN end_char="1681" id="token-12-30" morph="none" pos="word" start_char="1680">as</TOKEN>
<TOKEN end_char="1686" id="token-12-31" morph="none" pos="word" start_char="1683">late</TOKEN>
<TOKEN end_char="1693" id="token-12-32" morph="none" pos="word" start_char="1688">summer</TOKEN>
<TOKEN end_char="1694" id="token-12-33" morph="none" pos="punct" start_char="1694">.</TOKEN>
</SEG>
<SEG end_char="1706" id="segment-13" start_char="1697">
<ORIGINAL_TEXT>Newsletter</ORIGINAL_TEXT>
<TOKEN end_char="1706" id="token-13-0" morph="none" pos="word" start_char="1697">Newsletter</TOKEN>
</SEG>
<SEG end_char="1752" id="segment-14" start_char="1709">
<ORIGINAL_TEXT>Get the latest healthcare news and analysis.</ORIGINAL_TEXT>
<TOKEN end_char="1711" id="token-14-0" morph="none" pos="word" start_char="1709">Get</TOKEN>
<TOKEN end_char="1715" id="token-14-1" morph="none" pos="word" start_char="1713">the</TOKEN>
<TOKEN end_char="1722" id="token-14-2" morph="none" pos="word" start_char="1717">latest</TOKEN>
<TOKEN end_char="1733" id="token-14-3" morph="none" pos="word" start_char="1724">healthcare</TOKEN>
<TOKEN end_char="1738" id="token-14-4" morph="none" pos="word" start_char="1735">news</TOKEN>
<TOKEN end_char="1742" id="token-14-5" morph="none" pos="word" start_char="1740">and</TOKEN>
<TOKEN end_char="1751" id="token-14-6" morph="none" pos="word" start_char="1744">analysis</TOKEN>
<TOKEN end_char="1752" id="token-14-7" morph="none" pos="punct" start_char="1752">.</TOKEN>
</SEG>
<SEG end_char="1775" id="segment-15" start_char="1755">
<ORIGINAL_TEXT>Something is loading.</ORIGINAL_TEXT>
<TOKEN end_char="1763" id="token-15-0" morph="none" pos="word" start_char="1755">Something</TOKEN>
<TOKEN end_char="1766" id="token-15-1" morph="none" pos="word" start_char="1765">is</TOKEN>
<TOKEN end_char="1774" id="token-15-2" morph="none" pos="word" start_char="1768">loading</TOKEN>
<TOKEN end_char="1775" id="token-15-3" morph="none" pos="punct" start_char="1775">.</TOKEN>
</SEG>
<SEG end_char="1791" id="segment-16" start_char="1779">
<ORIGINAL_TEXT>Email address</ORIGINAL_TEXT>
<TOKEN end_char="1783" id="token-16-0" morph="none" pos="word" start_char="1779">Email</TOKEN>
<TOKEN end_char="1791" id="token-16-1" morph="none" pos="word" start_char="1785">address</TOKEN>
<TRANSLATED_TEXT>E-mail address</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="1950" id="segment-17" start_char="1794">
<ORIGINAL_TEXT>By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy Policy.</ORIGINAL_TEXT>
<TOKEN end_char="1795" id="token-17-0" morph="none" pos="word" start_char="1794">By</TOKEN>
<TOKEN end_char="1804" id="token-17-1" morph="none" pos="word" start_char="1797">clicking</TOKEN>
<TOKEN end_char="1806" id="token-17-2" morph="none" pos="punct" start_char="1806">‘</TOKEN>
<TOKEN end_char="1810" id="token-17-3" morph="none" pos="word" start_char="1807">Sign</TOKEN>
<TOKEN end_char="1813" id="token-17-4" morph="none" pos="word" start_char="1812">up</TOKEN>
<TOKEN end_char="1815" id="token-17-5" morph="none" pos="punct" start_char="1814">’,</TOKEN>
<TOKEN end_char="1819" id="token-17-6" morph="none" pos="word" start_char="1817">you</TOKEN>
<TOKEN end_char="1825" id="token-17-7" morph="none" pos="word" start_char="1821">agree</TOKEN>
<TOKEN end_char="1828" id="token-17-8" morph="none" pos="word" start_char="1827">to</TOKEN>
<TOKEN end_char="1836" id="token-17-9" morph="none" pos="word" start_char="1830">receive</TOKEN>
<TOKEN end_char="1846" id="token-17-10" morph="none" pos="word" start_char="1838">marketing</TOKEN>
<TOKEN end_char="1853" id="token-17-11" morph="none" pos="word" start_char="1848">emails</TOKEN>
<TOKEN end_char="1858" id="token-17-12" morph="none" pos="word" start_char="1855">from</TOKEN>
<TOKEN end_char="1866" id="token-17-13" morph="none" pos="word" start_char="1860">Insider</TOKEN>
<TOKEN end_char="1869" id="token-17-14" morph="none" pos="word" start_char="1868">as</TOKEN>
<TOKEN end_char="1874" id="token-17-15" morph="none" pos="word" start_char="1871">well</TOKEN>
<TOKEN end_char="1877" id="token-17-16" morph="none" pos="word" start_char="1876">as</TOKEN>
<TOKEN end_char="1883" id="token-17-17" morph="none" pos="word" start_char="1879">other</TOKEN>
<TOKEN end_char="1891" id="token-17-18" morph="none" pos="word" start_char="1885">partner</TOKEN>
<TOKEN end_char="1898" id="token-17-19" morph="none" pos="word" start_char="1893">offers</TOKEN>
<TOKEN end_char="1902" id="token-17-20" morph="none" pos="word" start_char="1900">and</TOKEN>
<TOKEN end_char="1909" id="token-17-21" morph="none" pos="word" start_char="1904">accept</TOKEN>
<TOKEN end_char="1913" id="token-17-22" morph="none" pos="word" start_char="1911">our</TOKEN>
<TOKEN end_char="1919" id="token-17-23" morph="none" pos="word" start_char="1915">Terms</TOKEN>
<TOKEN end_char="1922" id="token-17-24" morph="none" pos="word" start_char="1921">of</TOKEN>
<TOKEN end_char="1930" id="token-17-25" morph="none" pos="word" start_char="1924">Service</TOKEN>
<TOKEN end_char="1934" id="token-17-26" morph="none" pos="word" start_char="1932">and</TOKEN>
<TOKEN end_char="1942" id="token-17-27" morph="none" pos="word" start_char="1936">Privacy</TOKEN>
<TOKEN end_char="1949" id="token-17-28" morph="none" pos="word" start_char="1944">Policy</TOKEN>
<TOKEN end_char="1950" id="token-17-29" morph="none" pos="punct" start_char="1950">.</TOKEN>
</SEG>
<SEG end_char="2076" id="segment-18" start_char="1953">
<ORIGINAL_TEXT>A study from Milan's National Cancer Institute also found that four of Italy's coronavirus cases dated back to October 2019.</ORIGINAL_TEXT>
<TOKEN end_char="1953" id="token-18-0" morph="none" pos="word" start_char="1953">A</TOKEN>
<TOKEN end_char="1959" id="token-18-1" morph="none" pos="word" start_char="1955">study</TOKEN>
<TOKEN end_char="1964" id="token-18-2" morph="none" pos="word" start_char="1961">from</TOKEN>
<TOKEN end_char="1972" id="token-18-3" morph="none" pos="word" start_char="1966">Milan's</TOKEN>
<TOKEN end_char="1981" id="token-18-4" morph="none" pos="word" start_char="1974">National</TOKEN>
<TOKEN end_char="1988" id="token-18-5" morph="none" pos="word" start_char="1983">Cancer</TOKEN>
<TOKEN end_char="1998" id="token-18-6" morph="none" pos="word" start_char="1990">Institute</TOKEN>
<TOKEN end_char="2003" id="token-18-7" morph="none" pos="word" start_char="2000">also</TOKEN>
<TOKEN end_char="2009" id="token-18-8" morph="none" pos="word" start_char="2005">found</TOKEN>
<TOKEN end_char="2014" id="token-18-9" morph="none" pos="word" start_char="2011">that</TOKEN>
<TOKEN end_char="2019" id="token-18-10" morph="none" pos="word" start_char="2016">four</TOKEN>
<TOKEN end_char="2022" id="token-18-11" morph="none" pos="word" start_char="2021">of</TOKEN>
<TOKEN end_char="2030" id="token-18-12" morph="none" pos="word" start_char="2024">Italy's</TOKEN>
<TOKEN end_char="2042" id="token-18-13" morph="none" pos="word" start_char="2032">coronavirus</TOKEN>
<TOKEN end_char="2048" id="token-18-14" morph="none" pos="word" start_char="2044">cases</TOKEN>
<TOKEN end_char="2054" id="token-18-15" morph="none" pos="word" start_char="2050">dated</TOKEN>
<TOKEN end_char="2059" id="token-18-16" morph="none" pos="word" start_char="2056">back</TOKEN>
<TOKEN end_char="2062" id="token-18-17" morph="none" pos="word" start_char="2061">to</TOKEN>
<TOKEN end_char="2070" id="token-18-18" morph="none" pos="word" start_char="2064">October</TOKEN>
<TOKEN end_char="2075" id="token-18-19" morph="none" pos="word" start_char="2072">2019</TOKEN>
<TOKEN end_char="2076" id="token-18-20" morph="none" pos="punct" start_char="2076">.</TOKEN>
</SEG>
<SEG end_char="2154" id="segment-19" start_char="2078">
<ORIGINAL_TEXT>Another study suggests the virus reached the US' West Coast in December 2019.</ORIGINAL_TEXT>
<TOKEN end_char="2084" id="token-19-0" morph="none" pos="word" start_char="2078">Another</TOKEN>
<TOKEN end_char="2090" id="token-19-1" morph="none" pos="word" start_char="2086">study</TOKEN>
<TOKEN end_char="2099" id="token-19-2" morph="none" pos="word" start_char="2092">suggests</TOKEN>
<TOKEN end_char="2103" id="token-19-3" morph="none" pos="word" start_char="2101">the</TOKEN>
<TOKEN end_char="2109" id="token-19-4" morph="none" pos="word" start_char="2105">virus</TOKEN>
<TOKEN end_char="2117" id="token-19-5" morph="none" pos="word" start_char="2111">reached</TOKEN>
<TOKEN end_char="2121" id="token-19-6" morph="none" pos="word" start_char="2119">the</TOKEN>
<TOKEN end_char="2124" id="token-19-7" morph="none" pos="word" start_char="2123">US</TOKEN>
<TOKEN end_char="2125" id="token-19-8" morph="none" pos="punct" start_char="2125">'</TOKEN>
<TOKEN end_char="2130" id="token-19-9" morph="none" pos="word" start_char="2127">West</TOKEN>
<TOKEN end_char="2136" id="token-19-10" morph="none" pos="word" start_char="2132">Coast</TOKEN>
<TOKEN end_char="2139" id="token-19-11" morph="none" pos="word" start_char="2138">in</TOKEN>
<TOKEN end_char="2148" id="token-19-12" morph="none" pos="word" start_char="2141">December</TOKEN>
<TOKEN end_char="2153" id="token-19-13" morph="none" pos="word" start_char="2150">2019</TOKEN>
<TOKEN end_char="2154" id="token-19-14" morph="none" pos="punct" start_char="2154">.</TOKEN>
</SEG>
<SEG end_char="2345" id="segment-20" start_char="2157">
<ORIGINAL_TEXT>Although pinpointing the exact date of the virus' first jump from animals to people is impossible without more data, these findings suggest the pandemic's December anniversary is arbitrary.</ORIGINAL_TEXT>
<TOKEN end_char="2164" id="token-20-0" morph="none" pos="word" start_char="2157">Although</TOKEN>
<TOKEN end_char="2176" id="token-20-1" morph="none" pos="word" start_char="2166">pinpointing</TOKEN>
<TOKEN end_char="2180" id="token-20-2" morph="none" pos="word" start_char="2178">the</TOKEN>
<TOKEN end_char="2186" id="token-20-3" morph="none" pos="word" start_char="2182">exact</TOKEN>
<TOKEN end_char="2191" id="token-20-4" morph="none" pos="word" start_char="2188">date</TOKEN>
<TOKEN end_char="2194" id="token-20-5" morph="none" pos="word" start_char="2193">of</TOKEN>
<TOKEN end_char="2198" id="token-20-6" morph="none" pos="word" start_char="2196">the</TOKEN>
<TOKEN end_char="2204" id="token-20-7" morph="none" pos="word" start_char="2200">virus</TOKEN>
<TOKEN end_char="2205" id="token-20-8" morph="none" pos="punct" start_char="2205">'</TOKEN>
<TOKEN end_char="2211" id="token-20-9" morph="none" pos="word" start_char="2207">first</TOKEN>
<TOKEN end_char="2216" id="token-20-10" morph="none" pos="word" start_char="2213">jump</TOKEN>
<TOKEN end_char="2221" id="token-20-11" morph="none" pos="word" start_char="2218">from</TOKEN>
<TOKEN end_char="2229" id="token-20-12" morph="none" pos="word" start_char="2223">animals</TOKEN>
<TOKEN end_char="2232" id="token-20-13" morph="none" pos="word" start_char="2231">to</TOKEN>
<TOKEN end_char="2239" id="token-20-14" morph="none" pos="word" start_char="2234">people</TOKEN>
<TOKEN end_char="2242" id="token-20-15" morph="none" pos="word" start_char="2241">is</TOKEN>
<TOKEN end_char="2253" id="token-20-16" morph="none" pos="word" start_char="2244">impossible</TOKEN>
<TOKEN end_char="2261" id="token-20-17" morph="none" pos="word" start_char="2255">without</TOKEN>
<TOKEN end_char="2266" id="token-20-18" morph="none" pos="word" start_char="2263">more</TOKEN>
<TOKEN end_char="2271" id="token-20-19" morph="none" pos="word" start_char="2268">data</TOKEN>
<TOKEN end_char="2272" id="token-20-20" morph="none" pos="punct" start_char="2272">,</TOKEN>
<TOKEN end_char="2278" id="token-20-21" morph="none" pos="word" start_char="2274">these</TOKEN>
<TOKEN end_char="2287" id="token-20-22" morph="none" pos="word" start_char="2280">findings</TOKEN>
<TOKEN end_char="2295" id="token-20-23" morph="none" pos="word" start_char="2289">suggest</TOKEN>
<TOKEN end_char="2299" id="token-20-24" morph="none" pos="word" start_char="2297">the</TOKEN>
<TOKEN end_char="2310" id="token-20-25" morph="none" pos="word" start_char="2301">pandemic's</TOKEN>
<TOKEN end_char="2319" id="token-20-26" morph="none" pos="word" start_char="2312">December</TOKEN>
<TOKEN end_char="2331" id="token-20-27" morph="none" pos="word" start_char="2321">anniversary</TOKEN>
<TOKEN end_char="2334" id="token-20-28" morph="none" pos="word" start_char="2333">is</TOKEN>
<TOKEN end_char="2344" id="token-20-29" morph="none" pos="word" start_char="2336">arbitrary</TOKEN>
<TOKEN end_char="2345" id="token-20-30" morph="none" pos="punct" start_char="2345">.</TOKEN>
</SEG>
<SEG end_char="2399" id="segment-21" start_char="2348">
<ORIGINAL_TEXT>The virus was spreading in Wuhan before the December</ORIGINAL_TEXT>
<TOKEN end_char="2350" id="token-21-0" morph="none" pos="word" start_char="2348">The</TOKEN>
<TOKEN end_char="2356" id="token-21-1" morph="none" pos="word" start_char="2352">virus</TOKEN>
<TOKEN end_char="2360" id="token-21-2" morph="none" pos="word" start_char="2358">was</TOKEN>
<TOKEN end_char="2370" id="token-21-3" morph="none" pos="word" start_char="2362">spreading</TOKEN>
<TOKEN end_char="2373" id="token-21-4" morph="none" pos="word" start_char="2372">in</TOKEN>
<TOKEN end_char="2379" id="token-21-5" morph="none" pos="word" start_char="2375">Wuhan</TOKEN>
<TOKEN end_char="2386" id="token-21-6" morph="none" pos="word" start_char="2381">before</TOKEN>
<TOKEN end_char="2390" id="token-21-7" morph="none" pos="word" start_char="2388">the</TOKEN>
<TOKEN end_char="2399" id="token-21-8" morph="none" pos="word" start_char="2392">December</TOKEN>
</SEG>
<SEG end_char="2492" id="segment-22" start_char="2404">
<ORIGINAL_TEXT>Healthcare workers transport bodies outside a hospital in Wuhan, China, February 5, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="2413" id="token-22-0" morph="none" pos="word" start_char="2404">Healthcare</TOKEN>
<TOKEN end_char="2421" id="token-22-1" morph="none" pos="word" start_char="2415">workers</TOKEN>
<TOKEN end_char="2431" id="token-22-2" morph="none" pos="word" start_char="2423">transport</TOKEN>
<TOKEN end_char="2438" id="token-22-3" morph="none" pos="word" start_char="2433">bodies</TOKEN>
<TOKEN end_char="2446" id="token-22-4" morph="none" pos="word" start_char="2440">outside</TOKEN>
<TOKEN end_char="2448" id="token-22-5" morph="none" pos="word" start_char="2448">a</TOKEN>
<TOKEN end_char="2457" id="token-22-6" morph="none" pos="word" start_char="2450">hospital</TOKEN>
<TOKEN end_char="2460" id="token-22-7" morph="none" pos="word" start_char="2459">in</TOKEN>
<TOKEN end_char="2466" id="token-22-8" morph="none" pos="word" start_char="2462">Wuhan</TOKEN>
<TOKEN end_char="2467" id="token-22-9" morph="none" pos="punct" start_char="2467">,</TOKEN>
<TOKEN end_char="2473" id="token-22-10" morph="none" pos="word" start_char="2469">China</TOKEN>
<TOKEN end_char="2474" id="token-22-11" morph="none" pos="punct" start_char="2474">,</TOKEN>
<TOKEN end_char="2483" id="token-22-12" morph="none" pos="word" start_char="2476">February</TOKEN>
<TOKEN end_char="2485" id="token-22-13" morph="none" pos="word" start_char="2485">5</TOKEN>
<TOKEN end_char="2486" id="token-22-14" morph="none" pos="punct" start_char="2486">,</TOKEN>
<TOKEN end_char="2491" id="token-22-15" morph="none" pos="word" start_char="2488">2020</TOKEN>
<TOKEN end_char="2492" id="token-22-16" morph="none" pos="punct" start_char="2492">.</TOKEN>
</SEG>
<SEG end_char="2499" id="segment-23" start_char="2495">
<ORIGINAL_TEXT>Getty</ORIGINAL_TEXT>
<TOKEN end_char="2499" id="token-23-0" morph="none" pos="word" start_char="2495">Getty</TOKEN>
</SEG>
<SEG end_char="2651" id="segment-24" start_char="2503">
<ORIGINAL_TEXT>Wuhan public-health officials initially told the WHO about a mysterious illness that would later be named the novel coronavirus on December 31, 2019.</ORIGINAL_TEXT>
<TOKEN end_char="2507" id="token-24-0" morph="none" pos="word" start_char="2503">Wuhan</TOKEN>
<TOKEN end_char="2521" id="token-24-1" morph="none" pos="unknown" start_char="2509">public-health</TOKEN>
<TOKEN end_char="2531" id="token-24-2" morph="none" pos="word" start_char="2523">officials</TOKEN>
<TOKEN end_char="2541" id="token-24-3" morph="none" pos="word" start_char="2533">initially</TOKEN>
<TOKEN end_char="2546" id="token-24-4" morph="none" pos="word" start_char="2543">told</TOKEN>
<TOKEN end_char="2550" id="token-24-5" morph="none" pos="word" start_char="2548">the</TOKEN>
<TOKEN end_char="2554" id="token-24-6" morph="none" pos="word" start_char="2552">WHO</TOKEN>
<TOKEN end_char="2560" id="token-24-7" morph="none" pos="word" start_char="2556">about</TOKEN>
<TOKEN end_char="2562" id="token-24-8" morph="none" pos="word" start_char="2562">a</TOKEN>
<TOKEN end_char="2573" id="token-24-9" morph="none" pos="word" start_char="2564">mysterious</TOKEN>
<TOKEN end_char="2581" id="token-24-10" morph="none" pos="word" start_char="2575">illness</TOKEN>
<TOKEN end_char="2586" id="token-24-11" morph="none" pos="word" start_char="2583">that</TOKEN>
<TOKEN end_char="2592" id="token-24-12" morph="none" pos="word" start_char="2588">would</TOKEN>
<TOKEN end_char="2598" id="token-24-13" morph="none" pos="word" start_char="2594">later</TOKEN>
<TOKEN end_char="2601" id="token-24-14" morph="none" pos="word" start_char="2600">be</TOKEN>
<TOKEN end_char="2607" id="token-24-15" morph="none" pos="word" start_char="2603">named</TOKEN>
<TOKEN end_char="2611" id="token-24-16" morph="none" pos="word" start_char="2609">the</TOKEN>
<TOKEN end_char="2617" id="token-24-17" morph="none" pos="word" start_char="2613">novel</TOKEN>
<TOKEN end_char="2629" id="token-24-18" morph="none" pos="word" start_char="2619">coronavirus</TOKEN>
<TOKEN end_char="2632" id="token-24-19" morph="none" pos="word" start_char="2631">on</TOKEN>
<TOKEN end_char="2641" id="token-24-20" morph="none" pos="word" start_char="2634">December</TOKEN>
<TOKEN end_char="2644" id="token-24-21" morph="none" pos="word" start_char="2643">31</TOKEN>
<TOKEN end_char="2645" id="token-24-22" morph="none" pos="punct" start_char="2645">,</TOKEN>
<TOKEN end_char="2650" id="token-24-23" morph="none" pos="word" start_char="2647">2019</TOKEN>
<TOKEN end_char="2651" id="token-24-24" morph="none" pos="punct" start_char="2651">.</TOKEN>
</SEG>
<SEG end_char="2805" id="segment-25" start_char="2654">
<ORIGINAL_TEXT>But government records show China's first coronavirus case happened on November 17, 2019, according to an investigation by the South China Morning Post.</ORIGINAL_TEXT>
<TOKEN end_char="2656" id="token-25-0" morph="none" pos="word" start_char="2654">But</TOKEN>
<TOKEN end_char="2667" id="token-25-1" morph="none" pos="word" start_char="2658">government</TOKEN>
<TOKEN end_char="2675" id="token-25-2" morph="none" pos="word" start_char="2669">records</TOKEN>
<TOKEN end_char="2680" id="token-25-3" morph="none" pos="word" start_char="2677">show</TOKEN>
<TOKEN end_char="2688" id="token-25-4" morph="none" pos="word" start_char="2682">China's</TOKEN>
<TOKEN end_char="2694" id="token-25-5" morph="none" pos="word" start_char="2690">first</TOKEN>
<TOKEN end_char="2706" id="token-25-6" morph="none" pos="word" start_char="2696">coronavirus</TOKEN>
<TOKEN end_char="2711" id="token-25-7" morph="none" pos="word" start_char="2708">case</TOKEN>
<TOKEN end_char="2720" id="token-25-8" morph="none" pos="word" start_char="2713">happened</TOKEN>
<TOKEN end_char="2723" id="token-25-9" morph="none" pos="word" start_char="2722">on</TOKEN>
<TOKEN end_char="2732" id="token-25-10" morph="none" pos="word" start_char="2725">November</TOKEN>
<TOKEN end_char="2735" id="token-25-11" morph="none" pos="word" start_char="2734">17</TOKEN>
<TOKEN end_char="2736" id="token-25-12" morph="none" pos="punct" start_char="2736">,</TOKEN>
<TOKEN end_char="2741" id="token-25-13" morph="none" pos="word" start_char="2738">2019</TOKEN>
<TOKEN end_char="2742" id="token-25-14" morph="none" pos="punct" start_char="2742">,</TOKEN>
<TOKEN end_char="2752" id="token-25-15" morph="none" pos="word" start_char="2744">according</TOKEN>
<TOKEN end_char="2755" id="token-25-16" morph="none" pos="word" start_char="2754">to</TOKEN>
<TOKEN end_char="2758" id="token-25-17" morph="none" pos="word" start_char="2757">an</TOKEN>
<TOKEN end_char="2772" id="token-25-18" morph="none" pos="word" start_char="2760">investigation</TOKEN>
<TOKEN end_char="2775" id="token-25-19" morph="none" pos="word" start_char="2774">by</TOKEN>
<TOKEN end_char="2779" id="token-25-20" morph="none" pos="word" start_char="2777">the</TOKEN>
<TOKEN end_char="2785" id="token-25-21" morph="none" pos="word" start_char="2781">South</TOKEN>
<TOKEN end_char="2791" id="token-25-22" morph="none" pos="word" start_char="2787">China</TOKEN>
<TOKEN end_char="2799" id="token-25-23" morph="none" pos="word" start_char="2793">Morning</TOKEN>
<TOKEN end_char="2804" id="token-25-24" morph="none" pos="word" start_char="2801">Post</TOKEN>
<TOKEN end_char="2805" id="token-25-25" morph="none" pos="punct" start_char="2805">.</TOKEN>
</SEG>
<SEG end_char="2978" id="segment-26" start_char="2808">
<ORIGINAL_TEXT>According to the SCMP, Chinese medical experts pinpointed 60 coronavirus cases from November and December by reanalyzing samples taken from patients seen during that time.</ORIGINAL_TEXT>
<TOKEN end_char="2816" id="token-26-0" morph="none" pos="word" start_char="2808">According</TOKEN>
<TOKEN end_char="2819" id="token-26-1" morph="none" pos="word" start_char="2818">to</TOKEN>
<TOKEN end_char="2823" id="token-26-2" morph="none" pos="word" start_char="2821">the</TOKEN>
<TOKEN end_char="2828" id="token-26-3" morph="none" pos="word" start_char="2825">SCMP</TOKEN>
<TOKEN end_char="2829" id="token-26-4" morph="none" pos="punct" start_char="2829">,</TOKEN>
<TOKEN end_char="2837" id="token-26-5" morph="none" pos="word" start_char="2831">Chinese</TOKEN>
<TOKEN end_char="2845" id="token-26-6" morph="none" pos="word" start_char="2839">medical</TOKEN>
<TOKEN end_char="2853" id="token-26-7" morph="none" pos="word" start_char="2847">experts</TOKEN>
<TOKEN end_char="2864" id="token-26-8" morph="none" pos="word" start_char="2855">pinpointed</TOKEN>
<TOKEN end_char="2867" id="token-26-9" morph="none" pos="word" start_char="2866">60</TOKEN>
<TOKEN end_char="2879" id="token-26-10" morph="none" pos="word" start_char="2869">coronavirus</TOKEN>
<TOKEN end_char="2885" id="token-26-11" morph="none" pos="word" start_char="2881">cases</TOKEN>
<TOKEN end_char="2890" id="token-26-12" morph="none" pos="word" start_char="2887">from</TOKEN>
<TOKEN end_char="2899" id="token-26-13" morph="none" pos="word" start_char="2892">November</TOKEN>
<TOKEN end_char="2903" id="token-26-14" morph="none" pos="word" start_char="2901">and</TOKEN>
<TOKEN end_char="2912" id="token-26-15" morph="none" pos="word" start_char="2905">December</TOKEN>
<TOKEN end_char="2915" id="token-26-16" morph="none" pos="word" start_char="2914">by</TOKEN>
<TOKEN end_char="2927" id="token-26-17" morph="none" pos="word" start_char="2917">reanalyzing</TOKEN>
<TOKEN end_char="2935" id="token-26-18" morph="none" pos="word" start_char="2929">samples</TOKEN>
<TOKEN end_char="2941" id="token-26-19" morph="none" pos="word" start_char="2937">taken</TOKEN>
<TOKEN end_char="2946" id="token-26-20" morph="none" pos="word" start_char="2943">from</TOKEN>
<TOKEN end_char="2955" id="token-26-21" morph="none" pos="word" start_char="2948">patients</TOKEN>
<TOKEN end_char="2960" id="token-26-22" morph="none" pos="word" start_char="2957">seen</TOKEN>
<TOKEN end_char="2967" id="token-26-23" morph="none" pos="word" start_char="2962">during</TOKEN>
<TOKEN end_char="2972" id="token-26-24" morph="none" pos="word" start_char="2969">that</TOKEN>
<TOKEN end_char="2977" id="token-26-25" morph="none" pos="word" start_char="2974">time</TOKEN>
<TOKEN end_char="2978" id="token-26-26" morph="none" pos="punct" start_char="2978">.</TOKEN>
</SEG>
<SEG end_char="3136" id="segment-27" start_char="2980">
<ORIGINAL_TEXT>That analysis showed that a 55-year-old from Hubei was the first known case of COVID-19 in the world, though the disease hadn't been identified at that time.</ORIGINAL_TEXT>
<TOKEN end_char="2983" id="token-27-0" morph="none" pos="word" start_char="2980">That</TOKEN>
<TOKEN end_char="2992" id="token-27-1" morph="none" pos="word" start_char="2985">analysis</TOKEN>
<TOKEN end_char="2999" id="token-27-2" morph="none" pos="word" start_char="2994">showed</TOKEN>
<TOKEN end_char="3004" id="token-27-3" morph="none" pos="word" start_char="3001">that</TOKEN>
<TOKEN end_char="3006" id="token-27-4" morph="none" pos="word" start_char="3006">a</TOKEN>
<TOKEN end_char="3018" id="token-27-5" morph="none" pos="unknown" start_char="3008">55-year-old</TOKEN>
<TOKEN end_char="3023" id="token-27-6" morph="none" pos="word" start_char="3020">from</TOKEN>
<TOKEN end_char="3029" id="token-27-7" morph="none" pos="word" start_char="3025">Hubei</TOKEN>
<TOKEN end_char="3033" id="token-27-8" morph="none" pos="word" start_char="3031">was</TOKEN>
<TOKEN end_char="3037" id="token-27-9" morph="none" pos="word" start_char="3035">the</TOKEN>
<TOKEN end_char="3043" id="token-27-10" morph="none" pos="word" start_char="3039">first</TOKEN>
<TOKEN end_char="3049" id="token-27-11" morph="none" pos="word" start_char="3045">known</TOKEN>
<TOKEN end_char="3054" id="token-27-12" morph="none" pos="word" start_char="3051">case</TOKEN>
<TOKEN end_char="3057" id="token-27-13" morph="none" pos="word" start_char="3056">of</TOKEN>
<TOKEN end_char="3066" id="token-27-14" morph="none" pos="unknown" start_char="3059">COVID-19</TOKEN>
<TOKEN end_char="3069" id="token-27-15" morph="none" pos="word" start_char="3068">in</TOKEN>
<TOKEN end_char="3073" id="token-27-16" morph="none" pos="word" start_char="3071">the</TOKEN>
<TOKEN end_char="3079" id="token-27-17" morph="none" pos="word" start_char="3075">world</TOKEN>
<TOKEN end_char="3080" id="token-27-18" morph="none" pos="punct" start_char="3080">,</TOKEN>
<TOKEN end_char="3087" id="token-27-19" morph="none" pos="word" start_char="3082">though</TOKEN>
<TOKEN end_char="3091" id="token-27-20" morph="none" pos="word" start_char="3089">the</TOKEN>
<TOKEN end_char="3099" id="token-27-21" morph="none" pos="word" start_char="3093">disease</TOKEN>
<TOKEN end_char="3106" id="token-27-22" morph="none" pos="word" start_char="3101">hadn't</TOKEN>
<TOKEN end_char="3111" id="token-27-23" morph="none" pos="word" start_char="3108">been</TOKEN>
<TOKEN end_char="3122" id="token-27-24" morph="none" pos="word" start_char="3113">identified</TOKEN>
<TOKEN end_char="3125" id="token-27-25" morph="none" pos="word" start_char="3124">at</TOKEN>
<TOKEN end_char="3130" id="token-27-26" morph="none" pos="word" start_char="3127">that</TOKEN>
<TOKEN end_char="3135" id="token-27-27" morph="none" pos="word" start_char="3132">time</TOKEN>
<TOKEN end_char="3136" id="token-27-28" morph="none" pos="punct" start_char="3136">.</TOKEN>
</SEG>
<SEG end_char="3333" id="segment-28" start_char="3139">
<ORIGINAL_TEXT>Prior to the January WHO investigation, Chinese authorities worked to sample blood from 92 people in Hubei who were hospitalized with coronavirus-like symptoms prior to the start of the pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="3143" id="token-28-0" morph="none" pos="word" start_char="3139">Prior</TOKEN>
<TOKEN end_char="3146" id="token-28-1" morph="none" pos="word" start_char="3145">to</TOKEN>
<TOKEN end_char="3150" id="token-28-2" morph="none" pos="word" start_char="3148">the</TOKEN>
<TOKEN end_char="3158" id="token-28-3" morph="none" pos="word" start_char="3152">January</TOKEN>
<TOKEN end_char="3162" id="token-28-4" morph="none" pos="word" start_char="3160">WHO</TOKEN>
<TOKEN end_char="3176" id="token-28-5" morph="none" pos="word" start_char="3164">investigation</TOKEN>
<TOKEN end_char="3177" id="token-28-6" morph="none" pos="punct" start_char="3177">,</TOKEN>
<TOKEN end_char="3185" id="token-28-7" morph="none" pos="word" start_char="3179">Chinese</TOKEN>
<TOKEN end_char="3197" id="token-28-8" morph="none" pos="word" start_char="3187">authorities</TOKEN>
<TOKEN end_char="3204" id="token-28-9" morph="none" pos="word" start_char="3199">worked</TOKEN>
<TOKEN end_char="3207" id="token-28-10" morph="none" pos="word" start_char="3206">to</TOKEN>
<TOKEN end_char="3214" id="token-28-11" morph="none" pos="word" start_char="3209">sample</TOKEN>
<TOKEN end_char="3220" id="token-28-12" morph="none" pos="word" start_char="3216">blood</TOKEN>
<TOKEN end_char="3225" id="token-28-13" morph="none" pos="word" start_char="3222">from</TOKEN>
<TOKEN end_char="3228" id="token-28-14" morph="none" pos="word" start_char="3227">92</TOKEN>
<TOKEN end_char="3235" id="token-28-15" morph="none" pos="word" start_char="3230">people</TOKEN>
<TOKEN end_char="3238" id="token-28-16" morph="none" pos="word" start_char="3237">in</TOKEN>
<TOKEN end_char="3244" id="token-28-17" morph="none" pos="word" start_char="3240">Hubei</TOKEN>
<TOKEN end_char="3248" id="token-28-18" morph="none" pos="word" start_char="3246">who</TOKEN>
<TOKEN end_char="3253" id="token-28-19" morph="none" pos="word" start_char="3250">were</TOKEN>
<TOKEN end_char="3266" id="token-28-20" morph="none" pos="word" start_char="3255">hospitalized</TOKEN>
<TOKEN end_char="3271" id="token-28-21" morph="none" pos="word" start_char="3268">with</TOKEN>
<TOKEN end_char="3288" id="token-28-22" morph="none" pos="unknown" start_char="3273">coronavirus-like</TOKEN>
<TOKEN end_char="3297" id="token-28-23" morph="none" pos="word" start_char="3290">symptoms</TOKEN>
<TOKEN end_char="3303" id="token-28-24" morph="none" pos="word" start_char="3299">prior</TOKEN>
<TOKEN end_char="3306" id="token-28-25" morph="none" pos="word" start_char="3305">to</TOKEN>
<TOKEN end_char="3310" id="token-28-26" morph="none" pos="word" start_char="3308">the</TOKEN>
<TOKEN end_char="3316" id="token-28-27" morph="none" pos="word" start_char="3312">start</TOKEN>
<TOKEN end_char="3319" id="token-28-28" morph="none" pos="word" start_char="3318">of</TOKEN>
<TOKEN end_char="3323" id="token-28-29" morph="none" pos="word" start_char="3321">the</TOKEN>
<TOKEN end_char="3332" id="token-28-30" morph="none" pos="word" start_char="3325">pandemic</TOKEN>
<TOKEN end_char="3333" id="token-28-31" morph="none" pos="punct" start_char="3333">.</TOKEN>
</SEG>
<SEG end_char="3517" id="segment-29" start_char="3336">
<ORIGINAL_TEXT>They sampled blood from two-thirds of those patients that to check for coronavirus-specific antibodies, which would indicate the patients had previously been infected with the virus.</ORIGINAL_TEXT>
<TOKEN end_char="3339" id="token-29-0" morph="none" pos="word" start_char="3336">They</TOKEN>
<TOKEN end_char="3347" id="token-29-1" morph="none" pos="word" start_char="3341">sampled</TOKEN>
<TOKEN end_char="3353" id="token-29-2" morph="none" pos="word" start_char="3349">blood</TOKEN>
<TOKEN end_char="3358" id="token-29-3" morph="none" pos="word" start_char="3355">from</TOKEN>
<TOKEN end_char="3369" id="token-29-4" morph="none" pos="unknown" start_char="3360">two-thirds</TOKEN>
<TOKEN end_char="3372" id="token-29-5" morph="none" pos="word" start_char="3371">of</TOKEN>
<TOKEN end_char="3378" id="token-29-6" morph="none" pos="word" start_char="3374">those</TOKEN>
<TOKEN end_char="3387" id="token-29-7" morph="none" pos="word" start_char="3380">patients</TOKEN>
<TOKEN end_char="3392" id="token-29-8" morph="none" pos="word" start_char="3389">that</TOKEN>
<TOKEN end_char="3395" id="token-29-9" morph="none" pos="word" start_char="3394">to</TOKEN>
<TOKEN end_char="3401" id="token-29-10" morph="none" pos="word" start_char="3397">check</TOKEN>
<TOKEN end_char="3405" id="token-29-11" morph="none" pos="word" start_char="3403">for</TOKEN>
<TOKEN end_char="3426" id="token-29-12" morph="none" pos="unknown" start_char="3407">coronavirus-specific</TOKEN>
<TOKEN end_char="3437" id="token-29-13" morph="none" pos="word" start_char="3428">antibodies</TOKEN>
<TOKEN end_char="3438" id="token-29-14" morph="none" pos="punct" start_char="3438">,</TOKEN>
<TOKEN end_char="3444" id="token-29-15" morph="none" pos="word" start_char="3440">which</TOKEN>
<TOKEN end_char="3450" id="token-29-16" morph="none" pos="word" start_char="3446">would</TOKEN>
<TOKEN end_char="3459" id="token-29-17" morph="none" pos="word" start_char="3452">indicate</TOKEN>
<TOKEN end_char="3463" id="token-29-18" morph="none" pos="word" start_char="3461">the</TOKEN>
<TOKEN end_char="3472" id="token-29-19" morph="none" pos="word" start_char="3465">patients</TOKEN>
<TOKEN end_char="3476" id="token-29-20" morph="none" pos="word" start_char="3474">had</TOKEN>
<TOKEN end_char="3487" id="token-29-21" morph="none" pos="word" start_char="3478">previously</TOKEN>
<TOKEN end_char="3492" id="token-29-22" morph="none" pos="word" start_char="3489">been</TOKEN>
<TOKEN end_char="3501" id="token-29-23" morph="none" pos="word" start_char="3494">infected</TOKEN>
<TOKEN end_char="3506" id="token-29-24" morph="none" pos="word" start_char="3503">with</TOKEN>
<TOKEN end_char="3510" id="token-29-25" morph="none" pos="word" start_char="3508">the</TOKEN>
<TOKEN end_char="3516" id="token-29-26" morph="none" pos="word" start_char="3512">virus</TOKEN>
<TOKEN end_char="3517" id="token-29-27" morph="none" pos="punct" start_char="3517">.</TOKEN>
</SEG>
<SEG end_char="3608" id="segment-30" start_char="3519">
<ORIGINAL_TEXT>All of the samples tested negative for those antibodies, the Wall Street Journal reported.</ORIGINAL_TEXT>
<TOKEN end_char="3521" id="token-30-0" morph="none" pos="word" start_char="3519">All</TOKEN>
<TOKEN end_char="3524" id="token-30-1" morph="none" pos="word" start_char="3523">of</TOKEN>
<TOKEN end_char="3528" id="token-30-2" morph="none" pos="word" start_char="3526">the</TOKEN>
<TOKEN end_char="3536" id="token-30-3" morph="none" pos="word" start_char="3530">samples</TOKEN>
<TOKEN end_char="3543" id="token-30-4" morph="none" pos="word" start_char="3538">tested</TOKEN>
<TOKEN end_char="3552" id="token-30-5" morph="none" pos="word" start_char="3545">negative</TOKEN>
<TOKEN end_char="3556" id="token-30-6" morph="none" pos="word" start_char="3554">for</TOKEN>
<TOKEN end_char="3562" id="token-30-7" morph="none" pos="word" start_char="3558">those</TOKEN>
<TOKEN end_char="3573" id="token-30-8" morph="none" pos="word" start_char="3564">antibodies</TOKEN>
<TOKEN end_char="3574" id="token-30-9" morph="none" pos="punct" start_char="3574">,</TOKEN>
<TOKEN end_char="3578" id="token-30-10" morph="none" pos="word" start_char="3576">the</TOKEN>
<TOKEN end_char="3583" id="token-30-11" morph="none" pos="word" start_char="3580">Wall</TOKEN>
<TOKEN end_char="3590" id="token-30-12" morph="none" pos="word" start_char="3585">Street</TOKEN>
<TOKEN end_char="3598" id="token-30-13" morph="none" pos="word" start_char="3592">Journal</TOKEN>
<TOKEN end_char="3607" id="token-30-14" morph="none" pos="word" start_char="3600">reported</TOKEN>
<TOKEN end_char="3608" id="token-30-15" morph="none" pos="punct" start_char="3608">.</TOKEN>
</SEG>
<SEG end_char="3717" id="segment-31" start_char="3611">
<ORIGINAL_TEXT>The remaining one-third of those 92 patients had either died or refused to participate in antibody testing.</ORIGINAL_TEXT>
<TOKEN end_char="3613" id="token-31-0" morph="none" pos="word" start_char="3611">The</TOKEN>
<TOKEN end_char="3623" id="token-31-1" morph="none" pos="word" start_char="3615">remaining</TOKEN>
<TOKEN end_char="3633" id="token-31-2" morph="none" pos="unknown" start_char="3625">one-third</TOKEN>
<TOKEN end_char="3636" id="token-31-3" morph="none" pos="word" start_char="3635">of</TOKEN>
<TOKEN end_char="3642" id="token-31-4" morph="none" pos="word" start_char="3638">those</TOKEN>
<TOKEN end_char="3645" id="token-31-5" morph="none" pos="word" start_char="3644">92</TOKEN>
<TOKEN end_char="3654" id="token-31-6" morph="none" pos="word" start_char="3647">patients</TOKEN>
<TOKEN end_char="3658" id="token-31-7" morph="none" pos="word" start_char="3656">had</TOKEN>
<TOKEN end_char="3665" id="token-31-8" morph="none" pos="word" start_char="3660">either</TOKEN>
<TOKEN end_char="3670" id="token-31-9" morph="none" pos="word" start_char="3667">died</TOKEN>
<TOKEN end_char="3673" id="token-31-10" morph="none" pos="word" start_char="3672">or</TOKEN>
<TOKEN end_char="3681" id="token-31-11" morph="none" pos="word" start_char="3675">refused</TOKEN>
<TOKEN end_char="3684" id="token-31-12" morph="none" pos="word" start_char="3683">to</TOKEN>
<TOKEN end_char="3696" id="token-31-13" morph="none" pos="word" start_char="3686">participate</TOKEN>
<TOKEN end_char="3699" id="token-31-14" morph="none" pos="word" start_char="3698">in</TOKEN>
<TOKEN end_char="3708" id="token-31-15" morph="none" pos="word" start_char="3701">antibody</TOKEN>
<TOKEN end_char="3716" id="token-31-16" morph="none" pos="word" start_char="3710">testing</TOKEN>
<TOKEN end_char="3717" id="token-31-17" morph="none" pos="punct" start_char="3717">.</TOKEN>
</SEG>
<SEG end_char="3787" id="segment-32" start_char="3720">
<ORIGINAL_TEXT>The negative results may not mean those people didn't have COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="3722" id="token-32-0" morph="none" pos="word" start_char="3720">The</TOKEN>
<TOKEN end_char="3731" id="token-32-1" morph="none" pos="word" start_char="3724">negative</TOKEN>
<TOKEN end_char="3739" id="token-32-2" morph="none" pos="word" start_char="3733">results</TOKEN>
<TOKEN end_char="3743" id="token-32-3" morph="none" pos="word" start_char="3741">may</TOKEN>
<TOKEN end_char="3747" id="token-32-4" morph="none" pos="word" start_char="3745">not</TOKEN>
<TOKEN end_char="3752" id="token-32-5" morph="none" pos="word" start_char="3749">mean</TOKEN>
<TOKEN end_char="3758" id="token-32-6" morph="none" pos="word" start_char="3754">those</TOKEN>
<TOKEN end_char="3765" id="token-32-7" morph="none" pos="word" start_char="3760">people</TOKEN>
<TOKEN end_char="3772" id="token-32-8" morph="none" pos="word" start_char="3767">didn't</TOKEN>
<TOKEN end_char="3777" id="token-32-9" morph="none" pos="word" start_char="3774">have</TOKEN>
<TOKEN end_char="3786" id="token-32-10" morph="none" pos="unknown" start_char="3779">COVID-19</TOKEN>
<TOKEN end_char="3787" id="token-32-11" morph="none" pos="punct" start_char="3787">.</TOKEN>
</SEG>
<SEG end_char="3857" id="segment-33" start_char="3789">
<ORIGINAL_TEXT>Antibody levels do decrease over time, particularly after mild cases.</ORIGINAL_TEXT>
<TOKEN end_char="3796" id="token-33-0" morph="none" pos="word" start_char="3789">Antibody</TOKEN>
<TOKEN end_char="3803" id="token-33-1" morph="none" pos="word" start_char="3798">levels</TOKEN>
<TOKEN end_char="3806" id="token-33-2" morph="none" pos="word" start_char="3805">do</TOKEN>
<TOKEN end_char="3815" id="token-33-3" morph="none" pos="word" start_char="3808">decrease</TOKEN>
<TOKEN end_char="3820" id="token-33-4" morph="none" pos="word" start_char="3817">over</TOKEN>
<TOKEN end_char="3825" id="token-33-5" morph="none" pos="word" start_char="3822">time</TOKEN>
<TOKEN end_char="3826" id="token-33-6" morph="none" pos="punct" start_char="3826">,</TOKEN>
<TOKEN end_char="3839" id="token-33-7" morph="none" pos="word" start_char="3828">particularly</TOKEN>
<TOKEN end_char="3845" id="token-33-8" morph="none" pos="word" start_char="3841">after</TOKEN>
<TOKEN end_char="3850" id="token-33-9" morph="none" pos="word" start_char="3847">mild</TOKEN>
<TOKEN end_char="3856" id="token-33-10" morph="none" pos="word" start_char="3852">cases</TOKEN>
<TOKEN end_char="3857" id="token-33-11" morph="none" pos="punct" start_char="3857">.</TOKEN>
</SEG>
<SEG end_char="3934" id="segment-34" start_char="3859">
<ORIGINAL_TEXT>But those patients were also hospitalized, suggesting a more severe illness.</ORIGINAL_TEXT>
<TOKEN end_char="3861" id="token-34-0" morph="none" pos="word" start_char="3859">But</TOKEN>
<TOKEN end_char="3867" id="token-34-1" morph="none" pos="word" start_char="3863">those</TOKEN>
<TOKEN end_char="3876" id="token-34-2" morph="none" pos="word" start_char="3869">patients</TOKEN>
<TOKEN end_char="3881" id="token-34-3" morph="none" pos="word" start_char="3878">were</TOKEN>
<TOKEN end_char="3886" id="token-34-4" morph="none" pos="word" start_char="3883">also</TOKEN>
<TOKEN end_char="3899" id="token-34-5" morph="none" pos="word" start_char="3888">hospitalized</TOKEN>
<TOKEN end_char="3900" id="token-34-6" morph="none" pos="punct" start_char="3900">,</TOKEN>
<TOKEN end_char="3911" id="token-34-7" morph="none" pos="word" start_char="3902">suggesting</TOKEN>
<TOKEN end_char="3913" id="token-34-8" morph="none" pos="word" start_char="3913">a</TOKEN>
<TOKEN end_char="3918" id="token-34-9" morph="none" pos="word" start_char="3915">more</TOKEN>
<TOKEN end_char="3925" id="token-34-10" morph="none" pos="word" start_char="3920">severe</TOKEN>
<TOKEN end_char="3933" id="token-34-11" morph="none" pos="word" start_char="3927">illness</TOKEN>
<TOKEN end_char="3934" id="token-34-12" morph="none" pos="punct" start_char="3934">.</TOKEN>
</SEG>
<SEG end_char="3957" id="segment-35" start_char="3937">
<ORIGINAL_TEXT>"Antibodies do clear.</ORIGINAL_TEXT>
<TOKEN end_char="3937" id="token-35-0" morph="none" pos="punct" start_char="3937">"</TOKEN>
<TOKEN end_char="3947" id="token-35-1" morph="none" pos="word" start_char="3938">Antibodies</TOKEN>
<TOKEN end_char="3950" id="token-35-2" morph="none" pos="word" start_char="3949">do</TOKEN>
<TOKEN end_char="3956" id="token-35-3" morph="none" pos="word" start_char="3952">clear</TOKEN>
<TOKEN end_char="3957" id="token-35-4" morph="none" pos="punct" start_char="3957">.</TOKEN>
<TRANSLATED_TEXT>"Antistoffer er klart.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4097" id="segment-36" start_char="3959">
<ORIGINAL_TEXT>The levels go down, but less so in cases of severe infection," Marion Koopmans, a virologist on the WHO team, told the Wall Street Journal.</ORIGINAL_TEXT>
<TOKEN end_char="3961" id="token-36-0" morph="none" pos="word" start_char="3959">The</TOKEN>
<TOKEN end_char="3968" id="token-36-1" morph="none" pos="word" start_char="3963">levels</TOKEN>
<TOKEN end_char="3971" id="token-36-2" morph="none" pos="word" start_char="3970">go</TOKEN>
<TOKEN end_char="3976" id="token-36-3" morph="none" pos="word" start_char="3973">down</TOKEN>
<TOKEN end_char="3977" id="token-36-4" morph="none" pos="punct" start_char="3977">,</TOKEN>
<TOKEN end_char="3981" id="token-36-5" morph="none" pos="word" start_char="3979">but</TOKEN>
<TOKEN end_char="3986" id="token-36-6" morph="none" pos="word" start_char="3983">less</TOKEN>
<TOKEN end_char="3989" id="token-36-7" morph="none" pos="word" start_char="3988">so</TOKEN>
<TOKEN end_char="3992" id="token-36-8" morph="none" pos="word" start_char="3991">in</TOKEN>
<TOKEN end_char="3998" id="token-36-9" morph="none" pos="word" start_char="3994">cases</TOKEN>
<TOKEN end_char="4001" id="token-36-10" morph="none" pos="word" start_char="4000">of</TOKEN>
<TOKEN end_char="4008" id="token-36-11" morph="none" pos="word" start_char="4003">severe</TOKEN>
<TOKEN end_char="4018" id="token-36-12" morph="none" pos="word" start_char="4010">infection</TOKEN>
<TOKEN end_char="4020" id="token-36-13" morph="none" pos="punct" start_char="4019">,"</TOKEN>
<TOKEN end_char="4027" id="token-36-14" morph="none" pos="word" start_char="4022">Marion</TOKEN>
<TOKEN end_char="4036" id="token-36-15" morph="none" pos="word" start_char="4029">Koopmans</TOKEN>
<TOKEN end_char="4037" id="token-36-16" morph="none" pos="punct" start_char="4037">,</TOKEN>
<TOKEN end_char="4039" id="token-36-17" morph="none" pos="word" start_char="4039">a</TOKEN>
<TOKEN end_char="4050" id="token-36-18" morph="none" pos="word" start_char="4041">virologist</TOKEN>
<TOKEN end_char="4053" id="token-36-19" morph="none" pos="word" start_char="4052">on</TOKEN>
<TOKEN end_char="4057" id="token-36-20" morph="none" pos="word" start_char="4055">the</TOKEN>
<TOKEN end_char="4061" id="token-36-21" morph="none" pos="word" start_char="4059">WHO</TOKEN>
<TOKEN end_char="4066" id="token-36-22" morph="none" pos="word" start_char="4063">team</TOKEN>
<TOKEN end_char="4067" id="token-36-23" morph="none" pos="punct" start_char="4067">,</TOKEN>
<TOKEN end_char="4072" id="token-36-24" morph="none" pos="word" start_char="4069">told</TOKEN>
<TOKEN end_char="4076" id="token-36-25" morph="none" pos="word" start_char="4074">the</TOKEN>
<TOKEN end_char="4081" id="token-36-26" morph="none" pos="word" start_char="4078">Wall</TOKEN>
<TOKEN end_char="4088" id="token-36-27" morph="none" pos="word" start_char="4083">Street</TOKEN>
<TOKEN end_char="4096" id="token-36-28" morph="none" pos="word" start_char="4090">Journal</TOKEN>
<TOKEN end_char="4097" id="token-36-29" morph="none" pos="punct" start_char="4097">.</TOKEN>
</SEG>
<SEG end_char="4189" id="segment-37" start_char="4099">
<ORIGINAL_TEXT>"From what we know about serology, out of 92 cases you would at least have some positives."</ORIGINAL_TEXT>
<TOKEN end_char="4099" id="token-37-0" morph="none" pos="punct" start_char="4099">"</TOKEN>
<TOKEN end_char="4103" id="token-37-1" morph="none" pos="word" start_char="4100">From</TOKEN>
<TOKEN end_char="4108" id="token-37-2" morph="none" pos="word" start_char="4105">what</TOKEN>
<TOKEN end_char="4111" id="token-37-3" morph="none" pos="word" start_char="4110">we</TOKEN>
<TOKEN end_char="4116" id="token-37-4" morph="none" pos="word" start_char="4113">know</TOKEN>
<TOKEN end_char="4122" id="token-37-5" morph="none" pos="word" start_char="4118">about</TOKEN>
<TOKEN end_char="4131" id="token-37-6" morph="none" pos="word" start_char="4124">serology</TOKEN>
<TOKEN end_char="4132" id="token-37-7" morph="none" pos="punct" start_char="4132">,</TOKEN>
<TOKEN end_char="4136" id="token-37-8" morph="none" pos="word" start_char="4134">out</TOKEN>
<TOKEN end_char="4139" id="token-37-9" morph="none" pos="word" start_char="4138">of</TOKEN>
<TOKEN end_char="4142" id="token-37-10" morph="none" pos="word" start_char="4141">92</TOKEN>
<TOKEN end_char="4148" id="token-37-11" morph="none" pos="word" start_char="4144">cases</TOKEN>
<TOKEN end_char="4152" id="token-37-12" morph="none" pos="word" start_char="4150">you</TOKEN>
<TOKEN end_char="4158" id="token-37-13" morph="none" pos="word" start_char="4154">would</TOKEN>
<TOKEN end_char="4161" id="token-37-14" morph="none" pos="word" start_char="4160">at</TOKEN>
<TOKEN end_char="4167" id="token-37-15" morph="none" pos="word" start_char="4163">least</TOKEN>
<TOKEN end_char="4172" id="token-37-16" morph="none" pos="word" start_char="4169">have</TOKEN>
<TOKEN end_char="4177" id="token-37-17" morph="none" pos="word" start_char="4174">some</TOKEN>
<TOKEN end_char="4187" id="token-37-18" morph="none" pos="word" start_char="4179">positives</TOKEN>
<TOKEN end_char="4189" id="token-37-19" morph="none" pos="punct" start_char="4188">."</TOKEN>
</SEG>
<SEG end_char="4203" id="segment-38" start_char="4192">
<ORIGINAL_TEXT>A study from</ORIGINAL_TEXT>
<TOKEN end_char="4192" id="token-38-0" morph="none" pos="word" start_char="4192">A</TOKEN>
<TOKEN end_char="4198" id="token-38-1" morph="none" pos="word" start_char="4194">study</TOKEN>
<TOKEN end_char="4203" id="token-38-2" morph="none" pos="word" start_char="4200">from</TOKEN>
</SEG>
<SEG end_char="4238" id="segment-39" start_char="4206">
<ORIGINAL_TEXT>researchers at Harvard University</ORIGINAL_TEXT>
<TOKEN end_char="4216" id="token-39-0" morph="none" pos="word" start_char="4206">researchers</TOKEN>
<TOKEN end_char="4219" id="token-39-1" morph="none" pos="word" start_char="4218">at</TOKEN>
<TOKEN end_char="4227" id="token-39-2" morph="none" pos="word" start_char="4221">Harvard</TOKEN>
<TOKEN end_char="4238" id="token-39-3" morph="none" pos="word" start_char="4229">University</TOKEN>
</SEG>
<SEG end_char="4318" id="segment-40" start_char="4241">
<ORIGINAL_TEXT>did find more people were visiting Wuhan hospitals in the latter half of 2019.</ORIGINAL_TEXT>
<TOKEN end_char="4243" id="token-40-0" morph="none" pos="word" start_char="4241">did</TOKEN>
<TOKEN end_char="4248" id="token-40-1" morph="none" pos="word" start_char="4245">find</TOKEN>
<TOKEN end_char="4253" id="token-40-2" morph="none" pos="word" start_char="4250">more</TOKEN>
<TOKEN end_char="4260" id="token-40-3" morph="none" pos="word" start_char="4255">people</TOKEN>
<TOKEN end_char="4265" id="token-40-4" morph="none" pos="word" start_char="4262">were</TOKEN>
<TOKEN end_char="4274" id="token-40-5" morph="none" pos="word" start_char="4267">visiting</TOKEN>
<TOKEN end_char="4280" id="token-40-6" morph="none" pos="word" start_char="4276">Wuhan</TOKEN>
<TOKEN end_char="4290" id="token-40-7" morph="none" pos="word" start_char="4282">hospitals</TOKEN>
<TOKEN end_char="4293" id="token-40-8" morph="none" pos="word" start_char="4292">in</TOKEN>
<TOKEN end_char="4297" id="token-40-9" morph="none" pos="word" start_char="4295">the</TOKEN>
<TOKEN end_char="4304" id="token-40-10" morph="none" pos="word" start_char="4299">latter</TOKEN>
<TOKEN end_char="4309" id="token-40-11" morph="none" pos="word" start_char="4306">half</TOKEN>
<TOKEN end_char="4312" id="token-40-12" morph="none" pos="word" start_char="4311">of</TOKEN>
<TOKEN end_char="4317" id="token-40-13" morph="none" pos="word" start_char="4314">2019</TOKEN>
<TOKEN end_char="4318" id="token-40-14" morph="none" pos="punct" start_char="4318">.</TOKEN>
</SEG>
<SEG end_char="4413" id="segment-41" start_char="4320">
<ORIGINAL_TEXT>The study authors used satellite imagery of the city to measure traffic to six city hospitals.</ORIGINAL_TEXT>
<TOKEN end_char="4322" id="token-41-0" morph="none" pos="word" start_char="4320">The</TOKEN>
<TOKEN end_char="4328" id="token-41-1" morph="none" pos="word" start_char="4324">study</TOKEN>
<TOKEN end_char="4336" id="token-41-2" morph="none" pos="word" start_char="4330">authors</TOKEN>
<TOKEN end_char="4341" id="token-41-3" morph="none" pos="word" start_char="4338">used</TOKEN>
<TOKEN end_char="4351" id="token-41-4" morph="none" pos="word" start_char="4343">satellite</TOKEN>
<TOKEN end_char="4359" id="token-41-5" morph="none" pos="word" start_char="4353">imagery</TOKEN>
<TOKEN end_char="4362" id="token-41-6" morph="none" pos="word" start_char="4361">of</TOKEN>
<TOKEN end_char="4366" id="token-41-7" morph="none" pos="word" start_char="4364">the</TOKEN>
<TOKEN end_char="4371" id="token-41-8" morph="none" pos="word" start_char="4368">city</TOKEN>
<TOKEN end_char="4374" id="token-41-9" morph="none" pos="word" start_char="4373">to</TOKEN>
<TOKEN end_char="4382" id="token-41-10" morph="none" pos="word" start_char="4376">measure</TOKEN>
<TOKEN end_char="4390" id="token-41-11" morph="none" pos="word" start_char="4384">traffic</TOKEN>
<TOKEN end_char="4393" id="token-41-12" morph="none" pos="word" start_char="4392">to</TOKEN>
<TOKEN end_char="4397" id="token-41-13" morph="none" pos="word" start_char="4395">six</TOKEN>
<TOKEN end_char="4402" id="token-41-14" morph="none" pos="word" start_char="4399">city</TOKEN>
<TOKEN end_char="4412" id="token-41-15" morph="none" pos="word" start_char="4404">hospitals</TOKEN>
<TOKEN end_char="4413" id="token-41-16" morph="none" pos="punct" start_char="4413">.</TOKEN>
</SEG>
<SEG end_char="4488" id="segment-42" start_char="4415">
<ORIGINAL_TEXT>They saw an uptick starting in August 2019, which peaked six months later.</ORIGINAL_TEXT>
<TOKEN end_char="4418" id="token-42-0" morph="none" pos="word" start_char="4415">They</TOKEN>
<TOKEN end_char="4422" id="token-42-1" morph="none" pos="word" start_char="4420">saw</TOKEN>
<TOKEN end_char="4425" id="token-42-2" morph="none" pos="word" start_char="4424">an</TOKEN>
<TOKEN end_char="4432" id="token-42-3" morph="none" pos="word" start_char="4427">uptick</TOKEN>
<TOKEN end_char="4441" id="token-42-4" morph="none" pos="word" start_char="4434">starting</TOKEN>
<TOKEN end_char="4444" id="token-42-5" morph="none" pos="word" start_char="4443">in</TOKEN>
<TOKEN end_char="4451" id="token-42-6" morph="none" pos="word" start_char="4446">August</TOKEN>
<TOKEN end_char="4456" id="token-42-7" morph="none" pos="word" start_char="4453">2019</TOKEN>
<TOKEN end_char="4457" id="token-42-8" morph="none" pos="punct" start_char="4457">,</TOKEN>
<TOKEN end_char="4463" id="token-42-9" morph="none" pos="word" start_char="4459">which</TOKEN>
<TOKEN end_char="4470" id="token-42-10" morph="none" pos="word" start_char="4465">peaked</TOKEN>
<TOKEN end_char="4474" id="token-42-11" morph="none" pos="word" start_char="4472">six</TOKEN>
<TOKEN end_char="4481" id="token-42-12" morph="none" pos="word" start_char="4476">months</TOKEN>
<TOKEN end_char="4487" id="token-42-13" morph="none" pos="word" start_char="4483">later</TOKEN>
<TOKEN end_char="4488" id="token-42-14" morph="none" pos="punct" start_char="4488">.</TOKEN>
</SEG>
<SEG end_char="4593" id="segment-43" start_char="4490">
<ORIGINAL_TEXT>This timeline coincided with an increase in online search traffic for terms like "diarrhea" and "cough."</ORIGINAL_TEXT>
<TOKEN end_char="4493" id="token-43-0" morph="none" pos="word" start_char="4490">This</TOKEN>
<TOKEN end_char="4502" id="token-43-1" morph="none" pos="word" start_char="4495">timeline</TOKEN>
<TOKEN end_char="4512" id="token-43-2" morph="none" pos="word" start_char="4504">coincided</TOKEN>
<TOKEN end_char="4517" id="token-43-3" morph="none" pos="word" start_char="4514">with</TOKEN>
<TOKEN end_char="4520" id="token-43-4" morph="none" pos="word" start_char="4519">an</TOKEN>
<TOKEN end_char="4529" id="token-43-5" morph="none" pos="word" start_char="4522">increase</TOKEN>
<TOKEN end_char="4532" id="token-43-6" morph="none" pos="word" start_char="4531">in</TOKEN>
<TOKEN end_char="4539" id="token-43-7" morph="none" pos="word" start_char="4534">online</TOKEN>
<TOKEN end_char="4546" id="token-43-8" morph="none" pos="word" start_char="4541">search</TOKEN>
<TOKEN end_char="4554" id="token-43-9" morph="none" pos="word" start_char="4548">traffic</TOKEN>
<TOKEN end_char="4558" id="token-43-10" morph="none" pos="word" start_char="4556">for</TOKEN>
<TOKEN end_char="4564" id="token-43-11" morph="none" pos="word" start_char="4560">terms</TOKEN>
<TOKEN end_char="4569" id="token-43-12" morph="none" pos="word" start_char="4566">like</TOKEN>
<TOKEN end_char="4571" id="token-43-13" morph="none" pos="punct" start_char="4571">"</TOKEN>
<TOKEN end_char="4579" id="token-43-14" morph="none" pos="word" start_char="4572">diarrhea</TOKEN>
<TOKEN end_char="4580" id="token-43-15" morph="none" pos="punct" start_char="4580">"</TOKEN>
<TOKEN end_char="4584" id="token-43-16" morph="none" pos="word" start_char="4582">and</TOKEN>
<TOKEN end_char="4586" id="token-43-17" morph="none" pos="punct" start_char="4586">"</TOKEN>
<TOKEN end_char="4591" id="token-43-18" morph="none" pos="word" start_char="4587">cough</TOKEN>
<TOKEN end_char="4593" id="token-43-19" morph="none" pos="punct" start_char="4592">."</TOKEN>
</SEG>
<SEG end_char="4646" id="segment-44" start_char="4596">
<ORIGINAL_TEXT>The Wuhan market was not the origin of the pandemic</ORIGINAL_TEXT>
<TOKEN end_char="4598" id="token-44-0" morph="none" pos="word" start_char="4596">The</TOKEN>
<TOKEN end_char="4604" id="token-44-1" morph="none" pos="word" start_char="4600">Wuhan</TOKEN>
<TOKEN end_char="4611" id="token-44-2" morph="none" pos="word" start_char="4606">market</TOKEN>
<TOKEN end_char="4615" id="token-44-3" morph="none" pos="word" start_char="4613">was</TOKEN>
<TOKEN end_char="4619" id="token-44-4" morph="none" pos="word" start_char="4617">not</TOKEN>
<TOKEN end_char="4623" id="token-44-5" morph="none" pos="word" start_char="4621">the</TOKEN>
<TOKEN end_char="4630" id="token-44-6" morph="none" pos="word" start_char="4625">origin</TOKEN>
<TOKEN end_char="4633" id="token-44-7" morph="none" pos="word" start_char="4632">of</TOKEN>
<TOKEN end_char="4637" id="token-44-8" morph="none" pos="word" start_char="4635">the</TOKEN>
<TOKEN end_char="4646" id="token-44-9" morph="none" pos="word" start_char="4639">pandemic</TOKEN>
</SEG>
<SEG end_char="4740" id="segment-45" start_char="4651">
<ORIGINAL_TEXT>Security personnel wear masks walk in front of a field hospital in Wuhan on April 9, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="4658" id="token-45-0" morph="none" pos="word" start_char="4651">Security</TOKEN>
<TOKEN end_char="4668" id="token-45-1" morph="none" pos="word" start_char="4660">personnel</TOKEN>
<TOKEN end_char="4673" id="token-45-2" morph="none" pos="word" start_char="4670">wear</TOKEN>
<TOKEN end_char="4679" id="token-45-3" morph="none" pos="word" start_char="4675">masks</TOKEN>
<TOKEN end_char="4684" id="token-45-4" morph="none" pos="word" start_char="4681">walk</TOKEN>
<TOKEN end_char="4687" id="token-45-5" morph="none" pos="word" start_char="4686">in</TOKEN>
<TOKEN end_char="4693" id="token-45-6" morph="none" pos="word" start_char="4689">front</TOKEN>
<TOKEN end_char="4696" id="token-45-7" morph="none" pos="word" start_char="4695">of</TOKEN>
<TOKEN end_char="4698" id="token-45-8" morph="none" pos="word" start_char="4698">a</TOKEN>
<TOKEN end_char="4704" id="token-45-9" morph="none" pos="word" start_char="4700">field</TOKEN>
<TOKEN end_char="4713" id="token-45-10" morph="none" pos="word" start_char="4706">hospital</TOKEN>
<TOKEN end_char="4716" id="token-45-11" morph="none" pos="word" start_char="4715">in</TOKEN>
<TOKEN end_char="4722" id="token-45-12" morph="none" pos="word" start_char="4718">Wuhan</TOKEN>
<TOKEN end_char="4725" id="token-45-13" morph="none" pos="word" start_char="4724">on</TOKEN>
<TOKEN end_char="4731" id="token-45-14" morph="none" pos="word" start_char="4727">April</TOKEN>
<TOKEN end_char="4733" id="token-45-15" morph="none" pos="word" start_char="4733">9</TOKEN>
<TOKEN end_char="4734" id="token-45-16" morph="none" pos="punct" start_char="4734">,</TOKEN>
<TOKEN end_char="4739" id="token-45-17" morph="none" pos="word" start_char="4736">2020</TOKEN>
<TOKEN end_char="4740" id="token-45-18" morph="none" pos="punct" start_char="4740">.</TOKEN>
</SEG>
<SEG end_char="4769" id="segment-46" start_char="4743">
<ORIGINAL_TEXT>Noel Celis/AFP/Getty Images</ORIGINAL_TEXT>
<TOKEN end_char="4746" id="token-46-0" morph="none" pos="word" start_char="4743">Noel</TOKEN>
<TOKEN end_char="4762" id="token-46-1" morph="none" pos="unknown" start_char="4748">Celis/AFP/Getty</TOKEN>
<TOKEN end_char="4769" id="token-46-2" morph="none" pos="word" start_char="4764">Images</TOKEN>
</SEG>
<SEG end_char="4911" id="segment-47" start_char="4773">
<ORIGINAL_TEXT>Among the 41 coronavirus cases, Wuhan first reported, many were people who visited or worked at the city's Huanan Seafood Wholesale Market.</ORIGINAL_TEXT>
<TOKEN end_char="4777" id="token-47-0" morph="none" pos="word" start_char="4773">Among</TOKEN>
<TOKEN end_char="4781" id="token-47-1" morph="none" pos="word" start_char="4779">the</TOKEN>
<TOKEN end_char="4784" id="token-47-2" morph="none" pos="word" start_char="4783">41</TOKEN>
<TOKEN end_char="4796" id="token-47-3" morph="none" pos="word" start_char="4786">coronavirus</TOKEN>
<TOKEN end_char="4802" id="token-47-4" morph="none" pos="word" start_char="4798">cases</TOKEN>
<TOKEN end_char="4803" id="token-47-5" morph="none" pos="punct" start_char="4803">,</TOKEN>
<TOKEN end_char="4809" id="token-47-6" morph="none" pos="word" start_char="4805">Wuhan</TOKEN>
<TOKEN end_char="4815" id="token-47-7" morph="none" pos="word" start_char="4811">first</TOKEN>
<TOKEN end_char="4824" id="token-47-8" morph="none" pos="word" start_char="4817">reported</TOKEN>
<TOKEN end_char="4825" id="token-47-9" morph="none" pos="punct" start_char="4825">,</TOKEN>
<TOKEN end_char="4830" id="token-47-10" morph="none" pos="word" start_char="4827">many</TOKEN>
<TOKEN end_char="4835" id="token-47-11" morph="none" pos="word" start_char="4832">were</TOKEN>
<TOKEN end_char="4842" id="token-47-12" morph="none" pos="word" start_char="4837">people</TOKEN>
<TOKEN end_char="4846" id="token-47-13" morph="none" pos="word" start_char="4844">who</TOKEN>
<TOKEN end_char="4854" id="token-47-14" morph="none" pos="word" start_char="4848">visited</TOKEN>
<TOKEN end_char="4857" id="token-47-15" morph="none" pos="word" start_char="4856">or</TOKEN>
<TOKEN end_char="4864" id="token-47-16" morph="none" pos="word" start_char="4859">worked</TOKEN>
<TOKEN end_char="4867" id="token-47-17" morph="none" pos="word" start_char="4866">at</TOKEN>
<TOKEN end_char="4871" id="token-47-18" morph="none" pos="word" start_char="4869">the</TOKEN>
<TOKEN end_char="4878" id="token-47-19" morph="none" pos="word" start_char="4873">city's</TOKEN>
<TOKEN end_char="4885" id="token-47-20" morph="none" pos="word" start_char="4880">Huanan</TOKEN>
<TOKEN end_char="4893" id="token-47-21" morph="none" pos="word" start_char="4887">Seafood</TOKEN>
<TOKEN end_char="4903" id="token-47-22" morph="none" pos="word" start_char="4895">Wholesale</TOKEN>
<TOKEN end_char="4910" id="token-47-23" morph="none" pos="word" start_char="4905">Market</TOKEN>
<TOKEN end_char="4911" id="token-47-24" morph="none" pos="punct" start_char="4911">.</TOKEN>
</SEG>
<SEG end_char="5068" id="segment-48" start_char="4914">
<ORIGINAL_TEXT>But according to an April report, 13 of the 41 original cases had no link to the market — which suggests the market wasn't the origin site of the pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="4916" id="token-48-0" morph="none" pos="word" start_char="4914">But</TOKEN>
<TOKEN end_char="4926" id="token-48-1" morph="none" pos="word" start_char="4918">according</TOKEN>
<TOKEN end_char="4929" id="token-48-2" morph="none" pos="word" start_char="4928">to</TOKEN>
<TOKEN end_char="4932" id="token-48-3" morph="none" pos="word" start_char="4931">an</TOKEN>
<TOKEN end_char="4938" id="token-48-4" morph="none" pos="word" start_char="4934">April</TOKEN>
<TOKEN end_char="4945" id="token-48-5" morph="none" pos="word" start_char="4940">report</TOKEN>
<TOKEN end_char="4946" id="token-48-6" morph="none" pos="punct" start_char="4946">,</TOKEN>
<TOKEN end_char="4949" id="token-48-7" morph="none" pos="word" start_char="4948">13</TOKEN>
<TOKEN end_char="4952" id="token-48-8" morph="none" pos="word" start_char="4951">of</TOKEN>
<TOKEN end_char="4956" id="token-48-9" morph="none" pos="word" start_char="4954">the</TOKEN>
<TOKEN end_char="4959" id="token-48-10" morph="none" pos="word" start_char="4958">41</TOKEN>
<TOKEN end_char="4968" id="token-48-11" morph="none" pos="word" start_char="4961">original</TOKEN>
<TOKEN end_char="4974" id="token-48-12" morph="none" pos="word" start_char="4970">cases</TOKEN>
<TOKEN end_char="4978" id="token-48-13" morph="none" pos="word" start_char="4976">had</TOKEN>
<TOKEN end_char="4981" id="token-48-14" morph="none" pos="word" start_char="4980">no</TOKEN>
<TOKEN end_char="4986" id="token-48-15" morph="none" pos="word" start_char="4983">link</TOKEN>
<TOKEN end_char="4989" id="token-48-16" morph="none" pos="word" start_char="4988">to</TOKEN>
<TOKEN end_char="4993" id="token-48-17" morph="none" pos="word" start_char="4991">the</TOKEN>
<TOKEN end_char="5000" id="token-48-18" morph="none" pos="word" start_char="4995">market</TOKEN>
<TOKEN end_char="5002" id="token-48-19" morph="none" pos="punct" start_char="5002">—</TOKEN>
<TOKEN end_char="5008" id="token-48-20" morph="none" pos="word" start_char="5004">which</TOKEN>
<TOKEN end_char="5017" id="token-48-21" morph="none" pos="word" start_char="5010">suggests</TOKEN>
<TOKEN end_char="5021" id="token-48-22" morph="none" pos="word" start_char="5019">the</TOKEN>
<TOKEN end_char="5028" id="token-48-23" morph="none" pos="word" start_char="5023">market</TOKEN>
<TOKEN end_char="5035" id="token-48-24" morph="none" pos="word" start_char="5030">wasn't</TOKEN>
<TOKEN end_char="5039" id="token-48-25" morph="none" pos="word" start_char="5037">the</TOKEN>
<TOKEN end_char="5046" id="token-48-26" morph="none" pos="word" start_char="5041">origin</TOKEN>
<TOKEN end_char="5051" id="token-48-27" morph="none" pos="word" start_char="5048">site</TOKEN>
<TOKEN end_char="5054" id="token-48-28" morph="none" pos="word" start_char="5053">of</TOKEN>
<TOKEN end_char="5058" id="token-48-29" morph="none" pos="word" start_char="5056">the</TOKEN>
<TOKEN end_char="5067" id="token-48-30" morph="none" pos="word" start_char="5060">pandemic</TOKEN>
<TOKEN end_char="5068" id="token-48-31" morph="none" pos="punct" start_char="5068">.</TOKEN>
</SEG>
<SEG end_char="5176" id="segment-49" start_char="5071">
<ORIGINAL_TEXT>The WHO team confirmed the virus didn't make its initial jump from animals to humans at the Huanan market.</ORIGINAL_TEXT>
<TOKEN end_char="5073" id="token-49-0" morph="none" pos="word" start_char="5071">The</TOKEN>
<TOKEN end_char="5077" id="token-49-1" morph="none" pos="word" start_char="5075">WHO</TOKEN>
<TOKEN end_char="5082" id="token-49-2" morph="none" pos="word" start_char="5079">team</TOKEN>
<TOKEN end_char="5092" id="token-49-3" morph="none" pos="word" start_char="5084">confirmed</TOKEN>
<TOKEN end_char="5096" id="token-49-4" morph="none" pos="word" start_char="5094">the</TOKEN>
<TOKEN end_char="5102" id="token-49-5" morph="none" pos="word" start_char="5098">virus</TOKEN>
<TOKEN end_char="5109" id="token-49-6" morph="none" pos="word" start_char="5104">didn't</TOKEN>
<TOKEN end_char="5114" id="token-49-7" morph="none" pos="word" start_char="5111">make</TOKEN>
<TOKEN end_char="5118" id="token-49-8" morph="none" pos="word" start_char="5116">its</TOKEN>
<TOKEN end_char="5126" id="token-49-9" morph="none" pos="word" start_char="5120">initial</TOKEN>
<TOKEN end_char="5131" id="token-49-10" morph="none" pos="word" start_char="5128">jump</TOKEN>
<TOKEN end_char="5136" id="token-49-11" morph="none" pos="word" start_char="5133">from</TOKEN>
<TOKEN end_char="5144" id="token-49-12" morph="none" pos="word" start_char="5138">animals</TOKEN>
<TOKEN end_char="5147" id="token-49-13" morph="none" pos="word" start_char="5146">to</TOKEN>
<TOKEN end_char="5154" id="token-49-14" morph="none" pos="word" start_char="5149">humans</TOKEN>
<TOKEN end_char="5157" id="token-49-15" morph="none" pos="word" start_char="5156">at</TOKEN>
<TOKEN end_char="5161" id="token-49-16" morph="none" pos="word" start_char="5159">the</TOKEN>
<TOKEN end_char="5168" id="token-49-17" morph="none" pos="word" start_char="5163">Huanan</TOKEN>
<TOKEN end_char="5175" id="token-49-18" morph="none" pos="word" start_char="5170">market</TOKEN>
<TOKEN end_char="5176" id="token-49-19" morph="none" pos="punct" start_char="5176">.</TOKEN>
</SEG>
<SEG end_char="5415" id="segment-50" start_char="5178">
<ORIGINAL_TEXT>Evidence suggests the virus was circulating elsewhere in Wuhan before the market outbreak happened, Liang Wannian, a member of China's National Health Commission who assisted with the WHO investigation, said in a press conference Tuesday.</ORIGINAL_TEXT>
<TOKEN end_char="5185" id="token-50-0" morph="none" pos="word" start_char="5178">Evidence</TOKEN>
<TOKEN end_char="5194" id="token-50-1" morph="none" pos="word" start_char="5187">suggests</TOKEN>
<TOKEN end_char="5198" id="token-50-2" morph="none" pos="word" start_char="5196">the</TOKEN>
<TOKEN end_char="5204" id="token-50-3" morph="none" pos="word" start_char="5200">virus</TOKEN>
<TOKEN end_char="5208" id="token-50-4" morph="none" pos="word" start_char="5206">was</TOKEN>
<TOKEN end_char="5220" id="token-50-5" morph="none" pos="word" start_char="5210">circulating</TOKEN>
<TOKEN end_char="5230" id="token-50-6" morph="none" pos="word" start_char="5222">elsewhere</TOKEN>
<TOKEN end_char="5233" id="token-50-7" morph="none" pos="word" start_char="5232">in</TOKEN>
<TOKEN end_char="5239" id="token-50-8" morph="none" pos="word" start_char="5235">Wuhan</TOKEN>
<TOKEN end_char="5246" id="token-50-9" morph="none" pos="word" start_char="5241">before</TOKEN>
<TOKEN end_char="5250" id="token-50-10" morph="none" pos="word" start_char="5248">the</TOKEN>
<TOKEN end_char="5257" id="token-50-11" morph="none" pos="word" start_char="5252">market</TOKEN>
<TOKEN end_char="5266" id="token-50-12" morph="none" pos="word" start_char="5259">outbreak</TOKEN>
<TOKEN end_char="5275" id="token-50-13" morph="none" pos="word" start_char="5268">happened</TOKEN>
<TOKEN end_char="5276" id="token-50-14" morph="none" pos="punct" start_char="5276">,</TOKEN>
<TOKEN end_char="5282" id="token-50-15" morph="none" pos="word" start_char="5278">Liang</TOKEN>
<TOKEN end_char="5290" id="token-50-16" morph="none" pos="word" start_char="5284">Wannian</TOKEN>
<TOKEN end_char="5291" id="token-50-17" morph="none" pos="punct" start_char="5291">,</TOKEN>
<TOKEN end_char="5293" id="token-50-18" morph="none" pos="word" start_char="5293">a</TOKEN>
<TOKEN end_char="5300" id="token-50-19" morph="none" pos="word" start_char="5295">member</TOKEN>
<TOKEN end_char="5303" id="token-50-20" morph="none" pos="word" start_char="5302">of</TOKEN>
<TOKEN end_char="5311" id="token-50-21" morph="none" pos="word" start_char="5305">China's</TOKEN>
<TOKEN end_char="5320" id="token-50-22" morph="none" pos="word" start_char="5313">National</TOKEN>
<TOKEN end_char="5327" id="token-50-23" morph="none" pos="word" start_char="5322">Health</TOKEN>
<TOKEN end_char="5338" id="token-50-24" morph="none" pos="word" start_char="5329">Commission</TOKEN>
<TOKEN end_char="5342" id="token-50-25" morph="none" pos="word" start_char="5340">who</TOKEN>
<TOKEN end_char="5351" id="token-50-26" morph="none" pos="word" start_char="5344">assisted</TOKEN>
<TOKEN end_char="5356" id="token-50-27" morph="none" pos="word" start_char="5353">with</TOKEN>
<TOKEN end_char="5360" id="token-50-28" morph="none" pos="word" start_char="5358">the</TOKEN>
<TOKEN end_char="5364" id="token-50-29" morph="none" pos="word" start_char="5362">WHO</TOKEN>
<TOKEN end_char="5378" id="token-50-30" morph="none" pos="word" start_char="5366">investigation</TOKEN>
<TOKEN end_char="5379" id="token-50-31" morph="none" pos="punct" start_char="5379">,</TOKEN>
<TOKEN end_char="5384" id="token-50-32" morph="none" pos="word" start_char="5381">said</TOKEN>
<TOKEN end_char="5387" id="token-50-33" morph="none" pos="word" start_char="5386">in</TOKEN>
<TOKEN end_char="5389" id="token-50-34" morph="none" pos="word" start_char="5389">a</TOKEN>
<TOKEN end_char="5395" id="token-50-35" morph="none" pos="word" start_char="5391">press</TOKEN>
<TOKEN end_char="5406" id="token-50-36" morph="none" pos="word" start_char="5397">conference</TOKEN>
<TOKEN end_char="5414" id="token-50-37" morph="none" pos="word" start_char="5408">Tuesday</TOKEN>
<TOKEN end_char="5415" id="token-50-38" morph="none" pos="punct" start_char="5415">.</TOKEN>
</SEG>
<SEG end_char="5538" id="segment-51" start_char="5420">
<ORIGINAL_TEXT>This wet market in Wuhan, China, pictured on January 21, 2020, was linked to one of the earliest coronavirus outbreaks.</ORIGINAL_TEXT>
<TOKEN end_char="5423" id="token-51-0" morph="none" pos="word" start_char="5420">This</TOKEN>
<TOKEN end_char="5427" id="token-51-1" morph="none" pos="word" start_char="5425">wet</TOKEN>
<TOKEN end_char="5434" id="token-51-2" morph="none" pos="word" start_char="5429">market</TOKEN>
<TOKEN end_char="5437" id="token-51-3" morph="none" pos="word" start_char="5436">in</TOKEN>
<TOKEN end_char="5443" id="token-51-4" morph="none" pos="word" start_char="5439">Wuhan</TOKEN>
<TOKEN end_char="5444" id="token-51-5" morph="none" pos="punct" start_char="5444">,</TOKEN>
<TOKEN end_char="5450" id="token-51-6" morph="none" pos="word" start_char="5446">China</TOKEN>
<TOKEN end_char="5451" id="token-51-7" morph="none" pos="punct" start_char="5451">,</TOKEN>
<TOKEN end_char="5460" id="token-51-8" morph="none" pos="word" start_char="5453">pictured</TOKEN>
<TOKEN end_char="5463" id="token-51-9" morph="none" pos="word" start_char="5462">on</TOKEN>
<TOKEN end_char="5471" id="token-51-10" morph="none" pos="word" start_char="5465">January</TOKEN>
<TOKEN end_char="5474" id="token-51-11" morph="none" pos="word" start_char="5473">21</TOKEN>
<TOKEN end_char="5475" id="token-51-12" morph="none" pos="punct" start_char="5475">,</TOKEN>
<TOKEN end_char="5480" id="token-51-13" morph="none" pos="word" start_char="5477">2020</TOKEN>
<TOKEN end_char="5481" id="token-51-14" morph="none" pos="punct" start_char="5481">,</TOKEN>
<TOKEN end_char="5485" id="token-51-15" morph="none" pos="word" start_char="5483">was</TOKEN>
<TOKEN end_char="5492" id="token-51-16" morph="none" pos="word" start_char="5487">linked</TOKEN>
<TOKEN end_char="5495" id="token-51-17" morph="none" pos="word" start_char="5494">to</TOKEN>
<TOKEN end_char="5499" id="token-51-18" morph="none" pos="word" start_char="5497">one</TOKEN>
<TOKEN end_char="5502" id="token-51-19" morph="none" pos="word" start_char="5501">of</TOKEN>
<TOKEN end_char="5506" id="token-51-20" morph="none" pos="word" start_char="5504">the</TOKEN>
<TOKEN end_char="5515" id="token-51-21" morph="none" pos="word" start_char="5508">earliest</TOKEN>
<TOKEN end_char="5527" id="token-51-22" morph="none" pos="word" start_char="5517">coronavirus</TOKEN>
<TOKEN end_char="5537" id="token-51-23" morph="none" pos="word" start_char="5529">outbreaks</TOKEN>
<TOKEN end_char="5538" id="token-51-24" morph="none" pos="punct" start_char="5538">.</TOKEN>
</SEG>
<SEG end_char="5552" id="segment-52" start_char="5541">
<ORIGINAL_TEXT>Dake Kang/AP</ORIGINAL_TEXT>
<TOKEN end_char="5544" id="token-52-0" morph="none" pos="word" start_char="5541">Dake</TOKEN>
<TOKEN end_char="5552" id="token-52-1" morph="none" pos="unknown" start_char="5546">Kang/AP</TOKEN>
<TRANSLATED_TEXT>Kang Dake / AP</TRANSLATED_TEXT><DETECTED_LANGUAGE>id</DETECTED_LANGUAGE></SEG>
<SEG end_char="5697" id="segment-53" start_char="5556">
<ORIGINAL_TEXT>A May investigation also led the Chinese Center for Disease Control and Prevention to rule the market out as the origin place of the outbreak.</ORIGINAL_TEXT>
<TOKEN end_char="5556" id="token-53-0" morph="none" pos="word" start_char="5556">A</TOKEN>
<TOKEN end_char="5560" id="token-53-1" morph="none" pos="word" start_char="5558">May</TOKEN>
<TOKEN end_char="5574" id="token-53-2" morph="none" pos="word" start_char="5562">investigation</TOKEN>
<TOKEN end_char="5579" id="token-53-3" morph="none" pos="word" start_char="5576">also</TOKEN>
<TOKEN end_char="5583" id="token-53-4" morph="none" pos="word" start_char="5581">led</TOKEN>
<TOKEN end_char="5587" id="token-53-5" morph="none" pos="word" start_char="5585">the</TOKEN>
<TOKEN end_char="5595" id="token-53-6" morph="none" pos="word" start_char="5589">Chinese</TOKEN>
<TOKEN end_char="5602" id="token-53-7" morph="none" pos="word" start_char="5597">Center</TOKEN>
<TOKEN end_char="5606" id="token-53-8" morph="none" pos="word" start_char="5604">for</TOKEN>
<TOKEN end_char="5614" id="token-53-9" morph="none" pos="word" start_char="5608">Disease</TOKEN>
<TOKEN end_char="5622" id="token-53-10" morph="none" pos="word" start_char="5616">Control</TOKEN>
<TOKEN end_char="5626" id="token-53-11" morph="none" pos="word" start_char="5624">and</TOKEN>
<TOKEN end_char="5637" id="token-53-12" morph="none" pos="word" start_char="5628">Prevention</TOKEN>
<TOKEN end_char="5640" id="token-53-13" morph="none" pos="word" start_char="5639">to</TOKEN>
<TOKEN end_char="5645" id="token-53-14" morph="none" pos="word" start_char="5642">rule</TOKEN>
<TOKEN end_char="5649" id="token-53-15" morph="none" pos="word" start_char="5647">the</TOKEN>
<TOKEN end_char="5656" id="token-53-16" morph="none" pos="word" start_char="5651">market</TOKEN>
<TOKEN end_char="5660" id="token-53-17" morph="none" pos="word" start_char="5658">out</TOKEN>
<TOKEN end_char="5663" id="token-53-18" morph="none" pos="word" start_char="5662">as</TOKEN>
<TOKEN end_char="5667" id="token-53-19" morph="none" pos="word" start_char="5665">the</TOKEN>
<TOKEN end_char="5674" id="token-53-20" morph="none" pos="word" start_char="5669">origin</TOKEN>
<TOKEN end_char="5680" id="token-53-21" morph="none" pos="word" start_char="5676">place</TOKEN>
<TOKEN end_char="5683" id="token-53-22" morph="none" pos="word" start_char="5682">of</TOKEN>
<TOKEN end_char="5687" id="token-53-23" morph="none" pos="word" start_char="5685">the</TOKEN>
<TOKEN end_char="5696" id="token-53-24" morph="none" pos="word" start_char="5689">outbreak</TOKEN>
<TOKEN end_char="5697" id="token-53-25" morph="none" pos="punct" start_char="5697">.</TOKEN>
</SEG>
<SEG end_char="5769" id="segment-54" start_char="5699">
<ORIGINAL_TEXT>That's because none of the animals there tested positive for the virus.</ORIGINAL_TEXT>
<TOKEN end_char="5704" id="token-54-0" morph="none" pos="word" start_char="5699">That's</TOKEN>
<TOKEN end_char="5712" id="token-54-1" morph="none" pos="word" start_char="5706">because</TOKEN>
<TOKEN end_char="5717" id="token-54-2" morph="none" pos="word" start_char="5714">none</TOKEN>
<TOKEN end_char="5720" id="token-54-3" morph="none" pos="word" start_char="5719">of</TOKEN>
<TOKEN end_char="5724" id="token-54-4" morph="none" pos="word" start_char="5722">the</TOKEN>
<TOKEN end_char="5732" id="token-54-5" morph="none" pos="word" start_char="5726">animals</TOKEN>
<TOKEN end_char="5738" id="token-54-6" morph="none" pos="word" start_char="5734">there</TOKEN>
<TOKEN end_char="5745" id="token-54-7" morph="none" pos="word" start_char="5740">tested</TOKEN>
<TOKEN end_char="5754" id="token-54-8" morph="none" pos="word" start_char="5747">positive</TOKEN>
<TOKEN end_char="5758" id="token-54-9" morph="none" pos="word" start_char="5756">for</TOKEN>
<TOKEN end_char="5762" id="token-54-10" morph="none" pos="word" start_char="5760">the</TOKEN>
<TOKEN end_char="5768" id="token-54-11" morph="none" pos="word" start_char="5764">virus</TOKEN>
<TOKEN end_char="5769" id="token-54-12" morph="none" pos="punct" start_char="5769">.</TOKEN>
</SEG>
<SEG end_char="5916" id="segment-55" start_char="5772">
<ORIGINAL_TEXT>Most likely, the market was simply the site of an early superspreader event, with one sick person infecting an atypically large number of others.</ORIGINAL_TEXT>
<TOKEN end_char="5775" id="token-55-0" morph="none" pos="word" start_char="5772">Most</TOKEN>
<TOKEN end_char="5782" id="token-55-1" morph="none" pos="word" start_char="5777">likely</TOKEN>
<TOKEN end_char="5783" id="token-55-2" morph="none" pos="punct" start_char="5783">,</TOKEN>
<TOKEN end_char="5787" id="token-55-3" morph="none" pos="word" start_char="5785">the</TOKEN>
<TOKEN end_char="5794" id="token-55-4" morph="none" pos="word" start_char="5789">market</TOKEN>
<TOKEN end_char="5798" id="token-55-5" morph="none" pos="word" start_char="5796">was</TOKEN>
<TOKEN end_char="5805" id="token-55-6" morph="none" pos="word" start_char="5800">simply</TOKEN>
<TOKEN end_char="5809" id="token-55-7" morph="none" pos="word" start_char="5807">the</TOKEN>
<TOKEN end_char="5814" id="token-55-8" morph="none" pos="word" start_char="5811">site</TOKEN>
<TOKEN end_char="5817" id="token-55-9" morph="none" pos="word" start_char="5816">of</TOKEN>
<TOKEN end_char="5820" id="token-55-10" morph="none" pos="word" start_char="5819">an</TOKEN>
<TOKEN end_char="5826" id="token-55-11" morph="none" pos="word" start_char="5822">early</TOKEN>
<TOKEN end_char="5840" id="token-55-12" morph="none" pos="word" start_char="5828">superspreader</TOKEN>
<TOKEN end_char="5846" id="token-55-13" morph="none" pos="word" start_char="5842">event</TOKEN>
<TOKEN end_char="5847" id="token-55-14" morph="none" pos="punct" start_char="5847">,</TOKEN>
<TOKEN end_char="5852" id="token-55-15" morph="none" pos="word" start_char="5849">with</TOKEN>
<TOKEN end_char="5856" id="token-55-16" morph="none" pos="word" start_char="5854">one</TOKEN>
<TOKEN end_char="5861" id="token-55-17" morph="none" pos="word" start_char="5858">sick</TOKEN>
<TOKEN end_char="5868" id="token-55-18" morph="none" pos="word" start_char="5863">person</TOKEN>
<TOKEN end_char="5878" id="token-55-19" morph="none" pos="word" start_char="5870">infecting</TOKEN>
<TOKEN end_char="5881" id="token-55-20" morph="none" pos="word" start_char="5880">an</TOKEN>
<TOKEN end_char="5892" id="token-55-21" morph="none" pos="word" start_char="5883">atypically</TOKEN>
<TOKEN end_char="5898" id="token-55-22" morph="none" pos="word" start_char="5894">large</TOKEN>
<TOKEN end_char="5905" id="token-55-23" morph="none" pos="word" start_char="5900">number</TOKEN>
<TOKEN end_char="5908" id="token-55-24" morph="none" pos="word" start_char="5907">of</TOKEN>
<TOKEN end_char="5915" id="token-55-25" morph="none" pos="word" start_char="5910">others</TOKEN>
<TOKEN end_char="5916" id="token-55-26" morph="none" pos="punct" start_char="5916">.</TOKEN>
</SEG>
<SEG end_char="6024" id="segment-56" start_char="5918">
<ORIGINAL_TEXT>Superspreader events around the world have created clusters of infections that cropped up almost overnight.</ORIGINAL_TEXT>
<TOKEN end_char="5930" id="token-56-0" morph="none" pos="word" start_char="5918">Superspreader</TOKEN>
<TOKEN end_char="5937" id="token-56-1" morph="none" pos="word" start_char="5932">events</TOKEN>
<TOKEN end_char="5944" id="token-56-2" morph="none" pos="word" start_char="5939">around</TOKEN>
<TOKEN end_char="5948" id="token-56-3" morph="none" pos="word" start_char="5946">the</TOKEN>
<TOKEN end_char="5954" id="token-56-4" morph="none" pos="word" start_char="5950">world</TOKEN>
<TOKEN end_char="5959" id="token-56-5" morph="none" pos="word" start_char="5956">have</TOKEN>
<TOKEN end_char="5967" id="token-56-6" morph="none" pos="word" start_char="5961">created</TOKEN>
<TOKEN end_char="5976" id="token-56-7" morph="none" pos="word" start_char="5969">clusters</TOKEN>
<TOKEN end_char="5979" id="token-56-8" morph="none" pos="word" start_char="5978">of</TOKEN>
<TOKEN end_char="5990" id="token-56-9" morph="none" pos="word" start_char="5981">infections</TOKEN>
<TOKEN end_char="5995" id="token-56-10" morph="none" pos="word" start_char="5992">that</TOKEN>
<TOKEN end_char="6003" id="token-56-11" morph="none" pos="word" start_char="5997">cropped</TOKEN>
<TOKEN end_char="6006" id="token-56-12" morph="none" pos="word" start_char="6005">up</TOKEN>
<TOKEN end_char="6013" id="token-56-13" morph="none" pos="word" start_char="6008">almost</TOKEN>
<TOKEN end_char="6023" id="token-56-14" morph="none" pos="word" start_char="6015">overnight</TOKEN>
<TOKEN end_char="6024" id="token-56-15" morph="none" pos="punct" start_char="6024">.</TOKEN>
</SEG>
<SEG end_char="6086" id="segment-57" start_char="6027">
<ORIGINAL_TEXT>Research suggests the virus was in Italy in the fall of 2019</ORIGINAL_TEXT>
<TOKEN end_char="6034" id="token-57-0" morph="none" pos="word" start_char="6027">Research</TOKEN>
<TOKEN end_char="6043" id="token-57-1" morph="none" pos="word" start_char="6036">suggests</TOKEN>
<TOKEN end_char="6047" id="token-57-2" morph="none" pos="word" start_char="6045">the</TOKEN>
<TOKEN end_char="6053" id="token-57-3" morph="none" pos="word" start_char="6049">virus</TOKEN>
<TOKEN end_char="6057" id="token-57-4" morph="none" pos="word" start_char="6055">was</TOKEN>
<TOKEN end_char="6060" id="token-57-5" morph="none" pos="word" start_char="6059">in</TOKEN>
<TOKEN end_char="6066" id="token-57-6" morph="none" pos="word" start_char="6062">Italy</TOKEN>
<TOKEN end_char="6069" id="token-57-7" morph="none" pos="word" start_char="6068">in</TOKEN>
<TOKEN end_char="6073" id="token-57-8" morph="none" pos="word" start_char="6071">the</TOKEN>
<TOKEN end_char="6078" id="token-57-9" morph="none" pos="word" start_char="6075">fall</TOKEN>
<TOKEN end_char="6081" id="token-57-10" morph="none" pos="word" start_char="6080">of</TOKEN>
<TOKEN end_char="6086" id="token-57-11" morph="none" pos="word" start_char="6083">2019</TOKEN>
</SEG>
<SEG end_char="6236" id="segment-58" start_char="6091">
<ORIGINAL_TEXT>A COVID-19 patient is transported by nurses inside a biological containment stretcher in the Da Procida Hospital in Salerno, Italy, April 8, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="6091" id="token-58-0" morph="none" pos="word" start_char="6091">A</TOKEN>
<TOKEN end_char="6100" id="token-58-1" morph="none" pos="unknown" start_char="6093">COVID-19</TOKEN>
<TOKEN end_char="6108" id="token-58-2" morph="none" pos="word" start_char="6102">patient</TOKEN>
<TOKEN end_char="6111" id="token-58-3" morph="none" pos="word" start_char="6110">is</TOKEN>
<TOKEN end_char="6123" id="token-58-4" morph="none" pos="word" start_char="6113">transported</TOKEN>
<TOKEN end_char="6126" id="token-58-5" morph="none" pos="word" start_char="6125">by</TOKEN>
<TOKEN end_char="6133" id="token-58-6" morph="none" pos="word" start_char="6128">nurses</TOKEN>
<TOKEN end_char="6140" id="token-58-7" morph="none" pos="word" start_char="6135">inside</TOKEN>
<TOKEN end_char="6142" id="token-58-8" morph="none" pos="word" start_char="6142">a</TOKEN>
<TOKEN end_char="6153" id="token-58-9" morph="none" pos="word" start_char="6144">biological</TOKEN>
<TOKEN end_char="6165" id="token-58-10" morph="none" pos="word" start_char="6155">containment</TOKEN>
<TOKEN end_char="6175" id="token-58-11" morph="none" pos="word" start_char="6167">stretcher</TOKEN>
<TOKEN end_char="6178" id="token-58-12" morph="none" pos="word" start_char="6177">in</TOKEN>
<TOKEN end_char="6182" id="token-58-13" morph="none" pos="word" start_char="6180">the</TOKEN>
<TOKEN end_char="6185" id="token-58-14" morph="none" pos="word" start_char="6184">Da</TOKEN>
<TOKEN end_char="6193" id="token-58-15" morph="none" pos="word" start_char="6187">Procida</TOKEN>
<TOKEN end_char="6202" id="token-58-16" morph="none" pos="word" start_char="6195">Hospital</TOKEN>
<TOKEN end_char="6205" id="token-58-17" morph="none" pos="word" start_char="6204">in</TOKEN>
<TOKEN end_char="6213" id="token-58-18" morph="none" pos="word" start_char="6207">Salerno</TOKEN>
<TOKEN end_char="6214" id="token-58-19" morph="none" pos="punct" start_char="6214">,</TOKEN>
<TOKEN end_char="6220" id="token-58-20" morph="none" pos="word" start_char="6216">Italy</TOKEN>
<TOKEN end_char="6221" id="token-58-21" morph="none" pos="punct" start_char="6221">,</TOKEN>
<TOKEN end_char="6227" id="token-58-22" morph="none" pos="word" start_char="6223">April</TOKEN>
<TOKEN end_char="6229" id="token-58-23" morph="none" pos="word" start_char="6229">8</TOKEN>
<TOKEN end_char="6230" id="token-58-24" morph="none" pos="punct" start_char="6230">,</TOKEN>
<TOKEN end_char="6235" id="token-58-25" morph="none" pos="word" start_char="6232">2020</TOKEN>
<TOKEN end_char="6236" id="token-58-26" morph="none" pos="punct" start_char="6236">.</TOKEN>
</SEG>
<SEG end_char="6262" id="segment-59" start_char="6239">
<ORIGINAL_TEXT>Ivan Romano/Getty Images</ORIGINAL_TEXT>
<TOKEN end_char="6242" id="token-59-0" morph="none" pos="word" start_char="6239">Ivan</TOKEN>
<TOKEN end_char="6255" id="token-59-1" morph="none" pos="unknown" start_char="6244">Romano/Getty</TOKEN>
<TOKEN end_char="6262" id="token-59-2" morph="none" pos="word" start_char="6257">Images</TOKEN>
</SEG>
<SEG end_char="6349" id="segment-60" start_char="6266">
<ORIGINAL_TEXT>Italy recorded its first official coronavirus case in Lombardy on February 21, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="6270" id="token-60-0" morph="none" pos="word" start_char="6266">Italy</TOKEN>
<TOKEN end_char="6279" id="token-60-1" morph="none" pos="word" start_char="6272">recorded</TOKEN>
<TOKEN end_char="6283" id="token-60-2" morph="none" pos="word" start_char="6281">its</TOKEN>
<TOKEN end_char="6289" id="token-60-3" morph="none" pos="word" start_char="6285">first</TOKEN>
<TOKEN end_char="6298" id="token-60-4" morph="none" pos="word" start_char="6291">official</TOKEN>
<TOKEN end_char="6310" id="token-60-5" morph="none" pos="word" start_char="6300">coronavirus</TOKEN>
<TOKEN end_char="6315" id="token-60-6" morph="none" pos="word" start_char="6312">case</TOKEN>
<TOKEN end_char="6318" id="token-60-7" morph="none" pos="word" start_char="6317">in</TOKEN>
<TOKEN end_char="6327" id="token-60-8" morph="none" pos="word" start_char="6320">Lombardy</TOKEN>
<TOKEN end_char="6330" id="token-60-9" morph="none" pos="word" start_char="6329">on</TOKEN>
<TOKEN end_char="6339" id="token-60-10" morph="none" pos="word" start_char="6332">February</TOKEN>
<TOKEN end_char="6342" id="token-60-11" morph="none" pos="word" start_char="6341">21</TOKEN>
<TOKEN end_char="6343" id="token-60-12" morph="none" pos="punct" start_char="6343">,</TOKEN>
<TOKEN end_char="6348" id="token-60-13" morph="none" pos="word" start_char="6345">2020</TOKEN>
<TOKEN end_char="6349" id="token-60-14" morph="none" pos="punct" start_char="6349">.</TOKEN>
</SEG>
<SEG end_char="6483" id="segment-61" start_char="6351">
<ORIGINAL_TEXT>Yet a recent study found coronavirus antibodies in blood samples collected from 23 Italians in September 2019 and 27 in October 2019.</ORIGINAL_TEXT>
<TOKEN end_char="6353" id="token-61-0" morph="none" pos="word" start_char="6351">Yet</TOKEN>
<TOKEN end_char="6355" id="token-61-1" morph="none" pos="word" start_char="6355">a</TOKEN>
<TOKEN end_char="6362" id="token-61-2" morph="none" pos="word" start_char="6357">recent</TOKEN>
<TOKEN end_char="6368" id="token-61-3" morph="none" pos="word" start_char="6364">study</TOKEN>
<TOKEN end_char="6374" id="token-61-4" morph="none" pos="word" start_char="6370">found</TOKEN>
<TOKEN end_char="6386" id="token-61-5" morph="none" pos="word" start_char="6376">coronavirus</TOKEN>
<TOKEN end_char="6397" id="token-61-6" morph="none" pos="word" start_char="6388">antibodies</TOKEN>
<TOKEN end_char="6400" id="token-61-7" morph="none" pos="word" start_char="6399">in</TOKEN>
<TOKEN end_char="6406" id="token-61-8" morph="none" pos="word" start_char="6402">blood</TOKEN>
<TOKEN end_char="6414" id="token-61-9" morph="none" pos="word" start_char="6408">samples</TOKEN>
<TOKEN end_char="6424" id="token-61-10" morph="none" pos="word" start_char="6416">collected</TOKEN>
<TOKEN end_char="6429" id="token-61-11" morph="none" pos="word" start_char="6426">from</TOKEN>
<TOKEN end_char="6432" id="token-61-12" morph="none" pos="word" start_char="6431">23</TOKEN>
<TOKEN end_char="6441" id="token-61-13" morph="none" pos="word" start_char="6434">Italians</TOKEN>
<TOKEN end_char="6444" id="token-61-14" morph="none" pos="word" start_char="6443">in</TOKEN>
<TOKEN end_char="6454" id="token-61-15" morph="none" pos="word" start_char="6446">September</TOKEN>
<TOKEN end_char="6459" id="token-61-16" morph="none" pos="word" start_char="6456">2019</TOKEN>
<TOKEN end_char="6463" id="token-61-17" morph="none" pos="word" start_char="6461">and</TOKEN>
<TOKEN end_char="6466" id="token-61-18" morph="none" pos="word" start_char="6465">27</TOKEN>
<TOKEN end_char="6469" id="token-61-19" morph="none" pos="word" start_char="6468">in</TOKEN>
<TOKEN end_char="6477" id="token-61-20" morph="none" pos="word" start_char="6471">October</TOKEN>
<TOKEN end_char="6482" id="token-61-21" morph="none" pos="word" start_char="6479">2019</TOKEN>
<TOKEN end_char="6483" id="token-61-22" morph="none" pos="punct" start_char="6483">.</TOKEN>
</SEG>
<SEG end_char="6779" id="segment-62" start_char="6486">
<ORIGINAL_TEXT>"Our results indicate that SARS-CoV-2 circulated in Italy earlier than the first official COVID-19 cases were diagnosed in Lombardy, even long before the first official reports from the Chinese authorities, casting new light on the onset and spread of the COVID-19 pandemic," the authors wrote.</ORIGINAL_TEXT>
<TOKEN end_char="6486" id="token-62-0" morph="none" pos="punct" start_char="6486">"</TOKEN>
<TOKEN end_char="6489" id="token-62-1" morph="none" pos="word" start_char="6487">Our</TOKEN>
<TOKEN end_char="6497" id="token-62-2" morph="none" pos="word" start_char="6491">results</TOKEN>
<TOKEN end_char="6506" id="token-62-3" morph="none" pos="word" start_char="6499">indicate</TOKEN>
<TOKEN end_char="6511" id="token-62-4" morph="none" pos="word" start_char="6508">that</TOKEN>
<TOKEN end_char="6522" id="token-62-5" morph="none" pos="unknown" start_char="6513">SARS-CoV-2</TOKEN>
<TOKEN end_char="6533" id="token-62-6" morph="none" pos="word" start_char="6524">circulated</TOKEN>
<TOKEN end_char="6536" id="token-62-7" morph="none" pos="word" start_char="6535">in</TOKEN>
<TOKEN end_char="6542" id="token-62-8" morph="none" pos="word" start_char="6538">Italy</TOKEN>
<TOKEN end_char="6550" id="token-62-9" morph="none" pos="word" start_char="6544">earlier</TOKEN>
<TOKEN end_char="6555" id="token-62-10" morph="none" pos="word" start_char="6552">than</TOKEN>
<TOKEN end_char="6559" id="token-62-11" morph="none" pos="word" start_char="6557">the</TOKEN>
<TOKEN end_char="6565" id="token-62-12" morph="none" pos="word" start_char="6561">first</TOKEN>
<TOKEN end_char="6574" id="token-62-13" morph="none" pos="word" start_char="6567">official</TOKEN>
<TOKEN end_char="6583" id="token-62-14" morph="none" pos="unknown" start_char="6576">COVID-19</TOKEN>
<TOKEN end_char="6589" id="token-62-15" morph="none" pos="word" start_char="6585">cases</TOKEN>
<TOKEN end_char="6594" id="token-62-16" morph="none" pos="word" start_char="6591">were</TOKEN>
<TOKEN end_char="6604" id="token-62-17" morph="none" pos="word" start_char="6596">diagnosed</TOKEN>
<TOKEN end_char="6607" id="token-62-18" morph="none" pos="word" start_char="6606">in</TOKEN>
<TOKEN end_char="6616" id="token-62-19" morph="none" pos="word" start_char="6609">Lombardy</TOKEN>
<TOKEN end_char="6617" id="token-62-20" morph="none" pos="punct" start_char="6617">,</TOKEN>
<TOKEN end_char="6622" id="token-62-21" morph="none" pos="word" start_char="6619">even</TOKEN>
<TOKEN end_char="6627" id="token-62-22" morph="none" pos="word" start_char="6624">long</TOKEN>
<TOKEN end_char="6634" id="token-62-23" morph="none" pos="word" start_char="6629">before</TOKEN>
<TOKEN end_char="6638" id="token-62-24" morph="none" pos="word" start_char="6636">the</TOKEN>
<TOKEN end_char="6644" id="token-62-25" morph="none" pos="word" start_char="6640">first</TOKEN>
<TOKEN end_char="6653" id="token-62-26" morph="none" pos="word" start_char="6646">official</TOKEN>
<TOKEN end_char="6661" id="token-62-27" morph="none" pos="word" start_char="6655">reports</TOKEN>
<TOKEN end_char="6666" id="token-62-28" morph="none" pos="word" start_char="6663">from</TOKEN>
<TOKEN end_char="6670" id="token-62-29" morph="none" pos="word" start_char="6668">the</TOKEN>
<TOKEN end_char="6678" id="token-62-30" morph="none" pos="word" start_char="6672">Chinese</TOKEN>
<TOKEN end_char="6690" id="token-62-31" morph="none" pos="word" start_char="6680">authorities</TOKEN>
<TOKEN end_char="6691" id="token-62-32" morph="none" pos="punct" start_char="6691">,</TOKEN>
<TOKEN end_char="6699" id="token-62-33" morph="none" pos="word" start_char="6693">casting</TOKEN>
<TOKEN end_char="6703" id="token-62-34" morph="none" pos="word" start_char="6701">new</TOKEN>
<TOKEN end_char="6709" id="token-62-35" morph="none" pos="word" start_char="6705">light</TOKEN>
<TOKEN end_char="6712" id="token-62-36" morph="none" pos="word" start_char="6711">on</TOKEN>
<TOKEN end_char="6716" id="token-62-37" morph="none" pos="word" start_char="6714">the</TOKEN>
<TOKEN end_char="6722" id="token-62-38" morph="none" pos="word" start_char="6718">onset</TOKEN>
<TOKEN end_char="6726" id="token-62-39" morph="none" pos="word" start_char="6724">and</TOKEN>
<TOKEN end_char="6733" id="token-62-40" morph="none" pos="word" start_char="6728">spread</TOKEN>
<TOKEN end_char="6736" id="token-62-41" morph="none" pos="word" start_char="6735">of</TOKEN>
<TOKEN end_char="6740" id="token-62-42" morph="none" pos="word" start_char="6738">the</TOKEN>
<TOKEN end_char="6749" id="token-62-43" morph="none" pos="unknown" start_char="6742">COVID-19</TOKEN>
<TOKEN end_char="6758" id="token-62-44" morph="none" pos="word" start_char="6751">pandemic</TOKEN>
<TOKEN end_char="6760" id="token-62-45" morph="none" pos="punct" start_char="6759">,"</TOKEN>
<TOKEN end_char="6764" id="token-62-46" morph="none" pos="word" start_char="6762">the</TOKEN>
<TOKEN end_char="6772" id="token-62-47" morph="none" pos="word" start_char="6766">authors</TOKEN>
<TOKEN end_char="6778" id="token-62-48" morph="none" pos="word" start_char="6774">wrote</TOKEN>
<TOKEN end_char="6779" id="token-62-49" morph="none" pos="punct" start_char="6779">.</TOKEN>
</SEG>
<SEG end_char="6827" id="segment-63" start_char="6781">
<ORIGINAL_TEXT>(SARS-CoV-2 is the clinical name of the virus.)</ORIGINAL_TEXT>
<TOKEN end_char="6781" id="token-63-0" morph="none" pos="punct" start_char="6781">(</TOKEN>
<TOKEN end_char="6791" id="token-63-1" morph="none" pos="unknown" start_char="6782">SARS-CoV-2</TOKEN>
<TOKEN end_char="6794" id="token-63-2" morph="none" pos="word" start_char="6793">is</TOKEN>
<TOKEN end_char="6798" id="token-63-3" morph="none" pos="word" start_char="6796">the</TOKEN>
<TOKEN end_char="6807" id="token-63-4" morph="none" pos="word" start_char="6800">clinical</TOKEN>
<TOKEN end_char="6812" id="token-63-5" morph="none" pos="word" start_char="6809">name</TOKEN>
<TOKEN end_char="6815" id="token-63-6" morph="none" pos="word" start_char="6814">of</TOKEN>
<TOKEN end_char="6819" id="token-63-7" morph="none" pos="word" start_char="6817">the</TOKEN>
<TOKEN end_char="6825" id="token-63-8" morph="none" pos="word" start_char="6821">virus</TOKEN>
<TOKEN end_char="6827" id="token-63-9" morph="none" pos="punct" start_char="6826">.)</TOKEN>
</SEG>
<SEG end_char="7044" id="segment-64" start_char="6830">
<ORIGINAL_TEXT>A study conducted by Rome's Department of Environment and Health supports that conclusion: Researchers found the coronavirus' genetic material in sewage samples from Milan and Turin dating back to December 18, 2019.</ORIGINAL_TEXT>
<TOKEN end_char="6830" id="token-64-0" morph="none" pos="word" start_char="6830">A</TOKEN>
<TOKEN end_char="6836" id="token-64-1" morph="none" pos="word" start_char="6832">study</TOKEN>
<TOKEN end_char="6846" id="token-64-2" morph="none" pos="word" start_char="6838">conducted</TOKEN>
<TOKEN end_char="6849" id="token-64-3" morph="none" pos="word" start_char="6848">by</TOKEN>
<TOKEN end_char="6856" id="token-64-4" morph="none" pos="word" start_char="6851">Rome's</TOKEN>
<TOKEN end_char="6867" id="token-64-5" morph="none" pos="word" start_char="6858">Department</TOKEN>
<TOKEN end_char="6870" id="token-64-6" morph="none" pos="word" start_char="6869">of</TOKEN>
<TOKEN end_char="6882" id="token-64-7" morph="none" pos="word" start_char="6872">Environment</TOKEN>
<TOKEN end_char="6886" id="token-64-8" morph="none" pos="word" start_char="6884">and</TOKEN>
<TOKEN end_char="6893" id="token-64-9" morph="none" pos="word" start_char="6888">Health</TOKEN>
<TOKEN end_char="6902" id="token-64-10" morph="none" pos="word" start_char="6895">supports</TOKEN>
<TOKEN end_char="6907" id="token-64-11" morph="none" pos="word" start_char="6904">that</TOKEN>
<TOKEN end_char="6918" id="token-64-12" morph="none" pos="word" start_char="6909">conclusion</TOKEN>
<TOKEN end_char="6919" id="token-64-13" morph="none" pos="punct" start_char="6919">:</TOKEN>
<TOKEN end_char="6931" id="token-64-14" morph="none" pos="word" start_char="6921">Researchers</TOKEN>
<TOKEN end_char="6937" id="token-64-15" morph="none" pos="word" start_char="6933">found</TOKEN>
<TOKEN end_char="6941" id="token-64-16" morph="none" pos="word" start_char="6939">the</TOKEN>
<TOKEN end_char="6953" id="token-64-17" morph="none" pos="word" start_char="6943">coronavirus</TOKEN>
<TOKEN end_char="6954" id="token-64-18" morph="none" pos="punct" start_char="6954">'</TOKEN>
<TOKEN end_char="6962" id="token-64-19" morph="none" pos="word" start_char="6956">genetic</TOKEN>
<TOKEN end_char="6971" id="token-64-20" morph="none" pos="word" start_char="6964">material</TOKEN>
<TOKEN end_char="6974" id="token-64-21" morph="none" pos="word" start_char="6973">in</TOKEN>
<TOKEN end_char="6981" id="token-64-22" morph="none" pos="word" start_char="6976">sewage</TOKEN>
<TOKEN end_char="6989" id="token-64-23" morph="none" pos="word" start_char="6983">samples</TOKEN>
<TOKEN end_char="6994" id="token-64-24" morph="none" pos="word" start_char="6991">from</TOKEN>
<TOKEN end_char="7000" id="token-64-25" morph="none" pos="word" start_char="6996">Milan</TOKEN>
<TOKEN end_char="7004" id="token-64-26" morph="none" pos="word" start_char="7002">and</TOKEN>
<TOKEN end_char="7010" id="token-64-27" morph="none" pos="word" start_char="7006">Turin</TOKEN>
<TOKEN end_char="7017" id="token-64-28" morph="none" pos="word" start_char="7012">dating</TOKEN>
<TOKEN end_char="7022" id="token-64-29" morph="none" pos="word" start_char="7019">back</TOKEN>
<TOKEN end_char="7025" id="token-64-30" morph="none" pos="word" start_char="7024">to</TOKEN>
<TOKEN end_char="7034" id="token-64-31" morph="none" pos="word" start_char="7027">December</TOKEN>
<TOKEN end_char="7037" id="token-64-32" morph="none" pos="word" start_char="7036">18</TOKEN>
<TOKEN end_char="7038" id="token-64-33" morph="none" pos="punct" start_char="7038">,</TOKEN>
<TOKEN end_char="7043" id="token-64-34" morph="none" pos="word" start_char="7040">2019</TOKEN>
<TOKEN end_char="7044" id="token-64-35" morph="none" pos="punct" start_char="7044">.</TOKEN>
</SEG>
<SEG end_char="7196" id="segment-65" start_char="7048">
<ORIGINAL_TEXT>A man walks past a billboard raising awareness about the new coronavirus that reads "All together, without fear," in Naples, Italy on March 22, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7048" id="token-65-0" morph="none" pos="word" start_char="7048">A</TOKEN>
<TOKEN end_char="7052" id="token-65-1" morph="none" pos="word" start_char="7050">man</TOKEN>
<TOKEN end_char="7058" id="token-65-2" morph="none" pos="word" start_char="7054">walks</TOKEN>
<TOKEN end_char="7063" id="token-65-3" morph="none" pos="word" start_char="7060">past</TOKEN>
<TOKEN end_char="7065" id="token-65-4" morph="none" pos="word" start_char="7065">a</TOKEN>
<TOKEN end_char="7075" id="token-65-5" morph="none" pos="word" start_char="7067">billboard</TOKEN>
<TOKEN end_char="7083" id="token-65-6" morph="none" pos="word" start_char="7077">raising</TOKEN>
<TOKEN end_char="7093" id="token-65-7" morph="none" pos="word" start_char="7085">awareness</TOKEN>
<TOKEN end_char="7099" id="token-65-8" morph="none" pos="word" start_char="7095">about</TOKEN>
<TOKEN end_char="7103" id="token-65-9" morph="none" pos="word" start_char="7101">the</TOKEN>
<TOKEN end_char="7107" id="token-65-10" morph="none" pos="word" start_char="7105">new</TOKEN>
<TOKEN end_char="7119" id="token-65-11" morph="none" pos="word" start_char="7109">coronavirus</TOKEN>
<TOKEN end_char="7124" id="token-65-12" morph="none" pos="word" start_char="7121">that</TOKEN>
<TOKEN end_char="7130" id="token-65-13" morph="none" pos="word" start_char="7126">reads</TOKEN>
<TOKEN end_char="7132" id="token-65-14" morph="none" pos="punct" start_char="7132">"</TOKEN>
<TOKEN end_char="7135" id="token-65-15" morph="none" pos="word" start_char="7133">All</TOKEN>
<TOKEN end_char="7144" id="token-65-16" morph="none" pos="word" start_char="7137">together</TOKEN>
<TOKEN end_char="7145" id="token-65-17" morph="none" pos="punct" start_char="7145">,</TOKEN>
<TOKEN end_char="7153" id="token-65-18" morph="none" pos="word" start_char="7147">without</TOKEN>
<TOKEN end_char="7158" id="token-65-19" morph="none" pos="word" start_char="7155">fear</TOKEN>
<TOKEN end_char="7160" id="token-65-20" morph="none" pos="punct" start_char="7159">,"</TOKEN>
<TOKEN end_char="7163" id="token-65-21" morph="none" pos="word" start_char="7162">in</TOKEN>
<TOKEN end_char="7170" id="token-65-22" morph="none" pos="word" start_char="7165">Naples</TOKEN>
<TOKEN end_char="7171" id="token-65-23" morph="none" pos="punct" start_char="7171">,</TOKEN>
<TOKEN end_char="7177" id="token-65-24" morph="none" pos="word" start_char="7173">Italy</TOKEN>
<TOKEN end_char="7180" id="token-65-25" morph="none" pos="word" start_char="7179">on</TOKEN>
<TOKEN end_char="7186" id="token-65-26" morph="none" pos="word" start_char="7182">March</TOKEN>
<TOKEN end_char="7189" id="token-65-27" morph="none" pos="word" start_char="7188">22</TOKEN>
<TOKEN end_char="7190" id="token-65-28" morph="none" pos="punct" start_char="7190">,</TOKEN>
<TOKEN end_char="7195" id="token-65-29" morph="none" pos="word" start_char="7192">2020</TOKEN>
<TOKEN end_char="7196" id="token-65-30" morph="none" pos="punct" start_char="7196">.</TOKEN>
</SEG>
<SEG end_char="7222" id="segment-66" start_char="7199">
<ORIGINAL_TEXT>Carlo Hermann /AFP/Getty</ORIGINAL_TEXT>
<TOKEN end_char="7203" id="token-66-0" morph="none" pos="word" start_char="7199">Carlo</TOKEN>
<TOKEN end_char="7211" id="token-66-1" morph="none" pos="word" start_char="7205">Hermann</TOKEN>
<TOKEN end_char="7213" id="token-66-2" morph="none" pos="punct" start_char="7213">/</TOKEN>
<TOKEN end_char="7222" id="token-66-3" morph="none" pos="unknown" start_char="7214">AFP/Getty</TOKEN>
</SEG>
<SEG end_char="7297" id="segment-67" start_char="7226">
<ORIGINAL_TEXT>Spain and France also found clues that the virus was circulating in 2019</ORIGINAL_TEXT>
<TOKEN end_char="7230" id="token-67-0" morph="none" pos="word" start_char="7226">Spain</TOKEN>
<TOKEN end_char="7234" id="token-67-1" morph="none" pos="word" start_char="7232">and</TOKEN>
<TOKEN end_char="7241" id="token-67-2" morph="none" pos="word" start_char="7236">France</TOKEN>
<TOKEN end_char="7246" id="token-67-3" morph="none" pos="word" start_char="7243">also</TOKEN>
<TOKEN end_char="7252" id="token-67-4" morph="none" pos="word" start_char="7248">found</TOKEN>
<TOKEN end_char="7258" id="token-67-5" morph="none" pos="word" start_char="7254">clues</TOKEN>
<TOKEN end_char="7263" id="token-67-6" morph="none" pos="word" start_char="7260">that</TOKEN>
<TOKEN end_char="7267" id="token-67-7" morph="none" pos="word" start_char="7265">the</TOKEN>
<TOKEN end_char="7273" id="token-67-8" morph="none" pos="word" start_char="7269">virus</TOKEN>
<TOKEN end_char="7277" id="token-67-9" morph="none" pos="word" start_char="7275">was</TOKEN>
<TOKEN end_char="7289" id="token-67-10" morph="none" pos="word" start_char="7279">circulating</TOKEN>
<TOKEN end_char="7292" id="token-67-11" morph="none" pos="word" start_char="7291">in</TOKEN>
<TOKEN end_char="7297" id="token-67-12" morph="none" pos="word" start_char="7294">2019</TOKEN>
</SEG>
<SEG end_char="7440" id="segment-68" start_char="7301">
<ORIGINAL_TEXT>In May, doctors at a Paris hospital discovered that patients they'd treated for pneumonia on December 27, 2019, had been sick with COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="7302" id="token-68-0" morph="none" pos="word" start_char="7301">In</TOKEN>
<TOKEN end_char="7306" id="token-68-1" morph="none" pos="word" start_char="7304">May</TOKEN>
<TOKEN end_char="7307" id="token-68-2" morph="none" pos="punct" start_char="7307">,</TOKEN>
<TOKEN end_char="7315" id="token-68-3" morph="none" pos="word" start_char="7309">doctors</TOKEN>
<TOKEN end_char="7318" id="token-68-4" morph="none" pos="word" start_char="7317">at</TOKEN>
<TOKEN end_char="7320" id="token-68-5" morph="none" pos="word" start_char="7320">a</TOKEN>
<TOKEN end_char="7326" id="token-68-6" morph="none" pos="word" start_char="7322">Paris</TOKEN>
<TOKEN end_char="7335" id="token-68-7" morph="none" pos="word" start_char="7328">hospital</TOKEN>
<TOKEN end_char="7346" id="token-68-8" morph="none" pos="word" start_char="7337">discovered</TOKEN>
<TOKEN end_char="7351" id="token-68-9" morph="none" pos="word" start_char="7348">that</TOKEN>
<TOKEN end_char="7360" id="token-68-10" morph="none" pos="word" start_char="7353">patients</TOKEN>
<TOKEN end_char="7367" id="token-68-11" morph="none" pos="word" start_char="7362">they'd</TOKEN>
<TOKEN end_char="7375" id="token-68-12" morph="none" pos="word" start_char="7369">treated</TOKEN>
<TOKEN end_char="7379" id="token-68-13" morph="none" pos="word" start_char="7377">for</TOKEN>
<TOKEN end_char="7389" id="token-68-14" morph="none" pos="word" start_char="7381">pneumonia</TOKEN>
<TOKEN end_char="7392" id="token-68-15" morph="none" pos="word" start_char="7391">on</TOKEN>
<TOKEN end_char="7401" id="token-68-16" morph="none" pos="word" start_char="7394">December</TOKEN>
<TOKEN end_char="7404" id="token-68-17" morph="none" pos="word" start_char="7403">27</TOKEN>
<TOKEN end_char="7405" id="token-68-18" morph="none" pos="punct" start_char="7405">,</TOKEN>
<TOKEN end_char="7410" id="token-68-19" morph="none" pos="word" start_char="7407">2019</TOKEN>
<TOKEN end_char="7411" id="token-68-20" morph="none" pos="punct" start_char="7411">,</TOKEN>
<TOKEN end_char="7415" id="token-68-21" morph="none" pos="word" start_char="7413">had</TOKEN>
<TOKEN end_char="7420" id="token-68-22" morph="none" pos="word" start_char="7417">been</TOKEN>
<TOKEN end_char="7425" id="token-68-23" morph="none" pos="word" start_char="7422">sick</TOKEN>
<TOKEN end_char="7430" id="token-68-24" morph="none" pos="word" start_char="7427">with</TOKEN>
<TOKEN end_char="7439" id="token-68-25" morph="none" pos="unknown" start_char="7432">COVID-19</TOKEN>
<TOKEN end_char="7440" id="token-68-26" morph="none" pos="punct" start_char="7440">.</TOKEN>
</SEG>
<SEG end_char="7512" id="segment-69" start_char="7442">
<ORIGINAL_TEXT>France didn't record its first official case until January 24, however.</ORIGINAL_TEXT>
<TOKEN end_char="7447" id="token-69-0" morph="none" pos="word" start_char="7442">France</TOKEN>
<TOKEN end_char="7454" id="token-69-1" morph="none" pos="word" start_char="7449">didn't</TOKEN>
<TOKEN end_char="7461" id="token-69-2" morph="none" pos="word" start_char="7456">record</TOKEN>
<TOKEN end_char="7465" id="token-69-3" morph="none" pos="word" start_char="7463">its</TOKEN>
<TOKEN end_char="7471" id="token-69-4" morph="none" pos="word" start_char="7467">first</TOKEN>
<TOKEN end_char="7480" id="token-69-5" morph="none" pos="word" start_char="7473">official</TOKEN>
<TOKEN end_char="7485" id="token-69-6" morph="none" pos="word" start_char="7482">case</TOKEN>
<TOKEN end_char="7491" id="token-69-7" morph="none" pos="word" start_char="7487">until</TOKEN>
<TOKEN end_char="7499" id="token-69-8" morph="none" pos="word" start_char="7493">January</TOKEN>
<TOKEN end_char="7502" id="token-69-9" morph="none" pos="word" start_char="7501">24</TOKEN>
<TOKEN end_char="7503" id="token-69-10" morph="none" pos="punct" start_char="7503">,</TOKEN>
<TOKEN end_char="7511" id="token-69-11" morph="none" pos="word" start_char="7505">however</TOKEN>
<TOKEN end_char="7512" id="token-69-12" morph="none" pos="punct" start_char="7512">.</TOKEN>
</SEG>
<SEG end_char="7592" id="segment-70" start_char="7516">
<ORIGINAL_TEXT>People in line for coronavirus tests in Barcelona, Spain, on August 31, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7521" id="token-70-0" morph="none" pos="word" start_char="7516">People</TOKEN>
<TOKEN end_char="7524" id="token-70-1" morph="none" pos="word" start_char="7523">in</TOKEN>
<TOKEN end_char="7529" id="token-70-2" morph="none" pos="word" start_char="7526">line</TOKEN>
<TOKEN end_char="7533" id="token-70-3" morph="none" pos="word" start_char="7531">for</TOKEN>
<TOKEN end_char="7545" id="token-70-4" morph="none" pos="word" start_char="7535">coronavirus</TOKEN>
<TOKEN end_char="7551" id="token-70-5" morph="none" pos="word" start_char="7547">tests</TOKEN>
<TOKEN end_char="7554" id="token-70-6" morph="none" pos="word" start_char="7553">in</TOKEN>
<TOKEN end_char="7564" id="token-70-7" morph="none" pos="word" start_char="7556">Barcelona</TOKEN>
<TOKEN end_char="7565" id="token-70-8" morph="none" pos="punct" start_char="7565">,</TOKEN>
<TOKEN end_char="7571" id="token-70-9" morph="none" pos="word" start_char="7567">Spain</TOKEN>
<TOKEN end_char="7572" id="token-70-10" morph="none" pos="punct" start_char="7572">,</TOKEN>
<TOKEN end_char="7575" id="token-70-11" morph="none" pos="word" start_char="7574">on</TOKEN>
<TOKEN end_char="7582" id="token-70-12" morph="none" pos="word" start_char="7577">August</TOKEN>
<TOKEN end_char="7585" id="token-70-13" morph="none" pos="word" start_char="7584">31</TOKEN>
<TOKEN end_char="7586" id="token-70-14" morph="none" pos="punct" start_char="7586">,</TOKEN>
<TOKEN end_char="7591" id="token-70-15" morph="none" pos="word" start_char="7588">2020</TOKEN>
<TOKEN end_char="7592" id="token-70-16" morph="none" pos="punct" start_char="7592">.</TOKEN>
</SEG>
<SEG end_char="7619" id="segment-71" start_char="7595">
<ORIGINAL_TEXT>AP Photo/Emilio Morenatti</ORIGINAL_TEXT>
<TOKEN end_char="7596" id="token-71-0" morph="none" pos="word" start_char="7595">AP</TOKEN>
<TOKEN end_char="7609" id="token-71-1" morph="none" pos="unknown" start_char="7598">Photo/Emilio</TOKEN>
<TOKEN end_char="7619" id="token-71-2" morph="none" pos="word" start_char="7611">Morenatti</TOKEN>
<TRANSLATED_TEXT>AP Photo / Emilio Morenatti</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="7827" id="segment-72" start_char="7623">
<ORIGINAL_TEXT>In Spain, meanwhile, researchers from the University of Barcelona found evidence of the coronavirus in city sewage samples collected in mid-January 2020, six weeks before the country's first official case.</ORIGINAL_TEXT>
<TOKEN end_char="7624" id="token-72-0" morph="none" pos="word" start_char="7623">In</TOKEN>
<TOKEN end_char="7630" id="token-72-1" morph="none" pos="word" start_char="7626">Spain</TOKEN>
<TOKEN end_char="7631" id="token-72-2" morph="none" pos="punct" start_char="7631">,</TOKEN>
<TOKEN end_char="7641" id="token-72-3" morph="none" pos="word" start_char="7633">meanwhile</TOKEN>
<TOKEN end_char="7642" id="token-72-4" morph="none" pos="punct" start_char="7642">,</TOKEN>
<TOKEN end_char="7654" id="token-72-5" morph="none" pos="word" start_char="7644">researchers</TOKEN>
<TOKEN end_char="7659" id="token-72-6" morph="none" pos="word" start_char="7656">from</TOKEN>
<TOKEN end_char="7663" id="token-72-7" morph="none" pos="word" start_char="7661">the</TOKEN>
<TOKEN end_char="7674" id="token-72-8" morph="none" pos="word" start_char="7665">University</TOKEN>
<TOKEN end_char="7677" id="token-72-9" morph="none" pos="word" start_char="7676">of</TOKEN>
<TOKEN end_char="7687" id="token-72-10" morph="none" pos="word" start_char="7679">Barcelona</TOKEN>
<TOKEN end_char="7693" id="token-72-11" morph="none" pos="word" start_char="7689">found</TOKEN>
<TOKEN end_char="7702" id="token-72-12" morph="none" pos="word" start_char="7695">evidence</TOKEN>
<TOKEN end_char="7705" id="token-72-13" morph="none" pos="word" start_char="7704">of</TOKEN>
<TOKEN end_char="7709" id="token-72-14" morph="none" pos="word" start_char="7707">the</TOKEN>
<TOKEN end_char="7721" id="token-72-15" morph="none" pos="word" start_char="7711">coronavirus</TOKEN>
<TOKEN end_char="7724" id="token-72-16" morph="none" pos="word" start_char="7723">in</TOKEN>
<TOKEN end_char="7729" id="token-72-17" morph="none" pos="word" start_char="7726">city</TOKEN>
<TOKEN end_char="7736" id="token-72-18" morph="none" pos="word" start_char="7731">sewage</TOKEN>
<TOKEN end_char="7744" id="token-72-19" morph="none" pos="word" start_char="7738">samples</TOKEN>
<TOKEN end_char="7754" id="token-72-20" morph="none" pos="word" start_char="7746">collected</TOKEN>
<TOKEN end_char="7757" id="token-72-21" morph="none" pos="word" start_char="7756">in</TOKEN>
<TOKEN end_char="7769" id="token-72-22" morph="none" pos="unknown" start_char="7759">mid-January</TOKEN>
<TOKEN end_char="7774" id="token-72-23" morph="none" pos="word" start_char="7771">2020</TOKEN>
<TOKEN end_char="7775" id="token-72-24" morph="none" pos="punct" start_char="7775">,</TOKEN>
<TOKEN end_char="7779" id="token-72-25" morph="none" pos="word" start_char="7777">six</TOKEN>
<TOKEN end_char="7785" id="token-72-26" morph="none" pos="word" start_char="7781">weeks</TOKEN>
<TOKEN end_char="7792" id="token-72-27" morph="none" pos="word" start_char="7787">before</TOKEN>
<TOKEN end_char="7796" id="token-72-28" morph="none" pos="word" start_char="7794">the</TOKEN>
<TOKEN end_char="7806" id="token-72-29" morph="none" pos="word" start_char="7798">country's</TOKEN>
<TOKEN end_char="7812" id="token-72-30" morph="none" pos="word" start_char="7808">first</TOKEN>
<TOKEN end_char="7821" id="token-72-31" morph="none" pos="word" start_char="7814">official</TOKEN>
<TOKEN end_char="7826" id="token-72-32" morph="none" pos="word" start_char="7823">case</TOKEN>
<TOKEN end_char="7827" id="token-72-33" morph="none" pos="punct" start_char="7827">.</TOKEN>
</SEG>
<SEG end_char="7939" id="segment-73" start_char="7830">
<ORIGINAL_TEXT>Surprisingly, a sewage sample collected on March 12, 2019, also tested positive for traces of the coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="7841" id="token-73-0" morph="none" pos="word" start_char="7830">Surprisingly</TOKEN>
<TOKEN end_char="7842" id="token-73-1" morph="none" pos="punct" start_char="7842">,</TOKEN>
<TOKEN end_char="7844" id="token-73-2" morph="none" pos="word" start_char="7844">a</TOKEN>
<TOKEN end_char="7851" id="token-73-3" morph="none" pos="word" start_char="7846">sewage</TOKEN>
<TOKEN end_char="7858" id="token-73-4" morph="none" pos="word" start_char="7853">sample</TOKEN>
<TOKEN end_char="7868" id="token-73-5" morph="none" pos="word" start_char="7860">collected</TOKEN>
<TOKEN end_char="7871" id="token-73-6" morph="none" pos="word" start_char="7870">on</TOKEN>
<TOKEN end_char="7877" id="token-73-7" morph="none" pos="word" start_char="7873">March</TOKEN>
<TOKEN end_char="7880" id="token-73-8" morph="none" pos="word" start_char="7879">12</TOKEN>
<TOKEN end_char="7881" id="token-73-9" morph="none" pos="punct" start_char="7881">,</TOKEN>
<TOKEN end_char="7886" id="token-73-10" morph="none" pos="word" start_char="7883">2019</TOKEN>
<TOKEN end_char="7887" id="token-73-11" morph="none" pos="punct" start_char="7887">,</TOKEN>
<TOKEN end_char="7892" id="token-73-12" morph="none" pos="word" start_char="7889">also</TOKEN>
<TOKEN end_char="7899" id="token-73-13" morph="none" pos="word" start_char="7894">tested</TOKEN>
<TOKEN end_char="7908" id="token-73-14" morph="none" pos="word" start_char="7901">positive</TOKEN>
<TOKEN end_char="7912" id="token-73-15" morph="none" pos="word" start_char="7910">for</TOKEN>
<TOKEN end_char="7919" id="token-73-16" morph="none" pos="word" start_char="7914">traces</TOKEN>
<TOKEN end_char="7922" id="token-73-17" morph="none" pos="word" start_char="7921">of</TOKEN>
<TOKEN end_char="7926" id="token-73-18" morph="none" pos="word" start_char="7924">the</TOKEN>
<TOKEN end_char="7938" id="token-73-19" morph="none" pos="word" start_char="7928">coronavirus</TOKEN>
<TOKEN end_char="7939" id="token-73-20" morph="none" pos="punct" start_char="7939">.</TOKEN>
</SEG>
<SEG end_char="8048" id="segment-74" start_char="7941">
<ORIGINAL_TEXT>But testing wastewater isn't a perfect way to detect outbreaks, as Claire Crossan wrote in The Conversation.</ORIGINAL_TEXT>
<TOKEN end_char="7943" id="token-74-0" morph="none" pos="word" start_char="7941">But</TOKEN>
<TOKEN end_char="7951" id="token-74-1" morph="none" pos="word" start_char="7945">testing</TOKEN>
<TOKEN end_char="7962" id="token-74-2" morph="none" pos="word" start_char="7953">wastewater</TOKEN>
<TOKEN end_char="7968" id="token-74-3" morph="none" pos="word" start_char="7964">isn't</TOKEN>
<TOKEN end_char="7970" id="token-74-4" morph="none" pos="word" start_char="7970">a</TOKEN>
<TOKEN end_char="7978" id="token-74-5" morph="none" pos="word" start_char="7972">perfect</TOKEN>
<TOKEN end_char="7982" id="token-74-6" morph="none" pos="word" start_char="7980">way</TOKEN>
<TOKEN end_char="7985" id="token-74-7" morph="none" pos="word" start_char="7984">to</TOKEN>
<TOKEN end_char="7992" id="token-74-8" morph="none" pos="word" start_char="7987">detect</TOKEN>
<TOKEN end_char="8002" id="token-74-9" morph="none" pos="word" start_char="7994">outbreaks</TOKEN>
<TOKEN end_char="8003" id="token-74-10" morph="none" pos="punct" start_char="8003">,</TOKEN>
<TOKEN end_char="8006" id="token-74-11" morph="none" pos="word" start_char="8005">as</TOKEN>
<TOKEN end_char="8013" id="token-74-12" morph="none" pos="word" start_char="8008">Claire</TOKEN>
<TOKEN end_char="8021" id="token-74-13" morph="none" pos="word" start_char="8015">Crossan</TOKEN>
<TOKEN end_char="8027" id="token-74-14" morph="none" pos="word" start_char="8023">wrote</TOKEN>
<TOKEN end_char="8030" id="token-74-15" morph="none" pos="word" start_char="8029">in</TOKEN>
<TOKEN end_char="8034" id="token-74-16" morph="none" pos="word" start_char="8032">The</TOKEN>
<TOKEN end_char="8047" id="token-74-17" morph="none" pos="word" start_char="8036">Conversation</TOKEN>
<TOKEN end_char="8048" id="token-74-18" morph="none" pos="punct" start_char="8048">.</TOKEN>
</SEG>
<SEG end_char="8127" id="segment-75" start_char="8050">
<ORIGINAL_TEXT>So it's possible that the March sample had been contaminated during the study.</ORIGINAL_TEXT>
<TOKEN end_char="8051" id="token-75-0" morph="none" pos="word" start_char="8050">So</TOKEN>
<TOKEN end_char="8056" id="token-75-1" morph="none" pos="word" start_char="8053">it's</TOKEN>
<TOKEN end_char="8065" id="token-75-2" morph="none" pos="word" start_char="8058">possible</TOKEN>
<TOKEN end_char="8070" id="token-75-3" morph="none" pos="word" start_char="8067">that</TOKEN>
<TOKEN end_char="8074" id="token-75-4" morph="none" pos="word" start_char="8072">the</TOKEN>
<TOKEN end_char="8080" id="token-75-5" morph="none" pos="word" start_char="8076">March</TOKEN>
<TOKEN end_char="8087" id="token-75-6" morph="none" pos="word" start_char="8082">sample</TOKEN>
<TOKEN end_char="8091" id="token-75-7" morph="none" pos="word" start_char="8089">had</TOKEN>
<TOKEN end_char="8096" id="token-75-8" morph="none" pos="word" start_char="8093">been</TOKEN>
<TOKEN end_char="8109" id="token-75-9" morph="none" pos="word" start_char="8098">contaminated</TOKEN>
<TOKEN end_char="8116" id="token-75-10" morph="none" pos="word" start_char="8111">during</TOKEN>
<TOKEN end_char="8120" id="token-75-11" morph="none" pos="word" start_char="8118">the</TOKEN>
<TOKEN end_char="8126" id="token-75-12" morph="none" pos="word" start_char="8122">study</TOKEN>
<TOKEN end_char="8127" id="token-75-13" morph="none" pos="punct" start_char="8127">.</TOKEN>
</SEG>
<SEG end_char="8175" id="segment-76" start_char="8130">
<ORIGINAL_TEXT>By December 2019, the virus had reached the US</ORIGINAL_TEXT>
<TOKEN end_char="8131" id="token-76-0" morph="none" pos="word" start_char="8130">By</TOKEN>
<TOKEN end_char="8140" id="token-76-1" morph="none" pos="word" start_char="8133">December</TOKEN>
<TOKEN end_char="8145" id="token-76-2" morph="none" pos="word" start_char="8142">2019</TOKEN>
<TOKEN end_char="8146" id="token-76-3" morph="none" pos="punct" start_char="8146">,</TOKEN>
<TOKEN end_char="8150" id="token-76-4" morph="none" pos="word" start_char="8148">the</TOKEN>
<TOKEN end_char="8156" id="token-76-5" morph="none" pos="word" start_char="8152">virus</TOKEN>
<TOKEN end_char="8160" id="token-76-6" morph="none" pos="word" start_char="8158">had</TOKEN>
<TOKEN end_char="8168" id="token-76-7" morph="none" pos="word" start_char="8162">reached</TOKEN>
<TOKEN end_char="8172" id="token-76-8" morph="none" pos="word" start_char="8170">the</TOKEN>
<TOKEN end_char="8175" id="token-76-9" morph="none" pos="word" start_char="8174">US</TOKEN>
</SEG>
<SEG end_char="8251" id="segment-77" start_char="8180">
<ORIGINAL_TEXT>Few people wear masks on a pier in Oceanside, California, June 22, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="8182" id="token-77-0" morph="none" pos="word" start_char="8180">Few</TOKEN>
<TOKEN end_char="8189" id="token-77-1" morph="none" pos="word" start_char="8184">people</TOKEN>
<TOKEN end_char="8194" id="token-77-2" morph="none" pos="word" start_char="8191">wear</TOKEN>
<TOKEN end_char="8200" id="token-77-3" morph="none" pos="word" start_char="8196">masks</TOKEN>
<TOKEN end_char="8203" id="token-77-4" morph="none" pos="word" start_char="8202">on</TOKEN>
<TOKEN end_char="8205" id="token-77-5" morph="none" pos="word" start_char="8205">a</TOKEN>
<TOKEN end_char="8210" id="token-77-6" morph="none" pos="word" start_char="8207">pier</TOKEN>
<TOKEN end_char="8213" id="token-77-7" morph="none" pos="word" start_char="8212">in</TOKEN>
<TOKEN end_char="8223" id="token-77-8" morph="none" pos="word" start_char="8215">Oceanside</TOKEN>
<TOKEN end_char="8224" id="token-77-9" morph="none" pos="punct" start_char="8224">,</TOKEN>
<TOKEN end_char="8235" id="token-77-10" morph="none" pos="word" start_char="8226">California</TOKEN>
<TOKEN end_char="8236" id="token-77-11" morph="none" pos="punct" start_char="8236">,</TOKEN>
<TOKEN end_char="8241" id="token-77-12" morph="none" pos="word" start_char="8238">June</TOKEN>
<TOKEN end_char="8244" id="token-77-13" morph="none" pos="word" start_char="8243">22</TOKEN>
<TOKEN end_char="8245" id="token-77-14" morph="none" pos="punct" start_char="8245">,</TOKEN>
<TOKEN end_char="8250" id="token-77-15" morph="none" pos="word" start_char="8247">2020</TOKEN>
<TOKEN end_char="8251" id="token-77-16" morph="none" pos="punct" start_char="8251">.</TOKEN>
</SEG>
<SEG end_char="8271" id="segment-78" start_char="8254">
<ORIGINAL_TEXT>Mike Blake/Reuters</ORIGINAL_TEXT>
<TOKEN end_char="8257" id="token-78-0" morph="none" pos="word" start_char="8254">Mike</TOKEN>
<TOKEN end_char="8271" id="token-78-1" morph="none" pos="unknown" start_char="8259">Blake/Reuters</TOKEN>
<TRANSLATED_TEXT>Mike Blake / Reuters</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="8383" id="segment-79" start_char="8275">
<ORIGINAL_TEXT>Research in the US, too, offers evidence that the virus had gone global before humanity even knew it existed.</ORIGINAL_TEXT>
<TOKEN end_char="8282" id="token-79-0" morph="none" pos="word" start_char="8275">Research</TOKEN>
<TOKEN end_char="8285" id="token-79-1" morph="none" pos="word" start_char="8284">in</TOKEN>
<TOKEN end_char="8289" id="token-79-2" morph="none" pos="word" start_char="8287">the</TOKEN>
<TOKEN end_char="8292" id="token-79-3" morph="none" pos="word" start_char="8291">US</TOKEN>
<TOKEN end_char="8293" id="token-79-4" morph="none" pos="punct" start_char="8293">,</TOKEN>
<TOKEN end_char="8297" id="token-79-5" morph="none" pos="word" start_char="8295">too</TOKEN>
<TOKEN end_char="8298" id="token-79-6" morph="none" pos="punct" start_char="8298">,</TOKEN>
<TOKEN end_char="8305" id="token-79-7" morph="none" pos="word" start_char="8300">offers</TOKEN>
<TOKEN end_char="8314" id="token-79-8" morph="none" pos="word" start_char="8307">evidence</TOKEN>
<TOKEN end_char="8319" id="token-79-9" morph="none" pos="word" start_char="8316">that</TOKEN>
<TOKEN end_char="8323" id="token-79-10" morph="none" pos="word" start_char="8321">the</TOKEN>
<TOKEN end_char="8329" id="token-79-11" morph="none" pos="word" start_char="8325">virus</TOKEN>
<TOKEN end_char="8333" id="token-79-12" morph="none" pos="word" start_char="8331">had</TOKEN>
<TOKEN end_char="8338" id="token-79-13" morph="none" pos="word" start_char="8335">gone</TOKEN>
<TOKEN end_char="8345" id="token-79-14" morph="none" pos="word" start_char="8340">global</TOKEN>
<TOKEN end_char="8352" id="token-79-15" morph="none" pos="word" start_char="8347">before</TOKEN>
<TOKEN end_char="8361" id="token-79-16" morph="none" pos="word" start_char="8354">humanity</TOKEN>
<TOKEN end_char="8366" id="token-79-17" morph="none" pos="word" start_char="8363">even</TOKEN>
<TOKEN end_char="8371" id="token-79-18" morph="none" pos="word" start_char="8368">knew</TOKEN>
<TOKEN end_char="8374" id="token-79-19" morph="none" pos="word" start_char="8373">it</TOKEN>
<TOKEN end_char="8382" id="token-79-20" morph="none" pos="word" start_char="8376">existed</TOKEN>
<TOKEN end_char="8383" id="token-79-21" morph="none" pos="punct" start_char="8383">.</TOKEN>
</SEG>
<SEG end_char="8448" id="segment-80" start_char="8386">
<ORIGINAL_TEXT>The US recorded its first coronavirus case on January 20, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="8388" id="token-80-0" morph="none" pos="word" start_char="8386">The</TOKEN>
<TOKEN end_char="8391" id="token-80-1" morph="none" pos="word" start_char="8390">US</TOKEN>
<TOKEN end_char="8400" id="token-80-2" morph="none" pos="word" start_char="8393">recorded</TOKEN>
<TOKEN end_char="8404" id="token-80-3" morph="none" pos="word" start_char="8402">its</TOKEN>
<TOKEN end_char="8410" id="token-80-4" morph="none" pos="word" start_char="8406">first</TOKEN>
<TOKEN end_char="8422" id="token-80-5" morph="none" pos="word" start_char="8412">coronavirus</TOKEN>
<TOKEN end_char="8427" id="token-80-6" morph="none" pos="word" start_char="8424">case</TOKEN>
<TOKEN end_char="8430" id="token-80-7" morph="none" pos="word" start_char="8429">on</TOKEN>
<TOKEN end_char="8438" id="token-80-8" morph="none" pos="word" start_char="8432">January</TOKEN>
<TOKEN end_char="8441" id="token-80-9" morph="none" pos="word" start_char="8440">20</TOKEN>
<TOKEN end_char="8442" id="token-80-10" morph="none" pos="punct" start_char="8442">,</TOKEN>
<TOKEN end_char="8447" id="token-80-11" morph="none" pos="word" start_char="8444">2020</TOKEN>
<TOKEN end_char="8448" id="token-80-12" morph="none" pos="punct" start_char="8448">.</TOKEN>
</SEG>
<SEG end_char="8546" id="segment-81" start_char="8450">
<ORIGINAL_TEXT>But according to one study, the virus had reached the Pacific Northwest at least a month earlier.</ORIGINAL_TEXT>
<TOKEN end_char="8452" id="token-81-0" morph="none" pos="word" start_char="8450">But</TOKEN>
<TOKEN end_char="8462" id="token-81-1" morph="none" pos="word" start_char="8454">according</TOKEN>
<TOKEN end_char="8465" id="token-81-2" morph="none" pos="word" start_char="8464">to</TOKEN>
<TOKEN end_char="8469" id="token-81-3" morph="none" pos="word" start_char="8467">one</TOKEN>
<TOKEN end_char="8475" id="token-81-4" morph="none" pos="word" start_char="8471">study</TOKEN>
<TOKEN end_char="8476" id="token-81-5" morph="none" pos="punct" start_char="8476">,</TOKEN>
<TOKEN end_char="8480" id="token-81-6" morph="none" pos="word" start_char="8478">the</TOKEN>
<TOKEN end_char="8486" id="token-81-7" morph="none" pos="word" start_char="8482">virus</TOKEN>
<TOKEN end_char="8490" id="token-81-8" morph="none" pos="word" start_char="8488">had</TOKEN>
<TOKEN end_char="8498" id="token-81-9" morph="none" pos="word" start_char="8492">reached</TOKEN>
<TOKEN end_char="8502" id="token-81-10" morph="none" pos="word" start_char="8500">the</TOKEN>
<TOKEN end_char="8510" id="token-81-11" morph="none" pos="word" start_char="8504">Pacific</TOKEN>
<TOKEN end_char="8520" id="token-81-12" morph="none" pos="word" start_char="8512">Northwest</TOKEN>
<TOKEN end_char="8523" id="token-81-13" morph="none" pos="word" start_char="8522">at</TOKEN>
<TOKEN end_char="8529" id="token-81-14" morph="none" pos="word" start_char="8525">least</TOKEN>
<TOKEN end_char="8531" id="token-81-15" morph="none" pos="word" start_char="8531">a</TOKEN>
<TOKEN end_char="8537" id="token-81-16" morph="none" pos="word" start_char="8533">month</TOKEN>
<TOKEN end_char="8545" id="token-81-17" morph="none" pos="word" start_char="8539">earlier</TOKEN>
<TOKEN end_char="8546" id="token-81-18" morph="none" pos="punct" start_char="8546">.</TOKEN>
</SEG>
<SEG end_char="8743" id="segment-82" start_char="8548">
<ORIGINAL_TEXT>Blood samples collected by the American Red Cross in nine states, including California, Oregon, and Washington, showed that some Americans had coronavirus antibodies as early as December 13, 2019.</ORIGINAL_TEXT>
<TOKEN end_char="8552" id="token-82-0" morph="none" pos="word" start_char="8548">Blood</TOKEN>
<TOKEN end_char="8560" id="token-82-1" morph="none" pos="word" start_char="8554">samples</TOKEN>
<TOKEN end_char="8570" id="token-82-2" morph="none" pos="word" start_char="8562">collected</TOKEN>
<TOKEN end_char="8573" id="token-82-3" morph="none" pos="word" start_char="8572">by</TOKEN>
<TOKEN end_char="8577" id="token-82-4" morph="none" pos="word" start_char="8575">the</TOKEN>
<TOKEN end_char="8586" id="token-82-5" morph="none" pos="word" start_char="8579">American</TOKEN>
<TOKEN end_char="8590" id="token-82-6" morph="none" pos="word" start_char="8588">Red</TOKEN>
<TOKEN end_char="8596" id="token-82-7" morph="none" pos="word" start_char="8592">Cross</TOKEN>
<TOKEN end_char="8599" id="token-82-8" morph="none" pos="word" start_char="8598">in</TOKEN>
<TOKEN end_char="8604" id="token-82-9" morph="none" pos="word" start_char="8601">nine</TOKEN>
<TOKEN end_char="8611" id="token-82-10" morph="none" pos="word" start_char="8606">states</TOKEN>
<TOKEN end_char="8612" id="token-82-11" morph="none" pos="punct" start_char="8612">,</TOKEN>
<TOKEN end_char="8622" id="token-82-12" morph="none" pos="word" start_char="8614">including</TOKEN>
<TOKEN end_char="8633" id="token-82-13" morph="none" pos="word" start_char="8624">California</TOKEN>
<TOKEN end_char="8634" id="token-82-14" morph="none" pos="punct" start_char="8634">,</TOKEN>
<TOKEN end_char="8641" id="token-82-15" morph="none" pos="word" start_char="8636">Oregon</TOKEN>
<TOKEN end_char="8642" id="token-82-16" morph="none" pos="punct" start_char="8642">,</TOKEN>
<TOKEN end_char="8646" id="token-82-17" morph="none" pos="word" start_char="8644">and</TOKEN>
<TOKEN end_char="8657" id="token-82-18" morph="none" pos="word" start_char="8648">Washington</TOKEN>
<TOKEN end_char="8658" id="token-82-19" morph="none" pos="punct" start_char="8658">,</TOKEN>
<TOKEN end_char="8665" id="token-82-20" morph="none" pos="word" start_char="8660">showed</TOKEN>
<TOKEN end_char="8670" id="token-82-21" morph="none" pos="word" start_char="8667">that</TOKEN>
<TOKEN end_char="8675" id="token-82-22" morph="none" pos="word" start_char="8672">some</TOKEN>
<TOKEN end_char="8685" id="token-82-23" morph="none" pos="word" start_char="8677">Americans</TOKEN>
<TOKEN end_char="8689" id="token-82-24" morph="none" pos="word" start_char="8687">had</TOKEN>
<TOKEN end_char="8701" id="token-82-25" morph="none" pos="word" start_char="8691">coronavirus</TOKEN>
<TOKEN end_char="8712" id="token-82-26" morph="none" pos="word" start_char="8703">antibodies</TOKEN>
<TOKEN end_char="8715" id="token-82-27" morph="none" pos="word" start_char="8714">as</TOKEN>
<TOKEN end_char="8721" id="token-82-28" morph="none" pos="word" start_char="8717">early</TOKEN>
<TOKEN end_char="8724" id="token-82-29" morph="none" pos="word" start_char="8723">as</TOKEN>
<TOKEN end_char="8733" id="token-82-30" morph="none" pos="word" start_char="8726">December</TOKEN>
<TOKEN end_char="8736" id="token-82-31" morph="none" pos="word" start_char="8735">13</TOKEN>
<TOKEN end_char="8737" id="token-82-32" morph="none" pos="punct" start_char="8737">,</TOKEN>
<TOKEN end_char="8742" id="token-82-33" morph="none" pos="word" start_char="8739">2019</TOKEN>
<TOKEN end_char="8743" id="token-82-34" morph="none" pos="punct" start_char="8743">.</TOKEN>
</SEG>
<SEG end_char="8840" id="segment-83" start_char="8747">
<ORIGINAL_TEXT>A young resident of Detroit, Michigan, is tested for coronavirus antibodies on April 28, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="8747" id="token-83-0" morph="none" pos="word" start_char="8747">A</TOKEN>
<TOKEN end_char="8753" id="token-83-1" morph="none" pos="word" start_char="8749">young</TOKEN>
<TOKEN end_char="8762" id="token-83-2" morph="none" pos="word" start_char="8755">resident</TOKEN>
<TOKEN end_char="8765" id="token-83-3" morph="none" pos="word" start_char="8764">of</TOKEN>
<TOKEN end_char="8773" id="token-83-4" morph="none" pos="word" start_char="8767">Detroit</TOKEN>
<TOKEN end_char="8774" id="token-83-5" morph="none" pos="punct" start_char="8774">,</TOKEN>
<TOKEN end_char="8783" id="token-83-6" morph="none" pos="word" start_char="8776">Michigan</TOKEN>
<TOKEN end_char="8784" id="token-83-7" morph="none" pos="punct" start_char="8784">,</TOKEN>
<TOKEN end_char="8787" id="token-83-8" morph="none" pos="word" start_char="8786">is</TOKEN>
<TOKEN end_char="8794" id="token-83-9" morph="none" pos="word" start_char="8789">tested</TOKEN>
<TOKEN end_char="8798" id="token-83-10" morph="none" pos="word" start_char="8796">for</TOKEN>
<TOKEN end_char="8810" id="token-83-11" morph="none" pos="word" start_char="8800">coronavirus</TOKEN>
<TOKEN end_char="8821" id="token-83-12" morph="none" pos="word" start_char="8812">antibodies</TOKEN>
<TOKEN end_char="8824" id="token-83-13" morph="none" pos="word" start_char="8823">on</TOKEN>
<TOKEN end_char="8830" id="token-83-14" morph="none" pos="word" start_char="8826">April</TOKEN>
<TOKEN end_char="8833" id="token-83-15" morph="none" pos="word" start_char="8832">28</TOKEN>
<TOKEN end_char="8834" id="token-83-16" morph="none" pos="punct" start_char="8834">,</TOKEN>
<TOKEN end_char="8839" id="token-83-17" morph="none" pos="word" start_char="8836">2020</TOKEN>
<TOKEN end_char="8840" id="token-83-18" morph="none" pos="punct" start_char="8840">.</TOKEN>
</SEG>
<SEG end_char="8862" id="segment-84" start_char="8843">
<ORIGINAL_TEXT>REUTERS/Rebecca Cook</ORIGINAL_TEXT>
<TOKEN end_char="8857" id="token-84-0" morph="none" pos="unknown" start_char="8843">REUTERS/Rebecca</TOKEN>
<TOKEN end_char="8862" id="token-84-1" morph="none" pos="word" start_char="8859">Cook</TOKEN>
</SEG>
<SEG end_char="9055" id="segment-85" start_char="8866">
<ORIGINAL_TEXT>Antibodies are an imperfect measure of the outbreak since some research suggests our immune systems can create antibodies that recognize the new coronavirus in response to some common colds.</ORIGINAL_TEXT>
<TOKEN end_char="8875" id="token-85-0" morph="none" pos="word" start_char="8866">Antibodies</TOKEN>
<TOKEN end_char="8879" id="token-85-1" morph="none" pos="word" start_char="8877">are</TOKEN>
<TOKEN end_char="8882" id="token-85-2" morph="none" pos="word" start_char="8881">an</TOKEN>
<TOKEN end_char="8892" id="token-85-3" morph="none" pos="word" start_char="8884">imperfect</TOKEN>
<TOKEN end_char="8900" id="token-85-4" morph="none" pos="word" start_char="8894">measure</TOKEN>
<TOKEN end_char="8903" id="token-85-5" morph="none" pos="word" start_char="8902">of</TOKEN>
<TOKEN end_char="8907" id="token-85-6" morph="none" pos="word" start_char="8905">the</TOKEN>
<TOKEN end_char="8916" id="token-85-7" morph="none" pos="word" start_char="8909">outbreak</TOKEN>
<TOKEN end_char="8922" id="token-85-8" morph="none" pos="word" start_char="8918">since</TOKEN>
<TOKEN end_char="8927" id="token-85-9" morph="none" pos="word" start_char="8924">some</TOKEN>
<TOKEN end_char="8936" id="token-85-10" morph="none" pos="word" start_char="8929">research</TOKEN>
<TOKEN end_char="8945" id="token-85-11" morph="none" pos="word" start_char="8938">suggests</TOKEN>
<TOKEN end_char="8949" id="token-85-12" morph="none" pos="word" start_char="8947">our</TOKEN>
<TOKEN end_char="8956" id="token-85-13" morph="none" pos="word" start_char="8951">immune</TOKEN>
<TOKEN end_char="8964" id="token-85-14" morph="none" pos="word" start_char="8958">systems</TOKEN>
<TOKEN end_char="8968" id="token-85-15" morph="none" pos="word" start_char="8966">can</TOKEN>
<TOKEN end_char="8975" id="token-85-16" morph="none" pos="word" start_char="8970">create</TOKEN>
<TOKEN end_char="8986" id="token-85-17" morph="none" pos="word" start_char="8977">antibodies</TOKEN>
<TOKEN end_char="8991" id="token-85-18" morph="none" pos="word" start_char="8988">that</TOKEN>
<TOKEN end_char="9001" id="token-85-19" morph="none" pos="word" start_char="8993">recognize</TOKEN>
<TOKEN end_char="9005" id="token-85-20" morph="none" pos="word" start_char="9003">the</TOKEN>
<TOKEN end_char="9009" id="token-85-21" morph="none" pos="word" start_char="9007">new</TOKEN>
<TOKEN end_char="9021" id="token-85-22" morph="none" pos="word" start_char="9011">coronavirus</TOKEN>
<TOKEN end_char="9024" id="token-85-23" morph="none" pos="word" start_char="9023">in</TOKEN>
<TOKEN end_char="9033" id="token-85-24" morph="none" pos="word" start_char="9026">response</TOKEN>
<TOKEN end_char="9036" id="token-85-25" morph="none" pos="word" start_char="9035">to</TOKEN>
<TOKEN end_char="9041" id="token-85-26" morph="none" pos="word" start_char="9038">some</TOKEN>
<TOKEN end_char="9048" id="token-85-27" morph="none" pos="word" start_char="9043">common</TOKEN>
<TOKEN end_char="9054" id="token-85-28" morph="none" pos="word" start_char="9050">colds</TOKEN>
<TOKEN end_char="9055" id="token-85-29" morph="none" pos="punct" start_char="9055">.</TOKEN>
</SEG>
<SEG end_char="9102" id="segment-86" start_char="9057">
<ORIGINAL_TEXT>Antibody tests can also yield false positives.</ORIGINAL_TEXT>
<TOKEN end_char="9064" id="token-86-0" morph="none" pos="word" start_char="9057">Antibody</TOKEN>
<TOKEN end_char="9070" id="token-86-1" morph="none" pos="word" start_char="9066">tests</TOKEN>
<TOKEN end_char="9074" id="token-86-2" morph="none" pos="word" start_char="9072">can</TOKEN>
<TOKEN end_char="9079" id="token-86-3" morph="none" pos="word" start_char="9076">also</TOKEN>
<TOKEN end_char="9085" id="token-86-4" morph="none" pos="word" start_char="9081">yield</TOKEN>
<TOKEN end_char="9091" id="token-86-5" morph="none" pos="word" start_char="9087">false</TOKEN>
<TOKEN end_char="9101" id="token-86-6" morph="none" pos="word" start_char="9093">positives</TOKEN>
<TOKEN end_char="9102" id="token-86-7" morph="none" pos="punct" start_char="9102">.</TOKEN>
</SEG>
<SEG end_char="9275" id="segment-87" start_char="9105">
<ORIGINAL_TEXT>Yet in the past, scientists successfully used retrospective antibody studies to trace the origins of SARS and Middle East respiratory syndrome (MERS) — both coronaviruses.</ORIGINAL_TEXT>
<TOKEN end_char="9107" id="token-87-0" morph="none" pos="word" start_char="9105">Yet</TOKEN>
<TOKEN end_char="9110" id="token-87-1" morph="none" pos="word" start_char="9109">in</TOKEN>
<TOKEN end_char="9114" id="token-87-2" morph="none" pos="word" start_char="9112">the</TOKEN>
<TOKEN end_char="9119" id="token-87-3" morph="none" pos="word" start_char="9116">past</TOKEN>
<TOKEN end_char="9120" id="token-87-4" morph="none" pos="punct" start_char="9120">,</TOKEN>
<TOKEN end_char="9131" id="token-87-5" morph="none" pos="word" start_char="9122">scientists</TOKEN>
<TOKEN end_char="9144" id="token-87-6" morph="none" pos="word" start_char="9133">successfully</TOKEN>
<TOKEN end_char="9149" id="token-87-7" morph="none" pos="word" start_char="9146">used</TOKEN>
<TOKEN end_char="9163" id="token-87-8" morph="none" pos="word" start_char="9151">retrospective</TOKEN>
<TOKEN end_char="9172" id="token-87-9" morph="none" pos="word" start_char="9165">antibody</TOKEN>
<TOKEN end_char="9180" id="token-87-10" morph="none" pos="word" start_char="9174">studies</TOKEN>
<TOKEN end_char="9183" id="token-87-11" morph="none" pos="word" start_char="9182">to</TOKEN>
<TOKEN end_char="9189" id="token-87-12" morph="none" pos="word" start_char="9185">trace</TOKEN>
<TOKEN end_char="9193" id="token-87-13" morph="none" pos="word" start_char="9191">the</TOKEN>
<TOKEN end_char="9201" id="token-87-14" morph="none" pos="word" start_char="9195">origins</TOKEN>
<TOKEN end_char="9204" id="token-87-15" morph="none" pos="word" start_char="9203">of</TOKEN>
<TOKEN end_char="9209" id="token-87-16" morph="none" pos="word" start_char="9206">SARS</TOKEN>
<TOKEN end_char="9213" id="token-87-17" morph="none" pos="word" start_char="9211">and</TOKEN>
<TOKEN end_char="9220" id="token-87-18" morph="none" pos="word" start_char="9215">Middle</TOKEN>
<TOKEN end_char="9225" id="token-87-19" morph="none" pos="word" start_char="9222">East</TOKEN>
<TOKEN end_char="9237" id="token-87-20" morph="none" pos="word" start_char="9227">respiratory</TOKEN>
<TOKEN end_char="9246" id="token-87-21" morph="none" pos="word" start_char="9239">syndrome</TOKEN>
<TOKEN end_char="9248" id="token-87-22" morph="none" pos="punct" start_char="9248">(</TOKEN>
<TOKEN end_char="9252" id="token-87-23" morph="none" pos="word" start_char="9249">MERS</TOKEN>
<TOKEN end_char="9253" id="token-87-24" morph="none" pos="punct" start_char="9253">)</TOKEN>
<TOKEN end_char="9255" id="token-87-25" morph="none" pos="punct" start_char="9255">—</TOKEN>
<TOKEN end_char="9260" id="token-87-26" morph="none" pos="word" start_char="9257">both</TOKEN>
<TOKEN end_char="9274" id="token-87-27" morph="none" pos="word" start_char="9262">coronaviruses</TOKEN>
<TOKEN end_char="9275" id="token-87-28" morph="none" pos="punct" start_char="9275">.</TOKEN>
</SEG>
<SEG end_char="9451" id="segment-88" start_char="9277">
<ORIGINAL_TEXT>Virologists found antibodies specific to SARS in civet cats, and antibodies specific to MERS in camels, which is how they determined those to be each virus' animal progenitor.</ORIGINAL_TEXT>
<TOKEN end_char="9287" id="token-88-0" morph="none" pos="word" start_char="9277">Virologists</TOKEN>
<TOKEN end_char="9293" id="token-88-1" morph="none" pos="word" start_char="9289">found</TOKEN>
<TOKEN end_char="9304" id="token-88-2" morph="none" pos="word" start_char="9295">antibodies</TOKEN>
<TOKEN end_char="9313" id="token-88-3" morph="none" pos="word" start_char="9306">specific</TOKEN>
<TOKEN end_char="9316" id="token-88-4" morph="none" pos="word" start_char="9315">to</TOKEN>
<TOKEN end_char="9321" id="token-88-5" morph="none" pos="word" start_char="9318">SARS</TOKEN>
<TOKEN end_char="9324" id="token-88-6" morph="none" pos="word" start_char="9323">in</TOKEN>
<TOKEN end_char="9330" id="token-88-7" morph="none" pos="word" start_char="9326">civet</TOKEN>
<TOKEN end_char="9335" id="token-88-8" morph="none" pos="word" start_char="9332">cats</TOKEN>
<TOKEN end_char="9336" id="token-88-9" morph="none" pos="punct" start_char="9336">,</TOKEN>
<TOKEN end_char="9340" id="token-88-10" morph="none" pos="word" start_char="9338">and</TOKEN>
<TOKEN end_char="9351" id="token-88-11" morph="none" pos="word" start_char="9342">antibodies</TOKEN>
<TOKEN end_char="9360" id="token-88-12" morph="none" pos="word" start_char="9353">specific</TOKEN>
<TOKEN end_char="9363" id="token-88-13" morph="none" pos="word" start_char="9362">to</TOKEN>
<TOKEN end_char="9368" id="token-88-14" morph="none" pos="word" start_char="9365">MERS</TOKEN>
<TOKEN end_char="9371" id="token-88-15" morph="none" pos="word" start_char="9370">in</TOKEN>
<TOKEN end_char="9378" id="token-88-16" morph="none" pos="word" start_char="9373">camels</TOKEN>
<TOKEN end_char="9379" id="token-88-17" morph="none" pos="punct" start_char="9379">,</TOKEN>
<TOKEN end_char="9385" id="token-88-18" morph="none" pos="word" start_char="9381">which</TOKEN>
<TOKEN end_char="9388" id="token-88-19" morph="none" pos="word" start_char="9387">is</TOKEN>
<TOKEN end_char="9392" id="token-88-20" morph="none" pos="word" start_char="9390">how</TOKEN>
<TOKEN end_char="9397" id="token-88-21" morph="none" pos="word" start_char="9394">they</TOKEN>
<TOKEN end_char="9408" id="token-88-22" morph="none" pos="word" start_char="9399">determined</TOKEN>
<TOKEN end_char="9414" id="token-88-23" morph="none" pos="word" start_char="9410">those</TOKEN>
<TOKEN end_char="9417" id="token-88-24" morph="none" pos="word" start_char="9416">to</TOKEN>
<TOKEN end_char="9420" id="token-88-25" morph="none" pos="word" start_char="9419">be</TOKEN>
<TOKEN end_char="9425" id="token-88-26" morph="none" pos="word" start_char="9422">each</TOKEN>
<TOKEN end_char="9431" id="token-88-27" morph="none" pos="word" start_char="9427">virus</TOKEN>
<TOKEN end_char="9432" id="token-88-28" morph="none" pos="punct" start_char="9432">'</TOKEN>
<TOKEN end_char="9439" id="token-88-29" morph="none" pos="word" start_char="9434">animal</TOKEN>
<TOKEN end_char="9450" id="token-88-30" morph="none" pos="word" start_char="9441">progenitor</TOKEN>
<TOKEN end_char="9451" id="token-88-31" morph="none" pos="punct" start_char="9451">.</TOKEN>
</SEG>
<SEG end_char="9570" id="segment-89" start_char="9454">
<ORIGINAL_TEXT>Further examination of blood samples taken in 2019 could be the best way to find out when this pandemic really began.</ORIGINAL_TEXT>
<TOKEN end_char="9460" id="token-89-0" morph="none" pos="word" start_char="9454">Further</TOKEN>
<TOKEN end_char="9472" id="token-89-1" morph="none" pos="word" start_char="9462">examination</TOKEN>
<TOKEN end_char="9475" id="token-89-2" morph="none" pos="word" start_char="9474">of</TOKEN>
<TOKEN end_char="9481" id="token-89-3" morph="none" pos="word" start_char="9477">blood</TOKEN>
<TOKEN end_char="9489" id="token-89-4" morph="none" pos="word" start_char="9483">samples</TOKEN>
<TOKEN end_char="9495" id="token-89-5" morph="none" pos="word" start_char="9491">taken</TOKEN>
<TOKEN end_char="9498" id="token-89-6" morph="none" pos="word" start_char="9497">in</TOKEN>
<TOKEN end_char="9503" id="token-89-7" morph="none" pos="word" start_char="9500">2019</TOKEN>
<TOKEN end_char="9509" id="token-89-8" morph="none" pos="word" start_char="9505">could</TOKEN>
<TOKEN end_char="9512" id="token-89-9" morph="none" pos="word" start_char="9511">be</TOKEN>
<TOKEN end_char="9516" id="token-89-10" morph="none" pos="word" start_char="9514">the</TOKEN>
<TOKEN end_char="9521" id="token-89-11" morph="none" pos="word" start_char="9518">best</TOKEN>
<TOKEN end_char="9525" id="token-89-12" morph="none" pos="word" start_char="9523">way</TOKEN>
<TOKEN end_char="9528" id="token-89-13" morph="none" pos="word" start_char="9527">to</TOKEN>
<TOKEN end_char="9533" id="token-89-14" morph="none" pos="word" start_char="9530">find</TOKEN>
<TOKEN end_char="9537" id="token-89-15" morph="none" pos="word" start_char="9535">out</TOKEN>
<TOKEN end_char="9542" id="token-89-16" morph="none" pos="word" start_char="9539">when</TOKEN>
<TOKEN end_char="9547" id="token-89-17" morph="none" pos="word" start_char="9544">this</TOKEN>
<TOKEN end_char="9556" id="token-89-18" morph="none" pos="word" start_char="9549">pandemic</TOKEN>
<TOKEN end_char="9563" id="token-89-19" morph="none" pos="word" start_char="9558">really</TOKEN>
<TOKEN end_char="9569" id="token-89-20" morph="none" pos="word" start_char="9565">began</TOKEN>
<TOKEN end_char="9570" id="token-89-21" morph="none" pos="punct" start_char="9570">.</TOKEN>
</SEG>
<SEG end_char="9593" id="segment-90" start_char="9573">
<ORIGINAL_TEXT>Something is loading.</ORIGINAL_TEXT>
<TOKEN end_char="9581" id="token-90-0" morph="none" pos="word" start_char="9573">Something</TOKEN>
<TOKEN end_char="9584" id="token-90-1" morph="none" pos="word" start_char="9583">is</TOKEN>
<TOKEN end_char="9592" id="token-90-2" morph="none" pos="word" start_char="9586">loading</TOKEN>
<TOKEN end_char="9593" id="token-90-3" morph="none" pos="punct" start_char="9593">.</TOKEN>
</SEG>
<SEG end_char="9630" id="segment-91" start_char="9596">
<ORIGINAL_TEXT>Two crossed lines that form an 'X'.</ORIGINAL_TEXT>
<TOKEN end_char="9598" id="token-91-0" morph="none" pos="word" start_char="9596">Two</TOKEN>
<TOKEN end_char="9606" id="token-91-1" morph="none" pos="word" start_char="9600">crossed</TOKEN>
<TOKEN end_char="9612" id="token-91-2" morph="none" pos="word" start_char="9608">lines</TOKEN>
<TOKEN end_char="9617" id="token-91-3" morph="none" pos="word" start_char="9614">that</TOKEN>
<TOKEN end_char="9622" id="token-91-4" morph="none" pos="word" start_char="9619">form</TOKEN>
<TOKEN end_char="9625" id="token-91-5" morph="none" pos="word" start_char="9624">an</TOKEN>
<TOKEN end_char="9627" id="token-91-6" morph="none" pos="punct" start_char="9627">'</TOKEN>
<TOKEN end_char="9628" id="token-91-7" morph="none" pos="word" start_char="9628">X</TOKEN>
<TOKEN end_char="9630" id="token-91-8" morph="none" pos="punct" start_char="9629">'.</TOKEN>
</SEG>
<SEG end_char="9701" id="segment-92" start_char="9632">
<ORIGINAL_TEXT>It indicates a way to close an interaction, or dismiss a notification.</ORIGINAL_TEXT>
<TOKEN end_char="9633" id="token-92-0" morph="none" pos="word" start_char="9632">It</TOKEN>
<TOKEN end_char="9643" id="token-92-1" morph="none" pos="word" start_char="9635">indicates</TOKEN>
<TOKEN end_char="9645" id="token-92-2" morph="none" pos="word" start_char="9645">a</TOKEN>
<TOKEN end_char="9649" id="token-92-3" morph="none" pos="word" start_char="9647">way</TOKEN>
<TOKEN end_char="9652" id="token-92-4" morph="none" pos="word" start_char="9651">to</TOKEN>
<TOKEN end_char="9658" id="token-92-5" morph="none" pos="word" start_char="9654">close</TOKEN>
<TOKEN end_char="9661" id="token-92-6" morph="none" pos="word" start_char="9660">an</TOKEN>
<TOKEN end_char="9673" id="token-92-7" morph="none" pos="word" start_char="9663">interaction</TOKEN>
<TOKEN end_char="9674" id="token-92-8" morph="none" pos="punct" start_char="9674">,</TOKEN>
<TOKEN end_char="9677" id="token-92-9" morph="none" pos="word" start_char="9676">or</TOKEN>
<TOKEN end_char="9685" id="token-92-10" morph="none" pos="word" start_char="9679">dismiss</TOKEN>
<TOKEN end_char="9687" id="token-92-11" morph="none" pos="word" start_char="9687">a</TOKEN>
<TOKEN end_char="9700" id="token-92-12" morph="none" pos="word" start_char="9689">notification</TOKEN>
<TOKEN end_char="9701" id="token-92-13" morph="none" pos="punct" start_char="9701">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
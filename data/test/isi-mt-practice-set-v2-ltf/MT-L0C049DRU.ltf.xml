<LCTL_TEXT lang="eng">
<DOC grammar="none" id="L0C049DRU" lang="eng" raw_text_char_length="2831" raw_text_md5="327f4af48dba96817fb06df91cc1f90f" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="94" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Claims That the Obama Administration Gave $3.7 Million To Research Institute In China Is False</ORIGINAL_TEXT>
<TOKEN end_char="6" id="token-0-0" morph="none" pos="word" start_char="1">Claims</TOKEN>
<TOKEN end_char="11" id="token-0-1" morph="none" pos="word" start_char="8">That</TOKEN>
<TOKEN end_char="15" id="token-0-2" morph="none" pos="word" start_char="13">the</TOKEN>
<TOKEN end_char="21" id="token-0-3" morph="none" pos="word" start_char="17">Obama</TOKEN>
<TOKEN end_char="36" id="token-0-4" morph="none" pos="word" start_char="23">Administration</TOKEN>
<TOKEN end_char="41" id="token-0-5" morph="none" pos="word" start_char="38">Gave</TOKEN>
<TOKEN end_char="46" id="token-0-6" morph="none" pos="unknown" start_char="43">$3.7</TOKEN>
<TOKEN end_char="54" id="token-0-7" morph="none" pos="word" start_char="48">Million</TOKEN>
<TOKEN end_char="57" id="token-0-8" morph="none" pos="word" start_char="56">To</TOKEN>
<TOKEN end_char="66" id="token-0-9" morph="none" pos="word" start_char="59">Research</TOKEN>
<TOKEN end_char="76" id="token-0-10" morph="none" pos="word" start_char="68">Institute</TOKEN>
<TOKEN end_char="79" id="token-0-11" morph="none" pos="word" start_char="78">In</TOKEN>
<TOKEN end_char="85" id="token-0-12" morph="none" pos="word" start_char="81">China</TOKEN>
<TOKEN end_char="88" id="token-0-13" morph="none" pos="word" start_char="87">Is</TOKEN>
<TOKEN end_char="94" id="token-0-14" morph="none" pos="word" start_char="90">False</TOKEN>
</SEG>
<SEG end_char="119" id="segment-1" start_char="98">
<ORIGINAL_TEXT>(Flickr/Gage Skidmore)</ORIGINAL_TEXT>
<TOKEN end_char="98" id="token-1-0" morph="none" pos="punct" start_char="98">(</TOKEN>
<TOKEN end_char="109" id="token-1-1" morph="none" pos="unknown" start_char="99">Flickr/Gage</TOKEN>
<TOKEN end_char="118" id="token-1-2" morph="none" pos="word" start_char="111">Skidmore</TOKEN>
<TOKEN end_char="119" id="token-1-3" morph="none" pos="punct" start_char="119">)</TOKEN>
<TRANSLATED_TEXT>(Flickr / Gage Skidmore)</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="279" id="segment-2" start_char="123">
<ORIGINAL_TEXT>A claim that the Obama administration gave almost $4 million to a Wuhan research facility has gained traction online, however, the actual story is different.</ORIGINAL_TEXT>
<TOKEN end_char="123" id="token-2-0" morph="none" pos="word" start_char="123">A</TOKEN>
<TOKEN end_char="129" id="token-2-1" morph="none" pos="word" start_char="125">claim</TOKEN>
<TOKEN end_char="134" id="token-2-2" morph="none" pos="word" start_char="131">that</TOKEN>
<TOKEN end_char="138" id="token-2-3" morph="none" pos="word" start_char="136">the</TOKEN>
<TOKEN end_char="144" id="token-2-4" morph="none" pos="word" start_char="140">Obama</TOKEN>
<TOKEN end_char="159" id="token-2-5" morph="none" pos="word" start_char="146">administration</TOKEN>
<TOKEN end_char="164" id="token-2-6" morph="none" pos="word" start_char="161">gave</TOKEN>
<TOKEN end_char="171" id="token-2-7" morph="none" pos="word" start_char="166">almost</TOKEN>
<TOKEN end_char="174" id="token-2-8" morph="none" pos="unknown" start_char="173">$4</TOKEN>
<TOKEN end_char="182" id="token-2-9" morph="none" pos="word" start_char="176">million</TOKEN>
<TOKEN end_char="185" id="token-2-10" morph="none" pos="word" start_char="184">to</TOKEN>
<TOKEN end_char="187" id="token-2-11" morph="none" pos="word" start_char="187">a</TOKEN>
<TOKEN end_char="193" id="token-2-12" morph="none" pos="word" start_char="189">Wuhan</TOKEN>
<TOKEN end_char="202" id="token-2-13" morph="none" pos="word" start_char="195">research</TOKEN>
<TOKEN end_char="211" id="token-2-14" morph="none" pos="word" start_char="204">facility</TOKEN>
<TOKEN end_char="215" id="token-2-15" morph="none" pos="word" start_char="213">has</TOKEN>
<TOKEN end_char="222" id="token-2-16" morph="none" pos="word" start_char="217">gained</TOKEN>
<TOKEN end_char="231" id="token-2-17" morph="none" pos="word" start_char="224">traction</TOKEN>
<TOKEN end_char="238" id="token-2-18" morph="none" pos="word" start_char="233">online</TOKEN>
<TOKEN end_char="239" id="token-2-19" morph="none" pos="punct" start_char="239">,</TOKEN>
<TOKEN end_char="247" id="token-2-20" morph="none" pos="word" start_char="241">however</TOKEN>
<TOKEN end_char="248" id="token-2-21" morph="none" pos="punct" start_char="248">,</TOKEN>
<TOKEN end_char="252" id="token-2-22" morph="none" pos="word" start_char="250">the</TOKEN>
<TOKEN end_char="259" id="token-2-23" morph="none" pos="word" start_char="254">actual</TOKEN>
<TOKEN end_char="265" id="token-2-24" morph="none" pos="word" start_char="261">story</TOKEN>
<TOKEN end_char="268" id="token-2-25" morph="none" pos="word" start_char="267">is</TOKEN>
<TOKEN end_char="278" id="token-2-26" morph="none" pos="word" start_char="270">different</TOKEN>
<TOKEN end_char="279" id="token-2-27" morph="none" pos="punct" start_char="279">.</TOKEN>
</SEG>
<SEG end_char="546" id="segment-3" start_char="282">
<ORIGINAL_TEXT>According to Yahoo News, the claim that the U.S. government helped fund research into coronaviruses, spread after a Daily Mail report said it obtained documents showing the Wuhan Institute of Virology undertook coronavirus experiments on mammals captured in Yunnan.</ORIGINAL_TEXT>
<TOKEN end_char="290" id="token-3-0" morph="none" pos="word" start_char="282">According</TOKEN>
<TOKEN end_char="293" id="token-3-1" morph="none" pos="word" start_char="292">to</TOKEN>
<TOKEN end_char="299" id="token-3-2" morph="none" pos="word" start_char="295">Yahoo</TOKEN>
<TOKEN end_char="304" id="token-3-3" morph="none" pos="word" start_char="301">News</TOKEN>
<TOKEN end_char="305" id="token-3-4" morph="none" pos="punct" start_char="305">,</TOKEN>
<TOKEN end_char="309" id="token-3-5" morph="none" pos="word" start_char="307">the</TOKEN>
<TOKEN end_char="315" id="token-3-6" morph="none" pos="word" start_char="311">claim</TOKEN>
<TOKEN end_char="320" id="token-3-7" morph="none" pos="word" start_char="317">that</TOKEN>
<TOKEN end_char="324" id="token-3-8" morph="none" pos="word" start_char="322">the</TOKEN>
<TOKEN end_char="328" id="token-3-9" morph="none" pos="unknown" start_char="326">U.S</TOKEN>
<TOKEN end_char="329" id="token-3-10" morph="none" pos="punct" start_char="329">.</TOKEN>
<TOKEN end_char="340" id="token-3-11" morph="none" pos="word" start_char="331">government</TOKEN>
<TOKEN end_char="347" id="token-3-12" morph="none" pos="word" start_char="342">helped</TOKEN>
<TOKEN end_char="352" id="token-3-13" morph="none" pos="word" start_char="349">fund</TOKEN>
<TOKEN end_char="361" id="token-3-14" morph="none" pos="word" start_char="354">research</TOKEN>
<TOKEN end_char="366" id="token-3-15" morph="none" pos="word" start_char="363">into</TOKEN>
<TOKEN end_char="380" id="token-3-16" morph="none" pos="word" start_char="368">coronaviruses</TOKEN>
<TOKEN end_char="381" id="token-3-17" morph="none" pos="punct" start_char="381">,</TOKEN>
<TOKEN end_char="388" id="token-3-18" morph="none" pos="word" start_char="383">spread</TOKEN>
<TOKEN end_char="394" id="token-3-19" morph="none" pos="word" start_char="390">after</TOKEN>
<TOKEN end_char="396" id="token-3-20" morph="none" pos="word" start_char="396">a</TOKEN>
<TOKEN end_char="402" id="token-3-21" morph="none" pos="word" start_char="398">Daily</TOKEN>
<TOKEN end_char="407" id="token-3-22" morph="none" pos="word" start_char="404">Mail</TOKEN>
<TOKEN end_char="414" id="token-3-23" morph="none" pos="word" start_char="409">report</TOKEN>
<TOKEN end_char="419" id="token-3-24" morph="none" pos="word" start_char="416">said</TOKEN>
<TOKEN end_char="422" id="token-3-25" morph="none" pos="word" start_char="421">it</TOKEN>
<TOKEN end_char="431" id="token-3-26" morph="none" pos="word" start_char="424">obtained</TOKEN>
<TOKEN end_char="441" id="token-3-27" morph="none" pos="word" start_char="433">documents</TOKEN>
<TOKEN end_char="449" id="token-3-28" morph="none" pos="word" start_char="443">showing</TOKEN>
<TOKEN end_char="453" id="token-3-29" morph="none" pos="word" start_char="451">the</TOKEN>
<TOKEN end_char="459" id="token-3-30" morph="none" pos="word" start_char="455">Wuhan</TOKEN>
<TOKEN end_char="469" id="token-3-31" morph="none" pos="word" start_char="461">Institute</TOKEN>
<TOKEN end_char="472" id="token-3-32" morph="none" pos="word" start_char="471">of</TOKEN>
<TOKEN end_char="481" id="token-3-33" morph="none" pos="word" start_char="474">Virology</TOKEN>
<TOKEN end_char="491" id="token-3-34" morph="none" pos="word" start_char="483">undertook</TOKEN>
<TOKEN end_char="503" id="token-3-35" morph="none" pos="word" start_char="493">coronavirus</TOKEN>
<TOKEN end_char="515" id="token-3-36" morph="none" pos="word" start_char="505">experiments</TOKEN>
<TOKEN end_char="518" id="token-3-37" morph="none" pos="word" start_char="517">on</TOKEN>
<TOKEN end_char="526" id="token-3-38" morph="none" pos="word" start_char="520">mammals</TOKEN>
<TOKEN end_char="535" id="token-3-39" morph="none" pos="word" start_char="528">captured</TOKEN>
<TOKEN end_char="538" id="token-3-40" morph="none" pos="word" start_char="537">in</TOKEN>
<TOKEN end_char="545" id="token-3-41" morph="none" pos="word" start_char="540">Yunnan</TOKEN>
<TOKEN end_char="546" id="token-3-42" morph="none" pos="punct" start_char="546">.</TOKEN>
</SEG>
<SEG end_char="632" id="segment-4" start_char="549">
<ORIGINAL_TEXT>The report added that the Obama administration funded coronavirus research in China.</ORIGINAL_TEXT>
<TOKEN end_char="551" id="token-4-0" morph="none" pos="word" start_char="549">The</TOKEN>
<TOKEN end_char="558" id="token-4-1" morph="none" pos="word" start_char="553">report</TOKEN>
<TOKEN end_char="564" id="token-4-2" morph="none" pos="word" start_char="560">added</TOKEN>
<TOKEN end_char="569" id="token-4-3" morph="none" pos="word" start_char="566">that</TOKEN>
<TOKEN end_char="573" id="token-4-4" morph="none" pos="word" start_char="571">the</TOKEN>
<TOKEN end_char="579" id="token-4-5" morph="none" pos="word" start_char="575">Obama</TOKEN>
<TOKEN end_char="594" id="token-4-6" morph="none" pos="word" start_char="581">administration</TOKEN>
<TOKEN end_char="601" id="token-4-7" morph="none" pos="word" start_char="596">funded</TOKEN>
<TOKEN end_char="613" id="token-4-8" morph="none" pos="word" start_char="603">coronavirus</TOKEN>
<TOKEN end_char="622" id="token-4-9" morph="none" pos="word" start_char="615">research</TOKEN>
<TOKEN end_char="625" id="token-4-10" morph="none" pos="word" start_char="624">in</TOKEN>
<TOKEN end_char="631" id="token-4-11" morph="none" pos="word" start_char="627">China</TOKEN>
<TOKEN end_char="632" id="token-4-12" morph="none" pos="punct" start_char="632">.</TOKEN>
</SEG>
<SEG end_char="748" id="segment-5" start_char="634">
<ORIGINAL_TEXT>However, the truth is a grant overseen by the National Institutes of Health was provided to the EcoHealth Alliance.</ORIGINAL_TEXT>
<TOKEN end_char="640" id="token-5-0" morph="none" pos="word" start_char="634">However</TOKEN>
<TOKEN end_char="641" id="token-5-1" morph="none" pos="punct" start_char="641">,</TOKEN>
<TOKEN end_char="645" id="token-5-2" morph="none" pos="word" start_char="643">the</TOKEN>
<TOKEN end_char="651" id="token-5-3" morph="none" pos="word" start_char="647">truth</TOKEN>
<TOKEN end_char="654" id="token-5-4" morph="none" pos="word" start_char="653">is</TOKEN>
<TOKEN end_char="656" id="token-5-5" morph="none" pos="word" start_char="656">a</TOKEN>
<TOKEN end_char="662" id="token-5-6" morph="none" pos="word" start_char="658">grant</TOKEN>
<TOKEN end_char="671" id="token-5-7" morph="none" pos="word" start_char="664">overseen</TOKEN>
<TOKEN end_char="674" id="token-5-8" morph="none" pos="word" start_char="673">by</TOKEN>
<TOKEN end_char="678" id="token-5-9" morph="none" pos="word" start_char="676">the</TOKEN>
<TOKEN end_char="687" id="token-5-10" morph="none" pos="word" start_char="680">National</TOKEN>
<TOKEN end_char="698" id="token-5-11" morph="none" pos="word" start_char="689">Institutes</TOKEN>
<TOKEN end_char="701" id="token-5-12" morph="none" pos="word" start_char="700">of</TOKEN>
<TOKEN end_char="708" id="token-5-13" morph="none" pos="word" start_char="703">Health</TOKEN>
<TOKEN end_char="712" id="token-5-14" morph="none" pos="word" start_char="710">was</TOKEN>
<TOKEN end_char="721" id="token-5-15" morph="none" pos="word" start_char="714">provided</TOKEN>
<TOKEN end_char="724" id="token-5-16" morph="none" pos="word" start_char="723">to</TOKEN>
<TOKEN end_char="728" id="token-5-17" morph="none" pos="word" start_char="726">the</TOKEN>
<TOKEN end_char="738" id="token-5-18" morph="none" pos="word" start_char="730">EcoHealth</TOKEN>
<TOKEN end_char="747" id="token-5-19" morph="none" pos="word" start_char="740">Alliance</TOKEN>
<TOKEN end_char="748" id="token-5-20" morph="none" pos="punct" start_char="748">.</TOKEN>
</SEG>
<SEG end_char="832" id="segment-6" start_char="750">
<ORIGINAL_TEXT>The grant continued under the Trump administration until it was recently rescinded.</ORIGINAL_TEXT>
<TOKEN end_char="752" id="token-6-0" morph="none" pos="word" start_char="750">The</TOKEN>
<TOKEN end_char="758" id="token-6-1" morph="none" pos="word" start_char="754">grant</TOKEN>
<TOKEN end_char="768" id="token-6-2" morph="none" pos="word" start_char="760">continued</TOKEN>
<TOKEN end_char="774" id="token-6-3" morph="none" pos="word" start_char="770">under</TOKEN>
<TOKEN end_char="778" id="token-6-4" morph="none" pos="word" start_char="776">the</TOKEN>
<TOKEN end_char="784" id="token-6-5" morph="none" pos="word" start_char="780">Trump</TOKEN>
<TOKEN end_char="799" id="token-6-6" morph="none" pos="word" start_char="786">administration</TOKEN>
<TOKEN end_char="805" id="token-6-7" morph="none" pos="word" start_char="801">until</TOKEN>
<TOKEN end_char="808" id="token-6-8" morph="none" pos="word" start_char="807">it</TOKEN>
<TOKEN end_char="812" id="token-6-9" morph="none" pos="word" start_char="810">was</TOKEN>
<TOKEN end_char="821" id="token-6-10" morph="none" pos="word" start_char="814">recently</TOKEN>
<TOKEN end_char="831" id="token-6-11" morph="none" pos="word" start_char="823">rescinded</TOKEN>
<TOKEN end_char="832" id="token-6-12" morph="none" pos="punct" start_char="832">.</TOKEN>
</SEG>
<SEG end_char="967" id="segment-7" start_char="835">
<ORIGINAL_TEXT>The EcoHealth Alliance is a nongovernmental research group that focuses on emerging diseases caused by human and animal interactions.</ORIGINAL_TEXT>
<TOKEN end_char="837" id="token-7-0" morph="none" pos="word" start_char="835">The</TOKEN>
<TOKEN end_char="847" id="token-7-1" morph="none" pos="word" start_char="839">EcoHealth</TOKEN>
<TOKEN end_char="856" id="token-7-2" morph="none" pos="word" start_char="849">Alliance</TOKEN>
<TOKEN end_char="859" id="token-7-3" morph="none" pos="word" start_char="858">is</TOKEN>
<TOKEN end_char="861" id="token-7-4" morph="none" pos="word" start_char="861">a</TOKEN>
<TOKEN end_char="877" id="token-7-5" morph="none" pos="word" start_char="863">nongovernmental</TOKEN>
<TOKEN end_char="886" id="token-7-6" morph="none" pos="word" start_char="879">research</TOKEN>
<TOKEN end_char="892" id="token-7-7" morph="none" pos="word" start_char="888">group</TOKEN>
<TOKEN end_char="897" id="token-7-8" morph="none" pos="word" start_char="894">that</TOKEN>
<TOKEN end_char="905" id="token-7-9" morph="none" pos="word" start_char="899">focuses</TOKEN>
<TOKEN end_char="908" id="token-7-10" morph="none" pos="word" start_char="907">on</TOKEN>
<TOKEN end_char="917" id="token-7-11" morph="none" pos="word" start_char="910">emerging</TOKEN>
<TOKEN end_char="926" id="token-7-12" morph="none" pos="word" start_char="919">diseases</TOKEN>
<TOKEN end_char="933" id="token-7-13" morph="none" pos="word" start_char="928">caused</TOKEN>
<TOKEN end_char="936" id="token-7-14" morph="none" pos="word" start_char="935">by</TOKEN>
<TOKEN end_char="942" id="token-7-15" morph="none" pos="word" start_char="938">human</TOKEN>
<TOKEN end_char="946" id="token-7-16" morph="none" pos="word" start_char="944">and</TOKEN>
<TOKEN end_char="953" id="token-7-17" morph="none" pos="word" start_char="948">animal</TOKEN>
<TOKEN end_char="966" id="token-7-18" morph="none" pos="word" start_char="955">interactions</TOKEN>
<TOKEN end_char="967" id="token-7-19" morph="none" pos="punct" start_char="967">.</TOKEN>
</SEG>
<SEG end_char="1011" id="segment-8" start_char="969">
<ORIGINAL_TEXT>The NIH has funded the alliance since 2002.</ORIGINAL_TEXT>
<TOKEN end_char="971" id="token-8-0" morph="none" pos="word" start_char="969">The</TOKEN>
<TOKEN end_char="975" id="token-8-1" morph="none" pos="word" start_char="973">NIH</TOKEN>
<TOKEN end_char="979" id="token-8-2" morph="none" pos="word" start_char="977">has</TOKEN>
<TOKEN end_char="986" id="token-8-3" morph="none" pos="word" start_char="981">funded</TOKEN>
<TOKEN end_char="990" id="token-8-4" morph="none" pos="word" start_char="988">the</TOKEN>
<TOKEN end_char="999" id="token-8-5" morph="none" pos="word" start_char="992">alliance</TOKEN>
<TOKEN end_char="1005" id="token-8-6" morph="none" pos="word" start_char="1001">since</TOKEN>
<TOKEN end_char="1010" id="token-8-7" morph="none" pos="word" start_char="1007">2002</TOKEN>
<TOKEN end_char="1011" id="token-8-8" morph="none" pos="punct" start_char="1011">.</TOKEN>
</SEG>
<SEG end_char="1146" id="segment-9" start_char="1014">
<ORIGINAL_TEXT>In 2014, the NIH approved a grant to the alliance designated for research into "Understanding the Risk of Bat Coronavirus Emergence."</ORIGINAL_TEXT>
<TOKEN end_char="1015" id="token-9-0" morph="none" pos="word" start_char="1014">In</TOKEN>
<TOKEN end_char="1020" id="token-9-1" morph="none" pos="word" start_char="1017">2014</TOKEN>
<TOKEN end_char="1021" id="token-9-2" morph="none" pos="punct" start_char="1021">,</TOKEN>
<TOKEN end_char="1025" id="token-9-3" morph="none" pos="word" start_char="1023">the</TOKEN>
<TOKEN end_char="1029" id="token-9-4" morph="none" pos="word" start_char="1027">NIH</TOKEN>
<TOKEN end_char="1038" id="token-9-5" morph="none" pos="word" start_char="1031">approved</TOKEN>
<TOKEN end_char="1040" id="token-9-6" morph="none" pos="word" start_char="1040">a</TOKEN>
<TOKEN end_char="1046" id="token-9-7" morph="none" pos="word" start_char="1042">grant</TOKEN>
<TOKEN end_char="1049" id="token-9-8" morph="none" pos="word" start_char="1048">to</TOKEN>
<TOKEN end_char="1053" id="token-9-9" morph="none" pos="word" start_char="1051">the</TOKEN>
<TOKEN end_char="1062" id="token-9-10" morph="none" pos="word" start_char="1055">alliance</TOKEN>
<TOKEN end_char="1073" id="token-9-11" morph="none" pos="word" start_char="1064">designated</TOKEN>
<TOKEN end_char="1077" id="token-9-12" morph="none" pos="word" start_char="1075">for</TOKEN>
<TOKEN end_char="1086" id="token-9-13" morph="none" pos="word" start_char="1079">research</TOKEN>
<TOKEN end_char="1091" id="token-9-14" morph="none" pos="word" start_char="1088">into</TOKEN>
<TOKEN end_char="1093" id="token-9-15" morph="none" pos="punct" start_char="1093">"</TOKEN>
<TOKEN end_char="1106" id="token-9-16" morph="none" pos="word" start_char="1094">Understanding</TOKEN>
<TOKEN end_char="1110" id="token-9-17" morph="none" pos="word" start_char="1108">the</TOKEN>
<TOKEN end_char="1115" id="token-9-18" morph="none" pos="word" start_char="1112">Risk</TOKEN>
<TOKEN end_char="1118" id="token-9-19" morph="none" pos="word" start_char="1117">of</TOKEN>
<TOKEN end_char="1122" id="token-9-20" morph="none" pos="word" start_char="1120">Bat</TOKEN>
<TOKEN end_char="1134" id="token-9-21" morph="none" pos="word" start_char="1124">Coronavirus</TOKEN>
<TOKEN end_char="1144" id="token-9-22" morph="none" pos="word" start_char="1136">Emergence</TOKEN>
<TOKEN end_char="1146" id="token-9-23" morph="none" pos="punct" start_char="1145">."</TOKEN>
</SEG>
<SEG end_char="1311" id="segment-10" start_char="1149">
<ORIGINAL_TEXT>The project involved collaborating with researchers at the Wuhan Institute of Virology to study coronaviruses in bats and the risk of potential transfer to humans.</ORIGINAL_TEXT>
<TOKEN end_char="1151" id="token-10-0" morph="none" pos="word" start_char="1149">The</TOKEN>
<TOKEN end_char="1159" id="token-10-1" morph="none" pos="word" start_char="1153">project</TOKEN>
<TOKEN end_char="1168" id="token-10-2" morph="none" pos="word" start_char="1161">involved</TOKEN>
<TOKEN end_char="1182" id="token-10-3" morph="none" pos="word" start_char="1170">collaborating</TOKEN>
<TOKEN end_char="1187" id="token-10-4" morph="none" pos="word" start_char="1184">with</TOKEN>
<TOKEN end_char="1199" id="token-10-5" morph="none" pos="word" start_char="1189">researchers</TOKEN>
<TOKEN end_char="1202" id="token-10-6" morph="none" pos="word" start_char="1201">at</TOKEN>
<TOKEN end_char="1206" id="token-10-7" morph="none" pos="word" start_char="1204">the</TOKEN>
<TOKEN end_char="1212" id="token-10-8" morph="none" pos="word" start_char="1208">Wuhan</TOKEN>
<TOKEN end_char="1222" id="token-10-9" morph="none" pos="word" start_char="1214">Institute</TOKEN>
<TOKEN end_char="1225" id="token-10-10" morph="none" pos="word" start_char="1224">of</TOKEN>
<TOKEN end_char="1234" id="token-10-11" morph="none" pos="word" start_char="1227">Virology</TOKEN>
<TOKEN end_char="1237" id="token-10-12" morph="none" pos="word" start_char="1236">to</TOKEN>
<TOKEN end_char="1243" id="token-10-13" morph="none" pos="word" start_char="1239">study</TOKEN>
<TOKEN end_char="1257" id="token-10-14" morph="none" pos="word" start_char="1245">coronaviruses</TOKEN>
<TOKEN end_char="1260" id="token-10-15" morph="none" pos="word" start_char="1259">in</TOKEN>
<TOKEN end_char="1265" id="token-10-16" morph="none" pos="word" start_char="1262">bats</TOKEN>
<TOKEN end_char="1269" id="token-10-17" morph="none" pos="word" start_char="1267">and</TOKEN>
<TOKEN end_char="1273" id="token-10-18" morph="none" pos="word" start_char="1271">the</TOKEN>
<TOKEN end_char="1278" id="token-10-19" morph="none" pos="word" start_char="1275">risk</TOKEN>
<TOKEN end_char="1281" id="token-10-20" morph="none" pos="word" start_char="1280">of</TOKEN>
<TOKEN end_char="1291" id="token-10-21" morph="none" pos="word" start_char="1283">potential</TOKEN>
<TOKEN end_char="1300" id="token-10-22" morph="none" pos="word" start_char="1293">transfer</TOKEN>
<TOKEN end_char="1303" id="token-10-23" morph="none" pos="word" start_char="1302">to</TOKEN>
<TOKEN end_char="1310" id="token-10-24" morph="none" pos="word" start_char="1305">humans</TOKEN>
<TOKEN end_char="1311" id="token-10-25" morph="none" pos="punct" start_char="1311">.</TOKEN>
</SEG>
<SEG end_char="1466" id="segment-11" start_char="1313">
<ORIGINAL_TEXT>The project was created "to understand what factors allow coronaviruses, including close relatives to SARS, to evolve and jump into the human population."</ORIGINAL_TEXT>
<TOKEN end_char="1315" id="token-11-0" morph="none" pos="word" start_char="1313">The</TOKEN>
<TOKEN end_char="1323" id="token-11-1" morph="none" pos="word" start_char="1317">project</TOKEN>
<TOKEN end_char="1327" id="token-11-2" morph="none" pos="word" start_char="1325">was</TOKEN>
<TOKEN end_char="1335" id="token-11-3" morph="none" pos="word" start_char="1329">created</TOKEN>
<TOKEN end_char="1337" id="token-11-4" morph="none" pos="punct" start_char="1337">"</TOKEN>
<TOKEN end_char="1339" id="token-11-5" morph="none" pos="word" start_char="1338">to</TOKEN>
<TOKEN end_char="1350" id="token-11-6" morph="none" pos="word" start_char="1341">understand</TOKEN>
<TOKEN end_char="1355" id="token-11-7" morph="none" pos="word" start_char="1352">what</TOKEN>
<TOKEN end_char="1363" id="token-11-8" morph="none" pos="word" start_char="1357">factors</TOKEN>
<TOKEN end_char="1369" id="token-11-9" morph="none" pos="word" start_char="1365">allow</TOKEN>
<TOKEN end_char="1383" id="token-11-10" morph="none" pos="word" start_char="1371">coronaviruses</TOKEN>
<TOKEN end_char="1384" id="token-11-11" morph="none" pos="punct" start_char="1384">,</TOKEN>
<TOKEN end_char="1394" id="token-11-12" morph="none" pos="word" start_char="1386">including</TOKEN>
<TOKEN end_char="1400" id="token-11-13" morph="none" pos="word" start_char="1396">close</TOKEN>
<TOKEN end_char="1410" id="token-11-14" morph="none" pos="word" start_char="1402">relatives</TOKEN>
<TOKEN end_char="1413" id="token-11-15" morph="none" pos="word" start_char="1412">to</TOKEN>
<TOKEN end_char="1418" id="token-11-16" morph="none" pos="word" start_char="1415">SARS</TOKEN>
<TOKEN end_char="1419" id="token-11-17" morph="none" pos="punct" start_char="1419">,</TOKEN>
<TOKEN end_char="1422" id="token-11-18" morph="none" pos="word" start_char="1421">to</TOKEN>
<TOKEN end_char="1429" id="token-11-19" morph="none" pos="word" start_char="1424">evolve</TOKEN>
<TOKEN end_char="1433" id="token-11-20" morph="none" pos="word" start_char="1431">and</TOKEN>
<TOKEN end_char="1438" id="token-11-21" morph="none" pos="word" start_char="1435">jump</TOKEN>
<TOKEN end_char="1443" id="token-11-22" morph="none" pos="word" start_char="1440">into</TOKEN>
<TOKEN end_char="1447" id="token-11-23" morph="none" pos="word" start_char="1445">the</TOKEN>
<TOKEN end_char="1453" id="token-11-24" morph="none" pos="word" start_char="1449">human</TOKEN>
<TOKEN end_char="1464" id="token-11-25" morph="none" pos="word" start_char="1455">population</TOKEN>
<TOKEN end_char="1466" id="token-11-26" morph="none" pos="punct" start_char="1465">."</TOKEN>
</SEG>
<SEG end_char="1553" id="segment-12" start_char="1469">
<ORIGINAL_TEXT>The original five-year grant was reapproved by the Trump administration in July 2019.</ORIGINAL_TEXT>
<TOKEN end_char="1471" id="token-12-0" morph="none" pos="word" start_char="1469">The</TOKEN>
<TOKEN end_char="1480" id="token-12-1" morph="none" pos="word" start_char="1473">original</TOKEN>
<TOKEN end_char="1490" id="token-12-2" morph="none" pos="unknown" start_char="1482">five-year</TOKEN>
<TOKEN end_char="1496" id="token-12-3" morph="none" pos="word" start_char="1492">grant</TOKEN>
<TOKEN end_char="1500" id="token-12-4" morph="none" pos="word" start_char="1498">was</TOKEN>
<TOKEN end_char="1511" id="token-12-5" morph="none" pos="word" start_char="1502">reapproved</TOKEN>
<TOKEN end_char="1514" id="token-12-6" morph="none" pos="word" start_char="1513">by</TOKEN>
<TOKEN end_char="1518" id="token-12-7" morph="none" pos="word" start_char="1516">the</TOKEN>
<TOKEN end_char="1524" id="token-12-8" morph="none" pos="word" start_char="1520">Trump</TOKEN>
<TOKEN end_char="1539" id="token-12-9" morph="none" pos="word" start_char="1526">administration</TOKEN>
<TOKEN end_char="1542" id="token-12-10" morph="none" pos="word" start_char="1541">in</TOKEN>
<TOKEN end_char="1547" id="token-12-11" morph="none" pos="word" start_char="1544">July</TOKEN>
<TOKEN end_char="1552" id="token-12-12" morph="none" pos="word" start_char="1549">2019</TOKEN>
<TOKEN end_char="1553" id="token-12-13" morph="none" pos="punct" start_char="1553">.</TOKEN>
</SEG>
<SEG end_char="1678" id="segment-13" start_char="1555">
<ORIGINAL_TEXT>The effort spent $3,378,896 and resulted in 20 scientific reports on how zoonotic diseases may transfer from bats to humans.</ORIGINAL_TEXT>
<TOKEN end_char="1557" id="token-13-0" morph="none" pos="word" start_char="1555">The</TOKEN>
<TOKEN end_char="1564" id="token-13-1" morph="none" pos="word" start_char="1559">effort</TOKEN>
<TOKEN end_char="1570" id="token-13-2" morph="none" pos="word" start_char="1566">spent</TOKEN>
<TOKEN end_char="1581" id="token-13-3" morph="none" pos="unknown" start_char="1572">$3,378,896</TOKEN>
<TOKEN end_char="1585" id="token-13-4" morph="none" pos="word" start_char="1583">and</TOKEN>
<TOKEN end_char="1594" id="token-13-5" morph="none" pos="word" start_char="1587">resulted</TOKEN>
<TOKEN end_char="1597" id="token-13-6" morph="none" pos="word" start_char="1596">in</TOKEN>
<TOKEN end_char="1600" id="token-13-7" morph="none" pos="word" start_char="1599">20</TOKEN>
<TOKEN end_char="1611" id="token-13-8" morph="none" pos="word" start_char="1602">scientific</TOKEN>
<TOKEN end_char="1619" id="token-13-9" morph="none" pos="word" start_char="1613">reports</TOKEN>
<TOKEN end_char="1622" id="token-13-10" morph="none" pos="word" start_char="1621">on</TOKEN>
<TOKEN end_char="1626" id="token-13-11" morph="none" pos="word" start_char="1624">how</TOKEN>
<TOKEN end_char="1635" id="token-13-12" morph="none" pos="word" start_char="1628">zoonotic</TOKEN>
<TOKEN end_char="1644" id="token-13-13" morph="none" pos="word" start_char="1637">diseases</TOKEN>
<TOKEN end_char="1648" id="token-13-14" morph="none" pos="word" start_char="1646">may</TOKEN>
<TOKEN end_char="1657" id="token-13-15" morph="none" pos="word" start_char="1650">transfer</TOKEN>
<TOKEN end_char="1662" id="token-13-16" morph="none" pos="word" start_char="1659">from</TOKEN>
<TOKEN end_char="1667" id="token-13-17" morph="none" pos="word" start_char="1664">bats</TOKEN>
<TOKEN end_char="1670" id="token-13-18" morph="none" pos="word" start_char="1669">to</TOKEN>
<TOKEN end_char="1677" id="token-13-19" morph="none" pos="word" start_char="1672">humans</TOKEN>
<TOKEN end_char="1678" id="token-13-20" morph="none" pos="punct" start_char="1678">.</TOKEN>
</SEG>
<SEG end_char="1830" id="segment-14" start_char="1681">
<ORIGINAL_TEXT>The Daily Mail reported April 11, the research was funded by a $3.7 million grant from the Obama administration and the claim quickly gained traction.</ORIGINAL_TEXT>
<TOKEN end_char="1683" id="token-14-0" morph="none" pos="word" start_char="1681">The</TOKEN>
<TOKEN end_char="1689" id="token-14-1" morph="none" pos="word" start_char="1685">Daily</TOKEN>
<TOKEN end_char="1694" id="token-14-2" morph="none" pos="word" start_char="1691">Mail</TOKEN>
<TOKEN end_char="1703" id="token-14-3" morph="none" pos="word" start_char="1696">reported</TOKEN>
<TOKEN end_char="1709" id="token-14-4" morph="none" pos="word" start_char="1705">April</TOKEN>
<TOKEN end_char="1712" id="token-14-5" morph="none" pos="word" start_char="1711">11</TOKEN>
<TOKEN end_char="1713" id="token-14-6" morph="none" pos="punct" start_char="1713">,</TOKEN>
<TOKEN end_char="1717" id="token-14-7" morph="none" pos="word" start_char="1715">the</TOKEN>
<TOKEN end_char="1726" id="token-14-8" morph="none" pos="word" start_char="1719">research</TOKEN>
<TOKEN end_char="1730" id="token-14-9" morph="none" pos="word" start_char="1728">was</TOKEN>
<TOKEN end_char="1737" id="token-14-10" morph="none" pos="word" start_char="1732">funded</TOKEN>
<TOKEN end_char="1740" id="token-14-11" morph="none" pos="word" start_char="1739">by</TOKEN>
<TOKEN end_char="1742" id="token-14-12" morph="none" pos="word" start_char="1742">a</TOKEN>
<TOKEN end_char="1747" id="token-14-13" morph="none" pos="unknown" start_char="1744">$3.7</TOKEN>
<TOKEN end_char="1755" id="token-14-14" morph="none" pos="word" start_char="1749">million</TOKEN>
<TOKEN end_char="1761" id="token-14-15" morph="none" pos="word" start_char="1757">grant</TOKEN>
<TOKEN end_char="1766" id="token-14-16" morph="none" pos="word" start_char="1763">from</TOKEN>
<TOKEN end_char="1770" id="token-14-17" morph="none" pos="word" start_char="1768">the</TOKEN>
<TOKEN end_char="1776" id="token-14-18" morph="none" pos="word" start_char="1772">Obama</TOKEN>
<TOKEN end_char="1791" id="token-14-19" morph="none" pos="word" start_char="1778">administration</TOKEN>
<TOKEN end_char="1795" id="token-14-20" morph="none" pos="word" start_char="1793">and</TOKEN>
<TOKEN end_char="1799" id="token-14-21" morph="none" pos="word" start_char="1797">the</TOKEN>
<TOKEN end_char="1805" id="token-14-22" morph="none" pos="word" start_char="1801">claim</TOKEN>
<TOKEN end_char="1813" id="token-14-23" morph="none" pos="word" start_char="1807">quickly</TOKEN>
<TOKEN end_char="1820" id="token-14-24" morph="none" pos="word" start_char="1815">gained</TOKEN>
<TOKEN end_char="1829" id="token-14-25" morph="none" pos="word" start_char="1822">traction</TOKEN>
<TOKEN end_char="1830" id="token-14-26" morph="none" pos="punct" start_char="1830">.</TOKEN>
</SEG>
<SEG end_char="2006" id="segment-15" start_char="1833">
<ORIGINAL_TEXT>"For years, the US government has been funding cruel animal experiments at the Wuhan Institute of Virology, which may have contributed to the global spread of COVID-19," Rep.</ORIGINAL_TEXT>
<TOKEN end_char="1833" id="token-15-0" morph="none" pos="punct" start_char="1833">"</TOKEN>
<TOKEN end_char="1836" id="token-15-1" morph="none" pos="word" start_char="1834">For</TOKEN>
<TOKEN end_char="1842" id="token-15-2" morph="none" pos="word" start_char="1838">years</TOKEN>
<TOKEN end_char="1843" id="token-15-3" morph="none" pos="punct" start_char="1843">,</TOKEN>
<TOKEN end_char="1847" id="token-15-4" morph="none" pos="word" start_char="1845">the</TOKEN>
<TOKEN end_char="1850" id="token-15-5" morph="none" pos="word" start_char="1849">US</TOKEN>
<TOKEN end_char="1861" id="token-15-6" morph="none" pos="word" start_char="1852">government</TOKEN>
<TOKEN end_char="1865" id="token-15-7" morph="none" pos="word" start_char="1863">has</TOKEN>
<TOKEN end_char="1870" id="token-15-8" morph="none" pos="word" start_char="1867">been</TOKEN>
<TOKEN end_char="1878" id="token-15-9" morph="none" pos="word" start_char="1872">funding</TOKEN>
<TOKEN end_char="1884" id="token-15-10" morph="none" pos="word" start_char="1880">cruel</TOKEN>
<TOKEN end_char="1891" id="token-15-11" morph="none" pos="word" start_char="1886">animal</TOKEN>
<TOKEN end_char="1903" id="token-15-12" morph="none" pos="word" start_char="1893">experiments</TOKEN>
<TOKEN end_char="1906" id="token-15-13" morph="none" pos="word" start_char="1905">at</TOKEN>
<TOKEN end_char="1910" id="token-15-14" morph="none" pos="word" start_char="1908">the</TOKEN>
<TOKEN end_char="1916" id="token-15-15" morph="none" pos="word" start_char="1912">Wuhan</TOKEN>
<TOKEN end_char="1926" id="token-15-16" morph="none" pos="word" start_char="1918">Institute</TOKEN>
<TOKEN end_char="1929" id="token-15-17" morph="none" pos="word" start_char="1928">of</TOKEN>
<TOKEN end_char="1938" id="token-15-18" morph="none" pos="word" start_char="1931">Virology</TOKEN>
<TOKEN end_char="1939" id="token-15-19" morph="none" pos="punct" start_char="1939">,</TOKEN>
<TOKEN end_char="1945" id="token-15-20" morph="none" pos="word" start_char="1941">which</TOKEN>
<TOKEN end_char="1949" id="token-15-21" morph="none" pos="word" start_char="1947">may</TOKEN>
<TOKEN end_char="1954" id="token-15-22" morph="none" pos="word" start_char="1951">have</TOKEN>
<TOKEN end_char="1966" id="token-15-23" morph="none" pos="word" start_char="1956">contributed</TOKEN>
<TOKEN end_char="1969" id="token-15-24" morph="none" pos="word" start_char="1968">to</TOKEN>
<TOKEN end_char="1973" id="token-15-25" morph="none" pos="word" start_char="1971">the</TOKEN>
<TOKEN end_char="1980" id="token-15-26" morph="none" pos="word" start_char="1975">global</TOKEN>
<TOKEN end_char="1987" id="token-15-27" morph="none" pos="word" start_char="1982">spread</TOKEN>
<TOKEN end_char="1990" id="token-15-28" morph="none" pos="word" start_char="1989">of</TOKEN>
<TOKEN end_char="1999" id="token-15-29" morph="none" pos="unknown" start_char="1992">COVID-19</TOKEN>
<TOKEN end_char="2001" id="token-15-30" morph="none" pos="punct" start_char="2000">,"</TOKEN>
<TOKEN end_char="2005" id="token-15-31" morph="none" pos="word" start_char="2003">Rep</TOKEN>
<TOKEN end_char="2006" id="token-15-32" morph="none" pos="punct" start_char="2006">.</TOKEN>
</SEG>
<SEG end_char="2044" id="segment-16" start_char="2008">
<ORIGINAL_TEXT>Matt Gaetz, R-Fla., tweeted April 13.</ORIGINAL_TEXT>
<TOKEN end_char="2011" id="token-16-0" morph="none" pos="word" start_char="2008">Matt</TOKEN>
<TOKEN end_char="2017" id="token-16-1" morph="none" pos="word" start_char="2013">Gaetz</TOKEN>
<TOKEN end_char="2018" id="token-16-2" morph="none" pos="punct" start_char="2018">,</TOKEN>
<TOKEN end_char="2024" id="token-16-3" morph="none" pos="unknown" start_char="2020">R-Fla</TOKEN>
<TOKEN end_char="2026" id="token-16-4" morph="none" pos="punct" start_char="2025">.,</TOKEN>
<TOKEN end_char="2034" id="token-16-5" morph="none" pos="word" start_char="2028">tweeted</TOKEN>
<TOKEN end_char="2040" id="token-16-6" morph="none" pos="word" start_char="2036">April</TOKEN>
<TOKEN end_char="2043" id="token-16-7" morph="none" pos="word" start_char="2042">13</TOKEN>
<TOKEN end_char="2044" id="token-16-8" morph="none" pos="punct" start_char="2044">.</TOKEN>
</SEG>
<SEG end_char="2111" id="segment-17" start_char="2047">
<ORIGINAL_TEXT>Gaetz praised President Trump for ending the program on Fox News.</ORIGINAL_TEXT>
<TOKEN end_char="2051" id="token-17-0" morph="none" pos="word" start_char="2047">Gaetz</TOKEN>
<TOKEN end_char="2059" id="token-17-1" morph="none" pos="word" start_char="2053">praised</TOKEN>
<TOKEN end_char="2069" id="token-17-2" morph="none" pos="word" start_char="2061">President</TOKEN>
<TOKEN end_char="2075" id="token-17-3" morph="none" pos="word" start_char="2071">Trump</TOKEN>
<TOKEN end_char="2079" id="token-17-4" morph="none" pos="word" start_char="2077">for</TOKEN>
<TOKEN end_char="2086" id="token-17-5" morph="none" pos="word" start_char="2081">ending</TOKEN>
<TOKEN end_char="2090" id="token-17-6" morph="none" pos="word" start_char="2088">the</TOKEN>
<TOKEN end_char="2098" id="token-17-7" morph="none" pos="word" start_char="2092">program</TOKEN>
<TOKEN end_char="2101" id="token-17-8" morph="none" pos="word" start_char="2100">on</TOKEN>
<TOKEN end_char="2105" id="token-17-9" morph="none" pos="word" start_char="2103">Fox</TOKEN>
<TOKEN end_char="2110" id="token-17-10" morph="none" pos="word" start_char="2107">News</TOKEN>
<TOKEN end_char="2111" id="token-17-11" morph="none" pos="punct" start_char="2111">.</TOKEN>
</SEG>
<SEG end_char="2228" id="segment-18" start_char="2114">
<ORIGINAL_TEXT>When a reporter asked Trump about the grant money, he responded, "We will end that grant very quickly," Trump said.</ORIGINAL_TEXT>
<TOKEN end_char="2117" id="token-18-0" morph="none" pos="word" start_char="2114">When</TOKEN>
<TOKEN end_char="2119" id="token-18-1" morph="none" pos="word" start_char="2119">a</TOKEN>
<TOKEN end_char="2128" id="token-18-2" morph="none" pos="word" start_char="2121">reporter</TOKEN>
<TOKEN end_char="2134" id="token-18-3" morph="none" pos="word" start_char="2130">asked</TOKEN>
<TOKEN end_char="2140" id="token-18-4" morph="none" pos="word" start_char="2136">Trump</TOKEN>
<TOKEN end_char="2146" id="token-18-5" morph="none" pos="word" start_char="2142">about</TOKEN>
<TOKEN end_char="2150" id="token-18-6" morph="none" pos="word" start_char="2148">the</TOKEN>
<TOKEN end_char="2156" id="token-18-7" morph="none" pos="word" start_char="2152">grant</TOKEN>
<TOKEN end_char="2162" id="token-18-8" morph="none" pos="word" start_char="2158">money</TOKEN>
<TOKEN end_char="2163" id="token-18-9" morph="none" pos="punct" start_char="2163">,</TOKEN>
<TOKEN end_char="2166" id="token-18-10" morph="none" pos="word" start_char="2165">he</TOKEN>
<TOKEN end_char="2176" id="token-18-11" morph="none" pos="word" start_char="2168">responded</TOKEN>
<TOKEN end_char="2177" id="token-18-12" morph="none" pos="punct" start_char="2177">,</TOKEN>
<TOKEN end_char="2179" id="token-18-13" morph="none" pos="punct" start_char="2179">"</TOKEN>
<TOKEN end_char="2181" id="token-18-14" morph="none" pos="word" start_char="2180">We</TOKEN>
<TOKEN end_char="2186" id="token-18-15" morph="none" pos="word" start_char="2183">will</TOKEN>
<TOKEN end_char="2190" id="token-18-16" morph="none" pos="word" start_char="2188">end</TOKEN>
<TOKEN end_char="2195" id="token-18-17" morph="none" pos="word" start_char="2192">that</TOKEN>
<TOKEN end_char="2201" id="token-18-18" morph="none" pos="word" start_char="2197">grant</TOKEN>
<TOKEN end_char="2206" id="token-18-19" morph="none" pos="word" start_char="2203">very</TOKEN>
<TOKEN end_char="2214" id="token-18-20" morph="none" pos="word" start_char="2208">quickly</TOKEN>
<TOKEN end_char="2216" id="token-18-21" morph="none" pos="punct" start_char="2215">,"</TOKEN>
<TOKEN end_char="2222" id="token-18-22" morph="none" pos="word" start_char="2218">Trump</TOKEN>
<TOKEN end_char="2227" id="token-18-23" morph="none" pos="word" start_char="2224">said</TOKEN>
<TOKEN end_char="2228" id="token-18-24" morph="none" pos="punct" start_char="2228">.</TOKEN>
</SEG>
<SEG end_char="2264" id="segment-19" start_char="2230">
<ORIGINAL_TEXT>"It was made a number of years ago.</ORIGINAL_TEXT>
<TOKEN end_char="2230" id="token-19-0" morph="none" pos="punct" start_char="2230">"</TOKEN>
<TOKEN end_char="2232" id="token-19-1" morph="none" pos="word" start_char="2231">It</TOKEN>
<TOKEN end_char="2236" id="token-19-2" morph="none" pos="word" start_char="2234">was</TOKEN>
<TOKEN end_char="2241" id="token-19-3" morph="none" pos="word" start_char="2238">made</TOKEN>
<TOKEN end_char="2243" id="token-19-4" morph="none" pos="word" start_char="2243">a</TOKEN>
<TOKEN end_char="2250" id="token-19-5" morph="none" pos="word" start_char="2245">number</TOKEN>
<TOKEN end_char="2253" id="token-19-6" morph="none" pos="word" start_char="2252">of</TOKEN>
<TOKEN end_char="2259" id="token-19-7" morph="none" pos="word" start_char="2255">years</TOKEN>
<TOKEN end_char="2263" id="token-19-8" morph="none" pos="word" start_char="2261">ago</TOKEN>
<TOKEN end_char="2264" id="token-19-9" morph="none" pos="punct" start_char="2264">.</TOKEN>
</SEG>
<SEG end_char="2299" id="segment-20" start_char="2266">
<ORIGINAL_TEXT>Who was president then, I wonder?"</ORIGINAL_TEXT>
<TOKEN end_char="2268" id="token-20-0" morph="none" pos="word" start_char="2266">Who</TOKEN>
<TOKEN end_char="2272" id="token-20-1" morph="none" pos="word" start_char="2270">was</TOKEN>
<TOKEN end_char="2282" id="token-20-2" morph="none" pos="word" start_char="2274">president</TOKEN>
<TOKEN end_char="2287" id="token-20-3" morph="none" pos="word" start_char="2284">then</TOKEN>
<TOKEN end_char="2288" id="token-20-4" morph="none" pos="punct" start_char="2288">,</TOKEN>
<TOKEN end_char="2290" id="token-20-5" morph="none" pos="word" start_char="2290">I</TOKEN>
<TOKEN end_char="2297" id="token-20-6" morph="none" pos="word" start_char="2292">wonder</TOKEN>
<TOKEN end_char="2299" id="token-20-7" morph="none" pos="punct" start_char="2298">?"</TOKEN>
</SEG>
<SEG end_char="2344" id="segment-21" start_char="2302">
<ORIGINAL_TEXT>Other politicians also jumped on the claim.</ORIGINAL_TEXT>
<TOKEN end_char="2306" id="token-21-0" morph="none" pos="word" start_char="2302">Other</TOKEN>
<TOKEN end_char="2318" id="token-21-1" morph="none" pos="word" start_char="2308">politicians</TOKEN>
<TOKEN end_char="2323" id="token-21-2" morph="none" pos="word" start_char="2320">also</TOKEN>
<TOKEN end_char="2330" id="token-21-3" morph="none" pos="word" start_char="2325">jumped</TOKEN>
<TOKEN end_char="2333" id="token-21-4" morph="none" pos="word" start_char="2332">on</TOKEN>
<TOKEN end_char="2337" id="token-21-5" morph="none" pos="word" start_char="2335">the</TOKEN>
<TOKEN end_char="2343" id="token-21-6" morph="none" pos="word" start_char="2339">claim</TOKEN>
<TOKEN end_char="2344" id="token-21-7" morph="none" pos="punct" start_char="2344">.</TOKEN>
</SEG>
<SEG end_char="2349" id="segment-22" start_char="2346">
<ORIGINAL_TEXT>Sen.</ORIGINAL_TEXT>
<TOKEN end_char="2348" id="token-22-0" morph="none" pos="word" start_char="2346">Sen</TOKEN>
<TOKEN end_char="2349" id="token-22-1" morph="none" pos="punct" start_char="2349">.</TOKEN>
<TRANSLATED_TEXT>You...</TRANSLATED_TEXT><DETECTED_LANGUAGE>fi</DETECTED_LANGUAGE></SEG>
<SEG end_char="2369" id="segment-23" start_char="2351">
<ORIGINAL_TEXT>Tom Cotton (R-Ark.)</ORIGINAL_TEXT>
<TOKEN end_char="2353" id="token-23-0" morph="none" pos="word" start_char="2351">Tom</TOKEN>
<TOKEN end_char="2360" id="token-23-1" morph="none" pos="word" start_char="2355">Cotton</TOKEN>
<TOKEN end_char="2362" id="token-23-2" morph="none" pos="punct" start_char="2362">(</TOKEN>
<TOKEN end_char="2367" id="token-23-3" morph="none" pos="unknown" start_char="2363">R-Ark</TOKEN>
<TOKEN end_char="2369" id="token-23-4" morph="none" pos="punct" start_char="2368">.)</TOKEN>
</SEG>
<SEG end_char="2454" id="segment-24" start_char="2371">
<ORIGINAL_TEXT>accused the Chinese government of covering up its involvement in the virus’ origins.</ORIGINAL_TEXT>
<TOKEN end_char="2377" id="token-24-0" morph="none" pos="word" start_char="2371">accused</TOKEN>
<TOKEN end_char="2381" id="token-24-1" morph="none" pos="word" start_char="2379">the</TOKEN>
<TOKEN end_char="2389" id="token-24-2" morph="none" pos="word" start_char="2383">Chinese</TOKEN>
<TOKEN end_char="2400" id="token-24-3" morph="none" pos="word" start_char="2391">government</TOKEN>
<TOKEN end_char="2403" id="token-24-4" morph="none" pos="word" start_char="2402">of</TOKEN>
<TOKEN end_char="2412" id="token-24-5" morph="none" pos="word" start_char="2405">covering</TOKEN>
<TOKEN end_char="2415" id="token-24-6" morph="none" pos="word" start_char="2414">up</TOKEN>
<TOKEN end_char="2419" id="token-24-7" morph="none" pos="word" start_char="2417">its</TOKEN>
<TOKEN end_char="2431" id="token-24-8" morph="none" pos="word" start_char="2421">involvement</TOKEN>
<TOKEN end_char="2434" id="token-24-9" morph="none" pos="word" start_char="2433">in</TOKEN>
<TOKEN end_char="2438" id="token-24-10" morph="none" pos="word" start_char="2436">the</TOKEN>
<TOKEN end_char="2444" id="token-24-11" morph="none" pos="word" start_char="2440">virus</TOKEN>
<TOKEN end_char="2445" id="token-24-12" morph="none" pos="punct" start_char="2445">’</TOKEN>
<TOKEN end_char="2453" id="token-24-13" morph="none" pos="word" start_char="2447">origins</TOKEN>
<TOKEN end_char="2454" id="token-24-14" morph="none" pos="punct" start_char="2454">.</TOKEN>
</SEG>
<SEG end_char="2601" id="segment-25" start_char="2456">
<ORIGINAL_TEXT>"This evidence is circumstantial, to be sure, but it all points toward the Wuhan labs," the senator wrote in an op-ed for The Wall Street Journal.</ORIGINAL_TEXT>
<TOKEN end_char="2456" id="token-25-0" morph="none" pos="punct" start_char="2456">"</TOKEN>
<TOKEN end_char="2460" id="token-25-1" morph="none" pos="word" start_char="2457">This</TOKEN>
<TOKEN end_char="2469" id="token-25-2" morph="none" pos="word" start_char="2462">evidence</TOKEN>
<TOKEN end_char="2472" id="token-25-3" morph="none" pos="word" start_char="2471">is</TOKEN>
<TOKEN end_char="2487" id="token-25-4" morph="none" pos="word" start_char="2474">circumstantial</TOKEN>
<TOKEN end_char="2488" id="token-25-5" morph="none" pos="punct" start_char="2488">,</TOKEN>
<TOKEN end_char="2491" id="token-25-6" morph="none" pos="word" start_char="2490">to</TOKEN>
<TOKEN end_char="2494" id="token-25-7" morph="none" pos="word" start_char="2493">be</TOKEN>
<TOKEN end_char="2499" id="token-25-8" morph="none" pos="word" start_char="2496">sure</TOKEN>
<TOKEN end_char="2500" id="token-25-9" morph="none" pos="punct" start_char="2500">,</TOKEN>
<TOKEN end_char="2504" id="token-25-10" morph="none" pos="word" start_char="2502">but</TOKEN>
<TOKEN end_char="2507" id="token-25-11" morph="none" pos="word" start_char="2506">it</TOKEN>
<TOKEN end_char="2511" id="token-25-12" morph="none" pos="word" start_char="2509">all</TOKEN>
<TOKEN end_char="2518" id="token-25-13" morph="none" pos="word" start_char="2513">points</TOKEN>
<TOKEN end_char="2525" id="token-25-14" morph="none" pos="word" start_char="2520">toward</TOKEN>
<TOKEN end_char="2529" id="token-25-15" morph="none" pos="word" start_char="2527">the</TOKEN>
<TOKEN end_char="2535" id="token-25-16" morph="none" pos="word" start_char="2531">Wuhan</TOKEN>
<TOKEN end_char="2540" id="token-25-17" morph="none" pos="word" start_char="2537">labs</TOKEN>
<TOKEN end_char="2542" id="token-25-18" morph="none" pos="punct" start_char="2541">,"</TOKEN>
<TOKEN end_char="2546" id="token-25-19" morph="none" pos="word" start_char="2544">the</TOKEN>
<TOKEN end_char="2554" id="token-25-20" morph="none" pos="word" start_char="2548">senator</TOKEN>
<TOKEN end_char="2560" id="token-25-21" morph="none" pos="word" start_char="2556">wrote</TOKEN>
<TOKEN end_char="2563" id="token-25-22" morph="none" pos="word" start_char="2562">in</TOKEN>
<TOKEN end_char="2566" id="token-25-23" morph="none" pos="word" start_char="2565">an</TOKEN>
<TOKEN end_char="2572" id="token-25-24" morph="none" pos="unknown" start_char="2568">op-ed</TOKEN>
<TOKEN end_char="2576" id="token-25-25" morph="none" pos="word" start_char="2574">for</TOKEN>
<TOKEN end_char="2580" id="token-25-26" morph="none" pos="word" start_char="2578">The</TOKEN>
<TOKEN end_char="2585" id="token-25-27" morph="none" pos="word" start_char="2582">Wall</TOKEN>
<TOKEN end_char="2592" id="token-25-28" morph="none" pos="word" start_char="2587">Street</TOKEN>
<TOKEN end_char="2600" id="token-25-29" morph="none" pos="word" start_char="2594">Journal</TOKEN>
<TOKEN end_char="2601" id="token-25-30" morph="none" pos="punct" start_char="2601">.</TOKEN>
</SEG>
<SEG end_char="2695" id="segment-26" start_char="2604">
<ORIGINAL_TEXT>Last week, President Trump also blamed Obama for the lack of coronavirus testing in the U.S.</ORIGINAL_TEXT>
<TOKEN end_char="2607" id="token-26-0" morph="none" pos="word" start_char="2604">Last</TOKEN>
<TOKEN end_char="2612" id="token-26-1" morph="none" pos="word" start_char="2609">week</TOKEN>
<TOKEN end_char="2613" id="token-26-2" morph="none" pos="punct" start_char="2613">,</TOKEN>
<TOKEN end_char="2623" id="token-26-3" morph="none" pos="word" start_char="2615">President</TOKEN>
<TOKEN end_char="2629" id="token-26-4" morph="none" pos="word" start_char="2625">Trump</TOKEN>
<TOKEN end_char="2634" id="token-26-5" morph="none" pos="word" start_char="2631">also</TOKEN>
<TOKEN end_char="2641" id="token-26-6" morph="none" pos="word" start_char="2636">blamed</TOKEN>
<TOKEN end_char="2647" id="token-26-7" morph="none" pos="word" start_char="2643">Obama</TOKEN>
<TOKEN end_char="2651" id="token-26-8" morph="none" pos="word" start_char="2649">for</TOKEN>
<TOKEN end_char="2655" id="token-26-9" morph="none" pos="word" start_char="2653">the</TOKEN>
<TOKEN end_char="2660" id="token-26-10" morph="none" pos="word" start_char="2657">lack</TOKEN>
<TOKEN end_char="2663" id="token-26-11" morph="none" pos="word" start_char="2662">of</TOKEN>
<TOKEN end_char="2675" id="token-26-12" morph="none" pos="word" start_char="2665">coronavirus</TOKEN>
<TOKEN end_char="2683" id="token-26-13" morph="none" pos="word" start_char="2677">testing</TOKEN>
<TOKEN end_char="2686" id="token-26-14" morph="none" pos="word" start_char="2685">in</TOKEN>
<TOKEN end_char="2690" id="token-26-15" morph="none" pos="word" start_char="2688">the</TOKEN>
<TOKEN end_char="2694" id="token-26-16" morph="none" pos="unknown" start_char="2692">U.S</TOKEN>
<TOKEN end_char="2695" id="token-26-17" morph="none" pos="punct" start_char="2695">.</TOKEN>
</SEG>
<SEG end_char="2827" id="segment-27" start_char="2698">
<ORIGINAL_TEXT>In April, Trump also wondered why Obama hadn’t endorsed Joe Biden days after Bernie Sanders dropped out of the Democratic primary.</ORIGINAL_TEXT>
<TOKEN end_char="2699" id="token-27-0" morph="none" pos="word" start_char="2698">In</TOKEN>
<TOKEN end_char="2705" id="token-27-1" morph="none" pos="word" start_char="2701">April</TOKEN>
<TOKEN end_char="2706" id="token-27-2" morph="none" pos="punct" start_char="2706">,</TOKEN>
<TOKEN end_char="2712" id="token-27-3" morph="none" pos="word" start_char="2708">Trump</TOKEN>
<TOKEN end_char="2717" id="token-27-4" morph="none" pos="word" start_char="2714">also</TOKEN>
<TOKEN end_char="2726" id="token-27-5" morph="none" pos="word" start_char="2719">wondered</TOKEN>
<TOKEN end_char="2730" id="token-27-6" morph="none" pos="word" start_char="2728">why</TOKEN>
<TOKEN end_char="2736" id="token-27-7" morph="none" pos="word" start_char="2732">Obama</TOKEN>
<TOKEN end_char="2743" id="token-27-8" morph="none" pos="word" start_char="2738">hadn’t</TOKEN>
<TOKEN end_char="2752" id="token-27-9" morph="none" pos="word" start_char="2745">endorsed</TOKEN>
<TOKEN end_char="2756" id="token-27-10" morph="none" pos="word" start_char="2754">Joe</TOKEN>
<TOKEN end_char="2762" id="token-27-11" morph="none" pos="word" start_char="2758">Biden</TOKEN>
<TOKEN end_char="2767" id="token-27-12" morph="none" pos="word" start_char="2764">days</TOKEN>
<TOKEN end_char="2773" id="token-27-13" morph="none" pos="word" start_char="2769">after</TOKEN>
<TOKEN end_char="2780" id="token-27-14" morph="none" pos="word" start_char="2775">Bernie</TOKEN>
<TOKEN end_char="2788" id="token-27-15" morph="none" pos="word" start_char="2782">Sanders</TOKEN>
<TOKEN end_char="2796" id="token-27-16" morph="none" pos="word" start_char="2790">dropped</TOKEN>
<TOKEN end_char="2800" id="token-27-17" morph="none" pos="word" start_char="2798">out</TOKEN>
<TOKEN end_char="2803" id="token-27-18" morph="none" pos="word" start_char="2802">of</TOKEN>
<TOKEN end_char="2807" id="token-27-19" morph="none" pos="word" start_char="2805">the</TOKEN>
<TOKEN end_char="2818" id="token-27-20" morph="none" pos="word" start_char="2809">Democratic</TOKEN>
<TOKEN end_char="2826" id="token-27-21" morph="none" pos="word" start_char="2820">primary</TOKEN>
<TOKEN end_char="2827" id="token-27-22" morph="none" pos="punct" start_char="2827">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="rus">
<DOC grammar="none" id="L0C04958M" lang="rus" raw_text_char_length="3198" raw_text_md5="a13c79dfbaf2fac2fd79a3a9d69182c4" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="105" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Disinfo: Coronavirus was created on purpose, probably by the same British lab which poisoned the Skripals</ORIGINAL_TEXT>
<TOKEN end_char="7" id="token-0-0" morph="none" pos="word" start_char="1">Disinfo</TOKEN>
<TOKEN end_char="8" id="token-0-1" morph="none" pos="punct" start_char="8">:</TOKEN>
<TOKEN end_char="20" id="token-0-2" morph="none" pos="word" start_char="10">Coronavirus</TOKEN>
<TOKEN end_char="24" id="token-0-3" morph="none" pos="word" start_char="22">was</TOKEN>
<TOKEN end_char="32" id="token-0-4" morph="none" pos="word" start_char="26">created</TOKEN>
<TOKEN end_char="35" id="token-0-5" morph="none" pos="word" start_char="34">on</TOKEN>
<TOKEN end_char="43" id="token-0-6" morph="none" pos="word" start_char="37">purpose</TOKEN>
<TOKEN end_char="44" id="token-0-7" morph="none" pos="punct" start_char="44">,</TOKEN>
<TOKEN end_char="53" id="token-0-8" morph="none" pos="word" start_char="46">probably</TOKEN>
<TOKEN end_char="56" id="token-0-9" morph="none" pos="word" start_char="55">by</TOKEN>
<TOKEN end_char="60" id="token-0-10" morph="none" pos="word" start_char="58">the</TOKEN>
<TOKEN end_char="65" id="token-0-11" morph="none" pos="word" start_char="62">same</TOKEN>
<TOKEN end_char="73" id="token-0-12" morph="none" pos="word" start_char="67">British</TOKEN>
<TOKEN end_char="77" id="token-0-13" morph="none" pos="word" start_char="75">lab</TOKEN>
<TOKEN end_char="83" id="token-0-14" morph="none" pos="word" start_char="79">which</TOKEN>
<TOKEN end_char="92" id="token-0-15" morph="none" pos="word" start_char="85">poisoned</TOKEN>
<TOKEN end_char="96" id="token-0-16" morph="none" pos="word" start_char="94">the</TOKEN>
<TOKEN end_char="105" id="token-0-17" morph="none" pos="word" start_char="98">Skripals</TOKEN>
</SEG>
<SEG end_char="170" id="segment-1" start_char="109">
<ORIGINAL_TEXT>There is evidence that the coronavirus was created on purpose.</ORIGINAL_TEXT>
<TOKEN end_char="113" id="token-1-0" morph="none" pos="word" start_char="109">There</TOKEN>
<TOKEN end_char="116" id="token-1-1" morph="none" pos="word" start_char="115">is</TOKEN>
<TOKEN end_char="125" id="token-1-2" morph="none" pos="word" start_char="118">evidence</TOKEN>
<TOKEN end_char="130" id="token-1-3" morph="none" pos="word" start_char="127">that</TOKEN>
<TOKEN end_char="134" id="token-1-4" morph="none" pos="word" start_char="132">the</TOKEN>
<TOKEN end_char="146" id="token-1-5" morph="none" pos="word" start_char="136">coronavirus</TOKEN>
<TOKEN end_char="150" id="token-1-6" morph="none" pos="word" start_char="148">was</TOKEN>
<TOKEN end_char="158" id="token-1-7" morph="none" pos="word" start_char="152">created</TOKEN>
<TOKEN end_char="161" id="token-1-8" morph="none" pos="word" start_char="160">on</TOKEN>
<TOKEN end_char="169" id="token-1-9" morph="none" pos="word" start_char="163">purpose</TOKEN>
<TOKEN end_char="170" id="token-1-10" morph="none" pos="punct" start_char="170">.</TOKEN>
</SEG>
<SEG end_char="250" id="segment-2" start_char="172">
<ORIGINAL_TEXT>First of all, both the US and the UK have announced the existence of a vaccine.</ORIGINAL_TEXT>
<TOKEN end_char="176" id="token-2-0" morph="none" pos="word" start_char="172">First</TOKEN>
<TOKEN end_char="179" id="token-2-1" morph="none" pos="word" start_char="178">of</TOKEN>
<TOKEN end_char="183" id="token-2-2" morph="none" pos="word" start_char="181">all</TOKEN>
<TOKEN end_char="184" id="token-2-3" morph="none" pos="punct" start_char="184">,</TOKEN>
<TOKEN end_char="189" id="token-2-4" morph="none" pos="word" start_char="186">both</TOKEN>
<TOKEN end_char="193" id="token-2-5" morph="none" pos="word" start_char="191">the</TOKEN>
<TOKEN end_char="196" id="token-2-6" morph="none" pos="word" start_char="195">US</TOKEN>
<TOKEN end_char="200" id="token-2-7" morph="none" pos="word" start_char="198">and</TOKEN>
<TOKEN end_char="204" id="token-2-8" morph="none" pos="word" start_char="202">the</TOKEN>
<TOKEN end_char="207" id="token-2-9" morph="none" pos="word" start_char="206">UK</TOKEN>
<TOKEN end_char="212" id="token-2-10" morph="none" pos="word" start_char="209">have</TOKEN>
<TOKEN end_char="222" id="token-2-11" morph="none" pos="word" start_char="214">announced</TOKEN>
<TOKEN end_char="226" id="token-2-12" morph="none" pos="word" start_char="224">the</TOKEN>
<TOKEN end_char="236" id="token-2-13" morph="none" pos="word" start_char="228">existence</TOKEN>
<TOKEN end_char="239" id="token-2-14" morph="none" pos="word" start_char="238">of</TOKEN>
<TOKEN end_char="241" id="token-2-15" morph="none" pos="word" start_char="241">a</TOKEN>
<TOKEN end_char="249" id="token-2-16" morph="none" pos="word" start_char="243">vaccine</TOKEN>
<TOKEN end_char="250" id="token-2-17" morph="none" pos="punct" start_char="250">.</TOKEN>
</SEG>
<SEG end_char="360" id="segment-3" start_char="252">
<ORIGINAL_TEXT>But any expert knows that it’s not possible to create a vaccine against a virus, which was never seen before.</ORIGINAL_TEXT>
<TOKEN end_char="254" id="token-3-0" morph="none" pos="word" start_char="252">But</TOKEN>
<TOKEN end_char="258" id="token-3-1" morph="none" pos="word" start_char="256">any</TOKEN>
<TOKEN end_char="265" id="token-3-2" morph="none" pos="word" start_char="260">expert</TOKEN>
<TOKEN end_char="271" id="token-3-3" morph="none" pos="word" start_char="267">knows</TOKEN>
<TOKEN end_char="276" id="token-3-4" morph="none" pos="word" start_char="273">that</TOKEN>
<TOKEN end_char="281" id="token-3-5" morph="none" pos="word" start_char="278">it’s</TOKEN>
<TOKEN end_char="285" id="token-3-6" morph="none" pos="word" start_char="283">not</TOKEN>
<TOKEN end_char="294" id="token-3-7" morph="none" pos="word" start_char="287">possible</TOKEN>
<TOKEN end_char="297" id="token-3-8" morph="none" pos="word" start_char="296">to</TOKEN>
<TOKEN end_char="304" id="token-3-9" morph="none" pos="word" start_char="299">create</TOKEN>
<TOKEN end_char="306" id="token-3-10" morph="none" pos="word" start_char="306">a</TOKEN>
<TOKEN end_char="314" id="token-3-11" morph="none" pos="word" start_char="308">vaccine</TOKEN>
<TOKEN end_char="322" id="token-3-12" morph="none" pos="word" start_char="316">against</TOKEN>
<TOKEN end_char="324" id="token-3-13" morph="none" pos="word" start_char="324">a</TOKEN>
<TOKEN end_char="330" id="token-3-14" morph="none" pos="word" start_char="326">virus</TOKEN>
<TOKEN end_char="331" id="token-3-15" morph="none" pos="punct" start_char="331">,</TOKEN>
<TOKEN end_char="337" id="token-3-16" morph="none" pos="word" start_char="333">which</TOKEN>
<TOKEN end_char="341" id="token-3-17" morph="none" pos="word" start_char="339">was</TOKEN>
<TOKEN end_char="347" id="token-3-18" morph="none" pos="word" start_char="343">never</TOKEN>
<TOKEN end_char="352" id="token-3-19" morph="none" pos="word" start_char="349">seen</TOKEN>
<TOKEN end_char="359" id="token-3-20" morph="none" pos="word" start_char="354">before</TOKEN>
<TOKEN end_char="360" id="token-3-21" morph="none" pos="punct" start_char="360">.</TOKEN>
</SEG>
<SEG end_char="542" id="segment-4" start_char="362">
<ORIGINAL_TEXT>In UK the Porton Down laboratory, a quite well known organisation which has been dealing with chemical and biological weapons for a long time has said they already have the vaccine.</ORIGINAL_TEXT>
<TOKEN end_char="363" id="token-4-0" morph="none" pos="word" start_char="362">In</TOKEN>
<TOKEN end_char="366" id="token-4-1" morph="none" pos="word" start_char="365">UK</TOKEN>
<TOKEN end_char="370" id="token-4-2" morph="none" pos="word" start_char="368">the</TOKEN>
<TOKEN end_char="377" id="token-4-3" morph="none" pos="word" start_char="372">Porton</TOKEN>
<TOKEN end_char="382" id="token-4-4" morph="none" pos="word" start_char="379">Down</TOKEN>
<TOKEN end_char="393" id="token-4-5" morph="none" pos="word" start_char="384">laboratory</TOKEN>
<TOKEN end_char="394" id="token-4-6" morph="none" pos="punct" start_char="394">,</TOKEN>
<TOKEN end_char="396" id="token-4-7" morph="none" pos="word" start_char="396">a</TOKEN>
<TOKEN end_char="402" id="token-4-8" morph="none" pos="word" start_char="398">quite</TOKEN>
<TOKEN end_char="407" id="token-4-9" morph="none" pos="word" start_char="404">well</TOKEN>
<TOKEN end_char="413" id="token-4-10" morph="none" pos="word" start_char="409">known</TOKEN>
<TOKEN end_char="426" id="token-4-11" morph="none" pos="word" start_char="415">organisation</TOKEN>
<TOKEN end_char="432" id="token-4-12" morph="none" pos="word" start_char="428">which</TOKEN>
<TOKEN end_char="436" id="token-4-13" morph="none" pos="word" start_char="434">has</TOKEN>
<TOKEN end_char="441" id="token-4-14" morph="none" pos="word" start_char="438">been</TOKEN>
<TOKEN end_char="449" id="token-4-15" morph="none" pos="word" start_char="443">dealing</TOKEN>
<TOKEN end_char="454" id="token-4-16" morph="none" pos="word" start_char="451">with</TOKEN>
<TOKEN end_char="463" id="token-4-17" morph="none" pos="word" start_char="456">chemical</TOKEN>
<TOKEN end_char="467" id="token-4-18" morph="none" pos="word" start_char="465">and</TOKEN>
<TOKEN end_char="478" id="token-4-19" morph="none" pos="word" start_char="469">biological</TOKEN>
<TOKEN end_char="486" id="token-4-20" morph="none" pos="word" start_char="480">weapons</TOKEN>
<TOKEN end_char="490" id="token-4-21" morph="none" pos="word" start_char="488">for</TOKEN>
<TOKEN end_char="492" id="token-4-22" morph="none" pos="word" start_char="492">a</TOKEN>
<TOKEN end_char="497" id="token-4-23" morph="none" pos="word" start_char="494">long</TOKEN>
<TOKEN end_char="502" id="token-4-24" morph="none" pos="word" start_char="499">time</TOKEN>
<TOKEN end_char="506" id="token-4-25" morph="none" pos="word" start_char="504">has</TOKEN>
<TOKEN end_char="511" id="token-4-26" morph="none" pos="word" start_char="508">said</TOKEN>
<TOKEN end_char="516" id="token-4-27" morph="none" pos="word" start_char="513">they</TOKEN>
<TOKEN end_char="524" id="token-4-28" morph="none" pos="word" start_char="518">already</TOKEN>
<TOKEN end_char="529" id="token-4-29" morph="none" pos="word" start_char="526">have</TOKEN>
<TOKEN end_char="533" id="token-4-30" morph="none" pos="word" start_char="531">the</TOKEN>
<TOKEN end_char="541" id="token-4-31" morph="none" pos="word" start_char="535">vaccine</TOKEN>
<TOKEN end_char="542" id="token-4-32" morph="none" pos="punct" start_char="542">.</TOKEN>
</SEG>
<SEG end_char="606" id="segment-5" start_char="544">
<ORIGINAL_TEXT>According to media, they have patented it already one year ago!</ORIGINAL_TEXT>
<TOKEN end_char="552" id="token-5-0" morph="none" pos="word" start_char="544">According</TOKEN>
<TOKEN end_char="555" id="token-5-1" morph="none" pos="word" start_char="554">to</TOKEN>
<TOKEN end_char="561" id="token-5-2" morph="none" pos="word" start_char="557">media</TOKEN>
<TOKEN end_char="562" id="token-5-3" morph="none" pos="punct" start_char="562">,</TOKEN>
<TOKEN end_char="567" id="token-5-4" morph="none" pos="word" start_char="564">they</TOKEN>
<TOKEN end_char="572" id="token-5-5" morph="none" pos="word" start_char="569">have</TOKEN>
<TOKEN end_char="581" id="token-5-6" morph="none" pos="word" start_char="574">patented</TOKEN>
<TOKEN end_char="584" id="token-5-7" morph="none" pos="word" start_char="583">it</TOKEN>
<TOKEN end_char="592" id="token-5-8" morph="none" pos="word" start_char="586">already</TOKEN>
<TOKEN end_char="596" id="token-5-9" morph="none" pos="word" start_char="594">one</TOKEN>
<TOKEN end_char="601" id="token-5-10" morph="none" pos="word" start_char="598">year</TOKEN>
<TOKEN end_char="605" id="token-5-11" morph="none" pos="word" start_char="603">ago</TOKEN>
<TOKEN end_char="606" id="token-5-12" morph="none" pos="punct" start_char="606">!</TOKEN>
</SEG>
<SEG end_char="688" id="segment-6" start_char="609">
<ORIGINAL_TEXT>This is the same organisation which put the poison on the Skripals’ door handle.</ORIGINAL_TEXT>
<TOKEN end_char="612" id="token-6-0" morph="none" pos="word" start_char="609">This</TOKEN>
<TOKEN end_char="615" id="token-6-1" morph="none" pos="word" start_char="614">is</TOKEN>
<TOKEN end_char="619" id="token-6-2" morph="none" pos="word" start_char="617">the</TOKEN>
<TOKEN end_char="624" id="token-6-3" morph="none" pos="word" start_char="621">same</TOKEN>
<TOKEN end_char="637" id="token-6-4" morph="none" pos="word" start_char="626">organisation</TOKEN>
<TOKEN end_char="643" id="token-6-5" morph="none" pos="word" start_char="639">which</TOKEN>
<TOKEN end_char="647" id="token-6-6" morph="none" pos="word" start_char="645">put</TOKEN>
<TOKEN end_char="651" id="token-6-7" morph="none" pos="word" start_char="649">the</TOKEN>
<TOKEN end_char="658" id="token-6-8" morph="none" pos="word" start_char="653">poison</TOKEN>
<TOKEN end_char="661" id="token-6-9" morph="none" pos="word" start_char="660">on</TOKEN>
<TOKEN end_char="665" id="token-6-10" morph="none" pos="word" start_char="663">the</TOKEN>
<TOKEN end_char="674" id="token-6-11" morph="none" pos="word" start_char="667">Skripals</TOKEN>
<TOKEN end_char="675" id="token-6-12" morph="none" pos="punct" start_char="675">’</TOKEN>
<TOKEN end_char="680" id="token-6-13" morph="none" pos="word" start_char="677">door</TOKEN>
<TOKEN end_char="687" id="token-6-14" morph="none" pos="word" start_char="682">handle</TOKEN>
<TOKEN end_char="688" id="token-6-15" morph="none" pos="punct" start_char="688">.</TOKEN>
</SEG>
<SEG end_char="914" id="segment-7" start_char="690">
<ORIGINAL_TEXT>Probably they put something also over the city of Wuhan, Hubei province, for example, on the door handle of the subway, or rather not the door handle but this one [thing, object] which is being touched by thousands of people.</ORIGINAL_TEXT>
<TOKEN end_char="697" id="token-7-0" morph="none" pos="word" start_char="690">Probably</TOKEN>
<TOKEN end_char="702" id="token-7-1" morph="none" pos="word" start_char="699">they</TOKEN>
<TOKEN end_char="706" id="token-7-2" morph="none" pos="word" start_char="704">put</TOKEN>
<TOKEN end_char="716" id="token-7-3" morph="none" pos="word" start_char="708">something</TOKEN>
<TOKEN end_char="721" id="token-7-4" morph="none" pos="word" start_char="718">also</TOKEN>
<TOKEN end_char="726" id="token-7-5" morph="none" pos="word" start_char="723">over</TOKEN>
<TOKEN end_char="730" id="token-7-6" morph="none" pos="word" start_char="728">the</TOKEN>
<TOKEN end_char="735" id="token-7-7" morph="none" pos="word" start_char="732">city</TOKEN>
<TOKEN end_char="738" id="token-7-8" morph="none" pos="word" start_char="737">of</TOKEN>
<TOKEN end_char="744" id="token-7-9" morph="none" pos="word" start_char="740">Wuhan</TOKEN>
<TOKEN end_char="745" id="token-7-10" morph="none" pos="punct" start_char="745">,</TOKEN>
<TOKEN end_char="751" id="token-7-11" morph="none" pos="word" start_char="747">Hubei</TOKEN>
<TOKEN end_char="760" id="token-7-12" morph="none" pos="word" start_char="753">province</TOKEN>
<TOKEN end_char="761" id="token-7-13" morph="none" pos="punct" start_char="761">,</TOKEN>
<TOKEN end_char="765" id="token-7-14" morph="none" pos="word" start_char="763">for</TOKEN>
<TOKEN end_char="773" id="token-7-15" morph="none" pos="word" start_char="767">example</TOKEN>
<TOKEN end_char="774" id="token-7-16" morph="none" pos="punct" start_char="774">,</TOKEN>
<TOKEN end_char="777" id="token-7-17" morph="none" pos="word" start_char="776">on</TOKEN>
<TOKEN end_char="781" id="token-7-18" morph="none" pos="word" start_char="779">the</TOKEN>
<TOKEN end_char="786" id="token-7-19" morph="none" pos="word" start_char="783">door</TOKEN>
<TOKEN end_char="793" id="token-7-20" morph="none" pos="word" start_char="788">handle</TOKEN>
<TOKEN end_char="796" id="token-7-21" morph="none" pos="word" start_char="795">of</TOKEN>
<TOKEN end_char="800" id="token-7-22" morph="none" pos="word" start_char="798">the</TOKEN>
<TOKEN end_char="807" id="token-7-23" morph="none" pos="word" start_char="802">subway</TOKEN>
<TOKEN end_char="808" id="token-7-24" morph="none" pos="punct" start_char="808">,</TOKEN>
<TOKEN end_char="811" id="token-7-25" morph="none" pos="word" start_char="810">or</TOKEN>
<TOKEN end_char="818" id="token-7-26" morph="none" pos="word" start_char="813">rather</TOKEN>
<TOKEN end_char="822" id="token-7-27" morph="none" pos="word" start_char="820">not</TOKEN>
<TOKEN end_char="826" id="token-7-28" morph="none" pos="word" start_char="824">the</TOKEN>
<TOKEN end_char="831" id="token-7-29" morph="none" pos="word" start_char="828">door</TOKEN>
<TOKEN end_char="838" id="token-7-30" morph="none" pos="word" start_char="833">handle</TOKEN>
<TOKEN end_char="842" id="token-7-31" morph="none" pos="word" start_char="840">but</TOKEN>
<TOKEN end_char="847" id="token-7-32" morph="none" pos="word" start_char="844">this</TOKEN>
<TOKEN end_char="851" id="token-7-33" morph="none" pos="word" start_char="849">one</TOKEN>
<TOKEN end_char="853" id="token-7-34" morph="none" pos="punct" start_char="853">[</TOKEN>
<TOKEN end_char="858" id="token-7-35" morph="none" pos="word" start_char="854">thing</TOKEN>
<TOKEN end_char="859" id="token-7-36" morph="none" pos="punct" start_char="859">,</TOKEN>
<TOKEN end_char="866" id="token-7-37" morph="none" pos="word" start_char="861">object</TOKEN>
<TOKEN end_char="867" id="token-7-38" morph="none" pos="punct" start_char="867">]</TOKEN>
<TOKEN end_char="873" id="token-7-39" morph="none" pos="word" start_char="869">which</TOKEN>
<TOKEN end_char="876" id="token-7-40" morph="none" pos="word" start_char="875">is</TOKEN>
<TOKEN end_char="882" id="token-7-41" morph="none" pos="word" start_char="878">being</TOKEN>
<TOKEN end_char="890" id="token-7-42" morph="none" pos="word" start_char="884">touched</TOKEN>
<TOKEN end_char="893" id="token-7-43" morph="none" pos="word" start_char="892">by</TOKEN>
<TOKEN end_char="903" id="token-7-44" morph="none" pos="word" start_char="895">thousands</TOKEN>
<TOKEN end_char="906" id="token-7-45" morph="none" pos="word" start_char="905">of</TOKEN>
<TOKEN end_char="913" id="token-7-46" morph="none" pos="word" start_char="908">people</TOKEN>
<TOKEN end_char="914" id="token-7-47" morph="none" pos="punct" start_char="914">.</TOKEN>
</SEG>
<SEG end_char="964" id="segment-8" start_char="916">
<ORIGINAL_TEXT>Unfortunately, we can’t exclude such a situation.</ORIGINAL_TEXT>
<TOKEN end_char="928" id="token-8-0" morph="none" pos="word" start_char="916">Unfortunately</TOKEN>
<TOKEN end_char="929" id="token-8-1" morph="none" pos="punct" start_char="929">,</TOKEN>
<TOKEN end_char="932" id="token-8-2" morph="none" pos="word" start_char="931">we</TOKEN>
<TOKEN end_char="938" id="token-8-3" morph="none" pos="word" start_char="934">can’t</TOKEN>
<TOKEN end_char="946" id="token-8-4" morph="none" pos="word" start_char="940">exclude</TOKEN>
<TOKEN end_char="951" id="token-8-5" morph="none" pos="word" start_char="948">such</TOKEN>
<TOKEN end_char="953" id="token-8-6" morph="none" pos="word" start_char="953">a</TOKEN>
<TOKEN end_char="963" id="token-8-7" morph="none" pos="word" start_char="955">situation</TOKEN>
<TOKEN end_char="964" id="token-8-8" morph="none" pos="punct" start_char="964">.</TOKEN>
</SEG>
<SEG end_char="1110" id="segment-9" start_char="966">
<ORIGINAL_TEXT>It can be an act of biological sabotage, it might have been carried out not by a State, for example, the US, but by certain private corporations.</ORIGINAL_TEXT>
<TOKEN end_char="967" id="token-9-0" morph="none" pos="word" start_char="966">It</TOKEN>
<TOKEN end_char="971" id="token-9-1" morph="none" pos="word" start_char="969">can</TOKEN>
<TOKEN end_char="974" id="token-9-2" morph="none" pos="word" start_char="973">be</TOKEN>
<TOKEN end_char="977" id="token-9-3" morph="none" pos="word" start_char="976">an</TOKEN>
<TOKEN end_char="981" id="token-9-4" morph="none" pos="word" start_char="979">act</TOKEN>
<TOKEN end_char="984" id="token-9-5" morph="none" pos="word" start_char="983">of</TOKEN>
<TOKEN end_char="995" id="token-9-6" morph="none" pos="word" start_char="986">biological</TOKEN>
<TOKEN end_char="1004" id="token-9-7" morph="none" pos="word" start_char="997">sabotage</TOKEN>
<TOKEN end_char="1005" id="token-9-8" morph="none" pos="punct" start_char="1005">,</TOKEN>
<TOKEN end_char="1008" id="token-9-9" morph="none" pos="word" start_char="1007">it</TOKEN>
<TOKEN end_char="1014" id="token-9-10" morph="none" pos="word" start_char="1010">might</TOKEN>
<TOKEN end_char="1019" id="token-9-11" morph="none" pos="word" start_char="1016">have</TOKEN>
<TOKEN end_char="1024" id="token-9-12" morph="none" pos="word" start_char="1021">been</TOKEN>
<TOKEN end_char="1032" id="token-9-13" morph="none" pos="word" start_char="1026">carried</TOKEN>
<TOKEN end_char="1036" id="token-9-14" morph="none" pos="word" start_char="1034">out</TOKEN>
<TOKEN end_char="1040" id="token-9-15" morph="none" pos="word" start_char="1038">not</TOKEN>
<TOKEN end_char="1043" id="token-9-16" morph="none" pos="word" start_char="1042">by</TOKEN>
<TOKEN end_char="1045" id="token-9-17" morph="none" pos="word" start_char="1045">a</TOKEN>
<TOKEN end_char="1051" id="token-9-18" morph="none" pos="word" start_char="1047">State</TOKEN>
<TOKEN end_char="1052" id="token-9-19" morph="none" pos="punct" start_char="1052">,</TOKEN>
<TOKEN end_char="1056" id="token-9-20" morph="none" pos="word" start_char="1054">for</TOKEN>
<TOKEN end_char="1064" id="token-9-21" morph="none" pos="word" start_char="1058">example</TOKEN>
<TOKEN end_char="1065" id="token-9-22" morph="none" pos="punct" start_char="1065">,</TOKEN>
<TOKEN end_char="1069" id="token-9-23" morph="none" pos="word" start_char="1067">the</TOKEN>
<TOKEN end_char="1072" id="token-9-24" morph="none" pos="word" start_char="1071">US</TOKEN>
<TOKEN end_char="1073" id="token-9-25" morph="none" pos="punct" start_char="1073">,</TOKEN>
<TOKEN end_char="1077" id="token-9-26" morph="none" pos="word" start_char="1075">but</TOKEN>
<TOKEN end_char="1080" id="token-9-27" morph="none" pos="word" start_char="1079">by</TOKEN>
<TOKEN end_char="1088" id="token-9-28" morph="none" pos="word" start_char="1082">certain</TOKEN>
<TOKEN end_char="1096" id="token-9-29" morph="none" pos="word" start_char="1090">private</TOKEN>
<TOKEN end_char="1109" id="token-9-30" morph="none" pos="word" start_char="1098">corporations</TOKEN>
<TOKEN end_char="1110" id="token-9-31" morph="none" pos="punct" start_char="1110">.</TOKEN>
</SEG>
<SEG end_char="1245" id="segment-10" start_char="1112">
<ORIGINAL_TEXT>The appearance of such beneficiaries able to go on market already tomorrow with an already made vaccine is a not direct proof of that.</ORIGINAL_TEXT>
<TOKEN end_char="1114" id="token-10-0" morph="none" pos="word" start_char="1112">The</TOKEN>
<TOKEN end_char="1125" id="token-10-1" morph="none" pos="word" start_char="1116">appearance</TOKEN>
<TOKEN end_char="1128" id="token-10-2" morph="none" pos="word" start_char="1127">of</TOKEN>
<TOKEN end_char="1133" id="token-10-3" morph="none" pos="word" start_char="1130">such</TOKEN>
<TOKEN end_char="1147" id="token-10-4" morph="none" pos="word" start_char="1135">beneficiaries</TOKEN>
<TOKEN end_char="1152" id="token-10-5" morph="none" pos="word" start_char="1149">able</TOKEN>
<TOKEN end_char="1155" id="token-10-6" morph="none" pos="word" start_char="1154">to</TOKEN>
<TOKEN end_char="1158" id="token-10-7" morph="none" pos="word" start_char="1157">go</TOKEN>
<TOKEN end_char="1161" id="token-10-8" morph="none" pos="word" start_char="1160">on</TOKEN>
<TOKEN end_char="1168" id="token-10-9" morph="none" pos="word" start_char="1163">market</TOKEN>
<TOKEN end_char="1176" id="token-10-10" morph="none" pos="word" start_char="1170">already</TOKEN>
<TOKEN end_char="1185" id="token-10-11" morph="none" pos="word" start_char="1178">tomorrow</TOKEN>
<TOKEN end_char="1190" id="token-10-12" morph="none" pos="word" start_char="1187">with</TOKEN>
<TOKEN end_char="1193" id="token-10-13" morph="none" pos="word" start_char="1192">an</TOKEN>
<TOKEN end_char="1201" id="token-10-14" morph="none" pos="word" start_char="1195">already</TOKEN>
<TOKEN end_char="1206" id="token-10-15" morph="none" pos="word" start_char="1203">made</TOKEN>
<TOKEN end_char="1214" id="token-10-16" morph="none" pos="word" start_char="1208">vaccine</TOKEN>
<TOKEN end_char="1217" id="token-10-17" morph="none" pos="word" start_char="1216">is</TOKEN>
<TOKEN end_char="1219" id="token-10-18" morph="none" pos="word" start_char="1219">a</TOKEN>
<TOKEN end_char="1223" id="token-10-19" morph="none" pos="word" start_char="1221">not</TOKEN>
<TOKEN end_char="1230" id="token-10-20" morph="none" pos="word" start_char="1225">direct</TOKEN>
<TOKEN end_char="1236" id="token-10-21" morph="none" pos="word" start_char="1232">proof</TOKEN>
<TOKEN end_char="1239" id="token-10-22" morph="none" pos="word" start_char="1238">of</TOKEN>
<TOKEN end_char="1244" id="token-10-23" morph="none" pos="word" start_char="1241">that</TOKEN>
<TOKEN end_char="1245" id="token-10-24" morph="none" pos="punct" start_char="1245">.</TOKEN>
</SEG>
<SEG end_char="1420" id="segment-11" start_char="1248">
<ORIGINAL_TEXT>The statement has no supporting evidence and is another example of conspiracy narratives on a plot against China, profitable to the US; on the UK which invented coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="1250" id="token-11-0" morph="none" pos="word" start_char="1248">The</TOKEN>
<TOKEN end_char="1260" id="token-11-1" morph="none" pos="word" start_char="1252">statement</TOKEN>
<TOKEN end_char="1264" id="token-11-2" morph="none" pos="word" start_char="1262">has</TOKEN>
<TOKEN end_char="1267" id="token-11-3" morph="none" pos="word" start_char="1266">no</TOKEN>
<TOKEN end_char="1278" id="token-11-4" morph="none" pos="word" start_char="1269">supporting</TOKEN>
<TOKEN end_char="1287" id="token-11-5" morph="none" pos="word" start_char="1280">evidence</TOKEN>
<TOKEN end_char="1291" id="token-11-6" morph="none" pos="word" start_char="1289">and</TOKEN>
<TOKEN end_char="1294" id="token-11-7" morph="none" pos="word" start_char="1293">is</TOKEN>
<TOKEN end_char="1302" id="token-11-8" morph="none" pos="word" start_char="1296">another</TOKEN>
<TOKEN end_char="1310" id="token-11-9" morph="none" pos="word" start_char="1304">example</TOKEN>
<TOKEN end_char="1313" id="token-11-10" morph="none" pos="word" start_char="1312">of</TOKEN>
<TOKEN end_char="1324" id="token-11-11" morph="none" pos="word" start_char="1315">conspiracy</TOKEN>
<TOKEN end_char="1335" id="token-11-12" morph="none" pos="word" start_char="1326">narratives</TOKEN>
<TOKEN end_char="1338" id="token-11-13" morph="none" pos="word" start_char="1337">on</TOKEN>
<TOKEN end_char="1340" id="token-11-14" morph="none" pos="word" start_char="1340">a</TOKEN>
<TOKEN end_char="1345" id="token-11-15" morph="none" pos="word" start_char="1342">plot</TOKEN>
<TOKEN end_char="1353" id="token-11-16" morph="none" pos="word" start_char="1347">against</TOKEN>
<TOKEN end_char="1359" id="token-11-17" morph="none" pos="word" start_char="1355">China</TOKEN>
<TOKEN end_char="1360" id="token-11-18" morph="none" pos="punct" start_char="1360">,</TOKEN>
<TOKEN end_char="1371" id="token-11-19" morph="none" pos="word" start_char="1362">profitable</TOKEN>
<TOKEN end_char="1374" id="token-11-20" morph="none" pos="word" start_char="1373">to</TOKEN>
<TOKEN end_char="1378" id="token-11-21" morph="none" pos="word" start_char="1376">the</TOKEN>
<TOKEN end_char="1381" id="token-11-22" morph="none" pos="word" start_char="1380">US</TOKEN>
<TOKEN end_char="1382" id="token-11-23" morph="none" pos="punct" start_char="1382">;</TOKEN>
<TOKEN end_char="1385" id="token-11-24" morph="none" pos="word" start_char="1384">on</TOKEN>
<TOKEN end_char="1389" id="token-11-25" morph="none" pos="word" start_char="1387">the</TOKEN>
<TOKEN end_char="1392" id="token-11-26" morph="none" pos="word" start_char="1391">UK</TOKEN>
<TOKEN end_char="1398" id="token-11-27" morph="none" pos="word" start_char="1394">which</TOKEN>
<TOKEN end_char="1407" id="token-11-28" morph="none" pos="word" start_char="1400">invented</TOKEN>
<TOKEN end_char="1419" id="token-11-29" morph="none" pos="word" start_char="1409">coronavirus</TOKEN>
<TOKEN end_char="1420" id="token-11-30" morph="none" pos="punct" start_char="1420">.</TOKEN>
</SEG>
<SEG end_char="1491" id="segment-12" start_char="1422">
<ORIGINAL_TEXT>See more examples of groundless statements about the coronavirus here.</ORIGINAL_TEXT>
<TOKEN end_char="1424" id="token-12-0" morph="none" pos="word" start_char="1422">See</TOKEN>
<TOKEN end_char="1429" id="token-12-1" morph="none" pos="word" start_char="1426">more</TOKEN>
<TOKEN end_char="1438" id="token-12-2" morph="none" pos="word" start_char="1431">examples</TOKEN>
<TOKEN end_char="1441" id="token-12-3" morph="none" pos="word" start_char="1440">of</TOKEN>
<TOKEN end_char="1452" id="token-12-4" morph="none" pos="word" start_char="1443">groundless</TOKEN>
<TOKEN end_char="1463" id="token-12-5" morph="none" pos="word" start_char="1454">statements</TOKEN>
<TOKEN end_char="1469" id="token-12-6" morph="none" pos="word" start_char="1465">about</TOKEN>
<TOKEN end_char="1473" id="token-12-7" morph="none" pos="word" start_char="1471">the</TOKEN>
<TOKEN end_char="1485" id="token-12-8" morph="none" pos="word" start_char="1475">coronavirus</TOKEN>
<TOKEN end_char="1490" id="token-12-9" morph="none" pos="word" start_char="1487">here</TOKEN>
<TOKEN end_char="1491" id="token-12-10" morph="none" pos="punct" start_char="1491">.</TOKEN>
</SEG>
<SEG end_char="1609" id="segment-13" start_char="1494">
<ORIGINAL_TEXT>The current coronavirus (2019-nCoV) comes from a family of viruses that include other viruses such as SARS and MERS.</ORIGINAL_TEXT>
<TOKEN end_char="1496" id="token-13-0" morph="none" pos="word" start_char="1494">The</TOKEN>
<TOKEN end_char="1504" id="token-13-1" morph="none" pos="word" start_char="1498">current</TOKEN>
<TOKEN end_char="1516" id="token-13-2" morph="none" pos="word" start_char="1506">coronavirus</TOKEN>
<TOKEN end_char="1518" id="token-13-3" morph="none" pos="punct" start_char="1518">(</TOKEN>
<TOKEN end_char="1527" id="token-13-4" morph="none" pos="unknown" start_char="1519">2019-nCoV</TOKEN>
<TOKEN end_char="1528" id="token-13-5" morph="none" pos="punct" start_char="1528">)</TOKEN>
<TOKEN end_char="1534" id="token-13-6" morph="none" pos="word" start_char="1530">comes</TOKEN>
<TOKEN end_char="1539" id="token-13-7" morph="none" pos="word" start_char="1536">from</TOKEN>
<TOKEN end_char="1541" id="token-13-8" morph="none" pos="word" start_char="1541">a</TOKEN>
<TOKEN end_char="1548" id="token-13-9" morph="none" pos="word" start_char="1543">family</TOKEN>
<TOKEN end_char="1551" id="token-13-10" morph="none" pos="word" start_char="1550">of</TOKEN>
<TOKEN end_char="1559" id="token-13-11" morph="none" pos="word" start_char="1553">viruses</TOKEN>
<TOKEN end_char="1564" id="token-13-12" morph="none" pos="word" start_char="1561">that</TOKEN>
<TOKEN end_char="1572" id="token-13-13" morph="none" pos="word" start_char="1566">include</TOKEN>
<TOKEN end_char="1578" id="token-13-14" morph="none" pos="word" start_char="1574">other</TOKEN>
<TOKEN end_char="1586" id="token-13-15" morph="none" pos="word" start_char="1580">viruses</TOKEN>
<TOKEN end_char="1591" id="token-13-16" morph="none" pos="word" start_char="1588">such</TOKEN>
<TOKEN end_char="1594" id="token-13-17" morph="none" pos="word" start_char="1593">as</TOKEN>
<TOKEN end_char="1599" id="token-13-18" morph="none" pos="word" start_char="1596">SARS</TOKEN>
<TOKEN end_char="1603" id="token-13-19" morph="none" pos="word" start_char="1601">and</TOKEN>
<TOKEN end_char="1608" id="token-13-20" morph="none" pos="word" start_char="1605">MERS</TOKEN>
<TOKEN end_char="1609" id="token-13-21" morph="none" pos="punct" start_char="1609">.</TOKEN>
</SEG>
<SEG end_char="1869" id="segment-14" start_char="1611">
<ORIGINAL_TEXT>It was first reported in the Chinese city of Wuhan in central China and has been rapidly spreading with new cases being reported in the Asia-Pacific region as well as Europe, North America and the Middle East, causing more than 700 deaths by 10 February 2020.</ORIGINAL_TEXT>
<TOKEN end_char="1612" id="token-14-0" morph="none" pos="word" start_char="1611">It</TOKEN>
<TOKEN end_char="1616" id="token-14-1" morph="none" pos="word" start_char="1614">was</TOKEN>
<TOKEN end_char="1622" id="token-14-2" morph="none" pos="word" start_char="1618">first</TOKEN>
<TOKEN end_char="1631" id="token-14-3" morph="none" pos="word" start_char="1624">reported</TOKEN>
<TOKEN end_char="1634" id="token-14-4" morph="none" pos="word" start_char="1633">in</TOKEN>
<TOKEN end_char="1638" id="token-14-5" morph="none" pos="word" start_char="1636">the</TOKEN>
<TOKEN end_char="1646" id="token-14-6" morph="none" pos="word" start_char="1640">Chinese</TOKEN>
<TOKEN end_char="1651" id="token-14-7" morph="none" pos="word" start_char="1648">city</TOKEN>
<TOKEN end_char="1654" id="token-14-8" morph="none" pos="word" start_char="1653">of</TOKEN>
<TOKEN end_char="1660" id="token-14-9" morph="none" pos="word" start_char="1656">Wuhan</TOKEN>
<TOKEN end_char="1663" id="token-14-10" morph="none" pos="word" start_char="1662">in</TOKEN>
<TOKEN end_char="1671" id="token-14-11" morph="none" pos="word" start_char="1665">central</TOKEN>
<TOKEN end_char="1677" id="token-14-12" morph="none" pos="word" start_char="1673">China</TOKEN>
<TOKEN end_char="1681" id="token-14-13" morph="none" pos="word" start_char="1679">and</TOKEN>
<TOKEN end_char="1685" id="token-14-14" morph="none" pos="word" start_char="1683">has</TOKEN>
<TOKEN end_char="1690" id="token-14-15" morph="none" pos="word" start_char="1687">been</TOKEN>
<TOKEN end_char="1698" id="token-14-16" morph="none" pos="word" start_char="1692">rapidly</TOKEN>
<TOKEN end_char="1708" id="token-14-17" morph="none" pos="word" start_char="1700">spreading</TOKEN>
<TOKEN end_char="1713" id="token-14-18" morph="none" pos="word" start_char="1710">with</TOKEN>
<TOKEN end_char="1717" id="token-14-19" morph="none" pos="word" start_char="1715">new</TOKEN>
<TOKEN end_char="1723" id="token-14-20" morph="none" pos="word" start_char="1719">cases</TOKEN>
<TOKEN end_char="1729" id="token-14-21" morph="none" pos="word" start_char="1725">being</TOKEN>
<TOKEN end_char="1738" id="token-14-22" morph="none" pos="word" start_char="1731">reported</TOKEN>
<TOKEN end_char="1741" id="token-14-23" morph="none" pos="word" start_char="1740">in</TOKEN>
<TOKEN end_char="1745" id="token-14-24" morph="none" pos="word" start_char="1743">the</TOKEN>
<TOKEN end_char="1758" id="token-14-25" morph="none" pos="unknown" start_char="1747">Asia-Pacific</TOKEN>
<TOKEN end_char="1765" id="token-14-26" morph="none" pos="word" start_char="1760">region</TOKEN>
<TOKEN end_char="1768" id="token-14-27" morph="none" pos="word" start_char="1767">as</TOKEN>
<TOKEN end_char="1773" id="token-14-28" morph="none" pos="word" start_char="1770">well</TOKEN>
<TOKEN end_char="1776" id="token-14-29" morph="none" pos="word" start_char="1775">as</TOKEN>
<TOKEN end_char="1783" id="token-14-30" morph="none" pos="word" start_char="1778">Europe</TOKEN>
<TOKEN end_char="1784" id="token-14-31" morph="none" pos="punct" start_char="1784">,</TOKEN>
<TOKEN end_char="1790" id="token-14-32" morph="none" pos="word" start_char="1786">North</TOKEN>
<TOKEN end_char="1798" id="token-14-33" morph="none" pos="word" start_char="1792">America</TOKEN>
<TOKEN end_char="1802" id="token-14-34" morph="none" pos="word" start_char="1800">and</TOKEN>
<TOKEN end_char="1806" id="token-14-35" morph="none" pos="word" start_char="1804">the</TOKEN>
<TOKEN end_char="1813" id="token-14-36" morph="none" pos="word" start_char="1808">Middle</TOKEN>
<TOKEN end_char="1818" id="token-14-37" morph="none" pos="word" start_char="1815">East</TOKEN>
<TOKEN end_char="1819" id="token-14-38" morph="none" pos="punct" start_char="1819">,</TOKEN>
<TOKEN end_char="1827" id="token-14-39" morph="none" pos="word" start_char="1821">causing</TOKEN>
<TOKEN end_char="1832" id="token-14-40" morph="none" pos="word" start_char="1829">more</TOKEN>
<TOKEN end_char="1837" id="token-14-41" morph="none" pos="word" start_char="1834">than</TOKEN>
<TOKEN end_char="1841" id="token-14-42" morph="none" pos="word" start_char="1839">700</TOKEN>
<TOKEN end_char="1848" id="token-14-43" morph="none" pos="word" start_char="1843">deaths</TOKEN>
<TOKEN end_char="1851" id="token-14-44" morph="none" pos="word" start_char="1850">by</TOKEN>
<TOKEN end_char="1854" id="token-14-45" morph="none" pos="word" start_char="1853">10</TOKEN>
<TOKEN end_char="1863" id="token-14-46" morph="none" pos="word" start_char="1856">February</TOKEN>
<TOKEN end_char="1868" id="token-14-47" morph="none" pos="word" start_char="1865">2020</TOKEN>
<TOKEN end_char="1869" id="token-14-48" morph="none" pos="punct" start_char="1869">.</TOKEN>
</SEG>
<SEG end_char="1996" id="segment-15" start_char="1872">
<ORIGINAL_TEXT>The identity of the animal source of the coronavirus, named nCoV-2019, has been one of the key questions for the researchers.</ORIGINAL_TEXT>
<TOKEN end_char="1874" id="token-15-0" morph="none" pos="word" start_char="1872">The</TOKEN>
<TOKEN end_char="1883" id="token-15-1" morph="none" pos="word" start_char="1876">identity</TOKEN>
<TOKEN end_char="1886" id="token-15-2" morph="none" pos="word" start_char="1885">of</TOKEN>
<TOKEN end_char="1890" id="token-15-3" morph="none" pos="word" start_char="1888">the</TOKEN>
<TOKEN end_char="1897" id="token-15-4" morph="none" pos="word" start_char="1892">animal</TOKEN>
<TOKEN end_char="1904" id="token-15-5" morph="none" pos="word" start_char="1899">source</TOKEN>
<TOKEN end_char="1907" id="token-15-6" morph="none" pos="word" start_char="1906">of</TOKEN>
<TOKEN end_char="1911" id="token-15-7" morph="none" pos="word" start_char="1909">the</TOKEN>
<TOKEN end_char="1923" id="token-15-8" morph="none" pos="word" start_char="1913">coronavirus</TOKEN>
<TOKEN end_char="1924" id="token-15-9" morph="none" pos="punct" start_char="1924">,</TOKEN>
<TOKEN end_char="1930" id="token-15-10" morph="none" pos="word" start_char="1926">named</TOKEN>
<TOKEN end_char="1940" id="token-15-11" morph="none" pos="unknown" start_char="1932">nCoV-2019</TOKEN>
<TOKEN end_char="1941" id="token-15-12" morph="none" pos="punct" start_char="1941">,</TOKEN>
<TOKEN end_char="1945" id="token-15-13" morph="none" pos="word" start_char="1943">has</TOKEN>
<TOKEN end_char="1950" id="token-15-14" morph="none" pos="word" start_char="1947">been</TOKEN>
<TOKEN end_char="1954" id="token-15-15" morph="none" pos="word" start_char="1952">one</TOKEN>
<TOKEN end_char="1957" id="token-15-16" morph="none" pos="word" start_char="1956">of</TOKEN>
<TOKEN end_char="1961" id="token-15-17" morph="none" pos="word" start_char="1959">the</TOKEN>
<TOKEN end_char="1965" id="token-15-18" morph="none" pos="word" start_char="1963">key</TOKEN>
<TOKEN end_char="1975" id="token-15-19" morph="none" pos="word" start_char="1967">questions</TOKEN>
<TOKEN end_char="1979" id="token-15-20" morph="none" pos="word" start_char="1977">for</TOKEN>
<TOKEN end_char="1983" id="token-15-21" morph="none" pos="word" start_char="1981">the</TOKEN>
<TOKEN end_char="1995" id="token-15-22" morph="none" pos="word" start_char="1985">researchers</TOKEN>
<TOKEN end_char="1996" id="token-15-23" morph="none" pos="punct" start_char="1996">.</TOKEN>
</SEG>
<SEG end_char="2135" id="segment-16" start_char="1998">
<ORIGINAL_TEXT>Coronaviruses are known to circulate in mammals and birds, and scientists have already suggested that nCoV-2019 originally came from bats.</ORIGINAL_TEXT>
<TOKEN end_char="2010" id="token-16-0" morph="none" pos="word" start_char="1998">Coronaviruses</TOKEN>
<TOKEN end_char="2014" id="token-16-1" morph="none" pos="word" start_char="2012">are</TOKEN>
<TOKEN end_char="2020" id="token-16-2" morph="none" pos="word" start_char="2016">known</TOKEN>
<TOKEN end_char="2023" id="token-16-3" morph="none" pos="word" start_char="2022">to</TOKEN>
<TOKEN end_char="2033" id="token-16-4" morph="none" pos="word" start_char="2025">circulate</TOKEN>
<TOKEN end_char="2036" id="token-16-5" morph="none" pos="word" start_char="2035">in</TOKEN>
<TOKEN end_char="2044" id="token-16-6" morph="none" pos="word" start_char="2038">mammals</TOKEN>
<TOKEN end_char="2048" id="token-16-7" morph="none" pos="word" start_char="2046">and</TOKEN>
<TOKEN end_char="2054" id="token-16-8" morph="none" pos="word" start_char="2050">birds</TOKEN>
<TOKEN end_char="2055" id="token-16-9" morph="none" pos="punct" start_char="2055">,</TOKEN>
<TOKEN end_char="2059" id="token-16-10" morph="none" pos="word" start_char="2057">and</TOKEN>
<TOKEN end_char="2070" id="token-16-11" morph="none" pos="word" start_char="2061">scientists</TOKEN>
<TOKEN end_char="2075" id="token-16-12" morph="none" pos="word" start_char="2072">have</TOKEN>
<TOKEN end_char="2083" id="token-16-13" morph="none" pos="word" start_char="2077">already</TOKEN>
<TOKEN end_char="2093" id="token-16-14" morph="none" pos="word" start_char="2085">suggested</TOKEN>
<TOKEN end_char="2098" id="token-16-15" morph="none" pos="word" start_char="2095">that</TOKEN>
<TOKEN end_char="2108" id="token-16-16" morph="none" pos="unknown" start_char="2100">nCoV-2019</TOKEN>
<TOKEN end_char="2119" id="token-16-17" morph="none" pos="word" start_char="2110">originally</TOKEN>
<TOKEN end_char="2124" id="token-16-18" morph="none" pos="word" start_char="2121">came</TOKEN>
<TOKEN end_char="2129" id="token-16-19" morph="none" pos="word" start_char="2126">from</TOKEN>
<TOKEN end_char="2134" id="token-16-20" morph="none" pos="word" start_char="2131">bats</TOKEN>
<TOKEN end_char="2135" id="token-16-21" morph="none" pos="punct" start_char="2135">.</TOKEN>
</SEG>
<SEG end_char="2267" id="segment-17" start_char="2137">
<ORIGINAL_TEXT>One of the previous coronaviruses that caused severe acute respiratory syndrome, or SARS, spread from bats to civet cats to humans.</ORIGINAL_TEXT>
<TOKEN end_char="2139" id="token-17-0" morph="none" pos="word" start_char="2137">One</TOKEN>
<TOKEN end_char="2142" id="token-17-1" morph="none" pos="word" start_char="2141">of</TOKEN>
<TOKEN end_char="2146" id="token-17-2" morph="none" pos="word" start_char="2144">the</TOKEN>
<TOKEN end_char="2155" id="token-17-3" morph="none" pos="word" start_char="2148">previous</TOKEN>
<TOKEN end_char="2169" id="token-17-4" morph="none" pos="word" start_char="2157">coronaviruses</TOKEN>
<TOKEN end_char="2174" id="token-17-5" morph="none" pos="word" start_char="2171">that</TOKEN>
<TOKEN end_char="2181" id="token-17-6" morph="none" pos="word" start_char="2176">caused</TOKEN>
<TOKEN end_char="2188" id="token-17-7" morph="none" pos="word" start_char="2183">severe</TOKEN>
<TOKEN end_char="2194" id="token-17-8" morph="none" pos="word" start_char="2190">acute</TOKEN>
<TOKEN end_char="2206" id="token-17-9" morph="none" pos="word" start_char="2196">respiratory</TOKEN>
<TOKEN end_char="2215" id="token-17-10" morph="none" pos="word" start_char="2208">syndrome</TOKEN>
<TOKEN end_char="2216" id="token-17-11" morph="none" pos="punct" start_char="2216">,</TOKEN>
<TOKEN end_char="2219" id="token-17-12" morph="none" pos="word" start_char="2218">or</TOKEN>
<TOKEN end_char="2224" id="token-17-13" morph="none" pos="word" start_char="2221">SARS</TOKEN>
<TOKEN end_char="2225" id="token-17-14" morph="none" pos="punct" start_char="2225">,</TOKEN>
<TOKEN end_char="2232" id="token-17-15" morph="none" pos="word" start_char="2227">spread</TOKEN>
<TOKEN end_char="2237" id="token-17-16" morph="none" pos="word" start_char="2234">from</TOKEN>
<TOKEN end_char="2242" id="token-17-17" morph="none" pos="word" start_char="2239">bats</TOKEN>
<TOKEN end_char="2245" id="token-17-18" morph="none" pos="word" start_char="2244">to</TOKEN>
<TOKEN end_char="2251" id="token-17-19" morph="none" pos="word" start_char="2247">civet</TOKEN>
<TOKEN end_char="2256" id="token-17-20" morph="none" pos="word" start_char="2253">cats</TOKEN>
<TOKEN end_char="2259" id="token-17-21" morph="none" pos="word" start_char="2258">to</TOKEN>
<TOKEN end_char="2266" id="token-17-22" morph="none" pos="word" start_char="2261">humans</TOKEN>
<TOKEN end_char="2267" id="token-17-23" morph="none" pos="punct" start_char="2267">.</TOKEN>
</SEG>
<SEG end_char="2426" id="segment-18" start_char="2270">
<ORIGINAL_TEXT>Now, the South China Agricultural University in Guangzhou says that two of its researchers have identified the pangolin as the potential source of nCoV-2019.</ORIGINAL_TEXT>
<TOKEN end_char="2272" id="token-18-0" morph="none" pos="word" start_char="2270">Now</TOKEN>
<TOKEN end_char="2273" id="token-18-1" morph="none" pos="punct" start_char="2273">,</TOKEN>
<TOKEN end_char="2277" id="token-18-2" morph="none" pos="word" start_char="2275">the</TOKEN>
<TOKEN end_char="2283" id="token-18-3" morph="none" pos="word" start_char="2279">South</TOKEN>
<TOKEN end_char="2289" id="token-18-4" morph="none" pos="word" start_char="2285">China</TOKEN>
<TOKEN end_char="2302" id="token-18-5" morph="none" pos="word" start_char="2291">Agricultural</TOKEN>
<TOKEN end_char="2313" id="token-18-6" morph="none" pos="word" start_char="2304">University</TOKEN>
<TOKEN end_char="2316" id="token-18-7" morph="none" pos="word" start_char="2315">in</TOKEN>
<TOKEN end_char="2326" id="token-18-8" morph="none" pos="word" start_char="2318">Guangzhou</TOKEN>
<TOKEN end_char="2331" id="token-18-9" morph="none" pos="word" start_char="2328">says</TOKEN>
<TOKEN end_char="2336" id="token-18-10" morph="none" pos="word" start_char="2333">that</TOKEN>
<TOKEN end_char="2340" id="token-18-11" morph="none" pos="word" start_char="2338">two</TOKEN>
<TOKEN end_char="2343" id="token-18-12" morph="none" pos="word" start_char="2342">of</TOKEN>
<TOKEN end_char="2347" id="token-18-13" morph="none" pos="word" start_char="2345">its</TOKEN>
<TOKEN end_char="2359" id="token-18-14" morph="none" pos="word" start_char="2349">researchers</TOKEN>
<TOKEN end_char="2364" id="token-18-15" morph="none" pos="word" start_char="2361">have</TOKEN>
<TOKEN end_char="2375" id="token-18-16" morph="none" pos="word" start_char="2366">identified</TOKEN>
<TOKEN end_char="2379" id="token-18-17" morph="none" pos="word" start_char="2377">the</TOKEN>
<TOKEN end_char="2388" id="token-18-18" morph="none" pos="word" start_char="2381">pangolin</TOKEN>
<TOKEN end_char="2391" id="token-18-19" morph="none" pos="word" start_char="2390">as</TOKEN>
<TOKEN end_char="2395" id="token-18-20" morph="none" pos="word" start_char="2393">the</TOKEN>
<TOKEN end_char="2405" id="token-18-21" morph="none" pos="word" start_char="2397">potential</TOKEN>
<TOKEN end_char="2412" id="token-18-22" morph="none" pos="word" start_char="2407">source</TOKEN>
<TOKEN end_char="2415" id="token-18-23" morph="none" pos="word" start_char="2414">of</TOKEN>
<TOKEN end_char="2425" id="token-18-24" morph="none" pos="unknown" start_char="2417">nCoV-2019</TOKEN>
<TOKEN end_char="2426" id="token-18-25" morph="none" pos="punct" start_char="2426">.</TOKEN>
</SEG>
<SEG end_char="2500" id="segment-19" start_char="2428">
<ORIGINAL_TEXT>This was announced to reporters at a press conference on 7 February 2020.</ORIGINAL_TEXT>
<TOKEN end_char="2431" id="token-19-0" morph="none" pos="word" start_char="2428">This</TOKEN>
<TOKEN end_char="2435" id="token-19-1" morph="none" pos="word" start_char="2433">was</TOKEN>
<TOKEN end_char="2445" id="token-19-2" morph="none" pos="word" start_char="2437">announced</TOKEN>
<TOKEN end_char="2448" id="token-19-3" morph="none" pos="word" start_char="2447">to</TOKEN>
<TOKEN end_char="2458" id="token-19-4" morph="none" pos="word" start_char="2450">reporters</TOKEN>
<TOKEN end_char="2461" id="token-19-5" morph="none" pos="word" start_char="2460">at</TOKEN>
<TOKEN end_char="2463" id="token-19-6" morph="none" pos="word" start_char="2463">a</TOKEN>
<TOKEN end_char="2469" id="token-19-7" morph="none" pos="word" start_char="2465">press</TOKEN>
<TOKEN end_char="2480" id="token-19-8" morph="none" pos="word" start_char="2471">conference</TOKEN>
<TOKEN end_char="2483" id="token-19-9" morph="none" pos="word" start_char="2482">on</TOKEN>
<TOKEN end_char="2485" id="token-19-10" morph="none" pos="word" start_char="2485">7</TOKEN>
<TOKEN end_char="2494" id="token-19-11" morph="none" pos="word" start_char="2487">February</TOKEN>
<TOKEN end_char="2499" id="token-19-12" morph="none" pos="word" start_char="2496">2020</TOKEN>
<TOKEN end_char="2500" id="token-19-13" morph="none" pos="punct" start_char="2500">.</TOKEN>
</SEG>
<SEG end_char="2652" id="segment-20" start_char="2503">
<ORIGINAL_TEXT>As for the statement that British scientists from Porton Down laboratory put poison on the Skripals' door handle, it is not supported by any evidence.</ORIGINAL_TEXT>
<TOKEN end_char="2504" id="token-20-0" morph="none" pos="word" start_char="2503">As</TOKEN>
<TOKEN end_char="2508" id="token-20-1" morph="none" pos="word" start_char="2506">for</TOKEN>
<TOKEN end_char="2512" id="token-20-2" morph="none" pos="word" start_char="2510">the</TOKEN>
<TOKEN end_char="2522" id="token-20-3" morph="none" pos="word" start_char="2514">statement</TOKEN>
<TOKEN end_char="2527" id="token-20-4" morph="none" pos="word" start_char="2524">that</TOKEN>
<TOKEN end_char="2535" id="token-20-5" morph="none" pos="word" start_char="2529">British</TOKEN>
<TOKEN end_char="2546" id="token-20-6" morph="none" pos="word" start_char="2537">scientists</TOKEN>
<TOKEN end_char="2551" id="token-20-7" morph="none" pos="word" start_char="2548">from</TOKEN>
<TOKEN end_char="2558" id="token-20-8" morph="none" pos="word" start_char="2553">Porton</TOKEN>
<TOKEN end_char="2563" id="token-20-9" morph="none" pos="word" start_char="2560">Down</TOKEN>
<TOKEN end_char="2574" id="token-20-10" morph="none" pos="word" start_char="2565">laboratory</TOKEN>
<TOKEN end_char="2578" id="token-20-11" morph="none" pos="word" start_char="2576">put</TOKEN>
<TOKEN end_char="2585" id="token-20-12" morph="none" pos="word" start_char="2580">poison</TOKEN>
<TOKEN end_char="2588" id="token-20-13" morph="none" pos="word" start_char="2587">on</TOKEN>
<TOKEN end_char="2592" id="token-20-14" morph="none" pos="word" start_char="2590">the</TOKEN>
<TOKEN end_char="2601" id="token-20-15" morph="none" pos="word" start_char="2594">Skripals</TOKEN>
<TOKEN end_char="2602" id="token-20-16" morph="none" pos="punct" start_char="2602">'</TOKEN>
<TOKEN end_char="2607" id="token-20-17" morph="none" pos="word" start_char="2604">door</TOKEN>
<TOKEN end_char="2614" id="token-20-18" morph="none" pos="word" start_char="2609">handle</TOKEN>
<TOKEN end_char="2615" id="token-20-19" morph="none" pos="punct" start_char="2615">,</TOKEN>
<TOKEN end_char="2618" id="token-20-20" morph="none" pos="word" start_char="2617">it</TOKEN>
<TOKEN end_char="2621" id="token-20-21" morph="none" pos="word" start_char="2620">is</TOKEN>
<TOKEN end_char="2625" id="token-20-22" morph="none" pos="word" start_char="2623">not</TOKEN>
<TOKEN end_char="2635" id="token-20-23" morph="none" pos="word" start_char="2627">supported</TOKEN>
<TOKEN end_char="2638" id="token-20-24" morph="none" pos="word" start_char="2637">by</TOKEN>
<TOKEN end_char="2642" id="token-20-25" morph="none" pos="word" start_char="2640">any</TOKEN>
<TOKEN end_char="2651" id="token-20-26" morph="none" pos="word" start_char="2644">evidence</TOKEN>
<TOKEN end_char="2652" id="token-20-27" morph="none" pos="punct" start_char="2652">.</TOKEN>
</SEG>
<SEG end_char="2888" id="segment-21" start_char="2654">
<ORIGINAL_TEXT>British police and intelligence investigations have produced hard forensic evidence which was sufficient to charge two Russian nationals, identified as officers of the Russian Military Intelligence, GRU, for the attack on the Skripals.</ORIGINAL_TEXT>
<TOKEN end_char="2660" id="token-21-0" morph="none" pos="word" start_char="2654">British</TOKEN>
<TOKEN end_char="2667" id="token-21-1" morph="none" pos="word" start_char="2662">police</TOKEN>
<TOKEN end_char="2671" id="token-21-2" morph="none" pos="word" start_char="2669">and</TOKEN>
<TOKEN end_char="2684" id="token-21-3" morph="none" pos="word" start_char="2673">intelligence</TOKEN>
<TOKEN end_char="2699" id="token-21-4" morph="none" pos="word" start_char="2686">investigations</TOKEN>
<TOKEN end_char="2704" id="token-21-5" morph="none" pos="word" start_char="2701">have</TOKEN>
<TOKEN end_char="2713" id="token-21-6" morph="none" pos="word" start_char="2706">produced</TOKEN>
<TOKEN end_char="2718" id="token-21-7" morph="none" pos="word" start_char="2715">hard</TOKEN>
<TOKEN end_char="2727" id="token-21-8" morph="none" pos="word" start_char="2720">forensic</TOKEN>
<TOKEN end_char="2736" id="token-21-9" morph="none" pos="word" start_char="2729">evidence</TOKEN>
<TOKEN end_char="2742" id="token-21-10" morph="none" pos="word" start_char="2738">which</TOKEN>
<TOKEN end_char="2746" id="token-21-11" morph="none" pos="word" start_char="2744">was</TOKEN>
<TOKEN end_char="2757" id="token-21-12" morph="none" pos="word" start_char="2748">sufficient</TOKEN>
<TOKEN end_char="2760" id="token-21-13" morph="none" pos="word" start_char="2759">to</TOKEN>
<TOKEN end_char="2767" id="token-21-14" morph="none" pos="word" start_char="2762">charge</TOKEN>
<TOKEN end_char="2771" id="token-21-15" morph="none" pos="word" start_char="2769">two</TOKEN>
<TOKEN end_char="2779" id="token-21-16" morph="none" pos="word" start_char="2773">Russian</TOKEN>
<TOKEN end_char="2789" id="token-21-17" morph="none" pos="word" start_char="2781">nationals</TOKEN>
<TOKEN end_char="2790" id="token-21-18" morph="none" pos="punct" start_char="2790">,</TOKEN>
<TOKEN end_char="2801" id="token-21-19" morph="none" pos="word" start_char="2792">identified</TOKEN>
<TOKEN end_char="2804" id="token-21-20" morph="none" pos="word" start_char="2803">as</TOKEN>
<TOKEN end_char="2813" id="token-21-21" morph="none" pos="word" start_char="2806">officers</TOKEN>
<TOKEN end_char="2816" id="token-21-22" morph="none" pos="word" start_char="2815">of</TOKEN>
<TOKEN end_char="2820" id="token-21-23" morph="none" pos="word" start_char="2818">the</TOKEN>
<TOKEN end_char="2828" id="token-21-24" morph="none" pos="word" start_char="2822">Russian</TOKEN>
<TOKEN end_char="2837" id="token-21-25" morph="none" pos="word" start_char="2830">Military</TOKEN>
<TOKEN end_char="2850" id="token-21-26" morph="none" pos="word" start_char="2839">Intelligence</TOKEN>
<TOKEN end_char="2851" id="token-21-27" morph="none" pos="punct" start_char="2851">,</TOKEN>
<TOKEN end_char="2855" id="token-21-28" morph="none" pos="word" start_char="2853">GRU</TOKEN>
<TOKEN end_char="2856" id="token-21-29" morph="none" pos="punct" start_char="2856">,</TOKEN>
<TOKEN end_char="2860" id="token-21-30" morph="none" pos="word" start_char="2858">for</TOKEN>
<TOKEN end_char="2864" id="token-21-31" morph="none" pos="word" start_char="2862">the</TOKEN>
<TOKEN end_char="2871" id="token-21-32" morph="none" pos="word" start_char="2866">attack</TOKEN>
<TOKEN end_char="2874" id="token-21-33" morph="none" pos="word" start_char="2873">on</TOKEN>
<TOKEN end_char="2878" id="token-21-34" morph="none" pos="word" start_char="2876">the</TOKEN>
<TOKEN end_char="2887" id="token-21-35" morph="none" pos="word" start_char="2880">Skripals</TOKEN>
<TOKEN end_char="2888" id="token-21-36" morph="none" pos="punct" start_char="2888">.</TOKEN>
</SEG>
<SEG end_char="2942" id="segment-22" start_char="2890">
<ORIGINAL_TEXT>Part of the material has been released to the public.</ORIGINAL_TEXT>
<TOKEN end_char="2893" id="token-22-0" morph="none" pos="word" start_char="2890">Part</TOKEN>
<TOKEN end_char="2896" id="token-22-1" morph="none" pos="word" start_char="2895">of</TOKEN>
<TOKEN end_char="2900" id="token-22-2" morph="none" pos="word" start_char="2898">the</TOKEN>
<TOKEN end_char="2909" id="token-22-3" morph="none" pos="word" start_char="2902">material</TOKEN>
<TOKEN end_char="2913" id="token-22-4" morph="none" pos="word" start_char="2911">has</TOKEN>
<TOKEN end_char="2918" id="token-22-5" morph="none" pos="word" start_char="2915">been</TOKEN>
<TOKEN end_char="2927" id="token-22-6" morph="none" pos="word" start_char="2920">released</TOKEN>
<TOKEN end_char="2930" id="token-22-7" morph="none" pos="word" start_char="2929">to</TOKEN>
<TOKEN end_char="2934" id="token-22-8" morph="none" pos="word" start_char="2932">the</TOKEN>
<TOKEN end_char="2941" id="token-22-9" morph="none" pos="word" start_char="2936">public</TOKEN>
<TOKEN end_char="2942" id="token-22-10" morph="none" pos="punct" start_char="2942">.</TOKEN>
</SEG>
<SEG end_char="3131" id="segment-23" start_char="2945">
<ORIGINAL_TEXT>See previous pro-Kremlin disinformation cases, alleging that cancer, syphilis and Spanish flu are US biological weapons and that the Rockefeller foundation owns the patent for Zika virus.</ORIGINAL_TEXT>
<TOKEN end_char="2947" id="token-23-0" morph="none" pos="word" start_char="2945">See</TOKEN>
<TOKEN end_char="2956" id="token-23-1" morph="none" pos="word" start_char="2949">previous</TOKEN>
<TOKEN end_char="2968" id="token-23-2" morph="none" pos="unknown" start_char="2958">pro-Kremlin</TOKEN>
<TOKEN end_char="2983" id="token-23-3" morph="none" pos="word" start_char="2970">disinformation</TOKEN>
<TOKEN end_char="2989" id="token-23-4" morph="none" pos="word" start_char="2985">cases</TOKEN>
<TOKEN end_char="2990" id="token-23-5" morph="none" pos="punct" start_char="2990">,</TOKEN>
<TOKEN end_char="2999" id="token-23-6" morph="none" pos="word" start_char="2992">alleging</TOKEN>
<TOKEN end_char="3004" id="token-23-7" morph="none" pos="word" start_char="3001">that</TOKEN>
<TOKEN end_char="3011" id="token-23-8" morph="none" pos="word" start_char="3006">cancer</TOKEN>
<TOKEN end_char="3012" id="token-23-9" morph="none" pos="punct" start_char="3012">,</TOKEN>
<TOKEN end_char="3021" id="token-23-10" morph="none" pos="word" start_char="3014">syphilis</TOKEN>
<TOKEN end_char="3025" id="token-23-11" morph="none" pos="word" start_char="3023">and</TOKEN>
<TOKEN end_char="3033" id="token-23-12" morph="none" pos="word" start_char="3027">Spanish</TOKEN>
<TOKEN end_char="3037" id="token-23-13" morph="none" pos="word" start_char="3035">flu</TOKEN>
<TOKEN end_char="3041" id="token-23-14" morph="none" pos="word" start_char="3039">are</TOKEN>
<TOKEN end_char="3044" id="token-23-15" morph="none" pos="word" start_char="3043">US</TOKEN>
<TOKEN end_char="3055" id="token-23-16" morph="none" pos="word" start_char="3046">biological</TOKEN>
<TOKEN end_char="3063" id="token-23-17" morph="none" pos="word" start_char="3057">weapons</TOKEN>
<TOKEN end_char="3067" id="token-23-18" morph="none" pos="word" start_char="3065">and</TOKEN>
<TOKEN end_char="3072" id="token-23-19" morph="none" pos="word" start_char="3069">that</TOKEN>
<TOKEN end_char="3076" id="token-23-20" morph="none" pos="word" start_char="3074">the</TOKEN>
<TOKEN end_char="3088" id="token-23-21" morph="none" pos="word" start_char="3078">Rockefeller</TOKEN>
<TOKEN end_char="3099" id="token-23-22" morph="none" pos="word" start_char="3090">foundation</TOKEN>
<TOKEN end_char="3104" id="token-23-23" morph="none" pos="word" start_char="3101">owns</TOKEN>
<TOKEN end_char="3108" id="token-23-24" morph="none" pos="word" start_char="3106">the</TOKEN>
<TOKEN end_char="3115" id="token-23-25" morph="none" pos="word" start_char="3110">patent</TOKEN>
<TOKEN end_char="3119" id="token-23-26" morph="none" pos="word" start_char="3117">for</TOKEN>
<TOKEN end_char="3124" id="token-23-27" morph="none" pos="word" start_char="3121">Zika</TOKEN>
<TOKEN end_char="3130" id="token-23-28" morph="none" pos="word" start_char="3126">virus</TOKEN>
<TOKEN end_char="3131" id="token-23-29" morph="none" pos="punct" start_char="3131">.</TOKEN>
</SEG>
<SEG end_char="3194" id="segment-24" start_char="3133">
<ORIGINAL_TEXT>See also more disinformation cases on the Skripal's poisoning.</ORIGINAL_TEXT>
<TOKEN end_char="3135" id="token-24-0" morph="none" pos="word" start_char="3133">See</TOKEN>
<TOKEN end_char="3140" id="token-24-1" morph="none" pos="word" start_char="3137">also</TOKEN>
<TOKEN end_char="3145" id="token-24-2" morph="none" pos="word" start_char="3142">more</TOKEN>
<TOKEN end_char="3160" id="token-24-3" morph="none" pos="word" start_char="3147">disinformation</TOKEN>
<TOKEN end_char="3166" id="token-24-4" morph="none" pos="word" start_char="3162">cases</TOKEN>
<TOKEN end_char="3169" id="token-24-5" morph="none" pos="word" start_char="3168">on</TOKEN>
<TOKEN end_char="3173" id="token-24-6" morph="none" pos="word" start_char="3171">the</TOKEN>
<TOKEN end_char="3183" id="token-24-7" morph="none" pos="word" start_char="3175">Skripal's</TOKEN>
<TOKEN end_char="3193" id="token-24-8" morph="none" pos="word" start_char="3185">poisoning</TOKEN>
<TOKEN end_char="3194" id="token-24-9" morph="none" pos="punct" start_char="3194">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
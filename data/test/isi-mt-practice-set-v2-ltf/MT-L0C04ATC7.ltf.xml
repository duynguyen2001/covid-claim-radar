<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATC7" lang="spa" raw_text_char_length="3294" raw_text_md5="337933a80c9c075c9a4379fcae9c28f3" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="124" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Expertos cuestionan nueva hipótesis sobre el origen y la transmisión inicial del coronavirus que vincula a perros callejeros</ORIGINAL_TEXT>
<TOKEN end_char="8" id="token-0-0" morph="none" pos="word" start_char="1">Expertos</TOKEN>
<TOKEN end_char="19" id="token-0-1" morph="none" pos="word" start_char="10">cuestionan</TOKEN>
<TOKEN end_char="25" id="token-0-2" morph="none" pos="word" start_char="21">nueva</TOKEN>
<TOKEN end_char="35" id="token-0-3" morph="none" pos="word" start_char="27">hipótesis</TOKEN>
<TOKEN end_char="41" id="token-0-4" morph="none" pos="word" start_char="37">sobre</TOKEN>
<TOKEN end_char="44" id="token-0-5" morph="none" pos="word" start_char="43">el</TOKEN>
<TOKEN end_char="51" id="token-0-6" morph="none" pos="word" start_char="46">origen</TOKEN>
<TOKEN end_char="53" id="token-0-7" morph="none" pos="word" start_char="53">y</TOKEN>
<TOKEN end_char="56" id="token-0-8" morph="none" pos="word" start_char="55">la</TOKEN>
<TOKEN end_char="68" id="token-0-9" morph="none" pos="word" start_char="58">transmisión</TOKEN>
<TOKEN end_char="76" id="token-0-10" morph="none" pos="word" start_char="70">inicial</TOKEN>
<TOKEN end_char="80" id="token-0-11" morph="none" pos="word" start_char="78">del</TOKEN>
<TOKEN end_char="92" id="token-0-12" morph="none" pos="word" start_char="82">coronavirus</TOKEN>
<TOKEN end_char="96" id="token-0-13" morph="none" pos="word" start_char="94">que</TOKEN>
<TOKEN end_char="104" id="token-0-14" morph="none" pos="word" start_char="98">vincula</TOKEN>
<TOKEN end_char="106" id="token-0-15" morph="none" pos="word" start_char="106">a</TOKEN>
<TOKEN end_char="113" id="token-0-16" morph="none" pos="word" start_char="108">perros</TOKEN>
<TOKEN end_char="124" id="token-0-17" morph="none" pos="word" start_char="115">callejeros</TOKEN>
<TRANSLATED_TEXT>Experts question new hypotheses about the origin and initial transmission of the coronavirus that links street dogs</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="394" id="segment-1" start_char="128">
<ORIGINAL_TEXT>Un reciente estudio sugiere que los perros callejeros, en especial el tejido de sus intestinos, podrían haber contribuido a la evolución de un progenitor del SARS-CoV-2, que apunta la necesidad de incluir a los canes salvajes en los programas de vigilancias de virus.</ORIGINAL_TEXT>
<TOKEN end_char="129" id="token-1-0" morph="none" pos="word" start_char="128">Un</TOKEN>
<TOKEN end_char="138" id="token-1-1" morph="none" pos="word" start_char="131">reciente</TOKEN>
<TOKEN end_char="146" id="token-1-2" morph="none" pos="word" start_char="140">estudio</TOKEN>
<TOKEN end_char="154" id="token-1-3" morph="none" pos="word" start_char="148">sugiere</TOKEN>
<TOKEN end_char="158" id="token-1-4" morph="none" pos="word" start_char="156">que</TOKEN>
<TOKEN end_char="162" id="token-1-5" morph="none" pos="word" start_char="160">los</TOKEN>
<TOKEN end_char="169" id="token-1-6" morph="none" pos="word" start_char="164">perros</TOKEN>
<TOKEN end_char="180" id="token-1-7" morph="none" pos="word" start_char="171">callejeros</TOKEN>
<TOKEN end_char="181" id="token-1-8" morph="none" pos="punct" start_char="181">,</TOKEN>
<TOKEN end_char="184" id="token-1-9" morph="none" pos="word" start_char="183">en</TOKEN>
<TOKEN end_char="193" id="token-1-10" morph="none" pos="word" start_char="186">especial</TOKEN>
<TOKEN end_char="196" id="token-1-11" morph="none" pos="word" start_char="195">el</TOKEN>
<TOKEN end_char="203" id="token-1-12" morph="none" pos="word" start_char="198">tejido</TOKEN>
<TOKEN end_char="206" id="token-1-13" morph="none" pos="word" start_char="205">de</TOKEN>
<TOKEN end_char="210" id="token-1-14" morph="none" pos="word" start_char="208">sus</TOKEN>
<TOKEN end_char="221" id="token-1-15" morph="none" pos="word" start_char="212">intestinos</TOKEN>
<TOKEN end_char="222" id="token-1-16" morph="none" pos="punct" start_char="222">,</TOKEN>
<TOKEN end_char="230" id="token-1-17" morph="none" pos="word" start_char="224">podrían</TOKEN>
<TOKEN end_char="236" id="token-1-18" morph="none" pos="word" start_char="232">haber</TOKEN>
<TOKEN end_char="248" id="token-1-19" morph="none" pos="word" start_char="238">contribuido</TOKEN>
<TOKEN end_char="250" id="token-1-20" morph="none" pos="word" start_char="250">a</TOKEN>
<TOKEN end_char="253" id="token-1-21" morph="none" pos="word" start_char="252">la</TOKEN>
<TOKEN end_char="263" id="token-1-22" morph="none" pos="word" start_char="255">evolución</TOKEN>
<TOKEN end_char="266" id="token-1-23" morph="none" pos="word" start_char="265">de</TOKEN>
<TOKEN end_char="269" id="token-1-24" morph="none" pos="word" start_char="268">un</TOKEN>
<TOKEN end_char="280" id="token-1-25" morph="none" pos="word" start_char="271">progenitor</TOKEN>
<TOKEN end_char="284" id="token-1-26" morph="none" pos="word" start_char="282">del</TOKEN>
<TOKEN end_char="295" id="token-1-27" morph="none" pos="unknown" start_char="286">SARS-CoV-2</TOKEN>
<TOKEN end_char="296" id="token-1-28" morph="none" pos="punct" start_char="296">,</TOKEN>
<TOKEN end_char="300" id="token-1-29" morph="none" pos="word" start_char="298">que</TOKEN>
<TOKEN end_char="307" id="token-1-30" morph="none" pos="word" start_char="302">apunta</TOKEN>
<TOKEN end_char="310" id="token-1-31" morph="none" pos="word" start_char="309">la</TOKEN>
<TOKEN end_char="320" id="token-1-32" morph="none" pos="word" start_char="312">necesidad</TOKEN>
<TOKEN end_char="323" id="token-1-33" morph="none" pos="word" start_char="322">de</TOKEN>
<TOKEN end_char="331" id="token-1-34" morph="none" pos="word" start_char="325">incluir</TOKEN>
<TOKEN end_char="333" id="token-1-35" morph="none" pos="word" start_char="333">a</TOKEN>
<TOKEN end_char="337" id="token-1-36" morph="none" pos="word" start_char="335">los</TOKEN>
<TOKEN end_char="343" id="token-1-37" morph="none" pos="word" start_char="339">canes</TOKEN>
<TOKEN end_char="352" id="token-1-38" morph="none" pos="word" start_char="345">salvajes</TOKEN>
<TOKEN end_char="355" id="token-1-39" morph="none" pos="word" start_char="354">en</TOKEN>
<TOKEN end_char="359" id="token-1-40" morph="none" pos="word" start_char="357">los</TOKEN>
<TOKEN end_char="369" id="token-1-41" morph="none" pos="word" start_char="361">programas</TOKEN>
<TOKEN end_char="372" id="token-1-42" morph="none" pos="word" start_char="371">de</TOKEN>
<TOKEN end_char="384" id="token-1-43" morph="none" pos="word" start_char="374">vigilancias</TOKEN>
<TOKEN end_char="387" id="token-1-44" morph="none" pos="word" start_char="386">de</TOKEN>
<TOKEN end_char="393" id="token-1-45" morph="none" pos="word" start_char="389">virus</TOKEN>
<TOKEN end_char="394" id="token-1-46" morph="none" pos="punct" start_char="394">.</TOKEN>
<TRANSLATED_TEXT>A recent study suggests that street dogs, especially their gut tissue, may have contributed to the evolution of a parent of SARS-CoV-2, which points to the need to include wild dogs in virus surveillance programs.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="460" id="segment-2" start_char="397">
<ORIGINAL_TEXT>Este estudio, de la Universidad de Ottawa (Canadá) y que publica</ORIGINAL_TEXT>
<TOKEN end_char="400" id="token-2-0" morph="none" pos="word" start_char="397">Este</TOKEN>
<TOKEN end_char="408" id="token-2-1" morph="none" pos="word" start_char="402">estudio</TOKEN>
<TOKEN end_char="409" id="token-2-2" morph="none" pos="punct" start_char="409">,</TOKEN>
<TOKEN end_char="412" id="token-2-3" morph="none" pos="word" start_char="411">de</TOKEN>
<TOKEN end_char="415" id="token-2-4" morph="none" pos="word" start_char="414">la</TOKEN>
<TOKEN end_char="427" id="token-2-5" morph="none" pos="word" start_char="417">Universidad</TOKEN>
<TOKEN end_char="430" id="token-2-6" morph="none" pos="word" start_char="429">de</TOKEN>
<TOKEN end_char="437" id="token-2-7" morph="none" pos="word" start_char="432">Ottawa</TOKEN>
<TOKEN end_char="439" id="token-2-8" morph="none" pos="punct" start_char="439">(</TOKEN>
<TOKEN end_char="445" id="token-2-9" morph="none" pos="word" start_char="440">Canadá</TOKEN>
<TOKEN end_char="446" id="token-2-10" morph="none" pos="punct" start_char="446">)</TOKEN>
<TOKEN end_char="448" id="token-2-11" morph="none" pos="word" start_char="448">y</TOKEN>
<TOKEN end_char="452" id="token-2-12" morph="none" pos="word" start_char="450">que</TOKEN>
<TOKEN end_char="460" id="token-2-13" morph="none" pos="word" start_char="454">publica</TOKEN>
<TRANSLATED_TEXT>This study, from the University of Ottawa (Canada) and published by</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="493" id="segment-3" start_char="463">
<ORIGINAL_TEXT>Molecular Biology and Evolution</ORIGINAL_TEXT>
<TOKEN end_char="471" id="token-3-0" morph="none" pos="word" start_char="463">Molecular</TOKEN>
<TOKEN end_char="479" id="token-3-1" morph="none" pos="word" start_char="473">Biology</TOKEN>
<TOKEN end_char="483" id="token-3-2" morph="none" pos="word" start_char="481">and</TOKEN>
<TOKEN end_char="493" id="token-3-3" morph="none" pos="word" start_char="485">Evolution</TOKEN>
</SEG>
<SEG end_char="591" id="segment-4" start_char="496">
<ORIGINAL_TEXT>, proponer así una nueva hipótesis sobre el origen y transmisión inicial del actual coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="496" id="token-4-0" morph="none" pos="punct" start_char="496">,</TOKEN>
<TOKEN end_char="505" id="token-4-1" morph="none" pos="word" start_char="498">proponer</TOKEN>
<TOKEN end_char="509" id="token-4-2" morph="none" pos="word" start_char="507">así</TOKEN>
<TOKEN end_char="513" id="token-4-3" morph="none" pos="word" start_char="511">una</TOKEN>
<TOKEN end_char="519" id="token-4-4" morph="none" pos="word" start_char="515">nueva</TOKEN>
<TOKEN end_char="529" id="token-4-5" morph="none" pos="word" start_char="521">hipótesis</TOKEN>
<TOKEN end_char="535" id="token-4-6" morph="none" pos="word" start_char="531">sobre</TOKEN>
<TOKEN end_char="538" id="token-4-7" morph="none" pos="word" start_char="537">el</TOKEN>
<TOKEN end_char="545" id="token-4-8" morph="none" pos="word" start_char="540">origen</TOKEN>
<TOKEN end_char="547" id="token-4-9" morph="none" pos="word" start_char="547">y</TOKEN>
<TOKEN end_char="559" id="token-4-10" morph="none" pos="word" start_char="549">transmisión</TOKEN>
<TOKEN end_char="567" id="token-4-11" morph="none" pos="word" start_char="561">inicial</TOKEN>
<TOKEN end_char="571" id="token-4-12" morph="none" pos="word" start_char="569">del</TOKEN>
<TOKEN end_char="578" id="token-4-13" morph="none" pos="word" start_char="573">actual</TOKEN>
<TOKEN end_char="590" id="token-4-14" morph="none" pos="word" start_char="580">coronavirus</TOKEN>
<TOKEN end_char="591" id="token-4-15" morph="none" pos="punct" start_char="591">.</TOKEN>
<TRANSLATED_TEXT>, to propose a new hypothesis on the origin and initial transmission of the current coronavirus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="749" id="segment-5" start_char="593">
<ORIGINAL_TEXT>En otras investigaciones se ha indicado que los pangolines habían sido los intermediarios del SARS-CoV-2 para llegar desde los murciélagos hasta los humanos.</ORIGINAL_TEXT>
<TOKEN end_char="594" id="token-5-0" morph="none" pos="word" start_char="593">En</TOKEN>
<TOKEN end_char="600" id="token-5-1" morph="none" pos="word" start_char="596">otras</TOKEN>
<TOKEN end_char="616" id="token-5-2" morph="none" pos="word" start_char="602">investigaciones</TOKEN>
<TOKEN end_char="619" id="token-5-3" morph="none" pos="word" start_char="618">se</TOKEN>
<TOKEN end_char="622" id="token-5-4" morph="none" pos="word" start_char="621">ha</TOKEN>
<TOKEN end_char="631" id="token-5-5" morph="none" pos="word" start_char="624">indicado</TOKEN>
<TOKEN end_char="635" id="token-5-6" morph="none" pos="word" start_char="633">que</TOKEN>
<TOKEN end_char="639" id="token-5-7" morph="none" pos="word" start_char="637">los</TOKEN>
<TOKEN end_char="650" id="token-5-8" morph="none" pos="word" start_char="641">pangolines</TOKEN>
<TOKEN end_char="657" id="token-5-9" morph="none" pos="word" start_char="652">habían</TOKEN>
<TOKEN end_char="662" id="token-5-10" morph="none" pos="word" start_char="659">sido</TOKEN>
<TOKEN end_char="666" id="token-5-11" morph="none" pos="word" start_char="664">los</TOKEN>
<TOKEN end_char="681" id="token-5-12" morph="none" pos="word" start_char="668">intermediarios</TOKEN>
<TOKEN end_char="685" id="token-5-13" morph="none" pos="word" start_char="683">del</TOKEN>
<TOKEN end_char="696" id="token-5-14" morph="none" pos="unknown" start_char="687">SARS-CoV-2</TOKEN>
<TOKEN end_char="701" id="token-5-15" morph="none" pos="word" start_char="698">para</TOKEN>
<TOKEN end_char="708" id="token-5-16" morph="none" pos="word" start_char="703">llegar</TOKEN>
<TOKEN end_char="714" id="token-5-17" morph="none" pos="word" start_char="710">desde</TOKEN>
<TOKEN end_char="718" id="token-5-18" morph="none" pos="word" start_char="716">los</TOKEN>
<TOKEN end_char="730" id="token-5-19" morph="none" pos="word" start_char="720">murciélagos</TOKEN>
<TOKEN end_char="736" id="token-5-20" morph="none" pos="word" start_char="732">hasta</TOKEN>
<TOKEN end_char="740" id="token-5-21" morph="none" pos="word" start_char="738">los</TOKEN>
<TOKEN end_char="748" id="token-5-22" morph="none" pos="word" start_char="742">humanos</TOKEN>
<TOKEN end_char="749" id="token-5-23" morph="none" pos="punct" start_char="749">.</TOKEN>
<TRANSLATED_TEXT>Other research has indicated that pangolins had been the intermediaries for SARS-CoV-2 to reach from bats to humans.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1151" id="segment-6" start_char="752">
<ORIGINAL_TEXT>El ancestro del SARS-Cov-2 y de su pariente más cercano, un coronavirus de murciélago, "infectó el intestino de cánidos, lo que muy probablemente dio lugar a una rápida evolución del virus en los cánidos y su salto a los humanos", considera el autor del estudio Xuhua Xia, quien considera importante vigilar los coronavirus similares al SARS en los perros salvajes para la lucha contra el SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN end_char="753" id="token-6-0" morph="none" pos="word" start_char="752">El</TOKEN>
<TOKEN end_char="762" id="token-6-1" morph="none" pos="word" start_char="755">ancestro</TOKEN>
<TOKEN end_char="766" id="token-6-2" morph="none" pos="word" start_char="764">del</TOKEN>
<TOKEN end_char="777" id="token-6-3" morph="none" pos="unknown" start_char="768">SARS-Cov-2</TOKEN>
<TOKEN end_char="779" id="token-6-4" morph="none" pos="word" start_char="779">y</TOKEN>
<TOKEN end_char="782" id="token-6-5" morph="none" pos="word" start_char="781">de</TOKEN>
<TOKEN end_char="785" id="token-6-6" morph="none" pos="word" start_char="784">su</TOKEN>
<TOKEN end_char="794" id="token-6-7" morph="none" pos="word" start_char="787">pariente</TOKEN>
<TOKEN end_char="798" id="token-6-8" morph="none" pos="word" start_char="796">más</TOKEN>
<TOKEN end_char="806" id="token-6-9" morph="none" pos="word" start_char="800">cercano</TOKEN>
<TOKEN end_char="807" id="token-6-10" morph="none" pos="punct" start_char="807">,</TOKEN>
<TOKEN end_char="810" id="token-6-11" morph="none" pos="word" start_char="809">un</TOKEN>
<TOKEN end_char="822" id="token-6-12" morph="none" pos="word" start_char="812">coronavirus</TOKEN>
<TOKEN end_char="825" id="token-6-13" morph="none" pos="word" start_char="824">de</TOKEN>
<TOKEN end_char="836" id="token-6-14" morph="none" pos="word" start_char="827">murciélago</TOKEN>
<TOKEN end_char="837" id="token-6-15" morph="none" pos="punct" start_char="837">,</TOKEN>
<TOKEN end_char="839" id="token-6-16" morph="none" pos="punct" start_char="839">"</TOKEN>
<TOKEN end_char="846" id="token-6-17" morph="none" pos="word" start_char="840">infectó</TOKEN>
<TOKEN end_char="849" id="token-6-18" morph="none" pos="word" start_char="848">el</TOKEN>
<TOKEN end_char="859" id="token-6-19" morph="none" pos="word" start_char="851">intestino</TOKEN>
<TOKEN end_char="862" id="token-6-20" morph="none" pos="word" start_char="861">de</TOKEN>
<TOKEN end_char="870" id="token-6-21" morph="none" pos="word" start_char="864">cánidos</TOKEN>
<TOKEN end_char="871" id="token-6-22" morph="none" pos="punct" start_char="871">,</TOKEN>
<TOKEN end_char="874" id="token-6-23" morph="none" pos="word" start_char="873">lo</TOKEN>
<TOKEN end_char="878" id="token-6-24" morph="none" pos="word" start_char="876">que</TOKEN>
<TOKEN end_char="882" id="token-6-25" morph="none" pos="word" start_char="880">muy</TOKEN>
<TOKEN end_char="896" id="token-6-26" morph="none" pos="word" start_char="884">probablemente</TOKEN>
<TOKEN end_char="900" id="token-6-27" morph="none" pos="word" start_char="898">dio</TOKEN>
<TOKEN end_char="906" id="token-6-28" morph="none" pos="word" start_char="902">lugar</TOKEN>
<TOKEN end_char="908" id="token-6-29" morph="none" pos="word" start_char="908">a</TOKEN>
<TOKEN end_char="912" id="token-6-30" morph="none" pos="word" start_char="910">una</TOKEN>
<TOKEN end_char="919" id="token-6-31" morph="none" pos="word" start_char="914">rápida</TOKEN>
<TOKEN end_char="929" id="token-6-32" morph="none" pos="word" start_char="921">evolución</TOKEN>
<TOKEN end_char="933" id="token-6-33" morph="none" pos="word" start_char="931">del</TOKEN>
<TOKEN end_char="939" id="token-6-34" morph="none" pos="word" start_char="935">virus</TOKEN>
<TOKEN end_char="942" id="token-6-35" morph="none" pos="word" start_char="941">en</TOKEN>
<TOKEN end_char="946" id="token-6-36" morph="none" pos="word" start_char="944">los</TOKEN>
<TOKEN end_char="954" id="token-6-37" morph="none" pos="word" start_char="948">cánidos</TOKEN>
<TOKEN end_char="956" id="token-6-38" morph="none" pos="word" start_char="956">y</TOKEN>
<TOKEN end_char="959" id="token-6-39" morph="none" pos="word" start_char="958">su</TOKEN>
<TOKEN end_char="965" id="token-6-40" morph="none" pos="word" start_char="961">salto</TOKEN>
<TOKEN end_char="967" id="token-6-41" morph="none" pos="word" start_char="967">a</TOKEN>
<TOKEN end_char="971" id="token-6-42" morph="none" pos="word" start_char="969">los</TOKEN>
<TOKEN end_char="979" id="token-6-43" morph="none" pos="word" start_char="973">humanos</TOKEN>
<TOKEN end_char="981" id="token-6-44" morph="none" pos="punct" start_char="980">",</TOKEN>
<TOKEN end_char="991" id="token-6-45" morph="none" pos="word" start_char="983">considera</TOKEN>
<TOKEN end_char="994" id="token-6-46" morph="none" pos="word" start_char="993">el</TOKEN>
<TOKEN end_char="1000" id="token-6-47" morph="none" pos="word" start_char="996">autor</TOKEN>
<TOKEN end_char="1004" id="token-6-48" morph="none" pos="word" start_char="1002">del</TOKEN>
<TOKEN end_char="1012" id="token-6-49" morph="none" pos="word" start_char="1006">estudio</TOKEN>
<TOKEN end_char="1018" id="token-6-50" morph="none" pos="word" start_char="1014">Xuhua</TOKEN>
<TOKEN end_char="1022" id="token-6-51" morph="none" pos="word" start_char="1020">Xia</TOKEN>
<TOKEN end_char="1023" id="token-6-52" morph="none" pos="punct" start_char="1023">,</TOKEN>
<TOKEN end_char="1029" id="token-6-53" morph="none" pos="word" start_char="1025">quien</TOKEN>
<TOKEN end_char="1039" id="token-6-54" morph="none" pos="word" start_char="1031">considera</TOKEN>
<TOKEN end_char="1050" id="token-6-55" morph="none" pos="word" start_char="1041">importante</TOKEN>
<TOKEN end_char="1058" id="token-6-56" morph="none" pos="word" start_char="1052">vigilar</TOKEN>
<TOKEN end_char="1062" id="token-6-57" morph="none" pos="word" start_char="1060">los</TOKEN>
<TOKEN end_char="1074" id="token-6-58" morph="none" pos="word" start_char="1064">coronavirus</TOKEN>
<TOKEN end_char="1084" id="token-6-59" morph="none" pos="word" start_char="1076">similares</TOKEN>
<TOKEN end_char="1087" id="token-6-60" morph="none" pos="word" start_char="1086">al</TOKEN>
<TOKEN end_char="1092" id="token-6-61" morph="none" pos="word" start_char="1089">SARS</TOKEN>
<TOKEN end_char="1095" id="token-6-62" morph="none" pos="word" start_char="1094">en</TOKEN>
<TOKEN end_char="1099" id="token-6-63" morph="none" pos="word" start_char="1097">los</TOKEN>
<TOKEN end_char="1106" id="token-6-64" morph="none" pos="word" start_char="1101">perros</TOKEN>
<TOKEN end_char="1115" id="token-6-65" morph="none" pos="word" start_char="1108">salvajes</TOKEN>
<TOKEN end_char="1120" id="token-6-66" morph="none" pos="word" start_char="1117">para</TOKEN>
<TOKEN end_char="1123" id="token-6-67" morph="none" pos="word" start_char="1122">la</TOKEN>
<TOKEN end_char="1129" id="token-6-68" morph="none" pos="word" start_char="1125">lucha</TOKEN>
<TOKEN end_char="1136" id="token-6-69" morph="none" pos="word" start_char="1131">contra</TOKEN>
<TOKEN end_char="1139" id="token-6-70" morph="none" pos="word" start_char="1138">el</TOKEN>
<TOKEN end_char="1150" id="token-6-71" morph="none" pos="unknown" start_char="1141">SARS-CoV-2</TOKEN>
<TOKEN end_char="1151" id="token-6-72" morph="none" pos="punct" start_char="1151">.</TOKEN>
<TRANSLATED_TEXT>The ancestor of SARS-Cov-2 and its closest relative, a bat coronavirus, "infected the intestines of canids, which most likely resulted in a rapid evolution of the virus in canids and its jump to humans," considers the author of the study Xuhua Xia, who considers it important to monitor SARS-like coronaviruses in wild dogs for the fight against SARS-CoV-2.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1458" id="segment-7" start_char="1154">
<ORIGINAL_TEXT>Xia lleva tiempo estudiado las firmas moleculares de los virus, pues cuando estos invaden un huésped, sus genomas suelen llevar "las cicatrices de la batalla para luchar y evadir el sistema inmunológico" del infectado a través de cambios y adaptaciones que se encuentran en sus genomas, detalla la agencia</ORIGINAL_TEXT>
<TOKEN end_char="1156" id="token-7-0" morph="none" pos="word" start_char="1154">Xia</TOKEN>
<TOKEN end_char="1162" id="token-7-1" morph="none" pos="word" start_char="1158">lleva</TOKEN>
<TOKEN end_char="1169" id="token-7-2" morph="none" pos="word" start_char="1164">tiempo</TOKEN>
<TOKEN end_char="1179" id="token-7-3" morph="none" pos="word" start_char="1171">estudiado</TOKEN>
<TOKEN end_char="1183" id="token-7-4" morph="none" pos="word" start_char="1181">las</TOKEN>
<TOKEN end_char="1190" id="token-7-5" morph="none" pos="word" start_char="1185">firmas</TOKEN>
<TOKEN end_char="1202" id="token-7-6" morph="none" pos="word" start_char="1192">moleculares</TOKEN>
<TOKEN end_char="1205" id="token-7-7" morph="none" pos="word" start_char="1204">de</TOKEN>
<TOKEN end_char="1209" id="token-7-8" morph="none" pos="word" start_char="1207">los</TOKEN>
<TOKEN end_char="1215" id="token-7-9" morph="none" pos="word" start_char="1211">virus</TOKEN>
<TOKEN end_char="1216" id="token-7-10" morph="none" pos="punct" start_char="1216">,</TOKEN>
<TOKEN end_char="1221" id="token-7-11" morph="none" pos="word" start_char="1218">pues</TOKEN>
<TOKEN end_char="1228" id="token-7-12" morph="none" pos="word" start_char="1223">cuando</TOKEN>
<TOKEN end_char="1234" id="token-7-13" morph="none" pos="word" start_char="1230">estos</TOKEN>
<TOKEN end_char="1242" id="token-7-14" morph="none" pos="word" start_char="1236">invaden</TOKEN>
<TOKEN end_char="1245" id="token-7-15" morph="none" pos="word" start_char="1244">un</TOKEN>
<TOKEN end_char="1253" id="token-7-16" morph="none" pos="word" start_char="1247">huésped</TOKEN>
<TOKEN end_char="1254" id="token-7-17" morph="none" pos="punct" start_char="1254">,</TOKEN>
<TOKEN end_char="1258" id="token-7-18" morph="none" pos="word" start_char="1256">sus</TOKEN>
<TOKEN end_char="1266" id="token-7-19" morph="none" pos="word" start_char="1260">genomas</TOKEN>
<TOKEN end_char="1273" id="token-7-20" morph="none" pos="word" start_char="1268">suelen</TOKEN>
<TOKEN end_char="1280" id="token-7-21" morph="none" pos="word" start_char="1275">llevar</TOKEN>
<TOKEN end_char="1282" id="token-7-22" morph="none" pos="punct" start_char="1282">"</TOKEN>
<TOKEN end_char="1285" id="token-7-23" morph="none" pos="word" start_char="1283">las</TOKEN>
<TOKEN end_char="1296" id="token-7-24" morph="none" pos="word" start_char="1287">cicatrices</TOKEN>
<TOKEN end_char="1299" id="token-7-25" morph="none" pos="word" start_char="1298">de</TOKEN>
<TOKEN end_char="1302" id="token-7-26" morph="none" pos="word" start_char="1301">la</TOKEN>
<TOKEN end_char="1310" id="token-7-27" morph="none" pos="word" start_char="1304">batalla</TOKEN>
<TOKEN end_char="1315" id="token-7-28" morph="none" pos="word" start_char="1312">para</TOKEN>
<TOKEN end_char="1322" id="token-7-29" morph="none" pos="word" start_char="1317">luchar</TOKEN>
<TOKEN end_char="1324" id="token-7-30" morph="none" pos="word" start_char="1324">y</TOKEN>
<TOKEN end_char="1331" id="token-7-31" morph="none" pos="word" start_char="1326">evadir</TOKEN>
<TOKEN end_char="1334" id="token-7-32" morph="none" pos="word" start_char="1333">el</TOKEN>
<TOKEN end_char="1342" id="token-7-33" morph="none" pos="word" start_char="1336">sistema</TOKEN>
<TOKEN end_char="1355" id="token-7-34" morph="none" pos="word" start_char="1344">inmunológico</TOKEN>
<TOKEN end_char="1356" id="token-7-35" morph="none" pos="punct" start_char="1356">"</TOKEN>
<TOKEN end_char="1360" id="token-7-36" morph="none" pos="word" start_char="1358">del</TOKEN>
<TOKEN end_char="1370" id="token-7-37" morph="none" pos="word" start_char="1362">infectado</TOKEN>
<TOKEN end_char="1372" id="token-7-38" morph="none" pos="word" start_char="1372">a</TOKEN>
<TOKEN end_char="1379" id="token-7-39" morph="none" pos="word" start_char="1374">través</TOKEN>
<TOKEN end_char="1382" id="token-7-40" morph="none" pos="word" start_char="1381">de</TOKEN>
<TOKEN end_char="1390" id="token-7-41" morph="none" pos="word" start_char="1384">cambios</TOKEN>
<TOKEN end_char="1392" id="token-7-42" morph="none" pos="word" start_char="1392">y</TOKEN>
<TOKEN end_char="1405" id="token-7-43" morph="none" pos="word" start_char="1394">adaptaciones</TOKEN>
<TOKEN end_char="1409" id="token-7-44" morph="none" pos="word" start_char="1407">que</TOKEN>
<TOKEN end_char="1412" id="token-7-45" morph="none" pos="word" start_char="1411">se</TOKEN>
<TOKEN end_char="1423" id="token-7-46" morph="none" pos="word" start_char="1414">encuentran</TOKEN>
<TOKEN end_char="1426" id="token-7-47" morph="none" pos="word" start_char="1425">en</TOKEN>
<TOKEN end_char="1430" id="token-7-48" morph="none" pos="word" start_char="1428">sus</TOKEN>
<TOKEN end_char="1438" id="token-7-49" morph="none" pos="word" start_char="1432">genomas</TOKEN>
<TOKEN end_char="1439" id="token-7-50" morph="none" pos="punct" start_char="1439">,</TOKEN>
<TOKEN end_char="1447" id="token-7-51" morph="none" pos="word" start_char="1441">detalla</TOKEN>
<TOKEN end_char="1450" id="token-7-52" morph="none" pos="word" start_char="1449">la</TOKEN>
<TOKEN end_char="1458" id="token-7-53" morph="none" pos="word" start_char="1452">agencia</TOKEN>
<TRANSLATED_TEXT>Xia has long studied the molecular signatures of viruses, because when viruses invade a host, their genomes often carry "battle scars to fight and evade the immune system" of the infected through changes and adaptations found in their genomes, details agency</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1463" id="segment-8" start_char="1461">
<ORIGINAL_TEXT>Efe</ORIGINAL_TEXT>
<TOKEN end_char="1463" id="token-8-0" morph="none" pos="word" start_char="1461">Efe</TOKEN>
<TRANSLATED_TEXT>EFE</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="1466" id="segment-9" start_char="1466">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1466" id="token-9-0" morph="none" pos="punct" start_char="1466">.</TOKEN>
</SEG>
<SEG end_char="1740" id="segment-10" start_char="1469">
<ORIGINAL_TEXT>Sobre la posibilidad de que los perros pudieran transmitir en este momento el SARS-CoV2, Xian señaló que para ello el animal tendría que tener establecida una población de coronavirus en un tejido en contacto con el exterior, pero por el momento no hay evidencias de ello.</ORIGINAL_TEXT>
<TOKEN end_char="1473" id="token-10-0" morph="none" pos="word" start_char="1469">Sobre</TOKEN>
<TOKEN end_char="1476" id="token-10-1" morph="none" pos="word" start_char="1475">la</TOKEN>
<TOKEN end_char="1488" id="token-10-2" morph="none" pos="word" start_char="1478">posibilidad</TOKEN>
<TOKEN end_char="1491" id="token-10-3" morph="none" pos="word" start_char="1490">de</TOKEN>
<TOKEN end_char="1495" id="token-10-4" morph="none" pos="word" start_char="1493">que</TOKEN>
<TOKEN end_char="1499" id="token-10-5" morph="none" pos="word" start_char="1497">los</TOKEN>
<TOKEN end_char="1506" id="token-10-6" morph="none" pos="word" start_char="1501">perros</TOKEN>
<TOKEN end_char="1515" id="token-10-7" morph="none" pos="word" start_char="1508">pudieran</TOKEN>
<TOKEN end_char="1526" id="token-10-8" morph="none" pos="word" start_char="1517">transmitir</TOKEN>
<TOKEN end_char="1529" id="token-10-9" morph="none" pos="word" start_char="1528">en</TOKEN>
<TOKEN end_char="1534" id="token-10-10" morph="none" pos="word" start_char="1531">este</TOKEN>
<TOKEN end_char="1542" id="token-10-11" morph="none" pos="word" start_char="1536">momento</TOKEN>
<TOKEN end_char="1545" id="token-10-12" morph="none" pos="word" start_char="1544">el</TOKEN>
<TOKEN end_char="1555" id="token-10-13" morph="none" pos="unknown" start_char="1547">SARS-CoV2</TOKEN>
<TOKEN end_char="1556" id="token-10-14" morph="none" pos="punct" start_char="1556">,</TOKEN>
<TOKEN end_char="1561" id="token-10-15" morph="none" pos="word" start_char="1558">Xian</TOKEN>
<TOKEN end_char="1568" id="token-10-16" morph="none" pos="word" start_char="1563">señaló</TOKEN>
<TOKEN end_char="1572" id="token-10-17" morph="none" pos="word" start_char="1570">que</TOKEN>
<TOKEN end_char="1577" id="token-10-18" morph="none" pos="word" start_char="1574">para</TOKEN>
<TOKEN end_char="1582" id="token-10-19" morph="none" pos="word" start_char="1579">ello</TOKEN>
<TOKEN end_char="1585" id="token-10-20" morph="none" pos="word" start_char="1584">el</TOKEN>
<TOKEN end_char="1592" id="token-10-21" morph="none" pos="word" start_char="1587">animal</TOKEN>
<TOKEN end_char="1600" id="token-10-22" morph="none" pos="word" start_char="1594">tendría</TOKEN>
<TOKEN end_char="1604" id="token-10-23" morph="none" pos="word" start_char="1602">que</TOKEN>
<TOKEN end_char="1610" id="token-10-24" morph="none" pos="word" start_char="1606">tener</TOKEN>
<TOKEN end_char="1622" id="token-10-25" morph="none" pos="word" start_char="1612">establecida</TOKEN>
<TOKEN end_char="1626" id="token-10-26" morph="none" pos="word" start_char="1624">una</TOKEN>
<TOKEN end_char="1636" id="token-10-27" morph="none" pos="word" start_char="1628">población</TOKEN>
<TOKEN end_char="1639" id="token-10-28" morph="none" pos="word" start_char="1638">de</TOKEN>
<TOKEN end_char="1651" id="token-10-29" morph="none" pos="word" start_char="1641">coronavirus</TOKEN>
<TOKEN end_char="1654" id="token-10-30" morph="none" pos="word" start_char="1653">en</TOKEN>
<TOKEN end_char="1657" id="token-10-31" morph="none" pos="word" start_char="1656">un</TOKEN>
<TOKEN end_char="1664" id="token-10-32" morph="none" pos="word" start_char="1659">tejido</TOKEN>
<TOKEN end_char="1667" id="token-10-33" morph="none" pos="word" start_char="1666">en</TOKEN>
<TOKEN end_char="1676" id="token-10-34" morph="none" pos="word" start_char="1669">contacto</TOKEN>
<TOKEN end_char="1680" id="token-10-35" morph="none" pos="word" start_char="1678">con</TOKEN>
<TOKEN end_char="1683" id="token-10-36" morph="none" pos="word" start_char="1682">el</TOKEN>
<TOKEN end_char="1692" id="token-10-37" morph="none" pos="word" start_char="1685">exterior</TOKEN>
<TOKEN end_char="1693" id="token-10-38" morph="none" pos="punct" start_char="1693">,</TOKEN>
<TOKEN end_char="1698" id="token-10-39" morph="none" pos="word" start_char="1695">pero</TOKEN>
<TOKEN end_char="1702" id="token-10-40" morph="none" pos="word" start_char="1700">por</TOKEN>
<TOKEN end_char="1705" id="token-10-41" morph="none" pos="word" start_char="1704">el</TOKEN>
<TOKEN end_char="1713" id="token-10-42" morph="none" pos="word" start_char="1707">momento</TOKEN>
<TOKEN end_char="1716" id="token-10-43" morph="none" pos="word" start_char="1715">no</TOKEN>
<TOKEN end_char="1720" id="token-10-44" morph="none" pos="word" start_char="1718">hay</TOKEN>
<TOKEN end_char="1731" id="token-10-45" morph="none" pos="word" start_char="1722">evidencias</TOKEN>
<TOKEN end_char="1734" id="token-10-46" morph="none" pos="word" start_char="1733">de</TOKEN>
<TOKEN end_char="1739" id="token-10-47" morph="none" pos="word" start_char="1736">ello</TOKEN>
<TOKEN end_char="1740" id="token-10-48" morph="none" pos="punct" start_char="1740">.</TOKEN>
<TRANSLATED_TEXT>On the possibility that dogs could transmit SARS-CoV2 at this time, Xian noted that for this the animal would have to have established a population of coronavirus in a tissue in contact with the outside, but there is no evidence for this at this time.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1765" id="segment-11" start_char="1743">
<ORIGINAL_TEXT>Estudio recibe críticas</ORIGINAL_TEXT>
<TOKEN end_char="1749" id="token-11-0" morph="none" pos="word" start_char="1743">Estudio</TOKEN>
<TOKEN end_char="1756" id="token-11-1" morph="none" pos="word" start_char="1751">recibe</TOKEN>
<TOKEN end_char="1765" id="token-11-2" morph="none" pos="word" start_char="1758">críticas</TOKEN>
<TRANSLATED_TEXT>Study Receives Criticism</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1818" id="segment-12" start_char="1769">
<ORIGINAL_TEXT>La investigación de Xia tiene sus voces en contra.</ORIGINAL_TEXT>
<TOKEN end_char="1770" id="token-12-0" morph="none" pos="word" start_char="1769">La</TOKEN>
<TOKEN end_char="1784" id="token-12-1" morph="none" pos="word" start_char="1772">investigación</TOKEN>
<TOKEN end_char="1787" id="token-12-2" morph="none" pos="word" start_char="1786">de</TOKEN>
<TOKEN end_char="1791" id="token-12-3" morph="none" pos="word" start_char="1789">Xia</TOKEN>
<TOKEN end_char="1797" id="token-12-4" morph="none" pos="word" start_char="1793">tiene</TOKEN>
<TOKEN end_char="1801" id="token-12-5" morph="none" pos="word" start_char="1799">sus</TOKEN>
<TOKEN end_char="1807" id="token-12-6" morph="none" pos="word" start_char="1803">voces</TOKEN>
<TOKEN end_char="1810" id="token-12-7" morph="none" pos="word" start_char="1809">en</TOKEN>
<TOKEN end_char="1817" id="token-12-8" morph="none" pos="word" start_char="1812">contra</TOKEN>
<TOKEN end_char="1818" id="token-12-9" morph="none" pos="punct" start_char="1818">.</TOKEN>
<TRANSLATED_TEXT>Xia's investigation has her voices against it.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2157" id="segment-13" start_char="1820">
<ORIGINAL_TEXT>''Me resulta difícil entender cómo el autor ha podido concluir de este estudio, o hacer una hipótesis, que el virus que causa COVID-19 puede haber evolucionado a través de los perros'', señala James Wood, jefe del Departamento de Medicina Veterinaria e investigador de infecciones y control de enfermedades de la Universidad de Cambridge.</ORIGINAL_TEXT>
<TOKEN end_char="1821" id="token-13-0" morph="none" pos="punct" start_char="1820">''</TOKEN>
<TOKEN end_char="1823" id="token-13-1" morph="none" pos="word" start_char="1822">Me</TOKEN>
<TOKEN end_char="1831" id="token-13-2" morph="none" pos="word" start_char="1825">resulta</TOKEN>
<TOKEN end_char="1839" id="token-13-3" morph="none" pos="word" start_char="1833">difícil</TOKEN>
<TOKEN end_char="1848" id="token-13-4" morph="none" pos="word" start_char="1841">entender</TOKEN>
<TOKEN end_char="1853" id="token-13-5" morph="none" pos="word" start_char="1850">cómo</TOKEN>
<TOKEN end_char="1856" id="token-13-6" morph="none" pos="word" start_char="1855">el</TOKEN>
<TOKEN end_char="1862" id="token-13-7" morph="none" pos="word" start_char="1858">autor</TOKEN>
<TOKEN end_char="1865" id="token-13-8" morph="none" pos="word" start_char="1864">ha</TOKEN>
<TOKEN end_char="1872" id="token-13-9" morph="none" pos="word" start_char="1867">podido</TOKEN>
<TOKEN end_char="1881" id="token-13-10" morph="none" pos="word" start_char="1874">concluir</TOKEN>
<TOKEN end_char="1884" id="token-13-11" morph="none" pos="word" start_char="1883">de</TOKEN>
<TOKEN end_char="1889" id="token-13-12" morph="none" pos="word" start_char="1886">este</TOKEN>
<TOKEN end_char="1897" id="token-13-13" morph="none" pos="word" start_char="1891">estudio</TOKEN>
<TOKEN end_char="1898" id="token-13-14" morph="none" pos="punct" start_char="1898">,</TOKEN>
<TOKEN end_char="1900" id="token-13-15" morph="none" pos="word" start_char="1900">o</TOKEN>
<TOKEN end_char="1906" id="token-13-16" morph="none" pos="word" start_char="1902">hacer</TOKEN>
<TOKEN end_char="1910" id="token-13-17" morph="none" pos="word" start_char="1908">una</TOKEN>
<TOKEN end_char="1920" id="token-13-18" morph="none" pos="word" start_char="1912">hipótesis</TOKEN>
<TOKEN end_char="1921" id="token-13-19" morph="none" pos="punct" start_char="1921">,</TOKEN>
<TOKEN end_char="1925" id="token-13-20" morph="none" pos="word" start_char="1923">que</TOKEN>
<TOKEN end_char="1928" id="token-13-21" morph="none" pos="word" start_char="1927">el</TOKEN>
<TOKEN end_char="1934" id="token-13-22" morph="none" pos="word" start_char="1930">virus</TOKEN>
<TOKEN end_char="1938" id="token-13-23" morph="none" pos="word" start_char="1936">que</TOKEN>
<TOKEN end_char="1944" id="token-13-24" morph="none" pos="word" start_char="1940">causa</TOKEN>
<TOKEN end_char="1953" id="token-13-25" morph="none" pos="unknown" start_char="1946">COVID-19</TOKEN>
<TOKEN end_char="1959" id="token-13-26" morph="none" pos="word" start_char="1955">puede</TOKEN>
<TOKEN end_char="1965" id="token-13-27" morph="none" pos="word" start_char="1961">haber</TOKEN>
<TOKEN end_char="1978" id="token-13-28" morph="none" pos="word" start_char="1967">evolucionado</TOKEN>
<TOKEN end_char="1980" id="token-13-29" morph="none" pos="word" start_char="1980">a</TOKEN>
<TOKEN end_char="1987" id="token-13-30" morph="none" pos="word" start_char="1982">través</TOKEN>
<TOKEN end_char="1990" id="token-13-31" morph="none" pos="word" start_char="1989">de</TOKEN>
<TOKEN end_char="1994" id="token-13-32" morph="none" pos="word" start_char="1992">los</TOKEN>
<TOKEN end_char="2001" id="token-13-33" morph="none" pos="word" start_char="1996">perros</TOKEN>
<TOKEN end_char="2004" id="token-13-34" morph="none" pos="punct" start_char="2002">'',</TOKEN>
<TOKEN end_char="2011" id="token-13-35" morph="none" pos="word" start_char="2006">señala</TOKEN>
<TOKEN end_char="2017" id="token-13-36" morph="none" pos="word" start_char="2013">James</TOKEN>
<TOKEN end_char="2022" id="token-13-37" morph="none" pos="word" start_char="2019">Wood</TOKEN>
<TOKEN end_char="2023" id="token-13-38" morph="none" pos="punct" start_char="2023">,</TOKEN>
<TOKEN end_char="2028" id="token-13-39" morph="none" pos="word" start_char="2025">jefe</TOKEN>
<TOKEN end_char="2032" id="token-13-40" morph="none" pos="word" start_char="2030">del</TOKEN>
<TOKEN end_char="2045" id="token-13-41" morph="none" pos="word" start_char="2034">Departamento</TOKEN>
<TOKEN end_char="2048" id="token-13-42" morph="none" pos="word" start_char="2047">de</TOKEN>
<TOKEN end_char="2057" id="token-13-43" morph="none" pos="word" start_char="2050">Medicina</TOKEN>
<TOKEN end_char="2069" id="token-13-44" morph="none" pos="word" start_char="2059">Veterinaria</TOKEN>
<TOKEN end_char="2071" id="token-13-45" morph="none" pos="word" start_char="2071">e</TOKEN>
<TOKEN end_char="2084" id="token-13-46" morph="none" pos="word" start_char="2073">investigador</TOKEN>
<TOKEN end_char="2087" id="token-13-47" morph="none" pos="word" start_char="2086">de</TOKEN>
<TOKEN end_char="2099" id="token-13-48" morph="none" pos="word" start_char="2089">infecciones</TOKEN>
<TOKEN end_char="2101" id="token-13-49" morph="none" pos="word" start_char="2101">y</TOKEN>
<TOKEN end_char="2109" id="token-13-50" morph="none" pos="word" start_char="2103">control</TOKEN>
<TOKEN end_char="2112" id="token-13-51" morph="none" pos="word" start_char="2111">de</TOKEN>
<TOKEN end_char="2125" id="token-13-52" morph="none" pos="word" start_char="2114">enfermedades</TOKEN>
<TOKEN end_char="2128" id="token-13-53" morph="none" pos="word" start_char="2127">de</TOKEN>
<TOKEN end_char="2131" id="token-13-54" morph="none" pos="word" start_char="2130">la</TOKEN>
<TOKEN end_char="2143" id="token-13-55" morph="none" pos="word" start_char="2133">Universidad</TOKEN>
<TOKEN end_char="2146" id="token-13-56" morph="none" pos="word" start_char="2145">de</TOKEN>
<TOKEN end_char="2156" id="token-13-57" morph="none" pos="word" start_char="2148">Cambridge</TOKEN>
<TOKEN end_char="2157" id="token-13-58" morph="none" pos="punct" start_char="2157">.</TOKEN>
<TRANSLATED_TEXT>"I find it difficult to understand how the author has been able to conclude from this study, or to make a hypothesis, that the virus that causes COVID-19 may have evolved through dogs," says James Wood, Head of the Department of Veterinary Medicine and Infection and Disease Control Research at Cambridge University.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2230" id="segment-14" start_char="2160">
<ORIGINAL_TEXT>Wood considera que hay demasiada inferencia y muy pocos datos directos.</ORIGINAL_TEXT>
<TOKEN end_char="2163" id="token-14-0" morph="none" pos="word" start_char="2160">Wood</TOKEN>
<TOKEN end_char="2173" id="token-14-1" morph="none" pos="word" start_char="2165">considera</TOKEN>
<TOKEN end_char="2177" id="token-14-2" morph="none" pos="word" start_char="2175">que</TOKEN>
<TOKEN end_char="2181" id="token-14-3" morph="none" pos="word" start_char="2179">hay</TOKEN>
<TOKEN end_char="2191" id="token-14-4" morph="none" pos="word" start_char="2183">demasiada</TOKEN>
<TOKEN end_char="2202" id="token-14-5" morph="none" pos="word" start_char="2193">inferencia</TOKEN>
<TOKEN end_char="2204" id="token-14-6" morph="none" pos="word" start_char="2204">y</TOKEN>
<TOKEN end_char="2208" id="token-14-7" morph="none" pos="word" start_char="2206">muy</TOKEN>
<TOKEN end_char="2214" id="token-14-8" morph="none" pos="word" start_char="2210">pocos</TOKEN>
<TOKEN end_char="2220" id="token-14-9" morph="none" pos="word" start_char="2216">datos</TOKEN>
<TOKEN end_char="2229" id="token-14-10" morph="none" pos="word" start_char="2222">directos</TOKEN>
<TOKEN end_char="2230" id="token-14-11" morph="none" pos="punct" start_char="2230">.</TOKEN>
<TRANSLATED_TEXT>Wood considers that there is too much inference and too little direct data.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2361" id="segment-15" start_char="2232">
<ORIGINAL_TEXT>''No veo nada en este documento que respalde esta suposición y me preocupa que este documento haya sido publicado en esta revista.</ORIGINAL_TEXT>
<TOKEN end_char="2233" id="token-15-0" morph="none" pos="punct" start_char="2232">''</TOKEN>
<TOKEN end_char="2235" id="token-15-1" morph="none" pos="word" start_char="2234">No</TOKEN>
<TOKEN end_char="2239" id="token-15-2" morph="none" pos="word" start_char="2237">veo</TOKEN>
<TOKEN end_char="2244" id="token-15-3" morph="none" pos="word" start_char="2241">nada</TOKEN>
<TOKEN end_char="2247" id="token-15-4" morph="none" pos="word" start_char="2246">en</TOKEN>
<TOKEN end_char="2252" id="token-15-5" morph="none" pos="word" start_char="2249">este</TOKEN>
<TOKEN end_char="2262" id="token-15-6" morph="none" pos="word" start_char="2254">documento</TOKEN>
<TOKEN end_char="2266" id="token-15-7" morph="none" pos="word" start_char="2264">que</TOKEN>
<TOKEN end_char="2275" id="token-15-8" morph="none" pos="word" start_char="2268">respalde</TOKEN>
<TOKEN end_char="2280" id="token-15-9" morph="none" pos="word" start_char="2277">esta</TOKEN>
<TOKEN end_char="2291" id="token-15-10" morph="none" pos="word" start_char="2282">suposición</TOKEN>
<TOKEN end_char="2293" id="token-15-11" morph="none" pos="word" start_char="2293">y</TOKEN>
<TOKEN end_char="2296" id="token-15-12" morph="none" pos="word" start_char="2295">me</TOKEN>
<TOKEN end_char="2305" id="token-15-13" morph="none" pos="word" start_char="2298">preocupa</TOKEN>
<TOKEN end_char="2309" id="token-15-14" morph="none" pos="word" start_char="2307">que</TOKEN>
<TOKEN end_char="2314" id="token-15-15" morph="none" pos="word" start_char="2311">este</TOKEN>
<TOKEN end_char="2324" id="token-15-16" morph="none" pos="word" start_char="2316">documento</TOKEN>
<TOKEN end_char="2329" id="token-15-17" morph="none" pos="word" start_char="2326">haya</TOKEN>
<TOKEN end_char="2334" id="token-15-18" morph="none" pos="word" start_char="2331">sido</TOKEN>
<TOKEN end_char="2344" id="token-15-19" morph="none" pos="word" start_char="2336">publicado</TOKEN>
<TOKEN end_char="2347" id="token-15-20" morph="none" pos="word" start_char="2346">en</TOKEN>
<TOKEN end_char="2352" id="token-15-21" morph="none" pos="word" start_char="2349">esta</TOKEN>
<TOKEN end_char="2360" id="token-15-22" morph="none" pos="word" start_char="2354">revista</TOKEN>
<TOKEN end_char="2361" id="token-15-23" morph="none" pos="punct" start_char="2361">.</TOKEN>
<TRANSLATED_TEXT>I see nothing in this document that supports this assumption and I am concerned that this document has been published in this magazine.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2467" id="segment-16" start_char="2363">
<ORIGINAL_TEXT>No creo que ningún dueño de perro deba preocuparse como resultado de este trabajo'', agrega el experto al</ORIGINAL_TEXT>
<TOKEN end_char="2364" id="token-16-0" morph="none" pos="word" start_char="2363">No</TOKEN>
<TOKEN end_char="2369" id="token-16-1" morph="none" pos="word" start_char="2366">creo</TOKEN>
<TOKEN end_char="2373" id="token-16-2" morph="none" pos="word" start_char="2371">que</TOKEN>
<TOKEN end_char="2380" id="token-16-3" morph="none" pos="word" start_char="2375">ningún</TOKEN>
<TOKEN end_char="2386" id="token-16-4" morph="none" pos="word" start_char="2382">dueño</TOKEN>
<TOKEN end_char="2389" id="token-16-5" morph="none" pos="word" start_char="2388">de</TOKEN>
<TOKEN end_char="2395" id="token-16-6" morph="none" pos="word" start_char="2391">perro</TOKEN>
<TOKEN end_char="2400" id="token-16-7" morph="none" pos="word" start_char="2397">deba</TOKEN>
<TOKEN end_char="2412" id="token-16-8" morph="none" pos="word" start_char="2402">preocuparse</TOKEN>
<TOKEN end_char="2417" id="token-16-9" morph="none" pos="word" start_char="2414">como</TOKEN>
<TOKEN end_char="2427" id="token-16-10" morph="none" pos="word" start_char="2419">resultado</TOKEN>
<TOKEN end_char="2430" id="token-16-11" morph="none" pos="word" start_char="2429">de</TOKEN>
<TOKEN end_char="2435" id="token-16-12" morph="none" pos="word" start_char="2432">este</TOKEN>
<TOKEN end_char="2443" id="token-16-13" morph="none" pos="word" start_char="2437">trabajo</TOKEN>
<TOKEN end_char="2446" id="token-16-14" morph="none" pos="punct" start_char="2444">'',</TOKEN>
<TOKEN end_char="2453" id="token-16-15" morph="none" pos="word" start_char="2448">agrega</TOKEN>
<TOKEN end_char="2456" id="token-16-16" morph="none" pos="word" start_char="2455">el</TOKEN>
<TOKEN end_char="2464" id="token-16-17" morph="none" pos="word" start_char="2458">experto</TOKEN>
<TOKEN end_char="2467" id="token-16-18" morph="none" pos="word" start_char="2466">al</TOKEN>
<TRANSLATED_TEXT>I do not think any dog owner should be concerned as a result of this work, "the expert adds to the</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2479" id="segment-17" start_char="2470">
<ORIGINAL_TEXT>Daily Mail</ORIGINAL_TEXT>
<TOKEN end_char="2474" id="token-17-0" morph="none" pos="word" start_char="2470">Daily</TOKEN>
<TOKEN end_char="2479" id="token-17-1" morph="none" pos="word" start_char="2476">Mail</TOKEN>
</SEG>
<SEG end_char="2482" id="segment-18" start_char="2482">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="2482" id="token-18-0" morph="none" pos="punct" start_char="2482">.</TOKEN>
</SEG>
<SEG end_char="2820" id="segment-19" start_char="2485">
<ORIGINAL_TEXT>El profesor de Virología del Roslin Institute de la Universidad de Edimburgo, Paul Digard, apunta que la investigación de Xia adopta un enfoque muy limitado para examinar la secuencia del SARS-CoV-2 en busca de pistas sobre su origen que no brindan un respaldo convincente para la hipótesis de que los perros fueron la fuente del virus.</ORIGINAL_TEXT>
<TOKEN end_char="2486" id="token-19-0" morph="none" pos="word" start_char="2485">El</TOKEN>
<TOKEN end_char="2495" id="token-19-1" morph="none" pos="word" start_char="2488">profesor</TOKEN>
<TOKEN end_char="2498" id="token-19-2" morph="none" pos="word" start_char="2497">de</TOKEN>
<TOKEN end_char="2508" id="token-19-3" morph="none" pos="word" start_char="2500">Virología</TOKEN>
<TOKEN end_char="2512" id="token-19-4" morph="none" pos="word" start_char="2510">del</TOKEN>
<TOKEN end_char="2519" id="token-19-5" morph="none" pos="word" start_char="2514">Roslin</TOKEN>
<TOKEN end_char="2529" id="token-19-6" morph="none" pos="word" start_char="2521">Institute</TOKEN>
<TOKEN end_char="2532" id="token-19-7" morph="none" pos="word" start_char="2531">de</TOKEN>
<TOKEN end_char="2535" id="token-19-8" morph="none" pos="word" start_char="2534">la</TOKEN>
<TOKEN end_char="2547" id="token-19-9" morph="none" pos="word" start_char="2537">Universidad</TOKEN>
<TOKEN end_char="2550" id="token-19-10" morph="none" pos="word" start_char="2549">de</TOKEN>
<TOKEN end_char="2560" id="token-19-11" morph="none" pos="word" start_char="2552">Edimburgo</TOKEN>
<TOKEN end_char="2561" id="token-19-12" morph="none" pos="punct" start_char="2561">,</TOKEN>
<TOKEN end_char="2566" id="token-19-13" morph="none" pos="word" start_char="2563">Paul</TOKEN>
<TOKEN end_char="2573" id="token-19-14" morph="none" pos="word" start_char="2568">Digard</TOKEN>
<TOKEN end_char="2574" id="token-19-15" morph="none" pos="punct" start_char="2574">,</TOKEN>
<TOKEN end_char="2581" id="token-19-16" morph="none" pos="word" start_char="2576">apunta</TOKEN>
<TOKEN end_char="2585" id="token-19-17" morph="none" pos="word" start_char="2583">que</TOKEN>
<TOKEN end_char="2588" id="token-19-18" morph="none" pos="word" start_char="2587">la</TOKEN>
<TOKEN end_char="2602" id="token-19-19" morph="none" pos="word" start_char="2590">investigación</TOKEN>
<TOKEN end_char="2605" id="token-19-20" morph="none" pos="word" start_char="2604">de</TOKEN>
<TOKEN end_char="2609" id="token-19-21" morph="none" pos="word" start_char="2607">Xia</TOKEN>
<TOKEN end_char="2616" id="token-19-22" morph="none" pos="word" start_char="2611">adopta</TOKEN>
<TOKEN end_char="2619" id="token-19-23" morph="none" pos="word" start_char="2618">un</TOKEN>
<TOKEN end_char="2627" id="token-19-24" morph="none" pos="word" start_char="2621">enfoque</TOKEN>
<TOKEN end_char="2631" id="token-19-25" morph="none" pos="word" start_char="2629">muy</TOKEN>
<TOKEN end_char="2640" id="token-19-26" morph="none" pos="word" start_char="2633">limitado</TOKEN>
<TOKEN end_char="2645" id="token-19-27" morph="none" pos="word" start_char="2642">para</TOKEN>
<TOKEN end_char="2654" id="token-19-28" morph="none" pos="word" start_char="2647">examinar</TOKEN>
<TOKEN end_char="2657" id="token-19-29" morph="none" pos="word" start_char="2656">la</TOKEN>
<TOKEN end_char="2667" id="token-19-30" morph="none" pos="word" start_char="2659">secuencia</TOKEN>
<TOKEN end_char="2671" id="token-19-31" morph="none" pos="word" start_char="2669">del</TOKEN>
<TOKEN end_char="2682" id="token-19-32" morph="none" pos="unknown" start_char="2673">SARS-CoV-2</TOKEN>
<TOKEN end_char="2685" id="token-19-33" morph="none" pos="word" start_char="2684">en</TOKEN>
<TOKEN end_char="2691" id="token-19-34" morph="none" pos="word" start_char="2687">busca</TOKEN>
<TOKEN end_char="2694" id="token-19-35" morph="none" pos="word" start_char="2693">de</TOKEN>
<TOKEN end_char="2701" id="token-19-36" morph="none" pos="word" start_char="2696">pistas</TOKEN>
<TOKEN end_char="2707" id="token-19-37" morph="none" pos="word" start_char="2703">sobre</TOKEN>
<TOKEN end_char="2710" id="token-19-38" morph="none" pos="word" start_char="2709">su</TOKEN>
<TOKEN end_char="2717" id="token-19-39" morph="none" pos="word" start_char="2712">origen</TOKEN>
<TOKEN end_char="2721" id="token-19-40" morph="none" pos="word" start_char="2719">que</TOKEN>
<TOKEN end_char="2724" id="token-19-41" morph="none" pos="word" start_char="2723">no</TOKEN>
<TOKEN end_char="2732" id="token-19-42" morph="none" pos="word" start_char="2726">brindan</TOKEN>
<TOKEN end_char="2735" id="token-19-43" morph="none" pos="word" start_char="2734">un</TOKEN>
<TOKEN end_char="2744" id="token-19-44" morph="none" pos="word" start_char="2737">respaldo</TOKEN>
<TOKEN end_char="2756" id="token-19-45" morph="none" pos="word" start_char="2746">convincente</TOKEN>
<TOKEN end_char="2761" id="token-19-46" morph="none" pos="word" start_char="2758">para</TOKEN>
<TOKEN end_char="2764" id="token-19-47" morph="none" pos="word" start_char="2763">la</TOKEN>
<TOKEN end_char="2774" id="token-19-48" morph="none" pos="word" start_char="2766">hipótesis</TOKEN>
<TOKEN end_char="2777" id="token-19-49" morph="none" pos="word" start_char="2776">de</TOKEN>
<TOKEN end_char="2781" id="token-19-50" morph="none" pos="word" start_char="2779">que</TOKEN>
<TOKEN end_char="2785" id="token-19-51" morph="none" pos="word" start_char="2783">los</TOKEN>
<TOKEN end_char="2792" id="token-19-52" morph="none" pos="word" start_char="2787">perros</TOKEN>
<TOKEN end_char="2799" id="token-19-53" morph="none" pos="word" start_char="2794">fueron</TOKEN>
<TOKEN end_char="2802" id="token-19-54" morph="none" pos="word" start_char="2801">la</TOKEN>
<TOKEN end_char="2809" id="token-19-55" morph="none" pos="word" start_char="2804">fuente</TOKEN>
<TOKEN end_char="2813" id="token-19-56" morph="none" pos="word" start_char="2811">del</TOKEN>
<TOKEN end_char="2819" id="token-19-57" morph="none" pos="word" start_char="2815">virus</TOKEN>
<TOKEN end_char="2820" id="token-19-58" morph="none" pos="punct" start_char="2820">.</TOKEN>
<TRANSLATED_TEXT>Professor of Virology at the Roslin Institute at the University of Edinburgh, Paul Digard, notes that Xia's research takes a very limited approach to examining the SARS-CoV-2 sequence in search of clues about its origin that do not provide convincing support for the hypothesis that dogs were the source of the virus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3121" id="segment-20" start_char="2823">
<ORIGINAL_TEXT>Daniella Dos Santos, presidenta de la Asociación Británica de Veterinaria (BVA, por sus siglas en inglés), indica que esta investigación es puramente teórica y que ''el autor mismo señala que hasta la fecha no hay evidencia de que los perros puedan replicar o eliminar el virus que causa COVID-19''.</ORIGINAL_TEXT>
<TOKEN end_char="2830" id="token-20-0" morph="none" pos="word" start_char="2823">Daniella</TOKEN>
<TOKEN end_char="2834" id="token-20-1" morph="none" pos="word" start_char="2832">Dos</TOKEN>
<TOKEN end_char="2841" id="token-20-2" morph="none" pos="word" start_char="2836">Santos</TOKEN>
<TOKEN end_char="2842" id="token-20-3" morph="none" pos="punct" start_char="2842">,</TOKEN>
<TOKEN end_char="2853" id="token-20-4" morph="none" pos="word" start_char="2844">presidenta</TOKEN>
<TOKEN end_char="2856" id="token-20-5" morph="none" pos="word" start_char="2855">de</TOKEN>
<TOKEN end_char="2859" id="token-20-6" morph="none" pos="word" start_char="2858">la</TOKEN>
<TOKEN end_char="2870" id="token-20-7" morph="none" pos="word" start_char="2861">Asociación</TOKEN>
<TOKEN end_char="2880" id="token-20-8" morph="none" pos="word" start_char="2872">Británica</TOKEN>
<TOKEN end_char="2883" id="token-20-9" morph="none" pos="word" start_char="2882">de</TOKEN>
<TOKEN end_char="2895" id="token-20-10" morph="none" pos="word" start_char="2885">Veterinaria</TOKEN>
<TOKEN end_char="2897" id="token-20-11" morph="none" pos="punct" start_char="2897">(</TOKEN>
<TOKEN end_char="2900" id="token-20-12" morph="none" pos="word" start_char="2898">BVA</TOKEN>
<TOKEN end_char="2901" id="token-20-13" morph="none" pos="punct" start_char="2901">,</TOKEN>
<TOKEN end_char="2905" id="token-20-14" morph="none" pos="word" start_char="2903">por</TOKEN>
<TOKEN end_char="2909" id="token-20-15" morph="none" pos="word" start_char="2907">sus</TOKEN>
<TOKEN end_char="2916" id="token-20-16" morph="none" pos="word" start_char="2911">siglas</TOKEN>
<TOKEN end_char="2919" id="token-20-17" morph="none" pos="word" start_char="2918">en</TOKEN>
<TOKEN end_char="2926" id="token-20-18" morph="none" pos="word" start_char="2921">inglés</TOKEN>
<TOKEN end_char="2928" id="token-20-19" morph="none" pos="punct" start_char="2927">),</TOKEN>
<TOKEN end_char="2935" id="token-20-20" morph="none" pos="word" start_char="2930">indica</TOKEN>
<TOKEN end_char="2939" id="token-20-21" morph="none" pos="word" start_char="2937">que</TOKEN>
<TOKEN end_char="2944" id="token-20-22" morph="none" pos="word" start_char="2941">esta</TOKEN>
<TOKEN end_char="2958" id="token-20-23" morph="none" pos="word" start_char="2946">investigación</TOKEN>
<TOKEN end_char="2961" id="token-20-24" morph="none" pos="word" start_char="2960">es</TOKEN>
<TOKEN end_char="2971" id="token-20-25" morph="none" pos="word" start_char="2963">puramente</TOKEN>
<TOKEN end_char="2979" id="token-20-26" morph="none" pos="word" start_char="2973">teórica</TOKEN>
<TOKEN end_char="2981" id="token-20-27" morph="none" pos="word" start_char="2981">y</TOKEN>
<TOKEN end_char="2985" id="token-20-28" morph="none" pos="word" start_char="2983">que</TOKEN>
<TOKEN end_char="2988" id="token-20-29" morph="none" pos="punct" start_char="2987">''</TOKEN>
<TOKEN end_char="2990" id="token-20-30" morph="none" pos="word" start_char="2989">el</TOKEN>
<TOKEN end_char="2996" id="token-20-31" morph="none" pos="word" start_char="2992">autor</TOKEN>
<TOKEN end_char="3002" id="token-20-32" morph="none" pos="word" start_char="2998">mismo</TOKEN>
<TOKEN end_char="3009" id="token-20-33" morph="none" pos="word" start_char="3004">señala</TOKEN>
<TOKEN end_char="3013" id="token-20-34" morph="none" pos="word" start_char="3011">que</TOKEN>
<TOKEN end_char="3019" id="token-20-35" morph="none" pos="word" start_char="3015">hasta</TOKEN>
<TOKEN end_char="3022" id="token-20-36" morph="none" pos="word" start_char="3021">la</TOKEN>
<TOKEN end_char="3028" id="token-20-37" morph="none" pos="word" start_char="3024">fecha</TOKEN>
<TOKEN end_char="3031" id="token-20-38" morph="none" pos="word" start_char="3030">no</TOKEN>
<TOKEN end_char="3035" id="token-20-39" morph="none" pos="word" start_char="3033">hay</TOKEN>
<TOKEN end_char="3045" id="token-20-40" morph="none" pos="word" start_char="3037">evidencia</TOKEN>
<TOKEN end_char="3048" id="token-20-41" morph="none" pos="word" start_char="3047">de</TOKEN>
<TOKEN end_char="3052" id="token-20-42" morph="none" pos="word" start_char="3050">que</TOKEN>
<TOKEN end_char="3056" id="token-20-43" morph="none" pos="word" start_char="3054">los</TOKEN>
<TOKEN end_char="3063" id="token-20-44" morph="none" pos="word" start_char="3058">perros</TOKEN>
<TOKEN end_char="3070" id="token-20-45" morph="none" pos="word" start_char="3065">puedan</TOKEN>
<TOKEN end_char="3079" id="token-20-46" morph="none" pos="word" start_char="3072">replicar</TOKEN>
<TOKEN end_char="3081" id="token-20-47" morph="none" pos="word" start_char="3081">o</TOKEN>
<TOKEN end_char="3090" id="token-20-48" morph="none" pos="word" start_char="3083">eliminar</TOKEN>
<TOKEN end_char="3093" id="token-20-49" morph="none" pos="word" start_char="3092">el</TOKEN>
<TOKEN end_char="3099" id="token-20-50" morph="none" pos="word" start_char="3095">virus</TOKEN>
<TOKEN end_char="3103" id="token-20-51" morph="none" pos="word" start_char="3101">que</TOKEN>
<TOKEN end_char="3109" id="token-20-52" morph="none" pos="word" start_char="3105">causa</TOKEN>
<TOKEN end_char="3118" id="token-20-53" morph="none" pos="unknown" start_char="3111">COVID-19</TOKEN>
<TOKEN end_char="3121" id="token-20-54" morph="none" pos="punct" start_char="3119">''.</TOKEN>
<TRANSLATED_TEXT>Daniella Dos Santos, president of the British Veterinary Association (BVA), points out that this research is purely theoretical and that "the author himself points out that to date there is no evidence that dogs can replicate or eliminate the virus that causes COVID-19".</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3286" id="segment-21" start_char="3123">
<ORIGINAL_TEXT>''Instamos a la extrema precaución al interpretarlo como algo más que un recordatorio de que se está trabajando para considerar los orígenes del virus", puntualizó.</ORIGINAL_TEXT>
<TOKEN end_char="3124" id="token-21-0" morph="none" pos="punct" start_char="3123">''</TOKEN>
<TOKEN end_char="3132" id="token-21-1" morph="none" pos="word" start_char="3125">Instamos</TOKEN>
<TOKEN end_char="3134" id="token-21-2" morph="none" pos="word" start_char="3134">a</TOKEN>
<TOKEN end_char="3137" id="token-21-3" morph="none" pos="word" start_char="3136">la</TOKEN>
<TOKEN end_char="3145" id="token-21-4" morph="none" pos="word" start_char="3139">extrema</TOKEN>
<TOKEN end_char="3156" id="token-21-5" morph="none" pos="word" start_char="3147">precaución</TOKEN>
<TOKEN end_char="3159" id="token-21-6" morph="none" pos="word" start_char="3158">al</TOKEN>
<TOKEN end_char="3173" id="token-21-7" morph="none" pos="word" start_char="3161">interpretarlo</TOKEN>
<TOKEN end_char="3178" id="token-21-8" morph="none" pos="word" start_char="3175">como</TOKEN>
<TOKEN end_char="3183" id="token-21-9" morph="none" pos="word" start_char="3180">algo</TOKEN>
<TOKEN end_char="3187" id="token-21-10" morph="none" pos="word" start_char="3185">más</TOKEN>
<TOKEN end_char="3191" id="token-21-11" morph="none" pos="word" start_char="3189">que</TOKEN>
<TOKEN end_char="3194" id="token-21-12" morph="none" pos="word" start_char="3193">un</TOKEN>
<TOKEN end_char="3207" id="token-21-13" morph="none" pos="word" start_char="3196">recordatorio</TOKEN>
<TOKEN end_char="3210" id="token-21-14" morph="none" pos="word" start_char="3209">de</TOKEN>
<TOKEN end_char="3214" id="token-21-15" morph="none" pos="word" start_char="3212">que</TOKEN>
<TOKEN end_char="3217" id="token-21-16" morph="none" pos="word" start_char="3216">se</TOKEN>
<TOKEN end_char="3222" id="token-21-17" morph="none" pos="word" start_char="3219">está</TOKEN>
<TOKEN end_char="3233" id="token-21-18" morph="none" pos="word" start_char="3224">trabajando</TOKEN>
<TOKEN end_char="3238" id="token-21-19" morph="none" pos="word" start_char="3235">para</TOKEN>
<TOKEN end_char="3249" id="token-21-20" morph="none" pos="word" start_char="3240">considerar</TOKEN>
<TOKEN end_char="3253" id="token-21-21" morph="none" pos="word" start_char="3251">los</TOKEN>
<TOKEN end_char="3262" id="token-21-22" morph="none" pos="word" start_char="3255">orígenes</TOKEN>
<TOKEN end_char="3266" id="token-21-23" morph="none" pos="word" start_char="3264">del</TOKEN>
<TOKEN end_char="3272" id="token-21-24" morph="none" pos="word" start_char="3268">virus</TOKEN>
<TOKEN end_char="3274" id="token-21-25" morph="none" pos="punct" start_char="3273">",</TOKEN>
<TOKEN end_char="3285" id="token-21-26" morph="none" pos="word" start_char="3276">puntualizó</TOKEN>
<TOKEN end_char="3286" id="token-21-27" morph="none" pos="punct" start_char="3286">.</TOKEN>
<TRANSLATED_TEXT>"We urge extreme caution in interpreting it as more than a reminder that work is being done to consider the origins of the virus," he noted.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3290" id="segment-22" start_char="3288">
<ORIGINAL_TEXT>(I)</ORIGINAL_TEXT>
<TOKEN end_char="3288" id="token-22-0" morph="none" pos="punct" start_char="3288">(</TOKEN>
<TOKEN end_char="3289" id="token-22-1" morph="none" pos="word" start_char="3289">I</TOKEN>
<TOKEN end_char="3290" id="token-22-2" morph="none" pos="punct" start_char="3290">)</TOKEN>
<TRANSLATED_TEXT>(II)</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
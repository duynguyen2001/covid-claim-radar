<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CA5M" lang="spa" raw_text_char_length="5141" raw_text_md5="52ca9a736eee3788bd3ffd1497c68528" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="55" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Study lacks evidence on masks, isn’t linked to Stanford</ORIGINAL_TEXT>
<TOKEN end_char="5" id="token-0-0" morph="none" pos="word" start_char="1">Study</TOKEN>
<TOKEN end_char="11" id="token-0-1" morph="none" pos="word" start_char="7">lacks</TOKEN>
<TOKEN end_char="20" id="token-0-2" morph="none" pos="word" start_char="13">evidence</TOKEN>
<TOKEN end_char="23" id="token-0-3" morph="none" pos="word" start_char="22">on</TOKEN>
<TOKEN end_char="29" id="token-0-4" morph="none" pos="word" start_char="25">masks</TOKEN>
<TOKEN end_char="30" id="token-0-5" morph="none" pos="punct" start_char="30">,</TOKEN>
<TOKEN end_char="36" id="token-0-6" morph="none" pos="word" start_char="32">isn’t</TOKEN>
<TOKEN end_char="43" id="token-0-7" morph="none" pos="word" start_char="38">linked</TOKEN>
<TOKEN end_char="46" id="token-0-8" morph="none" pos="word" start_char="45">to</TOKEN>
<TOKEN end_char="55" id="token-0-9" morph="none" pos="word" start_char="48">Stanford</TOKEN>
</SEG>
<SEG end_char="208" id="segment-1" start_char="59">
<ORIGINAL_TEXT>CLAIM: A Stanford University study published on the National Institutes of Health website proves face masks are absolutely worthless against COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="63" id="token-1-0" morph="none" pos="word" start_char="59">CLAIM</TOKEN>
<TOKEN end_char="64" id="token-1-1" morph="none" pos="punct" start_char="64">:</TOKEN>
<TOKEN end_char="66" id="token-1-2" morph="none" pos="word" start_char="66">A</TOKEN>
<TOKEN end_char="75" id="token-1-3" morph="none" pos="word" start_char="68">Stanford</TOKEN>
<TOKEN end_char="86" id="token-1-4" morph="none" pos="word" start_char="77">University</TOKEN>
<TOKEN end_char="92" id="token-1-5" morph="none" pos="word" start_char="88">study</TOKEN>
<TOKEN end_char="102" id="token-1-6" morph="none" pos="word" start_char="94">published</TOKEN>
<TOKEN end_char="105" id="token-1-7" morph="none" pos="word" start_char="104">on</TOKEN>
<TOKEN end_char="109" id="token-1-8" morph="none" pos="word" start_char="107">the</TOKEN>
<TOKEN end_char="118" id="token-1-9" morph="none" pos="word" start_char="111">National</TOKEN>
<TOKEN end_char="129" id="token-1-10" morph="none" pos="word" start_char="120">Institutes</TOKEN>
<TOKEN end_char="132" id="token-1-11" morph="none" pos="word" start_char="131">of</TOKEN>
<TOKEN end_char="139" id="token-1-12" morph="none" pos="word" start_char="134">Health</TOKEN>
<TOKEN end_char="147" id="token-1-13" morph="none" pos="word" start_char="141">website</TOKEN>
<TOKEN end_char="154" id="token-1-14" morph="none" pos="word" start_char="149">proves</TOKEN>
<TOKEN end_char="159" id="token-1-15" morph="none" pos="word" start_char="156">face</TOKEN>
<TOKEN end_char="165" id="token-1-16" morph="none" pos="word" start_char="161">masks</TOKEN>
<TOKEN end_char="169" id="token-1-17" morph="none" pos="word" start_char="167">are</TOKEN>
<TOKEN end_char="180" id="token-1-18" morph="none" pos="word" start_char="171">absolutely</TOKEN>
<TOKEN end_char="190" id="token-1-19" morph="none" pos="word" start_char="182">worthless</TOKEN>
<TOKEN end_char="198" id="token-1-20" morph="none" pos="word" start_char="192">against</TOKEN>
<TOKEN end_char="207" id="token-1-21" morph="none" pos="unknown" start_char="200">COVID-19</TOKEN>
<TOKEN end_char="208" id="token-1-22" morph="none" pos="punct" start_char="208">.</TOKEN>
</SEG>
<SEG end_char="233" id="segment-2" start_char="211">
<ORIGINAL_TEXT>AP’S ASSESSMENT: False.</ORIGINAL_TEXT>
<TOKEN end_char="214" id="token-2-0" morph="none" pos="word" start_char="211">AP’S</TOKEN>
<TOKEN end_char="225" id="token-2-1" morph="none" pos="word" start_char="216">ASSESSMENT</TOKEN>
<TOKEN end_char="226" id="token-2-2" morph="none" pos="punct" start_char="226">:</TOKEN>
<TOKEN end_char="232" id="token-2-3" morph="none" pos="word" start_char="228">False</TOKEN>
<TOKEN end_char="233" id="token-2-4" morph="none" pos="punct" start_char="233">.</TOKEN>
<TRANSLATED_TEXT>AP'S EVALUATION: False.</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="381" id="segment-3" start_char="235">
<ORIGINAL_TEXT>This study is not affiliated with Stanford University, nor does the author work for the Veterans Affairs Palo Alto Health Care System as he claims.</ORIGINAL_TEXT>
<TOKEN end_char="238" id="token-3-0" morph="none" pos="word" start_char="235">This</TOKEN>
<TOKEN end_char="244" id="token-3-1" morph="none" pos="word" start_char="240">study</TOKEN>
<TOKEN end_char="247" id="token-3-2" morph="none" pos="word" start_char="246">is</TOKEN>
<TOKEN end_char="251" id="token-3-3" morph="none" pos="word" start_char="249">not</TOKEN>
<TOKEN end_char="262" id="token-3-4" morph="none" pos="word" start_char="253">affiliated</TOKEN>
<TOKEN end_char="267" id="token-3-5" morph="none" pos="word" start_char="264">with</TOKEN>
<TOKEN end_char="276" id="token-3-6" morph="none" pos="word" start_char="269">Stanford</TOKEN>
<TOKEN end_char="287" id="token-3-7" morph="none" pos="word" start_char="278">University</TOKEN>
<TOKEN end_char="288" id="token-3-8" morph="none" pos="punct" start_char="288">,</TOKEN>
<TOKEN end_char="292" id="token-3-9" morph="none" pos="word" start_char="290">nor</TOKEN>
<TOKEN end_char="297" id="token-3-10" morph="none" pos="word" start_char="294">does</TOKEN>
<TOKEN end_char="301" id="token-3-11" morph="none" pos="word" start_char="299">the</TOKEN>
<TOKEN end_char="308" id="token-3-12" morph="none" pos="word" start_char="303">author</TOKEN>
<TOKEN end_char="313" id="token-3-13" morph="none" pos="word" start_char="310">work</TOKEN>
<TOKEN end_char="317" id="token-3-14" morph="none" pos="word" start_char="315">for</TOKEN>
<TOKEN end_char="321" id="token-3-15" morph="none" pos="word" start_char="319">the</TOKEN>
<TOKEN end_char="330" id="token-3-16" morph="none" pos="word" start_char="323">Veterans</TOKEN>
<TOKEN end_char="338" id="token-3-17" morph="none" pos="word" start_char="332">Affairs</TOKEN>
<TOKEN end_char="343" id="token-3-18" morph="none" pos="word" start_char="340">Palo</TOKEN>
<TOKEN end_char="348" id="token-3-19" morph="none" pos="word" start_char="345">Alto</TOKEN>
<TOKEN end_char="355" id="token-3-20" morph="none" pos="word" start_char="350">Health</TOKEN>
<TOKEN end_char="360" id="token-3-21" morph="none" pos="word" start_char="357">Care</TOKEN>
<TOKEN end_char="367" id="token-3-22" morph="none" pos="word" start_char="362">System</TOKEN>
<TOKEN end_char="370" id="token-3-23" morph="none" pos="word" start_char="369">as</TOKEN>
<TOKEN end_char="373" id="token-3-24" morph="none" pos="word" start_char="372">he</TOKEN>
<TOKEN end_char="380" id="token-3-25" morph="none" pos="word" start_char="375">claims</TOKEN>
<TOKEN end_char="381" id="token-3-26" morph="none" pos="punct" start_char="381">.</TOKEN>
</SEG>
<SEG end_char="483" id="segment-4" start_char="383">
<ORIGINAL_TEXT>The study presents a hypothesis that includes false claims about the health effects of wearing masks.</ORIGINAL_TEXT>
<TOKEN end_char="385" id="token-4-0" morph="none" pos="word" start_char="383">The</TOKEN>
<TOKEN end_char="391" id="token-4-1" morph="none" pos="word" start_char="387">study</TOKEN>
<TOKEN end_char="400" id="token-4-2" morph="none" pos="word" start_char="393">presents</TOKEN>
<TOKEN end_char="402" id="token-4-3" morph="none" pos="word" start_char="402">a</TOKEN>
<TOKEN end_char="413" id="token-4-4" morph="none" pos="word" start_char="404">hypothesis</TOKEN>
<TOKEN end_char="418" id="token-4-5" morph="none" pos="word" start_char="415">that</TOKEN>
<TOKEN end_char="427" id="token-4-6" morph="none" pos="word" start_char="420">includes</TOKEN>
<TOKEN end_char="433" id="token-4-7" morph="none" pos="word" start_char="429">false</TOKEN>
<TOKEN end_char="440" id="token-4-8" morph="none" pos="word" start_char="435">claims</TOKEN>
<TOKEN end_char="446" id="token-4-9" morph="none" pos="word" start_char="442">about</TOKEN>
<TOKEN end_char="450" id="token-4-10" morph="none" pos="word" start_char="448">the</TOKEN>
<TOKEN end_char="457" id="token-4-11" morph="none" pos="word" start_char="452">health</TOKEN>
<TOKEN end_char="465" id="token-4-12" morph="none" pos="word" start_char="459">effects</TOKEN>
<TOKEN end_char="468" id="token-4-13" morph="none" pos="word" start_char="467">of</TOKEN>
<TOKEN end_char="476" id="token-4-14" morph="none" pos="word" start_char="470">wearing</TOKEN>
<TOKEN end_char="482" id="token-4-15" morph="none" pos="word" start_char="478">masks</TOKEN>
<TOKEN end_char="483" id="token-4-16" morph="none" pos="punct" start_char="483">.</TOKEN>
</SEG>
<SEG end_char="714" id="segment-5" start_char="485">
<ORIGINAL_TEXT>The U.S. Centers for Disease Control and Prevention continues to recommend wearing face coverings to reduce the spread of COVID-19, as research shows they can block the transmission of respiratory droplets, which spread the virus.</ORIGINAL_TEXT>
<TOKEN end_char="487" id="token-5-0" morph="none" pos="word" start_char="485">The</TOKEN>
<TOKEN end_char="491" id="token-5-1" morph="none" pos="unknown" start_char="489">U.S</TOKEN>
<TOKEN end_char="492" id="token-5-2" morph="none" pos="punct" start_char="492">.</TOKEN>
<TOKEN end_char="500" id="token-5-3" morph="none" pos="word" start_char="494">Centers</TOKEN>
<TOKEN end_char="504" id="token-5-4" morph="none" pos="word" start_char="502">for</TOKEN>
<TOKEN end_char="512" id="token-5-5" morph="none" pos="word" start_char="506">Disease</TOKEN>
<TOKEN end_char="520" id="token-5-6" morph="none" pos="word" start_char="514">Control</TOKEN>
<TOKEN end_char="524" id="token-5-7" morph="none" pos="word" start_char="522">and</TOKEN>
<TOKEN end_char="535" id="token-5-8" morph="none" pos="word" start_char="526">Prevention</TOKEN>
<TOKEN end_char="545" id="token-5-9" morph="none" pos="word" start_char="537">continues</TOKEN>
<TOKEN end_char="548" id="token-5-10" morph="none" pos="word" start_char="547">to</TOKEN>
<TOKEN end_char="558" id="token-5-11" morph="none" pos="word" start_char="550">recommend</TOKEN>
<TOKEN end_char="566" id="token-5-12" morph="none" pos="word" start_char="560">wearing</TOKEN>
<TOKEN end_char="571" id="token-5-13" morph="none" pos="word" start_char="568">face</TOKEN>
<TOKEN end_char="581" id="token-5-14" morph="none" pos="word" start_char="573">coverings</TOKEN>
<TOKEN end_char="584" id="token-5-15" morph="none" pos="word" start_char="583">to</TOKEN>
<TOKEN end_char="591" id="token-5-16" morph="none" pos="word" start_char="586">reduce</TOKEN>
<TOKEN end_char="595" id="token-5-17" morph="none" pos="word" start_char="593">the</TOKEN>
<TOKEN end_char="602" id="token-5-18" morph="none" pos="word" start_char="597">spread</TOKEN>
<TOKEN end_char="605" id="token-5-19" morph="none" pos="word" start_char="604">of</TOKEN>
<TOKEN end_char="614" id="token-5-20" morph="none" pos="unknown" start_char="607">COVID-19</TOKEN>
<TOKEN end_char="615" id="token-5-21" morph="none" pos="punct" start_char="615">,</TOKEN>
<TOKEN end_char="618" id="token-5-22" morph="none" pos="word" start_char="617">as</TOKEN>
<TOKEN end_char="627" id="token-5-23" morph="none" pos="word" start_char="620">research</TOKEN>
<TOKEN end_char="633" id="token-5-24" morph="none" pos="word" start_char="629">shows</TOKEN>
<TOKEN end_char="638" id="token-5-25" morph="none" pos="word" start_char="635">they</TOKEN>
<TOKEN end_char="642" id="token-5-26" morph="none" pos="word" start_char="640">can</TOKEN>
<TOKEN end_char="648" id="token-5-27" morph="none" pos="word" start_char="644">block</TOKEN>
<TOKEN end_char="652" id="token-5-28" morph="none" pos="word" start_char="650">the</TOKEN>
<TOKEN end_char="665" id="token-5-29" morph="none" pos="word" start_char="654">transmission</TOKEN>
<TOKEN end_char="668" id="token-5-30" morph="none" pos="word" start_char="667">of</TOKEN>
<TOKEN end_char="680" id="token-5-31" morph="none" pos="word" start_char="670">respiratory</TOKEN>
<TOKEN end_char="689" id="token-5-32" morph="none" pos="word" start_char="682">droplets</TOKEN>
<TOKEN end_char="690" id="token-5-33" morph="none" pos="punct" start_char="690">,</TOKEN>
<TOKEN end_char="696" id="token-5-34" morph="none" pos="word" start_char="692">which</TOKEN>
<TOKEN end_char="703" id="token-5-35" morph="none" pos="word" start_char="698">spread</TOKEN>
<TOKEN end_char="707" id="token-5-36" morph="none" pos="word" start_char="705">the</TOKEN>
<TOKEN end_char="713" id="token-5-37" morph="none" pos="word" start_char="709">virus</TOKEN>
<TOKEN end_char="714" id="token-5-38" morph="none" pos="punct" start_char="714">.</TOKEN>
</SEG>
<SEG end_char="955" id="segment-6" start_char="717">
<ORIGINAL_TEXT>THE FACTS: Websites and social media users ranging from political candidates to health influencers are falsely claiming a study published on a digital research repository came from Stanford University and proves face masks are ineffective.</ORIGINAL_TEXT>
<TOKEN end_char="719" id="token-6-0" morph="none" pos="word" start_char="717">THE</TOKEN>
<TOKEN end_char="725" id="token-6-1" morph="none" pos="word" start_char="721">FACTS</TOKEN>
<TOKEN end_char="726" id="token-6-2" morph="none" pos="punct" start_char="726">:</TOKEN>
<TOKEN end_char="735" id="token-6-3" morph="none" pos="word" start_char="728">Websites</TOKEN>
<TOKEN end_char="739" id="token-6-4" morph="none" pos="word" start_char="737">and</TOKEN>
<TOKEN end_char="746" id="token-6-5" morph="none" pos="word" start_char="741">social</TOKEN>
<TOKEN end_char="752" id="token-6-6" morph="none" pos="word" start_char="748">media</TOKEN>
<TOKEN end_char="758" id="token-6-7" morph="none" pos="word" start_char="754">users</TOKEN>
<TOKEN end_char="766" id="token-6-8" morph="none" pos="word" start_char="760">ranging</TOKEN>
<TOKEN end_char="771" id="token-6-9" morph="none" pos="word" start_char="768">from</TOKEN>
<TOKEN end_char="781" id="token-6-10" morph="none" pos="word" start_char="773">political</TOKEN>
<TOKEN end_char="792" id="token-6-11" morph="none" pos="word" start_char="783">candidates</TOKEN>
<TOKEN end_char="795" id="token-6-12" morph="none" pos="word" start_char="794">to</TOKEN>
<TOKEN end_char="802" id="token-6-13" morph="none" pos="word" start_char="797">health</TOKEN>
<TOKEN end_char="814" id="token-6-14" morph="none" pos="word" start_char="804">influencers</TOKEN>
<TOKEN end_char="818" id="token-6-15" morph="none" pos="word" start_char="816">are</TOKEN>
<TOKEN end_char="826" id="token-6-16" morph="none" pos="word" start_char="820">falsely</TOKEN>
<TOKEN end_char="835" id="token-6-17" morph="none" pos="word" start_char="828">claiming</TOKEN>
<TOKEN end_char="837" id="token-6-18" morph="none" pos="word" start_char="837">a</TOKEN>
<TOKEN end_char="843" id="token-6-19" morph="none" pos="word" start_char="839">study</TOKEN>
<TOKEN end_char="853" id="token-6-20" morph="none" pos="word" start_char="845">published</TOKEN>
<TOKEN end_char="856" id="token-6-21" morph="none" pos="word" start_char="855">on</TOKEN>
<TOKEN end_char="858" id="token-6-22" morph="none" pos="word" start_char="858">a</TOKEN>
<TOKEN end_char="866" id="token-6-23" morph="none" pos="word" start_char="860">digital</TOKEN>
<TOKEN end_char="875" id="token-6-24" morph="none" pos="word" start_char="868">research</TOKEN>
<TOKEN end_char="886" id="token-6-25" morph="none" pos="word" start_char="877">repository</TOKEN>
<TOKEN end_char="891" id="token-6-26" morph="none" pos="word" start_char="888">came</TOKEN>
<TOKEN end_char="896" id="token-6-27" morph="none" pos="word" start_char="893">from</TOKEN>
<TOKEN end_char="905" id="token-6-28" morph="none" pos="word" start_char="898">Stanford</TOKEN>
<TOKEN end_char="916" id="token-6-29" morph="none" pos="word" start_char="907">University</TOKEN>
<TOKEN end_char="920" id="token-6-30" morph="none" pos="word" start_char="918">and</TOKEN>
<TOKEN end_char="927" id="token-6-31" morph="none" pos="word" start_char="922">proves</TOKEN>
<TOKEN end_char="932" id="token-6-32" morph="none" pos="word" start_char="929">face</TOKEN>
<TOKEN end_char="938" id="token-6-33" morph="none" pos="word" start_char="934">masks</TOKEN>
<TOKEN end_char="942" id="token-6-34" morph="none" pos="word" start_char="940">are</TOKEN>
<TOKEN end_char="954" id="token-6-35" morph="none" pos="word" start_char="944">ineffective</TOKEN>
<TOKEN end_char="955" id="token-6-36" morph="none" pos="punct" start_char="955">.</TOKEN>
</SEG>
<SEG end_char="1177" id="segment-7" start_char="958">
<ORIGINAL_TEXT>In reality, the study is not affiliated with Stanford and is based on debunked claims about face masks, including the false notion that wearing a face covering decreases oxygen levels and increases carbon dioxide levels.</ORIGINAL_TEXT>
<TOKEN end_char="959" id="token-7-0" morph="none" pos="word" start_char="958">In</TOKEN>
<TOKEN end_char="967" id="token-7-1" morph="none" pos="word" start_char="961">reality</TOKEN>
<TOKEN end_char="968" id="token-7-2" morph="none" pos="punct" start_char="968">,</TOKEN>
<TOKEN end_char="972" id="token-7-3" morph="none" pos="word" start_char="970">the</TOKEN>
<TOKEN end_char="978" id="token-7-4" morph="none" pos="word" start_char="974">study</TOKEN>
<TOKEN end_char="981" id="token-7-5" morph="none" pos="word" start_char="980">is</TOKEN>
<TOKEN end_char="985" id="token-7-6" morph="none" pos="word" start_char="983">not</TOKEN>
<TOKEN end_char="996" id="token-7-7" morph="none" pos="word" start_char="987">affiliated</TOKEN>
<TOKEN end_char="1001" id="token-7-8" morph="none" pos="word" start_char="998">with</TOKEN>
<TOKEN end_char="1010" id="token-7-9" morph="none" pos="word" start_char="1003">Stanford</TOKEN>
<TOKEN end_char="1014" id="token-7-10" morph="none" pos="word" start_char="1012">and</TOKEN>
<TOKEN end_char="1017" id="token-7-11" morph="none" pos="word" start_char="1016">is</TOKEN>
<TOKEN end_char="1023" id="token-7-12" morph="none" pos="word" start_char="1019">based</TOKEN>
<TOKEN end_char="1026" id="token-7-13" morph="none" pos="word" start_char="1025">on</TOKEN>
<TOKEN end_char="1035" id="token-7-14" morph="none" pos="word" start_char="1028">debunked</TOKEN>
<TOKEN end_char="1042" id="token-7-15" morph="none" pos="word" start_char="1037">claims</TOKEN>
<TOKEN end_char="1048" id="token-7-16" morph="none" pos="word" start_char="1044">about</TOKEN>
<TOKEN end_char="1053" id="token-7-17" morph="none" pos="word" start_char="1050">face</TOKEN>
<TOKEN end_char="1059" id="token-7-18" morph="none" pos="word" start_char="1055">masks</TOKEN>
<TOKEN end_char="1060" id="token-7-19" morph="none" pos="punct" start_char="1060">,</TOKEN>
<TOKEN end_char="1070" id="token-7-20" morph="none" pos="word" start_char="1062">including</TOKEN>
<TOKEN end_char="1074" id="token-7-21" morph="none" pos="word" start_char="1072">the</TOKEN>
<TOKEN end_char="1080" id="token-7-22" morph="none" pos="word" start_char="1076">false</TOKEN>
<TOKEN end_char="1087" id="token-7-23" morph="none" pos="word" start_char="1082">notion</TOKEN>
<TOKEN end_char="1092" id="token-7-24" morph="none" pos="word" start_char="1089">that</TOKEN>
<TOKEN end_char="1100" id="token-7-25" morph="none" pos="word" start_char="1094">wearing</TOKEN>
<TOKEN end_char="1102" id="token-7-26" morph="none" pos="word" start_char="1102">a</TOKEN>
<TOKEN end_char="1107" id="token-7-27" morph="none" pos="word" start_char="1104">face</TOKEN>
<TOKEN end_char="1116" id="token-7-28" morph="none" pos="word" start_char="1109">covering</TOKEN>
<TOKEN end_char="1126" id="token-7-29" morph="none" pos="word" start_char="1118">decreases</TOKEN>
<TOKEN end_char="1133" id="token-7-30" morph="none" pos="word" start_char="1128">oxygen</TOKEN>
<TOKEN end_char="1140" id="token-7-31" morph="none" pos="word" start_char="1135">levels</TOKEN>
<TOKEN end_char="1144" id="token-7-32" morph="none" pos="word" start_char="1142">and</TOKEN>
<TOKEN end_char="1154" id="token-7-33" morph="none" pos="word" start_char="1146">increases</TOKEN>
<TOKEN end_char="1161" id="token-7-34" morph="none" pos="word" start_char="1156">carbon</TOKEN>
<TOKEN end_char="1169" id="token-7-35" morph="none" pos="word" start_char="1163">dioxide</TOKEN>
<TOKEN end_char="1176" id="token-7-36" morph="none" pos="word" start_char="1171">levels</TOKEN>
<TOKEN end_char="1177" id="token-7-37" morph="none" pos="punct" start_char="1177">.</TOKEN>
</SEG>
<SEG end_char="1326" id="segment-8" start_char="1180">
<ORIGINAL_TEXT>"Stanford peer review study on masks says they basically do not work for C-19," the local North Dakota TV show POVNow posted on Facebook on Monday.</ORIGINAL_TEXT>
<TOKEN end_char="1180" id="token-8-0" morph="none" pos="punct" start_char="1180">"</TOKEN>
<TOKEN end_char="1188" id="token-8-1" morph="none" pos="word" start_char="1181">Stanford</TOKEN>
<TOKEN end_char="1193" id="token-8-2" morph="none" pos="word" start_char="1190">peer</TOKEN>
<TOKEN end_char="1200" id="token-8-3" morph="none" pos="word" start_char="1195">review</TOKEN>
<TOKEN end_char="1206" id="token-8-4" morph="none" pos="word" start_char="1202">study</TOKEN>
<TOKEN end_char="1209" id="token-8-5" morph="none" pos="word" start_char="1208">on</TOKEN>
<TOKEN end_char="1215" id="token-8-6" morph="none" pos="word" start_char="1211">masks</TOKEN>
<TOKEN end_char="1220" id="token-8-7" morph="none" pos="word" start_char="1217">says</TOKEN>
<TOKEN end_char="1225" id="token-8-8" morph="none" pos="word" start_char="1222">they</TOKEN>
<TOKEN end_char="1235" id="token-8-9" morph="none" pos="word" start_char="1227">basically</TOKEN>
<TOKEN end_char="1238" id="token-8-10" morph="none" pos="word" start_char="1237">do</TOKEN>
<TOKEN end_char="1242" id="token-8-11" morph="none" pos="word" start_char="1240">not</TOKEN>
<TOKEN end_char="1247" id="token-8-12" morph="none" pos="word" start_char="1244">work</TOKEN>
<TOKEN end_char="1251" id="token-8-13" morph="none" pos="word" start_char="1249">for</TOKEN>
<TOKEN end_char="1256" id="token-8-14" morph="none" pos="unknown" start_char="1253">C-19</TOKEN>
<TOKEN end_char="1258" id="token-8-15" morph="none" pos="punct" start_char="1257">,"</TOKEN>
<TOKEN end_char="1262" id="token-8-16" morph="none" pos="word" start_char="1260">the</TOKEN>
<TOKEN end_char="1268" id="token-8-17" morph="none" pos="word" start_char="1264">local</TOKEN>
<TOKEN end_char="1274" id="token-8-18" morph="none" pos="word" start_char="1270">North</TOKEN>
<TOKEN end_char="1281" id="token-8-19" morph="none" pos="word" start_char="1276">Dakota</TOKEN>
<TOKEN end_char="1284" id="token-8-20" morph="none" pos="word" start_char="1283">TV</TOKEN>
<TOKEN end_char="1289" id="token-8-21" morph="none" pos="word" start_char="1286">show</TOKEN>
<TOKEN end_char="1296" id="token-8-22" morph="none" pos="word" start_char="1291">POVNow</TOKEN>
<TOKEN end_char="1303" id="token-8-23" morph="none" pos="word" start_char="1298">posted</TOKEN>
<TOKEN end_char="1306" id="token-8-24" morph="none" pos="word" start_char="1305">on</TOKEN>
<TOKEN end_char="1315" id="token-8-25" morph="none" pos="word" start_char="1308">Facebook</TOKEN>
<TOKEN end_char="1318" id="token-8-26" morph="none" pos="word" start_char="1317">on</TOKEN>
<TOKEN end_char="1325" id="token-8-27" morph="none" pos="word" start_char="1320">Monday</TOKEN>
<TOKEN end_char="1326" id="token-8-28" morph="none" pos="punct" start_char="1326">.</TOKEN>
</SEG>
<SEG end_char="1596" id="segment-9" start_char="1329">
<ORIGINAL_TEXT>"A recent Stanford study released by the NCBI, which is under the National Institutes of Health, showed that masks do absolutely nothing to help prevent the spread of COVID-19 and their use is even harmful," read a story on the conservative website The Gateway Pundit.</ORIGINAL_TEXT>
<TOKEN end_char="1329" id="token-9-0" morph="none" pos="punct" start_char="1329">"</TOKEN>
<TOKEN end_char="1330" id="token-9-1" morph="none" pos="word" start_char="1330">A</TOKEN>
<TOKEN end_char="1337" id="token-9-2" morph="none" pos="word" start_char="1332">recent</TOKEN>
<TOKEN end_char="1346" id="token-9-3" morph="none" pos="word" start_char="1339">Stanford</TOKEN>
<TOKEN end_char="1352" id="token-9-4" morph="none" pos="word" start_char="1348">study</TOKEN>
<TOKEN end_char="1361" id="token-9-5" morph="none" pos="word" start_char="1354">released</TOKEN>
<TOKEN end_char="1364" id="token-9-6" morph="none" pos="word" start_char="1363">by</TOKEN>
<TOKEN end_char="1368" id="token-9-7" morph="none" pos="word" start_char="1366">the</TOKEN>
<TOKEN end_char="1373" id="token-9-8" morph="none" pos="word" start_char="1370">NCBI</TOKEN>
<TOKEN end_char="1374" id="token-9-9" morph="none" pos="punct" start_char="1374">,</TOKEN>
<TOKEN end_char="1380" id="token-9-10" morph="none" pos="word" start_char="1376">which</TOKEN>
<TOKEN end_char="1383" id="token-9-11" morph="none" pos="word" start_char="1382">is</TOKEN>
<TOKEN end_char="1389" id="token-9-12" morph="none" pos="word" start_char="1385">under</TOKEN>
<TOKEN end_char="1393" id="token-9-13" morph="none" pos="word" start_char="1391">the</TOKEN>
<TOKEN end_char="1402" id="token-9-14" morph="none" pos="word" start_char="1395">National</TOKEN>
<TOKEN end_char="1413" id="token-9-15" morph="none" pos="word" start_char="1404">Institutes</TOKEN>
<TOKEN end_char="1416" id="token-9-16" morph="none" pos="word" start_char="1415">of</TOKEN>
<TOKEN end_char="1423" id="token-9-17" morph="none" pos="word" start_char="1418">Health</TOKEN>
<TOKEN end_char="1424" id="token-9-18" morph="none" pos="punct" start_char="1424">,</TOKEN>
<TOKEN end_char="1431" id="token-9-19" morph="none" pos="word" start_char="1426">showed</TOKEN>
<TOKEN end_char="1436" id="token-9-20" morph="none" pos="word" start_char="1433">that</TOKEN>
<TOKEN end_char="1442" id="token-9-21" morph="none" pos="word" start_char="1438">masks</TOKEN>
<TOKEN end_char="1445" id="token-9-22" morph="none" pos="word" start_char="1444">do</TOKEN>
<TOKEN end_char="1456" id="token-9-23" morph="none" pos="word" start_char="1447">absolutely</TOKEN>
<TOKEN end_char="1464" id="token-9-24" morph="none" pos="word" start_char="1458">nothing</TOKEN>
<TOKEN end_char="1467" id="token-9-25" morph="none" pos="word" start_char="1466">to</TOKEN>
<TOKEN end_char="1472" id="token-9-26" morph="none" pos="word" start_char="1469">help</TOKEN>
<TOKEN end_char="1480" id="token-9-27" morph="none" pos="word" start_char="1474">prevent</TOKEN>
<TOKEN end_char="1484" id="token-9-28" morph="none" pos="word" start_char="1482">the</TOKEN>
<TOKEN end_char="1491" id="token-9-29" morph="none" pos="word" start_char="1486">spread</TOKEN>
<TOKEN end_char="1494" id="token-9-30" morph="none" pos="word" start_char="1493">of</TOKEN>
<TOKEN end_char="1503" id="token-9-31" morph="none" pos="unknown" start_char="1496">COVID-19</TOKEN>
<TOKEN end_char="1507" id="token-9-32" morph="none" pos="word" start_char="1505">and</TOKEN>
<TOKEN end_char="1513" id="token-9-33" morph="none" pos="word" start_char="1509">their</TOKEN>
<TOKEN end_char="1517" id="token-9-34" morph="none" pos="word" start_char="1515">use</TOKEN>
<TOKEN end_char="1520" id="token-9-35" morph="none" pos="word" start_char="1519">is</TOKEN>
<TOKEN end_char="1525" id="token-9-36" morph="none" pos="word" start_char="1522">even</TOKEN>
<TOKEN end_char="1533" id="token-9-37" morph="none" pos="word" start_char="1527">harmful</TOKEN>
<TOKEN end_char="1535" id="token-9-38" morph="none" pos="punct" start_char="1534">,"</TOKEN>
<TOKEN end_char="1540" id="token-9-39" morph="none" pos="word" start_char="1537">read</TOKEN>
<TOKEN end_char="1542" id="token-9-40" morph="none" pos="word" start_char="1542">a</TOKEN>
<TOKEN end_char="1548" id="token-9-41" morph="none" pos="word" start_char="1544">story</TOKEN>
<TOKEN end_char="1551" id="token-9-42" morph="none" pos="word" start_char="1550">on</TOKEN>
<TOKEN end_char="1555" id="token-9-43" morph="none" pos="word" start_char="1553">the</TOKEN>
<TOKEN end_char="1568" id="token-9-44" morph="none" pos="word" start_char="1557">conservative</TOKEN>
<TOKEN end_char="1576" id="token-9-45" morph="none" pos="word" start_char="1570">website</TOKEN>
<TOKEN end_char="1580" id="token-9-46" morph="none" pos="word" start_char="1578">The</TOKEN>
<TOKEN end_char="1588" id="token-9-47" morph="none" pos="word" start_char="1582">Gateway</TOKEN>
<TOKEN end_char="1595" id="token-9-48" morph="none" pos="word" start_char="1590">Pundit</TOKEN>
<TOKEN end_char="1596" id="token-9-49" morph="none" pos="punct" start_char="1596">.</TOKEN>
</SEG>
<SEG end_char="1729" id="segment-10" start_char="1598">
<ORIGINAL_TEXT>The story was shared widely on Facebook and Twitter this week, including by Josh Mandel, a Republican U.S. Senate candidate in Ohio.</ORIGINAL_TEXT>
<TOKEN end_char="1600" id="token-10-0" morph="none" pos="word" start_char="1598">The</TOKEN>
<TOKEN end_char="1606" id="token-10-1" morph="none" pos="word" start_char="1602">story</TOKEN>
<TOKEN end_char="1610" id="token-10-2" morph="none" pos="word" start_char="1608">was</TOKEN>
<TOKEN end_char="1617" id="token-10-3" morph="none" pos="word" start_char="1612">shared</TOKEN>
<TOKEN end_char="1624" id="token-10-4" morph="none" pos="word" start_char="1619">widely</TOKEN>
<TOKEN end_char="1627" id="token-10-5" morph="none" pos="word" start_char="1626">on</TOKEN>
<TOKEN end_char="1636" id="token-10-6" morph="none" pos="word" start_char="1629">Facebook</TOKEN>
<TOKEN end_char="1640" id="token-10-7" morph="none" pos="word" start_char="1638">and</TOKEN>
<TOKEN end_char="1648" id="token-10-8" morph="none" pos="word" start_char="1642">Twitter</TOKEN>
<TOKEN end_char="1653" id="token-10-9" morph="none" pos="word" start_char="1650">this</TOKEN>
<TOKEN end_char="1658" id="token-10-10" morph="none" pos="word" start_char="1655">week</TOKEN>
<TOKEN end_char="1659" id="token-10-11" morph="none" pos="punct" start_char="1659">,</TOKEN>
<TOKEN end_char="1669" id="token-10-12" morph="none" pos="word" start_char="1661">including</TOKEN>
<TOKEN end_char="1672" id="token-10-13" morph="none" pos="word" start_char="1671">by</TOKEN>
<TOKEN end_char="1677" id="token-10-14" morph="none" pos="word" start_char="1674">Josh</TOKEN>
<TOKEN end_char="1684" id="token-10-15" morph="none" pos="word" start_char="1679">Mandel</TOKEN>
<TOKEN end_char="1685" id="token-10-16" morph="none" pos="punct" start_char="1685">,</TOKEN>
<TOKEN end_char="1687" id="token-10-17" morph="none" pos="word" start_char="1687">a</TOKEN>
<TOKEN end_char="1698" id="token-10-18" morph="none" pos="word" start_char="1689">Republican</TOKEN>
<TOKEN end_char="1702" id="token-10-19" morph="none" pos="unknown" start_char="1700">U.S</TOKEN>
<TOKEN end_char="1703" id="token-10-20" morph="none" pos="punct" start_char="1703">.</TOKEN>
<TOKEN end_char="1710" id="token-10-21" morph="none" pos="word" start_char="1705">Senate</TOKEN>
<TOKEN end_char="1720" id="token-10-22" morph="none" pos="word" start_char="1712">candidate</TOKEN>
<TOKEN end_char="1723" id="token-10-23" morph="none" pos="word" start_char="1722">in</TOKEN>
<TOKEN end_char="1728" id="token-10-24" morph="none" pos="word" start_char="1725">Ohio</TOKEN>
<TOKEN end_char="1729" id="token-10-25" morph="none" pos="punct" start_char="1729">.</TOKEN>
</SEG>
<SEG end_char="1959" id="segment-11" start_char="1732">
<ORIGINAL_TEXT>The study, titled "Facemasks in the COVID-19 era: A health hypothesis," claims that "scientific evidence supporting facemasks’ efficacy is lacking" while "adverse physiological, psychological and health effects are established."</ORIGINAL_TEXT>
<TOKEN end_char="1734" id="token-11-0" morph="none" pos="word" start_char="1732">The</TOKEN>
<TOKEN end_char="1740" id="token-11-1" morph="none" pos="word" start_char="1736">study</TOKEN>
<TOKEN end_char="1741" id="token-11-2" morph="none" pos="punct" start_char="1741">,</TOKEN>
<TOKEN end_char="1748" id="token-11-3" morph="none" pos="word" start_char="1743">titled</TOKEN>
<TOKEN end_char="1750" id="token-11-4" morph="none" pos="punct" start_char="1750">"</TOKEN>
<TOKEN end_char="1759" id="token-11-5" morph="none" pos="word" start_char="1751">Facemasks</TOKEN>
<TOKEN end_char="1762" id="token-11-6" morph="none" pos="word" start_char="1761">in</TOKEN>
<TOKEN end_char="1766" id="token-11-7" morph="none" pos="word" start_char="1764">the</TOKEN>
<TOKEN end_char="1775" id="token-11-8" morph="none" pos="unknown" start_char="1768">COVID-19</TOKEN>
<TOKEN end_char="1779" id="token-11-9" morph="none" pos="word" start_char="1777">era</TOKEN>
<TOKEN end_char="1780" id="token-11-10" morph="none" pos="punct" start_char="1780">:</TOKEN>
<TOKEN end_char="1782" id="token-11-11" morph="none" pos="word" start_char="1782">A</TOKEN>
<TOKEN end_char="1789" id="token-11-12" morph="none" pos="word" start_char="1784">health</TOKEN>
<TOKEN end_char="1800" id="token-11-13" morph="none" pos="word" start_char="1791">hypothesis</TOKEN>
<TOKEN end_char="1802" id="token-11-14" morph="none" pos="punct" start_char="1801">,"</TOKEN>
<TOKEN end_char="1809" id="token-11-15" morph="none" pos="word" start_char="1804">claims</TOKEN>
<TOKEN end_char="1814" id="token-11-16" morph="none" pos="word" start_char="1811">that</TOKEN>
<TOKEN end_char="1816" id="token-11-17" morph="none" pos="punct" start_char="1816">"</TOKEN>
<TOKEN end_char="1826" id="token-11-18" morph="none" pos="word" start_char="1817">scientific</TOKEN>
<TOKEN end_char="1835" id="token-11-19" morph="none" pos="word" start_char="1828">evidence</TOKEN>
<TOKEN end_char="1846" id="token-11-20" morph="none" pos="word" start_char="1837">supporting</TOKEN>
<TOKEN end_char="1856" id="token-11-21" morph="none" pos="word" start_char="1848">facemasks</TOKEN>
<TOKEN end_char="1857" id="token-11-22" morph="none" pos="punct" start_char="1857">’</TOKEN>
<TOKEN end_char="1866" id="token-11-23" morph="none" pos="word" start_char="1859">efficacy</TOKEN>
<TOKEN end_char="1869" id="token-11-24" morph="none" pos="word" start_char="1868">is</TOKEN>
<TOKEN end_char="1877" id="token-11-25" morph="none" pos="word" start_char="1871">lacking</TOKEN>
<TOKEN end_char="1878" id="token-11-26" morph="none" pos="punct" start_char="1878">"</TOKEN>
<TOKEN end_char="1884" id="token-11-27" morph="none" pos="word" start_char="1880">while</TOKEN>
<TOKEN end_char="1886" id="token-11-28" morph="none" pos="punct" start_char="1886">"</TOKEN>
<TOKEN end_char="1893" id="token-11-29" morph="none" pos="word" start_char="1887">adverse</TOKEN>
<TOKEN end_char="1907" id="token-11-30" morph="none" pos="word" start_char="1895">physiological</TOKEN>
<TOKEN end_char="1908" id="token-11-31" morph="none" pos="punct" start_char="1908">,</TOKEN>
<TOKEN end_char="1922" id="token-11-32" morph="none" pos="word" start_char="1910">psychological</TOKEN>
<TOKEN end_char="1926" id="token-11-33" morph="none" pos="word" start_char="1924">and</TOKEN>
<TOKEN end_char="1933" id="token-11-34" morph="none" pos="word" start_char="1928">health</TOKEN>
<TOKEN end_char="1941" id="token-11-35" morph="none" pos="word" start_char="1935">effects</TOKEN>
<TOKEN end_char="1945" id="token-11-36" morph="none" pos="word" start_char="1943">are</TOKEN>
<TOKEN end_char="1957" id="token-11-37" morph="none" pos="word" start_char="1947">established</TOKEN>
<TOKEN end_char="1959" id="token-11-38" morph="none" pos="punct" start_char="1958">."</TOKEN>
</SEG>
<SEG end_char="2153" id="segment-12" start_char="1961">
<ORIGINAL_TEXT>It makes a variety of claims about negative health impacts of masks, including the false claim that wearing a face mask restricts breathing, leading to the conditions hypoxemia and hypercapnia.</ORIGINAL_TEXT>
<TOKEN end_char="1962" id="token-12-0" morph="none" pos="word" start_char="1961">It</TOKEN>
<TOKEN end_char="1968" id="token-12-1" morph="none" pos="word" start_char="1964">makes</TOKEN>
<TOKEN end_char="1970" id="token-12-2" morph="none" pos="word" start_char="1970">a</TOKEN>
<TOKEN end_char="1978" id="token-12-3" morph="none" pos="word" start_char="1972">variety</TOKEN>
<TOKEN end_char="1981" id="token-12-4" morph="none" pos="word" start_char="1980">of</TOKEN>
<TOKEN end_char="1988" id="token-12-5" morph="none" pos="word" start_char="1983">claims</TOKEN>
<TOKEN end_char="1994" id="token-12-6" morph="none" pos="word" start_char="1990">about</TOKEN>
<TOKEN end_char="2003" id="token-12-7" morph="none" pos="word" start_char="1996">negative</TOKEN>
<TOKEN end_char="2010" id="token-12-8" morph="none" pos="word" start_char="2005">health</TOKEN>
<TOKEN end_char="2018" id="token-12-9" morph="none" pos="word" start_char="2012">impacts</TOKEN>
<TOKEN end_char="2021" id="token-12-10" morph="none" pos="word" start_char="2020">of</TOKEN>
<TOKEN end_char="2027" id="token-12-11" morph="none" pos="word" start_char="2023">masks</TOKEN>
<TOKEN end_char="2028" id="token-12-12" morph="none" pos="punct" start_char="2028">,</TOKEN>
<TOKEN end_char="2038" id="token-12-13" morph="none" pos="word" start_char="2030">including</TOKEN>
<TOKEN end_char="2042" id="token-12-14" morph="none" pos="word" start_char="2040">the</TOKEN>
<TOKEN end_char="2048" id="token-12-15" morph="none" pos="word" start_char="2044">false</TOKEN>
<TOKEN end_char="2054" id="token-12-16" morph="none" pos="word" start_char="2050">claim</TOKEN>
<TOKEN end_char="2059" id="token-12-17" morph="none" pos="word" start_char="2056">that</TOKEN>
<TOKEN end_char="2067" id="token-12-18" morph="none" pos="word" start_char="2061">wearing</TOKEN>
<TOKEN end_char="2069" id="token-12-19" morph="none" pos="word" start_char="2069">a</TOKEN>
<TOKEN end_char="2074" id="token-12-20" morph="none" pos="word" start_char="2071">face</TOKEN>
<TOKEN end_char="2079" id="token-12-21" morph="none" pos="word" start_char="2076">mask</TOKEN>
<TOKEN end_char="2089" id="token-12-22" morph="none" pos="word" start_char="2081">restricts</TOKEN>
<TOKEN end_char="2099" id="token-12-23" morph="none" pos="word" start_char="2091">breathing</TOKEN>
<TOKEN end_char="2100" id="token-12-24" morph="none" pos="punct" start_char="2100">,</TOKEN>
<TOKEN end_char="2108" id="token-12-25" morph="none" pos="word" start_char="2102">leading</TOKEN>
<TOKEN end_char="2111" id="token-12-26" morph="none" pos="word" start_char="2110">to</TOKEN>
<TOKEN end_char="2115" id="token-12-27" morph="none" pos="word" start_char="2113">the</TOKEN>
<TOKEN end_char="2126" id="token-12-28" morph="none" pos="word" start_char="2117">conditions</TOKEN>
<TOKEN end_char="2136" id="token-12-29" morph="none" pos="word" start_char="2128">hypoxemia</TOKEN>
<TOKEN end_char="2140" id="token-12-30" morph="none" pos="word" start_char="2138">and</TOKEN>
<TOKEN end_char="2152" id="token-12-31" morph="none" pos="word" start_char="2142">hypercapnia</TOKEN>
<TOKEN end_char="2153" id="token-12-32" morph="none" pos="punct" start_char="2153">.</TOKEN>
</SEG>
<SEG end_char="2329" id="segment-13" start_char="2156">
<ORIGINAL_TEXT>Many doctors have taken to social media to debunk claims about oxygen levels and masks, and The Associated Press also has previously debunked false claims about health risks.</ORIGINAL_TEXT>
<TOKEN end_char="2159" id="token-13-0" morph="none" pos="word" start_char="2156">Many</TOKEN>
<TOKEN end_char="2167" id="token-13-1" morph="none" pos="word" start_char="2161">doctors</TOKEN>
<TOKEN end_char="2172" id="token-13-2" morph="none" pos="word" start_char="2169">have</TOKEN>
<TOKEN end_char="2178" id="token-13-3" morph="none" pos="word" start_char="2174">taken</TOKEN>
<TOKEN end_char="2181" id="token-13-4" morph="none" pos="word" start_char="2180">to</TOKEN>
<TOKEN end_char="2188" id="token-13-5" morph="none" pos="word" start_char="2183">social</TOKEN>
<TOKEN end_char="2194" id="token-13-6" morph="none" pos="word" start_char="2190">media</TOKEN>
<TOKEN end_char="2197" id="token-13-7" morph="none" pos="word" start_char="2196">to</TOKEN>
<TOKEN end_char="2204" id="token-13-8" morph="none" pos="word" start_char="2199">debunk</TOKEN>
<TOKEN end_char="2211" id="token-13-9" morph="none" pos="word" start_char="2206">claims</TOKEN>
<TOKEN end_char="2217" id="token-13-10" morph="none" pos="word" start_char="2213">about</TOKEN>
<TOKEN end_char="2224" id="token-13-11" morph="none" pos="word" start_char="2219">oxygen</TOKEN>
<TOKEN end_char="2231" id="token-13-12" morph="none" pos="word" start_char="2226">levels</TOKEN>
<TOKEN end_char="2235" id="token-13-13" morph="none" pos="word" start_char="2233">and</TOKEN>
<TOKEN end_char="2241" id="token-13-14" morph="none" pos="word" start_char="2237">masks</TOKEN>
<TOKEN end_char="2242" id="token-13-15" morph="none" pos="punct" start_char="2242">,</TOKEN>
<TOKEN end_char="2246" id="token-13-16" morph="none" pos="word" start_char="2244">and</TOKEN>
<TOKEN end_char="2250" id="token-13-17" morph="none" pos="word" start_char="2248">The</TOKEN>
<TOKEN end_char="2261" id="token-13-18" morph="none" pos="word" start_char="2252">Associated</TOKEN>
<TOKEN end_char="2267" id="token-13-19" morph="none" pos="word" start_char="2263">Press</TOKEN>
<TOKEN end_char="2272" id="token-13-20" morph="none" pos="word" start_char="2269">also</TOKEN>
<TOKEN end_char="2276" id="token-13-21" morph="none" pos="word" start_char="2274">has</TOKEN>
<TOKEN end_char="2287" id="token-13-22" morph="none" pos="word" start_char="2278">previously</TOKEN>
<TOKEN end_char="2296" id="token-13-23" morph="none" pos="word" start_char="2289">debunked</TOKEN>
<TOKEN end_char="2302" id="token-13-24" morph="none" pos="word" start_char="2298">false</TOKEN>
<TOKEN end_char="2309" id="token-13-25" morph="none" pos="word" start_char="2304">claims</TOKEN>
<TOKEN end_char="2315" id="token-13-26" morph="none" pos="word" start_char="2311">about</TOKEN>
<TOKEN end_char="2322" id="token-13-27" morph="none" pos="word" start_char="2317">health</TOKEN>
<TOKEN end_char="2328" id="token-13-28" morph="none" pos="word" start_char="2324">risks</TOKEN>
<TOKEN end_char="2329" id="token-13-29" morph="none" pos="punct" start_char="2329">.</TOKEN>
</SEG>
<SEG end_char="2334" id="segment-14" start_char="2332">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN end_char="2333" id="token-14-0" morph="none" pos="word" start_char="2332">Dr</TOKEN>
<TOKEN end_char="2334" id="token-14-1" morph="none" pos="punct" start_char="2334">.</TOKEN>
<TRANSLATED_TEXT>dr.</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="2515" id="segment-15" start_char="2336">
<ORIGINAL_TEXT>Michael Niederman, a pulmonologist at Weill Cornell Medicine, previously told the AP that wearing masks does not decrease oxygen levels, nor does it increase carbon dioxide levels.</ORIGINAL_TEXT>
<TOKEN end_char="2342" id="token-15-0" morph="none" pos="word" start_char="2336">Michael</TOKEN>
<TOKEN end_char="2352" id="token-15-1" morph="none" pos="word" start_char="2344">Niederman</TOKEN>
<TOKEN end_char="2353" id="token-15-2" morph="none" pos="punct" start_char="2353">,</TOKEN>
<TOKEN end_char="2355" id="token-15-3" morph="none" pos="word" start_char="2355">a</TOKEN>
<TOKEN end_char="2369" id="token-15-4" morph="none" pos="word" start_char="2357">pulmonologist</TOKEN>
<TOKEN end_char="2372" id="token-15-5" morph="none" pos="word" start_char="2371">at</TOKEN>
<TOKEN end_char="2378" id="token-15-6" morph="none" pos="word" start_char="2374">Weill</TOKEN>
<TOKEN end_char="2386" id="token-15-7" morph="none" pos="word" start_char="2380">Cornell</TOKEN>
<TOKEN end_char="2395" id="token-15-8" morph="none" pos="word" start_char="2388">Medicine</TOKEN>
<TOKEN end_char="2396" id="token-15-9" morph="none" pos="punct" start_char="2396">,</TOKEN>
<TOKEN end_char="2407" id="token-15-10" morph="none" pos="word" start_char="2398">previously</TOKEN>
<TOKEN end_char="2412" id="token-15-11" morph="none" pos="word" start_char="2409">told</TOKEN>
<TOKEN end_char="2416" id="token-15-12" morph="none" pos="word" start_char="2414">the</TOKEN>
<TOKEN end_char="2419" id="token-15-13" morph="none" pos="word" start_char="2418">AP</TOKEN>
<TOKEN end_char="2424" id="token-15-14" morph="none" pos="word" start_char="2421">that</TOKEN>
<TOKEN end_char="2432" id="token-15-15" morph="none" pos="word" start_char="2426">wearing</TOKEN>
<TOKEN end_char="2438" id="token-15-16" morph="none" pos="word" start_char="2434">masks</TOKEN>
<TOKEN end_char="2443" id="token-15-17" morph="none" pos="word" start_char="2440">does</TOKEN>
<TOKEN end_char="2447" id="token-15-18" morph="none" pos="word" start_char="2445">not</TOKEN>
<TOKEN end_char="2456" id="token-15-19" morph="none" pos="word" start_char="2449">decrease</TOKEN>
<TOKEN end_char="2463" id="token-15-20" morph="none" pos="word" start_char="2458">oxygen</TOKEN>
<TOKEN end_char="2470" id="token-15-21" morph="none" pos="word" start_char="2465">levels</TOKEN>
<TOKEN end_char="2471" id="token-15-22" morph="none" pos="punct" start_char="2471">,</TOKEN>
<TOKEN end_char="2475" id="token-15-23" morph="none" pos="word" start_char="2473">nor</TOKEN>
<TOKEN end_char="2480" id="token-15-24" morph="none" pos="word" start_char="2477">does</TOKEN>
<TOKEN end_char="2483" id="token-15-25" morph="none" pos="word" start_char="2482">it</TOKEN>
<TOKEN end_char="2492" id="token-15-26" morph="none" pos="word" start_char="2485">increase</TOKEN>
<TOKEN end_char="2499" id="token-15-27" morph="none" pos="word" start_char="2494">carbon</TOKEN>
<TOKEN end_char="2507" id="token-15-28" morph="none" pos="word" start_char="2501">dioxide</TOKEN>
<TOKEN end_char="2514" id="token-15-29" morph="none" pos="word" start_char="2509">levels</TOKEN>
<TOKEN end_char="2515" id="token-15-30" morph="none" pos="punct" start_char="2515">.</TOKEN>
</SEG>
<SEG end_char="2750" id="segment-16" start_char="2517">
<ORIGINAL_TEXT>Dr. Russell Buhr, a pulmonary and critical care physician at UCLA Health, said gas molecules are much smaller than the pores in the material so there is no significant restriction keeping the gas from moving through the mask material.</ORIGINAL_TEXT>
<TOKEN end_char="2518" id="token-16-0" morph="none" pos="word" start_char="2517">Dr</TOKEN>
<TOKEN end_char="2519" id="token-16-1" morph="none" pos="punct" start_char="2519">.</TOKEN>
<TOKEN end_char="2527" id="token-16-2" morph="none" pos="word" start_char="2521">Russell</TOKEN>
<TOKEN end_char="2532" id="token-16-3" morph="none" pos="word" start_char="2529">Buhr</TOKEN>
<TOKEN end_char="2533" id="token-16-4" morph="none" pos="punct" start_char="2533">,</TOKEN>
<TOKEN end_char="2535" id="token-16-5" morph="none" pos="word" start_char="2535">a</TOKEN>
<TOKEN end_char="2545" id="token-16-6" morph="none" pos="word" start_char="2537">pulmonary</TOKEN>
<TOKEN end_char="2549" id="token-16-7" morph="none" pos="word" start_char="2547">and</TOKEN>
<TOKEN end_char="2558" id="token-16-8" morph="none" pos="word" start_char="2551">critical</TOKEN>
<TOKEN end_char="2563" id="token-16-9" morph="none" pos="word" start_char="2560">care</TOKEN>
<TOKEN end_char="2573" id="token-16-10" morph="none" pos="word" start_char="2565">physician</TOKEN>
<TOKEN end_char="2576" id="token-16-11" morph="none" pos="word" start_char="2575">at</TOKEN>
<TOKEN end_char="2581" id="token-16-12" morph="none" pos="word" start_char="2578">UCLA</TOKEN>
<TOKEN end_char="2588" id="token-16-13" morph="none" pos="word" start_char="2583">Health</TOKEN>
<TOKEN end_char="2589" id="token-16-14" morph="none" pos="punct" start_char="2589">,</TOKEN>
<TOKEN end_char="2594" id="token-16-15" morph="none" pos="word" start_char="2591">said</TOKEN>
<TOKEN end_char="2598" id="token-16-16" morph="none" pos="word" start_char="2596">gas</TOKEN>
<TOKEN end_char="2608" id="token-16-17" morph="none" pos="word" start_char="2600">molecules</TOKEN>
<TOKEN end_char="2612" id="token-16-18" morph="none" pos="word" start_char="2610">are</TOKEN>
<TOKEN end_char="2617" id="token-16-19" morph="none" pos="word" start_char="2614">much</TOKEN>
<TOKEN end_char="2625" id="token-16-20" morph="none" pos="word" start_char="2619">smaller</TOKEN>
<TOKEN end_char="2630" id="token-16-21" morph="none" pos="word" start_char="2627">than</TOKEN>
<TOKEN end_char="2634" id="token-16-22" morph="none" pos="word" start_char="2632">the</TOKEN>
<TOKEN end_char="2640" id="token-16-23" morph="none" pos="word" start_char="2636">pores</TOKEN>
<TOKEN end_char="2643" id="token-16-24" morph="none" pos="word" start_char="2642">in</TOKEN>
<TOKEN end_char="2647" id="token-16-25" morph="none" pos="word" start_char="2645">the</TOKEN>
<TOKEN end_char="2656" id="token-16-26" morph="none" pos="word" start_char="2649">material</TOKEN>
<TOKEN end_char="2659" id="token-16-27" morph="none" pos="word" start_char="2658">so</TOKEN>
<TOKEN end_char="2665" id="token-16-28" morph="none" pos="word" start_char="2661">there</TOKEN>
<TOKEN end_char="2668" id="token-16-29" morph="none" pos="word" start_char="2667">is</TOKEN>
<TOKEN end_char="2671" id="token-16-30" morph="none" pos="word" start_char="2670">no</TOKEN>
<TOKEN end_char="2683" id="token-16-31" morph="none" pos="word" start_char="2673">significant</TOKEN>
<TOKEN end_char="2695" id="token-16-32" morph="none" pos="word" start_char="2685">restriction</TOKEN>
<TOKEN end_char="2703" id="token-16-33" morph="none" pos="word" start_char="2697">keeping</TOKEN>
<TOKEN end_char="2707" id="token-16-34" morph="none" pos="word" start_char="2705">the</TOKEN>
<TOKEN end_char="2711" id="token-16-35" morph="none" pos="word" start_char="2709">gas</TOKEN>
<TOKEN end_char="2716" id="token-16-36" morph="none" pos="word" start_char="2713">from</TOKEN>
<TOKEN end_char="2723" id="token-16-37" morph="none" pos="word" start_char="2718">moving</TOKEN>
<TOKEN end_char="2731" id="token-16-38" morph="none" pos="word" start_char="2725">through</TOKEN>
<TOKEN end_char="2735" id="token-16-39" morph="none" pos="word" start_char="2733">the</TOKEN>
<TOKEN end_char="2740" id="token-16-40" morph="none" pos="word" start_char="2737">mask</TOKEN>
<TOKEN end_char="2749" id="token-16-41" morph="none" pos="word" start_char="2742">material</TOKEN>
<TOKEN end_char="2750" id="token-16-42" morph="none" pos="punct" start_char="2750">.</TOKEN>
</SEG>
<SEG end_char="2877" id="segment-17" start_char="2753">
<ORIGINAL_TEXT>The study also claimed there was a lack of evidence for the effectiveness of face masks in preventing the spread of COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="2755" id="token-17-0" morph="none" pos="word" start_char="2753">The</TOKEN>
<TOKEN end_char="2761" id="token-17-1" morph="none" pos="word" start_char="2757">study</TOKEN>
<TOKEN end_char="2766" id="token-17-2" morph="none" pos="word" start_char="2763">also</TOKEN>
<TOKEN end_char="2774" id="token-17-3" morph="none" pos="word" start_char="2768">claimed</TOKEN>
<TOKEN end_char="2780" id="token-17-4" morph="none" pos="word" start_char="2776">there</TOKEN>
<TOKEN end_char="2784" id="token-17-5" morph="none" pos="word" start_char="2782">was</TOKEN>
<TOKEN end_char="2786" id="token-17-6" morph="none" pos="word" start_char="2786">a</TOKEN>
<TOKEN end_char="2791" id="token-17-7" morph="none" pos="word" start_char="2788">lack</TOKEN>
<TOKEN end_char="2794" id="token-17-8" morph="none" pos="word" start_char="2793">of</TOKEN>
<TOKEN end_char="2803" id="token-17-9" morph="none" pos="word" start_char="2796">evidence</TOKEN>
<TOKEN end_char="2807" id="token-17-10" morph="none" pos="word" start_char="2805">for</TOKEN>
<TOKEN end_char="2811" id="token-17-11" morph="none" pos="word" start_char="2809">the</TOKEN>
<TOKEN end_char="2825" id="token-17-12" morph="none" pos="word" start_char="2813">effectiveness</TOKEN>
<TOKEN end_char="2828" id="token-17-13" morph="none" pos="word" start_char="2827">of</TOKEN>
<TOKEN end_char="2833" id="token-17-14" morph="none" pos="word" start_char="2830">face</TOKEN>
<TOKEN end_char="2839" id="token-17-15" morph="none" pos="word" start_char="2835">masks</TOKEN>
<TOKEN end_char="2842" id="token-17-16" morph="none" pos="word" start_char="2841">in</TOKEN>
<TOKEN end_char="2853" id="token-17-17" morph="none" pos="word" start_char="2844">preventing</TOKEN>
<TOKEN end_char="2857" id="token-17-18" morph="none" pos="word" start_char="2855">the</TOKEN>
<TOKEN end_char="2864" id="token-17-19" morph="none" pos="word" start_char="2859">spread</TOKEN>
<TOKEN end_char="2867" id="token-17-20" morph="none" pos="word" start_char="2866">of</TOKEN>
<TOKEN end_char="2876" id="token-17-21" morph="none" pos="unknown" start_char="2869">COVID-19</TOKEN>
<TOKEN end_char="2877" id="token-17-22" morph="none" pos="punct" start_char="2877">.</TOKEN>
</SEG>
<SEG end_char="2988" id="segment-18" start_char="2879">
<ORIGINAL_TEXT>In fact, a recent study added strong evidence that statewide mask mandates slow the spread of the coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="2880" id="token-18-0" morph="none" pos="word" start_char="2879">In</TOKEN>
<TOKEN end_char="2885" id="token-18-1" morph="none" pos="word" start_char="2882">fact</TOKEN>
<TOKEN end_char="2886" id="token-18-2" morph="none" pos="punct" start_char="2886">,</TOKEN>
<TOKEN end_char="2888" id="token-18-3" morph="none" pos="word" start_char="2888">a</TOKEN>
<TOKEN end_char="2895" id="token-18-4" morph="none" pos="word" start_char="2890">recent</TOKEN>
<TOKEN end_char="2901" id="token-18-5" morph="none" pos="word" start_char="2897">study</TOKEN>
<TOKEN end_char="2907" id="token-18-6" morph="none" pos="word" start_char="2903">added</TOKEN>
<TOKEN end_char="2914" id="token-18-7" morph="none" pos="word" start_char="2909">strong</TOKEN>
<TOKEN end_char="2923" id="token-18-8" morph="none" pos="word" start_char="2916">evidence</TOKEN>
<TOKEN end_char="2928" id="token-18-9" morph="none" pos="word" start_char="2925">that</TOKEN>
<TOKEN end_char="2938" id="token-18-10" morph="none" pos="word" start_char="2930">statewide</TOKEN>
<TOKEN end_char="2943" id="token-18-11" morph="none" pos="word" start_char="2940">mask</TOKEN>
<TOKEN end_char="2952" id="token-18-12" morph="none" pos="word" start_char="2945">mandates</TOKEN>
<TOKEN end_char="2957" id="token-18-13" morph="none" pos="word" start_char="2954">slow</TOKEN>
<TOKEN end_char="2961" id="token-18-14" morph="none" pos="word" start_char="2959">the</TOKEN>
<TOKEN end_char="2968" id="token-18-15" morph="none" pos="word" start_char="2963">spread</TOKEN>
<TOKEN end_char="2971" id="token-18-16" morph="none" pos="word" start_char="2970">of</TOKEN>
<TOKEN end_char="2975" id="token-18-17" morph="none" pos="word" start_char="2973">the</TOKEN>
<TOKEN end_char="2987" id="token-18-18" morph="none" pos="word" start_char="2977">coronavirus</TOKEN>
<TOKEN end_char="2988" id="token-18-19" morph="none" pos="punct" start_char="2988">.</TOKEN>
</SEG>
<SEG end_char="3155" id="segment-19" start_char="2990">
<ORIGINAL_TEXT>Research shows masks block virus particles from spreading from infected people who wear them, and can even provide some protection to uninfected people who wear them.</ORIGINAL_TEXT>
<TOKEN end_char="2997" id="token-19-0" morph="none" pos="word" start_char="2990">Research</TOKEN>
<TOKEN end_char="3003" id="token-19-1" morph="none" pos="word" start_char="2999">shows</TOKEN>
<TOKEN end_char="3009" id="token-19-2" morph="none" pos="word" start_char="3005">masks</TOKEN>
<TOKEN end_char="3015" id="token-19-3" morph="none" pos="word" start_char="3011">block</TOKEN>
<TOKEN end_char="3021" id="token-19-4" morph="none" pos="word" start_char="3017">virus</TOKEN>
<TOKEN end_char="3031" id="token-19-5" morph="none" pos="word" start_char="3023">particles</TOKEN>
<TOKEN end_char="3036" id="token-19-6" morph="none" pos="word" start_char="3033">from</TOKEN>
<TOKEN end_char="3046" id="token-19-7" morph="none" pos="word" start_char="3038">spreading</TOKEN>
<TOKEN end_char="3051" id="token-19-8" morph="none" pos="word" start_char="3048">from</TOKEN>
<TOKEN end_char="3060" id="token-19-9" morph="none" pos="word" start_char="3053">infected</TOKEN>
<TOKEN end_char="3067" id="token-19-10" morph="none" pos="word" start_char="3062">people</TOKEN>
<TOKEN end_char="3071" id="token-19-11" morph="none" pos="word" start_char="3069">who</TOKEN>
<TOKEN end_char="3076" id="token-19-12" morph="none" pos="word" start_char="3073">wear</TOKEN>
<TOKEN end_char="3081" id="token-19-13" morph="none" pos="word" start_char="3078">them</TOKEN>
<TOKEN end_char="3082" id="token-19-14" morph="none" pos="punct" start_char="3082">,</TOKEN>
<TOKEN end_char="3086" id="token-19-15" morph="none" pos="word" start_char="3084">and</TOKEN>
<TOKEN end_char="3090" id="token-19-16" morph="none" pos="word" start_char="3088">can</TOKEN>
<TOKEN end_char="3095" id="token-19-17" morph="none" pos="word" start_char="3092">even</TOKEN>
<TOKEN end_char="3103" id="token-19-18" morph="none" pos="word" start_char="3097">provide</TOKEN>
<TOKEN end_char="3108" id="token-19-19" morph="none" pos="word" start_char="3105">some</TOKEN>
<TOKEN end_char="3119" id="token-19-20" morph="none" pos="word" start_char="3110">protection</TOKEN>
<TOKEN end_char="3122" id="token-19-21" morph="none" pos="word" start_char="3121">to</TOKEN>
<TOKEN end_char="3133" id="token-19-22" morph="none" pos="word" start_char="3124">uninfected</TOKEN>
<TOKEN end_char="3140" id="token-19-23" morph="none" pos="word" start_char="3135">people</TOKEN>
<TOKEN end_char="3144" id="token-19-24" morph="none" pos="word" start_char="3142">who</TOKEN>
<TOKEN end_char="3149" id="token-19-25" morph="none" pos="word" start_char="3146">wear</TOKEN>
<TOKEN end_char="3154" id="token-19-26" morph="none" pos="word" start_char="3151">them</TOKEN>
<TOKEN end_char="3155" id="token-19-27" morph="none" pos="punct" start_char="3155">.</TOKEN>
</SEG>
<SEG end_char="3342" id="segment-20" start_char="3158">
<ORIGINAL_TEXT>The study circulating online this week was first published in November in the journal "Medical Hypotheses," which writes that its purpose is to "publish interesting theoretical papers."</ORIGINAL_TEXT>
<TOKEN end_char="3160" id="token-20-0" morph="none" pos="word" start_char="3158">The</TOKEN>
<TOKEN end_char="3166" id="token-20-1" morph="none" pos="word" start_char="3162">study</TOKEN>
<TOKEN end_char="3178" id="token-20-2" morph="none" pos="word" start_char="3168">circulating</TOKEN>
<TOKEN end_char="3185" id="token-20-3" morph="none" pos="word" start_char="3180">online</TOKEN>
<TOKEN end_char="3190" id="token-20-4" morph="none" pos="word" start_char="3187">this</TOKEN>
<TOKEN end_char="3195" id="token-20-5" morph="none" pos="word" start_char="3192">week</TOKEN>
<TOKEN end_char="3199" id="token-20-6" morph="none" pos="word" start_char="3197">was</TOKEN>
<TOKEN end_char="3205" id="token-20-7" morph="none" pos="word" start_char="3201">first</TOKEN>
<TOKEN end_char="3215" id="token-20-8" morph="none" pos="word" start_char="3207">published</TOKEN>
<TOKEN end_char="3218" id="token-20-9" morph="none" pos="word" start_char="3217">in</TOKEN>
<TOKEN end_char="3227" id="token-20-10" morph="none" pos="word" start_char="3220">November</TOKEN>
<TOKEN end_char="3230" id="token-20-11" morph="none" pos="word" start_char="3229">in</TOKEN>
<TOKEN end_char="3234" id="token-20-12" morph="none" pos="word" start_char="3232">the</TOKEN>
<TOKEN end_char="3242" id="token-20-13" morph="none" pos="word" start_char="3236">journal</TOKEN>
<TOKEN end_char="3244" id="token-20-14" morph="none" pos="punct" start_char="3244">"</TOKEN>
<TOKEN end_char="3251" id="token-20-15" morph="none" pos="word" start_char="3245">Medical</TOKEN>
<TOKEN end_char="3262" id="token-20-16" morph="none" pos="word" start_char="3253">Hypotheses</TOKEN>
<TOKEN end_char="3264" id="token-20-17" morph="none" pos="punct" start_char="3263">,"</TOKEN>
<TOKEN end_char="3270" id="token-20-18" morph="none" pos="word" start_char="3266">which</TOKEN>
<TOKEN end_char="3277" id="token-20-19" morph="none" pos="word" start_char="3272">writes</TOKEN>
<TOKEN end_char="3282" id="token-20-20" morph="none" pos="word" start_char="3279">that</TOKEN>
<TOKEN end_char="3286" id="token-20-21" morph="none" pos="word" start_char="3284">its</TOKEN>
<TOKEN end_char="3294" id="token-20-22" morph="none" pos="word" start_char="3288">purpose</TOKEN>
<TOKEN end_char="3297" id="token-20-23" morph="none" pos="word" start_char="3296">is</TOKEN>
<TOKEN end_char="3300" id="token-20-24" morph="none" pos="word" start_char="3299">to</TOKEN>
<TOKEN end_char="3302" id="token-20-25" morph="none" pos="punct" start_char="3302">"</TOKEN>
<TOKEN end_char="3309" id="token-20-26" morph="none" pos="word" start_char="3303">publish</TOKEN>
<TOKEN end_char="3321" id="token-20-27" morph="none" pos="word" start_char="3311">interesting</TOKEN>
<TOKEN end_char="3333" id="token-20-28" morph="none" pos="word" start_char="3323">theoretical</TOKEN>
<TOKEN end_char="3340" id="token-20-29" morph="none" pos="word" start_char="3335">papers</TOKEN>
<TOKEN end_char="3342" id="token-20-30" morph="none" pos="punct" start_char="3341">."</TOKEN>
</SEG>
<SEG end_char="3463" id="segment-21" start_char="3344">
<ORIGINAL_TEXT>Articles submitted to the journal are not meant to prove findings using primary data, but instead to advance hypotheses.</ORIGINAL_TEXT>
<TOKEN end_char="3351" id="token-21-0" morph="none" pos="word" start_char="3344">Articles</TOKEN>
<TOKEN end_char="3361" id="token-21-1" morph="none" pos="word" start_char="3353">submitted</TOKEN>
<TOKEN end_char="3364" id="token-21-2" morph="none" pos="word" start_char="3363">to</TOKEN>
<TOKEN end_char="3368" id="token-21-3" morph="none" pos="word" start_char="3366">the</TOKEN>
<TOKEN end_char="3376" id="token-21-4" morph="none" pos="word" start_char="3370">journal</TOKEN>
<TOKEN end_char="3380" id="token-21-5" morph="none" pos="word" start_char="3378">are</TOKEN>
<TOKEN end_char="3384" id="token-21-6" morph="none" pos="word" start_char="3382">not</TOKEN>
<TOKEN end_char="3390" id="token-21-7" morph="none" pos="word" start_char="3386">meant</TOKEN>
<TOKEN end_char="3393" id="token-21-8" morph="none" pos="word" start_char="3392">to</TOKEN>
<TOKEN end_char="3399" id="token-21-9" morph="none" pos="word" start_char="3395">prove</TOKEN>
<TOKEN end_char="3408" id="token-21-10" morph="none" pos="word" start_char="3401">findings</TOKEN>
<TOKEN end_char="3414" id="token-21-11" morph="none" pos="word" start_char="3410">using</TOKEN>
<TOKEN end_char="3422" id="token-21-12" morph="none" pos="word" start_char="3416">primary</TOKEN>
<TOKEN end_char="3427" id="token-21-13" morph="none" pos="word" start_char="3424">data</TOKEN>
<TOKEN end_char="3428" id="token-21-14" morph="none" pos="punct" start_char="3428">,</TOKEN>
<TOKEN end_char="3432" id="token-21-15" morph="none" pos="word" start_char="3430">but</TOKEN>
<TOKEN end_char="3440" id="token-21-16" morph="none" pos="word" start_char="3434">instead</TOKEN>
<TOKEN end_char="3443" id="token-21-17" morph="none" pos="word" start_char="3442">to</TOKEN>
<TOKEN end_char="3451" id="token-21-18" morph="none" pos="word" start_char="3445">advance</TOKEN>
<TOKEN end_char="3462" id="token-21-19" morph="none" pos="word" start_char="3453">hypotheses</TOKEN>
<TOKEN end_char="3463" id="token-21-20" morph="none" pos="punct" start_char="3463">.</TOKEN>
</SEG>
<SEG end_char="3631" id="segment-22" start_char="3466">
<ORIGINAL_TEXT>The journal has a "long history of publishing fringe science and hypotheses," according to David Gorski, a surgical oncologist who blogs about medical misinformation.</ORIGINAL_TEXT>
<TOKEN end_char="3468" id="token-22-0" morph="none" pos="word" start_char="3466">The</TOKEN>
<TOKEN end_char="3476" id="token-22-1" morph="none" pos="word" start_char="3470">journal</TOKEN>
<TOKEN end_char="3480" id="token-22-2" morph="none" pos="word" start_char="3478">has</TOKEN>
<TOKEN end_char="3482" id="token-22-3" morph="none" pos="word" start_char="3482">a</TOKEN>
<TOKEN end_char="3484" id="token-22-4" morph="none" pos="punct" start_char="3484">"</TOKEN>
<TOKEN end_char="3488" id="token-22-5" morph="none" pos="word" start_char="3485">long</TOKEN>
<TOKEN end_char="3496" id="token-22-6" morph="none" pos="word" start_char="3490">history</TOKEN>
<TOKEN end_char="3499" id="token-22-7" morph="none" pos="word" start_char="3498">of</TOKEN>
<TOKEN end_char="3510" id="token-22-8" morph="none" pos="word" start_char="3501">publishing</TOKEN>
<TOKEN end_char="3517" id="token-22-9" morph="none" pos="word" start_char="3512">fringe</TOKEN>
<TOKEN end_char="3525" id="token-22-10" morph="none" pos="word" start_char="3519">science</TOKEN>
<TOKEN end_char="3529" id="token-22-11" morph="none" pos="word" start_char="3527">and</TOKEN>
<TOKEN end_char="3540" id="token-22-12" morph="none" pos="word" start_char="3531">hypotheses</TOKEN>
<TOKEN end_char="3542" id="token-22-13" morph="none" pos="punct" start_char="3541">,"</TOKEN>
<TOKEN end_char="3552" id="token-22-14" morph="none" pos="word" start_char="3544">according</TOKEN>
<TOKEN end_char="3555" id="token-22-15" morph="none" pos="word" start_char="3554">to</TOKEN>
<TOKEN end_char="3561" id="token-22-16" morph="none" pos="word" start_char="3557">David</TOKEN>
<TOKEN end_char="3568" id="token-22-17" morph="none" pos="word" start_char="3563">Gorski</TOKEN>
<TOKEN end_char="3569" id="token-22-18" morph="none" pos="punct" start_char="3569">,</TOKEN>
<TOKEN end_char="3571" id="token-22-19" morph="none" pos="word" start_char="3571">a</TOKEN>
<TOKEN end_char="3580" id="token-22-20" morph="none" pos="word" start_char="3573">surgical</TOKEN>
<TOKEN end_char="3591" id="token-22-21" morph="none" pos="word" start_char="3582">oncologist</TOKEN>
<TOKEN end_char="3595" id="token-22-22" morph="none" pos="word" start_char="3593">who</TOKEN>
<TOKEN end_char="3601" id="token-22-23" morph="none" pos="word" start_char="3597">blogs</TOKEN>
<TOKEN end_char="3607" id="token-22-24" morph="none" pos="word" start_char="3603">about</TOKEN>
<TOKEN end_char="3615" id="token-22-25" morph="none" pos="word" start_char="3609">medical</TOKEN>
<TOKEN end_char="3630" id="token-22-26" morph="none" pos="word" start_char="3617">misinformation</TOKEN>
<TOKEN end_char="3631" id="token-22-27" morph="none" pos="punct" start_char="3631">.</TOKEN>
</SEG>
<SEG end_char="3741" id="segment-23" start_char="3634">
<ORIGINAL_TEXT>"Even ‘peer-reviewed,’ this journal is still publishing very low quality speculative articles," Gorski said.</ORIGINAL_TEXT>
<TOKEN end_char="3634" id="token-23-0" morph="none" pos="punct" start_char="3634">"</TOKEN>
<TOKEN end_char="3638" id="token-23-1" morph="none" pos="word" start_char="3635">Even</TOKEN>
<TOKEN end_char="3640" id="token-23-2" morph="none" pos="punct" start_char="3640">‘</TOKEN>
<TOKEN end_char="3653" id="token-23-3" morph="none" pos="unknown" start_char="3641">peer-reviewed</TOKEN>
<TOKEN end_char="3655" id="token-23-4" morph="none" pos="punct" start_char="3654">,’</TOKEN>
<TOKEN end_char="3660" id="token-23-5" morph="none" pos="word" start_char="3657">this</TOKEN>
<TOKEN end_char="3668" id="token-23-6" morph="none" pos="word" start_char="3662">journal</TOKEN>
<TOKEN end_char="3671" id="token-23-7" morph="none" pos="word" start_char="3670">is</TOKEN>
<TOKEN end_char="3677" id="token-23-8" morph="none" pos="word" start_char="3673">still</TOKEN>
<TOKEN end_char="3688" id="token-23-9" morph="none" pos="word" start_char="3679">publishing</TOKEN>
<TOKEN end_char="3693" id="token-23-10" morph="none" pos="word" start_char="3690">very</TOKEN>
<TOKEN end_char="3697" id="token-23-11" morph="none" pos="word" start_char="3695">low</TOKEN>
<TOKEN end_char="3705" id="token-23-12" morph="none" pos="word" start_char="3699">quality</TOKEN>
<TOKEN end_char="3717" id="token-23-13" morph="none" pos="word" start_char="3707">speculative</TOKEN>
<TOKEN end_char="3726" id="token-23-14" morph="none" pos="word" start_char="3719">articles</TOKEN>
<TOKEN end_char="3728" id="token-23-15" morph="none" pos="punct" start_char="3727">,"</TOKEN>
<TOKEN end_char="3735" id="token-23-16" morph="none" pos="word" start_char="3730">Gorski</TOKEN>
<TOKEN end_char="3740" id="token-23-17" morph="none" pos="word" start_char="3737">said</TOKEN>
<TOKEN end_char="3741" id="token-23-18" morph="none" pos="punct" start_char="3741">.</TOKEN>
</SEG>
<SEG end_char="3929" id="segment-24" start_char="3744">
<ORIGINAL_TEXT>The study’s author, Baruch Vainshelboim, is listed in the study as being affiliated with the cardiology division at the Veterans Affairs Palo Alto Health Care System/Stanford University.</ORIGINAL_TEXT>
<TOKEN end_char="3746" id="token-24-0" morph="none" pos="word" start_char="3744">The</TOKEN>
<TOKEN end_char="3754" id="token-24-1" morph="none" pos="word" start_char="3748">study’s</TOKEN>
<TOKEN end_char="3761" id="token-24-2" morph="none" pos="word" start_char="3756">author</TOKEN>
<TOKEN end_char="3762" id="token-24-3" morph="none" pos="punct" start_char="3762">,</TOKEN>
<TOKEN end_char="3769" id="token-24-4" morph="none" pos="word" start_char="3764">Baruch</TOKEN>
<TOKEN end_char="3782" id="token-24-5" morph="none" pos="word" start_char="3771">Vainshelboim</TOKEN>
<TOKEN end_char="3783" id="token-24-6" morph="none" pos="punct" start_char="3783">,</TOKEN>
<TOKEN end_char="3786" id="token-24-7" morph="none" pos="word" start_char="3785">is</TOKEN>
<TOKEN end_char="3793" id="token-24-8" morph="none" pos="word" start_char="3788">listed</TOKEN>
<TOKEN end_char="3796" id="token-24-9" morph="none" pos="word" start_char="3795">in</TOKEN>
<TOKEN end_char="3800" id="token-24-10" morph="none" pos="word" start_char="3798">the</TOKEN>
<TOKEN end_char="3806" id="token-24-11" morph="none" pos="word" start_char="3802">study</TOKEN>
<TOKEN end_char="3809" id="token-24-12" morph="none" pos="word" start_char="3808">as</TOKEN>
<TOKEN end_char="3815" id="token-24-13" morph="none" pos="word" start_char="3811">being</TOKEN>
<TOKEN end_char="3826" id="token-24-14" morph="none" pos="word" start_char="3817">affiliated</TOKEN>
<TOKEN end_char="3831" id="token-24-15" morph="none" pos="word" start_char="3828">with</TOKEN>
<TOKEN end_char="3835" id="token-24-16" morph="none" pos="word" start_char="3833">the</TOKEN>
<TOKEN end_char="3846" id="token-24-17" morph="none" pos="word" start_char="3837">cardiology</TOKEN>
<TOKEN end_char="3855" id="token-24-18" morph="none" pos="word" start_char="3848">division</TOKEN>
<TOKEN end_char="3858" id="token-24-19" morph="none" pos="word" start_char="3857">at</TOKEN>
<TOKEN end_char="3862" id="token-24-20" morph="none" pos="word" start_char="3860">the</TOKEN>
<TOKEN end_char="3871" id="token-24-21" morph="none" pos="word" start_char="3864">Veterans</TOKEN>
<TOKEN end_char="3879" id="token-24-22" morph="none" pos="word" start_char="3873">Affairs</TOKEN>
<TOKEN end_char="3884" id="token-24-23" morph="none" pos="word" start_char="3881">Palo</TOKEN>
<TOKEN end_char="3889" id="token-24-24" morph="none" pos="word" start_char="3886">Alto</TOKEN>
<TOKEN end_char="3896" id="token-24-25" morph="none" pos="word" start_char="3891">Health</TOKEN>
<TOKEN end_char="3901" id="token-24-26" morph="none" pos="word" start_char="3898">Care</TOKEN>
<TOKEN end_char="3917" id="token-24-27" morph="none" pos="unknown" start_char="3903">System/Stanford</TOKEN>
<TOKEN end_char="3928" id="token-24-28" morph="none" pos="word" start_char="3919">University</TOKEN>
<TOKEN end_char="3929" id="token-24-29" morph="none" pos="punct" start_char="3929">.</TOKEN>
</SEG>
<SEG end_char="4059" id="segment-25" start_char="3932">
<ORIGINAL_TEXT>However, a representative for the VA Palo Alto Health Care System told the AP in an email that Vainshelboim does not work there.</ORIGINAL_TEXT>
<TOKEN end_char="3938" id="token-25-0" morph="none" pos="word" start_char="3932">However</TOKEN>
<TOKEN end_char="3939" id="token-25-1" morph="none" pos="punct" start_char="3939">,</TOKEN>
<TOKEN end_char="3941" id="token-25-2" morph="none" pos="word" start_char="3941">a</TOKEN>
<TOKEN end_char="3956" id="token-25-3" morph="none" pos="word" start_char="3943">representative</TOKEN>
<TOKEN end_char="3960" id="token-25-4" morph="none" pos="word" start_char="3958">for</TOKEN>
<TOKEN end_char="3964" id="token-25-5" morph="none" pos="word" start_char="3962">the</TOKEN>
<TOKEN end_char="3967" id="token-25-6" morph="none" pos="word" start_char="3966">VA</TOKEN>
<TOKEN end_char="3972" id="token-25-7" morph="none" pos="word" start_char="3969">Palo</TOKEN>
<TOKEN end_char="3977" id="token-25-8" morph="none" pos="word" start_char="3974">Alto</TOKEN>
<TOKEN end_char="3984" id="token-25-9" morph="none" pos="word" start_char="3979">Health</TOKEN>
<TOKEN end_char="3989" id="token-25-10" morph="none" pos="word" start_char="3986">Care</TOKEN>
<TOKEN end_char="3996" id="token-25-11" morph="none" pos="word" start_char="3991">System</TOKEN>
<TOKEN end_char="4001" id="token-25-12" morph="none" pos="word" start_char="3998">told</TOKEN>
<TOKEN end_char="4005" id="token-25-13" morph="none" pos="word" start_char="4003">the</TOKEN>
<TOKEN end_char="4008" id="token-25-14" morph="none" pos="word" start_char="4007">AP</TOKEN>
<TOKEN end_char="4011" id="token-25-15" morph="none" pos="word" start_char="4010">in</TOKEN>
<TOKEN end_char="4014" id="token-25-16" morph="none" pos="word" start_char="4013">an</TOKEN>
<TOKEN end_char="4020" id="token-25-17" morph="none" pos="word" start_char="4016">email</TOKEN>
<TOKEN end_char="4025" id="token-25-18" morph="none" pos="word" start_char="4022">that</TOKEN>
<TOKEN end_char="4038" id="token-25-19" morph="none" pos="word" start_char="4027">Vainshelboim</TOKEN>
<TOKEN end_char="4043" id="token-25-20" morph="none" pos="word" start_char="4040">does</TOKEN>
<TOKEN end_char="4047" id="token-25-21" morph="none" pos="word" start_char="4045">not</TOKEN>
<TOKEN end_char="4052" id="token-25-22" morph="none" pos="word" start_char="4049">work</TOKEN>
<TOKEN end_char="4058" id="token-25-23" morph="none" pos="word" start_char="4054">there</TOKEN>
<TOKEN end_char="4059" id="token-25-24" morph="none" pos="punct" start_char="4059">.</TOKEN>
</SEG>
<SEG end_char="4191" id="segment-26" start_char="4062">
<ORIGINAL_TEXT>"I can confirm this person is not one of our physicians," wrote Michael Hill-Jackson, a public affairs specialist with the system.</ORIGINAL_TEXT>
<TOKEN end_char="4062" id="token-26-0" morph="none" pos="punct" start_char="4062">"</TOKEN>
<TOKEN end_char="4063" id="token-26-1" morph="none" pos="word" start_char="4063">I</TOKEN>
<TOKEN end_char="4067" id="token-26-2" morph="none" pos="word" start_char="4065">can</TOKEN>
<TOKEN end_char="4075" id="token-26-3" morph="none" pos="word" start_char="4069">confirm</TOKEN>
<TOKEN end_char="4080" id="token-26-4" morph="none" pos="word" start_char="4077">this</TOKEN>
<TOKEN end_char="4087" id="token-26-5" morph="none" pos="word" start_char="4082">person</TOKEN>
<TOKEN end_char="4090" id="token-26-6" morph="none" pos="word" start_char="4089">is</TOKEN>
<TOKEN end_char="4094" id="token-26-7" morph="none" pos="word" start_char="4092">not</TOKEN>
<TOKEN end_char="4098" id="token-26-8" morph="none" pos="word" start_char="4096">one</TOKEN>
<TOKEN end_char="4101" id="token-26-9" morph="none" pos="word" start_char="4100">of</TOKEN>
<TOKEN end_char="4105" id="token-26-10" morph="none" pos="word" start_char="4103">our</TOKEN>
<TOKEN end_char="4116" id="token-26-11" morph="none" pos="word" start_char="4107">physicians</TOKEN>
<TOKEN end_char="4118" id="token-26-12" morph="none" pos="punct" start_char="4117">,"</TOKEN>
<TOKEN end_char="4124" id="token-26-13" morph="none" pos="word" start_char="4120">wrote</TOKEN>
<TOKEN end_char="4132" id="token-26-14" morph="none" pos="word" start_char="4126">Michael</TOKEN>
<TOKEN end_char="4145" id="token-26-15" morph="none" pos="unknown" start_char="4134">Hill-Jackson</TOKEN>
<TOKEN end_char="4146" id="token-26-16" morph="none" pos="punct" start_char="4146">,</TOKEN>
<TOKEN end_char="4148" id="token-26-17" morph="none" pos="word" start_char="4148">a</TOKEN>
<TOKEN end_char="4155" id="token-26-18" morph="none" pos="word" start_char="4150">public</TOKEN>
<TOKEN end_char="4163" id="token-26-19" morph="none" pos="word" start_char="4157">affairs</TOKEN>
<TOKEN end_char="4174" id="token-26-20" morph="none" pos="word" start_char="4165">specialist</TOKEN>
<TOKEN end_char="4179" id="token-26-21" morph="none" pos="word" start_char="4176">with</TOKEN>
<TOKEN end_char="4183" id="token-26-22" morph="none" pos="word" start_char="4181">the</TOKEN>
<TOKEN end_char="4190" id="token-26-23" morph="none" pos="word" start_char="4185">system</TOKEN>
<TOKEN end_char="4191" id="token-26-24" morph="none" pos="punct" start_char="4191">.</TOKEN>
</SEG>
<SEG end_char="4272" id="segment-27" start_char="4193">
<ORIGINAL_TEXT>"I do not see him in our system and our Cardiology team has never heard of him."</ORIGINAL_TEXT>
<TOKEN end_char="4193" id="token-27-0" morph="none" pos="punct" start_char="4193">"</TOKEN>
<TOKEN end_char="4194" id="token-27-1" morph="none" pos="word" start_char="4194">I</TOKEN>
<TOKEN end_char="4197" id="token-27-2" morph="none" pos="word" start_char="4196">do</TOKEN>
<TOKEN end_char="4201" id="token-27-3" morph="none" pos="word" start_char="4199">not</TOKEN>
<TOKEN end_char="4205" id="token-27-4" morph="none" pos="word" start_char="4203">see</TOKEN>
<TOKEN end_char="4209" id="token-27-5" morph="none" pos="word" start_char="4207">him</TOKEN>
<TOKEN end_char="4212" id="token-27-6" morph="none" pos="word" start_char="4211">in</TOKEN>
<TOKEN end_char="4216" id="token-27-7" morph="none" pos="word" start_char="4214">our</TOKEN>
<TOKEN end_char="4223" id="token-27-8" morph="none" pos="word" start_char="4218">system</TOKEN>
<TOKEN end_char="4227" id="token-27-9" morph="none" pos="word" start_char="4225">and</TOKEN>
<TOKEN end_char="4231" id="token-27-10" morph="none" pos="word" start_char="4229">our</TOKEN>
<TOKEN end_char="4242" id="token-27-11" morph="none" pos="word" start_char="4233">Cardiology</TOKEN>
<TOKEN end_char="4247" id="token-27-12" morph="none" pos="word" start_char="4244">team</TOKEN>
<TOKEN end_char="4251" id="token-27-13" morph="none" pos="word" start_char="4249">has</TOKEN>
<TOKEN end_char="4257" id="token-27-14" morph="none" pos="word" start_char="4253">never</TOKEN>
<TOKEN end_char="4263" id="token-27-15" morph="none" pos="word" start_char="4259">heard</TOKEN>
<TOKEN end_char="4266" id="token-27-16" morph="none" pos="word" start_char="4265">of</TOKEN>
<TOKEN end_char="4270" id="token-27-17" morph="none" pos="word" start_char="4268">him</TOKEN>
<TOKEN end_char="4272" id="token-27-18" morph="none" pos="punct" start_char="4271">."</TOKEN>
</SEG>
<SEG end_char="4428" id="segment-28" start_char="4275">
<ORIGINAL_TEXT>Vainshelboim also does not work for Stanford, according to Julie Greicius, senior director of external communications for the university’s medical school.</ORIGINAL_TEXT>
<TOKEN end_char="4286" id="token-28-0" morph="none" pos="word" start_char="4275">Vainshelboim</TOKEN>
<TOKEN end_char="4291" id="token-28-1" morph="none" pos="word" start_char="4288">also</TOKEN>
<TOKEN end_char="4296" id="token-28-2" morph="none" pos="word" start_char="4293">does</TOKEN>
<TOKEN end_char="4300" id="token-28-3" morph="none" pos="word" start_char="4298">not</TOKEN>
<TOKEN end_char="4305" id="token-28-4" morph="none" pos="word" start_char="4302">work</TOKEN>
<TOKEN end_char="4309" id="token-28-5" morph="none" pos="word" start_char="4307">for</TOKEN>
<TOKEN end_char="4318" id="token-28-6" morph="none" pos="word" start_char="4311">Stanford</TOKEN>
<TOKEN end_char="4319" id="token-28-7" morph="none" pos="punct" start_char="4319">,</TOKEN>
<TOKEN end_char="4329" id="token-28-8" morph="none" pos="word" start_char="4321">according</TOKEN>
<TOKEN end_char="4332" id="token-28-9" morph="none" pos="word" start_char="4331">to</TOKEN>
<TOKEN end_char="4338" id="token-28-10" morph="none" pos="word" start_char="4334">Julie</TOKEN>
<TOKEN end_char="4347" id="token-28-11" morph="none" pos="word" start_char="4340">Greicius</TOKEN>
<TOKEN end_char="4348" id="token-28-12" morph="none" pos="punct" start_char="4348">,</TOKEN>
<TOKEN end_char="4355" id="token-28-13" morph="none" pos="word" start_char="4350">senior</TOKEN>
<TOKEN end_char="4364" id="token-28-14" morph="none" pos="word" start_char="4357">director</TOKEN>
<TOKEN end_char="4367" id="token-28-15" morph="none" pos="word" start_char="4366">of</TOKEN>
<TOKEN end_char="4376" id="token-28-16" morph="none" pos="word" start_char="4369">external</TOKEN>
<TOKEN end_char="4391" id="token-28-17" morph="none" pos="word" start_char="4378">communications</TOKEN>
<TOKEN end_char="4395" id="token-28-18" morph="none" pos="word" start_char="4393">for</TOKEN>
<TOKEN end_char="4399" id="token-28-19" morph="none" pos="word" start_char="4397">the</TOKEN>
<TOKEN end_char="4412" id="token-28-20" morph="none" pos="word" start_char="4401">university’s</TOKEN>
<TOKEN end_char="4420" id="token-28-21" morph="none" pos="word" start_char="4414">medical</TOKEN>
<TOKEN end_char="4427" id="token-28-22" morph="none" pos="word" start_char="4422">school</TOKEN>
<TOKEN end_char="4428" id="token-28-23" morph="none" pos="punct" start_char="4428">.</TOKEN>
</SEG>
<SEG end_char="4529" id="segment-29" start_char="4431">
<ORIGINAL_TEXT>"Stanford University has never employed Baruch Vainshelboim," Greicius wrote in an email to the AP.</ORIGINAL_TEXT>
<TOKEN end_char="4431" id="token-29-0" morph="none" pos="punct" start_char="4431">"</TOKEN>
<TOKEN end_char="4439" id="token-29-1" morph="none" pos="word" start_char="4432">Stanford</TOKEN>
<TOKEN end_char="4450" id="token-29-2" morph="none" pos="word" start_char="4441">University</TOKEN>
<TOKEN end_char="4454" id="token-29-3" morph="none" pos="word" start_char="4452">has</TOKEN>
<TOKEN end_char="4460" id="token-29-4" morph="none" pos="word" start_char="4456">never</TOKEN>
<TOKEN end_char="4469" id="token-29-5" morph="none" pos="word" start_char="4462">employed</TOKEN>
<TOKEN end_char="4476" id="token-29-6" morph="none" pos="word" start_char="4471">Baruch</TOKEN>
<TOKEN end_char="4489" id="token-29-7" morph="none" pos="word" start_char="4478">Vainshelboim</TOKEN>
<TOKEN end_char="4491" id="token-29-8" morph="none" pos="punct" start_char="4490">,"</TOKEN>
<TOKEN end_char="4500" id="token-29-9" morph="none" pos="word" start_char="4493">Greicius</TOKEN>
<TOKEN end_char="4506" id="token-29-10" morph="none" pos="word" start_char="4502">wrote</TOKEN>
<TOKEN end_char="4509" id="token-29-11" morph="none" pos="word" start_char="4508">in</TOKEN>
<TOKEN end_char="4512" id="token-29-12" morph="none" pos="word" start_char="4511">an</TOKEN>
<TOKEN end_char="4518" id="token-29-13" morph="none" pos="word" start_char="4514">email</TOKEN>
<TOKEN end_char="4521" id="token-29-14" morph="none" pos="word" start_char="4520">to</TOKEN>
<TOKEN end_char="4525" id="token-29-15" morph="none" pos="word" start_char="4523">the</TOKEN>
<TOKEN end_char="4528" id="token-29-16" morph="none" pos="word" start_char="4527">AP</TOKEN>
<TOKEN end_char="4529" id="token-29-17" morph="none" pos="punct" start_char="4529">.</TOKEN>
</SEG>
<SEG end_char="4643" id="segment-30" start_char="4531">
<ORIGINAL_TEXT>"Several years ago (2015), he was a visiting scholar at Stanford for a year, on matters unrelated to this paper."</ORIGINAL_TEXT>
<TOKEN end_char="4531" id="token-30-0" morph="none" pos="punct" start_char="4531">"</TOKEN>
<TOKEN end_char="4538" id="token-30-1" morph="none" pos="word" start_char="4532">Several</TOKEN>
<TOKEN end_char="4544" id="token-30-2" morph="none" pos="word" start_char="4540">years</TOKEN>
<TOKEN end_char="4548" id="token-30-3" morph="none" pos="word" start_char="4546">ago</TOKEN>
<TOKEN end_char="4550" id="token-30-4" morph="none" pos="punct" start_char="4550">(</TOKEN>
<TOKEN end_char="4554" id="token-30-5" morph="none" pos="word" start_char="4551">2015</TOKEN>
<TOKEN end_char="4556" id="token-30-6" morph="none" pos="punct" start_char="4555">),</TOKEN>
<TOKEN end_char="4559" id="token-30-7" morph="none" pos="word" start_char="4558">he</TOKEN>
<TOKEN end_char="4563" id="token-30-8" morph="none" pos="word" start_char="4561">was</TOKEN>
<TOKEN end_char="4565" id="token-30-9" morph="none" pos="word" start_char="4565">a</TOKEN>
<TOKEN end_char="4574" id="token-30-10" morph="none" pos="word" start_char="4567">visiting</TOKEN>
<TOKEN end_char="4582" id="token-30-11" morph="none" pos="word" start_char="4576">scholar</TOKEN>
<TOKEN end_char="4585" id="token-30-12" morph="none" pos="word" start_char="4584">at</TOKEN>
<TOKEN end_char="4594" id="token-30-13" morph="none" pos="word" start_char="4587">Stanford</TOKEN>
<TOKEN end_char="4598" id="token-30-14" morph="none" pos="word" start_char="4596">for</TOKEN>
<TOKEN end_char="4600" id="token-30-15" morph="none" pos="word" start_char="4600">a</TOKEN>
<TOKEN end_char="4605" id="token-30-16" morph="none" pos="word" start_char="4602">year</TOKEN>
<TOKEN end_char="4606" id="token-30-17" morph="none" pos="punct" start_char="4606">,</TOKEN>
<TOKEN end_char="4609" id="token-30-18" morph="none" pos="word" start_char="4608">on</TOKEN>
<TOKEN end_char="4617" id="token-30-19" morph="none" pos="word" start_char="4611">matters</TOKEN>
<TOKEN end_char="4627" id="token-30-20" morph="none" pos="word" start_char="4619">unrelated</TOKEN>
<TOKEN end_char="4630" id="token-30-21" morph="none" pos="word" start_char="4629">to</TOKEN>
<TOKEN end_char="4635" id="token-30-22" morph="none" pos="word" start_char="4632">this</TOKEN>
<TOKEN end_char="4641" id="token-30-23" morph="none" pos="word" start_char="4637">paper</TOKEN>
<TOKEN end_char="4643" id="token-30-24" morph="none" pos="punct" start_char="4642">."</TOKEN>
</SEG>
<SEG end_char="4808" id="segment-31" start_char="4646">
<ORIGINAL_TEXT>Vainshelboim, who lists himself on LinkedIn as a clinical exercise physiologist and does not list any current employment, did not respond to a request for comment.</ORIGINAL_TEXT>
<TOKEN end_char="4657" id="token-31-0" morph="none" pos="word" start_char="4646">Vainshelboim</TOKEN>
<TOKEN end_char="4658" id="token-31-1" morph="none" pos="punct" start_char="4658">,</TOKEN>
<TOKEN end_char="4662" id="token-31-2" morph="none" pos="word" start_char="4660">who</TOKEN>
<TOKEN end_char="4668" id="token-31-3" morph="none" pos="word" start_char="4664">lists</TOKEN>
<TOKEN end_char="4676" id="token-31-4" morph="none" pos="word" start_char="4670">himself</TOKEN>
<TOKEN end_char="4679" id="token-31-5" morph="none" pos="word" start_char="4678">on</TOKEN>
<TOKEN end_char="4688" id="token-31-6" morph="none" pos="word" start_char="4681">LinkedIn</TOKEN>
<TOKEN end_char="4691" id="token-31-7" morph="none" pos="word" start_char="4690">as</TOKEN>
<TOKEN end_char="4693" id="token-31-8" morph="none" pos="word" start_char="4693">a</TOKEN>
<TOKEN end_char="4702" id="token-31-9" morph="none" pos="word" start_char="4695">clinical</TOKEN>
<TOKEN end_char="4711" id="token-31-10" morph="none" pos="word" start_char="4704">exercise</TOKEN>
<TOKEN end_char="4724" id="token-31-11" morph="none" pos="word" start_char="4713">physiologist</TOKEN>
<TOKEN end_char="4728" id="token-31-12" morph="none" pos="word" start_char="4726">and</TOKEN>
<TOKEN end_char="4733" id="token-31-13" morph="none" pos="word" start_char="4730">does</TOKEN>
<TOKEN end_char="4737" id="token-31-14" morph="none" pos="word" start_char="4735">not</TOKEN>
<TOKEN end_char="4742" id="token-31-15" morph="none" pos="word" start_char="4739">list</TOKEN>
<TOKEN end_char="4746" id="token-31-16" morph="none" pos="word" start_char="4744">any</TOKEN>
<TOKEN end_char="4754" id="token-31-17" morph="none" pos="word" start_char="4748">current</TOKEN>
<TOKEN end_char="4765" id="token-31-18" morph="none" pos="word" start_char="4756">employment</TOKEN>
<TOKEN end_char="4766" id="token-31-19" morph="none" pos="punct" start_char="4766">,</TOKEN>
<TOKEN end_char="4770" id="token-31-20" morph="none" pos="word" start_char="4768">did</TOKEN>
<TOKEN end_char="4774" id="token-31-21" morph="none" pos="word" start_char="4772">not</TOKEN>
<TOKEN end_char="4782" id="token-31-22" morph="none" pos="word" start_char="4776">respond</TOKEN>
<TOKEN end_char="4785" id="token-31-23" morph="none" pos="word" start_char="4784">to</TOKEN>
<TOKEN end_char="4787" id="token-31-24" morph="none" pos="word" start_char="4787">a</TOKEN>
<TOKEN end_char="4795" id="token-31-25" morph="none" pos="word" start_char="4789">request</TOKEN>
<TOKEN end_char="4799" id="token-31-26" morph="none" pos="word" start_char="4797">for</TOKEN>
<TOKEN end_char="4807" id="token-31-27" morph="none" pos="word" start_char="4801">comment</TOKEN>
<TOKEN end_char="4808" id="token-31-28" morph="none" pos="punct" start_char="4808">.</TOKEN>
</SEG>
<SEG end_char="4813" id="segment-32" start_char="4811">
<ORIGINAL_TEXT>___</ORIGINAL_TEXT>
<TOKEN end_char="4813" id="token-32-0" morph="none" pos="word" start_char="4811">___</TOKEN>
<TRANSLATED_TEXT>_ _ _</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="5028" id="segment-33" start_char="4816">
<ORIGINAL_TEXT>This is part of The Associated Press’ ongoing effort to fact-check misinformation that is shared widely online, including work with Facebook to identify and reduce the circulation of false stories on the platform.</ORIGINAL_TEXT>
<TOKEN end_char="4819" id="token-33-0" morph="none" pos="word" start_char="4816">This</TOKEN>
<TOKEN end_char="4822" id="token-33-1" morph="none" pos="word" start_char="4821">is</TOKEN>
<TOKEN end_char="4827" id="token-33-2" morph="none" pos="word" start_char="4824">part</TOKEN>
<TOKEN end_char="4830" id="token-33-3" morph="none" pos="word" start_char="4829">of</TOKEN>
<TOKEN end_char="4834" id="token-33-4" morph="none" pos="word" start_char="4832">The</TOKEN>
<TOKEN end_char="4845" id="token-33-5" morph="none" pos="word" start_char="4836">Associated</TOKEN>
<TOKEN end_char="4851" id="token-33-6" morph="none" pos="word" start_char="4847">Press</TOKEN>
<TOKEN end_char="4852" id="token-33-7" morph="none" pos="punct" start_char="4852">’</TOKEN>
<TOKEN end_char="4860" id="token-33-8" morph="none" pos="word" start_char="4854">ongoing</TOKEN>
<TOKEN end_char="4867" id="token-33-9" morph="none" pos="word" start_char="4862">effort</TOKEN>
<TOKEN end_char="4870" id="token-33-10" morph="none" pos="word" start_char="4869">to</TOKEN>
<TOKEN end_char="4881" id="token-33-11" morph="none" pos="unknown" start_char="4872">fact-check</TOKEN>
<TOKEN end_char="4896" id="token-33-12" morph="none" pos="word" start_char="4883">misinformation</TOKEN>
<TOKEN end_char="4901" id="token-33-13" morph="none" pos="word" start_char="4898">that</TOKEN>
<TOKEN end_char="4904" id="token-33-14" morph="none" pos="word" start_char="4903">is</TOKEN>
<TOKEN end_char="4911" id="token-33-15" morph="none" pos="word" start_char="4906">shared</TOKEN>
<TOKEN end_char="4918" id="token-33-16" morph="none" pos="word" start_char="4913">widely</TOKEN>
<TOKEN end_char="4925" id="token-33-17" morph="none" pos="word" start_char="4920">online</TOKEN>
<TOKEN end_char="4926" id="token-33-18" morph="none" pos="punct" start_char="4926">,</TOKEN>
<TOKEN end_char="4936" id="token-33-19" morph="none" pos="word" start_char="4928">including</TOKEN>
<TOKEN end_char="4941" id="token-33-20" morph="none" pos="word" start_char="4938">work</TOKEN>
<TOKEN end_char="4946" id="token-33-21" morph="none" pos="word" start_char="4943">with</TOKEN>
<TOKEN end_char="4955" id="token-33-22" morph="none" pos="word" start_char="4948">Facebook</TOKEN>
<TOKEN end_char="4958" id="token-33-23" morph="none" pos="word" start_char="4957">to</TOKEN>
<TOKEN end_char="4967" id="token-33-24" morph="none" pos="word" start_char="4960">identify</TOKEN>
<TOKEN end_char="4971" id="token-33-25" morph="none" pos="word" start_char="4969">and</TOKEN>
<TOKEN end_char="4978" id="token-33-26" morph="none" pos="word" start_char="4973">reduce</TOKEN>
<TOKEN end_char="4982" id="token-33-27" morph="none" pos="word" start_char="4980">the</TOKEN>
<TOKEN end_char="4994" id="token-33-28" morph="none" pos="word" start_char="4984">circulation</TOKEN>
<TOKEN end_char="4997" id="token-33-29" morph="none" pos="word" start_char="4996">of</TOKEN>
<TOKEN end_char="5003" id="token-33-30" morph="none" pos="word" start_char="4999">false</TOKEN>
<TOKEN end_char="5011" id="token-33-31" morph="none" pos="word" start_char="5005">stories</TOKEN>
<TOKEN end_char="5014" id="token-33-32" morph="none" pos="word" start_char="5013">on</TOKEN>
<TOKEN end_char="5018" id="token-33-33" morph="none" pos="word" start_char="5016">the</TOKEN>
<TOKEN end_char="5027" id="token-33-34" morph="none" pos="word" start_char="5020">platform</TOKEN>
<TOKEN end_char="5028" id="token-33-35" morph="none" pos="punct" start_char="5028">.</TOKEN>
</SEG>
<SEG end_char="5137" id="segment-34" start_char="5031">
<ORIGINAL_TEXT>Here’s more information on Facebook’s fact-checking program: https://www.facebook.com/help/1952307158131536</ORIGINAL_TEXT>
<TOKEN end_char="5036" id="token-34-0" morph="none" pos="word" start_char="5031">Here’s</TOKEN>
<TOKEN end_char="5041" id="token-34-1" morph="none" pos="word" start_char="5038">more</TOKEN>
<TOKEN end_char="5053" id="token-34-2" morph="none" pos="word" start_char="5043">information</TOKEN>
<TOKEN end_char="5056" id="token-34-3" morph="none" pos="word" start_char="5055">on</TOKEN>
<TOKEN end_char="5067" id="token-34-4" morph="none" pos="word" start_char="5058">Facebook’s</TOKEN>
<TOKEN end_char="5081" id="token-34-5" morph="none" pos="unknown" start_char="5069">fact-checking</TOKEN>
<TOKEN end_char="5089" id="token-34-6" morph="none" pos="word" start_char="5083">program</TOKEN>
<TOKEN end_char="5090" id="token-34-7" morph="none" pos="punct" start_char="5090">:</TOKEN>
<TOKEN end_char="5137" id="token-34-8" morph="none" pos="url" start_char="5092">https://www.facebook.com/help/1952307158131536</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
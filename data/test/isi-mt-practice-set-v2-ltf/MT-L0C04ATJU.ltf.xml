<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATJU" lang="spa" raw_text_char_length="188" raw_text_md5="1656454f41217a6e92bad552fb4db98e" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="55" id="segment-0" start_char="1">
<ORIGINAL_TEXT>China reports further food-related coronavirus findings</ORIGINAL_TEXT>
<TOKEN end_char="5" id="token-0-0" morph="none" pos="word" start_char="1">China</TOKEN>
<TOKEN end_char="13" id="token-0-1" morph="none" pos="word" start_char="7">reports</TOKEN>
<TOKEN end_char="21" id="token-0-2" morph="none" pos="word" start_char="15">further</TOKEN>
<TOKEN end_char="34" id="token-0-3" morph="none" pos="unknown" start_char="23">food-related</TOKEN>
<TOKEN end_char="46" id="token-0-4" morph="none" pos="word" start_char="36">coronavirus</TOKEN>
<TOKEN end_char="55" id="token-0-5" morph="none" pos="word" start_char="48">findings</TOKEN>
</SEG>
<SEG end_char="110" id="segment-1" start_char="59">
<ORIGINAL_TEXT>As if nothing China exports isn't full of the virus.</ORIGINAL_TEXT>
<TOKEN end_char="60" id="token-1-0" morph="none" pos="word" start_char="59">As</TOKEN>
<TOKEN end_char="63" id="token-1-1" morph="none" pos="word" start_char="62">if</TOKEN>
<TOKEN end_char="71" id="token-1-2" morph="none" pos="word" start_char="65">nothing</TOKEN>
<TOKEN end_char="77" id="token-1-3" morph="none" pos="word" start_char="73">China</TOKEN>
<TOKEN end_char="85" id="token-1-4" morph="none" pos="word" start_char="79">exports</TOKEN>
<TOKEN end_char="91" id="token-1-5" morph="none" pos="word" start_char="87">isn't</TOKEN>
<TOKEN end_char="96" id="token-1-6" morph="none" pos="word" start_char="93">full</TOKEN>
<TOKEN end_char="99" id="token-1-7" morph="none" pos="word" start_char="98">of</TOKEN>
<TOKEN end_char="103" id="token-1-8" morph="none" pos="word" start_char="101">the</TOKEN>
<TOKEN end_char="109" id="token-1-9" morph="none" pos="word" start_char="105">virus</TOKEN>
<TOKEN end_char="110" id="token-1-10" morph="none" pos="punct" start_char="110">.</TOKEN>
</SEG>
<SEG end_char="172" id="segment-2" start_char="112">
<ORIGINAL_TEXT>They created this virus so let them live with it like we are!</ORIGINAL_TEXT>
<TOKEN end_char="115" id="token-2-0" morph="none" pos="word" start_char="112">They</TOKEN>
<TOKEN end_char="123" id="token-2-1" morph="none" pos="word" start_char="117">created</TOKEN>
<TOKEN end_char="128" id="token-2-2" morph="none" pos="word" start_char="125">this</TOKEN>
<TOKEN end_char="134" id="token-2-3" morph="none" pos="word" start_char="130">virus</TOKEN>
<TOKEN end_char="137" id="token-2-4" morph="none" pos="word" start_char="136">so</TOKEN>
<TOKEN end_char="141" id="token-2-5" morph="none" pos="word" start_char="139">let</TOKEN>
<TOKEN end_char="146" id="token-2-6" morph="none" pos="word" start_char="143">them</TOKEN>
<TOKEN end_char="151" id="token-2-7" morph="none" pos="word" start_char="148">live</TOKEN>
<TOKEN end_char="156" id="token-2-8" morph="none" pos="word" start_char="153">with</TOKEN>
<TOKEN end_char="159" id="token-2-9" morph="none" pos="word" start_char="158">it</TOKEN>
<TOKEN end_char="164" id="token-2-10" morph="none" pos="word" start_char="161">like</TOKEN>
<TOKEN end_char="167" id="token-2-11" morph="none" pos="word" start_char="166">we</TOKEN>
<TOKEN end_char="171" id="token-2-12" morph="none" pos="word" start_char="169">are</TOKEN>
<TOKEN end_char="172" id="token-2-13" morph="none" pos="punct" start_char="172">!</TOKEN>
</SEG>
<SEG end_char="184" id="segment-3" start_char="176">
<ORIGINAL_TEXT>I agree !</ORIGINAL_TEXT>
<TOKEN end_char="176" id="token-3-0" morph="none" pos="word" start_char="176">I</TOKEN>
<TOKEN end_char="182" id="token-3-1" morph="none" pos="word" start_char="178">agree</TOKEN>
<TOKEN end_char="184" id="token-3-2" morph="none" pos="punct" start_char="184">!</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
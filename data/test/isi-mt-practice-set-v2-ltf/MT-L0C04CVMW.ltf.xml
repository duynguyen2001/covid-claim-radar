<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CVMW" lang="spa" raw_text_char_length="10488" raw_text_md5="48758e5f01d246a0f617abc754e6af8e" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="174" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Current data from clinical trials offer no reliable evidence that ivermectin is effective against COVID-19; better-quality clinical trials are needed to resolve this question</ORIGINAL_TEXT>
<TOKEN end_char="7" id="token-0-0" morph="none" pos="word" start_char="1">Current</TOKEN>
<TOKEN end_char="12" id="token-0-1" morph="none" pos="word" start_char="9">data</TOKEN>
<TOKEN end_char="17" id="token-0-2" morph="none" pos="word" start_char="14">from</TOKEN>
<TOKEN end_char="26" id="token-0-3" morph="none" pos="word" start_char="19">clinical</TOKEN>
<TOKEN end_char="33" id="token-0-4" morph="none" pos="word" start_char="28">trials</TOKEN>
<TOKEN end_char="39" id="token-0-5" morph="none" pos="word" start_char="35">offer</TOKEN>
<TOKEN end_char="42" id="token-0-6" morph="none" pos="word" start_char="41">no</TOKEN>
<TOKEN end_char="51" id="token-0-7" morph="none" pos="word" start_char="44">reliable</TOKEN>
<TOKEN end_char="60" id="token-0-8" morph="none" pos="word" start_char="53">evidence</TOKEN>
<TOKEN end_char="65" id="token-0-9" morph="none" pos="word" start_char="62">that</TOKEN>
<TOKEN end_char="76" id="token-0-10" morph="none" pos="word" start_char="67">ivermectin</TOKEN>
<TOKEN end_char="79" id="token-0-11" morph="none" pos="word" start_char="78">is</TOKEN>
<TOKEN end_char="89" id="token-0-12" morph="none" pos="word" start_char="81">effective</TOKEN>
<TOKEN end_char="97" id="token-0-13" morph="none" pos="word" start_char="91">against</TOKEN>
<TOKEN end_char="106" id="token-0-14" morph="none" pos="unknown" start_char="99">COVID-19</TOKEN>
<TOKEN end_char="107" id="token-0-15" morph="none" pos="punct" start_char="107">;</TOKEN>
<TOKEN end_char="122" id="token-0-16" morph="none" pos="unknown" start_char="109">better-quality</TOKEN>
<TOKEN end_char="131" id="token-0-17" morph="none" pos="word" start_char="124">clinical</TOKEN>
<TOKEN end_char="138" id="token-0-18" morph="none" pos="word" start_char="133">trials</TOKEN>
<TOKEN end_char="142" id="token-0-19" morph="none" pos="word" start_char="140">are</TOKEN>
<TOKEN end_char="149" id="token-0-20" morph="none" pos="word" start_char="144">needed</TOKEN>
<TOKEN end_char="152" id="token-0-21" morph="none" pos="word" start_char="151">to</TOKEN>
<TOKEN end_char="160" id="token-0-22" morph="none" pos="word" start_char="154">resolve</TOKEN>
<TOKEN end_char="165" id="token-0-23" morph="none" pos="word" start_char="162">this</TOKEN>
<TOKEN end_char="174" id="token-0-24" morph="none" pos="word" start_char="167">question</TOKEN>
</SEG>
<SEG end_char="634" id="segment-1" start_char="178">
<ORIGINAL_TEXT>FULL CLAIM: "Ivermectin is the only thing we have that treats COVID at all stages […] Ivermectin substantially reduces deaths from COVID and prevents infections"; "If you go to Dr. Tess Lawrie, there are 51 studies published in the medical literature, 50 of them show ivermectin is not just effective, but highly effective"; "There are 12 [prophylaxis] studies showing that ivermectin has a close to 90% efficacy, which is equal or superior to the vaccines"</ORIGINAL_TEXT>
<TOKEN end_char="181" id="token-1-0" morph="none" pos="word" start_char="178">FULL</TOKEN>
<TOKEN end_char="187" id="token-1-1" morph="none" pos="word" start_char="183">CLAIM</TOKEN>
<TOKEN end_char="188" id="token-1-2" morph="none" pos="punct" start_char="188">:</TOKEN>
<TOKEN end_char="190" id="token-1-3" morph="none" pos="punct" start_char="190">"</TOKEN>
<TOKEN end_char="200" id="token-1-4" morph="none" pos="word" start_char="191">Ivermectin</TOKEN>
<TOKEN end_char="203" id="token-1-5" morph="none" pos="word" start_char="202">is</TOKEN>
<TOKEN end_char="207" id="token-1-6" morph="none" pos="word" start_char="205">the</TOKEN>
<TOKEN end_char="212" id="token-1-7" morph="none" pos="word" start_char="209">only</TOKEN>
<TOKEN end_char="218" id="token-1-8" morph="none" pos="word" start_char="214">thing</TOKEN>
<TOKEN end_char="221" id="token-1-9" morph="none" pos="word" start_char="220">we</TOKEN>
<TOKEN end_char="226" id="token-1-10" morph="none" pos="word" start_char="223">have</TOKEN>
<TOKEN end_char="231" id="token-1-11" morph="none" pos="word" start_char="228">that</TOKEN>
<TOKEN end_char="238" id="token-1-12" morph="none" pos="word" start_char="233">treats</TOKEN>
<TOKEN end_char="244" id="token-1-13" morph="none" pos="word" start_char="240">COVID</TOKEN>
<TOKEN end_char="247" id="token-1-14" morph="none" pos="word" start_char="246">at</TOKEN>
<TOKEN end_char="251" id="token-1-15" morph="none" pos="word" start_char="249">all</TOKEN>
<TOKEN end_char="258" id="token-1-16" morph="none" pos="word" start_char="253">stages</TOKEN>
<TOKEN end_char="262" id="token-1-17" morph="none" pos="punct" start_char="260">[…]</TOKEN>
<TOKEN end_char="273" id="token-1-18" morph="none" pos="word" start_char="264">Ivermectin</TOKEN>
<TOKEN end_char="287" id="token-1-19" morph="none" pos="word" start_char="275">substantially</TOKEN>
<TOKEN end_char="295" id="token-1-20" morph="none" pos="word" start_char="289">reduces</TOKEN>
<TOKEN end_char="302" id="token-1-21" morph="none" pos="word" start_char="297">deaths</TOKEN>
<TOKEN end_char="307" id="token-1-22" morph="none" pos="word" start_char="304">from</TOKEN>
<TOKEN end_char="313" id="token-1-23" morph="none" pos="word" start_char="309">COVID</TOKEN>
<TOKEN end_char="317" id="token-1-24" morph="none" pos="word" start_char="315">and</TOKEN>
<TOKEN end_char="326" id="token-1-25" morph="none" pos="word" start_char="319">prevents</TOKEN>
<TOKEN end_char="337" id="token-1-26" morph="none" pos="word" start_char="328">infections</TOKEN>
<TOKEN end_char="339" id="token-1-27" morph="none" pos="punct" start_char="338">";</TOKEN>
<TOKEN end_char="341" id="token-1-28" morph="none" pos="punct" start_char="341">"</TOKEN>
<TOKEN end_char="343" id="token-1-29" morph="none" pos="word" start_char="342">If</TOKEN>
<TOKEN end_char="347" id="token-1-30" morph="none" pos="word" start_char="345">you</TOKEN>
<TOKEN end_char="350" id="token-1-31" morph="none" pos="word" start_char="349">go</TOKEN>
<TOKEN end_char="353" id="token-1-32" morph="none" pos="word" start_char="352">to</TOKEN>
<TOKEN end_char="356" id="token-1-33" morph="none" pos="word" start_char="355">Dr</TOKEN>
<TOKEN end_char="357" id="token-1-34" morph="none" pos="punct" start_char="357">.</TOKEN>
<TOKEN end_char="362" id="token-1-35" morph="none" pos="word" start_char="359">Tess</TOKEN>
<TOKEN end_char="369" id="token-1-36" morph="none" pos="word" start_char="364">Lawrie</TOKEN>
<TOKEN end_char="370" id="token-1-37" morph="none" pos="punct" start_char="370">,</TOKEN>
<TOKEN end_char="376" id="token-1-38" morph="none" pos="word" start_char="372">there</TOKEN>
<TOKEN end_char="380" id="token-1-39" morph="none" pos="word" start_char="378">are</TOKEN>
<TOKEN end_char="383" id="token-1-40" morph="none" pos="word" start_char="382">51</TOKEN>
<TOKEN end_char="391" id="token-1-41" morph="none" pos="word" start_char="385">studies</TOKEN>
<TOKEN end_char="401" id="token-1-42" morph="none" pos="word" start_char="393">published</TOKEN>
<TOKEN end_char="404" id="token-1-43" morph="none" pos="word" start_char="403">in</TOKEN>
<TOKEN end_char="408" id="token-1-44" morph="none" pos="word" start_char="406">the</TOKEN>
<TOKEN end_char="416" id="token-1-45" morph="none" pos="word" start_char="410">medical</TOKEN>
<TOKEN end_char="427" id="token-1-46" morph="none" pos="word" start_char="418">literature</TOKEN>
<TOKEN end_char="428" id="token-1-47" morph="none" pos="punct" start_char="428">,</TOKEN>
<TOKEN end_char="431" id="token-1-48" morph="none" pos="word" start_char="430">50</TOKEN>
<TOKEN end_char="434" id="token-1-49" morph="none" pos="word" start_char="433">of</TOKEN>
<TOKEN end_char="439" id="token-1-50" morph="none" pos="word" start_char="436">them</TOKEN>
<TOKEN end_char="444" id="token-1-51" morph="none" pos="word" start_char="441">show</TOKEN>
<TOKEN end_char="455" id="token-1-52" morph="none" pos="word" start_char="446">ivermectin</TOKEN>
<TOKEN end_char="458" id="token-1-53" morph="none" pos="word" start_char="457">is</TOKEN>
<TOKEN end_char="462" id="token-1-54" morph="none" pos="word" start_char="460">not</TOKEN>
<TOKEN end_char="467" id="token-1-55" morph="none" pos="word" start_char="464">just</TOKEN>
<TOKEN end_char="477" id="token-1-56" morph="none" pos="word" start_char="469">effective</TOKEN>
<TOKEN end_char="478" id="token-1-57" morph="none" pos="punct" start_char="478">,</TOKEN>
<TOKEN end_char="482" id="token-1-58" morph="none" pos="word" start_char="480">but</TOKEN>
<TOKEN end_char="489" id="token-1-59" morph="none" pos="word" start_char="484">highly</TOKEN>
<TOKEN end_char="499" id="token-1-60" morph="none" pos="word" start_char="491">effective</TOKEN>
<TOKEN end_char="501" id="token-1-61" morph="none" pos="punct" start_char="500">";</TOKEN>
<TOKEN end_char="503" id="token-1-62" morph="none" pos="punct" start_char="503">"</TOKEN>
<TOKEN end_char="508" id="token-1-63" morph="none" pos="word" start_char="504">There</TOKEN>
<TOKEN end_char="512" id="token-1-64" morph="none" pos="word" start_char="510">are</TOKEN>
<TOKEN end_char="515" id="token-1-65" morph="none" pos="word" start_char="514">12</TOKEN>
<TOKEN end_char="517" id="token-1-66" morph="none" pos="punct" start_char="517">[</TOKEN>
<TOKEN end_char="528" id="token-1-67" morph="none" pos="word" start_char="518">prophylaxis</TOKEN>
<TOKEN end_char="529" id="token-1-68" morph="none" pos="punct" start_char="529">]</TOKEN>
<TOKEN end_char="537" id="token-1-69" morph="none" pos="word" start_char="531">studies</TOKEN>
<TOKEN end_char="545" id="token-1-70" morph="none" pos="word" start_char="539">showing</TOKEN>
<TOKEN end_char="550" id="token-1-71" morph="none" pos="word" start_char="547">that</TOKEN>
<TOKEN end_char="561" id="token-1-72" morph="none" pos="word" start_char="552">ivermectin</TOKEN>
<TOKEN end_char="565" id="token-1-73" morph="none" pos="word" start_char="563">has</TOKEN>
<TOKEN end_char="567" id="token-1-74" morph="none" pos="word" start_char="567">a</TOKEN>
<TOKEN end_char="573" id="token-1-75" morph="none" pos="word" start_char="569">close</TOKEN>
<TOKEN end_char="576" id="token-1-76" morph="none" pos="word" start_char="575">to</TOKEN>
<TOKEN end_char="579" id="token-1-77" morph="none" pos="word" start_char="578">90</TOKEN>
<TOKEN end_char="580" id="token-1-78" morph="none" pos="punct" start_char="580">%</TOKEN>
<TOKEN end_char="589" id="token-1-79" morph="none" pos="word" start_char="582">efficacy</TOKEN>
<TOKEN end_char="590" id="token-1-80" morph="none" pos="punct" start_char="590">,</TOKEN>
<TOKEN end_char="596" id="token-1-81" morph="none" pos="word" start_char="592">which</TOKEN>
<TOKEN end_char="599" id="token-1-82" morph="none" pos="word" start_char="598">is</TOKEN>
<TOKEN end_char="605" id="token-1-83" morph="none" pos="word" start_char="601">equal</TOKEN>
<TOKEN end_char="608" id="token-1-84" morph="none" pos="word" start_char="607">or</TOKEN>
<TOKEN end_char="617" id="token-1-85" morph="none" pos="word" start_char="610">superior</TOKEN>
<TOKEN end_char="620" id="token-1-86" morph="none" pos="word" start_char="619">to</TOKEN>
<TOKEN end_char="624" id="token-1-87" morph="none" pos="word" start_char="622">the</TOKEN>
<TOKEN end_char="633" id="token-1-88" morph="none" pos="word" start_char="626">vaccines</TOKEN>
<TOKEN end_char="634" id="token-1-89" morph="none" pos="punct" start_char="634">"</TOKEN>
</SEG>
<SEG end_char="829" id="segment-2" start_char="638">
<ORIGINAL_TEXT>A Sky News segment hosted by Alan Jones and featuring Craig Kelly, a Member of the Australian Parliament, claimed that scientific studies supported the use of ivermectin for treating COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="638" id="token-2-0" morph="none" pos="word" start_char="638">A</TOKEN>
<TOKEN end_char="642" id="token-2-1" morph="none" pos="word" start_char="640">Sky</TOKEN>
<TOKEN end_char="647" id="token-2-2" morph="none" pos="word" start_char="644">News</TOKEN>
<TOKEN end_char="655" id="token-2-3" morph="none" pos="word" start_char="649">segment</TOKEN>
<TOKEN end_char="662" id="token-2-4" morph="none" pos="word" start_char="657">hosted</TOKEN>
<TOKEN end_char="665" id="token-2-5" morph="none" pos="word" start_char="664">by</TOKEN>
<TOKEN end_char="670" id="token-2-6" morph="none" pos="word" start_char="667">Alan</TOKEN>
<TOKEN end_char="676" id="token-2-7" morph="none" pos="word" start_char="672">Jones</TOKEN>
<TOKEN end_char="680" id="token-2-8" morph="none" pos="word" start_char="678">and</TOKEN>
<TOKEN end_char="690" id="token-2-9" morph="none" pos="word" start_char="682">featuring</TOKEN>
<TOKEN end_char="696" id="token-2-10" morph="none" pos="word" start_char="692">Craig</TOKEN>
<TOKEN end_char="702" id="token-2-11" morph="none" pos="word" start_char="698">Kelly</TOKEN>
<TOKEN end_char="703" id="token-2-12" morph="none" pos="punct" start_char="703">,</TOKEN>
<TOKEN end_char="705" id="token-2-13" morph="none" pos="word" start_char="705">a</TOKEN>
<TOKEN end_char="712" id="token-2-14" morph="none" pos="word" start_char="707">Member</TOKEN>
<TOKEN end_char="715" id="token-2-15" morph="none" pos="word" start_char="714">of</TOKEN>
<TOKEN end_char="719" id="token-2-16" morph="none" pos="word" start_char="717">the</TOKEN>
<TOKEN end_char="730" id="token-2-17" morph="none" pos="word" start_char="721">Australian</TOKEN>
<TOKEN end_char="741" id="token-2-18" morph="none" pos="word" start_char="732">Parliament</TOKEN>
<TOKEN end_char="742" id="token-2-19" morph="none" pos="punct" start_char="742">,</TOKEN>
<TOKEN end_char="750" id="token-2-20" morph="none" pos="word" start_char="744">claimed</TOKEN>
<TOKEN end_char="755" id="token-2-21" morph="none" pos="word" start_char="752">that</TOKEN>
<TOKEN end_char="766" id="token-2-22" morph="none" pos="word" start_char="757">scientific</TOKEN>
<TOKEN end_char="774" id="token-2-23" morph="none" pos="word" start_char="768">studies</TOKEN>
<TOKEN end_char="784" id="token-2-24" morph="none" pos="word" start_char="776">supported</TOKEN>
<TOKEN end_char="788" id="token-2-25" morph="none" pos="word" start_char="786">the</TOKEN>
<TOKEN end_char="792" id="token-2-26" morph="none" pos="word" start_char="790">use</TOKEN>
<TOKEN end_char="795" id="token-2-27" morph="none" pos="word" start_char="794">of</TOKEN>
<TOKEN end_char="806" id="token-2-28" morph="none" pos="word" start_char="797">ivermectin</TOKEN>
<TOKEN end_char="810" id="token-2-29" morph="none" pos="word" start_char="808">for</TOKEN>
<TOKEN end_char="819" id="token-2-30" morph="none" pos="word" start_char="812">treating</TOKEN>
<TOKEN end_char="828" id="token-2-31" morph="none" pos="unknown" start_char="821">COVID-19</TOKEN>
<TOKEN end_char="829" id="token-2-32" morph="none" pos="punct" start_char="829">.</TOKEN>
</SEG>
<SEG end_char="1004" id="segment-3" start_char="831">
<ORIGINAL_TEXT>Published on 15 April 2021, the segment was shared on Kelly’s Facebook page, receiving more than 150,000 views and more than 6,500 interactions, including likes and comments.</ORIGINAL_TEXT>
<TOKEN end_char="839" id="token-3-0" morph="none" pos="word" start_char="831">Published</TOKEN>
<TOKEN end_char="842" id="token-3-1" morph="none" pos="word" start_char="841">on</TOKEN>
<TOKEN end_char="845" id="token-3-2" morph="none" pos="word" start_char="844">15</TOKEN>
<TOKEN end_char="851" id="token-3-3" morph="none" pos="word" start_char="847">April</TOKEN>
<TOKEN end_char="856" id="token-3-4" morph="none" pos="word" start_char="853">2021</TOKEN>
<TOKEN end_char="857" id="token-3-5" morph="none" pos="punct" start_char="857">,</TOKEN>
<TOKEN end_char="861" id="token-3-6" morph="none" pos="word" start_char="859">the</TOKEN>
<TOKEN end_char="869" id="token-3-7" morph="none" pos="word" start_char="863">segment</TOKEN>
<TOKEN end_char="873" id="token-3-8" morph="none" pos="word" start_char="871">was</TOKEN>
<TOKEN end_char="880" id="token-3-9" morph="none" pos="word" start_char="875">shared</TOKEN>
<TOKEN end_char="883" id="token-3-10" morph="none" pos="word" start_char="882">on</TOKEN>
<TOKEN end_char="891" id="token-3-11" morph="none" pos="word" start_char="885">Kelly’s</TOKEN>
<TOKEN end_char="900" id="token-3-12" morph="none" pos="word" start_char="893">Facebook</TOKEN>
<TOKEN end_char="905" id="token-3-13" morph="none" pos="word" start_char="902">page</TOKEN>
<TOKEN end_char="906" id="token-3-14" morph="none" pos="punct" start_char="906">,</TOKEN>
<TOKEN end_char="916" id="token-3-15" morph="none" pos="word" start_char="908">receiving</TOKEN>
<TOKEN end_char="921" id="token-3-16" morph="none" pos="word" start_char="918">more</TOKEN>
<TOKEN end_char="926" id="token-3-17" morph="none" pos="word" start_char="923">than</TOKEN>
<TOKEN end_char="934" id="token-3-18" morph="none" pos="unknown" start_char="928">150,000</TOKEN>
<TOKEN end_char="940" id="token-3-19" morph="none" pos="word" start_char="936">views</TOKEN>
<TOKEN end_char="944" id="token-3-20" morph="none" pos="word" start_char="942">and</TOKEN>
<TOKEN end_char="949" id="token-3-21" morph="none" pos="word" start_char="946">more</TOKEN>
<TOKEN end_char="954" id="token-3-22" morph="none" pos="word" start_char="951">than</TOKEN>
<TOKEN end_char="960" id="token-3-23" morph="none" pos="unknown" start_char="956">6,500</TOKEN>
<TOKEN end_char="973" id="token-3-24" morph="none" pos="word" start_char="962">interactions</TOKEN>
<TOKEN end_char="974" id="token-3-25" morph="none" pos="punct" start_char="974">,</TOKEN>
<TOKEN end_char="984" id="token-3-26" morph="none" pos="word" start_char="976">including</TOKEN>
<TOKEN end_char="990" id="token-3-27" morph="none" pos="word" start_char="986">likes</TOKEN>
<TOKEN end_char="994" id="token-3-28" morph="none" pos="word" start_char="992">and</TOKEN>
<TOKEN end_char="1003" id="token-3-29" morph="none" pos="word" start_char="996">comments</TOKEN>
<TOKEN end_char="1004" id="token-3-30" morph="none" pos="punct" start_char="1004">.</TOKEN>
</SEG>
<SEG end_char="1159" id="segment-4" start_char="1007">
<ORIGINAL_TEXT>This isn’t the first time that Kelly, who has no scientific training, made unsubstantiated claims about the efficacy of ivermectin for treating COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="1010" id="token-4-0" morph="none" pos="word" start_char="1007">This</TOKEN>
<TOKEN end_char="1016" id="token-4-1" morph="none" pos="word" start_char="1012">isn’t</TOKEN>
<TOKEN end_char="1020" id="token-4-2" morph="none" pos="word" start_char="1018">the</TOKEN>
<TOKEN end_char="1026" id="token-4-3" morph="none" pos="word" start_char="1022">first</TOKEN>
<TOKEN end_char="1031" id="token-4-4" morph="none" pos="word" start_char="1028">time</TOKEN>
<TOKEN end_char="1036" id="token-4-5" morph="none" pos="word" start_char="1033">that</TOKEN>
<TOKEN end_char="1042" id="token-4-6" morph="none" pos="word" start_char="1038">Kelly</TOKEN>
<TOKEN end_char="1043" id="token-4-7" morph="none" pos="punct" start_char="1043">,</TOKEN>
<TOKEN end_char="1047" id="token-4-8" morph="none" pos="word" start_char="1045">who</TOKEN>
<TOKEN end_char="1051" id="token-4-9" morph="none" pos="word" start_char="1049">has</TOKEN>
<TOKEN end_char="1054" id="token-4-10" morph="none" pos="word" start_char="1053">no</TOKEN>
<TOKEN end_char="1065" id="token-4-11" morph="none" pos="word" start_char="1056">scientific</TOKEN>
<TOKEN end_char="1074" id="token-4-12" morph="none" pos="word" start_char="1067">training</TOKEN>
<TOKEN end_char="1075" id="token-4-13" morph="none" pos="punct" start_char="1075">,</TOKEN>
<TOKEN end_char="1080" id="token-4-14" morph="none" pos="word" start_char="1077">made</TOKEN>
<TOKEN end_char="1096" id="token-4-15" morph="none" pos="word" start_char="1082">unsubstantiated</TOKEN>
<TOKEN end_char="1103" id="token-4-16" morph="none" pos="word" start_char="1098">claims</TOKEN>
<TOKEN end_char="1109" id="token-4-17" morph="none" pos="word" start_char="1105">about</TOKEN>
<TOKEN end_char="1113" id="token-4-18" morph="none" pos="word" start_char="1111">the</TOKEN>
<TOKEN end_char="1122" id="token-4-19" morph="none" pos="word" start_char="1115">efficacy</TOKEN>
<TOKEN end_char="1125" id="token-4-20" morph="none" pos="word" start_char="1124">of</TOKEN>
<TOKEN end_char="1136" id="token-4-21" morph="none" pos="word" start_char="1127">ivermectin</TOKEN>
<TOKEN end_char="1140" id="token-4-22" morph="none" pos="word" start_char="1138">for</TOKEN>
<TOKEN end_char="1149" id="token-4-23" morph="none" pos="word" start_char="1142">treating</TOKEN>
<TOKEN end_char="1158" id="token-4-24" morph="none" pos="unknown" start_char="1151">COVID-19</TOKEN>
<TOKEN end_char="1159" id="token-4-25" morph="none" pos="punct" start_char="1159">.</TOKEN>
</SEG>
<SEG end_char="1335" id="segment-5" start_char="1161">
<ORIGINAL_TEXT>During the interview, Kelly also cited the findings of physician Tess Lawrie, alleging that 50 out of 51 studies show "ivermectin is not just effective, but highly effective".</ORIGINAL_TEXT>
<TOKEN end_char="1166" id="token-5-0" morph="none" pos="word" start_char="1161">During</TOKEN>
<TOKEN end_char="1170" id="token-5-1" morph="none" pos="word" start_char="1168">the</TOKEN>
<TOKEN end_char="1180" id="token-5-2" morph="none" pos="word" start_char="1172">interview</TOKEN>
<TOKEN end_char="1181" id="token-5-3" morph="none" pos="punct" start_char="1181">,</TOKEN>
<TOKEN end_char="1187" id="token-5-4" morph="none" pos="word" start_char="1183">Kelly</TOKEN>
<TOKEN end_char="1192" id="token-5-5" morph="none" pos="word" start_char="1189">also</TOKEN>
<TOKEN end_char="1198" id="token-5-6" morph="none" pos="word" start_char="1194">cited</TOKEN>
<TOKEN end_char="1202" id="token-5-7" morph="none" pos="word" start_char="1200">the</TOKEN>
<TOKEN end_char="1211" id="token-5-8" morph="none" pos="word" start_char="1204">findings</TOKEN>
<TOKEN end_char="1214" id="token-5-9" morph="none" pos="word" start_char="1213">of</TOKEN>
<TOKEN end_char="1224" id="token-5-10" morph="none" pos="word" start_char="1216">physician</TOKEN>
<TOKEN end_char="1229" id="token-5-11" morph="none" pos="word" start_char="1226">Tess</TOKEN>
<TOKEN end_char="1236" id="token-5-12" morph="none" pos="word" start_char="1231">Lawrie</TOKEN>
<TOKEN end_char="1237" id="token-5-13" morph="none" pos="punct" start_char="1237">,</TOKEN>
<TOKEN end_char="1246" id="token-5-14" morph="none" pos="word" start_char="1239">alleging</TOKEN>
<TOKEN end_char="1251" id="token-5-15" morph="none" pos="word" start_char="1248">that</TOKEN>
<TOKEN end_char="1254" id="token-5-16" morph="none" pos="word" start_char="1253">50</TOKEN>
<TOKEN end_char="1258" id="token-5-17" morph="none" pos="word" start_char="1256">out</TOKEN>
<TOKEN end_char="1261" id="token-5-18" morph="none" pos="word" start_char="1260">of</TOKEN>
<TOKEN end_char="1264" id="token-5-19" morph="none" pos="word" start_char="1263">51</TOKEN>
<TOKEN end_char="1272" id="token-5-20" morph="none" pos="word" start_char="1266">studies</TOKEN>
<TOKEN end_char="1277" id="token-5-21" morph="none" pos="word" start_char="1274">show</TOKEN>
<TOKEN end_char="1279" id="token-5-22" morph="none" pos="punct" start_char="1279">"</TOKEN>
<TOKEN end_char="1289" id="token-5-23" morph="none" pos="word" start_char="1280">ivermectin</TOKEN>
<TOKEN end_char="1292" id="token-5-24" morph="none" pos="word" start_char="1291">is</TOKEN>
<TOKEN end_char="1296" id="token-5-25" morph="none" pos="word" start_char="1294">not</TOKEN>
<TOKEN end_char="1301" id="token-5-26" morph="none" pos="word" start_char="1298">just</TOKEN>
<TOKEN end_char="1311" id="token-5-27" morph="none" pos="word" start_char="1303">effective</TOKEN>
<TOKEN end_char="1312" id="token-5-28" morph="none" pos="punct" start_char="1312">,</TOKEN>
<TOKEN end_char="1316" id="token-5-29" morph="none" pos="word" start_char="1314">but</TOKEN>
<TOKEN end_char="1323" id="token-5-30" morph="none" pos="word" start_char="1318">highly</TOKEN>
<TOKEN end_char="1333" id="token-5-31" morph="none" pos="word" start_char="1325">effective</TOKEN>
<TOKEN end_char="1335" id="token-5-32" morph="none" pos="punct" start_char="1334">".</TOKEN>
</SEG>
<SEG end_char="1373" id="segment-6" start_char="1338">
<ORIGINAL_TEXT>Ivermectin is an antiparasitic drug.</ORIGINAL_TEXT>
<TOKEN end_char="1347" id="token-6-0" morph="none" pos="word" start_char="1338">Ivermectin</TOKEN>
<TOKEN end_char="1350" id="token-6-1" morph="none" pos="word" start_char="1349">is</TOKEN>
<TOKEN end_char="1353" id="token-6-2" morph="none" pos="word" start_char="1352">an</TOKEN>
<TOKEN end_char="1367" id="token-6-3" morph="none" pos="word" start_char="1355">antiparasitic</TOKEN>
<TOKEN end_char="1372" id="token-6-4" morph="none" pos="word" start_char="1369">drug</TOKEN>
<TOKEN end_char="1373" id="token-6-5" morph="none" pos="punct" start_char="1373">.</TOKEN>
</SEG>
<SEG end_char="1507" id="segment-7" start_char="1375">
<ORIGINAL_TEXT>Health Feedback addressed the unsupported claim that ivermectin is effective against COVID-19 in several reviews (see here and here).</ORIGINAL_TEXT>
<TOKEN end_char="1380" id="token-7-0" morph="none" pos="word" start_char="1375">Health</TOKEN>
<TOKEN end_char="1389" id="token-7-1" morph="none" pos="word" start_char="1382">Feedback</TOKEN>
<TOKEN end_char="1399" id="token-7-2" morph="none" pos="word" start_char="1391">addressed</TOKEN>
<TOKEN end_char="1403" id="token-7-3" morph="none" pos="word" start_char="1401">the</TOKEN>
<TOKEN end_char="1415" id="token-7-4" morph="none" pos="word" start_char="1405">unsupported</TOKEN>
<TOKEN end_char="1421" id="token-7-5" morph="none" pos="word" start_char="1417">claim</TOKEN>
<TOKEN end_char="1426" id="token-7-6" morph="none" pos="word" start_char="1423">that</TOKEN>
<TOKEN end_char="1437" id="token-7-7" morph="none" pos="word" start_char="1428">ivermectin</TOKEN>
<TOKEN end_char="1440" id="token-7-8" morph="none" pos="word" start_char="1439">is</TOKEN>
<TOKEN end_char="1450" id="token-7-9" morph="none" pos="word" start_char="1442">effective</TOKEN>
<TOKEN end_char="1458" id="token-7-10" morph="none" pos="word" start_char="1452">against</TOKEN>
<TOKEN end_char="1467" id="token-7-11" morph="none" pos="unknown" start_char="1460">COVID-19</TOKEN>
<TOKEN end_char="1470" id="token-7-12" morph="none" pos="word" start_char="1469">in</TOKEN>
<TOKEN end_char="1478" id="token-7-13" morph="none" pos="word" start_char="1472">several</TOKEN>
<TOKEN end_char="1486" id="token-7-14" morph="none" pos="word" start_char="1480">reviews</TOKEN>
<TOKEN end_char="1488" id="token-7-15" morph="none" pos="punct" start_char="1488">(</TOKEN>
<TOKEN end_char="1491" id="token-7-16" morph="none" pos="word" start_char="1489">see</TOKEN>
<TOKEN end_char="1496" id="token-7-17" morph="none" pos="word" start_char="1493">here</TOKEN>
<TOKEN end_char="1500" id="token-7-18" morph="none" pos="word" start_char="1498">and</TOKEN>
<TOKEN end_char="1505" id="token-7-19" morph="none" pos="word" start_char="1502">here</TOKEN>
<TOKEN end_char="1507" id="token-7-20" morph="none" pos="punct" start_char="1506">).</TOKEN>
</SEG>
<SEG end_char="1648" id="segment-8" start_char="1509">
<ORIGINAL_TEXT>Claims about ivermectin’s efficacy began with a study that reported that ivermectin reduced viral replication of SARS-CoV-2 in cell cultures</ORIGINAL_TEXT>
<TOKEN end_char="1514" id="token-8-0" morph="none" pos="word" start_char="1509">Claims</TOKEN>
<TOKEN end_char="1520" id="token-8-1" morph="none" pos="word" start_char="1516">about</TOKEN>
<TOKEN end_char="1533" id="token-8-2" morph="none" pos="word" start_char="1522">ivermectin’s</TOKEN>
<TOKEN end_char="1542" id="token-8-3" morph="none" pos="word" start_char="1535">efficacy</TOKEN>
<TOKEN end_char="1548" id="token-8-4" morph="none" pos="word" start_char="1544">began</TOKEN>
<TOKEN end_char="1553" id="token-8-5" morph="none" pos="word" start_char="1550">with</TOKEN>
<TOKEN end_char="1555" id="token-8-6" morph="none" pos="word" start_char="1555">a</TOKEN>
<TOKEN end_char="1561" id="token-8-7" morph="none" pos="word" start_char="1557">study</TOKEN>
<TOKEN end_char="1566" id="token-8-8" morph="none" pos="word" start_char="1563">that</TOKEN>
<TOKEN end_char="1575" id="token-8-9" morph="none" pos="word" start_char="1568">reported</TOKEN>
<TOKEN end_char="1580" id="token-8-10" morph="none" pos="word" start_char="1577">that</TOKEN>
<TOKEN end_char="1591" id="token-8-11" morph="none" pos="word" start_char="1582">ivermectin</TOKEN>
<TOKEN end_char="1599" id="token-8-12" morph="none" pos="word" start_char="1593">reduced</TOKEN>
<TOKEN end_char="1605" id="token-8-13" morph="none" pos="word" start_char="1601">viral</TOKEN>
<TOKEN end_char="1617" id="token-8-14" morph="none" pos="word" start_char="1607">replication</TOKEN>
<TOKEN end_char="1620" id="token-8-15" morph="none" pos="word" start_char="1619">of</TOKEN>
<TOKEN end_char="1631" id="token-8-16" morph="none" pos="unknown" start_char="1622">SARS-CoV-2</TOKEN>
<TOKEN end_char="1634" id="token-8-17" morph="none" pos="word" start_char="1633">in</TOKEN>
<TOKEN end_char="1639" id="token-8-18" morph="none" pos="word" start_char="1636">cell</TOKEN>
<TOKEN end_char="1648" id="token-8-19" morph="none" pos="word" start_char="1641">cultures</TOKEN>
</SEG>
<SEG end_char="1653" id="segment-9" start_char="1651">
<ORIGINAL_TEXT>[1]</ORIGINAL_TEXT>
<TOKEN end_char="1651" id="token-9-0" morph="none" pos="punct" start_char="1651">[</TOKEN>
<TOKEN end_char="1652" id="token-9-1" morph="none" pos="word" start_char="1652">1</TOKEN>
<TOKEN end_char="1653" id="token-9-2" morph="none" pos="punct" start_char="1653">]</TOKEN>
</SEG>
<SEG end_char="1656" id="segment-10" start_char="1656">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1656" id="token-10-0" morph="none" pos="punct" start_char="1656">.</TOKEN>
</SEG>
<SEG end_char="1822" id="segment-11" start_char="1659">
<ORIGINAL_TEXT>However, other scientists pointed out that this only occurred at "physiologically unattainable concentrations", as seen in this June 2020 editorial published in the</ORIGINAL_TEXT>
<TOKEN end_char="1665" id="token-11-0" morph="none" pos="word" start_char="1659">However</TOKEN>
<TOKEN end_char="1666" id="token-11-1" morph="none" pos="punct" start_char="1666">,</TOKEN>
<TOKEN end_char="1672" id="token-11-2" morph="none" pos="word" start_char="1668">other</TOKEN>
<TOKEN end_char="1683" id="token-11-3" morph="none" pos="word" start_char="1674">scientists</TOKEN>
<TOKEN end_char="1691" id="token-11-4" morph="none" pos="word" start_char="1685">pointed</TOKEN>
<TOKEN end_char="1695" id="token-11-5" morph="none" pos="word" start_char="1693">out</TOKEN>
<TOKEN end_char="1700" id="token-11-6" morph="none" pos="word" start_char="1697">that</TOKEN>
<TOKEN end_char="1705" id="token-11-7" morph="none" pos="word" start_char="1702">this</TOKEN>
<TOKEN end_char="1710" id="token-11-8" morph="none" pos="word" start_char="1707">only</TOKEN>
<TOKEN end_char="1719" id="token-11-9" morph="none" pos="word" start_char="1712">occurred</TOKEN>
<TOKEN end_char="1722" id="token-11-10" morph="none" pos="word" start_char="1721">at</TOKEN>
<TOKEN end_char="1724" id="token-11-11" morph="none" pos="punct" start_char="1724">"</TOKEN>
<TOKEN end_char="1739" id="token-11-12" morph="none" pos="word" start_char="1725">physiologically</TOKEN>
<TOKEN end_char="1752" id="token-11-13" morph="none" pos="word" start_char="1741">unattainable</TOKEN>
<TOKEN end_char="1767" id="token-11-14" morph="none" pos="word" start_char="1754">concentrations</TOKEN>
<TOKEN end_char="1769" id="token-11-15" morph="none" pos="punct" start_char="1768">",</TOKEN>
<TOKEN end_char="1772" id="token-11-16" morph="none" pos="word" start_char="1771">as</TOKEN>
<TOKEN end_char="1777" id="token-11-17" morph="none" pos="word" start_char="1774">seen</TOKEN>
<TOKEN end_char="1780" id="token-11-18" morph="none" pos="word" start_char="1779">in</TOKEN>
<TOKEN end_char="1785" id="token-11-19" morph="none" pos="word" start_char="1782">this</TOKEN>
<TOKEN end_char="1790" id="token-11-20" morph="none" pos="word" start_char="1787">June</TOKEN>
<TOKEN end_char="1795" id="token-11-21" morph="none" pos="word" start_char="1792">2020</TOKEN>
<TOKEN end_char="1805" id="token-11-22" morph="none" pos="word" start_char="1797">editorial</TOKEN>
<TOKEN end_char="1815" id="token-11-23" morph="none" pos="word" start_char="1807">published</TOKEN>
<TOKEN end_char="1818" id="token-11-24" morph="none" pos="word" start_char="1817">in</TOKEN>
<TOKEN end_char="1822" id="token-11-25" morph="none" pos="word" start_char="1820">the</TOKEN>
</SEG>
<SEG end_char="1873" id="segment-12" start_char="1825">
<ORIGINAL_TEXT>American Journal of Tropical Medicine and Hygiene</ORIGINAL_TEXT>
<TOKEN end_char="1832" id="token-12-0" morph="none" pos="word" start_char="1825">American</TOKEN>
<TOKEN end_char="1840" id="token-12-1" morph="none" pos="word" start_char="1834">Journal</TOKEN>
<TOKEN end_char="1843" id="token-12-2" morph="none" pos="word" start_char="1842">of</TOKEN>
<TOKEN end_char="1852" id="token-12-3" morph="none" pos="word" start_char="1845">Tropical</TOKEN>
<TOKEN end_char="1861" id="token-12-4" morph="none" pos="word" start_char="1854">Medicine</TOKEN>
<TOKEN end_char="1865" id="token-12-5" morph="none" pos="word" start_char="1863">and</TOKEN>
<TOKEN end_char="1873" id="token-12-6" morph="none" pos="word" start_char="1867">Hygiene</TOKEN>
</SEG>
<SEG end_char="1878" id="segment-13" start_char="1876">
<ORIGINAL_TEXT>[2]</ORIGINAL_TEXT>
<TOKEN end_char="1876" id="token-13-0" morph="none" pos="punct" start_char="1876">[</TOKEN>
<TOKEN end_char="1877" id="token-13-1" morph="none" pos="word" start_char="1877">2</TOKEN>
<TOKEN end_char="1878" id="token-13-2" morph="none" pos="punct" start_char="1878">]</TOKEN>
</SEG>
<SEG end_char="1881" id="segment-14" start_char="1881">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1881" id="token-14-0" morph="none" pos="punct" start_char="1881">.</TOKEN>
</SEG>
<SEG end_char="2067" id="segment-15" start_char="1883">
<ORIGINAL_TEXT>The same editorial acknowledged that this alone wouldn’t rule out the possibility that ivermectin had some beneficial effect in people, hence clinical trials would still be of interest.</ORIGINAL_TEXT>
<TOKEN end_char="1885" id="token-15-0" morph="none" pos="word" start_char="1883">The</TOKEN>
<TOKEN end_char="1890" id="token-15-1" morph="none" pos="word" start_char="1887">same</TOKEN>
<TOKEN end_char="1900" id="token-15-2" morph="none" pos="word" start_char="1892">editorial</TOKEN>
<TOKEN end_char="1913" id="token-15-3" morph="none" pos="word" start_char="1902">acknowledged</TOKEN>
<TOKEN end_char="1918" id="token-15-4" morph="none" pos="word" start_char="1915">that</TOKEN>
<TOKEN end_char="1923" id="token-15-5" morph="none" pos="word" start_char="1920">this</TOKEN>
<TOKEN end_char="1929" id="token-15-6" morph="none" pos="word" start_char="1925">alone</TOKEN>
<TOKEN end_char="1938" id="token-15-7" morph="none" pos="word" start_char="1931">wouldn’t</TOKEN>
<TOKEN end_char="1943" id="token-15-8" morph="none" pos="word" start_char="1940">rule</TOKEN>
<TOKEN end_char="1947" id="token-15-9" morph="none" pos="word" start_char="1945">out</TOKEN>
<TOKEN end_char="1951" id="token-15-10" morph="none" pos="word" start_char="1949">the</TOKEN>
<TOKEN end_char="1963" id="token-15-11" morph="none" pos="word" start_char="1953">possibility</TOKEN>
<TOKEN end_char="1968" id="token-15-12" morph="none" pos="word" start_char="1965">that</TOKEN>
<TOKEN end_char="1979" id="token-15-13" morph="none" pos="word" start_char="1970">ivermectin</TOKEN>
<TOKEN end_char="1983" id="token-15-14" morph="none" pos="word" start_char="1981">had</TOKEN>
<TOKEN end_char="1988" id="token-15-15" morph="none" pos="word" start_char="1985">some</TOKEN>
<TOKEN end_char="1999" id="token-15-16" morph="none" pos="word" start_char="1990">beneficial</TOKEN>
<TOKEN end_char="2006" id="token-15-17" morph="none" pos="word" start_char="2001">effect</TOKEN>
<TOKEN end_char="2009" id="token-15-18" morph="none" pos="word" start_char="2008">in</TOKEN>
<TOKEN end_char="2016" id="token-15-19" morph="none" pos="word" start_char="2011">people</TOKEN>
<TOKEN end_char="2017" id="token-15-20" morph="none" pos="punct" start_char="2017">,</TOKEN>
<TOKEN end_char="2023" id="token-15-21" morph="none" pos="word" start_char="2019">hence</TOKEN>
<TOKEN end_char="2032" id="token-15-22" morph="none" pos="word" start_char="2025">clinical</TOKEN>
<TOKEN end_char="2039" id="token-15-23" morph="none" pos="word" start_char="2034">trials</TOKEN>
<TOKEN end_char="2045" id="token-15-24" morph="none" pos="word" start_char="2041">would</TOKEN>
<TOKEN end_char="2051" id="token-15-25" morph="none" pos="word" start_char="2047">still</TOKEN>
<TOKEN end_char="2054" id="token-15-26" morph="none" pos="word" start_char="2053">be</TOKEN>
<TOKEN end_char="2057" id="token-15-27" morph="none" pos="word" start_char="2056">of</TOKEN>
<TOKEN end_char="2066" id="token-15-28" morph="none" pos="word" start_char="2059">interest</TOKEN>
<TOKEN end_char="2067" id="token-15-29" morph="none" pos="punct" start_char="2067">.</TOKEN>
</SEG>
<SEG end_char="2203" id="segment-16" start_char="2070">
<ORIGINAL_TEXT>Since that editorial’s publication, numerous clinical trials studying the efficacy of ivermectin against COVID-19 have been conducted.</ORIGINAL_TEXT>
<TOKEN end_char="2074" id="token-16-0" morph="none" pos="word" start_char="2070">Since</TOKEN>
<TOKEN end_char="2079" id="token-16-1" morph="none" pos="word" start_char="2076">that</TOKEN>
<TOKEN end_char="2091" id="token-16-2" morph="none" pos="word" start_char="2081">editorial’s</TOKEN>
<TOKEN end_char="2103" id="token-16-3" morph="none" pos="word" start_char="2093">publication</TOKEN>
<TOKEN end_char="2104" id="token-16-4" morph="none" pos="punct" start_char="2104">,</TOKEN>
<TOKEN end_char="2113" id="token-16-5" morph="none" pos="word" start_char="2106">numerous</TOKEN>
<TOKEN end_char="2122" id="token-16-6" morph="none" pos="word" start_char="2115">clinical</TOKEN>
<TOKEN end_char="2129" id="token-16-7" morph="none" pos="word" start_char="2124">trials</TOKEN>
<TOKEN end_char="2138" id="token-16-8" morph="none" pos="word" start_char="2131">studying</TOKEN>
<TOKEN end_char="2142" id="token-16-9" morph="none" pos="word" start_char="2140">the</TOKEN>
<TOKEN end_char="2151" id="token-16-10" morph="none" pos="word" start_char="2144">efficacy</TOKEN>
<TOKEN end_char="2154" id="token-16-11" morph="none" pos="word" start_char="2153">of</TOKEN>
<TOKEN end_char="2165" id="token-16-12" morph="none" pos="word" start_char="2156">ivermectin</TOKEN>
<TOKEN end_char="2173" id="token-16-13" morph="none" pos="word" start_char="2167">against</TOKEN>
<TOKEN end_char="2182" id="token-16-14" morph="none" pos="unknown" start_char="2175">COVID-19</TOKEN>
<TOKEN end_char="2187" id="token-16-15" morph="none" pos="word" start_char="2184">have</TOKEN>
<TOKEN end_char="2192" id="token-16-16" morph="none" pos="word" start_char="2189">been</TOKEN>
<TOKEN end_char="2202" id="token-16-17" morph="none" pos="word" start_char="2194">conducted</TOKEN>
<TOKEN end_char="2203" id="token-16-18" morph="none" pos="punct" start_char="2203">.</TOKEN>
</SEG>
<SEG end_char="2355" id="segment-17" start_char="2205">
<ORIGINAL_TEXT>Public health authorities have attempted to use currently available data to provide the best possible guidance, at this time, on the use of ivermectin.</ORIGINAL_TEXT>
<TOKEN end_char="2210" id="token-17-0" morph="none" pos="word" start_char="2205">Public</TOKEN>
<TOKEN end_char="2217" id="token-17-1" morph="none" pos="word" start_char="2212">health</TOKEN>
<TOKEN end_char="2229" id="token-17-2" morph="none" pos="word" start_char="2219">authorities</TOKEN>
<TOKEN end_char="2234" id="token-17-3" morph="none" pos="word" start_char="2231">have</TOKEN>
<TOKEN end_char="2244" id="token-17-4" morph="none" pos="word" start_char="2236">attempted</TOKEN>
<TOKEN end_char="2247" id="token-17-5" morph="none" pos="word" start_char="2246">to</TOKEN>
<TOKEN end_char="2251" id="token-17-6" morph="none" pos="word" start_char="2249">use</TOKEN>
<TOKEN end_char="2261" id="token-17-7" morph="none" pos="word" start_char="2253">currently</TOKEN>
<TOKEN end_char="2271" id="token-17-8" morph="none" pos="word" start_char="2263">available</TOKEN>
<TOKEN end_char="2276" id="token-17-9" morph="none" pos="word" start_char="2273">data</TOKEN>
<TOKEN end_char="2279" id="token-17-10" morph="none" pos="word" start_char="2278">to</TOKEN>
<TOKEN end_char="2287" id="token-17-11" morph="none" pos="word" start_char="2281">provide</TOKEN>
<TOKEN end_char="2291" id="token-17-12" morph="none" pos="word" start_char="2289">the</TOKEN>
<TOKEN end_char="2296" id="token-17-13" morph="none" pos="word" start_char="2293">best</TOKEN>
<TOKEN end_char="2305" id="token-17-14" morph="none" pos="word" start_char="2298">possible</TOKEN>
<TOKEN end_char="2314" id="token-17-15" morph="none" pos="word" start_char="2307">guidance</TOKEN>
<TOKEN end_char="2315" id="token-17-16" morph="none" pos="punct" start_char="2315">,</TOKEN>
<TOKEN end_char="2318" id="token-17-17" morph="none" pos="word" start_char="2317">at</TOKEN>
<TOKEN end_char="2323" id="token-17-18" morph="none" pos="word" start_char="2320">this</TOKEN>
<TOKEN end_char="2328" id="token-17-19" morph="none" pos="word" start_char="2325">time</TOKEN>
<TOKEN end_char="2329" id="token-17-20" morph="none" pos="punct" start_char="2329">,</TOKEN>
<TOKEN end_char="2332" id="token-17-21" morph="none" pos="word" start_char="2331">on</TOKEN>
<TOKEN end_char="2336" id="token-17-22" morph="none" pos="word" start_char="2334">the</TOKEN>
<TOKEN end_char="2340" id="token-17-23" morph="none" pos="word" start_char="2338">use</TOKEN>
<TOKEN end_char="2343" id="token-17-24" morph="none" pos="word" start_char="2342">of</TOKEN>
<TOKEN end_char="2354" id="token-17-25" morph="none" pos="word" start_char="2345">ivermectin</TOKEN>
<TOKEN end_char="2355" id="token-17-26" morph="none" pos="punct" start_char="2355">.</TOKEN>
</SEG>
<SEG end_char="2493" id="segment-18" start_char="2358">
<ORIGINAL_TEXT>For example, the World Health Organization (WHO) evaluated data from 16 randomized controlled trials, which included 2,407 participants.</ORIGINAL_TEXT>
<TOKEN end_char="2360" id="token-18-0" morph="none" pos="word" start_char="2358">For</TOKEN>
<TOKEN end_char="2368" id="token-18-1" morph="none" pos="word" start_char="2362">example</TOKEN>
<TOKEN end_char="2369" id="token-18-2" morph="none" pos="punct" start_char="2369">,</TOKEN>
<TOKEN end_char="2373" id="token-18-3" morph="none" pos="word" start_char="2371">the</TOKEN>
<TOKEN end_char="2379" id="token-18-4" morph="none" pos="word" start_char="2375">World</TOKEN>
<TOKEN end_char="2386" id="token-18-5" morph="none" pos="word" start_char="2381">Health</TOKEN>
<TOKEN end_char="2399" id="token-18-6" morph="none" pos="word" start_char="2388">Organization</TOKEN>
<TOKEN end_char="2401" id="token-18-7" morph="none" pos="punct" start_char="2401">(</TOKEN>
<TOKEN end_char="2404" id="token-18-8" morph="none" pos="word" start_char="2402">WHO</TOKEN>
<TOKEN end_char="2405" id="token-18-9" morph="none" pos="punct" start_char="2405">)</TOKEN>
<TOKEN end_char="2415" id="token-18-10" morph="none" pos="word" start_char="2407">evaluated</TOKEN>
<TOKEN end_char="2420" id="token-18-11" morph="none" pos="word" start_char="2417">data</TOKEN>
<TOKEN end_char="2425" id="token-18-12" morph="none" pos="word" start_char="2422">from</TOKEN>
<TOKEN end_char="2428" id="token-18-13" morph="none" pos="word" start_char="2427">16</TOKEN>
<TOKEN end_char="2439" id="token-18-14" morph="none" pos="word" start_char="2430">randomized</TOKEN>
<TOKEN end_char="2450" id="token-18-15" morph="none" pos="word" start_char="2441">controlled</TOKEN>
<TOKEN end_char="2457" id="token-18-16" morph="none" pos="word" start_char="2452">trials</TOKEN>
<TOKEN end_char="2458" id="token-18-17" morph="none" pos="punct" start_char="2458">,</TOKEN>
<TOKEN end_char="2464" id="token-18-18" morph="none" pos="word" start_char="2460">which</TOKEN>
<TOKEN end_char="2473" id="token-18-19" morph="none" pos="word" start_char="2466">included</TOKEN>
<TOKEN end_char="2479" id="token-18-20" morph="none" pos="unknown" start_char="2475">2,407</TOKEN>
<TOKEN end_char="2492" id="token-18-21" morph="none" pos="word" start_char="2481">participants</TOKEN>
<TOKEN end_char="2493" id="token-18-22" morph="none" pos="punct" start_char="2493">.</TOKEN>
</SEG>
<SEG end_char="2698" id="segment-19" start_char="2495">
<ORIGINAL_TEXT>Its living guideline on proposed therapeutics for COVID-19, most recently updated on 31 March 2021, recommended "not to use ivermectin in patients with COVID-19 except in the context of a clinical trial".</ORIGINAL_TEXT>
<TOKEN end_char="2497" id="token-19-0" morph="none" pos="word" start_char="2495">Its</TOKEN>
<TOKEN end_char="2504" id="token-19-1" morph="none" pos="word" start_char="2499">living</TOKEN>
<TOKEN end_char="2514" id="token-19-2" morph="none" pos="word" start_char="2506">guideline</TOKEN>
<TOKEN end_char="2517" id="token-19-3" morph="none" pos="word" start_char="2516">on</TOKEN>
<TOKEN end_char="2526" id="token-19-4" morph="none" pos="word" start_char="2519">proposed</TOKEN>
<TOKEN end_char="2539" id="token-19-5" morph="none" pos="word" start_char="2528">therapeutics</TOKEN>
<TOKEN end_char="2543" id="token-19-6" morph="none" pos="word" start_char="2541">for</TOKEN>
<TOKEN end_char="2552" id="token-19-7" morph="none" pos="unknown" start_char="2545">COVID-19</TOKEN>
<TOKEN end_char="2553" id="token-19-8" morph="none" pos="punct" start_char="2553">,</TOKEN>
<TOKEN end_char="2558" id="token-19-9" morph="none" pos="word" start_char="2555">most</TOKEN>
<TOKEN end_char="2567" id="token-19-10" morph="none" pos="word" start_char="2560">recently</TOKEN>
<TOKEN end_char="2575" id="token-19-11" morph="none" pos="word" start_char="2569">updated</TOKEN>
<TOKEN end_char="2578" id="token-19-12" morph="none" pos="word" start_char="2577">on</TOKEN>
<TOKEN end_char="2581" id="token-19-13" morph="none" pos="word" start_char="2580">31</TOKEN>
<TOKEN end_char="2587" id="token-19-14" morph="none" pos="word" start_char="2583">March</TOKEN>
<TOKEN end_char="2592" id="token-19-15" morph="none" pos="word" start_char="2589">2021</TOKEN>
<TOKEN end_char="2593" id="token-19-16" morph="none" pos="punct" start_char="2593">,</TOKEN>
<TOKEN end_char="2605" id="token-19-17" morph="none" pos="word" start_char="2595">recommended</TOKEN>
<TOKEN end_char="2607" id="token-19-18" morph="none" pos="punct" start_char="2607">"</TOKEN>
<TOKEN end_char="2610" id="token-19-19" morph="none" pos="word" start_char="2608">not</TOKEN>
<TOKEN end_char="2613" id="token-19-20" morph="none" pos="word" start_char="2612">to</TOKEN>
<TOKEN end_char="2617" id="token-19-21" morph="none" pos="word" start_char="2615">use</TOKEN>
<TOKEN end_char="2628" id="token-19-22" morph="none" pos="word" start_char="2619">ivermectin</TOKEN>
<TOKEN end_char="2631" id="token-19-23" morph="none" pos="word" start_char="2630">in</TOKEN>
<TOKEN end_char="2640" id="token-19-24" morph="none" pos="word" start_char="2633">patients</TOKEN>
<TOKEN end_char="2645" id="token-19-25" morph="none" pos="word" start_char="2642">with</TOKEN>
<TOKEN end_char="2654" id="token-19-26" morph="none" pos="unknown" start_char="2647">COVID-19</TOKEN>
<TOKEN end_char="2661" id="token-19-27" morph="none" pos="word" start_char="2656">except</TOKEN>
<TOKEN end_char="2664" id="token-19-28" morph="none" pos="word" start_char="2663">in</TOKEN>
<TOKEN end_char="2668" id="token-19-29" morph="none" pos="word" start_char="2666">the</TOKEN>
<TOKEN end_char="2676" id="token-19-30" morph="none" pos="word" start_char="2670">context</TOKEN>
<TOKEN end_char="2679" id="token-19-31" morph="none" pos="word" start_char="2678">of</TOKEN>
<TOKEN end_char="2681" id="token-19-32" morph="none" pos="word" start_char="2681">a</TOKEN>
<TOKEN end_char="2690" id="token-19-33" morph="none" pos="word" start_char="2683">clinical</TOKEN>
<TOKEN end_char="2696" id="token-19-34" morph="none" pos="word" start_char="2692">trial</TOKEN>
<TOKEN end_char="2698" id="token-19-35" morph="none" pos="punct" start_char="2697">".</TOKEN>
</SEG>
<SEG end_char="2770" id="segment-20" start_char="2701">
<ORIGINAL_TEXT>The guideline also explained the decision not to recommend ivermectin:</ORIGINAL_TEXT>
<TOKEN end_char="2703" id="token-20-0" morph="none" pos="word" start_char="2701">The</TOKEN>
<TOKEN end_char="2713" id="token-20-1" morph="none" pos="word" start_char="2705">guideline</TOKEN>
<TOKEN end_char="2718" id="token-20-2" morph="none" pos="word" start_char="2715">also</TOKEN>
<TOKEN end_char="2728" id="token-20-3" morph="none" pos="word" start_char="2720">explained</TOKEN>
<TOKEN end_char="2732" id="token-20-4" morph="none" pos="word" start_char="2730">the</TOKEN>
<TOKEN end_char="2741" id="token-20-5" morph="none" pos="word" start_char="2734">decision</TOKEN>
<TOKEN end_char="2745" id="token-20-6" morph="none" pos="word" start_char="2743">not</TOKEN>
<TOKEN end_char="2748" id="token-20-7" morph="none" pos="word" start_char="2747">to</TOKEN>
<TOKEN end_char="2758" id="token-20-8" morph="none" pos="word" start_char="2750">recommend</TOKEN>
<TOKEN end_char="2769" id="token-20-9" morph="none" pos="word" start_char="2760">ivermectin</TOKEN>
<TOKEN end_char="2770" id="token-20-10" morph="none" pos="punct" start_char="2770">:</TOKEN>
</SEG>
<SEG end_char="2773" id="segment-21" start_char="2773">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN end_char="2773" id="token-21-0" morph="none" pos="punct" start_char="2773">"</TOKEN>
</SEG>
<SEG end_char="2993" id="segment-22" start_char="2776">
<ORIGINAL_TEXT>The effects of ivermectin on mortality, need for invasive mechanical ventilation, hospital admission, duration of hospitalization and time to viral clearance all remain very uncertain (all very low certainty evidence).</ORIGINAL_TEXT>
<TOKEN end_char="2778" id="token-22-0" morph="none" pos="word" start_char="2776">The</TOKEN>
<TOKEN end_char="2786" id="token-22-1" morph="none" pos="word" start_char="2780">effects</TOKEN>
<TOKEN end_char="2789" id="token-22-2" morph="none" pos="word" start_char="2788">of</TOKEN>
<TOKEN end_char="2800" id="token-22-3" morph="none" pos="word" start_char="2791">ivermectin</TOKEN>
<TOKEN end_char="2803" id="token-22-4" morph="none" pos="word" start_char="2802">on</TOKEN>
<TOKEN end_char="2813" id="token-22-5" morph="none" pos="word" start_char="2805">mortality</TOKEN>
<TOKEN end_char="2814" id="token-22-6" morph="none" pos="punct" start_char="2814">,</TOKEN>
<TOKEN end_char="2819" id="token-22-7" morph="none" pos="word" start_char="2816">need</TOKEN>
<TOKEN end_char="2823" id="token-22-8" morph="none" pos="word" start_char="2821">for</TOKEN>
<TOKEN end_char="2832" id="token-22-9" morph="none" pos="word" start_char="2825">invasive</TOKEN>
<TOKEN end_char="2843" id="token-22-10" morph="none" pos="word" start_char="2834">mechanical</TOKEN>
<TOKEN end_char="2855" id="token-22-11" morph="none" pos="word" start_char="2845">ventilation</TOKEN>
<TOKEN end_char="2856" id="token-22-12" morph="none" pos="punct" start_char="2856">,</TOKEN>
<TOKEN end_char="2865" id="token-22-13" morph="none" pos="word" start_char="2858">hospital</TOKEN>
<TOKEN end_char="2875" id="token-22-14" morph="none" pos="word" start_char="2867">admission</TOKEN>
<TOKEN end_char="2876" id="token-22-15" morph="none" pos="punct" start_char="2876">,</TOKEN>
<TOKEN end_char="2885" id="token-22-16" morph="none" pos="word" start_char="2878">duration</TOKEN>
<TOKEN end_char="2888" id="token-22-17" morph="none" pos="word" start_char="2887">of</TOKEN>
<TOKEN end_char="2904" id="token-22-18" morph="none" pos="word" start_char="2890">hospitalization</TOKEN>
<TOKEN end_char="2908" id="token-22-19" morph="none" pos="word" start_char="2906">and</TOKEN>
<TOKEN end_char="2913" id="token-22-20" morph="none" pos="word" start_char="2910">time</TOKEN>
<TOKEN end_char="2916" id="token-22-21" morph="none" pos="word" start_char="2915">to</TOKEN>
<TOKEN end_char="2922" id="token-22-22" morph="none" pos="word" start_char="2918">viral</TOKEN>
<TOKEN end_char="2932" id="token-22-23" morph="none" pos="word" start_char="2924">clearance</TOKEN>
<TOKEN end_char="2936" id="token-22-24" morph="none" pos="word" start_char="2934">all</TOKEN>
<TOKEN end_char="2943" id="token-22-25" morph="none" pos="word" start_char="2938">remain</TOKEN>
<TOKEN end_char="2948" id="token-22-26" morph="none" pos="word" start_char="2945">very</TOKEN>
<TOKEN end_char="2958" id="token-22-27" morph="none" pos="word" start_char="2950">uncertain</TOKEN>
<TOKEN end_char="2960" id="token-22-28" morph="none" pos="punct" start_char="2960">(</TOKEN>
<TOKEN end_char="2963" id="token-22-29" morph="none" pos="word" start_char="2961">all</TOKEN>
<TOKEN end_char="2968" id="token-22-30" morph="none" pos="word" start_char="2965">very</TOKEN>
<TOKEN end_char="2972" id="token-22-31" morph="none" pos="word" start_char="2970">low</TOKEN>
<TOKEN end_char="2982" id="token-22-32" morph="none" pos="word" start_char="2974">certainty</TOKEN>
<TOKEN end_char="2991" id="token-22-33" morph="none" pos="word" start_char="2984">evidence</TOKEN>
<TOKEN end_char="2993" id="token-22-34" morph="none" pos="punct" start_char="2992">).</TOKEN>
</SEG>
<SEG end_char="3212" id="segment-23" start_char="2995">
<ORIGINAL_TEXT>The uncertainty results from important concerns related to risk of bias in the included studies, and imprecision from a very low number of events and, in some cases, wide confidence intervals (CIs) in pooled estimates.</ORIGINAL_TEXT>
<TOKEN end_char="2997" id="token-23-0" morph="none" pos="word" start_char="2995">The</TOKEN>
<TOKEN end_char="3009" id="token-23-1" morph="none" pos="word" start_char="2999">uncertainty</TOKEN>
<TOKEN end_char="3017" id="token-23-2" morph="none" pos="word" start_char="3011">results</TOKEN>
<TOKEN end_char="3022" id="token-23-3" morph="none" pos="word" start_char="3019">from</TOKEN>
<TOKEN end_char="3032" id="token-23-4" morph="none" pos="word" start_char="3024">important</TOKEN>
<TOKEN end_char="3041" id="token-23-5" morph="none" pos="word" start_char="3034">concerns</TOKEN>
<TOKEN end_char="3049" id="token-23-6" morph="none" pos="word" start_char="3043">related</TOKEN>
<TOKEN end_char="3052" id="token-23-7" morph="none" pos="word" start_char="3051">to</TOKEN>
<TOKEN end_char="3057" id="token-23-8" morph="none" pos="word" start_char="3054">risk</TOKEN>
<TOKEN end_char="3060" id="token-23-9" morph="none" pos="word" start_char="3059">of</TOKEN>
<TOKEN end_char="3065" id="token-23-10" morph="none" pos="word" start_char="3062">bias</TOKEN>
<TOKEN end_char="3068" id="token-23-11" morph="none" pos="word" start_char="3067">in</TOKEN>
<TOKEN end_char="3072" id="token-23-12" morph="none" pos="word" start_char="3070">the</TOKEN>
<TOKEN end_char="3081" id="token-23-13" morph="none" pos="word" start_char="3074">included</TOKEN>
<TOKEN end_char="3089" id="token-23-14" morph="none" pos="word" start_char="3083">studies</TOKEN>
<TOKEN end_char="3090" id="token-23-15" morph="none" pos="punct" start_char="3090">,</TOKEN>
<TOKEN end_char="3094" id="token-23-16" morph="none" pos="word" start_char="3092">and</TOKEN>
<TOKEN end_char="3106" id="token-23-17" morph="none" pos="word" start_char="3096">imprecision</TOKEN>
<TOKEN end_char="3111" id="token-23-18" morph="none" pos="word" start_char="3108">from</TOKEN>
<TOKEN end_char="3113" id="token-23-19" morph="none" pos="word" start_char="3113">a</TOKEN>
<TOKEN end_char="3118" id="token-23-20" morph="none" pos="word" start_char="3115">very</TOKEN>
<TOKEN end_char="3122" id="token-23-21" morph="none" pos="word" start_char="3120">low</TOKEN>
<TOKEN end_char="3129" id="token-23-22" morph="none" pos="word" start_char="3124">number</TOKEN>
<TOKEN end_char="3132" id="token-23-23" morph="none" pos="word" start_char="3131">of</TOKEN>
<TOKEN end_char="3139" id="token-23-24" morph="none" pos="word" start_char="3134">events</TOKEN>
<TOKEN end_char="3143" id="token-23-25" morph="none" pos="word" start_char="3141">and</TOKEN>
<TOKEN end_char="3144" id="token-23-26" morph="none" pos="punct" start_char="3144">,</TOKEN>
<TOKEN end_char="3147" id="token-23-27" morph="none" pos="word" start_char="3146">in</TOKEN>
<TOKEN end_char="3152" id="token-23-28" morph="none" pos="word" start_char="3149">some</TOKEN>
<TOKEN end_char="3158" id="token-23-29" morph="none" pos="word" start_char="3154">cases</TOKEN>
<TOKEN end_char="3159" id="token-23-30" morph="none" pos="punct" start_char="3159">,</TOKEN>
<TOKEN end_char="3164" id="token-23-31" morph="none" pos="word" start_char="3161">wide</TOKEN>
<TOKEN end_char="3175" id="token-23-32" morph="none" pos="word" start_char="3166">confidence</TOKEN>
<TOKEN end_char="3185" id="token-23-33" morph="none" pos="word" start_char="3177">intervals</TOKEN>
<TOKEN end_char="3187" id="token-23-34" morph="none" pos="punct" start_char="3187">(</TOKEN>
<TOKEN end_char="3190" id="token-23-35" morph="none" pos="word" start_char="3188">CIs</TOKEN>
<TOKEN end_char="3191" id="token-23-36" morph="none" pos="punct" start_char="3191">)</TOKEN>
<TOKEN end_char="3194" id="token-23-37" morph="none" pos="word" start_char="3193">in</TOKEN>
<TOKEN end_char="3201" id="token-23-38" morph="none" pos="word" start_char="3196">pooled</TOKEN>
<TOKEN end_char="3211" id="token-23-39" morph="none" pos="word" start_char="3203">estimates</TOKEN>
<TOKEN end_char="3212" id="token-23-40" morph="none" pos="punct" start_char="3212">.</TOKEN>
</SEG>
<SEG end_char="3215" id="segment-24" start_char="3215">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN end_char="3215" id="token-24-0" morph="none" pos="punct" start_char="3215">"</TOKEN>
</SEG>
<SEG end_char="3386" id="segment-25" start_char="3219">
<ORIGINAL_TEXT>The guideline also stated that "further high-quality clinical trials examining this drug would be essential before any recommendation for use as part of clinical care".</ORIGINAL_TEXT>
<TOKEN end_char="3221" id="token-25-0" morph="none" pos="word" start_char="3219">The</TOKEN>
<TOKEN end_char="3231" id="token-25-1" morph="none" pos="word" start_char="3223">guideline</TOKEN>
<TOKEN end_char="3236" id="token-25-2" morph="none" pos="word" start_char="3233">also</TOKEN>
<TOKEN end_char="3243" id="token-25-3" morph="none" pos="word" start_char="3238">stated</TOKEN>
<TOKEN end_char="3248" id="token-25-4" morph="none" pos="word" start_char="3245">that</TOKEN>
<TOKEN end_char="3250" id="token-25-5" morph="none" pos="punct" start_char="3250">"</TOKEN>
<TOKEN end_char="3257" id="token-25-6" morph="none" pos="word" start_char="3251">further</TOKEN>
<TOKEN end_char="3270" id="token-25-7" morph="none" pos="unknown" start_char="3259">high-quality</TOKEN>
<TOKEN end_char="3279" id="token-25-8" morph="none" pos="word" start_char="3272">clinical</TOKEN>
<TOKEN end_char="3286" id="token-25-9" morph="none" pos="word" start_char="3281">trials</TOKEN>
<TOKEN end_char="3296" id="token-25-10" morph="none" pos="word" start_char="3288">examining</TOKEN>
<TOKEN end_char="3301" id="token-25-11" morph="none" pos="word" start_char="3298">this</TOKEN>
<TOKEN end_char="3306" id="token-25-12" morph="none" pos="word" start_char="3303">drug</TOKEN>
<TOKEN end_char="3312" id="token-25-13" morph="none" pos="word" start_char="3308">would</TOKEN>
<TOKEN end_char="3315" id="token-25-14" morph="none" pos="word" start_char="3314">be</TOKEN>
<TOKEN end_char="3325" id="token-25-15" morph="none" pos="word" start_char="3317">essential</TOKEN>
<TOKEN end_char="3332" id="token-25-16" morph="none" pos="word" start_char="3327">before</TOKEN>
<TOKEN end_char="3336" id="token-25-17" morph="none" pos="word" start_char="3334">any</TOKEN>
<TOKEN end_char="3351" id="token-25-18" morph="none" pos="word" start_char="3338">recommendation</TOKEN>
<TOKEN end_char="3355" id="token-25-19" morph="none" pos="word" start_char="3353">for</TOKEN>
<TOKEN end_char="3359" id="token-25-20" morph="none" pos="word" start_char="3357">use</TOKEN>
<TOKEN end_char="3362" id="token-25-21" morph="none" pos="word" start_char="3361">as</TOKEN>
<TOKEN end_char="3367" id="token-25-22" morph="none" pos="word" start_char="3364">part</TOKEN>
<TOKEN end_char="3370" id="token-25-23" morph="none" pos="word" start_char="3369">of</TOKEN>
<TOKEN end_char="3379" id="token-25-24" morph="none" pos="word" start_char="3372">clinical</TOKEN>
<TOKEN end_char="3384" id="token-25-25" morph="none" pos="word" start_char="3381">care</TOKEN>
<TOKEN end_char="3386" id="token-25-26" morph="none" pos="punct" start_char="3385">".</TOKEN>
</SEG>
<SEG end_char="3518" id="segment-26" start_char="3389">
<ORIGINAL_TEXT>Likewise, the U.S. National Institutes of Health evaluated multiple clinical trials, some of which are listed here, and concluded:</ORIGINAL_TEXT>
<TOKEN end_char="3396" id="token-26-0" morph="none" pos="word" start_char="3389">Likewise</TOKEN>
<TOKEN end_char="3397" id="token-26-1" morph="none" pos="punct" start_char="3397">,</TOKEN>
<TOKEN end_char="3401" id="token-26-2" morph="none" pos="word" start_char="3399">the</TOKEN>
<TOKEN end_char="3405" id="token-26-3" morph="none" pos="unknown" start_char="3403">U.S</TOKEN>
<TOKEN end_char="3406" id="token-26-4" morph="none" pos="punct" start_char="3406">.</TOKEN>
<TOKEN end_char="3415" id="token-26-5" morph="none" pos="word" start_char="3408">National</TOKEN>
<TOKEN end_char="3426" id="token-26-6" morph="none" pos="word" start_char="3417">Institutes</TOKEN>
<TOKEN end_char="3429" id="token-26-7" morph="none" pos="word" start_char="3428">of</TOKEN>
<TOKEN end_char="3436" id="token-26-8" morph="none" pos="word" start_char="3431">Health</TOKEN>
<TOKEN end_char="3446" id="token-26-9" morph="none" pos="word" start_char="3438">evaluated</TOKEN>
<TOKEN end_char="3455" id="token-26-10" morph="none" pos="word" start_char="3448">multiple</TOKEN>
<TOKEN end_char="3464" id="token-26-11" morph="none" pos="word" start_char="3457">clinical</TOKEN>
<TOKEN end_char="3471" id="token-26-12" morph="none" pos="word" start_char="3466">trials</TOKEN>
<TOKEN end_char="3472" id="token-26-13" morph="none" pos="punct" start_char="3472">,</TOKEN>
<TOKEN end_char="3477" id="token-26-14" morph="none" pos="word" start_char="3474">some</TOKEN>
<TOKEN end_char="3480" id="token-26-15" morph="none" pos="word" start_char="3479">of</TOKEN>
<TOKEN end_char="3486" id="token-26-16" morph="none" pos="word" start_char="3482">which</TOKEN>
<TOKEN end_char="3490" id="token-26-17" morph="none" pos="word" start_char="3488">are</TOKEN>
<TOKEN end_char="3497" id="token-26-18" morph="none" pos="word" start_char="3492">listed</TOKEN>
<TOKEN end_char="3502" id="token-26-19" morph="none" pos="word" start_char="3499">here</TOKEN>
<TOKEN end_char="3503" id="token-26-20" morph="none" pos="punct" start_char="3503">,</TOKEN>
<TOKEN end_char="3507" id="token-26-21" morph="none" pos="word" start_char="3505">and</TOKEN>
<TOKEN end_char="3517" id="token-26-22" morph="none" pos="word" start_char="3509">concluded</TOKEN>
<TOKEN end_char="3518" id="token-26-23" morph="none" pos="punct" start_char="3518">:</TOKEN>
</SEG>
<SEG end_char="3650" id="segment-27" start_char="3521">
<ORIGINAL_TEXT>"There are insufficient data for the Panel to recommend either for or against the use of ivermectin for the treatment of COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="3521" id="token-27-0" morph="none" pos="punct" start_char="3521">"</TOKEN>
<TOKEN end_char="3526" id="token-27-1" morph="none" pos="word" start_char="3522">There</TOKEN>
<TOKEN end_char="3530" id="token-27-2" morph="none" pos="word" start_char="3528">are</TOKEN>
<TOKEN end_char="3543" id="token-27-3" morph="none" pos="word" start_char="3532">insufficient</TOKEN>
<TOKEN end_char="3548" id="token-27-4" morph="none" pos="word" start_char="3545">data</TOKEN>
<TOKEN end_char="3552" id="token-27-5" morph="none" pos="word" start_char="3550">for</TOKEN>
<TOKEN end_char="3556" id="token-27-6" morph="none" pos="word" start_char="3554">the</TOKEN>
<TOKEN end_char="3562" id="token-27-7" morph="none" pos="word" start_char="3558">Panel</TOKEN>
<TOKEN end_char="3565" id="token-27-8" morph="none" pos="word" start_char="3564">to</TOKEN>
<TOKEN end_char="3575" id="token-27-9" morph="none" pos="word" start_char="3567">recommend</TOKEN>
<TOKEN end_char="3582" id="token-27-10" morph="none" pos="word" start_char="3577">either</TOKEN>
<TOKEN end_char="3586" id="token-27-11" morph="none" pos="word" start_char="3584">for</TOKEN>
<TOKEN end_char="3589" id="token-27-12" morph="none" pos="word" start_char="3588">or</TOKEN>
<TOKEN end_char="3597" id="token-27-13" morph="none" pos="word" start_char="3591">against</TOKEN>
<TOKEN end_char="3601" id="token-27-14" morph="none" pos="word" start_char="3599">the</TOKEN>
<TOKEN end_char="3605" id="token-27-15" morph="none" pos="word" start_char="3603">use</TOKEN>
<TOKEN end_char="3608" id="token-27-16" morph="none" pos="word" start_char="3607">of</TOKEN>
<TOKEN end_char="3619" id="token-27-17" morph="none" pos="word" start_char="3610">ivermectin</TOKEN>
<TOKEN end_char="3623" id="token-27-18" morph="none" pos="word" start_char="3621">for</TOKEN>
<TOKEN end_char="3627" id="token-27-19" morph="none" pos="word" start_char="3625">the</TOKEN>
<TOKEN end_char="3637" id="token-27-20" morph="none" pos="word" start_char="3629">treatment</TOKEN>
<TOKEN end_char="3640" id="token-27-21" morph="none" pos="word" start_char="3639">of</TOKEN>
<TOKEN end_char="3649" id="token-27-22" morph="none" pos="unknown" start_char="3642">COVID-19</TOKEN>
<TOKEN end_char="3650" id="token-27-23" morph="none" pos="punct" start_char="3650">.</TOKEN>
</SEG>
<SEG end_char="3851" id="segment-28" start_char="3652">
<ORIGINAL_TEXT>Results from adequately powered, well-designed, and well-conducted clinical trials are needed to provide more specific, evidence-based guidance on the role of ivermectin in the treatment of COVID-19."</ORIGINAL_TEXT>
<TOKEN end_char="3658" id="token-28-0" morph="none" pos="word" start_char="3652">Results</TOKEN>
<TOKEN end_char="3663" id="token-28-1" morph="none" pos="word" start_char="3660">from</TOKEN>
<TOKEN end_char="3674" id="token-28-2" morph="none" pos="word" start_char="3665">adequately</TOKEN>
<TOKEN end_char="3682" id="token-28-3" morph="none" pos="word" start_char="3676">powered</TOKEN>
<TOKEN end_char="3683" id="token-28-4" morph="none" pos="punct" start_char="3683">,</TOKEN>
<TOKEN end_char="3697" id="token-28-5" morph="none" pos="unknown" start_char="3685">well-designed</TOKEN>
<TOKEN end_char="3698" id="token-28-6" morph="none" pos="punct" start_char="3698">,</TOKEN>
<TOKEN end_char="3702" id="token-28-7" morph="none" pos="word" start_char="3700">and</TOKEN>
<TOKEN end_char="3717" id="token-28-8" morph="none" pos="unknown" start_char="3704">well-conducted</TOKEN>
<TOKEN end_char="3726" id="token-28-9" morph="none" pos="word" start_char="3719">clinical</TOKEN>
<TOKEN end_char="3733" id="token-28-10" morph="none" pos="word" start_char="3728">trials</TOKEN>
<TOKEN end_char="3737" id="token-28-11" morph="none" pos="word" start_char="3735">are</TOKEN>
<TOKEN end_char="3744" id="token-28-12" morph="none" pos="word" start_char="3739">needed</TOKEN>
<TOKEN end_char="3747" id="token-28-13" morph="none" pos="word" start_char="3746">to</TOKEN>
<TOKEN end_char="3755" id="token-28-14" morph="none" pos="word" start_char="3749">provide</TOKEN>
<TOKEN end_char="3760" id="token-28-15" morph="none" pos="word" start_char="3757">more</TOKEN>
<TOKEN end_char="3769" id="token-28-16" morph="none" pos="word" start_char="3762">specific</TOKEN>
<TOKEN end_char="3770" id="token-28-17" morph="none" pos="punct" start_char="3770">,</TOKEN>
<TOKEN end_char="3785" id="token-28-18" morph="none" pos="unknown" start_char="3772">evidence-based</TOKEN>
<TOKEN end_char="3794" id="token-28-19" morph="none" pos="word" start_char="3787">guidance</TOKEN>
<TOKEN end_char="3797" id="token-28-20" morph="none" pos="word" start_char="3796">on</TOKEN>
<TOKEN end_char="3801" id="token-28-21" morph="none" pos="word" start_char="3799">the</TOKEN>
<TOKEN end_char="3806" id="token-28-22" morph="none" pos="word" start_char="3803">role</TOKEN>
<TOKEN end_char="3809" id="token-28-23" morph="none" pos="word" start_char="3808">of</TOKEN>
<TOKEN end_char="3820" id="token-28-24" morph="none" pos="word" start_char="3811">ivermectin</TOKEN>
<TOKEN end_char="3823" id="token-28-25" morph="none" pos="word" start_char="3822">in</TOKEN>
<TOKEN end_char="3827" id="token-28-26" morph="none" pos="word" start_char="3825">the</TOKEN>
<TOKEN end_char="3837" id="token-28-27" morph="none" pos="word" start_char="3829">treatment</TOKEN>
<TOKEN end_char="3840" id="token-28-28" morph="none" pos="word" start_char="3839">of</TOKEN>
<TOKEN end_char="3849" id="token-28-29" morph="none" pos="unknown" start_char="3842">COVID-19</TOKEN>
<TOKEN end_char="3851" id="token-28-30" morph="none" pos="punct" start_char="3850">."</TOKEN>
</SEG>
<SEG end_char="3979" id="segment-29" start_char="3855">
<ORIGINAL_TEXT>Overall, clinical trials have thus far failed to provide reliable evidence supporting the use of ivermectin against COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="3861" id="token-29-0" morph="none" pos="word" start_char="3855">Overall</TOKEN>
<TOKEN end_char="3862" id="token-29-1" morph="none" pos="punct" start_char="3862">,</TOKEN>
<TOKEN end_char="3871" id="token-29-2" morph="none" pos="word" start_char="3864">clinical</TOKEN>
<TOKEN end_char="3878" id="token-29-3" morph="none" pos="word" start_char="3873">trials</TOKEN>
<TOKEN end_char="3883" id="token-29-4" morph="none" pos="word" start_char="3880">have</TOKEN>
<TOKEN end_char="3888" id="token-29-5" morph="none" pos="word" start_char="3885">thus</TOKEN>
<TOKEN end_char="3892" id="token-29-6" morph="none" pos="word" start_char="3890">far</TOKEN>
<TOKEN end_char="3899" id="token-29-7" morph="none" pos="word" start_char="3894">failed</TOKEN>
<TOKEN end_char="3902" id="token-29-8" morph="none" pos="word" start_char="3901">to</TOKEN>
<TOKEN end_char="3910" id="token-29-9" morph="none" pos="word" start_char="3904">provide</TOKEN>
<TOKEN end_char="3919" id="token-29-10" morph="none" pos="word" start_char="3912">reliable</TOKEN>
<TOKEN end_char="3928" id="token-29-11" morph="none" pos="word" start_char="3921">evidence</TOKEN>
<TOKEN end_char="3939" id="token-29-12" morph="none" pos="word" start_char="3930">supporting</TOKEN>
<TOKEN end_char="3943" id="token-29-13" morph="none" pos="word" start_char="3941">the</TOKEN>
<TOKEN end_char="3947" id="token-29-14" morph="none" pos="word" start_char="3945">use</TOKEN>
<TOKEN end_char="3950" id="token-29-15" morph="none" pos="word" start_char="3949">of</TOKEN>
<TOKEN end_char="3961" id="token-29-16" morph="none" pos="word" start_char="3952">ivermectin</TOKEN>
<TOKEN end_char="3969" id="token-29-17" morph="none" pos="word" start_char="3963">against</TOKEN>
<TOKEN end_char="3978" id="token-29-18" morph="none" pos="unknown" start_char="3971">COVID-19</TOKEN>
<TOKEN end_char="3979" id="token-29-19" morph="none" pos="punct" start_char="3979">.</TOKEN>
</SEG>
<SEG end_char="4071" id="segment-30" start_char="3981">
<ORIGINAL_TEXT>This is because the trials varied in terms of quality and many were at a high risk of bias.</ORIGINAL_TEXT>
<TOKEN end_char="3984" id="token-30-0" morph="none" pos="word" start_char="3981">This</TOKEN>
<TOKEN end_char="3987" id="token-30-1" morph="none" pos="word" start_char="3986">is</TOKEN>
<TOKEN end_char="3995" id="token-30-2" morph="none" pos="word" start_char="3989">because</TOKEN>
<TOKEN end_char="3999" id="token-30-3" morph="none" pos="word" start_char="3997">the</TOKEN>
<TOKEN end_char="4006" id="token-30-4" morph="none" pos="word" start_char="4001">trials</TOKEN>
<TOKEN end_char="4013" id="token-30-5" morph="none" pos="word" start_char="4008">varied</TOKEN>
<TOKEN end_char="4016" id="token-30-6" morph="none" pos="word" start_char="4015">in</TOKEN>
<TOKEN end_char="4022" id="token-30-7" morph="none" pos="word" start_char="4018">terms</TOKEN>
<TOKEN end_char="4025" id="token-30-8" morph="none" pos="word" start_char="4024">of</TOKEN>
<TOKEN end_char="4033" id="token-30-9" morph="none" pos="word" start_char="4027">quality</TOKEN>
<TOKEN end_char="4037" id="token-30-10" morph="none" pos="word" start_char="4035">and</TOKEN>
<TOKEN end_char="4042" id="token-30-11" morph="none" pos="word" start_char="4039">many</TOKEN>
<TOKEN end_char="4047" id="token-30-12" morph="none" pos="word" start_char="4044">were</TOKEN>
<TOKEN end_char="4050" id="token-30-13" morph="none" pos="word" start_char="4049">at</TOKEN>
<TOKEN end_char="4052" id="token-30-14" morph="none" pos="word" start_char="4052">a</TOKEN>
<TOKEN end_char="4057" id="token-30-15" morph="none" pos="word" start_char="4054">high</TOKEN>
<TOKEN end_char="4062" id="token-30-16" morph="none" pos="word" start_char="4059">risk</TOKEN>
<TOKEN end_char="4065" id="token-30-17" morph="none" pos="word" start_char="4064">of</TOKEN>
<TOKEN end_char="4070" id="token-30-18" morph="none" pos="word" start_char="4067">bias</TOKEN>
<TOKEN end_char="4071" id="token-30-19" morph="none" pos="punct" start_char="4071">.</TOKEN>
</SEG>
<SEG end_char="4175" id="segment-31" start_char="4073">
<ORIGINAL_TEXT>These limitations are the result of several factors, such as the trial design and the study population.</ORIGINAL_TEXT>
<TOKEN end_char="4077" id="token-31-0" morph="none" pos="word" start_char="4073">These</TOKEN>
<TOKEN end_char="4089" id="token-31-1" morph="none" pos="word" start_char="4079">limitations</TOKEN>
<TOKEN end_char="4093" id="token-31-2" morph="none" pos="word" start_char="4091">are</TOKEN>
<TOKEN end_char="4097" id="token-31-3" morph="none" pos="word" start_char="4095">the</TOKEN>
<TOKEN end_char="4104" id="token-31-4" morph="none" pos="word" start_char="4099">result</TOKEN>
<TOKEN end_char="4107" id="token-31-5" morph="none" pos="word" start_char="4106">of</TOKEN>
<TOKEN end_char="4115" id="token-31-6" morph="none" pos="word" start_char="4109">several</TOKEN>
<TOKEN end_char="4123" id="token-31-7" morph="none" pos="word" start_char="4117">factors</TOKEN>
<TOKEN end_char="4124" id="token-31-8" morph="none" pos="punct" start_char="4124">,</TOKEN>
<TOKEN end_char="4129" id="token-31-9" morph="none" pos="word" start_char="4126">such</TOKEN>
<TOKEN end_char="4132" id="token-31-10" morph="none" pos="word" start_char="4131">as</TOKEN>
<TOKEN end_char="4136" id="token-31-11" morph="none" pos="word" start_char="4134">the</TOKEN>
<TOKEN end_char="4142" id="token-31-12" morph="none" pos="word" start_char="4138">trial</TOKEN>
<TOKEN end_char="4149" id="token-31-13" morph="none" pos="word" start_char="4144">design</TOKEN>
<TOKEN end_char="4153" id="token-31-14" morph="none" pos="word" start_char="4151">and</TOKEN>
<TOKEN end_char="4157" id="token-31-15" morph="none" pos="word" start_char="4155">the</TOKEN>
<TOKEN end_char="4163" id="token-31-16" morph="none" pos="word" start_char="4159">study</TOKEN>
<TOKEN end_char="4174" id="token-31-17" morph="none" pos="word" start_char="4165">population</TOKEN>
<TOKEN end_char="4175" id="token-31-18" morph="none" pos="punct" start_char="4175">.</TOKEN>
</SEG>
<SEG end_char="4334" id="segment-32" start_char="4177">
<ORIGINAL_TEXT>And as scientists pointed out in this Health Feedback review, more rigorously designed studies found that ivermectin provided no benefit to COVID-19 patients.</ORIGINAL_TEXT>
<TOKEN end_char="4179" id="token-32-0" morph="none" pos="word" start_char="4177">And</TOKEN>
<TOKEN end_char="4182" id="token-32-1" morph="none" pos="word" start_char="4181">as</TOKEN>
<TOKEN end_char="4193" id="token-32-2" morph="none" pos="word" start_char="4184">scientists</TOKEN>
<TOKEN end_char="4201" id="token-32-3" morph="none" pos="word" start_char="4195">pointed</TOKEN>
<TOKEN end_char="4205" id="token-32-4" morph="none" pos="word" start_char="4203">out</TOKEN>
<TOKEN end_char="4208" id="token-32-5" morph="none" pos="word" start_char="4207">in</TOKEN>
<TOKEN end_char="4213" id="token-32-6" morph="none" pos="word" start_char="4210">this</TOKEN>
<TOKEN end_char="4220" id="token-32-7" morph="none" pos="word" start_char="4215">Health</TOKEN>
<TOKEN end_char="4229" id="token-32-8" morph="none" pos="word" start_char="4222">Feedback</TOKEN>
<TOKEN end_char="4236" id="token-32-9" morph="none" pos="word" start_char="4231">review</TOKEN>
<TOKEN end_char="4237" id="token-32-10" morph="none" pos="punct" start_char="4237">,</TOKEN>
<TOKEN end_char="4242" id="token-32-11" morph="none" pos="word" start_char="4239">more</TOKEN>
<TOKEN end_char="4253" id="token-32-12" morph="none" pos="word" start_char="4244">rigorously</TOKEN>
<TOKEN end_char="4262" id="token-32-13" morph="none" pos="word" start_char="4255">designed</TOKEN>
<TOKEN end_char="4270" id="token-32-14" morph="none" pos="word" start_char="4264">studies</TOKEN>
<TOKEN end_char="4276" id="token-32-15" morph="none" pos="word" start_char="4272">found</TOKEN>
<TOKEN end_char="4281" id="token-32-16" morph="none" pos="word" start_char="4278">that</TOKEN>
<TOKEN end_char="4292" id="token-32-17" morph="none" pos="word" start_char="4283">ivermectin</TOKEN>
<TOKEN end_char="4301" id="token-32-18" morph="none" pos="word" start_char="4294">provided</TOKEN>
<TOKEN end_char="4304" id="token-32-19" morph="none" pos="word" start_char="4303">no</TOKEN>
<TOKEN end_char="4312" id="token-32-20" morph="none" pos="word" start_char="4306">benefit</TOKEN>
<TOKEN end_char="4315" id="token-32-21" morph="none" pos="word" start_char="4314">to</TOKEN>
<TOKEN end_char="4324" id="token-32-22" morph="none" pos="unknown" start_char="4317">COVID-19</TOKEN>
<TOKEN end_char="4333" id="token-32-23" morph="none" pos="word" start_char="4326">patients</TOKEN>
<TOKEN end_char="4334" id="token-32-24" morph="none" pos="punct" start_char="4334">.</TOKEN>
</SEG>
<SEG end_char="4425" id="segment-33" start_char="4337">
<ORIGINAL_TEXT>Kelly cited physician Tess Lawrie when claiming that 51 studies showed ivermectin worked.</ORIGINAL_TEXT>
<TOKEN end_char="4341" id="token-33-0" morph="none" pos="word" start_char="4337">Kelly</TOKEN>
<TOKEN end_char="4347" id="token-33-1" morph="none" pos="word" start_char="4343">cited</TOKEN>
<TOKEN end_char="4357" id="token-33-2" morph="none" pos="word" start_char="4349">physician</TOKEN>
<TOKEN end_char="4362" id="token-33-3" morph="none" pos="word" start_char="4359">Tess</TOKEN>
<TOKEN end_char="4369" id="token-33-4" morph="none" pos="word" start_char="4364">Lawrie</TOKEN>
<TOKEN end_char="4374" id="token-33-5" morph="none" pos="word" start_char="4371">when</TOKEN>
<TOKEN end_char="4383" id="token-33-6" morph="none" pos="word" start_char="4376">claiming</TOKEN>
<TOKEN end_char="4388" id="token-33-7" morph="none" pos="word" start_char="4385">that</TOKEN>
<TOKEN end_char="4391" id="token-33-8" morph="none" pos="word" start_char="4390">51</TOKEN>
<TOKEN end_char="4399" id="token-33-9" morph="none" pos="word" start_char="4393">studies</TOKEN>
<TOKEN end_char="4406" id="token-33-10" morph="none" pos="word" start_char="4401">showed</TOKEN>
<TOKEN end_char="4417" id="token-33-11" morph="none" pos="word" start_char="4408">ivermectin</TOKEN>
<TOKEN end_char="4424" id="token-33-12" morph="none" pos="word" start_char="4419">worked</TOKEN>
<TOKEN end_char="4425" id="token-33-13" morph="none" pos="punct" start_char="4425">.</TOKEN>
</SEG>
<SEG end_char="4642" id="segment-34" start_char="4427">
<ORIGINAL_TEXT>While Lawrie and her colleagues published a meta-analysis of ivermectin studies, which itself was rife with problems as detailed in this Health Feedback review, that meta-analysis only examined fewer than 30 studies.</ORIGINAL_TEXT>
<TOKEN end_char="4431" id="token-34-0" morph="none" pos="word" start_char="4427">While</TOKEN>
<TOKEN end_char="4438" id="token-34-1" morph="none" pos="word" start_char="4433">Lawrie</TOKEN>
<TOKEN end_char="4442" id="token-34-2" morph="none" pos="word" start_char="4440">and</TOKEN>
<TOKEN end_char="4446" id="token-34-3" morph="none" pos="word" start_char="4444">her</TOKEN>
<TOKEN end_char="4457" id="token-34-4" morph="none" pos="word" start_char="4448">colleagues</TOKEN>
<TOKEN end_char="4467" id="token-34-5" morph="none" pos="word" start_char="4459">published</TOKEN>
<TOKEN end_char="4469" id="token-34-6" morph="none" pos="word" start_char="4469">a</TOKEN>
<TOKEN end_char="4483" id="token-34-7" morph="none" pos="unknown" start_char="4471">meta-analysis</TOKEN>
<TOKEN end_char="4486" id="token-34-8" morph="none" pos="word" start_char="4485">of</TOKEN>
<TOKEN end_char="4497" id="token-34-9" morph="none" pos="word" start_char="4488">ivermectin</TOKEN>
<TOKEN end_char="4505" id="token-34-10" morph="none" pos="word" start_char="4499">studies</TOKEN>
<TOKEN end_char="4506" id="token-34-11" morph="none" pos="punct" start_char="4506">,</TOKEN>
<TOKEN end_char="4512" id="token-34-12" morph="none" pos="word" start_char="4508">which</TOKEN>
<TOKEN end_char="4519" id="token-34-13" morph="none" pos="word" start_char="4514">itself</TOKEN>
<TOKEN end_char="4523" id="token-34-14" morph="none" pos="word" start_char="4521">was</TOKEN>
<TOKEN end_char="4528" id="token-34-15" morph="none" pos="word" start_char="4525">rife</TOKEN>
<TOKEN end_char="4533" id="token-34-16" morph="none" pos="word" start_char="4530">with</TOKEN>
<TOKEN end_char="4542" id="token-34-17" morph="none" pos="word" start_char="4535">problems</TOKEN>
<TOKEN end_char="4545" id="token-34-18" morph="none" pos="word" start_char="4544">as</TOKEN>
<TOKEN end_char="4554" id="token-34-19" morph="none" pos="word" start_char="4547">detailed</TOKEN>
<TOKEN end_char="4557" id="token-34-20" morph="none" pos="word" start_char="4556">in</TOKEN>
<TOKEN end_char="4562" id="token-34-21" morph="none" pos="word" start_char="4559">this</TOKEN>
<TOKEN end_char="4569" id="token-34-22" morph="none" pos="word" start_char="4564">Health</TOKEN>
<TOKEN end_char="4578" id="token-34-23" morph="none" pos="word" start_char="4571">Feedback</TOKEN>
<TOKEN end_char="4585" id="token-34-24" morph="none" pos="word" start_char="4580">review</TOKEN>
<TOKEN end_char="4586" id="token-34-25" morph="none" pos="punct" start_char="4586">,</TOKEN>
<TOKEN end_char="4591" id="token-34-26" morph="none" pos="word" start_char="4588">that</TOKEN>
<TOKEN end_char="4605" id="token-34-27" morph="none" pos="unknown" start_char="4593">meta-analysis</TOKEN>
<TOKEN end_char="4610" id="token-34-28" morph="none" pos="word" start_char="4607">only</TOKEN>
<TOKEN end_char="4619" id="token-34-29" morph="none" pos="word" start_char="4612">examined</TOKEN>
<TOKEN end_char="4625" id="token-34-30" morph="none" pos="word" start_char="4621">fewer</TOKEN>
<TOKEN end_char="4630" id="token-34-31" morph="none" pos="word" start_char="4627">than</TOKEN>
<TOKEN end_char="4633" id="token-34-32" morph="none" pos="word" start_char="4632">30</TOKEN>
<TOKEN end_char="4641" id="token-34-33" morph="none" pos="word" start_char="4635">studies</TOKEN>
<TOKEN end_char="4642" id="token-34-34" morph="none" pos="punct" start_char="4642">.</TOKEN>
</SEG>
<SEG end_char="4838" id="segment-35" start_char="4644">
<ORIGINAL_TEXT>Kelly may have instead been referencing the website run by a group named CovidAnalysis, which claimed that there have been 52 trials for ivermectin to date, a figure much more similar to Kelly’s.</ORIGINAL_TEXT>
<TOKEN end_char="4648" id="token-35-0" morph="none" pos="word" start_char="4644">Kelly</TOKEN>
<TOKEN end_char="4652" id="token-35-1" morph="none" pos="word" start_char="4650">may</TOKEN>
<TOKEN end_char="4657" id="token-35-2" morph="none" pos="word" start_char="4654">have</TOKEN>
<TOKEN end_char="4665" id="token-35-3" morph="none" pos="word" start_char="4659">instead</TOKEN>
<TOKEN end_char="4670" id="token-35-4" morph="none" pos="word" start_char="4667">been</TOKEN>
<TOKEN end_char="4682" id="token-35-5" morph="none" pos="word" start_char="4672">referencing</TOKEN>
<TOKEN end_char="4686" id="token-35-6" morph="none" pos="word" start_char="4684">the</TOKEN>
<TOKEN end_char="4694" id="token-35-7" morph="none" pos="word" start_char="4688">website</TOKEN>
<TOKEN end_char="4698" id="token-35-8" morph="none" pos="word" start_char="4696">run</TOKEN>
<TOKEN end_char="4701" id="token-35-9" morph="none" pos="word" start_char="4700">by</TOKEN>
<TOKEN end_char="4703" id="token-35-10" morph="none" pos="word" start_char="4703">a</TOKEN>
<TOKEN end_char="4709" id="token-35-11" morph="none" pos="word" start_char="4705">group</TOKEN>
<TOKEN end_char="4715" id="token-35-12" morph="none" pos="word" start_char="4711">named</TOKEN>
<TOKEN end_char="4729" id="token-35-13" morph="none" pos="word" start_char="4717">CovidAnalysis</TOKEN>
<TOKEN end_char="4730" id="token-35-14" morph="none" pos="punct" start_char="4730">,</TOKEN>
<TOKEN end_char="4736" id="token-35-15" morph="none" pos="word" start_char="4732">which</TOKEN>
<TOKEN end_char="4744" id="token-35-16" morph="none" pos="word" start_char="4738">claimed</TOKEN>
<TOKEN end_char="4749" id="token-35-17" morph="none" pos="word" start_char="4746">that</TOKEN>
<TOKEN end_char="4755" id="token-35-18" morph="none" pos="word" start_char="4751">there</TOKEN>
<TOKEN end_char="4760" id="token-35-19" morph="none" pos="word" start_char="4757">have</TOKEN>
<TOKEN end_char="4765" id="token-35-20" morph="none" pos="word" start_char="4762">been</TOKEN>
<TOKEN end_char="4768" id="token-35-21" morph="none" pos="word" start_char="4767">52</TOKEN>
<TOKEN end_char="4775" id="token-35-22" morph="none" pos="word" start_char="4770">trials</TOKEN>
<TOKEN end_char="4779" id="token-35-23" morph="none" pos="word" start_char="4777">for</TOKEN>
<TOKEN end_char="4790" id="token-35-24" morph="none" pos="word" start_char="4781">ivermectin</TOKEN>
<TOKEN end_char="4793" id="token-35-25" morph="none" pos="word" start_char="4792">to</TOKEN>
<TOKEN end_char="4798" id="token-35-26" morph="none" pos="word" start_char="4795">date</TOKEN>
<TOKEN end_char="4799" id="token-35-27" morph="none" pos="punct" start_char="4799">,</TOKEN>
<TOKEN end_char="4801" id="token-35-28" morph="none" pos="word" start_char="4801">a</TOKEN>
<TOKEN end_char="4808" id="token-35-29" morph="none" pos="word" start_char="4803">figure</TOKEN>
<TOKEN end_char="4813" id="token-35-30" morph="none" pos="word" start_char="4810">much</TOKEN>
<TOKEN end_char="4818" id="token-35-31" morph="none" pos="word" start_char="4815">more</TOKEN>
<TOKEN end_char="4826" id="token-35-32" morph="none" pos="word" start_char="4820">similar</TOKEN>
<TOKEN end_char="4829" id="token-35-33" morph="none" pos="word" start_char="4828">to</TOKEN>
<TOKEN end_char="4837" id="token-35-34" morph="none" pos="word" start_char="4831">Kelly’s</TOKEN>
<TOKEN end_char="4838" id="token-35-35" morph="none" pos="punct" start_char="4838">.</TOKEN>
</SEG>
<SEG end_char="4984" id="segment-36" start_char="4841">
<ORIGINAL_TEXT>CovidAnalysis conducted a meta-analysis of ivermectin studies and claimed that ivermectin works to treat and prevent (prophylaxis) for COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="4853" id="token-36-0" morph="none" pos="word" start_char="4841">CovidAnalysis</TOKEN>
<TOKEN end_char="4863" id="token-36-1" morph="none" pos="word" start_char="4855">conducted</TOKEN>
<TOKEN end_char="4865" id="token-36-2" morph="none" pos="word" start_char="4865">a</TOKEN>
<TOKEN end_char="4879" id="token-36-3" morph="none" pos="unknown" start_char="4867">meta-analysis</TOKEN>
<TOKEN end_char="4882" id="token-36-4" morph="none" pos="word" start_char="4881">of</TOKEN>
<TOKEN end_char="4893" id="token-36-5" morph="none" pos="word" start_char="4884">ivermectin</TOKEN>
<TOKEN end_char="4901" id="token-36-6" morph="none" pos="word" start_char="4895">studies</TOKEN>
<TOKEN end_char="4905" id="token-36-7" morph="none" pos="word" start_char="4903">and</TOKEN>
<TOKEN end_char="4913" id="token-36-8" morph="none" pos="word" start_char="4907">claimed</TOKEN>
<TOKEN end_char="4918" id="token-36-9" morph="none" pos="word" start_char="4915">that</TOKEN>
<TOKEN end_char="4929" id="token-36-10" morph="none" pos="word" start_char="4920">ivermectin</TOKEN>
<TOKEN end_char="4935" id="token-36-11" morph="none" pos="word" start_char="4931">works</TOKEN>
<TOKEN end_char="4938" id="token-36-12" morph="none" pos="word" start_char="4937">to</TOKEN>
<TOKEN end_char="4944" id="token-36-13" morph="none" pos="word" start_char="4940">treat</TOKEN>
<TOKEN end_char="4948" id="token-36-14" morph="none" pos="word" start_char="4946">and</TOKEN>
<TOKEN end_char="4956" id="token-36-15" morph="none" pos="word" start_char="4950">prevent</TOKEN>
<TOKEN end_char="4958" id="token-36-16" morph="none" pos="punct" start_char="4958">(</TOKEN>
<TOKEN end_char="4969" id="token-36-17" morph="none" pos="word" start_char="4959">prophylaxis</TOKEN>
<TOKEN end_char="4970" id="token-36-18" morph="none" pos="punct" start_char="4970">)</TOKEN>
<TOKEN end_char="4974" id="token-36-19" morph="none" pos="word" start_char="4972">for</TOKEN>
<TOKEN end_char="4983" id="token-36-20" morph="none" pos="unknown" start_char="4976">COVID-19</TOKEN>
<TOKEN end_char="4984" id="token-36-21" morph="none" pos="punct" start_char="4984">.</TOKEN>
</SEG>
<SEG end_char="5055" id="segment-37" start_char="4986">
<ORIGINAL_TEXT>However, its own analysis indicates that its conclusions aren’t sound.</ORIGINAL_TEXT>
<TOKEN end_char="4992" id="token-37-0" morph="none" pos="word" start_char="4986">However</TOKEN>
<TOKEN end_char="4993" id="token-37-1" morph="none" pos="punct" start_char="4993">,</TOKEN>
<TOKEN end_char="4997" id="token-37-2" morph="none" pos="word" start_char="4995">its</TOKEN>
<TOKEN end_char="5001" id="token-37-3" morph="none" pos="word" start_char="4999">own</TOKEN>
<TOKEN end_char="5010" id="token-37-4" morph="none" pos="word" start_char="5003">analysis</TOKEN>
<TOKEN end_char="5020" id="token-37-5" morph="none" pos="word" start_char="5012">indicates</TOKEN>
<TOKEN end_char="5025" id="token-37-6" morph="none" pos="word" start_char="5022">that</TOKEN>
<TOKEN end_char="5029" id="token-37-7" morph="none" pos="word" start_char="5027">its</TOKEN>
<TOKEN end_char="5041" id="token-37-8" morph="none" pos="word" start_char="5031">conclusions</TOKEN>
<TOKEN end_char="5048" id="token-37-9" morph="none" pos="word" start_char="5043">aren’t</TOKEN>
<TOKEN end_char="5054" id="token-37-10" morph="none" pos="word" start_char="5050">sound</TOKEN>
<TOKEN end_char="5055" id="token-37-11" morph="none" pos="punct" start_char="5055">.</TOKEN>
</SEG>
<SEG end_char="5136" id="segment-38" start_char="5058">
<ORIGINAL_TEXT>For example, one important measure to note in a meta-analysis is heterogeneity.</ORIGINAL_TEXT>
<TOKEN end_char="5060" id="token-38-0" morph="none" pos="word" start_char="5058">For</TOKEN>
<TOKEN end_char="5068" id="token-38-1" morph="none" pos="word" start_char="5062">example</TOKEN>
<TOKEN end_char="5069" id="token-38-2" morph="none" pos="punct" start_char="5069">,</TOKEN>
<TOKEN end_char="5073" id="token-38-3" morph="none" pos="word" start_char="5071">one</TOKEN>
<TOKEN end_char="5083" id="token-38-4" morph="none" pos="word" start_char="5075">important</TOKEN>
<TOKEN end_char="5091" id="token-38-5" morph="none" pos="word" start_char="5085">measure</TOKEN>
<TOKEN end_char="5094" id="token-38-6" morph="none" pos="word" start_char="5093">to</TOKEN>
<TOKEN end_char="5099" id="token-38-7" morph="none" pos="word" start_char="5096">note</TOKEN>
<TOKEN end_char="5102" id="token-38-8" morph="none" pos="word" start_char="5101">in</TOKEN>
<TOKEN end_char="5104" id="token-38-9" morph="none" pos="word" start_char="5104">a</TOKEN>
<TOKEN end_char="5118" id="token-38-10" morph="none" pos="unknown" start_char="5106">meta-analysis</TOKEN>
<TOKEN end_char="5121" id="token-38-11" morph="none" pos="word" start_char="5120">is</TOKEN>
<TOKEN end_char="5135" id="token-38-12" morph="none" pos="word" start_char="5123">heterogeneity</TOKEN>
<TOKEN end_char="5136" id="token-38-13" morph="none" pos="punct" start_char="5136">.</TOKEN>
</SEG>
<SEG end_char="5244" id="segment-39" start_char="5138">
<ORIGINAL_TEXT>This measure tells us whether the results of the studies in a meta-analysis are consistent with each other.</ORIGINAL_TEXT>
<TOKEN end_char="5141" id="token-39-0" morph="none" pos="word" start_char="5138">This</TOKEN>
<TOKEN end_char="5149" id="token-39-1" morph="none" pos="word" start_char="5143">measure</TOKEN>
<TOKEN end_char="5155" id="token-39-2" morph="none" pos="word" start_char="5151">tells</TOKEN>
<TOKEN end_char="5158" id="token-39-3" morph="none" pos="word" start_char="5157">us</TOKEN>
<TOKEN end_char="5166" id="token-39-4" morph="none" pos="word" start_char="5160">whether</TOKEN>
<TOKEN end_char="5170" id="token-39-5" morph="none" pos="word" start_char="5168">the</TOKEN>
<TOKEN end_char="5178" id="token-39-6" morph="none" pos="word" start_char="5172">results</TOKEN>
<TOKEN end_char="5181" id="token-39-7" morph="none" pos="word" start_char="5180">of</TOKEN>
<TOKEN end_char="5185" id="token-39-8" morph="none" pos="word" start_char="5183">the</TOKEN>
<TOKEN end_char="5193" id="token-39-9" morph="none" pos="word" start_char="5187">studies</TOKEN>
<TOKEN end_char="5196" id="token-39-10" morph="none" pos="word" start_char="5195">in</TOKEN>
<TOKEN end_char="5198" id="token-39-11" morph="none" pos="word" start_char="5198">a</TOKEN>
<TOKEN end_char="5212" id="token-39-12" morph="none" pos="unknown" start_char="5200">meta-analysis</TOKEN>
<TOKEN end_char="5216" id="token-39-13" morph="none" pos="word" start_char="5214">are</TOKEN>
<TOKEN end_char="5227" id="token-39-14" morph="none" pos="word" start_char="5218">consistent</TOKEN>
<TOKEN end_char="5232" id="token-39-15" morph="none" pos="word" start_char="5229">with</TOKEN>
<TOKEN end_char="5237" id="token-39-16" morph="none" pos="word" start_char="5234">each</TOKEN>
<TOKEN end_char="5243" id="token-39-17" morph="none" pos="word" start_char="5239">other</TOKEN>
<TOKEN end_char="5244" id="token-39-18" morph="none" pos="punct" start_char="5244">.</TOKEN>
</SEG>
<SEG end_char="5379" id="segment-40" start_char="5246">
<ORIGINAL_TEXT>Variability in results can arise from different factors, such as the study population and the way outcomes in the study were measured.</ORIGINAL_TEXT>
<TOKEN end_char="5256" id="token-40-0" morph="none" pos="word" start_char="5246">Variability</TOKEN>
<TOKEN end_char="5259" id="token-40-1" morph="none" pos="word" start_char="5258">in</TOKEN>
<TOKEN end_char="5267" id="token-40-2" morph="none" pos="word" start_char="5261">results</TOKEN>
<TOKEN end_char="5271" id="token-40-3" morph="none" pos="word" start_char="5269">can</TOKEN>
<TOKEN end_char="5277" id="token-40-4" morph="none" pos="word" start_char="5273">arise</TOKEN>
<TOKEN end_char="5282" id="token-40-5" morph="none" pos="word" start_char="5279">from</TOKEN>
<TOKEN end_char="5292" id="token-40-6" morph="none" pos="word" start_char="5284">different</TOKEN>
<TOKEN end_char="5300" id="token-40-7" morph="none" pos="word" start_char="5294">factors</TOKEN>
<TOKEN end_char="5301" id="token-40-8" morph="none" pos="punct" start_char="5301">,</TOKEN>
<TOKEN end_char="5306" id="token-40-9" morph="none" pos="word" start_char="5303">such</TOKEN>
<TOKEN end_char="5309" id="token-40-10" morph="none" pos="word" start_char="5308">as</TOKEN>
<TOKEN end_char="5313" id="token-40-11" morph="none" pos="word" start_char="5311">the</TOKEN>
<TOKEN end_char="5319" id="token-40-12" morph="none" pos="word" start_char="5315">study</TOKEN>
<TOKEN end_char="5330" id="token-40-13" morph="none" pos="word" start_char="5321">population</TOKEN>
<TOKEN end_char="5334" id="token-40-14" morph="none" pos="word" start_char="5332">and</TOKEN>
<TOKEN end_char="5338" id="token-40-15" morph="none" pos="word" start_char="5336">the</TOKEN>
<TOKEN end_char="5342" id="token-40-16" morph="none" pos="word" start_char="5340">way</TOKEN>
<TOKEN end_char="5351" id="token-40-17" morph="none" pos="word" start_char="5344">outcomes</TOKEN>
<TOKEN end_char="5354" id="token-40-18" morph="none" pos="word" start_char="5353">in</TOKEN>
<TOKEN end_char="5358" id="token-40-19" morph="none" pos="word" start_char="5356">the</TOKEN>
<TOKEN end_char="5364" id="token-40-20" morph="none" pos="word" start_char="5360">study</TOKEN>
<TOKEN end_char="5369" id="token-40-21" morph="none" pos="word" start_char="5366">were</TOKEN>
<TOKEN end_char="5378" id="token-40-22" morph="none" pos="word" start_char="5371">measured</TOKEN>
<TOKEN end_char="5379" id="token-40-23" morph="none" pos="punct" start_char="5379">.</TOKEN>
</SEG>
<SEG end_char="5422" id="segment-41" start_char="5381">
<ORIGINAL_TEXT>A common way to measure heterogeneity is I</ORIGINAL_TEXT>
<TOKEN end_char="5381" id="token-41-0" morph="none" pos="word" start_char="5381">A</TOKEN>
<TOKEN end_char="5388" id="token-41-1" morph="none" pos="word" start_char="5383">common</TOKEN>
<TOKEN end_char="5392" id="token-41-2" morph="none" pos="word" start_char="5390">way</TOKEN>
<TOKEN end_char="5395" id="token-41-3" morph="none" pos="word" start_char="5394">to</TOKEN>
<TOKEN end_char="5403" id="token-41-4" morph="none" pos="word" start_char="5397">measure</TOKEN>
<TOKEN end_char="5417" id="token-41-5" morph="none" pos="word" start_char="5405">heterogeneity</TOKEN>
<TOKEN end_char="5420" id="token-41-6" morph="none" pos="word" start_char="5419">is</TOKEN>
<TOKEN end_char="5422" id="token-41-7" morph="none" pos="word" start_char="5422">I</TOKEN>
</SEG>
<SEG end_char="5425" id="segment-42" start_char="5425">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN end_char="5425" id="token-42-0" morph="none" pos="word" start_char="5425">2</TOKEN>
</SEG>
<SEG end_char="5428" id="segment-43" start_char="5428">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="5428" id="token-43-0" morph="none" pos="punct" start_char="5428">.</TOKEN>
</SEG>
<SEG end_char="5750" id="segment-44" start_char="5431">
<ORIGINAL_TEXT>The Cochrane Network, a not-for-profit organization which conducts "systematic reviews and other synthesized research evidence", stated that "Meta-analysis should only be considered when a group of studies is sufficiently homogeneous in terms of participants, interventions and outcomes to provide a meaningful summary".</ORIGINAL_TEXT>
<TOKEN end_char="5433" id="token-44-0" morph="none" pos="word" start_char="5431">The</TOKEN>
<TOKEN end_char="5442" id="token-44-1" morph="none" pos="word" start_char="5435">Cochrane</TOKEN>
<TOKEN end_char="5450" id="token-44-2" morph="none" pos="word" start_char="5444">Network</TOKEN>
<TOKEN end_char="5451" id="token-44-3" morph="none" pos="punct" start_char="5451">,</TOKEN>
<TOKEN end_char="5453" id="token-44-4" morph="none" pos="word" start_char="5453">a</TOKEN>
<TOKEN end_char="5468" id="token-44-5" morph="none" pos="unknown" start_char="5455">not-for-profit</TOKEN>
<TOKEN end_char="5481" id="token-44-6" morph="none" pos="word" start_char="5470">organization</TOKEN>
<TOKEN end_char="5487" id="token-44-7" morph="none" pos="word" start_char="5483">which</TOKEN>
<TOKEN end_char="5496" id="token-44-8" morph="none" pos="word" start_char="5489">conducts</TOKEN>
<TOKEN end_char="5498" id="token-44-9" morph="none" pos="punct" start_char="5498">"</TOKEN>
<TOKEN end_char="5508" id="token-44-10" morph="none" pos="word" start_char="5499">systematic</TOKEN>
<TOKEN end_char="5516" id="token-44-11" morph="none" pos="word" start_char="5510">reviews</TOKEN>
<TOKEN end_char="5520" id="token-44-12" morph="none" pos="word" start_char="5518">and</TOKEN>
<TOKEN end_char="5526" id="token-44-13" morph="none" pos="word" start_char="5522">other</TOKEN>
<TOKEN end_char="5538" id="token-44-14" morph="none" pos="word" start_char="5528">synthesized</TOKEN>
<TOKEN end_char="5547" id="token-44-15" morph="none" pos="word" start_char="5540">research</TOKEN>
<TOKEN end_char="5556" id="token-44-16" morph="none" pos="word" start_char="5549">evidence</TOKEN>
<TOKEN end_char="5558" id="token-44-17" morph="none" pos="punct" start_char="5557">",</TOKEN>
<TOKEN end_char="5565" id="token-44-18" morph="none" pos="word" start_char="5560">stated</TOKEN>
<TOKEN end_char="5570" id="token-44-19" morph="none" pos="word" start_char="5567">that</TOKEN>
<TOKEN end_char="5572" id="token-44-20" morph="none" pos="punct" start_char="5572">"</TOKEN>
<TOKEN end_char="5585" id="token-44-21" morph="none" pos="unknown" start_char="5573">Meta-analysis</TOKEN>
<TOKEN end_char="5592" id="token-44-22" morph="none" pos="word" start_char="5587">should</TOKEN>
<TOKEN end_char="5597" id="token-44-23" morph="none" pos="word" start_char="5594">only</TOKEN>
<TOKEN end_char="5600" id="token-44-24" morph="none" pos="word" start_char="5599">be</TOKEN>
<TOKEN end_char="5611" id="token-44-25" morph="none" pos="word" start_char="5602">considered</TOKEN>
<TOKEN end_char="5616" id="token-44-26" morph="none" pos="word" start_char="5613">when</TOKEN>
<TOKEN end_char="5618" id="token-44-27" morph="none" pos="word" start_char="5618">a</TOKEN>
<TOKEN end_char="5624" id="token-44-28" morph="none" pos="word" start_char="5620">group</TOKEN>
<TOKEN end_char="5627" id="token-44-29" morph="none" pos="word" start_char="5626">of</TOKEN>
<TOKEN end_char="5635" id="token-44-30" morph="none" pos="word" start_char="5629">studies</TOKEN>
<TOKEN end_char="5638" id="token-44-31" morph="none" pos="word" start_char="5637">is</TOKEN>
<TOKEN end_char="5651" id="token-44-32" morph="none" pos="word" start_char="5640">sufficiently</TOKEN>
<TOKEN end_char="5663" id="token-44-33" morph="none" pos="word" start_char="5653">homogeneous</TOKEN>
<TOKEN end_char="5666" id="token-44-34" morph="none" pos="word" start_char="5665">in</TOKEN>
<TOKEN end_char="5672" id="token-44-35" morph="none" pos="word" start_char="5668">terms</TOKEN>
<TOKEN end_char="5675" id="token-44-36" morph="none" pos="word" start_char="5674">of</TOKEN>
<TOKEN end_char="5688" id="token-44-37" morph="none" pos="word" start_char="5677">participants</TOKEN>
<TOKEN end_char="5689" id="token-44-38" morph="none" pos="punct" start_char="5689">,</TOKEN>
<TOKEN end_char="5703" id="token-44-39" morph="none" pos="word" start_char="5691">interventions</TOKEN>
<TOKEN end_char="5707" id="token-44-40" morph="none" pos="word" start_char="5705">and</TOKEN>
<TOKEN end_char="5716" id="token-44-41" morph="none" pos="word" start_char="5709">outcomes</TOKEN>
<TOKEN end_char="5719" id="token-44-42" morph="none" pos="word" start_char="5718">to</TOKEN>
<TOKEN end_char="5727" id="token-44-43" morph="none" pos="word" start_char="5721">provide</TOKEN>
<TOKEN end_char="5729" id="token-44-44" morph="none" pos="word" start_char="5729">a</TOKEN>
<TOKEN end_char="5740" id="token-44-45" morph="none" pos="word" start_char="5731">meaningful</TOKEN>
<TOKEN end_char="5748" id="token-44-46" morph="none" pos="word" start_char="5742">summary</TOKEN>
<TOKEN end_char="5750" id="token-44-47" morph="none" pos="punct" start_char="5749">".</TOKEN>
</SEG>
<SEG end_char="5806" id="segment-45" start_char="5752">
<ORIGINAL_TEXT>It also provided a "rough guide to interpretation [of I</ORIGINAL_TEXT>
<TOKEN end_char="5753" id="token-45-0" morph="none" pos="word" start_char="5752">It</TOKEN>
<TOKEN end_char="5758" id="token-45-1" morph="none" pos="word" start_char="5755">also</TOKEN>
<TOKEN end_char="5767" id="token-45-2" morph="none" pos="word" start_char="5760">provided</TOKEN>
<TOKEN end_char="5769" id="token-45-3" morph="none" pos="word" start_char="5769">a</TOKEN>
<TOKEN end_char="5771" id="token-45-4" morph="none" pos="punct" start_char="5771">"</TOKEN>
<TOKEN end_char="5776" id="token-45-5" morph="none" pos="word" start_char="5772">rough</TOKEN>
<TOKEN end_char="5782" id="token-45-6" morph="none" pos="word" start_char="5778">guide</TOKEN>
<TOKEN end_char="5785" id="token-45-7" morph="none" pos="word" start_char="5784">to</TOKEN>
<TOKEN end_char="5800" id="token-45-8" morph="none" pos="word" start_char="5787">interpretation</TOKEN>
<TOKEN end_char="5802" id="token-45-9" morph="none" pos="punct" start_char="5802">[</TOKEN>
<TOKEN end_char="5804" id="token-45-10" morph="none" pos="word" start_char="5803">of</TOKEN>
<TOKEN end_char="5806" id="token-45-11" morph="none" pos="word" start_char="5806">I</TOKEN>
</SEG>
<SEG end_char="5809" id="segment-46" start_char="5809">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN end_char="5809" id="token-46-0" morph="none" pos="word" start_char="5809">2</TOKEN>
</SEG>
<SEG end_char="5867" id="segment-47" start_char="5812">
<ORIGINAL_TEXT>] in the context of meta-analyses of randomized trials":</ORIGINAL_TEXT>
<TOKEN end_char="5812" id="token-47-0" morph="none" pos="punct" start_char="5812">]</TOKEN>
<TOKEN end_char="5815" id="token-47-1" morph="none" pos="word" start_char="5814">in</TOKEN>
<TOKEN end_char="5819" id="token-47-2" morph="none" pos="word" start_char="5817">the</TOKEN>
<TOKEN end_char="5827" id="token-47-3" morph="none" pos="word" start_char="5821">context</TOKEN>
<TOKEN end_char="5830" id="token-47-4" morph="none" pos="word" start_char="5829">of</TOKEN>
<TOKEN end_char="5844" id="token-47-5" morph="none" pos="unknown" start_char="5832">meta-analyses</TOKEN>
<TOKEN end_char="5847" id="token-47-6" morph="none" pos="word" start_char="5846">of</TOKEN>
<TOKEN end_char="5858" id="token-47-7" morph="none" pos="word" start_char="5849">randomized</TOKEN>
<TOKEN end_char="5865" id="token-47-8" morph="none" pos="word" start_char="5860">trials</TOKEN>
<TOKEN end_char="5867" id="token-47-9" morph="none" pos="punct" start_char="5866">":</TOKEN>
</SEG>
<SEG end_char="5870" id="segment-48" start_char="5870">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN end_char="5870" id="token-48-0" morph="none" pos="punct" start_char="5870">"</TOKEN>
</SEG>
<SEG end_char="5906" id="segment-49" start_char="5873">
<ORIGINAL_TEXT>0% to 40%: might not be important;</ORIGINAL_TEXT>
<TOKEN end_char="5873" id="token-49-0" morph="none" pos="word" start_char="5873">0</TOKEN>
<TOKEN end_char="5874" id="token-49-1" morph="none" pos="punct" start_char="5874">%</TOKEN>
<TOKEN end_char="5877" id="token-49-2" morph="none" pos="word" start_char="5876">to</TOKEN>
<TOKEN end_char="5880" id="token-49-3" morph="none" pos="word" start_char="5879">40</TOKEN>
<TOKEN end_char="5882" id="token-49-4" morph="none" pos="punct" start_char="5881">%:</TOKEN>
<TOKEN end_char="5888" id="token-49-5" morph="none" pos="word" start_char="5884">might</TOKEN>
<TOKEN end_char="5892" id="token-49-6" morph="none" pos="word" start_char="5890">not</TOKEN>
<TOKEN end_char="5895" id="token-49-7" morph="none" pos="word" start_char="5894">be</TOKEN>
<TOKEN end_char="5905" id="token-49-8" morph="none" pos="word" start_char="5897">important</TOKEN>
<TOKEN end_char="5906" id="token-49-9" morph="none" pos="punct" start_char="5906">;</TOKEN>
</SEG>
<SEG end_char="5959" id="segment-50" start_char="5910">
<ORIGINAL_TEXT>30% to 60%: may represent moderate heterogeneity*;</ORIGINAL_TEXT>
<TOKEN end_char="5911" id="token-50-0" morph="none" pos="word" start_char="5910">30</TOKEN>
<TOKEN end_char="5912" id="token-50-1" morph="none" pos="punct" start_char="5912">%</TOKEN>
<TOKEN end_char="5915" id="token-50-2" morph="none" pos="word" start_char="5914">to</TOKEN>
<TOKEN end_char="5918" id="token-50-3" morph="none" pos="word" start_char="5917">60</TOKEN>
<TOKEN end_char="5920" id="token-50-4" morph="none" pos="punct" start_char="5919">%:</TOKEN>
<TOKEN end_char="5924" id="token-50-5" morph="none" pos="word" start_char="5922">may</TOKEN>
<TOKEN end_char="5934" id="token-50-6" morph="none" pos="word" start_char="5926">represent</TOKEN>
<TOKEN end_char="5943" id="token-50-7" morph="none" pos="word" start_char="5936">moderate</TOKEN>
<TOKEN end_char="5957" id="token-50-8" morph="none" pos="word" start_char="5945">heterogeneity</TOKEN>
<TOKEN end_char="5959" id="token-50-9" morph="none" pos="punct" start_char="5958">*;</TOKEN>
</SEG>
<SEG end_char="6015" id="segment-51" start_char="5963">
<ORIGINAL_TEXT>50% to 90%: may represent substantial heterogeneity*;</ORIGINAL_TEXT>
<TOKEN end_char="5964" id="token-51-0" morph="none" pos="word" start_char="5963">50</TOKEN>
<TOKEN end_char="5965" id="token-51-1" morph="none" pos="punct" start_char="5965">%</TOKEN>
<TOKEN end_char="5968" id="token-51-2" morph="none" pos="word" start_char="5967">to</TOKEN>
<TOKEN end_char="5971" id="token-51-3" morph="none" pos="word" start_char="5970">90</TOKEN>
<TOKEN end_char="5973" id="token-51-4" morph="none" pos="punct" start_char="5972">%:</TOKEN>
<TOKEN end_char="5977" id="token-51-5" morph="none" pos="word" start_char="5975">may</TOKEN>
<TOKEN end_char="5987" id="token-51-6" morph="none" pos="word" start_char="5979">represent</TOKEN>
<TOKEN end_char="5999" id="token-51-7" morph="none" pos="word" start_char="5989">substantial</TOKEN>
<TOKEN end_char="6013" id="token-51-8" morph="none" pos="word" start_char="6001">heterogeneity</TOKEN>
<TOKEN end_char="6015" id="token-51-9" morph="none" pos="punct" start_char="6014">*;</TOKEN>
</SEG>
<SEG end_char="6059" id="segment-52" start_char="6019">
<ORIGINAL_TEXT>75% to 100%: considerable heterogeneity*.</ORIGINAL_TEXT>
<TOKEN end_char="6020" id="token-52-0" morph="none" pos="word" start_char="6019">75</TOKEN>
<TOKEN end_char="6021" id="token-52-1" morph="none" pos="punct" start_char="6021">%</TOKEN>
<TOKEN end_char="6024" id="token-52-2" morph="none" pos="word" start_char="6023">to</TOKEN>
<TOKEN end_char="6028" id="token-52-3" morph="none" pos="word" start_char="6026">100</TOKEN>
<TOKEN end_char="6030" id="token-52-4" morph="none" pos="punct" start_char="6029">%:</TOKEN>
<TOKEN end_char="6043" id="token-52-5" morph="none" pos="word" start_char="6032">considerable</TOKEN>
<TOKEN end_char="6057" id="token-52-6" morph="none" pos="word" start_char="6045">heterogeneity</TOKEN>
<TOKEN end_char="6059" id="token-52-7" morph="none" pos="punct" start_char="6058">*.</TOKEN>
</SEG>
<SEG end_char="6104" id="segment-53" start_char="6063">
<ORIGINAL_TEXT>*The importance of the observed value of I</ORIGINAL_TEXT>
<TOKEN end_char="6063" id="token-53-0" morph="none" pos="punct" start_char="6063">*</TOKEN>
<TOKEN end_char="6066" id="token-53-1" morph="none" pos="word" start_char="6064">The</TOKEN>
<TOKEN end_char="6077" id="token-53-2" morph="none" pos="word" start_char="6068">importance</TOKEN>
<TOKEN end_char="6080" id="token-53-3" morph="none" pos="word" start_char="6079">of</TOKEN>
<TOKEN end_char="6084" id="token-53-4" morph="none" pos="word" start_char="6082">the</TOKEN>
<TOKEN end_char="6093" id="token-53-5" morph="none" pos="word" start_char="6086">observed</TOKEN>
<TOKEN end_char="6099" id="token-53-6" morph="none" pos="word" start_char="6095">value</TOKEN>
<TOKEN end_char="6102" id="token-53-7" morph="none" pos="word" start_char="6101">of</TOKEN>
<TOKEN end_char="6104" id="token-53-8" morph="none" pos="word" start_char="6104">I</TOKEN>
</SEG>
<SEG end_char="6107" id="segment-54" start_char="6107">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN end_char="6107" id="token-54-0" morph="none" pos="word" start_char="6107">2</TOKEN>
</SEG>
<SEG end_char="6233" id="segment-55" start_char="6110">
<ORIGINAL_TEXT>depends on (1) magnitude and direction of effects, and (2) strength of evidence for heterogeneity (e.g. P value from the Chi</ORIGINAL_TEXT>
<TOKEN end_char="6116" id="token-55-0" morph="none" pos="word" start_char="6110">depends</TOKEN>
<TOKEN end_char="6119" id="token-55-1" morph="none" pos="word" start_char="6118">on</TOKEN>
<TOKEN end_char="6121" id="token-55-2" morph="none" pos="punct" start_char="6121">(</TOKEN>
<TOKEN end_char="6122" id="token-55-3" morph="none" pos="word" start_char="6122">1</TOKEN>
<TOKEN end_char="6123" id="token-55-4" morph="none" pos="punct" start_char="6123">)</TOKEN>
<TOKEN end_char="6133" id="token-55-5" morph="none" pos="word" start_char="6125">magnitude</TOKEN>
<TOKEN end_char="6137" id="token-55-6" morph="none" pos="word" start_char="6135">and</TOKEN>
<TOKEN end_char="6147" id="token-55-7" morph="none" pos="word" start_char="6139">direction</TOKEN>
<TOKEN end_char="6150" id="token-55-8" morph="none" pos="word" start_char="6149">of</TOKEN>
<TOKEN end_char="6158" id="token-55-9" morph="none" pos="word" start_char="6152">effects</TOKEN>
<TOKEN end_char="6159" id="token-55-10" morph="none" pos="punct" start_char="6159">,</TOKEN>
<TOKEN end_char="6163" id="token-55-11" morph="none" pos="word" start_char="6161">and</TOKEN>
<TOKEN end_char="6165" id="token-55-12" morph="none" pos="punct" start_char="6165">(</TOKEN>
<TOKEN end_char="6166" id="token-55-13" morph="none" pos="word" start_char="6166">2</TOKEN>
<TOKEN end_char="6167" id="token-55-14" morph="none" pos="punct" start_char="6167">)</TOKEN>
<TOKEN end_char="6176" id="token-55-15" morph="none" pos="word" start_char="6169">strength</TOKEN>
<TOKEN end_char="6179" id="token-55-16" morph="none" pos="word" start_char="6178">of</TOKEN>
<TOKEN end_char="6188" id="token-55-17" morph="none" pos="word" start_char="6181">evidence</TOKEN>
<TOKEN end_char="6192" id="token-55-18" morph="none" pos="word" start_char="6190">for</TOKEN>
<TOKEN end_char="6206" id="token-55-19" morph="none" pos="word" start_char="6194">heterogeneity</TOKEN>
<TOKEN end_char="6208" id="token-55-20" morph="none" pos="punct" start_char="6208">(</TOKEN>
<TOKEN end_char="6211" id="token-55-21" morph="none" pos="unknown" start_char="6209">e.g</TOKEN>
<TOKEN end_char="6212" id="token-55-22" morph="none" pos="punct" start_char="6212">.</TOKEN>
<TOKEN end_char="6214" id="token-55-23" morph="none" pos="word" start_char="6214">P</TOKEN>
<TOKEN end_char="6220" id="token-55-24" morph="none" pos="word" start_char="6216">value</TOKEN>
<TOKEN end_char="6225" id="token-55-25" morph="none" pos="word" start_char="6222">from</TOKEN>
<TOKEN end_char="6229" id="token-55-26" morph="none" pos="word" start_char="6227">the</TOKEN>
<TOKEN end_char="6233" id="token-55-27" morph="none" pos="word" start_char="6231">Chi</TOKEN>
</SEG>
<SEG end_char="6236" id="segment-56" start_char="6236">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN end_char="6236" id="token-56-0" morph="none" pos="word" start_char="6236">2</TOKEN>
</SEG>
<SEG end_char="6274" id="segment-57" start_char="6239">
<ORIGINAL_TEXT>test, or a confidence interval for I</ORIGINAL_TEXT>
<TOKEN end_char="6242" id="token-57-0" morph="none" pos="word" start_char="6239">test</TOKEN>
<TOKEN end_char="6243" id="token-57-1" morph="none" pos="punct" start_char="6243">,</TOKEN>
<TOKEN end_char="6246" id="token-57-2" morph="none" pos="word" start_char="6245">or</TOKEN>
<TOKEN end_char="6248" id="token-57-3" morph="none" pos="word" start_char="6248">a</TOKEN>
<TOKEN end_char="6259" id="token-57-4" morph="none" pos="word" start_char="6250">confidence</TOKEN>
<TOKEN end_char="6268" id="token-57-5" morph="none" pos="word" start_char="6261">interval</TOKEN>
<TOKEN end_char="6272" id="token-57-6" morph="none" pos="word" start_char="6270">for</TOKEN>
<TOKEN end_char="6274" id="token-57-7" morph="none" pos="word" start_char="6274">I</TOKEN>
</SEG>
<SEG end_char="6277" id="segment-58" start_char="6277">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN end_char="6277" id="token-58-0" morph="none" pos="word" start_char="6277">2</TOKEN>
</SEG>
<SEG end_char="6310" id="segment-59" start_char="6280">
<ORIGINAL_TEXT>: uncertainty in the value of I</ORIGINAL_TEXT>
<TOKEN end_char="6280" id="token-59-0" morph="none" pos="punct" start_char="6280">:</TOKEN>
<TOKEN end_char="6292" id="token-59-1" morph="none" pos="word" start_char="6282">uncertainty</TOKEN>
<TOKEN end_char="6295" id="token-59-2" morph="none" pos="word" start_char="6294">in</TOKEN>
<TOKEN end_char="6299" id="token-59-3" morph="none" pos="word" start_char="6297">the</TOKEN>
<TOKEN end_char="6305" id="token-59-4" morph="none" pos="word" start_char="6301">value</TOKEN>
<TOKEN end_char="6308" id="token-59-5" morph="none" pos="word" start_char="6307">of</TOKEN>
<TOKEN end_char="6310" id="token-59-6" morph="none" pos="word" start_char="6310">I</TOKEN>
</SEG>
<SEG end_char="6313" id="segment-60" start_char="6313">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN end_char="6313" id="token-60-0" morph="none" pos="word" start_char="6313">2</TOKEN>
</SEG>
<SEG end_char="6367" id="segment-61" start_char="6316">
<ORIGINAL_TEXT>is substantial when the number of studies is small).</ORIGINAL_TEXT>
<TOKEN end_char="6317" id="token-61-0" morph="none" pos="word" start_char="6316">is</TOKEN>
<TOKEN end_char="6329" id="token-61-1" morph="none" pos="word" start_char="6319">substantial</TOKEN>
<TOKEN end_char="6334" id="token-61-2" morph="none" pos="word" start_char="6331">when</TOKEN>
<TOKEN end_char="6338" id="token-61-3" morph="none" pos="word" start_char="6336">the</TOKEN>
<TOKEN end_char="6345" id="token-61-4" morph="none" pos="word" start_char="6340">number</TOKEN>
<TOKEN end_char="6348" id="token-61-5" morph="none" pos="word" start_char="6347">of</TOKEN>
<TOKEN end_char="6356" id="token-61-6" morph="none" pos="word" start_char="6350">studies</TOKEN>
<TOKEN end_char="6359" id="token-61-7" morph="none" pos="word" start_char="6358">is</TOKEN>
<TOKEN end_char="6365" id="token-61-8" morph="none" pos="word" start_char="6361">small</TOKEN>
<TOKEN end_char="6367" id="token-61-9" morph="none" pos="punct" start_char="6366">).</TOKEN>
</SEG>
<SEG end_char="6370" id="segment-62" start_char="6370">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN end_char="6370" id="token-62-0" morph="none" pos="punct" start_char="6370">"</TOKEN>
</SEG>
<SEG end_char="6398" id="segment-63" start_char="6373">
<ORIGINAL_TEXT>In an article published by</ORIGINAL_TEXT>
<TOKEN end_char="6374" id="token-63-0" morph="none" pos="word" start_char="6373">In</TOKEN>
<TOKEN end_char="6377" id="token-63-1" morph="none" pos="word" start_char="6376">an</TOKEN>
<TOKEN end_char="6385" id="token-63-2" morph="none" pos="word" start_char="6379">article</TOKEN>
<TOKEN end_char="6395" id="token-63-3" morph="none" pos="word" start_char="6387">published</TOKEN>
<TOKEN end_char="6398" id="token-63-4" morph="none" pos="word" start_char="6397">by</TOKEN>
</SEG>
<SEG end_char="6403" id="segment-64" start_char="6401">
<ORIGINAL_TEXT>BMJ</ORIGINAL_TEXT>
<TOKEN end_char="6403" id="token-64-0" morph="none" pos="word" start_char="6401">BMJ</TOKEN>
</SEG>
<SEG end_char="6408" id="segment-65" start_char="6406">
<ORIGINAL_TEXT>[3]</ORIGINAL_TEXT>
<TOKEN end_char="6406" id="token-65-0" morph="none" pos="punct" start_char="6406">[</TOKEN>
<TOKEN end_char="6407" id="token-65-1" morph="none" pos="word" start_char="6407">3</TOKEN>
<TOKEN end_char="6408" id="token-65-2" morph="none" pos="punct" start_char="6408">]</TOKEN>
</SEG>
<SEG end_char="6419" id="segment-66" start_char="6411">
<ORIGINAL_TEXT>, Higgins</ORIGINAL_TEXT>
<TOKEN end_char="6411" id="token-66-0" morph="none" pos="punct" start_char="6411">,</TOKEN>
<TOKEN end_char="6419" id="token-66-1" morph="none" pos="word" start_char="6413">Higgins</TOKEN>
<TRANSLATED_TEXT>Higgins</TRANSLATED_TEXT><DETECTED_LANGUAGE>tl</DETECTED_LANGUAGE></SEG>
<SEG end_char="6427" id="segment-67" start_char="6422">
<ORIGINAL_TEXT>et al.</ORIGINAL_TEXT>
<TOKEN end_char="6423" id="token-67-0" morph="none" pos="word" start_char="6422">et</TOKEN>
<TOKEN end_char="6426" id="token-67-1" morph="none" pos="word" start_char="6425">al</TOKEN>
<TOKEN end_char="6427" id="token-67-2" morph="none" pos="punct" start_char="6427">.</TOKEN>
</SEG>
<SEG end_char="6439" id="segment-68" start_char="6430">
<ORIGINAL_TEXT>explained:</ORIGINAL_TEXT>
<TOKEN end_char="6438" id="token-68-0" morph="none" pos="word" start_char="6430">explained</TOKEN>
<TOKEN end_char="6439" id="token-68-1" morph="none" pos="punct" start_char="6439">:</TOKEN>
</SEG>
<SEG end_char="6442" id="segment-69" start_char="6442">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN end_char="6442" id="token-69-0" morph="none" pos="punct" start_char="6442">"</TOKEN>
</SEG>
<SEG end_char="6538" id="segment-70" start_char="6445">
<ORIGINAL_TEXT>Assessment of the consistency of effects across studies is an essential part of meta-analysis.</ORIGINAL_TEXT>
<TOKEN end_char="6454" id="token-70-0" morph="none" pos="word" start_char="6445">Assessment</TOKEN>
<TOKEN end_char="6457" id="token-70-1" morph="none" pos="word" start_char="6456">of</TOKEN>
<TOKEN end_char="6461" id="token-70-2" morph="none" pos="word" start_char="6459">the</TOKEN>
<TOKEN end_char="6473" id="token-70-3" morph="none" pos="word" start_char="6463">consistency</TOKEN>
<TOKEN end_char="6476" id="token-70-4" morph="none" pos="word" start_char="6475">of</TOKEN>
<TOKEN end_char="6484" id="token-70-5" morph="none" pos="word" start_char="6478">effects</TOKEN>
<TOKEN end_char="6491" id="token-70-6" morph="none" pos="word" start_char="6486">across</TOKEN>
<TOKEN end_char="6499" id="token-70-7" morph="none" pos="word" start_char="6493">studies</TOKEN>
<TOKEN end_char="6502" id="token-70-8" morph="none" pos="word" start_char="6501">is</TOKEN>
<TOKEN end_char="6505" id="token-70-9" morph="none" pos="word" start_char="6504">an</TOKEN>
<TOKEN end_char="6515" id="token-70-10" morph="none" pos="word" start_char="6507">essential</TOKEN>
<TOKEN end_char="6520" id="token-70-11" morph="none" pos="word" start_char="6517">part</TOKEN>
<TOKEN end_char="6523" id="token-70-12" morph="none" pos="word" start_char="6522">of</TOKEN>
<TOKEN end_char="6537" id="token-70-13" morph="none" pos="unknown" start_char="6525">meta-analysis</TOKEN>
<TOKEN end_char="6538" id="token-70-14" morph="none" pos="punct" start_char="6538">.</TOKEN>
</SEG>
<SEG end_char="6675" id="segment-71" start_char="6540">
<ORIGINAL_TEXT>Unless we know how consistent the results of studies are, we cannot determine the generalisability of the findings of the meta-analysis.</ORIGINAL_TEXT>
<TOKEN end_char="6545" id="token-71-0" morph="none" pos="word" start_char="6540">Unless</TOKEN>
<TOKEN end_char="6548" id="token-71-1" morph="none" pos="word" start_char="6547">we</TOKEN>
<TOKEN end_char="6553" id="token-71-2" morph="none" pos="word" start_char="6550">know</TOKEN>
<TOKEN end_char="6557" id="token-71-3" morph="none" pos="word" start_char="6555">how</TOKEN>
<TOKEN end_char="6568" id="token-71-4" morph="none" pos="word" start_char="6559">consistent</TOKEN>
<TOKEN end_char="6572" id="token-71-5" morph="none" pos="word" start_char="6570">the</TOKEN>
<TOKEN end_char="6580" id="token-71-6" morph="none" pos="word" start_char="6574">results</TOKEN>
<TOKEN end_char="6583" id="token-71-7" morph="none" pos="word" start_char="6582">of</TOKEN>
<TOKEN end_char="6591" id="token-71-8" morph="none" pos="word" start_char="6585">studies</TOKEN>
<TOKEN end_char="6595" id="token-71-9" morph="none" pos="word" start_char="6593">are</TOKEN>
<TOKEN end_char="6596" id="token-71-10" morph="none" pos="punct" start_char="6596">,</TOKEN>
<TOKEN end_char="6599" id="token-71-11" morph="none" pos="word" start_char="6598">we</TOKEN>
<TOKEN end_char="6606" id="token-71-12" morph="none" pos="word" start_char="6601">cannot</TOKEN>
<TOKEN end_char="6616" id="token-71-13" morph="none" pos="word" start_char="6608">determine</TOKEN>
<TOKEN end_char="6620" id="token-71-14" morph="none" pos="word" start_char="6618">the</TOKEN>
<TOKEN end_char="6637" id="token-71-15" morph="none" pos="word" start_char="6622">generalisability</TOKEN>
<TOKEN end_char="6640" id="token-71-16" morph="none" pos="word" start_char="6639">of</TOKEN>
<TOKEN end_char="6644" id="token-71-17" morph="none" pos="word" start_char="6642">the</TOKEN>
<TOKEN end_char="6653" id="token-71-18" morph="none" pos="word" start_char="6646">findings</TOKEN>
<TOKEN end_char="6656" id="token-71-19" morph="none" pos="word" start_char="6655">of</TOKEN>
<TOKEN end_char="6660" id="token-71-20" morph="none" pos="word" start_char="6658">the</TOKEN>
<TOKEN end_char="6674" id="token-71-21" morph="none" pos="unknown" start_char="6662">meta-analysis</TOKEN>
<TOKEN end_char="6675" id="token-71-22" morph="none" pos="punct" start_char="6675">.</TOKEN>
</SEG>
<SEG end_char="6678" id="segment-72" start_char="6678">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN end_char="6678" id="token-72-0" morph="none" pos="punct" start_char="6678">"</TOKEN>
</SEG>
<SEG end_char="6701" id="segment-73" start_char="6682">
<ORIGINAL_TEXT>Overall, the lower I</ORIGINAL_TEXT>
<TOKEN end_char="6688" id="token-73-0" morph="none" pos="word" start_char="6682">Overall</TOKEN>
<TOKEN end_char="6689" id="token-73-1" morph="none" pos="punct" start_char="6689">,</TOKEN>
<TOKEN end_char="6693" id="token-73-2" morph="none" pos="word" start_char="6691">the</TOKEN>
<TOKEN end_char="6699" id="token-73-3" morph="none" pos="word" start_char="6695">lower</TOKEN>
<TOKEN end_char="6701" id="token-73-4" morph="none" pos="word" start_char="6701">I</TOKEN>
</SEG>
<SEG end_char="6704" id="segment-74" start_char="6704">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN end_char="6704" id="token-74-0" morph="none" pos="word" start_char="6704">2</TOKEN>
</SEG>
<SEG end_char="6830" id="segment-75" start_char="6707">
<ORIGINAL_TEXT>is, the smaller the heterogeneity is, and the greater the confidence researchers can have in the reliability of the results.</ORIGINAL_TEXT>
<TOKEN end_char="6708" id="token-75-0" morph="none" pos="word" start_char="6707">is</TOKEN>
<TOKEN end_char="6709" id="token-75-1" morph="none" pos="punct" start_char="6709">,</TOKEN>
<TOKEN end_char="6713" id="token-75-2" morph="none" pos="word" start_char="6711">the</TOKEN>
<TOKEN end_char="6721" id="token-75-3" morph="none" pos="word" start_char="6715">smaller</TOKEN>
<TOKEN end_char="6725" id="token-75-4" morph="none" pos="word" start_char="6723">the</TOKEN>
<TOKEN end_char="6739" id="token-75-5" morph="none" pos="word" start_char="6727">heterogeneity</TOKEN>
<TOKEN end_char="6742" id="token-75-6" morph="none" pos="word" start_char="6741">is</TOKEN>
<TOKEN end_char="6743" id="token-75-7" morph="none" pos="punct" start_char="6743">,</TOKEN>
<TOKEN end_char="6747" id="token-75-8" morph="none" pos="word" start_char="6745">and</TOKEN>
<TOKEN end_char="6751" id="token-75-9" morph="none" pos="word" start_char="6749">the</TOKEN>
<TOKEN end_char="6759" id="token-75-10" morph="none" pos="word" start_char="6753">greater</TOKEN>
<TOKEN end_char="6763" id="token-75-11" morph="none" pos="word" start_char="6761">the</TOKEN>
<TOKEN end_char="6774" id="token-75-12" morph="none" pos="word" start_char="6765">confidence</TOKEN>
<TOKEN end_char="6786" id="token-75-13" morph="none" pos="word" start_char="6776">researchers</TOKEN>
<TOKEN end_char="6790" id="token-75-14" morph="none" pos="word" start_char="6788">can</TOKEN>
<TOKEN end_char="6795" id="token-75-15" morph="none" pos="word" start_char="6792">have</TOKEN>
<TOKEN end_char="6798" id="token-75-16" morph="none" pos="word" start_char="6797">in</TOKEN>
<TOKEN end_char="6802" id="token-75-17" morph="none" pos="word" start_char="6800">the</TOKEN>
<TOKEN end_char="6814" id="token-75-18" morph="none" pos="word" start_char="6804">reliability</TOKEN>
<TOKEN end_char="6817" id="token-75-19" morph="none" pos="word" start_char="6816">of</TOKEN>
<TOKEN end_char="6821" id="token-75-20" morph="none" pos="word" start_char="6819">the</TOKEN>
<TOKEN end_char="6829" id="token-75-21" morph="none" pos="word" start_char="6823">results</TOKEN>
<TOKEN end_char="6830" id="token-75-22" morph="none" pos="punct" start_char="6830">.</TOKEN>
</SEG>
<SEG end_char="6919" id="segment-76" start_char="6833">
<ORIGINAL_TEXT>Looking at CovidAnalysis’ ivermectin analysis (see figure below), we can see that the I</ORIGINAL_TEXT>
<TOKEN end_char="6839" id="token-76-0" morph="none" pos="word" start_char="6833">Looking</TOKEN>
<TOKEN end_char="6842" id="token-76-1" morph="none" pos="word" start_char="6841">at</TOKEN>
<TOKEN end_char="6856" id="token-76-2" morph="none" pos="word" start_char="6844">CovidAnalysis</TOKEN>
<TOKEN end_char="6857" id="token-76-3" morph="none" pos="punct" start_char="6857">’</TOKEN>
<TOKEN end_char="6868" id="token-76-4" morph="none" pos="word" start_char="6859">ivermectin</TOKEN>
<TOKEN end_char="6877" id="token-76-5" morph="none" pos="word" start_char="6870">analysis</TOKEN>
<TOKEN end_char="6879" id="token-76-6" morph="none" pos="punct" start_char="6879">(</TOKEN>
<TOKEN end_char="6882" id="token-76-7" morph="none" pos="word" start_char="6880">see</TOKEN>
<TOKEN end_char="6889" id="token-76-8" morph="none" pos="word" start_char="6884">figure</TOKEN>
<TOKEN end_char="6895" id="token-76-9" morph="none" pos="word" start_char="6891">below</TOKEN>
<TOKEN end_char="6897" id="token-76-10" morph="none" pos="punct" start_char="6896">),</TOKEN>
<TOKEN end_char="6900" id="token-76-11" morph="none" pos="word" start_char="6899">we</TOKEN>
<TOKEN end_char="6904" id="token-76-12" morph="none" pos="word" start_char="6902">can</TOKEN>
<TOKEN end_char="6908" id="token-76-13" morph="none" pos="word" start_char="6906">see</TOKEN>
<TOKEN end_char="6913" id="token-76-14" morph="none" pos="word" start_char="6910">that</TOKEN>
<TOKEN end_char="6917" id="token-76-15" morph="none" pos="word" start_char="6915">the</TOKEN>
<TOKEN end_char="6919" id="token-76-16" morph="none" pos="word" start_char="6919">I</TOKEN>
</SEG>
<SEG end_char="6922" id="segment-77" start_char="6922">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN end_char="6922" id="token-77-0" morph="none" pos="word" start_char="6922">2</TOKEN>
</SEG>
<SEG end_char="7039" id="segment-78" start_char="6925">
<ORIGINAL_TEXT>values reported for "early treatment", "late treatment", and "prophylaxis" are 85%, 65.6%, and 83.8%, respectively.</ORIGINAL_TEXT>
<TOKEN end_char="6930" id="token-78-0" morph="none" pos="word" start_char="6925">values</TOKEN>
<TOKEN end_char="6939" id="token-78-1" morph="none" pos="word" start_char="6932">reported</TOKEN>
<TOKEN end_char="6943" id="token-78-2" morph="none" pos="word" start_char="6941">for</TOKEN>
<TOKEN end_char="6945" id="token-78-3" morph="none" pos="punct" start_char="6945">"</TOKEN>
<TOKEN end_char="6950" id="token-78-4" morph="none" pos="word" start_char="6946">early</TOKEN>
<TOKEN end_char="6960" id="token-78-5" morph="none" pos="word" start_char="6952">treatment</TOKEN>
<TOKEN end_char="6962" id="token-78-6" morph="none" pos="punct" start_char="6961">",</TOKEN>
<TOKEN end_char="6964" id="token-78-7" morph="none" pos="punct" start_char="6964">"</TOKEN>
<TOKEN end_char="6968" id="token-78-8" morph="none" pos="word" start_char="6965">late</TOKEN>
<TOKEN end_char="6978" id="token-78-9" morph="none" pos="word" start_char="6970">treatment</TOKEN>
<TOKEN end_char="6980" id="token-78-10" morph="none" pos="punct" start_char="6979">",</TOKEN>
<TOKEN end_char="6984" id="token-78-11" morph="none" pos="word" start_char="6982">and</TOKEN>
<TOKEN end_char="6986" id="token-78-12" morph="none" pos="punct" start_char="6986">"</TOKEN>
<TOKEN end_char="6997" id="token-78-13" morph="none" pos="word" start_char="6987">prophylaxis</TOKEN>
<TOKEN end_char="6998" id="token-78-14" morph="none" pos="punct" start_char="6998">"</TOKEN>
<TOKEN end_char="7002" id="token-78-15" morph="none" pos="word" start_char="7000">are</TOKEN>
<TOKEN end_char="7005" id="token-78-16" morph="none" pos="word" start_char="7004">85</TOKEN>
<TOKEN end_char="7007" id="token-78-17" morph="none" pos="punct" start_char="7006">%,</TOKEN>
<TOKEN end_char="7012" id="token-78-18" morph="none" pos="unknown" start_char="7009">65.6</TOKEN>
<TOKEN end_char="7014" id="token-78-19" morph="none" pos="punct" start_char="7013">%,</TOKEN>
<TOKEN end_char="7018" id="token-78-20" morph="none" pos="word" start_char="7016">and</TOKEN>
<TOKEN end_char="7023" id="token-78-21" morph="none" pos="unknown" start_char="7020">83.8</TOKEN>
<TOKEN end_char="7025" id="token-78-22" morph="none" pos="punct" start_char="7024">%,</TOKEN>
<TOKEN end_char="7038" id="token-78-23" morph="none" pos="word" start_char="7027">respectively</TOKEN>
<TOKEN end_char="7039" id="token-78-24" morph="none" pos="punct" start_char="7039">.</TOKEN>
</SEG>
<SEG end_char="7173" id="segment-79" start_char="7041">
<ORIGINAL_TEXT>These values indicate that the results of the studies in the meta-analysis are very different from one another, or very heterogenous.</ORIGINAL_TEXT>
<TOKEN end_char="7045" id="token-79-0" morph="none" pos="word" start_char="7041">These</TOKEN>
<TOKEN end_char="7052" id="token-79-1" morph="none" pos="word" start_char="7047">values</TOKEN>
<TOKEN end_char="7061" id="token-79-2" morph="none" pos="word" start_char="7054">indicate</TOKEN>
<TOKEN end_char="7066" id="token-79-3" morph="none" pos="word" start_char="7063">that</TOKEN>
<TOKEN end_char="7070" id="token-79-4" morph="none" pos="word" start_char="7068">the</TOKEN>
<TOKEN end_char="7078" id="token-79-5" morph="none" pos="word" start_char="7072">results</TOKEN>
<TOKEN end_char="7081" id="token-79-6" morph="none" pos="word" start_char="7080">of</TOKEN>
<TOKEN end_char="7085" id="token-79-7" morph="none" pos="word" start_char="7083">the</TOKEN>
<TOKEN end_char="7093" id="token-79-8" morph="none" pos="word" start_char="7087">studies</TOKEN>
<TOKEN end_char="7096" id="token-79-9" morph="none" pos="word" start_char="7095">in</TOKEN>
<TOKEN end_char="7100" id="token-79-10" morph="none" pos="word" start_char="7098">the</TOKEN>
<TOKEN end_char="7114" id="token-79-11" morph="none" pos="unknown" start_char="7102">meta-analysis</TOKEN>
<TOKEN end_char="7118" id="token-79-12" morph="none" pos="word" start_char="7116">are</TOKEN>
<TOKEN end_char="7123" id="token-79-13" morph="none" pos="word" start_char="7120">very</TOKEN>
<TOKEN end_char="7133" id="token-79-14" morph="none" pos="word" start_char="7125">different</TOKEN>
<TOKEN end_char="7138" id="token-79-15" morph="none" pos="word" start_char="7135">from</TOKEN>
<TOKEN end_char="7142" id="token-79-16" morph="none" pos="word" start_char="7140">one</TOKEN>
<TOKEN end_char="7150" id="token-79-17" morph="none" pos="word" start_char="7144">another</TOKEN>
<TOKEN end_char="7151" id="token-79-18" morph="none" pos="punct" start_char="7151">,</TOKEN>
<TOKEN end_char="7154" id="token-79-19" morph="none" pos="word" start_char="7153">or</TOKEN>
<TOKEN end_char="7159" id="token-79-20" morph="none" pos="word" start_char="7156">very</TOKEN>
<TOKEN end_char="7172" id="token-79-21" morph="none" pos="word" start_char="7161">heterogenous</TOKEN>
<TOKEN end_char="7173" id="token-79-22" morph="none" pos="punct" start_char="7173">.</TOKEN>
</SEG>
<SEG end_char="7257" id="segment-80" start_char="7175">
<ORIGINAL_TEXT>As explained above, this reduces the reliability of the meta-analysis’ conclusions.</ORIGINAL_TEXT>
<TOKEN end_char="7176" id="token-80-0" morph="none" pos="word" start_char="7175">As</TOKEN>
<TOKEN end_char="7186" id="token-80-1" morph="none" pos="word" start_char="7178">explained</TOKEN>
<TOKEN end_char="7192" id="token-80-2" morph="none" pos="word" start_char="7188">above</TOKEN>
<TOKEN end_char="7193" id="token-80-3" morph="none" pos="punct" start_char="7193">,</TOKEN>
<TOKEN end_char="7198" id="token-80-4" morph="none" pos="word" start_char="7195">this</TOKEN>
<TOKEN end_char="7206" id="token-80-5" morph="none" pos="word" start_char="7200">reduces</TOKEN>
<TOKEN end_char="7210" id="token-80-6" morph="none" pos="word" start_char="7208">the</TOKEN>
<TOKEN end_char="7222" id="token-80-7" morph="none" pos="word" start_char="7212">reliability</TOKEN>
<TOKEN end_char="7225" id="token-80-8" morph="none" pos="word" start_char="7224">of</TOKEN>
<TOKEN end_char="7229" id="token-80-9" morph="none" pos="word" start_char="7227">the</TOKEN>
<TOKEN end_char="7243" id="token-80-10" morph="none" pos="unknown" start_char="7231">meta-analysis</TOKEN>
<TOKEN end_char="7244" id="token-80-11" morph="none" pos="punct" start_char="7244">’</TOKEN>
<TOKEN end_char="7256" id="token-80-12" morph="none" pos="word" start_char="7246">conclusions</TOKEN>
<TOKEN end_char="7257" id="token-80-13" morph="none" pos="punct" start_char="7257">.</TOKEN>
</SEG>
<SEG end_char="7268" id="segment-81" start_char="7260">
<ORIGINAL_TEXT>Figure 1.</ORIGINAL_TEXT>
<TOKEN end_char="7265" id="token-81-0" morph="none" pos="word" start_char="7260">Figure</TOKEN>
<TOKEN end_char="7267" id="token-81-1" morph="none" pos="word" start_char="7267">1</TOKEN>
<TOKEN end_char="7268" id="token-81-2" morph="none" pos="punct" start_char="7268">.</TOKEN>
<TRANSLATED_TEXT>Figura 1.</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="7382" id="segment-82" start_char="7270">
<ORIGINAL_TEXT>A forest plot showing the meta-analysis of ivermectin’s effect on different outcomes, conducted by CovidAnalysis.</ORIGINAL_TEXT>
<TOKEN end_char="7270" id="token-82-0" morph="none" pos="word" start_char="7270">A</TOKEN>
<TOKEN end_char="7277" id="token-82-1" morph="none" pos="word" start_char="7272">forest</TOKEN>
<TOKEN end_char="7282" id="token-82-2" morph="none" pos="word" start_char="7279">plot</TOKEN>
<TOKEN end_char="7290" id="token-82-3" morph="none" pos="word" start_char="7284">showing</TOKEN>
<TOKEN end_char="7294" id="token-82-4" morph="none" pos="word" start_char="7292">the</TOKEN>
<TOKEN end_char="7308" id="token-82-5" morph="none" pos="unknown" start_char="7296">meta-analysis</TOKEN>
<TOKEN end_char="7311" id="token-82-6" morph="none" pos="word" start_char="7310">of</TOKEN>
<TOKEN end_char="7324" id="token-82-7" morph="none" pos="word" start_char="7313">ivermectin’s</TOKEN>
<TOKEN end_char="7331" id="token-82-8" morph="none" pos="word" start_char="7326">effect</TOKEN>
<TOKEN end_char="7334" id="token-82-9" morph="none" pos="word" start_char="7333">on</TOKEN>
<TOKEN end_char="7344" id="token-82-10" morph="none" pos="word" start_char="7336">different</TOKEN>
<TOKEN end_char="7353" id="token-82-11" morph="none" pos="word" start_char="7346">outcomes</TOKEN>
<TOKEN end_char="7354" id="token-82-12" morph="none" pos="punct" start_char="7354">,</TOKEN>
<TOKEN end_char="7364" id="token-82-13" morph="none" pos="word" start_char="7356">conducted</TOKEN>
<TOKEN end_char="7367" id="token-82-14" morph="none" pos="word" start_char="7366">by</TOKEN>
<TOKEN end_char="7381" id="token-82-15" morph="none" pos="word" start_char="7369">CovidAnalysis</TOKEN>
<TOKEN end_char="7382" id="token-82-16" morph="none" pos="punct" start_char="7382">.</TOKEN>
</SEG>
<SEG end_char="7613" id="segment-83" start_char="7386">
<ORIGINAL_TEXT>Yet at no point did CovidAnalysis acknowledge the limitations in its analysis or express any uncertainty about its conclusions, misleading readers into believing that there is already reliable evidence for ivermectin’s efficacy.</ORIGINAL_TEXT>
<TOKEN end_char="7388" id="token-83-0" morph="none" pos="word" start_char="7386">Yet</TOKEN>
<TOKEN end_char="7391" id="token-83-1" morph="none" pos="word" start_char="7390">at</TOKEN>
<TOKEN end_char="7394" id="token-83-2" morph="none" pos="word" start_char="7393">no</TOKEN>
<TOKEN end_char="7400" id="token-83-3" morph="none" pos="word" start_char="7396">point</TOKEN>
<TOKEN end_char="7404" id="token-83-4" morph="none" pos="word" start_char="7402">did</TOKEN>
<TOKEN end_char="7418" id="token-83-5" morph="none" pos="word" start_char="7406">CovidAnalysis</TOKEN>
<TOKEN end_char="7430" id="token-83-6" morph="none" pos="word" start_char="7420">acknowledge</TOKEN>
<TOKEN end_char="7434" id="token-83-7" morph="none" pos="word" start_char="7432">the</TOKEN>
<TOKEN end_char="7446" id="token-83-8" morph="none" pos="word" start_char="7436">limitations</TOKEN>
<TOKEN end_char="7449" id="token-83-9" morph="none" pos="word" start_char="7448">in</TOKEN>
<TOKEN end_char="7453" id="token-83-10" morph="none" pos="word" start_char="7451">its</TOKEN>
<TOKEN end_char="7462" id="token-83-11" morph="none" pos="word" start_char="7455">analysis</TOKEN>
<TOKEN end_char="7465" id="token-83-12" morph="none" pos="word" start_char="7464">or</TOKEN>
<TOKEN end_char="7473" id="token-83-13" morph="none" pos="word" start_char="7467">express</TOKEN>
<TOKEN end_char="7477" id="token-83-14" morph="none" pos="word" start_char="7475">any</TOKEN>
<TOKEN end_char="7489" id="token-83-15" morph="none" pos="word" start_char="7479">uncertainty</TOKEN>
<TOKEN end_char="7495" id="token-83-16" morph="none" pos="word" start_char="7491">about</TOKEN>
<TOKEN end_char="7499" id="token-83-17" morph="none" pos="word" start_char="7497">its</TOKEN>
<TOKEN end_char="7511" id="token-83-18" morph="none" pos="word" start_char="7501">conclusions</TOKEN>
<TOKEN end_char="7512" id="token-83-19" morph="none" pos="punct" start_char="7512">,</TOKEN>
<TOKEN end_char="7523" id="token-83-20" morph="none" pos="word" start_char="7514">misleading</TOKEN>
<TOKEN end_char="7531" id="token-83-21" morph="none" pos="word" start_char="7525">readers</TOKEN>
<TOKEN end_char="7536" id="token-83-22" morph="none" pos="word" start_char="7533">into</TOKEN>
<TOKEN end_char="7546" id="token-83-23" morph="none" pos="word" start_char="7538">believing</TOKEN>
<TOKEN end_char="7551" id="token-83-24" morph="none" pos="word" start_char="7548">that</TOKEN>
<TOKEN end_char="7557" id="token-83-25" morph="none" pos="word" start_char="7553">there</TOKEN>
<TOKEN end_char="7560" id="token-83-26" morph="none" pos="word" start_char="7559">is</TOKEN>
<TOKEN end_char="7568" id="token-83-27" morph="none" pos="word" start_char="7562">already</TOKEN>
<TOKEN end_char="7577" id="token-83-28" morph="none" pos="word" start_char="7570">reliable</TOKEN>
<TOKEN end_char="7586" id="token-83-29" morph="none" pos="word" start_char="7579">evidence</TOKEN>
<TOKEN end_char="7590" id="token-83-30" morph="none" pos="word" start_char="7588">for</TOKEN>
<TOKEN end_char="7603" id="token-83-31" morph="none" pos="word" start_char="7592">ivermectin’s</TOKEN>
<TOKEN end_char="7612" id="token-83-32" morph="none" pos="word" start_char="7605">efficacy</TOKEN>
<TOKEN end_char="7613" id="token-83-33" morph="none" pos="punct" start_char="7613">.</TOKEN>
</SEG>
<SEG end_char="7753" id="segment-84" start_char="7615">
<ORIGINAL_TEXT>This behavior is consistent with its earlier, misleading "analysis" purporting to show that hydroxychloroquine effectively treats COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="7618" id="token-84-0" morph="none" pos="word" start_char="7615">This</TOKEN>
<TOKEN end_char="7627" id="token-84-1" morph="none" pos="word" start_char="7620">behavior</TOKEN>
<TOKEN end_char="7630" id="token-84-2" morph="none" pos="word" start_char="7629">is</TOKEN>
<TOKEN end_char="7641" id="token-84-3" morph="none" pos="word" start_char="7632">consistent</TOKEN>
<TOKEN end_char="7646" id="token-84-4" morph="none" pos="word" start_char="7643">with</TOKEN>
<TOKEN end_char="7650" id="token-84-5" morph="none" pos="word" start_char="7648">its</TOKEN>
<TOKEN end_char="7658" id="token-84-6" morph="none" pos="word" start_char="7652">earlier</TOKEN>
<TOKEN end_char="7659" id="token-84-7" morph="none" pos="punct" start_char="7659">,</TOKEN>
<TOKEN end_char="7670" id="token-84-8" morph="none" pos="word" start_char="7661">misleading</TOKEN>
<TOKEN end_char="7672" id="token-84-9" morph="none" pos="punct" start_char="7672">"</TOKEN>
<TOKEN end_char="7680" id="token-84-10" morph="none" pos="word" start_char="7673">analysis</TOKEN>
<TOKEN end_char="7681" id="token-84-11" morph="none" pos="punct" start_char="7681">"</TOKEN>
<TOKEN end_char="7692" id="token-84-12" morph="none" pos="word" start_char="7683">purporting</TOKEN>
<TOKEN end_char="7695" id="token-84-13" morph="none" pos="word" start_char="7694">to</TOKEN>
<TOKEN end_char="7700" id="token-84-14" morph="none" pos="word" start_char="7697">show</TOKEN>
<TOKEN end_char="7705" id="token-84-15" morph="none" pos="word" start_char="7702">that</TOKEN>
<TOKEN end_char="7724" id="token-84-16" morph="none" pos="word" start_char="7707">hydroxychloroquine</TOKEN>
<TOKEN end_char="7736" id="token-84-17" morph="none" pos="word" start_char="7726">effectively</TOKEN>
<TOKEN end_char="7743" id="token-84-18" morph="none" pos="word" start_char="7738">treats</TOKEN>
<TOKEN end_char="7752" id="token-84-19" morph="none" pos="unknown" start_char="7745">COVID-19</TOKEN>
<TOKEN end_char="7753" id="token-84-20" morph="none" pos="punct" start_char="7753">.</TOKEN>
</SEG>
<SEG end_char="7939" id="segment-85" start_char="7756">
<ORIGINAL_TEXT>Indeed, by examining the details of each study provided in Figure 6, we can see details of how the studies differed from each other, which can suggest how the heterogeneity came about.</ORIGINAL_TEXT>
<TOKEN end_char="7761" id="token-85-0" morph="none" pos="word" start_char="7756">Indeed</TOKEN>
<TOKEN end_char="7762" id="token-85-1" morph="none" pos="punct" start_char="7762">,</TOKEN>
<TOKEN end_char="7765" id="token-85-2" morph="none" pos="word" start_char="7764">by</TOKEN>
<TOKEN end_char="7775" id="token-85-3" morph="none" pos="word" start_char="7767">examining</TOKEN>
<TOKEN end_char="7779" id="token-85-4" morph="none" pos="word" start_char="7777">the</TOKEN>
<TOKEN end_char="7787" id="token-85-5" morph="none" pos="word" start_char="7781">details</TOKEN>
<TOKEN end_char="7790" id="token-85-6" morph="none" pos="word" start_char="7789">of</TOKEN>
<TOKEN end_char="7795" id="token-85-7" morph="none" pos="word" start_char="7792">each</TOKEN>
<TOKEN end_char="7801" id="token-85-8" morph="none" pos="word" start_char="7797">study</TOKEN>
<TOKEN end_char="7810" id="token-85-9" morph="none" pos="word" start_char="7803">provided</TOKEN>
<TOKEN end_char="7813" id="token-85-10" morph="none" pos="word" start_char="7812">in</TOKEN>
<TOKEN end_char="7820" id="token-85-11" morph="none" pos="word" start_char="7815">Figure</TOKEN>
<TOKEN end_char="7822" id="token-85-12" morph="none" pos="word" start_char="7822">6</TOKEN>
<TOKEN end_char="7823" id="token-85-13" morph="none" pos="punct" start_char="7823">,</TOKEN>
<TOKEN end_char="7826" id="token-85-14" morph="none" pos="word" start_char="7825">we</TOKEN>
<TOKEN end_char="7830" id="token-85-15" morph="none" pos="word" start_char="7828">can</TOKEN>
<TOKEN end_char="7834" id="token-85-16" morph="none" pos="word" start_char="7832">see</TOKEN>
<TOKEN end_char="7842" id="token-85-17" morph="none" pos="word" start_char="7836">details</TOKEN>
<TOKEN end_char="7845" id="token-85-18" morph="none" pos="word" start_char="7844">of</TOKEN>
<TOKEN end_char="7849" id="token-85-19" morph="none" pos="word" start_char="7847">how</TOKEN>
<TOKEN end_char="7853" id="token-85-20" morph="none" pos="word" start_char="7851">the</TOKEN>
<TOKEN end_char="7861" id="token-85-21" morph="none" pos="word" start_char="7855">studies</TOKEN>
<TOKEN end_char="7870" id="token-85-22" morph="none" pos="word" start_char="7863">differed</TOKEN>
<TOKEN end_char="7875" id="token-85-23" morph="none" pos="word" start_char="7872">from</TOKEN>
<TOKEN end_char="7880" id="token-85-24" morph="none" pos="word" start_char="7877">each</TOKEN>
<TOKEN end_char="7886" id="token-85-25" morph="none" pos="word" start_char="7882">other</TOKEN>
<TOKEN end_char="7887" id="token-85-26" morph="none" pos="punct" start_char="7887">,</TOKEN>
<TOKEN end_char="7893" id="token-85-27" morph="none" pos="word" start_char="7889">which</TOKEN>
<TOKEN end_char="7897" id="token-85-28" morph="none" pos="word" start_char="7895">can</TOKEN>
<TOKEN end_char="7905" id="token-85-29" morph="none" pos="word" start_char="7899">suggest</TOKEN>
<TOKEN end_char="7909" id="token-85-30" morph="none" pos="word" start_char="7907">how</TOKEN>
<TOKEN end_char="7913" id="token-85-31" morph="none" pos="word" start_char="7911">the</TOKEN>
<TOKEN end_char="7927" id="token-85-32" morph="none" pos="word" start_char="7915">heterogeneity</TOKEN>
<TOKEN end_char="7932" id="token-85-33" morph="none" pos="word" start_char="7929">came</TOKEN>
<TOKEN end_char="7938" id="token-85-34" morph="none" pos="word" start_char="7934">about</TOKEN>
<TOKEN end_char="7939" id="token-85-35" morph="none" pos="punct" start_char="7939">.</TOKEN>
</SEG>
<SEG end_char="8045" id="segment-86" start_char="7942">
<ORIGINAL_TEXT>For example, 12 of the 52 ivermectin studies involved combined treatment of ivermectin with other drugs.</ORIGINAL_TEXT>
<TOKEN end_char="7944" id="token-86-0" morph="none" pos="word" start_char="7942">For</TOKEN>
<TOKEN end_char="7952" id="token-86-1" morph="none" pos="word" start_char="7946">example</TOKEN>
<TOKEN end_char="7953" id="token-86-2" morph="none" pos="punct" start_char="7953">,</TOKEN>
<TOKEN end_char="7956" id="token-86-3" morph="none" pos="word" start_char="7955">12</TOKEN>
<TOKEN end_char="7959" id="token-86-4" morph="none" pos="word" start_char="7958">of</TOKEN>
<TOKEN end_char="7963" id="token-86-5" morph="none" pos="word" start_char="7961">the</TOKEN>
<TOKEN end_char="7966" id="token-86-6" morph="none" pos="word" start_char="7965">52</TOKEN>
<TOKEN end_char="7977" id="token-86-7" morph="none" pos="word" start_char="7968">ivermectin</TOKEN>
<TOKEN end_char="7985" id="token-86-8" morph="none" pos="word" start_char="7979">studies</TOKEN>
<TOKEN end_char="7994" id="token-86-9" morph="none" pos="word" start_char="7987">involved</TOKEN>
<TOKEN end_char="8003" id="token-86-10" morph="none" pos="word" start_char="7996">combined</TOKEN>
<TOKEN end_char="8013" id="token-86-11" morph="none" pos="word" start_char="8005">treatment</TOKEN>
<TOKEN end_char="8016" id="token-86-12" morph="none" pos="word" start_char="8015">of</TOKEN>
<TOKEN end_char="8027" id="token-86-13" morph="none" pos="word" start_char="8018">ivermectin</TOKEN>
<TOKEN end_char="8032" id="token-86-14" morph="none" pos="word" start_char="8029">with</TOKEN>
<TOKEN end_char="8038" id="token-86-15" morph="none" pos="word" start_char="8034">other</TOKEN>
<TOKEN end_char="8044" id="token-86-16" morph="none" pos="word" start_char="8040">drugs</TOKEN>
<TOKEN end_char="8045" id="token-86-17" morph="none" pos="punct" start_char="8045">.</TOKEN>
</SEG>
<SEG end_char="8141" id="segment-87" start_char="8047">
<ORIGINAL_TEXT>This means that the effects observed in these studies cannot be attributed to ivermectin alone.</ORIGINAL_TEXT>
<TOKEN end_char="8050" id="token-87-0" morph="none" pos="word" start_char="8047">This</TOKEN>
<TOKEN end_char="8056" id="token-87-1" morph="none" pos="word" start_char="8052">means</TOKEN>
<TOKEN end_char="8061" id="token-87-2" morph="none" pos="word" start_char="8058">that</TOKEN>
<TOKEN end_char="8065" id="token-87-3" morph="none" pos="word" start_char="8063">the</TOKEN>
<TOKEN end_char="8073" id="token-87-4" morph="none" pos="word" start_char="8067">effects</TOKEN>
<TOKEN end_char="8082" id="token-87-5" morph="none" pos="word" start_char="8075">observed</TOKEN>
<TOKEN end_char="8085" id="token-87-6" morph="none" pos="word" start_char="8084">in</TOKEN>
<TOKEN end_char="8091" id="token-87-7" morph="none" pos="word" start_char="8087">these</TOKEN>
<TOKEN end_char="8099" id="token-87-8" morph="none" pos="word" start_char="8093">studies</TOKEN>
<TOKEN end_char="8106" id="token-87-9" morph="none" pos="word" start_char="8101">cannot</TOKEN>
<TOKEN end_char="8109" id="token-87-10" morph="none" pos="word" start_char="8108">be</TOKEN>
<TOKEN end_char="8120" id="token-87-11" morph="none" pos="word" start_char="8111">attributed</TOKEN>
<TOKEN end_char="8123" id="token-87-12" morph="none" pos="word" start_char="8122">to</TOKEN>
<TOKEN end_char="8134" id="token-87-13" morph="none" pos="word" start_char="8125">ivermectin</TOKEN>
<TOKEN end_char="8140" id="token-87-14" morph="none" pos="word" start_char="8136">alone</TOKEN>
<TOKEN end_char="8141" id="token-87-15" morph="none" pos="punct" start_char="8141">.</TOKEN>
</SEG>
<SEG end_char="8360" id="segment-88" start_char="8144">
<ORIGINAL_TEXT>Another source of variability is that the studies measured different outcomes, ranging from mortality, length of hospital stay, changes in viral load, and recovery time, which were all combined into a single analysis.</ORIGINAL_TEXT>
<TOKEN end_char="8150" id="token-88-0" morph="none" pos="word" start_char="8144">Another</TOKEN>
<TOKEN end_char="8157" id="token-88-1" morph="none" pos="word" start_char="8152">source</TOKEN>
<TOKEN end_char="8160" id="token-88-2" morph="none" pos="word" start_char="8159">of</TOKEN>
<TOKEN end_char="8172" id="token-88-3" morph="none" pos="word" start_char="8162">variability</TOKEN>
<TOKEN end_char="8175" id="token-88-4" morph="none" pos="word" start_char="8174">is</TOKEN>
<TOKEN end_char="8180" id="token-88-5" morph="none" pos="word" start_char="8177">that</TOKEN>
<TOKEN end_char="8184" id="token-88-6" morph="none" pos="word" start_char="8182">the</TOKEN>
<TOKEN end_char="8192" id="token-88-7" morph="none" pos="word" start_char="8186">studies</TOKEN>
<TOKEN end_char="8201" id="token-88-8" morph="none" pos="word" start_char="8194">measured</TOKEN>
<TOKEN end_char="8211" id="token-88-9" morph="none" pos="word" start_char="8203">different</TOKEN>
<TOKEN end_char="8220" id="token-88-10" morph="none" pos="word" start_char="8213">outcomes</TOKEN>
<TOKEN end_char="8221" id="token-88-11" morph="none" pos="punct" start_char="8221">,</TOKEN>
<TOKEN end_char="8229" id="token-88-12" morph="none" pos="word" start_char="8223">ranging</TOKEN>
<TOKEN end_char="8234" id="token-88-13" morph="none" pos="word" start_char="8231">from</TOKEN>
<TOKEN end_char="8244" id="token-88-14" morph="none" pos="word" start_char="8236">mortality</TOKEN>
<TOKEN end_char="8245" id="token-88-15" morph="none" pos="punct" start_char="8245">,</TOKEN>
<TOKEN end_char="8252" id="token-88-16" morph="none" pos="word" start_char="8247">length</TOKEN>
<TOKEN end_char="8255" id="token-88-17" morph="none" pos="word" start_char="8254">of</TOKEN>
<TOKEN end_char="8264" id="token-88-18" morph="none" pos="word" start_char="8257">hospital</TOKEN>
<TOKEN end_char="8269" id="token-88-19" morph="none" pos="word" start_char="8266">stay</TOKEN>
<TOKEN end_char="8270" id="token-88-20" morph="none" pos="punct" start_char="8270">,</TOKEN>
<TOKEN end_char="8278" id="token-88-21" morph="none" pos="word" start_char="8272">changes</TOKEN>
<TOKEN end_char="8281" id="token-88-22" morph="none" pos="word" start_char="8280">in</TOKEN>
<TOKEN end_char="8287" id="token-88-23" morph="none" pos="word" start_char="8283">viral</TOKEN>
<TOKEN end_char="8292" id="token-88-24" morph="none" pos="word" start_char="8289">load</TOKEN>
<TOKEN end_char="8293" id="token-88-25" morph="none" pos="punct" start_char="8293">,</TOKEN>
<TOKEN end_char="8297" id="token-88-26" morph="none" pos="word" start_char="8295">and</TOKEN>
<TOKEN end_char="8306" id="token-88-27" morph="none" pos="word" start_char="8299">recovery</TOKEN>
<TOKEN end_char="8311" id="token-88-28" morph="none" pos="word" start_char="8308">time</TOKEN>
<TOKEN end_char="8312" id="token-88-29" morph="none" pos="punct" start_char="8312">,</TOKEN>
<TOKEN end_char="8318" id="token-88-30" morph="none" pos="word" start_char="8314">which</TOKEN>
<TOKEN end_char="8323" id="token-88-31" morph="none" pos="word" start_char="8320">were</TOKEN>
<TOKEN end_char="8327" id="token-88-32" morph="none" pos="word" start_char="8325">all</TOKEN>
<TOKEN end_char="8336" id="token-88-33" morph="none" pos="word" start_char="8329">combined</TOKEN>
<TOKEN end_char="8341" id="token-88-34" morph="none" pos="word" start_char="8338">into</TOKEN>
<TOKEN end_char="8343" id="token-88-35" morph="none" pos="word" start_char="8343">a</TOKEN>
<TOKEN end_char="8350" id="token-88-36" morph="none" pos="word" start_char="8345">single</TOKEN>
<TOKEN end_char="8359" id="token-88-37" morph="none" pos="word" start_char="8352">analysis</TOKEN>
<TOKEN end_char="8360" id="token-88-38" morph="none" pos="punct" start_char="8360">.</TOKEN>
</SEG>
<SEG end_char="8615" id="segment-89" start_char="8363">
<ORIGINAL_TEXT>In other words, far from providing reliable evidence that "ivermectin works", as the website claimed, the findings of CovidAnalysis only reinforce the fact that clinical trials so far provide a low level of certainty—as highlighted in the WHO guideline.</ORIGINAL_TEXT>
<TOKEN end_char="8364" id="token-89-0" morph="none" pos="word" start_char="8363">In</TOKEN>
<TOKEN end_char="8370" id="token-89-1" morph="none" pos="word" start_char="8366">other</TOKEN>
<TOKEN end_char="8376" id="token-89-2" morph="none" pos="word" start_char="8372">words</TOKEN>
<TOKEN end_char="8377" id="token-89-3" morph="none" pos="punct" start_char="8377">,</TOKEN>
<TOKEN end_char="8381" id="token-89-4" morph="none" pos="word" start_char="8379">far</TOKEN>
<TOKEN end_char="8386" id="token-89-5" morph="none" pos="word" start_char="8383">from</TOKEN>
<TOKEN end_char="8396" id="token-89-6" morph="none" pos="word" start_char="8388">providing</TOKEN>
<TOKEN end_char="8405" id="token-89-7" morph="none" pos="word" start_char="8398">reliable</TOKEN>
<TOKEN end_char="8414" id="token-89-8" morph="none" pos="word" start_char="8407">evidence</TOKEN>
<TOKEN end_char="8419" id="token-89-9" morph="none" pos="word" start_char="8416">that</TOKEN>
<TOKEN end_char="8421" id="token-89-10" morph="none" pos="punct" start_char="8421">"</TOKEN>
<TOKEN end_char="8431" id="token-89-11" morph="none" pos="word" start_char="8422">ivermectin</TOKEN>
<TOKEN end_char="8437" id="token-89-12" morph="none" pos="word" start_char="8433">works</TOKEN>
<TOKEN end_char="8439" id="token-89-13" morph="none" pos="punct" start_char="8438">",</TOKEN>
<TOKEN end_char="8442" id="token-89-14" morph="none" pos="word" start_char="8441">as</TOKEN>
<TOKEN end_char="8446" id="token-89-15" morph="none" pos="word" start_char="8444">the</TOKEN>
<TOKEN end_char="8454" id="token-89-16" morph="none" pos="word" start_char="8448">website</TOKEN>
<TOKEN end_char="8462" id="token-89-17" morph="none" pos="word" start_char="8456">claimed</TOKEN>
<TOKEN end_char="8463" id="token-89-18" morph="none" pos="punct" start_char="8463">,</TOKEN>
<TOKEN end_char="8467" id="token-89-19" morph="none" pos="word" start_char="8465">the</TOKEN>
<TOKEN end_char="8476" id="token-89-20" morph="none" pos="word" start_char="8469">findings</TOKEN>
<TOKEN end_char="8479" id="token-89-21" morph="none" pos="word" start_char="8478">of</TOKEN>
<TOKEN end_char="8493" id="token-89-22" morph="none" pos="word" start_char="8481">CovidAnalysis</TOKEN>
<TOKEN end_char="8498" id="token-89-23" morph="none" pos="word" start_char="8495">only</TOKEN>
<TOKEN end_char="8508" id="token-89-24" morph="none" pos="word" start_char="8500">reinforce</TOKEN>
<TOKEN end_char="8512" id="token-89-25" morph="none" pos="word" start_char="8510">the</TOKEN>
<TOKEN end_char="8517" id="token-89-26" morph="none" pos="word" start_char="8514">fact</TOKEN>
<TOKEN end_char="8522" id="token-89-27" morph="none" pos="word" start_char="8519">that</TOKEN>
<TOKEN end_char="8531" id="token-89-28" morph="none" pos="word" start_char="8524">clinical</TOKEN>
<TOKEN end_char="8538" id="token-89-29" morph="none" pos="word" start_char="8533">trials</TOKEN>
<TOKEN end_char="8541" id="token-89-30" morph="none" pos="word" start_char="8540">so</TOKEN>
<TOKEN end_char="8545" id="token-89-31" morph="none" pos="word" start_char="8543">far</TOKEN>
<TOKEN end_char="8553" id="token-89-32" morph="none" pos="word" start_char="8547">provide</TOKEN>
<TOKEN end_char="8555" id="token-89-33" morph="none" pos="word" start_char="8555">a</TOKEN>
<TOKEN end_char="8559" id="token-89-34" morph="none" pos="word" start_char="8557">low</TOKEN>
<TOKEN end_char="8565" id="token-89-35" morph="none" pos="word" start_char="8561">level</TOKEN>
<TOKEN end_char="8568" id="token-89-36" morph="none" pos="word" start_char="8567">of</TOKEN>
<TOKEN end_char="8581" id="token-89-37" morph="none" pos="unknown" start_char="8570">certainty—as</TOKEN>
<TOKEN end_char="8593" id="token-89-38" morph="none" pos="word" start_char="8583">highlighted</TOKEN>
<TOKEN end_char="8596" id="token-89-39" morph="none" pos="word" start_char="8595">in</TOKEN>
<TOKEN end_char="8600" id="token-89-40" morph="none" pos="word" start_char="8598">the</TOKEN>
<TOKEN end_char="8604" id="token-89-41" morph="none" pos="word" start_char="8602">WHO</TOKEN>
<TOKEN end_char="8614" id="token-89-42" morph="none" pos="word" start_char="8606">guideline</TOKEN>
<TOKEN end_char="8615" id="token-89-43" morph="none" pos="punct" start_char="8615">.</TOKEN>
</SEG>
<SEG end_char="8780" id="segment-90" start_char="8618">
<ORIGINAL_TEXT>It is useful to note that among the voices discouraging the use of ivermectin for COVID-19 treatment is Merck, the pharmaceutical company that produces ivermectin.</ORIGINAL_TEXT>
<TOKEN end_char="8619" id="token-90-0" morph="none" pos="word" start_char="8618">It</TOKEN>
<TOKEN end_char="8622" id="token-90-1" morph="none" pos="word" start_char="8621">is</TOKEN>
<TOKEN end_char="8629" id="token-90-2" morph="none" pos="word" start_char="8624">useful</TOKEN>
<TOKEN end_char="8632" id="token-90-3" morph="none" pos="word" start_char="8631">to</TOKEN>
<TOKEN end_char="8637" id="token-90-4" morph="none" pos="word" start_char="8634">note</TOKEN>
<TOKEN end_char="8642" id="token-90-5" morph="none" pos="word" start_char="8639">that</TOKEN>
<TOKEN end_char="8648" id="token-90-6" morph="none" pos="word" start_char="8644">among</TOKEN>
<TOKEN end_char="8652" id="token-90-7" morph="none" pos="word" start_char="8650">the</TOKEN>
<TOKEN end_char="8659" id="token-90-8" morph="none" pos="word" start_char="8654">voices</TOKEN>
<TOKEN end_char="8672" id="token-90-9" morph="none" pos="word" start_char="8661">discouraging</TOKEN>
<TOKEN end_char="8676" id="token-90-10" morph="none" pos="word" start_char="8674">the</TOKEN>
<TOKEN end_char="8680" id="token-90-11" morph="none" pos="word" start_char="8678">use</TOKEN>
<TOKEN end_char="8683" id="token-90-12" morph="none" pos="word" start_char="8682">of</TOKEN>
<TOKEN end_char="8694" id="token-90-13" morph="none" pos="word" start_char="8685">ivermectin</TOKEN>
<TOKEN end_char="8698" id="token-90-14" morph="none" pos="word" start_char="8696">for</TOKEN>
<TOKEN end_char="8707" id="token-90-15" morph="none" pos="unknown" start_char="8700">COVID-19</TOKEN>
<TOKEN end_char="8717" id="token-90-16" morph="none" pos="word" start_char="8709">treatment</TOKEN>
<TOKEN end_char="8720" id="token-90-17" morph="none" pos="word" start_char="8719">is</TOKEN>
<TOKEN end_char="8726" id="token-90-18" morph="none" pos="word" start_char="8722">Merck</TOKEN>
<TOKEN end_char="8727" id="token-90-19" morph="none" pos="punct" start_char="8727">,</TOKEN>
<TOKEN end_char="8731" id="token-90-20" morph="none" pos="word" start_char="8729">the</TOKEN>
<TOKEN end_char="8746" id="token-90-21" morph="none" pos="word" start_char="8733">pharmaceutical</TOKEN>
<TOKEN end_char="8754" id="token-90-22" morph="none" pos="word" start_char="8748">company</TOKEN>
<TOKEN end_char="8759" id="token-90-23" morph="none" pos="word" start_char="8756">that</TOKEN>
<TOKEN end_char="8768" id="token-90-24" morph="none" pos="word" start_char="8761">produces</TOKEN>
<TOKEN end_char="8779" id="token-90-25" morph="none" pos="word" start_char="8770">ivermectin</TOKEN>
<TOKEN end_char="8780" id="token-90-26" morph="none" pos="punct" start_char="8780">.</TOKEN>
</SEG>
<SEG end_char="9020" id="segment-91" start_char="8782">
<ORIGINAL_TEXT>Given that it would stand to profit if ivermectin were used for COVID-19 treatment, it is significant that the company stated that it doesn’t recommend ivermectin for COVID-19 because there is no meaningful clinical evidence supporting it.</ORIGINAL_TEXT>
<TOKEN end_char="8786" id="token-91-0" morph="none" pos="word" start_char="8782">Given</TOKEN>
<TOKEN end_char="8791" id="token-91-1" morph="none" pos="word" start_char="8788">that</TOKEN>
<TOKEN end_char="8794" id="token-91-2" morph="none" pos="word" start_char="8793">it</TOKEN>
<TOKEN end_char="8800" id="token-91-3" morph="none" pos="word" start_char="8796">would</TOKEN>
<TOKEN end_char="8806" id="token-91-4" morph="none" pos="word" start_char="8802">stand</TOKEN>
<TOKEN end_char="8809" id="token-91-5" morph="none" pos="word" start_char="8808">to</TOKEN>
<TOKEN end_char="8816" id="token-91-6" morph="none" pos="word" start_char="8811">profit</TOKEN>
<TOKEN end_char="8819" id="token-91-7" morph="none" pos="word" start_char="8818">if</TOKEN>
<TOKEN end_char="8830" id="token-91-8" morph="none" pos="word" start_char="8821">ivermectin</TOKEN>
<TOKEN end_char="8835" id="token-91-9" morph="none" pos="word" start_char="8832">were</TOKEN>
<TOKEN end_char="8840" id="token-91-10" morph="none" pos="word" start_char="8837">used</TOKEN>
<TOKEN end_char="8844" id="token-91-11" morph="none" pos="word" start_char="8842">for</TOKEN>
<TOKEN end_char="8853" id="token-91-12" morph="none" pos="unknown" start_char="8846">COVID-19</TOKEN>
<TOKEN end_char="8863" id="token-91-13" morph="none" pos="word" start_char="8855">treatment</TOKEN>
<TOKEN end_char="8864" id="token-91-14" morph="none" pos="punct" start_char="8864">,</TOKEN>
<TOKEN end_char="8867" id="token-91-15" morph="none" pos="word" start_char="8866">it</TOKEN>
<TOKEN end_char="8870" id="token-91-16" morph="none" pos="word" start_char="8869">is</TOKEN>
<TOKEN end_char="8882" id="token-91-17" morph="none" pos="word" start_char="8872">significant</TOKEN>
<TOKEN end_char="8887" id="token-91-18" morph="none" pos="word" start_char="8884">that</TOKEN>
<TOKEN end_char="8891" id="token-91-19" morph="none" pos="word" start_char="8889">the</TOKEN>
<TOKEN end_char="8899" id="token-91-20" morph="none" pos="word" start_char="8893">company</TOKEN>
<TOKEN end_char="8906" id="token-91-21" morph="none" pos="word" start_char="8901">stated</TOKEN>
<TOKEN end_char="8911" id="token-91-22" morph="none" pos="word" start_char="8908">that</TOKEN>
<TOKEN end_char="8914" id="token-91-23" morph="none" pos="word" start_char="8913">it</TOKEN>
<TOKEN end_char="8922" id="token-91-24" morph="none" pos="word" start_char="8916">doesn’t</TOKEN>
<TOKEN end_char="8932" id="token-91-25" morph="none" pos="word" start_char="8924">recommend</TOKEN>
<TOKEN end_char="8943" id="token-91-26" morph="none" pos="word" start_char="8934">ivermectin</TOKEN>
<TOKEN end_char="8947" id="token-91-27" morph="none" pos="word" start_char="8945">for</TOKEN>
<TOKEN end_char="8956" id="token-91-28" morph="none" pos="unknown" start_char="8949">COVID-19</TOKEN>
<TOKEN end_char="8964" id="token-91-29" morph="none" pos="word" start_char="8958">because</TOKEN>
<TOKEN end_char="8970" id="token-91-30" morph="none" pos="word" start_char="8966">there</TOKEN>
<TOKEN end_char="8973" id="token-91-31" morph="none" pos="word" start_char="8972">is</TOKEN>
<TOKEN end_char="8976" id="token-91-32" morph="none" pos="word" start_char="8975">no</TOKEN>
<TOKEN end_char="8987" id="token-91-33" morph="none" pos="word" start_char="8978">meaningful</TOKEN>
<TOKEN end_char="8996" id="token-91-34" morph="none" pos="word" start_char="8989">clinical</TOKEN>
<TOKEN end_char="9005" id="token-91-35" morph="none" pos="word" start_char="8998">evidence</TOKEN>
<TOKEN end_char="9016" id="token-91-36" morph="none" pos="word" start_char="9007">supporting</TOKEN>
<TOKEN end_char="9019" id="token-91-37" morph="none" pos="word" start_char="9018">it</TOKEN>
<TOKEN end_char="9020" id="token-91-38" morph="none" pos="punct" start_char="9020">.</TOKEN>
</SEG>
<SEG end_char="9147" id="segment-92" start_char="9023">
<ORIGINAL_TEXT>Finally, Kelly accused "the people that are pushing the vaccines" of suppressing the use of ivermectin for treating COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="9029" id="token-92-0" morph="none" pos="word" start_char="9023">Finally</TOKEN>
<TOKEN end_char="9030" id="token-92-1" morph="none" pos="punct" start_char="9030">,</TOKEN>
<TOKEN end_char="9036" id="token-92-2" morph="none" pos="word" start_char="9032">Kelly</TOKEN>
<TOKEN end_char="9044" id="token-92-3" morph="none" pos="word" start_char="9038">accused</TOKEN>
<TOKEN end_char="9046" id="token-92-4" morph="none" pos="punct" start_char="9046">"</TOKEN>
<TOKEN end_char="9049" id="token-92-5" morph="none" pos="word" start_char="9047">the</TOKEN>
<TOKEN end_char="9056" id="token-92-6" morph="none" pos="word" start_char="9051">people</TOKEN>
<TOKEN end_char="9061" id="token-92-7" morph="none" pos="word" start_char="9058">that</TOKEN>
<TOKEN end_char="9065" id="token-92-8" morph="none" pos="word" start_char="9063">are</TOKEN>
<TOKEN end_char="9073" id="token-92-9" morph="none" pos="word" start_char="9067">pushing</TOKEN>
<TOKEN end_char="9077" id="token-92-10" morph="none" pos="word" start_char="9075">the</TOKEN>
<TOKEN end_char="9086" id="token-92-11" morph="none" pos="word" start_char="9079">vaccines</TOKEN>
<TOKEN end_char="9087" id="token-92-12" morph="none" pos="punct" start_char="9087">"</TOKEN>
<TOKEN end_char="9090" id="token-92-13" morph="none" pos="word" start_char="9089">of</TOKEN>
<TOKEN end_char="9102" id="token-92-14" morph="none" pos="word" start_char="9092">suppressing</TOKEN>
<TOKEN end_char="9106" id="token-92-15" morph="none" pos="word" start_char="9104">the</TOKEN>
<TOKEN end_char="9110" id="token-92-16" morph="none" pos="word" start_char="9108">use</TOKEN>
<TOKEN end_char="9113" id="token-92-17" morph="none" pos="word" start_char="9112">of</TOKEN>
<TOKEN end_char="9124" id="token-92-18" morph="none" pos="word" start_char="9115">ivermectin</TOKEN>
<TOKEN end_char="9128" id="token-92-19" morph="none" pos="word" start_char="9126">for</TOKEN>
<TOKEN end_char="9137" id="token-92-20" morph="none" pos="word" start_char="9130">treating</TOKEN>
<TOKEN end_char="9146" id="token-92-21" morph="none" pos="unknown" start_char="9139">COVID-19</TOKEN>
<TOKEN end_char="9147" id="token-92-22" morph="none" pos="punct" start_char="9147">.</TOKEN>
</SEG>
<SEG end_char="9244" id="segment-93" start_char="9149">
<ORIGINAL_TEXT>He provided no evidence for this claim nor did he provide any examples of who these people were.</ORIGINAL_TEXT>
<TOKEN end_char="9150" id="token-93-0" morph="none" pos="word" start_char="9149">He</TOKEN>
<TOKEN end_char="9159" id="token-93-1" morph="none" pos="word" start_char="9152">provided</TOKEN>
<TOKEN end_char="9162" id="token-93-2" morph="none" pos="word" start_char="9161">no</TOKEN>
<TOKEN end_char="9171" id="token-93-3" morph="none" pos="word" start_char="9164">evidence</TOKEN>
<TOKEN end_char="9175" id="token-93-4" morph="none" pos="word" start_char="9173">for</TOKEN>
<TOKEN end_char="9180" id="token-93-5" morph="none" pos="word" start_char="9177">this</TOKEN>
<TOKEN end_char="9186" id="token-93-6" morph="none" pos="word" start_char="9182">claim</TOKEN>
<TOKEN end_char="9190" id="token-93-7" morph="none" pos="word" start_char="9188">nor</TOKEN>
<TOKEN end_char="9194" id="token-93-8" morph="none" pos="word" start_char="9192">did</TOKEN>
<TOKEN end_char="9197" id="token-93-9" morph="none" pos="word" start_char="9196">he</TOKEN>
<TOKEN end_char="9205" id="token-93-10" morph="none" pos="word" start_char="9199">provide</TOKEN>
<TOKEN end_char="9209" id="token-93-11" morph="none" pos="word" start_char="9207">any</TOKEN>
<TOKEN end_char="9218" id="token-93-12" morph="none" pos="word" start_char="9211">examples</TOKEN>
<TOKEN end_char="9221" id="token-93-13" morph="none" pos="word" start_char="9220">of</TOKEN>
<TOKEN end_char="9225" id="token-93-14" morph="none" pos="word" start_char="9223">who</TOKEN>
<TOKEN end_char="9231" id="token-93-15" morph="none" pos="word" start_char="9227">these</TOKEN>
<TOKEN end_char="9238" id="token-93-16" morph="none" pos="word" start_char="9233">people</TOKEN>
<TOKEN end_char="9243" id="token-93-17" morph="none" pos="word" start_char="9240">were</TOKEN>
<TOKEN end_char="9244" id="token-93-18" morph="none" pos="punct" start_char="9244">.</TOKEN>
</SEG>
<SEG end_char="9283" id="segment-94" start_char="9246">
<ORIGINAL_TEXT>The claim is also flawed in reasoning.</ORIGINAL_TEXT>
<TOKEN end_char="9248" id="token-94-0" morph="none" pos="word" start_char="9246">The</TOKEN>
<TOKEN end_char="9254" id="token-94-1" morph="none" pos="word" start_char="9250">claim</TOKEN>
<TOKEN end_char="9257" id="token-94-2" morph="none" pos="word" start_char="9256">is</TOKEN>
<TOKEN end_char="9262" id="token-94-3" morph="none" pos="word" start_char="9259">also</TOKEN>
<TOKEN end_char="9269" id="token-94-4" morph="none" pos="word" start_char="9264">flawed</TOKEN>
<TOKEN end_char="9272" id="token-94-5" morph="none" pos="word" start_char="9271">in</TOKEN>
<TOKEN end_char="9282" id="token-94-6" morph="none" pos="word" start_char="9274">reasoning</TOKEN>
<TOKEN end_char="9283" id="token-94-7" morph="none" pos="punct" start_char="9283">.</TOKEN>
</SEG>
<SEG end_char="9484" id="segment-95" start_char="9285">
<ORIGINAL_TEXT>Even if ivermectin were eventually proven to be an effective drug for COVID-19, it wouldn’t make vaccines useless (or vice versa), just as seat belts don’t render brakes or airbags in a car redundant.</ORIGINAL_TEXT>
<TOKEN end_char="9288" id="token-95-0" morph="none" pos="word" start_char="9285">Even</TOKEN>
<TOKEN end_char="9291" id="token-95-1" morph="none" pos="word" start_char="9290">if</TOKEN>
<TOKEN end_char="9302" id="token-95-2" morph="none" pos="word" start_char="9293">ivermectin</TOKEN>
<TOKEN end_char="9307" id="token-95-3" morph="none" pos="word" start_char="9304">were</TOKEN>
<TOKEN end_char="9318" id="token-95-4" morph="none" pos="word" start_char="9309">eventually</TOKEN>
<TOKEN end_char="9325" id="token-95-5" morph="none" pos="word" start_char="9320">proven</TOKEN>
<TOKEN end_char="9328" id="token-95-6" morph="none" pos="word" start_char="9327">to</TOKEN>
<TOKEN end_char="9331" id="token-95-7" morph="none" pos="word" start_char="9330">be</TOKEN>
<TOKEN end_char="9334" id="token-95-8" morph="none" pos="word" start_char="9333">an</TOKEN>
<TOKEN end_char="9344" id="token-95-9" morph="none" pos="word" start_char="9336">effective</TOKEN>
<TOKEN end_char="9349" id="token-95-10" morph="none" pos="word" start_char="9346">drug</TOKEN>
<TOKEN end_char="9353" id="token-95-11" morph="none" pos="word" start_char="9351">for</TOKEN>
<TOKEN end_char="9362" id="token-95-12" morph="none" pos="unknown" start_char="9355">COVID-19</TOKEN>
<TOKEN end_char="9363" id="token-95-13" morph="none" pos="punct" start_char="9363">,</TOKEN>
<TOKEN end_char="9366" id="token-95-14" morph="none" pos="word" start_char="9365">it</TOKEN>
<TOKEN end_char="9375" id="token-95-15" morph="none" pos="word" start_char="9368">wouldn’t</TOKEN>
<TOKEN end_char="9380" id="token-95-16" morph="none" pos="word" start_char="9377">make</TOKEN>
<TOKEN end_char="9389" id="token-95-17" morph="none" pos="word" start_char="9382">vaccines</TOKEN>
<TOKEN end_char="9397" id="token-95-18" morph="none" pos="word" start_char="9391">useless</TOKEN>
<TOKEN end_char="9399" id="token-95-19" morph="none" pos="punct" start_char="9399">(</TOKEN>
<TOKEN end_char="9401" id="token-95-20" morph="none" pos="word" start_char="9400">or</TOKEN>
<TOKEN end_char="9406" id="token-95-21" morph="none" pos="word" start_char="9403">vice</TOKEN>
<TOKEN end_char="9412" id="token-95-22" morph="none" pos="word" start_char="9408">versa</TOKEN>
<TOKEN end_char="9414" id="token-95-23" morph="none" pos="punct" start_char="9413">),</TOKEN>
<TOKEN end_char="9419" id="token-95-24" morph="none" pos="word" start_char="9416">just</TOKEN>
<TOKEN end_char="9422" id="token-95-25" morph="none" pos="word" start_char="9421">as</TOKEN>
<TOKEN end_char="9427" id="token-95-26" morph="none" pos="word" start_char="9424">seat</TOKEN>
<TOKEN end_char="9433" id="token-95-27" morph="none" pos="word" start_char="9429">belts</TOKEN>
<TOKEN end_char="9439" id="token-95-28" morph="none" pos="word" start_char="9435">don’t</TOKEN>
<TOKEN end_char="9446" id="token-95-29" morph="none" pos="word" start_char="9441">render</TOKEN>
<TOKEN end_char="9453" id="token-95-30" morph="none" pos="word" start_char="9448">brakes</TOKEN>
<TOKEN end_char="9456" id="token-95-31" morph="none" pos="word" start_char="9455">or</TOKEN>
<TOKEN end_char="9464" id="token-95-32" morph="none" pos="word" start_char="9458">airbags</TOKEN>
<TOKEN end_char="9467" id="token-95-33" morph="none" pos="word" start_char="9466">in</TOKEN>
<TOKEN end_char="9469" id="token-95-34" morph="none" pos="word" start_char="9469">a</TOKEN>
<TOKEN end_char="9473" id="token-95-35" morph="none" pos="word" start_char="9471">car</TOKEN>
<TOKEN end_char="9483" id="token-95-36" morph="none" pos="word" start_char="9475">redundant</TOKEN>
<TOKEN end_char="9484" id="token-95-37" morph="none" pos="punct" start_char="9484">.</TOKEN>
</SEG>
<SEG end_char="9609" id="segment-96" start_char="9487">
<ORIGINAL_TEXT>Overall, the claim that ivermectin can effectively treat and prevent COVID-19 remains unsubstantiated by reliable evidence.</ORIGINAL_TEXT>
<TOKEN end_char="9493" id="token-96-0" morph="none" pos="word" start_char="9487">Overall</TOKEN>
<TOKEN end_char="9494" id="token-96-1" morph="none" pos="punct" start_char="9494">,</TOKEN>
<TOKEN end_char="9498" id="token-96-2" morph="none" pos="word" start_char="9496">the</TOKEN>
<TOKEN end_char="9504" id="token-96-3" morph="none" pos="word" start_char="9500">claim</TOKEN>
<TOKEN end_char="9509" id="token-96-4" morph="none" pos="word" start_char="9506">that</TOKEN>
<TOKEN end_char="9520" id="token-96-5" morph="none" pos="word" start_char="9511">ivermectin</TOKEN>
<TOKEN end_char="9524" id="token-96-6" morph="none" pos="word" start_char="9522">can</TOKEN>
<TOKEN end_char="9536" id="token-96-7" morph="none" pos="word" start_char="9526">effectively</TOKEN>
<TOKEN end_char="9542" id="token-96-8" morph="none" pos="word" start_char="9538">treat</TOKEN>
<TOKEN end_char="9546" id="token-96-9" morph="none" pos="word" start_char="9544">and</TOKEN>
<TOKEN end_char="9554" id="token-96-10" morph="none" pos="word" start_char="9548">prevent</TOKEN>
<TOKEN end_char="9563" id="token-96-11" morph="none" pos="unknown" start_char="9556">COVID-19</TOKEN>
<TOKEN end_char="9571" id="token-96-12" morph="none" pos="word" start_char="9565">remains</TOKEN>
<TOKEN end_char="9587" id="token-96-13" morph="none" pos="word" start_char="9573">unsubstantiated</TOKEN>
<TOKEN end_char="9590" id="token-96-14" morph="none" pos="word" start_char="9589">by</TOKEN>
<TOKEN end_char="9599" id="token-96-15" morph="none" pos="word" start_char="9592">reliable</TOKEN>
<TOKEN end_char="9608" id="token-96-16" morph="none" pos="word" start_char="9601">evidence</TOKEN>
<TOKEN end_char="9609" id="token-96-17" morph="none" pos="punct" start_char="9609">.</TOKEN>
</SEG>
<SEG end_char="9692" id="segment-97" start_char="9611">
<ORIGINAL_TEXT>Researchers have called for high-quality clinical trials to resolve this question.</ORIGINAL_TEXT>
<TOKEN end_char="9621" id="token-97-0" morph="none" pos="word" start_char="9611">Researchers</TOKEN>
<TOKEN end_char="9626" id="token-97-1" morph="none" pos="word" start_char="9623">have</TOKEN>
<TOKEN end_char="9633" id="token-97-2" morph="none" pos="word" start_char="9628">called</TOKEN>
<TOKEN end_char="9637" id="token-97-3" morph="none" pos="word" start_char="9635">for</TOKEN>
<TOKEN end_char="9650" id="token-97-4" morph="none" pos="unknown" start_char="9639">high-quality</TOKEN>
<TOKEN end_char="9659" id="token-97-5" morph="none" pos="word" start_char="9652">clinical</TOKEN>
<TOKEN end_char="9666" id="token-97-6" morph="none" pos="word" start_char="9661">trials</TOKEN>
<TOKEN end_char="9669" id="token-97-7" morph="none" pos="word" start_char="9668">to</TOKEN>
<TOKEN end_char="9677" id="token-97-8" morph="none" pos="word" start_char="9671">resolve</TOKEN>
<TOKEN end_char="9682" id="token-97-9" morph="none" pos="word" start_char="9679">this</TOKEN>
<TOKEN end_char="9691" id="token-97-10" morph="none" pos="word" start_char="9684">question</TOKEN>
<TOKEN end_char="9692" id="token-97-11" morph="none" pos="punct" start_char="9692">.</TOKEN>
</SEG>
<SEG end_char="9996" id="segment-98" start_char="9694">
<ORIGINAL_TEXT>While recommendations may change in the future, should reliable evidence emerge, many health authorities, including the WHO, don’t currently recommend ivermectin as a COVID-19 treatment or preventative due to the lack of evidence supporting it, except as part of clinical trials evaluating its efficacy.</ORIGINAL_TEXT>
<TOKEN end_char="9698" id="token-98-0" morph="none" pos="word" start_char="9694">While</TOKEN>
<TOKEN end_char="9714" id="token-98-1" morph="none" pos="word" start_char="9700">recommendations</TOKEN>
<TOKEN end_char="9718" id="token-98-2" morph="none" pos="word" start_char="9716">may</TOKEN>
<TOKEN end_char="9725" id="token-98-3" morph="none" pos="word" start_char="9720">change</TOKEN>
<TOKEN end_char="9728" id="token-98-4" morph="none" pos="word" start_char="9727">in</TOKEN>
<TOKEN end_char="9732" id="token-98-5" morph="none" pos="word" start_char="9730">the</TOKEN>
<TOKEN end_char="9739" id="token-98-6" morph="none" pos="word" start_char="9734">future</TOKEN>
<TOKEN end_char="9740" id="token-98-7" morph="none" pos="punct" start_char="9740">,</TOKEN>
<TOKEN end_char="9747" id="token-98-8" morph="none" pos="word" start_char="9742">should</TOKEN>
<TOKEN end_char="9756" id="token-98-9" morph="none" pos="word" start_char="9749">reliable</TOKEN>
<TOKEN end_char="9765" id="token-98-10" morph="none" pos="word" start_char="9758">evidence</TOKEN>
<TOKEN end_char="9772" id="token-98-11" morph="none" pos="word" start_char="9767">emerge</TOKEN>
<TOKEN end_char="9773" id="token-98-12" morph="none" pos="punct" start_char="9773">,</TOKEN>
<TOKEN end_char="9778" id="token-98-13" morph="none" pos="word" start_char="9775">many</TOKEN>
<TOKEN end_char="9785" id="token-98-14" morph="none" pos="word" start_char="9780">health</TOKEN>
<TOKEN end_char="9797" id="token-98-15" morph="none" pos="word" start_char="9787">authorities</TOKEN>
<TOKEN end_char="9798" id="token-98-16" morph="none" pos="punct" start_char="9798">,</TOKEN>
<TOKEN end_char="9808" id="token-98-17" morph="none" pos="word" start_char="9800">including</TOKEN>
<TOKEN end_char="9812" id="token-98-18" morph="none" pos="word" start_char="9810">the</TOKEN>
<TOKEN end_char="9816" id="token-98-19" morph="none" pos="word" start_char="9814">WHO</TOKEN>
<TOKEN end_char="9817" id="token-98-20" morph="none" pos="punct" start_char="9817">,</TOKEN>
<TOKEN end_char="9823" id="token-98-21" morph="none" pos="word" start_char="9819">don’t</TOKEN>
<TOKEN end_char="9833" id="token-98-22" morph="none" pos="word" start_char="9825">currently</TOKEN>
<TOKEN end_char="9843" id="token-98-23" morph="none" pos="word" start_char="9835">recommend</TOKEN>
<TOKEN end_char="9854" id="token-98-24" morph="none" pos="word" start_char="9845">ivermectin</TOKEN>
<TOKEN end_char="9857" id="token-98-25" morph="none" pos="word" start_char="9856">as</TOKEN>
<TOKEN end_char="9859" id="token-98-26" morph="none" pos="word" start_char="9859">a</TOKEN>
<TOKEN end_char="9868" id="token-98-27" morph="none" pos="unknown" start_char="9861">COVID-19</TOKEN>
<TOKEN end_char="9878" id="token-98-28" morph="none" pos="word" start_char="9870">treatment</TOKEN>
<TOKEN end_char="9881" id="token-98-29" morph="none" pos="word" start_char="9880">or</TOKEN>
<TOKEN end_char="9894" id="token-98-30" morph="none" pos="word" start_char="9883">preventative</TOKEN>
<TOKEN end_char="9898" id="token-98-31" morph="none" pos="word" start_char="9896">due</TOKEN>
<TOKEN end_char="9901" id="token-98-32" morph="none" pos="word" start_char="9900">to</TOKEN>
<TOKEN end_char="9905" id="token-98-33" morph="none" pos="word" start_char="9903">the</TOKEN>
<TOKEN end_char="9910" id="token-98-34" morph="none" pos="word" start_char="9907">lack</TOKEN>
<TOKEN end_char="9913" id="token-98-35" morph="none" pos="word" start_char="9912">of</TOKEN>
<TOKEN end_char="9922" id="token-98-36" morph="none" pos="word" start_char="9915">evidence</TOKEN>
<TOKEN end_char="9933" id="token-98-37" morph="none" pos="word" start_char="9924">supporting</TOKEN>
<TOKEN end_char="9936" id="token-98-38" morph="none" pos="word" start_char="9935">it</TOKEN>
<TOKEN end_char="9937" id="token-98-39" morph="none" pos="punct" start_char="9937">,</TOKEN>
<TOKEN end_char="9944" id="token-98-40" morph="none" pos="word" start_char="9939">except</TOKEN>
<TOKEN end_char="9947" id="token-98-41" morph="none" pos="word" start_char="9946">as</TOKEN>
<TOKEN end_char="9952" id="token-98-42" morph="none" pos="word" start_char="9949">part</TOKEN>
<TOKEN end_char="9955" id="token-98-43" morph="none" pos="word" start_char="9954">of</TOKEN>
<TOKEN end_char="9964" id="token-98-44" morph="none" pos="word" start_char="9957">clinical</TOKEN>
<TOKEN end_char="9971" id="token-98-45" morph="none" pos="word" start_char="9966">trials</TOKEN>
<TOKEN end_char="9982" id="token-98-46" morph="none" pos="word" start_char="9973">evaluating</TOKEN>
<TOKEN end_char="9986" id="token-98-47" morph="none" pos="word" start_char="9984">its</TOKEN>
<TOKEN end_char="9995" id="token-98-48" morph="none" pos="word" start_char="9988">efficacy</TOKEN>
<TOKEN end_char="9996" id="token-98-49" morph="none" pos="punct" start_char="9996">.</TOKEN>
</SEG>
<SEG end_char="10007" id="segment-99" start_char="9999">
<ORIGINAL_TEXT>READ MORE</ORIGINAL_TEXT>
<TOKEN end_char="10002" id="token-99-0" morph="none" pos="word" start_char="9999">READ</TOKEN>
<TOKEN end_char="10007" id="token-99-1" morph="none" pos="word" start_char="10004">MORE</TOKEN>
<TRANSLATED_TEXT>RAAD MORE</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="10128" id="segment-100" start_char="10011">
<ORIGINAL_TEXT>Scientist Hilda Bastian published several blog posts explaining how to interpret a meta-analysis here, here, and here.</ORIGINAL_TEXT>
<TOKEN end_char="10019" id="token-100-0" morph="none" pos="word" start_char="10011">Scientist</TOKEN>
<TOKEN end_char="10025" id="token-100-1" morph="none" pos="word" start_char="10021">Hilda</TOKEN>
<TOKEN end_char="10033" id="token-100-2" morph="none" pos="word" start_char="10027">Bastian</TOKEN>
<TOKEN end_char="10043" id="token-100-3" morph="none" pos="word" start_char="10035">published</TOKEN>
<TOKEN end_char="10051" id="token-100-4" morph="none" pos="word" start_char="10045">several</TOKEN>
<TOKEN end_char="10056" id="token-100-5" morph="none" pos="word" start_char="10053">blog</TOKEN>
<TOKEN end_char="10062" id="token-100-6" morph="none" pos="word" start_char="10058">posts</TOKEN>
<TOKEN end_char="10073" id="token-100-7" morph="none" pos="word" start_char="10064">explaining</TOKEN>
<TOKEN end_char="10077" id="token-100-8" morph="none" pos="word" start_char="10075">how</TOKEN>
<TOKEN end_char="10080" id="token-100-9" morph="none" pos="word" start_char="10079">to</TOKEN>
<TOKEN end_char="10090" id="token-100-10" morph="none" pos="word" start_char="10082">interpret</TOKEN>
<TOKEN end_char="10092" id="token-100-11" morph="none" pos="word" start_char="10092">a</TOKEN>
<TOKEN end_char="10106" id="token-100-12" morph="none" pos="unknown" start_char="10094">meta-analysis</TOKEN>
<TOKEN end_char="10111" id="token-100-13" morph="none" pos="word" start_char="10108">here</TOKEN>
<TOKEN end_char="10112" id="token-100-14" morph="none" pos="punct" start_char="10112">,</TOKEN>
<TOKEN end_char="10117" id="token-100-15" morph="none" pos="word" start_char="10114">here</TOKEN>
<TOKEN end_char="10118" id="token-100-16" morph="none" pos="punct" start_char="10118">,</TOKEN>
<TOKEN end_char="10122" id="token-100-17" morph="none" pos="word" start_char="10120">and</TOKEN>
<TOKEN end_char="10127" id="token-100-18" morph="none" pos="word" start_char="10124">here</TOKEN>
<TOKEN end_char="10128" id="token-100-19" morph="none" pos="punct" start_char="10128">.</TOKEN>
</SEG>
<SEG end_char="10140" id="segment-101" start_char="10131">
<ORIGINAL_TEXT>REFERENCES</ORIGINAL_TEXT>
<TOKEN end_char="10140" id="token-101-0" morph="none" pos="word" start_char="10131">REFERENCES</TOKEN>
</SEG>
<SEG end_char="10159" id="segment-102" start_char="10145">
<ORIGINAL_TEXT>1 – Caly et al.</ORIGINAL_TEXT>
<TOKEN end_char="10145" id="token-102-0" morph="none" pos="word" start_char="10145">1</TOKEN>
<TOKEN end_char="10147" id="token-102-1" morph="none" pos="punct" start_char="10147">–</TOKEN>
<TOKEN end_char="10152" id="token-102-2" morph="none" pos="word" start_char="10149">Caly</TOKEN>
<TOKEN end_char="10155" id="token-102-3" morph="none" pos="word" start_char="10154">et</TOKEN>
<TOKEN end_char="10158" id="token-102-4" morph="none" pos="word" start_char="10157">al</TOKEN>
<TOKEN end_char="10159" id="token-102-5" morph="none" pos="punct" start_char="10159">.</TOKEN>
</SEG>
<SEG end_char="10248" id="segment-103" start_char="10161">
<ORIGINAL_TEXT>(2020) The FDA-approved drug ivermectin inhibits the replication of SARS-CoV-2 in vitro.</ORIGINAL_TEXT>
<TOKEN end_char="10161" id="token-103-0" morph="none" pos="punct" start_char="10161">(</TOKEN>
<TOKEN end_char="10165" id="token-103-1" morph="none" pos="word" start_char="10162">2020</TOKEN>
<TOKEN end_char="10166" id="token-103-2" morph="none" pos="punct" start_char="10166">)</TOKEN>
<TOKEN end_char="10170" id="token-103-3" morph="none" pos="word" start_char="10168">The</TOKEN>
<TOKEN end_char="10183" id="token-103-4" morph="none" pos="unknown" start_char="10172">FDA-approved</TOKEN>
<TOKEN end_char="10188" id="token-103-5" morph="none" pos="word" start_char="10185">drug</TOKEN>
<TOKEN end_char="10199" id="token-103-6" morph="none" pos="word" start_char="10190">ivermectin</TOKEN>
<TOKEN end_char="10208" id="token-103-7" morph="none" pos="word" start_char="10201">inhibits</TOKEN>
<TOKEN end_char="10212" id="token-103-8" morph="none" pos="word" start_char="10210">the</TOKEN>
<TOKEN end_char="10224" id="token-103-9" morph="none" pos="word" start_char="10214">replication</TOKEN>
<TOKEN end_char="10227" id="token-103-10" morph="none" pos="word" start_char="10226">of</TOKEN>
<TOKEN end_char="10238" id="token-103-11" morph="none" pos="unknown" start_char="10229">SARS-CoV-2</TOKEN>
<TOKEN end_char="10241" id="token-103-12" morph="none" pos="word" start_char="10240">in</TOKEN>
<TOKEN end_char="10247" id="token-103-13" morph="none" pos="word" start_char="10243">vitro</TOKEN>
<TOKEN end_char="10248" id="token-103-14" morph="none" pos="punct" start_char="10248">.</TOKEN>
</SEG>
<SEG end_char="10268" id="segment-104" start_char="10250">
<ORIGINAL_TEXT>Antiviral Research.</ORIGINAL_TEXT>
<TOKEN end_char="10258" id="token-104-0" morph="none" pos="word" start_char="10250">Antiviral</TOKEN>
<TOKEN end_char="10267" id="token-104-1" morph="none" pos="word" start_char="10260">Research</TOKEN>
<TOKEN end_char="10268" id="token-104-2" morph="none" pos="punct" start_char="10268">.</TOKEN>
</SEG>
<SEG end_char="10290" id="segment-105" start_char="10272">
<ORIGINAL_TEXT>2 – Chaccour et al.</ORIGINAL_TEXT>
<TOKEN end_char="10272" id="token-105-0" morph="none" pos="word" start_char="10272">2</TOKEN>
<TOKEN end_char="10274" id="token-105-1" morph="none" pos="punct" start_char="10274">–</TOKEN>
<TOKEN end_char="10283" id="token-105-2" morph="none" pos="word" start_char="10276">Chaccour</TOKEN>
<TOKEN end_char="10286" id="token-105-3" morph="none" pos="word" start_char="10285">et</TOKEN>
<TOKEN end_char="10289" id="token-105-4" morph="none" pos="word" start_char="10288">al</TOKEN>
<TOKEN end_char="10290" id="token-105-5" morph="none" pos="punct" start_char="10290">.</TOKEN>
<TRANSLATED_TEXT>2. Chaccourt et al.</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="10357" id="segment-106" start_char="10292">
<ORIGINAL_TEXT>(2020) Ivermectin and COVID-19: Keeping Rigor in Times of Urgency.</ORIGINAL_TEXT>
<TOKEN end_char="10292" id="token-106-0" morph="none" pos="punct" start_char="10292">(</TOKEN>
<TOKEN end_char="10296" id="token-106-1" morph="none" pos="word" start_char="10293">2020</TOKEN>
<TOKEN end_char="10297" id="token-106-2" morph="none" pos="punct" start_char="10297">)</TOKEN>
<TOKEN end_char="10308" id="token-106-3" morph="none" pos="word" start_char="10299">Ivermectin</TOKEN>
<TOKEN end_char="10312" id="token-106-4" morph="none" pos="word" start_char="10310">and</TOKEN>
<TOKEN end_char="10321" id="token-106-5" morph="none" pos="unknown" start_char="10314">COVID-19</TOKEN>
<TOKEN end_char="10322" id="token-106-6" morph="none" pos="punct" start_char="10322">:</TOKEN>
<TOKEN end_char="10330" id="token-106-7" morph="none" pos="word" start_char="10324">Keeping</TOKEN>
<TOKEN end_char="10336" id="token-106-8" morph="none" pos="word" start_char="10332">Rigor</TOKEN>
<TOKEN end_char="10339" id="token-106-9" morph="none" pos="word" start_char="10338">in</TOKEN>
<TOKEN end_char="10345" id="token-106-10" morph="none" pos="word" start_char="10341">Times</TOKEN>
<TOKEN end_char="10348" id="token-106-11" morph="none" pos="word" start_char="10347">of</TOKEN>
<TOKEN end_char="10356" id="token-106-12" morph="none" pos="word" start_char="10350">Urgency</TOKEN>
<TOKEN end_char="10357" id="token-106-13" morph="none" pos="punct" start_char="10357">.</TOKEN>
</SEG>
<SEG end_char="10408" id="segment-107" start_char="10359">
<ORIGINAL_TEXT>American Journal of Tropical Medicine and Hygiene.</ORIGINAL_TEXT>
<TOKEN end_char="10366" id="token-107-0" morph="none" pos="word" start_char="10359">American</TOKEN>
<TOKEN end_char="10374" id="token-107-1" morph="none" pos="word" start_char="10368">Journal</TOKEN>
<TOKEN end_char="10377" id="token-107-2" morph="none" pos="word" start_char="10376">of</TOKEN>
<TOKEN end_char="10386" id="token-107-3" morph="none" pos="word" start_char="10379">Tropical</TOKEN>
<TOKEN end_char="10395" id="token-107-4" morph="none" pos="word" start_char="10388">Medicine</TOKEN>
<TOKEN end_char="10399" id="token-107-5" morph="none" pos="word" start_char="10397">and</TOKEN>
<TOKEN end_char="10407" id="token-107-6" morph="none" pos="word" start_char="10401">Hygiene</TOKEN>
<TOKEN end_char="10408" id="token-107-7" morph="none" pos="punct" start_char="10408">.</TOKEN>
</SEG>
<SEG end_char="10429" id="segment-108" start_char="10412">
<ORIGINAL_TEXT>3 – Higgins et al.</ORIGINAL_TEXT>
<TOKEN end_char="10412" id="token-108-0" morph="none" pos="word" start_char="10412">3</TOKEN>
<TOKEN end_char="10414" id="token-108-1" morph="none" pos="punct" start_char="10414">–</TOKEN>
<TOKEN end_char="10422" id="token-108-2" morph="none" pos="word" start_char="10416">Higgins</TOKEN>
<TOKEN end_char="10425" id="token-108-3" morph="none" pos="word" start_char="10424">et</TOKEN>
<TOKEN end_char="10428" id="token-108-4" morph="none" pos="word" start_char="10427">al</TOKEN>
<TOKEN end_char="10429" id="token-108-5" morph="none" pos="punct" start_char="10429">.</TOKEN>
<TRANSLATED_TEXT>3 - Higgins et al.</TRANSLATED_TEXT><DETECTED_LANGUAGE>da</DETECTED_LANGUAGE></SEG>
<SEG end_char="10478" id="segment-109" start_char="10431">
<ORIGINAL_TEXT>(2003) Measuring inconsistency in meta-analyses.</ORIGINAL_TEXT>
<TOKEN end_char="10431" id="token-109-0" morph="none" pos="punct" start_char="10431">(</TOKEN>
<TOKEN end_char="10435" id="token-109-1" morph="none" pos="word" start_char="10432">2003</TOKEN>
<TOKEN end_char="10436" id="token-109-2" morph="none" pos="punct" start_char="10436">)</TOKEN>
<TOKEN end_char="10446" id="token-109-3" morph="none" pos="word" start_char="10438">Measuring</TOKEN>
<TOKEN end_char="10460" id="token-109-4" morph="none" pos="word" start_char="10448">inconsistency</TOKEN>
<TOKEN end_char="10463" id="token-109-5" morph="none" pos="word" start_char="10462">in</TOKEN>
<TOKEN end_char="10477" id="token-109-6" morph="none" pos="unknown" start_char="10465">meta-analyses</TOKEN>
<TOKEN end_char="10478" id="token-109-7" morph="none" pos="punct" start_char="10478">.</TOKEN>
</SEG>
<SEG end_char="10483" id="segment-110" start_char="10480">
<ORIGINAL_TEXT>BMJ.</ORIGINAL_TEXT>
<TOKEN end_char="10482" id="token-110-0" morph="none" pos="word" start_char="10480">BMJ</TOKEN>
<TOKEN end_char="10483" id="token-110-1" morph="none" pos="punct" start_char="10483">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
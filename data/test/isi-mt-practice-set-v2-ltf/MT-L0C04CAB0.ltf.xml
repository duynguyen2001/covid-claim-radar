<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CAB0" lang="spa" raw_text_char_length="1521" raw_text_md5="654907567cd2a581df261f11803d905e" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="59" id="segment-0" start_char="1">
<ORIGINAL_TEXT>China says covid-19 might have originated in Northern Italy</ORIGINAL_TEXT>
<TOKEN end_char="5" id="token-0-0" morph="none" pos="word" start_char="1">China</TOKEN>
<TOKEN end_char="10" id="token-0-1" morph="none" pos="word" start_char="7">says</TOKEN>
<TOKEN end_char="19" id="token-0-2" morph="none" pos="unknown" start_char="12">covid-19</TOKEN>
<TOKEN end_char="25" id="token-0-3" morph="none" pos="word" start_char="21">might</TOKEN>
<TOKEN end_char="30" id="token-0-4" morph="none" pos="word" start_char="27">have</TOKEN>
<TOKEN end_char="41" id="token-0-5" morph="none" pos="word" start_char="32">originated</TOKEN>
<TOKEN end_char="44" id="token-0-6" morph="none" pos="word" start_char="43">in</TOKEN>
<TOKEN end_char="53" id="token-0-7" morph="none" pos="word" start_char="46">Northern</TOKEN>
<TOKEN end_char="59" id="token-0-8" morph="none" pos="word" start_char="55">Italy</TOKEN>
</SEG>
<SEG end_char="140" id="segment-1" start_char="67">
<ORIGINAL_TEXT>China thinks that covid-19 originally developed in Italy and not in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="71" id="token-1-0" morph="none" pos="word" start_char="67">China</TOKEN>
<TOKEN end_char="78" id="token-1-1" morph="none" pos="word" start_char="73">thinks</TOKEN>
<TOKEN end_char="83" id="token-1-2" morph="none" pos="word" start_char="80">that</TOKEN>
<TOKEN end_char="92" id="token-1-3" morph="none" pos="unknown" start_char="85">covid-19</TOKEN>
<TOKEN end_char="103" id="token-1-4" morph="none" pos="word" start_char="94">originally</TOKEN>
<TOKEN end_char="113" id="token-1-5" morph="none" pos="word" start_char="105">developed</TOKEN>
<TOKEN end_char="116" id="token-1-6" morph="none" pos="word" start_char="115">in</TOKEN>
<TOKEN end_char="122" id="token-1-7" morph="none" pos="word" start_char="118">Italy</TOKEN>
<TOKEN end_char="126" id="token-1-8" morph="none" pos="word" start_char="124">and</TOKEN>
<TOKEN end_char="130" id="token-1-9" morph="none" pos="word" start_char="128">not</TOKEN>
<TOKEN end_char="133" id="token-1-10" morph="none" pos="word" start_char="132">in</TOKEN>
<TOKEN end_char="139" id="token-1-11" morph="none" pos="word" start_char="135">Wuhan</TOKEN>
<TOKEN end_char="140" id="token-1-12" morph="none" pos="punct" start_char="140">.</TOKEN>
</SEG>
<SEG end_char="191" id="segment-2" start_char="142">
<ORIGINAL_TEXT>The news has been relaunched by the New York Post.</ORIGINAL_TEXT>
<TOKEN end_char="144" id="token-2-0" morph="none" pos="word" start_char="142">The</TOKEN>
<TOKEN end_char="149" id="token-2-1" morph="none" pos="word" start_char="146">news</TOKEN>
<TOKEN end_char="153" id="token-2-2" morph="none" pos="word" start_char="151">has</TOKEN>
<TOKEN end_char="158" id="token-2-3" morph="none" pos="word" start_char="155">been</TOKEN>
<TOKEN end_char="169" id="token-2-4" morph="none" pos="word" start_char="160">relaunched</TOKEN>
<TOKEN end_char="172" id="token-2-5" morph="none" pos="word" start_char="171">by</TOKEN>
<TOKEN end_char="176" id="token-2-6" morph="none" pos="word" start_char="174">the</TOKEN>
<TOKEN end_char="180" id="token-2-7" morph="none" pos="word" start_char="178">New</TOKEN>
<TOKEN end_char="185" id="token-2-8" morph="none" pos="word" start_char="182">York</TOKEN>
<TOKEN end_char="190" id="token-2-9" morph="none" pos="word" start_char="187">Post</TOKEN>
<TOKEN end_char="191" id="token-2-10" morph="none" pos="punct" start_char="191">.</TOKEN>
</SEG>
<SEG end_char="332" id="segment-3" start_char="193">
<ORIGINAL_TEXT>The Government in Beijing is giving great importance to an Italian study that highlights how covid-19 was circulating in Italy in late 2019.</ORIGINAL_TEXT>
<TOKEN end_char="195" id="token-3-0" morph="none" pos="word" start_char="193">The</TOKEN>
<TOKEN end_char="206" id="token-3-1" morph="none" pos="word" start_char="197">Government</TOKEN>
<TOKEN end_char="209" id="token-3-2" morph="none" pos="word" start_char="208">in</TOKEN>
<TOKEN end_char="217" id="token-3-3" morph="none" pos="word" start_char="211">Beijing</TOKEN>
<TOKEN end_char="220" id="token-3-4" morph="none" pos="word" start_char="219">is</TOKEN>
<TOKEN end_char="227" id="token-3-5" morph="none" pos="word" start_char="222">giving</TOKEN>
<TOKEN end_char="233" id="token-3-6" morph="none" pos="word" start_char="229">great</TOKEN>
<TOKEN end_char="244" id="token-3-7" morph="none" pos="word" start_char="235">importance</TOKEN>
<TOKEN end_char="247" id="token-3-8" morph="none" pos="word" start_char="246">to</TOKEN>
<TOKEN end_char="250" id="token-3-9" morph="none" pos="word" start_char="249">an</TOKEN>
<TOKEN end_char="258" id="token-3-10" morph="none" pos="word" start_char="252">Italian</TOKEN>
<TOKEN end_char="264" id="token-3-11" morph="none" pos="word" start_char="260">study</TOKEN>
<TOKEN end_char="269" id="token-3-12" morph="none" pos="word" start_char="266">that</TOKEN>
<TOKEN end_char="280" id="token-3-13" morph="none" pos="word" start_char="271">highlights</TOKEN>
<TOKEN end_char="284" id="token-3-14" morph="none" pos="word" start_char="282">how</TOKEN>
<TOKEN end_char="293" id="token-3-15" morph="none" pos="unknown" start_char="286">covid-19</TOKEN>
<TOKEN end_char="297" id="token-3-16" morph="none" pos="word" start_char="295">was</TOKEN>
<TOKEN end_char="309" id="token-3-17" morph="none" pos="word" start_char="299">circulating</TOKEN>
<TOKEN end_char="312" id="token-3-18" morph="none" pos="word" start_char="311">in</TOKEN>
<TOKEN end_char="318" id="token-3-19" morph="none" pos="word" start_char="314">Italy</TOKEN>
<TOKEN end_char="321" id="token-3-20" morph="none" pos="word" start_char="320">in</TOKEN>
<TOKEN end_char="326" id="token-3-21" morph="none" pos="word" start_char="323">late</TOKEN>
<TOKEN end_char="331" id="token-3-22" morph="none" pos="word" start_char="328">2019</TOKEN>
<TOKEN end_char="332" id="token-3-23" morph="none" pos="punct" start_char="332">.</TOKEN>
</SEG>
<SEG end_char="609" id="segment-4" start_char="335">
<ORIGINAL_TEXT>The spokesman of the Chinese Foreign Ministry, Zhao Lijiain, told the UK Times how this study demonstrates even more that tracing the origin of the virus is a complex scientific issue "that should be left to scientists, it is a fluid process that can involve many countries".</ORIGINAL_TEXT>
<TOKEN end_char="337" id="token-4-0" morph="none" pos="word" start_char="335">The</TOKEN>
<TOKEN end_char="347" id="token-4-1" morph="none" pos="word" start_char="339">spokesman</TOKEN>
<TOKEN end_char="350" id="token-4-2" morph="none" pos="word" start_char="349">of</TOKEN>
<TOKEN end_char="354" id="token-4-3" morph="none" pos="word" start_char="352">the</TOKEN>
<TOKEN end_char="362" id="token-4-4" morph="none" pos="word" start_char="356">Chinese</TOKEN>
<TOKEN end_char="370" id="token-4-5" morph="none" pos="word" start_char="364">Foreign</TOKEN>
<TOKEN end_char="379" id="token-4-6" morph="none" pos="word" start_char="372">Ministry</TOKEN>
<TOKEN end_char="380" id="token-4-7" morph="none" pos="punct" start_char="380">,</TOKEN>
<TOKEN end_char="385" id="token-4-8" morph="none" pos="word" start_char="382">Zhao</TOKEN>
<TOKEN end_char="393" id="token-4-9" morph="none" pos="word" start_char="387">Lijiain</TOKEN>
<TOKEN end_char="394" id="token-4-10" morph="none" pos="punct" start_char="394">,</TOKEN>
<TOKEN end_char="399" id="token-4-11" morph="none" pos="word" start_char="396">told</TOKEN>
<TOKEN end_char="403" id="token-4-12" morph="none" pos="word" start_char="401">the</TOKEN>
<TOKEN end_char="406" id="token-4-13" morph="none" pos="word" start_char="405">UK</TOKEN>
<TOKEN end_char="412" id="token-4-14" morph="none" pos="word" start_char="408">Times</TOKEN>
<TOKEN end_char="416" id="token-4-15" morph="none" pos="word" start_char="414">how</TOKEN>
<TOKEN end_char="421" id="token-4-16" morph="none" pos="word" start_char="418">this</TOKEN>
<TOKEN end_char="427" id="token-4-17" morph="none" pos="word" start_char="423">study</TOKEN>
<TOKEN end_char="440" id="token-4-18" morph="none" pos="word" start_char="429">demonstrates</TOKEN>
<TOKEN end_char="445" id="token-4-19" morph="none" pos="word" start_char="442">even</TOKEN>
<TOKEN end_char="450" id="token-4-20" morph="none" pos="word" start_char="447">more</TOKEN>
<TOKEN end_char="455" id="token-4-21" morph="none" pos="word" start_char="452">that</TOKEN>
<TOKEN end_char="463" id="token-4-22" morph="none" pos="word" start_char="457">tracing</TOKEN>
<TOKEN end_char="467" id="token-4-23" morph="none" pos="word" start_char="465">the</TOKEN>
<TOKEN end_char="474" id="token-4-24" morph="none" pos="word" start_char="469">origin</TOKEN>
<TOKEN end_char="477" id="token-4-25" morph="none" pos="word" start_char="476">of</TOKEN>
<TOKEN end_char="481" id="token-4-26" morph="none" pos="word" start_char="479">the</TOKEN>
<TOKEN end_char="487" id="token-4-27" morph="none" pos="word" start_char="483">virus</TOKEN>
<TOKEN end_char="490" id="token-4-28" morph="none" pos="word" start_char="489">is</TOKEN>
<TOKEN end_char="492" id="token-4-29" morph="none" pos="word" start_char="492">a</TOKEN>
<TOKEN end_char="500" id="token-4-30" morph="none" pos="word" start_char="494">complex</TOKEN>
<TOKEN end_char="511" id="token-4-31" morph="none" pos="word" start_char="502">scientific</TOKEN>
<TOKEN end_char="517" id="token-4-32" morph="none" pos="word" start_char="513">issue</TOKEN>
<TOKEN end_char="519" id="token-4-33" morph="none" pos="punct" start_char="519">"</TOKEN>
<TOKEN end_char="523" id="token-4-34" morph="none" pos="word" start_char="520">that</TOKEN>
<TOKEN end_char="530" id="token-4-35" morph="none" pos="word" start_char="525">should</TOKEN>
<TOKEN end_char="533" id="token-4-36" morph="none" pos="word" start_char="532">be</TOKEN>
<TOKEN end_char="538" id="token-4-37" morph="none" pos="word" start_char="535">left</TOKEN>
<TOKEN end_char="541" id="token-4-38" morph="none" pos="word" start_char="540">to</TOKEN>
<TOKEN end_char="552" id="token-4-39" morph="none" pos="word" start_char="543">scientists</TOKEN>
<TOKEN end_char="553" id="token-4-40" morph="none" pos="punct" start_char="553">,</TOKEN>
<TOKEN end_char="556" id="token-4-41" morph="none" pos="word" start_char="555">it</TOKEN>
<TOKEN end_char="559" id="token-4-42" morph="none" pos="word" start_char="558">is</TOKEN>
<TOKEN end_char="561" id="token-4-43" morph="none" pos="word" start_char="561">a</TOKEN>
<TOKEN end_char="567" id="token-4-44" morph="none" pos="word" start_char="563">fluid</TOKEN>
<TOKEN end_char="575" id="token-4-45" morph="none" pos="word" start_char="569">process</TOKEN>
<TOKEN end_char="580" id="token-4-46" morph="none" pos="word" start_char="577">that</TOKEN>
<TOKEN end_char="584" id="token-4-47" morph="none" pos="word" start_char="582">can</TOKEN>
<TOKEN end_char="592" id="token-4-48" morph="none" pos="word" start_char="586">involve</TOKEN>
<TOKEN end_char="597" id="token-4-49" morph="none" pos="word" start_char="594">many</TOKEN>
<TOKEN end_char="607" id="token-4-50" morph="none" pos="word" start_char="599">countries</TOKEN>
<TOKEN end_char="609" id="token-4-51" morph="none" pos="punct" start_char="608">".</TOKEN>
</SEG>
<SEG end_char="722" id="segment-5" start_char="612">
<ORIGINAL_TEXT>It is not the first time that China tries to remove all its responsibility for the development of the pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="613" id="token-5-0" morph="none" pos="word" start_char="612">It</TOKEN>
<TOKEN end_char="616" id="token-5-1" morph="none" pos="word" start_char="615">is</TOKEN>
<TOKEN end_char="620" id="token-5-2" morph="none" pos="word" start_char="618">not</TOKEN>
<TOKEN end_char="624" id="token-5-3" morph="none" pos="word" start_char="622">the</TOKEN>
<TOKEN end_char="630" id="token-5-4" morph="none" pos="word" start_char="626">first</TOKEN>
<TOKEN end_char="635" id="token-5-5" morph="none" pos="word" start_char="632">time</TOKEN>
<TOKEN end_char="640" id="token-5-6" morph="none" pos="word" start_char="637">that</TOKEN>
<TOKEN end_char="646" id="token-5-7" morph="none" pos="word" start_char="642">China</TOKEN>
<TOKEN end_char="652" id="token-5-8" morph="none" pos="word" start_char="648">tries</TOKEN>
<TOKEN end_char="655" id="token-5-9" morph="none" pos="word" start_char="654">to</TOKEN>
<TOKEN end_char="662" id="token-5-10" morph="none" pos="word" start_char="657">remove</TOKEN>
<TOKEN end_char="666" id="token-5-11" morph="none" pos="word" start_char="664">all</TOKEN>
<TOKEN end_char="670" id="token-5-12" morph="none" pos="word" start_char="668">its</TOKEN>
<TOKEN end_char="685" id="token-5-13" morph="none" pos="word" start_char="672">responsibility</TOKEN>
<TOKEN end_char="689" id="token-5-14" morph="none" pos="word" start_char="687">for</TOKEN>
<TOKEN end_char="693" id="token-5-15" morph="none" pos="word" start_char="691">the</TOKEN>
<TOKEN end_char="705" id="token-5-16" morph="none" pos="word" start_char="695">development</TOKEN>
<TOKEN end_char="708" id="token-5-17" morph="none" pos="word" start_char="707">of</TOKEN>
<TOKEN end_char="712" id="token-5-18" morph="none" pos="word" start_char="710">the</TOKEN>
<TOKEN end_char="721" id="token-5-19" morph="none" pos="word" start_char="714">pandemic</TOKEN>
<TOKEN end_char="722" id="token-5-20" morph="none" pos="punct" start_char="722">.</TOKEN>
</SEG>
<SEG end_char="948" id="segment-6" start_char="724">
<ORIGINAL_TEXT>In the past it turned the spotlight on a possible responsibility of Spain, as well as on the United States that could be responsible for bringing the virus to Wuhan in October 2019 on the occasion of the World Military Games.</ORIGINAL_TEXT>
<TOKEN end_char="725" id="token-6-0" morph="none" pos="word" start_char="724">In</TOKEN>
<TOKEN end_char="729" id="token-6-1" morph="none" pos="word" start_char="727">the</TOKEN>
<TOKEN end_char="734" id="token-6-2" morph="none" pos="word" start_char="731">past</TOKEN>
<TOKEN end_char="737" id="token-6-3" morph="none" pos="word" start_char="736">it</TOKEN>
<TOKEN end_char="744" id="token-6-4" morph="none" pos="word" start_char="739">turned</TOKEN>
<TOKEN end_char="748" id="token-6-5" morph="none" pos="word" start_char="746">the</TOKEN>
<TOKEN end_char="758" id="token-6-6" morph="none" pos="word" start_char="750">spotlight</TOKEN>
<TOKEN end_char="761" id="token-6-7" morph="none" pos="word" start_char="760">on</TOKEN>
<TOKEN end_char="763" id="token-6-8" morph="none" pos="word" start_char="763">a</TOKEN>
<TOKEN end_char="772" id="token-6-9" morph="none" pos="word" start_char="765">possible</TOKEN>
<TOKEN end_char="787" id="token-6-10" morph="none" pos="word" start_char="774">responsibility</TOKEN>
<TOKEN end_char="790" id="token-6-11" morph="none" pos="word" start_char="789">of</TOKEN>
<TOKEN end_char="796" id="token-6-12" morph="none" pos="word" start_char="792">Spain</TOKEN>
<TOKEN end_char="797" id="token-6-13" morph="none" pos="punct" start_char="797">,</TOKEN>
<TOKEN end_char="800" id="token-6-14" morph="none" pos="word" start_char="799">as</TOKEN>
<TOKEN end_char="805" id="token-6-15" morph="none" pos="word" start_char="802">well</TOKEN>
<TOKEN end_char="808" id="token-6-16" morph="none" pos="word" start_char="807">as</TOKEN>
<TOKEN end_char="811" id="token-6-17" morph="none" pos="word" start_char="810">on</TOKEN>
<TOKEN end_char="815" id="token-6-18" morph="none" pos="word" start_char="813">the</TOKEN>
<TOKEN end_char="822" id="token-6-19" morph="none" pos="word" start_char="817">United</TOKEN>
<TOKEN end_char="829" id="token-6-20" morph="none" pos="word" start_char="824">States</TOKEN>
<TOKEN end_char="834" id="token-6-21" morph="none" pos="word" start_char="831">that</TOKEN>
<TOKEN end_char="840" id="token-6-22" morph="none" pos="word" start_char="836">could</TOKEN>
<TOKEN end_char="843" id="token-6-23" morph="none" pos="word" start_char="842">be</TOKEN>
<TOKEN end_char="855" id="token-6-24" morph="none" pos="word" start_char="845">responsible</TOKEN>
<TOKEN end_char="859" id="token-6-25" morph="none" pos="word" start_char="857">for</TOKEN>
<TOKEN end_char="868" id="token-6-26" morph="none" pos="word" start_char="861">bringing</TOKEN>
<TOKEN end_char="872" id="token-6-27" morph="none" pos="word" start_char="870">the</TOKEN>
<TOKEN end_char="878" id="token-6-28" morph="none" pos="word" start_char="874">virus</TOKEN>
<TOKEN end_char="881" id="token-6-29" morph="none" pos="word" start_char="880">to</TOKEN>
<TOKEN end_char="887" id="token-6-30" morph="none" pos="word" start_char="883">Wuhan</TOKEN>
<TOKEN end_char="890" id="token-6-31" morph="none" pos="word" start_char="889">in</TOKEN>
<TOKEN end_char="898" id="token-6-32" morph="none" pos="word" start_char="892">October</TOKEN>
<TOKEN end_char="903" id="token-6-33" morph="none" pos="word" start_char="900">2019</TOKEN>
<TOKEN end_char="906" id="token-6-34" morph="none" pos="word" start_char="905">on</TOKEN>
<TOKEN end_char="910" id="token-6-35" morph="none" pos="word" start_char="908">the</TOKEN>
<TOKEN end_char="919" id="token-6-36" morph="none" pos="word" start_char="912">occasion</TOKEN>
<TOKEN end_char="922" id="token-6-37" morph="none" pos="word" start_char="921">of</TOKEN>
<TOKEN end_char="926" id="token-6-38" morph="none" pos="word" start_char="924">the</TOKEN>
<TOKEN end_char="932" id="token-6-39" morph="none" pos="word" start_char="928">World</TOKEN>
<TOKEN end_char="941" id="token-6-40" morph="none" pos="word" start_char="934">Military</TOKEN>
<TOKEN end_char="947" id="token-6-41" morph="none" pos="word" start_char="943">Games</TOKEN>
<TOKEN end_char="948" id="token-6-42" morph="none" pos="punct" start_char="948">.</TOKEN>
</SEG>
<SEG end_char="1123" id="segment-7" start_char="951">
<ORIGINAL_TEXT>In addition to this, the WHO has previously stated that the virus may not have originated in China, but it could have circulated in other countries, albeit asymptomatically.</ORIGINAL_TEXT>
<TOKEN end_char="952" id="token-7-0" morph="none" pos="word" start_char="951">In</TOKEN>
<TOKEN end_char="961" id="token-7-1" morph="none" pos="word" start_char="954">addition</TOKEN>
<TOKEN end_char="964" id="token-7-2" morph="none" pos="word" start_char="963">to</TOKEN>
<TOKEN end_char="969" id="token-7-3" morph="none" pos="word" start_char="966">this</TOKEN>
<TOKEN end_char="970" id="token-7-4" morph="none" pos="punct" start_char="970">,</TOKEN>
<TOKEN end_char="974" id="token-7-5" morph="none" pos="word" start_char="972">the</TOKEN>
<TOKEN end_char="978" id="token-7-6" morph="none" pos="word" start_char="976">WHO</TOKEN>
<TOKEN end_char="982" id="token-7-7" morph="none" pos="word" start_char="980">has</TOKEN>
<TOKEN end_char="993" id="token-7-8" morph="none" pos="word" start_char="984">previously</TOKEN>
<TOKEN end_char="1000" id="token-7-9" morph="none" pos="word" start_char="995">stated</TOKEN>
<TOKEN end_char="1005" id="token-7-10" morph="none" pos="word" start_char="1002">that</TOKEN>
<TOKEN end_char="1009" id="token-7-11" morph="none" pos="word" start_char="1007">the</TOKEN>
<TOKEN end_char="1015" id="token-7-12" morph="none" pos="word" start_char="1011">virus</TOKEN>
<TOKEN end_char="1019" id="token-7-13" morph="none" pos="word" start_char="1017">may</TOKEN>
<TOKEN end_char="1023" id="token-7-14" morph="none" pos="word" start_char="1021">not</TOKEN>
<TOKEN end_char="1028" id="token-7-15" morph="none" pos="word" start_char="1025">have</TOKEN>
<TOKEN end_char="1039" id="token-7-16" morph="none" pos="word" start_char="1030">originated</TOKEN>
<TOKEN end_char="1042" id="token-7-17" morph="none" pos="word" start_char="1041">in</TOKEN>
<TOKEN end_char="1048" id="token-7-18" morph="none" pos="word" start_char="1044">China</TOKEN>
<TOKEN end_char="1049" id="token-7-19" morph="none" pos="punct" start_char="1049">,</TOKEN>
<TOKEN end_char="1053" id="token-7-20" morph="none" pos="word" start_char="1051">but</TOKEN>
<TOKEN end_char="1056" id="token-7-21" morph="none" pos="word" start_char="1055">it</TOKEN>
<TOKEN end_char="1062" id="token-7-22" morph="none" pos="word" start_char="1058">could</TOKEN>
<TOKEN end_char="1067" id="token-7-23" morph="none" pos="word" start_char="1064">have</TOKEN>
<TOKEN end_char="1078" id="token-7-24" morph="none" pos="word" start_char="1069">circulated</TOKEN>
<TOKEN end_char="1081" id="token-7-25" morph="none" pos="word" start_char="1080">in</TOKEN>
<TOKEN end_char="1087" id="token-7-26" morph="none" pos="word" start_char="1083">other</TOKEN>
<TOKEN end_char="1097" id="token-7-27" morph="none" pos="word" start_char="1089">countries</TOKEN>
<TOKEN end_char="1098" id="token-7-28" morph="none" pos="punct" start_char="1098">,</TOKEN>
<TOKEN end_char="1105" id="token-7-29" morph="none" pos="word" start_char="1100">albeit</TOKEN>
<TOKEN end_char="1122" id="token-7-30" morph="none" pos="word" start_char="1107">asymptomatically</TOKEN>
<TOKEN end_char="1123" id="token-7-31" morph="none" pos="punct" start_char="1123">.</TOKEN>
</SEG>
<SEG end_char="1275" id="segment-8" start_char="1126">
<ORIGINAL_TEXT>However, many scientists are skeptical of the Italian study’s findings along with the fact that it doesn't rule out the covid-19 originating in China.</ORIGINAL_TEXT>
<TOKEN end_char="1132" id="token-8-0" morph="none" pos="word" start_char="1126">However</TOKEN>
<TOKEN end_char="1133" id="token-8-1" morph="none" pos="punct" start_char="1133">,</TOKEN>
<TOKEN end_char="1138" id="token-8-2" morph="none" pos="word" start_char="1135">many</TOKEN>
<TOKEN end_char="1149" id="token-8-3" morph="none" pos="word" start_char="1140">scientists</TOKEN>
<TOKEN end_char="1153" id="token-8-4" morph="none" pos="word" start_char="1151">are</TOKEN>
<TOKEN end_char="1163" id="token-8-5" morph="none" pos="word" start_char="1155">skeptical</TOKEN>
<TOKEN end_char="1166" id="token-8-6" morph="none" pos="word" start_char="1165">of</TOKEN>
<TOKEN end_char="1170" id="token-8-7" morph="none" pos="word" start_char="1168">the</TOKEN>
<TOKEN end_char="1178" id="token-8-8" morph="none" pos="word" start_char="1172">Italian</TOKEN>
<TOKEN end_char="1186" id="token-8-9" morph="none" pos="word" start_char="1180">study’s</TOKEN>
<TOKEN end_char="1195" id="token-8-10" morph="none" pos="word" start_char="1188">findings</TOKEN>
<TOKEN end_char="1201" id="token-8-11" morph="none" pos="word" start_char="1197">along</TOKEN>
<TOKEN end_char="1206" id="token-8-12" morph="none" pos="word" start_char="1203">with</TOKEN>
<TOKEN end_char="1210" id="token-8-13" morph="none" pos="word" start_char="1208">the</TOKEN>
<TOKEN end_char="1215" id="token-8-14" morph="none" pos="word" start_char="1212">fact</TOKEN>
<TOKEN end_char="1220" id="token-8-15" morph="none" pos="word" start_char="1217">that</TOKEN>
<TOKEN end_char="1223" id="token-8-16" morph="none" pos="word" start_char="1222">it</TOKEN>
<TOKEN end_char="1231" id="token-8-17" morph="none" pos="word" start_char="1225">doesn't</TOKEN>
<TOKEN end_char="1236" id="token-8-18" morph="none" pos="word" start_char="1233">rule</TOKEN>
<TOKEN end_char="1240" id="token-8-19" morph="none" pos="word" start_char="1238">out</TOKEN>
<TOKEN end_char="1244" id="token-8-20" morph="none" pos="word" start_char="1242">the</TOKEN>
<TOKEN end_char="1253" id="token-8-21" morph="none" pos="unknown" start_char="1246">covid-19</TOKEN>
<TOKEN end_char="1265" id="token-8-22" morph="none" pos="word" start_char="1255">originating</TOKEN>
<TOKEN end_char="1268" id="token-8-23" morph="none" pos="word" start_char="1267">in</TOKEN>
<TOKEN end_char="1274" id="token-8-24" morph="none" pos="word" start_char="1270">China</TOKEN>
<TOKEN end_char="1275" id="token-8-25" morph="none" pos="punct" start_char="1275">.</TOKEN>
</SEG>
<SEG end_char="1517" id="segment-9" start_char="1278">
<ORIGINAL_TEXT>"We know that China delayed announcing its outbreak so there is no telling when it started there, and China has very strong commercial links with northern Italy," said Giovanni Apolone of Milan’s National Cancer Institute told the UK Times.</ORIGINAL_TEXT>
<TOKEN end_char="1278" id="token-9-0" morph="none" pos="punct" start_char="1278">"</TOKEN>
<TOKEN end_char="1280" id="token-9-1" morph="none" pos="word" start_char="1279">We</TOKEN>
<TOKEN end_char="1285" id="token-9-2" morph="none" pos="word" start_char="1282">know</TOKEN>
<TOKEN end_char="1290" id="token-9-3" morph="none" pos="word" start_char="1287">that</TOKEN>
<TOKEN end_char="1296" id="token-9-4" morph="none" pos="word" start_char="1292">China</TOKEN>
<TOKEN end_char="1304" id="token-9-5" morph="none" pos="word" start_char="1298">delayed</TOKEN>
<TOKEN end_char="1315" id="token-9-6" morph="none" pos="word" start_char="1306">announcing</TOKEN>
<TOKEN end_char="1319" id="token-9-7" morph="none" pos="word" start_char="1317">its</TOKEN>
<TOKEN end_char="1328" id="token-9-8" morph="none" pos="word" start_char="1321">outbreak</TOKEN>
<TOKEN end_char="1331" id="token-9-9" morph="none" pos="word" start_char="1330">so</TOKEN>
<TOKEN end_char="1337" id="token-9-10" morph="none" pos="word" start_char="1333">there</TOKEN>
<TOKEN end_char="1340" id="token-9-11" morph="none" pos="word" start_char="1339">is</TOKEN>
<TOKEN end_char="1343" id="token-9-12" morph="none" pos="word" start_char="1342">no</TOKEN>
<TOKEN end_char="1351" id="token-9-13" morph="none" pos="word" start_char="1345">telling</TOKEN>
<TOKEN end_char="1356" id="token-9-14" morph="none" pos="word" start_char="1353">when</TOKEN>
<TOKEN end_char="1359" id="token-9-15" morph="none" pos="word" start_char="1358">it</TOKEN>
<TOKEN end_char="1367" id="token-9-16" morph="none" pos="word" start_char="1361">started</TOKEN>
<TOKEN end_char="1373" id="token-9-17" morph="none" pos="word" start_char="1369">there</TOKEN>
<TOKEN end_char="1374" id="token-9-18" morph="none" pos="punct" start_char="1374">,</TOKEN>
<TOKEN end_char="1378" id="token-9-19" morph="none" pos="word" start_char="1376">and</TOKEN>
<TOKEN end_char="1384" id="token-9-20" morph="none" pos="word" start_char="1380">China</TOKEN>
<TOKEN end_char="1388" id="token-9-21" morph="none" pos="word" start_char="1386">has</TOKEN>
<TOKEN end_char="1393" id="token-9-22" morph="none" pos="word" start_char="1390">very</TOKEN>
<TOKEN end_char="1400" id="token-9-23" morph="none" pos="word" start_char="1395">strong</TOKEN>
<TOKEN end_char="1411" id="token-9-24" morph="none" pos="word" start_char="1402">commercial</TOKEN>
<TOKEN end_char="1417" id="token-9-25" morph="none" pos="word" start_char="1413">links</TOKEN>
<TOKEN end_char="1422" id="token-9-26" morph="none" pos="word" start_char="1419">with</TOKEN>
<TOKEN end_char="1431" id="token-9-27" morph="none" pos="word" start_char="1424">northern</TOKEN>
<TOKEN end_char="1437" id="token-9-28" morph="none" pos="word" start_char="1433">Italy</TOKEN>
<TOKEN end_char="1439" id="token-9-29" morph="none" pos="punct" start_char="1438">,"</TOKEN>
<TOKEN end_char="1444" id="token-9-30" morph="none" pos="word" start_char="1441">said</TOKEN>
<TOKEN end_char="1453" id="token-9-31" morph="none" pos="word" start_char="1446">Giovanni</TOKEN>
<TOKEN end_char="1461" id="token-9-32" morph="none" pos="word" start_char="1455">Apolone</TOKEN>
<TOKEN end_char="1464" id="token-9-33" morph="none" pos="word" start_char="1463">of</TOKEN>
<TOKEN end_char="1472" id="token-9-34" morph="none" pos="word" start_char="1466">Milan’s</TOKEN>
<TOKEN end_char="1481" id="token-9-35" morph="none" pos="word" start_char="1474">National</TOKEN>
<TOKEN end_char="1488" id="token-9-36" morph="none" pos="word" start_char="1483">Cancer</TOKEN>
<TOKEN end_char="1498" id="token-9-37" morph="none" pos="word" start_char="1490">Institute</TOKEN>
<TOKEN end_char="1503" id="token-9-38" morph="none" pos="word" start_char="1500">told</TOKEN>
<TOKEN end_char="1507" id="token-9-39" morph="none" pos="word" start_char="1505">the</TOKEN>
<TOKEN end_char="1510" id="token-9-40" morph="none" pos="word" start_char="1509">UK</TOKEN>
<TOKEN end_char="1516" id="token-9-41" morph="none" pos="word" start_char="1512">Times</TOKEN>
<TOKEN end_char="1517" id="token-9-42" morph="none" pos="punct" start_char="1517">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
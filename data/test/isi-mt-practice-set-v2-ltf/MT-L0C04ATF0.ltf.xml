<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATF0" lang="spa" raw_text_char_length="2547" raw_text_md5="cd7ca88208edecec75aa1bf338d12b48" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="104" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Fern Britton questions if Covid is a ‘conspiracy to control population’ as she admits she’s ‘not coping’</ORIGINAL_TEXT>
<TOKEN end_char="4" id="token-0-0" morph="none" pos="word" start_char="1">Fern</TOKEN>
<TOKEN end_char="12" id="token-0-1" morph="none" pos="word" start_char="6">Britton</TOKEN>
<TOKEN end_char="22" id="token-0-2" morph="none" pos="word" start_char="14">questions</TOKEN>
<TOKEN end_char="25" id="token-0-3" morph="none" pos="word" start_char="24">if</TOKEN>
<TOKEN end_char="31" id="token-0-4" morph="none" pos="word" start_char="27">Covid</TOKEN>
<TOKEN end_char="34" id="token-0-5" morph="none" pos="word" start_char="33">is</TOKEN>
<TOKEN end_char="36" id="token-0-6" morph="none" pos="word" start_char="36">a</TOKEN>
<TOKEN end_char="38" id="token-0-7" morph="none" pos="punct" start_char="38">‘</TOKEN>
<TOKEN end_char="48" id="token-0-8" morph="none" pos="word" start_char="39">conspiracy</TOKEN>
<TOKEN end_char="51" id="token-0-9" morph="none" pos="word" start_char="50">to</TOKEN>
<TOKEN end_char="59" id="token-0-10" morph="none" pos="word" start_char="53">control</TOKEN>
<TOKEN end_char="70" id="token-0-11" morph="none" pos="word" start_char="61">population</TOKEN>
<TOKEN end_char="71" id="token-0-12" morph="none" pos="punct" start_char="71">’</TOKEN>
<TOKEN end_char="74" id="token-0-13" morph="none" pos="word" start_char="73">as</TOKEN>
<TOKEN end_char="78" id="token-0-14" morph="none" pos="word" start_char="76">she</TOKEN>
<TOKEN end_char="85" id="token-0-15" morph="none" pos="word" start_char="80">admits</TOKEN>
<TOKEN end_char="91" id="token-0-16" morph="none" pos="word" start_char="87">she’s</TOKEN>
<TOKEN end_char="93" id="token-0-17" morph="none" pos="punct" start_char="93">‘</TOKEN>
<TOKEN end_char="96" id="token-0-18" morph="none" pos="word" start_char="94">not</TOKEN>
<TOKEN end_char="103" id="token-0-19" morph="none" pos="word" start_char="98">coping</TOKEN>
<TOKEN end_char="104" id="token-0-20" morph="none" pos="punct" start_char="104">’</TOKEN>
</SEG>
<SEG end_char="216" id="segment-1" start_char="108">
<ORIGINAL_TEXT>FERN Britton questions if Covid is a "conspiracy to control the population" as she admits she’s "not coping".</ORIGINAL_TEXT>
<TOKEN end_char="111" id="token-1-0" morph="none" pos="word" start_char="108">FERN</TOKEN>
<TOKEN end_char="119" id="token-1-1" morph="none" pos="word" start_char="113">Britton</TOKEN>
<TOKEN end_char="129" id="token-1-2" morph="none" pos="word" start_char="121">questions</TOKEN>
<TOKEN end_char="132" id="token-1-3" morph="none" pos="word" start_char="131">if</TOKEN>
<TOKEN end_char="138" id="token-1-4" morph="none" pos="word" start_char="134">Covid</TOKEN>
<TOKEN end_char="141" id="token-1-5" morph="none" pos="word" start_char="140">is</TOKEN>
<TOKEN end_char="143" id="token-1-6" morph="none" pos="word" start_char="143">a</TOKEN>
<TOKEN end_char="145" id="token-1-7" morph="none" pos="punct" start_char="145">"</TOKEN>
<TOKEN end_char="155" id="token-1-8" morph="none" pos="word" start_char="146">conspiracy</TOKEN>
<TOKEN end_char="158" id="token-1-9" morph="none" pos="word" start_char="157">to</TOKEN>
<TOKEN end_char="166" id="token-1-10" morph="none" pos="word" start_char="160">control</TOKEN>
<TOKEN end_char="170" id="token-1-11" morph="none" pos="word" start_char="168">the</TOKEN>
<TOKEN end_char="181" id="token-1-12" morph="none" pos="word" start_char="172">population</TOKEN>
<TOKEN end_char="182" id="token-1-13" morph="none" pos="punct" start_char="182">"</TOKEN>
<TOKEN end_char="185" id="token-1-14" morph="none" pos="word" start_char="184">as</TOKEN>
<TOKEN end_char="189" id="token-1-15" morph="none" pos="word" start_char="187">she</TOKEN>
<TOKEN end_char="196" id="token-1-16" morph="none" pos="word" start_char="191">admits</TOKEN>
<TOKEN end_char="202" id="token-1-17" morph="none" pos="word" start_char="198">she’s</TOKEN>
<TOKEN end_char="204" id="token-1-18" morph="none" pos="punct" start_char="204">"</TOKEN>
<TOKEN end_char="207" id="token-1-19" morph="none" pos="word" start_char="205">not</TOKEN>
<TOKEN end_char="214" id="token-1-20" morph="none" pos="word" start_char="209">coping</TOKEN>
<TOKEN end_char="216" id="token-1-21" morph="none" pos="punct" start_char="215">".</TOKEN>
</SEG>
<SEG end_char="361" id="segment-2" start_char="219">
<ORIGINAL_TEXT>The presenter, 64, she believes "Covid is a real and dangerous virus" as she opened up a discussion on conspiracy theories around the pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="221" id="token-2-0" morph="none" pos="word" start_char="219">The</TOKEN>
<TOKEN end_char="231" id="token-2-1" morph="none" pos="word" start_char="223">presenter</TOKEN>
<TOKEN end_char="232" id="token-2-2" morph="none" pos="punct" start_char="232">,</TOKEN>
<TOKEN end_char="235" id="token-2-3" morph="none" pos="word" start_char="234">64</TOKEN>
<TOKEN end_char="236" id="token-2-4" morph="none" pos="punct" start_char="236">,</TOKEN>
<TOKEN end_char="240" id="token-2-5" morph="none" pos="word" start_char="238">she</TOKEN>
<TOKEN end_char="249" id="token-2-6" morph="none" pos="word" start_char="242">believes</TOKEN>
<TOKEN end_char="251" id="token-2-7" morph="none" pos="punct" start_char="251">"</TOKEN>
<TOKEN end_char="256" id="token-2-8" morph="none" pos="word" start_char="252">Covid</TOKEN>
<TOKEN end_char="259" id="token-2-9" morph="none" pos="word" start_char="258">is</TOKEN>
<TOKEN end_char="261" id="token-2-10" morph="none" pos="word" start_char="261">a</TOKEN>
<TOKEN end_char="266" id="token-2-11" morph="none" pos="word" start_char="263">real</TOKEN>
<TOKEN end_char="270" id="token-2-12" morph="none" pos="word" start_char="268">and</TOKEN>
<TOKEN end_char="280" id="token-2-13" morph="none" pos="word" start_char="272">dangerous</TOKEN>
<TOKEN end_char="286" id="token-2-14" morph="none" pos="word" start_char="282">virus</TOKEN>
<TOKEN end_char="287" id="token-2-15" morph="none" pos="punct" start_char="287">"</TOKEN>
<TOKEN end_char="290" id="token-2-16" morph="none" pos="word" start_char="289">as</TOKEN>
<TOKEN end_char="294" id="token-2-17" morph="none" pos="word" start_char="292">she</TOKEN>
<TOKEN end_char="301" id="token-2-18" morph="none" pos="word" start_char="296">opened</TOKEN>
<TOKEN end_char="304" id="token-2-19" morph="none" pos="word" start_char="303">up</TOKEN>
<TOKEN end_char="306" id="token-2-20" morph="none" pos="word" start_char="306">a</TOKEN>
<TOKEN end_char="317" id="token-2-21" morph="none" pos="word" start_char="308">discussion</TOKEN>
<TOKEN end_char="320" id="token-2-22" morph="none" pos="word" start_char="319">on</TOKEN>
<TOKEN end_char="331" id="token-2-23" morph="none" pos="word" start_char="322">conspiracy</TOKEN>
<TOKEN end_char="340" id="token-2-24" morph="none" pos="word" start_char="333">theories</TOKEN>
<TOKEN end_char="347" id="token-2-25" morph="none" pos="word" start_char="342">around</TOKEN>
<TOKEN end_char="351" id="token-2-26" morph="none" pos="word" start_char="349">the</TOKEN>
<TOKEN end_char="360" id="token-2-27" morph="none" pos="word" start_char="353">pandemic</TOKEN>
<TOKEN end_char="361" id="token-2-28" morph="none" pos="punct" start_char="361">.</TOKEN>
</SEG>
<SEG end_char="364" id="segment-3" start_char="364">
<ORIGINAL_TEXT>5</ORIGINAL_TEXT>
<TOKEN end_char="364" id="token-3-0" morph="none" pos="word" start_char="364">5</TOKEN>
</SEG>
<SEG end_char="429" id="segment-4" start_char="367">
<ORIGINAL_TEXT>Fern Britton said she’s "not coping" while talking to followers</ORIGINAL_TEXT>
<TOKEN end_char="370" id="token-4-0" morph="none" pos="word" start_char="367">Fern</TOKEN>
<TOKEN end_char="378" id="token-4-1" morph="none" pos="word" start_char="372">Britton</TOKEN>
<TOKEN end_char="383" id="token-4-2" morph="none" pos="word" start_char="380">said</TOKEN>
<TOKEN end_char="389" id="token-4-3" morph="none" pos="word" start_char="385">she’s</TOKEN>
<TOKEN end_char="391" id="token-4-4" morph="none" pos="punct" start_char="391">"</TOKEN>
<TOKEN end_char="394" id="token-4-5" morph="none" pos="word" start_char="392">not</TOKEN>
<TOKEN end_char="401" id="token-4-6" morph="none" pos="word" start_char="396">coping</TOKEN>
<TOKEN end_char="402" id="token-4-7" morph="none" pos="punct" start_char="402">"</TOKEN>
<TOKEN end_char="408" id="token-4-8" morph="none" pos="word" start_char="404">while</TOKEN>
<TOKEN end_char="416" id="token-4-9" morph="none" pos="word" start_char="410">talking</TOKEN>
<TOKEN end_char="419" id="token-4-10" morph="none" pos="word" start_char="418">to</TOKEN>
<TOKEN end_char="429" id="token-4-11" morph="none" pos="word" start_char="421">followers</TOKEN>
</SEG>
<SEG end_char="600" id="segment-5" start_char="433">
<ORIGINAL_TEXT>Speaking to her followers on Twitter, Fern said: "I believe Covid is a real and dangerous virus running amok amongst the worlds population and ruining the worlds [sic.]</ORIGINAL_TEXT>
<TOKEN end_char="440" id="token-5-0" morph="none" pos="word" start_char="433">Speaking</TOKEN>
<TOKEN end_char="443" id="token-5-1" morph="none" pos="word" start_char="442">to</TOKEN>
<TOKEN end_char="447" id="token-5-2" morph="none" pos="word" start_char="445">her</TOKEN>
<TOKEN end_char="457" id="token-5-3" morph="none" pos="word" start_char="449">followers</TOKEN>
<TOKEN end_char="460" id="token-5-4" morph="none" pos="word" start_char="459">on</TOKEN>
<TOKEN end_char="468" id="token-5-5" morph="none" pos="word" start_char="462">Twitter</TOKEN>
<TOKEN end_char="469" id="token-5-6" morph="none" pos="punct" start_char="469">,</TOKEN>
<TOKEN end_char="474" id="token-5-7" morph="none" pos="word" start_char="471">Fern</TOKEN>
<TOKEN end_char="479" id="token-5-8" morph="none" pos="word" start_char="476">said</TOKEN>
<TOKEN end_char="480" id="token-5-9" morph="none" pos="punct" start_char="480">:</TOKEN>
<TOKEN end_char="482" id="token-5-10" morph="none" pos="punct" start_char="482">"</TOKEN>
<TOKEN end_char="483" id="token-5-11" morph="none" pos="word" start_char="483">I</TOKEN>
<TOKEN end_char="491" id="token-5-12" morph="none" pos="word" start_char="485">believe</TOKEN>
<TOKEN end_char="497" id="token-5-13" morph="none" pos="word" start_char="493">Covid</TOKEN>
<TOKEN end_char="500" id="token-5-14" morph="none" pos="word" start_char="499">is</TOKEN>
<TOKEN end_char="502" id="token-5-15" morph="none" pos="word" start_char="502">a</TOKEN>
<TOKEN end_char="507" id="token-5-16" morph="none" pos="word" start_char="504">real</TOKEN>
<TOKEN end_char="511" id="token-5-17" morph="none" pos="word" start_char="509">and</TOKEN>
<TOKEN end_char="521" id="token-5-18" morph="none" pos="word" start_char="513">dangerous</TOKEN>
<TOKEN end_char="527" id="token-5-19" morph="none" pos="word" start_char="523">virus</TOKEN>
<TOKEN end_char="535" id="token-5-20" morph="none" pos="word" start_char="529">running</TOKEN>
<TOKEN end_char="540" id="token-5-21" morph="none" pos="word" start_char="537">amok</TOKEN>
<TOKEN end_char="548" id="token-5-22" morph="none" pos="word" start_char="542">amongst</TOKEN>
<TOKEN end_char="552" id="token-5-23" morph="none" pos="word" start_char="550">the</TOKEN>
<TOKEN end_char="559" id="token-5-24" morph="none" pos="word" start_char="554">worlds</TOKEN>
<TOKEN end_char="570" id="token-5-25" morph="none" pos="word" start_char="561">population</TOKEN>
<TOKEN end_char="574" id="token-5-26" morph="none" pos="word" start_char="572">and</TOKEN>
<TOKEN end_char="582" id="token-5-27" morph="none" pos="word" start_char="576">ruining</TOKEN>
<TOKEN end_char="586" id="token-5-28" morph="none" pos="word" start_char="584">the</TOKEN>
<TOKEN end_char="593" id="token-5-29" morph="none" pos="word" start_char="588">worlds</TOKEN>
<TOKEN end_char="595" id="token-5-30" morph="none" pos="punct" start_char="595">[</TOKEN>
<TOKEN end_char="598" id="token-5-31" morph="none" pos="word" start_char="596">sic</TOKEN>
<TOKEN end_char="600" id="token-5-32" morph="none" pos="punct" start_char="599">.]</TOKEN>
</SEG>
<SEG end_char="609" id="segment-6" start_char="602">
<ORIGINAL_TEXT>economy.</ORIGINAL_TEXT>
<TOKEN end_char="608" id="token-6-0" morph="none" pos="word" start_char="602">economy</TOKEN>
<TOKEN end_char="609" id="token-6-1" morph="none" pos="punct" start_char="609">.</TOKEN>
<TRANSLATED_TEXT>economia.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="678" id="segment-7" start_char="612">
<ORIGINAL_TEXT>"However, if this is all a con to control us, what is the end game?</ORIGINAL_TEXT>
<TOKEN end_char="612" id="token-7-0" morph="none" pos="punct" start_char="612">"</TOKEN>
<TOKEN end_char="619" id="token-7-1" morph="none" pos="word" start_char="613">However</TOKEN>
<TOKEN end_char="620" id="token-7-2" morph="none" pos="punct" start_char="620">,</TOKEN>
<TOKEN end_char="623" id="token-7-3" morph="none" pos="word" start_char="622">if</TOKEN>
<TOKEN end_char="628" id="token-7-4" morph="none" pos="word" start_char="625">this</TOKEN>
<TOKEN end_char="631" id="token-7-5" morph="none" pos="word" start_char="630">is</TOKEN>
<TOKEN end_char="635" id="token-7-6" morph="none" pos="word" start_char="633">all</TOKEN>
<TOKEN end_char="637" id="token-7-7" morph="none" pos="word" start_char="637">a</TOKEN>
<TOKEN end_char="641" id="token-7-8" morph="none" pos="word" start_char="639">con</TOKEN>
<TOKEN end_char="644" id="token-7-9" morph="none" pos="word" start_char="643">to</TOKEN>
<TOKEN end_char="652" id="token-7-10" morph="none" pos="word" start_char="646">control</TOKEN>
<TOKEN end_char="655" id="token-7-11" morph="none" pos="word" start_char="654">us</TOKEN>
<TOKEN end_char="656" id="token-7-12" morph="none" pos="punct" start_char="656">,</TOKEN>
<TOKEN end_char="661" id="token-7-13" morph="none" pos="word" start_char="658">what</TOKEN>
<TOKEN end_char="664" id="token-7-14" morph="none" pos="word" start_char="663">is</TOKEN>
<TOKEN end_char="668" id="token-7-15" morph="none" pos="word" start_char="666">the</TOKEN>
<TOKEN end_char="672" id="token-7-16" morph="none" pos="word" start_char="670">end</TOKEN>
<TOKEN end_char="677" id="token-7-17" morph="none" pos="word" start_char="674">game</TOKEN>
<TOKEN end_char="678" id="token-7-18" morph="none" pos="punct" start_char="678">?</TOKEN>
</SEG>
<SEG end_char="710" id="segment-8" start_char="680">
<ORIGINAL_TEXT>This is an authentic question."</ORIGINAL_TEXT>
<TOKEN end_char="683" id="token-8-0" morph="none" pos="word" start_char="680">This</TOKEN>
<TOKEN end_char="686" id="token-8-1" morph="none" pos="word" start_char="685">is</TOKEN>
<TOKEN end_char="689" id="token-8-2" morph="none" pos="word" start_char="688">an</TOKEN>
<TOKEN end_char="699" id="token-8-3" morph="none" pos="word" start_char="691">authentic</TOKEN>
<TOKEN end_char="708" id="token-8-4" morph="none" pos="word" start_char="701">question</TOKEN>
<TOKEN end_char="710" id="token-8-5" morph="none" pos="punct" start_char="709">."</TOKEN>
</SEG>
<SEG end_char="792" id="segment-9" start_char="713">
<ORIGINAL_TEXT>The former This Morning presenters fans mostly agreed there wasn’t a conspiracy.</ORIGINAL_TEXT>
<TOKEN end_char="715" id="token-9-0" morph="none" pos="word" start_char="713">The</TOKEN>
<TOKEN end_char="722" id="token-9-1" morph="none" pos="word" start_char="717">former</TOKEN>
<TOKEN end_char="727" id="token-9-2" morph="none" pos="word" start_char="724">This</TOKEN>
<TOKEN end_char="735" id="token-9-3" morph="none" pos="word" start_char="729">Morning</TOKEN>
<TOKEN end_char="746" id="token-9-4" morph="none" pos="word" start_char="737">presenters</TOKEN>
<TOKEN end_char="751" id="token-9-5" morph="none" pos="word" start_char="748">fans</TOKEN>
<TOKEN end_char="758" id="token-9-6" morph="none" pos="word" start_char="753">mostly</TOKEN>
<TOKEN end_char="765" id="token-9-7" morph="none" pos="word" start_char="760">agreed</TOKEN>
<TOKEN end_char="771" id="token-9-8" morph="none" pos="word" start_char="767">there</TOKEN>
<TOKEN end_char="778" id="token-9-9" morph="none" pos="word" start_char="773">wasn’t</TOKEN>
<TOKEN end_char="780" id="token-9-10" morph="none" pos="word" start_char="780">a</TOKEN>
<TOKEN end_char="791" id="token-9-11" morph="none" pos="word" start_char="782">conspiracy</TOKEN>
<TOKEN end_char="792" id="token-9-12" morph="none" pos="punct" start_char="792">.</TOKEN>
</SEG>
<SEG end_char="882" id="segment-10" start_char="795">
<ORIGINAL_TEXT>One person said: "There isn’t is there, this is a virus Microbe not a global conspiracy.</ORIGINAL_TEXT>
<TOKEN end_char="797" id="token-10-0" morph="none" pos="word" start_char="795">One</TOKEN>
<TOKEN end_char="804" id="token-10-1" morph="none" pos="word" start_char="799">person</TOKEN>
<TOKEN end_char="809" id="token-10-2" morph="none" pos="word" start_char="806">said</TOKEN>
<TOKEN end_char="810" id="token-10-3" morph="none" pos="punct" start_char="810">:</TOKEN>
<TOKEN end_char="812" id="token-10-4" morph="none" pos="punct" start_char="812">"</TOKEN>
<TOKEN end_char="817" id="token-10-5" morph="none" pos="word" start_char="813">There</TOKEN>
<TOKEN end_char="823" id="token-10-6" morph="none" pos="word" start_char="819">isn’t</TOKEN>
<TOKEN end_char="826" id="token-10-7" morph="none" pos="word" start_char="825">is</TOKEN>
<TOKEN end_char="832" id="token-10-8" morph="none" pos="word" start_char="828">there</TOKEN>
<TOKEN end_char="833" id="token-10-9" morph="none" pos="punct" start_char="833">,</TOKEN>
<TOKEN end_char="838" id="token-10-10" morph="none" pos="word" start_char="835">this</TOKEN>
<TOKEN end_char="841" id="token-10-11" morph="none" pos="word" start_char="840">is</TOKEN>
<TOKEN end_char="843" id="token-10-12" morph="none" pos="word" start_char="843">a</TOKEN>
<TOKEN end_char="849" id="token-10-13" morph="none" pos="word" start_char="845">virus</TOKEN>
<TOKEN end_char="857" id="token-10-14" morph="none" pos="word" start_char="851">Microbe</TOKEN>
<TOKEN end_char="861" id="token-10-15" morph="none" pos="word" start_char="859">not</TOKEN>
<TOKEN end_char="863" id="token-10-16" morph="none" pos="word" start_char="863">a</TOKEN>
<TOKEN end_char="870" id="token-10-17" morph="none" pos="word" start_char="865">global</TOKEN>
<TOKEN end_char="881" id="token-10-18" morph="none" pos="word" start_char="872">conspiracy</TOKEN>
<TOKEN end_char="882" id="token-10-19" morph="none" pos="punct" start_char="882">.</TOKEN>
</SEG>
<SEG end_char="1039" id="segment-11" start_char="884">
<ORIGINAL_TEXT>We both know that and as painful as it is we have to keep chasing down anyone says otherwise, your question there is an intelligent way of doing it, thanks!</ORIGINAL_TEXT>
<TOKEN end_char="885" id="token-11-0" morph="none" pos="word" start_char="884">We</TOKEN>
<TOKEN end_char="890" id="token-11-1" morph="none" pos="word" start_char="887">both</TOKEN>
<TOKEN end_char="895" id="token-11-2" morph="none" pos="word" start_char="892">know</TOKEN>
<TOKEN end_char="900" id="token-11-3" morph="none" pos="word" start_char="897">that</TOKEN>
<TOKEN end_char="904" id="token-11-4" morph="none" pos="word" start_char="902">and</TOKEN>
<TOKEN end_char="907" id="token-11-5" morph="none" pos="word" start_char="906">as</TOKEN>
<TOKEN end_char="915" id="token-11-6" morph="none" pos="word" start_char="909">painful</TOKEN>
<TOKEN end_char="918" id="token-11-7" morph="none" pos="word" start_char="917">as</TOKEN>
<TOKEN end_char="921" id="token-11-8" morph="none" pos="word" start_char="920">it</TOKEN>
<TOKEN end_char="924" id="token-11-9" morph="none" pos="word" start_char="923">is</TOKEN>
<TOKEN end_char="927" id="token-11-10" morph="none" pos="word" start_char="926">we</TOKEN>
<TOKEN end_char="932" id="token-11-11" morph="none" pos="word" start_char="929">have</TOKEN>
<TOKEN end_char="935" id="token-11-12" morph="none" pos="word" start_char="934">to</TOKEN>
<TOKEN end_char="940" id="token-11-13" morph="none" pos="word" start_char="937">keep</TOKEN>
<TOKEN end_char="948" id="token-11-14" morph="none" pos="word" start_char="942">chasing</TOKEN>
<TOKEN end_char="953" id="token-11-15" morph="none" pos="word" start_char="950">down</TOKEN>
<TOKEN end_char="960" id="token-11-16" morph="none" pos="word" start_char="955">anyone</TOKEN>
<TOKEN end_char="965" id="token-11-17" morph="none" pos="word" start_char="962">says</TOKEN>
<TOKEN end_char="975" id="token-11-18" morph="none" pos="word" start_char="967">otherwise</TOKEN>
<TOKEN end_char="976" id="token-11-19" morph="none" pos="punct" start_char="976">,</TOKEN>
<TOKEN end_char="981" id="token-11-20" morph="none" pos="word" start_char="978">your</TOKEN>
<TOKEN end_char="990" id="token-11-21" morph="none" pos="word" start_char="983">question</TOKEN>
<TOKEN end_char="996" id="token-11-22" morph="none" pos="word" start_char="992">there</TOKEN>
<TOKEN end_char="999" id="token-11-23" morph="none" pos="word" start_char="998">is</TOKEN>
<TOKEN end_char="1002" id="token-11-24" morph="none" pos="word" start_char="1001">an</TOKEN>
<TOKEN end_char="1014" id="token-11-25" morph="none" pos="word" start_char="1004">intelligent</TOKEN>
<TOKEN end_char="1018" id="token-11-26" morph="none" pos="word" start_char="1016">way</TOKEN>
<TOKEN end_char="1021" id="token-11-27" morph="none" pos="word" start_char="1020">of</TOKEN>
<TOKEN end_char="1027" id="token-11-28" morph="none" pos="word" start_char="1023">doing</TOKEN>
<TOKEN end_char="1030" id="token-11-29" morph="none" pos="word" start_char="1029">it</TOKEN>
<TOKEN end_char="1031" id="token-11-30" morph="none" pos="punct" start_char="1031">,</TOKEN>
<TOKEN end_char="1038" id="token-11-31" morph="none" pos="word" start_char="1033">thanks</TOKEN>
<TOKEN end_char="1039" id="token-11-32" morph="none" pos="punct" start_char="1039">!</TOKEN>
</SEG>
<SEG end_char="1119" id="segment-12" start_char="1041">
<ORIGINAL_TEXT>(Shamelessly steals idea Smiling face with open mouth and tightly-closed eyes)"</ORIGINAL_TEXT>
<TOKEN end_char="1041" id="token-12-0" morph="none" pos="punct" start_char="1041">(</TOKEN>
<TOKEN end_char="1052" id="token-12-1" morph="none" pos="word" start_char="1042">Shamelessly</TOKEN>
<TOKEN end_char="1059" id="token-12-2" morph="none" pos="word" start_char="1054">steals</TOKEN>
<TOKEN end_char="1064" id="token-12-3" morph="none" pos="word" start_char="1061">idea</TOKEN>
<TOKEN end_char="1072" id="token-12-4" morph="none" pos="word" start_char="1066">Smiling</TOKEN>
<TOKEN end_char="1077" id="token-12-5" morph="none" pos="word" start_char="1074">face</TOKEN>
<TOKEN end_char="1082" id="token-12-6" morph="none" pos="word" start_char="1079">with</TOKEN>
<TOKEN end_char="1087" id="token-12-7" morph="none" pos="word" start_char="1084">open</TOKEN>
<TOKEN end_char="1093" id="token-12-8" morph="none" pos="word" start_char="1089">mouth</TOKEN>
<TOKEN end_char="1097" id="token-12-9" morph="none" pos="word" start_char="1095">and</TOKEN>
<TOKEN end_char="1112" id="token-12-10" morph="none" pos="unknown" start_char="1099">tightly-closed</TOKEN>
<TOKEN end_char="1117" id="token-12-11" morph="none" pos="word" start_char="1114">eyes</TOKEN>
<TOKEN end_char="1119" id="token-12-12" morph="none" pos="punct" start_char="1118">)"</TOKEN>
</SEG>
<SEG end_char="1130" id="segment-13" start_char="1122">
<ORIGINAL_TEXT>Twitter 5</ORIGINAL_TEXT>
<TOKEN end_char="1128" id="token-13-0" morph="none" pos="word" start_char="1122">Twitter</TOKEN>
<TOKEN end_char="1130" id="token-13-1" morph="none" pos="word" start_char="1130">5</TOKEN>
</SEG>
<SEG end_char="1181" id="segment-14" start_char="1133">
<ORIGINAL_TEXT>The star questioned the Covid conspiracy theories</ORIGINAL_TEXT>
<TOKEN end_char="1135" id="token-14-0" morph="none" pos="word" start_char="1133">The</TOKEN>
<TOKEN end_char="1140" id="token-14-1" morph="none" pos="word" start_char="1137">star</TOKEN>
<TOKEN end_char="1151" id="token-14-2" morph="none" pos="word" start_char="1142">questioned</TOKEN>
<TOKEN end_char="1155" id="token-14-3" morph="none" pos="word" start_char="1153">the</TOKEN>
<TOKEN end_char="1161" id="token-14-4" morph="none" pos="word" start_char="1157">Covid</TOKEN>
<TOKEN end_char="1172" id="token-14-5" morph="none" pos="word" start_char="1163">conspiracy</TOKEN>
<TOKEN end_char="1181" id="token-14-6" morph="none" pos="word" start_char="1174">theories</TOKEN>
</SEG>
<SEG end_char="1185" id="segment-15" start_char="1185">
<ORIGINAL_TEXT>5</ORIGINAL_TEXT>
<TOKEN end_char="1185" id="token-15-0" morph="none" pos="word" start_char="1185">5</TOKEN>
</SEG>
<SEG end_char="1242" id="segment-16" start_char="1188">
<ORIGINAL_TEXT>Fern shares the sentiment with Brits across the country</ORIGINAL_TEXT>
<TOKEN end_char="1191" id="token-16-0" morph="none" pos="word" start_char="1188">Fern</TOKEN>
<TOKEN end_char="1198" id="token-16-1" morph="none" pos="word" start_char="1193">shares</TOKEN>
<TOKEN end_char="1202" id="token-16-2" morph="none" pos="word" start_char="1200">the</TOKEN>
<TOKEN end_char="1212" id="token-16-3" morph="none" pos="word" start_char="1204">sentiment</TOKEN>
<TOKEN end_char="1217" id="token-16-4" morph="none" pos="word" start_char="1214">with</TOKEN>
<TOKEN end_char="1223" id="token-16-5" morph="none" pos="word" start_char="1219">Brits</TOKEN>
<TOKEN end_char="1230" id="token-16-6" morph="none" pos="word" start_char="1225">across</TOKEN>
<TOKEN end_char="1234" id="token-16-7" morph="none" pos="word" start_char="1232">the</TOKEN>
<TOKEN end_char="1242" id="token-16-8" morph="none" pos="word" start_char="1236">country</TOKEN>
</SEG>
<SEG end_char="1296" id="segment-17" start_char="1246">
<ORIGINAL_TEXT>Another added: "This is exactly what I keep saying!</ORIGINAL_TEXT>
<TOKEN end_char="1252" id="token-17-0" morph="none" pos="word" start_char="1246">Another</TOKEN>
<TOKEN end_char="1258" id="token-17-1" morph="none" pos="word" start_char="1254">added</TOKEN>
<TOKEN end_char="1259" id="token-17-2" morph="none" pos="punct" start_char="1259">:</TOKEN>
<TOKEN end_char="1261" id="token-17-3" morph="none" pos="punct" start_char="1261">"</TOKEN>
<TOKEN end_char="1265" id="token-17-4" morph="none" pos="word" start_char="1262">This</TOKEN>
<TOKEN end_char="1268" id="token-17-5" morph="none" pos="word" start_char="1267">is</TOKEN>
<TOKEN end_char="1276" id="token-17-6" morph="none" pos="word" start_char="1270">exactly</TOKEN>
<TOKEN end_char="1281" id="token-17-7" morph="none" pos="word" start_char="1278">what</TOKEN>
<TOKEN end_char="1283" id="token-17-8" morph="none" pos="word" start_char="1283">I</TOKEN>
<TOKEN end_char="1288" id="token-17-9" morph="none" pos="word" start_char="1285">keep</TOKEN>
<TOKEN end_char="1295" id="token-17-10" morph="none" pos="word" start_char="1290">saying</TOKEN>
<TOKEN end_char="1296" id="token-17-11" morph="none" pos="punct" start_char="1296">!</TOKEN>
</SEG>
<SEG end_char="1401" id="segment-18" start_char="1298">
<ORIGINAL_TEXT>What is the benefit to the whole world pretending there’s a virus, people losing their livelihoods, etc.</ORIGINAL_TEXT>
<TOKEN end_char="1301" id="token-18-0" morph="none" pos="word" start_char="1298">What</TOKEN>
<TOKEN end_char="1304" id="token-18-1" morph="none" pos="word" start_char="1303">is</TOKEN>
<TOKEN end_char="1308" id="token-18-2" morph="none" pos="word" start_char="1306">the</TOKEN>
<TOKEN end_char="1316" id="token-18-3" morph="none" pos="word" start_char="1310">benefit</TOKEN>
<TOKEN end_char="1319" id="token-18-4" morph="none" pos="word" start_char="1318">to</TOKEN>
<TOKEN end_char="1323" id="token-18-5" morph="none" pos="word" start_char="1321">the</TOKEN>
<TOKEN end_char="1329" id="token-18-6" morph="none" pos="word" start_char="1325">whole</TOKEN>
<TOKEN end_char="1335" id="token-18-7" morph="none" pos="word" start_char="1331">world</TOKEN>
<TOKEN end_char="1346" id="token-18-8" morph="none" pos="word" start_char="1337">pretending</TOKEN>
<TOKEN end_char="1354" id="token-18-9" morph="none" pos="word" start_char="1348">there’s</TOKEN>
<TOKEN end_char="1356" id="token-18-10" morph="none" pos="word" start_char="1356">a</TOKEN>
<TOKEN end_char="1362" id="token-18-11" morph="none" pos="word" start_char="1358">virus</TOKEN>
<TOKEN end_char="1363" id="token-18-12" morph="none" pos="punct" start_char="1363">,</TOKEN>
<TOKEN end_char="1370" id="token-18-13" morph="none" pos="word" start_char="1365">people</TOKEN>
<TOKEN end_char="1377" id="token-18-14" morph="none" pos="word" start_char="1372">losing</TOKEN>
<TOKEN end_char="1383" id="token-18-15" morph="none" pos="word" start_char="1379">their</TOKEN>
<TOKEN end_char="1395" id="token-18-16" morph="none" pos="word" start_char="1385">livelihoods</TOKEN>
<TOKEN end_char="1396" id="token-18-17" morph="none" pos="punct" start_char="1396">,</TOKEN>
<TOKEN end_char="1400" id="token-18-18" morph="none" pos="word" start_char="1398">etc</TOKEN>
<TOKEN end_char="1401" id="token-18-19" morph="none" pos="punct" start_char="1401">.</TOKEN>
</SEG>
<SEG end_char="1446" id="segment-19" start_char="1403">
<ORIGINAL_TEXT>Funny they can never answer that when I ask.</ORIGINAL_TEXT>
<TOKEN end_char="1407" id="token-19-0" morph="none" pos="word" start_char="1403">Funny</TOKEN>
<TOKEN end_char="1412" id="token-19-1" morph="none" pos="word" start_char="1409">they</TOKEN>
<TOKEN end_char="1416" id="token-19-2" morph="none" pos="word" start_char="1414">can</TOKEN>
<TOKEN end_char="1422" id="token-19-3" morph="none" pos="word" start_char="1418">never</TOKEN>
<TOKEN end_char="1429" id="token-19-4" morph="none" pos="word" start_char="1424">answer</TOKEN>
<TOKEN end_char="1434" id="token-19-5" morph="none" pos="word" start_char="1431">that</TOKEN>
<TOKEN end_char="1439" id="token-19-6" morph="none" pos="word" start_char="1436">when</TOKEN>
<TOKEN end_char="1441" id="token-19-7" morph="none" pos="word" start_char="1441">I</TOKEN>
<TOKEN end_char="1445" id="token-19-8" morph="none" pos="word" start_char="1443">ask</TOKEN>
<TOKEN end_char="1446" id="token-19-9" morph="none" pos="punct" start_char="1446">.</TOKEN>
</SEG>
<SEG end_char="1468" id="segment-20" start_char="1448">
<ORIGINAL_TEXT>Its totally bonkers!"</ORIGINAL_TEXT>
<TOKEN end_char="1450" id="token-20-0" morph="none" pos="word" start_char="1448">Its</TOKEN>
<TOKEN end_char="1458" id="token-20-1" morph="none" pos="word" start_char="1452">totally</TOKEN>
<TOKEN end_char="1466" id="token-20-2" morph="none" pos="word" start_char="1460">bonkers</TOKEN>
<TOKEN end_char="1468" id="token-20-3" morph="none" pos="punct" start_char="1467">!"</TOKEN>
</SEG>
<SEG end_char="1519" id="segment-21" start_char="1471">
<ORIGINAL_TEXT>However, one person said: "Oh god don’t say that.</ORIGINAL_TEXT>
<TOKEN end_char="1477" id="token-21-0" morph="none" pos="word" start_char="1471">However</TOKEN>
<TOKEN end_char="1478" id="token-21-1" morph="none" pos="punct" start_char="1478">,</TOKEN>
<TOKEN end_char="1482" id="token-21-2" morph="none" pos="word" start_char="1480">one</TOKEN>
<TOKEN end_char="1489" id="token-21-3" morph="none" pos="word" start_char="1484">person</TOKEN>
<TOKEN end_char="1494" id="token-21-4" morph="none" pos="word" start_char="1491">said</TOKEN>
<TOKEN end_char="1495" id="token-21-5" morph="none" pos="punct" start_char="1495">:</TOKEN>
<TOKEN end_char="1497" id="token-21-6" morph="none" pos="punct" start_char="1497">"</TOKEN>
<TOKEN end_char="1499" id="token-21-7" morph="none" pos="word" start_char="1498">Oh</TOKEN>
<TOKEN end_char="1503" id="token-21-8" morph="none" pos="word" start_char="1501">god</TOKEN>
<TOKEN end_char="1509" id="token-21-9" morph="none" pos="word" start_char="1505">don’t</TOKEN>
<TOKEN end_char="1513" id="token-21-10" morph="none" pos="word" start_char="1511">say</TOKEN>
<TOKEN end_char="1518" id="token-21-11" morph="none" pos="word" start_char="1515">that</TOKEN>
<TOKEN end_char="1519" id="token-21-12" morph="none" pos="punct" start_char="1519">.</TOKEN>
</SEG>
<SEG end_char="1545" id="segment-22" start_char="1521">
<ORIGINAL_TEXT>I’m not coping as it is."</ORIGINAL_TEXT>
<TOKEN end_char="1523" id="token-22-0" morph="none" pos="word" start_char="1521">I’m</TOKEN>
<TOKEN end_char="1527" id="token-22-1" morph="none" pos="word" start_char="1525">not</TOKEN>
<TOKEN end_char="1534" id="token-22-2" morph="none" pos="word" start_char="1529">coping</TOKEN>
<TOKEN end_char="1537" id="token-22-3" morph="none" pos="word" start_char="1536">as</TOKEN>
<TOKEN end_char="1540" id="token-22-4" morph="none" pos="word" start_char="1539">it</TOKEN>
<TOKEN end_char="1543" id="token-22-5" morph="none" pos="word" start_char="1542">is</TOKEN>
<TOKEN end_char="1545" id="token-22-6" morph="none" pos="punct" start_char="1544">."</TOKEN>
</SEG>
<SEG end_char="1580" id="segment-23" start_char="1548">
<ORIGINAL_TEXT>To which Fern replied: "Oh Grant.</ORIGINAL_TEXT>
<TOKEN end_char="1549" id="token-23-0" morph="none" pos="word" start_char="1548">To</TOKEN>
<TOKEN end_char="1555" id="token-23-1" morph="none" pos="word" start_char="1551">which</TOKEN>
<TOKEN end_char="1560" id="token-23-2" morph="none" pos="word" start_char="1557">Fern</TOKEN>
<TOKEN end_char="1568" id="token-23-3" morph="none" pos="word" start_char="1562">replied</TOKEN>
<TOKEN end_char="1569" id="token-23-4" morph="none" pos="punct" start_char="1569">:</TOKEN>
<TOKEN end_char="1571" id="token-23-5" morph="none" pos="punct" start_char="1571">"</TOKEN>
<TOKEN end_char="1573" id="token-23-6" morph="none" pos="word" start_char="1572">Oh</TOKEN>
<TOKEN end_char="1579" id="token-23-7" morph="none" pos="word" start_char="1575">Grant</TOKEN>
<TOKEN end_char="1580" id="token-23-8" morph="none" pos="punct" start_char="1580">.</TOKEN>
</SEG>
<SEG end_char="1594" id="segment-24" start_char="1582">
<ORIGINAL_TEXT>Me neither x"</ORIGINAL_TEXT>
<TOKEN end_char="1583" id="token-24-0" morph="none" pos="word" start_char="1582">Me</TOKEN>
<TOKEN end_char="1591" id="token-24-1" morph="none" pos="word" start_char="1585">neither</TOKEN>
<TOKEN end_char="1593" id="token-24-2" morph="none" pos="word" start_char="1593">x</TOKEN>
<TOKEN end_char="1594" id="token-24-3" morph="none" pos="punct" start_char="1594">"</TOKEN>
<TRANSLATED_TEXT>Me neither x "</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="1720" id="segment-25" start_char="1597">
<ORIGINAL_TEXT>The best-selling author has been living in Cornwall since she split with her husband Phil Vickery in January after 20 years.</ORIGINAL_TEXT>
<TOKEN end_char="1599" id="token-25-0" morph="none" pos="word" start_char="1597">The</TOKEN>
<TOKEN end_char="1612" id="token-25-1" morph="none" pos="unknown" start_char="1601">best-selling</TOKEN>
<TOKEN end_char="1619" id="token-25-2" morph="none" pos="word" start_char="1614">author</TOKEN>
<TOKEN end_char="1623" id="token-25-3" morph="none" pos="word" start_char="1621">has</TOKEN>
<TOKEN end_char="1628" id="token-25-4" morph="none" pos="word" start_char="1625">been</TOKEN>
<TOKEN end_char="1635" id="token-25-5" morph="none" pos="word" start_char="1630">living</TOKEN>
<TOKEN end_char="1638" id="token-25-6" morph="none" pos="word" start_char="1637">in</TOKEN>
<TOKEN end_char="1647" id="token-25-7" morph="none" pos="word" start_char="1640">Cornwall</TOKEN>
<TOKEN end_char="1653" id="token-25-8" morph="none" pos="word" start_char="1649">since</TOKEN>
<TOKEN end_char="1657" id="token-25-9" morph="none" pos="word" start_char="1655">she</TOKEN>
<TOKEN end_char="1663" id="token-25-10" morph="none" pos="word" start_char="1659">split</TOKEN>
<TOKEN end_char="1668" id="token-25-11" morph="none" pos="word" start_char="1665">with</TOKEN>
<TOKEN end_char="1672" id="token-25-12" morph="none" pos="word" start_char="1670">her</TOKEN>
<TOKEN end_char="1680" id="token-25-13" morph="none" pos="word" start_char="1674">husband</TOKEN>
<TOKEN end_char="1685" id="token-25-14" morph="none" pos="word" start_char="1682">Phil</TOKEN>
<TOKEN end_char="1693" id="token-25-15" morph="none" pos="word" start_char="1687">Vickery</TOKEN>
<TOKEN end_char="1696" id="token-25-16" morph="none" pos="word" start_char="1695">in</TOKEN>
<TOKEN end_char="1704" id="token-25-17" morph="none" pos="word" start_char="1698">January</TOKEN>
<TOKEN end_char="1710" id="token-25-18" morph="none" pos="word" start_char="1706">after</TOKEN>
<TOKEN end_char="1713" id="token-25-19" morph="none" pos="word" start_char="1712">20</TOKEN>
<TOKEN end_char="1719" id="token-25-20" morph="none" pos="word" start_char="1715">years</TOKEN>
<TOKEN end_char="1720" id="token-25-21" morph="none" pos="punct" start_char="1720">.</TOKEN>
</SEG>
<SEG end_char="1723" id="segment-26" start_char="1723">
<ORIGINAL_TEXT>5</ORIGINAL_TEXT>
<TOKEN end_char="1723" id="token-26-0" morph="none" pos="word" start_char="1723">5</TOKEN>
</SEG>
<SEG end_char="1763" id="segment-27" start_char="1726">
<ORIGINAL_TEXT>Fern split with Phil Vickery last year</ORIGINAL_TEXT>
<TOKEN end_char="1729" id="token-27-0" morph="none" pos="word" start_char="1726">Fern</TOKEN>
<TOKEN end_char="1735" id="token-27-1" morph="none" pos="word" start_char="1731">split</TOKEN>
<TOKEN end_char="1740" id="token-27-2" morph="none" pos="word" start_char="1737">with</TOKEN>
<TOKEN end_char="1745" id="token-27-3" morph="none" pos="word" start_char="1742">Phil</TOKEN>
<TOKEN end_char="1753" id="token-27-4" morph="none" pos="word" start_char="1747">Vickery</TOKEN>
<TOKEN end_char="1758" id="token-27-5" morph="none" pos="word" start_char="1755">last</TOKEN>
<TOKEN end_char="1763" id="token-27-6" morph="none" pos="word" start_char="1760">year</TOKEN>
</SEG>
<SEG end_char="1957" id="segment-28" start_char="1767">
<ORIGINAL_TEXT>The mum-of-four – who was previously married to TV exec Clive Jones – admitted in November that she misses the company of a man – but has decided she doesn’t want another partner in her life.</ORIGINAL_TEXT>
<TOKEN end_char="1769" id="token-28-0" morph="none" pos="word" start_char="1767">The</TOKEN>
<TOKEN end_char="1781" id="token-28-1" morph="none" pos="unknown" start_char="1771">mum-of-four</TOKEN>
<TOKEN end_char="1783" id="token-28-2" morph="none" pos="punct" start_char="1783">–</TOKEN>
<TOKEN end_char="1787" id="token-28-3" morph="none" pos="word" start_char="1785">who</TOKEN>
<TOKEN end_char="1791" id="token-28-4" morph="none" pos="word" start_char="1789">was</TOKEN>
<TOKEN end_char="1802" id="token-28-5" morph="none" pos="word" start_char="1793">previously</TOKEN>
<TOKEN end_char="1810" id="token-28-6" morph="none" pos="word" start_char="1804">married</TOKEN>
<TOKEN end_char="1813" id="token-28-7" morph="none" pos="word" start_char="1812">to</TOKEN>
<TOKEN end_char="1816" id="token-28-8" morph="none" pos="word" start_char="1815">TV</TOKEN>
<TOKEN end_char="1821" id="token-28-9" morph="none" pos="word" start_char="1818">exec</TOKEN>
<TOKEN end_char="1827" id="token-28-10" morph="none" pos="word" start_char="1823">Clive</TOKEN>
<TOKEN end_char="1833" id="token-28-11" morph="none" pos="word" start_char="1829">Jones</TOKEN>
<TOKEN end_char="1835" id="token-28-12" morph="none" pos="punct" start_char="1835">–</TOKEN>
<TOKEN end_char="1844" id="token-28-13" morph="none" pos="word" start_char="1837">admitted</TOKEN>
<TOKEN end_char="1847" id="token-28-14" morph="none" pos="word" start_char="1846">in</TOKEN>
<TOKEN end_char="1856" id="token-28-15" morph="none" pos="word" start_char="1849">November</TOKEN>
<TOKEN end_char="1861" id="token-28-16" morph="none" pos="word" start_char="1858">that</TOKEN>
<TOKEN end_char="1865" id="token-28-17" morph="none" pos="word" start_char="1863">she</TOKEN>
<TOKEN end_char="1872" id="token-28-18" morph="none" pos="word" start_char="1867">misses</TOKEN>
<TOKEN end_char="1876" id="token-28-19" morph="none" pos="word" start_char="1874">the</TOKEN>
<TOKEN end_char="1884" id="token-28-20" morph="none" pos="word" start_char="1878">company</TOKEN>
<TOKEN end_char="1887" id="token-28-21" morph="none" pos="word" start_char="1886">of</TOKEN>
<TOKEN end_char="1889" id="token-28-22" morph="none" pos="word" start_char="1889">a</TOKEN>
<TOKEN end_char="1893" id="token-28-23" morph="none" pos="word" start_char="1891">man</TOKEN>
<TOKEN end_char="1895" id="token-28-24" morph="none" pos="punct" start_char="1895">–</TOKEN>
<TOKEN end_char="1899" id="token-28-25" morph="none" pos="word" start_char="1897">but</TOKEN>
<TOKEN end_char="1903" id="token-28-26" morph="none" pos="word" start_char="1901">has</TOKEN>
<TOKEN end_char="1911" id="token-28-27" morph="none" pos="word" start_char="1905">decided</TOKEN>
<TOKEN end_char="1915" id="token-28-28" morph="none" pos="word" start_char="1913">she</TOKEN>
<TOKEN end_char="1923" id="token-28-29" morph="none" pos="word" start_char="1917">doesn’t</TOKEN>
<TOKEN end_char="1928" id="token-28-30" morph="none" pos="word" start_char="1925">want</TOKEN>
<TOKEN end_char="1936" id="token-28-31" morph="none" pos="word" start_char="1930">another</TOKEN>
<TOKEN end_char="1944" id="token-28-32" morph="none" pos="word" start_char="1938">partner</TOKEN>
<TOKEN end_char="1947" id="token-28-33" morph="none" pos="word" start_char="1946">in</TOKEN>
<TOKEN end_char="1951" id="token-28-34" morph="none" pos="word" start_char="1949">her</TOKEN>
<TOKEN end_char="1956" id="token-28-35" morph="none" pos="word" start_char="1953">life</TOKEN>
<TOKEN end_char="1957" id="token-28-36" morph="none" pos="punct" start_char="1957">.</TOKEN>
</SEG>
<SEG end_char="2205" id="segment-29" start_char="1960">
<ORIGINAL_TEXT>She told The Mirror: "That’s not to say I don’t miss being married, because I have been married to two incredible husbands for over 30 years, so I have been married for a very long time – two very interesting men who survived being married to me.</ORIGINAL_TEXT>
<TOKEN end_char="1962" id="token-29-0" morph="none" pos="word" start_char="1960">She</TOKEN>
<TOKEN end_char="1967" id="token-29-1" morph="none" pos="word" start_char="1964">told</TOKEN>
<TOKEN end_char="1971" id="token-29-2" morph="none" pos="word" start_char="1969">The</TOKEN>
<TOKEN end_char="1978" id="token-29-3" morph="none" pos="word" start_char="1973">Mirror</TOKEN>
<TOKEN end_char="1979" id="token-29-4" morph="none" pos="punct" start_char="1979">:</TOKEN>
<TOKEN end_char="1981" id="token-29-5" morph="none" pos="punct" start_char="1981">"</TOKEN>
<TOKEN end_char="1987" id="token-29-6" morph="none" pos="word" start_char="1982">That’s</TOKEN>
<TOKEN end_char="1991" id="token-29-7" morph="none" pos="word" start_char="1989">not</TOKEN>
<TOKEN end_char="1994" id="token-29-8" morph="none" pos="word" start_char="1993">to</TOKEN>
<TOKEN end_char="1998" id="token-29-9" morph="none" pos="word" start_char="1996">say</TOKEN>
<TOKEN end_char="2000" id="token-29-10" morph="none" pos="word" start_char="2000">I</TOKEN>
<TOKEN end_char="2006" id="token-29-11" morph="none" pos="word" start_char="2002">don’t</TOKEN>
<TOKEN end_char="2011" id="token-29-12" morph="none" pos="word" start_char="2008">miss</TOKEN>
<TOKEN end_char="2017" id="token-29-13" morph="none" pos="word" start_char="2013">being</TOKEN>
<TOKEN end_char="2025" id="token-29-14" morph="none" pos="word" start_char="2019">married</TOKEN>
<TOKEN end_char="2026" id="token-29-15" morph="none" pos="punct" start_char="2026">,</TOKEN>
<TOKEN end_char="2034" id="token-29-16" morph="none" pos="word" start_char="2028">because</TOKEN>
<TOKEN end_char="2036" id="token-29-17" morph="none" pos="word" start_char="2036">I</TOKEN>
<TOKEN end_char="2041" id="token-29-18" morph="none" pos="word" start_char="2038">have</TOKEN>
<TOKEN end_char="2046" id="token-29-19" morph="none" pos="word" start_char="2043">been</TOKEN>
<TOKEN end_char="2054" id="token-29-20" morph="none" pos="word" start_char="2048">married</TOKEN>
<TOKEN end_char="2057" id="token-29-21" morph="none" pos="word" start_char="2056">to</TOKEN>
<TOKEN end_char="2061" id="token-29-22" morph="none" pos="word" start_char="2059">two</TOKEN>
<TOKEN end_char="2072" id="token-29-23" morph="none" pos="word" start_char="2063">incredible</TOKEN>
<TOKEN end_char="2081" id="token-29-24" morph="none" pos="word" start_char="2074">husbands</TOKEN>
<TOKEN end_char="2085" id="token-29-25" morph="none" pos="word" start_char="2083">for</TOKEN>
<TOKEN end_char="2090" id="token-29-26" morph="none" pos="word" start_char="2087">over</TOKEN>
<TOKEN end_char="2093" id="token-29-27" morph="none" pos="word" start_char="2092">30</TOKEN>
<TOKEN end_char="2099" id="token-29-28" morph="none" pos="word" start_char="2095">years</TOKEN>
<TOKEN end_char="2100" id="token-29-29" morph="none" pos="punct" start_char="2100">,</TOKEN>
<TOKEN end_char="2103" id="token-29-30" morph="none" pos="word" start_char="2102">so</TOKEN>
<TOKEN end_char="2105" id="token-29-31" morph="none" pos="word" start_char="2105">I</TOKEN>
<TOKEN end_char="2110" id="token-29-32" morph="none" pos="word" start_char="2107">have</TOKEN>
<TOKEN end_char="2115" id="token-29-33" morph="none" pos="word" start_char="2112">been</TOKEN>
<TOKEN end_char="2123" id="token-29-34" morph="none" pos="word" start_char="2117">married</TOKEN>
<TOKEN end_char="2127" id="token-29-35" morph="none" pos="word" start_char="2125">for</TOKEN>
<TOKEN end_char="2129" id="token-29-36" morph="none" pos="word" start_char="2129">a</TOKEN>
<TOKEN end_char="2134" id="token-29-37" morph="none" pos="word" start_char="2131">very</TOKEN>
<TOKEN end_char="2139" id="token-29-38" morph="none" pos="word" start_char="2136">long</TOKEN>
<TOKEN end_char="2144" id="token-29-39" morph="none" pos="word" start_char="2141">time</TOKEN>
<TOKEN end_char="2146" id="token-29-40" morph="none" pos="punct" start_char="2146">–</TOKEN>
<TOKEN end_char="2150" id="token-29-41" morph="none" pos="word" start_char="2148">two</TOKEN>
<TOKEN end_char="2155" id="token-29-42" morph="none" pos="word" start_char="2152">very</TOKEN>
<TOKEN end_char="2167" id="token-29-43" morph="none" pos="word" start_char="2157">interesting</TOKEN>
<TOKEN end_char="2171" id="token-29-44" morph="none" pos="word" start_char="2169">men</TOKEN>
<TOKEN end_char="2175" id="token-29-45" morph="none" pos="word" start_char="2173">who</TOKEN>
<TOKEN end_char="2184" id="token-29-46" morph="none" pos="word" start_char="2177">survived</TOKEN>
<TOKEN end_char="2190" id="token-29-47" morph="none" pos="word" start_char="2186">being</TOKEN>
<TOKEN end_char="2198" id="token-29-48" morph="none" pos="word" start_char="2192">married</TOKEN>
<TOKEN end_char="2201" id="token-29-49" morph="none" pos="word" start_char="2200">to</TOKEN>
<TOKEN end_char="2204" id="token-29-50" morph="none" pos="word" start_char="2203">me</TOKEN>
<TOKEN end_char="2205" id="token-29-51" morph="none" pos="punct" start_char="2205">.</TOKEN>
</SEG>
<SEG end_char="2303" id="segment-30" start_char="2208">
<ORIGINAL_TEXT>"It is difficult and it is painful but let’s skip over that… I am not looking for anybody else."</ORIGINAL_TEXT>
<TOKEN end_char="2208" id="token-30-0" morph="none" pos="punct" start_char="2208">"</TOKEN>
<TOKEN end_char="2210" id="token-30-1" morph="none" pos="word" start_char="2209">It</TOKEN>
<TOKEN end_char="2213" id="token-30-2" morph="none" pos="word" start_char="2212">is</TOKEN>
<TOKEN end_char="2223" id="token-30-3" morph="none" pos="word" start_char="2215">difficult</TOKEN>
<TOKEN end_char="2227" id="token-30-4" morph="none" pos="word" start_char="2225">and</TOKEN>
<TOKEN end_char="2230" id="token-30-5" morph="none" pos="word" start_char="2229">it</TOKEN>
<TOKEN end_char="2233" id="token-30-6" morph="none" pos="word" start_char="2232">is</TOKEN>
<TOKEN end_char="2241" id="token-30-7" morph="none" pos="word" start_char="2235">painful</TOKEN>
<TOKEN end_char="2245" id="token-30-8" morph="none" pos="word" start_char="2243">but</TOKEN>
<TOKEN end_char="2251" id="token-30-9" morph="none" pos="word" start_char="2247">let’s</TOKEN>
<TOKEN end_char="2256" id="token-30-10" morph="none" pos="word" start_char="2253">skip</TOKEN>
<TOKEN end_char="2261" id="token-30-11" morph="none" pos="word" start_char="2258">over</TOKEN>
<TOKEN end_char="2266" id="token-30-12" morph="none" pos="word" start_char="2263">that</TOKEN>
<TOKEN end_char="2267" id="token-30-13" morph="none" pos="punct" start_char="2267">…</TOKEN>
<TOKEN end_char="2269" id="token-30-14" morph="none" pos="word" start_char="2269">I</TOKEN>
<TOKEN end_char="2272" id="token-30-15" morph="none" pos="word" start_char="2271">am</TOKEN>
<TOKEN end_char="2276" id="token-30-16" morph="none" pos="word" start_char="2274">not</TOKEN>
<TOKEN end_char="2284" id="token-30-17" morph="none" pos="word" start_char="2278">looking</TOKEN>
<TOKEN end_char="2288" id="token-30-18" morph="none" pos="word" start_char="2286">for</TOKEN>
<TOKEN end_char="2296" id="token-30-19" morph="none" pos="word" start_char="2290">anybody</TOKEN>
<TOKEN end_char="2301" id="token-30-20" morph="none" pos="word" start_char="2298">else</TOKEN>
<TOKEN end_char="2303" id="token-30-21" morph="none" pos="punct" start_char="2302">."</TOKEN>
</SEG>
<SEG end_char="2441" id="segment-31" start_char="2306">
<ORIGINAL_TEXT>Ferne also admitted she enjoys having "autonomy" over her time and "what I want to do", adding that she plans to travel the world at 70.</ORIGINAL_TEXT>
<TOKEN end_char="2310" id="token-31-0" morph="none" pos="word" start_char="2306">Ferne</TOKEN>
<TOKEN end_char="2315" id="token-31-1" morph="none" pos="word" start_char="2312">also</TOKEN>
<TOKEN end_char="2324" id="token-31-2" morph="none" pos="word" start_char="2317">admitted</TOKEN>
<TOKEN end_char="2328" id="token-31-3" morph="none" pos="word" start_char="2326">she</TOKEN>
<TOKEN end_char="2335" id="token-31-4" morph="none" pos="word" start_char="2330">enjoys</TOKEN>
<TOKEN end_char="2342" id="token-31-5" morph="none" pos="word" start_char="2337">having</TOKEN>
<TOKEN end_char="2344" id="token-31-6" morph="none" pos="punct" start_char="2344">"</TOKEN>
<TOKEN end_char="2352" id="token-31-7" morph="none" pos="word" start_char="2345">autonomy</TOKEN>
<TOKEN end_char="2353" id="token-31-8" morph="none" pos="punct" start_char="2353">"</TOKEN>
<TOKEN end_char="2358" id="token-31-9" morph="none" pos="word" start_char="2355">over</TOKEN>
<TOKEN end_char="2362" id="token-31-10" morph="none" pos="word" start_char="2360">her</TOKEN>
<TOKEN end_char="2367" id="token-31-11" morph="none" pos="word" start_char="2364">time</TOKEN>
<TOKEN end_char="2371" id="token-31-12" morph="none" pos="word" start_char="2369">and</TOKEN>
<TOKEN end_char="2373" id="token-31-13" morph="none" pos="punct" start_char="2373">"</TOKEN>
<TOKEN end_char="2377" id="token-31-14" morph="none" pos="word" start_char="2374">what</TOKEN>
<TOKEN end_char="2379" id="token-31-15" morph="none" pos="word" start_char="2379">I</TOKEN>
<TOKEN end_char="2384" id="token-31-16" morph="none" pos="word" start_char="2381">want</TOKEN>
<TOKEN end_char="2387" id="token-31-17" morph="none" pos="word" start_char="2386">to</TOKEN>
<TOKEN end_char="2390" id="token-31-18" morph="none" pos="word" start_char="2389">do</TOKEN>
<TOKEN end_char="2392" id="token-31-19" morph="none" pos="punct" start_char="2391">",</TOKEN>
<TOKEN end_char="2399" id="token-31-20" morph="none" pos="word" start_char="2394">adding</TOKEN>
<TOKEN end_char="2404" id="token-31-21" morph="none" pos="word" start_char="2401">that</TOKEN>
<TOKEN end_char="2408" id="token-31-22" morph="none" pos="word" start_char="2406">she</TOKEN>
<TOKEN end_char="2414" id="token-31-23" morph="none" pos="word" start_char="2410">plans</TOKEN>
<TOKEN end_char="2417" id="token-31-24" morph="none" pos="word" start_char="2416">to</TOKEN>
<TOKEN end_char="2424" id="token-31-25" morph="none" pos="word" start_char="2419">travel</TOKEN>
<TOKEN end_char="2428" id="token-31-26" morph="none" pos="word" start_char="2426">the</TOKEN>
<TOKEN end_char="2434" id="token-31-27" morph="none" pos="word" start_char="2430">world</TOKEN>
<TOKEN end_char="2437" id="token-31-28" morph="none" pos="word" start_char="2436">at</TOKEN>
<TOKEN end_char="2440" id="token-31-29" morph="none" pos="word" start_char="2439">70</TOKEN>
<TOKEN end_char="2441" id="token-31-30" morph="none" pos="punct" start_char="2441">.</TOKEN>
</SEG>
<SEG end_char="2543" id="segment-32" start_char="2444">
<ORIGINAL_TEXT>Meanwhile, Phil has exchanged a string of messages with Yorkshire Dales sheep farmer Alison O’Neill.</ORIGINAL_TEXT>
<TOKEN end_char="2452" id="token-32-0" morph="none" pos="word" start_char="2444">Meanwhile</TOKEN>
<TOKEN end_char="2453" id="token-32-1" morph="none" pos="punct" start_char="2453">,</TOKEN>
<TOKEN end_char="2458" id="token-32-2" morph="none" pos="word" start_char="2455">Phil</TOKEN>
<TOKEN end_char="2462" id="token-32-3" morph="none" pos="word" start_char="2460">has</TOKEN>
<TOKEN end_char="2472" id="token-32-4" morph="none" pos="word" start_char="2464">exchanged</TOKEN>
<TOKEN end_char="2474" id="token-32-5" morph="none" pos="word" start_char="2474">a</TOKEN>
<TOKEN end_char="2481" id="token-32-6" morph="none" pos="word" start_char="2476">string</TOKEN>
<TOKEN end_char="2484" id="token-32-7" morph="none" pos="word" start_char="2483">of</TOKEN>
<TOKEN end_char="2493" id="token-32-8" morph="none" pos="word" start_char="2486">messages</TOKEN>
<TOKEN end_char="2498" id="token-32-9" morph="none" pos="word" start_char="2495">with</TOKEN>
<TOKEN end_char="2508" id="token-32-10" morph="none" pos="word" start_char="2500">Yorkshire</TOKEN>
<TOKEN end_char="2514" id="token-32-11" morph="none" pos="word" start_char="2510">Dales</TOKEN>
<TOKEN end_char="2520" id="token-32-12" morph="none" pos="word" start_char="2516">sheep</TOKEN>
<TOKEN end_char="2527" id="token-32-13" morph="none" pos="word" start_char="2522">farmer</TOKEN>
<TOKEN end_char="2534" id="token-32-14" morph="none" pos="word" start_char="2529">Alison</TOKEN>
<TOKEN end_char="2542" id="token-32-15" morph="none" pos="word" start_char="2536">O’Neill</TOKEN>
<TOKEN end_char="2543" id="token-32-16" morph="none" pos="punct" start_char="2543">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
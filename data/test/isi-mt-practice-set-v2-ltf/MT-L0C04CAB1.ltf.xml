<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CAB1" lang="spa" raw_text_char_length="3434" raw_text_md5="cb422a2c2ce774ac7ea6ec4963f4eb07" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="75" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Chinese scientists now claim coronavirus originated in India in summer 2019</ORIGINAL_TEXT>
<TOKEN end_char="7" id="token-0-0" morph="none" pos="word" start_char="1">Chinese</TOKEN>
<TOKEN end_char="18" id="token-0-1" morph="none" pos="word" start_char="9">scientists</TOKEN>
<TOKEN end_char="22" id="token-0-2" morph="none" pos="word" start_char="20">now</TOKEN>
<TOKEN end_char="28" id="token-0-3" morph="none" pos="word" start_char="24">claim</TOKEN>
<TOKEN end_char="40" id="token-0-4" morph="none" pos="word" start_char="30">coronavirus</TOKEN>
<TOKEN end_char="51" id="token-0-5" morph="none" pos="word" start_char="42">originated</TOKEN>
<TOKEN end_char="54" id="token-0-6" morph="none" pos="word" start_char="53">in</TOKEN>
<TOKEN end_char="60" id="token-0-7" morph="none" pos="word" start_char="56">India</TOKEN>
<TOKEN end_char="63" id="token-0-8" morph="none" pos="word" start_char="62">in</TOKEN>
<TOKEN end_char="70" id="token-0-9" morph="none" pos="word" start_char="65">summer</TOKEN>
<TOKEN end_char="75" id="token-0-10" morph="none" pos="word" start_char="72">2019</TOKEN>
</SEG>
<SEG end_char="169" id="segment-1" start_char="80">
<ORIGINAL_TEXT>Beijing has for long been trying to shift the blame for the outbreak of novel coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="86" id="token-1-0" morph="none" pos="word" start_char="80">Beijing</TOKEN>
<TOKEN end_char="90" id="token-1-1" morph="none" pos="word" start_char="88">has</TOKEN>
<TOKEN end_char="94" id="token-1-2" morph="none" pos="word" start_char="92">for</TOKEN>
<TOKEN end_char="99" id="token-1-3" morph="none" pos="word" start_char="96">long</TOKEN>
<TOKEN end_char="104" id="token-1-4" morph="none" pos="word" start_char="101">been</TOKEN>
<TOKEN end_char="111" id="token-1-5" morph="none" pos="word" start_char="106">trying</TOKEN>
<TOKEN end_char="114" id="token-1-6" morph="none" pos="word" start_char="113">to</TOKEN>
<TOKEN end_char="120" id="token-1-7" morph="none" pos="word" start_char="116">shift</TOKEN>
<TOKEN end_char="124" id="token-1-8" morph="none" pos="word" start_char="122">the</TOKEN>
<TOKEN end_char="130" id="token-1-9" morph="none" pos="word" start_char="126">blame</TOKEN>
<TOKEN end_char="134" id="token-1-10" morph="none" pos="word" start_char="132">for</TOKEN>
<TOKEN end_char="138" id="token-1-11" morph="none" pos="word" start_char="136">the</TOKEN>
<TOKEN end_char="147" id="token-1-12" morph="none" pos="word" start_char="140">outbreak</TOKEN>
<TOKEN end_char="150" id="token-1-13" morph="none" pos="word" start_char="149">of</TOKEN>
<TOKEN end_char="156" id="token-1-14" morph="none" pos="word" start_char="152">novel</TOKEN>
<TOKEN end_char="168" id="token-1-15" morph="none" pos="word" start_char="158">coronavirus</TOKEN>
<TOKEN end_char="169" id="token-1-16" morph="none" pos="punct" start_char="169">.</TOKEN>
</SEG>
<SEG end_char="274" id="segment-2" start_char="171">
<ORIGINAL_TEXT>It was Europe first, and now Chinese researchers have claimed that the deadly virus originated in India.</ORIGINAL_TEXT>
<TOKEN end_char="172" id="token-2-0" morph="none" pos="word" start_char="171">It</TOKEN>
<TOKEN end_char="176" id="token-2-1" morph="none" pos="word" start_char="174">was</TOKEN>
<TOKEN end_char="183" id="token-2-2" morph="none" pos="word" start_char="178">Europe</TOKEN>
<TOKEN end_char="189" id="token-2-3" morph="none" pos="word" start_char="185">first</TOKEN>
<TOKEN end_char="190" id="token-2-4" morph="none" pos="punct" start_char="190">,</TOKEN>
<TOKEN end_char="194" id="token-2-5" morph="none" pos="word" start_char="192">and</TOKEN>
<TOKEN end_char="198" id="token-2-6" morph="none" pos="word" start_char="196">now</TOKEN>
<TOKEN end_char="206" id="token-2-7" morph="none" pos="word" start_char="200">Chinese</TOKEN>
<TOKEN end_char="218" id="token-2-8" morph="none" pos="word" start_char="208">researchers</TOKEN>
<TOKEN end_char="223" id="token-2-9" morph="none" pos="word" start_char="220">have</TOKEN>
<TOKEN end_char="231" id="token-2-10" morph="none" pos="word" start_char="225">claimed</TOKEN>
<TOKEN end_char="236" id="token-2-11" morph="none" pos="word" start_char="233">that</TOKEN>
<TOKEN end_char="240" id="token-2-12" morph="none" pos="word" start_char="238">the</TOKEN>
<TOKEN end_char="247" id="token-2-13" morph="none" pos="word" start_char="242">deadly</TOKEN>
<TOKEN end_char="253" id="token-2-14" morph="none" pos="word" start_char="249">virus</TOKEN>
<TOKEN end_char="264" id="token-2-15" morph="none" pos="word" start_char="255">originated</TOKEN>
<TOKEN end_char="267" id="token-2-16" morph="none" pos="word" start_char="266">in</TOKEN>
<TOKEN end_char="273" id="token-2-17" morph="none" pos="word" start_char="269">India</TOKEN>
<TOKEN end_char="274" id="token-2-18" morph="none" pos="punct" start_char="274">.</TOKEN>
</SEG>
<SEG end_char="443" id="segment-3" start_char="277">
<ORIGINAL_TEXT>A team from the Chinese Academy of Sciences argues the virus likely originated in India in the summer of 2019 -- jumping from animals to humans via contaminated water.</ORIGINAL_TEXT>
<TOKEN end_char="277" id="token-3-0" morph="none" pos="word" start_char="277">A</TOKEN>
<TOKEN end_char="282" id="token-3-1" morph="none" pos="word" start_char="279">team</TOKEN>
<TOKEN end_char="287" id="token-3-2" morph="none" pos="word" start_char="284">from</TOKEN>
<TOKEN end_char="291" id="token-3-3" morph="none" pos="word" start_char="289">the</TOKEN>
<TOKEN end_char="299" id="token-3-4" morph="none" pos="word" start_char="293">Chinese</TOKEN>
<TOKEN end_char="307" id="token-3-5" morph="none" pos="word" start_char="301">Academy</TOKEN>
<TOKEN end_char="310" id="token-3-6" morph="none" pos="word" start_char="309">of</TOKEN>
<TOKEN end_char="319" id="token-3-7" morph="none" pos="word" start_char="312">Sciences</TOKEN>
<TOKEN end_char="326" id="token-3-8" morph="none" pos="word" start_char="321">argues</TOKEN>
<TOKEN end_char="330" id="token-3-9" morph="none" pos="word" start_char="328">the</TOKEN>
<TOKEN end_char="336" id="token-3-10" morph="none" pos="word" start_char="332">virus</TOKEN>
<TOKEN end_char="343" id="token-3-11" morph="none" pos="word" start_char="338">likely</TOKEN>
<TOKEN end_char="354" id="token-3-12" morph="none" pos="word" start_char="345">originated</TOKEN>
<TOKEN end_char="357" id="token-3-13" morph="none" pos="word" start_char="356">in</TOKEN>
<TOKEN end_char="363" id="token-3-14" morph="none" pos="word" start_char="359">India</TOKEN>
<TOKEN end_char="366" id="token-3-15" morph="none" pos="word" start_char="365">in</TOKEN>
<TOKEN end_char="370" id="token-3-16" morph="none" pos="word" start_char="368">the</TOKEN>
<TOKEN end_char="377" id="token-3-17" morph="none" pos="word" start_char="372">summer</TOKEN>
<TOKEN end_char="380" id="token-3-18" morph="none" pos="word" start_char="379">of</TOKEN>
<TOKEN end_char="385" id="token-3-19" morph="none" pos="word" start_char="382">2019</TOKEN>
<TOKEN end_char="388" id="token-3-20" morph="none" pos="punct" start_char="387">--</TOKEN>
<TOKEN end_char="396" id="token-3-21" morph="none" pos="word" start_char="390">jumping</TOKEN>
<TOKEN end_char="401" id="token-3-22" morph="none" pos="word" start_char="398">from</TOKEN>
<TOKEN end_char="409" id="token-3-23" morph="none" pos="word" start_char="403">animals</TOKEN>
<TOKEN end_char="412" id="token-3-24" morph="none" pos="word" start_char="411">to</TOKEN>
<TOKEN end_char="419" id="token-3-25" morph="none" pos="word" start_char="414">humans</TOKEN>
<TOKEN end_char="423" id="token-3-26" morph="none" pos="word" start_char="421">via</TOKEN>
<TOKEN end_char="436" id="token-3-27" morph="none" pos="word" start_char="425">contaminated</TOKEN>
<TOKEN end_char="442" id="token-3-28" morph="none" pos="word" start_char="438">water</TOKEN>
<TOKEN end_char="443" id="token-3-29" morph="none" pos="punct" start_char="443">.</TOKEN>
</SEG>
<SEG end_char="521" id="segment-4" start_char="446">
<ORIGINAL_TEXT>They said it then travelled unnoticed to Wuhan, where it was first detected.</ORIGINAL_TEXT>
<TOKEN end_char="449" id="token-4-0" morph="none" pos="word" start_char="446">They</TOKEN>
<TOKEN end_char="454" id="token-4-1" morph="none" pos="word" start_char="451">said</TOKEN>
<TOKEN end_char="457" id="token-4-2" morph="none" pos="word" start_char="456">it</TOKEN>
<TOKEN end_char="462" id="token-4-3" morph="none" pos="word" start_char="459">then</TOKEN>
<TOKEN end_char="472" id="token-4-4" morph="none" pos="word" start_char="464">travelled</TOKEN>
<TOKEN end_char="482" id="token-4-5" morph="none" pos="word" start_char="474">unnoticed</TOKEN>
<TOKEN end_char="485" id="token-4-6" morph="none" pos="word" start_char="484">to</TOKEN>
<TOKEN end_char="491" id="token-4-7" morph="none" pos="word" start_char="487">Wuhan</TOKEN>
<TOKEN end_char="492" id="token-4-8" morph="none" pos="punct" start_char="492">,</TOKEN>
<TOKEN end_char="498" id="token-4-9" morph="none" pos="word" start_char="494">where</TOKEN>
<TOKEN end_char="501" id="token-4-10" morph="none" pos="word" start_char="500">it</TOKEN>
<TOKEN end_char="505" id="token-4-11" morph="none" pos="word" start_char="503">was</TOKEN>
<TOKEN end_char="511" id="token-4-12" morph="none" pos="word" start_char="507">first</TOKEN>
<TOKEN end_char="520" id="token-4-13" morph="none" pos="word" start_char="513">detected</TOKEN>
<TOKEN end_char="521" id="token-4-14" morph="none" pos="punct" start_char="521">.</TOKEN>
</SEG>
<SEG end_char="640" id="segment-5" start_char="524">
<ORIGINAL_TEXT>Chinese authorities have earlier pointed the finger of blame to Italy, the US and Europe -- largely without evidence.</ORIGINAL_TEXT>
<TOKEN end_char="530" id="token-5-0" morph="none" pos="word" start_char="524">Chinese</TOKEN>
<TOKEN end_char="542" id="token-5-1" morph="none" pos="word" start_char="532">authorities</TOKEN>
<TOKEN end_char="547" id="token-5-2" morph="none" pos="word" start_char="544">have</TOKEN>
<TOKEN end_char="555" id="token-5-3" morph="none" pos="word" start_char="549">earlier</TOKEN>
<TOKEN end_char="563" id="token-5-4" morph="none" pos="word" start_char="557">pointed</TOKEN>
<TOKEN end_char="567" id="token-5-5" morph="none" pos="word" start_char="565">the</TOKEN>
<TOKEN end_char="574" id="token-5-6" morph="none" pos="word" start_char="569">finger</TOKEN>
<TOKEN end_char="577" id="token-5-7" morph="none" pos="word" start_char="576">of</TOKEN>
<TOKEN end_char="583" id="token-5-8" morph="none" pos="word" start_char="579">blame</TOKEN>
<TOKEN end_char="586" id="token-5-9" morph="none" pos="word" start_char="585">to</TOKEN>
<TOKEN end_char="592" id="token-5-10" morph="none" pos="word" start_char="588">Italy</TOKEN>
<TOKEN end_char="593" id="token-5-11" morph="none" pos="punct" start_char="593">,</TOKEN>
<TOKEN end_char="597" id="token-5-12" morph="none" pos="word" start_char="595">the</TOKEN>
<TOKEN end_char="600" id="token-5-13" morph="none" pos="word" start_char="599">US</TOKEN>
<TOKEN end_char="604" id="token-5-14" morph="none" pos="word" start_char="602">and</TOKEN>
<TOKEN end_char="611" id="token-5-15" morph="none" pos="word" start_char="606">Europe</TOKEN>
<TOKEN end_char="614" id="token-5-16" morph="none" pos="punct" start_char="613">--</TOKEN>
<TOKEN end_char="622" id="token-5-17" morph="none" pos="word" start_char="616">largely</TOKEN>
<TOKEN end_char="630" id="token-5-18" morph="none" pos="word" start_char="624">without</TOKEN>
<TOKEN end_char="639" id="token-5-19" morph="none" pos="word" start_char="632">evidence</TOKEN>
<TOKEN end_char="640" id="token-5-20" morph="none" pos="punct" start_char="640">.</TOKEN>
</SEG>
<SEG end_char="738" id="segment-6" start_char="643">
<ORIGINAL_TEXT>This new blame comes against a backdrop of increased political tensions between India and China.</ORIGINAL_TEXT>
<TOKEN end_char="646" id="token-6-0" morph="none" pos="word" start_char="643">This</TOKEN>
<TOKEN end_char="650" id="token-6-1" morph="none" pos="word" start_char="648">new</TOKEN>
<TOKEN end_char="656" id="token-6-2" morph="none" pos="word" start_char="652">blame</TOKEN>
<TOKEN end_char="662" id="token-6-3" morph="none" pos="word" start_char="658">comes</TOKEN>
<TOKEN end_char="670" id="token-6-4" morph="none" pos="word" start_char="664">against</TOKEN>
<TOKEN end_char="672" id="token-6-5" morph="none" pos="word" start_char="672">a</TOKEN>
<TOKEN end_char="681" id="token-6-6" morph="none" pos="word" start_char="674">backdrop</TOKEN>
<TOKEN end_char="684" id="token-6-7" morph="none" pos="word" start_char="683">of</TOKEN>
<TOKEN end_char="694" id="token-6-8" morph="none" pos="word" start_char="686">increased</TOKEN>
<TOKEN end_char="704" id="token-6-9" morph="none" pos="word" start_char="696">political</TOKEN>
<TOKEN end_char="713" id="token-6-10" morph="none" pos="word" start_char="706">tensions</TOKEN>
<TOKEN end_char="721" id="token-6-11" morph="none" pos="word" start_char="715">between</TOKEN>
<TOKEN end_char="727" id="token-6-12" morph="none" pos="word" start_char="723">India</TOKEN>
<TOKEN end_char="731" id="token-6-13" morph="none" pos="word" start_char="729">and</TOKEN>
<TOKEN end_char="737" id="token-6-14" morph="none" pos="word" start_char="733">China</TOKEN>
<TOKEN end_char="738" id="token-6-15" morph="none" pos="punct" start_char="738">.</TOKEN>
</SEG>
<SEG end_char="832" id="segment-7" start_char="741">
<ORIGINAL_TEXT>In their paper, the Chinese team use phylogenetic analysis to trace the origins of Covid-19.</ORIGINAL_TEXT>
<TOKEN end_char="742" id="token-7-0" morph="none" pos="word" start_char="741">In</TOKEN>
<TOKEN end_char="748" id="token-7-1" morph="none" pos="word" start_char="744">their</TOKEN>
<TOKEN end_char="754" id="token-7-2" morph="none" pos="word" start_char="750">paper</TOKEN>
<TOKEN end_char="755" id="token-7-3" morph="none" pos="punct" start_char="755">,</TOKEN>
<TOKEN end_char="759" id="token-7-4" morph="none" pos="word" start_char="757">the</TOKEN>
<TOKEN end_char="767" id="token-7-5" morph="none" pos="word" start_char="761">Chinese</TOKEN>
<TOKEN end_char="772" id="token-7-6" morph="none" pos="word" start_char="769">team</TOKEN>
<TOKEN end_char="776" id="token-7-7" morph="none" pos="word" start_char="774">use</TOKEN>
<TOKEN end_char="789" id="token-7-8" morph="none" pos="word" start_char="778">phylogenetic</TOKEN>
<TOKEN end_char="798" id="token-7-9" morph="none" pos="word" start_char="791">analysis</TOKEN>
<TOKEN end_char="801" id="token-7-10" morph="none" pos="word" start_char="800">to</TOKEN>
<TOKEN end_char="807" id="token-7-11" morph="none" pos="word" start_char="803">trace</TOKEN>
<TOKEN end_char="811" id="token-7-12" morph="none" pos="word" start_char="809">the</TOKEN>
<TOKEN end_char="819" id="token-7-13" morph="none" pos="word" start_char="813">origins</TOKEN>
<TOKEN end_char="822" id="token-7-14" morph="none" pos="word" start_char="821">of</TOKEN>
<TOKEN end_char="831" id="token-7-15" morph="none" pos="unknown" start_char="824">Covid-19</TOKEN>
<TOKEN end_char="832" id="token-7-16" morph="none" pos="punct" start_char="832">.</TOKEN>
</SEG>
<SEG end_char="961" id="segment-8" start_char="835">
<ORIGINAL_TEXT>Viruses, like all cells, mutate as they reproduce, meaning tiny changes occur in their DNA each time they replicate themselves.</ORIGINAL_TEXT>
<TOKEN end_char="841" id="token-8-0" morph="none" pos="word" start_char="835">Viruses</TOKEN>
<TOKEN end_char="842" id="token-8-1" morph="none" pos="punct" start_char="842">,</TOKEN>
<TOKEN end_char="847" id="token-8-2" morph="none" pos="word" start_char="844">like</TOKEN>
<TOKEN end_char="851" id="token-8-3" morph="none" pos="word" start_char="849">all</TOKEN>
<TOKEN end_char="857" id="token-8-4" morph="none" pos="word" start_char="853">cells</TOKEN>
<TOKEN end_char="858" id="token-8-5" morph="none" pos="punct" start_char="858">,</TOKEN>
<TOKEN end_char="865" id="token-8-6" morph="none" pos="word" start_char="860">mutate</TOKEN>
<TOKEN end_char="868" id="token-8-7" morph="none" pos="word" start_char="867">as</TOKEN>
<TOKEN end_char="873" id="token-8-8" morph="none" pos="word" start_char="870">they</TOKEN>
<TOKEN end_char="883" id="token-8-9" morph="none" pos="word" start_char="875">reproduce</TOKEN>
<TOKEN end_char="884" id="token-8-10" morph="none" pos="punct" start_char="884">,</TOKEN>
<TOKEN end_char="892" id="token-8-11" morph="none" pos="word" start_char="886">meaning</TOKEN>
<TOKEN end_char="897" id="token-8-12" morph="none" pos="word" start_char="894">tiny</TOKEN>
<TOKEN end_char="905" id="token-8-13" morph="none" pos="word" start_char="899">changes</TOKEN>
<TOKEN end_char="911" id="token-8-14" morph="none" pos="word" start_char="907">occur</TOKEN>
<TOKEN end_char="914" id="token-8-15" morph="none" pos="word" start_char="913">in</TOKEN>
<TOKEN end_char="920" id="token-8-16" morph="none" pos="word" start_char="916">their</TOKEN>
<TOKEN end_char="924" id="token-8-17" morph="none" pos="word" start_char="922">DNA</TOKEN>
<TOKEN end_char="929" id="token-8-18" morph="none" pos="word" start_char="926">each</TOKEN>
<TOKEN end_char="934" id="token-8-19" morph="none" pos="word" start_char="931">time</TOKEN>
<TOKEN end_char="939" id="token-8-20" morph="none" pos="word" start_char="936">they</TOKEN>
<TOKEN end_char="949" id="token-8-21" morph="none" pos="word" start_char="941">replicate</TOKEN>
<TOKEN end_char="960" id="token-8-22" morph="none" pos="word" start_char="951">themselves</TOKEN>
<TOKEN end_char="961" id="token-8-23" morph="none" pos="punct" start_char="961">.</TOKEN>
</SEG>
<SEG end_char="985" id="segment-9" start_char="966">
<ORIGINAL_TEXT>Something went wrong</ORIGINAL_TEXT>
<TOKEN end_char="974" id="token-9-0" morph="none" pos="word" start_char="966">Something</TOKEN>
<TOKEN end_char="979" id="token-9-1" morph="none" pos="word" start_char="976">went</TOKEN>
<TOKEN end_char="985" id="token-9-2" morph="none" pos="word" start_char="981">wrong</TOKEN>
</SEG>
<SEG end_char="1071" id="segment-10" start_char="988">
<ORIGINAL_TEXT>Session ID 45e609d2-21a0-7450-b3a3-db2e8b6b5654:bea781ec-2258-138d-ad9e-4132553e5a8b</ORIGINAL_TEXT>
<TOKEN end_char="994" id="token-10-0" morph="none" pos="word" start_char="988">Session</TOKEN>
<TOKEN end_char="997" id="token-10-1" morph="none" pos="word" start_char="996">ID</TOKEN>
<TOKEN end_char="1071" id="token-10-2" morph="none" pos="unknown" start_char="999">45e609d2-21a0-7450-b3a3-db2e8b6b5654:bea781ec-2258-138d-ad9e-4132553e5a8b</TOKEN>
<TRANSLATED_TEXT>Session ID 45e609d2-21a0-7450-b3a3-db2e8b6b5654: bea781ec-2258-138d-ad9e-4132553e5a8b</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="1316" id="segment-11" start_char="1074">
<ORIGINAL_TEXT>The scientists argue their method of investigation rules out the virus found in Wuhan as the 'original' virus, and instead points to eight other countries: Bangladesh, the USA, Greece, Australia, India, Italy, Czech Republic, Russia or Serbia.</ORIGINAL_TEXT>
<TOKEN end_char="1076" id="token-11-0" morph="none" pos="word" start_char="1074">The</TOKEN>
<TOKEN end_char="1087" id="token-11-1" morph="none" pos="word" start_char="1078">scientists</TOKEN>
<TOKEN end_char="1093" id="token-11-2" morph="none" pos="word" start_char="1089">argue</TOKEN>
<TOKEN end_char="1099" id="token-11-3" morph="none" pos="word" start_char="1095">their</TOKEN>
<TOKEN end_char="1106" id="token-11-4" morph="none" pos="word" start_char="1101">method</TOKEN>
<TOKEN end_char="1109" id="token-11-5" morph="none" pos="word" start_char="1108">of</TOKEN>
<TOKEN end_char="1123" id="token-11-6" morph="none" pos="word" start_char="1111">investigation</TOKEN>
<TOKEN end_char="1129" id="token-11-7" morph="none" pos="word" start_char="1125">rules</TOKEN>
<TOKEN end_char="1133" id="token-11-8" morph="none" pos="word" start_char="1131">out</TOKEN>
<TOKEN end_char="1137" id="token-11-9" morph="none" pos="word" start_char="1135">the</TOKEN>
<TOKEN end_char="1143" id="token-11-10" morph="none" pos="word" start_char="1139">virus</TOKEN>
<TOKEN end_char="1149" id="token-11-11" morph="none" pos="word" start_char="1145">found</TOKEN>
<TOKEN end_char="1152" id="token-11-12" morph="none" pos="word" start_char="1151">in</TOKEN>
<TOKEN end_char="1158" id="token-11-13" morph="none" pos="word" start_char="1154">Wuhan</TOKEN>
<TOKEN end_char="1161" id="token-11-14" morph="none" pos="word" start_char="1160">as</TOKEN>
<TOKEN end_char="1165" id="token-11-15" morph="none" pos="word" start_char="1163">the</TOKEN>
<TOKEN end_char="1167" id="token-11-16" morph="none" pos="punct" start_char="1167">'</TOKEN>
<TOKEN end_char="1175" id="token-11-17" morph="none" pos="word" start_char="1168">original</TOKEN>
<TOKEN end_char="1176" id="token-11-18" morph="none" pos="punct" start_char="1176">'</TOKEN>
<TOKEN end_char="1182" id="token-11-19" morph="none" pos="word" start_char="1178">virus</TOKEN>
<TOKEN end_char="1183" id="token-11-20" morph="none" pos="punct" start_char="1183">,</TOKEN>
<TOKEN end_char="1187" id="token-11-21" morph="none" pos="word" start_char="1185">and</TOKEN>
<TOKEN end_char="1195" id="token-11-22" morph="none" pos="word" start_char="1189">instead</TOKEN>
<TOKEN end_char="1202" id="token-11-23" morph="none" pos="word" start_char="1197">points</TOKEN>
<TOKEN end_char="1205" id="token-11-24" morph="none" pos="word" start_char="1204">to</TOKEN>
<TOKEN end_char="1211" id="token-11-25" morph="none" pos="word" start_char="1207">eight</TOKEN>
<TOKEN end_char="1217" id="token-11-26" morph="none" pos="word" start_char="1213">other</TOKEN>
<TOKEN end_char="1227" id="token-11-27" morph="none" pos="word" start_char="1219">countries</TOKEN>
<TOKEN end_char="1228" id="token-11-28" morph="none" pos="punct" start_char="1228">:</TOKEN>
<TOKEN end_char="1239" id="token-11-29" morph="none" pos="word" start_char="1230">Bangladesh</TOKEN>
<TOKEN end_char="1240" id="token-11-30" morph="none" pos="punct" start_char="1240">,</TOKEN>
<TOKEN end_char="1244" id="token-11-31" morph="none" pos="word" start_char="1242">the</TOKEN>
<TOKEN end_char="1248" id="token-11-32" morph="none" pos="word" start_char="1246">USA</TOKEN>
<TOKEN end_char="1249" id="token-11-33" morph="none" pos="punct" start_char="1249">,</TOKEN>
<TOKEN end_char="1256" id="token-11-34" morph="none" pos="word" start_char="1251">Greece</TOKEN>
<TOKEN end_char="1257" id="token-11-35" morph="none" pos="punct" start_char="1257">,</TOKEN>
<TOKEN end_char="1267" id="token-11-36" morph="none" pos="word" start_char="1259">Australia</TOKEN>
<TOKEN end_char="1268" id="token-11-37" morph="none" pos="punct" start_char="1268">,</TOKEN>
<TOKEN end_char="1274" id="token-11-38" morph="none" pos="word" start_char="1270">India</TOKEN>
<TOKEN end_char="1275" id="token-11-39" morph="none" pos="punct" start_char="1275">,</TOKEN>
<TOKEN end_char="1281" id="token-11-40" morph="none" pos="word" start_char="1277">Italy</TOKEN>
<TOKEN end_char="1282" id="token-11-41" morph="none" pos="punct" start_char="1282">,</TOKEN>
<TOKEN end_char="1288" id="token-11-42" morph="none" pos="word" start_char="1284">Czech</TOKEN>
<TOKEN end_char="1297" id="token-11-43" morph="none" pos="word" start_char="1290">Republic</TOKEN>
<TOKEN end_char="1298" id="token-11-44" morph="none" pos="punct" start_char="1298">,</TOKEN>
<TOKEN end_char="1305" id="token-11-45" morph="none" pos="word" start_char="1300">Russia</TOKEN>
<TOKEN end_char="1308" id="token-11-46" morph="none" pos="word" start_char="1307">or</TOKEN>
<TOKEN end_char="1315" id="token-11-47" morph="none" pos="word" start_char="1310">Serbia</TOKEN>
<TOKEN end_char="1316" id="token-11-48" morph="none" pos="punct" start_char="1316">.</TOKEN>
</SEG>
<SEG end_char="1507" id="segment-12" start_char="1319">
<ORIGINAL_TEXT>Researchers go on to argue that because India and Bangladesh both recorded samples with low mutations and are geographic neighbours, it is likely that the first transmission occurred there.</ORIGINAL_TEXT>
<TOKEN end_char="1329" id="token-12-0" morph="none" pos="word" start_char="1319">Researchers</TOKEN>
<TOKEN end_char="1332" id="token-12-1" morph="none" pos="word" start_char="1331">go</TOKEN>
<TOKEN end_char="1335" id="token-12-2" morph="none" pos="word" start_char="1334">on</TOKEN>
<TOKEN end_char="1338" id="token-12-3" morph="none" pos="word" start_char="1337">to</TOKEN>
<TOKEN end_char="1344" id="token-12-4" morph="none" pos="word" start_char="1340">argue</TOKEN>
<TOKEN end_char="1349" id="token-12-5" morph="none" pos="word" start_char="1346">that</TOKEN>
<TOKEN end_char="1357" id="token-12-6" morph="none" pos="word" start_char="1351">because</TOKEN>
<TOKEN end_char="1363" id="token-12-7" morph="none" pos="word" start_char="1359">India</TOKEN>
<TOKEN end_char="1367" id="token-12-8" morph="none" pos="word" start_char="1365">and</TOKEN>
<TOKEN end_char="1378" id="token-12-9" morph="none" pos="word" start_char="1369">Bangladesh</TOKEN>
<TOKEN end_char="1383" id="token-12-10" morph="none" pos="word" start_char="1380">both</TOKEN>
<TOKEN end_char="1392" id="token-12-11" morph="none" pos="word" start_char="1385">recorded</TOKEN>
<TOKEN end_char="1400" id="token-12-12" morph="none" pos="word" start_char="1394">samples</TOKEN>
<TOKEN end_char="1405" id="token-12-13" morph="none" pos="word" start_char="1402">with</TOKEN>
<TOKEN end_char="1409" id="token-12-14" morph="none" pos="word" start_char="1407">low</TOKEN>
<TOKEN end_char="1419" id="token-12-15" morph="none" pos="word" start_char="1411">mutations</TOKEN>
<TOKEN end_char="1423" id="token-12-16" morph="none" pos="word" start_char="1421">and</TOKEN>
<TOKEN end_char="1427" id="token-12-17" morph="none" pos="word" start_char="1425">are</TOKEN>
<TOKEN end_char="1438" id="token-12-18" morph="none" pos="word" start_char="1429">geographic</TOKEN>
<TOKEN end_char="1449" id="token-12-19" morph="none" pos="word" start_char="1440">neighbours</TOKEN>
<TOKEN end_char="1450" id="token-12-20" morph="none" pos="punct" start_char="1450">,</TOKEN>
<TOKEN end_char="1453" id="token-12-21" morph="none" pos="word" start_char="1452">it</TOKEN>
<TOKEN end_char="1456" id="token-12-22" morph="none" pos="word" start_char="1455">is</TOKEN>
<TOKEN end_char="1463" id="token-12-23" morph="none" pos="word" start_char="1458">likely</TOKEN>
<TOKEN end_char="1468" id="token-12-24" morph="none" pos="word" start_char="1465">that</TOKEN>
<TOKEN end_char="1472" id="token-12-25" morph="none" pos="word" start_char="1470">the</TOKEN>
<TOKEN end_char="1478" id="token-12-26" morph="none" pos="word" start_char="1474">first</TOKEN>
<TOKEN end_char="1491" id="token-12-27" morph="none" pos="word" start_char="1480">transmission</TOKEN>
<TOKEN end_char="1500" id="token-12-28" morph="none" pos="word" start_char="1493">occurred</TOKEN>
<TOKEN end_char="1506" id="token-12-29" morph="none" pos="word" start_char="1502">there</TOKEN>
<TOKEN end_char="1507" id="token-12-30" morph="none" pos="punct" start_char="1507">.</TOKEN>
</SEG>
<SEG end_char="1733" id="segment-13" start_char="1510">
<ORIGINAL_TEXT>Their unproven theory goes on to say: "The water shortage made wild animals such as monkeys engage in the deadly fight over water among each other and would have surely increased the chance of human-wild animal interactions.</ORIGINAL_TEXT>
<TOKEN end_char="1514" id="token-13-0" morph="none" pos="word" start_char="1510">Their</TOKEN>
<TOKEN end_char="1523" id="token-13-1" morph="none" pos="word" start_char="1516">unproven</TOKEN>
<TOKEN end_char="1530" id="token-13-2" morph="none" pos="word" start_char="1525">theory</TOKEN>
<TOKEN end_char="1535" id="token-13-3" morph="none" pos="word" start_char="1532">goes</TOKEN>
<TOKEN end_char="1538" id="token-13-4" morph="none" pos="word" start_char="1537">on</TOKEN>
<TOKEN end_char="1541" id="token-13-5" morph="none" pos="word" start_char="1540">to</TOKEN>
<TOKEN end_char="1545" id="token-13-6" morph="none" pos="word" start_char="1543">say</TOKEN>
<TOKEN end_char="1546" id="token-13-7" morph="none" pos="punct" start_char="1546">:</TOKEN>
<TOKEN end_char="1548" id="token-13-8" morph="none" pos="punct" start_char="1548">"</TOKEN>
<TOKEN end_char="1551" id="token-13-9" morph="none" pos="word" start_char="1549">The</TOKEN>
<TOKEN end_char="1557" id="token-13-10" morph="none" pos="word" start_char="1553">water</TOKEN>
<TOKEN end_char="1566" id="token-13-11" morph="none" pos="word" start_char="1559">shortage</TOKEN>
<TOKEN end_char="1571" id="token-13-12" morph="none" pos="word" start_char="1568">made</TOKEN>
<TOKEN end_char="1576" id="token-13-13" morph="none" pos="word" start_char="1573">wild</TOKEN>
<TOKEN end_char="1584" id="token-13-14" morph="none" pos="word" start_char="1578">animals</TOKEN>
<TOKEN end_char="1589" id="token-13-15" morph="none" pos="word" start_char="1586">such</TOKEN>
<TOKEN end_char="1592" id="token-13-16" morph="none" pos="word" start_char="1591">as</TOKEN>
<TOKEN end_char="1600" id="token-13-17" morph="none" pos="word" start_char="1594">monkeys</TOKEN>
<TOKEN end_char="1607" id="token-13-18" morph="none" pos="word" start_char="1602">engage</TOKEN>
<TOKEN end_char="1610" id="token-13-19" morph="none" pos="word" start_char="1609">in</TOKEN>
<TOKEN end_char="1614" id="token-13-20" morph="none" pos="word" start_char="1612">the</TOKEN>
<TOKEN end_char="1621" id="token-13-21" morph="none" pos="word" start_char="1616">deadly</TOKEN>
<TOKEN end_char="1627" id="token-13-22" morph="none" pos="word" start_char="1623">fight</TOKEN>
<TOKEN end_char="1632" id="token-13-23" morph="none" pos="word" start_char="1629">over</TOKEN>
<TOKEN end_char="1638" id="token-13-24" morph="none" pos="word" start_char="1634">water</TOKEN>
<TOKEN end_char="1644" id="token-13-25" morph="none" pos="word" start_char="1640">among</TOKEN>
<TOKEN end_char="1649" id="token-13-26" morph="none" pos="word" start_char="1646">each</TOKEN>
<TOKEN end_char="1655" id="token-13-27" morph="none" pos="word" start_char="1651">other</TOKEN>
<TOKEN end_char="1659" id="token-13-28" morph="none" pos="word" start_char="1657">and</TOKEN>
<TOKEN end_char="1665" id="token-13-29" morph="none" pos="word" start_char="1661">would</TOKEN>
<TOKEN end_char="1670" id="token-13-30" morph="none" pos="word" start_char="1667">have</TOKEN>
<TOKEN end_char="1677" id="token-13-31" morph="none" pos="word" start_char="1672">surely</TOKEN>
<TOKEN end_char="1687" id="token-13-32" morph="none" pos="word" start_char="1679">increased</TOKEN>
<TOKEN end_char="1691" id="token-13-33" morph="none" pos="word" start_char="1689">the</TOKEN>
<TOKEN end_char="1698" id="token-13-34" morph="none" pos="word" start_char="1693">chance</TOKEN>
<TOKEN end_char="1701" id="token-13-35" morph="none" pos="word" start_char="1700">of</TOKEN>
<TOKEN end_char="1712" id="token-13-36" morph="none" pos="unknown" start_char="1703">human-wild</TOKEN>
<TOKEN end_char="1719" id="token-13-37" morph="none" pos="word" start_char="1714">animal</TOKEN>
<TOKEN end_char="1732" id="token-13-38" morph="none" pos="word" start_char="1721">interactions</TOKEN>
<TOKEN end_char="1733" id="token-13-39" morph="none" pos="punct" start_char="1733">.</TOKEN>
</SEG>
<SEG end_char="1850" id="segment-14" start_char="1735">
<ORIGINAL_TEXT>We speculated that the [animal to human] transmission of SARS-CoV-2 might be associated with this unusual heat wave.</ORIGINAL_TEXT>
<TOKEN end_char="1736" id="token-14-0" morph="none" pos="word" start_char="1735">We</TOKEN>
<TOKEN end_char="1747" id="token-14-1" morph="none" pos="word" start_char="1738">speculated</TOKEN>
<TOKEN end_char="1752" id="token-14-2" morph="none" pos="word" start_char="1749">that</TOKEN>
<TOKEN end_char="1756" id="token-14-3" morph="none" pos="word" start_char="1754">the</TOKEN>
<TOKEN end_char="1758" id="token-14-4" morph="none" pos="punct" start_char="1758">[</TOKEN>
<TOKEN end_char="1764" id="token-14-5" morph="none" pos="word" start_char="1759">animal</TOKEN>
<TOKEN end_char="1767" id="token-14-6" morph="none" pos="word" start_char="1766">to</TOKEN>
<TOKEN end_char="1773" id="token-14-7" morph="none" pos="word" start_char="1769">human</TOKEN>
<TOKEN end_char="1774" id="token-14-8" morph="none" pos="punct" start_char="1774">]</TOKEN>
<TOKEN end_char="1787" id="token-14-9" morph="none" pos="word" start_char="1776">transmission</TOKEN>
<TOKEN end_char="1790" id="token-14-10" morph="none" pos="word" start_char="1789">of</TOKEN>
<TOKEN end_char="1801" id="token-14-11" morph="none" pos="unknown" start_char="1792">SARS-CoV-2</TOKEN>
<TOKEN end_char="1807" id="token-14-12" morph="none" pos="word" start_char="1803">might</TOKEN>
<TOKEN end_char="1810" id="token-14-13" morph="none" pos="word" start_char="1809">be</TOKEN>
<TOKEN end_char="1821" id="token-14-14" morph="none" pos="word" start_char="1812">associated</TOKEN>
<TOKEN end_char="1826" id="token-14-15" morph="none" pos="word" start_char="1823">with</TOKEN>
<TOKEN end_char="1831" id="token-14-16" morph="none" pos="word" start_char="1828">this</TOKEN>
<TOKEN end_char="1839" id="token-14-17" morph="none" pos="word" start_char="1833">unusual</TOKEN>
<TOKEN end_char="1844" id="token-14-18" morph="none" pos="word" start_char="1841">heat</TOKEN>
<TOKEN end_char="1849" id="token-14-19" morph="none" pos="word" start_char="1846">wave</TOKEN>
<TOKEN end_char="1850" id="token-14-20" morph="none" pos="punct" start_char="1850">.</TOKEN>
</SEG>
<SEG end_char="1964" id="segment-15" start_char="1853">
<ORIGINAL_TEXT>"India's poor healthcare system and young population allowed the virus to spread undetected for several months."</ORIGINAL_TEXT>
<TOKEN end_char="1853" id="token-15-0" morph="none" pos="punct" start_char="1853">"</TOKEN>
<TOKEN end_char="1860" id="token-15-1" morph="none" pos="word" start_char="1854">India's</TOKEN>
<TOKEN end_char="1865" id="token-15-2" morph="none" pos="word" start_char="1862">poor</TOKEN>
<TOKEN end_char="1876" id="token-15-3" morph="none" pos="word" start_char="1867">healthcare</TOKEN>
<TOKEN end_char="1883" id="token-15-4" morph="none" pos="word" start_char="1878">system</TOKEN>
<TOKEN end_char="1887" id="token-15-5" morph="none" pos="word" start_char="1885">and</TOKEN>
<TOKEN end_char="1893" id="token-15-6" morph="none" pos="word" start_char="1889">young</TOKEN>
<TOKEN end_char="1904" id="token-15-7" morph="none" pos="word" start_char="1895">population</TOKEN>
<TOKEN end_char="1912" id="token-15-8" morph="none" pos="word" start_char="1906">allowed</TOKEN>
<TOKEN end_char="1916" id="token-15-9" morph="none" pos="word" start_char="1914">the</TOKEN>
<TOKEN end_char="1922" id="token-15-10" morph="none" pos="word" start_char="1918">virus</TOKEN>
<TOKEN end_char="1925" id="token-15-11" morph="none" pos="word" start_char="1924">to</TOKEN>
<TOKEN end_char="1932" id="token-15-12" morph="none" pos="word" start_char="1927">spread</TOKEN>
<TOKEN end_char="1943" id="token-15-13" morph="none" pos="word" start_char="1934">undetected</TOKEN>
<TOKEN end_char="1947" id="token-15-14" morph="none" pos="word" start_char="1945">for</TOKEN>
<TOKEN end_char="1955" id="token-15-15" morph="none" pos="word" start_char="1949">several</TOKEN>
<TOKEN end_char="1962" id="token-15-16" morph="none" pos="word" start_char="1957">months</TOKEN>
<TOKEN end_char="1964" id="token-15-17" morph="none" pos="punct" start_char="1963">."</TOKEN>
</SEG>
<SEG end_char="2066" id="segment-16" start_char="1967">
<ORIGINAL_TEXT>Despite the bizarre claims, coronavirus is believed to have first emerged in China in December 2019.</ORIGINAL_TEXT>
<TOKEN end_char="1973" id="token-16-0" morph="none" pos="word" start_char="1967">Despite</TOKEN>
<TOKEN end_char="1977" id="token-16-1" morph="none" pos="word" start_char="1975">the</TOKEN>
<TOKEN end_char="1985" id="token-16-2" morph="none" pos="word" start_char="1979">bizarre</TOKEN>
<TOKEN end_char="1992" id="token-16-3" morph="none" pos="word" start_char="1987">claims</TOKEN>
<TOKEN end_char="1993" id="token-16-4" morph="none" pos="punct" start_char="1993">,</TOKEN>
<TOKEN end_char="2005" id="token-16-5" morph="none" pos="word" start_char="1995">coronavirus</TOKEN>
<TOKEN end_char="2008" id="token-16-6" morph="none" pos="word" start_char="2007">is</TOKEN>
<TOKEN end_char="2017" id="token-16-7" morph="none" pos="word" start_char="2010">believed</TOKEN>
<TOKEN end_char="2020" id="token-16-8" morph="none" pos="word" start_char="2019">to</TOKEN>
<TOKEN end_char="2025" id="token-16-9" morph="none" pos="word" start_char="2022">have</TOKEN>
<TOKEN end_char="2031" id="token-16-10" morph="none" pos="word" start_char="2027">first</TOKEN>
<TOKEN end_char="2039" id="token-16-11" morph="none" pos="word" start_char="2033">emerged</TOKEN>
<TOKEN end_char="2042" id="token-16-12" morph="none" pos="word" start_char="2041">in</TOKEN>
<TOKEN end_char="2048" id="token-16-13" morph="none" pos="word" start_char="2044">China</TOKEN>
<TOKEN end_char="2051" id="token-16-14" morph="none" pos="word" start_char="2050">in</TOKEN>
<TOKEN end_char="2060" id="token-16-15" morph="none" pos="word" start_char="2053">December</TOKEN>
<TOKEN end_char="2065" id="token-16-16" morph="none" pos="word" start_char="2062">2019</TOKEN>
<TOKEN end_char="2066" id="token-16-17" morph="none" pos="punct" start_char="2066">.</TOKEN>
</SEG>
<SEG end_char="2175" id="segment-17" start_char="2069">
<ORIGINAL_TEXT>It was first linked to a cluster of cases of 'pneumonia of unknown origin' at a seafood market in the city.</ORIGINAL_TEXT>
<TOKEN end_char="2070" id="token-17-0" morph="none" pos="word" start_char="2069">It</TOKEN>
<TOKEN end_char="2074" id="token-17-1" morph="none" pos="word" start_char="2072">was</TOKEN>
<TOKEN end_char="2080" id="token-17-2" morph="none" pos="word" start_char="2076">first</TOKEN>
<TOKEN end_char="2087" id="token-17-3" morph="none" pos="word" start_char="2082">linked</TOKEN>
<TOKEN end_char="2090" id="token-17-4" morph="none" pos="word" start_char="2089">to</TOKEN>
<TOKEN end_char="2092" id="token-17-5" morph="none" pos="word" start_char="2092">a</TOKEN>
<TOKEN end_char="2100" id="token-17-6" morph="none" pos="word" start_char="2094">cluster</TOKEN>
<TOKEN end_char="2103" id="token-17-7" morph="none" pos="word" start_char="2102">of</TOKEN>
<TOKEN end_char="2109" id="token-17-8" morph="none" pos="word" start_char="2105">cases</TOKEN>
<TOKEN end_char="2112" id="token-17-9" morph="none" pos="word" start_char="2111">of</TOKEN>
<TOKEN end_char="2114" id="token-17-10" morph="none" pos="punct" start_char="2114">'</TOKEN>
<TOKEN end_char="2123" id="token-17-11" morph="none" pos="word" start_char="2115">pneumonia</TOKEN>
<TOKEN end_char="2126" id="token-17-12" morph="none" pos="word" start_char="2125">of</TOKEN>
<TOKEN end_char="2134" id="token-17-13" morph="none" pos="word" start_char="2128">unknown</TOKEN>
<TOKEN end_char="2141" id="token-17-14" morph="none" pos="word" start_char="2136">origin</TOKEN>
<TOKEN end_char="2142" id="token-17-15" morph="none" pos="punct" start_char="2142">'</TOKEN>
<TOKEN end_char="2145" id="token-17-16" morph="none" pos="word" start_char="2144">at</TOKEN>
<TOKEN end_char="2147" id="token-17-17" morph="none" pos="word" start_char="2147">a</TOKEN>
<TOKEN end_char="2155" id="token-17-18" morph="none" pos="word" start_char="2149">seafood</TOKEN>
<TOKEN end_char="2162" id="token-17-19" morph="none" pos="word" start_char="2157">market</TOKEN>
<TOKEN end_char="2165" id="token-17-20" morph="none" pos="word" start_char="2164">in</TOKEN>
<TOKEN end_char="2169" id="token-17-21" morph="none" pos="word" start_char="2167">the</TOKEN>
<TOKEN end_char="2174" id="token-17-22" morph="none" pos="word" start_char="2171">city</TOKEN>
<TOKEN end_char="2175" id="token-17-23" morph="none" pos="punct" start_char="2175">.</TOKEN>
</SEG>
<SEG end_char="2467" id="segment-18" start_char="2178">
<ORIGINAL_TEXT>Earlier on Friday, Chinese state media cited the presence of the novel coronavirus on imported frozen food packaging, as well as scientific papers, claiming that the coronavirus was circulating in Europe earlier than previously believed, as evidence that China may not have been its origin.</ORIGINAL_TEXT>
<TOKEN end_char="2184" id="token-18-0" morph="none" pos="word" start_char="2178">Earlier</TOKEN>
<TOKEN end_char="2187" id="token-18-1" morph="none" pos="word" start_char="2186">on</TOKEN>
<TOKEN end_char="2194" id="token-18-2" morph="none" pos="word" start_char="2189">Friday</TOKEN>
<TOKEN end_char="2195" id="token-18-3" morph="none" pos="punct" start_char="2195">,</TOKEN>
<TOKEN end_char="2203" id="token-18-4" morph="none" pos="word" start_char="2197">Chinese</TOKEN>
<TOKEN end_char="2209" id="token-18-5" morph="none" pos="word" start_char="2205">state</TOKEN>
<TOKEN end_char="2215" id="token-18-6" morph="none" pos="word" start_char="2211">media</TOKEN>
<TOKEN end_char="2221" id="token-18-7" morph="none" pos="word" start_char="2217">cited</TOKEN>
<TOKEN end_char="2225" id="token-18-8" morph="none" pos="word" start_char="2223">the</TOKEN>
<TOKEN end_char="2234" id="token-18-9" morph="none" pos="word" start_char="2227">presence</TOKEN>
<TOKEN end_char="2237" id="token-18-10" morph="none" pos="word" start_char="2236">of</TOKEN>
<TOKEN end_char="2241" id="token-18-11" morph="none" pos="word" start_char="2239">the</TOKEN>
<TOKEN end_char="2247" id="token-18-12" morph="none" pos="word" start_char="2243">novel</TOKEN>
<TOKEN end_char="2259" id="token-18-13" morph="none" pos="word" start_char="2249">coronavirus</TOKEN>
<TOKEN end_char="2262" id="token-18-14" morph="none" pos="word" start_char="2261">on</TOKEN>
<TOKEN end_char="2271" id="token-18-15" morph="none" pos="word" start_char="2264">imported</TOKEN>
<TOKEN end_char="2278" id="token-18-16" morph="none" pos="word" start_char="2273">frozen</TOKEN>
<TOKEN end_char="2283" id="token-18-17" morph="none" pos="word" start_char="2280">food</TOKEN>
<TOKEN end_char="2293" id="token-18-18" morph="none" pos="word" start_char="2285">packaging</TOKEN>
<TOKEN end_char="2294" id="token-18-19" morph="none" pos="punct" start_char="2294">,</TOKEN>
<TOKEN end_char="2297" id="token-18-20" morph="none" pos="word" start_char="2296">as</TOKEN>
<TOKEN end_char="2302" id="token-18-21" morph="none" pos="word" start_char="2299">well</TOKEN>
<TOKEN end_char="2305" id="token-18-22" morph="none" pos="word" start_char="2304">as</TOKEN>
<TOKEN end_char="2316" id="token-18-23" morph="none" pos="word" start_char="2307">scientific</TOKEN>
<TOKEN end_char="2323" id="token-18-24" morph="none" pos="word" start_char="2318">papers</TOKEN>
<TOKEN end_char="2324" id="token-18-25" morph="none" pos="punct" start_char="2324">,</TOKEN>
<TOKEN end_char="2333" id="token-18-26" morph="none" pos="word" start_char="2326">claiming</TOKEN>
<TOKEN end_char="2338" id="token-18-27" morph="none" pos="word" start_char="2335">that</TOKEN>
<TOKEN end_char="2342" id="token-18-28" morph="none" pos="word" start_char="2340">the</TOKEN>
<TOKEN end_char="2354" id="token-18-29" morph="none" pos="word" start_char="2344">coronavirus</TOKEN>
<TOKEN end_char="2358" id="token-18-30" morph="none" pos="word" start_char="2356">was</TOKEN>
<TOKEN end_char="2370" id="token-18-31" morph="none" pos="word" start_char="2360">circulating</TOKEN>
<TOKEN end_char="2373" id="token-18-32" morph="none" pos="word" start_char="2372">in</TOKEN>
<TOKEN end_char="2380" id="token-18-33" morph="none" pos="word" start_char="2375">Europe</TOKEN>
<TOKEN end_char="2388" id="token-18-34" morph="none" pos="word" start_char="2382">earlier</TOKEN>
<TOKEN end_char="2393" id="token-18-35" morph="none" pos="word" start_char="2390">than</TOKEN>
<TOKEN end_char="2404" id="token-18-36" morph="none" pos="word" start_char="2395">previously</TOKEN>
<TOKEN end_char="2413" id="token-18-37" morph="none" pos="word" start_char="2406">believed</TOKEN>
<TOKEN end_char="2414" id="token-18-38" morph="none" pos="punct" start_char="2414">,</TOKEN>
<TOKEN end_char="2417" id="token-18-39" morph="none" pos="word" start_char="2416">as</TOKEN>
<TOKEN end_char="2426" id="token-18-40" morph="none" pos="word" start_char="2419">evidence</TOKEN>
<TOKEN end_char="2431" id="token-18-41" morph="none" pos="word" start_char="2428">that</TOKEN>
<TOKEN end_char="2437" id="token-18-42" morph="none" pos="word" start_char="2433">China</TOKEN>
<TOKEN end_char="2441" id="token-18-43" morph="none" pos="word" start_char="2439">may</TOKEN>
<TOKEN end_char="2445" id="token-18-44" morph="none" pos="word" start_char="2443">not</TOKEN>
<TOKEN end_char="2450" id="token-18-45" morph="none" pos="word" start_char="2447">have</TOKEN>
<TOKEN end_char="2455" id="token-18-46" morph="none" pos="word" start_char="2452">been</TOKEN>
<TOKEN end_char="2459" id="token-18-47" morph="none" pos="word" start_char="2457">its</TOKEN>
<TOKEN end_char="2466" id="token-18-48" morph="none" pos="word" start_char="2461">origin</TOKEN>
<TOKEN end_char="2467" id="token-18-49" morph="none" pos="punct" start_char="2467">.</TOKEN>
</SEG>
<SEG end_char="2712" id="segment-19" start_char="2470">
<ORIGINAL_TEXT>To this end, the World Health Organisation's top emergency expert said on Friday it would be "highly speculative" for the WHO to say the coronavirus did not emerge in China, where it was first identified in a food market in December last year.</ORIGINAL_TEXT>
<TOKEN end_char="2471" id="token-19-0" morph="none" pos="word" start_char="2470">To</TOKEN>
<TOKEN end_char="2476" id="token-19-1" morph="none" pos="word" start_char="2473">this</TOKEN>
<TOKEN end_char="2480" id="token-19-2" morph="none" pos="word" start_char="2478">end</TOKEN>
<TOKEN end_char="2481" id="token-19-3" morph="none" pos="punct" start_char="2481">,</TOKEN>
<TOKEN end_char="2485" id="token-19-4" morph="none" pos="word" start_char="2483">the</TOKEN>
<TOKEN end_char="2491" id="token-19-5" morph="none" pos="word" start_char="2487">World</TOKEN>
<TOKEN end_char="2498" id="token-19-6" morph="none" pos="word" start_char="2493">Health</TOKEN>
<TOKEN end_char="2513" id="token-19-7" morph="none" pos="word" start_char="2500">Organisation's</TOKEN>
<TOKEN end_char="2517" id="token-19-8" morph="none" pos="word" start_char="2515">top</TOKEN>
<TOKEN end_char="2527" id="token-19-9" morph="none" pos="word" start_char="2519">emergency</TOKEN>
<TOKEN end_char="2534" id="token-19-10" morph="none" pos="word" start_char="2529">expert</TOKEN>
<TOKEN end_char="2539" id="token-19-11" morph="none" pos="word" start_char="2536">said</TOKEN>
<TOKEN end_char="2542" id="token-19-12" morph="none" pos="word" start_char="2541">on</TOKEN>
<TOKEN end_char="2549" id="token-19-13" morph="none" pos="word" start_char="2544">Friday</TOKEN>
<TOKEN end_char="2552" id="token-19-14" morph="none" pos="word" start_char="2551">it</TOKEN>
<TOKEN end_char="2558" id="token-19-15" morph="none" pos="word" start_char="2554">would</TOKEN>
<TOKEN end_char="2561" id="token-19-16" morph="none" pos="word" start_char="2560">be</TOKEN>
<TOKEN end_char="2563" id="token-19-17" morph="none" pos="punct" start_char="2563">"</TOKEN>
<TOKEN end_char="2569" id="token-19-18" morph="none" pos="word" start_char="2564">highly</TOKEN>
<TOKEN end_char="2581" id="token-19-19" morph="none" pos="word" start_char="2571">speculative</TOKEN>
<TOKEN end_char="2582" id="token-19-20" morph="none" pos="punct" start_char="2582">"</TOKEN>
<TOKEN end_char="2586" id="token-19-21" morph="none" pos="word" start_char="2584">for</TOKEN>
<TOKEN end_char="2590" id="token-19-22" morph="none" pos="word" start_char="2588">the</TOKEN>
<TOKEN end_char="2594" id="token-19-23" morph="none" pos="word" start_char="2592">WHO</TOKEN>
<TOKEN end_char="2597" id="token-19-24" morph="none" pos="word" start_char="2596">to</TOKEN>
<TOKEN end_char="2601" id="token-19-25" morph="none" pos="word" start_char="2599">say</TOKEN>
<TOKEN end_char="2605" id="token-19-26" morph="none" pos="word" start_char="2603">the</TOKEN>
<TOKEN end_char="2617" id="token-19-27" morph="none" pos="word" start_char="2607">coronavirus</TOKEN>
<TOKEN end_char="2621" id="token-19-28" morph="none" pos="word" start_char="2619">did</TOKEN>
<TOKEN end_char="2625" id="token-19-29" morph="none" pos="word" start_char="2623">not</TOKEN>
<TOKEN end_char="2632" id="token-19-30" morph="none" pos="word" start_char="2627">emerge</TOKEN>
<TOKEN end_char="2635" id="token-19-31" morph="none" pos="word" start_char="2634">in</TOKEN>
<TOKEN end_char="2641" id="token-19-32" morph="none" pos="word" start_char="2637">China</TOKEN>
<TOKEN end_char="2642" id="token-19-33" morph="none" pos="punct" start_char="2642">,</TOKEN>
<TOKEN end_char="2648" id="token-19-34" morph="none" pos="word" start_char="2644">where</TOKEN>
<TOKEN end_char="2651" id="token-19-35" morph="none" pos="word" start_char="2650">it</TOKEN>
<TOKEN end_char="2655" id="token-19-36" morph="none" pos="word" start_char="2653">was</TOKEN>
<TOKEN end_char="2661" id="token-19-37" morph="none" pos="word" start_char="2657">first</TOKEN>
<TOKEN end_char="2672" id="token-19-38" morph="none" pos="word" start_char="2663">identified</TOKEN>
<TOKEN end_char="2675" id="token-19-39" morph="none" pos="word" start_char="2674">in</TOKEN>
<TOKEN end_char="2677" id="token-19-40" morph="none" pos="word" start_char="2677">a</TOKEN>
<TOKEN end_char="2682" id="token-19-41" morph="none" pos="word" start_char="2679">food</TOKEN>
<TOKEN end_char="2689" id="token-19-42" morph="none" pos="word" start_char="2684">market</TOKEN>
<TOKEN end_char="2692" id="token-19-43" morph="none" pos="word" start_char="2691">in</TOKEN>
<TOKEN end_char="2701" id="token-19-44" morph="none" pos="word" start_char="2694">December</TOKEN>
<TOKEN end_char="2706" id="token-19-45" morph="none" pos="word" start_char="2703">last</TOKEN>
<TOKEN end_char="2711" id="token-19-46" morph="none" pos="word" start_char="2708">year</TOKEN>
<TOKEN end_char="2712" id="token-19-47" morph="none" pos="punct" start_char="2712">.</TOKEN>
</SEG>
<SEG end_char="2988" id="segment-20" start_char="2715">
<ORIGINAL_TEXT>China is pushing a narrative via state media that the virus existed abroad before it was discovered in the central city of Wuhan, citing the presence of coronavirus on imported frozen food packaging and scientific papers claiming it had been circulating in Europe last year.</ORIGINAL_TEXT>
<TOKEN end_char="2719" id="token-20-0" morph="none" pos="word" start_char="2715">China</TOKEN>
<TOKEN end_char="2722" id="token-20-1" morph="none" pos="word" start_char="2721">is</TOKEN>
<TOKEN end_char="2730" id="token-20-2" morph="none" pos="word" start_char="2724">pushing</TOKEN>
<TOKEN end_char="2732" id="token-20-3" morph="none" pos="word" start_char="2732">a</TOKEN>
<TOKEN end_char="2742" id="token-20-4" morph="none" pos="word" start_char="2734">narrative</TOKEN>
<TOKEN end_char="2746" id="token-20-5" morph="none" pos="word" start_char="2744">via</TOKEN>
<TOKEN end_char="2752" id="token-20-6" morph="none" pos="word" start_char="2748">state</TOKEN>
<TOKEN end_char="2758" id="token-20-7" morph="none" pos="word" start_char="2754">media</TOKEN>
<TOKEN end_char="2763" id="token-20-8" morph="none" pos="word" start_char="2760">that</TOKEN>
<TOKEN end_char="2767" id="token-20-9" morph="none" pos="word" start_char="2765">the</TOKEN>
<TOKEN end_char="2773" id="token-20-10" morph="none" pos="word" start_char="2769">virus</TOKEN>
<TOKEN end_char="2781" id="token-20-11" morph="none" pos="word" start_char="2775">existed</TOKEN>
<TOKEN end_char="2788" id="token-20-12" morph="none" pos="word" start_char="2783">abroad</TOKEN>
<TOKEN end_char="2795" id="token-20-13" morph="none" pos="word" start_char="2790">before</TOKEN>
<TOKEN end_char="2798" id="token-20-14" morph="none" pos="word" start_char="2797">it</TOKEN>
<TOKEN end_char="2802" id="token-20-15" morph="none" pos="word" start_char="2800">was</TOKEN>
<TOKEN end_char="2813" id="token-20-16" morph="none" pos="word" start_char="2804">discovered</TOKEN>
<TOKEN end_char="2816" id="token-20-17" morph="none" pos="word" start_char="2815">in</TOKEN>
<TOKEN end_char="2820" id="token-20-18" morph="none" pos="word" start_char="2818">the</TOKEN>
<TOKEN end_char="2828" id="token-20-19" morph="none" pos="word" start_char="2822">central</TOKEN>
<TOKEN end_char="2833" id="token-20-20" morph="none" pos="word" start_char="2830">city</TOKEN>
<TOKEN end_char="2836" id="token-20-21" morph="none" pos="word" start_char="2835">of</TOKEN>
<TOKEN end_char="2842" id="token-20-22" morph="none" pos="word" start_char="2838">Wuhan</TOKEN>
<TOKEN end_char="2843" id="token-20-23" morph="none" pos="punct" start_char="2843">,</TOKEN>
<TOKEN end_char="2850" id="token-20-24" morph="none" pos="word" start_char="2845">citing</TOKEN>
<TOKEN end_char="2854" id="token-20-25" morph="none" pos="word" start_char="2852">the</TOKEN>
<TOKEN end_char="2863" id="token-20-26" morph="none" pos="word" start_char="2856">presence</TOKEN>
<TOKEN end_char="2866" id="token-20-27" morph="none" pos="word" start_char="2865">of</TOKEN>
<TOKEN end_char="2878" id="token-20-28" morph="none" pos="word" start_char="2868">coronavirus</TOKEN>
<TOKEN end_char="2881" id="token-20-29" morph="none" pos="word" start_char="2880">on</TOKEN>
<TOKEN end_char="2890" id="token-20-30" morph="none" pos="word" start_char="2883">imported</TOKEN>
<TOKEN end_char="2897" id="token-20-31" morph="none" pos="word" start_char="2892">frozen</TOKEN>
<TOKEN end_char="2902" id="token-20-32" morph="none" pos="word" start_char="2899">food</TOKEN>
<TOKEN end_char="2912" id="token-20-33" morph="none" pos="word" start_char="2904">packaging</TOKEN>
<TOKEN end_char="2916" id="token-20-34" morph="none" pos="word" start_char="2914">and</TOKEN>
<TOKEN end_char="2927" id="token-20-35" morph="none" pos="word" start_char="2918">scientific</TOKEN>
<TOKEN end_char="2934" id="token-20-36" morph="none" pos="word" start_char="2929">papers</TOKEN>
<TOKEN end_char="2943" id="token-20-37" morph="none" pos="word" start_char="2936">claiming</TOKEN>
<TOKEN end_char="2946" id="token-20-38" morph="none" pos="word" start_char="2945">it</TOKEN>
<TOKEN end_char="2950" id="token-20-39" morph="none" pos="word" start_char="2948">had</TOKEN>
<TOKEN end_char="2955" id="token-20-40" morph="none" pos="word" start_char="2952">been</TOKEN>
<TOKEN end_char="2967" id="token-20-41" morph="none" pos="word" start_char="2957">circulating</TOKEN>
<TOKEN end_char="2970" id="token-20-42" morph="none" pos="word" start_char="2969">in</TOKEN>
<TOKEN end_char="2977" id="token-20-43" morph="none" pos="word" start_char="2972">Europe</TOKEN>
<TOKEN end_char="2982" id="token-20-44" morph="none" pos="word" start_char="2979">last</TOKEN>
<TOKEN end_char="2987" id="token-20-45" morph="none" pos="word" start_char="2984">year</TOKEN>
<TOKEN end_char="2988" id="token-20-46" morph="none" pos="punct" start_char="2988">.</TOKEN>
</SEG>
<SEG end_char="3196" id="segment-21" start_char="2991">
<ORIGINAL_TEXT>"I think it`s highly speculative for us to say that the disease did not emerge in China," Mike Ryan said at a virtual briefing in Geneva after being asked if COVID-19 could have first emerged outside China.</ORIGINAL_TEXT>
<TOKEN end_char="2991" id="token-21-0" morph="none" pos="punct" start_char="2991">"</TOKEN>
<TOKEN end_char="2992" id="token-21-1" morph="none" pos="word" start_char="2992">I</TOKEN>
<TOKEN end_char="2998" id="token-21-2" morph="none" pos="word" start_char="2994">think</TOKEN>
<TOKEN end_char="3003" id="token-21-3" morph="none" pos="unknown" start_char="3000">it`s</TOKEN>
<TOKEN end_char="3010" id="token-21-4" morph="none" pos="word" start_char="3005">highly</TOKEN>
<TOKEN end_char="3022" id="token-21-5" morph="none" pos="word" start_char="3012">speculative</TOKEN>
<TOKEN end_char="3026" id="token-21-6" morph="none" pos="word" start_char="3024">for</TOKEN>
<TOKEN end_char="3029" id="token-21-7" morph="none" pos="word" start_char="3028">us</TOKEN>
<TOKEN end_char="3032" id="token-21-8" morph="none" pos="word" start_char="3031">to</TOKEN>
<TOKEN end_char="3036" id="token-21-9" morph="none" pos="word" start_char="3034">say</TOKEN>
<TOKEN end_char="3041" id="token-21-10" morph="none" pos="word" start_char="3038">that</TOKEN>
<TOKEN end_char="3045" id="token-21-11" morph="none" pos="word" start_char="3043">the</TOKEN>
<TOKEN end_char="3053" id="token-21-12" morph="none" pos="word" start_char="3047">disease</TOKEN>
<TOKEN end_char="3057" id="token-21-13" morph="none" pos="word" start_char="3055">did</TOKEN>
<TOKEN end_char="3061" id="token-21-14" morph="none" pos="word" start_char="3059">not</TOKEN>
<TOKEN end_char="3068" id="token-21-15" morph="none" pos="word" start_char="3063">emerge</TOKEN>
<TOKEN end_char="3071" id="token-21-16" morph="none" pos="word" start_char="3070">in</TOKEN>
<TOKEN end_char="3077" id="token-21-17" morph="none" pos="word" start_char="3073">China</TOKEN>
<TOKEN end_char="3079" id="token-21-18" morph="none" pos="punct" start_char="3078">,"</TOKEN>
<TOKEN end_char="3084" id="token-21-19" morph="none" pos="word" start_char="3081">Mike</TOKEN>
<TOKEN end_char="3089" id="token-21-20" morph="none" pos="word" start_char="3086">Ryan</TOKEN>
<TOKEN end_char="3094" id="token-21-21" morph="none" pos="word" start_char="3091">said</TOKEN>
<TOKEN end_char="3097" id="token-21-22" morph="none" pos="word" start_char="3096">at</TOKEN>
<TOKEN end_char="3099" id="token-21-23" morph="none" pos="word" start_char="3099">a</TOKEN>
<TOKEN end_char="3107" id="token-21-24" morph="none" pos="word" start_char="3101">virtual</TOKEN>
<TOKEN end_char="3116" id="token-21-25" morph="none" pos="word" start_char="3109">briefing</TOKEN>
<TOKEN end_char="3119" id="token-21-26" morph="none" pos="word" start_char="3118">in</TOKEN>
<TOKEN end_char="3126" id="token-21-27" morph="none" pos="word" start_char="3121">Geneva</TOKEN>
<TOKEN end_char="3132" id="token-21-28" morph="none" pos="word" start_char="3128">after</TOKEN>
<TOKEN end_char="3138" id="token-21-29" morph="none" pos="word" start_char="3134">being</TOKEN>
<TOKEN end_char="3144" id="token-21-30" morph="none" pos="word" start_char="3140">asked</TOKEN>
<TOKEN end_char="3147" id="token-21-31" morph="none" pos="word" start_char="3146">if</TOKEN>
<TOKEN end_char="3156" id="token-21-32" morph="none" pos="unknown" start_char="3149">COVID-19</TOKEN>
<TOKEN end_char="3162" id="token-21-33" morph="none" pos="word" start_char="3158">could</TOKEN>
<TOKEN end_char="3167" id="token-21-34" morph="none" pos="word" start_char="3164">have</TOKEN>
<TOKEN end_char="3173" id="token-21-35" morph="none" pos="word" start_char="3169">first</TOKEN>
<TOKEN end_char="3181" id="token-21-36" morph="none" pos="word" start_char="3175">emerged</TOKEN>
<TOKEN end_char="3189" id="token-21-37" morph="none" pos="word" start_char="3183">outside</TOKEN>
<TOKEN end_char="3195" id="token-21-38" morph="none" pos="word" start_char="3191">China</TOKEN>
<TOKEN end_char="3196" id="token-21-39" morph="none" pos="punct" start_char="3196">.</TOKEN>
</SEG>
<SEG end_char="3312" id="segment-22" start_char="3199">
<ORIGINAL_TEXT>He repeated that the WHO intended to send researchers to the Wuhan food market to probe the virus origins further.</ORIGINAL_TEXT>
<TOKEN end_char="3200" id="token-22-0" morph="none" pos="word" start_char="3199">He</TOKEN>
<TOKEN end_char="3209" id="token-22-1" morph="none" pos="word" start_char="3202">repeated</TOKEN>
<TOKEN end_char="3214" id="token-22-2" morph="none" pos="word" start_char="3211">that</TOKEN>
<TOKEN end_char="3218" id="token-22-3" morph="none" pos="word" start_char="3216">the</TOKEN>
<TOKEN end_char="3222" id="token-22-4" morph="none" pos="word" start_char="3220">WHO</TOKEN>
<TOKEN end_char="3231" id="token-22-5" morph="none" pos="word" start_char="3224">intended</TOKEN>
<TOKEN end_char="3234" id="token-22-6" morph="none" pos="word" start_char="3233">to</TOKEN>
<TOKEN end_char="3239" id="token-22-7" morph="none" pos="word" start_char="3236">send</TOKEN>
<TOKEN end_char="3251" id="token-22-8" morph="none" pos="word" start_char="3241">researchers</TOKEN>
<TOKEN end_char="3254" id="token-22-9" morph="none" pos="word" start_char="3253">to</TOKEN>
<TOKEN end_char="3258" id="token-22-10" morph="none" pos="word" start_char="3256">the</TOKEN>
<TOKEN end_char="3264" id="token-22-11" morph="none" pos="word" start_char="3260">Wuhan</TOKEN>
<TOKEN end_char="3269" id="token-22-12" morph="none" pos="word" start_char="3266">food</TOKEN>
<TOKEN end_char="3276" id="token-22-13" morph="none" pos="word" start_char="3271">market</TOKEN>
<TOKEN end_char="3279" id="token-22-14" morph="none" pos="word" start_char="3278">to</TOKEN>
<TOKEN end_char="3285" id="token-22-15" morph="none" pos="word" start_char="3281">probe</TOKEN>
<TOKEN end_char="3289" id="token-22-16" morph="none" pos="word" start_char="3287">the</TOKEN>
<TOKEN end_char="3295" id="token-22-17" morph="none" pos="word" start_char="3291">virus</TOKEN>
<TOKEN end_char="3303" id="token-22-18" morph="none" pos="word" start_char="3297">origins</TOKEN>
<TOKEN end_char="3311" id="token-22-19" morph="none" pos="word" start_char="3305">further</TOKEN>
<TOKEN end_char="3312" id="token-22-20" morph="none" pos="punct" start_char="3312">.</TOKEN>
</SEG>
<SEG end_char="3430" id="segment-23" start_char="3315">
<ORIGINAL_TEXT>The WHO has been accused by the Trump administration of being "China-centric", allegations it has repeatedly denied.</ORIGINAL_TEXT>
<TOKEN end_char="3317" id="token-23-0" morph="none" pos="word" start_char="3315">The</TOKEN>
<TOKEN end_char="3321" id="token-23-1" morph="none" pos="word" start_char="3319">WHO</TOKEN>
<TOKEN end_char="3325" id="token-23-2" morph="none" pos="word" start_char="3323">has</TOKEN>
<TOKEN end_char="3330" id="token-23-3" morph="none" pos="word" start_char="3327">been</TOKEN>
<TOKEN end_char="3338" id="token-23-4" morph="none" pos="word" start_char="3332">accused</TOKEN>
<TOKEN end_char="3341" id="token-23-5" morph="none" pos="word" start_char="3340">by</TOKEN>
<TOKEN end_char="3345" id="token-23-6" morph="none" pos="word" start_char="3343">the</TOKEN>
<TOKEN end_char="3351" id="token-23-7" morph="none" pos="word" start_char="3347">Trump</TOKEN>
<TOKEN end_char="3366" id="token-23-8" morph="none" pos="word" start_char="3353">administration</TOKEN>
<TOKEN end_char="3369" id="token-23-9" morph="none" pos="word" start_char="3368">of</TOKEN>
<TOKEN end_char="3375" id="token-23-10" morph="none" pos="word" start_char="3371">being</TOKEN>
<TOKEN end_char="3377" id="token-23-11" morph="none" pos="punct" start_char="3377">"</TOKEN>
<TOKEN end_char="3390" id="token-23-12" morph="none" pos="unknown" start_char="3378">China-centric</TOKEN>
<TOKEN end_char="3392" id="token-23-13" morph="none" pos="punct" start_char="3391">",</TOKEN>
<TOKEN end_char="3404" id="token-23-14" morph="none" pos="word" start_char="3394">allegations</TOKEN>
<TOKEN end_char="3407" id="token-23-15" morph="none" pos="word" start_char="3406">it</TOKEN>
<TOKEN end_char="3411" id="token-23-16" morph="none" pos="word" start_char="3409">has</TOKEN>
<TOKEN end_char="3422" id="token-23-17" morph="none" pos="word" start_char="3413">repeatedly</TOKEN>
<TOKEN end_char="3429" id="token-23-18" morph="none" pos="word" start_char="3424">denied</TOKEN>
<TOKEN end_char="3430" id="token-23-19" morph="none" pos="punct" start_char="3430">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
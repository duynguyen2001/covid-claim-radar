<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CABX" lang="spa" raw_text_char_length="3197" raw_text_md5="c62144077531cf29335673626d8e2c73" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="21" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Coronavirus cover-up?</ORIGINAL_TEXT>
<TOKEN end_char="11" id="token-0-0" morph="none" pos="word" start_char="1">Coronavirus</TOKEN>
<TOKEN end_char="20" id="token-0-1" morph="none" pos="unknown" start_char="13">cover-up</TOKEN>
<TOKEN end_char="21" id="token-0-2" morph="none" pos="punct" start_char="21">?</TOKEN>
</SEG>
<SEG end_char="89" id="segment-1" start_char="23">
<ORIGINAL_TEXT>First case confirmed on Nov 17 NOT end of December, China data says</ORIGINAL_TEXT>
<TOKEN end_char="27" id="token-1-0" morph="none" pos="word" start_char="23">First</TOKEN>
<TOKEN end_char="32" id="token-1-1" morph="none" pos="word" start_char="29">case</TOKEN>
<TOKEN end_char="42" id="token-1-2" morph="none" pos="word" start_char="34">confirmed</TOKEN>
<TOKEN end_char="45" id="token-1-3" morph="none" pos="word" start_char="44">on</TOKEN>
<TOKEN end_char="49" id="token-1-4" morph="none" pos="word" start_char="47">Nov</TOKEN>
<TOKEN end_char="52" id="token-1-5" morph="none" pos="word" start_char="51">17</TOKEN>
<TOKEN end_char="56" id="token-1-6" morph="none" pos="word" start_char="54">NOT</TOKEN>
<TOKEN end_char="60" id="token-1-7" morph="none" pos="word" start_char="58">end</TOKEN>
<TOKEN end_char="63" id="token-1-8" morph="none" pos="word" start_char="62">of</TOKEN>
<TOKEN end_char="72" id="token-1-9" morph="none" pos="word" start_char="65">December</TOKEN>
<TOKEN end_char="73" id="token-1-10" morph="none" pos="punct" start_char="73">,</TOKEN>
<TOKEN end_char="79" id="token-1-11" morph="none" pos="word" start_char="75">China</TOKEN>
<TOKEN end_char="84" id="token-1-12" morph="none" pos="word" start_char="81">data</TOKEN>
<TOKEN end_char="89" id="token-1-13" morph="none" pos="word" start_char="86">says</TOKEN>
</SEG>
<SEG end_char="378" id="segment-2" start_char="93">
<ORIGINAL_TEXT>Data compiled by the authorities suggesting the outbreak got underway significantly will doubtless prove concerning to the international medical community - and Chinese health officials now scrambling to trace undocumented cases in a bid to better understand how the illness has spread.</ORIGINAL_TEXT>
<TOKEN end_char="96" id="token-2-0" morph="none" pos="word" start_char="93">Data</TOKEN>
<TOKEN end_char="105" id="token-2-1" morph="none" pos="word" start_char="98">compiled</TOKEN>
<TOKEN end_char="108" id="token-2-2" morph="none" pos="word" start_char="107">by</TOKEN>
<TOKEN end_char="112" id="token-2-3" morph="none" pos="word" start_char="110">the</TOKEN>
<TOKEN end_char="124" id="token-2-4" morph="none" pos="word" start_char="114">authorities</TOKEN>
<TOKEN end_char="135" id="token-2-5" morph="none" pos="word" start_char="126">suggesting</TOKEN>
<TOKEN end_char="139" id="token-2-6" morph="none" pos="word" start_char="137">the</TOKEN>
<TOKEN end_char="148" id="token-2-7" morph="none" pos="word" start_char="141">outbreak</TOKEN>
<TOKEN end_char="152" id="token-2-8" morph="none" pos="word" start_char="150">got</TOKEN>
<TOKEN end_char="161" id="token-2-9" morph="none" pos="word" start_char="154">underway</TOKEN>
<TOKEN end_char="175" id="token-2-10" morph="none" pos="word" start_char="163">significantly</TOKEN>
<TOKEN end_char="180" id="token-2-11" morph="none" pos="word" start_char="177">will</TOKEN>
<TOKEN end_char="190" id="token-2-12" morph="none" pos="word" start_char="182">doubtless</TOKEN>
<TOKEN end_char="196" id="token-2-13" morph="none" pos="word" start_char="192">prove</TOKEN>
<TOKEN end_char="207" id="token-2-14" morph="none" pos="word" start_char="198">concerning</TOKEN>
<TOKEN end_char="210" id="token-2-15" morph="none" pos="word" start_char="209">to</TOKEN>
<TOKEN end_char="214" id="token-2-16" morph="none" pos="word" start_char="212">the</TOKEN>
<TOKEN end_char="228" id="token-2-17" morph="none" pos="word" start_char="216">international</TOKEN>
<TOKEN end_char="236" id="token-2-18" morph="none" pos="word" start_char="230">medical</TOKEN>
<TOKEN end_char="246" id="token-2-19" morph="none" pos="word" start_char="238">community</TOKEN>
<TOKEN end_char="248" id="token-2-20" morph="none" pos="punct" start_char="248">-</TOKEN>
<TOKEN end_char="252" id="token-2-21" morph="none" pos="word" start_char="250">and</TOKEN>
<TOKEN end_char="260" id="token-2-22" morph="none" pos="word" start_char="254">Chinese</TOKEN>
<TOKEN end_char="267" id="token-2-23" morph="none" pos="word" start_char="262">health</TOKEN>
<TOKEN end_char="277" id="token-2-24" morph="none" pos="word" start_char="269">officials</TOKEN>
<TOKEN end_char="281" id="token-2-25" morph="none" pos="word" start_char="279">now</TOKEN>
<TOKEN end_char="292" id="token-2-26" morph="none" pos="word" start_char="283">scrambling</TOKEN>
<TOKEN end_char="295" id="token-2-27" morph="none" pos="word" start_char="294">to</TOKEN>
<TOKEN end_char="301" id="token-2-28" morph="none" pos="word" start_char="297">trace</TOKEN>
<TOKEN end_char="314" id="token-2-29" morph="none" pos="word" start_char="303">undocumented</TOKEN>
<TOKEN end_char="320" id="token-2-30" morph="none" pos="word" start_char="316">cases</TOKEN>
<TOKEN end_char="323" id="token-2-31" morph="none" pos="word" start_char="322">in</TOKEN>
<TOKEN end_char="325" id="token-2-32" morph="none" pos="word" start_char="325">a</TOKEN>
<TOKEN end_char="329" id="token-2-33" morph="none" pos="word" start_char="327">bid</TOKEN>
<TOKEN end_char="332" id="token-2-34" morph="none" pos="word" start_char="331">to</TOKEN>
<TOKEN end_char="339" id="token-2-35" morph="none" pos="word" start_char="334">better</TOKEN>
<TOKEN end_char="350" id="token-2-36" morph="none" pos="word" start_char="341">understand</TOKEN>
<TOKEN end_char="354" id="token-2-37" morph="none" pos="word" start_char="352">how</TOKEN>
<TOKEN end_char="358" id="token-2-38" morph="none" pos="word" start_char="356">the</TOKEN>
<TOKEN end_char="366" id="token-2-39" morph="none" pos="word" start_char="360">illness</TOKEN>
<TOKEN end_char="370" id="token-2-40" morph="none" pos="word" start_char="368">has</TOKEN>
<TOKEN end_char="377" id="token-2-41" morph="none" pos="word" start_char="372">spread</TOKEN>
<TOKEN end_char="378" id="token-2-42" morph="none" pos="punct" start_char="378">.</TOKEN>
</SEG>
<SEG end_char="538" id="segment-3" start_char="380">
<ORIGINAL_TEXT>Up to now, it was widely believed that the disease emerged at the end of November after cases associated with a seafood market in Wuhan began to be identified.</ORIGINAL_TEXT>
<TOKEN end_char="381" id="token-3-0" morph="none" pos="word" start_char="380">Up</TOKEN>
<TOKEN end_char="384" id="token-3-1" morph="none" pos="word" start_char="383">to</TOKEN>
<TOKEN end_char="388" id="token-3-2" morph="none" pos="word" start_char="386">now</TOKEN>
<TOKEN end_char="389" id="token-3-3" morph="none" pos="punct" start_char="389">,</TOKEN>
<TOKEN end_char="392" id="token-3-4" morph="none" pos="word" start_char="391">it</TOKEN>
<TOKEN end_char="396" id="token-3-5" morph="none" pos="word" start_char="394">was</TOKEN>
<TOKEN end_char="403" id="token-3-6" morph="none" pos="word" start_char="398">widely</TOKEN>
<TOKEN end_char="412" id="token-3-7" morph="none" pos="word" start_char="405">believed</TOKEN>
<TOKEN end_char="417" id="token-3-8" morph="none" pos="word" start_char="414">that</TOKEN>
<TOKEN end_char="421" id="token-3-9" morph="none" pos="word" start_char="419">the</TOKEN>
<TOKEN end_char="429" id="token-3-10" morph="none" pos="word" start_char="423">disease</TOKEN>
<TOKEN end_char="437" id="token-3-11" morph="none" pos="word" start_char="431">emerged</TOKEN>
<TOKEN end_char="440" id="token-3-12" morph="none" pos="word" start_char="439">at</TOKEN>
<TOKEN end_char="444" id="token-3-13" morph="none" pos="word" start_char="442">the</TOKEN>
<TOKEN end_char="448" id="token-3-14" morph="none" pos="word" start_char="446">end</TOKEN>
<TOKEN end_char="451" id="token-3-15" morph="none" pos="word" start_char="450">of</TOKEN>
<TOKEN end_char="460" id="token-3-16" morph="none" pos="word" start_char="453">November</TOKEN>
<TOKEN end_char="466" id="token-3-17" morph="none" pos="word" start_char="462">after</TOKEN>
<TOKEN end_char="472" id="token-3-18" morph="none" pos="word" start_char="468">cases</TOKEN>
<TOKEN end_char="483" id="token-3-19" morph="none" pos="word" start_char="474">associated</TOKEN>
<TOKEN end_char="488" id="token-3-20" morph="none" pos="word" start_char="485">with</TOKEN>
<TOKEN end_char="490" id="token-3-21" morph="none" pos="word" start_char="490">a</TOKEN>
<TOKEN end_char="498" id="token-3-22" morph="none" pos="word" start_char="492">seafood</TOKEN>
<TOKEN end_char="505" id="token-3-23" morph="none" pos="word" start_char="500">market</TOKEN>
<TOKEN end_char="508" id="token-3-24" morph="none" pos="word" start_char="507">in</TOKEN>
<TOKEN end_char="514" id="token-3-25" morph="none" pos="word" start_char="510">Wuhan</TOKEN>
<TOKEN end_char="520" id="token-3-26" morph="none" pos="word" start_char="516">began</TOKEN>
<TOKEN end_char="523" id="token-3-27" morph="none" pos="word" start_char="522">to</TOKEN>
<TOKEN end_char="526" id="token-3-28" morph="none" pos="word" start_char="525">be</TOKEN>
<TOKEN end_char="537" id="token-3-29" morph="none" pos="word" start_char="528">identified</TOKEN>
<TOKEN end_char="538" id="token-3-30" morph="none" pos="punct" start_char="538">.</TOKEN>
</SEG>
<SEG end_char="760" id="segment-4" start_char="541">
<ORIGINAL_TEXT>The World Health Organization issued a press release on January 5, warning of a "mystery lung disease" which had first been reported on New Year's Eve in Wuhan, and which had infected 44 people, leaving 11 seriously ill.</ORIGINAL_TEXT>
<TOKEN end_char="543" id="token-4-0" morph="none" pos="word" start_char="541">The</TOKEN>
<TOKEN end_char="549" id="token-4-1" morph="none" pos="word" start_char="545">World</TOKEN>
<TOKEN end_char="556" id="token-4-2" morph="none" pos="word" start_char="551">Health</TOKEN>
<TOKEN end_char="569" id="token-4-3" morph="none" pos="word" start_char="558">Organization</TOKEN>
<TOKEN end_char="576" id="token-4-4" morph="none" pos="word" start_char="571">issued</TOKEN>
<TOKEN end_char="578" id="token-4-5" morph="none" pos="word" start_char="578">a</TOKEN>
<TOKEN end_char="584" id="token-4-6" morph="none" pos="word" start_char="580">press</TOKEN>
<TOKEN end_char="592" id="token-4-7" morph="none" pos="word" start_char="586">release</TOKEN>
<TOKEN end_char="595" id="token-4-8" morph="none" pos="word" start_char="594">on</TOKEN>
<TOKEN end_char="603" id="token-4-9" morph="none" pos="word" start_char="597">January</TOKEN>
<TOKEN end_char="605" id="token-4-10" morph="none" pos="word" start_char="605">5</TOKEN>
<TOKEN end_char="606" id="token-4-11" morph="none" pos="punct" start_char="606">,</TOKEN>
<TOKEN end_char="614" id="token-4-12" morph="none" pos="word" start_char="608">warning</TOKEN>
<TOKEN end_char="617" id="token-4-13" morph="none" pos="word" start_char="616">of</TOKEN>
<TOKEN end_char="619" id="token-4-14" morph="none" pos="word" start_char="619">a</TOKEN>
<TOKEN end_char="621" id="token-4-15" morph="none" pos="punct" start_char="621">"</TOKEN>
<TOKEN end_char="628" id="token-4-16" morph="none" pos="word" start_char="622">mystery</TOKEN>
<TOKEN end_char="633" id="token-4-17" morph="none" pos="word" start_char="630">lung</TOKEN>
<TOKEN end_char="641" id="token-4-18" morph="none" pos="word" start_char="635">disease</TOKEN>
<TOKEN end_char="642" id="token-4-19" morph="none" pos="punct" start_char="642">"</TOKEN>
<TOKEN end_char="648" id="token-4-20" morph="none" pos="word" start_char="644">which</TOKEN>
<TOKEN end_char="652" id="token-4-21" morph="none" pos="word" start_char="650">had</TOKEN>
<TOKEN end_char="658" id="token-4-22" morph="none" pos="word" start_char="654">first</TOKEN>
<TOKEN end_char="663" id="token-4-23" morph="none" pos="word" start_char="660">been</TOKEN>
<TOKEN end_char="672" id="token-4-24" morph="none" pos="word" start_char="665">reported</TOKEN>
<TOKEN end_char="675" id="token-4-25" morph="none" pos="word" start_char="674">on</TOKEN>
<TOKEN end_char="679" id="token-4-26" morph="none" pos="word" start_char="677">New</TOKEN>
<TOKEN end_char="686" id="token-4-27" morph="none" pos="word" start_char="681">Year's</TOKEN>
<TOKEN end_char="690" id="token-4-28" morph="none" pos="word" start_char="688">Eve</TOKEN>
<TOKEN end_char="693" id="token-4-29" morph="none" pos="word" start_char="692">in</TOKEN>
<TOKEN end_char="699" id="token-4-30" morph="none" pos="word" start_char="695">Wuhan</TOKEN>
<TOKEN end_char="700" id="token-4-31" morph="none" pos="punct" start_char="700">,</TOKEN>
<TOKEN end_char="704" id="token-4-32" morph="none" pos="word" start_char="702">and</TOKEN>
<TOKEN end_char="710" id="token-4-33" morph="none" pos="word" start_char="706">which</TOKEN>
<TOKEN end_char="714" id="token-4-34" morph="none" pos="word" start_char="712">had</TOKEN>
<TOKEN end_char="723" id="token-4-35" morph="none" pos="word" start_char="716">infected</TOKEN>
<TOKEN end_char="726" id="token-4-36" morph="none" pos="word" start_char="725">44</TOKEN>
<TOKEN end_char="733" id="token-4-37" morph="none" pos="word" start_char="728">people</TOKEN>
<TOKEN end_char="734" id="token-4-38" morph="none" pos="punct" start_char="734">,</TOKEN>
<TOKEN end_char="742" id="token-4-39" morph="none" pos="word" start_char="736">leaving</TOKEN>
<TOKEN end_char="745" id="token-4-40" morph="none" pos="word" start_char="744">11</TOKEN>
<TOKEN end_char="755" id="token-4-41" morph="none" pos="word" start_char="747">seriously</TOKEN>
<TOKEN end_char="759" id="token-4-42" morph="none" pos="word" start_char="757">ill</TOKEN>
<TOKEN end_char="760" id="token-4-43" morph="none" pos="punct" start_char="760">.</TOKEN>
</SEG>
<SEG end_char="830" id="segment-5" start_char="763">
<ORIGINAL_TEXT>However, it now appears the disease originated considerably earlier.</ORIGINAL_TEXT>
<TOKEN end_char="769" id="token-5-0" morph="none" pos="word" start_char="763">However</TOKEN>
<TOKEN end_char="770" id="token-5-1" morph="none" pos="punct" start_char="770">,</TOKEN>
<TOKEN end_char="773" id="token-5-2" morph="none" pos="word" start_char="772">it</TOKEN>
<TOKEN end_char="777" id="token-5-3" morph="none" pos="word" start_char="775">now</TOKEN>
<TOKEN end_char="785" id="token-5-4" morph="none" pos="word" start_char="779">appears</TOKEN>
<TOKEN end_char="789" id="token-5-5" morph="none" pos="word" start_char="787">the</TOKEN>
<TOKEN end_char="797" id="token-5-6" morph="none" pos="word" start_char="791">disease</TOKEN>
<TOKEN end_char="808" id="token-5-7" morph="none" pos="word" start_char="799">originated</TOKEN>
<TOKEN end_char="821" id="token-5-8" morph="none" pos="word" start_char="810">considerably</TOKEN>
<TOKEN end_char="829" id="token-5-9" morph="none" pos="word" start_char="823">earlier</TOKEN>
<TOKEN end_char="830" id="token-5-10" morph="none" pos="punct" start_char="830">.</TOKEN>
</SEG>
<SEG end_char="996" id="segment-6" start_char="833">
<ORIGINAL_TEXT>Data gathered by the Chinese government indicates at least 266 people who were infected last year, all of whom were placed under medical surveillance at some stage.</ORIGINAL_TEXT>
<TOKEN end_char="836" id="token-6-0" morph="none" pos="word" start_char="833">Data</TOKEN>
<TOKEN end_char="845" id="token-6-1" morph="none" pos="word" start_char="838">gathered</TOKEN>
<TOKEN end_char="848" id="token-6-2" morph="none" pos="word" start_char="847">by</TOKEN>
<TOKEN end_char="852" id="token-6-3" morph="none" pos="word" start_char="850">the</TOKEN>
<TOKEN end_char="860" id="token-6-4" morph="none" pos="word" start_char="854">Chinese</TOKEN>
<TOKEN end_char="871" id="token-6-5" morph="none" pos="word" start_char="862">government</TOKEN>
<TOKEN end_char="881" id="token-6-6" morph="none" pos="word" start_char="873">indicates</TOKEN>
<TOKEN end_char="884" id="token-6-7" morph="none" pos="word" start_char="883">at</TOKEN>
<TOKEN end_char="890" id="token-6-8" morph="none" pos="word" start_char="886">least</TOKEN>
<TOKEN end_char="894" id="token-6-9" morph="none" pos="word" start_char="892">266</TOKEN>
<TOKEN end_char="901" id="token-6-10" morph="none" pos="word" start_char="896">people</TOKEN>
<TOKEN end_char="905" id="token-6-11" morph="none" pos="word" start_char="903">who</TOKEN>
<TOKEN end_char="910" id="token-6-12" morph="none" pos="word" start_char="907">were</TOKEN>
<TOKEN end_char="919" id="token-6-13" morph="none" pos="word" start_char="912">infected</TOKEN>
<TOKEN end_char="924" id="token-6-14" morph="none" pos="word" start_char="921">last</TOKEN>
<TOKEN end_char="929" id="token-6-15" morph="none" pos="word" start_char="926">year</TOKEN>
<TOKEN end_char="930" id="token-6-16" morph="none" pos="punct" start_char="930">,</TOKEN>
<TOKEN end_char="934" id="token-6-17" morph="none" pos="word" start_char="932">all</TOKEN>
<TOKEN end_char="937" id="token-6-18" morph="none" pos="word" start_char="936">of</TOKEN>
<TOKEN end_char="942" id="token-6-19" morph="none" pos="word" start_char="939">whom</TOKEN>
<TOKEN end_char="947" id="token-6-20" morph="none" pos="word" start_char="944">were</TOKEN>
<TOKEN end_char="954" id="token-6-21" morph="none" pos="word" start_char="949">placed</TOKEN>
<TOKEN end_char="960" id="token-6-22" morph="none" pos="word" start_char="956">under</TOKEN>
<TOKEN end_char="968" id="token-6-23" morph="none" pos="word" start_char="962">medical</TOKEN>
<TOKEN end_char="981" id="token-6-24" morph="none" pos="word" start_char="970">surveillance</TOKEN>
<TOKEN end_char="984" id="token-6-25" morph="none" pos="word" start_char="983">at</TOKEN>
<TOKEN end_char="989" id="token-6-26" morph="none" pos="word" start_char="986">some</TOKEN>
<TOKEN end_char="995" id="token-6-27" morph="none" pos="word" start_char="991">stage</TOKEN>
<TOKEN end_char="996" id="token-6-28" morph="none" pos="punct" start_char="996">.</TOKEN>
</SEG>
<SEG end_char="1135" id="segment-7" start_char="999">
<ORIGINAL_TEXT>A proportion of the figure has probably been backdated as a result of health authorities testing specimens taken from suspected patients.</ORIGINAL_TEXT>
<TOKEN end_char="999" id="token-7-0" morph="none" pos="word" start_char="999">A</TOKEN>
<TOKEN end_char="1010" id="token-7-1" morph="none" pos="word" start_char="1001">proportion</TOKEN>
<TOKEN end_char="1013" id="token-7-2" morph="none" pos="word" start_char="1012">of</TOKEN>
<TOKEN end_char="1017" id="token-7-3" morph="none" pos="word" start_char="1015">the</TOKEN>
<TOKEN end_char="1024" id="token-7-4" morph="none" pos="word" start_char="1019">figure</TOKEN>
<TOKEN end_char="1028" id="token-7-5" morph="none" pos="word" start_char="1026">has</TOKEN>
<TOKEN end_char="1037" id="token-7-6" morph="none" pos="word" start_char="1030">probably</TOKEN>
<TOKEN end_char="1042" id="token-7-7" morph="none" pos="word" start_char="1039">been</TOKEN>
<TOKEN end_char="1052" id="token-7-8" morph="none" pos="word" start_char="1044">backdated</TOKEN>
<TOKEN end_char="1055" id="token-7-9" morph="none" pos="word" start_char="1054">as</TOKEN>
<TOKEN end_char="1057" id="token-7-10" morph="none" pos="word" start_char="1057">a</TOKEN>
<TOKEN end_char="1064" id="token-7-11" morph="none" pos="word" start_char="1059">result</TOKEN>
<TOKEN end_char="1067" id="token-7-12" morph="none" pos="word" start_char="1066">of</TOKEN>
<TOKEN end_char="1074" id="token-7-13" morph="none" pos="word" start_char="1069">health</TOKEN>
<TOKEN end_char="1086" id="token-7-14" morph="none" pos="word" start_char="1076">authorities</TOKEN>
<TOKEN end_char="1094" id="token-7-15" morph="none" pos="word" start_char="1088">testing</TOKEN>
<TOKEN end_char="1104" id="token-7-16" morph="none" pos="word" start_char="1096">specimens</TOKEN>
<TOKEN end_char="1110" id="token-7-17" morph="none" pos="word" start_char="1106">taken</TOKEN>
<TOKEN end_char="1115" id="token-7-18" morph="none" pos="word" start_char="1112">from</TOKEN>
<TOKEN end_char="1125" id="token-7-19" morph="none" pos="word" start_char="1117">suspected</TOKEN>
<TOKEN end_char="1134" id="token-7-20" morph="none" pos="word" start_char="1127">patients</TOKEN>
<TOKEN end_char="1135" id="token-7-21" morph="none" pos="punct" start_char="1135">.</TOKEN>
</SEG>
<SEG end_char="1244" id="segment-8" start_char="1138">
<ORIGINAL_TEXT>The data suggests the first person to have contracted Covid-19 may have been a 55-year-old, on November 17.</ORIGINAL_TEXT>
<TOKEN end_char="1140" id="token-8-0" morph="none" pos="word" start_char="1138">The</TOKEN>
<TOKEN end_char="1145" id="token-8-1" morph="none" pos="word" start_char="1142">data</TOKEN>
<TOKEN end_char="1154" id="token-8-2" morph="none" pos="word" start_char="1147">suggests</TOKEN>
<TOKEN end_char="1158" id="token-8-3" morph="none" pos="word" start_char="1156">the</TOKEN>
<TOKEN end_char="1164" id="token-8-4" morph="none" pos="word" start_char="1160">first</TOKEN>
<TOKEN end_char="1171" id="token-8-5" morph="none" pos="word" start_char="1166">person</TOKEN>
<TOKEN end_char="1174" id="token-8-6" morph="none" pos="word" start_char="1173">to</TOKEN>
<TOKEN end_char="1179" id="token-8-7" morph="none" pos="word" start_char="1176">have</TOKEN>
<TOKEN end_char="1190" id="token-8-8" morph="none" pos="word" start_char="1181">contracted</TOKEN>
<TOKEN end_char="1199" id="token-8-9" morph="none" pos="unknown" start_char="1192">Covid-19</TOKEN>
<TOKEN end_char="1203" id="token-8-10" morph="none" pos="word" start_char="1201">may</TOKEN>
<TOKEN end_char="1208" id="token-8-11" morph="none" pos="word" start_char="1205">have</TOKEN>
<TOKEN end_char="1213" id="token-8-12" morph="none" pos="word" start_char="1210">been</TOKEN>
<TOKEN end_char="1215" id="token-8-13" morph="none" pos="word" start_char="1215">a</TOKEN>
<TOKEN end_char="1227" id="token-8-14" morph="none" pos="unknown" start_char="1217">55-year-old</TOKEN>
<TOKEN end_char="1228" id="token-8-15" morph="none" pos="punct" start_char="1228">,</TOKEN>
<TOKEN end_char="1231" id="token-8-16" morph="none" pos="word" start_char="1230">on</TOKEN>
<TOKEN end_char="1240" id="token-8-17" morph="none" pos="word" start_char="1233">November</TOKEN>
<TOKEN end_char="1243" id="token-8-18" morph="none" pos="word" start_char="1242">17</TOKEN>
<TOKEN end_char="1244" id="token-8-19" morph="none" pos="punct" start_char="1244">.</TOKEN>
</SEG>
<SEG end_char="1519" id="segment-9" start_char="1247">
<ORIGINAL_TEXT>Afterwards, between one and five new cases a day were reported, with the number of cases rising to 27 by December 15, and to 60 by December 20 - 11 days before the date mentioned in the WHO's press release, although the WHO's website puts the first infection to December 8.</ORIGINAL_TEXT>
<TOKEN end_char="1256" id="token-9-0" morph="none" pos="word" start_char="1247">Afterwards</TOKEN>
<TOKEN end_char="1257" id="token-9-1" morph="none" pos="punct" start_char="1257">,</TOKEN>
<TOKEN end_char="1265" id="token-9-2" morph="none" pos="word" start_char="1259">between</TOKEN>
<TOKEN end_char="1269" id="token-9-3" morph="none" pos="word" start_char="1267">one</TOKEN>
<TOKEN end_char="1273" id="token-9-4" morph="none" pos="word" start_char="1271">and</TOKEN>
<TOKEN end_char="1278" id="token-9-5" morph="none" pos="word" start_char="1275">five</TOKEN>
<TOKEN end_char="1282" id="token-9-6" morph="none" pos="word" start_char="1280">new</TOKEN>
<TOKEN end_char="1288" id="token-9-7" morph="none" pos="word" start_char="1284">cases</TOKEN>
<TOKEN end_char="1290" id="token-9-8" morph="none" pos="word" start_char="1290">a</TOKEN>
<TOKEN end_char="1294" id="token-9-9" morph="none" pos="word" start_char="1292">day</TOKEN>
<TOKEN end_char="1299" id="token-9-10" morph="none" pos="word" start_char="1296">were</TOKEN>
<TOKEN end_char="1308" id="token-9-11" morph="none" pos="word" start_char="1301">reported</TOKEN>
<TOKEN end_char="1309" id="token-9-12" morph="none" pos="punct" start_char="1309">,</TOKEN>
<TOKEN end_char="1314" id="token-9-13" morph="none" pos="word" start_char="1311">with</TOKEN>
<TOKEN end_char="1318" id="token-9-14" morph="none" pos="word" start_char="1316">the</TOKEN>
<TOKEN end_char="1325" id="token-9-15" morph="none" pos="word" start_char="1320">number</TOKEN>
<TOKEN end_char="1328" id="token-9-16" morph="none" pos="word" start_char="1327">of</TOKEN>
<TOKEN end_char="1334" id="token-9-17" morph="none" pos="word" start_char="1330">cases</TOKEN>
<TOKEN end_char="1341" id="token-9-18" morph="none" pos="word" start_char="1336">rising</TOKEN>
<TOKEN end_char="1344" id="token-9-19" morph="none" pos="word" start_char="1343">to</TOKEN>
<TOKEN end_char="1347" id="token-9-20" morph="none" pos="word" start_char="1346">27</TOKEN>
<TOKEN end_char="1350" id="token-9-21" morph="none" pos="word" start_char="1349">by</TOKEN>
<TOKEN end_char="1359" id="token-9-22" morph="none" pos="word" start_char="1352">December</TOKEN>
<TOKEN end_char="1362" id="token-9-23" morph="none" pos="word" start_char="1361">15</TOKEN>
<TOKEN end_char="1363" id="token-9-24" morph="none" pos="punct" start_char="1363">,</TOKEN>
<TOKEN end_char="1367" id="token-9-25" morph="none" pos="word" start_char="1365">and</TOKEN>
<TOKEN end_char="1370" id="token-9-26" morph="none" pos="word" start_char="1369">to</TOKEN>
<TOKEN end_char="1373" id="token-9-27" morph="none" pos="word" start_char="1372">60</TOKEN>
<TOKEN end_char="1376" id="token-9-28" morph="none" pos="word" start_char="1375">by</TOKEN>
<TOKEN end_char="1385" id="token-9-29" morph="none" pos="word" start_char="1378">December</TOKEN>
<TOKEN end_char="1388" id="token-9-30" morph="none" pos="word" start_char="1387">20</TOKEN>
<TOKEN end_char="1390" id="token-9-31" morph="none" pos="punct" start_char="1390">-</TOKEN>
<TOKEN end_char="1393" id="token-9-32" morph="none" pos="word" start_char="1392">11</TOKEN>
<TOKEN end_char="1398" id="token-9-33" morph="none" pos="word" start_char="1395">days</TOKEN>
<TOKEN end_char="1405" id="token-9-34" morph="none" pos="word" start_char="1400">before</TOKEN>
<TOKEN end_char="1409" id="token-9-35" morph="none" pos="word" start_char="1407">the</TOKEN>
<TOKEN end_char="1414" id="token-9-36" morph="none" pos="word" start_char="1411">date</TOKEN>
<TOKEN end_char="1424" id="token-9-37" morph="none" pos="word" start_char="1416">mentioned</TOKEN>
<TOKEN end_char="1427" id="token-9-38" morph="none" pos="word" start_char="1426">in</TOKEN>
<TOKEN end_char="1431" id="token-9-39" morph="none" pos="word" start_char="1429">the</TOKEN>
<TOKEN end_char="1437" id="token-9-40" morph="none" pos="word" start_char="1433">WHO's</TOKEN>
<TOKEN end_char="1443" id="token-9-41" morph="none" pos="word" start_char="1439">press</TOKEN>
<TOKEN end_char="1451" id="token-9-42" morph="none" pos="word" start_char="1445">release</TOKEN>
<TOKEN end_char="1452" id="token-9-43" morph="none" pos="punct" start_char="1452">,</TOKEN>
<TOKEN end_char="1461" id="token-9-44" morph="none" pos="word" start_char="1454">although</TOKEN>
<TOKEN end_char="1465" id="token-9-45" morph="none" pos="word" start_char="1463">the</TOKEN>
<TOKEN end_char="1471" id="token-9-46" morph="none" pos="word" start_char="1467">WHO's</TOKEN>
<TOKEN end_char="1479" id="token-9-47" morph="none" pos="word" start_char="1473">website</TOKEN>
<TOKEN end_char="1484" id="token-9-48" morph="none" pos="word" start_char="1481">puts</TOKEN>
<TOKEN end_char="1488" id="token-9-49" morph="none" pos="word" start_char="1486">the</TOKEN>
<TOKEN end_char="1494" id="token-9-50" morph="none" pos="word" start_char="1490">first</TOKEN>
<TOKEN end_char="1504" id="token-9-51" morph="none" pos="word" start_char="1496">infection</TOKEN>
<TOKEN end_char="1507" id="token-9-52" morph="none" pos="word" start_char="1506">to</TOKEN>
<TOKEN end_char="1516" id="token-9-53" morph="none" pos="word" start_char="1509">December</TOKEN>
<TOKEN end_char="1518" id="token-9-54" morph="none" pos="word" start_char="1518">8</TOKEN>
<TOKEN end_char="1519" id="token-9-55" morph="none" pos="punct" start_char="1519">.</TOKEN>
</SEG>
<SEG end_char="1660" id="segment-10" start_char="1522">
<ORIGINAL_TEXT>On the first day of 2020, the figure stood at 381 - several days before the first reports of the illness began to surface in Western media.</ORIGINAL_TEXT>
<TOKEN end_char="1523" id="token-10-0" morph="none" pos="word" start_char="1522">On</TOKEN>
<TOKEN end_char="1527" id="token-10-1" morph="none" pos="word" start_char="1525">the</TOKEN>
<TOKEN end_char="1533" id="token-10-2" morph="none" pos="word" start_char="1529">first</TOKEN>
<TOKEN end_char="1537" id="token-10-3" morph="none" pos="word" start_char="1535">day</TOKEN>
<TOKEN end_char="1540" id="token-10-4" morph="none" pos="word" start_char="1539">of</TOKEN>
<TOKEN end_char="1545" id="token-10-5" morph="none" pos="word" start_char="1542">2020</TOKEN>
<TOKEN end_char="1546" id="token-10-6" morph="none" pos="punct" start_char="1546">,</TOKEN>
<TOKEN end_char="1550" id="token-10-7" morph="none" pos="word" start_char="1548">the</TOKEN>
<TOKEN end_char="1557" id="token-10-8" morph="none" pos="word" start_char="1552">figure</TOKEN>
<TOKEN end_char="1563" id="token-10-9" morph="none" pos="word" start_char="1559">stood</TOKEN>
<TOKEN end_char="1566" id="token-10-10" morph="none" pos="word" start_char="1565">at</TOKEN>
<TOKEN end_char="1570" id="token-10-11" morph="none" pos="word" start_char="1568">381</TOKEN>
<TOKEN end_char="1572" id="token-10-12" morph="none" pos="punct" start_char="1572">-</TOKEN>
<TOKEN end_char="1580" id="token-10-13" morph="none" pos="word" start_char="1574">several</TOKEN>
<TOKEN end_char="1585" id="token-10-14" morph="none" pos="word" start_char="1582">days</TOKEN>
<TOKEN end_char="1592" id="token-10-15" morph="none" pos="word" start_char="1587">before</TOKEN>
<TOKEN end_char="1596" id="token-10-16" morph="none" pos="word" start_char="1594">the</TOKEN>
<TOKEN end_char="1602" id="token-10-17" morph="none" pos="word" start_char="1598">first</TOKEN>
<TOKEN end_char="1610" id="token-10-18" morph="none" pos="word" start_char="1604">reports</TOKEN>
<TOKEN end_char="1613" id="token-10-19" morph="none" pos="word" start_char="1612">of</TOKEN>
<TOKEN end_char="1617" id="token-10-20" morph="none" pos="word" start_char="1615">the</TOKEN>
<TOKEN end_char="1625" id="token-10-21" morph="none" pos="word" start_char="1619">illness</TOKEN>
<TOKEN end_char="1631" id="token-10-22" morph="none" pos="word" start_char="1627">began</TOKEN>
<TOKEN end_char="1634" id="token-10-23" morph="none" pos="word" start_char="1633">to</TOKEN>
<TOKEN end_char="1642" id="token-10-24" morph="none" pos="word" start_char="1636">surface</TOKEN>
<TOKEN end_char="1645" id="token-10-25" morph="none" pos="word" start_char="1644">in</TOKEN>
<TOKEN end_char="1653" id="token-10-26" morph="none" pos="word" start_char="1647">Western</TOKEN>
<TOKEN end_char="1659" id="token-10-27" morph="none" pos="word" start_char="1655">media</TOKEN>
<TOKEN end_char="1660" id="token-10-28" morph="none" pos="punct" start_char="1660">.</TOKEN>
</SEG>
<SEG end_char="1863" id="segment-11" start_char="1663">
<ORIGINAL_TEXT>Scientists are now urgently trying to identify patient zero, which would enable them to trace the source of the disease, which epidemiologists think jumped to humans from a wild animal, possibly a bat.</ORIGINAL_TEXT>
<TOKEN end_char="1672" id="token-11-0" morph="none" pos="word" start_char="1663">Scientists</TOKEN>
<TOKEN end_char="1676" id="token-11-1" morph="none" pos="word" start_char="1674">are</TOKEN>
<TOKEN end_char="1680" id="token-11-2" morph="none" pos="word" start_char="1678">now</TOKEN>
<TOKEN end_char="1689" id="token-11-3" morph="none" pos="word" start_char="1682">urgently</TOKEN>
<TOKEN end_char="1696" id="token-11-4" morph="none" pos="word" start_char="1691">trying</TOKEN>
<TOKEN end_char="1699" id="token-11-5" morph="none" pos="word" start_char="1698">to</TOKEN>
<TOKEN end_char="1708" id="token-11-6" morph="none" pos="word" start_char="1701">identify</TOKEN>
<TOKEN end_char="1716" id="token-11-7" morph="none" pos="word" start_char="1710">patient</TOKEN>
<TOKEN end_char="1721" id="token-11-8" morph="none" pos="word" start_char="1718">zero</TOKEN>
<TOKEN end_char="1722" id="token-11-9" morph="none" pos="punct" start_char="1722">,</TOKEN>
<TOKEN end_char="1728" id="token-11-10" morph="none" pos="word" start_char="1724">which</TOKEN>
<TOKEN end_char="1734" id="token-11-11" morph="none" pos="word" start_char="1730">would</TOKEN>
<TOKEN end_char="1741" id="token-11-12" morph="none" pos="word" start_char="1736">enable</TOKEN>
<TOKEN end_char="1746" id="token-11-13" morph="none" pos="word" start_char="1743">them</TOKEN>
<TOKEN end_char="1749" id="token-11-14" morph="none" pos="word" start_char="1748">to</TOKEN>
<TOKEN end_char="1755" id="token-11-15" morph="none" pos="word" start_char="1751">trace</TOKEN>
<TOKEN end_char="1759" id="token-11-16" morph="none" pos="word" start_char="1757">the</TOKEN>
<TOKEN end_char="1766" id="token-11-17" morph="none" pos="word" start_char="1761">source</TOKEN>
<TOKEN end_char="1769" id="token-11-18" morph="none" pos="word" start_char="1768">of</TOKEN>
<TOKEN end_char="1773" id="token-11-19" morph="none" pos="word" start_char="1771">the</TOKEN>
<TOKEN end_char="1781" id="token-11-20" morph="none" pos="word" start_char="1775">disease</TOKEN>
<TOKEN end_char="1782" id="token-11-21" morph="none" pos="punct" start_char="1782">,</TOKEN>
<TOKEN end_char="1788" id="token-11-22" morph="none" pos="word" start_char="1784">which</TOKEN>
<TOKEN end_char="1804" id="token-11-23" morph="none" pos="word" start_char="1790">epidemiologists</TOKEN>
<TOKEN end_char="1810" id="token-11-24" morph="none" pos="word" start_char="1806">think</TOKEN>
<TOKEN end_char="1817" id="token-11-25" morph="none" pos="word" start_char="1812">jumped</TOKEN>
<TOKEN end_char="1820" id="token-11-26" morph="none" pos="word" start_char="1819">to</TOKEN>
<TOKEN end_char="1827" id="token-11-27" morph="none" pos="word" start_char="1822">humans</TOKEN>
<TOKEN end_char="1832" id="token-11-28" morph="none" pos="word" start_char="1829">from</TOKEN>
<TOKEN end_char="1834" id="token-11-29" morph="none" pos="word" start_char="1834">a</TOKEN>
<TOKEN end_char="1839" id="token-11-30" morph="none" pos="word" start_char="1836">wild</TOKEN>
<TOKEN end_char="1846" id="token-11-31" morph="none" pos="word" start_char="1841">animal</TOKEN>
<TOKEN end_char="1847" id="token-11-32" morph="none" pos="punct" start_char="1847">,</TOKEN>
<TOKEN end_char="1856" id="token-11-33" morph="none" pos="word" start_char="1849">possibly</TOKEN>
<TOKEN end_char="1858" id="token-11-34" morph="none" pos="word" start_char="1858">a</TOKEN>
<TOKEN end_char="1862" id="token-11-35" morph="none" pos="word" start_char="1860">bat</TOKEN>
<TOKEN end_char="1863" id="token-11-36" morph="none" pos="punct" start_char="1863">.</TOKEN>
</SEG>
<SEG end_char="2011" id="segment-12" start_char="1866">
<ORIGINAL_TEXT>None of the nine cases reported in November - four men and five women, aged between 39 and 39 - has so far been confirmed as being such a patient.</ORIGINAL_TEXT>
<TOKEN end_char="1869" id="token-12-0" morph="none" pos="word" start_char="1866">None</TOKEN>
<TOKEN end_char="1872" id="token-12-1" morph="none" pos="word" start_char="1871">of</TOKEN>
<TOKEN end_char="1876" id="token-12-2" morph="none" pos="word" start_char="1874">the</TOKEN>
<TOKEN end_char="1881" id="token-12-3" morph="none" pos="word" start_char="1878">nine</TOKEN>
<TOKEN end_char="1887" id="token-12-4" morph="none" pos="word" start_char="1883">cases</TOKEN>
<TOKEN end_char="1896" id="token-12-5" morph="none" pos="word" start_char="1889">reported</TOKEN>
<TOKEN end_char="1899" id="token-12-6" morph="none" pos="word" start_char="1898">in</TOKEN>
<TOKEN end_char="1908" id="token-12-7" morph="none" pos="word" start_char="1901">November</TOKEN>
<TOKEN end_char="1910" id="token-12-8" morph="none" pos="punct" start_char="1910">-</TOKEN>
<TOKEN end_char="1915" id="token-12-9" morph="none" pos="word" start_char="1912">four</TOKEN>
<TOKEN end_char="1919" id="token-12-10" morph="none" pos="word" start_char="1917">men</TOKEN>
<TOKEN end_char="1923" id="token-12-11" morph="none" pos="word" start_char="1921">and</TOKEN>
<TOKEN end_char="1928" id="token-12-12" morph="none" pos="word" start_char="1925">five</TOKEN>
<TOKEN end_char="1934" id="token-12-13" morph="none" pos="word" start_char="1930">women</TOKEN>
<TOKEN end_char="1935" id="token-12-14" morph="none" pos="punct" start_char="1935">,</TOKEN>
<TOKEN end_char="1940" id="token-12-15" morph="none" pos="word" start_char="1937">aged</TOKEN>
<TOKEN end_char="1948" id="token-12-16" morph="none" pos="word" start_char="1942">between</TOKEN>
<TOKEN end_char="1951" id="token-12-17" morph="none" pos="word" start_char="1950">39</TOKEN>
<TOKEN end_char="1955" id="token-12-18" morph="none" pos="word" start_char="1953">and</TOKEN>
<TOKEN end_char="1958" id="token-12-19" morph="none" pos="word" start_char="1957">39</TOKEN>
<TOKEN end_char="1960" id="token-12-20" morph="none" pos="punct" start_char="1960">-</TOKEN>
<TOKEN end_char="1964" id="token-12-21" morph="none" pos="word" start_char="1962">has</TOKEN>
<TOKEN end_char="1967" id="token-12-22" morph="none" pos="word" start_char="1966">so</TOKEN>
<TOKEN end_char="1971" id="token-12-23" morph="none" pos="word" start_char="1969">far</TOKEN>
<TOKEN end_char="1976" id="token-12-24" morph="none" pos="word" start_char="1973">been</TOKEN>
<TOKEN end_char="1986" id="token-12-25" morph="none" pos="word" start_char="1978">confirmed</TOKEN>
<TOKEN end_char="1989" id="token-12-26" morph="none" pos="word" start_char="1988">as</TOKEN>
<TOKEN end_char="1995" id="token-12-27" morph="none" pos="word" start_char="1991">being</TOKEN>
<TOKEN end_char="2000" id="token-12-28" morph="none" pos="word" start_char="1997">such</TOKEN>
<TOKEN end_char="2002" id="token-12-29" morph="none" pos="word" start_char="2002">a</TOKEN>
<TOKEN end_char="2010" id="token-12-30" morph="none" pos="word" start_char="2004">patient</TOKEN>
<TOKEN end_char="2011" id="token-12-31" morph="none" pos="punct" start_char="2011">.</TOKEN>
</SEG>
<SEG end_char="2023" id="segment-13" start_char="2014">
<ORIGINAL_TEXT>DON'T MISS</ORIGINAL_TEXT>
<TOKEN end_char="2018" id="token-13-0" morph="none" pos="word" start_char="2014">DON'T</TOKEN>
<TOKEN end_char="2023" id="token-13-1" morph="none" pos="word" start_char="2020">MISS</TOKEN>
</SEG>
<SEG end_char="2076" id="segment-14" start_char="2028">
<ORIGINAL_TEXT>Dr Li Wenliang has been hailed as a hero in China</ORIGINAL_TEXT>
<TOKEN end_char="2029" id="token-14-0" morph="none" pos="word" start_char="2028">Dr</TOKEN>
<TOKEN end_char="2032" id="token-14-1" morph="none" pos="word" start_char="2031">Li</TOKEN>
<TOKEN end_char="2041" id="token-14-2" morph="none" pos="word" start_char="2034">Wenliang</TOKEN>
<TOKEN end_char="2045" id="token-14-3" morph="none" pos="word" start_char="2043">has</TOKEN>
<TOKEN end_char="2050" id="token-14-4" morph="none" pos="word" start_char="2047">been</TOKEN>
<TOKEN end_char="2057" id="token-14-5" morph="none" pos="word" start_char="2052">hailed</TOKEN>
<TOKEN end_char="2060" id="token-14-6" morph="none" pos="word" start_char="2059">as</TOKEN>
<TOKEN end_char="2062" id="token-14-7" morph="none" pos="word" start_char="2062">a</TOKEN>
<TOKEN end_char="2067" id="token-14-8" morph="none" pos="word" start_char="2064">hero</TOKEN>
<TOKEN end_char="2070" id="token-14-9" morph="none" pos="word" start_char="2069">in</TOKEN>
<TOKEN end_char="2076" id="token-14-10" morph="none" pos="word" start_char="2072">China</TOKEN>
</SEG>
<SEG end_char="2232" id="segment-15" start_char="2080">
<ORIGINAL_TEXT>A report published in medical journal The Lancet by doctors from Wuhan's Jinyintan Hospital previously put dated the first known infection to December 1.</ORIGINAL_TEXT>
<TOKEN end_char="2080" id="token-15-0" morph="none" pos="word" start_char="2080">A</TOKEN>
<TOKEN end_char="2087" id="token-15-1" morph="none" pos="word" start_char="2082">report</TOKEN>
<TOKEN end_char="2097" id="token-15-2" morph="none" pos="word" start_char="2089">published</TOKEN>
<TOKEN end_char="2100" id="token-15-3" morph="none" pos="word" start_char="2099">in</TOKEN>
<TOKEN end_char="2108" id="token-15-4" morph="none" pos="word" start_char="2102">medical</TOKEN>
<TOKEN end_char="2116" id="token-15-5" morph="none" pos="word" start_char="2110">journal</TOKEN>
<TOKEN end_char="2120" id="token-15-6" morph="none" pos="word" start_char="2118">The</TOKEN>
<TOKEN end_char="2127" id="token-15-7" morph="none" pos="word" start_char="2122">Lancet</TOKEN>
<TOKEN end_char="2130" id="token-15-8" morph="none" pos="word" start_char="2129">by</TOKEN>
<TOKEN end_char="2138" id="token-15-9" morph="none" pos="word" start_char="2132">doctors</TOKEN>
<TOKEN end_char="2143" id="token-15-10" morph="none" pos="word" start_char="2140">from</TOKEN>
<TOKEN end_char="2151" id="token-15-11" morph="none" pos="word" start_char="2145">Wuhan's</TOKEN>
<TOKEN end_char="2161" id="token-15-12" morph="none" pos="word" start_char="2153">Jinyintan</TOKEN>
<TOKEN end_char="2170" id="token-15-13" morph="none" pos="word" start_char="2163">Hospital</TOKEN>
<TOKEN end_char="2181" id="token-15-14" morph="none" pos="word" start_char="2172">previously</TOKEN>
<TOKEN end_char="2185" id="token-15-15" morph="none" pos="word" start_char="2183">put</TOKEN>
<TOKEN end_char="2191" id="token-15-16" morph="none" pos="word" start_char="2187">dated</TOKEN>
<TOKEN end_char="2195" id="token-15-17" morph="none" pos="word" start_char="2193">the</TOKEN>
<TOKEN end_char="2201" id="token-15-18" morph="none" pos="word" start_char="2197">first</TOKEN>
<TOKEN end_char="2207" id="token-15-19" morph="none" pos="word" start_char="2203">known</TOKEN>
<TOKEN end_char="2217" id="token-15-20" morph="none" pos="word" start_char="2209">infection</TOKEN>
<TOKEN end_char="2220" id="token-15-21" morph="none" pos="word" start_char="2219">to</TOKEN>
<TOKEN end_char="2229" id="token-15-22" morph="none" pos="word" start_char="2222">December</TOKEN>
<TOKEN end_char="2231" id="token-15-23" morph="none" pos="word" start_char="2231">1</TOKEN>
<TOKEN end_char="2232" id="token-15-24" morph="none" pos="punct" start_char="2232">.</TOKEN>
</SEG>
<SEG end_char="2454" id="segment-16" start_char="2235">
<ORIGINAL_TEXT>Speaking to Chinese magazine People in an interview which was later censored, Dr Ai Fen said she was reprimanded after telling superiors about about a "Sars-like" virus-related illness affecting patients in mid-December.</ORIGINAL_TEXT>
<TOKEN end_char="2242" id="token-16-0" morph="none" pos="word" start_char="2235">Speaking</TOKEN>
<TOKEN end_char="2245" id="token-16-1" morph="none" pos="word" start_char="2244">to</TOKEN>
<TOKEN end_char="2253" id="token-16-2" morph="none" pos="word" start_char="2247">Chinese</TOKEN>
<TOKEN end_char="2262" id="token-16-3" morph="none" pos="word" start_char="2255">magazine</TOKEN>
<TOKEN end_char="2269" id="token-16-4" morph="none" pos="word" start_char="2264">People</TOKEN>
<TOKEN end_char="2272" id="token-16-5" morph="none" pos="word" start_char="2271">in</TOKEN>
<TOKEN end_char="2275" id="token-16-6" morph="none" pos="word" start_char="2274">an</TOKEN>
<TOKEN end_char="2285" id="token-16-7" morph="none" pos="word" start_char="2277">interview</TOKEN>
<TOKEN end_char="2291" id="token-16-8" morph="none" pos="word" start_char="2287">which</TOKEN>
<TOKEN end_char="2295" id="token-16-9" morph="none" pos="word" start_char="2293">was</TOKEN>
<TOKEN end_char="2301" id="token-16-10" morph="none" pos="word" start_char="2297">later</TOKEN>
<TOKEN end_char="2310" id="token-16-11" morph="none" pos="word" start_char="2303">censored</TOKEN>
<TOKEN end_char="2311" id="token-16-12" morph="none" pos="punct" start_char="2311">,</TOKEN>
<TOKEN end_char="2314" id="token-16-13" morph="none" pos="word" start_char="2313">Dr</TOKEN>
<TOKEN end_char="2317" id="token-16-14" morph="none" pos="word" start_char="2316">Ai</TOKEN>
<TOKEN end_char="2321" id="token-16-15" morph="none" pos="word" start_char="2319">Fen</TOKEN>
<TOKEN end_char="2326" id="token-16-16" morph="none" pos="word" start_char="2323">said</TOKEN>
<TOKEN end_char="2330" id="token-16-17" morph="none" pos="word" start_char="2328">she</TOKEN>
<TOKEN end_char="2334" id="token-16-18" morph="none" pos="word" start_char="2332">was</TOKEN>
<TOKEN end_char="2346" id="token-16-19" morph="none" pos="word" start_char="2336">reprimanded</TOKEN>
<TOKEN end_char="2352" id="token-16-20" morph="none" pos="word" start_char="2348">after</TOKEN>
<TOKEN end_char="2360" id="token-16-21" morph="none" pos="word" start_char="2354">telling</TOKEN>
<TOKEN end_char="2370" id="token-16-22" morph="none" pos="word" start_char="2362">superiors</TOKEN>
<TOKEN end_char="2376" id="token-16-23" morph="none" pos="word" start_char="2372">about</TOKEN>
<TOKEN end_char="2382" id="token-16-24" morph="none" pos="word" start_char="2378">about</TOKEN>
<TOKEN end_char="2384" id="token-16-25" morph="none" pos="word" start_char="2384">a</TOKEN>
<TOKEN end_char="2386" id="token-16-26" morph="none" pos="punct" start_char="2386">"</TOKEN>
<TOKEN end_char="2395" id="token-16-27" morph="none" pos="unknown" start_char="2387">Sars-like</TOKEN>
<TOKEN end_char="2396" id="token-16-28" morph="none" pos="punct" start_char="2396">"</TOKEN>
<TOKEN end_char="2410" id="token-16-29" morph="none" pos="unknown" start_char="2398">virus-related</TOKEN>
<TOKEN end_char="2418" id="token-16-30" morph="none" pos="word" start_char="2412">illness</TOKEN>
<TOKEN end_char="2428" id="token-16-31" morph="none" pos="word" start_char="2420">affecting</TOKEN>
<TOKEN end_char="2437" id="token-16-32" morph="none" pos="word" start_char="2430">patients</TOKEN>
<TOKEN end_char="2440" id="token-16-33" morph="none" pos="word" start_char="2439">in</TOKEN>
<TOKEN end_char="2453" id="token-16-34" morph="none" pos="unknown" start_char="2442">mid-December</TOKEN>
<TOKEN end_char="2454" id="token-16-35" morph="none" pos="punct" start_char="2454">.</TOKEN>
</SEG>
<SEG end_char="2545" id="segment-17" start_char="2457">
<ORIGINAL_TEXT>She said: "If I had known what was to happen, I would not have cared about the reprimand.</ORIGINAL_TEXT>
<TOKEN end_char="2459" id="token-17-0" morph="none" pos="word" start_char="2457">She</TOKEN>
<TOKEN end_char="2464" id="token-17-1" morph="none" pos="word" start_char="2461">said</TOKEN>
<TOKEN end_char="2465" id="token-17-2" morph="none" pos="punct" start_char="2465">:</TOKEN>
<TOKEN end_char="2467" id="token-17-3" morph="none" pos="punct" start_char="2467">"</TOKEN>
<TOKEN end_char="2469" id="token-17-4" morph="none" pos="word" start_char="2468">If</TOKEN>
<TOKEN end_char="2471" id="token-17-5" morph="none" pos="word" start_char="2471">I</TOKEN>
<TOKEN end_char="2475" id="token-17-6" morph="none" pos="word" start_char="2473">had</TOKEN>
<TOKEN end_char="2481" id="token-17-7" morph="none" pos="word" start_char="2477">known</TOKEN>
<TOKEN end_char="2486" id="token-17-8" morph="none" pos="word" start_char="2483">what</TOKEN>
<TOKEN end_char="2490" id="token-17-9" morph="none" pos="word" start_char="2488">was</TOKEN>
<TOKEN end_char="2493" id="token-17-10" morph="none" pos="word" start_char="2492">to</TOKEN>
<TOKEN end_char="2500" id="token-17-11" morph="none" pos="word" start_char="2495">happen</TOKEN>
<TOKEN end_char="2501" id="token-17-12" morph="none" pos="punct" start_char="2501">,</TOKEN>
<TOKEN end_char="2503" id="token-17-13" morph="none" pos="word" start_char="2503">I</TOKEN>
<TOKEN end_char="2509" id="token-17-14" morph="none" pos="word" start_char="2505">would</TOKEN>
<TOKEN end_char="2513" id="token-17-15" morph="none" pos="word" start_char="2511">not</TOKEN>
<TOKEN end_char="2518" id="token-17-16" morph="none" pos="word" start_char="2515">have</TOKEN>
<TOKEN end_char="2524" id="token-17-17" morph="none" pos="word" start_char="2520">cared</TOKEN>
<TOKEN end_char="2530" id="token-17-18" morph="none" pos="word" start_char="2526">about</TOKEN>
<TOKEN end_char="2534" id="token-17-19" morph="none" pos="word" start_char="2532">the</TOKEN>
<TOKEN end_char="2544" id="token-17-20" morph="none" pos="word" start_char="2536">reprimand</TOKEN>
<TOKEN end_char="2545" id="token-17-21" morph="none" pos="punct" start_char="2545">.</TOKEN>
</SEG>
<SEG end_char="2616" id="segment-18" start_char="2548">
<ORIGINAL_TEXT>"I would have f****** talked about it to whoever, whereever I could."</ORIGINAL_TEXT>
<TOKEN end_char="2548" id="token-18-0" morph="none" pos="punct" start_char="2548">"</TOKEN>
<TOKEN end_char="2549" id="token-18-1" morph="none" pos="word" start_char="2549">I</TOKEN>
<TOKEN end_char="2555" id="token-18-2" morph="none" pos="word" start_char="2551">would</TOKEN>
<TOKEN end_char="2560" id="token-18-3" morph="none" pos="word" start_char="2557">have</TOKEN>
<TOKEN end_char="2562" id="token-18-4" morph="none" pos="word" start_char="2562">f</TOKEN>
<TOKEN end_char="2568" id="token-18-5" morph="none" pos="punct" start_char="2563">******</TOKEN>
<TOKEN end_char="2575" id="token-18-6" morph="none" pos="word" start_char="2570">talked</TOKEN>
<TOKEN end_char="2581" id="token-18-7" morph="none" pos="word" start_char="2577">about</TOKEN>
<TOKEN end_char="2584" id="token-18-8" morph="none" pos="word" start_char="2583">it</TOKEN>
<TOKEN end_char="2587" id="token-18-9" morph="none" pos="word" start_char="2586">to</TOKEN>
<TOKEN end_char="2595" id="token-18-10" morph="none" pos="word" start_char="2589">whoever</TOKEN>
<TOKEN end_char="2596" id="token-18-11" morph="none" pos="punct" start_char="2596">,</TOKEN>
<TOKEN end_char="2606" id="token-18-12" morph="none" pos="word" start_char="2598">whereever</TOKEN>
<TOKEN end_char="2608" id="token-18-13" morph="none" pos="word" start_char="2608">I</TOKEN>
<TOKEN end_char="2614" id="token-18-14" morph="none" pos="word" start_char="2610">could</TOKEN>
<TOKEN end_char="2616" id="token-18-15" morph="none" pos="punct" start_char="2615">."</TOKEN>
</SEG>
<SEG end_char="2785" id="segment-19" start_char="2619">
<ORIGINAL_TEXT>Dr Li Wenliang, who died of the illness on February 6, was detained by police for "spreading false rumours" after taking to Twitter to warn about the mysterious virus.</ORIGINAL_TEXT>
<TOKEN end_char="2620" id="token-19-0" morph="none" pos="word" start_char="2619">Dr</TOKEN>
<TOKEN end_char="2623" id="token-19-1" morph="none" pos="word" start_char="2622">Li</TOKEN>
<TOKEN end_char="2632" id="token-19-2" morph="none" pos="word" start_char="2625">Wenliang</TOKEN>
<TOKEN end_char="2633" id="token-19-3" morph="none" pos="punct" start_char="2633">,</TOKEN>
<TOKEN end_char="2637" id="token-19-4" morph="none" pos="word" start_char="2635">who</TOKEN>
<TOKEN end_char="2642" id="token-19-5" morph="none" pos="word" start_char="2639">died</TOKEN>
<TOKEN end_char="2645" id="token-19-6" morph="none" pos="word" start_char="2644">of</TOKEN>
<TOKEN end_char="2649" id="token-19-7" morph="none" pos="word" start_char="2647">the</TOKEN>
<TOKEN end_char="2657" id="token-19-8" morph="none" pos="word" start_char="2651">illness</TOKEN>
<TOKEN end_char="2660" id="token-19-9" morph="none" pos="word" start_char="2659">on</TOKEN>
<TOKEN end_char="2669" id="token-19-10" morph="none" pos="word" start_char="2662">February</TOKEN>
<TOKEN end_char="2671" id="token-19-11" morph="none" pos="word" start_char="2671">6</TOKEN>
<TOKEN end_char="2672" id="token-19-12" morph="none" pos="punct" start_char="2672">,</TOKEN>
<TOKEN end_char="2676" id="token-19-13" morph="none" pos="word" start_char="2674">was</TOKEN>
<TOKEN end_char="2685" id="token-19-14" morph="none" pos="word" start_char="2678">detained</TOKEN>
<TOKEN end_char="2688" id="token-19-15" morph="none" pos="word" start_char="2687">by</TOKEN>
<TOKEN end_char="2695" id="token-19-16" morph="none" pos="word" start_char="2690">police</TOKEN>
<TOKEN end_char="2699" id="token-19-17" morph="none" pos="word" start_char="2697">for</TOKEN>
<TOKEN end_char="2701" id="token-19-18" morph="none" pos="punct" start_char="2701">"</TOKEN>
<TOKEN end_char="2710" id="token-19-19" morph="none" pos="word" start_char="2702">spreading</TOKEN>
<TOKEN end_char="2716" id="token-19-20" morph="none" pos="word" start_char="2712">false</TOKEN>
<TOKEN end_char="2724" id="token-19-21" morph="none" pos="word" start_char="2718">rumours</TOKEN>
<TOKEN end_char="2725" id="token-19-22" morph="none" pos="punct" start_char="2725">"</TOKEN>
<TOKEN end_char="2731" id="token-19-23" morph="none" pos="word" start_char="2727">after</TOKEN>
<TOKEN end_char="2738" id="token-19-24" morph="none" pos="word" start_char="2733">taking</TOKEN>
<TOKEN end_char="2741" id="token-19-25" morph="none" pos="word" start_char="2740">to</TOKEN>
<TOKEN end_char="2749" id="token-19-26" morph="none" pos="word" start_char="2743">Twitter</TOKEN>
<TOKEN end_char="2752" id="token-19-27" morph="none" pos="word" start_char="2751">to</TOKEN>
<TOKEN end_char="2757" id="token-19-28" morph="none" pos="word" start_char="2754">warn</TOKEN>
<TOKEN end_char="2763" id="token-19-29" morph="none" pos="word" start_char="2759">about</TOKEN>
<TOKEN end_char="2767" id="token-19-30" morph="none" pos="word" start_char="2765">the</TOKEN>
<TOKEN end_char="2778" id="token-19-31" morph="none" pos="word" start_char="2769">mysterious</TOKEN>
<TOKEN end_char="2784" id="token-19-32" morph="none" pos="word" start_char="2780">virus</TOKEN>
<TOKEN end_char="2785" id="token-19-33" morph="none" pos="punct" start_char="2785">.</TOKEN>
</SEG>
<SEG end_char="2830" id="segment-20" start_char="2788">
<ORIGINAL_TEXT>The case has prompted outrage across China.</ORIGINAL_TEXT>
<TOKEN end_char="2790" id="token-20-0" morph="none" pos="word" start_char="2788">The</TOKEN>
<TOKEN end_char="2795" id="token-20-1" morph="none" pos="word" start_char="2792">case</TOKEN>
<TOKEN end_char="2799" id="token-20-2" morph="none" pos="word" start_char="2797">has</TOKEN>
<TOKEN end_char="2808" id="token-20-3" morph="none" pos="word" start_char="2801">prompted</TOKEN>
<TOKEN end_char="2816" id="token-20-4" morph="none" pos="word" start_char="2810">outrage</TOKEN>
<TOKEN end_char="2823" id="token-20-5" morph="none" pos="word" start_char="2818">across</TOKEN>
<TOKEN end_char="2829" id="token-20-6" morph="none" pos="word" start_char="2825">China</TOKEN>
<TOKEN end_char="2830" id="token-20-7" morph="none" pos="punct" start_char="2830">.</TOKEN>
</SEG>
<SEG end_char="3026" id="segment-21" start_char="2833">
<ORIGINAL_TEXT>Meanwhile the South China Morning Post claimed although doctors in Wuhan collected samples from suspected cases in late December, red tape prevented them from confirming their findings for days.</ORIGINAL_TEXT>
<TOKEN end_char="2841" id="token-21-0" morph="none" pos="word" start_char="2833">Meanwhile</TOKEN>
<TOKEN end_char="2845" id="token-21-1" morph="none" pos="word" start_char="2843">the</TOKEN>
<TOKEN end_char="2851" id="token-21-2" morph="none" pos="word" start_char="2847">South</TOKEN>
<TOKEN end_char="2857" id="token-21-3" morph="none" pos="word" start_char="2853">China</TOKEN>
<TOKEN end_char="2865" id="token-21-4" morph="none" pos="word" start_char="2859">Morning</TOKEN>
<TOKEN end_char="2870" id="token-21-5" morph="none" pos="word" start_char="2867">Post</TOKEN>
<TOKEN end_char="2878" id="token-21-6" morph="none" pos="word" start_char="2872">claimed</TOKEN>
<TOKEN end_char="2887" id="token-21-7" morph="none" pos="word" start_char="2880">although</TOKEN>
<TOKEN end_char="2895" id="token-21-8" morph="none" pos="word" start_char="2889">doctors</TOKEN>
<TOKEN end_char="2898" id="token-21-9" morph="none" pos="word" start_char="2897">in</TOKEN>
<TOKEN end_char="2904" id="token-21-10" morph="none" pos="word" start_char="2900">Wuhan</TOKEN>
<TOKEN end_char="2914" id="token-21-11" morph="none" pos="word" start_char="2906">collected</TOKEN>
<TOKEN end_char="2922" id="token-21-12" morph="none" pos="word" start_char="2916">samples</TOKEN>
<TOKEN end_char="2927" id="token-21-13" morph="none" pos="word" start_char="2924">from</TOKEN>
<TOKEN end_char="2937" id="token-21-14" morph="none" pos="word" start_char="2929">suspected</TOKEN>
<TOKEN end_char="2943" id="token-21-15" morph="none" pos="word" start_char="2939">cases</TOKEN>
<TOKEN end_char="2946" id="token-21-16" morph="none" pos="word" start_char="2945">in</TOKEN>
<TOKEN end_char="2951" id="token-21-17" morph="none" pos="word" start_char="2948">late</TOKEN>
<TOKEN end_char="2960" id="token-21-18" morph="none" pos="word" start_char="2953">December</TOKEN>
<TOKEN end_char="2961" id="token-21-19" morph="none" pos="punct" start_char="2961">,</TOKEN>
<TOKEN end_char="2965" id="token-21-20" morph="none" pos="word" start_char="2963">red</TOKEN>
<TOKEN end_char="2970" id="token-21-21" morph="none" pos="word" start_char="2967">tape</TOKEN>
<TOKEN end_char="2980" id="token-21-22" morph="none" pos="word" start_char="2972">prevented</TOKEN>
<TOKEN end_char="2985" id="token-21-23" morph="none" pos="word" start_char="2982">them</TOKEN>
<TOKEN end_char="2990" id="token-21-24" morph="none" pos="word" start_char="2987">from</TOKEN>
<TOKEN end_char="3001" id="token-21-25" morph="none" pos="word" start_char="2992">confirming</TOKEN>
<TOKEN end_char="3007" id="token-21-26" morph="none" pos="word" start_char="3003">their</TOKEN>
<TOKEN end_char="3016" id="token-21-27" morph="none" pos="word" start_char="3009">findings</TOKEN>
<TOKEN end_char="3020" id="token-21-28" morph="none" pos="word" start_char="3018">for</TOKEN>
<TOKEN end_char="3025" id="token-21-29" morph="none" pos="word" start_char="3022">days</TOKEN>
<TOKEN end_char="3026" id="token-21-30" morph="none" pos="punct" start_char="3026">.</TOKEN>
</SEG>
<SEG end_char="3090" id="segment-22" start_char="3029">
<ORIGINAL_TEXT>They were also told not to disclose any details to the public.</ORIGINAL_TEXT>
<TOKEN end_char="3032" id="token-22-0" morph="none" pos="word" start_char="3029">They</TOKEN>
<TOKEN end_char="3037" id="token-22-1" morph="none" pos="word" start_char="3034">were</TOKEN>
<TOKEN end_char="3042" id="token-22-2" morph="none" pos="word" start_char="3039">also</TOKEN>
<TOKEN end_char="3047" id="token-22-3" morph="none" pos="word" start_char="3044">told</TOKEN>
<TOKEN end_char="3051" id="token-22-4" morph="none" pos="word" start_char="3049">not</TOKEN>
<TOKEN end_char="3054" id="token-22-5" morph="none" pos="word" start_char="3053">to</TOKEN>
<TOKEN end_char="3063" id="token-22-6" morph="none" pos="word" start_char="3056">disclose</TOKEN>
<TOKEN end_char="3067" id="token-22-7" morph="none" pos="word" start_char="3065">any</TOKEN>
<TOKEN end_char="3075" id="token-22-8" morph="none" pos="word" start_char="3069">details</TOKEN>
<TOKEN end_char="3078" id="token-22-9" morph="none" pos="word" start_char="3077">to</TOKEN>
<TOKEN end_char="3082" id="token-22-10" morph="none" pos="word" start_char="3080">the</TOKEN>
<TOKEN end_char="3089" id="token-22-11" morph="none" pos="word" start_char="3084">public</TOKEN>
<TOKEN end_char="3090" id="token-22-12" morph="none" pos="punct" start_char="3090">.</TOKEN>
</SEG>
<SEG end_char="3193" id="segment-23" start_char="3093">
<ORIGINAL_TEXT>Even on January 11, Wuhan’s health authorities continued to claim there were only 41 confirmed cases.</ORIGINAL_TEXT>
<TOKEN end_char="3096" id="token-23-0" morph="none" pos="word" start_char="3093">Even</TOKEN>
<TOKEN end_char="3099" id="token-23-1" morph="none" pos="word" start_char="3098">on</TOKEN>
<TOKEN end_char="3107" id="token-23-2" morph="none" pos="word" start_char="3101">January</TOKEN>
<TOKEN end_char="3110" id="token-23-3" morph="none" pos="word" start_char="3109">11</TOKEN>
<TOKEN end_char="3111" id="token-23-4" morph="none" pos="punct" start_char="3111">,</TOKEN>
<TOKEN end_char="3119" id="token-23-5" morph="none" pos="word" start_char="3113">Wuhan’s</TOKEN>
<TOKEN end_char="3126" id="token-23-6" morph="none" pos="word" start_char="3121">health</TOKEN>
<TOKEN end_char="3138" id="token-23-7" morph="none" pos="word" start_char="3128">authorities</TOKEN>
<TOKEN end_char="3148" id="token-23-8" morph="none" pos="word" start_char="3140">continued</TOKEN>
<TOKEN end_char="3151" id="token-23-9" morph="none" pos="word" start_char="3150">to</TOKEN>
<TOKEN end_char="3157" id="token-23-10" morph="none" pos="word" start_char="3153">claim</TOKEN>
<TOKEN end_char="3163" id="token-23-11" morph="none" pos="word" start_char="3159">there</TOKEN>
<TOKEN end_char="3168" id="token-23-12" morph="none" pos="word" start_char="3165">were</TOKEN>
<TOKEN end_char="3173" id="token-23-13" morph="none" pos="word" start_char="3170">only</TOKEN>
<TOKEN end_char="3176" id="token-23-14" morph="none" pos="word" start_char="3175">41</TOKEN>
<TOKEN end_char="3186" id="token-23-15" morph="none" pos="word" start_char="3178">confirmed</TOKEN>
<TOKEN end_char="3192" id="token-23-16" morph="none" pos="word" start_char="3188">cases</TOKEN>
<TOKEN end_char="3193" id="token-23-17" morph="none" pos="punct" start_char="3193">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CVMY" lang="spa" raw_text_char_length="5541" raw_text_md5="7beb3fc33fd518c7f47010633393e04b" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="103" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Is plasma from people who have recovered from COVID-19 an effective treatment for people with COVID-19?</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">Is</TOKEN>
<TOKEN end_char="9" id="token-0-1" morph="none" pos="word" start_char="4">plasma</TOKEN>
<TOKEN end_char="14" id="token-0-2" morph="none" pos="word" start_char="11">from</TOKEN>
<TOKEN end_char="21" id="token-0-3" morph="none" pos="word" start_char="16">people</TOKEN>
<TOKEN end_char="25" id="token-0-4" morph="none" pos="word" start_char="23">who</TOKEN>
<TOKEN end_char="30" id="token-0-5" morph="none" pos="word" start_char="27">have</TOKEN>
<TOKEN end_char="40" id="token-0-6" morph="none" pos="word" start_char="32">recovered</TOKEN>
<TOKEN end_char="45" id="token-0-7" morph="none" pos="word" start_char="42">from</TOKEN>
<TOKEN end_char="54" id="token-0-8" morph="none" pos="unknown" start_char="47">COVID-19</TOKEN>
<TOKEN end_char="57" id="token-0-9" morph="none" pos="word" start_char="56">an</TOKEN>
<TOKEN end_char="67" id="token-0-10" morph="none" pos="word" start_char="59">effective</TOKEN>
<TOKEN end_char="77" id="token-0-11" morph="none" pos="word" start_char="69">treatment</TOKEN>
<TOKEN end_char="81" id="token-0-12" morph="none" pos="word" start_char="79">for</TOKEN>
<TOKEN end_char="88" id="token-0-13" morph="none" pos="word" start_char="83">people</TOKEN>
<TOKEN end_char="93" id="token-0-14" morph="none" pos="word" start_char="90">with</TOKEN>
<TOKEN end_char="102" id="token-0-15" morph="none" pos="unknown" start_char="95">COVID-19</TOKEN>
<TOKEN end_char="103" id="token-0-16" morph="none" pos="punct" start_char="103">?</TOKEN>
</SEG>
<SEG end_char="118" id="segment-1" start_char="107">
<ORIGINAL_TEXT>Key messages</ORIGINAL_TEXT>
<TOKEN end_char="109" id="token-1-0" morph="none" pos="word" start_char="107">Key</TOKEN>
<TOKEN end_char="118" id="token-1-1" morph="none" pos="word" start_char="111">messages</TOKEN>
<TRANSLATED_TEXT>Kernberichten</TRANSLATED_TEXT><DETECTED_LANGUAGE>da</DETECTED_LANGUAGE></SEG>
<SEG end_char="246" id="segment-2" start_char="121">
<ORIGINAL_TEXT>• We are very confident that convalescent plasma has no benefits for the treatment of people with moderate to severe COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="121" id="token-2-0" morph="none" pos="punct" start_char="121">•</TOKEN>
<TOKEN end_char="124" id="token-2-1" morph="none" pos="word" start_char="123">We</TOKEN>
<TOKEN end_char="128" id="token-2-2" morph="none" pos="word" start_char="126">are</TOKEN>
<TOKEN end_char="133" id="token-2-3" morph="none" pos="word" start_char="130">very</TOKEN>
<TOKEN end_char="143" id="token-2-4" morph="none" pos="word" start_char="135">confident</TOKEN>
<TOKEN end_char="148" id="token-2-5" morph="none" pos="word" start_char="145">that</TOKEN>
<TOKEN end_char="161" id="token-2-6" morph="none" pos="word" start_char="150">convalescent</TOKEN>
<TOKEN end_char="168" id="token-2-7" morph="none" pos="word" start_char="163">plasma</TOKEN>
<TOKEN end_char="172" id="token-2-8" morph="none" pos="word" start_char="170">has</TOKEN>
<TOKEN end_char="175" id="token-2-9" morph="none" pos="word" start_char="174">no</TOKEN>
<TOKEN end_char="184" id="token-2-10" morph="none" pos="word" start_char="177">benefits</TOKEN>
<TOKEN end_char="188" id="token-2-11" morph="none" pos="word" start_char="186">for</TOKEN>
<TOKEN end_char="192" id="token-2-12" morph="none" pos="word" start_char="190">the</TOKEN>
<TOKEN end_char="202" id="token-2-13" morph="none" pos="word" start_char="194">treatment</TOKEN>
<TOKEN end_char="205" id="token-2-14" morph="none" pos="word" start_char="204">of</TOKEN>
<TOKEN end_char="212" id="token-2-15" morph="none" pos="word" start_char="207">people</TOKEN>
<TOKEN end_char="217" id="token-2-16" morph="none" pos="word" start_char="214">with</TOKEN>
<TOKEN end_char="226" id="token-2-17" morph="none" pos="word" start_char="219">moderate</TOKEN>
<TOKEN end_char="229" id="token-2-18" morph="none" pos="word" start_char="228">to</TOKEN>
<TOKEN end_char="236" id="token-2-19" morph="none" pos="word" start_char="231">severe</TOKEN>
<TOKEN end_char="245" id="token-2-20" morph="none" pos="unknown" start_char="238">COVID-19</TOKEN>
<TOKEN end_char="246" id="token-2-21" morph="none" pos="punct" start_char="246">.</TOKEN>
</SEG>
<SEG end_char="371" id="segment-3" start_char="249">
<ORIGINAL_TEXT>• We are uncertain about the effects of convalescent plasma for treating people with mild COVID-19 or who have no symptoms.</ORIGINAL_TEXT>
<TOKEN end_char="249" id="token-3-0" morph="none" pos="punct" start_char="249">•</TOKEN>
<TOKEN end_char="252" id="token-3-1" morph="none" pos="word" start_char="251">We</TOKEN>
<TOKEN end_char="256" id="token-3-2" morph="none" pos="word" start_char="254">are</TOKEN>
<TOKEN end_char="266" id="token-3-3" morph="none" pos="word" start_char="258">uncertain</TOKEN>
<TOKEN end_char="272" id="token-3-4" morph="none" pos="word" start_char="268">about</TOKEN>
<TOKEN end_char="276" id="token-3-5" morph="none" pos="word" start_char="274">the</TOKEN>
<TOKEN end_char="284" id="token-3-6" morph="none" pos="word" start_char="278">effects</TOKEN>
<TOKEN end_char="287" id="token-3-7" morph="none" pos="word" start_char="286">of</TOKEN>
<TOKEN end_char="300" id="token-3-8" morph="none" pos="word" start_char="289">convalescent</TOKEN>
<TOKEN end_char="307" id="token-3-9" morph="none" pos="word" start_char="302">plasma</TOKEN>
<TOKEN end_char="311" id="token-3-10" morph="none" pos="word" start_char="309">for</TOKEN>
<TOKEN end_char="320" id="token-3-11" morph="none" pos="word" start_char="313">treating</TOKEN>
<TOKEN end_char="327" id="token-3-12" morph="none" pos="word" start_char="322">people</TOKEN>
<TOKEN end_char="332" id="token-3-13" morph="none" pos="word" start_char="329">with</TOKEN>
<TOKEN end_char="337" id="token-3-14" morph="none" pos="word" start_char="334">mild</TOKEN>
<TOKEN end_char="346" id="token-3-15" morph="none" pos="unknown" start_char="339">COVID-19</TOKEN>
<TOKEN end_char="349" id="token-3-16" morph="none" pos="word" start_char="348">or</TOKEN>
<TOKEN end_char="353" id="token-3-17" morph="none" pos="word" start_char="351">who</TOKEN>
<TOKEN end_char="358" id="token-3-18" morph="none" pos="word" start_char="355">have</TOKEN>
<TOKEN end_char="361" id="token-3-19" morph="none" pos="word" start_char="360">no</TOKEN>
<TOKEN end_char="370" id="token-3-20" morph="none" pos="word" start_char="363">symptoms</TOKEN>
<TOKEN end_char="371" id="token-3-21" morph="none" pos="punct" start_char="371">.</TOKEN>
</SEG>
<SEG end_char="446" id="segment-4" start_char="374">
<ORIGINAL_TEXT>• We found about 130 ongoing, unpublished and recently published studies.</ORIGINAL_TEXT>
<TOKEN end_char="374" id="token-4-0" morph="none" pos="punct" start_char="374">•</TOKEN>
<TOKEN end_char="377" id="token-4-1" morph="none" pos="word" start_char="376">We</TOKEN>
<TOKEN end_char="383" id="token-4-2" morph="none" pos="word" start_char="379">found</TOKEN>
<TOKEN end_char="389" id="token-4-3" morph="none" pos="word" start_char="385">about</TOKEN>
<TOKEN end_char="393" id="token-4-4" morph="none" pos="word" start_char="391">130</TOKEN>
<TOKEN end_char="401" id="token-4-5" morph="none" pos="word" start_char="395">ongoing</TOKEN>
<TOKEN end_char="402" id="token-4-6" morph="none" pos="punct" start_char="402">,</TOKEN>
<TOKEN end_char="414" id="token-4-7" morph="none" pos="word" start_char="404">unpublished</TOKEN>
<TOKEN end_char="418" id="token-4-8" morph="none" pos="word" start_char="416">and</TOKEN>
<TOKEN end_char="427" id="token-4-9" morph="none" pos="word" start_char="420">recently</TOKEN>
<TOKEN end_char="437" id="token-4-10" morph="none" pos="word" start_char="429">published</TOKEN>
<TOKEN end_char="445" id="token-4-11" morph="none" pos="word" start_char="439">studies</TOKEN>
<TOKEN end_char="446" id="token-4-12" morph="none" pos="punct" start_char="446">.</TOKEN>
</SEG>
<SEG end_char="526" id="segment-5" start_char="448">
<ORIGINAL_TEXT>We will update our review with evidence from these studies as soon as possible.</ORIGINAL_TEXT>
<TOKEN end_char="449" id="token-5-0" morph="none" pos="word" start_char="448">We</TOKEN>
<TOKEN end_char="454" id="token-5-1" morph="none" pos="word" start_char="451">will</TOKEN>
<TOKEN end_char="461" id="token-5-2" morph="none" pos="word" start_char="456">update</TOKEN>
<TOKEN end_char="465" id="token-5-3" morph="none" pos="word" start_char="463">our</TOKEN>
<TOKEN end_char="472" id="token-5-4" morph="none" pos="word" start_char="467">review</TOKEN>
<TOKEN end_char="477" id="token-5-5" morph="none" pos="word" start_char="474">with</TOKEN>
<TOKEN end_char="486" id="token-5-6" morph="none" pos="word" start_char="479">evidence</TOKEN>
<TOKEN end_char="491" id="token-5-7" morph="none" pos="word" start_char="488">from</TOKEN>
<TOKEN end_char="497" id="token-5-8" morph="none" pos="word" start_char="493">these</TOKEN>
<TOKEN end_char="505" id="token-5-9" morph="none" pos="word" start_char="499">studies</TOKEN>
<TOKEN end_char="508" id="token-5-10" morph="none" pos="word" start_char="507">as</TOKEN>
<TOKEN end_char="513" id="token-5-11" morph="none" pos="word" start_char="510">soon</TOKEN>
<TOKEN end_char="516" id="token-5-12" morph="none" pos="word" start_char="515">as</TOKEN>
<TOKEN end_char="525" id="token-5-13" morph="none" pos="word" start_char="518">possible</TOKEN>
<TOKEN end_char="526" id="token-5-14" morph="none" pos="punct" start_char="526">.</TOKEN>
</SEG>
<SEG end_char="575" id="segment-6" start_char="528">
<ORIGINAL_TEXT>New evidence may answer our remaining questions.</ORIGINAL_TEXT>
<TOKEN end_char="530" id="token-6-0" morph="none" pos="word" start_char="528">New</TOKEN>
<TOKEN end_char="539" id="token-6-1" morph="none" pos="word" start_char="532">evidence</TOKEN>
<TOKEN end_char="543" id="token-6-2" morph="none" pos="word" start_char="541">may</TOKEN>
<TOKEN end_char="550" id="token-6-3" morph="none" pos="word" start_char="545">answer</TOKEN>
<TOKEN end_char="554" id="token-6-4" morph="none" pos="word" start_char="552">our</TOKEN>
<TOKEN end_char="564" id="token-6-5" morph="none" pos="word" start_char="556">remaining</TOKEN>
<TOKEN end_char="574" id="token-6-6" morph="none" pos="word" start_char="566">questions</TOKEN>
<TOKEN end_char="575" id="token-6-7" morph="none" pos="punct" start_char="575">.</TOKEN>
</SEG>
<SEG end_char="605" id="segment-7" start_char="578">
<ORIGINAL_TEXT>What is convalescent plasma?</ORIGINAL_TEXT>
<TOKEN end_char="581" id="token-7-0" morph="none" pos="word" start_char="578">What</TOKEN>
<TOKEN end_char="584" id="token-7-1" morph="none" pos="word" start_char="583">is</TOKEN>
<TOKEN end_char="597" id="token-7-2" morph="none" pos="word" start_char="586">convalescent</TOKEN>
<TOKEN end_char="604" id="token-7-3" morph="none" pos="word" start_char="599">plasma</TOKEN>
<TOKEN end_char="605" id="token-7-4" morph="none" pos="punct" start_char="605">?</TOKEN>
</SEG>
<SEG end_char="677" id="segment-8" start_char="608">
<ORIGINAL_TEXT>The body produces antibodies as one of its defences against infection.</ORIGINAL_TEXT>
<TOKEN end_char="610" id="token-8-0" morph="none" pos="word" start_char="608">The</TOKEN>
<TOKEN end_char="615" id="token-8-1" morph="none" pos="word" start_char="612">body</TOKEN>
<TOKEN end_char="624" id="token-8-2" morph="none" pos="word" start_char="617">produces</TOKEN>
<TOKEN end_char="635" id="token-8-3" morph="none" pos="word" start_char="626">antibodies</TOKEN>
<TOKEN end_char="638" id="token-8-4" morph="none" pos="word" start_char="637">as</TOKEN>
<TOKEN end_char="642" id="token-8-5" morph="none" pos="word" start_char="640">one</TOKEN>
<TOKEN end_char="645" id="token-8-6" morph="none" pos="word" start_char="644">of</TOKEN>
<TOKEN end_char="649" id="token-8-7" morph="none" pos="word" start_char="647">its</TOKEN>
<TOKEN end_char="658" id="token-8-8" morph="none" pos="word" start_char="651">defences</TOKEN>
<TOKEN end_char="666" id="token-8-9" morph="none" pos="word" start_char="660">against</TOKEN>
<TOKEN end_char="676" id="token-8-10" morph="none" pos="word" start_char="668">infection</TOKEN>
<TOKEN end_char="677" id="token-8-11" morph="none" pos="punct" start_char="677">.</TOKEN>
</SEG>
<SEG end_char="734" id="segment-9" start_char="679">
<ORIGINAL_TEXT>Antibodies are found in part of the blood called plasma.</ORIGINAL_TEXT>
<TOKEN end_char="688" id="token-9-0" morph="none" pos="word" start_char="679">Antibodies</TOKEN>
<TOKEN end_char="692" id="token-9-1" morph="none" pos="word" start_char="690">are</TOKEN>
<TOKEN end_char="698" id="token-9-2" morph="none" pos="word" start_char="694">found</TOKEN>
<TOKEN end_char="701" id="token-9-3" morph="none" pos="word" start_char="700">in</TOKEN>
<TOKEN end_char="706" id="token-9-4" morph="none" pos="word" start_char="703">part</TOKEN>
<TOKEN end_char="709" id="token-9-5" morph="none" pos="word" start_char="708">of</TOKEN>
<TOKEN end_char="713" id="token-9-6" morph="none" pos="word" start_char="711">the</TOKEN>
<TOKEN end_char="719" id="token-9-7" morph="none" pos="word" start_char="715">blood</TOKEN>
<TOKEN end_char="726" id="token-9-8" morph="none" pos="word" start_char="721">called</TOKEN>
<TOKEN end_char="733" id="token-9-9" morph="none" pos="word" start_char="728">plasma</TOKEN>
<TOKEN end_char="734" id="token-9-10" morph="none" pos="punct" start_char="734">.</TOKEN>
</SEG>
<SEG end_char="868" id="segment-10" start_char="736">
<ORIGINAL_TEXT>Plasma from people who have recovered from the COVID-19 virus contains COVID-19 antibodies, and can be used to make two preparations.</ORIGINAL_TEXT>
<TOKEN end_char="741" id="token-10-0" morph="none" pos="word" start_char="736">Plasma</TOKEN>
<TOKEN end_char="746" id="token-10-1" morph="none" pos="word" start_char="743">from</TOKEN>
<TOKEN end_char="753" id="token-10-2" morph="none" pos="word" start_char="748">people</TOKEN>
<TOKEN end_char="757" id="token-10-3" morph="none" pos="word" start_char="755">who</TOKEN>
<TOKEN end_char="762" id="token-10-4" morph="none" pos="word" start_char="759">have</TOKEN>
<TOKEN end_char="772" id="token-10-5" morph="none" pos="word" start_char="764">recovered</TOKEN>
<TOKEN end_char="777" id="token-10-6" morph="none" pos="word" start_char="774">from</TOKEN>
<TOKEN end_char="781" id="token-10-7" morph="none" pos="word" start_char="779">the</TOKEN>
<TOKEN end_char="790" id="token-10-8" morph="none" pos="unknown" start_char="783">COVID-19</TOKEN>
<TOKEN end_char="796" id="token-10-9" morph="none" pos="word" start_char="792">virus</TOKEN>
<TOKEN end_char="805" id="token-10-10" morph="none" pos="word" start_char="798">contains</TOKEN>
<TOKEN end_char="814" id="token-10-11" morph="none" pos="unknown" start_char="807">COVID-19</TOKEN>
<TOKEN end_char="825" id="token-10-12" morph="none" pos="word" start_char="816">antibodies</TOKEN>
<TOKEN end_char="826" id="token-10-13" morph="none" pos="punct" start_char="826">,</TOKEN>
<TOKEN end_char="830" id="token-10-14" morph="none" pos="word" start_char="828">and</TOKEN>
<TOKEN end_char="834" id="token-10-15" morph="none" pos="word" start_char="832">can</TOKEN>
<TOKEN end_char="837" id="token-10-16" morph="none" pos="word" start_char="836">be</TOKEN>
<TOKEN end_char="842" id="token-10-17" morph="none" pos="word" start_char="839">used</TOKEN>
<TOKEN end_char="845" id="token-10-18" morph="none" pos="word" start_char="844">to</TOKEN>
<TOKEN end_char="850" id="token-10-19" morph="none" pos="word" start_char="847">make</TOKEN>
<TOKEN end_char="854" id="token-10-20" morph="none" pos="word" start_char="852">two</TOKEN>
<TOKEN end_char="867" id="token-10-21" morph="none" pos="word" start_char="856">preparations</TOKEN>
<TOKEN end_char="868" id="token-10-22" morph="none" pos="punct" start_char="868">.</TOKEN>
</SEG>
<SEG end_char="969" id="segment-11" start_char="870">
<ORIGINAL_TEXT>Firstly, it can be used to make convalescent plasma, which is plasma that contains these antibodies.</ORIGINAL_TEXT>
<TOKEN end_char="876" id="token-11-0" morph="none" pos="word" start_char="870">Firstly</TOKEN>
<TOKEN end_char="877" id="token-11-1" morph="none" pos="punct" start_char="877">,</TOKEN>
<TOKEN end_char="880" id="token-11-2" morph="none" pos="word" start_char="879">it</TOKEN>
<TOKEN end_char="884" id="token-11-3" morph="none" pos="word" start_char="882">can</TOKEN>
<TOKEN end_char="887" id="token-11-4" morph="none" pos="word" start_char="886">be</TOKEN>
<TOKEN end_char="892" id="token-11-5" morph="none" pos="word" start_char="889">used</TOKEN>
<TOKEN end_char="895" id="token-11-6" morph="none" pos="word" start_char="894">to</TOKEN>
<TOKEN end_char="900" id="token-11-7" morph="none" pos="word" start_char="897">make</TOKEN>
<TOKEN end_char="913" id="token-11-8" morph="none" pos="word" start_char="902">convalescent</TOKEN>
<TOKEN end_char="920" id="token-11-9" morph="none" pos="word" start_char="915">plasma</TOKEN>
<TOKEN end_char="921" id="token-11-10" morph="none" pos="punct" start_char="921">,</TOKEN>
<TOKEN end_char="927" id="token-11-11" morph="none" pos="word" start_char="923">which</TOKEN>
<TOKEN end_char="930" id="token-11-12" morph="none" pos="word" start_char="929">is</TOKEN>
<TOKEN end_char="937" id="token-11-13" morph="none" pos="word" start_char="932">plasma</TOKEN>
<TOKEN end_char="942" id="token-11-14" morph="none" pos="word" start_char="939">that</TOKEN>
<TOKEN end_char="951" id="token-11-15" morph="none" pos="word" start_char="944">contains</TOKEN>
<TOKEN end_char="957" id="token-11-16" morph="none" pos="word" start_char="953">these</TOKEN>
<TOKEN end_char="968" id="token-11-17" morph="none" pos="word" start_char="959">antibodies</TOKEN>
<TOKEN end_char="969" id="token-11-18" morph="none" pos="punct" start_char="969">.</TOKEN>
</SEG>
<SEG end_char="1098" id="segment-12" start_char="971">
<ORIGINAL_TEXT>Secondly, it can be used to make hyperimmune immunoglobulin, which is more concentrated, and therefore contains more antibodies.</ORIGINAL_TEXT>
<TOKEN end_char="978" id="token-12-0" morph="none" pos="word" start_char="971">Secondly</TOKEN>
<TOKEN end_char="979" id="token-12-1" morph="none" pos="punct" start_char="979">,</TOKEN>
<TOKEN end_char="982" id="token-12-2" morph="none" pos="word" start_char="981">it</TOKEN>
<TOKEN end_char="986" id="token-12-3" morph="none" pos="word" start_char="984">can</TOKEN>
<TOKEN end_char="989" id="token-12-4" morph="none" pos="word" start_char="988">be</TOKEN>
<TOKEN end_char="994" id="token-12-5" morph="none" pos="word" start_char="991">used</TOKEN>
<TOKEN end_char="997" id="token-12-6" morph="none" pos="word" start_char="996">to</TOKEN>
<TOKEN end_char="1002" id="token-12-7" morph="none" pos="word" start_char="999">make</TOKEN>
<TOKEN end_char="1014" id="token-12-8" morph="none" pos="word" start_char="1004">hyperimmune</TOKEN>
<TOKEN end_char="1029" id="token-12-9" morph="none" pos="word" start_char="1016">immunoglobulin</TOKEN>
<TOKEN end_char="1030" id="token-12-10" morph="none" pos="punct" start_char="1030">,</TOKEN>
<TOKEN end_char="1036" id="token-12-11" morph="none" pos="word" start_char="1032">which</TOKEN>
<TOKEN end_char="1039" id="token-12-12" morph="none" pos="word" start_char="1038">is</TOKEN>
<TOKEN end_char="1044" id="token-12-13" morph="none" pos="word" start_char="1041">more</TOKEN>
<TOKEN end_char="1057" id="token-12-14" morph="none" pos="word" start_char="1046">concentrated</TOKEN>
<TOKEN end_char="1058" id="token-12-15" morph="none" pos="punct" start_char="1058">,</TOKEN>
<TOKEN end_char="1062" id="token-12-16" morph="none" pos="word" start_char="1060">and</TOKEN>
<TOKEN end_char="1072" id="token-12-17" morph="none" pos="word" start_char="1064">therefore</TOKEN>
<TOKEN end_char="1081" id="token-12-18" morph="none" pos="word" start_char="1074">contains</TOKEN>
<TOKEN end_char="1086" id="token-12-19" morph="none" pos="word" start_char="1083">more</TOKEN>
<TOKEN end_char="1097" id="token-12-20" morph="none" pos="word" start_char="1088">antibodies</TOKEN>
<TOKEN end_char="1098" id="token-12-21" morph="none" pos="punct" start_char="1098">.</TOKEN>
</SEG>
<SEG end_char="1201" id="segment-13" start_char="1101">
<ORIGINAL_TEXT>Convalescent plasma and hyperimmune immunoglobulin have been used successfully to treat some viruses.</ORIGINAL_TEXT>
<TOKEN end_char="1112" id="token-13-0" morph="none" pos="word" start_char="1101">Convalescent</TOKEN>
<TOKEN end_char="1119" id="token-13-1" morph="none" pos="word" start_char="1114">plasma</TOKEN>
<TOKEN end_char="1123" id="token-13-2" morph="none" pos="word" start_char="1121">and</TOKEN>
<TOKEN end_char="1135" id="token-13-3" morph="none" pos="word" start_char="1125">hyperimmune</TOKEN>
<TOKEN end_char="1150" id="token-13-4" morph="none" pos="word" start_char="1137">immunoglobulin</TOKEN>
<TOKEN end_char="1155" id="token-13-5" morph="none" pos="word" start_char="1152">have</TOKEN>
<TOKEN end_char="1160" id="token-13-6" morph="none" pos="word" start_char="1157">been</TOKEN>
<TOKEN end_char="1165" id="token-13-7" morph="none" pos="word" start_char="1162">used</TOKEN>
<TOKEN end_char="1178" id="token-13-8" morph="none" pos="word" start_char="1167">successfully</TOKEN>
<TOKEN end_char="1181" id="token-13-9" morph="none" pos="word" start_char="1180">to</TOKEN>
<TOKEN end_char="1187" id="token-13-10" morph="none" pos="word" start_char="1183">treat</TOKEN>
<TOKEN end_char="1192" id="token-13-11" morph="none" pos="word" start_char="1189">some</TOKEN>
<TOKEN end_char="1200" id="token-13-12" morph="none" pos="word" start_char="1194">viruses</TOKEN>
<TOKEN end_char="1201" id="token-13-13" morph="none" pos="punct" start_char="1201">.</TOKEN>
</SEG>
<SEG end_char="1311" id="segment-14" start_char="1203">
<ORIGINAL_TEXT>These treatments (given by a drip or injection) are generally well-tolerated, but can cause unwanted effects.</ORIGINAL_TEXT>
<TOKEN end_char="1207" id="token-14-0" morph="none" pos="word" start_char="1203">These</TOKEN>
<TOKEN end_char="1218" id="token-14-1" morph="none" pos="word" start_char="1209">treatments</TOKEN>
<TOKEN end_char="1220" id="token-14-2" morph="none" pos="punct" start_char="1220">(</TOKEN>
<TOKEN end_char="1225" id="token-14-3" morph="none" pos="word" start_char="1221">given</TOKEN>
<TOKEN end_char="1228" id="token-14-4" morph="none" pos="word" start_char="1227">by</TOKEN>
<TOKEN end_char="1230" id="token-14-5" morph="none" pos="word" start_char="1230">a</TOKEN>
<TOKEN end_char="1235" id="token-14-6" morph="none" pos="word" start_char="1232">drip</TOKEN>
<TOKEN end_char="1238" id="token-14-7" morph="none" pos="word" start_char="1237">or</TOKEN>
<TOKEN end_char="1248" id="token-14-8" morph="none" pos="word" start_char="1240">injection</TOKEN>
<TOKEN end_char="1249" id="token-14-9" morph="none" pos="punct" start_char="1249">)</TOKEN>
<TOKEN end_char="1253" id="token-14-10" morph="none" pos="word" start_char="1251">are</TOKEN>
<TOKEN end_char="1263" id="token-14-11" morph="none" pos="word" start_char="1255">generally</TOKEN>
<TOKEN end_char="1278" id="token-14-12" morph="none" pos="unknown" start_char="1265">well-tolerated</TOKEN>
<TOKEN end_char="1279" id="token-14-13" morph="none" pos="punct" start_char="1279">,</TOKEN>
<TOKEN end_char="1283" id="token-14-14" morph="none" pos="word" start_char="1281">but</TOKEN>
<TOKEN end_char="1287" id="token-14-15" morph="none" pos="word" start_char="1285">can</TOKEN>
<TOKEN end_char="1293" id="token-14-16" morph="none" pos="word" start_char="1289">cause</TOKEN>
<TOKEN end_char="1302" id="token-14-17" morph="none" pos="word" start_char="1295">unwanted</TOKEN>
<TOKEN end_char="1310" id="token-14-18" morph="none" pos="word" start_char="1304">effects</TOKEN>
<TOKEN end_char="1311" id="token-14-19" morph="none" pos="punct" start_char="1311">.</TOKEN>
</SEG>
<SEG end_char="1342" id="segment-15" start_char="1314">
<ORIGINAL_TEXT>What did we want to find out?</ORIGINAL_TEXT>
<TOKEN end_char="1317" id="token-15-0" morph="none" pos="word" start_char="1314">What</TOKEN>
<TOKEN end_char="1321" id="token-15-1" morph="none" pos="word" start_char="1319">did</TOKEN>
<TOKEN end_char="1324" id="token-15-2" morph="none" pos="word" start_char="1323">we</TOKEN>
<TOKEN end_char="1329" id="token-15-3" morph="none" pos="word" start_char="1326">want</TOKEN>
<TOKEN end_char="1332" id="token-15-4" morph="none" pos="word" start_char="1331">to</TOKEN>
<TOKEN end_char="1337" id="token-15-5" morph="none" pos="word" start_char="1334">find</TOKEN>
<TOKEN end_char="1341" id="token-15-6" morph="none" pos="word" start_char="1339">out</TOKEN>
<TOKEN end_char="1342" id="token-15-7" morph="none" pos="punct" start_char="1342">?</TOKEN>
</SEG>
<SEG end_char="1484" id="segment-16" start_char="1345">
<ORIGINAL_TEXT>We wanted to find out whether convalescent plasma or hyperimmune immunoglobulin are effective treatments for people with confirmed COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="1346" id="token-16-0" morph="none" pos="word" start_char="1345">We</TOKEN>
<TOKEN end_char="1353" id="token-16-1" morph="none" pos="word" start_char="1348">wanted</TOKEN>
<TOKEN end_char="1356" id="token-16-2" morph="none" pos="word" start_char="1355">to</TOKEN>
<TOKEN end_char="1361" id="token-16-3" morph="none" pos="word" start_char="1358">find</TOKEN>
<TOKEN end_char="1365" id="token-16-4" morph="none" pos="word" start_char="1363">out</TOKEN>
<TOKEN end_char="1373" id="token-16-5" morph="none" pos="word" start_char="1367">whether</TOKEN>
<TOKEN end_char="1386" id="token-16-6" morph="none" pos="word" start_char="1375">convalescent</TOKEN>
<TOKEN end_char="1393" id="token-16-7" morph="none" pos="word" start_char="1388">plasma</TOKEN>
<TOKEN end_char="1396" id="token-16-8" morph="none" pos="word" start_char="1395">or</TOKEN>
<TOKEN end_char="1408" id="token-16-9" morph="none" pos="word" start_char="1398">hyperimmune</TOKEN>
<TOKEN end_char="1423" id="token-16-10" morph="none" pos="word" start_char="1410">immunoglobulin</TOKEN>
<TOKEN end_char="1427" id="token-16-11" morph="none" pos="word" start_char="1425">are</TOKEN>
<TOKEN end_char="1437" id="token-16-12" morph="none" pos="word" start_char="1429">effective</TOKEN>
<TOKEN end_char="1448" id="token-16-13" morph="none" pos="word" start_char="1439">treatments</TOKEN>
<TOKEN end_char="1452" id="token-16-14" morph="none" pos="word" start_char="1450">for</TOKEN>
<TOKEN end_char="1459" id="token-16-15" morph="none" pos="word" start_char="1454">people</TOKEN>
<TOKEN end_char="1464" id="token-16-16" morph="none" pos="word" start_char="1461">with</TOKEN>
<TOKEN end_char="1474" id="token-16-17" morph="none" pos="word" start_char="1466">confirmed</TOKEN>
<TOKEN end_char="1483" id="token-16-18" morph="none" pos="unknown" start_char="1476">COVID-19</TOKEN>
<TOKEN end_char="1484" id="token-16-19" morph="none" pos="punct" start_char="1484">.</TOKEN>
</SEG>
<SEG end_char="1498" id="segment-17" start_char="1486">
<ORIGINAL_TEXT>We looked at:</ORIGINAL_TEXT>
<TOKEN end_char="1487" id="token-17-0" morph="none" pos="word" start_char="1486">We</TOKEN>
<TOKEN end_char="1494" id="token-17-1" morph="none" pos="word" start_char="1489">looked</TOKEN>
<TOKEN end_char="1497" id="token-17-2" morph="none" pos="word" start_char="1496">at</TOKEN>
<TOKEN end_char="1498" id="token-17-3" morph="none" pos="punct" start_char="1498">:</TOKEN>
<TRANSLATED_TEXT>Abbiamo esaminato:</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="1595" id="segment-18" start_char="1501">
<ORIGINAL_TEXT>• deaths from any cause after treatment with convalescent plasma or hyperimmune immunoglobulin;</ORIGINAL_TEXT>
<TOKEN end_char="1501" id="token-18-0" morph="none" pos="punct" start_char="1501">•</TOKEN>
<TOKEN end_char="1508" id="token-18-1" morph="none" pos="word" start_char="1503">deaths</TOKEN>
<TOKEN end_char="1513" id="token-18-2" morph="none" pos="word" start_char="1510">from</TOKEN>
<TOKEN end_char="1517" id="token-18-3" morph="none" pos="word" start_char="1515">any</TOKEN>
<TOKEN end_char="1523" id="token-18-4" morph="none" pos="word" start_char="1519">cause</TOKEN>
<TOKEN end_char="1529" id="token-18-5" morph="none" pos="word" start_char="1525">after</TOKEN>
<TOKEN end_char="1539" id="token-18-6" morph="none" pos="word" start_char="1531">treatment</TOKEN>
<TOKEN end_char="1544" id="token-18-7" morph="none" pos="word" start_char="1541">with</TOKEN>
<TOKEN end_char="1557" id="token-18-8" morph="none" pos="word" start_char="1546">convalescent</TOKEN>
<TOKEN end_char="1564" id="token-18-9" morph="none" pos="word" start_char="1559">plasma</TOKEN>
<TOKEN end_char="1567" id="token-18-10" morph="none" pos="word" start_char="1566">or</TOKEN>
<TOKEN end_char="1579" id="token-18-11" morph="none" pos="word" start_char="1569">hyperimmune</TOKEN>
<TOKEN end_char="1594" id="token-18-12" morph="none" pos="word" start_char="1581">immunoglobulin</TOKEN>
<TOKEN end_char="1595" id="token-18-13" morph="none" pos="punct" start_char="1595">;</TOKEN>
</SEG>
<SEG end_char="1789" id="segment-19" start_char="1598">
<ORIGINAL_TEXT>• improvement or worsening of patients’ condition, measured by the number of people who needed help from a ventilator (a machine that helps people breathe if they cannot breathe on their own);</ORIGINAL_TEXT>
<TOKEN end_char="1598" id="token-19-0" morph="none" pos="punct" start_char="1598">•</TOKEN>
<TOKEN end_char="1610" id="token-19-1" morph="none" pos="word" start_char="1600">improvement</TOKEN>
<TOKEN end_char="1613" id="token-19-2" morph="none" pos="word" start_char="1612">or</TOKEN>
<TOKEN end_char="1623" id="token-19-3" morph="none" pos="word" start_char="1615">worsening</TOKEN>
<TOKEN end_char="1626" id="token-19-4" morph="none" pos="word" start_char="1625">of</TOKEN>
<TOKEN end_char="1635" id="token-19-5" morph="none" pos="word" start_char="1628">patients</TOKEN>
<TOKEN end_char="1636" id="token-19-6" morph="none" pos="punct" start_char="1636">’</TOKEN>
<TOKEN end_char="1646" id="token-19-7" morph="none" pos="word" start_char="1638">condition</TOKEN>
<TOKEN end_char="1647" id="token-19-8" morph="none" pos="punct" start_char="1647">,</TOKEN>
<TOKEN end_char="1656" id="token-19-9" morph="none" pos="word" start_char="1649">measured</TOKEN>
<TOKEN end_char="1659" id="token-19-10" morph="none" pos="word" start_char="1658">by</TOKEN>
<TOKEN end_char="1663" id="token-19-11" morph="none" pos="word" start_char="1661">the</TOKEN>
<TOKEN end_char="1670" id="token-19-12" morph="none" pos="word" start_char="1665">number</TOKEN>
<TOKEN end_char="1673" id="token-19-13" morph="none" pos="word" start_char="1672">of</TOKEN>
<TOKEN end_char="1680" id="token-19-14" morph="none" pos="word" start_char="1675">people</TOKEN>
<TOKEN end_char="1684" id="token-19-15" morph="none" pos="word" start_char="1682">who</TOKEN>
<TOKEN end_char="1691" id="token-19-16" morph="none" pos="word" start_char="1686">needed</TOKEN>
<TOKEN end_char="1696" id="token-19-17" morph="none" pos="word" start_char="1693">help</TOKEN>
<TOKEN end_char="1701" id="token-19-18" morph="none" pos="word" start_char="1698">from</TOKEN>
<TOKEN end_char="1703" id="token-19-19" morph="none" pos="word" start_char="1703">a</TOKEN>
<TOKEN end_char="1714" id="token-19-20" morph="none" pos="word" start_char="1705">ventilator</TOKEN>
<TOKEN end_char="1716" id="token-19-21" morph="none" pos="punct" start_char="1716">(</TOKEN>
<TOKEN end_char="1717" id="token-19-22" morph="none" pos="word" start_char="1717">a</TOKEN>
<TOKEN end_char="1725" id="token-19-23" morph="none" pos="word" start_char="1719">machine</TOKEN>
<TOKEN end_char="1730" id="token-19-24" morph="none" pos="word" start_char="1727">that</TOKEN>
<TOKEN end_char="1736" id="token-19-25" morph="none" pos="word" start_char="1732">helps</TOKEN>
<TOKEN end_char="1743" id="token-19-26" morph="none" pos="word" start_char="1738">people</TOKEN>
<TOKEN end_char="1751" id="token-19-27" morph="none" pos="word" start_char="1745">breathe</TOKEN>
<TOKEN end_char="1754" id="token-19-28" morph="none" pos="word" start_char="1753">if</TOKEN>
<TOKEN end_char="1759" id="token-19-29" morph="none" pos="word" start_char="1756">they</TOKEN>
<TOKEN end_char="1766" id="token-19-30" morph="none" pos="word" start_char="1761">cannot</TOKEN>
<TOKEN end_char="1774" id="token-19-31" morph="none" pos="word" start_char="1768">breathe</TOKEN>
<TOKEN end_char="1777" id="token-19-32" morph="none" pos="word" start_char="1776">on</TOKEN>
<TOKEN end_char="1783" id="token-19-33" morph="none" pos="word" start_char="1779">their</TOKEN>
<TOKEN end_char="1787" id="token-19-34" morph="none" pos="word" start_char="1785">own</TOKEN>
<TOKEN end_char="1789" id="token-19-35" morph="none" pos="punct" start_char="1788">);</TOKEN>
</SEG>
<SEG end_char="1813" id="segment-20" start_char="1792">
<ORIGINAL_TEXT>• quality of life; and</ORIGINAL_TEXT>
<TOKEN end_char="1792" id="token-20-0" morph="none" pos="punct" start_char="1792">•</TOKEN>
<TOKEN end_char="1800" id="token-20-1" morph="none" pos="word" start_char="1794">quality</TOKEN>
<TOKEN end_char="1803" id="token-20-2" morph="none" pos="word" start_char="1802">of</TOKEN>
<TOKEN end_char="1808" id="token-20-3" morph="none" pos="word" start_char="1805">life</TOKEN>
<TOKEN end_char="1809" id="token-20-4" morph="none" pos="punct" start_char="1809">;</TOKEN>
<TOKEN end_char="1813" id="token-20-5" morph="none" pos="word" start_char="1811">and</TOKEN>
</SEG>
<SEG end_char="1834" id="segment-21" start_char="1816">
<ORIGINAL_TEXT>• unwanted effects.</ORIGINAL_TEXT>
<TOKEN end_char="1816" id="token-21-0" morph="none" pos="punct" start_char="1816">•</TOKEN>
<TOKEN end_char="1825" id="token-21-1" morph="none" pos="word" start_char="1818">unwanted</TOKEN>
<TOKEN end_char="1833" id="token-21-2" morph="none" pos="word" start_char="1827">effects</TOKEN>
<TOKEN end_char="1834" id="token-21-3" morph="none" pos="punct" start_char="1834">.</TOKEN>
</SEG>
<SEG end_char="1851" id="segment-22" start_char="1837">
<ORIGINAL_TEXT>What did we do?</ORIGINAL_TEXT>
<TOKEN end_char="1840" id="token-22-0" morph="none" pos="word" start_char="1837">What</TOKEN>
<TOKEN end_char="1844" id="token-22-1" morph="none" pos="word" start_char="1842">did</TOKEN>
<TOKEN end_char="1847" id="token-22-2" morph="none" pos="word" start_char="1846">we</TOKEN>
<TOKEN end_char="1850" id="token-22-3" morph="none" pos="word" start_char="1849">do</TOKEN>
<TOKEN end_char="1851" id="token-22-4" morph="none" pos="punct" start_char="1851">?</TOKEN>
</SEG>
<SEG end_char="1975" id="segment-23" start_char="1854">
<ORIGINAL_TEXT>We searched for studies that investigated convalescent plasma or hyperimmune immunoglobulin to treat people with COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="1855" id="token-23-0" morph="none" pos="word" start_char="1854">We</TOKEN>
<TOKEN end_char="1864" id="token-23-1" morph="none" pos="word" start_char="1857">searched</TOKEN>
<TOKEN end_char="1868" id="token-23-2" morph="none" pos="word" start_char="1866">for</TOKEN>
<TOKEN end_char="1876" id="token-23-3" morph="none" pos="word" start_char="1870">studies</TOKEN>
<TOKEN end_char="1881" id="token-23-4" morph="none" pos="word" start_char="1878">that</TOKEN>
<TOKEN end_char="1894" id="token-23-5" morph="none" pos="word" start_char="1883">investigated</TOKEN>
<TOKEN end_char="1907" id="token-23-6" morph="none" pos="word" start_char="1896">convalescent</TOKEN>
<TOKEN end_char="1914" id="token-23-7" morph="none" pos="word" start_char="1909">plasma</TOKEN>
<TOKEN end_char="1917" id="token-23-8" morph="none" pos="word" start_char="1916">or</TOKEN>
<TOKEN end_char="1929" id="token-23-9" morph="none" pos="word" start_char="1919">hyperimmune</TOKEN>
<TOKEN end_char="1944" id="token-23-10" morph="none" pos="word" start_char="1931">immunoglobulin</TOKEN>
<TOKEN end_char="1947" id="token-23-11" morph="none" pos="word" start_char="1946">to</TOKEN>
<TOKEN end_char="1953" id="token-23-12" morph="none" pos="word" start_char="1949">treat</TOKEN>
<TOKEN end_char="1960" id="token-23-13" morph="none" pos="word" start_char="1955">people</TOKEN>
<TOKEN end_char="1965" id="token-23-14" morph="none" pos="word" start_char="1962">with</TOKEN>
<TOKEN end_char="1974" id="token-23-15" morph="none" pos="unknown" start_char="1967">COVID-19</TOKEN>
<TOKEN end_char="1975" id="token-23-16" morph="none" pos="punct" start_char="1975">.</TOKEN>
</SEG>
<SEG end_char="2120" id="segment-24" start_char="1977">
<ORIGINAL_TEXT>Studies could take place anywhere in the world and include participants of any age, gender or ethnicity, with mild, moderate or severe COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="1983" id="token-24-0" morph="none" pos="word" start_char="1977">Studies</TOKEN>
<TOKEN end_char="1989" id="token-24-1" morph="none" pos="word" start_char="1985">could</TOKEN>
<TOKEN end_char="1994" id="token-24-2" morph="none" pos="word" start_char="1991">take</TOKEN>
<TOKEN end_char="2000" id="token-24-3" morph="none" pos="word" start_char="1996">place</TOKEN>
<TOKEN end_char="2009" id="token-24-4" morph="none" pos="word" start_char="2002">anywhere</TOKEN>
<TOKEN end_char="2012" id="token-24-5" morph="none" pos="word" start_char="2011">in</TOKEN>
<TOKEN end_char="2016" id="token-24-6" morph="none" pos="word" start_char="2014">the</TOKEN>
<TOKEN end_char="2022" id="token-24-7" morph="none" pos="word" start_char="2018">world</TOKEN>
<TOKEN end_char="2026" id="token-24-8" morph="none" pos="word" start_char="2024">and</TOKEN>
<TOKEN end_char="2034" id="token-24-9" morph="none" pos="word" start_char="2028">include</TOKEN>
<TOKEN end_char="2047" id="token-24-10" morph="none" pos="word" start_char="2036">participants</TOKEN>
<TOKEN end_char="2050" id="token-24-11" morph="none" pos="word" start_char="2049">of</TOKEN>
<TOKEN end_char="2054" id="token-24-12" morph="none" pos="word" start_char="2052">any</TOKEN>
<TOKEN end_char="2058" id="token-24-13" morph="none" pos="word" start_char="2056">age</TOKEN>
<TOKEN end_char="2059" id="token-24-14" morph="none" pos="punct" start_char="2059">,</TOKEN>
<TOKEN end_char="2066" id="token-24-15" morph="none" pos="word" start_char="2061">gender</TOKEN>
<TOKEN end_char="2069" id="token-24-16" morph="none" pos="word" start_char="2068">or</TOKEN>
<TOKEN end_char="2079" id="token-24-17" morph="none" pos="word" start_char="2071">ethnicity</TOKEN>
<TOKEN end_char="2080" id="token-24-18" morph="none" pos="punct" start_char="2080">,</TOKEN>
<TOKEN end_char="2085" id="token-24-19" morph="none" pos="word" start_char="2082">with</TOKEN>
<TOKEN end_char="2090" id="token-24-20" morph="none" pos="word" start_char="2087">mild</TOKEN>
<TOKEN end_char="2091" id="token-24-21" morph="none" pos="punct" start_char="2091">,</TOKEN>
<TOKEN end_char="2100" id="token-24-22" morph="none" pos="word" start_char="2093">moderate</TOKEN>
<TOKEN end_char="2103" id="token-24-23" morph="none" pos="word" start_char="2102">or</TOKEN>
<TOKEN end_char="2110" id="token-24-24" morph="none" pos="word" start_char="2105">severe</TOKEN>
<TOKEN end_char="2119" id="token-24-25" morph="none" pos="unknown" start_char="2112">COVID-19</TOKEN>
<TOKEN end_char="2120" id="token-24-26" morph="none" pos="punct" start_char="2120">.</TOKEN>
</SEG>
<SEG end_char="2184" id="segment-25" start_char="2123">
<ORIGINAL_TEXT>Where possible we pooled the studies’ results to analyse them.</ORIGINAL_TEXT>
<TOKEN end_char="2127" id="token-25-0" morph="none" pos="word" start_char="2123">Where</TOKEN>
<TOKEN end_char="2136" id="token-25-1" morph="none" pos="word" start_char="2129">possible</TOKEN>
<TOKEN end_char="2139" id="token-25-2" morph="none" pos="word" start_char="2138">we</TOKEN>
<TOKEN end_char="2146" id="token-25-3" morph="none" pos="word" start_char="2141">pooled</TOKEN>
<TOKEN end_char="2150" id="token-25-4" morph="none" pos="word" start_char="2148">the</TOKEN>
<TOKEN end_char="2158" id="token-25-5" morph="none" pos="word" start_char="2152">studies</TOKEN>
<TOKEN end_char="2159" id="token-25-6" morph="none" pos="punct" start_char="2159">’</TOKEN>
<TOKEN end_char="2167" id="token-25-7" morph="none" pos="word" start_char="2161">results</TOKEN>
<TOKEN end_char="2170" id="token-25-8" morph="none" pos="word" start_char="2169">to</TOKEN>
<TOKEN end_char="2178" id="token-25-9" morph="none" pos="word" start_char="2172">analyse</TOKEN>
<TOKEN end_char="2183" id="token-25-10" morph="none" pos="word" start_char="2180">them</TOKEN>
<TOKEN end_char="2184" id="token-25-11" morph="none" pos="punct" start_char="2184">.</TOKEN>
</SEG>
<SEG end_char="2275" id="segment-26" start_char="2186">
<ORIGINAL_TEXT>We rated our confidence in the evidence, based on factors such as study methods and sizes.</ORIGINAL_TEXT>
<TOKEN end_char="2187" id="token-26-0" morph="none" pos="word" start_char="2186">We</TOKEN>
<TOKEN end_char="2193" id="token-26-1" morph="none" pos="word" start_char="2189">rated</TOKEN>
<TOKEN end_char="2197" id="token-26-2" morph="none" pos="word" start_char="2195">our</TOKEN>
<TOKEN end_char="2208" id="token-26-3" morph="none" pos="word" start_char="2199">confidence</TOKEN>
<TOKEN end_char="2211" id="token-26-4" morph="none" pos="word" start_char="2210">in</TOKEN>
<TOKEN end_char="2215" id="token-26-5" morph="none" pos="word" start_char="2213">the</TOKEN>
<TOKEN end_char="2224" id="token-26-6" morph="none" pos="word" start_char="2217">evidence</TOKEN>
<TOKEN end_char="2225" id="token-26-7" morph="none" pos="punct" start_char="2225">,</TOKEN>
<TOKEN end_char="2231" id="token-26-8" morph="none" pos="word" start_char="2227">based</TOKEN>
<TOKEN end_char="2234" id="token-26-9" morph="none" pos="word" start_char="2233">on</TOKEN>
<TOKEN end_char="2242" id="token-26-10" morph="none" pos="word" start_char="2236">factors</TOKEN>
<TOKEN end_char="2247" id="token-26-11" morph="none" pos="word" start_char="2244">such</TOKEN>
<TOKEN end_char="2250" id="token-26-12" morph="none" pos="word" start_char="2249">as</TOKEN>
<TOKEN end_char="2256" id="token-26-13" morph="none" pos="word" start_char="2252">study</TOKEN>
<TOKEN end_char="2264" id="token-26-14" morph="none" pos="word" start_char="2258">methods</TOKEN>
<TOKEN end_char="2268" id="token-26-15" morph="none" pos="word" start_char="2266">and</TOKEN>
<TOKEN end_char="2274" id="token-26-16" morph="none" pos="word" start_char="2270">sizes</TOKEN>
<TOKEN end_char="2275" id="token-26-17" morph="none" pos="punct" start_char="2275">.</TOKEN>
</SEG>
<SEG end_char="2294" id="segment-27" start_char="2278">
<ORIGINAL_TEXT>What did we find?</ORIGINAL_TEXT>
<TOKEN end_char="2281" id="token-27-0" morph="none" pos="word" start_char="2278">What</TOKEN>
<TOKEN end_char="2285" id="token-27-1" morph="none" pos="word" start_char="2283">did</TOKEN>
<TOKEN end_char="2288" id="token-27-2" morph="none" pos="word" start_char="2287">we</TOKEN>
<TOKEN end_char="2293" id="token-27-3" morph="none" pos="word" start_char="2290">find</TOKEN>
<TOKEN end_char="2294" id="token-27-4" morph="none" pos="punct" start_char="2294">?</TOKEN>
</SEG>
<SEG end_char="2379" id="segment-28" start_char="2297">
<ORIGINAL_TEXT>We found 13 studies with 48,509 participants that investigated convalescent plasma.</ORIGINAL_TEXT>
<TOKEN end_char="2298" id="token-28-0" morph="none" pos="word" start_char="2297">We</TOKEN>
<TOKEN end_char="2304" id="token-28-1" morph="none" pos="word" start_char="2300">found</TOKEN>
<TOKEN end_char="2307" id="token-28-2" morph="none" pos="word" start_char="2306">13</TOKEN>
<TOKEN end_char="2315" id="token-28-3" morph="none" pos="word" start_char="2309">studies</TOKEN>
<TOKEN end_char="2320" id="token-28-4" morph="none" pos="word" start_char="2317">with</TOKEN>
<TOKEN end_char="2327" id="token-28-5" morph="none" pos="unknown" start_char="2322">48,509</TOKEN>
<TOKEN end_char="2340" id="token-28-6" morph="none" pos="word" start_char="2329">participants</TOKEN>
<TOKEN end_char="2345" id="token-28-7" morph="none" pos="word" start_char="2342">that</TOKEN>
<TOKEN end_char="2358" id="token-28-8" morph="none" pos="word" start_char="2347">investigated</TOKEN>
<TOKEN end_char="2371" id="token-28-9" morph="none" pos="word" start_char="2360">convalescent</TOKEN>
<TOKEN end_char="2378" id="token-28-10" morph="none" pos="word" start_char="2373">plasma</TOKEN>
<TOKEN end_char="2379" id="token-28-11" morph="none" pos="punct" start_char="2379">.</TOKEN>
</SEG>
<SEG end_char="2462" id="segment-29" start_char="2381">
<ORIGINAL_TEXT>All but one of the studies included participants with moderate to severe COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="2383" id="token-29-0" morph="none" pos="word" start_char="2381">All</TOKEN>
<TOKEN end_char="2387" id="token-29-1" morph="none" pos="word" start_char="2385">but</TOKEN>
<TOKEN end_char="2391" id="token-29-2" morph="none" pos="word" start_char="2389">one</TOKEN>
<TOKEN end_char="2394" id="token-29-3" morph="none" pos="word" start_char="2393">of</TOKEN>
<TOKEN end_char="2398" id="token-29-4" morph="none" pos="word" start_char="2396">the</TOKEN>
<TOKEN end_char="2406" id="token-29-5" morph="none" pos="word" start_char="2400">studies</TOKEN>
<TOKEN end_char="2415" id="token-29-6" morph="none" pos="word" start_char="2408">included</TOKEN>
<TOKEN end_char="2428" id="token-29-7" morph="none" pos="word" start_char="2417">participants</TOKEN>
<TOKEN end_char="2433" id="token-29-8" morph="none" pos="word" start_char="2430">with</TOKEN>
<TOKEN end_char="2442" id="token-29-9" morph="none" pos="word" start_char="2435">moderate</TOKEN>
<TOKEN end_char="2445" id="token-29-10" morph="none" pos="word" start_char="2444">to</TOKEN>
<TOKEN end_char="2452" id="token-29-11" morph="none" pos="word" start_char="2447">severe</TOKEN>
<TOKEN end_char="2461" id="token-29-12" morph="none" pos="unknown" start_char="2454">COVID-19</TOKEN>
<TOKEN end_char="2462" id="token-29-13" morph="none" pos="punct" start_char="2462">.</TOKEN>
</SEG>
<SEG end_char="2536" id="segment-30" start_char="2464">
<ORIGINAL_TEXT>We did not find any studies that investigated hyperimmune immunoglobulin.</ORIGINAL_TEXT>
<TOKEN end_char="2465" id="token-30-0" morph="none" pos="word" start_char="2464">We</TOKEN>
<TOKEN end_char="2469" id="token-30-1" morph="none" pos="word" start_char="2467">did</TOKEN>
<TOKEN end_char="2473" id="token-30-2" morph="none" pos="word" start_char="2471">not</TOKEN>
<TOKEN end_char="2478" id="token-30-3" morph="none" pos="word" start_char="2475">find</TOKEN>
<TOKEN end_char="2482" id="token-30-4" morph="none" pos="word" start_char="2480">any</TOKEN>
<TOKEN end_char="2490" id="token-30-5" morph="none" pos="word" start_char="2484">studies</TOKEN>
<TOKEN end_char="2495" id="token-30-6" morph="none" pos="word" start_char="2492">that</TOKEN>
<TOKEN end_char="2508" id="token-30-7" morph="none" pos="word" start_char="2497">investigated</TOKEN>
<TOKEN end_char="2520" id="token-30-8" morph="none" pos="word" start_char="2510">hyperimmune</TOKEN>
<TOKEN end_char="2535" id="token-30-9" morph="none" pos="word" start_char="2522">immunoglobulin</TOKEN>
<TOKEN end_char="2536" id="token-30-10" morph="none" pos="punct" start_char="2536">.</TOKEN>
</SEG>
<SEG end_char="2609" id="segment-31" start_char="2538">
<ORIGINAL_TEXT>Studies mainly took place in hospitals, in countries all over the world.</ORIGINAL_TEXT>
<TOKEN end_char="2544" id="token-31-0" morph="none" pos="word" start_char="2538">Studies</TOKEN>
<TOKEN end_char="2551" id="token-31-1" morph="none" pos="word" start_char="2546">mainly</TOKEN>
<TOKEN end_char="2556" id="token-31-2" morph="none" pos="word" start_char="2553">took</TOKEN>
<TOKEN end_char="2562" id="token-31-3" morph="none" pos="word" start_char="2558">place</TOKEN>
<TOKEN end_char="2565" id="token-31-4" morph="none" pos="word" start_char="2564">in</TOKEN>
<TOKEN end_char="2575" id="token-31-5" morph="none" pos="word" start_char="2567">hospitals</TOKEN>
<TOKEN end_char="2576" id="token-31-6" morph="none" pos="punct" start_char="2576">,</TOKEN>
<TOKEN end_char="2579" id="token-31-7" morph="none" pos="word" start_char="2578">in</TOKEN>
<TOKEN end_char="2589" id="token-31-8" morph="none" pos="word" start_char="2581">countries</TOKEN>
<TOKEN end_char="2593" id="token-31-9" morph="none" pos="word" start_char="2591">all</TOKEN>
<TOKEN end_char="2598" id="token-31-10" morph="none" pos="word" start_char="2595">over</TOKEN>
<TOKEN end_char="2602" id="token-31-11" morph="none" pos="word" start_char="2600">the</TOKEN>
<TOKEN end_char="2608" id="token-31-12" morph="none" pos="word" start_char="2604">world</TOKEN>
<TOKEN end_char="2609" id="token-31-13" morph="none" pos="punct" start_char="2609">.</TOKEN>
</SEG>
<SEG end_char="2696" id="segment-32" start_char="2612">
<ORIGINAL_TEXT>Moderate to severe COVID-19 Convalescent plasma compared to placebo or standard care:</ORIGINAL_TEXT>
<TOKEN end_char="2619" id="token-32-0" morph="none" pos="word" start_char="2612">Moderate</TOKEN>
<TOKEN end_char="2622" id="token-32-1" morph="none" pos="word" start_char="2621">to</TOKEN>
<TOKEN end_char="2629" id="token-32-2" morph="none" pos="word" start_char="2624">severe</TOKEN>
<TOKEN end_char="2638" id="token-32-3" morph="none" pos="unknown" start_char="2631">COVID-19</TOKEN>
<TOKEN end_char="2651" id="token-32-4" morph="none" pos="word" start_char="2640">Convalescent</TOKEN>
<TOKEN end_char="2658" id="token-32-5" morph="none" pos="word" start_char="2653">plasma</TOKEN>
<TOKEN end_char="2667" id="token-32-6" morph="none" pos="word" start_char="2660">compared</TOKEN>
<TOKEN end_char="2670" id="token-32-7" morph="none" pos="word" start_char="2669">to</TOKEN>
<TOKEN end_char="2678" id="token-32-8" morph="none" pos="word" start_char="2672">placebo</TOKEN>
<TOKEN end_char="2681" id="token-32-9" morph="none" pos="word" start_char="2680">or</TOKEN>
<TOKEN end_char="2690" id="token-32-10" morph="none" pos="word" start_char="2683">standard</TOKEN>
<TOKEN end_char="2695" id="token-32-11" morph="none" pos="word" start_char="2692">care</TOKEN>
<TOKEN end_char="2696" id="token-32-12" morph="none" pos="punct" start_char="2696">:</TOKEN>
</SEG>
<SEG end_char="2798" id="segment-33" start_char="2699">
<ORIGINAL_TEXT>• convalescent plasma makes no difference to deaths from any cause at up to 28 days after treatment.</ORIGINAL_TEXT>
<TOKEN end_char="2699" id="token-33-0" morph="none" pos="punct" start_char="2699">•</TOKEN>
<TOKEN end_char="2712" id="token-33-1" morph="none" pos="word" start_char="2701">convalescent</TOKEN>
<TOKEN end_char="2719" id="token-33-2" morph="none" pos="word" start_char="2714">plasma</TOKEN>
<TOKEN end_char="2725" id="token-33-3" morph="none" pos="word" start_char="2721">makes</TOKEN>
<TOKEN end_char="2728" id="token-33-4" morph="none" pos="word" start_char="2727">no</TOKEN>
<TOKEN end_char="2739" id="token-33-5" morph="none" pos="word" start_char="2730">difference</TOKEN>
<TOKEN end_char="2742" id="token-33-6" morph="none" pos="word" start_char="2741">to</TOKEN>
<TOKEN end_char="2749" id="token-33-7" morph="none" pos="word" start_char="2744">deaths</TOKEN>
<TOKEN end_char="2754" id="token-33-8" morph="none" pos="word" start_char="2751">from</TOKEN>
<TOKEN end_char="2758" id="token-33-9" morph="none" pos="word" start_char="2756">any</TOKEN>
<TOKEN end_char="2764" id="token-33-10" morph="none" pos="word" start_char="2760">cause</TOKEN>
<TOKEN end_char="2767" id="token-33-11" morph="none" pos="word" start_char="2766">at</TOKEN>
<TOKEN end_char="2770" id="token-33-12" morph="none" pos="word" start_char="2769">up</TOKEN>
<TOKEN end_char="2773" id="token-33-13" morph="none" pos="word" start_char="2772">to</TOKEN>
<TOKEN end_char="2776" id="token-33-14" morph="none" pos="word" start_char="2775">28</TOKEN>
<TOKEN end_char="2781" id="token-33-15" morph="none" pos="word" start_char="2778">days</TOKEN>
<TOKEN end_char="2787" id="token-33-16" morph="none" pos="word" start_char="2783">after</TOKEN>
<TOKEN end_char="2797" id="token-33-17" morph="none" pos="word" start_char="2789">treatment</TOKEN>
<TOKEN end_char="2798" id="token-33-18" morph="none" pos="punct" start_char="2798">.</TOKEN>
</SEG>
<SEG end_char="2958" id="segment-34" start_char="2800">
<ORIGINAL_TEXT>About 237 in 1000 people given placebo or standard care died, compared to 233 in 1000 people who had been given convalescent plasma (7 studies, 12,646 people);</ORIGINAL_TEXT>
<TOKEN end_char="2804" id="token-34-0" morph="none" pos="word" start_char="2800">About</TOKEN>
<TOKEN end_char="2808" id="token-34-1" morph="none" pos="word" start_char="2806">237</TOKEN>
<TOKEN end_char="2811" id="token-34-2" morph="none" pos="word" start_char="2810">in</TOKEN>
<TOKEN end_char="2816" id="token-34-3" morph="none" pos="word" start_char="2813">1000</TOKEN>
<TOKEN end_char="2823" id="token-34-4" morph="none" pos="word" start_char="2818">people</TOKEN>
<TOKEN end_char="2829" id="token-34-5" morph="none" pos="word" start_char="2825">given</TOKEN>
<TOKEN end_char="2837" id="token-34-6" morph="none" pos="word" start_char="2831">placebo</TOKEN>
<TOKEN end_char="2840" id="token-34-7" morph="none" pos="word" start_char="2839">or</TOKEN>
<TOKEN end_char="2849" id="token-34-8" morph="none" pos="word" start_char="2842">standard</TOKEN>
<TOKEN end_char="2854" id="token-34-9" morph="none" pos="word" start_char="2851">care</TOKEN>
<TOKEN end_char="2859" id="token-34-10" morph="none" pos="word" start_char="2856">died</TOKEN>
<TOKEN end_char="2860" id="token-34-11" morph="none" pos="punct" start_char="2860">,</TOKEN>
<TOKEN end_char="2869" id="token-34-12" morph="none" pos="word" start_char="2862">compared</TOKEN>
<TOKEN end_char="2872" id="token-34-13" morph="none" pos="word" start_char="2871">to</TOKEN>
<TOKEN end_char="2876" id="token-34-14" morph="none" pos="word" start_char="2874">233</TOKEN>
<TOKEN end_char="2879" id="token-34-15" morph="none" pos="word" start_char="2878">in</TOKEN>
<TOKEN end_char="2884" id="token-34-16" morph="none" pos="word" start_char="2881">1000</TOKEN>
<TOKEN end_char="2891" id="token-34-17" morph="none" pos="word" start_char="2886">people</TOKEN>
<TOKEN end_char="2895" id="token-34-18" morph="none" pos="word" start_char="2893">who</TOKEN>
<TOKEN end_char="2899" id="token-34-19" morph="none" pos="word" start_char="2897">had</TOKEN>
<TOKEN end_char="2904" id="token-34-20" morph="none" pos="word" start_char="2901">been</TOKEN>
<TOKEN end_char="2910" id="token-34-21" morph="none" pos="word" start_char="2906">given</TOKEN>
<TOKEN end_char="2923" id="token-34-22" morph="none" pos="word" start_char="2912">convalescent</TOKEN>
<TOKEN end_char="2930" id="token-34-23" morph="none" pos="word" start_char="2925">plasma</TOKEN>
<TOKEN end_char="2932" id="token-34-24" morph="none" pos="punct" start_char="2932">(</TOKEN>
<TOKEN end_char="2933" id="token-34-25" morph="none" pos="word" start_char="2933">7</TOKEN>
<TOKEN end_char="2941" id="token-34-26" morph="none" pos="word" start_char="2935">studies</TOKEN>
<TOKEN end_char="2942" id="token-34-27" morph="none" pos="punct" start_char="2942">,</TOKEN>
<TOKEN end_char="2949" id="token-34-28" morph="none" pos="unknown" start_char="2944">12,646</TOKEN>
<TOKEN end_char="2956" id="token-34-29" morph="none" pos="word" start_char="2951">people</TOKEN>
<TOKEN end_char="2958" id="token-34-30" morph="none" pos="punct" start_char="2957">);</TOKEN>
</SEG>
<SEG end_char="3315" id="segment-35" start_char="2961">
<ORIGINAL_TEXT>• convalescent plasma makes little to no difference to the improvement of patients’ condition in terms of needing less breathing support for the overall population needing any breathing support before the start of treatment (8 studies, 12,682 people), and also not for the people that were ventilated at the beginning of the study (2 studies, 630 people);</ORIGINAL_TEXT>
<TOKEN end_char="2961" id="token-35-0" morph="none" pos="punct" start_char="2961">•</TOKEN>
<TOKEN end_char="2974" id="token-35-1" morph="none" pos="word" start_char="2963">convalescent</TOKEN>
<TOKEN end_char="2981" id="token-35-2" morph="none" pos="word" start_char="2976">plasma</TOKEN>
<TOKEN end_char="2987" id="token-35-3" morph="none" pos="word" start_char="2983">makes</TOKEN>
<TOKEN end_char="2994" id="token-35-4" morph="none" pos="word" start_char="2989">little</TOKEN>
<TOKEN end_char="2997" id="token-35-5" morph="none" pos="word" start_char="2996">to</TOKEN>
<TOKEN end_char="3000" id="token-35-6" morph="none" pos="word" start_char="2999">no</TOKEN>
<TOKEN end_char="3011" id="token-35-7" morph="none" pos="word" start_char="3002">difference</TOKEN>
<TOKEN end_char="3014" id="token-35-8" morph="none" pos="word" start_char="3013">to</TOKEN>
<TOKEN end_char="3018" id="token-35-9" morph="none" pos="word" start_char="3016">the</TOKEN>
<TOKEN end_char="3030" id="token-35-10" morph="none" pos="word" start_char="3020">improvement</TOKEN>
<TOKEN end_char="3033" id="token-35-11" morph="none" pos="word" start_char="3032">of</TOKEN>
<TOKEN end_char="3042" id="token-35-12" morph="none" pos="word" start_char="3035">patients</TOKEN>
<TOKEN end_char="3043" id="token-35-13" morph="none" pos="punct" start_char="3043">’</TOKEN>
<TOKEN end_char="3053" id="token-35-14" morph="none" pos="word" start_char="3045">condition</TOKEN>
<TOKEN end_char="3056" id="token-35-15" morph="none" pos="word" start_char="3055">in</TOKEN>
<TOKEN end_char="3062" id="token-35-16" morph="none" pos="word" start_char="3058">terms</TOKEN>
<TOKEN end_char="3065" id="token-35-17" morph="none" pos="word" start_char="3064">of</TOKEN>
<TOKEN end_char="3073" id="token-35-18" morph="none" pos="word" start_char="3067">needing</TOKEN>
<TOKEN end_char="3078" id="token-35-19" morph="none" pos="word" start_char="3075">less</TOKEN>
<TOKEN end_char="3088" id="token-35-20" morph="none" pos="word" start_char="3080">breathing</TOKEN>
<TOKEN end_char="3096" id="token-35-21" morph="none" pos="word" start_char="3090">support</TOKEN>
<TOKEN end_char="3100" id="token-35-22" morph="none" pos="word" start_char="3098">for</TOKEN>
<TOKEN end_char="3104" id="token-35-23" morph="none" pos="word" start_char="3102">the</TOKEN>
<TOKEN end_char="3112" id="token-35-24" morph="none" pos="word" start_char="3106">overall</TOKEN>
<TOKEN end_char="3123" id="token-35-25" morph="none" pos="word" start_char="3114">population</TOKEN>
<TOKEN end_char="3131" id="token-35-26" morph="none" pos="word" start_char="3125">needing</TOKEN>
<TOKEN end_char="3135" id="token-35-27" morph="none" pos="word" start_char="3133">any</TOKEN>
<TOKEN end_char="3145" id="token-35-28" morph="none" pos="word" start_char="3137">breathing</TOKEN>
<TOKEN end_char="3153" id="token-35-29" morph="none" pos="word" start_char="3147">support</TOKEN>
<TOKEN end_char="3160" id="token-35-30" morph="none" pos="word" start_char="3155">before</TOKEN>
<TOKEN end_char="3164" id="token-35-31" morph="none" pos="word" start_char="3162">the</TOKEN>
<TOKEN end_char="3170" id="token-35-32" morph="none" pos="word" start_char="3166">start</TOKEN>
<TOKEN end_char="3173" id="token-35-33" morph="none" pos="word" start_char="3172">of</TOKEN>
<TOKEN end_char="3183" id="token-35-34" morph="none" pos="word" start_char="3175">treatment</TOKEN>
<TOKEN end_char="3185" id="token-35-35" morph="none" pos="punct" start_char="3185">(</TOKEN>
<TOKEN end_char="3186" id="token-35-36" morph="none" pos="word" start_char="3186">8</TOKEN>
<TOKEN end_char="3194" id="token-35-37" morph="none" pos="word" start_char="3188">studies</TOKEN>
<TOKEN end_char="3195" id="token-35-38" morph="none" pos="punct" start_char="3195">,</TOKEN>
<TOKEN end_char="3202" id="token-35-39" morph="none" pos="unknown" start_char="3197">12,682</TOKEN>
<TOKEN end_char="3209" id="token-35-40" morph="none" pos="word" start_char="3204">people</TOKEN>
<TOKEN end_char="3211" id="token-35-41" morph="none" pos="punct" start_char="3210">),</TOKEN>
<TOKEN end_char="3215" id="token-35-42" morph="none" pos="word" start_char="3213">and</TOKEN>
<TOKEN end_char="3220" id="token-35-43" morph="none" pos="word" start_char="3217">also</TOKEN>
<TOKEN end_char="3224" id="token-35-44" morph="none" pos="word" start_char="3222">not</TOKEN>
<TOKEN end_char="3228" id="token-35-45" morph="none" pos="word" start_char="3226">for</TOKEN>
<TOKEN end_char="3232" id="token-35-46" morph="none" pos="word" start_char="3230">the</TOKEN>
<TOKEN end_char="3239" id="token-35-47" morph="none" pos="word" start_char="3234">people</TOKEN>
<TOKEN end_char="3244" id="token-35-48" morph="none" pos="word" start_char="3241">that</TOKEN>
<TOKEN end_char="3249" id="token-35-49" morph="none" pos="word" start_char="3246">were</TOKEN>
<TOKEN end_char="3260" id="token-35-50" morph="none" pos="word" start_char="3251">ventilated</TOKEN>
<TOKEN end_char="3263" id="token-35-51" morph="none" pos="word" start_char="3262">at</TOKEN>
<TOKEN end_char="3267" id="token-35-52" morph="none" pos="word" start_char="3265">the</TOKEN>
<TOKEN end_char="3277" id="token-35-53" morph="none" pos="word" start_char="3269">beginning</TOKEN>
<TOKEN end_char="3280" id="token-35-54" morph="none" pos="word" start_char="3279">of</TOKEN>
<TOKEN end_char="3284" id="token-35-55" morph="none" pos="word" start_char="3282">the</TOKEN>
<TOKEN end_char="3290" id="token-35-56" morph="none" pos="word" start_char="3286">study</TOKEN>
<TOKEN end_char="3292" id="token-35-57" morph="none" pos="punct" start_char="3292">(</TOKEN>
<TOKEN end_char="3293" id="token-35-58" morph="none" pos="word" start_char="3293">2</TOKEN>
<TOKEN end_char="3301" id="token-35-59" morph="none" pos="word" start_char="3295">studies</TOKEN>
<TOKEN end_char="3302" id="token-35-60" morph="none" pos="punct" start_char="3302">,</TOKEN>
<TOKEN end_char="3306" id="token-35-61" morph="none" pos="word" start_char="3304">630</TOKEN>
<TOKEN end_char="3313" id="token-35-62" morph="none" pos="word" start_char="3308">people</TOKEN>
<TOKEN end_char="3315" id="token-35-63" morph="none" pos="punct" start_char="3314">);</TOKEN>
</SEG>
<SEG end_char="3399" id="segment-36" start_char="3318">
<ORIGINAL_TEXT>• convalescent plasma makes no difference to the worsening of patients’ condition.</ORIGINAL_TEXT>
<TOKEN end_char="3318" id="token-36-0" morph="none" pos="punct" start_char="3318">•</TOKEN>
<TOKEN end_char="3331" id="token-36-1" morph="none" pos="word" start_char="3320">convalescent</TOKEN>
<TOKEN end_char="3338" id="token-36-2" morph="none" pos="word" start_char="3333">plasma</TOKEN>
<TOKEN end_char="3344" id="token-36-3" morph="none" pos="word" start_char="3340">makes</TOKEN>
<TOKEN end_char="3347" id="token-36-4" morph="none" pos="word" start_char="3346">no</TOKEN>
<TOKEN end_char="3358" id="token-36-5" morph="none" pos="word" start_char="3349">difference</TOKEN>
<TOKEN end_char="3361" id="token-36-6" morph="none" pos="word" start_char="3360">to</TOKEN>
<TOKEN end_char="3365" id="token-36-7" morph="none" pos="word" start_char="3363">the</TOKEN>
<TOKEN end_char="3375" id="token-36-8" morph="none" pos="word" start_char="3367">worsening</TOKEN>
<TOKEN end_char="3378" id="token-36-9" morph="none" pos="word" start_char="3377">of</TOKEN>
<TOKEN end_char="3387" id="token-36-10" morph="none" pos="word" start_char="3380">patients</TOKEN>
<TOKEN end_char="3388" id="token-36-11" morph="none" pos="punct" start_char="3388">’</TOKEN>
<TOKEN end_char="3398" id="token-36-12" morph="none" pos="word" start_char="3390">condition</TOKEN>
<TOKEN end_char="3399" id="token-36-13" morph="none" pos="punct" start_char="3399">.</TOKEN>
</SEG>
<SEG end_char="3593" id="segment-37" start_char="3401">
<ORIGINAL_TEXT>About 126 in 1000 people given placebo or standard care needed invasive mechanical ventilation, compared to 123 in 1000 people who had been given convalescent plasma (4 studies, 11,765 people);</ORIGINAL_TEXT>
<TOKEN end_char="3405" id="token-37-0" morph="none" pos="word" start_char="3401">About</TOKEN>
<TOKEN end_char="3409" id="token-37-1" morph="none" pos="word" start_char="3407">126</TOKEN>
<TOKEN end_char="3412" id="token-37-2" morph="none" pos="word" start_char="3411">in</TOKEN>
<TOKEN end_char="3417" id="token-37-3" morph="none" pos="word" start_char="3414">1000</TOKEN>
<TOKEN end_char="3424" id="token-37-4" morph="none" pos="word" start_char="3419">people</TOKEN>
<TOKEN end_char="3430" id="token-37-5" morph="none" pos="word" start_char="3426">given</TOKEN>
<TOKEN end_char="3438" id="token-37-6" morph="none" pos="word" start_char="3432">placebo</TOKEN>
<TOKEN end_char="3441" id="token-37-7" morph="none" pos="word" start_char="3440">or</TOKEN>
<TOKEN end_char="3450" id="token-37-8" morph="none" pos="word" start_char="3443">standard</TOKEN>
<TOKEN end_char="3455" id="token-37-9" morph="none" pos="word" start_char="3452">care</TOKEN>
<TOKEN end_char="3462" id="token-37-10" morph="none" pos="word" start_char="3457">needed</TOKEN>
<TOKEN end_char="3471" id="token-37-11" morph="none" pos="word" start_char="3464">invasive</TOKEN>
<TOKEN end_char="3482" id="token-37-12" morph="none" pos="word" start_char="3473">mechanical</TOKEN>
<TOKEN end_char="3494" id="token-37-13" morph="none" pos="word" start_char="3484">ventilation</TOKEN>
<TOKEN end_char="3495" id="token-37-14" morph="none" pos="punct" start_char="3495">,</TOKEN>
<TOKEN end_char="3504" id="token-37-15" morph="none" pos="word" start_char="3497">compared</TOKEN>
<TOKEN end_char="3507" id="token-37-16" morph="none" pos="word" start_char="3506">to</TOKEN>
<TOKEN end_char="3511" id="token-37-17" morph="none" pos="word" start_char="3509">123</TOKEN>
<TOKEN end_char="3514" id="token-37-18" morph="none" pos="word" start_char="3513">in</TOKEN>
<TOKEN end_char="3519" id="token-37-19" morph="none" pos="word" start_char="3516">1000</TOKEN>
<TOKEN end_char="3526" id="token-37-20" morph="none" pos="word" start_char="3521">people</TOKEN>
<TOKEN end_char="3530" id="token-37-21" morph="none" pos="word" start_char="3528">who</TOKEN>
<TOKEN end_char="3534" id="token-37-22" morph="none" pos="word" start_char="3532">had</TOKEN>
<TOKEN end_char="3539" id="token-37-23" morph="none" pos="word" start_char="3536">been</TOKEN>
<TOKEN end_char="3545" id="token-37-24" morph="none" pos="word" start_char="3541">given</TOKEN>
<TOKEN end_char="3558" id="token-37-25" morph="none" pos="word" start_char="3547">convalescent</TOKEN>
<TOKEN end_char="3565" id="token-37-26" morph="none" pos="word" start_char="3560">plasma</TOKEN>
<TOKEN end_char="3567" id="token-37-27" morph="none" pos="punct" start_char="3567">(</TOKEN>
<TOKEN end_char="3568" id="token-37-28" morph="none" pos="word" start_char="3568">4</TOKEN>
<TOKEN end_char="3576" id="token-37-29" morph="none" pos="word" start_char="3570">studies</TOKEN>
<TOKEN end_char="3577" id="token-37-30" morph="none" pos="punct" start_char="3577">,</TOKEN>
<TOKEN end_char="3584" id="token-37-31" morph="none" pos="unknown" start_char="3579">11,765</TOKEN>
<TOKEN end_char="3591" id="token-37-32" morph="none" pos="word" start_char="3586">people</TOKEN>
<TOKEN end_char="3593" id="token-37-33" morph="none" pos="punct" start_char="3592">);</TOKEN>
</SEG>
<SEG end_char="3660" id="segment-38" start_char="3596">
<ORIGINAL_TEXT>• convalescent plasma may make no difference to unwanted effects.</ORIGINAL_TEXT>
<TOKEN end_char="3596" id="token-38-0" morph="none" pos="punct" start_char="3596">•</TOKEN>
<TOKEN end_char="3609" id="token-38-1" morph="none" pos="word" start_char="3598">convalescent</TOKEN>
<TOKEN end_char="3616" id="token-38-2" morph="none" pos="word" start_char="3611">plasma</TOKEN>
<TOKEN end_char="3620" id="token-38-3" morph="none" pos="word" start_char="3618">may</TOKEN>
<TOKEN end_char="3625" id="token-38-4" morph="none" pos="word" start_char="3622">make</TOKEN>
<TOKEN end_char="3628" id="token-38-5" morph="none" pos="word" start_char="3627">no</TOKEN>
<TOKEN end_char="3639" id="token-38-6" morph="none" pos="word" start_char="3630">difference</TOKEN>
<TOKEN end_char="3642" id="token-38-7" morph="none" pos="word" start_char="3641">to</TOKEN>
<TOKEN end_char="3651" id="token-38-8" morph="none" pos="word" start_char="3644">unwanted</TOKEN>
<TOKEN end_char="3659" id="token-38-9" morph="none" pos="word" start_char="3653">effects</TOKEN>
<TOKEN end_char="3660" id="token-38-10" morph="none" pos="punct" start_char="3660">.</TOKEN>
</SEG>
<SEG end_char="3801" id="segment-39" start_char="3662">
<ORIGINAL_TEXT>The 8 studies that reported unwanted effects measured and reported their results very differently, so we are unable to draw any conclusions.</ORIGINAL_TEXT>
<TOKEN end_char="3664" id="token-39-0" morph="none" pos="word" start_char="3662">The</TOKEN>
<TOKEN end_char="3666" id="token-39-1" morph="none" pos="word" start_char="3666">8</TOKEN>
<TOKEN end_char="3674" id="token-39-2" morph="none" pos="word" start_char="3668">studies</TOKEN>
<TOKEN end_char="3679" id="token-39-3" morph="none" pos="word" start_char="3676">that</TOKEN>
<TOKEN end_char="3688" id="token-39-4" morph="none" pos="word" start_char="3681">reported</TOKEN>
<TOKEN end_char="3697" id="token-39-5" morph="none" pos="word" start_char="3690">unwanted</TOKEN>
<TOKEN end_char="3705" id="token-39-6" morph="none" pos="word" start_char="3699">effects</TOKEN>
<TOKEN end_char="3714" id="token-39-7" morph="none" pos="word" start_char="3707">measured</TOKEN>
<TOKEN end_char="3718" id="token-39-8" morph="none" pos="word" start_char="3716">and</TOKEN>
<TOKEN end_char="3727" id="token-39-9" morph="none" pos="word" start_char="3720">reported</TOKEN>
<TOKEN end_char="3733" id="token-39-10" morph="none" pos="word" start_char="3729">their</TOKEN>
<TOKEN end_char="3741" id="token-39-11" morph="none" pos="word" start_char="3735">results</TOKEN>
<TOKEN end_char="3746" id="token-39-12" morph="none" pos="word" start_char="3743">very</TOKEN>
<TOKEN end_char="3758" id="token-39-13" morph="none" pos="word" start_char="3748">differently</TOKEN>
<TOKEN end_char="3759" id="token-39-14" morph="none" pos="punct" start_char="3759">,</TOKEN>
<TOKEN end_char="3762" id="token-39-15" morph="none" pos="word" start_char="3761">so</TOKEN>
<TOKEN end_char="3765" id="token-39-16" morph="none" pos="word" start_char="3764">we</TOKEN>
<TOKEN end_char="3769" id="token-39-17" morph="none" pos="word" start_char="3767">are</TOKEN>
<TOKEN end_char="3776" id="token-39-18" morph="none" pos="word" start_char="3771">unable</TOKEN>
<TOKEN end_char="3779" id="token-39-19" morph="none" pos="word" start_char="3778">to</TOKEN>
<TOKEN end_char="3784" id="token-39-20" morph="none" pos="word" start_char="3781">draw</TOKEN>
<TOKEN end_char="3788" id="token-39-21" morph="none" pos="word" start_char="3786">any</TOKEN>
<TOKEN end_char="3800" id="token-39-22" morph="none" pos="word" start_char="3790">conclusions</TOKEN>
<TOKEN end_char="3801" id="token-39-23" morph="none" pos="punct" start_char="3801">.</TOKEN>
</SEG>
<SEG end_char="3848" id="segment-40" start_char="3804">
<ORIGINAL_TEXT>None of the studies reported quality of life.</ORIGINAL_TEXT>
<TOKEN end_char="3807" id="token-40-0" morph="none" pos="word" start_char="3804">None</TOKEN>
<TOKEN end_char="3810" id="token-40-1" morph="none" pos="word" start_char="3809">of</TOKEN>
<TOKEN end_char="3814" id="token-40-2" morph="none" pos="word" start_char="3812">the</TOKEN>
<TOKEN end_char="3822" id="token-40-3" morph="none" pos="word" start_char="3816">studies</TOKEN>
<TOKEN end_char="3831" id="token-40-4" morph="none" pos="word" start_char="3824">reported</TOKEN>
<TOKEN end_char="3839" id="token-40-5" morph="none" pos="word" start_char="3833">quality</TOKEN>
<TOKEN end_char="3842" id="token-40-6" morph="none" pos="word" start_char="3841">of</TOKEN>
<TOKEN end_char="3847" id="token-40-7" morph="none" pos="word" start_char="3844">life</TOKEN>
<TOKEN end_char="3848" id="token-40-8" morph="none" pos="punct" start_char="3848">.</TOKEN>
</SEG>
<SEG end_char="4064" id="segment-41" start_char="3851">
<ORIGINAL_TEXT>Mild COVID-19 We do not know if convalescent plasma compared to placebo or standard care makes a difference to number of deaths, improvement or worsening of patients’ condition, quality of life or unwanted effects.</ORIGINAL_TEXT>
<TOKEN end_char="3854" id="token-41-0" morph="none" pos="word" start_char="3851">Mild</TOKEN>
<TOKEN end_char="3863" id="token-41-1" morph="none" pos="unknown" start_char="3856">COVID-19</TOKEN>
<TOKEN end_char="3866" id="token-41-2" morph="none" pos="word" start_char="3865">We</TOKEN>
<TOKEN end_char="3869" id="token-41-3" morph="none" pos="word" start_char="3868">do</TOKEN>
<TOKEN end_char="3873" id="token-41-4" morph="none" pos="word" start_char="3871">not</TOKEN>
<TOKEN end_char="3878" id="token-41-5" morph="none" pos="word" start_char="3875">know</TOKEN>
<TOKEN end_char="3881" id="token-41-6" morph="none" pos="word" start_char="3880">if</TOKEN>
<TOKEN end_char="3894" id="token-41-7" morph="none" pos="word" start_char="3883">convalescent</TOKEN>
<TOKEN end_char="3901" id="token-41-8" morph="none" pos="word" start_char="3896">plasma</TOKEN>
<TOKEN end_char="3910" id="token-41-9" morph="none" pos="word" start_char="3903">compared</TOKEN>
<TOKEN end_char="3913" id="token-41-10" morph="none" pos="word" start_char="3912">to</TOKEN>
<TOKEN end_char="3921" id="token-41-11" morph="none" pos="word" start_char="3915">placebo</TOKEN>
<TOKEN end_char="3924" id="token-41-12" morph="none" pos="word" start_char="3923">or</TOKEN>
<TOKEN end_char="3933" id="token-41-13" morph="none" pos="word" start_char="3926">standard</TOKEN>
<TOKEN end_char="3938" id="token-41-14" morph="none" pos="word" start_char="3935">care</TOKEN>
<TOKEN end_char="3944" id="token-41-15" morph="none" pos="word" start_char="3940">makes</TOKEN>
<TOKEN end_char="3946" id="token-41-16" morph="none" pos="word" start_char="3946">a</TOKEN>
<TOKEN end_char="3957" id="token-41-17" morph="none" pos="word" start_char="3948">difference</TOKEN>
<TOKEN end_char="3960" id="token-41-18" morph="none" pos="word" start_char="3959">to</TOKEN>
<TOKEN end_char="3967" id="token-41-19" morph="none" pos="word" start_char="3962">number</TOKEN>
<TOKEN end_char="3970" id="token-41-20" morph="none" pos="word" start_char="3969">of</TOKEN>
<TOKEN end_char="3977" id="token-41-21" morph="none" pos="word" start_char="3972">deaths</TOKEN>
<TOKEN end_char="3978" id="token-41-22" morph="none" pos="punct" start_char="3978">,</TOKEN>
<TOKEN end_char="3990" id="token-41-23" morph="none" pos="word" start_char="3980">improvement</TOKEN>
<TOKEN end_char="3993" id="token-41-24" morph="none" pos="word" start_char="3992">or</TOKEN>
<TOKEN end_char="4003" id="token-41-25" morph="none" pos="word" start_char="3995">worsening</TOKEN>
<TOKEN end_char="4006" id="token-41-26" morph="none" pos="word" start_char="4005">of</TOKEN>
<TOKEN end_char="4015" id="token-41-27" morph="none" pos="word" start_char="4008">patients</TOKEN>
<TOKEN end_char="4016" id="token-41-28" morph="none" pos="punct" start_char="4016">’</TOKEN>
<TOKEN end_char="4026" id="token-41-29" morph="none" pos="word" start_char="4018">condition</TOKEN>
<TOKEN end_char="4027" id="token-41-30" morph="none" pos="punct" start_char="4027">,</TOKEN>
<TOKEN end_char="4035" id="token-41-31" morph="none" pos="word" start_char="4029">quality</TOKEN>
<TOKEN end_char="4038" id="token-41-32" morph="none" pos="word" start_char="4037">of</TOKEN>
<TOKEN end_char="4043" id="token-41-33" morph="none" pos="word" start_char="4040">life</TOKEN>
<TOKEN end_char="4046" id="token-41-34" morph="none" pos="word" start_char="4045">or</TOKEN>
<TOKEN end_char="4055" id="token-41-35" morph="none" pos="word" start_char="4048">unwanted</TOKEN>
<TOKEN end_char="4063" id="token-41-36" morph="none" pos="word" start_char="4057">effects</TOKEN>
<TOKEN end_char="4064" id="token-41-37" morph="none" pos="punct" start_char="4064">.</TOKEN>
</SEG>
<SEG end_char="4151" id="segment-42" start_char="4066">
<ORIGINAL_TEXT>We found only one study with 160 participants that assessed people with mild COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="4067" id="token-42-0" morph="none" pos="word" start_char="4066">We</TOKEN>
<TOKEN end_char="4073" id="token-42-1" morph="none" pos="word" start_char="4069">found</TOKEN>
<TOKEN end_char="4078" id="token-42-2" morph="none" pos="word" start_char="4075">only</TOKEN>
<TOKEN end_char="4082" id="token-42-3" morph="none" pos="word" start_char="4080">one</TOKEN>
<TOKEN end_char="4088" id="token-42-4" morph="none" pos="word" start_char="4084">study</TOKEN>
<TOKEN end_char="4093" id="token-42-5" morph="none" pos="word" start_char="4090">with</TOKEN>
<TOKEN end_char="4097" id="token-42-6" morph="none" pos="word" start_char="4095">160</TOKEN>
<TOKEN end_char="4110" id="token-42-7" morph="none" pos="word" start_char="4099">participants</TOKEN>
<TOKEN end_char="4115" id="token-42-8" morph="none" pos="word" start_char="4112">that</TOKEN>
<TOKEN end_char="4124" id="token-42-9" morph="none" pos="word" start_char="4117">assessed</TOKEN>
<TOKEN end_char="4131" id="token-42-10" morph="none" pos="word" start_char="4126">people</TOKEN>
<TOKEN end_char="4136" id="token-42-11" morph="none" pos="word" start_char="4133">with</TOKEN>
<TOKEN end_char="4141" id="token-42-12" morph="none" pos="word" start_char="4138">mild</TOKEN>
<TOKEN end_char="4150" id="token-42-13" morph="none" pos="unknown" start_char="4143">COVID-19</TOKEN>
<TOKEN end_char="4151" id="token-42-14" morph="none" pos="punct" start_char="4151">.</TOKEN>
</SEG>
<SEG end_char="4194" id="segment-43" start_char="4154">
<ORIGINAL_TEXT>What are the limitations of the evidence?</ORIGINAL_TEXT>
<TOKEN end_char="4157" id="token-43-0" morph="none" pos="word" start_char="4154">What</TOKEN>
<TOKEN end_char="4161" id="token-43-1" morph="none" pos="word" start_char="4159">are</TOKEN>
<TOKEN end_char="4165" id="token-43-2" morph="none" pos="word" start_char="4163">the</TOKEN>
<TOKEN end_char="4177" id="token-43-3" morph="none" pos="word" start_char="4167">limitations</TOKEN>
<TOKEN end_char="4180" id="token-43-4" morph="none" pos="word" start_char="4179">of</TOKEN>
<TOKEN end_char="4184" id="token-43-5" morph="none" pos="word" start_char="4182">the</TOKEN>
<TOKEN end_char="4193" id="token-43-6" morph="none" pos="word" start_char="4186">evidence</TOKEN>
<TOKEN end_char="4194" id="token-43-7" morph="none" pos="punct" start_char="4194">?</TOKEN>
</SEG>
<SEG end_char="4357" id="segment-44" start_char="4197">
<ORIGINAL_TEXT>• We are very confident in the evidence for deaths from any cause and improvement or worsening of patients’ condition in people with moderate to severe COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="4197" id="token-44-0" morph="none" pos="punct" start_char="4197">•</TOKEN>
<TOKEN end_char="4200" id="token-44-1" morph="none" pos="word" start_char="4199">We</TOKEN>
<TOKEN end_char="4204" id="token-44-2" morph="none" pos="word" start_char="4202">are</TOKEN>
<TOKEN end_char="4209" id="token-44-3" morph="none" pos="word" start_char="4206">very</TOKEN>
<TOKEN end_char="4219" id="token-44-4" morph="none" pos="word" start_char="4211">confident</TOKEN>
<TOKEN end_char="4222" id="token-44-5" morph="none" pos="word" start_char="4221">in</TOKEN>
<TOKEN end_char="4226" id="token-44-6" morph="none" pos="word" start_char="4224">the</TOKEN>
<TOKEN end_char="4235" id="token-44-7" morph="none" pos="word" start_char="4228">evidence</TOKEN>
<TOKEN end_char="4239" id="token-44-8" morph="none" pos="word" start_char="4237">for</TOKEN>
<TOKEN end_char="4246" id="token-44-9" morph="none" pos="word" start_char="4241">deaths</TOKEN>
<TOKEN end_char="4251" id="token-44-10" morph="none" pos="word" start_char="4248">from</TOKEN>
<TOKEN end_char="4255" id="token-44-11" morph="none" pos="word" start_char="4253">any</TOKEN>
<TOKEN end_char="4261" id="token-44-12" morph="none" pos="word" start_char="4257">cause</TOKEN>
<TOKEN end_char="4265" id="token-44-13" morph="none" pos="word" start_char="4263">and</TOKEN>
<TOKEN end_char="4277" id="token-44-14" morph="none" pos="word" start_char="4267">improvement</TOKEN>
<TOKEN end_char="4280" id="token-44-15" morph="none" pos="word" start_char="4279">or</TOKEN>
<TOKEN end_char="4290" id="token-44-16" morph="none" pos="word" start_char="4282">worsening</TOKEN>
<TOKEN end_char="4293" id="token-44-17" morph="none" pos="word" start_char="4292">of</TOKEN>
<TOKEN end_char="4302" id="token-44-18" morph="none" pos="word" start_char="4295">patients</TOKEN>
<TOKEN end_char="4303" id="token-44-19" morph="none" pos="punct" start_char="4303">’</TOKEN>
<TOKEN end_char="4313" id="token-44-20" morph="none" pos="word" start_char="4305">condition</TOKEN>
<TOKEN end_char="4316" id="token-44-21" morph="none" pos="word" start_char="4315">in</TOKEN>
<TOKEN end_char="4323" id="token-44-22" morph="none" pos="word" start_char="4318">people</TOKEN>
<TOKEN end_char="4328" id="token-44-23" morph="none" pos="word" start_char="4325">with</TOKEN>
<TOKEN end_char="4337" id="token-44-24" morph="none" pos="word" start_char="4330">moderate</TOKEN>
<TOKEN end_char="4340" id="token-44-25" morph="none" pos="word" start_char="4339">to</TOKEN>
<TOKEN end_char="4347" id="token-44-26" morph="none" pos="word" start_char="4342">severe</TOKEN>
<TOKEN end_char="4356" id="token-44-27" morph="none" pos="unknown" start_char="4349">COVID-19</TOKEN>
<TOKEN end_char="4357" id="token-44-28" morph="none" pos="punct" start_char="4357">.</TOKEN>
</SEG>
<SEG end_char="4579" id="segment-45" start_char="4360">
<ORIGINAL_TEXT>• Our confidence in the other evidence for people with moderate and severe, and mild COVID-19 is very limited because the studies were very different and did not measure and record their results using consistent methods.</ORIGINAL_TEXT>
<TOKEN end_char="4360" id="token-45-0" morph="none" pos="punct" start_char="4360">•</TOKEN>
<TOKEN end_char="4364" id="token-45-1" morph="none" pos="word" start_char="4362">Our</TOKEN>
<TOKEN end_char="4375" id="token-45-2" morph="none" pos="word" start_char="4366">confidence</TOKEN>
<TOKEN end_char="4378" id="token-45-3" morph="none" pos="word" start_char="4377">in</TOKEN>
<TOKEN end_char="4382" id="token-45-4" morph="none" pos="word" start_char="4380">the</TOKEN>
<TOKEN end_char="4388" id="token-45-5" morph="none" pos="word" start_char="4384">other</TOKEN>
<TOKEN end_char="4397" id="token-45-6" morph="none" pos="word" start_char="4390">evidence</TOKEN>
<TOKEN end_char="4401" id="token-45-7" morph="none" pos="word" start_char="4399">for</TOKEN>
<TOKEN end_char="4408" id="token-45-8" morph="none" pos="word" start_char="4403">people</TOKEN>
<TOKEN end_char="4413" id="token-45-9" morph="none" pos="word" start_char="4410">with</TOKEN>
<TOKEN end_char="4422" id="token-45-10" morph="none" pos="word" start_char="4415">moderate</TOKEN>
<TOKEN end_char="4426" id="token-45-11" morph="none" pos="word" start_char="4424">and</TOKEN>
<TOKEN end_char="4433" id="token-45-12" morph="none" pos="word" start_char="4428">severe</TOKEN>
<TOKEN end_char="4434" id="token-45-13" morph="none" pos="punct" start_char="4434">,</TOKEN>
<TOKEN end_char="4438" id="token-45-14" morph="none" pos="word" start_char="4436">and</TOKEN>
<TOKEN end_char="4443" id="token-45-15" morph="none" pos="word" start_char="4440">mild</TOKEN>
<TOKEN end_char="4452" id="token-45-16" morph="none" pos="unknown" start_char="4445">COVID-19</TOKEN>
<TOKEN end_char="4455" id="token-45-17" morph="none" pos="word" start_char="4454">is</TOKEN>
<TOKEN end_char="4460" id="token-45-18" morph="none" pos="word" start_char="4457">very</TOKEN>
<TOKEN end_char="4468" id="token-45-19" morph="none" pos="word" start_char="4462">limited</TOKEN>
<TOKEN end_char="4476" id="token-45-20" morph="none" pos="word" start_char="4470">because</TOKEN>
<TOKEN end_char="4480" id="token-45-21" morph="none" pos="word" start_char="4478">the</TOKEN>
<TOKEN end_char="4488" id="token-45-22" morph="none" pos="word" start_char="4482">studies</TOKEN>
<TOKEN end_char="4493" id="token-45-23" morph="none" pos="word" start_char="4490">were</TOKEN>
<TOKEN end_char="4498" id="token-45-24" morph="none" pos="word" start_char="4495">very</TOKEN>
<TOKEN end_char="4508" id="token-45-25" morph="none" pos="word" start_char="4500">different</TOKEN>
<TOKEN end_char="4512" id="token-45-26" morph="none" pos="word" start_char="4510">and</TOKEN>
<TOKEN end_char="4516" id="token-45-27" morph="none" pos="word" start_char="4514">did</TOKEN>
<TOKEN end_char="4520" id="token-45-28" morph="none" pos="word" start_char="4518">not</TOKEN>
<TOKEN end_char="4528" id="token-45-29" morph="none" pos="word" start_char="4522">measure</TOKEN>
<TOKEN end_char="4532" id="token-45-30" morph="none" pos="word" start_char="4530">and</TOKEN>
<TOKEN end_char="4539" id="token-45-31" morph="none" pos="word" start_char="4534">record</TOKEN>
<TOKEN end_char="4545" id="token-45-32" morph="none" pos="word" start_char="4541">their</TOKEN>
<TOKEN end_char="4553" id="token-45-33" morph="none" pos="word" start_char="4547">results</TOKEN>
<TOKEN end_char="4559" id="token-45-34" morph="none" pos="word" start_char="4555">using</TOKEN>
<TOKEN end_char="4570" id="token-45-35" morph="none" pos="word" start_char="4561">consistent</TOKEN>
<TOKEN end_char="4578" id="token-45-36" morph="none" pos="word" start_char="4572">methods</TOKEN>
<TOKEN end_char="4579" id="token-45-37" morph="none" pos="punct" start_char="4579">.</TOKEN>
</SEG>
<SEG end_char="4663" id="segment-46" start_char="4582">
<ORIGINAL_TEXT>• We found little useful evidence on unwanted effects and none on quality of life.</ORIGINAL_TEXT>
<TOKEN end_char="4582" id="token-46-0" morph="none" pos="punct" start_char="4582">•</TOKEN>
<TOKEN end_char="4585" id="token-46-1" morph="none" pos="word" start_char="4584">We</TOKEN>
<TOKEN end_char="4591" id="token-46-2" morph="none" pos="word" start_char="4587">found</TOKEN>
<TOKEN end_char="4598" id="token-46-3" morph="none" pos="word" start_char="4593">little</TOKEN>
<TOKEN end_char="4605" id="token-46-4" morph="none" pos="word" start_char="4600">useful</TOKEN>
<TOKEN end_char="4614" id="token-46-5" morph="none" pos="word" start_char="4607">evidence</TOKEN>
<TOKEN end_char="4617" id="token-46-6" morph="none" pos="word" start_char="4616">on</TOKEN>
<TOKEN end_char="4626" id="token-46-7" morph="none" pos="word" start_char="4619">unwanted</TOKEN>
<TOKEN end_char="4634" id="token-46-8" morph="none" pos="word" start_char="4628">effects</TOKEN>
<TOKEN end_char="4638" id="token-46-9" morph="none" pos="word" start_char="4636">and</TOKEN>
<TOKEN end_char="4643" id="token-46-10" morph="none" pos="word" start_char="4640">none</TOKEN>
<TOKEN end_char="4646" id="token-46-11" morph="none" pos="word" start_char="4645">on</TOKEN>
<TOKEN end_char="4654" id="token-46-12" morph="none" pos="word" start_char="4648">quality</TOKEN>
<TOKEN end_char="4657" id="token-46-13" morph="none" pos="word" start_char="4656">of</TOKEN>
<TOKEN end_char="4662" id="token-46-14" morph="none" pos="word" start_char="4659">life</TOKEN>
<TOKEN end_char="4663" id="token-46-15" morph="none" pos="punct" start_char="4663">.</TOKEN>
</SEG>
<SEG end_char="4697" id="segment-47" start_char="4666">
<ORIGINAL_TEXT>How up to date is this evidence?</ORIGINAL_TEXT>
<TOKEN end_char="4668" id="token-47-0" morph="none" pos="word" start_char="4666">How</TOKEN>
<TOKEN end_char="4671" id="token-47-1" morph="none" pos="word" start_char="4670">up</TOKEN>
<TOKEN end_char="4674" id="token-47-2" morph="none" pos="word" start_char="4673">to</TOKEN>
<TOKEN end_char="4679" id="token-47-3" morph="none" pos="word" start_char="4676">date</TOKEN>
<TOKEN end_char="4682" id="token-47-4" morph="none" pos="word" start_char="4681">is</TOKEN>
<TOKEN end_char="4687" id="token-47-5" morph="none" pos="word" start_char="4684">this</TOKEN>
<TOKEN end_char="4696" id="token-47-6" morph="none" pos="word" start_char="4689">evidence</TOKEN>
<TOKEN end_char="4697" id="token-47-7" morph="none" pos="punct" start_char="4697">?</TOKEN>
</SEG>
<SEG end_char="4740" id="segment-48" start_char="4700">
<ORIGINAL_TEXT>This is the fourth version of our review.</ORIGINAL_TEXT>
<TOKEN end_char="4703" id="token-48-0" morph="none" pos="word" start_char="4700">This</TOKEN>
<TOKEN end_char="4706" id="token-48-1" morph="none" pos="word" start_char="4705">is</TOKEN>
<TOKEN end_char="4710" id="token-48-2" morph="none" pos="word" start_char="4708">the</TOKEN>
<TOKEN end_char="4717" id="token-48-3" morph="none" pos="word" start_char="4712">fourth</TOKEN>
<TOKEN end_char="4725" id="token-48-4" morph="none" pos="word" start_char="4719">version</TOKEN>
<TOKEN end_char="4728" id="token-48-5" morph="none" pos="word" start_char="4727">of</TOKEN>
<TOKEN end_char="4732" id="token-48-6" morph="none" pos="word" start_char="4730">our</TOKEN>
<TOKEN end_char="4739" id="token-48-7" morph="none" pos="word" start_char="4734">review</TOKEN>
<TOKEN end_char="4740" id="token-48-8" morph="none" pos="punct" start_char="4740">.</TOKEN>
</SEG>
<SEG end_char="4785" id="segment-49" start_char="4742">
<ORIGINAL_TEXT>The evidence is up to date to 17 March 2021.</ORIGINAL_TEXT>
<TOKEN end_char="4744" id="token-49-0" morph="none" pos="word" start_char="4742">The</TOKEN>
<TOKEN end_char="4753" id="token-49-1" morph="none" pos="word" start_char="4746">evidence</TOKEN>
<TOKEN end_char="4756" id="token-49-2" morph="none" pos="word" start_char="4755">is</TOKEN>
<TOKEN end_char="4759" id="token-49-3" morph="none" pos="word" start_char="4758">up</TOKEN>
<TOKEN end_char="4762" id="token-49-4" morph="none" pos="word" start_char="4761">to</TOKEN>
<TOKEN end_char="4767" id="token-49-5" morph="none" pos="word" start_char="4764">date</TOKEN>
<TOKEN end_char="4770" id="token-49-6" morph="none" pos="word" start_char="4769">to</TOKEN>
<TOKEN end_char="4773" id="token-49-7" morph="none" pos="word" start_char="4772">17</TOKEN>
<TOKEN end_char="4779" id="token-49-8" morph="none" pos="word" start_char="4775">March</TOKEN>
<TOKEN end_char="4784" id="token-49-9" morph="none" pos="word" start_char="4781">2021</TOKEN>
<TOKEN end_char="4785" id="token-49-10" morph="none" pos="punct" start_char="4785">.</TOKEN>
</SEG>
<SEG end_char="5006" id="segment-50" start_char="4788">
<ORIGINAL_TEXT>We have high certainty in the evidence that convalescent plasma for the treatment of individuals with moderate to severe disease does not reduce mortality and has little to no impact on measures of clinical improvement.</ORIGINAL_TEXT>
<TOKEN end_char="4789" id="token-50-0" morph="none" pos="word" start_char="4788">We</TOKEN>
<TOKEN end_char="4794" id="token-50-1" morph="none" pos="word" start_char="4791">have</TOKEN>
<TOKEN end_char="4799" id="token-50-2" morph="none" pos="word" start_char="4796">high</TOKEN>
<TOKEN end_char="4809" id="token-50-3" morph="none" pos="word" start_char="4801">certainty</TOKEN>
<TOKEN end_char="4812" id="token-50-4" morph="none" pos="word" start_char="4811">in</TOKEN>
<TOKEN end_char="4816" id="token-50-5" morph="none" pos="word" start_char="4814">the</TOKEN>
<TOKEN end_char="4825" id="token-50-6" morph="none" pos="word" start_char="4818">evidence</TOKEN>
<TOKEN end_char="4830" id="token-50-7" morph="none" pos="word" start_char="4827">that</TOKEN>
<TOKEN end_char="4843" id="token-50-8" morph="none" pos="word" start_char="4832">convalescent</TOKEN>
<TOKEN end_char="4850" id="token-50-9" morph="none" pos="word" start_char="4845">plasma</TOKEN>
<TOKEN end_char="4854" id="token-50-10" morph="none" pos="word" start_char="4852">for</TOKEN>
<TOKEN end_char="4858" id="token-50-11" morph="none" pos="word" start_char="4856">the</TOKEN>
<TOKEN end_char="4868" id="token-50-12" morph="none" pos="word" start_char="4860">treatment</TOKEN>
<TOKEN end_char="4871" id="token-50-13" morph="none" pos="word" start_char="4870">of</TOKEN>
<TOKEN end_char="4883" id="token-50-14" morph="none" pos="word" start_char="4873">individuals</TOKEN>
<TOKEN end_char="4888" id="token-50-15" morph="none" pos="word" start_char="4885">with</TOKEN>
<TOKEN end_char="4897" id="token-50-16" morph="none" pos="word" start_char="4890">moderate</TOKEN>
<TOKEN end_char="4900" id="token-50-17" morph="none" pos="word" start_char="4899">to</TOKEN>
<TOKEN end_char="4907" id="token-50-18" morph="none" pos="word" start_char="4902">severe</TOKEN>
<TOKEN end_char="4915" id="token-50-19" morph="none" pos="word" start_char="4909">disease</TOKEN>
<TOKEN end_char="4920" id="token-50-20" morph="none" pos="word" start_char="4917">does</TOKEN>
<TOKEN end_char="4924" id="token-50-21" morph="none" pos="word" start_char="4922">not</TOKEN>
<TOKEN end_char="4931" id="token-50-22" morph="none" pos="word" start_char="4926">reduce</TOKEN>
<TOKEN end_char="4941" id="token-50-23" morph="none" pos="word" start_char="4933">mortality</TOKEN>
<TOKEN end_char="4945" id="token-50-24" morph="none" pos="word" start_char="4943">and</TOKEN>
<TOKEN end_char="4949" id="token-50-25" morph="none" pos="word" start_char="4947">has</TOKEN>
<TOKEN end_char="4956" id="token-50-26" morph="none" pos="word" start_char="4951">little</TOKEN>
<TOKEN end_char="4959" id="token-50-27" morph="none" pos="word" start_char="4958">to</TOKEN>
<TOKEN end_char="4962" id="token-50-28" morph="none" pos="word" start_char="4961">no</TOKEN>
<TOKEN end_char="4969" id="token-50-29" morph="none" pos="word" start_char="4964">impact</TOKEN>
<TOKEN end_char="4972" id="token-50-30" morph="none" pos="word" start_char="4971">on</TOKEN>
<TOKEN end_char="4981" id="token-50-31" morph="none" pos="word" start_char="4974">measures</TOKEN>
<TOKEN end_char="4984" id="token-50-32" morph="none" pos="word" start_char="4983">of</TOKEN>
<TOKEN end_char="4993" id="token-50-33" morph="none" pos="word" start_char="4986">clinical</TOKEN>
<TOKEN end_char="5005" id="token-50-34" morph="none" pos="word" start_char="4995">improvement</TOKEN>
<TOKEN end_char="5006" id="token-50-35" morph="none" pos="punct" start_char="5006">.</TOKEN>
</SEG>
<SEG end_char="5073" id="segment-51" start_char="5008">
<ORIGINAL_TEXT>We are uncertain about the adverse effects of convalescent plasma.</ORIGINAL_TEXT>
<TOKEN end_char="5009" id="token-51-0" morph="none" pos="word" start_char="5008">We</TOKEN>
<TOKEN end_char="5013" id="token-51-1" morph="none" pos="word" start_char="5011">are</TOKEN>
<TOKEN end_char="5023" id="token-51-2" morph="none" pos="word" start_char="5015">uncertain</TOKEN>
<TOKEN end_char="5029" id="token-51-3" morph="none" pos="word" start_char="5025">about</TOKEN>
<TOKEN end_char="5033" id="token-51-4" morph="none" pos="word" start_char="5031">the</TOKEN>
<TOKEN end_char="5041" id="token-51-5" morph="none" pos="word" start_char="5035">adverse</TOKEN>
<TOKEN end_char="5049" id="token-51-6" morph="none" pos="word" start_char="5043">effects</TOKEN>
<TOKEN end_char="5052" id="token-51-7" morph="none" pos="word" start_char="5051">of</TOKEN>
<TOKEN end_char="5065" id="token-51-8" morph="none" pos="word" start_char="5054">convalescent</TOKEN>
<TOKEN end_char="5072" id="token-51-9" morph="none" pos="word" start_char="5067">plasma</TOKEN>
<TOKEN end_char="5073" id="token-51-10" morph="none" pos="punct" start_char="5073">.</TOKEN>
</SEG>
<SEG end_char="5199" id="segment-52" start_char="5075">
<ORIGINAL_TEXT>While major efforts to conduct research on COVID-19 are being made, heterogeneous reporting of outcomes is still problematic.</ORIGINAL_TEXT>
<TOKEN end_char="5079" id="token-52-0" morph="none" pos="word" start_char="5075">While</TOKEN>
<TOKEN end_char="5085" id="token-52-1" morph="none" pos="word" start_char="5081">major</TOKEN>
<TOKEN end_char="5093" id="token-52-2" morph="none" pos="word" start_char="5087">efforts</TOKEN>
<TOKEN end_char="5096" id="token-52-3" morph="none" pos="word" start_char="5095">to</TOKEN>
<TOKEN end_char="5104" id="token-52-4" morph="none" pos="word" start_char="5098">conduct</TOKEN>
<TOKEN end_char="5113" id="token-52-5" morph="none" pos="word" start_char="5106">research</TOKEN>
<TOKEN end_char="5116" id="token-52-6" morph="none" pos="word" start_char="5115">on</TOKEN>
<TOKEN end_char="5125" id="token-52-7" morph="none" pos="unknown" start_char="5118">COVID-19</TOKEN>
<TOKEN end_char="5129" id="token-52-8" morph="none" pos="word" start_char="5127">are</TOKEN>
<TOKEN end_char="5135" id="token-52-9" morph="none" pos="word" start_char="5131">being</TOKEN>
<TOKEN end_char="5140" id="token-52-10" morph="none" pos="word" start_char="5137">made</TOKEN>
<TOKEN end_char="5141" id="token-52-11" morph="none" pos="punct" start_char="5141">,</TOKEN>
<TOKEN end_char="5155" id="token-52-12" morph="none" pos="word" start_char="5143">heterogeneous</TOKEN>
<TOKEN end_char="5165" id="token-52-13" morph="none" pos="word" start_char="5157">reporting</TOKEN>
<TOKEN end_char="5168" id="token-52-14" morph="none" pos="word" start_char="5167">of</TOKEN>
<TOKEN end_char="5177" id="token-52-15" morph="none" pos="word" start_char="5170">outcomes</TOKEN>
<TOKEN end_char="5180" id="token-52-16" morph="none" pos="word" start_char="5179">is</TOKEN>
<TOKEN end_char="5186" id="token-52-17" morph="none" pos="word" start_char="5182">still</TOKEN>
<TOKEN end_char="5198" id="token-52-18" morph="none" pos="word" start_char="5188">problematic</TOKEN>
<TOKEN end_char="5199" id="token-52-19" morph="none" pos="punct" start_char="5199">.</TOKEN>
</SEG>
<SEG end_char="5308" id="segment-53" start_char="5201">
<ORIGINAL_TEXT>There are 100 ongoing studies and 33 studies reporting in a study registry as being completed or terminated.</ORIGINAL_TEXT>
<TOKEN end_char="5205" id="token-53-0" morph="none" pos="word" start_char="5201">There</TOKEN>
<TOKEN end_char="5209" id="token-53-1" morph="none" pos="word" start_char="5207">are</TOKEN>
<TOKEN end_char="5213" id="token-53-2" morph="none" pos="word" start_char="5211">100</TOKEN>
<TOKEN end_char="5221" id="token-53-3" morph="none" pos="word" start_char="5215">ongoing</TOKEN>
<TOKEN end_char="5229" id="token-53-4" morph="none" pos="word" start_char="5223">studies</TOKEN>
<TOKEN end_char="5233" id="token-53-5" morph="none" pos="word" start_char="5231">and</TOKEN>
<TOKEN end_char="5236" id="token-53-6" morph="none" pos="word" start_char="5235">33</TOKEN>
<TOKEN end_char="5244" id="token-53-7" morph="none" pos="word" start_char="5238">studies</TOKEN>
<TOKEN end_char="5254" id="token-53-8" morph="none" pos="word" start_char="5246">reporting</TOKEN>
<TOKEN end_char="5257" id="token-53-9" morph="none" pos="word" start_char="5256">in</TOKEN>
<TOKEN end_char="5259" id="token-53-10" morph="none" pos="word" start_char="5259">a</TOKEN>
<TOKEN end_char="5265" id="token-53-11" morph="none" pos="word" start_char="5261">study</TOKEN>
<TOKEN end_char="5274" id="token-53-12" morph="none" pos="word" start_char="5267">registry</TOKEN>
<TOKEN end_char="5277" id="token-53-13" morph="none" pos="word" start_char="5276">as</TOKEN>
<TOKEN end_char="5283" id="token-53-14" morph="none" pos="word" start_char="5279">being</TOKEN>
<TOKEN end_char="5293" id="token-53-15" morph="none" pos="word" start_char="5285">completed</TOKEN>
<TOKEN end_char="5296" id="token-53-16" morph="none" pos="word" start_char="5295">or</TOKEN>
<TOKEN end_char="5307" id="token-53-17" morph="none" pos="word" start_char="5298">terminated</TOKEN>
<TOKEN end_char="5308" id="token-53-18" morph="none" pos="punct" start_char="5308">.</TOKEN>
</SEG>
<SEG end_char="5537" id="segment-54" start_char="5310">
<ORIGINAL_TEXT>Publication of ongoing studies might resolve some of the uncertainties around hyperimmune immunoglobulin therapy for people with any disease severity, and convalescent plasma therapy for people with asymptomatic or mild disease.</ORIGINAL_TEXT>
<TOKEN end_char="5320" id="token-54-0" morph="none" pos="word" start_char="5310">Publication</TOKEN>
<TOKEN end_char="5323" id="token-54-1" morph="none" pos="word" start_char="5322">of</TOKEN>
<TOKEN end_char="5331" id="token-54-2" morph="none" pos="word" start_char="5325">ongoing</TOKEN>
<TOKEN end_char="5339" id="token-54-3" morph="none" pos="word" start_char="5333">studies</TOKEN>
<TOKEN end_char="5345" id="token-54-4" morph="none" pos="word" start_char="5341">might</TOKEN>
<TOKEN end_char="5353" id="token-54-5" morph="none" pos="word" start_char="5347">resolve</TOKEN>
<TOKEN end_char="5358" id="token-54-6" morph="none" pos="word" start_char="5355">some</TOKEN>
<TOKEN end_char="5361" id="token-54-7" morph="none" pos="word" start_char="5360">of</TOKEN>
<TOKEN end_char="5365" id="token-54-8" morph="none" pos="word" start_char="5363">the</TOKEN>
<TOKEN end_char="5379" id="token-54-9" morph="none" pos="word" start_char="5367">uncertainties</TOKEN>
<TOKEN end_char="5386" id="token-54-10" morph="none" pos="word" start_char="5381">around</TOKEN>
<TOKEN end_char="5398" id="token-54-11" morph="none" pos="word" start_char="5388">hyperimmune</TOKEN>
<TOKEN end_char="5413" id="token-54-12" morph="none" pos="word" start_char="5400">immunoglobulin</TOKEN>
<TOKEN end_char="5421" id="token-54-13" morph="none" pos="word" start_char="5415">therapy</TOKEN>
<TOKEN end_char="5425" id="token-54-14" morph="none" pos="word" start_char="5423">for</TOKEN>
<TOKEN end_char="5432" id="token-54-15" morph="none" pos="word" start_char="5427">people</TOKEN>
<TOKEN end_char="5437" id="token-54-16" morph="none" pos="word" start_char="5434">with</TOKEN>
<TOKEN end_char="5441" id="token-54-17" morph="none" pos="word" start_char="5439">any</TOKEN>
<TOKEN end_char="5449" id="token-54-18" morph="none" pos="word" start_char="5443">disease</TOKEN>
<TOKEN end_char="5458" id="token-54-19" morph="none" pos="word" start_char="5451">severity</TOKEN>
<TOKEN end_char="5459" id="token-54-20" morph="none" pos="punct" start_char="5459">,</TOKEN>
<TOKEN end_char="5463" id="token-54-21" morph="none" pos="word" start_char="5461">and</TOKEN>
<TOKEN end_char="5476" id="token-54-22" morph="none" pos="word" start_char="5465">convalescent</TOKEN>
<TOKEN end_char="5483" id="token-54-23" morph="none" pos="word" start_char="5478">plasma</TOKEN>
<TOKEN end_char="5491" id="token-54-24" morph="none" pos="word" start_char="5485">therapy</TOKEN>
<TOKEN end_char="5495" id="token-54-25" morph="none" pos="word" start_char="5493">for</TOKEN>
<TOKEN end_char="5502" id="token-54-26" morph="none" pos="word" start_char="5497">people</TOKEN>
<TOKEN end_char="5507" id="token-54-27" morph="none" pos="word" start_char="5504">with</TOKEN>
<TOKEN end_char="5520" id="token-54-28" morph="none" pos="word" start_char="5509">asymptomatic</TOKEN>
<TOKEN end_char="5523" id="token-54-29" morph="none" pos="word" start_char="5522">or</TOKEN>
<TOKEN end_char="5528" id="token-54-30" morph="none" pos="word" start_char="5525">mild</TOKEN>
<TOKEN end_char="5536" id="token-54-31" morph="none" pos="word" start_char="5530">disease</TOKEN>
<TOKEN end_char="5537" id="token-54-32" morph="none" pos="punct" start_char="5537">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
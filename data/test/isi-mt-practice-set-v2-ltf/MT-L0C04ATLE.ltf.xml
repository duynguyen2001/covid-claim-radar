<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATLE" lang="spa" raw_text_char_length="8255" raw_text_md5="778371d9f703828c5938f37df871a9b9" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="50" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Wash Your Hands—but Beware the Electric Hand Dryer</ORIGINAL_TEXT>
<TOKEN end_char="4" id="token-0-0" morph="none" pos="word" start_char="1">Wash</TOKEN>
<TOKEN end_char="9" id="token-0-1" morph="none" pos="word" start_char="6">Your</TOKEN>
<TOKEN end_char="19" id="token-0-2" morph="none" pos="unknown" start_char="11">Hands—but</TOKEN>
<TOKEN end_char="26" id="token-0-3" morph="none" pos="word" start_char="21">Beware</TOKEN>
<TOKEN end_char="30" id="token-0-4" morph="none" pos="word" start_char="28">the</TOKEN>
<TOKEN end_char="39" id="token-0-5" morph="none" pos="word" start_char="32">Electric</TOKEN>
<TOKEN end_char="44" id="token-0-6" morph="none" pos="word" start_char="41">Hand</TOKEN>
<TOKEN end_char="50" id="token-0-7" morph="none" pos="word" start_char="46">Dryer</TOKEN>
</SEG>
<SEG end_char="65" id="segment-1" start_char="54">
<ORIGINAL_TEXT>Tom Bartlett</ORIGINAL_TEXT>
<TOKEN end_char="56" id="token-1-0" morph="none" pos="word" start_char="54">Tom</TOKEN>
<TOKEN end_char="65" id="token-1-1" morph="none" pos="word" start_char="58">Bartlett</TOKEN>
<TRANSLATED_TEXT>Tom Bartlett.</TRANSLATED_TEXT><DETECTED_LANGUAGE>no</DETECTED_LANGUAGE></SEG>
<SEG end_char="72" id="segment-2" start_char="68">
<ORIGINAL_TEXT>Ideas</ORIGINAL_TEXT>
<TOKEN end_char="72" id="token-2-0" morph="none" pos="word" start_char="68">Ideas</TOKEN>
</SEG>
<SEG end_char="93" id="segment-3" start_char="75">
<ORIGINAL_TEXT>03.06.2020 01:29 PM</ORIGINAL_TEXT>
<TOKEN end_char="84" id="token-3-0" morph="none" pos="unknown" start_char="75">03.06.2020</TOKEN>
<TOKEN end_char="90" id="token-3-1" morph="none" pos="unknown" start_char="86">01:29</TOKEN>
<TOKEN end_char="93" id="token-3-2" morph="none" pos="word" start_char="92">PM</TOKEN>
<TRANSLATED_TEXT>03.06.2020 01: 29 PM</TRANSLATED_TEXT><DETECTED_LANGUAGE>tl</DETECTED_LANGUAGE></SEG>
<SEG end_char="145" id="segment-4" start_char="96">
<ORIGINAL_TEXT>Wash Your Hands—but Beware the Electric Hand Dryer</ORIGINAL_TEXT>
<TOKEN end_char="99" id="token-4-0" morph="none" pos="word" start_char="96">Wash</TOKEN>
<TOKEN end_char="104" id="token-4-1" morph="none" pos="word" start_char="101">Your</TOKEN>
<TOKEN end_char="114" id="token-4-2" morph="none" pos="unknown" start_char="106">Hands—but</TOKEN>
<TOKEN end_char="121" id="token-4-3" morph="none" pos="word" start_char="116">Beware</TOKEN>
<TOKEN end_char="125" id="token-4-4" morph="none" pos="word" start_char="123">the</TOKEN>
<TOKEN end_char="134" id="token-4-5" morph="none" pos="word" start_char="127">Electric</TOKEN>
<TOKEN end_char="139" id="token-4-6" morph="none" pos="word" start_char="136">Hand</TOKEN>
<TOKEN end_char="145" id="token-4-7" morph="none" pos="word" start_char="141">Dryer</TOKEN>
</SEG>
<SEG end_char="224" id="segment-5" start_char="149">
<ORIGINAL_TEXT>"Electric towels" were supposed to prevent the spread of contagious disease.</ORIGINAL_TEXT>
<TOKEN end_char="149" id="token-5-0" morph="none" pos="punct" start_char="149">"</TOKEN>
<TOKEN end_char="157" id="token-5-1" morph="none" pos="word" start_char="150">Electric</TOKEN>
<TOKEN end_char="164" id="token-5-2" morph="none" pos="word" start_char="159">towels</TOKEN>
<TOKEN end_char="165" id="token-5-3" morph="none" pos="punct" start_char="165">"</TOKEN>
<TOKEN end_char="170" id="token-5-4" morph="none" pos="word" start_char="167">were</TOKEN>
<TOKEN end_char="179" id="token-5-5" morph="none" pos="word" start_char="172">supposed</TOKEN>
<TOKEN end_char="182" id="token-5-6" morph="none" pos="word" start_char="181">to</TOKEN>
<TOKEN end_char="190" id="token-5-7" morph="none" pos="word" start_char="184">prevent</TOKEN>
<TOKEN end_char="194" id="token-5-8" morph="none" pos="word" start_char="192">the</TOKEN>
<TOKEN end_char="201" id="token-5-9" morph="none" pos="word" start_char="196">spread</TOKEN>
<TOKEN end_char="204" id="token-5-10" morph="none" pos="word" start_char="203">of</TOKEN>
<TOKEN end_char="215" id="token-5-11" morph="none" pos="word" start_char="206">contagious</TOKEN>
<TOKEN end_char="223" id="token-5-12" morph="none" pos="word" start_char="217">disease</TOKEN>
<TOKEN end_char="224" id="token-5-13" morph="none" pos="punct" start_char="224">.</TOKEN>
</SEG>
<SEG end_char="265" id="segment-6" start_char="226">
<ORIGINAL_TEXT>What if they've been doing the opposite?</ORIGINAL_TEXT>
<TOKEN end_char="229" id="token-6-0" morph="none" pos="word" start_char="226">What</TOKEN>
<TOKEN end_char="232" id="token-6-1" morph="none" pos="word" start_char="231">if</TOKEN>
<TOKEN end_char="240" id="token-6-2" morph="none" pos="word" start_char="234">they've</TOKEN>
<TOKEN end_char="245" id="token-6-3" morph="none" pos="word" start_char="242">been</TOKEN>
<TOKEN end_char="251" id="token-6-4" morph="none" pos="word" start_char="247">doing</TOKEN>
<TOKEN end_char="255" id="token-6-5" morph="none" pos="word" start_char="253">the</TOKEN>
<TOKEN end_char="264" id="token-6-6" morph="none" pos="word" start_char="257">opposite</TOKEN>
<TOKEN end_char="265" id="token-6-7" morph="none" pos="punct" start_char="265">?</TOKEN>
</SEG>
<SEG end_char="293" id="segment-7" start_char="268">
<ORIGINAL_TEXT>Save this story for later.</ORIGINAL_TEXT>
<TOKEN end_char="271" id="token-7-0" morph="none" pos="word" start_char="268">Save</TOKEN>
<TOKEN end_char="276" id="token-7-1" morph="none" pos="word" start_char="273">this</TOKEN>
<TOKEN end_char="282" id="token-7-2" morph="none" pos="word" start_char="278">story</TOKEN>
<TOKEN end_char="286" id="token-7-3" morph="none" pos="word" start_char="284">for</TOKEN>
<TOKEN end_char="292" id="token-7-4" morph="none" pos="word" start_char="288">later</TOKEN>
<TOKEN end_char="293" id="token-7-5" morph="none" pos="punct" start_char="293">.</TOKEN>
</SEG>
<SEG end_char="320" id="segment-8" start_char="297">
<ORIGINAL_TEXT>Photograph: Getty Images</ORIGINAL_TEXT>
<TOKEN end_char="306" id="token-8-0" morph="none" pos="word" start_char="297">Photograph</TOKEN>
<TOKEN end_char="307" id="token-8-1" morph="none" pos="punct" start_char="307">:</TOKEN>
<TOKEN end_char="313" id="token-8-2" morph="none" pos="word" start_char="309">Getty</TOKEN>
<TOKEN end_char="320" id="token-8-3" morph="none" pos="word" start_char="315">Images</TOKEN>
</SEG>
<SEG end_char="519" id="segment-9" start_char="324">
<ORIGINAL_TEXT>The spread of Covid-19 has turned us into a nation of hand-washing obsessives, citizens who vigorously interlace our fingers and circle-scrub our thumbs with an exacting, anxiety-fueled intensity.</ORIGINAL_TEXT>
<TOKEN end_char="326" id="token-9-0" morph="none" pos="word" start_char="324">The</TOKEN>
<TOKEN end_char="333" id="token-9-1" morph="none" pos="word" start_char="328">spread</TOKEN>
<TOKEN end_char="336" id="token-9-2" morph="none" pos="word" start_char="335">of</TOKEN>
<TOKEN end_char="345" id="token-9-3" morph="none" pos="unknown" start_char="338">Covid-19</TOKEN>
<TOKEN end_char="349" id="token-9-4" morph="none" pos="word" start_char="347">has</TOKEN>
<TOKEN end_char="356" id="token-9-5" morph="none" pos="word" start_char="351">turned</TOKEN>
<TOKEN end_char="359" id="token-9-6" morph="none" pos="word" start_char="358">us</TOKEN>
<TOKEN end_char="364" id="token-9-7" morph="none" pos="word" start_char="361">into</TOKEN>
<TOKEN end_char="366" id="token-9-8" morph="none" pos="word" start_char="366">a</TOKEN>
<TOKEN end_char="373" id="token-9-9" morph="none" pos="word" start_char="368">nation</TOKEN>
<TOKEN end_char="376" id="token-9-10" morph="none" pos="word" start_char="375">of</TOKEN>
<TOKEN end_char="389" id="token-9-11" morph="none" pos="unknown" start_char="378">hand-washing</TOKEN>
<TOKEN end_char="400" id="token-9-12" morph="none" pos="word" start_char="391">obsessives</TOKEN>
<TOKEN end_char="401" id="token-9-13" morph="none" pos="punct" start_char="401">,</TOKEN>
<TOKEN end_char="410" id="token-9-14" morph="none" pos="word" start_char="403">citizens</TOKEN>
<TOKEN end_char="414" id="token-9-15" morph="none" pos="word" start_char="412">who</TOKEN>
<TOKEN end_char="425" id="token-9-16" morph="none" pos="word" start_char="416">vigorously</TOKEN>
<TOKEN end_char="435" id="token-9-17" morph="none" pos="word" start_char="427">interlace</TOKEN>
<TOKEN end_char="439" id="token-9-18" morph="none" pos="word" start_char="437">our</TOKEN>
<TOKEN end_char="447" id="token-9-19" morph="none" pos="word" start_char="441">fingers</TOKEN>
<TOKEN end_char="451" id="token-9-20" morph="none" pos="word" start_char="449">and</TOKEN>
<TOKEN end_char="464" id="token-9-21" morph="none" pos="unknown" start_char="453">circle-scrub</TOKEN>
<TOKEN end_char="468" id="token-9-22" morph="none" pos="word" start_char="466">our</TOKEN>
<TOKEN end_char="475" id="token-9-23" morph="none" pos="word" start_char="470">thumbs</TOKEN>
<TOKEN end_char="480" id="token-9-24" morph="none" pos="word" start_char="477">with</TOKEN>
<TOKEN end_char="483" id="token-9-25" morph="none" pos="word" start_char="482">an</TOKEN>
<TOKEN end_char="492" id="token-9-26" morph="none" pos="word" start_char="485">exacting</TOKEN>
<TOKEN end_char="493" id="token-9-27" morph="none" pos="punct" start_char="493">,</TOKEN>
<TOKEN end_char="508" id="token-9-28" morph="none" pos="unknown" start_char="495">anxiety-fueled</TOKEN>
<TOKEN end_char="518" id="token-9-29" morph="none" pos="word" start_char="510">intensity</TOKEN>
<TOKEN end_char="519" id="token-9-30" morph="none" pos="punct" start_char="519">.</TOKEN>
</SEG>
<SEG end_char="748" id="segment-10" start_char="521">
<ORIGINAL_TEXT>But it’s not over when you flip off the faucet: Drying your hands matters too, because damp skin provides a hospitable environment for microorganisms and, as a result, might increase the likelihood that you’ll pass on pathogens.</ORIGINAL_TEXT>
<TOKEN end_char="523" id="token-10-0" morph="none" pos="word" start_char="521">But</TOKEN>
<TOKEN end_char="528" id="token-10-1" morph="none" pos="word" start_char="525">it’s</TOKEN>
<TOKEN end_char="532" id="token-10-2" morph="none" pos="word" start_char="530">not</TOKEN>
<TOKEN end_char="537" id="token-10-3" morph="none" pos="word" start_char="534">over</TOKEN>
<TOKEN end_char="542" id="token-10-4" morph="none" pos="word" start_char="539">when</TOKEN>
<TOKEN end_char="546" id="token-10-5" morph="none" pos="word" start_char="544">you</TOKEN>
<TOKEN end_char="551" id="token-10-6" morph="none" pos="word" start_char="548">flip</TOKEN>
<TOKEN end_char="555" id="token-10-7" morph="none" pos="word" start_char="553">off</TOKEN>
<TOKEN end_char="559" id="token-10-8" morph="none" pos="word" start_char="557">the</TOKEN>
<TOKEN end_char="566" id="token-10-9" morph="none" pos="word" start_char="561">faucet</TOKEN>
<TOKEN end_char="567" id="token-10-10" morph="none" pos="punct" start_char="567">:</TOKEN>
<TOKEN end_char="574" id="token-10-11" morph="none" pos="word" start_char="569">Drying</TOKEN>
<TOKEN end_char="579" id="token-10-12" morph="none" pos="word" start_char="576">your</TOKEN>
<TOKEN end_char="585" id="token-10-13" morph="none" pos="word" start_char="581">hands</TOKEN>
<TOKEN end_char="593" id="token-10-14" morph="none" pos="word" start_char="587">matters</TOKEN>
<TOKEN end_char="597" id="token-10-15" morph="none" pos="word" start_char="595">too</TOKEN>
<TOKEN end_char="598" id="token-10-16" morph="none" pos="punct" start_char="598">,</TOKEN>
<TOKEN end_char="606" id="token-10-17" morph="none" pos="word" start_char="600">because</TOKEN>
<TOKEN end_char="611" id="token-10-18" morph="none" pos="word" start_char="608">damp</TOKEN>
<TOKEN end_char="616" id="token-10-19" morph="none" pos="word" start_char="613">skin</TOKEN>
<TOKEN end_char="625" id="token-10-20" morph="none" pos="word" start_char="618">provides</TOKEN>
<TOKEN end_char="627" id="token-10-21" morph="none" pos="word" start_char="627">a</TOKEN>
<TOKEN end_char="638" id="token-10-22" morph="none" pos="word" start_char="629">hospitable</TOKEN>
<TOKEN end_char="650" id="token-10-23" morph="none" pos="word" start_char="640">environment</TOKEN>
<TOKEN end_char="654" id="token-10-24" morph="none" pos="word" start_char="652">for</TOKEN>
<TOKEN end_char="669" id="token-10-25" morph="none" pos="word" start_char="656">microorganisms</TOKEN>
<TOKEN end_char="673" id="token-10-26" morph="none" pos="word" start_char="671">and</TOKEN>
<TOKEN end_char="674" id="token-10-27" morph="none" pos="punct" start_char="674">,</TOKEN>
<TOKEN end_char="677" id="token-10-28" morph="none" pos="word" start_char="676">as</TOKEN>
<TOKEN end_char="679" id="token-10-29" morph="none" pos="word" start_char="679">a</TOKEN>
<TOKEN end_char="686" id="token-10-30" morph="none" pos="word" start_char="681">result</TOKEN>
<TOKEN end_char="687" id="token-10-31" morph="none" pos="punct" start_char="687">,</TOKEN>
<TOKEN end_char="693" id="token-10-32" morph="none" pos="word" start_char="689">might</TOKEN>
<TOKEN end_char="702" id="token-10-33" morph="none" pos="word" start_char="695">increase</TOKEN>
<TOKEN end_char="706" id="token-10-34" morph="none" pos="word" start_char="704">the</TOKEN>
<TOKEN end_char="717" id="token-10-35" morph="none" pos="word" start_char="708">likelihood</TOKEN>
<TOKEN end_char="722" id="token-10-36" morph="none" pos="word" start_char="719">that</TOKEN>
<TOKEN end_char="729" id="token-10-37" morph="none" pos="word" start_char="724">you’ll</TOKEN>
<TOKEN end_char="734" id="token-10-38" morph="none" pos="word" start_char="731">pass</TOKEN>
<TOKEN end_char="737" id="token-10-39" morph="none" pos="word" start_char="736">on</TOKEN>
<TOKEN end_char="747" id="token-10-40" morph="none" pos="word" start_char="739">pathogens</TOKEN>
<TOKEN end_char="748" id="token-10-41" morph="none" pos="punct" start_char="748">.</TOKEN>
</SEG>
<SEG end_char="925" id="segment-11" start_char="751">
<ORIGINAL_TEXT>So now, as we confront what could be a society-altering disease outbreak, it seems worth taking a hard look at the widely reviled yet seemingly ubiquitous electric hand dryer.</ORIGINAL_TEXT>
<TOKEN end_char="752" id="token-11-0" morph="none" pos="word" start_char="751">So</TOKEN>
<TOKEN end_char="756" id="token-11-1" morph="none" pos="word" start_char="754">now</TOKEN>
<TOKEN end_char="757" id="token-11-2" morph="none" pos="punct" start_char="757">,</TOKEN>
<TOKEN end_char="760" id="token-11-3" morph="none" pos="word" start_char="759">as</TOKEN>
<TOKEN end_char="763" id="token-11-4" morph="none" pos="word" start_char="762">we</TOKEN>
<TOKEN end_char="772" id="token-11-5" morph="none" pos="word" start_char="765">confront</TOKEN>
<TOKEN end_char="777" id="token-11-6" morph="none" pos="word" start_char="774">what</TOKEN>
<TOKEN end_char="783" id="token-11-7" morph="none" pos="word" start_char="779">could</TOKEN>
<TOKEN end_char="786" id="token-11-8" morph="none" pos="word" start_char="785">be</TOKEN>
<TOKEN end_char="788" id="token-11-9" morph="none" pos="word" start_char="788">a</TOKEN>
<TOKEN end_char="805" id="token-11-10" morph="none" pos="unknown" start_char="790">society-altering</TOKEN>
<TOKEN end_char="813" id="token-11-11" morph="none" pos="word" start_char="807">disease</TOKEN>
<TOKEN end_char="822" id="token-11-12" morph="none" pos="word" start_char="815">outbreak</TOKEN>
<TOKEN end_char="823" id="token-11-13" morph="none" pos="punct" start_char="823">,</TOKEN>
<TOKEN end_char="826" id="token-11-14" morph="none" pos="word" start_char="825">it</TOKEN>
<TOKEN end_char="832" id="token-11-15" morph="none" pos="word" start_char="828">seems</TOKEN>
<TOKEN end_char="838" id="token-11-16" morph="none" pos="word" start_char="834">worth</TOKEN>
<TOKEN end_char="845" id="token-11-17" morph="none" pos="word" start_char="840">taking</TOKEN>
<TOKEN end_char="847" id="token-11-18" morph="none" pos="word" start_char="847">a</TOKEN>
<TOKEN end_char="852" id="token-11-19" morph="none" pos="word" start_char="849">hard</TOKEN>
<TOKEN end_char="857" id="token-11-20" morph="none" pos="word" start_char="854">look</TOKEN>
<TOKEN end_char="860" id="token-11-21" morph="none" pos="word" start_char="859">at</TOKEN>
<TOKEN end_char="864" id="token-11-22" morph="none" pos="word" start_char="862">the</TOKEN>
<TOKEN end_char="871" id="token-11-23" morph="none" pos="word" start_char="866">widely</TOKEN>
<TOKEN end_char="879" id="token-11-24" morph="none" pos="word" start_char="873">reviled</TOKEN>
<TOKEN end_char="883" id="token-11-25" morph="none" pos="word" start_char="881">yet</TOKEN>
<TOKEN end_char="893" id="token-11-26" morph="none" pos="word" start_char="885">seemingly</TOKEN>
<TOKEN end_char="904" id="token-11-27" morph="none" pos="word" start_char="895">ubiquitous</TOKEN>
<TOKEN end_char="913" id="token-11-28" morph="none" pos="word" start_char="906">electric</TOKEN>
<TOKEN end_char="918" id="token-11-29" morph="none" pos="word" start_char="915">hand</TOKEN>
<TOKEN end_char="924" id="token-11-30" morph="none" pos="word" start_char="920">dryer</TOKEN>
<TOKEN end_char="925" id="token-11-31" morph="none" pos="punct" start_char="925">.</TOKEN>
</SEG>
<SEG end_char="993" id="segment-12" start_char="927">
<ORIGINAL_TEXT>Are they as hygienic as paper towels, as their manufacturers claim?</ORIGINAL_TEXT>
<TOKEN end_char="929" id="token-12-0" morph="none" pos="word" start_char="927">Are</TOKEN>
<TOKEN end_char="934" id="token-12-1" morph="none" pos="word" start_char="931">they</TOKEN>
<TOKEN end_char="937" id="token-12-2" morph="none" pos="word" start_char="936">as</TOKEN>
<TOKEN end_char="946" id="token-12-3" morph="none" pos="word" start_char="939">hygienic</TOKEN>
<TOKEN end_char="949" id="token-12-4" morph="none" pos="word" start_char="948">as</TOKEN>
<TOKEN end_char="955" id="token-12-5" morph="none" pos="word" start_char="951">paper</TOKEN>
<TOKEN end_char="962" id="token-12-6" morph="none" pos="word" start_char="957">towels</TOKEN>
<TOKEN end_char="963" id="token-12-7" morph="none" pos="punct" start_char="963">,</TOKEN>
<TOKEN end_char="966" id="token-12-8" morph="none" pos="word" start_char="965">as</TOKEN>
<TOKEN end_char="972" id="token-12-9" morph="none" pos="word" start_char="968">their</TOKEN>
<TOKEN end_char="986" id="token-12-10" morph="none" pos="word" start_char="974">manufacturers</TOKEN>
<TOKEN end_char="992" id="token-12-11" morph="none" pos="word" start_char="988">claim</TOKEN>
<TOKEN end_char="993" id="token-12-12" morph="none" pos="punct" start_char="993">?</TOKEN>
</SEG>
<SEG end_char="1189" id="segment-13" start_char="996">
<ORIGINAL_TEXT>The earliest pitches for hand dryers played up their supposed ability when it comes to "preventing the spread of contagious disease," as a 1924 newspaper ad for the Airdry Electric Towel put it.</ORIGINAL_TEXT>
<TOKEN end_char="998" id="token-13-0" morph="none" pos="word" start_char="996">The</TOKEN>
<TOKEN end_char="1007" id="token-13-1" morph="none" pos="word" start_char="1000">earliest</TOKEN>
<TOKEN end_char="1015" id="token-13-2" morph="none" pos="word" start_char="1009">pitches</TOKEN>
<TOKEN end_char="1019" id="token-13-3" morph="none" pos="word" start_char="1017">for</TOKEN>
<TOKEN end_char="1024" id="token-13-4" morph="none" pos="word" start_char="1021">hand</TOKEN>
<TOKEN end_char="1031" id="token-13-5" morph="none" pos="word" start_char="1026">dryers</TOKEN>
<TOKEN end_char="1038" id="token-13-6" morph="none" pos="word" start_char="1033">played</TOKEN>
<TOKEN end_char="1041" id="token-13-7" morph="none" pos="word" start_char="1040">up</TOKEN>
<TOKEN end_char="1047" id="token-13-8" morph="none" pos="word" start_char="1043">their</TOKEN>
<TOKEN end_char="1056" id="token-13-9" morph="none" pos="word" start_char="1049">supposed</TOKEN>
<TOKEN end_char="1064" id="token-13-10" morph="none" pos="word" start_char="1058">ability</TOKEN>
<TOKEN end_char="1069" id="token-13-11" morph="none" pos="word" start_char="1066">when</TOKEN>
<TOKEN end_char="1072" id="token-13-12" morph="none" pos="word" start_char="1071">it</TOKEN>
<TOKEN end_char="1078" id="token-13-13" morph="none" pos="word" start_char="1074">comes</TOKEN>
<TOKEN end_char="1081" id="token-13-14" morph="none" pos="word" start_char="1080">to</TOKEN>
<TOKEN end_char="1083" id="token-13-15" morph="none" pos="punct" start_char="1083">"</TOKEN>
<TOKEN end_char="1093" id="token-13-16" morph="none" pos="word" start_char="1084">preventing</TOKEN>
<TOKEN end_char="1097" id="token-13-17" morph="none" pos="word" start_char="1095">the</TOKEN>
<TOKEN end_char="1104" id="token-13-18" morph="none" pos="word" start_char="1099">spread</TOKEN>
<TOKEN end_char="1107" id="token-13-19" morph="none" pos="word" start_char="1106">of</TOKEN>
<TOKEN end_char="1118" id="token-13-20" morph="none" pos="word" start_char="1109">contagious</TOKEN>
<TOKEN end_char="1126" id="token-13-21" morph="none" pos="word" start_char="1120">disease</TOKEN>
<TOKEN end_char="1128" id="token-13-22" morph="none" pos="punct" start_char="1127">,"</TOKEN>
<TOKEN end_char="1131" id="token-13-23" morph="none" pos="word" start_char="1130">as</TOKEN>
<TOKEN end_char="1133" id="token-13-24" morph="none" pos="word" start_char="1133">a</TOKEN>
<TOKEN end_char="1138" id="token-13-25" morph="none" pos="word" start_char="1135">1924</TOKEN>
<TOKEN end_char="1148" id="token-13-26" morph="none" pos="word" start_char="1140">newspaper</TOKEN>
<TOKEN end_char="1151" id="token-13-27" morph="none" pos="word" start_char="1150">ad</TOKEN>
<TOKEN end_char="1155" id="token-13-28" morph="none" pos="word" start_char="1153">for</TOKEN>
<TOKEN end_char="1159" id="token-13-29" morph="none" pos="word" start_char="1157">the</TOKEN>
<TOKEN end_char="1166" id="token-13-30" morph="none" pos="word" start_char="1161">Airdry</TOKEN>
<TOKEN end_char="1175" id="token-13-31" morph="none" pos="word" start_char="1168">Electric</TOKEN>
<TOKEN end_char="1181" id="token-13-32" morph="none" pos="word" start_char="1177">Towel</TOKEN>
<TOKEN end_char="1185" id="token-13-33" morph="none" pos="word" start_char="1183">put</TOKEN>
<TOKEN end_char="1188" id="token-13-34" morph="none" pos="word" start_char="1187">it</TOKEN>
<TOKEN end_char="1189" id="token-13-35" morph="none" pos="punct" start_char="1189">.</TOKEN>
</SEG>
<SEG end_char="1485" id="segment-14" start_char="1191">
<ORIGINAL_TEXT>More recently, Dyson, whose Airblade hand dryer promises to "scrape water from hands like a windshield wiper," has bragged that its HEPA air filter captures particles as tiny as .3 microns in diameter, much like the N95 face masks that are now selling for AirPod Pro–equivalent prices on Amazon.</ORIGINAL_TEXT>
<TOKEN end_char="1194" id="token-14-0" morph="none" pos="word" start_char="1191">More</TOKEN>
<TOKEN end_char="1203" id="token-14-1" morph="none" pos="word" start_char="1196">recently</TOKEN>
<TOKEN end_char="1204" id="token-14-2" morph="none" pos="punct" start_char="1204">,</TOKEN>
<TOKEN end_char="1210" id="token-14-3" morph="none" pos="word" start_char="1206">Dyson</TOKEN>
<TOKEN end_char="1211" id="token-14-4" morph="none" pos="punct" start_char="1211">,</TOKEN>
<TOKEN end_char="1217" id="token-14-5" morph="none" pos="word" start_char="1213">whose</TOKEN>
<TOKEN end_char="1226" id="token-14-6" morph="none" pos="word" start_char="1219">Airblade</TOKEN>
<TOKEN end_char="1231" id="token-14-7" morph="none" pos="word" start_char="1228">hand</TOKEN>
<TOKEN end_char="1237" id="token-14-8" morph="none" pos="word" start_char="1233">dryer</TOKEN>
<TOKEN end_char="1246" id="token-14-9" morph="none" pos="word" start_char="1239">promises</TOKEN>
<TOKEN end_char="1249" id="token-14-10" morph="none" pos="word" start_char="1248">to</TOKEN>
<TOKEN end_char="1251" id="token-14-11" morph="none" pos="punct" start_char="1251">"</TOKEN>
<TOKEN end_char="1257" id="token-14-12" morph="none" pos="word" start_char="1252">scrape</TOKEN>
<TOKEN end_char="1263" id="token-14-13" morph="none" pos="word" start_char="1259">water</TOKEN>
<TOKEN end_char="1268" id="token-14-14" morph="none" pos="word" start_char="1265">from</TOKEN>
<TOKEN end_char="1274" id="token-14-15" morph="none" pos="word" start_char="1270">hands</TOKEN>
<TOKEN end_char="1279" id="token-14-16" morph="none" pos="word" start_char="1276">like</TOKEN>
<TOKEN end_char="1281" id="token-14-17" morph="none" pos="word" start_char="1281">a</TOKEN>
<TOKEN end_char="1292" id="token-14-18" morph="none" pos="word" start_char="1283">windshield</TOKEN>
<TOKEN end_char="1298" id="token-14-19" morph="none" pos="word" start_char="1294">wiper</TOKEN>
<TOKEN end_char="1300" id="token-14-20" morph="none" pos="punct" start_char="1299">,"</TOKEN>
<TOKEN end_char="1304" id="token-14-21" morph="none" pos="word" start_char="1302">has</TOKEN>
<TOKEN end_char="1312" id="token-14-22" morph="none" pos="word" start_char="1306">bragged</TOKEN>
<TOKEN end_char="1317" id="token-14-23" morph="none" pos="word" start_char="1314">that</TOKEN>
<TOKEN end_char="1321" id="token-14-24" morph="none" pos="word" start_char="1319">its</TOKEN>
<TOKEN end_char="1326" id="token-14-25" morph="none" pos="word" start_char="1323">HEPA</TOKEN>
<TOKEN end_char="1330" id="token-14-26" morph="none" pos="word" start_char="1328">air</TOKEN>
<TOKEN end_char="1337" id="token-14-27" morph="none" pos="word" start_char="1332">filter</TOKEN>
<TOKEN end_char="1346" id="token-14-28" morph="none" pos="word" start_char="1339">captures</TOKEN>
<TOKEN end_char="1356" id="token-14-29" morph="none" pos="word" start_char="1348">particles</TOKEN>
<TOKEN end_char="1359" id="token-14-30" morph="none" pos="word" start_char="1358">as</TOKEN>
<TOKEN end_char="1364" id="token-14-31" morph="none" pos="word" start_char="1361">tiny</TOKEN>
<TOKEN end_char="1367" id="token-14-32" morph="none" pos="word" start_char="1366">as</TOKEN>
<TOKEN end_char="1370" id="token-14-33" morph="none" pos="word" start_char="1369">.3</TOKEN>
<TOKEN end_char="1378" id="token-14-34" morph="none" pos="word" start_char="1372">microns</TOKEN>
<TOKEN end_char="1381" id="token-14-35" morph="none" pos="word" start_char="1380">in</TOKEN>
<TOKEN end_char="1390" id="token-14-36" morph="none" pos="word" start_char="1383">diameter</TOKEN>
<TOKEN end_char="1391" id="token-14-37" morph="none" pos="punct" start_char="1391">,</TOKEN>
<TOKEN end_char="1396" id="token-14-38" morph="none" pos="word" start_char="1393">much</TOKEN>
<TOKEN end_char="1401" id="token-14-39" morph="none" pos="word" start_char="1398">like</TOKEN>
<TOKEN end_char="1405" id="token-14-40" morph="none" pos="word" start_char="1403">the</TOKEN>
<TOKEN end_char="1409" id="token-14-41" morph="none" pos="word" start_char="1407">N95</TOKEN>
<TOKEN end_char="1414" id="token-14-42" morph="none" pos="word" start_char="1411">face</TOKEN>
<TOKEN end_char="1420" id="token-14-43" morph="none" pos="word" start_char="1416">masks</TOKEN>
<TOKEN end_char="1425" id="token-14-44" morph="none" pos="word" start_char="1422">that</TOKEN>
<TOKEN end_char="1429" id="token-14-45" morph="none" pos="word" start_char="1427">are</TOKEN>
<TOKEN end_char="1433" id="token-14-46" morph="none" pos="word" start_char="1431">now</TOKEN>
<TOKEN end_char="1441" id="token-14-47" morph="none" pos="word" start_char="1435">selling</TOKEN>
<TOKEN end_char="1445" id="token-14-48" morph="none" pos="word" start_char="1443">for</TOKEN>
<TOKEN end_char="1452" id="token-14-49" morph="none" pos="word" start_char="1447">AirPod</TOKEN>
<TOKEN end_char="1467" id="token-14-50" morph="none" pos="unknown" start_char="1454">Pro–equivalent</TOKEN>
<TOKEN end_char="1474" id="token-14-51" morph="none" pos="word" start_char="1469">prices</TOKEN>
<TOKEN end_char="1477" id="token-14-52" morph="none" pos="word" start_char="1476">on</TOKEN>
<TOKEN end_char="1484" id="token-14-53" morph="none" pos="word" start_char="1479">Amazon</TOKEN>
<TOKEN end_char="1485" id="token-14-54" morph="none" pos="punct" start_char="1485">.</TOKEN>
</SEG>
<SEG end_char="1702" id="segment-15" start_char="1488">
<ORIGINAL_TEXT>But the quality of the intake filter doesn’t address whether blowing air at high speeds is a smart idea given that it may be sending droplets and particles from your just-washed hands flying rapidly every which way.</ORIGINAL_TEXT>
<TOKEN end_char="1490" id="token-15-0" morph="none" pos="word" start_char="1488">But</TOKEN>
<TOKEN end_char="1494" id="token-15-1" morph="none" pos="word" start_char="1492">the</TOKEN>
<TOKEN end_char="1502" id="token-15-2" morph="none" pos="word" start_char="1496">quality</TOKEN>
<TOKEN end_char="1505" id="token-15-3" morph="none" pos="word" start_char="1504">of</TOKEN>
<TOKEN end_char="1509" id="token-15-4" morph="none" pos="word" start_char="1507">the</TOKEN>
<TOKEN end_char="1516" id="token-15-5" morph="none" pos="word" start_char="1511">intake</TOKEN>
<TOKEN end_char="1523" id="token-15-6" morph="none" pos="word" start_char="1518">filter</TOKEN>
<TOKEN end_char="1531" id="token-15-7" morph="none" pos="word" start_char="1525">doesn’t</TOKEN>
<TOKEN end_char="1539" id="token-15-8" morph="none" pos="word" start_char="1533">address</TOKEN>
<TOKEN end_char="1547" id="token-15-9" morph="none" pos="word" start_char="1541">whether</TOKEN>
<TOKEN end_char="1555" id="token-15-10" morph="none" pos="word" start_char="1549">blowing</TOKEN>
<TOKEN end_char="1559" id="token-15-11" morph="none" pos="word" start_char="1557">air</TOKEN>
<TOKEN end_char="1562" id="token-15-12" morph="none" pos="word" start_char="1561">at</TOKEN>
<TOKEN end_char="1567" id="token-15-13" morph="none" pos="word" start_char="1564">high</TOKEN>
<TOKEN end_char="1574" id="token-15-14" morph="none" pos="word" start_char="1569">speeds</TOKEN>
<TOKEN end_char="1577" id="token-15-15" morph="none" pos="word" start_char="1576">is</TOKEN>
<TOKEN end_char="1579" id="token-15-16" morph="none" pos="word" start_char="1579">a</TOKEN>
<TOKEN end_char="1585" id="token-15-17" morph="none" pos="word" start_char="1581">smart</TOKEN>
<TOKEN end_char="1590" id="token-15-18" morph="none" pos="word" start_char="1587">idea</TOKEN>
<TOKEN end_char="1596" id="token-15-19" morph="none" pos="word" start_char="1592">given</TOKEN>
<TOKEN end_char="1601" id="token-15-20" morph="none" pos="word" start_char="1598">that</TOKEN>
<TOKEN end_char="1604" id="token-15-21" morph="none" pos="word" start_char="1603">it</TOKEN>
<TOKEN end_char="1608" id="token-15-22" morph="none" pos="word" start_char="1606">may</TOKEN>
<TOKEN end_char="1611" id="token-15-23" morph="none" pos="word" start_char="1610">be</TOKEN>
<TOKEN end_char="1619" id="token-15-24" morph="none" pos="word" start_char="1613">sending</TOKEN>
<TOKEN end_char="1628" id="token-15-25" morph="none" pos="word" start_char="1621">droplets</TOKEN>
<TOKEN end_char="1632" id="token-15-26" morph="none" pos="word" start_char="1630">and</TOKEN>
<TOKEN end_char="1642" id="token-15-27" morph="none" pos="word" start_char="1634">particles</TOKEN>
<TOKEN end_char="1647" id="token-15-28" morph="none" pos="word" start_char="1644">from</TOKEN>
<TOKEN end_char="1652" id="token-15-29" morph="none" pos="word" start_char="1649">your</TOKEN>
<TOKEN end_char="1664" id="token-15-30" morph="none" pos="unknown" start_char="1654">just-washed</TOKEN>
<TOKEN end_char="1670" id="token-15-31" morph="none" pos="word" start_char="1666">hands</TOKEN>
<TOKEN end_char="1677" id="token-15-32" morph="none" pos="word" start_char="1672">flying</TOKEN>
<TOKEN end_char="1685" id="token-15-33" morph="none" pos="word" start_char="1679">rapidly</TOKEN>
<TOKEN end_char="1691" id="token-15-34" morph="none" pos="word" start_char="1687">every</TOKEN>
<TOKEN end_char="1697" id="token-15-35" morph="none" pos="word" start_char="1693">which</TOKEN>
<TOKEN end_char="1701" id="token-15-36" morph="none" pos="word" start_char="1699">way</TOKEN>
<TOKEN end_char="1702" id="token-15-37" morph="none" pos="punct" start_char="1702">.</TOKEN>
</SEG>
<SEG end_char="1791" id="segment-16" start_char="1704">
<ORIGINAL_TEXT>When you dig into the science on hand dryers, you’ll come across reason to be concerned.</ORIGINAL_TEXT>
<TOKEN end_char="1707" id="token-16-0" morph="none" pos="word" start_char="1704">When</TOKEN>
<TOKEN end_char="1711" id="token-16-1" morph="none" pos="word" start_char="1709">you</TOKEN>
<TOKEN end_char="1715" id="token-16-2" morph="none" pos="word" start_char="1713">dig</TOKEN>
<TOKEN end_char="1720" id="token-16-3" morph="none" pos="word" start_char="1717">into</TOKEN>
<TOKEN end_char="1724" id="token-16-4" morph="none" pos="word" start_char="1722">the</TOKEN>
<TOKEN end_char="1732" id="token-16-5" morph="none" pos="word" start_char="1726">science</TOKEN>
<TOKEN end_char="1735" id="token-16-6" morph="none" pos="word" start_char="1734">on</TOKEN>
<TOKEN end_char="1740" id="token-16-7" morph="none" pos="word" start_char="1737">hand</TOKEN>
<TOKEN end_char="1747" id="token-16-8" morph="none" pos="word" start_char="1742">dryers</TOKEN>
<TOKEN end_char="1748" id="token-16-9" morph="none" pos="punct" start_char="1748">,</TOKEN>
<TOKEN end_char="1755" id="token-16-10" morph="none" pos="word" start_char="1750">you’ll</TOKEN>
<TOKEN end_char="1760" id="token-16-11" morph="none" pos="word" start_char="1757">come</TOKEN>
<TOKEN end_char="1767" id="token-16-12" morph="none" pos="word" start_char="1762">across</TOKEN>
<TOKEN end_char="1774" id="token-16-13" morph="none" pos="word" start_char="1769">reason</TOKEN>
<TOKEN end_char="1777" id="token-16-14" morph="none" pos="word" start_char="1776">to</TOKEN>
<TOKEN end_char="1780" id="token-16-15" morph="none" pos="word" start_char="1779">be</TOKEN>
<TOKEN end_char="1790" id="token-16-16" morph="none" pos="word" start_char="1782">concerned</TOKEN>
<TOKEN end_char="1791" id="token-16-17" morph="none" pos="punct" start_char="1791">.</TOKEN>
</SEG>
<SEG end_char="1994" id="segment-17" start_char="1793">
<ORIGINAL_TEXT>A study published in 1989 found that gentler, old-style hand dryers blew bacteria over a three-foot radius and onto the user’s clothes, which considering the era was probably an acid-washed jean jacket.</ORIGINAL_TEXT>
<TOKEN end_char="1793" id="token-17-0" morph="none" pos="word" start_char="1793">A</TOKEN>
<TOKEN end_char="1799" id="token-17-1" morph="none" pos="word" start_char="1795">study</TOKEN>
<TOKEN end_char="1809" id="token-17-2" morph="none" pos="word" start_char="1801">published</TOKEN>
<TOKEN end_char="1812" id="token-17-3" morph="none" pos="word" start_char="1811">in</TOKEN>
<TOKEN end_char="1817" id="token-17-4" morph="none" pos="word" start_char="1814">1989</TOKEN>
<TOKEN end_char="1823" id="token-17-5" morph="none" pos="word" start_char="1819">found</TOKEN>
<TOKEN end_char="1828" id="token-17-6" morph="none" pos="word" start_char="1825">that</TOKEN>
<TOKEN end_char="1836" id="token-17-7" morph="none" pos="word" start_char="1830">gentler</TOKEN>
<TOKEN end_char="1837" id="token-17-8" morph="none" pos="punct" start_char="1837">,</TOKEN>
<TOKEN end_char="1847" id="token-17-9" morph="none" pos="unknown" start_char="1839">old-style</TOKEN>
<TOKEN end_char="1852" id="token-17-10" morph="none" pos="word" start_char="1849">hand</TOKEN>
<TOKEN end_char="1859" id="token-17-11" morph="none" pos="word" start_char="1854">dryers</TOKEN>
<TOKEN end_char="1864" id="token-17-12" morph="none" pos="word" start_char="1861">blew</TOKEN>
<TOKEN end_char="1873" id="token-17-13" morph="none" pos="word" start_char="1866">bacteria</TOKEN>
<TOKEN end_char="1878" id="token-17-14" morph="none" pos="word" start_char="1875">over</TOKEN>
<TOKEN end_char="1880" id="token-17-15" morph="none" pos="word" start_char="1880">a</TOKEN>
<TOKEN end_char="1891" id="token-17-16" morph="none" pos="unknown" start_char="1882">three-foot</TOKEN>
<TOKEN end_char="1898" id="token-17-17" morph="none" pos="word" start_char="1893">radius</TOKEN>
<TOKEN end_char="1902" id="token-17-18" morph="none" pos="word" start_char="1900">and</TOKEN>
<TOKEN end_char="1907" id="token-17-19" morph="none" pos="word" start_char="1904">onto</TOKEN>
<TOKEN end_char="1911" id="token-17-20" morph="none" pos="word" start_char="1909">the</TOKEN>
<TOKEN end_char="1918" id="token-17-21" morph="none" pos="word" start_char="1913">user’s</TOKEN>
<TOKEN end_char="1926" id="token-17-22" morph="none" pos="word" start_char="1920">clothes</TOKEN>
<TOKEN end_char="1927" id="token-17-23" morph="none" pos="punct" start_char="1927">,</TOKEN>
<TOKEN end_char="1933" id="token-17-24" morph="none" pos="word" start_char="1929">which</TOKEN>
<TOKEN end_char="1945" id="token-17-25" morph="none" pos="word" start_char="1935">considering</TOKEN>
<TOKEN end_char="1949" id="token-17-26" morph="none" pos="word" start_char="1947">the</TOKEN>
<TOKEN end_char="1953" id="token-17-27" morph="none" pos="word" start_char="1951">era</TOKEN>
<TOKEN end_char="1957" id="token-17-28" morph="none" pos="word" start_char="1955">was</TOKEN>
<TOKEN end_char="1966" id="token-17-29" morph="none" pos="word" start_char="1959">probably</TOKEN>
<TOKEN end_char="1969" id="token-17-30" morph="none" pos="word" start_char="1968">an</TOKEN>
<TOKEN end_char="1981" id="token-17-31" morph="none" pos="unknown" start_char="1971">acid-washed</TOKEN>
<TOKEN end_char="1986" id="token-17-32" morph="none" pos="word" start_char="1983">jean</TOKEN>
<TOKEN end_char="1993" id="token-17-33" morph="none" pos="word" start_char="1988">jacket</TOKEN>
<TOKEN end_char="1994" id="token-17-34" morph="none" pos="punct" start_char="1994">.</TOKEN>
</SEG>
<SEG end_char="2173" id="segment-18" start_char="1997">
<ORIGINAL_TEXT>A 2018 study produced even more troubling results, finding that "potential pathogens and spores" could be "dispersed throughout buildings and deposited on hands by hand dryers."</ORIGINAL_TEXT>
<TOKEN end_char="1997" id="token-18-0" morph="none" pos="word" start_char="1997">A</TOKEN>
<TOKEN end_char="2002" id="token-18-1" morph="none" pos="word" start_char="1999">2018</TOKEN>
<TOKEN end_char="2008" id="token-18-2" morph="none" pos="word" start_char="2004">study</TOKEN>
<TOKEN end_char="2017" id="token-18-3" morph="none" pos="word" start_char="2010">produced</TOKEN>
<TOKEN end_char="2022" id="token-18-4" morph="none" pos="word" start_char="2019">even</TOKEN>
<TOKEN end_char="2027" id="token-18-5" morph="none" pos="word" start_char="2024">more</TOKEN>
<TOKEN end_char="2037" id="token-18-6" morph="none" pos="word" start_char="2029">troubling</TOKEN>
<TOKEN end_char="2045" id="token-18-7" morph="none" pos="word" start_char="2039">results</TOKEN>
<TOKEN end_char="2046" id="token-18-8" morph="none" pos="punct" start_char="2046">,</TOKEN>
<TOKEN end_char="2054" id="token-18-9" morph="none" pos="word" start_char="2048">finding</TOKEN>
<TOKEN end_char="2059" id="token-18-10" morph="none" pos="word" start_char="2056">that</TOKEN>
<TOKEN end_char="2061" id="token-18-11" morph="none" pos="punct" start_char="2061">"</TOKEN>
<TOKEN end_char="2070" id="token-18-12" morph="none" pos="word" start_char="2062">potential</TOKEN>
<TOKEN end_char="2080" id="token-18-13" morph="none" pos="word" start_char="2072">pathogens</TOKEN>
<TOKEN end_char="2084" id="token-18-14" morph="none" pos="word" start_char="2082">and</TOKEN>
<TOKEN end_char="2091" id="token-18-15" morph="none" pos="word" start_char="2086">spores</TOKEN>
<TOKEN end_char="2092" id="token-18-16" morph="none" pos="punct" start_char="2092">"</TOKEN>
<TOKEN end_char="2098" id="token-18-17" morph="none" pos="word" start_char="2094">could</TOKEN>
<TOKEN end_char="2101" id="token-18-18" morph="none" pos="word" start_char="2100">be</TOKEN>
<TOKEN end_char="2103" id="token-18-19" morph="none" pos="punct" start_char="2103">"</TOKEN>
<TOKEN end_char="2112" id="token-18-20" morph="none" pos="word" start_char="2104">dispersed</TOKEN>
<TOKEN end_char="2123" id="token-18-21" morph="none" pos="word" start_char="2114">throughout</TOKEN>
<TOKEN end_char="2133" id="token-18-22" morph="none" pos="word" start_char="2125">buildings</TOKEN>
<TOKEN end_char="2137" id="token-18-23" morph="none" pos="word" start_char="2135">and</TOKEN>
<TOKEN end_char="2147" id="token-18-24" morph="none" pos="word" start_char="2139">deposited</TOKEN>
<TOKEN end_char="2150" id="token-18-25" morph="none" pos="word" start_char="2149">on</TOKEN>
<TOKEN end_char="2156" id="token-18-26" morph="none" pos="word" start_char="2152">hands</TOKEN>
<TOKEN end_char="2159" id="token-18-27" morph="none" pos="word" start_char="2158">by</TOKEN>
<TOKEN end_char="2164" id="token-18-28" morph="none" pos="word" start_char="2161">hand</TOKEN>
<TOKEN end_char="2171" id="token-18-29" morph="none" pos="word" start_char="2166">dryers</TOKEN>
<TOKEN end_char="2173" id="token-18-30" morph="none" pos="punct" start_char="2172">."</TOKEN>
</SEG>
<SEG end_char="2412" id="segment-19" start_char="2175">
<ORIGINAL_TEXT>It tested conventional hot-air models with and without filters and determined that the filters "most likely reduce the number of potentially pathogenic bacteria with the potential to colonize hands but do not eliminate the risk entirely."</ORIGINAL_TEXT>
<TOKEN end_char="2176" id="token-19-0" morph="none" pos="word" start_char="2175">It</TOKEN>
<TOKEN end_char="2183" id="token-19-1" morph="none" pos="word" start_char="2178">tested</TOKEN>
<TOKEN end_char="2196" id="token-19-2" morph="none" pos="word" start_char="2185">conventional</TOKEN>
<TOKEN end_char="2204" id="token-19-3" morph="none" pos="unknown" start_char="2198">hot-air</TOKEN>
<TOKEN end_char="2211" id="token-19-4" morph="none" pos="word" start_char="2206">models</TOKEN>
<TOKEN end_char="2216" id="token-19-5" morph="none" pos="word" start_char="2213">with</TOKEN>
<TOKEN end_char="2220" id="token-19-6" morph="none" pos="word" start_char="2218">and</TOKEN>
<TOKEN end_char="2228" id="token-19-7" morph="none" pos="word" start_char="2222">without</TOKEN>
<TOKEN end_char="2236" id="token-19-8" morph="none" pos="word" start_char="2230">filters</TOKEN>
<TOKEN end_char="2240" id="token-19-9" morph="none" pos="word" start_char="2238">and</TOKEN>
<TOKEN end_char="2251" id="token-19-10" morph="none" pos="word" start_char="2242">determined</TOKEN>
<TOKEN end_char="2256" id="token-19-11" morph="none" pos="word" start_char="2253">that</TOKEN>
<TOKEN end_char="2260" id="token-19-12" morph="none" pos="word" start_char="2258">the</TOKEN>
<TOKEN end_char="2268" id="token-19-13" morph="none" pos="word" start_char="2262">filters</TOKEN>
<TOKEN end_char="2270" id="token-19-14" morph="none" pos="punct" start_char="2270">"</TOKEN>
<TOKEN end_char="2274" id="token-19-15" morph="none" pos="word" start_char="2271">most</TOKEN>
<TOKEN end_char="2281" id="token-19-16" morph="none" pos="word" start_char="2276">likely</TOKEN>
<TOKEN end_char="2288" id="token-19-17" morph="none" pos="word" start_char="2283">reduce</TOKEN>
<TOKEN end_char="2292" id="token-19-18" morph="none" pos="word" start_char="2290">the</TOKEN>
<TOKEN end_char="2299" id="token-19-19" morph="none" pos="word" start_char="2294">number</TOKEN>
<TOKEN end_char="2302" id="token-19-20" morph="none" pos="word" start_char="2301">of</TOKEN>
<TOKEN end_char="2314" id="token-19-21" morph="none" pos="word" start_char="2304">potentially</TOKEN>
<TOKEN end_char="2325" id="token-19-22" morph="none" pos="word" start_char="2316">pathogenic</TOKEN>
<TOKEN end_char="2334" id="token-19-23" morph="none" pos="word" start_char="2327">bacteria</TOKEN>
<TOKEN end_char="2339" id="token-19-24" morph="none" pos="word" start_char="2336">with</TOKEN>
<TOKEN end_char="2343" id="token-19-25" morph="none" pos="word" start_char="2341">the</TOKEN>
<TOKEN end_char="2353" id="token-19-26" morph="none" pos="word" start_char="2345">potential</TOKEN>
<TOKEN end_char="2356" id="token-19-27" morph="none" pos="word" start_char="2355">to</TOKEN>
<TOKEN end_char="2365" id="token-19-28" morph="none" pos="word" start_char="2358">colonize</TOKEN>
<TOKEN end_char="2371" id="token-19-29" morph="none" pos="word" start_char="2367">hands</TOKEN>
<TOKEN end_char="2375" id="token-19-30" morph="none" pos="word" start_char="2373">but</TOKEN>
<TOKEN end_char="2378" id="token-19-31" morph="none" pos="word" start_char="2377">do</TOKEN>
<TOKEN end_char="2382" id="token-19-32" morph="none" pos="word" start_char="2380">not</TOKEN>
<TOKEN end_char="2392" id="token-19-33" morph="none" pos="word" start_char="2384">eliminate</TOKEN>
<TOKEN end_char="2396" id="token-19-34" morph="none" pos="word" start_char="2394">the</TOKEN>
<TOKEN end_char="2401" id="token-19-35" morph="none" pos="word" start_char="2398">risk</TOKEN>
<TOKEN end_char="2410" id="token-19-36" morph="none" pos="word" start_char="2403">entirely</TOKEN>
<TOKEN end_char="2412" id="token-19-37" morph="none" pos="punct" start_char="2411">."</TOKEN>
</SEG>
<SEG end_char="2642" id="segment-20" start_char="2414">
<ORIGINAL_TEXT>A 2015 study found that super-aggro hand-dryers like the ones made by Dyson, which use higher-speed jets of air at room temperature, "produced significantly greater aerosolization of virus on the hands" than the traditional kind.</ORIGINAL_TEXT>
<TOKEN end_char="2414" id="token-20-0" morph="none" pos="word" start_char="2414">A</TOKEN>
<TOKEN end_char="2419" id="token-20-1" morph="none" pos="word" start_char="2416">2015</TOKEN>
<TOKEN end_char="2425" id="token-20-2" morph="none" pos="word" start_char="2421">study</TOKEN>
<TOKEN end_char="2431" id="token-20-3" morph="none" pos="word" start_char="2427">found</TOKEN>
<TOKEN end_char="2436" id="token-20-4" morph="none" pos="word" start_char="2433">that</TOKEN>
<TOKEN end_char="2448" id="token-20-5" morph="none" pos="unknown" start_char="2438">super-aggro</TOKEN>
<TOKEN end_char="2460" id="token-20-6" morph="none" pos="unknown" start_char="2450">hand-dryers</TOKEN>
<TOKEN end_char="2465" id="token-20-7" morph="none" pos="word" start_char="2462">like</TOKEN>
<TOKEN end_char="2469" id="token-20-8" morph="none" pos="word" start_char="2467">the</TOKEN>
<TOKEN end_char="2474" id="token-20-9" morph="none" pos="word" start_char="2471">ones</TOKEN>
<TOKEN end_char="2479" id="token-20-10" morph="none" pos="word" start_char="2476">made</TOKEN>
<TOKEN end_char="2482" id="token-20-11" morph="none" pos="word" start_char="2481">by</TOKEN>
<TOKEN end_char="2488" id="token-20-12" morph="none" pos="word" start_char="2484">Dyson</TOKEN>
<TOKEN end_char="2489" id="token-20-13" morph="none" pos="punct" start_char="2489">,</TOKEN>
<TOKEN end_char="2495" id="token-20-14" morph="none" pos="word" start_char="2491">which</TOKEN>
<TOKEN end_char="2499" id="token-20-15" morph="none" pos="word" start_char="2497">use</TOKEN>
<TOKEN end_char="2512" id="token-20-16" morph="none" pos="unknown" start_char="2501">higher-speed</TOKEN>
<TOKEN end_char="2517" id="token-20-17" morph="none" pos="word" start_char="2514">jets</TOKEN>
<TOKEN end_char="2520" id="token-20-18" morph="none" pos="word" start_char="2519">of</TOKEN>
<TOKEN end_char="2524" id="token-20-19" morph="none" pos="word" start_char="2522">air</TOKEN>
<TOKEN end_char="2527" id="token-20-20" morph="none" pos="word" start_char="2526">at</TOKEN>
<TOKEN end_char="2532" id="token-20-21" morph="none" pos="word" start_char="2529">room</TOKEN>
<TOKEN end_char="2544" id="token-20-22" morph="none" pos="word" start_char="2534">temperature</TOKEN>
<TOKEN end_char="2545" id="token-20-23" morph="none" pos="punct" start_char="2545">,</TOKEN>
<TOKEN end_char="2547" id="token-20-24" morph="none" pos="punct" start_char="2547">"</TOKEN>
<TOKEN end_char="2555" id="token-20-25" morph="none" pos="word" start_char="2548">produced</TOKEN>
<TOKEN end_char="2569" id="token-20-26" morph="none" pos="word" start_char="2557">significantly</TOKEN>
<TOKEN end_char="2577" id="token-20-27" morph="none" pos="word" start_char="2571">greater</TOKEN>
<TOKEN end_char="2592" id="token-20-28" morph="none" pos="word" start_char="2579">aerosolization</TOKEN>
<TOKEN end_char="2595" id="token-20-29" morph="none" pos="word" start_char="2594">of</TOKEN>
<TOKEN end_char="2601" id="token-20-30" morph="none" pos="word" start_char="2597">virus</TOKEN>
<TOKEN end_char="2604" id="token-20-31" morph="none" pos="word" start_char="2603">on</TOKEN>
<TOKEN end_char="2608" id="token-20-32" morph="none" pos="word" start_char="2606">the</TOKEN>
<TOKEN end_char="2614" id="token-20-33" morph="none" pos="word" start_char="2610">hands</TOKEN>
<TOKEN end_char="2615" id="token-20-34" morph="none" pos="punct" start_char="2615">"</TOKEN>
<TOKEN end_char="2620" id="token-20-35" morph="none" pos="word" start_char="2617">than</TOKEN>
<TOKEN end_char="2624" id="token-20-36" morph="none" pos="word" start_char="2622">the</TOKEN>
<TOKEN end_char="2636" id="token-20-37" morph="none" pos="word" start_char="2626">traditional</TOKEN>
<TOKEN end_char="2641" id="token-20-38" morph="none" pos="word" start_char="2638">kind</TOKEN>
<TOKEN end_char="2642" id="token-20-39" morph="none" pos="punct" start_char="2642">.</TOKEN>
</SEG>
<SEG end_char="2744" id="segment-21" start_char="2644">
<ORIGINAL_TEXT>Paper towels, meanwhile, were found to cause about the same amount of viral spread as hot-air models.</ORIGINAL_TEXT>
<TOKEN end_char="2648" id="token-21-0" morph="none" pos="word" start_char="2644">Paper</TOKEN>
<TOKEN end_char="2655" id="token-21-1" morph="none" pos="word" start_char="2650">towels</TOKEN>
<TOKEN end_char="2656" id="token-21-2" morph="none" pos="punct" start_char="2656">,</TOKEN>
<TOKEN end_char="2666" id="token-21-3" morph="none" pos="word" start_char="2658">meanwhile</TOKEN>
<TOKEN end_char="2667" id="token-21-4" morph="none" pos="punct" start_char="2667">,</TOKEN>
<TOKEN end_char="2672" id="token-21-5" morph="none" pos="word" start_char="2669">were</TOKEN>
<TOKEN end_char="2678" id="token-21-6" morph="none" pos="word" start_char="2674">found</TOKEN>
<TOKEN end_char="2681" id="token-21-7" morph="none" pos="word" start_char="2680">to</TOKEN>
<TOKEN end_char="2687" id="token-21-8" morph="none" pos="word" start_char="2683">cause</TOKEN>
<TOKEN end_char="2693" id="token-21-9" morph="none" pos="word" start_char="2689">about</TOKEN>
<TOKEN end_char="2697" id="token-21-10" morph="none" pos="word" start_char="2695">the</TOKEN>
<TOKEN end_char="2702" id="token-21-11" morph="none" pos="word" start_char="2699">same</TOKEN>
<TOKEN end_char="2709" id="token-21-12" morph="none" pos="word" start_char="2704">amount</TOKEN>
<TOKEN end_char="2712" id="token-21-13" morph="none" pos="word" start_char="2711">of</TOKEN>
<TOKEN end_char="2718" id="token-21-14" morph="none" pos="word" start_char="2714">viral</TOKEN>
<TOKEN end_char="2725" id="token-21-15" morph="none" pos="word" start_char="2720">spread</TOKEN>
<TOKEN end_char="2728" id="token-21-16" morph="none" pos="word" start_char="2727">as</TOKEN>
<TOKEN end_char="2736" id="token-21-17" morph="none" pos="unknown" start_char="2730">hot-air</TOKEN>
<TOKEN end_char="2743" id="token-21-18" morph="none" pos="word" start_char="2738">models</TOKEN>
<TOKEN end_char="2744" id="token-21-19" morph="none" pos="punct" start_char="2744">.</TOKEN>
</SEG>
<SEG end_char="2806" id="segment-22" start_char="2747">
<ORIGINAL_TEXT>A 2012 analysis of 12 studies over four decades published in</ORIGINAL_TEXT>
<TOKEN end_char="2747" id="token-22-0" morph="none" pos="word" start_char="2747">A</TOKEN>
<TOKEN end_char="2752" id="token-22-1" morph="none" pos="word" start_char="2749">2012</TOKEN>
<TOKEN end_char="2761" id="token-22-2" morph="none" pos="word" start_char="2754">analysis</TOKEN>
<TOKEN end_char="2764" id="token-22-3" morph="none" pos="word" start_char="2763">of</TOKEN>
<TOKEN end_char="2767" id="token-22-4" morph="none" pos="word" start_char="2766">12</TOKEN>
<TOKEN end_char="2775" id="token-22-5" morph="none" pos="word" start_char="2769">studies</TOKEN>
<TOKEN end_char="2780" id="token-22-6" morph="none" pos="word" start_char="2777">over</TOKEN>
<TOKEN end_char="2785" id="token-22-7" morph="none" pos="word" start_char="2782">four</TOKEN>
<TOKEN end_char="2793" id="token-22-8" morph="none" pos="word" start_char="2787">decades</TOKEN>
<TOKEN end_char="2803" id="token-22-9" morph="none" pos="word" start_char="2795">published</TOKEN>
<TOKEN end_char="2806" id="token-22-10" morph="none" pos="word" start_char="2805">in</TOKEN>
</SEG>
<SEG end_char="2831" id="segment-23" start_char="2809">
<ORIGINAL_TEXT>Mayo Clinic Proceedings</ORIGINAL_TEXT>
<TOKEN end_char="2812" id="token-23-0" morph="none" pos="word" start_char="2809">Mayo</TOKEN>
<TOKEN end_char="2819" id="token-23-1" morph="none" pos="word" start_char="2814">Clinic</TOKEN>
<TOKEN end_char="2831" id="token-23-2" morph="none" pos="word" start_char="2821">Proceedings</TOKEN>
</SEG>
<SEG end_char="3032" id="segment-24" start_char="2834">
<ORIGINAL_TEXT>concluded that "[f]rom a hygiene viewpoint, paper towels are superior to electric air dryers" and that they should be used in "locations in which hygiene is paramount, such as hospitals and clinics."</ORIGINAL_TEXT>
<TOKEN end_char="2842" id="token-24-0" morph="none" pos="word" start_char="2834">concluded</TOKEN>
<TOKEN end_char="2847" id="token-24-1" morph="none" pos="word" start_char="2844">that</TOKEN>
<TOKEN end_char="2850" id="token-24-2" morph="none" pos="punct" start_char="2849">"[</TOKEN>
<TOKEN end_char="2855" id="token-24-3" morph="none" pos="unknown" start_char="2851">f]rom</TOKEN>
<TOKEN end_char="2857" id="token-24-4" morph="none" pos="word" start_char="2857">a</TOKEN>
<TOKEN end_char="2865" id="token-24-5" morph="none" pos="word" start_char="2859">hygiene</TOKEN>
<TOKEN end_char="2875" id="token-24-6" morph="none" pos="word" start_char="2867">viewpoint</TOKEN>
<TOKEN end_char="2876" id="token-24-7" morph="none" pos="punct" start_char="2876">,</TOKEN>
<TOKEN end_char="2882" id="token-24-8" morph="none" pos="word" start_char="2878">paper</TOKEN>
<TOKEN end_char="2889" id="token-24-9" morph="none" pos="word" start_char="2884">towels</TOKEN>
<TOKEN end_char="2893" id="token-24-10" morph="none" pos="word" start_char="2891">are</TOKEN>
<TOKEN end_char="2902" id="token-24-11" morph="none" pos="word" start_char="2895">superior</TOKEN>
<TOKEN end_char="2905" id="token-24-12" morph="none" pos="word" start_char="2904">to</TOKEN>
<TOKEN end_char="2914" id="token-24-13" morph="none" pos="word" start_char="2907">electric</TOKEN>
<TOKEN end_char="2918" id="token-24-14" morph="none" pos="word" start_char="2916">air</TOKEN>
<TOKEN end_char="2925" id="token-24-15" morph="none" pos="word" start_char="2920">dryers</TOKEN>
<TOKEN end_char="2926" id="token-24-16" morph="none" pos="punct" start_char="2926">"</TOKEN>
<TOKEN end_char="2930" id="token-24-17" morph="none" pos="word" start_char="2928">and</TOKEN>
<TOKEN end_char="2935" id="token-24-18" morph="none" pos="word" start_char="2932">that</TOKEN>
<TOKEN end_char="2940" id="token-24-19" morph="none" pos="word" start_char="2937">they</TOKEN>
<TOKEN end_char="2947" id="token-24-20" morph="none" pos="word" start_char="2942">should</TOKEN>
<TOKEN end_char="2950" id="token-24-21" morph="none" pos="word" start_char="2949">be</TOKEN>
<TOKEN end_char="2955" id="token-24-22" morph="none" pos="word" start_char="2952">used</TOKEN>
<TOKEN end_char="2958" id="token-24-23" morph="none" pos="word" start_char="2957">in</TOKEN>
<TOKEN end_char="2960" id="token-24-24" morph="none" pos="punct" start_char="2960">"</TOKEN>
<TOKEN end_char="2969" id="token-24-25" morph="none" pos="word" start_char="2961">locations</TOKEN>
<TOKEN end_char="2972" id="token-24-26" morph="none" pos="word" start_char="2971">in</TOKEN>
<TOKEN end_char="2978" id="token-24-27" morph="none" pos="word" start_char="2974">which</TOKEN>
<TOKEN end_char="2986" id="token-24-28" morph="none" pos="word" start_char="2980">hygiene</TOKEN>
<TOKEN end_char="2989" id="token-24-29" morph="none" pos="word" start_char="2988">is</TOKEN>
<TOKEN end_char="2999" id="token-24-30" morph="none" pos="word" start_char="2991">paramount</TOKEN>
<TOKEN end_char="3000" id="token-24-31" morph="none" pos="punct" start_char="3000">,</TOKEN>
<TOKEN end_char="3005" id="token-24-32" morph="none" pos="word" start_char="3002">such</TOKEN>
<TOKEN end_char="3008" id="token-24-33" morph="none" pos="word" start_char="3007">as</TOKEN>
<TOKEN end_char="3018" id="token-24-34" morph="none" pos="word" start_char="3010">hospitals</TOKEN>
<TOKEN end_char="3022" id="token-24-35" morph="none" pos="word" start_char="3020">and</TOKEN>
<TOKEN end_char="3030" id="token-24-36" morph="none" pos="word" start_char="3024">clinics</TOKEN>
<TOKEN end_char="3032" id="token-24-37" morph="none" pos="punct" start_char="3031">."</TOKEN>
</SEG>
<SEG end_char="3153" id="segment-25" start_char="3034">
<ORIGINAL_TEXT>Though it could be argued that hygiene should be paramount in the restroom of, say, your neighborhood Panera Bread, too.</ORIGINAL_TEXT>
<TOKEN end_char="3039" id="token-25-0" morph="none" pos="word" start_char="3034">Though</TOKEN>
<TOKEN end_char="3042" id="token-25-1" morph="none" pos="word" start_char="3041">it</TOKEN>
<TOKEN end_char="3048" id="token-25-2" morph="none" pos="word" start_char="3044">could</TOKEN>
<TOKEN end_char="3051" id="token-25-3" morph="none" pos="word" start_char="3050">be</TOKEN>
<TOKEN end_char="3058" id="token-25-4" morph="none" pos="word" start_char="3053">argued</TOKEN>
<TOKEN end_char="3063" id="token-25-5" morph="none" pos="word" start_char="3060">that</TOKEN>
<TOKEN end_char="3071" id="token-25-6" morph="none" pos="word" start_char="3065">hygiene</TOKEN>
<TOKEN end_char="3078" id="token-25-7" morph="none" pos="word" start_char="3073">should</TOKEN>
<TOKEN end_char="3081" id="token-25-8" morph="none" pos="word" start_char="3080">be</TOKEN>
<TOKEN end_char="3091" id="token-25-9" morph="none" pos="word" start_char="3083">paramount</TOKEN>
<TOKEN end_char="3094" id="token-25-10" morph="none" pos="word" start_char="3093">in</TOKEN>
<TOKEN end_char="3098" id="token-25-11" morph="none" pos="word" start_char="3096">the</TOKEN>
<TOKEN end_char="3107" id="token-25-12" morph="none" pos="word" start_char="3100">restroom</TOKEN>
<TOKEN end_char="3110" id="token-25-13" morph="none" pos="word" start_char="3109">of</TOKEN>
<TOKEN end_char="3111" id="token-25-14" morph="none" pos="punct" start_char="3111">,</TOKEN>
<TOKEN end_char="3115" id="token-25-15" morph="none" pos="word" start_char="3113">say</TOKEN>
<TOKEN end_char="3116" id="token-25-16" morph="none" pos="punct" start_char="3116">,</TOKEN>
<TOKEN end_char="3121" id="token-25-17" morph="none" pos="word" start_char="3118">your</TOKEN>
<TOKEN end_char="3134" id="token-25-18" morph="none" pos="word" start_char="3123">neighborhood</TOKEN>
<TOKEN end_char="3141" id="token-25-19" morph="none" pos="word" start_char="3136">Panera</TOKEN>
<TOKEN end_char="3147" id="token-25-20" morph="none" pos="word" start_char="3143">Bread</TOKEN>
<TOKEN end_char="3148" id="token-25-21" morph="none" pos="punct" start_char="3148">,</TOKEN>
<TOKEN end_char="3152" id="token-25-22" morph="none" pos="word" start_char="3150">too</TOKEN>
<TOKEN end_char="3153" id="token-25-23" morph="none" pos="punct" start_char="3153">.</TOKEN>
</SEG>
<SEG end_char="3259" id="segment-26" start_char="3155">
<ORIGINAL_TEXT>The analysis did find that dryers like Dyson’s "led to much less bacterial transfer than hot air dryers."</ORIGINAL_TEXT>
<TOKEN end_char="3157" id="token-26-0" morph="none" pos="word" start_char="3155">The</TOKEN>
<TOKEN end_char="3166" id="token-26-1" morph="none" pos="word" start_char="3159">analysis</TOKEN>
<TOKEN end_char="3170" id="token-26-2" morph="none" pos="word" start_char="3168">did</TOKEN>
<TOKEN end_char="3175" id="token-26-3" morph="none" pos="word" start_char="3172">find</TOKEN>
<TOKEN end_char="3180" id="token-26-4" morph="none" pos="word" start_char="3177">that</TOKEN>
<TOKEN end_char="3187" id="token-26-5" morph="none" pos="word" start_char="3182">dryers</TOKEN>
<TOKEN end_char="3192" id="token-26-6" morph="none" pos="word" start_char="3189">like</TOKEN>
<TOKEN end_char="3200" id="token-26-7" morph="none" pos="word" start_char="3194">Dyson’s</TOKEN>
<TOKEN end_char="3202" id="token-26-8" morph="none" pos="punct" start_char="3202">"</TOKEN>
<TOKEN end_char="3205" id="token-26-9" morph="none" pos="word" start_char="3203">led</TOKEN>
<TOKEN end_char="3208" id="token-26-10" morph="none" pos="word" start_char="3207">to</TOKEN>
<TOKEN end_char="3213" id="token-26-11" morph="none" pos="word" start_char="3210">much</TOKEN>
<TOKEN end_char="3218" id="token-26-12" morph="none" pos="word" start_char="3215">less</TOKEN>
<TOKEN end_char="3228" id="token-26-13" morph="none" pos="word" start_char="3220">bacterial</TOKEN>
<TOKEN end_char="3237" id="token-26-14" morph="none" pos="word" start_char="3230">transfer</TOKEN>
<TOKEN end_char="3242" id="token-26-15" morph="none" pos="word" start_char="3239">than</TOKEN>
<TOKEN end_char="3246" id="token-26-16" morph="none" pos="word" start_char="3244">hot</TOKEN>
<TOKEN end_char="3250" id="token-26-17" morph="none" pos="word" start_char="3248">air</TOKEN>
<TOKEN end_char="3257" id="token-26-18" morph="none" pos="word" start_char="3252">dryers</TOKEN>
<TOKEN end_char="3259" id="token-26-19" morph="none" pos="punct" start_char="3258">."</TOKEN>
</SEG>
<SEG end_char="3372" id="segment-27" start_char="3262">
<ORIGINAL_TEXT>So does that tell us anything about whether hand dryers could spread a virus like the one that causes Covid-19?</ORIGINAL_TEXT>
<TOKEN end_char="3263" id="token-27-0" morph="none" pos="word" start_char="3262">So</TOKEN>
<TOKEN end_char="3268" id="token-27-1" morph="none" pos="word" start_char="3265">does</TOKEN>
<TOKEN end_char="3273" id="token-27-2" morph="none" pos="word" start_char="3270">that</TOKEN>
<TOKEN end_char="3278" id="token-27-3" morph="none" pos="word" start_char="3275">tell</TOKEN>
<TOKEN end_char="3281" id="token-27-4" morph="none" pos="word" start_char="3280">us</TOKEN>
<TOKEN end_char="3290" id="token-27-5" morph="none" pos="word" start_char="3283">anything</TOKEN>
<TOKEN end_char="3296" id="token-27-6" morph="none" pos="word" start_char="3292">about</TOKEN>
<TOKEN end_char="3304" id="token-27-7" morph="none" pos="word" start_char="3298">whether</TOKEN>
<TOKEN end_char="3309" id="token-27-8" morph="none" pos="word" start_char="3306">hand</TOKEN>
<TOKEN end_char="3316" id="token-27-9" morph="none" pos="word" start_char="3311">dryers</TOKEN>
<TOKEN end_char="3322" id="token-27-10" morph="none" pos="word" start_char="3318">could</TOKEN>
<TOKEN end_char="3329" id="token-27-11" morph="none" pos="word" start_char="3324">spread</TOKEN>
<TOKEN end_char="3331" id="token-27-12" morph="none" pos="word" start_char="3331">a</TOKEN>
<TOKEN end_char="3337" id="token-27-13" morph="none" pos="word" start_char="3333">virus</TOKEN>
<TOKEN end_char="3342" id="token-27-14" morph="none" pos="word" start_char="3339">like</TOKEN>
<TOKEN end_char="3346" id="token-27-15" morph="none" pos="word" start_char="3344">the</TOKEN>
<TOKEN end_char="3350" id="token-27-16" morph="none" pos="word" start_char="3348">one</TOKEN>
<TOKEN end_char="3355" id="token-27-17" morph="none" pos="word" start_char="3352">that</TOKEN>
<TOKEN end_char="3362" id="token-27-18" morph="none" pos="word" start_char="3357">causes</TOKEN>
<TOKEN end_char="3371" id="token-27-19" morph="none" pos="unknown" start_char="3364">Covid-19</TOKEN>
<TOKEN end_char="3372" id="token-27-20" morph="none" pos="punct" start_char="3372">?</TOKEN>
</SEG>
<SEG end_char="3484" id="segment-28" start_char="3374">
<ORIGINAL_TEXT>I called Peter Setlow, a biochemist at the University of Connecticut and one of the authors of that 2018 study.</ORIGINAL_TEXT>
<TOKEN end_char="3374" id="token-28-0" morph="none" pos="word" start_char="3374">I</TOKEN>
<TOKEN end_char="3381" id="token-28-1" morph="none" pos="word" start_char="3376">called</TOKEN>
<TOKEN end_char="3387" id="token-28-2" morph="none" pos="word" start_char="3383">Peter</TOKEN>
<TOKEN end_char="3394" id="token-28-3" morph="none" pos="word" start_char="3389">Setlow</TOKEN>
<TOKEN end_char="3395" id="token-28-4" morph="none" pos="punct" start_char="3395">,</TOKEN>
<TOKEN end_char="3397" id="token-28-5" morph="none" pos="word" start_char="3397">a</TOKEN>
<TOKEN end_char="3408" id="token-28-6" morph="none" pos="word" start_char="3399">biochemist</TOKEN>
<TOKEN end_char="3411" id="token-28-7" morph="none" pos="word" start_char="3410">at</TOKEN>
<TOKEN end_char="3415" id="token-28-8" morph="none" pos="word" start_char="3413">the</TOKEN>
<TOKEN end_char="3426" id="token-28-9" morph="none" pos="word" start_char="3417">University</TOKEN>
<TOKEN end_char="3429" id="token-28-10" morph="none" pos="word" start_char="3428">of</TOKEN>
<TOKEN end_char="3441" id="token-28-11" morph="none" pos="word" start_char="3431">Connecticut</TOKEN>
<TOKEN end_char="3445" id="token-28-12" morph="none" pos="word" start_char="3443">and</TOKEN>
<TOKEN end_char="3449" id="token-28-13" morph="none" pos="word" start_char="3447">one</TOKEN>
<TOKEN end_char="3452" id="token-28-14" morph="none" pos="word" start_char="3451">of</TOKEN>
<TOKEN end_char="3456" id="token-28-15" morph="none" pos="word" start_char="3454">the</TOKEN>
<TOKEN end_char="3464" id="token-28-16" morph="none" pos="word" start_char="3458">authors</TOKEN>
<TOKEN end_char="3467" id="token-28-17" morph="none" pos="word" start_char="3466">of</TOKEN>
<TOKEN end_char="3472" id="token-28-18" morph="none" pos="word" start_char="3469">that</TOKEN>
<TOKEN end_char="3477" id="token-28-19" morph="none" pos="word" start_char="3474">2018</TOKEN>
<TOKEN end_char="3483" id="token-28-20" morph="none" pos="word" start_char="3479">study</TOKEN>
<TOKEN end_char="3484" id="token-28-21" morph="none" pos="punct" start_char="3484">.</TOKEN>
</SEG>
<SEG end_char="3663" id="segment-29" start_char="3486">
<ORIGINAL_TEXT>Setlow is a "spore guy" not an infectious disease expert, but he nonetheless came away from that research with a deep and abiding distrust of hand dryers regardless of the model.</ORIGINAL_TEXT>
<TOKEN end_char="3491" id="token-29-0" morph="none" pos="word" start_char="3486">Setlow</TOKEN>
<TOKEN end_char="3494" id="token-29-1" morph="none" pos="word" start_char="3493">is</TOKEN>
<TOKEN end_char="3496" id="token-29-2" morph="none" pos="word" start_char="3496">a</TOKEN>
<TOKEN end_char="3498" id="token-29-3" morph="none" pos="punct" start_char="3498">"</TOKEN>
<TOKEN end_char="3503" id="token-29-4" morph="none" pos="word" start_char="3499">spore</TOKEN>
<TOKEN end_char="3507" id="token-29-5" morph="none" pos="word" start_char="3505">guy</TOKEN>
<TOKEN end_char="3508" id="token-29-6" morph="none" pos="punct" start_char="3508">"</TOKEN>
<TOKEN end_char="3512" id="token-29-7" morph="none" pos="word" start_char="3510">not</TOKEN>
<TOKEN end_char="3515" id="token-29-8" morph="none" pos="word" start_char="3514">an</TOKEN>
<TOKEN end_char="3526" id="token-29-9" morph="none" pos="word" start_char="3517">infectious</TOKEN>
<TOKEN end_char="3534" id="token-29-10" morph="none" pos="word" start_char="3528">disease</TOKEN>
<TOKEN end_char="3541" id="token-29-11" morph="none" pos="word" start_char="3536">expert</TOKEN>
<TOKEN end_char="3542" id="token-29-12" morph="none" pos="punct" start_char="3542">,</TOKEN>
<TOKEN end_char="3546" id="token-29-13" morph="none" pos="word" start_char="3544">but</TOKEN>
<TOKEN end_char="3549" id="token-29-14" morph="none" pos="word" start_char="3548">he</TOKEN>
<TOKEN end_char="3561" id="token-29-15" morph="none" pos="word" start_char="3551">nonetheless</TOKEN>
<TOKEN end_char="3566" id="token-29-16" morph="none" pos="word" start_char="3563">came</TOKEN>
<TOKEN end_char="3571" id="token-29-17" morph="none" pos="word" start_char="3568">away</TOKEN>
<TOKEN end_char="3576" id="token-29-18" morph="none" pos="word" start_char="3573">from</TOKEN>
<TOKEN end_char="3581" id="token-29-19" morph="none" pos="word" start_char="3578">that</TOKEN>
<TOKEN end_char="3590" id="token-29-20" morph="none" pos="word" start_char="3583">research</TOKEN>
<TOKEN end_char="3595" id="token-29-21" morph="none" pos="word" start_char="3592">with</TOKEN>
<TOKEN end_char="3597" id="token-29-22" morph="none" pos="word" start_char="3597">a</TOKEN>
<TOKEN end_char="3602" id="token-29-23" morph="none" pos="word" start_char="3599">deep</TOKEN>
<TOKEN end_char="3606" id="token-29-24" morph="none" pos="word" start_char="3604">and</TOKEN>
<TOKEN end_char="3614" id="token-29-25" morph="none" pos="word" start_char="3608">abiding</TOKEN>
<TOKEN end_char="3623" id="token-29-26" morph="none" pos="word" start_char="3616">distrust</TOKEN>
<TOKEN end_char="3626" id="token-29-27" morph="none" pos="word" start_char="3625">of</TOKEN>
<TOKEN end_char="3631" id="token-29-28" morph="none" pos="word" start_char="3628">hand</TOKEN>
<TOKEN end_char="3638" id="token-29-29" morph="none" pos="word" start_char="3633">dryers</TOKEN>
<TOKEN end_char="3649" id="token-29-30" morph="none" pos="word" start_char="3640">regardless</TOKEN>
<TOKEN end_char="3652" id="token-29-31" morph="none" pos="word" start_char="3651">of</TOKEN>
<TOKEN end_char="3656" id="token-29-32" morph="none" pos="word" start_char="3654">the</TOKEN>
<TOKEN end_char="3662" id="token-29-33" morph="none" pos="word" start_char="3658">model</TOKEN>
<TOKEN end_char="3663" id="token-29-34" morph="none" pos="punct" start_char="3663">.</TOKEN>
</SEG>
<SEG end_char="3705" id="segment-30" start_char="3665">
<ORIGINAL_TEXT>"Sorry, hand-dryer industry," he told me.</ORIGINAL_TEXT>
<TOKEN end_char="3665" id="token-30-0" morph="none" pos="punct" start_char="3665">"</TOKEN>
<TOKEN end_char="3670" id="token-30-1" morph="none" pos="word" start_char="3666">Sorry</TOKEN>
<TOKEN end_char="3671" id="token-30-2" morph="none" pos="punct" start_char="3671">,</TOKEN>
<TOKEN end_char="3682" id="token-30-3" morph="none" pos="unknown" start_char="3673">hand-dryer</TOKEN>
<TOKEN end_char="3691" id="token-30-4" morph="none" pos="word" start_char="3684">industry</TOKEN>
<TOKEN end_char="3693" id="token-30-5" morph="none" pos="punct" start_char="3692">,"</TOKEN>
<TOKEN end_char="3696" id="token-30-6" morph="none" pos="word" start_char="3695">he</TOKEN>
<TOKEN end_char="3701" id="token-30-7" morph="none" pos="word" start_char="3698">told</TOKEN>
<TOKEN end_char="3704" id="token-30-8" morph="none" pos="word" start_char="3703">me</TOKEN>
<TOKEN end_char="3705" id="token-30-9" morph="none" pos="punct" start_char="3705">.</TOKEN>
</SEG>
<SEG end_char="3759" id="segment-31" start_char="3707">
<ORIGINAL_TEXT>"My personal opinion is that they shouldn’t be used."</ORIGINAL_TEXT>
<TOKEN end_char="3707" id="token-31-0" morph="none" pos="punct" start_char="3707">"</TOKEN>
<TOKEN end_char="3709" id="token-31-1" morph="none" pos="word" start_char="3708">My</TOKEN>
<TOKEN end_char="3718" id="token-31-2" morph="none" pos="word" start_char="3711">personal</TOKEN>
<TOKEN end_char="3726" id="token-31-3" morph="none" pos="word" start_char="3720">opinion</TOKEN>
<TOKEN end_char="3729" id="token-31-4" morph="none" pos="word" start_char="3728">is</TOKEN>
<TOKEN end_char="3734" id="token-31-5" morph="none" pos="word" start_char="3731">that</TOKEN>
<TOKEN end_char="3739" id="token-31-6" morph="none" pos="word" start_char="3736">they</TOKEN>
<TOKEN end_char="3749" id="token-31-7" morph="none" pos="word" start_char="3741">shouldn’t</TOKEN>
<TOKEN end_char="3752" id="token-31-8" morph="none" pos="word" start_char="3751">be</TOKEN>
<TOKEN end_char="3757" id="token-31-9" morph="none" pos="word" start_char="3754">used</TOKEN>
<TOKEN end_char="3759" id="token-31-10" morph="none" pos="punct" start_char="3758">."</TOKEN>
</SEG>
<SEG end_char="4088" id="segment-32" start_char="3762">
<ORIGINAL_TEXT>There’s been understandable blowback from the hand-dryer industry, which questions the methodology of some of this research and notes that certain studies pegging hand dryers as disease vectors—including the one cited above, from 2015—were carried out by researchers who had worked as consultants for paper-towel manufacturers.</ORIGINAL_TEXT>
<TOKEN end_char="3768" id="token-32-0" morph="none" pos="word" start_char="3762">There’s</TOKEN>
<TOKEN end_char="3773" id="token-32-1" morph="none" pos="word" start_char="3770">been</TOKEN>
<TOKEN end_char="3788" id="token-32-2" morph="none" pos="word" start_char="3775">understandable</TOKEN>
<TOKEN end_char="3797" id="token-32-3" morph="none" pos="word" start_char="3790">blowback</TOKEN>
<TOKEN end_char="3802" id="token-32-4" morph="none" pos="word" start_char="3799">from</TOKEN>
<TOKEN end_char="3806" id="token-32-5" morph="none" pos="word" start_char="3804">the</TOKEN>
<TOKEN end_char="3817" id="token-32-6" morph="none" pos="unknown" start_char="3808">hand-dryer</TOKEN>
<TOKEN end_char="3826" id="token-32-7" morph="none" pos="word" start_char="3819">industry</TOKEN>
<TOKEN end_char="3827" id="token-32-8" morph="none" pos="punct" start_char="3827">,</TOKEN>
<TOKEN end_char="3833" id="token-32-9" morph="none" pos="word" start_char="3829">which</TOKEN>
<TOKEN end_char="3843" id="token-32-10" morph="none" pos="word" start_char="3835">questions</TOKEN>
<TOKEN end_char="3847" id="token-32-11" morph="none" pos="word" start_char="3845">the</TOKEN>
<TOKEN end_char="3859" id="token-32-12" morph="none" pos="word" start_char="3849">methodology</TOKEN>
<TOKEN end_char="3862" id="token-32-13" morph="none" pos="word" start_char="3861">of</TOKEN>
<TOKEN end_char="3867" id="token-32-14" morph="none" pos="word" start_char="3864">some</TOKEN>
<TOKEN end_char="3870" id="token-32-15" morph="none" pos="word" start_char="3869">of</TOKEN>
<TOKEN end_char="3875" id="token-32-16" morph="none" pos="word" start_char="3872">this</TOKEN>
<TOKEN end_char="3884" id="token-32-17" morph="none" pos="word" start_char="3877">research</TOKEN>
<TOKEN end_char="3888" id="token-32-18" morph="none" pos="word" start_char="3886">and</TOKEN>
<TOKEN end_char="3894" id="token-32-19" morph="none" pos="word" start_char="3890">notes</TOKEN>
<TOKEN end_char="3899" id="token-32-20" morph="none" pos="word" start_char="3896">that</TOKEN>
<TOKEN end_char="3907" id="token-32-21" morph="none" pos="word" start_char="3901">certain</TOKEN>
<TOKEN end_char="3915" id="token-32-22" morph="none" pos="word" start_char="3909">studies</TOKEN>
<TOKEN end_char="3923" id="token-32-23" morph="none" pos="word" start_char="3917">pegging</TOKEN>
<TOKEN end_char="3928" id="token-32-24" morph="none" pos="word" start_char="3925">hand</TOKEN>
<TOKEN end_char="3935" id="token-32-25" morph="none" pos="word" start_char="3930">dryers</TOKEN>
<TOKEN end_char="3938" id="token-32-26" morph="none" pos="word" start_char="3937">as</TOKEN>
<TOKEN end_char="3946" id="token-32-27" morph="none" pos="word" start_char="3940">disease</TOKEN>
<TOKEN end_char="3964" id="token-32-28" morph="none" pos="unknown" start_char="3948">vectors—including</TOKEN>
<TOKEN end_char="3968" id="token-32-29" morph="none" pos="word" start_char="3966">the</TOKEN>
<TOKEN end_char="3972" id="token-32-30" morph="none" pos="word" start_char="3970">one</TOKEN>
<TOKEN end_char="3978" id="token-32-31" morph="none" pos="word" start_char="3974">cited</TOKEN>
<TOKEN end_char="3984" id="token-32-32" morph="none" pos="word" start_char="3980">above</TOKEN>
<TOKEN end_char="3985" id="token-32-33" morph="none" pos="punct" start_char="3985">,</TOKEN>
<TOKEN end_char="3990" id="token-32-34" morph="none" pos="word" start_char="3987">from</TOKEN>
<TOKEN end_char="4000" id="token-32-35" morph="none" pos="unknown" start_char="3992">2015—were</TOKEN>
<TOKEN end_char="4008" id="token-32-36" morph="none" pos="word" start_char="4002">carried</TOKEN>
<TOKEN end_char="4012" id="token-32-37" morph="none" pos="word" start_char="4010">out</TOKEN>
<TOKEN end_char="4015" id="token-32-38" morph="none" pos="word" start_char="4014">by</TOKEN>
<TOKEN end_char="4027" id="token-32-39" morph="none" pos="word" start_char="4017">researchers</TOKEN>
<TOKEN end_char="4031" id="token-32-40" morph="none" pos="word" start_char="4029">who</TOKEN>
<TOKEN end_char="4035" id="token-32-41" morph="none" pos="word" start_char="4033">had</TOKEN>
<TOKEN end_char="4042" id="token-32-42" morph="none" pos="word" start_char="4037">worked</TOKEN>
<TOKEN end_char="4045" id="token-32-43" morph="none" pos="word" start_char="4044">as</TOKEN>
<TOKEN end_char="4057" id="token-32-44" morph="none" pos="word" start_char="4047">consultants</TOKEN>
<TOKEN end_char="4061" id="token-32-45" morph="none" pos="word" start_char="4059">for</TOKEN>
<TOKEN end_char="4073" id="token-32-46" morph="none" pos="unknown" start_char="4063">paper-towel</TOKEN>
<TOKEN end_char="4087" id="token-32-47" morph="none" pos="word" start_char="4075">manufacturers</TOKEN>
<TOKEN end_char="4088" id="token-32-48" morph="none" pos="punct" start_char="4088">.</TOKEN>
</SEG>
<SEG end_char="4133" id="segment-33" start_char="4090">
<ORIGINAL_TEXT>This is true in some, though not all, cases.</ORIGINAL_TEXT>
<TOKEN end_char="4093" id="token-33-0" morph="none" pos="word" start_char="4090">This</TOKEN>
<TOKEN end_char="4096" id="token-33-1" morph="none" pos="word" start_char="4095">is</TOKEN>
<TOKEN end_char="4101" id="token-33-2" morph="none" pos="word" start_char="4098">true</TOKEN>
<TOKEN end_char="4104" id="token-33-3" morph="none" pos="word" start_char="4103">in</TOKEN>
<TOKEN end_char="4109" id="token-33-4" morph="none" pos="word" start_char="4106">some</TOKEN>
<TOKEN end_char="4110" id="token-33-5" morph="none" pos="punct" start_char="4110">,</TOKEN>
<TOKEN end_char="4117" id="token-33-6" morph="none" pos="word" start_char="4112">though</TOKEN>
<TOKEN end_char="4121" id="token-33-7" morph="none" pos="word" start_char="4119">not</TOKEN>
<TOKEN end_char="4125" id="token-33-8" morph="none" pos="word" start_char="4123">all</TOKEN>
<TOKEN end_char="4126" id="token-33-9" morph="none" pos="punct" start_char="4126">,</TOKEN>
<TOKEN end_char="4132" id="token-33-10" morph="none" pos="word" start_char="4128">cases</TOKEN>
<TOKEN end_char="4133" id="token-33-11" morph="none" pos="punct" start_char="4133">.</TOKEN>
</SEG>
<SEG end_char="4221" id="segment-34" start_char="4135">
<ORIGINAL_TEXT>Dyson got in on the game by funding a study, published last April, that found—surprise!</ORIGINAL_TEXT>
<TOKEN end_char="4139" id="token-34-0" morph="none" pos="word" start_char="4135">Dyson</TOKEN>
<TOKEN end_char="4143" id="token-34-1" morph="none" pos="word" start_char="4141">got</TOKEN>
<TOKEN end_char="4146" id="token-34-2" morph="none" pos="word" start_char="4145">in</TOKEN>
<TOKEN end_char="4149" id="token-34-3" morph="none" pos="word" start_char="4148">on</TOKEN>
<TOKEN end_char="4153" id="token-34-4" morph="none" pos="word" start_char="4151">the</TOKEN>
<TOKEN end_char="4158" id="token-34-5" morph="none" pos="word" start_char="4155">game</TOKEN>
<TOKEN end_char="4161" id="token-34-6" morph="none" pos="word" start_char="4160">by</TOKEN>
<TOKEN end_char="4169" id="token-34-7" morph="none" pos="word" start_char="4163">funding</TOKEN>
<TOKEN end_char="4171" id="token-34-8" morph="none" pos="word" start_char="4171">a</TOKEN>
<TOKEN end_char="4177" id="token-34-9" morph="none" pos="word" start_char="4173">study</TOKEN>
<TOKEN end_char="4178" id="token-34-10" morph="none" pos="punct" start_char="4178">,</TOKEN>
<TOKEN end_char="4188" id="token-34-11" morph="none" pos="word" start_char="4180">published</TOKEN>
<TOKEN end_char="4193" id="token-34-12" morph="none" pos="word" start_char="4190">last</TOKEN>
<TOKEN end_char="4199" id="token-34-13" morph="none" pos="word" start_char="4195">April</TOKEN>
<TOKEN end_char="4200" id="token-34-14" morph="none" pos="punct" start_char="4200">,</TOKEN>
<TOKEN end_char="4205" id="token-34-15" morph="none" pos="word" start_char="4202">that</TOKEN>
<TOKEN end_char="4220" id="token-34-16" morph="none" pos="unknown" start_char="4207">found—surprise</TOKEN>
<TOKEN end_char="4221" id="token-34-17" morph="none" pos="punct" start_char="4221">!</TOKEN>
</SEG>
<SEG end_char="4326" id="segment-35" start_char="4223">
<ORIGINAL_TEXT>—hands dried with the company’s own Airblade harbored fewer bacteria than those dried with paper towels.</ORIGINAL_TEXT>
<TOKEN end_char="4223" id="token-35-0" morph="none" pos="punct" start_char="4223">—</TOKEN>
<TOKEN end_char="4228" id="token-35-1" morph="none" pos="word" start_char="4224">hands</TOKEN>
<TOKEN end_char="4234" id="token-35-2" morph="none" pos="word" start_char="4230">dried</TOKEN>
<TOKEN end_char="4239" id="token-35-3" morph="none" pos="word" start_char="4236">with</TOKEN>
<TOKEN end_char="4243" id="token-35-4" morph="none" pos="word" start_char="4241">the</TOKEN>
<TOKEN end_char="4253" id="token-35-5" morph="none" pos="word" start_char="4245">company’s</TOKEN>
<TOKEN end_char="4257" id="token-35-6" morph="none" pos="word" start_char="4255">own</TOKEN>
<TOKEN end_char="4266" id="token-35-7" morph="none" pos="word" start_char="4259">Airblade</TOKEN>
<TOKEN end_char="4275" id="token-35-8" morph="none" pos="word" start_char="4268">harbored</TOKEN>
<TOKEN end_char="4281" id="token-35-9" morph="none" pos="word" start_char="4277">fewer</TOKEN>
<TOKEN end_char="4290" id="token-35-10" morph="none" pos="word" start_char="4283">bacteria</TOKEN>
<TOKEN end_char="4295" id="token-35-11" morph="none" pos="word" start_char="4292">than</TOKEN>
<TOKEN end_char="4301" id="token-35-12" morph="none" pos="word" start_char="4297">those</TOKEN>
<TOKEN end_char="4307" id="token-35-13" morph="none" pos="word" start_char="4303">dried</TOKEN>
<TOKEN end_char="4312" id="token-35-14" morph="none" pos="word" start_char="4309">with</TOKEN>
<TOKEN end_char="4318" id="token-35-15" morph="none" pos="word" start_char="4314">paper</TOKEN>
<TOKEN end_char="4325" id="token-35-16" morph="none" pos="word" start_char="4320">towels</TOKEN>
<TOKEN end_char="4326" id="token-35-17" morph="none" pos="punct" start_char="4326">.</TOKEN>
</SEG>
<SEG end_char="4380" id="segment-36" start_char="4329">
<ORIGINAL_TEXT>There’s reason to be skeptical of last year’s paper.</ORIGINAL_TEXT>
<TOKEN end_char="4335" id="token-36-0" morph="none" pos="word" start_char="4329">There’s</TOKEN>
<TOKEN end_char="4342" id="token-36-1" morph="none" pos="word" start_char="4337">reason</TOKEN>
<TOKEN end_char="4345" id="token-36-2" morph="none" pos="word" start_char="4344">to</TOKEN>
<TOKEN end_char="4348" id="token-36-3" morph="none" pos="word" start_char="4347">be</TOKEN>
<TOKEN end_char="4358" id="token-36-4" morph="none" pos="word" start_char="4350">skeptical</TOKEN>
<TOKEN end_char="4361" id="token-36-5" morph="none" pos="word" start_char="4360">of</TOKEN>
<TOKEN end_char="4366" id="token-36-6" morph="none" pos="word" start_char="4363">last</TOKEN>
<TOKEN end_char="4373" id="token-36-7" morph="none" pos="word" start_char="4368">year’s</TOKEN>
<TOKEN end_char="4379" id="token-36-8" morph="none" pos="word" start_char="4375">paper</TOKEN>
<TOKEN end_char="4380" id="token-36-9" morph="none" pos="punct" start_char="4380">.</TOKEN>
</SEG>
<SEG end_char="4522" id="segment-37" start_char="4382">
<ORIGINAL_TEXT>In the study, subjects "slowly" moved their hands in and out of the machine for a full minute, something no normal human is ever going to do.</ORIGINAL_TEXT>
<TOKEN end_char="4383" id="token-37-0" morph="none" pos="word" start_char="4382">In</TOKEN>
<TOKEN end_char="4387" id="token-37-1" morph="none" pos="word" start_char="4385">the</TOKEN>
<TOKEN end_char="4393" id="token-37-2" morph="none" pos="word" start_char="4389">study</TOKEN>
<TOKEN end_char="4394" id="token-37-3" morph="none" pos="punct" start_char="4394">,</TOKEN>
<TOKEN end_char="4403" id="token-37-4" morph="none" pos="word" start_char="4396">subjects</TOKEN>
<TOKEN end_char="4405" id="token-37-5" morph="none" pos="punct" start_char="4405">"</TOKEN>
<TOKEN end_char="4411" id="token-37-6" morph="none" pos="word" start_char="4406">slowly</TOKEN>
<TOKEN end_char="4412" id="token-37-7" morph="none" pos="punct" start_char="4412">"</TOKEN>
<TOKEN end_char="4418" id="token-37-8" morph="none" pos="word" start_char="4414">moved</TOKEN>
<TOKEN end_char="4424" id="token-37-9" morph="none" pos="word" start_char="4420">their</TOKEN>
<TOKEN end_char="4430" id="token-37-10" morph="none" pos="word" start_char="4426">hands</TOKEN>
<TOKEN end_char="4433" id="token-37-11" morph="none" pos="word" start_char="4432">in</TOKEN>
<TOKEN end_char="4437" id="token-37-12" morph="none" pos="word" start_char="4435">and</TOKEN>
<TOKEN end_char="4441" id="token-37-13" morph="none" pos="word" start_char="4439">out</TOKEN>
<TOKEN end_char="4444" id="token-37-14" morph="none" pos="word" start_char="4443">of</TOKEN>
<TOKEN end_char="4448" id="token-37-15" morph="none" pos="word" start_char="4446">the</TOKEN>
<TOKEN end_char="4456" id="token-37-16" morph="none" pos="word" start_char="4450">machine</TOKEN>
<TOKEN end_char="4460" id="token-37-17" morph="none" pos="word" start_char="4458">for</TOKEN>
<TOKEN end_char="4462" id="token-37-18" morph="none" pos="word" start_char="4462">a</TOKEN>
<TOKEN end_char="4467" id="token-37-19" morph="none" pos="word" start_char="4464">full</TOKEN>
<TOKEN end_char="4474" id="token-37-20" morph="none" pos="word" start_char="4469">minute</TOKEN>
<TOKEN end_char="4475" id="token-37-21" morph="none" pos="punct" start_char="4475">,</TOKEN>
<TOKEN end_char="4485" id="token-37-22" morph="none" pos="word" start_char="4477">something</TOKEN>
<TOKEN end_char="4488" id="token-37-23" morph="none" pos="word" start_char="4487">no</TOKEN>
<TOKEN end_char="4495" id="token-37-24" morph="none" pos="word" start_char="4490">normal</TOKEN>
<TOKEN end_char="4501" id="token-37-25" morph="none" pos="word" start_char="4497">human</TOKEN>
<TOKEN end_char="4504" id="token-37-26" morph="none" pos="word" start_char="4503">is</TOKEN>
<TOKEN end_char="4509" id="token-37-27" morph="none" pos="word" start_char="4506">ever</TOKEN>
<TOKEN end_char="4515" id="token-37-28" morph="none" pos="word" start_char="4511">going</TOKEN>
<TOKEN end_char="4518" id="token-37-29" morph="none" pos="word" start_char="4517">to</TOKEN>
<TOKEN end_char="4521" id="token-37-30" morph="none" pos="word" start_char="4520">do</TOKEN>
<TOKEN end_char="4522" id="token-37-31" morph="none" pos="punct" start_char="4522">.</TOKEN>
</SEG>
<SEG end_char="4632" id="segment-38" start_char="4524">
<ORIGINAL_TEXT>Besides, Dyson says elsewhere that the model dries hands satisfactorily in a mere 12 seconds, so which is it?</ORIGINAL_TEXT>
<TOKEN end_char="4530" id="token-38-0" morph="none" pos="word" start_char="4524">Besides</TOKEN>
<TOKEN end_char="4531" id="token-38-1" morph="none" pos="punct" start_char="4531">,</TOKEN>
<TOKEN end_char="4537" id="token-38-2" morph="none" pos="word" start_char="4533">Dyson</TOKEN>
<TOKEN end_char="4542" id="token-38-3" morph="none" pos="word" start_char="4539">says</TOKEN>
<TOKEN end_char="4552" id="token-38-4" morph="none" pos="word" start_char="4544">elsewhere</TOKEN>
<TOKEN end_char="4557" id="token-38-5" morph="none" pos="word" start_char="4554">that</TOKEN>
<TOKEN end_char="4561" id="token-38-6" morph="none" pos="word" start_char="4559">the</TOKEN>
<TOKEN end_char="4567" id="token-38-7" morph="none" pos="word" start_char="4563">model</TOKEN>
<TOKEN end_char="4573" id="token-38-8" morph="none" pos="word" start_char="4569">dries</TOKEN>
<TOKEN end_char="4579" id="token-38-9" morph="none" pos="word" start_char="4575">hands</TOKEN>
<TOKEN end_char="4594" id="token-38-10" morph="none" pos="word" start_char="4581">satisfactorily</TOKEN>
<TOKEN end_char="4597" id="token-38-11" morph="none" pos="word" start_char="4596">in</TOKEN>
<TOKEN end_char="4599" id="token-38-12" morph="none" pos="word" start_char="4599">a</TOKEN>
<TOKEN end_char="4604" id="token-38-13" morph="none" pos="word" start_char="4601">mere</TOKEN>
<TOKEN end_char="4607" id="token-38-14" morph="none" pos="word" start_char="4606">12</TOKEN>
<TOKEN end_char="4615" id="token-38-15" morph="none" pos="word" start_char="4609">seconds</TOKEN>
<TOKEN end_char="4616" id="token-38-16" morph="none" pos="punct" start_char="4616">,</TOKEN>
<TOKEN end_char="4619" id="token-38-17" morph="none" pos="word" start_char="4618">so</TOKEN>
<TOKEN end_char="4625" id="token-38-18" morph="none" pos="word" start_char="4621">which</TOKEN>
<TOKEN end_char="4628" id="token-38-19" morph="none" pos="word" start_char="4627">is</TOKEN>
<TOKEN end_char="4631" id="token-38-20" morph="none" pos="word" start_char="4630">it</TOKEN>
<TOKEN end_char="4632" id="token-38-21" morph="none" pos="punct" start_char="4632">?</TOKEN>
</SEG>
<SEG end_char="4786" id="segment-39" start_char="4634">
<ORIGINAL_TEXT>More importantly, that study only looked at the bacteria left behind on hands post-drying, not whether particles might have been blown onto your clothes.</ORIGINAL_TEXT>
<TOKEN end_char="4637" id="token-39-0" morph="none" pos="word" start_char="4634">More</TOKEN>
<TOKEN end_char="4649" id="token-39-1" morph="none" pos="word" start_char="4639">importantly</TOKEN>
<TOKEN end_char="4650" id="token-39-2" morph="none" pos="punct" start_char="4650">,</TOKEN>
<TOKEN end_char="4655" id="token-39-3" morph="none" pos="word" start_char="4652">that</TOKEN>
<TOKEN end_char="4661" id="token-39-4" morph="none" pos="word" start_char="4657">study</TOKEN>
<TOKEN end_char="4666" id="token-39-5" morph="none" pos="word" start_char="4663">only</TOKEN>
<TOKEN end_char="4673" id="token-39-6" morph="none" pos="word" start_char="4668">looked</TOKEN>
<TOKEN end_char="4676" id="token-39-7" morph="none" pos="word" start_char="4675">at</TOKEN>
<TOKEN end_char="4680" id="token-39-8" morph="none" pos="word" start_char="4678">the</TOKEN>
<TOKEN end_char="4689" id="token-39-9" morph="none" pos="word" start_char="4682">bacteria</TOKEN>
<TOKEN end_char="4694" id="token-39-10" morph="none" pos="word" start_char="4691">left</TOKEN>
<TOKEN end_char="4701" id="token-39-11" morph="none" pos="word" start_char="4696">behind</TOKEN>
<TOKEN end_char="4704" id="token-39-12" morph="none" pos="word" start_char="4703">on</TOKEN>
<TOKEN end_char="4710" id="token-39-13" morph="none" pos="word" start_char="4706">hands</TOKEN>
<TOKEN end_char="4722" id="token-39-14" morph="none" pos="unknown" start_char="4712">post-drying</TOKEN>
<TOKEN end_char="4723" id="token-39-15" morph="none" pos="punct" start_char="4723">,</TOKEN>
<TOKEN end_char="4727" id="token-39-16" morph="none" pos="word" start_char="4725">not</TOKEN>
<TOKEN end_char="4735" id="token-39-17" morph="none" pos="word" start_char="4729">whether</TOKEN>
<TOKEN end_char="4745" id="token-39-18" morph="none" pos="word" start_char="4737">particles</TOKEN>
<TOKEN end_char="4751" id="token-39-19" morph="none" pos="word" start_char="4747">might</TOKEN>
<TOKEN end_char="4756" id="token-39-20" morph="none" pos="word" start_char="4753">have</TOKEN>
<TOKEN end_char="4761" id="token-39-21" morph="none" pos="word" start_char="4758">been</TOKEN>
<TOKEN end_char="4767" id="token-39-22" morph="none" pos="word" start_char="4763">blown</TOKEN>
<TOKEN end_char="4772" id="token-39-23" morph="none" pos="word" start_char="4769">onto</TOKEN>
<TOKEN end_char="4777" id="token-39-24" morph="none" pos="word" start_char="4774">your</TOKEN>
<TOKEN end_char="4785" id="token-39-25" morph="none" pos="word" start_char="4779">clothes</TOKEN>
<TOKEN end_char="4786" id="token-39-26" morph="none" pos="punct" start_char="4786">.</TOKEN>
</SEG>
<SEG end_char="4926" id="segment-40" start_char="4789">
<ORIGINAL_TEXT>It’s not just a matter of public health: There are fortunes at stake in the science war between the paper-towel and hand-dryer industries.</ORIGINAL_TEXT>
<TOKEN end_char="4792" id="token-40-0" morph="none" pos="word" start_char="4789">It’s</TOKEN>
<TOKEN end_char="4796" id="token-40-1" morph="none" pos="word" start_char="4794">not</TOKEN>
<TOKEN end_char="4801" id="token-40-2" morph="none" pos="word" start_char="4798">just</TOKEN>
<TOKEN end_char="4803" id="token-40-3" morph="none" pos="word" start_char="4803">a</TOKEN>
<TOKEN end_char="4810" id="token-40-4" morph="none" pos="word" start_char="4805">matter</TOKEN>
<TOKEN end_char="4813" id="token-40-5" morph="none" pos="word" start_char="4812">of</TOKEN>
<TOKEN end_char="4820" id="token-40-6" morph="none" pos="word" start_char="4815">public</TOKEN>
<TOKEN end_char="4827" id="token-40-7" morph="none" pos="word" start_char="4822">health</TOKEN>
<TOKEN end_char="4828" id="token-40-8" morph="none" pos="punct" start_char="4828">:</TOKEN>
<TOKEN end_char="4834" id="token-40-9" morph="none" pos="word" start_char="4830">There</TOKEN>
<TOKEN end_char="4838" id="token-40-10" morph="none" pos="word" start_char="4836">are</TOKEN>
<TOKEN end_char="4847" id="token-40-11" morph="none" pos="word" start_char="4840">fortunes</TOKEN>
<TOKEN end_char="4850" id="token-40-12" morph="none" pos="word" start_char="4849">at</TOKEN>
<TOKEN end_char="4856" id="token-40-13" morph="none" pos="word" start_char="4852">stake</TOKEN>
<TOKEN end_char="4859" id="token-40-14" morph="none" pos="word" start_char="4858">in</TOKEN>
<TOKEN end_char="4863" id="token-40-15" morph="none" pos="word" start_char="4861">the</TOKEN>
<TOKEN end_char="4871" id="token-40-16" morph="none" pos="word" start_char="4865">science</TOKEN>
<TOKEN end_char="4875" id="token-40-17" morph="none" pos="word" start_char="4873">war</TOKEN>
<TOKEN end_char="4883" id="token-40-18" morph="none" pos="word" start_char="4877">between</TOKEN>
<TOKEN end_char="4887" id="token-40-19" morph="none" pos="word" start_char="4885">the</TOKEN>
<TOKEN end_char="4899" id="token-40-20" morph="none" pos="unknown" start_char="4889">paper-towel</TOKEN>
<TOKEN end_char="4903" id="token-40-21" morph="none" pos="word" start_char="4901">and</TOKEN>
<TOKEN end_char="4914" id="token-40-22" morph="none" pos="unknown" start_char="4905">hand-dryer</TOKEN>
<TOKEN end_char="4925" id="token-40-23" morph="none" pos="word" start_char="4916">industries</TOKEN>
<TOKEN end_char="4926" id="token-40-24" morph="none" pos="punct" start_char="4926">.</TOKEN>
</SEG>
<SEG end_char="5154" id="segment-41" start_char="4928">
<ORIGINAL_TEXT>Multifold paper towels, the kind commonly used in bathrooms, are a several-billion-dollar-a-year behemoth, and one recent estimate of the global market for hand dryers puts the number at a shade under $800 million, and growing.</ORIGINAL_TEXT>
<TOKEN end_char="4936" id="token-41-0" morph="none" pos="word" start_char="4928">Multifold</TOKEN>
<TOKEN end_char="4942" id="token-41-1" morph="none" pos="word" start_char="4938">paper</TOKEN>
<TOKEN end_char="4949" id="token-41-2" morph="none" pos="word" start_char="4944">towels</TOKEN>
<TOKEN end_char="4950" id="token-41-3" morph="none" pos="punct" start_char="4950">,</TOKEN>
<TOKEN end_char="4954" id="token-41-4" morph="none" pos="word" start_char="4952">the</TOKEN>
<TOKEN end_char="4959" id="token-41-5" morph="none" pos="word" start_char="4956">kind</TOKEN>
<TOKEN end_char="4968" id="token-41-6" morph="none" pos="word" start_char="4961">commonly</TOKEN>
<TOKEN end_char="4973" id="token-41-7" morph="none" pos="word" start_char="4970">used</TOKEN>
<TOKEN end_char="4976" id="token-41-8" morph="none" pos="word" start_char="4975">in</TOKEN>
<TOKEN end_char="4986" id="token-41-9" morph="none" pos="word" start_char="4978">bathrooms</TOKEN>
<TOKEN end_char="4987" id="token-41-10" morph="none" pos="punct" start_char="4987">,</TOKEN>
<TOKEN end_char="4991" id="token-41-11" morph="none" pos="word" start_char="4989">are</TOKEN>
<TOKEN end_char="4993" id="token-41-12" morph="none" pos="word" start_char="4993">a</TOKEN>
<TOKEN end_char="5023" id="token-41-13" morph="none" pos="unknown" start_char="4995">several-billion-dollar-a-year</TOKEN>
<TOKEN end_char="5032" id="token-41-14" morph="none" pos="word" start_char="5025">behemoth</TOKEN>
<TOKEN end_char="5033" id="token-41-15" morph="none" pos="punct" start_char="5033">,</TOKEN>
<TOKEN end_char="5037" id="token-41-16" morph="none" pos="word" start_char="5035">and</TOKEN>
<TOKEN end_char="5041" id="token-41-17" morph="none" pos="word" start_char="5039">one</TOKEN>
<TOKEN end_char="5048" id="token-41-18" morph="none" pos="word" start_char="5043">recent</TOKEN>
<TOKEN end_char="5057" id="token-41-19" morph="none" pos="word" start_char="5050">estimate</TOKEN>
<TOKEN end_char="5060" id="token-41-20" morph="none" pos="word" start_char="5059">of</TOKEN>
<TOKEN end_char="5064" id="token-41-21" morph="none" pos="word" start_char="5062">the</TOKEN>
<TOKEN end_char="5071" id="token-41-22" morph="none" pos="word" start_char="5066">global</TOKEN>
<TOKEN end_char="5078" id="token-41-23" morph="none" pos="word" start_char="5073">market</TOKEN>
<TOKEN end_char="5082" id="token-41-24" morph="none" pos="word" start_char="5080">for</TOKEN>
<TOKEN end_char="5087" id="token-41-25" morph="none" pos="word" start_char="5084">hand</TOKEN>
<TOKEN end_char="5094" id="token-41-26" morph="none" pos="word" start_char="5089">dryers</TOKEN>
<TOKEN end_char="5099" id="token-41-27" morph="none" pos="word" start_char="5096">puts</TOKEN>
<TOKEN end_char="5103" id="token-41-28" morph="none" pos="word" start_char="5101">the</TOKEN>
<TOKEN end_char="5110" id="token-41-29" morph="none" pos="word" start_char="5105">number</TOKEN>
<TOKEN end_char="5113" id="token-41-30" morph="none" pos="word" start_char="5112">at</TOKEN>
<TOKEN end_char="5115" id="token-41-31" morph="none" pos="word" start_char="5115">a</TOKEN>
<TOKEN end_char="5121" id="token-41-32" morph="none" pos="word" start_char="5117">shade</TOKEN>
<TOKEN end_char="5127" id="token-41-33" morph="none" pos="word" start_char="5123">under</TOKEN>
<TOKEN end_char="5132" id="token-41-34" morph="none" pos="unknown" start_char="5129">$800</TOKEN>
<TOKEN end_char="5140" id="token-41-35" morph="none" pos="word" start_char="5134">million</TOKEN>
<TOKEN end_char="5141" id="token-41-36" morph="none" pos="punct" start_char="5141">,</TOKEN>
<TOKEN end_char="5145" id="token-41-37" morph="none" pos="word" start_char="5143">and</TOKEN>
<TOKEN end_char="5153" id="token-41-38" morph="none" pos="word" start_char="5147">growing</TOKEN>
<TOKEN end_char="5154" id="token-41-39" morph="none" pos="punct" start_char="5154">.</TOKEN>
</SEG>
<SEG end_char="5267" id="segment-42" start_char="5156">
<ORIGINAL_TEXT>This is big money and obviously no company wants their products to be viewed as more likely to make people sick.</ORIGINAL_TEXT>
<TOKEN end_char="5159" id="token-42-0" morph="none" pos="word" start_char="5156">This</TOKEN>
<TOKEN end_char="5162" id="token-42-1" morph="none" pos="word" start_char="5161">is</TOKEN>
<TOKEN end_char="5166" id="token-42-2" morph="none" pos="word" start_char="5164">big</TOKEN>
<TOKEN end_char="5172" id="token-42-3" morph="none" pos="word" start_char="5168">money</TOKEN>
<TOKEN end_char="5176" id="token-42-4" morph="none" pos="word" start_char="5174">and</TOKEN>
<TOKEN end_char="5186" id="token-42-5" morph="none" pos="word" start_char="5178">obviously</TOKEN>
<TOKEN end_char="5189" id="token-42-6" morph="none" pos="word" start_char="5188">no</TOKEN>
<TOKEN end_char="5197" id="token-42-7" morph="none" pos="word" start_char="5191">company</TOKEN>
<TOKEN end_char="5203" id="token-42-8" morph="none" pos="word" start_char="5199">wants</TOKEN>
<TOKEN end_char="5209" id="token-42-9" morph="none" pos="word" start_char="5205">their</TOKEN>
<TOKEN end_char="5218" id="token-42-10" morph="none" pos="word" start_char="5211">products</TOKEN>
<TOKEN end_char="5221" id="token-42-11" morph="none" pos="word" start_char="5220">to</TOKEN>
<TOKEN end_char="5224" id="token-42-12" morph="none" pos="word" start_char="5223">be</TOKEN>
<TOKEN end_char="5231" id="token-42-13" morph="none" pos="word" start_char="5226">viewed</TOKEN>
<TOKEN end_char="5234" id="token-42-14" morph="none" pos="word" start_char="5233">as</TOKEN>
<TOKEN end_char="5239" id="token-42-15" morph="none" pos="word" start_char="5236">more</TOKEN>
<TOKEN end_char="5246" id="token-42-16" morph="none" pos="word" start_char="5241">likely</TOKEN>
<TOKEN end_char="5249" id="token-42-17" morph="none" pos="word" start_char="5248">to</TOKEN>
<TOKEN end_char="5254" id="token-42-18" morph="none" pos="word" start_char="5251">make</TOKEN>
<TOKEN end_char="5261" id="token-42-19" morph="none" pos="word" start_char="5256">people</TOKEN>
<TOKEN end_char="5266" id="token-42-20" morph="none" pos="word" start_char="5263">sick</TOKEN>
<TOKEN end_char="5267" id="token-42-21" morph="none" pos="punct" start_char="5267">.</TOKEN>
</SEG>
<SEG end_char="5404" id="segment-43" start_char="5269">
<ORIGINAL_TEXT>Dyson has made the case that, while other brands of hand dryers might spread disease, its products are perfectly safe even in hospitals.</ORIGINAL_TEXT>
<TOKEN end_char="5273" id="token-43-0" morph="none" pos="word" start_char="5269">Dyson</TOKEN>
<TOKEN end_char="5277" id="token-43-1" morph="none" pos="word" start_char="5275">has</TOKEN>
<TOKEN end_char="5282" id="token-43-2" morph="none" pos="word" start_char="5279">made</TOKEN>
<TOKEN end_char="5286" id="token-43-3" morph="none" pos="word" start_char="5284">the</TOKEN>
<TOKEN end_char="5291" id="token-43-4" morph="none" pos="word" start_char="5288">case</TOKEN>
<TOKEN end_char="5296" id="token-43-5" morph="none" pos="word" start_char="5293">that</TOKEN>
<TOKEN end_char="5297" id="token-43-6" morph="none" pos="punct" start_char="5297">,</TOKEN>
<TOKEN end_char="5303" id="token-43-7" morph="none" pos="word" start_char="5299">while</TOKEN>
<TOKEN end_char="5309" id="token-43-8" morph="none" pos="word" start_char="5305">other</TOKEN>
<TOKEN end_char="5316" id="token-43-9" morph="none" pos="word" start_char="5311">brands</TOKEN>
<TOKEN end_char="5319" id="token-43-10" morph="none" pos="word" start_char="5318">of</TOKEN>
<TOKEN end_char="5324" id="token-43-11" morph="none" pos="word" start_char="5321">hand</TOKEN>
<TOKEN end_char="5331" id="token-43-12" morph="none" pos="word" start_char="5326">dryers</TOKEN>
<TOKEN end_char="5337" id="token-43-13" morph="none" pos="word" start_char="5333">might</TOKEN>
<TOKEN end_char="5344" id="token-43-14" morph="none" pos="word" start_char="5339">spread</TOKEN>
<TOKEN end_char="5352" id="token-43-15" morph="none" pos="word" start_char="5346">disease</TOKEN>
<TOKEN end_char="5353" id="token-43-16" morph="none" pos="punct" start_char="5353">,</TOKEN>
<TOKEN end_char="5357" id="token-43-17" morph="none" pos="word" start_char="5355">its</TOKEN>
<TOKEN end_char="5366" id="token-43-18" morph="none" pos="word" start_char="5359">products</TOKEN>
<TOKEN end_char="5370" id="token-43-19" morph="none" pos="word" start_char="5368">are</TOKEN>
<TOKEN end_char="5380" id="token-43-20" morph="none" pos="word" start_char="5372">perfectly</TOKEN>
<TOKEN end_char="5385" id="token-43-21" morph="none" pos="word" start_char="5382">safe</TOKEN>
<TOKEN end_char="5390" id="token-43-22" morph="none" pos="word" start_char="5387">even</TOKEN>
<TOKEN end_char="5393" id="token-43-23" morph="none" pos="word" start_char="5392">in</TOKEN>
<TOKEN end_char="5403" id="token-43-24" morph="none" pos="word" start_char="5395">hospitals</TOKEN>
<TOKEN end_char="5404" id="token-43-25" morph="none" pos="punct" start_char="5404">.</TOKEN>
</SEG>
<SEG end_char="5587" id="segment-44" start_char="5406">
<ORIGINAL_TEXT>Karen Holeyman, lead research scientist and microbiologist at Dyson, also notes via email that "Dyson Airblade™ hand dryers are proven hygienic," and referred to its HEPA air filter.</ORIGINAL_TEXT>
<TOKEN end_char="5410" id="token-44-0" morph="none" pos="word" start_char="5406">Karen</TOKEN>
<TOKEN end_char="5419" id="token-44-1" morph="none" pos="word" start_char="5412">Holeyman</TOKEN>
<TOKEN end_char="5420" id="token-44-2" morph="none" pos="punct" start_char="5420">,</TOKEN>
<TOKEN end_char="5425" id="token-44-3" morph="none" pos="word" start_char="5422">lead</TOKEN>
<TOKEN end_char="5434" id="token-44-4" morph="none" pos="word" start_char="5427">research</TOKEN>
<TOKEN end_char="5444" id="token-44-5" morph="none" pos="word" start_char="5436">scientist</TOKEN>
<TOKEN end_char="5448" id="token-44-6" morph="none" pos="word" start_char="5446">and</TOKEN>
<TOKEN end_char="5463" id="token-44-7" morph="none" pos="word" start_char="5450">microbiologist</TOKEN>
<TOKEN end_char="5466" id="token-44-8" morph="none" pos="word" start_char="5465">at</TOKEN>
<TOKEN end_char="5472" id="token-44-9" morph="none" pos="word" start_char="5468">Dyson</TOKEN>
<TOKEN end_char="5473" id="token-44-10" morph="none" pos="punct" start_char="5473">,</TOKEN>
<TOKEN end_char="5478" id="token-44-11" morph="none" pos="word" start_char="5475">also</TOKEN>
<TOKEN end_char="5484" id="token-44-12" morph="none" pos="word" start_char="5480">notes</TOKEN>
<TOKEN end_char="5488" id="token-44-13" morph="none" pos="word" start_char="5486">via</TOKEN>
<TOKEN end_char="5494" id="token-44-14" morph="none" pos="word" start_char="5490">email</TOKEN>
<TOKEN end_char="5499" id="token-44-15" morph="none" pos="word" start_char="5496">that</TOKEN>
<TOKEN end_char="5501" id="token-44-16" morph="none" pos="punct" start_char="5501">"</TOKEN>
<TOKEN end_char="5506" id="token-44-17" morph="none" pos="word" start_char="5502">Dyson</TOKEN>
<TOKEN end_char="5516" id="token-44-18" morph="none" pos="unknown" start_char="5508">Airblade™</TOKEN>
<TOKEN end_char="5521" id="token-44-19" morph="none" pos="word" start_char="5518">hand</TOKEN>
<TOKEN end_char="5528" id="token-44-20" morph="none" pos="word" start_char="5523">dryers</TOKEN>
<TOKEN end_char="5532" id="token-44-21" morph="none" pos="word" start_char="5530">are</TOKEN>
<TOKEN end_char="5539" id="token-44-22" morph="none" pos="word" start_char="5534">proven</TOKEN>
<TOKEN end_char="5548" id="token-44-23" morph="none" pos="word" start_char="5541">hygienic</TOKEN>
<TOKEN end_char="5550" id="token-44-24" morph="none" pos="punct" start_char="5549">,"</TOKEN>
<TOKEN end_char="5554" id="token-44-25" morph="none" pos="word" start_char="5552">and</TOKEN>
<TOKEN end_char="5563" id="token-44-26" morph="none" pos="word" start_char="5556">referred</TOKEN>
<TOKEN end_char="5566" id="token-44-27" morph="none" pos="word" start_char="5565">to</TOKEN>
<TOKEN end_char="5570" id="token-44-28" morph="none" pos="word" start_char="5568">its</TOKEN>
<TOKEN end_char="5575" id="token-44-29" morph="none" pos="word" start_char="5572">HEPA</TOKEN>
<TOKEN end_char="5579" id="token-44-30" morph="none" pos="word" start_char="5577">air</TOKEN>
<TOKEN end_char="5586" id="token-44-31" morph="none" pos="word" start_char="5581">filter</TOKEN>
<TOKEN end_char="5587" id="token-44-32" morph="none" pos="punct" start_char="5587">.</TOKEN>
</SEG>
<SEG end_char="5687" id="segment-45" start_char="5590">
<ORIGINAL_TEXT>Yet it’s hard to read the scientific papers without concluding that, well, paper is the way to go.</ORIGINAL_TEXT>
<TOKEN end_char="5592" id="token-45-0" morph="none" pos="word" start_char="5590">Yet</TOKEN>
<TOKEN end_char="5597" id="token-45-1" morph="none" pos="word" start_char="5594">it’s</TOKEN>
<TOKEN end_char="5602" id="token-45-2" morph="none" pos="word" start_char="5599">hard</TOKEN>
<TOKEN end_char="5605" id="token-45-3" morph="none" pos="word" start_char="5604">to</TOKEN>
<TOKEN end_char="5610" id="token-45-4" morph="none" pos="word" start_char="5607">read</TOKEN>
<TOKEN end_char="5614" id="token-45-5" morph="none" pos="word" start_char="5612">the</TOKEN>
<TOKEN end_char="5625" id="token-45-6" morph="none" pos="word" start_char="5616">scientific</TOKEN>
<TOKEN end_char="5632" id="token-45-7" morph="none" pos="word" start_char="5627">papers</TOKEN>
<TOKEN end_char="5640" id="token-45-8" morph="none" pos="word" start_char="5634">without</TOKEN>
<TOKEN end_char="5651" id="token-45-9" morph="none" pos="word" start_char="5642">concluding</TOKEN>
<TOKEN end_char="5656" id="token-45-10" morph="none" pos="word" start_char="5653">that</TOKEN>
<TOKEN end_char="5657" id="token-45-11" morph="none" pos="punct" start_char="5657">,</TOKEN>
<TOKEN end_char="5662" id="token-45-12" morph="none" pos="word" start_char="5659">well</TOKEN>
<TOKEN end_char="5663" id="token-45-13" morph="none" pos="punct" start_char="5663">,</TOKEN>
<TOKEN end_char="5669" id="token-45-14" morph="none" pos="word" start_char="5665">paper</TOKEN>
<TOKEN end_char="5672" id="token-45-15" morph="none" pos="word" start_char="5671">is</TOKEN>
<TOKEN end_char="5676" id="token-45-16" morph="none" pos="word" start_char="5674">the</TOKEN>
<TOKEN end_char="5680" id="token-45-17" morph="none" pos="word" start_char="5678">way</TOKEN>
<TOKEN end_char="5683" id="token-45-18" morph="none" pos="word" start_char="5682">to</TOKEN>
<TOKEN end_char="5686" id="token-45-19" morph="none" pos="word" start_char="5685">go</TOKEN>
<TOKEN end_char="5687" id="token-45-20" morph="none" pos="punct" start_char="5687">.</TOKEN>
</SEG>
<SEG end_char="5818" id="segment-46" start_char="5689">
<ORIGINAL_TEXT>If the science seems to lean in that direction, though, why have electric dryers continued to claim more and more tiled territory?</ORIGINAL_TEXT>
<TOKEN end_char="5690" id="token-46-0" morph="none" pos="word" start_char="5689">If</TOKEN>
<TOKEN end_char="5694" id="token-46-1" morph="none" pos="word" start_char="5692">the</TOKEN>
<TOKEN end_char="5702" id="token-46-2" morph="none" pos="word" start_char="5696">science</TOKEN>
<TOKEN end_char="5708" id="token-46-3" morph="none" pos="word" start_char="5704">seems</TOKEN>
<TOKEN end_char="5711" id="token-46-4" morph="none" pos="word" start_char="5710">to</TOKEN>
<TOKEN end_char="5716" id="token-46-5" morph="none" pos="word" start_char="5713">lean</TOKEN>
<TOKEN end_char="5719" id="token-46-6" morph="none" pos="word" start_char="5718">in</TOKEN>
<TOKEN end_char="5724" id="token-46-7" morph="none" pos="word" start_char="5721">that</TOKEN>
<TOKEN end_char="5734" id="token-46-8" morph="none" pos="word" start_char="5726">direction</TOKEN>
<TOKEN end_char="5735" id="token-46-9" morph="none" pos="punct" start_char="5735">,</TOKEN>
<TOKEN end_char="5742" id="token-46-10" morph="none" pos="word" start_char="5737">though</TOKEN>
<TOKEN end_char="5743" id="token-46-11" morph="none" pos="punct" start_char="5743">,</TOKEN>
<TOKEN end_char="5747" id="token-46-12" morph="none" pos="word" start_char="5745">why</TOKEN>
<TOKEN end_char="5752" id="token-46-13" morph="none" pos="word" start_char="5749">have</TOKEN>
<TOKEN end_char="5761" id="token-46-14" morph="none" pos="word" start_char="5754">electric</TOKEN>
<TOKEN end_char="5768" id="token-46-15" morph="none" pos="word" start_char="5763">dryers</TOKEN>
<TOKEN end_char="5778" id="token-46-16" morph="none" pos="word" start_char="5770">continued</TOKEN>
<TOKEN end_char="5781" id="token-46-17" morph="none" pos="word" start_char="5780">to</TOKEN>
<TOKEN end_char="5787" id="token-46-18" morph="none" pos="word" start_char="5783">claim</TOKEN>
<TOKEN end_char="5792" id="token-46-19" morph="none" pos="word" start_char="5789">more</TOKEN>
<TOKEN end_char="5796" id="token-46-20" morph="none" pos="word" start_char="5794">and</TOKEN>
<TOKEN end_char="5801" id="token-46-21" morph="none" pos="word" start_char="5798">more</TOKEN>
<TOKEN end_char="5807" id="token-46-22" morph="none" pos="word" start_char="5803">tiled</TOKEN>
<TOKEN end_char="5817" id="token-46-23" morph="none" pos="word" start_char="5809">territory</TOKEN>
<TOKEN end_char="5818" id="token-46-24" morph="none" pos="punct" start_char="5818">?</TOKEN>
</SEG>
<SEG end_char="5865" id="segment-47" start_char="5820">
<ORIGINAL_TEXT>For starters, they do have undeniable upsides.</ORIGINAL_TEXT>
<TOKEN end_char="5822" id="token-47-0" morph="none" pos="word" start_char="5820">For</TOKEN>
<TOKEN end_char="5831" id="token-47-1" morph="none" pos="word" start_char="5824">starters</TOKEN>
<TOKEN end_char="5832" id="token-47-2" morph="none" pos="punct" start_char="5832">,</TOKEN>
<TOKEN end_char="5837" id="token-47-3" morph="none" pos="word" start_char="5834">they</TOKEN>
<TOKEN end_char="5840" id="token-47-4" morph="none" pos="word" start_char="5839">do</TOKEN>
<TOKEN end_char="5845" id="token-47-5" morph="none" pos="word" start_char="5842">have</TOKEN>
<TOKEN end_char="5856" id="token-47-6" morph="none" pos="word" start_char="5847">undeniable</TOKEN>
<TOKEN end_char="5864" id="token-47-7" morph="none" pos="word" start_char="5858">upsides</TOKEN>
<TOKEN end_char="5865" id="token-47-8" morph="none" pos="punct" start_char="5865">.</TOKEN>
</SEG>
<SEG end_char="5960" id="segment-48" start_char="5867">
<ORIGINAL_TEXT>Unlike paper towels, hand dryers don’t create waste and they’re drastically cheaper over time.</ORIGINAL_TEXT>
<TOKEN end_char="5872" id="token-48-0" morph="none" pos="word" start_char="5867">Unlike</TOKEN>
<TOKEN end_char="5878" id="token-48-1" morph="none" pos="word" start_char="5874">paper</TOKEN>
<TOKEN end_char="5885" id="token-48-2" morph="none" pos="word" start_char="5880">towels</TOKEN>
<TOKEN end_char="5886" id="token-48-3" morph="none" pos="punct" start_char="5886">,</TOKEN>
<TOKEN end_char="5891" id="token-48-4" morph="none" pos="word" start_char="5888">hand</TOKEN>
<TOKEN end_char="5898" id="token-48-5" morph="none" pos="word" start_char="5893">dryers</TOKEN>
<TOKEN end_char="5904" id="token-48-6" morph="none" pos="word" start_char="5900">don’t</TOKEN>
<TOKEN end_char="5911" id="token-48-7" morph="none" pos="word" start_char="5906">create</TOKEN>
<TOKEN end_char="5917" id="token-48-8" morph="none" pos="word" start_char="5913">waste</TOKEN>
<TOKEN end_char="5921" id="token-48-9" morph="none" pos="word" start_char="5919">and</TOKEN>
<TOKEN end_char="5929" id="token-48-10" morph="none" pos="word" start_char="5923">they’re</TOKEN>
<TOKEN end_char="5941" id="token-48-11" morph="none" pos="word" start_char="5931">drastically</TOKEN>
<TOKEN end_char="5949" id="token-48-12" morph="none" pos="word" start_char="5943">cheaper</TOKEN>
<TOKEN end_char="5954" id="token-48-13" morph="none" pos="word" start_char="5951">over</TOKEN>
<TOKEN end_char="5959" id="token-48-14" morph="none" pos="word" start_char="5956">time</TOKEN>
<TOKEN end_char="5960" id="token-48-15" morph="none" pos="punct" start_char="5960">.</TOKEN>
</SEG>
<SEG end_char="6156" id="segment-49" start_char="5962">
<ORIGINAL_TEXT>The annual cost for paper towels in a public restroom can easily top a thousand dollars, while the electricity required to run a hand dryer costs about a fifth of that, according to one estimate.</ORIGINAL_TEXT>
<TOKEN end_char="5964" id="token-49-0" morph="none" pos="word" start_char="5962">The</TOKEN>
<TOKEN end_char="5971" id="token-49-1" morph="none" pos="word" start_char="5966">annual</TOKEN>
<TOKEN end_char="5976" id="token-49-2" morph="none" pos="word" start_char="5973">cost</TOKEN>
<TOKEN end_char="5980" id="token-49-3" morph="none" pos="word" start_char="5978">for</TOKEN>
<TOKEN end_char="5986" id="token-49-4" morph="none" pos="word" start_char="5982">paper</TOKEN>
<TOKEN end_char="5993" id="token-49-5" morph="none" pos="word" start_char="5988">towels</TOKEN>
<TOKEN end_char="5996" id="token-49-6" morph="none" pos="word" start_char="5995">in</TOKEN>
<TOKEN end_char="5998" id="token-49-7" morph="none" pos="word" start_char="5998">a</TOKEN>
<TOKEN end_char="6005" id="token-49-8" morph="none" pos="word" start_char="6000">public</TOKEN>
<TOKEN end_char="6014" id="token-49-9" morph="none" pos="word" start_char="6007">restroom</TOKEN>
<TOKEN end_char="6018" id="token-49-10" morph="none" pos="word" start_char="6016">can</TOKEN>
<TOKEN end_char="6025" id="token-49-11" morph="none" pos="word" start_char="6020">easily</TOKEN>
<TOKEN end_char="6029" id="token-49-12" morph="none" pos="word" start_char="6027">top</TOKEN>
<TOKEN end_char="6031" id="token-49-13" morph="none" pos="word" start_char="6031">a</TOKEN>
<TOKEN end_char="6040" id="token-49-14" morph="none" pos="word" start_char="6033">thousand</TOKEN>
<TOKEN end_char="6048" id="token-49-15" morph="none" pos="word" start_char="6042">dollars</TOKEN>
<TOKEN end_char="6049" id="token-49-16" morph="none" pos="punct" start_char="6049">,</TOKEN>
<TOKEN end_char="6055" id="token-49-17" morph="none" pos="word" start_char="6051">while</TOKEN>
<TOKEN end_char="6059" id="token-49-18" morph="none" pos="word" start_char="6057">the</TOKEN>
<TOKEN end_char="6071" id="token-49-19" morph="none" pos="word" start_char="6061">electricity</TOKEN>
<TOKEN end_char="6080" id="token-49-20" morph="none" pos="word" start_char="6073">required</TOKEN>
<TOKEN end_char="6083" id="token-49-21" morph="none" pos="word" start_char="6082">to</TOKEN>
<TOKEN end_char="6087" id="token-49-22" morph="none" pos="word" start_char="6085">run</TOKEN>
<TOKEN end_char="6089" id="token-49-23" morph="none" pos="word" start_char="6089">a</TOKEN>
<TOKEN end_char="6094" id="token-49-24" morph="none" pos="word" start_char="6091">hand</TOKEN>
<TOKEN end_char="6100" id="token-49-25" morph="none" pos="word" start_char="6096">dryer</TOKEN>
<TOKEN end_char="6106" id="token-49-26" morph="none" pos="word" start_char="6102">costs</TOKEN>
<TOKEN end_char="6112" id="token-49-27" morph="none" pos="word" start_char="6108">about</TOKEN>
<TOKEN end_char="6114" id="token-49-28" morph="none" pos="word" start_char="6114">a</TOKEN>
<TOKEN end_char="6120" id="token-49-29" morph="none" pos="word" start_char="6116">fifth</TOKEN>
<TOKEN end_char="6123" id="token-49-30" morph="none" pos="word" start_char="6122">of</TOKEN>
<TOKEN end_char="6128" id="token-49-31" morph="none" pos="word" start_char="6125">that</TOKEN>
<TOKEN end_char="6129" id="token-49-32" morph="none" pos="punct" start_char="6129">,</TOKEN>
<TOKEN end_char="6139" id="token-49-33" morph="none" pos="word" start_char="6131">according</TOKEN>
<TOKEN end_char="6142" id="token-49-34" morph="none" pos="word" start_char="6141">to</TOKEN>
<TOKEN end_char="6146" id="token-49-35" morph="none" pos="word" start_char="6144">one</TOKEN>
<TOKEN end_char="6155" id="token-49-36" morph="none" pos="word" start_char="6148">estimate</TOKEN>
<TOKEN end_char="6156" id="token-49-37" morph="none" pos="punct" start_char="6156">.</TOKEN>
</SEG>
<SEG end_char="6268" id="segment-50" start_char="6159">
<ORIGINAL_TEXT>But focusing on paper towel prices seems a little ridiculous when epidemiologists are calculating death rates.</ORIGINAL_TEXT>
<TOKEN end_char="6161" id="token-50-0" morph="none" pos="word" start_char="6159">But</TOKEN>
<TOKEN end_char="6170" id="token-50-1" morph="none" pos="word" start_char="6163">focusing</TOKEN>
<TOKEN end_char="6173" id="token-50-2" morph="none" pos="word" start_char="6172">on</TOKEN>
<TOKEN end_char="6179" id="token-50-3" morph="none" pos="word" start_char="6175">paper</TOKEN>
<TOKEN end_char="6185" id="token-50-4" morph="none" pos="word" start_char="6181">towel</TOKEN>
<TOKEN end_char="6192" id="token-50-5" morph="none" pos="word" start_char="6187">prices</TOKEN>
<TOKEN end_char="6198" id="token-50-6" morph="none" pos="word" start_char="6194">seems</TOKEN>
<TOKEN end_char="6200" id="token-50-7" morph="none" pos="word" start_char="6200">a</TOKEN>
<TOKEN end_char="6207" id="token-50-8" morph="none" pos="word" start_char="6202">little</TOKEN>
<TOKEN end_char="6218" id="token-50-9" morph="none" pos="word" start_char="6209">ridiculous</TOKEN>
<TOKEN end_char="6223" id="token-50-10" morph="none" pos="word" start_char="6220">when</TOKEN>
<TOKEN end_char="6239" id="token-50-11" morph="none" pos="word" start_char="6225">epidemiologists</TOKEN>
<TOKEN end_char="6243" id="token-50-12" morph="none" pos="word" start_char="6241">are</TOKEN>
<TOKEN end_char="6255" id="token-50-13" morph="none" pos="word" start_char="6245">calculating</TOKEN>
<TOKEN end_char="6261" id="token-50-14" morph="none" pos="word" start_char="6257">death</TOKEN>
<TOKEN end_char="6267" id="token-50-15" morph="none" pos="word" start_char="6263">rates</TOKEN>
<TOKEN end_char="6268" id="token-50-16" morph="none" pos="punct" start_char="6268">.</TOKEN>
</SEG>
<SEG end_char="6334" id="segment-51" start_char="6270">
<ORIGINAL_TEXT>We’re at a moment when hand-washing must be taken very seriously.</ORIGINAL_TEXT>
<TOKEN end_char="6274" id="token-51-0" morph="none" pos="word" start_char="6270">We’re</TOKEN>
<TOKEN end_char="6277" id="token-51-1" morph="none" pos="word" start_char="6276">at</TOKEN>
<TOKEN end_char="6279" id="token-51-2" morph="none" pos="word" start_char="6279">a</TOKEN>
<TOKEN end_char="6286" id="token-51-3" morph="none" pos="word" start_char="6281">moment</TOKEN>
<TOKEN end_char="6291" id="token-51-4" morph="none" pos="word" start_char="6288">when</TOKEN>
<TOKEN end_char="6304" id="token-51-5" morph="none" pos="unknown" start_char="6293">hand-washing</TOKEN>
<TOKEN end_char="6309" id="token-51-6" morph="none" pos="word" start_char="6306">must</TOKEN>
<TOKEN end_char="6312" id="token-51-7" morph="none" pos="word" start_char="6311">be</TOKEN>
<TOKEN end_char="6318" id="token-51-8" morph="none" pos="word" start_char="6314">taken</TOKEN>
<TOKEN end_char="6323" id="token-51-9" morph="none" pos="word" start_char="6320">very</TOKEN>
<TOKEN end_char="6333" id="token-51-10" morph="none" pos="word" start_char="6325">seriously</TOKEN>
<TOKEN end_char="6334" id="token-51-11" morph="none" pos="punct" start_char="6334">.</TOKEN>
</SEG>
<SEG end_char="6368" id="segment-52" start_char="6336">
<ORIGINAL_TEXT>The same is true for hand-drying.</ORIGINAL_TEXT>
<TOKEN end_char="6338" id="token-52-0" morph="none" pos="word" start_char="6336">The</TOKEN>
<TOKEN end_char="6343" id="token-52-1" morph="none" pos="word" start_char="6340">same</TOKEN>
<TOKEN end_char="6346" id="token-52-2" morph="none" pos="word" start_char="6345">is</TOKEN>
<TOKEN end_char="6351" id="token-52-3" morph="none" pos="word" start_char="6348">true</TOKEN>
<TOKEN end_char="6355" id="token-52-4" morph="none" pos="word" start_char="6353">for</TOKEN>
<TOKEN end_char="6367" id="token-52-5" morph="none" pos="unknown" start_char="6357">hand-drying</TOKEN>
<TOKEN end_char="6368" id="token-52-6" morph="none" pos="punct" start_char="6368">.</TOKEN>
</SEG>
<SEG end_char="6506" id="segment-53" start_char="6370">
<ORIGINAL_TEXT>Electric hand dryers appear to be a modern, more responsible solution to an everyday problem—but one that may not live up to its billing.</ORIGINAL_TEXT>
<TOKEN end_char="6377" id="token-53-0" morph="none" pos="word" start_char="6370">Electric</TOKEN>
<TOKEN end_char="6382" id="token-53-1" morph="none" pos="word" start_char="6379">hand</TOKEN>
<TOKEN end_char="6389" id="token-53-2" morph="none" pos="word" start_char="6384">dryers</TOKEN>
<TOKEN end_char="6396" id="token-53-3" morph="none" pos="word" start_char="6391">appear</TOKEN>
<TOKEN end_char="6399" id="token-53-4" morph="none" pos="word" start_char="6398">to</TOKEN>
<TOKEN end_char="6402" id="token-53-5" morph="none" pos="word" start_char="6401">be</TOKEN>
<TOKEN end_char="6404" id="token-53-6" morph="none" pos="word" start_char="6404">a</TOKEN>
<TOKEN end_char="6411" id="token-53-7" morph="none" pos="word" start_char="6406">modern</TOKEN>
<TOKEN end_char="6412" id="token-53-8" morph="none" pos="punct" start_char="6412">,</TOKEN>
<TOKEN end_char="6417" id="token-53-9" morph="none" pos="word" start_char="6414">more</TOKEN>
<TOKEN end_char="6429" id="token-53-10" morph="none" pos="word" start_char="6419">responsible</TOKEN>
<TOKEN end_char="6438" id="token-53-11" morph="none" pos="word" start_char="6431">solution</TOKEN>
<TOKEN end_char="6441" id="token-53-12" morph="none" pos="word" start_char="6440">to</TOKEN>
<TOKEN end_char="6444" id="token-53-13" morph="none" pos="word" start_char="6443">an</TOKEN>
<TOKEN end_char="6453" id="token-53-14" morph="none" pos="word" start_char="6446">everyday</TOKEN>
<TOKEN end_char="6465" id="token-53-15" morph="none" pos="unknown" start_char="6455">problem—but</TOKEN>
<TOKEN end_char="6469" id="token-53-16" morph="none" pos="word" start_char="6467">one</TOKEN>
<TOKEN end_char="6474" id="token-53-17" morph="none" pos="word" start_char="6471">that</TOKEN>
<TOKEN end_char="6478" id="token-53-18" morph="none" pos="word" start_char="6476">may</TOKEN>
<TOKEN end_char="6482" id="token-53-19" morph="none" pos="word" start_char="6480">not</TOKEN>
<TOKEN end_char="6487" id="token-53-20" morph="none" pos="word" start_char="6484">live</TOKEN>
<TOKEN end_char="6490" id="token-53-21" morph="none" pos="word" start_char="6489">up</TOKEN>
<TOKEN end_char="6493" id="token-53-22" morph="none" pos="word" start_char="6492">to</TOKEN>
<TOKEN end_char="6497" id="token-53-23" morph="none" pos="word" start_char="6495">its</TOKEN>
<TOKEN end_char="6505" id="token-53-24" morph="none" pos="word" start_char="6499">billing</TOKEN>
<TOKEN end_char="6506" id="token-53-25" morph="none" pos="punct" start_char="6506">.</TOKEN>
</SEG>
<SEG end_char="6551" id="segment-54" start_char="6510">
<ORIGINAL_TEXT>Read all of our coronavirus coverage here.</ORIGINAL_TEXT>
<TOKEN end_char="6513" id="token-54-0" morph="none" pos="word" start_char="6510">Read</TOKEN>
<TOKEN end_char="6517" id="token-54-1" morph="none" pos="word" start_char="6515">all</TOKEN>
<TOKEN end_char="6520" id="token-54-2" morph="none" pos="word" start_char="6519">of</TOKEN>
<TOKEN end_char="6524" id="token-54-3" morph="none" pos="word" start_char="6522">our</TOKEN>
<TOKEN end_char="6536" id="token-54-4" morph="none" pos="word" start_char="6526">coronavirus</TOKEN>
<TOKEN end_char="6545" id="token-54-5" morph="none" pos="word" start_char="6538">coverage</TOKEN>
<TOKEN end_char="6550" id="token-54-6" morph="none" pos="word" start_char="6547">here</TOKEN>
<TOKEN end_char="6551" id="token-54-7" morph="none" pos="punct" start_char="6551">.</TOKEN>
</SEG>
<SEG end_char="6680" id="segment-55" start_char="6554">
<ORIGINAL_TEXT>Updated 3/12/2020 5:25pm EST: This story has been updated to include comment from Dyson; to clarify that the 2012 analysis from</ORIGINAL_TEXT>
<TOKEN end_char="6560" id="token-55-0" morph="none" pos="word" start_char="6554">Updated</TOKEN>
<TOKEN end_char="6570" id="token-55-1" morph="none" pos="unknown" start_char="6562">3/12/2020</TOKEN>
<TOKEN end_char="6577" id="token-55-2" morph="none" pos="unknown" start_char="6572">5:25pm</TOKEN>
<TOKEN end_char="6581" id="token-55-3" morph="none" pos="word" start_char="6579">EST</TOKEN>
<TOKEN end_char="6582" id="token-55-4" morph="none" pos="punct" start_char="6582">:</TOKEN>
<TOKEN end_char="6587" id="token-55-5" morph="none" pos="word" start_char="6584">This</TOKEN>
<TOKEN end_char="6593" id="token-55-6" morph="none" pos="word" start_char="6589">story</TOKEN>
<TOKEN end_char="6597" id="token-55-7" morph="none" pos="word" start_char="6595">has</TOKEN>
<TOKEN end_char="6602" id="token-55-8" morph="none" pos="word" start_char="6599">been</TOKEN>
<TOKEN end_char="6610" id="token-55-9" morph="none" pos="word" start_char="6604">updated</TOKEN>
<TOKEN end_char="6613" id="token-55-10" morph="none" pos="word" start_char="6612">to</TOKEN>
<TOKEN end_char="6621" id="token-55-11" morph="none" pos="word" start_char="6615">include</TOKEN>
<TOKEN end_char="6629" id="token-55-12" morph="none" pos="word" start_char="6623">comment</TOKEN>
<TOKEN end_char="6634" id="token-55-13" morph="none" pos="word" start_char="6631">from</TOKEN>
<TOKEN end_char="6640" id="token-55-14" morph="none" pos="word" start_char="6636">Dyson</TOKEN>
<TOKEN end_char="6641" id="token-55-15" morph="none" pos="punct" start_char="6641">;</TOKEN>
<TOKEN end_char="6644" id="token-55-16" morph="none" pos="word" start_char="6643">to</TOKEN>
<TOKEN end_char="6652" id="token-55-17" morph="none" pos="word" start_char="6646">clarify</TOKEN>
<TOKEN end_char="6657" id="token-55-18" morph="none" pos="word" start_char="6654">that</TOKEN>
<TOKEN end_char="6661" id="token-55-19" morph="none" pos="word" start_char="6659">the</TOKEN>
<TOKEN end_char="6666" id="token-55-20" morph="none" pos="word" start_char="6663">2012</TOKEN>
<TOKEN end_char="6675" id="token-55-21" morph="none" pos="word" start_char="6668">analysis</TOKEN>
<TOKEN end_char="6680" id="token-55-22" morph="none" pos="word" start_char="6677">from</TOKEN>
</SEG>
<SEG end_char="6705" id="segment-56" start_char="6683">
<ORIGINAL_TEXT>Mayo Clinic Proceedings</ORIGINAL_TEXT>
<TOKEN end_char="6686" id="token-56-0" morph="none" pos="word" start_char="6683">Mayo</TOKEN>
<TOKEN end_char="6693" id="token-56-1" morph="none" pos="word" start_char="6688">Clinic</TOKEN>
<TOKEN end_char="6705" id="token-56-2" morph="none" pos="word" start_char="6695">Proceedings</TOKEN>
</SEG>
<SEG end_char="6972" id="segment-57" start_char="6708">
<ORIGINAL_TEXT>found that high-speed air dryers "led to much less bacterial transfer than hot air dryers," and that the 2018 study referenced tested conventional hot-air dryers; and to remove any implication that drying hands on pants may be more hygienic than using a hand dryer.</ORIGINAL_TEXT>
<TOKEN end_char="6712" id="token-57-0" morph="none" pos="word" start_char="6708">found</TOKEN>
<TOKEN end_char="6717" id="token-57-1" morph="none" pos="word" start_char="6714">that</TOKEN>
<TOKEN end_char="6728" id="token-57-2" morph="none" pos="unknown" start_char="6719">high-speed</TOKEN>
<TOKEN end_char="6732" id="token-57-3" morph="none" pos="word" start_char="6730">air</TOKEN>
<TOKEN end_char="6739" id="token-57-4" morph="none" pos="word" start_char="6734">dryers</TOKEN>
<TOKEN end_char="6741" id="token-57-5" morph="none" pos="punct" start_char="6741">"</TOKEN>
<TOKEN end_char="6744" id="token-57-6" morph="none" pos="word" start_char="6742">led</TOKEN>
<TOKEN end_char="6747" id="token-57-7" morph="none" pos="word" start_char="6746">to</TOKEN>
<TOKEN end_char="6752" id="token-57-8" morph="none" pos="word" start_char="6749">much</TOKEN>
<TOKEN end_char="6757" id="token-57-9" morph="none" pos="word" start_char="6754">less</TOKEN>
<TOKEN end_char="6767" id="token-57-10" morph="none" pos="word" start_char="6759">bacterial</TOKEN>
<TOKEN end_char="6776" id="token-57-11" morph="none" pos="word" start_char="6769">transfer</TOKEN>
<TOKEN end_char="6781" id="token-57-12" morph="none" pos="word" start_char="6778">than</TOKEN>
<TOKEN end_char="6785" id="token-57-13" morph="none" pos="word" start_char="6783">hot</TOKEN>
<TOKEN end_char="6789" id="token-57-14" morph="none" pos="word" start_char="6787">air</TOKEN>
<TOKEN end_char="6796" id="token-57-15" morph="none" pos="word" start_char="6791">dryers</TOKEN>
<TOKEN end_char="6798" id="token-57-16" morph="none" pos="punct" start_char="6797">,"</TOKEN>
<TOKEN end_char="6802" id="token-57-17" morph="none" pos="word" start_char="6800">and</TOKEN>
<TOKEN end_char="6807" id="token-57-18" morph="none" pos="word" start_char="6804">that</TOKEN>
<TOKEN end_char="6811" id="token-57-19" morph="none" pos="word" start_char="6809">the</TOKEN>
<TOKEN end_char="6816" id="token-57-20" morph="none" pos="word" start_char="6813">2018</TOKEN>
<TOKEN end_char="6822" id="token-57-21" morph="none" pos="word" start_char="6818">study</TOKEN>
<TOKEN end_char="6833" id="token-57-22" morph="none" pos="word" start_char="6824">referenced</TOKEN>
<TOKEN end_char="6840" id="token-57-23" morph="none" pos="word" start_char="6835">tested</TOKEN>
<TOKEN end_char="6853" id="token-57-24" morph="none" pos="word" start_char="6842">conventional</TOKEN>
<TOKEN end_char="6861" id="token-57-25" morph="none" pos="unknown" start_char="6855">hot-air</TOKEN>
<TOKEN end_char="6868" id="token-57-26" morph="none" pos="word" start_char="6863">dryers</TOKEN>
<TOKEN end_char="6869" id="token-57-27" morph="none" pos="punct" start_char="6869">;</TOKEN>
<TOKEN end_char="6873" id="token-57-28" morph="none" pos="word" start_char="6871">and</TOKEN>
<TOKEN end_char="6876" id="token-57-29" morph="none" pos="word" start_char="6875">to</TOKEN>
<TOKEN end_char="6883" id="token-57-30" morph="none" pos="word" start_char="6878">remove</TOKEN>
<TOKEN end_char="6887" id="token-57-31" morph="none" pos="word" start_char="6885">any</TOKEN>
<TOKEN end_char="6899" id="token-57-32" morph="none" pos="word" start_char="6889">implication</TOKEN>
<TOKEN end_char="6904" id="token-57-33" morph="none" pos="word" start_char="6901">that</TOKEN>
<TOKEN end_char="6911" id="token-57-34" morph="none" pos="word" start_char="6906">drying</TOKEN>
<TOKEN end_char="6917" id="token-57-35" morph="none" pos="word" start_char="6913">hands</TOKEN>
<TOKEN end_char="6920" id="token-57-36" morph="none" pos="word" start_char="6919">on</TOKEN>
<TOKEN end_char="6926" id="token-57-37" morph="none" pos="word" start_char="6922">pants</TOKEN>
<TOKEN end_char="6930" id="token-57-38" morph="none" pos="word" start_char="6928">may</TOKEN>
<TOKEN end_char="6933" id="token-57-39" morph="none" pos="word" start_char="6932">be</TOKEN>
<TOKEN end_char="6938" id="token-57-40" morph="none" pos="word" start_char="6935">more</TOKEN>
<TOKEN end_char="6947" id="token-57-41" morph="none" pos="word" start_char="6940">hygienic</TOKEN>
<TOKEN end_char="6952" id="token-57-42" morph="none" pos="word" start_char="6949">than</TOKEN>
<TOKEN end_char="6958" id="token-57-43" morph="none" pos="word" start_char="6954">using</TOKEN>
<TOKEN end_char="6960" id="token-57-44" morph="none" pos="word" start_char="6960">a</TOKEN>
<TOKEN end_char="6965" id="token-57-45" morph="none" pos="word" start_char="6962">hand</TOKEN>
<TOKEN end_char="6971" id="token-57-46" morph="none" pos="word" start_char="6967">dryer</TOKEN>
<TOKEN end_char="6972" id="token-57-47" morph="none" pos="punct" start_char="6972">.</TOKEN>
</SEG>
<SEG end_char="7030" id="segment-58" start_char="6974">
<ORIGINAL_TEXT>The language has been sharpened and clarified throughout.</ORIGINAL_TEXT>
<TOKEN end_char="6976" id="token-58-0" morph="none" pos="word" start_char="6974">The</TOKEN>
<TOKEN end_char="6985" id="token-58-1" morph="none" pos="word" start_char="6978">language</TOKEN>
<TOKEN end_char="6989" id="token-58-2" morph="none" pos="word" start_char="6987">has</TOKEN>
<TOKEN end_char="6994" id="token-58-3" morph="none" pos="word" start_char="6991">been</TOKEN>
<TOKEN end_char="7004" id="token-58-4" morph="none" pos="word" start_char="6996">sharpened</TOKEN>
<TOKEN end_char="7008" id="token-58-5" morph="none" pos="word" start_char="7006">and</TOKEN>
<TOKEN end_char="7018" id="token-58-6" morph="none" pos="word" start_char="7010">clarified</TOKEN>
<TOKEN end_char="7029" id="token-58-7" morph="none" pos="word" start_char="7020">throughout</TOKEN>
<TOKEN end_char="7030" id="token-58-8" morph="none" pos="punct" start_char="7030">.</TOKEN>
</SEG>
<SEG end_char="7402" id="segment-59" start_char="7033">
<ORIGINAL_TEXT>Updated 3/19/2020 5:20pm EST: Since this article was published, Dyson has provided the following statement: "Karen Holeyman, lead research scientist and microbiologist at Dyson, notes via email that ‘Dyson Airblade™ hand dryers are proven hygienic, and there is no scientific basis to suggest that our hand dryers spread pathogens or are less hygienic than paper towels.</ORIGINAL_TEXT>
<TOKEN end_char="7039" id="token-59-0" morph="none" pos="word" start_char="7033">Updated</TOKEN>
<TOKEN end_char="7049" id="token-59-1" morph="none" pos="unknown" start_char="7041">3/19/2020</TOKEN>
<TOKEN end_char="7056" id="token-59-2" morph="none" pos="unknown" start_char="7051">5:20pm</TOKEN>
<TOKEN end_char="7060" id="token-59-3" morph="none" pos="word" start_char="7058">EST</TOKEN>
<TOKEN end_char="7061" id="token-59-4" morph="none" pos="punct" start_char="7061">:</TOKEN>
<TOKEN end_char="7067" id="token-59-5" morph="none" pos="word" start_char="7063">Since</TOKEN>
<TOKEN end_char="7072" id="token-59-6" morph="none" pos="word" start_char="7069">this</TOKEN>
<TOKEN end_char="7080" id="token-59-7" morph="none" pos="word" start_char="7074">article</TOKEN>
<TOKEN end_char="7084" id="token-59-8" morph="none" pos="word" start_char="7082">was</TOKEN>
<TOKEN end_char="7094" id="token-59-9" morph="none" pos="word" start_char="7086">published</TOKEN>
<TOKEN end_char="7095" id="token-59-10" morph="none" pos="punct" start_char="7095">,</TOKEN>
<TOKEN end_char="7101" id="token-59-11" morph="none" pos="word" start_char="7097">Dyson</TOKEN>
<TOKEN end_char="7105" id="token-59-12" morph="none" pos="word" start_char="7103">has</TOKEN>
<TOKEN end_char="7114" id="token-59-13" morph="none" pos="word" start_char="7107">provided</TOKEN>
<TOKEN end_char="7118" id="token-59-14" morph="none" pos="word" start_char="7116">the</TOKEN>
<TOKEN end_char="7128" id="token-59-15" morph="none" pos="word" start_char="7120">following</TOKEN>
<TOKEN end_char="7138" id="token-59-16" morph="none" pos="word" start_char="7130">statement</TOKEN>
<TOKEN end_char="7139" id="token-59-17" morph="none" pos="punct" start_char="7139">:</TOKEN>
<TOKEN end_char="7141" id="token-59-18" morph="none" pos="punct" start_char="7141">"</TOKEN>
<TOKEN end_char="7146" id="token-59-19" morph="none" pos="word" start_char="7142">Karen</TOKEN>
<TOKEN end_char="7155" id="token-59-20" morph="none" pos="word" start_char="7148">Holeyman</TOKEN>
<TOKEN end_char="7156" id="token-59-21" morph="none" pos="punct" start_char="7156">,</TOKEN>
<TOKEN end_char="7161" id="token-59-22" morph="none" pos="word" start_char="7158">lead</TOKEN>
<TOKEN end_char="7170" id="token-59-23" morph="none" pos="word" start_char="7163">research</TOKEN>
<TOKEN end_char="7180" id="token-59-24" morph="none" pos="word" start_char="7172">scientist</TOKEN>
<TOKEN end_char="7184" id="token-59-25" morph="none" pos="word" start_char="7182">and</TOKEN>
<TOKEN end_char="7199" id="token-59-26" morph="none" pos="word" start_char="7186">microbiologist</TOKEN>
<TOKEN end_char="7202" id="token-59-27" morph="none" pos="word" start_char="7201">at</TOKEN>
<TOKEN end_char="7208" id="token-59-28" morph="none" pos="word" start_char="7204">Dyson</TOKEN>
<TOKEN end_char="7209" id="token-59-29" morph="none" pos="punct" start_char="7209">,</TOKEN>
<TOKEN end_char="7215" id="token-59-30" morph="none" pos="word" start_char="7211">notes</TOKEN>
<TOKEN end_char="7219" id="token-59-31" morph="none" pos="word" start_char="7217">via</TOKEN>
<TOKEN end_char="7225" id="token-59-32" morph="none" pos="word" start_char="7221">email</TOKEN>
<TOKEN end_char="7230" id="token-59-33" morph="none" pos="word" start_char="7227">that</TOKEN>
<TOKEN end_char="7232" id="token-59-34" morph="none" pos="punct" start_char="7232">‘</TOKEN>
<TOKEN end_char="7237" id="token-59-35" morph="none" pos="word" start_char="7233">Dyson</TOKEN>
<TOKEN end_char="7247" id="token-59-36" morph="none" pos="unknown" start_char="7239">Airblade™</TOKEN>
<TOKEN end_char="7252" id="token-59-37" morph="none" pos="word" start_char="7249">hand</TOKEN>
<TOKEN end_char="7259" id="token-59-38" morph="none" pos="word" start_char="7254">dryers</TOKEN>
<TOKEN end_char="7263" id="token-59-39" morph="none" pos="word" start_char="7261">are</TOKEN>
<TOKEN end_char="7270" id="token-59-40" morph="none" pos="word" start_char="7265">proven</TOKEN>
<TOKEN end_char="7279" id="token-59-41" morph="none" pos="word" start_char="7272">hygienic</TOKEN>
<TOKEN end_char="7280" id="token-59-42" morph="none" pos="punct" start_char="7280">,</TOKEN>
<TOKEN end_char="7284" id="token-59-43" morph="none" pos="word" start_char="7282">and</TOKEN>
<TOKEN end_char="7290" id="token-59-44" morph="none" pos="word" start_char="7286">there</TOKEN>
<TOKEN end_char="7293" id="token-59-45" morph="none" pos="word" start_char="7292">is</TOKEN>
<TOKEN end_char="7296" id="token-59-46" morph="none" pos="word" start_char="7295">no</TOKEN>
<TOKEN end_char="7307" id="token-59-47" morph="none" pos="word" start_char="7298">scientific</TOKEN>
<TOKEN end_char="7313" id="token-59-48" morph="none" pos="word" start_char="7309">basis</TOKEN>
<TOKEN end_char="7316" id="token-59-49" morph="none" pos="word" start_char="7315">to</TOKEN>
<TOKEN end_char="7324" id="token-59-50" morph="none" pos="word" start_char="7318">suggest</TOKEN>
<TOKEN end_char="7329" id="token-59-51" morph="none" pos="word" start_char="7326">that</TOKEN>
<TOKEN end_char="7333" id="token-59-52" morph="none" pos="word" start_char="7331">our</TOKEN>
<TOKEN end_char="7338" id="token-59-53" morph="none" pos="word" start_char="7335">hand</TOKEN>
<TOKEN end_char="7345" id="token-59-54" morph="none" pos="word" start_char="7340">dryers</TOKEN>
<TOKEN end_char="7352" id="token-59-55" morph="none" pos="word" start_char="7347">spread</TOKEN>
<TOKEN end_char="7362" id="token-59-56" morph="none" pos="word" start_char="7354">pathogens</TOKEN>
<TOKEN end_char="7365" id="token-59-57" morph="none" pos="word" start_char="7364">or</TOKEN>
<TOKEN end_char="7369" id="token-59-58" morph="none" pos="word" start_char="7367">are</TOKEN>
<TOKEN end_char="7374" id="token-59-59" morph="none" pos="word" start_char="7371">less</TOKEN>
<TOKEN end_char="7383" id="token-59-60" morph="none" pos="word" start_char="7376">hygienic</TOKEN>
<TOKEN end_char="7388" id="token-59-61" morph="none" pos="word" start_char="7385">than</TOKEN>
<TOKEN end_char="7394" id="token-59-62" morph="none" pos="word" start_char="7390">paper</TOKEN>
<TOKEN end_char="7401" id="token-59-63" morph="none" pos="word" start_char="7396">towels</TOKEN>
<TOKEN end_char="7402" id="token-59-64" morph="none" pos="punct" start_char="7402">.</TOKEN>
</SEG>
<SEG end_char="7635" id="segment-60" start_char="7404">
<ORIGINAL_TEXT>The 2015 study referenced was funded by the paper towel industry and tellingly did not employ methodology which represents real-world use and instead used unwashed hands covered in unrealistically high levels of virus contamination.</ORIGINAL_TEXT>
<TOKEN end_char="7406" id="token-60-0" morph="none" pos="word" start_char="7404">The</TOKEN>
<TOKEN end_char="7411" id="token-60-1" morph="none" pos="word" start_char="7408">2015</TOKEN>
<TOKEN end_char="7417" id="token-60-2" morph="none" pos="word" start_char="7413">study</TOKEN>
<TOKEN end_char="7428" id="token-60-3" morph="none" pos="word" start_char="7419">referenced</TOKEN>
<TOKEN end_char="7432" id="token-60-4" morph="none" pos="word" start_char="7430">was</TOKEN>
<TOKEN end_char="7439" id="token-60-5" morph="none" pos="word" start_char="7434">funded</TOKEN>
<TOKEN end_char="7442" id="token-60-6" morph="none" pos="word" start_char="7441">by</TOKEN>
<TOKEN end_char="7446" id="token-60-7" morph="none" pos="word" start_char="7444">the</TOKEN>
<TOKEN end_char="7452" id="token-60-8" morph="none" pos="word" start_char="7448">paper</TOKEN>
<TOKEN end_char="7458" id="token-60-9" morph="none" pos="word" start_char="7454">towel</TOKEN>
<TOKEN end_char="7467" id="token-60-10" morph="none" pos="word" start_char="7460">industry</TOKEN>
<TOKEN end_char="7471" id="token-60-11" morph="none" pos="word" start_char="7469">and</TOKEN>
<TOKEN end_char="7481" id="token-60-12" morph="none" pos="word" start_char="7473">tellingly</TOKEN>
<TOKEN end_char="7485" id="token-60-13" morph="none" pos="word" start_char="7483">did</TOKEN>
<TOKEN end_char="7489" id="token-60-14" morph="none" pos="word" start_char="7487">not</TOKEN>
<TOKEN end_char="7496" id="token-60-15" morph="none" pos="word" start_char="7491">employ</TOKEN>
<TOKEN end_char="7508" id="token-60-16" morph="none" pos="word" start_char="7498">methodology</TOKEN>
<TOKEN end_char="7514" id="token-60-17" morph="none" pos="word" start_char="7510">which</TOKEN>
<TOKEN end_char="7525" id="token-60-18" morph="none" pos="word" start_char="7516">represents</TOKEN>
<TOKEN end_char="7536" id="token-60-19" morph="none" pos="unknown" start_char="7527">real-world</TOKEN>
<TOKEN end_char="7540" id="token-60-20" morph="none" pos="word" start_char="7538">use</TOKEN>
<TOKEN end_char="7544" id="token-60-21" morph="none" pos="word" start_char="7542">and</TOKEN>
<TOKEN end_char="7552" id="token-60-22" morph="none" pos="word" start_char="7546">instead</TOKEN>
<TOKEN end_char="7557" id="token-60-23" morph="none" pos="word" start_char="7554">used</TOKEN>
<TOKEN end_char="7566" id="token-60-24" morph="none" pos="word" start_char="7559">unwashed</TOKEN>
<TOKEN end_char="7572" id="token-60-25" morph="none" pos="word" start_char="7568">hands</TOKEN>
<TOKEN end_char="7580" id="token-60-26" morph="none" pos="word" start_char="7574">covered</TOKEN>
<TOKEN end_char="7583" id="token-60-27" morph="none" pos="word" start_char="7582">in</TOKEN>
<TOKEN end_char="7599" id="token-60-28" morph="none" pos="word" start_char="7585">unrealistically</TOKEN>
<TOKEN end_char="7604" id="token-60-29" morph="none" pos="word" start_char="7601">high</TOKEN>
<TOKEN end_char="7611" id="token-60-30" morph="none" pos="word" start_char="7606">levels</TOKEN>
<TOKEN end_char="7614" id="token-60-31" morph="none" pos="word" start_char="7613">of</TOKEN>
<TOKEN end_char="7620" id="token-60-32" morph="none" pos="word" start_char="7616">virus</TOKEN>
<TOKEN end_char="7634" id="token-60-33" morph="none" pos="word" start_char="7622">contamination</TOKEN>
<TOKEN end_char="7635" id="token-60-34" morph="none" pos="punct" start_char="7635">.</TOKEN>
</SEG>
<SEG end_char="7773" id="segment-61" start_char="7637">
<ORIGINAL_TEXT>In addition, Dyson Airblade™ hand dryers are the only hand dryers that have been globally certified hygienic by NSF P335 accreditation.’"</ORIGINAL_TEXT>
<TOKEN end_char="7638" id="token-61-0" morph="none" pos="word" start_char="7637">In</TOKEN>
<TOKEN end_char="7647" id="token-61-1" morph="none" pos="word" start_char="7640">addition</TOKEN>
<TOKEN end_char="7648" id="token-61-2" morph="none" pos="punct" start_char="7648">,</TOKEN>
<TOKEN end_char="7654" id="token-61-3" morph="none" pos="word" start_char="7650">Dyson</TOKEN>
<TOKEN end_char="7664" id="token-61-4" morph="none" pos="unknown" start_char="7656">Airblade™</TOKEN>
<TOKEN end_char="7669" id="token-61-5" morph="none" pos="word" start_char="7666">hand</TOKEN>
<TOKEN end_char="7676" id="token-61-6" morph="none" pos="word" start_char="7671">dryers</TOKEN>
<TOKEN end_char="7680" id="token-61-7" morph="none" pos="word" start_char="7678">are</TOKEN>
<TOKEN end_char="7684" id="token-61-8" morph="none" pos="word" start_char="7682">the</TOKEN>
<TOKEN end_char="7689" id="token-61-9" morph="none" pos="word" start_char="7686">only</TOKEN>
<TOKEN end_char="7694" id="token-61-10" morph="none" pos="word" start_char="7691">hand</TOKEN>
<TOKEN end_char="7701" id="token-61-11" morph="none" pos="word" start_char="7696">dryers</TOKEN>
<TOKEN end_char="7706" id="token-61-12" morph="none" pos="word" start_char="7703">that</TOKEN>
<TOKEN end_char="7711" id="token-61-13" morph="none" pos="word" start_char="7708">have</TOKEN>
<TOKEN end_char="7716" id="token-61-14" morph="none" pos="word" start_char="7713">been</TOKEN>
<TOKEN end_char="7725" id="token-61-15" morph="none" pos="word" start_char="7718">globally</TOKEN>
<TOKEN end_char="7735" id="token-61-16" morph="none" pos="word" start_char="7727">certified</TOKEN>
<TOKEN end_char="7744" id="token-61-17" morph="none" pos="word" start_char="7737">hygienic</TOKEN>
<TOKEN end_char="7747" id="token-61-18" morph="none" pos="word" start_char="7746">by</TOKEN>
<TOKEN end_char="7751" id="token-61-19" morph="none" pos="word" start_char="7749">NSF</TOKEN>
<TOKEN end_char="7756" id="token-61-20" morph="none" pos="word" start_char="7753">P335</TOKEN>
<TOKEN end_char="7770" id="token-61-21" morph="none" pos="word" start_char="7758">accreditation</TOKEN>
<TOKEN end_char="7773" id="token-61-22" morph="none" pos="punct" start_char="7771">.’"</TOKEN>
</SEG>
<SEG end_char="7800" id="segment-62" start_char="7777">
<ORIGINAL_TEXT>More Great WIRED Stories</ORIGINAL_TEXT>
<TOKEN end_char="7780" id="token-62-0" morph="none" pos="word" start_char="7777">More</TOKEN>
<TOKEN end_char="7786" id="token-62-1" morph="none" pos="word" start_char="7782">Great</TOKEN>
<TOKEN end_char="7792" id="token-62-2" morph="none" pos="word" start_char="7788">WIRED</TOKEN>
<TOKEN end_char="7800" id="token-62-3" morph="none" pos="word" start_char="7794">Stories</TOKEN>
</SEG>
<SEG end_char="7836" id="segment-63" start_char="7803">
<ORIGINAL_TEXT>Silicon Valley ruined work culture</ORIGINAL_TEXT>
<TOKEN end_char="7809" id="token-63-0" morph="none" pos="word" start_char="7803">Silicon</TOKEN>
<TOKEN end_char="7816" id="token-63-1" morph="none" pos="word" start_char="7811">Valley</TOKEN>
<TOKEN end_char="7823" id="token-63-2" morph="none" pos="word" start_char="7818">ruined</TOKEN>
<TOKEN end_char="7828" id="token-63-3" morph="none" pos="word" start_char="7825">work</TOKEN>
<TOKEN end_char="7836" id="token-63-4" morph="none" pos="word" start_char="7830">culture</TOKEN>
</SEG>
<SEG end_char="7896" id="segment-64" start_char="7839">
<ORIGINAL_TEXT>Going the distance (and beyond) to catch marathon cheaters</ORIGINAL_TEXT>
<TOKEN end_char="7843" id="token-64-0" morph="none" pos="word" start_char="7839">Going</TOKEN>
<TOKEN end_char="7847" id="token-64-1" morph="none" pos="word" start_char="7845">the</TOKEN>
<TOKEN end_char="7856" id="token-64-2" morph="none" pos="word" start_char="7849">distance</TOKEN>
<TOKEN end_char="7858" id="token-64-3" morph="none" pos="punct" start_char="7858">(</TOKEN>
<TOKEN end_char="7861" id="token-64-4" morph="none" pos="word" start_char="7859">and</TOKEN>
<TOKEN end_char="7868" id="token-64-5" morph="none" pos="word" start_char="7863">beyond</TOKEN>
<TOKEN end_char="7869" id="token-64-6" morph="none" pos="punct" start_char="7869">)</TOKEN>
<TOKEN end_char="7872" id="token-64-7" morph="none" pos="word" start_char="7871">to</TOKEN>
<TOKEN end_char="7878" id="token-64-8" morph="none" pos="word" start_char="7874">catch</TOKEN>
<TOKEN end_char="7887" id="token-64-9" morph="none" pos="word" start_char="7880">marathon</TOKEN>
<TOKEN end_char="7896" id="token-64-10" morph="none" pos="word" start_char="7889">cheaters</TOKEN>
</SEG>
<SEG end_char="7950" id="segment-65" start_char="7899">
<ORIGINAL_TEXT>NASA’s epic gamble to get martian dirt back to Earth</ORIGINAL_TEXT>
<TOKEN end_char="7904" id="token-65-0" morph="none" pos="word" start_char="7899">NASA’s</TOKEN>
<TOKEN end_char="7909" id="token-65-1" morph="none" pos="word" start_char="7906">epic</TOKEN>
<TOKEN end_char="7916" id="token-65-2" morph="none" pos="word" start_char="7911">gamble</TOKEN>
<TOKEN end_char="7919" id="token-65-3" morph="none" pos="word" start_char="7918">to</TOKEN>
<TOKEN end_char="7923" id="token-65-4" morph="none" pos="word" start_char="7921">get</TOKEN>
<TOKEN end_char="7931" id="token-65-5" morph="none" pos="word" start_char="7925">martian</TOKEN>
<TOKEN end_char="7936" id="token-65-6" morph="none" pos="word" start_char="7933">dirt</TOKEN>
<TOKEN end_char="7941" id="token-65-7" morph="none" pos="word" start_char="7938">back</TOKEN>
<TOKEN end_char="7944" id="token-65-8" morph="none" pos="word" start_char="7943">to</TOKEN>
<TOKEN end_char="7950" id="token-65-9" morph="none" pos="word" start_char="7946">Earth</TOKEN>
</SEG>
<SEG end_char="8010" id="segment-66" start_char="7953">
<ORIGINAL_TEXT>Plane contrails have a surprising effect on global warming</ORIGINAL_TEXT>
<TOKEN end_char="7957" id="token-66-0" morph="none" pos="word" start_char="7953">Plane</TOKEN>
<TOKEN end_char="7967" id="token-66-1" morph="none" pos="word" start_char="7959">contrails</TOKEN>
<TOKEN end_char="7972" id="token-66-2" morph="none" pos="word" start_char="7969">have</TOKEN>
<TOKEN end_char="7974" id="token-66-3" morph="none" pos="word" start_char="7974">a</TOKEN>
<TOKEN end_char="7985" id="token-66-4" morph="none" pos="word" start_char="7976">surprising</TOKEN>
<TOKEN end_char="7992" id="token-66-5" morph="none" pos="word" start_char="7987">effect</TOKEN>
<TOKEN end_char="7995" id="token-66-6" morph="none" pos="word" start_char="7994">on</TOKEN>
<TOKEN end_char="8002" id="token-66-7" morph="none" pos="word" start_char="7997">global</TOKEN>
<TOKEN end_char="8010" id="token-66-8" morph="none" pos="word" start_char="8004">warming</TOKEN>
</SEG>
<SEG end_char="8057" id="segment-67" start_char="8013">
<ORIGINAL_TEXT>Can you spot the idioms in these photographs?</ORIGINAL_TEXT>
<TOKEN end_char="8015" id="token-67-0" morph="none" pos="word" start_char="8013">Can</TOKEN>
<TOKEN end_char="8019" id="token-67-1" morph="none" pos="word" start_char="8017">you</TOKEN>
<TOKEN end_char="8024" id="token-67-2" morph="none" pos="word" start_char="8021">spot</TOKEN>
<TOKEN end_char="8028" id="token-67-3" morph="none" pos="word" start_char="8026">the</TOKEN>
<TOKEN end_char="8035" id="token-67-4" morph="none" pos="word" start_char="8030">idioms</TOKEN>
<TOKEN end_char="8038" id="token-67-5" morph="none" pos="word" start_char="8037">in</TOKEN>
<TOKEN end_char="8044" id="token-67-6" morph="none" pos="word" start_char="8040">these</TOKEN>
<TOKEN end_char="8056" id="token-67-7" morph="none" pos="word" start_char="8046">photographs</TOKEN>
<TOKEN end_char="8057" id="token-67-8" morph="none" pos="punct" start_char="8057">?</TOKEN>
</SEG>
<SEG end_char="8104" id="segment-68" start_char="8060">
<ORIGINAL_TEXT>👁 A defeated chess champ makes peace with AI.</ORIGINAL_TEXT>
<TOKEN end_char="8060" id="token-68-0" morph="none" pos="unknown" start_char="8060">👁</TOKEN>
<TOKEN end_char="8062" id="token-68-1" morph="none" pos="word" start_char="8062">A</TOKEN>
<TOKEN end_char="8071" id="token-68-2" morph="none" pos="word" start_char="8064">defeated</TOKEN>
<TOKEN end_char="8077" id="token-68-3" morph="none" pos="word" start_char="8073">chess</TOKEN>
<TOKEN end_char="8083" id="token-68-4" morph="none" pos="word" start_char="8079">champ</TOKEN>
<TOKEN end_char="8089" id="token-68-5" morph="none" pos="word" start_char="8085">makes</TOKEN>
<TOKEN end_char="8095" id="token-68-6" morph="none" pos="word" start_char="8091">peace</TOKEN>
<TOKEN end_char="8100" id="token-68-7" morph="none" pos="word" start_char="8097">with</TOKEN>
<TOKEN end_char="8103" id="token-68-8" morph="none" pos="word" start_char="8102">AI</TOKEN>
<TOKEN end_char="8104" id="token-68-9" morph="none" pos="punct" start_char="8104">.</TOKEN>
</SEG>
<SEG end_char="8129" id="segment-69" start_char="8106">
<ORIGINAL_TEXT>Plus, the latest AI news</ORIGINAL_TEXT>
<TOKEN end_char="8109" id="token-69-0" morph="none" pos="word" start_char="8106">Plus</TOKEN>
<TOKEN end_char="8110" id="token-69-1" morph="none" pos="punct" start_char="8110">,</TOKEN>
<TOKEN end_char="8114" id="token-69-2" morph="none" pos="word" start_char="8112">the</TOKEN>
<TOKEN end_char="8121" id="token-69-3" morph="none" pos="word" start_char="8116">latest</TOKEN>
<TOKEN end_char="8124" id="token-69-4" morph="none" pos="word" start_char="8123">AI</TOKEN>
<TOKEN end_char="8129" id="token-69-5" morph="none" pos="word" start_char="8126">news</TOKEN>
</SEG>
<SEG end_char="8251" id="segment-70" start_char="8132">
<ORIGINAL_TEXT>✨ Optimize your home life with our Gear team’s best picks, from robot vacuums to affordable mattresses to smart speakers</ORIGINAL_TEXT>
<TOKEN end_char="8132" id="token-70-0" morph="none" pos="unknown" start_char="8132">✨</TOKEN>
<TOKEN end_char="8141" id="token-70-1" morph="none" pos="word" start_char="8134">Optimize</TOKEN>
<TOKEN end_char="8146" id="token-70-2" morph="none" pos="word" start_char="8143">your</TOKEN>
<TOKEN end_char="8151" id="token-70-3" morph="none" pos="word" start_char="8148">home</TOKEN>
<TOKEN end_char="8156" id="token-70-4" morph="none" pos="word" start_char="8153">life</TOKEN>
<TOKEN end_char="8161" id="token-70-5" morph="none" pos="word" start_char="8158">with</TOKEN>
<TOKEN end_char="8165" id="token-70-6" morph="none" pos="word" start_char="8163">our</TOKEN>
<TOKEN end_char="8170" id="token-70-7" morph="none" pos="word" start_char="8167">Gear</TOKEN>
<TOKEN end_char="8177" id="token-70-8" morph="none" pos="word" start_char="8172">team’s</TOKEN>
<TOKEN end_char="8182" id="token-70-9" morph="none" pos="word" start_char="8179">best</TOKEN>
<TOKEN end_char="8188" id="token-70-10" morph="none" pos="word" start_char="8184">picks</TOKEN>
<TOKEN end_char="8189" id="token-70-11" morph="none" pos="punct" start_char="8189">,</TOKEN>
<TOKEN end_char="8194" id="token-70-12" morph="none" pos="word" start_char="8191">from</TOKEN>
<TOKEN end_char="8200" id="token-70-13" morph="none" pos="word" start_char="8196">robot</TOKEN>
<TOKEN end_char="8208" id="token-70-14" morph="none" pos="word" start_char="8202">vacuums</TOKEN>
<TOKEN end_char="8211" id="token-70-15" morph="none" pos="word" start_char="8210">to</TOKEN>
<TOKEN end_char="8222" id="token-70-16" morph="none" pos="word" start_char="8213">affordable</TOKEN>
<TOKEN end_char="8233" id="token-70-17" morph="none" pos="word" start_char="8224">mattresses</TOKEN>
<TOKEN end_char="8236" id="token-70-18" morph="none" pos="word" start_char="8235">to</TOKEN>
<TOKEN end_char="8242" id="token-70-19" morph="none" pos="word" start_char="8238">smart</TOKEN>
<TOKEN end_char="8251" id="token-70-20" morph="none" pos="word" start_char="8244">speakers</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
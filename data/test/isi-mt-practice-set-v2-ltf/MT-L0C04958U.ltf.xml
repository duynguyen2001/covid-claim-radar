<LCTL_TEXT lang="rus">
<DOC grammar="none" id="L0C04958U" lang="rus" raw_text_char_length="8441" raw_text_md5="f836d58121e0a38b047c166bc7d99f5c" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="81" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Fact check: Coronavirus not man-made or engineered but its origin remains unclear</ORIGINAL_TEXT>
<TOKEN end_char="4" id="token-0-0" morph="none" pos="word" start_char="1">Fact</TOKEN>
<TOKEN end_char="10" id="token-0-1" morph="none" pos="word" start_char="6">check</TOKEN>
<TOKEN end_char="11" id="token-0-2" morph="none" pos="punct" start_char="11">:</TOKEN>
<TOKEN end_char="23" id="token-0-3" morph="none" pos="word" start_char="13">Coronavirus</TOKEN>
<TOKEN end_char="27" id="token-0-4" morph="none" pos="word" start_char="25">not</TOKEN>
<TOKEN end_char="36" id="token-0-5" morph="none" pos="unknown" start_char="29">man-made</TOKEN>
<TOKEN end_char="39" id="token-0-6" morph="none" pos="word" start_char="38">or</TOKEN>
<TOKEN end_char="50" id="token-0-7" morph="none" pos="word" start_char="41">engineered</TOKEN>
<TOKEN end_char="54" id="token-0-8" morph="none" pos="word" start_char="52">but</TOKEN>
<TOKEN end_char="58" id="token-0-9" morph="none" pos="word" start_char="56">its</TOKEN>
<TOKEN end_char="65" id="token-0-10" morph="none" pos="word" start_char="60">origin</TOKEN>
<TOKEN end_char="73" id="token-0-11" morph="none" pos="word" start_char="67">remains</TOKEN>
<TOKEN end_char="81" id="token-0-12" morph="none" pos="word" start_char="75">unclear</TOKEN>
</SEG>
<SEG end_char="216" id="segment-1" start_char="86">
<ORIGINAL_TEXT>Corrections Clarifications: This fact-check has been revised based on updated reporting since it was first published in March 2020.</ORIGINAL_TEXT>
<TOKEN end_char="96" id="token-1-0" morph="none" pos="word" start_char="86">Corrections</TOKEN>
<TOKEN end_char="111" id="token-1-1" morph="none" pos="word" start_char="98">Clarifications</TOKEN>
<TOKEN end_char="112" id="token-1-2" morph="none" pos="punct" start_char="112">:</TOKEN>
<TOKEN end_char="117" id="token-1-3" morph="none" pos="word" start_char="114">This</TOKEN>
<TOKEN end_char="128" id="token-1-4" morph="none" pos="unknown" start_char="119">fact-check</TOKEN>
<TOKEN end_char="132" id="token-1-5" morph="none" pos="word" start_char="130">has</TOKEN>
<TOKEN end_char="137" id="token-1-6" morph="none" pos="word" start_char="134">been</TOKEN>
<TOKEN end_char="145" id="token-1-7" morph="none" pos="word" start_char="139">revised</TOKEN>
<TOKEN end_char="151" id="token-1-8" morph="none" pos="word" start_char="147">based</TOKEN>
<TOKEN end_char="154" id="token-1-9" morph="none" pos="word" start_char="153">on</TOKEN>
<TOKEN end_char="162" id="token-1-10" morph="none" pos="word" start_char="156">updated</TOKEN>
<TOKEN end_char="172" id="token-1-11" morph="none" pos="word" start_char="164">reporting</TOKEN>
<TOKEN end_char="178" id="token-1-12" morph="none" pos="word" start_char="174">since</TOKEN>
<TOKEN end_char="181" id="token-1-13" morph="none" pos="word" start_char="180">it</TOKEN>
<TOKEN end_char="185" id="token-1-14" morph="none" pos="word" start_char="183">was</TOKEN>
<TOKEN end_char="191" id="token-1-15" morph="none" pos="word" start_char="187">first</TOKEN>
<TOKEN end_char="201" id="token-1-16" morph="none" pos="word" start_char="193">published</TOKEN>
<TOKEN end_char="204" id="token-1-17" morph="none" pos="word" start_char="203">in</TOKEN>
<TOKEN end_char="210" id="token-1-18" morph="none" pos="word" start_char="206">March</TOKEN>
<TOKEN end_char="215" id="token-1-19" morph="none" pos="word" start_char="212">2020</TOKEN>
<TOKEN end_char="216" id="token-1-20" morph="none" pos="punct" start_char="216">.</TOKEN>
</SEG>
<SEG end_char="300" id="segment-2" start_char="218">
<ORIGINAL_TEXT>The rating on the claim has been changed to Partly False to reflect that reporting.</ORIGINAL_TEXT>
<TOKEN end_char="220" id="token-2-0" morph="none" pos="word" start_char="218">The</TOKEN>
<TOKEN end_char="227" id="token-2-1" morph="none" pos="word" start_char="222">rating</TOKEN>
<TOKEN end_char="230" id="token-2-2" morph="none" pos="word" start_char="229">on</TOKEN>
<TOKEN end_char="234" id="token-2-3" morph="none" pos="word" start_char="232">the</TOKEN>
<TOKEN end_char="240" id="token-2-4" morph="none" pos="word" start_char="236">claim</TOKEN>
<TOKEN end_char="244" id="token-2-5" morph="none" pos="word" start_char="242">has</TOKEN>
<TOKEN end_char="249" id="token-2-6" morph="none" pos="word" start_char="246">been</TOKEN>
<TOKEN end_char="257" id="token-2-7" morph="none" pos="word" start_char="251">changed</TOKEN>
<TOKEN end_char="260" id="token-2-8" morph="none" pos="word" start_char="259">to</TOKEN>
<TOKEN end_char="267" id="token-2-9" morph="none" pos="word" start_char="262">Partly</TOKEN>
<TOKEN end_char="273" id="token-2-10" morph="none" pos="word" start_char="269">False</TOKEN>
<TOKEN end_char="276" id="token-2-11" morph="none" pos="word" start_char="275">to</TOKEN>
<TOKEN end_char="284" id="token-2-12" morph="none" pos="word" start_char="278">reflect</TOKEN>
<TOKEN end_char="289" id="token-2-13" morph="none" pos="word" start_char="286">that</TOKEN>
<TOKEN end_char="299" id="token-2-14" morph="none" pos="word" start_char="291">reporting</TOKEN>
<TOKEN end_char="300" id="token-2-15" morph="none" pos="punct" start_char="300">.</TOKEN>
</SEG>
<SEG end_char="418" id="segment-3" start_char="303">
<ORIGINAL_TEXT>In February 2021, this story has been updated to reflect current information on the origin of the novel coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="304" id="token-3-0" morph="none" pos="word" start_char="303">In</TOKEN>
<TOKEN end_char="313" id="token-3-1" morph="none" pos="word" start_char="306">February</TOKEN>
<TOKEN end_char="318" id="token-3-2" morph="none" pos="word" start_char="315">2021</TOKEN>
<TOKEN end_char="319" id="token-3-3" morph="none" pos="punct" start_char="319">,</TOKEN>
<TOKEN end_char="324" id="token-3-4" morph="none" pos="word" start_char="321">this</TOKEN>
<TOKEN end_char="330" id="token-3-5" morph="none" pos="word" start_char="326">story</TOKEN>
<TOKEN end_char="334" id="token-3-6" morph="none" pos="word" start_char="332">has</TOKEN>
<TOKEN end_char="339" id="token-3-7" morph="none" pos="word" start_char="336">been</TOKEN>
<TOKEN end_char="347" id="token-3-8" morph="none" pos="word" start_char="341">updated</TOKEN>
<TOKEN end_char="350" id="token-3-9" morph="none" pos="word" start_char="349">to</TOKEN>
<TOKEN end_char="358" id="token-3-10" morph="none" pos="word" start_char="352">reflect</TOKEN>
<TOKEN end_char="366" id="token-3-11" morph="none" pos="word" start_char="360">current</TOKEN>
<TOKEN end_char="378" id="token-3-12" morph="none" pos="word" start_char="368">information</TOKEN>
<TOKEN end_char="381" id="token-3-13" morph="none" pos="word" start_char="380">on</TOKEN>
<TOKEN end_char="385" id="token-3-14" morph="none" pos="word" start_char="383">the</TOKEN>
<TOKEN end_char="392" id="token-3-15" morph="none" pos="word" start_char="387">origin</TOKEN>
<TOKEN end_char="395" id="token-3-16" morph="none" pos="word" start_char="394">of</TOKEN>
<TOKEN end_char="399" id="token-3-17" morph="none" pos="word" start_char="397">the</TOKEN>
<TOKEN end_char="405" id="token-3-18" morph="none" pos="word" start_char="401">novel</TOKEN>
<TOKEN end_char="417" id="token-3-19" morph="none" pos="word" start_char="407">coronavirus</TOKEN>
<TOKEN end_char="418" id="token-3-20" morph="none" pos="punct" start_char="418">.</TOKEN>
</SEG>
<SEG end_char="492" id="segment-4" start_char="422">
<ORIGINAL_TEXT>The claim: The coronavirus may have originated in a Chinese laboratory.</ORIGINAL_TEXT>
<TOKEN end_char="424" id="token-4-0" morph="none" pos="word" start_char="422">The</TOKEN>
<TOKEN end_char="430" id="token-4-1" morph="none" pos="word" start_char="426">claim</TOKEN>
<TOKEN end_char="431" id="token-4-2" morph="none" pos="punct" start_char="431">:</TOKEN>
<TOKEN end_char="435" id="token-4-3" morph="none" pos="word" start_char="433">The</TOKEN>
<TOKEN end_char="447" id="token-4-4" morph="none" pos="word" start_char="437">coronavirus</TOKEN>
<TOKEN end_char="451" id="token-4-5" morph="none" pos="word" start_char="449">may</TOKEN>
<TOKEN end_char="456" id="token-4-6" morph="none" pos="word" start_char="453">have</TOKEN>
<TOKEN end_char="467" id="token-4-7" morph="none" pos="word" start_char="458">originated</TOKEN>
<TOKEN end_char="470" id="token-4-8" morph="none" pos="word" start_char="469">in</TOKEN>
<TOKEN end_char="472" id="token-4-9" morph="none" pos="word" start_char="472">a</TOKEN>
<TOKEN end_char="480" id="token-4-10" morph="none" pos="word" start_char="474">Chinese</TOKEN>
<TOKEN end_char="491" id="token-4-11" morph="none" pos="word" start_char="482">laboratory</TOKEN>
<TOKEN end_char="492" id="token-4-12" morph="none" pos="punct" start_char="492">.</TOKEN>
</SEG>
<SEG end_char="570" id="segment-5" start_char="496">
<ORIGINAL_TEXT>As the new coronavirus spreads, theories about its origins have circulated.</ORIGINAL_TEXT>
<TOKEN end_char="497" id="token-5-0" morph="none" pos="word" start_char="496">As</TOKEN>
<TOKEN end_char="501" id="token-5-1" morph="none" pos="word" start_char="499">the</TOKEN>
<TOKEN end_char="505" id="token-5-2" morph="none" pos="word" start_char="503">new</TOKEN>
<TOKEN end_char="517" id="token-5-3" morph="none" pos="word" start_char="507">coronavirus</TOKEN>
<TOKEN end_char="525" id="token-5-4" morph="none" pos="word" start_char="519">spreads</TOKEN>
<TOKEN end_char="526" id="token-5-5" morph="none" pos="punct" start_char="526">,</TOKEN>
<TOKEN end_char="535" id="token-5-6" morph="none" pos="word" start_char="528">theories</TOKEN>
<TOKEN end_char="541" id="token-5-7" morph="none" pos="word" start_char="537">about</TOKEN>
<TOKEN end_char="545" id="token-5-8" morph="none" pos="word" start_char="543">its</TOKEN>
<TOKEN end_char="553" id="token-5-9" morph="none" pos="word" start_char="547">origins</TOKEN>
<TOKEN end_char="558" id="token-5-10" morph="none" pos="word" start_char="555">have</TOKEN>
<TOKEN end_char="569" id="token-5-11" morph="none" pos="word" start_char="560">circulated</TOKEN>
<TOKEN end_char="570" id="token-5-12" morph="none" pos="punct" start_char="570">.</TOKEN>
</SEG>
<SEG end_char="655" id="segment-6" start_char="572">
<ORIGINAL_TEXT>And as scientists have studied the virus, some theories have been debunked as false.</ORIGINAL_TEXT>
<TOKEN end_char="574" id="token-6-0" morph="none" pos="word" start_char="572">And</TOKEN>
<TOKEN end_char="577" id="token-6-1" morph="none" pos="word" start_char="576">as</TOKEN>
<TOKEN end_char="588" id="token-6-2" morph="none" pos="word" start_char="579">scientists</TOKEN>
<TOKEN end_char="593" id="token-6-3" morph="none" pos="word" start_char="590">have</TOKEN>
<TOKEN end_char="601" id="token-6-4" morph="none" pos="word" start_char="595">studied</TOKEN>
<TOKEN end_char="605" id="token-6-5" morph="none" pos="word" start_char="603">the</TOKEN>
<TOKEN end_char="611" id="token-6-6" morph="none" pos="word" start_char="607">virus</TOKEN>
<TOKEN end_char="612" id="token-6-7" morph="none" pos="punct" start_char="612">,</TOKEN>
<TOKEN end_char="617" id="token-6-8" morph="none" pos="word" start_char="614">some</TOKEN>
<TOKEN end_char="626" id="token-6-9" morph="none" pos="word" start_char="619">theories</TOKEN>
<TOKEN end_char="631" id="token-6-10" morph="none" pos="word" start_char="628">have</TOKEN>
<TOKEN end_char="636" id="token-6-11" morph="none" pos="word" start_char="633">been</TOKEN>
<TOKEN end_char="645" id="token-6-12" morph="none" pos="word" start_char="638">debunked</TOKEN>
<TOKEN end_char="648" id="token-6-13" morph="none" pos="word" start_char="647">as</TOKEN>
<TOKEN end_char="654" id="token-6-14" morph="none" pos="word" start_char="650">false</TOKEN>
<TOKEN end_char="655" id="token-6-15" morph="none" pos="punct" start_char="655">.</TOKEN>
</SEG>
<SEG end_char="881" id="segment-7" start_char="658">
<ORIGINAL_TEXT>One of the most prominent initial reports on the virus is an article published in January 2020 by the right-leaning Washington Times that suggests the coronavirus may have originated in a research laboratory in Wuhan, China.</ORIGINAL_TEXT>
<TOKEN end_char="660" id="token-7-0" morph="none" pos="word" start_char="658">One</TOKEN>
<TOKEN end_char="663" id="token-7-1" morph="none" pos="word" start_char="662">of</TOKEN>
<TOKEN end_char="667" id="token-7-2" morph="none" pos="word" start_char="665">the</TOKEN>
<TOKEN end_char="672" id="token-7-3" morph="none" pos="word" start_char="669">most</TOKEN>
<TOKEN end_char="682" id="token-7-4" morph="none" pos="word" start_char="674">prominent</TOKEN>
<TOKEN end_char="690" id="token-7-5" morph="none" pos="word" start_char="684">initial</TOKEN>
<TOKEN end_char="698" id="token-7-6" morph="none" pos="word" start_char="692">reports</TOKEN>
<TOKEN end_char="701" id="token-7-7" morph="none" pos="word" start_char="700">on</TOKEN>
<TOKEN end_char="705" id="token-7-8" morph="none" pos="word" start_char="703">the</TOKEN>
<TOKEN end_char="711" id="token-7-9" morph="none" pos="word" start_char="707">virus</TOKEN>
<TOKEN end_char="714" id="token-7-10" morph="none" pos="word" start_char="713">is</TOKEN>
<TOKEN end_char="717" id="token-7-11" morph="none" pos="word" start_char="716">an</TOKEN>
<TOKEN end_char="725" id="token-7-12" morph="none" pos="word" start_char="719">article</TOKEN>
<TOKEN end_char="735" id="token-7-13" morph="none" pos="word" start_char="727">published</TOKEN>
<TOKEN end_char="738" id="token-7-14" morph="none" pos="word" start_char="737">in</TOKEN>
<TOKEN end_char="746" id="token-7-15" morph="none" pos="word" start_char="740">January</TOKEN>
<TOKEN end_char="751" id="token-7-16" morph="none" pos="word" start_char="748">2020</TOKEN>
<TOKEN end_char="754" id="token-7-17" morph="none" pos="word" start_char="753">by</TOKEN>
<TOKEN end_char="758" id="token-7-18" morph="none" pos="word" start_char="756">the</TOKEN>
<TOKEN end_char="772" id="token-7-19" morph="none" pos="unknown" start_char="760">right-leaning</TOKEN>
<TOKEN end_char="783" id="token-7-20" morph="none" pos="word" start_char="774">Washington</TOKEN>
<TOKEN end_char="789" id="token-7-21" morph="none" pos="word" start_char="785">Times</TOKEN>
<TOKEN end_char="794" id="token-7-22" morph="none" pos="word" start_char="791">that</TOKEN>
<TOKEN end_char="803" id="token-7-23" morph="none" pos="word" start_char="796">suggests</TOKEN>
<TOKEN end_char="807" id="token-7-24" morph="none" pos="word" start_char="805">the</TOKEN>
<TOKEN end_char="819" id="token-7-25" morph="none" pos="word" start_char="809">coronavirus</TOKEN>
<TOKEN end_char="823" id="token-7-26" morph="none" pos="word" start_char="821">may</TOKEN>
<TOKEN end_char="828" id="token-7-27" morph="none" pos="word" start_char="825">have</TOKEN>
<TOKEN end_char="839" id="token-7-28" morph="none" pos="word" start_char="830">originated</TOKEN>
<TOKEN end_char="842" id="token-7-29" morph="none" pos="word" start_char="841">in</TOKEN>
<TOKEN end_char="844" id="token-7-30" morph="none" pos="word" start_char="844">a</TOKEN>
<TOKEN end_char="853" id="token-7-31" morph="none" pos="word" start_char="846">research</TOKEN>
<TOKEN end_char="864" id="token-7-32" morph="none" pos="word" start_char="855">laboratory</TOKEN>
<TOKEN end_char="867" id="token-7-33" morph="none" pos="word" start_char="866">in</TOKEN>
<TOKEN end_char="873" id="token-7-34" morph="none" pos="word" start_char="869">Wuhan</TOKEN>
<TOKEN end_char="874" id="token-7-35" morph="none" pos="punct" start_char="874">,</TOKEN>
<TOKEN end_char="880" id="token-7-36" morph="none" pos="word" start_char="876">China</TOKEN>
<TOKEN end_char="881" id="token-7-37" morph="none" pos="punct" start_char="881">.</TOKEN>
</SEG>
<SEG end_char="975" id="segment-8" start_char="884">
<ORIGINAL_TEXT>More:Fact check: Coronavirus originated in China, not elsewhere, researchers and studies say</ORIGINAL_TEXT>
<TOKEN end_char="892" id="token-8-0" morph="none" pos="unknown" start_char="884">More:Fact</TOKEN>
<TOKEN end_char="898" id="token-8-1" morph="none" pos="word" start_char="894">check</TOKEN>
<TOKEN end_char="899" id="token-8-2" morph="none" pos="punct" start_char="899">:</TOKEN>
<TOKEN end_char="911" id="token-8-3" morph="none" pos="word" start_char="901">Coronavirus</TOKEN>
<TOKEN end_char="922" id="token-8-4" morph="none" pos="word" start_char="913">originated</TOKEN>
<TOKEN end_char="925" id="token-8-5" morph="none" pos="word" start_char="924">in</TOKEN>
<TOKEN end_char="931" id="token-8-6" morph="none" pos="word" start_char="927">China</TOKEN>
<TOKEN end_char="932" id="token-8-7" morph="none" pos="punct" start_char="932">,</TOKEN>
<TOKEN end_char="936" id="token-8-8" morph="none" pos="word" start_char="934">not</TOKEN>
<TOKEN end_char="946" id="token-8-9" morph="none" pos="word" start_char="938">elsewhere</TOKEN>
<TOKEN end_char="947" id="token-8-10" morph="none" pos="punct" start_char="947">,</TOKEN>
<TOKEN end_char="959" id="token-8-11" morph="none" pos="word" start_char="949">researchers</TOKEN>
<TOKEN end_char="963" id="token-8-12" morph="none" pos="word" start_char="961">and</TOKEN>
<TOKEN end_char="971" id="token-8-13" morph="none" pos="word" start_char="965">studies</TOKEN>
<TOKEN end_char="975" id="token-8-14" morph="none" pos="word" start_char="973">say</TOKEN>
</SEG>
<SEG end_char="1221" id="segment-9" start_char="978">
<ORIGINAL_TEXT>The article quoted a former military intelligence officer who claimed the Wuhan Institute of Virology, a maximum-security Chinese laboratory granted authority to research dangerous pathogens, "is linked to Beijing’s covert bio-weapons program."</ORIGINAL_TEXT>
<TOKEN end_char="980" id="token-9-0" morph="none" pos="word" start_char="978">The</TOKEN>
<TOKEN end_char="988" id="token-9-1" morph="none" pos="word" start_char="982">article</TOKEN>
<TOKEN end_char="995" id="token-9-2" morph="none" pos="word" start_char="990">quoted</TOKEN>
<TOKEN end_char="997" id="token-9-3" morph="none" pos="word" start_char="997">a</TOKEN>
<TOKEN end_char="1004" id="token-9-4" morph="none" pos="word" start_char="999">former</TOKEN>
<TOKEN end_char="1013" id="token-9-5" morph="none" pos="word" start_char="1006">military</TOKEN>
<TOKEN end_char="1026" id="token-9-6" morph="none" pos="word" start_char="1015">intelligence</TOKEN>
<TOKEN end_char="1034" id="token-9-7" morph="none" pos="word" start_char="1028">officer</TOKEN>
<TOKEN end_char="1038" id="token-9-8" morph="none" pos="word" start_char="1036">who</TOKEN>
<TOKEN end_char="1046" id="token-9-9" morph="none" pos="word" start_char="1040">claimed</TOKEN>
<TOKEN end_char="1050" id="token-9-10" morph="none" pos="word" start_char="1048">the</TOKEN>
<TOKEN end_char="1056" id="token-9-11" morph="none" pos="word" start_char="1052">Wuhan</TOKEN>
<TOKEN end_char="1066" id="token-9-12" morph="none" pos="word" start_char="1058">Institute</TOKEN>
<TOKEN end_char="1069" id="token-9-13" morph="none" pos="word" start_char="1068">of</TOKEN>
<TOKEN end_char="1078" id="token-9-14" morph="none" pos="word" start_char="1071">Virology</TOKEN>
<TOKEN end_char="1079" id="token-9-15" morph="none" pos="punct" start_char="1079">,</TOKEN>
<TOKEN end_char="1081" id="token-9-16" morph="none" pos="word" start_char="1081">a</TOKEN>
<TOKEN end_char="1098" id="token-9-17" morph="none" pos="unknown" start_char="1083">maximum-security</TOKEN>
<TOKEN end_char="1106" id="token-9-18" morph="none" pos="word" start_char="1100">Chinese</TOKEN>
<TOKEN end_char="1117" id="token-9-19" morph="none" pos="word" start_char="1108">laboratory</TOKEN>
<TOKEN end_char="1125" id="token-9-20" morph="none" pos="word" start_char="1119">granted</TOKEN>
<TOKEN end_char="1135" id="token-9-21" morph="none" pos="word" start_char="1127">authority</TOKEN>
<TOKEN end_char="1138" id="token-9-22" morph="none" pos="word" start_char="1137">to</TOKEN>
<TOKEN end_char="1147" id="token-9-23" morph="none" pos="word" start_char="1140">research</TOKEN>
<TOKEN end_char="1157" id="token-9-24" morph="none" pos="word" start_char="1149">dangerous</TOKEN>
<TOKEN end_char="1167" id="token-9-25" morph="none" pos="word" start_char="1159">pathogens</TOKEN>
<TOKEN end_char="1168" id="token-9-26" morph="none" pos="punct" start_char="1168">,</TOKEN>
<TOKEN end_char="1170" id="token-9-27" morph="none" pos="punct" start_char="1170">"</TOKEN>
<TOKEN end_char="1172" id="token-9-28" morph="none" pos="word" start_char="1171">is</TOKEN>
<TOKEN end_char="1179" id="token-9-29" morph="none" pos="word" start_char="1174">linked</TOKEN>
<TOKEN end_char="1182" id="token-9-30" morph="none" pos="word" start_char="1181">to</TOKEN>
<TOKEN end_char="1192" id="token-9-31" morph="none" pos="word" start_char="1184">Beijing’s</TOKEN>
<TOKEN end_char="1199" id="token-9-32" morph="none" pos="word" start_char="1194">covert</TOKEN>
<TOKEN end_char="1211" id="token-9-33" morph="none" pos="unknown" start_char="1201">bio-weapons</TOKEN>
<TOKEN end_char="1219" id="token-9-34" morph="none" pos="word" start_char="1213">program</TOKEN>
<TOKEN end_char="1221" id="token-9-35" morph="none" pos="punct" start_char="1220">."</TOKEN>
</SEG>
<SEG end_char="1349" id="segment-10" start_char="1224">
<ORIGINAL_TEXT>In mid-March, USA TODAY contacted the author of the article, Bill Gertz, with a request to comment but did not get a response.</ORIGINAL_TEXT>
<TOKEN end_char="1225" id="token-10-0" morph="none" pos="word" start_char="1224">In</TOKEN>
<TOKEN end_char="1235" id="token-10-1" morph="none" pos="unknown" start_char="1227">mid-March</TOKEN>
<TOKEN end_char="1236" id="token-10-2" morph="none" pos="punct" start_char="1236">,</TOKEN>
<TOKEN end_char="1240" id="token-10-3" morph="none" pos="word" start_char="1238">USA</TOKEN>
<TOKEN end_char="1246" id="token-10-4" morph="none" pos="word" start_char="1242">TODAY</TOKEN>
<TOKEN end_char="1256" id="token-10-5" morph="none" pos="word" start_char="1248">contacted</TOKEN>
<TOKEN end_char="1260" id="token-10-6" morph="none" pos="word" start_char="1258">the</TOKEN>
<TOKEN end_char="1267" id="token-10-7" morph="none" pos="word" start_char="1262">author</TOKEN>
<TOKEN end_char="1270" id="token-10-8" morph="none" pos="word" start_char="1269">of</TOKEN>
<TOKEN end_char="1274" id="token-10-9" morph="none" pos="word" start_char="1272">the</TOKEN>
<TOKEN end_char="1282" id="token-10-10" morph="none" pos="word" start_char="1276">article</TOKEN>
<TOKEN end_char="1283" id="token-10-11" morph="none" pos="punct" start_char="1283">,</TOKEN>
<TOKEN end_char="1288" id="token-10-12" morph="none" pos="word" start_char="1285">Bill</TOKEN>
<TOKEN end_char="1294" id="token-10-13" morph="none" pos="word" start_char="1290">Gertz</TOKEN>
<TOKEN end_char="1295" id="token-10-14" morph="none" pos="punct" start_char="1295">,</TOKEN>
<TOKEN end_char="1300" id="token-10-15" morph="none" pos="word" start_char="1297">with</TOKEN>
<TOKEN end_char="1302" id="token-10-16" morph="none" pos="word" start_char="1302">a</TOKEN>
<TOKEN end_char="1310" id="token-10-17" morph="none" pos="word" start_char="1304">request</TOKEN>
<TOKEN end_char="1313" id="token-10-18" morph="none" pos="word" start_char="1312">to</TOKEN>
<TOKEN end_char="1321" id="token-10-19" morph="none" pos="word" start_char="1315">comment</TOKEN>
<TOKEN end_char="1325" id="token-10-20" morph="none" pos="word" start_char="1323">but</TOKEN>
<TOKEN end_char="1329" id="token-10-21" morph="none" pos="word" start_char="1327">did</TOKEN>
<TOKEN end_char="1333" id="token-10-22" morph="none" pos="word" start_char="1331">not</TOKEN>
<TOKEN end_char="1337" id="token-10-23" morph="none" pos="word" start_char="1335">get</TOKEN>
<TOKEN end_char="1339" id="token-10-24" morph="none" pos="word" start_char="1339">a</TOKEN>
<TOKEN end_char="1348" id="token-10-25" morph="none" pos="word" start_char="1341">response</TOKEN>
<TOKEN end_char="1349" id="token-10-26" morph="none" pos="punct" start_char="1349">.</TOKEN>
</SEG>
<SEG end_char="1576" id="segment-11" start_char="1352">
<ORIGINAL_TEXT>On March 25, the Washington Times published an updated article that reflects what an editor's note said is updated reporting: "Since this story ran, scientists outside of China have had a chance to study the SARS-CoV-2 virus.</ORIGINAL_TEXT>
<TOKEN end_char="1353" id="token-11-0" morph="none" pos="word" start_char="1352">On</TOKEN>
<TOKEN end_char="1359" id="token-11-1" morph="none" pos="word" start_char="1355">March</TOKEN>
<TOKEN end_char="1362" id="token-11-2" morph="none" pos="word" start_char="1361">25</TOKEN>
<TOKEN end_char="1363" id="token-11-3" morph="none" pos="punct" start_char="1363">,</TOKEN>
<TOKEN end_char="1367" id="token-11-4" morph="none" pos="word" start_char="1365">the</TOKEN>
<TOKEN end_char="1378" id="token-11-5" morph="none" pos="word" start_char="1369">Washington</TOKEN>
<TOKEN end_char="1384" id="token-11-6" morph="none" pos="word" start_char="1380">Times</TOKEN>
<TOKEN end_char="1394" id="token-11-7" morph="none" pos="word" start_char="1386">published</TOKEN>
<TOKEN end_char="1397" id="token-11-8" morph="none" pos="word" start_char="1396">an</TOKEN>
<TOKEN end_char="1405" id="token-11-9" morph="none" pos="word" start_char="1399">updated</TOKEN>
<TOKEN end_char="1413" id="token-11-10" morph="none" pos="word" start_char="1407">article</TOKEN>
<TOKEN end_char="1418" id="token-11-11" morph="none" pos="word" start_char="1415">that</TOKEN>
<TOKEN end_char="1427" id="token-11-12" morph="none" pos="word" start_char="1420">reflects</TOKEN>
<TOKEN end_char="1432" id="token-11-13" morph="none" pos="word" start_char="1429">what</TOKEN>
<TOKEN end_char="1435" id="token-11-14" morph="none" pos="word" start_char="1434">an</TOKEN>
<TOKEN end_char="1444" id="token-11-15" morph="none" pos="word" start_char="1437">editor's</TOKEN>
<TOKEN end_char="1449" id="token-11-16" morph="none" pos="word" start_char="1446">note</TOKEN>
<TOKEN end_char="1454" id="token-11-17" morph="none" pos="word" start_char="1451">said</TOKEN>
<TOKEN end_char="1457" id="token-11-18" morph="none" pos="word" start_char="1456">is</TOKEN>
<TOKEN end_char="1465" id="token-11-19" morph="none" pos="word" start_char="1459">updated</TOKEN>
<TOKEN end_char="1475" id="token-11-20" morph="none" pos="word" start_char="1467">reporting</TOKEN>
<TOKEN end_char="1476" id="token-11-21" morph="none" pos="punct" start_char="1476">:</TOKEN>
<TOKEN end_char="1478" id="token-11-22" morph="none" pos="punct" start_char="1478">"</TOKEN>
<TOKEN end_char="1483" id="token-11-23" morph="none" pos="word" start_char="1479">Since</TOKEN>
<TOKEN end_char="1488" id="token-11-24" morph="none" pos="word" start_char="1485">this</TOKEN>
<TOKEN end_char="1494" id="token-11-25" morph="none" pos="word" start_char="1490">story</TOKEN>
<TOKEN end_char="1498" id="token-11-26" morph="none" pos="word" start_char="1496">ran</TOKEN>
<TOKEN end_char="1499" id="token-11-27" morph="none" pos="punct" start_char="1499">,</TOKEN>
<TOKEN end_char="1510" id="token-11-28" morph="none" pos="word" start_char="1501">scientists</TOKEN>
<TOKEN end_char="1518" id="token-11-29" morph="none" pos="word" start_char="1512">outside</TOKEN>
<TOKEN end_char="1521" id="token-11-30" morph="none" pos="word" start_char="1520">of</TOKEN>
<TOKEN end_char="1527" id="token-11-31" morph="none" pos="word" start_char="1523">China</TOKEN>
<TOKEN end_char="1532" id="token-11-32" morph="none" pos="word" start_char="1529">have</TOKEN>
<TOKEN end_char="1536" id="token-11-33" morph="none" pos="word" start_char="1534">had</TOKEN>
<TOKEN end_char="1538" id="token-11-34" morph="none" pos="word" start_char="1538">a</TOKEN>
<TOKEN end_char="1545" id="token-11-35" morph="none" pos="word" start_char="1540">chance</TOKEN>
<TOKEN end_char="1548" id="token-11-36" morph="none" pos="word" start_char="1547">to</TOKEN>
<TOKEN end_char="1554" id="token-11-37" morph="none" pos="word" start_char="1550">study</TOKEN>
<TOKEN end_char="1558" id="token-11-38" morph="none" pos="word" start_char="1556">the</TOKEN>
<TOKEN end_char="1569" id="token-11-39" morph="none" pos="unknown" start_char="1560">SARS-CoV-2</TOKEN>
<TOKEN end_char="1575" id="token-11-40" morph="none" pos="word" start_char="1571">virus</TOKEN>
<TOKEN end_char="1576" id="token-11-41" morph="none" pos="punct" start_char="1576">.</TOKEN>
</SEG>
<SEG end_char="1806" id="segment-12" start_char="1578">
<ORIGINAL_TEXT>They concluded it does not show signs of having been manufactured or purposefully manipulated in a lab, though the exact origin remains murky and experts debate whether it may have leaked from a Chinese lab that was studying it."</ORIGINAL_TEXT>
<TOKEN end_char="1581" id="token-12-0" morph="none" pos="word" start_char="1578">They</TOKEN>
<TOKEN end_char="1591" id="token-12-1" morph="none" pos="word" start_char="1583">concluded</TOKEN>
<TOKEN end_char="1594" id="token-12-2" morph="none" pos="word" start_char="1593">it</TOKEN>
<TOKEN end_char="1599" id="token-12-3" morph="none" pos="word" start_char="1596">does</TOKEN>
<TOKEN end_char="1603" id="token-12-4" morph="none" pos="word" start_char="1601">not</TOKEN>
<TOKEN end_char="1608" id="token-12-5" morph="none" pos="word" start_char="1605">show</TOKEN>
<TOKEN end_char="1614" id="token-12-6" morph="none" pos="word" start_char="1610">signs</TOKEN>
<TOKEN end_char="1617" id="token-12-7" morph="none" pos="word" start_char="1616">of</TOKEN>
<TOKEN end_char="1624" id="token-12-8" morph="none" pos="word" start_char="1619">having</TOKEN>
<TOKEN end_char="1629" id="token-12-9" morph="none" pos="word" start_char="1626">been</TOKEN>
<TOKEN end_char="1642" id="token-12-10" morph="none" pos="word" start_char="1631">manufactured</TOKEN>
<TOKEN end_char="1645" id="token-12-11" morph="none" pos="word" start_char="1644">or</TOKEN>
<TOKEN end_char="1658" id="token-12-12" morph="none" pos="word" start_char="1647">purposefully</TOKEN>
<TOKEN end_char="1670" id="token-12-13" morph="none" pos="word" start_char="1660">manipulated</TOKEN>
<TOKEN end_char="1673" id="token-12-14" morph="none" pos="word" start_char="1672">in</TOKEN>
<TOKEN end_char="1675" id="token-12-15" morph="none" pos="word" start_char="1675">a</TOKEN>
<TOKEN end_char="1679" id="token-12-16" morph="none" pos="word" start_char="1677">lab</TOKEN>
<TOKEN end_char="1680" id="token-12-17" morph="none" pos="punct" start_char="1680">,</TOKEN>
<TOKEN end_char="1687" id="token-12-18" morph="none" pos="word" start_char="1682">though</TOKEN>
<TOKEN end_char="1691" id="token-12-19" morph="none" pos="word" start_char="1689">the</TOKEN>
<TOKEN end_char="1697" id="token-12-20" morph="none" pos="word" start_char="1693">exact</TOKEN>
<TOKEN end_char="1704" id="token-12-21" morph="none" pos="word" start_char="1699">origin</TOKEN>
<TOKEN end_char="1712" id="token-12-22" morph="none" pos="word" start_char="1706">remains</TOKEN>
<TOKEN end_char="1718" id="token-12-23" morph="none" pos="word" start_char="1714">murky</TOKEN>
<TOKEN end_char="1722" id="token-12-24" morph="none" pos="word" start_char="1720">and</TOKEN>
<TOKEN end_char="1730" id="token-12-25" morph="none" pos="word" start_char="1724">experts</TOKEN>
<TOKEN end_char="1737" id="token-12-26" morph="none" pos="word" start_char="1732">debate</TOKEN>
<TOKEN end_char="1745" id="token-12-27" morph="none" pos="word" start_char="1739">whether</TOKEN>
<TOKEN end_char="1748" id="token-12-28" morph="none" pos="word" start_char="1747">it</TOKEN>
<TOKEN end_char="1752" id="token-12-29" morph="none" pos="word" start_char="1750">may</TOKEN>
<TOKEN end_char="1757" id="token-12-30" morph="none" pos="word" start_char="1754">have</TOKEN>
<TOKEN end_char="1764" id="token-12-31" morph="none" pos="word" start_char="1759">leaked</TOKEN>
<TOKEN end_char="1769" id="token-12-32" morph="none" pos="word" start_char="1766">from</TOKEN>
<TOKEN end_char="1771" id="token-12-33" morph="none" pos="word" start_char="1771">a</TOKEN>
<TOKEN end_char="1779" id="token-12-34" morph="none" pos="word" start_char="1773">Chinese</TOKEN>
<TOKEN end_char="1783" id="token-12-35" morph="none" pos="word" start_char="1781">lab</TOKEN>
<TOKEN end_char="1788" id="token-12-36" morph="none" pos="word" start_char="1785">that</TOKEN>
<TOKEN end_char="1792" id="token-12-37" morph="none" pos="word" start_char="1790">was</TOKEN>
<TOKEN end_char="1801" id="token-12-38" morph="none" pos="word" start_char="1794">studying</TOKEN>
<TOKEN end_char="1804" id="token-12-39" morph="none" pos="word" start_char="1803">it</TOKEN>
<TOKEN end_char="1806" id="token-12-40" morph="none" pos="punct" start_char="1805">."</TOKEN>
</SEG>
<SEG end_char="1917" id="segment-13" start_char="1809">
<ORIGINAL_TEXT>People on multiple platforms and networks have shared the same or a similar version of the conspiracy theory.</ORIGINAL_TEXT>
<TOKEN end_char="1814" id="token-13-0" morph="none" pos="word" start_char="1809">People</TOKEN>
<TOKEN end_char="1817" id="token-13-1" morph="none" pos="word" start_char="1816">on</TOKEN>
<TOKEN end_char="1826" id="token-13-2" morph="none" pos="word" start_char="1819">multiple</TOKEN>
<TOKEN end_char="1836" id="token-13-3" morph="none" pos="word" start_char="1828">platforms</TOKEN>
<TOKEN end_char="1840" id="token-13-4" morph="none" pos="word" start_char="1838">and</TOKEN>
<TOKEN end_char="1849" id="token-13-5" morph="none" pos="word" start_char="1842">networks</TOKEN>
<TOKEN end_char="1854" id="token-13-6" morph="none" pos="word" start_char="1851">have</TOKEN>
<TOKEN end_char="1861" id="token-13-7" morph="none" pos="word" start_char="1856">shared</TOKEN>
<TOKEN end_char="1865" id="token-13-8" morph="none" pos="word" start_char="1863">the</TOKEN>
<TOKEN end_char="1870" id="token-13-9" morph="none" pos="word" start_char="1867">same</TOKEN>
<TOKEN end_char="1873" id="token-13-10" morph="none" pos="word" start_char="1872">or</TOKEN>
<TOKEN end_char="1875" id="token-13-11" morph="none" pos="word" start_char="1875">a</TOKEN>
<TOKEN end_char="1883" id="token-13-12" morph="none" pos="word" start_char="1877">similar</TOKEN>
<TOKEN end_char="1891" id="token-13-13" morph="none" pos="word" start_char="1885">version</TOKEN>
<TOKEN end_char="1894" id="token-13-14" morph="none" pos="word" start_char="1893">of</TOKEN>
<TOKEN end_char="1898" id="token-13-15" morph="none" pos="word" start_char="1896">the</TOKEN>
<TOKEN end_char="1909" id="token-13-16" morph="none" pos="word" start_char="1900">conspiracy</TOKEN>
<TOKEN end_char="1916" id="token-13-17" morph="none" pos="word" start_char="1911">theory</TOKEN>
<TOKEN end_char="1917" id="token-13-18" morph="none" pos="punct" start_char="1917">.</TOKEN>
</SEG>
<SEG end_char="1923" id="segment-14" start_char="1920">
<ORIGINAL_TEXT>Sen.</ORIGINAL_TEXT>
<TOKEN end_char="1922" id="token-14-0" morph="none" pos="word" start_char="1920">Sen</TOKEN>
<TOKEN end_char="1923" id="token-14-1" morph="none" pos="punct" start_char="1923">.</TOKEN>
<TRANSLATED_TEXT>You...</TRANSLATED_TEXT><DETECTED_LANGUAGE>fi</DETECTED_LANGUAGE></SEG>
<SEG end_char="2064" id="segment-15" start_char="1925">
<ORIGINAL_TEXT>Tom Cotton, R-Ark., has suggested to Congress and Fox News that there may be a connection between the Wuhan lab and the origin of the virus.</ORIGINAL_TEXT>
<TOKEN end_char="1927" id="token-15-0" morph="none" pos="word" start_char="1925">Tom</TOKEN>
<TOKEN end_char="1934" id="token-15-1" morph="none" pos="word" start_char="1929">Cotton</TOKEN>
<TOKEN end_char="1935" id="token-15-2" morph="none" pos="punct" start_char="1935">,</TOKEN>
<TOKEN end_char="1941" id="token-15-3" morph="none" pos="unknown" start_char="1937">R-Ark</TOKEN>
<TOKEN end_char="1943" id="token-15-4" morph="none" pos="punct" start_char="1942">.,</TOKEN>
<TOKEN end_char="1947" id="token-15-5" morph="none" pos="word" start_char="1945">has</TOKEN>
<TOKEN end_char="1957" id="token-15-6" morph="none" pos="word" start_char="1949">suggested</TOKEN>
<TOKEN end_char="1960" id="token-15-7" morph="none" pos="word" start_char="1959">to</TOKEN>
<TOKEN end_char="1969" id="token-15-8" morph="none" pos="word" start_char="1962">Congress</TOKEN>
<TOKEN end_char="1973" id="token-15-9" morph="none" pos="word" start_char="1971">and</TOKEN>
<TOKEN end_char="1977" id="token-15-10" morph="none" pos="word" start_char="1975">Fox</TOKEN>
<TOKEN end_char="1982" id="token-15-11" morph="none" pos="word" start_char="1979">News</TOKEN>
<TOKEN end_char="1987" id="token-15-12" morph="none" pos="word" start_char="1984">that</TOKEN>
<TOKEN end_char="1993" id="token-15-13" morph="none" pos="word" start_char="1989">there</TOKEN>
<TOKEN end_char="1997" id="token-15-14" morph="none" pos="word" start_char="1995">may</TOKEN>
<TOKEN end_char="2000" id="token-15-15" morph="none" pos="word" start_char="1999">be</TOKEN>
<TOKEN end_char="2002" id="token-15-16" morph="none" pos="word" start_char="2002">a</TOKEN>
<TOKEN end_char="2013" id="token-15-17" morph="none" pos="word" start_char="2004">connection</TOKEN>
<TOKEN end_char="2021" id="token-15-18" morph="none" pos="word" start_char="2015">between</TOKEN>
<TOKEN end_char="2025" id="token-15-19" morph="none" pos="word" start_char="2023">the</TOKEN>
<TOKEN end_char="2031" id="token-15-20" morph="none" pos="word" start_char="2027">Wuhan</TOKEN>
<TOKEN end_char="2035" id="token-15-21" morph="none" pos="word" start_char="2033">lab</TOKEN>
<TOKEN end_char="2039" id="token-15-22" morph="none" pos="word" start_char="2037">and</TOKEN>
<TOKEN end_char="2043" id="token-15-23" morph="none" pos="word" start_char="2041">the</TOKEN>
<TOKEN end_char="2050" id="token-15-24" morph="none" pos="word" start_char="2045">origin</TOKEN>
<TOKEN end_char="2053" id="token-15-25" morph="none" pos="word" start_char="2052">of</TOKEN>
<TOKEN end_char="2057" id="token-15-26" morph="none" pos="word" start_char="2055">the</TOKEN>
<TOKEN end_char="2063" id="token-15-27" morph="none" pos="word" start_char="2059">virus</TOKEN>
<TOKEN end_char="2064" id="token-15-28" morph="none" pos="punct" start_char="2064">.</TOKEN>
</SEG>
<SEG end_char="2255" id="segment-16" start_char="2066">
<ORIGINAL_TEXT>And conservative radio host Rush Limbaugh wrote in an article in February that "it probably is a ChiCom (Chinese Communist) laboratory experiment that is in the process of being weaponized."</ORIGINAL_TEXT>
<TOKEN end_char="2068" id="token-16-0" morph="none" pos="word" start_char="2066">And</TOKEN>
<TOKEN end_char="2081" id="token-16-1" morph="none" pos="word" start_char="2070">conservative</TOKEN>
<TOKEN end_char="2087" id="token-16-2" morph="none" pos="word" start_char="2083">radio</TOKEN>
<TOKEN end_char="2092" id="token-16-3" morph="none" pos="word" start_char="2089">host</TOKEN>
<TOKEN end_char="2097" id="token-16-4" morph="none" pos="word" start_char="2094">Rush</TOKEN>
<TOKEN end_char="2106" id="token-16-5" morph="none" pos="word" start_char="2099">Limbaugh</TOKEN>
<TOKEN end_char="2112" id="token-16-6" morph="none" pos="word" start_char="2108">wrote</TOKEN>
<TOKEN end_char="2115" id="token-16-7" morph="none" pos="word" start_char="2114">in</TOKEN>
<TOKEN end_char="2118" id="token-16-8" morph="none" pos="word" start_char="2117">an</TOKEN>
<TOKEN end_char="2126" id="token-16-9" morph="none" pos="word" start_char="2120">article</TOKEN>
<TOKEN end_char="2129" id="token-16-10" morph="none" pos="word" start_char="2128">in</TOKEN>
<TOKEN end_char="2138" id="token-16-11" morph="none" pos="word" start_char="2131">February</TOKEN>
<TOKEN end_char="2143" id="token-16-12" morph="none" pos="word" start_char="2140">that</TOKEN>
<TOKEN end_char="2145" id="token-16-13" morph="none" pos="punct" start_char="2145">"</TOKEN>
<TOKEN end_char="2147" id="token-16-14" morph="none" pos="word" start_char="2146">it</TOKEN>
<TOKEN end_char="2156" id="token-16-15" morph="none" pos="word" start_char="2149">probably</TOKEN>
<TOKEN end_char="2159" id="token-16-16" morph="none" pos="word" start_char="2158">is</TOKEN>
<TOKEN end_char="2161" id="token-16-17" morph="none" pos="word" start_char="2161">a</TOKEN>
<TOKEN end_char="2168" id="token-16-18" morph="none" pos="word" start_char="2163">ChiCom</TOKEN>
<TOKEN end_char="2170" id="token-16-19" morph="none" pos="punct" start_char="2170">(</TOKEN>
<TOKEN end_char="2177" id="token-16-20" morph="none" pos="word" start_char="2171">Chinese</TOKEN>
<TOKEN end_char="2187" id="token-16-21" morph="none" pos="word" start_char="2179">Communist</TOKEN>
<TOKEN end_char="2188" id="token-16-22" morph="none" pos="punct" start_char="2188">)</TOKEN>
<TOKEN end_char="2199" id="token-16-23" morph="none" pos="word" start_char="2190">laboratory</TOKEN>
<TOKEN end_char="2210" id="token-16-24" morph="none" pos="word" start_char="2201">experiment</TOKEN>
<TOKEN end_char="2215" id="token-16-25" morph="none" pos="word" start_char="2212">that</TOKEN>
<TOKEN end_char="2218" id="token-16-26" morph="none" pos="word" start_char="2217">is</TOKEN>
<TOKEN end_char="2221" id="token-16-27" morph="none" pos="word" start_char="2220">in</TOKEN>
<TOKEN end_char="2225" id="token-16-28" morph="none" pos="word" start_char="2223">the</TOKEN>
<TOKEN end_char="2233" id="token-16-29" morph="none" pos="word" start_char="2227">process</TOKEN>
<TOKEN end_char="2236" id="token-16-30" morph="none" pos="word" start_char="2235">of</TOKEN>
<TOKEN end_char="2242" id="token-16-31" morph="none" pos="word" start_char="2238">being</TOKEN>
<TOKEN end_char="2253" id="token-16-32" morph="none" pos="word" start_char="2244">weaponized</TOKEN>
<TOKEN end_char="2255" id="token-16-33" morph="none" pos="punct" start_char="2254">."</TOKEN>
</SEG>
<SEG end_char="2346" id="segment-17" start_char="2258">
<ORIGINAL_TEXT>Former White House strategist Steve Bannon repeated a similar claim on Fox News in March.</ORIGINAL_TEXT>
<TOKEN end_char="2263" id="token-17-0" morph="none" pos="word" start_char="2258">Former</TOKEN>
<TOKEN end_char="2269" id="token-17-1" morph="none" pos="word" start_char="2265">White</TOKEN>
<TOKEN end_char="2275" id="token-17-2" morph="none" pos="word" start_char="2271">House</TOKEN>
<TOKEN end_char="2286" id="token-17-3" morph="none" pos="word" start_char="2277">strategist</TOKEN>
<TOKEN end_char="2292" id="token-17-4" morph="none" pos="word" start_char="2288">Steve</TOKEN>
<TOKEN end_char="2299" id="token-17-5" morph="none" pos="word" start_char="2294">Bannon</TOKEN>
<TOKEN end_char="2308" id="token-17-6" morph="none" pos="word" start_char="2301">repeated</TOKEN>
<TOKEN end_char="2310" id="token-17-7" morph="none" pos="word" start_char="2310">a</TOKEN>
<TOKEN end_char="2318" id="token-17-8" morph="none" pos="word" start_char="2312">similar</TOKEN>
<TOKEN end_char="2324" id="token-17-9" morph="none" pos="word" start_char="2320">claim</TOKEN>
<TOKEN end_char="2327" id="token-17-10" morph="none" pos="word" start_char="2326">on</TOKEN>
<TOKEN end_char="2331" id="token-17-11" morph="none" pos="word" start_char="2329">Fox</TOKEN>
<TOKEN end_char="2336" id="token-17-12" morph="none" pos="word" start_char="2333">News</TOKEN>
<TOKEN end_char="2339" id="token-17-13" morph="none" pos="word" start_char="2338">in</TOKEN>
<TOKEN end_char="2345" id="token-17-14" morph="none" pos="word" start_char="2341">March</TOKEN>
<TOKEN end_char="2346" id="token-17-15" morph="none" pos="punct" start_char="2346">.</TOKEN>
</SEG>
<SEG end_char="2432" id="segment-18" start_char="2348">
<ORIGINAL_TEXT>And opinion columnist Steven Mosher touted the idea in the New York Post in February.</ORIGINAL_TEXT>
<TOKEN end_char="2350" id="token-18-0" morph="none" pos="word" start_char="2348">And</TOKEN>
<TOKEN end_char="2358" id="token-18-1" morph="none" pos="word" start_char="2352">opinion</TOKEN>
<TOKEN end_char="2368" id="token-18-2" morph="none" pos="word" start_char="2360">columnist</TOKEN>
<TOKEN end_char="2375" id="token-18-3" morph="none" pos="word" start_char="2370">Steven</TOKEN>
<TOKEN end_char="2382" id="token-18-4" morph="none" pos="word" start_char="2377">Mosher</TOKEN>
<TOKEN end_char="2389" id="token-18-5" morph="none" pos="word" start_char="2384">touted</TOKEN>
<TOKEN end_char="2393" id="token-18-6" morph="none" pos="word" start_char="2391">the</TOKEN>
<TOKEN end_char="2398" id="token-18-7" morph="none" pos="word" start_char="2395">idea</TOKEN>
<TOKEN end_char="2401" id="token-18-8" morph="none" pos="word" start_char="2400">in</TOKEN>
<TOKEN end_char="2405" id="token-18-9" morph="none" pos="word" start_char="2403">the</TOKEN>
<TOKEN end_char="2409" id="token-18-10" morph="none" pos="word" start_char="2407">New</TOKEN>
<TOKEN end_char="2414" id="token-18-11" morph="none" pos="word" start_char="2411">York</TOKEN>
<TOKEN end_char="2419" id="token-18-12" morph="none" pos="word" start_char="2416">Post</TOKEN>
<TOKEN end_char="2422" id="token-18-13" morph="none" pos="word" start_char="2421">in</TOKEN>
<TOKEN end_char="2431" id="token-18-14" morph="none" pos="word" start_char="2424">February</TOKEN>
<TOKEN end_char="2432" id="token-18-15" morph="none" pos="punct" start_char="2432">.</TOKEN>
</SEG>
<SEG end_char="2592" id="segment-19" start_char="2435">
<ORIGINAL_TEXT>Vox reported the claim also has been shared widely via message boards in China, prompting Chinese officials to release a statement denouncing the information.</ORIGINAL_TEXT>
<TOKEN end_char="2437" id="token-19-0" morph="none" pos="word" start_char="2435">Vox</TOKEN>
<TOKEN end_char="2446" id="token-19-1" morph="none" pos="word" start_char="2439">reported</TOKEN>
<TOKEN end_char="2450" id="token-19-2" morph="none" pos="word" start_char="2448">the</TOKEN>
<TOKEN end_char="2456" id="token-19-3" morph="none" pos="word" start_char="2452">claim</TOKEN>
<TOKEN end_char="2461" id="token-19-4" morph="none" pos="word" start_char="2458">also</TOKEN>
<TOKEN end_char="2465" id="token-19-5" morph="none" pos="word" start_char="2463">has</TOKEN>
<TOKEN end_char="2470" id="token-19-6" morph="none" pos="word" start_char="2467">been</TOKEN>
<TOKEN end_char="2477" id="token-19-7" morph="none" pos="word" start_char="2472">shared</TOKEN>
<TOKEN end_char="2484" id="token-19-8" morph="none" pos="word" start_char="2479">widely</TOKEN>
<TOKEN end_char="2488" id="token-19-9" morph="none" pos="word" start_char="2486">via</TOKEN>
<TOKEN end_char="2496" id="token-19-10" morph="none" pos="word" start_char="2490">message</TOKEN>
<TOKEN end_char="2503" id="token-19-11" morph="none" pos="word" start_char="2498">boards</TOKEN>
<TOKEN end_char="2506" id="token-19-12" morph="none" pos="word" start_char="2505">in</TOKEN>
<TOKEN end_char="2512" id="token-19-13" morph="none" pos="word" start_char="2508">China</TOKEN>
<TOKEN end_char="2513" id="token-19-14" morph="none" pos="punct" start_char="2513">,</TOKEN>
<TOKEN end_char="2523" id="token-19-15" morph="none" pos="word" start_char="2515">prompting</TOKEN>
<TOKEN end_char="2531" id="token-19-16" morph="none" pos="word" start_char="2525">Chinese</TOKEN>
<TOKEN end_char="2541" id="token-19-17" morph="none" pos="word" start_char="2533">officials</TOKEN>
<TOKEN end_char="2544" id="token-19-18" morph="none" pos="word" start_char="2543">to</TOKEN>
<TOKEN end_char="2552" id="token-19-19" morph="none" pos="word" start_char="2546">release</TOKEN>
<TOKEN end_char="2554" id="token-19-20" morph="none" pos="word" start_char="2554">a</TOKEN>
<TOKEN end_char="2564" id="token-19-21" morph="none" pos="word" start_char="2556">statement</TOKEN>
<TOKEN end_char="2575" id="token-19-22" morph="none" pos="word" start_char="2566">denouncing</TOKEN>
<TOKEN end_char="2579" id="token-19-23" morph="none" pos="word" start_char="2577">the</TOKEN>
<TOKEN end_char="2591" id="token-19-24" morph="none" pos="word" start_char="2581">information</TOKEN>
<TOKEN end_char="2592" id="token-19-25" morph="none" pos="punct" start_char="2592">.</TOKEN>
</SEG>
<SEG end_char="2652" id="segment-20" start_char="2595">
<ORIGINAL_TEXT>What researchers say: COVID-19 likely originated in nature</ORIGINAL_TEXT>
<TOKEN end_char="2598" id="token-20-0" morph="none" pos="word" start_char="2595">What</TOKEN>
<TOKEN end_char="2610" id="token-20-1" morph="none" pos="word" start_char="2600">researchers</TOKEN>
<TOKEN end_char="2614" id="token-20-2" morph="none" pos="word" start_char="2612">say</TOKEN>
<TOKEN end_char="2615" id="token-20-3" morph="none" pos="punct" start_char="2615">:</TOKEN>
<TOKEN end_char="2624" id="token-20-4" morph="none" pos="unknown" start_char="2617">COVID-19</TOKEN>
<TOKEN end_char="2631" id="token-20-5" morph="none" pos="word" start_char="2626">likely</TOKEN>
<TOKEN end_char="2642" id="token-20-6" morph="none" pos="word" start_char="2633">originated</TOKEN>
<TOKEN end_char="2645" id="token-20-7" morph="none" pos="word" start_char="2644">in</TOKEN>
<TOKEN end_char="2652" id="token-20-8" morph="none" pos="word" start_char="2647">nature</TOKEN>
</SEG>
<SEG end_char="2766" id="segment-21" start_char="2656">
<ORIGINAL_TEXT>Researchers have been racing to learn about the virus since it was recognized in December 2019 as a new strain.</ORIGINAL_TEXT>
<TOKEN end_char="2666" id="token-21-0" morph="none" pos="word" start_char="2656">Researchers</TOKEN>
<TOKEN end_char="2671" id="token-21-1" morph="none" pos="word" start_char="2668">have</TOKEN>
<TOKEN end_char="2676" id="token-21-2" morph="none" pos="word" start_char="2673">been</TOKEN>
<TOKEN end_char="2683" id="token-21-3" morph="none" pos="word" start_char="2678">racing</TOKEN>
<TOKEN end_char="2686" id="token-21-4" morph="none" pos="word" start_char="2685">to</TOKEN>
<TOKEN end_char="2692" id="token-21-5" morph="none" pos="word" start_char="2688">learn</TOKEN>
<TOKEN end_char="2698" id="token-21-6" morph="none" pos="word" start_char="2694">about</TOKEN>
<TOKEN end_char="2702" id="token-21-7" morph="none" pos="word" start_char="2700">the</TOKEN>
<TOKEN end_char="2708" id="token-21-8" morph="none" pos="word" start_char="2704">virus</TOKEN>
<TOKEN end_char="2714" id="token-21-9" morph="none" pos="word" start_char="2710">since</TOKEN>
<TOKEN end_char="2717" id="token-21-10" morph="none" pos="word" start_char="2716">it</TOKEN>
<TOKEN end_char="2721" id="token-21-11" morph="none" pos="word" start_char="2719">was</TOKEN>
<TOKEN end_char="2732" id="token-21-12" morph="none" pos="word" start_char="2723">recognized</TOKEN>
<TOKEN end_char="2735" id="token-21-13" morph="none" pos="word" start_char="2734">in</TOKEN>
<TOKEN end_char="2744" id="token-21-14" morph="none" pos="word" start_char="2737">December</TOKEN>
<TOKEN end_char="2749" id="token-21-15" morph="none" pos="word" start_char="2746">2019</TOKEN>
<TOKEN end_char="2752" id="token-21-16" morph="none" pos="word" start_char="2751">as</TOKEN>
<TOKEN end_char="2754" id="token-21-17" morph="none" pos="word" start_char="2754">a</TOKEN>
<TOKEN end_char="2758" id="token-21-18" morph="none" pos="word" start_char="2756">new</TOKEN>
<TOKEN end_char="2765" id="token-21-19" morph="none" pos="word" start_char="2760">strain</TOKEN>
<TOKEN end_char="2766" id="token-21-20" morph="none" pos="punct" start_char="2766">.</TOKEN>
</SEG>
<SEG end_char="2849" id="segment-22" start_char="2768">
<ORIGINAL_TEXT>Medical journals have pointed toward animals in nature as the origin of the virus.</ORIGINAL_TEXT>
<TOKEN end_char="2774" id="token-22-0" morph="none" pos="word" start_char="2768">Medical</TOKEN>
<TOKEN end_char="2783" id="token-22-1" morph="none" pos="word" start_char="2776">journals</TOKEN>
<TOKEN end_char="2788" id="token-22-2" morph="none" pos="word" start_char="2785">have</TOKEN>
<TOKEN end_char="2796" id="token-22-3" morph="none" pos="word" start_char="2790">pointed</TOKEN>
<TOKEN end_char="2803" id="token-22-4" morph="none" pos="word" start_char="2798">toward</TOKEN>
<TOKEN end_char="2811" id="token-22-5" morph="none" pos="word" start_char="2805">animals</TOKEN>
<TOKEN end_char="2814" id="token-22-6" morph="none" pos="word" start_char="2813">in</TOKEN>
<TOKEN end_char="2821" id="token-22-7" morph="none" pos="word" start_char="2816">nature</TOKEN>
<TOKEN end_char="2824" id="token-22-8" morph="none" pos="word" start_char="2823">as</TOKEN>
<TOKEN end_char="2828" id="token-22-9" morph="none" pos="word" start_char="2826">the</TOKEN>
<TOKEN end_char="2835" id="token-22-10" morph="none" pos="word" start_char="2830">origin</TOKEN>
<TOKEN end_char="2838" id="token-22-11" morph="none" pos="word" start_char="2837">of</TOKEN>
<TOKEN end_char="2842" id="token-22-12" morph="none" pos="word" start_char="2840">the</TOKEN>
<TOKEN end_char="2848" id="token-22-13" morph="none" pos="word" start_char="2844">virus</TOKEN>
<TOKEN end_char="2849" id="token-22-14" morph="none" pos="punct" start_char="2849">.</TOKEN>
</SEG>
<SEG end_char="3078" id="segment-23" start_char="2852">
<ORIGINAL_TEXT>On April 21, the World Health Organization noted at a briefing that available evidence indicates coronavirus originated in animals in China late last year and was not manipulated or produced in a laboratory as has been alleged.</ORIGINAL_TEXT>
<TOKEN end_char="2853" id="token-23-0" morph="none" pos="word" start_char="2852">On</TOKEN>
<TOKEN end_char="2859" id="token-23-1" morph="none" pos="word" start_char="2855">April</TOKEN>
<TOKEN end_char="2862" id="token-23-2" morph="none" pos="word" start_char="2861">21</TOKEN>
<TOKEN end_char="2863" id="token-23-3" morph="none" pos="punct" start_char="2863">,</TOKEN>
<TOKEN end_char="2867" id="token-23-4" morph="none" pos="word" start_char="2865">the</TOKEN>
<TOKEN end_char="2873" id="token-23-5" morph="none" pos="word" start_char="2869">World</TOKEN>
<TOKEN end_char="2880" id="token-23-6" morph="none" pos="word" start_char="2875">Health</TOKEN>
<TOKEN end_char="2893" id="token-23-7" morph="none" pos="word" start_char="2882">Organization</TOKEN>
<TOKEN end_char="2899" id="token-23-8" morph="none" pos="word" start_char="2895">noted</TOKEN>
<TOKEN end_char="2902" id="token-23-9" morph="none" pos="word" start_char="2901">at</TOKEN>
<TOKEN end_char="2904" id="token-23-10" morph="none" pos="word" start_char="2904">a</TOKEN>
<TOKEN end_char="2913" id="token-23-11" morph="none" pos="word" start_char="2906">briefing</TOKEN>
<TOKEN end_char="2918" id="token-23-12" morph="none" pos="word" start_char="2915">that</TOKEN>
<TOKEN end_char="2928" id="token-23-13" morph="none" pos="word" start_char="2920">available</TOKEN>
<TOKEN end_char="2937" id="token-23-14" morph="none" pos="word" start_char="2930">evidence</TOKEN>
<TOKEN end_char="2947" id="token-23-15" morph="none" pos="word" start_char="2939">indicates</TOKEN>
<TOKEN end_char="2959" id="token-23-16" morph="none" pos="word" start_char="2949">coronavirus</TOKEN>
<TOKEN end_char="2970" id="token-23-17" morph="none" pos="word" start_char="2961">originated</TOKEN>
<TOKEN end_char="2973" id="token-23-18" morph="none" pos="word" start_char="2972">in</TOKEN>
<TOKEN end_char="2981" id="token-23-19" morph="none" pos="word" start_char="2975">animals</TOKEN>
<TOKEN end_char="2984" id="token-23-20" morph="none" pos="word" start_char="2983">in</TOKEN>
<TOKEN end_char="2990" id="token-23-21" morph="none" pos="word" start_char="2986">China</TOKEN>
<TOKEN end_char="2995" id="token-23-22" morph="none" pos="word" start_char="2992">late</TOKEN>
<TOKEN end_char="3000" id="token-23-23" morph="none" pos="word" start_char="2997">last</TOKEN>
<TOKEN end_char="3005" id="token-23-24" morph="none" pos="word" start_char="3002">year</TOKEN>
<TOKEN end_char="3009" id="token-23-25" morph="none" pos="word" start_char="3007">and</TOKEN>
<TOKEN end_char="3013" id="token-23-26" morph="none" pos="word" start_char="3011">was</TOKEN>
<TOKEN end_char="3017" id="token-23-27" morph="none" pos="word" start_char="3015">not</TOKEN>
<TOKEN end_char="3029" id="token-23-28" morph="none" pos="word" start_char="3019">manipulated</TOKEN>
<TOKEN end_char="3032" id="token-23-29" morph="none" pos="word" start_char="3031">or</TOKEN>
<TOKEN end_char="3041" id="token-23-30" morph="none" pos="word" start_char="3034">produced</TOKEN>
<TOKEN end_char="3044" id="token-23-31" morph="none" pos="word" start_char="3043">in</TOKEN>
<TOKEN end_char="3046" id="token-23-32" morph="none" pos="word" start_char="3046">a</TOKEN>
<TOKEN end_char="3057" id="token-23-33" morph="none" pos="word" start_char="3048">laboratory</TOKEN>
<TOKEN end_char="3060" id="token-23-34" morph="none" pos="word" start_char="3059">as</TOKEN>
<TOKEN end_char="3064" id="token-23-35" morph="none" pos="word" start_char="3062">has</TOKEN>
<TOKEN end_char="3069" id="token-23-36" morph="none" pos="word" start_char="3066">been</TOKEN>
<TOKEN end_char="3077" id="token-23-37" morph="none" pos="word" start_char="3071">alleged</TOKEN>
<TOKEN end_char="3078" id="token-23-38" morph="none" pos="punct" start_char="3078">.</TOKEN>
</SEG>
<SEG end_char="3176" id="segment-24" start_char="3081">
<ORIGINAL_TEXT>"It is probable, likely, that the virus is of animal origin," WHO spokeswoman Fadela Chaib said.</ORIGINAL_TEXT>
<TOKEN end_char="3081" id="token-24-0" morph="none" pos="punct" start_char="3081">"</TOKEN>
<TOKEN end_char="3083" id="token-24-1" morph="none" pos="word" start_char="3082">It</TOKEN>
<TOKEN end_char="3086" id="token-24-2" morph="none" pos="word" start_char="3085">is</TOKEN>
<TOKEN end_char="3095" id="token-24-3" morph="none" pos="word" start_char="3088">probable</TOKEN>
<TOKEN end_char="3096" id="token-24-4" morph="none" pos="punct" start_char="3096">,</TOKEN>
<TOKEN end_char="3103" id="token-24-5" morph="none" pos="word" start_char="3098">likely</TOKEN>
<TOKEN end_char="3104" id="token-24-6" morph="none" pos="punct" start_char="3104">,</TOKEN>
<TOKEN end_char="3109" id="token-24-7" morph="none" pos="word" start_char="3106">that</TOKEN>
<TOKEN end_char="3113" id="token-24-8" morph="none" pos="word" start_char="3111">the</TOKEN>
<TOKEN end_char="3119" id="token-24-9" morph="none" pos="word" start_char="3115">virus</TOKEN>
<TOKEN end_char="3122" id="token-24-10" morph="none" pos="word" start_char="3121">is</TOKEN>
<TOKEN end_char="3125" id="token-24-11" morph="none" pos="word" start_char="3124">of</TOKEN>
<TOKEN end_char="3132" id="token-24-12" morph="none" pos="word" start_char="3127">animal</TOKEN>
<TOKEN end_char="3139" id="token-24-13" morph="none" pos="word" start_char="3134">origin</TOKEN>
<TOKEN end_char="3141" id="token-24-14" morph="none" pos="punct" start_char="3140">,"</TOKEN>
<TOKEN end_char="3145" id="token-24-15" morph="none" pos="word" start_char="3143">WHO</TOKEN>
<TOKEN end_char="3157" id="token-24-16" morph="none" pos="word" start_char="3147">spokeswoman</TOKEN>
<TOKEN end_char="3164" id="token-24-17" morph="none" pos="word" start_char="3159">Fadela</TOKEN>
<TOKEN end_char="3170" id="token-24-18" morph="none" pos="word" start_char="3166">Chaib</TOKEN>
<TOKEN end_char="3175" id="token-24-19" morph="none" pos="word" start_char="3172">said</TOKEN>
<TOKEN end_char="3176" id="token-24-20" morph="none" pos="punct" start_char="3176">.</TOKEN>
</SEG>
<SEG end_char="3425" id="segment-25" start_char="3179">
<ORIGINAL_TEXT>Richard Ebright, a professor of chemical biology at Rutgers University, said earlier this year in an interview with The Washington Post: "Based on the virus genome and properties, there is no indication whatsoever that it was an engineered virus."</ORIGINAL_TEXT>
<TOKEN end_char="3185" id="token-25-0" morph="none" pos="word" start_char="3179">Richard</TOKEN>
<TOKEN end_char="3193" id="token-25-1" morph="none" pos="word" start_char="3187">Ebright</TOKEN>
<TOKEN end_char="3194" id="token-25-2" morph="none" pos="punct" start_char="3194">,</TOKEN>
<TOKEN end_char="3196" id="token-25-3" morph="none" pos="word" start_char="3196">a</TOKEN>
<TOKEN end_char="3206" id="token-25-4" morph="none" pos="word" start_char="3198">professor</TOKEN>
<TOKEN end_char="3209" id="token-25-5" morph="none" pos="word" start_char="3208">of</TOKEN>
<TOKEN end_char="3218" id="token-25-6" morph="none" pos="word" start_char="3211">chemical</TOKEN>
<TOKEN end_char="3226" id="token-25-7" morph="none" pos="word" start_char="3220">biology</TOKEN>
<TOKEN end_char="3229" id="token-25-8" morph="none" pos="word" start_char="3228">at</TOKEN>
<TOKEN end_char="3237" id="token-25-9" morph="none" pos="word" start_char="3231">Rutgers</TOKEN>
<TOKEN end_char="3248" id="token-25-10" morph="none" pos="word" start_char="3239">University</TOKEN>
<TOKEN end_char="3249" id="token-25-11" morph="none" pos="punct" start_char="3249">,</TOKEN>
<TOKEN end_char="3254" id="token-25-12" morph="none" pos="word" start_char="3251">said</TOKEN>
<TOKEN end_char="3262" id="token-25-13" morph="none" pos="word" start_char="3256">earlier</TOKEN>
<TOKEN end_char="3267" id="token-25-14" morph="none" pos="word" start_char="3264">this</TOKEN>
<TOKEN end_char="3272" id="token-25-15" morph="none" pos="word" start_char="3269">year</TOKEN>
<TOKEN end_char="3275" id="token-25-16" morph="none" pos="word" start_char="3274">in</TOKEN>
<TOKEN end_char="3278" id="token-25-17" morph="none" pos="word" start_char="3277">an</TOKEN>
<TOKEN end_char="3288" id="token-25-18" morph="none" pos="word" start_char="3280">interview</TOKEN>
<TOKEN end_char="3293" id="token-25-19" morph="none" pos="word" start_char="3290">with</TOKEN>
<TOKEN end_char="3297" id="token-25-20" morph="none" pos="word" start_char="3295">The</TOKEN>
<TOKEN end_char="3308" id="token-25-21" morph="none" pos="word" start_char="3299">Washington</TOKEN>
<TOKEN end_char="3313" id="token-25-22" morph="none" pos="word" start_char="3310">Post</TOKEN>
<TOKEN end_char="3314" id="token-25-23" morph="none" pos="punct" start_char="3314">:</TOKEN>
<TOKEN end_char="3316" id="token-25-24" morph="none" pos="punct" start_char="3316">"</TOKEN>
<TOKEN end_char="3321" id="token-25-25" morph="none" pos="word" start_char="3317">Based</TOKEN>
<TOKEN end_char="3324" id="token-25-26" morph="none" pos="word" start_char="3323">on</TOKEN>
<TOKEN end_char="3328" id="token-25-27" morph="none" pos="word" start_char="3326">the</TOKEN>
<TOKEN end_char="3334" id="token-25-28" morph="none" pos="word" start_char="3330">virus</TOKEN>
<TOKEN end_char="3341" id="token-25-29" morph="none" pos="word" start_char="3336">genome</TOKEN>
<TOKEN end_char="3345" id="token-25-30" morph="none" pos="word" start_char="3343">and</TOKEN>
<TOKEN end_char="3356" id="token-25-31" morph="none" pos="word" start_char="3347">properties</TOKEN>
<TOKEN end_char="3357" id="token-25-32" morph="none" pos="punct" start_char="3357">,</TOKEN>
<TOKEN end_char="3363" id="token-25-33" morph="none" pos="word" start_char="3359">there</TOKEN>
<TOKEN end_char="3366" id="token-25-34" morph="none" pos="word" start_char="3365">is</TOKEN>
<TOKEN end_char="3369" id="token-25-35" morph="none" pos="word" start_char="3368">no</TOKEN>
<TOKEN end_char="3380" id="token-25-36" morph="none" pos="word" start_char="3371">indication</TOKEN>
<TOKEN end_char="3391" id="token-25-37" morph="none" pos="word" start_char="3382">whatsoever</TOKEN>
<TOKEN end_char="3396" id="token-25-38" morph="none" pos="word" start_char="3393">that</TOKEN>
<TOKEN end_char="3399" id="token-25-39" morph="none" pos="word" start_char="3398">it</TOKEN>
<TOKEN end_char="3403" id="token-25-40" morph="none" pos="word" start_char="3401">was</TOKEN>
<TOKEN end_char="3406" id="token-25-41" morph="none" pos="word" start_char="3405">an</TOKEN>
<TOKEN end_char="3417" id="token-25-42" morph="none" pos="word" start_char="3408">engineered</TOKEN>
<TOKEN end_char="3423" id="token-25-43" morph="none" pos="word" start_char="3419">virus</TOKEN>
<TOKEN end_char="3425" id="token-25-44" morph="none" pos="punct" start_char="3424">."</TOKEN>
</SEG>
<SEG end_char="3567" id="segment-26" start_char="3428">
<ORIGINAL_TEXT>The Washington Post reported most countries have abandoned their bioweapons programs after years of work did not yield satisfactory results.</ORIGINAL_TEXT>
<TOKEN end_char="3430" id="token-26-0" morph="none" pos="word" start_char="3428">The</TOKEN>
<TOKEN end_char="3441" id="token-26-1" morph="none" pos="word" start_char="3432">Washington</TOKEN>
<TOKEN end_char="3446" id="token-26-2" morph="none" pos="word" start_char="3443">Post</TOKEN>
<TOKEN end_char="3455" id="token-26-3" morph="none" pos="word" start_char="3448">reported</TOKEN>
<TOKEN end_char="3460" id="token-26-4" morph="none" pos="word" start_char="3457">most</TOKEN>
<TOKEN end_char="3470" id="token-26-5" morph="none" pos="word" start_char="3462">countries</TOKEN>
<TOKEN end_char="3475" id="token-26-6" morph="none" pos="word" start_char="3472">have</TOKEN>
<TOKEN end_char="3485" id="token-26-7" morph="none" pos="word" start_char="3477">abandoned</TOKEN>
<TOKEN end_char="3491" id="token-26-8" morph="none" pos="word" start_char="3487">their</TOKEN>
<TOKEN end_char="3502" id="token-26-9" morph="none" pos="word" start_char="3493">bioweapons</TOKEN>
<TOKEN end_char="3511" id="token-26-10" morph="none" pos="word" start_char="3504">programs</TOKEN>
<TOKEN end_char="3517" id="token-26-11" morph="none" pos="word" start_char="3513">after</TOKEN>
<TOKEN end_char="3523" id="token-26-12" morph="none" pos="word" start_char="3519">years</TOKEN>
<TOKEN end_char="3526" id="token-26-13" morph="none" pos="word" start_char="3525">of</TOKEN>
<TOKEN end_char="3531" id="token-26-14" morph="none" pos="word" start_char="3528">work</TOKEN>
<TOKEN end_char="3535" id="token-26-15" morph="none" pos="word" start_char="3533">did</TOKEN>
<TOKEN end_char="3539" id="token-26-16" morph="none" pos="word" start_char="3537">not</TOKEN>
<TOKEN end_char="3545" id="token-26-17" morph="none" pos="word" start_char="3541">yield</TOKEN>
<TOKEN end_char="3558" id="token-26-18" morph="none" pos="word" start_char="3547">satisfactory</TOKEN>
<TOKEN end_char="3566" id="token-26-19" morph="none" pos="word" start_char="3560">results</TOKEN>
<TOKEN end_char="3567" id="token-26-20" morph="none" pos="punct" start_char="3567">.</TOKEN>
</SEG>
<SEG end_char="3669" id="segment-27" start_char="3570">
<ORIGINAL_TEXT>The Scripps Research Institute released a study that rejects the notion that the virus was man-made.</ORIGINAL_TEXT>
<TOKEN end_char="3572" id="token-27-0" morph="none" pos="word" start_char="3570">The</TOKEN>
<TOKEN end_char="3580" id="token-27-1" morph="none" pos="word" start_char="3574">Scripps</TOKEN>
<TOKEN end_char="3589" id="token-27-2" morph="none" pos="word" start_char="3582">Research</TOKEN>
<TOKEN end_char="3599" id="token-27-3" morph="none" pos="word" start_char="3591">Institute</TOKEN>
<TOKEN end_char="3608" id="token-27-4" morph="none" pos="word" start_char="3601">released</TOKEN>
<TOKEN end_char="3610" id="token-27-5" morph="none" pos="word" start_char="3610">a</TOKEN>
<TOKEN end_char="3616" id="token-27-6" morph="none" pos="word" start_char="3612">study</TOKEN>
<TOKEN end_char="3621" id="token-27-7" morph="none" pos="word" start_char="3618">that</TOKEN>
<TOKEN end_char="3629" id="token-27-8" morph="none" pos="word" start_char="3623">rejects</TOKEN>
<TOKEN end_char="3633" id="token-27-9" morph="none" pos="word" start_char="3631">the</TOKEN>
<TOKEN end_char="3640" id="token-27-10" morph="none" pos="word" start_char="3635">notion</TOKEN>
<TOKEN end_char="3645" id="token-27-11" morph="none" pos="word" start_char="3642">that</TOKEN>
<TOKEN end_char="3649" id="token-27-12" morph="none" pos="word" start_char="3647">the</TOKEN>
<TOKEN end_char="3655" id="token-27-13" morph="none" pos="word" start_char="3651">virus</TOKEN>
<TOKEN end_char="3659" id="token-27-14" morph="none" pos="word" start_char="3657">was</TOKEN>
<TOKEN end_char="3668" id="token-27-15" morph="none" pos="unknown" start_char="3661">man-made</TOKEN>
<TOKEN end_char="3669" id="token-27-16" morph="none" pos="punct" start_char="3669">.</TOKEN>
</SEG>
<SEG end_char="3828" id="segment-28" start_char="3671">
<ORIGINAL_TEXT>Researchers concluded that if the virus were engineered, its genome sequence would more closely resemble earlier and more serious versions of the coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="3681" id="token-28-0" morph="none" pos="word" start_char="3671">Researchers</TOKEN>
<TOKEN end_char="3691" id="token-28-1" morph="none" pos="word" start_char="3683">concluded</TOKEN>
<TOKEN end_char="3696" id="token-28-2" morph="none" pos="word" start_char="3693">that</TOKEN>
<TOKEN end_char="3699" id="token-28-3" morph="none" pos="word" start_char="3698">if</TOKEN>
<TOKEN end_char="3703" id="token-28-4" morph="none" pos="word" start_char="3701">the</TOKEN>
<TOKEN end_char="3709" id="token-28-5" morph="none" pos="word" start_char="3705">virus</TOKEN>
<TOKEN end_char="3714" id="token-28-6" morph="none" pos="word" start_char="3711">were</TOKEN>
<TOKEN end_char="3725" id="token-28-7" morph="none" pos="word" start_char="3716">engineered</TOKEN>
<TOKEN end_char="3726" id="token-28-8" morph="none" pos="punct" start_char="3726">,</TOKEN>
<TOKEN end_char="3730" id="token-28-9" morph="none" pos="word" start_char="3728">its</TOKEN>
<TOKEN end_char="3737" id="token-28-10" morph="none" pos="word" start_char="3732">genome</TOKEN>
<TOKEN end_char="3746" id="token-28-11" morph="none" pos="word" start_char="3739">sequence</TOKEN>
<TOKEN end_char="3752" id="token-28-12" morph="none" pos="word" start_char="3748">would</TOKEN>
<TOKEN end_char="3757" id="token-28-13" morph="none" pos="word" start_char="3754">more</TOKEN>
<TOKEN end_char="3765" id="token-28-14" morph="none" pos="word" start_char="3759">closely</TOKEN>
<TOKEN end_char="3774" id="token-28-15" morph="none" pos="word" start_char="3767">resemble</TOKEN>
<TOKEN end_char="3782" id="token-28-16" morph="none" pos="word" start_char="3776">earlier</TOKEN>
<TOKEN end_char="3786" id="token-28-17" morph="none" pos="word" start_char="3784">and</TOKEN>
<TOKEN end_char="3791" id="token-28-18" morph="none" pos="word" start_char="3788">more</TOKEN>
<TOKEN end_char="3799" id="token-28-19" morph="none" pos="word" start_char="3793">serious</TOKEN>
<TOKEN end_char="3808" id="token-28-20" morph="none" pos="word" start_char="3801">versions</TOKEN>
<TOKEN end_char="3811" id="token-28-21" morph="none" pos="word" start_char="3810">of</TOKEN>
<TOKEN end_char="3815" id="token-28-22" morph="none" pos="word" start_char="3813">the</TOKEN>
<TOKEN end_char="3827" id="token-28-23" morph="none" pos="word" start_char="3817">coronavirus</TOKEN>
<TOKEN end_char="3828" id="token-28-24" morph="none" pos="punct" start_char="3828">.</TOKEN>
</SEG>
<SEG end_char="4001" id="segment-29" start_char="3831">
<ORIGINAL_TEXT>"If someone were seeking to engineer a new coronavirus as a pathogen, they would have constructed it from the backbone of a virus known to cause illness," the report said.</ORIGINAL_TEXT>
<TOKEN end_char="3831" id="token-29-0" morph="none" pos="punct" start_char="3831">"</TOKEN>
<TOKEN end_char="3833" id="token-29-1" morph="none" pos="word" start_char="3832">If</TOKEN>
<TOKEN end_char="3841" id="token-29-2" morph="none" pos="word" start_char="3835">someone</TOKEN>
<TOKEN end_char="3846" id="token-29-3" morph="none" pos="word" start_char="3843">were</TOKEN>
<TOKEN end_char="3854" id="token-29-4" morph="none" pos="word" start_char="3848">seeking</TOKEN>
<TOKEN end_char="3857" id="token-29-5" morph="none" pos="word" start_char="3856">to</TOKEN>
<TOKEN end_char="3866" id="token-29-6" morph="none" pos="word" start_char="3859">engineer</TOKEN>
<TOKEN end_char="3868" id="token-29-7" morph="none" pos="word" start_char="3868">a</TOKEN>
<TOKEN end_char="3872" id="token-29-8" morph="none" pos="word" start_char="3870">new</TOKEN>
<TOKEN end_char="3884" id="token-29-9" morph="none" pos="word" start_char="3874">coronavirus</TOKEN>
<TOKEN end_char="3887" id="token-29-10" morph="none" pos="word" start_char="3886">as</TOKEN>
<TOKEN end_char="3889" id="token-29-11" morph="none" pos="word" start_char="3889">a</TOKEN>
<TOKEN end_char="3898" id="token-29-12" morph="none" pos="word" start_char="3891">pathogen</TOKEN>
<TOKEN end_char="3899" id="token-29-13" morph="none" pos="punct" start_char="3899">,</TOKEN>
<TOKEN end_char="3904" id="token-29-14" morph="none" pos="word" start_char="3901">they</TOKEN>
<TOKEN end_char="3910" id="token-29-15" morph="none" pos="word" start_char="3906">would</TOKEN>
<TOKEN end_char="3915" id="token-29-16" morph="none" pos="word" start_char="3912">have</TOKEN>
<TOKEN end_char="3927" id="token-29-17" morph="none" pos="word" start_char="3917">constructed</TOKEN>
<TOKEN end_char="3930" id="token-29-18" morph="none" pos="word" start_char="3929">it</TOKEN>
<TOKEN end_char="3935" id="token-29-19" morph="none" pos="word" start_char="3932">from</TOKEN>
<TOKEN end_char="3939" id="token-29-20" morph="none" pos="word" start_char="3937">the</TOKEN>
<TOKEN end_char="3948" id="token-29-21" morph="none" pos="word" start_char="3941">backbone</TOKEN>
<TOKEN end_char="3951" id="token-29-22" morph="none" pos="word" start_char="3950">of</TOKEN>
<TOKEN end_char="3953" id="token-29-23" morph="none" pos="word" start_char="3953">a</TOKEN>
<TOKEN end_char="3959" id="token-29-24" morph="none" pos="word" start_char="3955">virus</TOKEN>
<TOKEN end_char="3965" id="token-29-25" morph="none" pos="word" start_char="3961">known</TOKEN>
<TOKEN end_char="3968" id="token-29-26" morph="none" pos="word" start_char="3967">to</TOKEN>
<TOKEN end_char="3974" id="token-29-27" morph="none" pos="word" start_char="3970">cause</TOKEN>
<TOKEN end_char="3982" id="token-29-28" morph="none" pos="word" start_char="3976">illness</TOKEN>
<TOKEN end_char="3984" id="token-29-29" morph="none" pos="punct" start_char="3983">,"</TOKEN>
<TOKEN end_char="3988" id="token-29-30" morph="none" pos="word" start_char="3986">the</TOKEN>
<TOKEN end_char="3995" id="token-29-31" morph="none" pos="word" start_char="3990">report</TOKEN>
<TOKEN end_char="4000" id="token-29-32" morph="none" pos="word" start_char="3997">said</TOKEN>
<TOKEN end_char="4001" id="token-29-33" morph="none" pos="punct" start_char="4001">.</TOKEN>
</SEG>
<SEG end_char="4188" id="segment-30" start_char="4003">
<ORIGINAL_TEXT>"But the scientists found that the SARS-CoV-2 backbone differed substantially from those of already known coronaviruses and mostly resembled related viruses found in bats and pangolins."</ORIGINAL_TEXT>
<TOKEN end_char="4003" id="token-30-0" morph="none" pos="punct" start_char="4003">"</TOKEN>
<TOKEN end_char="4006" id="token-30-1" morph="none" pos="word" start_char="4004">But</TOKEN>
<TOKEN end_char="4010" id="token-30-2" morph="none" pos="word" start_char="4008">the</TOKEN>
<TOKEN end_char="4021" id="token-30-3" morph="none" pos="word" start_char="4012">scientists</TOKEN>
<TOKEN end_char="4027" id="token-30-4" morph="none" pos="word" start_char="4023">found</TOKEN>
<TOKEN end_char="4032" id="token-30-5" morph="none" pos="word" start_char="4029">that</TOKEN>
<TOKEN end_char="4036" id="token-30-6" morph="none" pos="word" start_char="4034">the</TOKEN>
<TOKEN end_char="4047" id="token-30-7" morph="none" pos="unknown" start_char="4038">SARS-CoV-2</TOKEN>
<TOKEN end_char="4056" id="token-30-8" morph="none" pos="word" start_char="4049">backbone</TOKEN>
<TOKEN end_char="4065" id="token-30-9" morph="none" pos="word" start_char="4058">differed</TOKEN>
<TOKEN end_char="4079" id="token-30-10" morph="none" pos="word" start_char="4067">substantially</TOKEN>
<TOKEN end_char="4084" id="token-30-11" morph="none" pos="word" start_char="4081">from</TOKEN>
<TOKEN end_char="4090" id="token-30-12" morph="none" pos="word" start_char="4086">those</TOKEN>
<TOKEN end_char="4093" id="token-30-13" morph="none" pos="word" start_char="4092">of</TOKEN>
<TOKEN end_char="4101" id="token-30-14" morph="none" pos="word" start_char="4095">already</TOKEN>
<TOKEN end_char="4107" id="token-30-15" morph="none" pos="word" start_char="4103">known</TOKEN>
<TOKEN end_char="4121" id="token-30-16" morph="none" pos="word" start_char="4109">coronaviruses</TOKEN>
<TOKEN end_char="4125" id="token-30-17" morph="none" pos="word" start_char="4123">and</TOKEN>
<TOKEN end_char="4132" id="token-30-18" morph="none" pos="word" start_char="4127">mostly</TOKEN>
<TOKEN end_char="4142" id="token-30-19" morph="none" pos="word" start_char="4134">resembled</TOKEN>
<TOKEN end_char="4150" id="token-30-20" morph="none" pos="word" start_char="4144">related</TOKEN>
<TOKEN end_char="4158" id="token-30-21" morph="none" pos="word" start_char="4152">viruses</TOKEN>
<TOKEN end_char="4164" id="token-30-22" morph="none" pos="word" start_char="4160">found</TOKEN>
<TOKEN end_char="4167" id="token-30-23" morph="none" pos="word" start_char="4166">in</TOKEN>
<TOKEN end_char="4172" id="token-30-24" morph="none" pos="word" start_char="4169">bats</TOKEN>
<TOKEN end_char="4176" id="token-30-25" morph="none" pos="word" start_char="4174">and</TOKEN>
<TOKEN end_char="4186" id="token-30-26" morph="none" pos="word" start_char="4178">pangolins</TOKEN>
<TOKEN end_char="4188" id="token-30-27" morph="none" pos="punct" start_char="4187">."</TOKEN>
</SEG>
<SEG end_char="4611" id="segment-31" start_char="4191">
<ORIGINAL_TEXT>A statement in the Lancet, a medical journal, written by public health officials who have been following the progression of the virus also asserted that animals are the likely source: "Scientists from multiple countries have published and analysed genomes of the causative agent, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), and they overwhelmingly conclude that this coronavirus originated in wildlife."</ORIGINAL_TEXT>
<TOKEN end_char="4191" id="token-31-0" morph="none" pos="word" start_char="4191">A</TOKEN>
<TOKEN end_char="4201" id="token-31-1" morph="none" pos="word" start_char="4193">statement</TOKEN>
<TOKEN end_char="4204" id="token-31-2" morph="none" pos="word" start_char="4203">in</TOKEN>
<TOKEN end_char="4208" id="token-31-3" morph="none" pos="word" start_char="4206">the</TOKEN>
<TOKEN end_char="4215" id="token-31-4" morph="none" pos="word" start_char="4210">Lancet</TOKEN>
<TOKEN end_char="4216" id="token-31-5" morph="none" pos="punct" start_char="4216">,</TOKEN>
<TOKEN end_char="4218" id="token-31-6" morph="none" pos="word" start_char="4218">a</TOKEN>
<TOKEN end_char="4226" id="token-31-7" morph="none" pos="word" start_char="4220">medical</TOKEN>
<TOKEN end_char="4234" id="token-31-8" morph="none" pos="word" start_char="4228">journal</TOKEN>
<TOKEN end_char="4235" id="token-31-9" morph="none" pos="punct" start_char="4235">,</TOKEN>
<TOKEN end_char="4243" id="token-31-10" morph="none" pos="word" start_char="4237">written</TOKEN>
<TOKEN end_char="4246" id="token-31-11" morph="none" pos="word" start_char="4245">by</TOKEN>
<TOKEN end_char="4253" id="token-31-12" morph="none" pos="word" start_char="4248">public</TOKEN>
<TOKEN end_char="4260" id="token-31-13" morph="none" pos="word" start_char="4255">health</TOKEN>
<TOKEN end_char="4270" id="token-31-14" morph="none" pos="word" start_char="4262">officials</TOKEN>
<TOKEN end_char="4274" id="token-31-15" morph="none" pos="word" start_char="4272">who</TOKEN>
<TOKEN end_char="4279" id="token-31-16" morph="none" pos="word" start_char="4276">have</TOKEN>
<TOKEN end_char="4284" id="token-31-17" morph="none" pos="word" start_char="4281">been</TOKEN>
<TOKEN end_char="4294" id="token-31-18" morph="none" pos="word" start_char="4286">following</TOKEN>
<TOKEN end_char="4298" id="token-31-19" morph="none" pos="word" start_char="4296">the</TOKEN>
<TOKEN end_char="4310" id="token-31-20" morph="none" pos="word" start_char="4300">progression</TOKEN>
<TOKEN end_char="4313" id="token-31-21" morph="none" pos="word" start_char="4312">of</TOKEN>
<TOKEN end_char="4317" id="token-31-22" morph="none" pos="word" start_char="4315">the</TOKEN>
<TOKEN end_char="4323" id="token-31-23" morph="none" pos="word" start_char="4319">virus</TOKEN>
<TOKEN end_char="4328" id="token-31-24" morph="none" pos="word" start_char="4325">also</TOKEN>
<TOKEN end_char="4337" id="token-31-25" morph="none" pos="word" start_char="4330">asserted</TOKEN>
<TOKEN end_char="4342" id="token-31-26" morph="none" pos="word" start_char="4339">that</TOKEN>
<TOKEN end_char="4350" id="token-31-27" morph="none" pos="word" start_char="4344">animals</TOKEN>
<TOKEN end_char="4354" id="token-31-28" morph="none" pos="word" start_char="4352">are</TOKEN>
<TOKEN end_char="4358" id="token-31-29" morph="none" pos="word" start_char="4356">the</TOKEN>
<TOKEN end_char="4365" id="token-31-30" morph="none" pos="word" start_char="4360">likely</TOKEN>
<TOKEN end_char="4372" id="token-31-31" morph="none" pos="word" start_char="4367">source</TOKEN>
<TOKEN end_char="4373" id="token-31-32" morph="none" pos="punct" start_char="4373">:</TOKEN>
<TOKEN end_char="4375" id="token-31-33" morph="none" pos="punct" start_char="4375">"</TOKEN>
<TOKEN end_char="4385" id="token-31-34" morph="none" pos="word" start_char="4376">Scientists</TOKEN>
<TOKEN end_char="4390" id="token-31-35" morph="none" pos="word" start_char="4387">from</TOKEN>
<TOKEN end_char="4399" id="token-31-36" morph="none" pos="word" start_char="4392">multiple</TOKEN>
<TOKEN end_char="4409" id="token-31-37" morph="none" pos="word" start_char="4401">countries</TOKEN>
<TOKEN end_char="4414" id="token-31-38" morph="none" pos="word" start_char="4411">have</TOKEN>
<TOKEN end_char="4424" id="token-31-39" morph="none" pos="word" start_char="4416">published</TOKEN>
<TOKEN end_char="4428" id="token-31-40" morph="none" pos="word" start_char="4426">and</TOKEN>
<TOKEN end_char="4437" id="token-31-41" morph="none" pos="word" start_char="4430">analysed</TOKEN>
<TOKEN end_char="4445" id="token-31-42" morph="none" pos="word" start_char="4439">genomes</TOKEN>
<TOKEN end_char="4448" id="token-31-43" morph="none" pos="word" start_char="4447">of</TOKEN>
<TOKEN end_char="4452" id="token-31-44" morph="none" pos="word" start_char="4450">the</TOKEN>
<TOKEN end_char="4462" id="token-31-45" morph="none" pos="word" start_char="4454">causative</TOKEN>
<TOKEN end_char="4468" id="token-31-46" morph="none" pos="word" start_char="4464">agent</TOKEN>
<TOKEN end_char="4469" id="token-31-47" morph="none" pos="punct" start_char="4469">,</TOKEN>
<TOKEN end_char="4476" id="token-31-48" morph="none" pos="word" start_char="4471">severe</TOKEN>
<TOKEN end_char="4482" id="token-31-49" morph="none" pos="word" start_char="4478">acute</TOKEN>
<TOKEN end_char="4494" id="token-31-50" morph="none" pos="word" start_char="4484">respiratory</TOKEN>
<TOKEN end_char="4503" id="token-31-51" morph="none" pos="word" start_char="4496">syndrome</TOKEN>
<TOKEN end_char="4515" id="token-31-52" morph="none" pos="word" start_char="4505">coronavirus</TOKEN>
<TOKEN end_char="4517" id="token-31-53" morph="none" pos="word" start_char="4517">2</TOKEN>
<TOKEN end_char="4519" id="token-31-54" morph="none" pos="punct" start_char="4519">(</TOKEN>
<TOKEN end_char="4529" id="token-31-55" morph="none" pos="unknown" start_char="4520">SARS-CoV-2</TOKEN>
<TOKEN end_char="4531" id="token-31-56" morph="none" pos="punct" start_char="4530">),</TOKEN>
<TOKEN end_char="4535" id="token-31-57" morph="none" pos="word" start_char="4533">and</TOKEN>
<TOKEN end_char="4540" id="token-31-58" morph="none" pos="word" start_char="4537">they</TOKEN>
<TOKEN end_char="4555" id="token-31-59" morph="none" pos="word" start_char="4542">overwhelmingly</TOKEN>
<TOKEN end_char="4564" id="token-31-60" morph="none" pos="word" start_char="4557">conclude</TOKEN>
<TOKEN end_char="4569" id="token-31-61" morph="none" pos="word" start_char="4566">that</TOKEN>
<TOKEN end_char="4574" id="token-31-62" morph="none" pos="word" start_char="4571">this</TOKEN>
<TOKEN end_char="4586" id="token-31-63" morph="none" pos="word" start_char="4576">coronavirus</TOKEN>
<TOKEN end_char="4597" id="token-31-64" morph="none" pos="word" start_char="4588">originated</TOKEN>
<TOKEN end_char="4600" id="token-31-65" morph="none" pos="word" start_char="4599">in</TOKEN>
<TOKEN end_char="4609" id="token-31-66" morph="none" pos="word" start_char="4602">wildlife</TOKEN>
<TOKEN end_char="4611" id="token-31-67" morph="none" pos="punct" start_char="4610">."</TOKEN>
</SEG>
<SEG end_char="4726" id="segment-32" start_char="4614">
<ORIGINAL_TEXT>The statement referenced multiple academic and government sources that supported the Lancet article’s conclusion.</ORIGINAL_TEXT>
<TOKEN end_char="4616" id="token-32-0" morph="none" pos="word" start_char="4614">The</TOKEN>
<TOKEN end_char="4626" id="token-32-1" morph="none" pos="word" start_char="4618">statement</TOKEN>
<TOKEN end_char="4637" id="token-32-2" morph="none" pos="word" start_char="4628">referenced</TOKEN>
<TOKEN end_char="4646" id="token-32-3" morph="none" pos="word" start_char="4639">multiple</TOKEN>
<TOKEN end_char="4655" id="token-32-4" morph="none" pos="word" start_char="4648">academic</TOKEN>
<TOKEN end_char="4659" id="token-32-5" morph="none" pos="word" start_char="4657">and</TOKEN>
<TOKEN end_char="4670" id="token-32-6" morph="none" pos="word" start_char="4661">government</TOKEN>
<TOKEN end_char="4678" id="token-32-7" morph="none" pos="word" start_char="4672">sources</TOKEN>
<TOKEN end_char="4683" id="token-32-8" morph="none" pos="word" start_char="4680">that</TOKEN>
<TOKEN end_char="4693" id="token-32-9" morph="none" pos="word" start_char="4685">supported</TOKEN>
<TOKEN end_char="4697" id="token-32-10" morph="none" pos="word" start_char="4695">the</TOKEN>
<TOKEN end_char="4704" id="token-32-11" morph="none" pos="word" start_char="4699">Lancet</TOKEN>
<TOKEN end_char="4714" id="token-32-12" morph="none" pos="word" start_char="4706">article’s</TOKEN>
<TOKEN end_char="4725" id="token-32-13" morph="none" pos="word" start_char="4716">conclusion</TOKEN>
<TOKEN end_char="4726" id="token-32-14" morph="none" pos="punct" start_char="4726">.</TOKEN>
</SEG>
<SEG end_char="4978" id="segment-33" start_char="4728">
<ORIGINAL_TEXT>These sources include the Cold Spring Harbor Laboratory; Nature; U.S. National Academies of Science, Engineering and Medicine; the New England Journal of Medicine; the Chinese Medical Journal; and the medical journal Infection, Genetics and Evolution.</ORIGINAL_TEXT>
<TOKEN end_char="4732" id="token-33-0" morph="none" pos="word" start_char="4728">These</TOKEN>
<TOKEN end_char="4740" id="token-33-1" morph="none" pos="word" start_char="4734">sources</TOKEN>
<TOKEN end_char="4748" id="token-33-2" morph="none" pos="word" start_char="4742">include</TOKEN>
<TOKEN end_char="4752" id="token-33-3" morph="none" pos="word" start_char="4750">the</TOKEN>
<TOKEN end_char="4757" id="token-33-4" morph="none" pos="word" start_char="4754">Cold</TOKEN>
<TOKEN end_char="4764" id="token-33-5" morph="none" pos="word" start_char="4759">Spring</TOKEN>
<TOKEN end_char="4771" id="token-33-6" morph="none" pos="word" start_char="4766">Harbor</TOKEN>
<TOKEN end_char="4782" id="token-33-7" morph="none" pos="word" start_char="4773">Laboratory</TOKEN>
<TOKEN end_char="4783" id="token-33-8" morph="none" pos="punct" start_char="4783">;</TOKEN>
<TOKEN end_char="4790" id="token-33-9" morph="none" pos="word" start_char="4785">Nature</TOKEN>
<TOKEN end_char="4791" id="token-33-10" morph="none" pos="punct" start_char="4791">;</TOKEN>
<TOKEN end_char="4795" id="token-33-11" morph="none" pos="unknown" start_char="4793">U.S</TOKEN>
<TOKEN end_char="4796" id="token-33-12" morph="none" pos="punct" start_char="4796">.</TOKEN>
<TOKEN end_char="4805" id="token-33-13" morph="none" pos="word" start_char="4798">National</TOKEN>
<TOKEN end_char="4815" id="token-33-14" morph="none" pos="word" start_char="4807">Academies</TOKEN>
<TOKEN end_char="4818" id="token-33-15" morph="none" pos="word" start_char="4817">of</TOKEN>
<TOKEN end_char="4826" id="token-33-16" morph="none" pos="word" start_char="4820">Science</TOKEN>
<TOKEN end_char="4827" id="token-33-17" morph="none" pos="punct" start_char="4827">,</TOKEN>
<TOKEN end_char="4839" id="token-33-18" morph="none" pos="word" start_char="4829">Engineering</TOKEN>
<TOKEN end_char="4843" id="token-33-19" morph="none" pos="word" start_char="4841">and</TOKEN>
<TOKEN end_char="4852" id="token-33-20" morph="none" pos="word" start_char="4845">Medicine</TOKEN>
<TOKEN end_char="4853" id="token-33-21" morph="none" pos="punct" start_char="4853">;</TOKEN>
<TOKEN end_char="4857" id="token-33-22" morph="none" pos="word" start_char="4855">the</TOKEN>
<TOKEN end_char="4861" id="token-33-23" morph="none" pos="word" start_char="4859">New</TOKEN>
<TOKEN end_char="4869" id="token-33-24" morph="none" pos="word" start_char="4863">England</TOKEN>
<TOKEN end_char="4877" id="token-33-25" morph="none" pos="word" start_char="4871">Journal</TOKEN>
<TOKEN end_char="4880" id="token-33-26" morph="none" pos="word" start_char="4879">of</TOKEN>
<TOKEN end_char="4889" id="token-33-27" morph="none" pos="word" start_char="4882">Medicine</TOKEN>
<TOKEN end_char="4890" id="token-33-28" morph="none" pos="punct" start_char="4890">;</TOKEN>
<TOKEN end_char="4894" id="token-33-29" morph="none" pos="word" start_char="4892">the</TOKEN>
<TOKEN end_char="4902" id="token-33-30" morph="none" pos="word" start_char="4896">Chinese</TOKEN>
<TOKEN end_char="4910" id="token-33-31" morph="none" pos="word" start_char="4904">Medical</TOKEN>
<TOKEN end_char="4918" id="token-33-32" morph="none" pos="word" start_char="4912">Journal</TOKEN>
<TOKEN end_char="4919" id="token-33-33" morph="none" pos="punct" start_char="4919">;</TOKEN>
<TOKEN end_char="4923" id="token-33-34" morph="none" pos="word" start_char="4921">and</TOKEN>
<TOKEN end_char="4927" id="token-33-35" morph="none" pos="word" start_char="4925">the</TOKEN>
<TOKEN end_char="4935" id="token-33-36" morph="none" pos="word" start_char="4929">medical</TOKEN>
<TOKEN end_char="4943" id="token-33-37" morph="none" pos="word" start_char="4937">journal</TOKEN>
<TOKEN end_char="4953" id="token-33-38" morph="none" pos="word" start_char="4945">Infection</TOKEN>
<TOKEN end_char="4954" id="token-33-39" morph="none" pos="punct" start_char="4954">,</TOKEN>
<TOKEN end_char="4963" id="token-33-40" morph="none" pos="word" start_char="4956">Genetics</TOKEN>
<TOKEN end_char="4967" id="token-33-41" morph="none" pos="word" start_char="4965">and</TOKEN>
<TOKEN end_char="4977" id="token-33-42" morph="none" pos="word" start_char="4969">Evolution</TOKEN>
<TOKEN end_char="4978" id="token-33-43" morph="none" pos="punct" start_char="4978">.</TOKEN>
</SEG>
<SEG end_char="5194" id="segment-34" start_char="4981">
<ORIGINAL_TEXT>Researchers who analyzed the genome of the coronavirus found its sequence shared a very high resemblance to a coronavirus in bats, but it's possible other animals may have been involved in the transmission process.</ORIGINAL_TEXT>
<TOKEN end_char="4991" id="token-34-0" morph="none" pos="word" start_char="4981">Researchers</TOKEN>
<TOKEN end_char="4995" id="token-34-1" morph="none" pos="word" start_char="4993">who</TOKEN>
<TOKEN end_char="5004" id="token-34-2" morph="none" pos="word" start_char="4997">analyzed</TOKEN>
<TOKEN end_char="5008" id="token-34-3" morph="none" pos="word" start_char="5006">the</TOKEN>
<TOKEN end_char="5015" id="token-34-4" morph="none" pos="word" start_char="5010">genome</TOKEN>
<TOKEN end_char="5018" id="token-34-5" morph="none" pos="word" start_char="5017">of</TOKEN>
<TOKEN end_char="5022" id="token-34-6" morph="none" pos="word" start_char="5020">the</TOKEN>
<TOKEN end_char="5034" id="token-34-7" morph="none" pos="word" start_char="5024">coronavirus</TOKEN>
<TOKEN end_char="5040" id="token-34-8" morph="none" pos="word" start_char="5036">found</TOKEN>
<TOKEN end_char="5044" id="token-34-9" morph="none" pos="word" start_char="5042">its</TOKEN>
<TOKEN end_char="5053" id="token-34-10" morph="none" pos="word" start_char="5046">sequence</TOKEN>
<TOKEN end_char="5060" id="token-34-11" morph="none" pos="word" start_char="5055">shared</TOKEN>
<TOKEN end_char="5062" id="token-34-12" morph="none" pos="word" start_char="5062">a</TOKEN>
<TOKEN end_char="5067" id="token-34-13" morph="none" pos="word" start_char="5064">very</TOKEN>
<TOKEN end_char="5072" id="token-34-14" morph="none" pos="word" start_char="5069">high</TOKEN>
<TOKEN end_char="5084" id="token-34-15" morph="none" pos="word" start_char="5074">resemblance</TOKEN>
<TOKEN end_char="5087" id="token-34-16" morph="none" pos="word" start_char="5086">to</TOKEN>
<TOKEN end_char="5089" id="token-34-17" morph="none" pos="word" start_char="5089">a</TOKEN>
<TOKEN end_char="5101" id="token-34-18" morph="none" pos="word" start_char="5091">coronavirus</TOKEN>
<TOKEN end_char="5104" id="token-34-19" morph="none" pos="word" start_char="5103">in</TOKEN>
<TOKEN end_char="5109" id="token-34-20" morph="none" pos="word" start_char="5106">bats</TOKEN>
<TOKEN end_char="5110" id="token-34-21" morph="none" pos="punct" start_char="5110">,</TOKEN>
<TOKEN end_char="5114" id="token-34-22" morph="none" pos="word" start_char="5112">but</TOKEN>
<TOKEN end_char="5119" id="token-34-23" morph="none" pos="word" start_char="5116">it's</TOKEN>
<TOKEN end_char="5128" id="token-34-24" morph="none" pos="word" start_char="5121">possible</TOKEN>
<TOKEN end_char="5134" id="token-34-25" morph="none" pos="word" start_char="5130">other</TOKEN>
<TOKEN end_char="5142" id="token-34-26" morph="none" pos="word" start_char="5136">animals</TOKEN>
<TOKEN end_char="5146" id="token-34-27" morph="none" pos="word" start_char="5144">may</TOKEN>
<TOKEN end_char="5151" id="token-34-28" morph="none" pos="word" start_char="5148">have</TOKEN>
<TOKEN end_char="5156" id="token-34-29" morph="none" pos="word" start_char="5153">been</TOKEN>
<TOKEN end_char="5165" id="token-34-30" morph="none" pos="word" start_char="5158">involved</TOKEN>
<TOKEN end_char="5168" id="token-34-31" morph="none" pos="word" start_char="5167">in</TOKEN>
<TOKEN end_char="5172" id="token-34-32" morph="none" pos="word" start_char="5170">the</TOKEN>
<TOKEN end_char="5185" id="token-34-33" morph="none" pos="word" start_char="5174">transmission</TOKEN>
<TOKEN end_char="5193" id="token-34-34" morph="none" pos="word" start_char="5187">process</TOKEN>
<TOKEN end_char="5194" id="token-34-35" morph="none" pos="punct" start_char="5194">.</TOKEN>
</SEG>
<SEG end_char="5326" id="segment-35" start_char="5197">
<ORIGINAL_TEXT>"2019-nCoV is 96% identical at the whole-genome level to a bat coronavirus," a study published in the science journal Nature said.</ORIGINAL_TEXT>
<TOKEN end_char="5197" id="token-35-0" morph="none" pos="punct" start_char="5197">"</TOKEN>
<TOKEN end_char="5206" id="token-35-1" morph="none" pos="unknown" start_char="5198">2019-nCoV</TOKEN>
<TOKEN end_char="5209" id="token-35-2" morph="none" pos="word" start_char="5208">is</TOKEN>
<TOKEN end_char="5212" id="token-35-3" morph="none" pos="word" start_char="5211">96</TOKEN>
<TOKEN end_char="5213" id="token-35-4" morph="none" pos="punct" start_char="5213">%</TOKEN>
<TOKEN end_char="5223" id="token-35-5" morph="none" pos="word" start_char="5215">identical</TOKEN>
<TOKEN end_char="5226" id="token-35-6" morph="none" pos="word" start_char="5225">at</TOKEN>
<TOKEN end_char="5230" id="token-35-7" morph="none" pos="word" start_char="5228">the</TOKEN>
<TOKEN end_char="5243" id="token-35-8" morph="none" pos="unknown" start_char="5232">whole-genome</TOKEN>
<TOKEN end_char="5249" id="token-35-9" morph="none" pos="word" start_char="5245">level</TOKEN>
<TOKEN end_char="5252" id="token-35-10" morph="none" pos="word" start_char="5251">to</TOKEN>
<TOKEN end_char="5254" id="token-35-11" morph="none" pos="word" start_char="5254">a</TOKEN>
<TOKEN end_char="5258" id="token-35-12" morph="none" pos="word" start_char="5256">bat</TOKEN>
<TOKEN end_char="5270" id="token-35-13" morph="none" pos="word" start_char="5260">coronavirus</TOKEN>
<TOKEN end_char="5272" id="token-35-14" morph="none" pos="punct" start_char="5271">,"</TOKEN>
<TOKEN end_char="5274" id="token-35-15" morph="none" pos="word" start_char="5274">a</TOKEN>
<TOKEN end_char="5280" id="token-35-16" morph="none" pos="word" start_char="5276">study</TOKEN>
<TOKEN end_char="5290" id="token-35-17" morph="none" pos="word" start_char="5282">published</TOKEN>
<TOKEN end_char="5293" id="token-35-18" morph="none" pos="word" start_char="5292">in</TOKEN>
<TOKEN end_char="5297" id="token-35-19" morph="none" pos="word" start_char="5295">the</TOKEN>
<TOKEN end_char="5305" id="token-35-20" morph="none" pos="word" start_char="5299">science</TOKEN>
<TOKEN end_char="5313" id="token-35-21" morph="none" pos="word" start_char="5307">journal</TOKEN>
<TOKEN end_char="5320" id="token-35-22" morph="none" pos="word" start_char="5315">Nature</TOKEN>
<TOKEN end_char="5325" id="token-35-23" morph="none" pos="word" start_char="5322">said</TOKEN>
<TOKEN end_char="5326" id="token-35-24" morph="none" pos="punct" start_char="5326">.</TOKEN>
</SEG>
<SEG end_char="5513" id="segment-36" start_char="5329">
<ORIGINAL_TEXT>Another study published in the Lancet found results based on samples collected from nine patients who had contracted the virus corroborated the theory that the virus had come from bats.</ORIGINAL_TEXT>
<TOKEN end_char="5335" id="token-36-0" morph="none" pos="word" start_char="5329">Another</TOKEN>
<TOKEN end_char="5341" id="token-36-1" morph="none" pos="word" start_char="5337">study</TOKEN>
<TOKEN end_char="5351" id="token-36-2" morph="none" pos="word" start_char="5343">published</TOKEN>
<TOKEN end_char="5354" id="token-36-3" morph="none" pos="word" start_char="5353">in</TOKEN>
<TOKEN end_char="5358" id="token-36-4" morph="none" pos="word" start_char="5356">the</TOKEN>
<TOKEN end_char="5365" id="token-36-5" morph="none" pos="word" start_char="5360">Lancet</TOKEN>
<TOKEN end_char="5371" id="token-36-6" morph="none" pos="word" start_char="5367">found</TOKEN>
<TOKEN end_char="5379" id="token-36-7" morph="none" pos="word" start_char="5373">results</TOKEN>
<TOKEN end_char="5385" id="token-36-8" morph="none" pos="word" start_char="5381">based</TOKEN>
<TOKEN end_char="5388" id="token-36-9" morph="none" pos="word" start_char="5387">on</TOKEN>
<TOKEN end_char="5396" id="token-36-10" morph="none" pos="word" start_char="5390">samples</TOKEN>
<TOKEN end_char="5406" id="token-36-11" morph="none" pos="word" start_char="5398">collected</TOKEN>
<TOKEN end_char="5411" id="token-36-12" morph="none" pos="word" start_char="5408">from</TOKEN>
<TOKEN end_char="5416" id="token-36-13" morph="none" pos="word" start_char="5413">nine</TOKEN>
<TOKEN end_char="5425" id="token-36-14" morph="none" pos="word" start_char="5418">patients</TOKEN>
<TOKEN end_char="5429" id="token-36-15" morph="none" pos="word" start_char="5427">who</TOKEN>
<TOKEN end_char="5433" id="token-36-16" morph="none" pos="word" start_char="5431">had</TOKEN>
<TOKEN end_char="5444" id="token-36-17" morph="none" pos="word" start_char="5435">contracted</TOKEN>
<TOKEN end_char="5448" id="token-36-18" morph="none" pos="word" start_char="5446">the</TOKEN>
<TOKEN end_char="5454" id="token-36-19" morph="none" pos="word" start_char="5450">virus</TOKEN>
<TOKEN end_char="5467" id="token-36-20" morph="none" pos="word" start_char="5456">corroborated</TOKEN>
<TOKEN end_char="5471" id="token-36-21" morph="none" pos="word" start_char="5469">the</TOKEN>
<TOKEN end_char="5478" id="token-36-22" morph="none" pos="word" start_char="5473">theory</TOKEN>
<TOKEN end_char="5483" id="token-36-23" morph="none" pos="word" start_char="5480">that</TOKEN>
<TOKEN end_char="5487" id="token-36-24" morph="none" pos="word" start_char="5485">the</TOKEN>
<TOKEN end_char="5493" id="token-36-25" morph="none" pos="word" start_char="5489">virus</TOKEN>
<TOKEN end_char="5497" id="token-36-26" morph="none" pos="word" start_char="5495">had</TOKEN>
<TOKEN end_char="5502" id="token-36-27" morph="none" pos="word" start_char="5499">come</TOKEN>
<TOKEN end_char="5507" id="token-36-28" morph="none" pos="word" start_char="5504">from</TOKEN>
<TOKEN end_char="5512" id="token-36-29" morph="none" pos="word" start_char="5509">bats</TOKEN>
<TOKEN end_char="5513" id="token-36-30" morph="none" pos="punct" start_char="5513">.</TOKEN>
</SEG>
<SEG end_char="5679" id="segment-37" start_char="5515">
<ORIGINAL_TEXT>Researchers concluded the genome sequences of the coronavirus "was closely related … to two bat-derived severe acute respiratory syndrome (SARS)-like coronaviruses."</ORIGINAL_TEXT>
<TOKEN end_char="5525" id="token-37-0" morph="none" pos="word" start_char="5515">Researchers</TOKEN>
<TOKEN end_char="5535" id="token-37-1" morph="none" pos="word" start_char="5527">concluded</TOKEN>
<TOKEN end_char="5539" id="token-37-2" morph="none" pos="word" start_char="5537">the</TOKEN>
<TOKEN end_char="5546" id="token-37-3" morph="none" pos="word" start_char="5541">genome</TOKEN>
<TOKEN end_char="5556" id="token-37-4" morph="none" pos="word" start_char="5548">sequences</TOKEN>
<TOKEN end_char="5559" id="token-37-5" morph="none" pos="word" start_char="5558">of</TOKEN>
<TOKEN end_char="5563" id="token-37-6" morph="none" pos="word" start_char="5561">the</TOKEN>
<TOKEN end_char="5575" id="token-37-7" morph="none" pos="word" start_char="5565">coronavirus</TOKEN>
<TOKEN end_char="5577" id="token-37-8" morph="none" pos="punct" start_char="5577">"</TOKEN>
<TOKEN end_char="5580" id="token-37-9" morph="none" pos="word" start_char="5578">was</TOKEN>
<TOKEN end_char="5588" id="token-37-10" morph="none" pos="word" start_char="5582">closely</TOKEN>
<TOKEN end_char="5596" id="token-37-11" morph="none" pos="word" start_char="5590">related</TOKEN>
<TOKEN end_char="5598" id="token-37-12" morph="none" pos="punct" start_char="5598">…</TOKEN>
<TOKEN end_char="5601" id="token-37-13" morph="none" pos="word" start_char="5600">to</TOKEN>
<TOKEN end_char="5605" id="token-37-14" morph="none" pos="word" start_char="5603">two</TOKEN>
<TOKEN end_char="5617" id="token-37-15" morph="none" pos="unknown" start_char="5607">bat-derived</TOKEN>
<TOKEN end_char="5624" id="token-37-16" morph="none" pos="word" start_char="5619">severe</TOKEN>
<TOKEN end_char="5630" id="token-37-17" morph="none" pos="word" start_char="5626">acute</TOKEN>
<TOKEN end_char="5642" id="token-37-18" morph="none" pos="word" start_char="5632">respiratory</TOKEN>
<TOKEN end_char="5651" id="token-37-19" morph="none" pos="word" start_char="5644">syndrome</TOKEN>
<TOKEN end_char="5653" id="token-37-20" morph="none" pos="punct" start_char="5653">(</TOKEN>
<TOKEN end_char="5663" id="token-37-21" morph="none" pos="unknown" start_char="5654">SARS)-like</TOKEN>
<TOKEN end_char="5677" id="token-37-22" morph="none" pos="word" start_char="5665">coronaviruses</TOKEN>
<TOKEN end_char="5679" id="token-37-23" morph="none" pos="punct" start_char="5678">."</TOKEN>
</SEG>
<SEG end_char="5906" id="segment-38" start_char="5682">
<ORIGINAL_TEXT>Although scientists say they believe bats were likely the original host, it’s also very possible, the study notes, that the virus was transferred from a bat to another animal that may have been at the seafood market in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="5689" id="token-38-0" morph="none" pos="word" start_char="5682">Although</TOKEN>
<TOKEN end_char="5700" id="token-38-1" morph="none" pos="word" start_char="5691">scientists</TOKEN>
<TOKEN end_char="5704" id="token-38-2" morph="none" pos="word" start_char="5702">say</TOKEN>
<TOKEN end_char="5709" id="token-38-3" morph="none" pos="word" start_char="5706">they</TOKEN>
<TOKEN end_char="5717" id="token-38-4" morph="none" pos="word" start_char="5711">believe</TOKEN>
<TOKEN end_char="5722" id="token-38-5" morph="none" pos="word" start_char="5719">bats</TOKEN>
<TOKEN end_char="5727" id="token-38-6" morph="none" pos="word" start_char="5724">were</TOKEN>
<TOKEN end_char="5734" id="token-38-7" morph="none" pos="word" start_char="5729">likely</TOKEN>
<TOKEN end_char="5738" id="token-38-8" morph="none" pos="word" start_char="5736">the</TOKEN>
<TOKEN end_char="5747" id="token-38-9" morph="none" pos="word" start_char="5740">original</TOKEN>
<TOKEN end_char="5752" id="token-38-10" morph="none" pos="word" start_char="5749">host</TOKEN>
<TOKEN end_char="5753" id="token-38-11" morph="none" pos="punct" start_char="5753">,</TOKEN>
<TOKEN end_char="5758" id="token-38-12" morph="none" pos="word" start_char="5755">it’s</TOKEN>
<TOKEN end_char="5763" id="token-38-13" morph="none" pos="word" start_char="5760">also</TOKEN>
<TOKEN end_char="5768" id="token-38-14" morph="none" pos="word" start_char="5765">very</TOKEN>
<TOKEN end_char="5777" id="token-38-15" morph="none" pos="word" start_char="5770">possible</TOKEN>
<TOKEN end_char="5778" id="token-38-16" morph="none" pos="punct" start_char="5778">,</TOKEN>
<TOKEN end_char="5782" id="token-38-17" morph="none" pos="word" start_char="5780">the</TOKEN>
<TOKEN end_char="5788" id="token-38-18" morph="none" pos="word" start_char="5784">study</TOKEN>
<TOKEN end_char="5794" id="token-38-19" morph="none" pos="word" start_char="5790">notes</TOKEN>
<TOKEN end_char="5795" id="token-38-20" morph="none" pos="punct" start_char="5795">,</TOKEN>
<TOKEN end_char="5800" id="token-38-21" morph="none" pos="word" start_char="5797">that</TOKEN>
<TOKEN end_char="5804" id="token-38-22" morph="none" pos="word" start_char="5802">the</TOKEN>
<TOKEN end_char="5810" id="token-38-23" morph="none" pos="word" start_char="5806">virus</TOKEN>
<TOKEN end_char="5814" id="token-38-24" morph="none" pos="word" start_char="5812">was</TOKEN>
<TOKEN end_char="5826" id="token-38-25" morph="none" pos="word" start_char="5816">transferred</TOKEN>
<TOKEN end_char="5831" id="token-38-26" morph="none" pos="word" start_char="5828">from</TOKEN>
<TOKEN end_char="5833" id="token-38-27" morph="none" pos="word" start_char="5833">a</TOKEN>
<TOKEN end_char="5837" id="token-38-28" morph="none" pos="word" start_char="5835">bat</TOKEN>
<TOKEN end_char="5840" id="token-38-29" morph="none" pos="word" start_char="5839">to</TOKEN>
<TOKEN end_char="5848" id="token-38-30" morph="none" pos="word" start_char="5842">another</TOKEN>
<TOKEN end_char="5855" id="token-38-31" morph="none" pos="word" start_char="5850">animal</TOKEN>
<TOKEN end_char="5860" id="token-38-32" morph="none" pos="word" start_char="5857">that</TOKEN>
<TOKEN end_char="5864" id="token-38-33" morph="none" pos="word" start_char="5862">may</TOKEN>
<TOKEN end_char="5869" id="token-38-34" morph="none" pos="word" start_char="5866">have</TOKEN>
<TOKEN end_char="5874" id="token-38-35" morph="none" pos="word" start_char="5871">been</TOKEN>
<TOKEN end_char="5877" id="token-38-36" morph="none" pos="word" start_char="5876">at</TOKEN>
<TOKEN end_char="5881" id="token-38-37" morph="none" pos="word" start_char="5879">the</TOKEN>
<TOKEN end_char="5889" id="token-38-38" morph="none" pos="word" start_char="5883">seafood</TOKEN>
<TOKEN end_char="5896" id="token-38-39" morph="none" pos="word" start_char="5891">market</TOKEN>
<TOKEN end_char="5899" id="token-38-40" morph="none" pos="word" start_char="5898">in</TOKEN>
<TOKEN end_char="5905" id="token-38-41" morph="none" pos="word" start_char="5901">Wuhan</TOKEN>
<TOKEN end_char="5906" id="token-38-42" morph="none" pos="punct" start_char="5906">.</TOKEN>
</SEG>
<SEG end_char="5995" id="segment-39" start_char="5909">
<ORIGINAL_TEXT>While experts agree the virus came from nature, its origins beyond that remain unclear.</ORIGINAL_TEXT>
<TOKEN end_char="5913" id="token-39-0" morph="none" pos="word" start_char="5909">While</TOKEN>
<TOKEN end_char="5921" id="token-39-1" morph="none" pos="word" start_char="5915">experts</TOKEN>
<TOKEN end_char="5927" id="token-39-2" morph="none" pos="word" start_char="5923">agree</TOKEN>
<TOKEN end_char="5931" id="token-39-3" morph="none" pos="word" start_char="5929">the</TOKEN>
<TOKEN end_char="5937" id="token-39-4" morph="none" pos="word" start_char="5933">virus</TOKEN>
<TOKEN end_char="5942" id="token-39-5" morph="none" pos="word" start_char="5939">came</TOKEN>
<TOKEN end_char="5947" id="token-39-6" morph="none" pos="word" start_char="5944">from</TOKEN>
<TOKEN end_char="5954" id="token-39-7" morph="none" pos="word" start_char="5949">nature</TOKEN>
<TOKEN end_char="5955" id="token-39-8" morph="none" pos="punct" start_char="5955">,</TOKEN>
<TOKEN end_char="5959" id="token-39-9" morph="none" pos="word" start_char="5957">its</TOKEN>
<TOKEN end_char="5967" id="token-39-10" morph="none" pos="word" start_char="5961">origins</TOKEN>
<TOKEN end_char="5974" id="token-39-11" morph="none" pos="word" start_char="5969">beyond</TOKEN>
<TOKEN end_char="5979" id="token-39-12" morph="none" pos="word" start_char="5976">that</TOKEN>
<TOKEN end_char="5986" id="token-39-13" morph="none" pos="word" start_char="5981">remain</TOKEN>
<TOKEN end_char="5994" id="token-39-14" morph="none" pos="word" start_char="5988">unclear</TOKEN>
<TOKEN end_char="5995" id="token-39-15" morph="none" pos="punct" start_char="5995">.</TOKEN>
</SEG>
<SEG end_char="6145" id="segment-40" start_char="5998">
<ORIGINAL_TEXT>One scenario has the virus occurring naturally – from a bat, say – but accidentally escaping the research facility because of poor safety protocols.</ORIGINAL_TEXT>
<TOKEN end_char="6000" id="token-40-0" morph="none" pos="word" start_char="5998">One</TOKEN>
<TOKEN end_char="6009" id="token-40-1" morph="none" pos="word" start_char="6002">scenario</TOKEN>
<TOKEN end_char="6013" id="token-40-2" morph="none" pos="word" start_char="6011">has</TOKEN>
<TOKEN end_char="6017" id="token-40-3" morph="none" pos="word" start_char="6015">the</TOKEN>
<TOKEN end_char="6023" id="token-40-4" morph="none" pos="word" start_char="6019">virus</TOKEN>
<TOKEN end_char="6033" id="token-40-5" morph="none" pos="word" start_char="6025">occurring</TOKEN>
<TOKEN end_char="6043" id="token-40-6" morph="none" pos="word" start_char="6035">naturally</TOKEN>
<TOKEN end_char="6045" id="token-40-7" morph="none" pos="punct" start_char="6045">–</TOKEN>
<TOKEN end_char="6050" id="token-40-8" morph="none" pos="word" start_char="6047">from</TOKEN>
<TOKEN end_char="6052" id="token-40-9" morph="none" pos="word" start_char="6052">a</TOKEN>
<TOKEN end_char="6056" id="token-40-10" morph="none" pos="word" start_char="6054">bat</TOKEN>
<TOKEN end_char="6057" id="token-40-11" morph="none" pos="punct" start_char="6057">,</TOKEN>
<TOKEN end_char="6061" id="token-40-12" morph="none" pos="word" start_char="6059">say</TOKEN>
<TOKEN end_char="6063" id="token-40-13" morph="none" pos="punct" start_char="6063">–</TOKEN>
<TOKEN end_char="6067" id="token-40-14" morph="none" pos="word" start_char="6065">but</TOKEN>
<TOKEN end_char="6080" id="token-40-15" morph="none" pos="word" start_char="6069">accidentally</TOKEN>
<TOKEN end_char="6089" id="token-40-16" morph="none" pos="word" start_char="6082">escaping</TOKEN>
<TOKEN end_char="6093" id="token-40-17" morph="none" pos="word" start_char="6091">the</TOKEN>
<TOKEN end_char="6102" id="token-40-18" morph="none" pos="word" start_char="6095">research</TOKEN>
<TOKEN end_char="6111" id="token-40-19" morph="none" pos="word" start_char="6104">facility</TOKEN>
<TOKEN end_char="6119" id="token-40-20" morph="none" pos="word" start_char="6113">because</TOKEN>
<TOKEN end_char="6122" id="token-40-21" morph="none" pos="word" start_char="6121">of</TOKEN>
<TOKEN end_char="6127" id="token-40-22" morph="none" pos="word" start_char="6124">poor</TOKEN>
<TOKEN end_char="6134" id="token-40-23" morph="none" pos="word" start_char="6129">safety</TOKEN>
<TOKEN end_char="6144" id="token-40-24" morph="none" pos="word" start_char="6136">protocols</TOKEN>
<TOKEN end_char="6145" id="token-40-25" morph="none" pos="punct" start_char="6145">.</TOKEN>
</SEG>
<SEG end_char="6387" id="segment-41" start_char="6147">
<ORIGINAL_TEXT>This is based on circumstantial evidence such as the Wuhan Institute of Virology's history of studying coronaviruses in bats, the lab's proximity to where some of the infections were first diagnosed and China's lax safety record in its labs.</ORIGINAL_TEXT>
<TOKEN end_char="6150" id="token-41-0" morph="none" pos="word" start_char="6147">This</TOKEN>
<TOKEN end_char="6153" id="token-41-1" morph="none" pos="word" start_char="6152">is</TOKEN>
<TOKEN end_char="6159" id="token-41-2" morph="none" pos="word" start_char="6155">based</TOKEN>
<TOKEN end_char="6162" id="token-41-3" morph="none" pos="word" start_char="6161">on</TOKEN>
<TOKEN end_char="6177" id="token-41-4" morph="none" pos="word" start_char="6164">circumstantial</TOKEN>
<TOKEN end_char="6186" id="token-41-5" morph="none" pos="word" start_char="6179">evidence</TOKEN>
<TOKEN end_char="6191" id="token-41-6" morph="none" pos="word" start_char="6188">such</TOKEN>
<TOKEN end_char="6194" id="token-41-7" morph="none" pos="word" start_char="6193">as</TOKEN>
<TOKEN end_char="6198" id="token-41-8" morph="none" pos="word" start_char="6196">the</TOKEN>
<TOKEN end_char="6204" id="token-41-9" morph="none" pos="word" start_char="6200">Wuhan</TOKEN>
<TOKEN end_char="6214" id="token-41-10" morph="none" pos="word" start_char="6206">Institute</TOKEN>
<TOKEN end_char="6217" id="token-41-11" morph="none" pos="word" start_char="6216">of</TOKEN>
<TOKEN end_char="6228" id="token-41-12" morph="none" pos="word" start_char="6219">Virology's</TOKEN>
<TOKEN end_char="6236" id="token-41-13" morph="none" pos="word" start_char="6230">history</TOKEN>
<TOKEN end_char="6239" id="token-41-14" morph="none" pos="word" start_char="6238">of</TOKEN>
<TOKEN end_char="6248" id="token-41-15" morph="none" pos="word" start_char="6241">studying</TOKEN>
<TOKEN end_char="6262" id="token-41-16" morph="none" pos="word" start_char="6250">coronaviruses</TOKEN>
<TOKEN end_char="6265" id="token-41-17" morph="none" pos="word" start_char="6264">in</TOKEN>
<TOKEN end_char="6270" id="token-41-18" morph="none" pos="word" start_char="6267">bats</TOKEN>
<TOKEN end_char="6271" id="token-41-19" morph="none" pos="punct" start_char="6271">,</TOKEN>
<TOKEN end_char="6275" id="token-41-20" morph="none" pos="word" start_char="6273">the</TOKEN>
<TOKEN end_char="6281" id="token-41-21" morph="none" pos="word" start_char="6277">lab's</TOKEN>
<TOKEN end_char="6291" id="token-41-22" morph="none" pos="word" start_char="6283">proximity</TOKEN>
<TOKEN end_char="6294" id="token-41-23" morph="none" pos="word" start_char="6293">to</TOKEN>
<TOKEN end_char="6300" id="token-41-24" morph="none" pos="word" start_char="6296">where</TOKEN>
<TOKEN end_char="6305" id="token-41-25" morph="none" pos="word" start_char="6302">some</TOKEN>
<TOKEN end_char="6308" id="token-41-26" morph="none" pos="word" start_char="6307">of</TOKEN>
<TOKEN end_char="6312" id="token-41-27" morph="none" pos="word" start_char="6310">the</TOKEN>
<TOKEN end_char="6323" id="token-41-28" morph="none" pos="word" start_char="6314">infections</TOKEN>
<TOKEN end_char="6328" id="token-41-29" morph="none" pos="word" start_char="6325">were</TOKEN>
<TOKEN end_char="6334" id="token-41-30" morph="none" pos="word" start_char="6330">first</TOKEN>
<TOKEN end_char="6344" id="token-41-31" morph="none" pos="word" start_char="6336">diagnosed</TOKEN>
<TOKEN end_char="6348" id="token-41-32" morph="none" pos="word" start_char="6346">and</TOKEN>
<TOKEN end_char="6356" id="token-41-33" morph="none" pos="word" start_char="6350">China's</TOKEN>
<TOKEN end_char="6360" id="token-41-34" morph="none" pos="word" start_char="6358">lax</TOKEN>
<TOKEN end_char="6367" id="token-41-35" morph="none" pos="word" start_char="6362">safety</TOKEN>
<TOKEN end_char="6374" id="token-41-36" morph="none" pos="word" start_char="6369">record</TOKEN>
<TOKEN end_char="6377" id="token-41-37" morph="none" pos="word" start_char="6376">in</TOKEN>
<TOKEN end_char="6381" id="token-41-38" morph="none" pos="word" start_char="6379">its</TOKEN>
<TOKEN end_char="6386" id="token-41-39" morph="none" pos="word" start_char="6383">labs</TOKEN>
<TOKEN end_char="6387" id="token-41-40" morph="none" pos="punct" start_char="6387">.</TOKEN>
</SEG>
<SEG end_char="6557" id="segment-42" start_char="6390">
<ORIGINAL_TEXT>Anthony Fauci, the U.S.'s top infectious disease expert, was dismissive of the theory of an accidental escape from a Chinese laboratory, USA TODAY reported on April 18.</ORIGINAL_TEXT>
<TOKEN end_char="6396" id="token-42-0" morph="none" pos="word" start_char="6390">Anthony</TOKEN>
<TOKEN end_char="6402" id="token-42-1" morph="none" pos="word" start_char="6398">Fauci</TOKEN>
<TOKEN end_char="6403" id="token-42-2" morph="none" pos="punct" start_char="6403">,</TOKEN>
<TOKEN end_char="6407" id="token-42-3" morph="none" pos="word" start_char="6405">the</TOKEN>
<TOKEN end_char="6414" id="token-42-4" morph="none" pos="unknown" start_char="6409">U.S.'s</TOKEN>
<TOKEN end_char="6418" id="token-42-5" morph="none" pos="word" start_char="6416">top</TOKEN>
<TOKEN end_char="6429" id="token-42-6" morph="none" pos="word" start_char="6420">infectious</TOKEN>
<TOKEN end_char="6437" id="token-42-7" morph="none" pos="word" start_char="6431">disease</TOKEN>
<TOKEN end_char="6444" id="token-42-8" morph="none" pos="word" start_char="6439">expert</TOKEN>
<TOKEN end_char="6445" id="token-42-9" morph="none" pos="punct" start_char="6445">,</TOKEN>
<TOKEN end_char="6449" id="token-42-10" morph="none" pos="word" start_char="6447">was</TOKEN>
<TOKEN end_char="6460" id="token-42-11" morph="none" pos="word" start_char="6451">dismissive</TOKEN>
<TOKEN end_char="6463" id="token-42-12" morph="none" pos="word" start_char="6462">of</TOKEN>
<TOKEN end_char="6467" id="token-42-13" morph="none" pos="word" start_char="6465">the</TOKEN>
<TOKEN end_char="6474" id="token-42-14" morph="none" pos="word" start_char="6469">theory</TOKEN>
<TOKEN end_char="6477" id="token-42-15" morph="none" pos="word" start_char="6476">of</TOKEN>
<TOKEN end_char="6480" id="token-42-16" morph="none" pos="word" start_char="6479">an</TOKEN>
<TOKEN end_char="6491" id="token-42-17" morph="none" pos="word" start_char="6482">accidental</TOKEN>
<TOKEN end_char="6498" id="token-42-18" morph="none" pos="word" start_char="6493">escape</TOKEN>
<TOKEN end_char="6503" id="token-42-19" morph="none" pos="word" start_char="6500">from</TOKEN>
<TOKEN end_char="6505" id="token-42-20" morph="none" pos="word" start_char="6505">a</TOKEN>
<TOKEN end_char="6513" id="token-42-21" morph="none" pos="word" start_char="6507">Chinese</TOKEN>
<TOKEN end_char="6524" id="token-42-22" morph="none" pos="word" start_char="6515">laboratory</TOKEN>
<TOKEN end_char="6525" id="token-42-23" morph="none" pos="punct" start_char="6525">,</TOKEN>
<TOKEN end_char="6529" id="token-42-24" morph="none" pos="word" start_char="6527">USA</TOKEN>
<TOKEN end_char="6535" id="token-42-25" morph="none" pos="word" start_char="6531">TODAY</TOKEN>
<TOKEN end_char="6544" id="token-42-26" morph="none" pos="word" start_char="6537">reported</TOKEN>
<TOKEN end_char="6547" id="token-42-27" morph="none" pos="word" start_char="6546">on</TOKEN>
<TOKEN end_char="6553" id="token-42-28" morph="none" pos="word" start_char="6549">April</TOKEN>
<TOKEN end_char="6556" id="token-42-29" morph="none" pos="word" start_char="6555">18</TOKEN>
<TOKEN end_char="6557" id="token-42-30" morph="none" pos="punct" start_char="6557">.</TOKEN>
</SEG>
<SEG end_char="6660" id="segment-43" start_char="6560">
<ORIGINAL_TEXT>"A group of highly qualified evolutionary virologists looked at the sequences in bats as they evolve.</ORIGINAL_TEXT>
<TOKEN end_char="6560" id="token-43-0" morph="none" pos="punct" start_char="6560">"</TOKEN>
<TOKEN end_char="6561" id="token-43-1" morph="none" pos="word" start_char="6561">A</TOKEN>
<TOKEN end_char="6567" id="token-43-2" morph="none" pos="word" start_char="6563">group</TOKEN>
<TOKEN end_char="6570" id="token-43-3" morph="none" pos="word" start_char="6569">of</TOKEN>
<TOKEN end_char="6577" id="token-43-4" morph="none" pos="word" start_char="6572">highly</TOKEN>
<TOKEN end_char="6587" id="token-43-5" morph="none" pos="word" start_char="6579">qualified</TOKEN>
<TOKEN end_char="6600" id="token-43-6" morph="none" pos="word" start_char="6589">evolutionary</TOKEN>
<TOKEN end_char="6612" id="token-43-7" morph="none" pos="word" start_char="6602">virologists</TOKEN>
<TOKEN end_char="6619" id="token-43-8" morph="none" pos="word" start_char="6614">looked</TOKEN>
<TOKEN end_char="6622" id="token-43-9" morph="none" pos="word" start_char="6621">at</TOKEN>
<TOKEN end_char="6626" id="token-43-10" morph="none" pos="word" start_char="6624">the</TOKEN>
<TOKEN end_char="6636" id="token-43-11" morph="none" pos="word" start_char="6628">sequences</TOKEN>
<TOKEN end_char="6639" id="token-43-12" morph="none" pos="word" start_char="6638">in</TOKEN>
<TOKEN end_char="6644" id="token-43-13" morph="none" pos="word" start_char="6641">bats</TOKEN>
<TOKEN end_char="6647" id="token-43-14" morph="none" pos="word" start_char="6646">as</TOKEN>
<TOKEN end_char="6652" id="token-43-15" morph="none" pos="word" start_char="6649">they</TOKEN>
<TOKEN end_char="6659" id="token-43-16" morph="none" pos="word" start_char="6654">evolve</TOKEN>
<TOKEN end_char="6660" id="token-43-17" morph="none" pos="punct" start_char="6660">.</TOKEN>
</SEG>
<SEG end_char="6849" id="segment-44" start_char="6662">
<ORIGINAL_TEXT>The mutations that it took to get to the point where it is now are totally consistent with a jump of a species from an animal to a human," he said Friday in the White House press briefing.</ORIGINAL_TEXT>
<TOKEN end_char="6664" id="token-44-0" morph="none" pos="word" start_char="6662">The</TOKEN>
<TOKEN end_char="6674" id="token-44-1" morph="none" pos="word" start_char="6666">mutations</TOKEN>
<TOKEN end_char="6679" id="token-44-2" morph="none" pos="word" start_char="6676">that</TOKEN>
<TOKEN end_char="6682" id="token-44-3" morph="none" pos="word" start_char="6681">it</TOKEN>
<TOKEN end_char="6687" id="token-44-4" morph="none" pos="word" start_char="6684">took</TOKEN>
<TOKEN end_char="6690" id="token-44-5" morph="none" pos="word" start_char="6689">to</TOKEN>
<TOKEN end_char="6694" id="token-44-6" morph="none" pos="word" start_char="6692">get</TOKEN>
<TOKEN end_char="6697" id="token-44-7" morph="none" pos="word" start_char="6696">to</TOKEN>
<TOKEN end_char="6701" id="token-44-8" morph="none" pos="word" start_char="6699">the</TOKEN>
<TOKEN end_char="6707" id="token-44-9" morph="none" pos="word" start_char="6703">point</TOKEN>
<TOKEN end_char="6713" id="token-44-10" morph="none" pos="word" start_char="6709">where</TOKEN>
<TOKEN end_char="6716" id="token-44-11" morph="none" pos="word" start_char="6715">it</TOKEN>
<TOKEN end_char="6719" id="token-44-12" morph="none" pos="word" start_char="6718">is</TOKEN>
<TOKEN end_char="6723" id="token-44-13" morph="none" pos="word" start_char="6721">now</TOKEN>
<TOKEN end_char="6727" id="token-44-14" morph="none" pos="word" start_char="6725">are</TOKEN>
<TOKEN end_char="6735" id="token-44-15" morph="none" pos="word" start_char="6729">totally</TOKEN>
<TOKEN end_char="6746" id="token-44-16" morph="none" pos="word" start_char="6737">consistent</TOKEN>
<TOKEN end_char="6751" id="token-44-17" morph="none" pos="word" start_char="6748">with</TOKEN>
<TOKEN end_char="6753" id="token-44-18" morph="none" pos="word" start_char="6753">a</TOKEN>
<TOKEN end_char="6758" id="token-44-19" morph="none" pos="word" start_char="6755">jump</TOKEN>
<TOKEN end_char="6761" id="token-44-20" morph="none" pos="word" start_char="6760">of</TOKEN>
<TOKEN end_char="6763" id="token-44-21" morph="none" pos="word" start_char="6763">a</TOKEN>
<TOKEN end_char="6771" id="token-44-22" morph="none" pos="word" start_char="6765">species</TOKEN>
<TOKEN end_char="6776" id="token-44-23" morph="none" pos="word" start_char="6773">from</TOKEN>
<TOKEN end_char="6779" id="token-44-24" morph="none" pos="word" start_char="6778">an</TOKEN>
<TOKEN end_char="6786" id="token-44-25" morph="none" pos="word" start_char="6781">animal</TOKEN>
<TOKEN end_char="6789" id="token-44-26" morph="none" pos="word" start_char="6788">to</TOKEN>
<TOKEN end_char="6791" id="token-44-27" morph="none" pos="word" start_char="6791">a</TOKEN>
<TOKEN end_char="6797" id="token-44-28" morph="none" pos="word" start_char="6793">human</TOKEN>
<TOKEN end_char="6799" id="token-44-29" morph="none" pos="punct" start_char="6798">,"</TOKEN>
<TOKEN end_char="6802" id="token-44-30" morph="none" pos="word" start_char="6801">he</TOKEN>
<TOKEN end_char="6807" id="token-44-31" morph="none" pos="word" start_char="6804">said</TOKEN>
<TOKEN end_char="6814" id="token-44-32" morph="none" pos="word" start_char="6809">Friday</TOKEN>
<TOKEN end_char="6817" id="token-44-33" morph="none" pos="word" start_char="6816">in</TOKEN>
<TOKEN end_char="6821" id="token-44-34" morph="none" pos="word" start_char="6819">the</TOKEN>
<TOKEN end_char="6827" id="token-44-35" morph="none" pos="word" start_char="6823">White</TOKEN>
<TOKEN end_char="6833" id="token-44-36" morph="none" pos="word" start_char="6829">House</TOKEN>
<TOKEN end_char="6839" id="token-44-37" morph="none" pos="word" start_char="6835">press</TOKEN>
<TOKEN end_char="6848" id="token-44-38" morph="none" pos="word" start_char="6841">briefing</TOKEN>
<TOKEN end_char="6849" id="token-44-39" morph="none" pos="punct" start_char="6849">.</TOKEN>
</SEG>
<SEG end_char="7202" id="segment-45" start_char="6852">
<ORIGINAL_TEXT>But two administration officials with knowledge of the investigation, speaking to USA TODAY on condition of anonymity because it is classified and sensitive, said they have always questioned China's account of how the virus originated and have taken seriously suggestions that it may have resulted from a lab accident that the Chinese are covering up.</ORIGINAL_TEXT>
<TOKEN end_char="6854" id="token-45-0" morph="none" pos="word" start_char="6852">But</TOKEN>
<TOKEN end_char="6858" id="token-45-1" morph="none" pos="word" start_char="6856">two</TOKEN>
<TOKEN end_char="6873" id="token-45-2" morph="none" pos="word" start_char="6860">administration</TOKEN>
<TOKEN end_char="6883" id="token-45-3" morph="none" pos="word" start_char="6875">officials</TOKEN>
<TOKEN end_char="6888" id="token-45-4" morph="none" pos="word" start_char="6885">with</TOKEN>
<TOKEN end_char="6898" id="token-45-5" morph="none" pos="word" start_char="6890">knowledge</TOKEN>
<TOKEN end_char="6901" id="token-45-6" morph="none" pos="word" start_char="6900">of</TOKEN>
<TOKEN end_char="6905" id="token-45-7" morph="none" pos="word" start_char="6903">the</TOKEN>
<TOKEN end_char="6919" id="token-45-8" morph="none" pos="word" start_char="6907">investigation</TOKEN>
<TOKEN end_char="6920" id="token-45-9" morph="none" pos="punct" start_char="6920">,</TOKEN>
<TOKEN end_char="6929" id="token-45-10" morph="none" pos="word" start_char="6922">speaking</TOKEN>
<TOKEN end_char="6932" id="token-45-11" morph="none" pos="word" start_char="6931">to</TOKEN>
<TOKEN end_char="6936" id="token-45-12" morph="none" pos="word" start_char="6934">USA</TOKEN>
<TOKEN end_char="6942" id="token-45-13" morph="none" pos="word" start_char="6938">TODAY</TOKEN>
<TOKEN end_char="6945" id="token-45-14" morph="none" pos="word" start_char="6944">on</TOKEN>
<TOKEN end_char="6955" id="token-45-15" morph="none" pos="word" start_char="6947">condition</TOKEN>
<TOKEN end_char="6958" id="token-45-16" morph="none" pos="word" start_char="6957">of</TOKEN>
<TOKEN end_char="6968" id="token-45-17" morph="none" pos="word" start_char="6960">anonymity</TOKEN>
<TOKEN end_char="6976" id="token-45-18" morph="none" pos="word" start_char="6970">because</TOKEN>
<TOKEN end_char="6979" id="token-45-19" morph="none" pos="word" start_char="6978">it</TOKEN>
<TOKEN end_char="6982" id="token-45-20" morph="none" pos="word" start_char="6981">is</TOKEN>
<TOKEN end_char="6993" id="token-45-21" morph="none" pos="word" start_char="6984">classified</TOKEN>
<TOKEN end_char="6997" id="token-45-22" morph="none" pos="word" start_char="6995">and</TOKEN>
<TOKEN end_char="7007" id="token-45-23" morph="none" pos="word" start_char="6999">sensitive</TOKEN>
<TOKEN end_char="7008" id="token-45-24" morph="none" pos="punct" start_char="7008">,</TOKEN>
<TOKEN end_char="7013" id="token-45-25" morph="none" pos="word" start_char="7010">said</TOKEN>
<TOKEN end_char="7018" id="token-45-26" morph="none" pos="word" start_char="7015">they</TOKEN>
<TOKEN end_char="7023" id="token-45-27" morph="none" pos="word" start_char="7020">have</TOKEN>
<TOKEN end_char="7030" id="token-45-28" morph="none" pos="word" start_char="7025">always</TOKEN>
<TOKEN end_char="7041" id="token-45-29" morph="none" pos="word" start_char="7032">questioned</TOKEN>
<TOKEN end_char="7049" id="token-45-30" morph="none" pos="word" start_char="7043">China's</TOKEN>
<TOKEN end_char="7057" id="token-45-31" morph="none" pos="word" start_char="7051">account</TOKEN>
<TOKEN end_char="7060" id="token-45-32" morph="none" pos="word" start_char="7059">of</TOKEN>
<TOKEN end_char="7064" id="token-45-33" morph="none" pos="word" start_char="7062">how</TOKEN>
<TOKEN end_char="7068" id="token-45-34" morph="none" pos="word" start_char="7066">the</TOKEN>
<TOKEN end_char="7074" id="token-45-35" morph="none" pos="word" start_char="7070">virus</TOKEN>
<TOKEN end_char="7085" id="token-45-36" morph="none" pos="word" start_char="7076">originated</TOKEN>
<TOKEN end_char="7089" id="token-45-37" morph="none" pos="word" start_char="7087">and</TOKEN>
<TOKEN end_char="7094" id="token-45-38" morph="none" pos="word" start_char="7091">have</TOKEN>
<TOKEN end_char="7100" id="token-45-39" morph="none" pos="word" start_char="7096">taken</TOKEN>
<TOKEN end_char="7110" id="token-45-40" morph="none" pos="word" start_char="7102">seriously</TOKEN>
<TOKEN end_char="7122" id="token-45-41" morph="none" pos="word" start_char="7112">suggestions</TOKEN>
<TOKEN end_char="7127" id="token-45-42" morph="none" pos="word" start_char="7124">that</TOKEN>
<TOKEN end_char="7130" id="token-45-43" morph="none" pos="word" start_char="7129">it</TOKEN>
<TOKEN end_char="7134" id="token-45-44" morph="none" pos="word" start_char="7132">may</TOKEN>
<TOKEN end_char="7139" id="token-45-45" morph="none" pos="word" start_char="7136">have</TOKEN>
<TOKEN end_char="7148" id="token-45-46" morph="none" pos="word" start_char="7141">resulted</TOKEN>
<TOKEN end_char="7153" id="token-45-47" morph="none" pos="word" start_char="7150">from</TOKEN>
<TOKEN end_char="7155" id="token-45-48" morph="none" pos="word" start_char="7155">a</TOKEN>
<TOKEN end_char="7159" id="token-45-49" morph="none" pos="word" start_char="7157">lab</TOKEN>
<TOKEN end_char="7168" id="token-45-50" morph="none" pos="word" start_char="7161">accident</TOKEN>
<TOKEN end_char="7173" id="token-45-51" morph="none" pos="word" start_char="7170">that</TOKEN>
<TOKEN end_char="7177" id="token-45-52" morph="none" pos="word" start_char="7175">the</TOKEN>
<TOKEN end_char="7185" id="token-45-53" morph="none" pos="word" start_char="7179">Chinese</TOKEN>
<TOKEN end_char="7189" id="token-45-54" morph="none" pos="word" start_char="7187">are</TOKEN>
<TOKEN end_char="7198" id="token-45-55" morph="none" pos="word" start_char="7191">covering</TOKEN>
<TOKEN end_char="7201" id="token-45-56" morph="none" pos="word" start_char="7200">up</TOKEN>
<TOKEN end_char="7202" id="token-45-57" morph="none" pos="punct" start_char="7202">.</TOKEN>
</SEG>
<SEG end_char="7259" id="segment-46" start_char="7205">
<ORIGINAL_TEXT>"There's a high level of suspicion," one official said.</ORIGINAL_TEXT>
<TOKEN end_char="7205" id="token-46-0" morph="none" pos="punct" start_char="7205">"</TOKEN>
<TOKEN end_char="7212" id="token-46-1" morph="none" pos="word" start_char="7206">There's</TOKEN>
<TOKEN end_char="7214" id="token-46-2" morph="none" pos="word" start_char="7214">a</TOKEN>
<TOKEN end_char="7219" id="token-46-3" morph="none" pos="word" start_char="7216">high</TOKEN>
<TOKEN end_char="7225" id="token-46-4" morph="none" pos="word" start_char="7221">level</TOKEN>
<TOKEN end_char="7228" id="token-46-5" morph="none" pos="word" start_char="7227">of</TOKEN>
<TOKEN end_char="7238" id="token-46-6" morph="none" pos="word" start_char="7230">suspicion</TOKEN>
<TOKEN end_char="7240" id="token-46-7" morph="none" pos="punct" start_char="7239">,"</TOKEN>
<TOKEN end_char="7244" id="token-46-8" morph="none" pos="word" start_char="7242">one</TOKEN>
<TOKEN end_char="7253" id="token-46-9" morph="none" pos="word" start_char="7246">official</TOKEN>
<TOKEN end_char="7258" id="token-46-10" morph="none" pos="word" start_char="7255">said</TOKEN>
<TOKEN end_char="7259" id="token-46-11" morph="none" pos="punct" start_char="7259">.</TOKEN>
</SEG>
<SEG end_char="7393" id="segment-47" start_char="7262">
<ORIGINAL_TEXT>The officials emphasized that no conclusions have been drawn from an investigation that is ongoing among U.S. intelligence agencies.</ORIGINAL_TEXT>
<TOKEN end_char="7264" id="token-47-0" morph="none" pos="word" start_char="7262">The</TOKEN>
<TOKEN end_char="7274" id="token-47-1" morph="none" pos="word" start_char="7266">officials</TOKEN>
<TOKEN end_char="7285" id="token-47-2" morph="none" pos="word" start_char="7276">emphasized</TOKEN>
<TOKEN end_char="7290" id="token-47-3" morph="none" pos="word" start_char="7287">that</TOKEN>
<TOKEN end_char="7293" id="token-47-4" morph="none" pos="word" start_char="7292">no</TOKEN>
<TOKEN end_char="7305" id="token-47-5" morph="none" pos="word" start_char="7295">conclusions</TOKEN>
<TOKEN end_char="7310" id="token-47-6" morph="none" pos="word" start_char="7307">have</TOKEN>
<TOKEN end_char="7315" id="token-47-7" morph="none" pos="word" start_char="7312">been</TOKEN>
<TOKEN end_char="7321" id="token-47-8" morph="none" pos="word" start_char="7317">drawn</TOKEN>
<TOKEN end_char="7326" id="token-47-9" morph="none" pos="word" start_char="7323">from</TOKEN>
<TOKEN end_char="7329" id="token-47-10" morph="none" pos="word" start_char="7328">an</TOKEN>
<TOKEN end_char="7343" id="token-47-11" morph="none" pos="word" start_char="7331">investigation</TOKEN>
<TOKEN end_char="7348" id="token-47-12" morph="none" pos="word" start_char="7345">that</TOKEN>
<TOKEN end_char="7351" id="token-47-13" morph="none" pos="word" start_char="7350">is</TOKEN>
<TOKEN end_char="7359" id="token-47-14" morph="none" pos="word" start_char="7353">ongoing</TOKEN>
<TOKEN end_char="7365" id="token-47-15" morph="none" pos="word" start_char="7361">among</TOKEN>
<TOKEN end_char="7369" id="token-47-16" morph="none" pos="unknown" start_char="7367">U.S</TOKEN>
<TOKEN end_char="7370" id="token-47-17" morph="none" pos="punct" start_char="7370">.</TOKEN>
<TOKEN end_char="7383" id="token-47-18" morph="none" pos="word" start_char="7372">intelligence</TOKEN>
<TOKEN end_char="7392" id="token-47-19" morph="none" pos="word" start_char="7385">agencies</TOKEN>
<TOKEN end_char="7393" id="token-47-20" morph="none" pos="punct" start_char="7393">.</TOKEN>
</SEG>
<SEG end_char="7414" id="segment-48" start_char="7396">
<ORIGINAL_TEXT>But even as of Jan.</ORIGINAL_TEXT>
<TOKEN end_char="7398" id="token-48-0" morph="none" pos="word" start_char="7396">But</TOKEN>
<TOKEN end_char="7403" id="token-48-1" morph="none" pos="word" start_char="7400">even</TOKEN>
<TOKEN end_char="7406" id="token-48-2" morph="none" pos="word" start_char="7405">as</TOKEN>
<TOKEN end_char="7409" id="token-48-3" morph="none" pos="word" start_char="7408">of</TOKEN>
<TOKEN end_char="7413" id="token-48-4" morph="none" pos="word" start_char="7411">Jan</TOKEN>
<TOKEN end_char="7414" id="token-48-5" morph="none" pos="punct" start_char="7414">.</TOKEN>
</SEG>
<SEG end_char="7641" id="segment-49" start_char="7416">
<ORIGINAL_TEXT>15, 2021, its origins are unclear, as described in this State Department statement: "The U.S. government does not know exactly where, when, or how the COVID-19 virus — known as SARS-CoV-2 — was transmitted initially to humans.</ORIGINAL_TEXT>
<TOKEN end_char="7417" id="token-49-0" morph="none" pos="word" start_char="7416">15</TOKEN>
<TOKEN end_char="7418" id="token-49-1" morph="none" pos="punct" start_char="7418">,</TOKEN>
<TOKEN end_char="7423" id="token-49-2" morph="none" pos="word" start_char="7420">2021</TOKEN>
<TOKEN end_char="7424" id="token-49-3" morph="none" pos="punct" start_char="7424">,</TOKEN>
<TOKEN end_char="7428" id="token-49-4" morph="none" pos="word" start_char="7426">its</TOKEN>
<TOKEN end_char="7436" id="token-49-5" morph="none" pos="word" start_char="7430">origins</TOKEN>
<TOKEN end_char="7440" id="token-49-6" morph="none" pos="word" start_char="7438">are</TOKEN>
<TOKEN end_char="7448" id="token-49-7" morph="none" pos="word" start_char="7442">unclear</TOKEN>
<TOKEN end_char="7449" id="token-49-8" morph="none" pos="punct" start_char="7449">,</TOKEN>
<TOKEN end_char="7452" id="token-49-9" morph="none" pos="word" start_char="7451">as</TOKEN>
<TOKEN end_char="7462" id="token-49-10" morph="none" pos="word" start_char="7454">described</TOKEN>
<TOKEN end_char="7465" id="token-49-11" morph="none" pos="word" start_char="7464">in</TOKEN>
<TOKEN end_char="7470" id="token-49-12" morph="none" pos="word" start_char="7467">this</TOKEN>
<TOKEN end_char="7476" id="token-49-13" morph="none" pos="word" start_char="7472">State</TOKEN>
<TOKEN end_char="7487" id="token-49-14" morph="none" pos="word" start_char="7478">Department</TOKEN>
<TOKEN end_char="7497" id="token-49-15" morph="none" pos="word" start_char="7489">statement</TOKEN>
<TOKEN end_char="7498" id="token-49-16" morph="none" pos="punct" start_char="7498">:</TOKEN>
<TOKEN end_char="7500" id="token-49-17" morph="none" pos="punct" start_char="7500">"</TOKEN>
<TOKEN end_char="7503" id="token-49-18" morph="none" pos="word" start_char="7501">The</TOKEN>
<TOKEN end_char="7507" id="token-49-19" morph="none" pos="unknown" start_char="7505">U.S</TOKEN>
<TOKEN end_char="7508" id="token-49-20" morph="none" pos="punct" start_char="7508">.</TOKEN>
<TOKEN end_char="7519" id="token-49-21" morph="none" pos="word" start_char="7510">government</TOKEN>
<TOKEN end_char="7524" id="token-49-22" morph="none" pos="word" start_char="7521">does</TOKEN>
<TOKEN end_char="7528" id="token-49-23" morph="none" pos="word" start_char="7526">not</TOKEN>
<TOKEN end_char="7533" id="token-49-24" morph="none" pos="word" start_char="7530">know</TOKEN>
<TOKEN end_char="7541" id="token-49-25" morph="none" pos="word" start_char="7535">exactly</TOKEN>
<TOKEN end_char="7547" id="token-49-26" morph="none" pos="word" start_char="7543">where</TOKEN>
<TOKEN end_char="7548" id="token-49-27" morph="none" pos="punct" start_char="7548">,</TOKEN>
<TOKEN end_char="7553" id="token-49-28" morph="none" pos="word" start_char="7550">when</TOKEN>
<TOKEN end_char="7554" id="token-49-29" morph="none" pos="punct" start_char="7554">,</TOKEN>
<TOKEN end_char="7557" id="token-49-30" morph="none" pos="word" start_char="7556">or</TOKEN>
<TOKEN end_char="7561" id="token-49-31" morph="none" pos="word" start_char="7559">how</TOKEN>
<TOKEN end_char="7565" id="token-49-32" morph="none" pos="word" start_char="7563">the</TOKEN>
<TOKEN end_char="7574" id="token-49-33" morph="none" pos="unknown" start_char="7567">COVID-19</TOKEN>
<TOKEN end_char="7580" id="token-49-34" morph="none" pos="word" start_char="7576">virus</TOKEN>
<TOKEN end_char="7582" id="token-49-35" morph="none" pos="punct" start_char="7582">—</TOKEN>
<TOKEN end_char="7588" id="token-49-36" morph="none" pos="word" start_char="7584">known</TOKEN>
<TOKEN end_char="7591" id="token-49-37" morph="none" pos="word" start_char="7590">as</TOKEN>
<TOKEN end_char="7602" id="token-49-38" morph="none" pos="unknown" start_char="7593">SARS-CoV-2</TOKEN>
<TOKEN end_char="7604" id="token-49-39" morph="none" pos="punct" start_char="7604">—</TOKEN>
<TOKEN end_char="7608" id="token-49-40" morph="none" pos="word" start_char="7606">was</TOKEN>
<TOKEN end_char="7620" id="token-49-41" morph="none" pos="word" start_char="7610">transmitted</TOKEN>
<TOKEN end_char="7630" id="token-49-42" morph="none" pos="word" start_char="7622">initially</TOKEN>
<TOKEN end_char="7633" id="token-49-43" morph="none" pos="word" start_char="7632">to</TOKEN>
<TOKEN end_char="7640" id="token-49-44" morph="none" pos="word" start_char="7635">humans</TOKEN>
<TOKEN end_char="7641" id="token-49-45" morph="none" pos="punct" start_char="7641">.</TOKEN>
</SEG>
<SEG end_char="7796" id="segment-50" start_char="7643">
<ORIGINAL_TEXT>We have not determined whether the outbreak began through contact with infected animals or was the result of an accident at a laboratory in Wuhan, China."</ORIGINAL_TEXT>
<TOKEN end_char="7644" id="token-50-0" morph="none" pos="word" start_char="7643">We</TOKEN>
<TOKEN end_char="7649" id="token-50-1" morph="none" pos="word" start_char="7646">have</TOKEN>
<TOKEN end_char="7653" id="token-50-2" morph="none" pos="word" start_char="7651">not</TOKEN>
<TOKEN end_char="7664" id="token-50-3" morph="none" pos="word" start_char="7655">determined</TOKEN>
<TOKEN end_char="7672" id="token-50-4" morph="none" pos="word" start_char="7666">whether</TOKEN>
<TOKEN end_char="7676" id="token-50-5" morph="none" pos="word" start_char="7674">the</TOKEN>
<TOKEN end_char="7685" id="token-50-6" morph="none" pos="word" start_char="7678">outbreak</TOKEN>
<TOKEN end_char="7691" id="token-50-7" morph="none" pos="word" start_char="7687">began</TOKEN>
<TOKEN end_char="7699" id="token-50-8" morph="none" pos="word" start_char="7693">through</TOKEN>
<TOKEN end_char="7707" id="token-50-9" morph="none" pos="word" start_char="7701">contact</TOKEN>
<TOKEN end_char="7712" id="token-50-10" morph="none" pos="word" start_char="7709">with</TOKEN>
<TOKEN end_char="7721" id="token-50-11" morph="none" pos="word" start_char="7714">infected</TOKEN>
<TOKEN end_char="7729" id="token-50-12" morph="none" pos="word" start_char="7723">animals</TOKEN>
<TOKEN end_char="7732" id="token-50-13" morph="none" pos="word" start_char="7731">or</TOKEN>
<TOKEN end_char="7736" id="token-50-14" morph="none" pos="word" start_char="7734">was</TOKEN>
<TOKEN end_char="7740" id="token-50-15" morph="none" pos="word" start_char="7738">the</TOKEN>
<TOKEN end_char="7747" id="token-50-16" morph="none" pos="word" start_char="7742">result</TOKEN>
<TOKEN end_char="7750" id="token-50-17" morph="none" pos="word" start_char="7749">of</TOKEN>
<TOKEN end_char="7753" id="token-50-18" morph="none" pos="word" start_char="7752">an</TOKEN>
<TOKEN end_char="7762" id="token-50-19" morph="none" pos="word" start_char="7755">accident</TOKEN>
<TOKEN end_char="7765" id="token-50-20" morph="none" pos="word" start_char="7764">at</TOKEN>
<TOKEN end_char="7767" id="token-50-21" morph="none" pos="word" start_char="7767">a</TOKEN>
<TOKEN end_char="7778" id="token-50-22" morph="none" pos="word" start_char="7769">laboratory</TOKEN>
<TOKEN end_char="7781" id="token-50-23" morph="none" pos="word" start_char="7780">in</TOKEN>
<TOKEN end_char="7787" id="token-50-24" morph="none" pos="word" start_char="7783">Wuhan</TOKEN>
<TOKEN end_char="7788" id="token-50-25" morph="none" pos="punct" start_char="7788">,</TOKEN>
<TOKEN end_char="7794" id="token-50-26" morph="none" pos="word" start_char="7790">China</TOKEN>
<TOKEN end_char="7796" id="token-50-27" morph="none" pos="punct" start_char="7795">."</TOKEN>
</SEG>
<SEG end_char="7822" id="segment-51" start_char="7799">
<ORIGINAL_TEXT>Our ruling: Partly False</ORIGINAL_TEXT>
<TOKEN end_char="7801" id="token-51-0" morph="none" pos="word" start_char="7799">Our</TOKEN>
<TOKEN end_char="7808" id="token-51-1" morph="none" pos="word" start_char="7803">ruling</TOKEN>
<TOKEN end_char="7809" id="token-51-2" morph="none" pos="punct" start_char="7809">:</TOKEN>
<TOKEN end_char="7816" id="token-51-3" morph="none" pos="word" start_char="7811">Partly</TOKEN>
<TOKEN end_char="7822" id="token-51-4" morph="none" pos="word" start_char="7818">False</TOKEN>
</SEG>
<SEG end_char="7910" id="segment-52" start_char="7826">
<ORIGINAL_TEXT>We rate the claim that COVID-19 may have originated in a Chinese lab as PARTLY FALSE.</ORIGINAL_TEXT>
<TOKEN end_char="7827" id="token-52-0" morph="none" pos="word" start_char="7826">We</TOKEN>
<TOKEN end_char="7832" id="token-52-1" morph="none" pos="word" start_char="7829">rate</TOKEN>
<TOKEN end_char="7836" id="token-52-2" morph="none" pos="word" start_char="7834">the</TOKEN>
<TOKEN end_char="7842" id="token-52-3" morph="none" pos="word" start_char="7838">claim</TOKEN>
<TOKEN end_char="7847" id="token-52-4" morph="none" pos="word" start_char="7844">that</TOKEN>
<TOKEN end_char="7856" id="token-52-5" morph="none" pos="unknown" start_char="7849">COVID-19</TOKEN>
<TOKEN end_char="7860" id="token-52-6" morph="none" pos="word" start_char="7858">may</TOKEN>
<TOKEN end_char="7865" id="token-52-7" morph="none" pos="word" start_char="7862">have</TOKEN>
<TOKEN end_char="7876" id="token-52-8" morph="none" pos="word" start_char="7867">originated</TOKEN>
<TOKEN end_char="7879" id="token-52-9" morph="none" pos="word" start_char="7878">in</TOKEN>
<TOKEN end_char="7881" id="token-52-10" morph="none" pos="word" start_char="7881">a</TOKEN>
<TOKEN end_char="7889" id="token-52-11" morph="none" pos="word" start_char="7883">Chinese</TOKEN>
<TOKEN end_char="7893" id="token-52-12" morph="none" pos="word" start_char="7891">lab</TOKEN>
<TOKEN end_char="7896" id="token-52-13" morph="none" pos="word" start_char="7895">as</TOKEN>
<TOKEN end_char="7903" id="token-52-14" morph="none" pos="word" start_char="7898">PARTLY</TOKEN>
<TOKEN end_char="7909" id="token-52-15" morph="none" pos="word" start_char="7905">FALSE</TOKEN>
<TOKEN end_char="7910" id="token-52-16" morph="none" pos="punct" start_char="7910">.</TOKEN>
</SEG>
<SEG end_char="8129" id="segment-53" start_char="7912">
<ORIGINAL_TEXT>Suggestions that the novel coronavirus was engineered for use in bioweapons in a high-security biomedical laboratory in Wuhan, China, were debunked, based on scientific research since the virus began its global spread.</ORIGINAL_TEXT>
<TOKEN end_char="7922" id="token-53-0" morph="none" pos="word" start_char="7912">Suggestions</TOKEN>
<TOKEN end_char="7927" id="token-53-1" morph="none" pos="word" start_char="7924">that</TOKEN>
<TOKEN end_char="7931" id="token-53-2" morph="none" pos="word" start_char="7929">the</TOKEN>
<TOKEN end_char="7937" id="token-53-3" morph="none" pos="word" start_char="7933">novel</TOKEN>
<TOKEN end_char="7949" id="token-53-4" morph="none" pos="word" start_char="7939">coronavirus</TOKEN>
<TOKEN end_char="7953" id="token-53-5" morph="none" pos="word" start_char="7951">was</TOKEN>
<TOKEN end_char="7964" id="token-53-6" morph="none" pos="word" start_char="7955">engineered</TOKEN>
<TOKEN end_char="7968" id="token-53-7" morph="none" pos="word" start_char="7966">for</TOKEN>
<TOKEN end_char="7972" id="token-53-8" morph="none" pos="word" start_char="7970">use</TOKEN>
<TOKEN end_char="7975" id="token-53-9" morph="none" pos="word" start_char="7974">in</TOKEN>
<TOKEN end_char="7986" id="token-53-10" morph="none" pos="word" start_char="7977">bioweapons</TOKEN>
<TOKEN end_char="7989" id="token-53-11" morph="none" pos="word" start_char="7988">in</TOKEN>
<TOKEN end_char="7991" id="token-53-12" morph="none" pos="word" start_char="7991">a</TOKEN>
<TOKEN end_char="8005" id="token-53-13" morph="none" pos="unknown" start_char="7993">high-security</TOKEN>
<TOKEN end_char="8016" id="token-53-14" morph="none" pos="word" start_char="8007">biomedical</TOKEN>
<TOKEN end_char="8027" id="token-53-15" morph="none" pos="word" start_char="8018">laboratory</TOKEN>
<TOKEN end_char="8030" id="token-53-16" morph="none" pos="word" start_char="8029">in</TOKEN>
<TOKEN end_char="8036" id="token-53-17" morph="none" pos="word" start_char="8032">Wuhan</TOKEN>
<TOKEN end_char="8037" id="token-53-18" morph="none" pos="punct" start_char="8037">,</TOKEN>
<TOKEN end_char="8043" id="token-53-19" morph="none" pos="word" start_char="8039">China</TOKEN>
<TOKEN end_char="8044" id="token-53-20" morph="none" pos="punct" start_char="8044">,</TOKEN>
<TOKEN end_char="8049" id="token-53-21" morph="none" pos="word" start_char="8046">were</TOKEN>
<TOKEN end_char="8058" id="token-53-22" morph="none" pos="word" start_char="8051">debunked</TOKEN>
<TOKEN end_char="8059" id="token-53-23" morph="none" pos="punct" start_char="8059">,</TOKEN>
<TOKEN end_char="8065" id="token-53-24" morph="none" pos="word" start_char="8061">based</TOKEN>
<TOKEN end_char="8068" id="token-53-25" morph="none" pos="word" start_char="8067">on</TOKEN>
<TOKEN end_char="8079" id="token-53-26" morph="none" pos="word" start_char="8070">scientific</TOKEN>
<TOKEN end_char="8088" id="token-53-27" morph="none" pos="word" start_char="8081">research</TOKEN>
<TOKEN end_char="8094" id="token-53-28" morph="none" pos="word" start_char="8090">since</TOKEN>
<TOKEN end_char="8098" id="token-53-29" morph="none" pos="word" start_char="8096">the</TOKEN>
<TOKEN end_char="8104" id="token-53-30" morph="none" pos="word" start_char="8100">virus</TOKEN>
<TOKEN end_char="8110" id="token-53-31" morph="none" pos="word" start_char="8106">began</TOKEN>
<TOKEN end_char="8114" id="token-53-32" morph="none" pos="word" start_char="8112">its</TOKEN>
<TOKEN end_char="8121" id="token-53-33" morph="none" pos="word" start_char="8116">global</TOKEN>
<TOKEN end_char="8128" id="token-53-34" morph="none" pos="word" start_char="8123">spread</TOKEN>
<TOKEN end_char="8129" id="token-53-35" morph="none" pos="punct" start_char="8129">.</TOKEN>
</SEG>
<SEG end_char="8296" id="segment-54" start_char="8131">
<ORIGINAL_TEXT>Investigations continue into where COVID-19 began, and no conclusions can be drawn, nor has evidence been presented, that definitively explains the pathogen’s origin.</ORIGINAL_TEXT>
<TOKEN end_char="8144" id="token-54-0" morph="none" pos="word" start_char="8131">Investigations</TOKEN>
<TOKEN end_char="8153" id="token-54-1" morph="none" pos="word" start_char="8146">continue</TOKEN>
<TOKEN end_char="8158" id="token-54-2" morph="none" pos="word" start_char="8155">into</TOKEN>
<TOKEN end_char="8164" id="token-54-3" morph="none" pos="word" start_char="8160">where</TOKEN>
<TOKEN end_char="8173" id="token-54-4" morph="none" pos="unknown" start_char="8166">COVID-19</TOKEN>
<TOKEN end_char="8179" id="token-54-5" morph="none" pos="word" start_char="8175">began</TOKEN>
<TOKEN end_char="8180" id="token-54-6" morph="none" pos="punct" start_char="8180">,</TOKEN>
<TOKEN end_char="8184" id="token-54-7" morph="none" pos="word" start_char="8182">and</TOKEN>
<TOKEN end_char="8187" id="token-54-8" morph="none" pos="word" start_char="8186">no</TOKEN>
<TOKEN end_char="8199" id="token-54-9" morph="none" pos="word" start_char="8189">conclusions</TOKEN>
<TOKEN end_char="8203" id="token-54-10" morph="none" pos="word" start_char="8201">can</TOKEN>
<TOKEN end_char="8206" id="token-54-11" morph="none" pos="word" start_char="8205">be</TOKEN>
<TOKEN end_char="8212" id="token-54-12" morph="none" pos="word" start_char="8208">drawn</TOKEN>
<TOKEN end_char="8213" id="token-54-13" morph="none" pos="punct" start_char="8213">,</TOKEN>
<TOKEN end_char="8217" id="token-54-14" morph="none" pos="word" start_char="8215">nor</TOKEN>
<TOKEN end_char="8221" id="token-54-15" morph="none" pos="word" start_char="8219">has</TOKEN>
<TOKEN end_char="8230" id="token-54-16" morph="none" pos="word" start_char="8223">evidence</TOKEN>
<TOKEN end_char="8235" id="token-54-17" morph="none" pos="word" start_char="8232">been</TOKEN>
<TOKEN end_char="8245" id="token-54-18" morph="none" pos="word" start_char="8237">presented</TOKEN>
<TOKEN end_char="8246" id="token-54-19" morph="none" pos="punct" start_char="8246">,</TOKEN>
<TOKEN end_char="8251" id="token-54-20" morph="none" pos="word" start_char="8248">that</TOKEN>
<TOKEN end_char="8264" id="token-54-21" morph="none" pos="word" start_char="8253">definitively</TOKEN>
<TOKEN end_char="8273" id="token-54-22" morph="none" pos="word" start_char="8266">explains</TOKEN>
<TOKEN end_char="8277" id="token-54-23" morph="none" pos="word" start_char="8275">the</TOKEN>
<TOKEN end_char="8288" id="token-54-24" morph="none" pos="word" start_char="8279">pathogen’s</TOKEN>
<TOKEN end_char="8295" id="token-54-25" morph="none" pos="word" start_char="8290">origin</TOKEN>
<TOKEN end_char="8296" id="token-54-26" morph="none" pos="punct" start_char="8296">.</TOKEN>
</SEG>
<SEG end_char="8412" id="segment-55" start_char="8298">
<ORIGINAL_TEXT>Circumstantial evidence suggests the virus could have escaped from the Wuhan lab due to a lapse in safety measures.</ORIGINAL_TEXT>
<TOKEN end_char="8311" id="token-55-0" morph="none" pos="word" start_char="8298">Circumstantial</TOKEN>
<TOKEN end_char="8320" id="token-55-1" morph="none" pos="word" start_char="8313">evidence</TOKEN>
<TOKEN end_char="8329" id="token-55-2" morph="none" pos="word" start_char="8322">suggests</TOKEN>
<TOKEN end_char="8333" id="token-55-3" morph="none" pos="word" start_char="8331">the</TOKEN>
<TOKEN end_char="8339" id="token-55-4" morph="none" pos="word" start_char="8335">virus</TOKEN>
<TOKEN end_char="8345" id="token-55-5" morph="none" pos="word" start_char="8341">could</TOKEN>
<TOKEN end_char="8350" id="token-55-6" morph="none" pos="word" start_char="8347">have</TOKEN>
<TOKEN end_char="8358" id="token-55-7" morph="none" pos="word" start_char="8352">escaped</TOKEN>
<TOKEN end_char="8363" id="token-55-8" morph="none" pos="word" start_char="8360">from</TOKEN>
<TOKEN end_char="8367" id="token-55-9" morph="none" pos="word" start_char="8365">the</TOKEN>
<TOKEN end_char="8373" id="token-55-10" morph="none" pos="word" start_char="8369">Wuhan</TOKEN>
<TOKEN end_char="8377" id="token-55-11" morph="none" pos="word" start_char="8375">lab</TOKEN>
<TOKEN end_char="8381" id="token-55-12" morph="none" pos="word" start_char="8379">due</TOKEN>
<TOKEN end_char="8384" id="token-55-13" morph="none" pos="word" start_char="8383">to</TOKEN>
<TOKEN end_char="8386" id="token-55-14" morph="none" pos="word" start_char="8386">a</TOKEN>
<TOKEN end_char="8392" id="token-55-15" morph="none" pos="word" start_char="8388">lapse</TOKEN>
<TOKEN end_char="8395" id="token-55-16" morph="none" pos="word" start_char="8394">in</TOKEN>
<TOKEN end_char="8402" id="token-55-17" morph="none" pos="word" start_char="8397">safety</TOKEN>
<TOKEN end_char="8411" id="token-55-18" morph="none" pos="word" start_char="8404">measures</TOKEN>
<TOKEN end_char="8412" id="token-55-19" morph="none" pos="punct" start_char="8412">.</TOKEN>
</SEG>
<SEG end_char="8437" id="segment-56" start_char="8415">
<ORIGINAL_TEXT>Our fact-check sources:</ORIGINAL_TEXT>
<TOKEN end_char="8417" id="token-56-0" morph="none" pos="word" start_char="8415">Our</TOKEN>
<TOKEN end_char="8428" id="token-56-1" morph="none" pos="unknown" start_char="8419">fact-check</TOKEN>
<TOKEN end_char="8436" id="token-56-2" morph="none" pos="word" start_char="8430">sources</TOKEN>
<TOKEN end_char="8437" id="token-56-3" morph="none" pos="punct" start_char="8437">:</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
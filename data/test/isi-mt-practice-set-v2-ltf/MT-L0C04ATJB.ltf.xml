<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATJB" lang="spa" raw_text_char_length="2391" raw_text_md5="e6e1c1bc6cb7986af232331a254c40d2" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="80" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Does the coronavirus no longer exist clinically as claimed by an Italian doctor?</ORIGINAL_TEXT>
<TOKEN end_char="4" id="token-0-0" morph="none" pos="word" start_char="1">Does</TOKEN>
<TOKEN end_char="8" id="token-0-1" morph="none" pos="word" start_char="6">the</TOKEN>
<TOKEN end_char="20" id="token-0-2" morph="none" pos="word" start_char="10">coronavirus</TOKEN>
<TOKEN end_char="23" id="token-0-3" morph="none" pos="word" start_char="22">no</TOKEN>
<TOKEN end_char="30" id="token-0-4" morph="none" pos="word" start_char="25">longer</TOKEN>
<TOKEN end_char="36" id="token-0-5" morph="none" pos="word" start_char="32">exist</TOKEN>
<TOKEN end_char="47" id="token-0-6" morph="none" pos="word" start_char="38">clinically</TOKEN>
<TOKEN end_char="50" id="token-0-7" morph="none" pos="word" start_char="49">as</TOKEN>
<TOKEN end_char="58" id="token-0-8" morph="none" pos="word" start_char="52">claimed</TOKEN>
<TOKEN end_char="61" id="token-0-9" morph="none" pos="word" start_char="60">by</TOKEN>
<TOKEN end_char="64" id="token-0-10" morph="none" pos="word" start_char="63">an</TOKEN>
<TOKEN end_char="72" id="token-0-11" morph="none" pos="word" start_char="66">Italian</TOKEN>
<TOKEN end_char="79" id="token-0-12" morph="none" pos="word" start_char="74">doctor</TOKEN>
<TOKEN end_char="80" id="token-0-13" morph="none" pos="punct" start_char="80">?</TOKEN>
</SEG>
<SEG end_char="102" id="segment-1" start_char="82">
<ORIGINAL_TEXT>Belgian experts speak</ORIGINAL_TEXT>
<TOKEN end_char="88" id="token-1-0" morph="none" pos="word" start_char="82">Belgian</TOKEN>
<TOKEN end_char="96" id="token-1-1" morph="none" pos="word" start_char="90">experts</TOKEN>
<TOKEN end_char="102" id="token-1-2" morph="none" pos="word" start_char="98">speak</TOKEN>
<TRANSLATED_TEXT>Belgische deskundigen spreken</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="161" id="segment-2" start_char="107">
<ORIGINAL_TEXT>Marc Van Ranst and Geert Meyfroidt warned the Belgians.</ORIGINAL_TEXT>
<TOKEN end_char="110" id="token-2-0" morph="none" pos="word" start_char="107">Marc</TOKEN>
<TOKEN end_char="114" id="token-2-1" morph="none" pos="word" start_char="112">Van</TOKEN>
<TOKEN end_char="120" id="token-2-2" morph="none" pos="word" start_char="116">Ranst</TOKEN>
<TOKEN end_char="124" id="token-2-3" morph="none" pos="word" start_char="122">and</TOKEN>
<TOKEN end_char="130" id="token-2-4" morph="none" pos="word" start_char="126">Geert</TOKEN>
<TOKEN end_char="140" id="token-2-5" morph="none" pos="word" start_char="132">Meyfroidt</TOKEN>
<TOKEN end_char="147" id="token-2-6" morph="none" pos="word" start_char="142">warned</TOKEN>
<TOKEN end_char="151" id="token-2-7" morph="none" pos="word" start_char="149">the</TOKEN>
<TOKEN end_char="160" id="token-2-8" morph="none" pos="word" start_char="153">Belgians</TOKEN>
<TOKEN end_char="161" id="token-2-9" morph="none" pos="punct" start_char="161">.</TOKEN>
</SEG>
<SEG end_char="204" id="segment-3" start_char="165">
<ORIGINAL_TEXT>"The virus no longer exists clinically".</ORIGINAL_TEXT>
<TOKEN end_char="165" id="token-3-0" morph="none" pos="punct" start_char="165">"</TOKEN>
<TOKEN end_char="168" id="token-3-1" morph="none" pos="word" start_char="166">The</TOKEN>
<TOKEN end_char="174" id="token-3-2" morph="none" pos="word" start_char="170">virus</TOKEN>
<TOKEN end_char="177" id="token-3-3" morph="none" pos="word" start_char="176">no</TOKEN>
<TOKEN end_char="184" id="token-3-4" morph="none" pos="word" start_char="179">longer</TOKEN>
<TOKEN end_char="191" id="token-3-5" morph="none" pos="word" start_char="186">exists</TOKEN>
<TOKEN end_char="202" id="token-3-6" morph="none" pos="word" start_char="193">clinically</TOKEN>
<TOKEN end_char="204" id="token-3-7" morph="none" pos="punct" start_char="203">".</TOKEN>
</SEG>
<SEG end_char="227" id="segment-4" start_char="206">
<ORIGINAL_TEXT>This was stated by Dr.</ORIGINAL_TEXT>
<TOKEN end_char="209" id="token-4-0" morph="none" pos="word" start_char="206">This</TOKEN>
<TOKEN end_char="213" id="token-4-1" morph="none" pos="word" start_char="211">was</TOKEN>
<TOKEN end_char="220" id="token-4-2" morph="none" pos="word" start_char="215">stated</TOKEN>
<TOKEN end_char="223" id="token-4-3" morph="none" pos="word" start_char="222">by</TOKEN>
<TOKEN end_char="226" id="token-4-4" morph="none" pos="word" start_char="225">Dr</TOKEN>
<TOKEN end_char="227" id="token-4-5" morph="none" pos="punct" start_char="227">.</TOKEN>
</SEG>
<SEG end_char="314" id="segment-5" start_char="229">
<ORIGINAL_TEXT>Albert Zangrillo, director of the San Raffaele hospital in Milan, this Monday, June 1.</ORIGINAL_TEXT>
<TOKEN end_char="234" id="token-5-0" morph="none" pos="word" start_char="229">Albert</TOKEN>
<TOKEN end_char="244" id="token-5-1" morph="none" pos="word" start_char="236">Zangrillo</TOKEN>
<TOKEN end_char="245" id="token-5-2" morph="none" pos="punct" start_char="245">,</TOKEN>
<TOKEN end_char="254" id="token-5-3" morph="none" pos="word" start_char="247">director</TOKEN>
<TOKEN end_char="257" id="token-5-4" morph="none" pos="word" start_char="256">of</TOKEN>
<TOKEN end_char="261" id="token-5-5" morph="none" pos="word" start_char="259">the</TOKEN>
<TOKEN end_char="265" id="token-5-6" morph="none" pos="word" start_char="263">San</TOKEN>
<TOKEN end_char="274" id="token-5-7" morph="none" pos="word" start_char="267">Raffaele</TOKEN>
<TOKEN end_char="283" id="token-5-8" morph="none" pos="word" start_char="276">hospital</TOKEN>
<TOKEN end_char="286" id="token-5-9" morph="none" pos="word" start_char="285">in</TOKEN>
<TOKEN end_char="292" id="token-5-10" morph="none" pos="word" start_char="288">Milan</TOKEN>
<TOKEN end_char="293" id="token-5-11" morph="none" pos="punct" start_char="293">,</TOKEN>
<TOKEN end_char="298" id="token-5-12" morph="none" pos="word" start_char="295">this</TOKEN>
<TOKEN end_char="305" id="token-5-13" morph="none" pos="word" start_char="300">Monday</TOKEN>
<TOKEN end_char="306" id="token-5-14" morph="none" pos="punct" start_char="306">,</TOKEN>
<TOKEN end_char="311" id="token-5-15" morph="none" pos="word" start_char="308">June</TOKEN>
<TOKEN end_char="313" id="token-5-16" morph="none" pos="word" start_char="313">1</TOKEN>
<TOKEN end_char="314" id="token-5-17" morph="none" pos="punct" start_char="314">.</TOKEN>
</SEG>
<SEG end_char="447" id="segment-6" start_char="316">
<ORIGINAL_TEXT>Comments emphasizing that the strength of the virus would have considerably weakened which were just as quickly reframed by the WHO.</ORIGINAL_TEXT>
<TOKEN end_char="323" id="token-6-0" morph="none" pos="word" start_char="316">Comments</TOKEN>
<TOKEN end_char="335" id="token-6-1" morph="none" pos="word" start_char="325">emphasizing</TOKEN>
<TOKEN end_char="340" id="token-6-2" morph="none" pos="word" start_char="337">that</TOKEN>
<TOKEN end_char="344" id="token-6-3" morph="none" pos="word" start_char="342">the</TOKEN>
<TOKEN end_char="353" id="token-6-4" morph="none" pos="word" start_char="346">strength</TOKEN>
<TOKEN end_char="356" id="token-6-5" morph="none" pos="word" start_char="355">of</TOKEN>
<TOKEN end_char="360" id="token-6-6" morph="none" pos="word" start_char="358">the</TOKEN>
<TOKEN end_char="366" id="token-6-7" morph="none" pos="word" start_char="362">virus</TOKEN>
<TOKEN end_char="372" id="token-6-8" morph="none" pos="word" start_char="368">would</TOKEN>
<TOKEN end_char="377" id="token-6-9" morph="none" pos="word" start_char="374">have</TOKEN>
<TOKEN end_char="390" id="token-6-10" morph="none" pos="word" start_char="379">considerably</TOKEN>
<TOKEN end_char="399" id="token-6-11" morph="none" pos="word" start_char="392">weakened</TOKEN>
<TOKEN end_char="405" id="token-6-12" morph="none" pos="word" start_char="401">which</TOKEN>
<TOKEN end_char="410" id="token-6-13" morph="none" pos="word" start_char="407">were</TOKEN>
<TOKEN end_char="415" id="token-6-14" morph="none" pos="word" start_char="412">just</TOKEN>
<TOKEN end_char="418" id="token-6-15" morph="none" pos="word" start_char="417">as</TOKEN>
<TOKEN end_char="426" id="token-6-16" morph="none" pos="word" start_char="420">quickly</TOKEN>
<TOKEN end_char="435" id="token-6-17" morph="none" pos="word" start_char="428">reframed</TOKEN>
<TOKEN end_char="438" id="token-6-18" morph="none" pos="word" start_char="437">by</TOKEN>
<TOKEN end_char="442" id="token-6-19" morph="none" pos="word" start_char="440">the</TOKEN>
<TOKEN end_char="446" id="token-6-20" morph="none" pos="word" start_char="444">WHO</TOKEN>
<TOKEN end_char="447" id="token-6-21" morph="none" pos="punct" start_char="447">.</TOKEN>
</SEG>
<SEG end_char="493" id="segment-7" start_char="449">
<ORIGINAL_TEXT>The agency pointed to a misleading statement.</ORIGINAL_TEXT>
<TOKEN end_char="451" id="token-7-0" morph="none" pos="word" start_char="449">The</TOKEN>
<TOKEN end_char="458" id="token-7-1" morph="none" pos="word" start_char="453">agency</TOKEN>
<TOKEN end_char="466" id="token-7-2" morph="none" pos="word" start_char="460">pointed</TOKEN>
<TOKEN end_char="469" id="token-7-3" morph="none" pos="word" start_char="468">to</TOKEN>
<TOKEN end_char="471" id="token-7-4" morph="none" pos="word" start_char="471">a</TOKEN>
<TOKEN end_char="482" id="token-7-5" morph="none" pos="word" start_char="473">misleading</TOKEN>
<TOKEN end_char="492" id="token-7-6" morph="none" pos="word" start_char="484">statement</TOKEN>
<TOKEN end_char="493" id="token-7-7" morph="none" pos="punct" start_char="493">.</TOKEN>
</SEG>
<SEG end_char="711" id="segment-8" start_char="495">
<ORIGINAL_TEXT>"We must be exceptionally careful not to give the impression that suddenly the virus, by its own free will, has decided to become less pathogenic, responded Michael Ryan, head of the emergency response program at WHO.</ORIGINAL_TEXT>
<TOKEN end_char="495" id="token-8-0" morph="none" pos="punct" start_char="495">"</TOKEN>
<TOKEN end_char="497" id="token-8-1" morph="none" pos="word" start_char="496">We</TOKEN>
<TOKEN end_char="502" id="token-8-2" morph="none" pos="word" start_char="499">must</TOKEN>
<TOKEN end_char="505" id="token-8-3" morph="none" pos="word" start_char="504">be</TOKEN>
<TOKEN end_char="519" id="token-8-4" morph="none" pos="word" start_char="507">exceptionally</TOKEN>
<TOKEN end_char="527" id="token-8-5" morph="none" pos="word" start_char="521">careful</TOKEN>
<TOKEN end_char="531" id="token-8-6" morph="none" pos="word" start_char="529">not</TOKEN>
<TOKEN end_char="534" id="token-8-7" morph="none" pos="word" start_char="533">to</TOKEN>
<TOKEN end_char="539" id="token-8-8" morph="none" pos="word" start_char="536">give</TOKEN>
<TOKEN end_char="543" id="token-8-9" morph="none" pos="word" start_char="541">the</TOKEN>
<TOKEN end_char="554" id="token-8-10" morph="none" pos="word" start_char="545">impression</TOKEN>
<TOKEN end_char="559" id="token-8-11" morph="none" pos="word" start_char="556">that</TOKEN>
<TOKEN end_char="568" id="token-8-12" morph="none" pos="word" start_char="561">suddenly</TOKEN>
<TOKEN end_char="572" id="token-8-13" morph="none" pos="word" start_char="570">the</TOKEN>
<TOKEN end_char="578" id="token-8-14" morph="none" pos="word" start_char="574">virus</TOKEN>
<TOKEN end_char="579" id="token-8-15" morph="none" pos="punct" start_char="579">,</TOKEN>
<TOKEN end_char="582" id="token-8-16" morph="none" pos="word" start_char="581">by</TOKEN>
<TOKEN end_char="586" id="token-8-17" morph="none" pos="word" start_char="584">its</TOKEN>
<TOKEN end_char="590" id="token-8-18" morph="none" pos="word" start_char="588">own</TOKEN>
<TOKEN end_char="595" id="token-8-19" morph="none" pos="word" start_char="592">free</TOKEN>
<TOKEN end_char="600" id="token-8-20" morph="none" pos="word" start_char="597">will</TOKEN>
<TOKEN end_char="601" id="token-8-21" morph="none" pos="punct" start_char="601">,</TOKEN>
<TOKEN end_char="605" id="token-8-22" morph="none" pos="word" start_char="603">has</TOKEN>
<TOKEN end_char="613" id="token-8-23" morph="none" pos="word" start_char="607">decided</TOKEN>
<TOKEN end_char="616" id="token-8-24" morph="none" pos="word" start_char="615">to</TOKEN>
<TOKEN end_char="623" id="token-8-25" morph="none" pos="word" start_char="618">become</TOKEN>
<TOKEN end_char="628" id="token-8-26" morph="none" pos="word" start_char="625">less</TOKEN>
<TOKEN end_char="639" id="token-8-27" morph="none" pos="word" start_char="630">pathogenic</TOKEN>
<TOKEN end_char="640" id="token-8-28" morph="none" pos="punct" start_char="640">,</TOKEN>
<TOKEN end_char="650" id="token-8-29" morph="none" pos="word" start_char="642">responded</TOKEN>
<TOKEN end_char="658" id="token-8-30" morph="none" pos="word" start_char="652">Michael</TOKEN>
<TOKEN end_char="663" id="token-8-31" morph="none" pos="word" start_char="660">Ryan</TOKEN>
<TOKEN end_char="664" id="token-8-32" morph="none" pos="punct" start_char="664">,</TOKEN>
<TOKEN end_char="669" id="token-8-33" morph="none" pos="word" start_char="666">head</TOKEN>
<TOKEN end_char="672" id="token-8-34" morph="none" pos="word" start_char="671">of</TOKEN>
<TOKEN end_char="676" id="token-8-35" morph="none" pos="word" start_char="674">the</TOKEN>
<TOKEN end_char="686" id="token-8-36" morph="none" pos="word" start_char="678">emergency</TOKEN>
<TOKEN end_char="695" id="token-8-37" morph="none" pos="word" start_char="688">response</TOKEN>
<TOKEN end_char="703" id="token-8-38" morph="none" pos="word" start_char="697">program</TOKEN>
<TOKEN end_char="706" id="token-8-39" morph="none" pos="word" start_char="705">at</TOKEN>
<TOKEN end_char="710" id="token-8-40" morph="none" pos="word" start_char="708">WHO</TOKEN>
<TOKEN end_char="711" id="token-8-41" morph="none" pos="punct" start_char="711">.</TOKEN>
</SEG>
<SEG end_char="739" id="segment-9" start_char="713">
<ORIGINAL_TEXT>It is not the case at all."</ORIGINAL_TEXT>
<TOKEN end_char="714" id="token-9-0" morph="none" pos="word" start_char="713">It</TOKEN>
<TOKEN end_char="717" id="token-9-1" morph="none" pos="word" start_char="716">is</TOKEN>
<TOKEN end_char="721" id="token-9-2" morph="none" pos="word" start_char="719">not</TOKEN>
<TOKEN end_char="725" id="token-9-3" morph="none" pos="word" start_char="723">the</TOKEN>
<TOKEN end_char="730" id="token-9-4" morph="none" pos="word" start_char="727">case</TOKEN>
<TOKEN end_char="733" id="token-9-5" morph="none" pos="word" start_char="732">at</TOKEN>
<TOKEN end_char="737" id="token-9-6" morph="none" pos="word" start_char="735">all</TOKEN>
<TOKEN end_char="739" id="token-9-7" morph="none" pos="punct" start_char="738">."</TOKEN>
</SEG>
<SEG end_char="751" id="segment-10" start_char="742">
<ORIGINAL_TEXT>"No proof"</ORIGINAL_TEXT>
<TOKEN end_char="742" id="token-10-0" morph="none" pos="punct" start_char="742">"</TOKEN>
<TOKEN end_char="744" id="token-10-1" morph="none" pos="word" start_char="743">No</TOKEN>
<TOKEN end_char="750" id="token-10-2" morph="none" pos="word" start_char="746">proof</TOKEN>
<TOKEN end_char="751" id="token-10-3" morph="none" pos="punct" start_char="751">"</TOKEN>
</SEG>
<SEG end_char="951" id="segment-11" start_char="755">
<ORIGINAL_TEXT>While in Belgium the trend is optimistic in view of the fairly low figures from the latest epidemiological reports, the experts also wished to remain cautious regarding the Italian doctor’s claims.</ORIGINAL_TEXT>
<TOKEN end_char="759" id="token-11-0" morph="none" pos="word" start_char="755">While</TOKEN>
<TOKEN end_char="762" id="token-11-1" morph="none" pos="word" start_char="761">in</TOKEN>
<TOKEN end_char="770" id="token-11-2" morph="none" pos="word" start_char="764">Belgium</TOKEN>
<TOKEN end_char="774" id="token-11-3" morph="none" pos="word" start_char="772">the</TOKEN>
<TOKEN end_char="780" id="token-11-4" morph="none" pos="word" start_char="776">trend</TOKEN>
<TOKEN end_char="783" id="token-11-5" morph="none" pos="word" start_char="782">is</TOKEN>
<TOKEN end_char="794" id="token-11-6" morph="none" pos="word" start_char="785">optimistic</TOKEN>
<TOKEN end_char="797" id="token-11-7" morph="none" pos="word" start_char="796">in</TOKEN>
<TOKEN end_char="802" id="token-11-8" morph="none" pos="word" start_char="799">view</TOKEN>
<TOKEN end_char="805" id="token-11-9" morph="none" pos="word" start_char="804">of</TOKEN>
<TOKEN end_char="809" id="token-11-10" morph="none" pos="word" start_char="807">the</TOKEN>
<TOKEN end_char="816" id="token-11-11" morph="none" pos="word" start_char="811">fairly</TOKEN>
<TOKEN end_char="820" id="token-11-12" morph="none" pos="word" start_char="818">low</TOKEN>
<TOKEN end_char="828" id="token-11-13" morph="none" pos="word" start_char="822">figures</TOKEN>
<TOKEN end_char="833" id="token-11-14" morph="none" pos="word" start_char="830">from</TOKEN>
<TOKEN end_char="837" id="token-11-15" morph="none" pos="word" start_char="835">the</TOKEN>
<TOKEN end_char="844" id="token-11-16" morph="none" pos="word" start_char="839">latest</TOKEN>
<TOKEN end_char="860" id="token-11-17" morph="none" pos="word" start_char="846">epidemiological</TOKEN>
<TOKEN end_char="868" id="token-11-18" morph="none" pos="word" start_char="862">reports</TOKEN>
<TOKEN end_char="869" id="token-11-19" morph="none" pos="punct" start_char="869">,</TOKEN>
<TOKEN end_char="873" id="token-11-20" morph="none" pos="word" start_char="871">the</TOKEN>
<TOKEN end_char="881" id="token-11-21" morph="none" pos="word" start_char="875">experts</TOKEN>
<TOKEN end_char="886" id="token-11-22" morph="none" pos="word" start_char="883">also</TOKEN>
<TOKEN end_char="893" id="token-11-23" morph="none" pos="word" start_char="888">wished</TOKEN>
<TOKEN end_char="896" id="token-11-24" morph="none" pos="word" start_char="895">to</TOKEN>
<TOKEN end_char="903" id="token-11-25" morph="none" pos="word" start_char="898">remain</TOKEN>
<TOKEN end_char="912" id="token-11-26" morph="none" pos="word" start_char="905">cautious</TOKEN>
<TOKEN end_char="922" id="token-11-27" morph="none" pos="word" start_char="914">regarding</TOKEN>
<TOKEN end_char="926" id="token-11-28" morph="none" pos="word" start_char="924">the</TOKEN>
<TOKEN end_char="934" id="token-11-29" morph="none" pos="word" start_char="928">Italian</TOKEN>
<TOKEN end_char="943" id="token-11-30" morph="none" pos="word" start_char="936">doctor’s</TOKEN>
<TOKEN end_char="950" id="token-11-31" morph="none" pos="word" start_char="945">claims</TOKEN>
<TOKEN end_char="951" id="token-11-32" morph="none" pos="punct" start_char="951">.</TOKEN>
</SEG>
<SEG end_char="1090" id="segment-12" start_char="953">
<ORIGINAL_TEXT>"There is no evidence that the coronavirus has weakened or become less contagious," warned specialists, interviewed by our colleagues from</ORIGINAL_TEXT>
<TOKEN end_char="953" id="token-12-0" morph="none" pos="punct" start_char="953">"</TOKEN>
<TOKEN end_char="958" id="token-12-1" morph="none" pos="word" start_char="954">There</TOKEN>
<TOKEN end_char="961" id="token-12-2" morph="none" pos="word" start_char="960">is</TOKEN>
<TOKEN end_char="964" id="token-12-3" morph="none" pos="word" start_char="963">no</TOKEN>
<TOKEN end_char="973" id="token-12-4" morph="none" pos="word" start_char="966">evidence</TOKEN>
<TOKEN end_char="978" id="token-12-5" morph="none" pos="word" start_char="975">that</TOKEN>
<TOKEN end_char="982" id="token-12-6" morph="none" pos="word" start_char="980">the</TOKEN>
<TOKEN end_char="994" id="token-12-7" morph="none" pos="word" start_char="984">coronavirus</TOKEN>
<TOKEN end_char="998" id="token-12-8" morph="none" pos="word" start_char="996">has</TOKEN>
<TOKEN end_char="1007" id="token-12-9" morph="none" pos="word" start_char="1000">weakened</TOKEN>
<TOKEN end_char="1010" id="token-12-10" morph="none" pos="word" start_char="1009">or</TOKEN>
<TOKEN end_char="1017" id="token-12-11" morph="none" pos="word" start_char="1012">become</TOKEN>
<TOKEN end_char="1022" id="token-12-12" morph="none" pos="word" start_char="1019">less</TOKEN>
<TOKEN end_char="1033" id="token-12-13" morph="none" pos="word" start_char="1024">contagious</TOKEN>
<TOKEN end_char="1035" id="token-12-14" morph="none" pos="punct" start_char="1034">,"</TOKEN>
<TOKEN end_char="1042" id="token-12-15" morph="none" pos="word" start_char="1037">warned</TOKEN>
<TOKEN end_char="1054" id="token-12-16" morph="none" pos="word" start_char="1044">specialists</TOKEN>
<TOKEN end_char="1055" id="token-12-17" morph="none" pos="punct" start_char="1055">,</TOKEN>
<TOKEN end_char="1067" id="token-12-18" morph="none" pos="word" start_char="1057">interviewed</TOKEN>
<TOKEN end_char="1070" id="token-12-19" morph="none" pos="word" start_char="1069">by</TOKEN>
<TOKEN end_char="1074" id="token-12-20" morph="none" pos="word" start_char="1072">our</TOKEN>
<TOKEN end_char="1085" id="token-12-21" morph="none" pos="word" start_char="1076">colleagues</TOKEN>
<TOKEN end_char="1090" id="token-12-22" morph="none" pos="word" start_char="1087">from</TOKEN>
</SEG>
<SEG end_char="1110" id="segment-13" start_char="1093">
<ORIGINAL_TEXT>Het Laatste Nieuws</ORIGINAL_TEXT>
<TOKEN end_char="1095" id="token-13-0" morph="none" pos="word" start_char="1093">Het</TOKEN>
<TOKEN end_char="1103" id="token-13-1" morph="none" pos="word" start_char="1097">Laatste</TOKEN>
<TOKEN end_char="1110" id="token-13-2" morph="none" pos="word" start_char="1105">Nieuws</TOKEN>
<TRANSLATED_TEXT>Latest News</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="1113" id="segment-14" start_char="1113">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1113" id="token-14-0" morph="none" pos="punct" start_char="1113">.</TOKEN>
</SEG>
<SEG end_char="1238" id="segment-15" start_char="1115">
<ORIGINAL_TEXT>Virologist Marc Van Ranst (KULeuven), for his part, recalled that one could always be as sick in the event of contamination.</ORIGINAL_TEXT>
<TOKEN end_char="1124" id="token-15-0" morph="none" pos="word" start_char="1115">Virologist</TOKEN>
<TOKEN end_char="1129" id="token-15-1" morph="none" pos="word" start_char="1126">Marc</TOKEN>
<TOKEN end_char="1133" id="token-15-2" morph="none" pos="word" start_char="1131">Van</TOKEN>
<TOKEN end_char="1139" id="token-15-3" morph="none" pos="word" start_char="1135">Ranst</TOKEN>
<TOKEN end_char="1141" id="token-15-4" morph="none" pos="punct" start_char="1141">(</TOKEN>
<TOKEN end_char="1149" id="token-15-5" morph="none" pos="word" start_char="1142">KULeuven</TOKEN>
<TOKEN end_char="1151" id="token-15-6" morph="none" pos="punct" start_char="1150">),</TOKEN>
<TOKEN end_char="1155" id="token-15-7" morph="none" pos="word" start_char="1153">for</TOKEN>
<TOKEN end_char="1159" id="token-15-8" morph="none" pos="word" start_char="1157">his</TOKEN>
<TOKEN end_char="1164" id="token-15-9" morph="none" pos="word" start_char="1161">part</TOKEN>
<TOKEN end_char="1165" id="token-15-10" morph="none" pos="punct" start_char="1165">,</TOKEN>
<TOKEN end_char="1174" id="token-15-11" morph="none" pos="word" start_char="1167">recalled</TOKEN>
<TOKEN end_char="1179" id="token-15-12" morph="none" pos="word" start_char="1176">that</TOKEN>
<TOKEN end_char="1183" id="token-15-13" morph="none" pos="word" start_char="1181">one</TOKEN>
<TOKEN end_char="1189" id="token-15-14" morph="none" pos="word" start_char="1185">could</TOKEN>
<TOKEN end_char="1196" id="token-15-15" morph="none" pos="word" start_char="1191">always</TOKEN>
<TOKEN end_char="1199" id="token-15-16" morph="none" pos="word" start_char="1198">be</TOKEN>
<TOKEN end_char="1202" id="token-15-17" morph="none" pos="word" start_char="1201">as</TOKEN>
<TOKEN end_char="1207" id="token-15-18" morph="none" pos="word" start_char="1204">sick</TOKEN>
<TOKEN end_char="1210" id="token-15-19" morph="none" pos="word" start_char="1209">in</TOKEN>
<TOKEN end_char="1214" id="token-15-20" morph="none" pos="word" start_char="1212">the</TOKEN>
<TOKEN end_char="1220" id="token-15-21" morph="none" pos="word" start_char="1216">event</TOKEN>
<TOKEN end_char="1223" id="token-15-22" morph="none" pos="word" start_char="1222">of</TOKEN>
<TOKEN end_char="1237" id="token-15-23" morph="none" pos="word" start_char="1225">contamination</TOKEN>
<TOKEN end_char="1238" id="token-15-24" morph="none" pos="punct" start_char="1238">.</TOKEN>
</SEG>
<SEG end_char="1422" id="segment-16" start_char="1240">
<ORIGINAL_TEXT>"People have the impression that a virus does less damage at the beginning or at the end of the epidemic, because there are fewer people affected, noted the expert member of the GEES.</ORIGINAL_TEXT>
<TOKEN end_char="1240" id="token-16-0" morph="none" pos="punct" start_char="1240">"</TOKEN>
<TOKEN end_char="1246" id="token-16-1" morph="none" pos="word" start_char="1241">People</TOKEN>
<TOKEN end_char="1251" id="token-16-2" morph="none" pos="word" start_char="1248">have</TOKEN>
<TOKEN end_char="1255" id="token-16-3" morph="none" pos="word" start_char="1253">the</TOKEN>
<TOKEN end_char="1266" id="token-16-4" morph="none" pos="word" start_char="1257">impression</TOKEN>
<TOKEN end_char="1271" id="token-16-5" morph="none" pos="word" start_char="1268">that</TOKEN>
<TOKEN end_char="1273" id="token-16-6" morph="none" pos="word" start_char="1273">a</TOKEN>
<TOKEN end_char="1279" id="token-16-7" morph="none" pos="word" start_char="1275">virus</TOKEN>
<TOKEN end_char="1284" id="token-16-8" morph="none" pos="word" start_char="1281">does</TOKEN>
<TOKEN end_char="1289" id="token-16-9" morph="none" pos="word" start_char="1286">less</TOKEN>
<TOKEN end_char="1296" id="token-16-10" morph="none" pos="word" start_char="1291">damage</TOKEN>
<TOKEN end_char="1299" id="token-16-11" morph="none" pos="word" start_char="1298">at</TOKEN>
<TOKEN end_char="1303" id="token-16-12" morph="none" pos="word" start_char="1301">the</TOKEN>
<TOKEN end_char="1313" id="token-16-13" morph="none" pos="word" start_char="1305">beginning</TOKEN>
<TOKEN end_char="1316" id="token-16-14" morph="none" pos="word" start_char="1315">or</TOKEN>
<TOKEN end_char="1319" id="token-16-15" morph="none" pos="word" start_char="1318">at</TOKEN>
<TOKEN end_char="1323" id="token-16-16" morph="none" pos="word" start_char="1321">the</TOKEN>
<TOKEN end_char="1327" id="token-16-17" morph="none" pos="word" start_char="1325">end</TOKEN>
<TOKEN end_char="1330" id="token-16-18" morph="none" pos="word" start_char="1329">of</TOKEN>
<TOKEN end_char="1334" id="token-16-19" morph="none" pos="word" start_char="1332">the</TOKEN>
<TOKEN end_char="1343" id="token-16-20" morph="none" pos="word" start_char="1336">epidemic</TOKEN>
<TOKEN end_char="1344" id="token-16-21" morph="none" pos="punct" start_char="1344">,</TOKEN>
<TOKEN end_char="1352" id="token-16-22" morph="none" pos="word" start_char="1346">because</TOKEN>
<TOKEN end_char="1358" id="token-16-23" morph="none" pos="word" start_char="1354">there</TOKEN>
<TOKEN end_char="1362" id="token-16-24" morph="none" pos="word" start_char="1360">are</TOKEN>
<TOKEN end_char="1368" id="token-16-25" morph="none" pos="word" start_char="1364">fewer</TOKEN>
<TOKEN end_char="1375" id="token-16-26" morph="none" pos="word" start_char="1370">people</TOKEN>
<TOKEN end_char="1384" id="token-16-27" morph="none" pos="word" start_char="1377">affected</TOKEN>
<TOKEN end_char="1385" id="token-16-28" morph="none" pos="punct" start_char="1385">,</TOKEN>
<TOKEN end_char="1391" id="token-16-29" morph="none" pos="word" start_char="1387">noted</TOKEN>
<TOKEN end_char="1395" id="token-16-30" morph="none" pos="word" start_char="1393">the</TOKEN>
<TOKEN end_char="1402" id="token-16-31" morph="none" pos="word" start_char="1397">expert</TOKEN>
<TOKEN end_char="1409" id="token-16-32" morph="none" pos="word" start_char="1404">member</TOKEN>
<TOKEN end_char="1412" id="token-16-33" morph="none" pos="word" start_char="1411">of</TOKEN>
<TOKEN end_char="1416" id="token-16-34" morph="none" pos="word" start_char="1414">the</TOKEN>
<TOKEN end_char="1421" id="token-16-35" morph="none" pos="word" start_char="1418">GEES</TOKEN>
<TOKEN end_char="1422" id="token-16-36" morph="none" pos="punct" start_char="1422">.</TOKEN>
</SEG>
<SEG end_char="1511" id="segment-17" start_char="1424">
<ORIGINAL_TEXT>But whether you are infected at start or end of the pandemic, you will always be sick. "</ORIGINAL_TEXT>
<TOKEN end_char="1426" id="token-17-0" morph="none" pos="word" start_char="1424">But</TOKEN>
<TOKEN end_char="1434" id="token-17-1" morph="none" pos="word" start_char="1428">whether</TOKEN>
<TOKEN end_char="1438" id="token-17-2" morph="none" pos="word" start_char="1436">you</TOKEN>
<TOKEN end_char="1442" id="token-17-3" morph="none" pos="word" start_char="1440">are</TOKEN>
<TOKEN end_char="1451" id="token-17-4" morph="none" pos="word" start_char="1444">infected</TOKEN>
<TOKEN end_char="1454" id="token-17-5" morph="none" pos="word" start_char="1453">at</TOKEN>
<TOKEN end_char="1460" id="token-17-6" morph="none" pos="word" start_char="1456">start</TOKEN>
<TOKEN end_char="1463" id="token-17-7" morph="none" pos="word" start_char="1462">or</TOKEN>
<TOKEN end_char="1467" id="token-17-8" morph="none" pos="word" start_char="1465">end</TOKEN>
<TOKEN end_char="1470" id="token-17-9" morph="none" pos="word" start_char="1469">of</TOKEN>
<TOKEN end_char="1474" id="token-17-10" morph="none" pos="word" start_char="1472">the</TOKEN>
<TOKEN end_char="1483" id="token-17-11" morph="none" pos="word" start_char="1476">pandemic</TOKEN>
<TOKEN end_char="1484" id="token-17-12" morph="none" pos="punct" start_char="1484">,</TOKEN>
<TOKEN end_char="1488" id="token-17-13" morph="none" pos="word" start_char="1486">you</TOKEN>
<TOKEN end_char="1493" id="token-17-14" morph="none" pos="word" start_char="1490">will</TOKEN>
<TOKEN end_char="1500" id="token-17-15" morph="none" pos="word" start_char="1495">always</TOKEN>
<TOKEN end_char="1503" id="token-17-16" morph="none" pos="word" start_char="1502">be</TOKEN>
<TOKEN end_char="1508" id="token-17-17" morph="none" pos="word" start_char="1505">sick</TOKEN>
<TOKEN end_char="1509" id="token-17-18" morph="none" pos="punct" start_char="1509">.</TOKEN>
<TOKEN end_char="1511" id="token-17-19" morph="none" pos="punct" start_char="1511">"</TOKEN>
</SEG>
<SEG end_char="1605" id="segment-18" start_char="1514">
<ORIGINAL_TEXT>Same story with Geert Meyfroidt, president of the Belgian Association of Intensive Medicine.</ORIGINAL_TEXT>
<TOKEN end_char="1517" id="token-18-0" morph="none" pos="word" start_char="1514">Same</TOKEN>
<TOKEN end_char="1523" id="token-18-1" morph="none" pos="word" start_char="1519">story</TOKEN>
<TOKEN end_char="1528" id="token-18-2" morph="none" pos="word" start_char="1525">with</TOKEN>
<TOKEN end_char="1534" id="token-18-3" morph="none" pos="word" start_char="1530">Geert</TOKEN>
<TOKEN end_char="1544" id="token-18-4" morph="none" pos="word" start_char="1536">Meyfroidt</TOKEN>
<TOKEN end_char="1545" id="token-18-5" morph="none" pos="punct" start_char="1545">,</TOKEN>
<TOKEN end_char="1555" id="token-18-6" morph="none" pos="word" start_char="1547">president</TOKEN>
<TOKEN end_char="1558" id="token-18-7" morph="none" pos="word" start_char="1557">of</TOKEN>
<TOKEN end_char="1562" id="token-18-8" morph="none" pos="word" start_char="1560">the</TOKEN>
<TOKEN end_char="1570" id="token-18-9" morph="none" pos="word" start_char="1564">Belgian</TOKEN>
<TOKEN end_char="1582" id="token-18-10" morph="none" pos="word" start_char="1572">Association</TOKEN>
<TOKEN end_char="1585" id="token-18-11" morph="none" pos="word" start_char="1584">of</TOKEN>
<TOKEN end_char="1595" id="token-18-12" morph="none" pos="word" start_char="1587">Intensive</TOKEN>
<TOKEN end_char="1604" id="token-18-13" morph="none" pos="word" start_char="1597">Medicine</TOKEN>
<TOKEN end_char="1605" id="token-18-14" morph="none" pos="punct" start_char="1605">.</TOKEN>
</SEG>
<SEG end_char="1718" id="segment-19" start_char="1607">
<ORIGINAL_TEXT>"We will reach the end of the epidemic when no new infection has been registered for at least a month," he said.</ORIGINAL_TEXT>
<TOKEN end_char="1607" id="token-19-0" morph="none" pos="punct" start_char="1607">"</TOKEN>
<TOKEN end_char="1609" id="token-19-1" morph="none" pos="word" start_char="1608">We</TOKEN>
<TOKEN end_char="1614" id="token-19-2" morph="none" pos="word" start_char="1611">will</TOKEN>
<TOKEN end_char="1620" id="token-19-3" morph="none" pos="word" start_char="1616">reach</TOKEN>
<TOKEN end_char="1624" id="token-19-4" morph="none" pos="word" start_char="1622">the</TOKEN>
<TOKEN end_char="1628" id="token-19-5" morph="none" pos="word" start_char="1626">end</TOKEN>
<TOKEN end_char="1631" id="token-19-6" morph="none" pos="word" start_char="1630">of</TOKEN>
<TOKEN end_char="1635" id="token-19-7" morph="none" pos="word" start_char="1633">the</TOKEN>
<TOKEN end_char="1644" id="token-19-8" morph="none" pos="word" start_char="1637">epidemic</TOKEN>
<TOKEN end_char="1649" id="token-19-9" morph="none" pos="word" start_char="1646">when</TOKEN>
<TOKEN end_char="1652" id="token-19-10" morph="none" pos="word" start_char="1651">no</TOKEN>
<TOKEN end_char="1656" id="token-19-11" morph="none" pos="word" start_char="1654">new</TOKEN>
<TOKEN end_char="1666" id="token-19-12" morph="none" pos="word" start_char="1658">infection</TOKEN>
<TOKEN end_char="1670" id="token-19-13" morph="none" pos="word" start_char="1668">has</TOKEN>
<TOKEN end_char="1675" id="token-19-14" morph="none" pos="word" start_char="1672">been</TOKEN>
<TOKEN end_char="1686" id="token-19-15" morph="none" pos="word" start_char="1677">registered</TOKEN>
<TOKEN end_char="1690" id="token-19-16" morph="none" pos="word" start_char="1688">for</TOKEN>
<TOKEN end_char="1693" id="token-19-17" morph="none" pos="word" start_char="1692">at</TOKEN>
<TOKEN end_char="1699" id="token-19-18" morph="none" pos="word" start_char="1695">least</TOKEN>
<TOKEN end_char="1701" id="token-19-19" morph="none" pos="word" start_char="1701">a</TOKEN>
<TOKEN end_char="1707" id="token-19-20" morph="none" pos="word" start_char="1703">month</TOKEN>
<TOKEN end_char="1709" id="token-19-21" morph="none" pos="punct" start_char="1708">,"</TOKEN>
<TOKEN end_char="1712" id="token-19-22" morph="none" pos="word" start_char="1711">he</TOKEN>
<TOKEN end_char="1717" id="token-19-23" morph="none" pos="word" start_char="1714">said</TOKEN>
<TOKEN end_char="1718" id="token-19-24" morph="none" pos="punct" start_char="1718">.</TOKEN>
</SEG>
<SEG end_char="1738" id="segment-20" start_char="1721">
<ORIGINAL_TEXT>Het Laatste Nieuws</ORIGINAL_TEXT>
<TOKEN end_char="1723" id="token-20-0" morph="none" pos="word" start_char="1721">Het</TOKEN>
<TOKEN end_char="1731" id="token-20-1" morph="none" pos="word" start_char="1725">Laatste</TOKEN>
<TOKEN end_char="1738" id="token-20-2" morph="none" pos="word" start_char="1733">Nieuws</TOKEN>
<TRANSLATED_TEXT>Latest News</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="1741" id="segment-21" start_char="1741">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1741" id="token-21-0" morph="none" pos="punct" start_char="1741">.</TOKEN>
</SEG>
<SEG end_char="1770" id="segment-22" start_char="1743">
<ORIGINAL_TEXT>We are not there yet at all.</ORIGINAL_TEXT>
<TOKEN end_char="1744" id="token-22-0" morph="none" pos="word" start_char="1743">We</TOKEN>
<TOKEN end_char="1748" id="token-22-1" morph="none" pos="word" start_char="1746">are</TOKEN>
<TOKEN end_char="1752" id="token-22-2" morph="none" pos="word" start_char="1750">not</TOKEN>
<TOKEN end_char="1758" id="token-22-3" morph="none" pos="word" start_char="1754">there</TOKEN>
<TOKEN end_char="1762" id="token-22-4" morph="none" pos="word" start_char="1760">yet</TOKEN>
<TOKEN end_char="1765" id="token-22-5" morph="none" pos="word" start_char="1764">at</TOKEN>
<TOKEN end_char="1769" id="token-22-6" morph="none" pos="word" start_char="1767">all</TOKEN>
<TOKEN end_char="1770" id="token-22-7" morph="none" pos="punct" start_char="1770">.</TOKEN>
</SEG>
<SEG end_char="1948" id="segment-23" start_char="1772">
<ORIGINAL_TEXT>There are now no more new patients entering intensive care, but if you look at the percentages there are still as many people who fall seriously ill as those who are less ill. "</ORIGINAL_TEXT>
<TOKEN end_char="1776" id="token-23-0" morph="none" pos="word" start_char="1772">There</TOKEN>
<TOKEN end_char="1780" id="token-23-1" morph="none" pos="word" start_char="1778">are</TOKEN>
<TOKEN end_char="1784" id="token-23-2" morph="none" pos="word" start_char="1782">now</TOKEN>
<TOKEN end_char="1787" id="token-23-3" morph="none" pos="word" start_char="1786">no</TOKEN>
<TOKEN end_char="1792" id="token-23-4" morph="none" pos="word" start_char="1789">more</TOKEN>
<TOKEN end_char="1796" id="token-23-5" morph="none" pos="word" start_char="1794">new</TOKEN>
<TOKEN end_char="1805" id="token-23-6" morph="none" pos="word" start_char="1798">patients</TOKEN>
<TOKEN end_char="1814" id="token-23-7" morph="none" pos="word" start_char="1807">entering</TOKEN>
<TOKEN end_char="1824" id="token-23-8" morph="none" pos="word" start_char="1816">intensive</TOKEN>
<TOKEN end_char="1829" id="token-23-9" morph="none" pos="word" start_char="1826">care</TOKEN>
<TOKEN end_char="1830" id="token-23-10" morph="none" pos="punct" start_char="1830">,</TOKEN>
<TOKEN end_char="1834" id="token-23-11" morph="none" pos="word" start_char="1832">but</TOKEN>
<TOKEN end_char="1837" id="token-23-12" morph="none" pos="word" start_char="1836">if</TOKEN>
<TOKEN end_char="1841" id="token-23-13" morph="none" pos="word" start_char="1839">you</TOKEN>
<TOKEN end_char="1846" id="token-23-14" morph="none" pos="word" start_char="1843">look</TOKEN>
<TOKEN end_char="1849" id="token-23-15" morph="none" pos="word" start_char="1848">at</TOKEN>
<TOKEN end_char="1853" id="token-23-16" morph="none" pos="word" start_char="1851">the</TOKEN>
<TOKEN end_char="1865" id="token-23-17" morph="none" pos="word" start_char="1855">percentages</TOKEN>
<TOKEN end_char="1871" id="token-23-18" morph="none" pos="word" start_char="1867">there</TOKEN>
<TOKEN end_char="1875" id="token-23-19" morph="none" pos="word" start_char="1873">are</TOKEN>
<TOKEN end_char="1881" id="token-23-20" morph="none" pos="word" start_char="1877">still</TOKEN>
<TOKEN end_char="1884" id="token-23-21" morph="none" pos="word" start_char="1883">as</TOKEN>
<TOKEN end_char="1889" id="token-23-22" morph="none" pos="word" start_char="1886">many</TOKEN>
<TOKEN end_char="1896" id="token-23-23" morph="none" pos="word" start_char="1891">people</TOKEN>
<TOKEN end_char="1900" id="token-23-24" morph="none" pos="word" start_char="1898">who</TOKEN>
<TOKEN end_char="1905" id="token-23-25" morph="none" pos="word" start_char="1902">fall</TOKEN>
<TOKEN end_char="1915" id="token-23-26" morph="none" pos="word" start_char="1907">seriously</TOKEN>
<TOKEN end_char="1919" id="token-23-27" morph="none" pos="word" start_char="1917">ill</TOKEN>
<TOKEN end_char="1922" id="token-23-28" morph="none" pos="word" start_char="1921">as</TOKEN>
<TOKEN end_char="1928" id="token-23-29" morph="none" pos="word" start_char="1924">those</TOKEN>
<TOKEN end_char="1932" id="token-23-30" morph="none" pos="word" start_char="1930">who</TOKEN>
<TOKEN end_char="1936" id="token-23-31" morph="none" pos="word" start_char="1934">are</TOKEN>
<TOKEN end_char="1941" id="token-23-32" morph="none" pos="word" start_char="1938">less</TOKEN>
<TOKEN end_char="1945" id="token-23-33" morph="none" pos="word" start_char="1943">ill</TOKEN>
<TOKEN end_char="1946" id="token-23-34" morph="none" pos="punct" start_char="1946">.</TOKEN>
<TOKEN end_char="1948" id="token-23-35" morph="none" pos="punct" start_char="1948">"</TOKEN>
</SEG>
<SEG end_char="1962" id="segment-24" start_char="1951">
<ORIGINAL_TEXT>Like a pizza</ORIGINAL_TEXT>
<TOKEN end_char="1954" id="token-24-0" morph="none" pos="word" start_char="1951">Like</TOKEN>
<TOKEN end_char="1956" id="token-24-1" morph="none" pos="word" start_char="1956">a</TOKEN>
<TOKEN end_char="1962" id="token-24-2" morph="none" pos="word" start_char="1958">pizza</TOKEN>
</SEG>
<SEG end_char="2070" id="segment-25" start_char="1966">
<ORIGINAL_TEXT>Dr. Zangrillo relied on samples from his hospital to state that the "virus no longer existed clinically".</ORIGINAL_TEXT>
<TOKEN end_char="1967" id="token-25-0" morph="none" pos="word" start_char="1966">Dr</TOKEN>
<TOKEN end_char="1968" id="token-25-1" morph="none" pos="punct" start_char="1968">.</TOKEN>
<TOKEN end_char="1978" id="token-25-2" morph="none" pos="word" start_char="1970">Zangrillo</TOKEN>
<TOKEN end_char="1985" id="token-25-3" morph="none" pos="word" start_char="1980">relied</TOKEN>
<TOKEN end_char="1988" id="token-25-4" morph="none" pos="word" start_char="1987">on</TOKEN>
<TOKEN end_char="1996" id="token-25-5" morph="none" pos="word" start_char="1990">samples</TOKEN>
<TOKEN end_char="2001" id="token-25-6" morph="none" pos="word" start_char="1998">from</TOKEN>
<TOKEN end_char="2005" id="token-25-7" morph="none" pos="word" start_char="2003">his</TOKEN>
<TOKEN end_char="2014" id="token-25-8" morph="none" pos="word" start_char="2007">hospital</TOKEN>
<TOKEN end_char="2017" id="token-25-9" morph="none" pos="word" start_char="2016">to</TOKEN>
<TOKEN end_char="2023" id="token-25-10" morph="none" pos="word" start_char="2019">state</TOKEN>
<TOKEN end_char="2028" id="token-25-11" morph="none" pos="word" start_char="2025">that</TOKEN>
<TOKEN end_char="2032" id="token-25-12" morph="none" pos="word" start_char="2030">the</TOKEN>
<TOKEN end_char="2034" id="token-25-13" morph="none" pos="punct" start_char="2034">"</TOKEN>
<TOKEN end_char="2039" id="token-25-14" morph="none" pos="word" start_char="2035">virus</TOKEN>
<TOKEN end_char="2042" id="token-25-15" morph="none" pos="word" start_char="2041">no</TOKEN>
<TOKEN end_char="2049" id="token-25-16" morph="none" pos="word" start_char="2044">longer</TOKEN>
<TOKEN end_char="2057" id="token-25-17" morph="none" pos="word" start_char="2051">existed</TOKEN>
<TOKEN end_char="2068" id="token-25-18" morph="none" pos="word" start_char="2059">clinically</TOKEN>
<TOKEN end_char="2070" id="token-25-19" morph="none" pos="punct" start_char="2069">".</TOKEN>
</SEG>
<SEG end_char="2161" id="segment-26" start_char="2072">
<ORIGINAL_TEXT>According to an American researcher, it does not make sense to make certain cases general.</ORIGINAL_TEXT>
<TOKEN end_char="2080" id="token-26-0" morph="none" pos="word" start_char="2072">According</TOKEN>
<TOKEN end_char="2083" id="token-26-1" morph="none" pos="word" start_char="2082">to</TOKEN>
<TOKEN end_char="2086" id="token-26-2" morph="none" pos="word" start_char="2085">an</TOKEN>
<TOKEN end_char="2095" id="token-26-3" morph="none" pos="word" start_char="2088">American</TOKEN>
<TOKEN end_char="2106" id="token-26-4" morph="none" pos="word" start_char="2097">researcher</TOKEN>
<TOKEN end_char="2107" id="token-26-5" morph="none" pos="punct" start_char="2107">,</TOKEN>
<TOKEN end_char="2110" id="token-26-6" morph="none" pos="word" start_char="2109">it</TOKEN>
<TOKEN end_char="2115" id="token-26-7" morph="none" pos="word" start_char="2112">does</TOKEN>
<TOKEN end_char="2119" id="token-26-8" morph="none" pos="word" start_char="2117">not</TOKEN>
<TOKEN end_char="2124" id="token-26-9" morph="none" pos="word" start_char="2121">make</TOKEN>
<TOKEN end_char="2130" id="token-26-10" morph="none" pos="word" start_char="2126">sense</TOKEN>
<TOKEN end_char="2133" id="token-26-11" morph="none" pos="word" start_char="2132">to</TOKEN>
<TOKEN end_char="2138" id="token-26-12" morph="none" pos="word" start_char="2135">make</TOKEN>
<TOKEN end_char="2146" id="token-26-13" morph="none" pos="word" start_char="2140">certain</TOKEN>
<TOKEN end_char="2152" id="token-26-14" morph="none" pos="word" start_char="2148">cases</TOKEN>
<TOKEN end_char="2160" id="token-26-15" morph="none" pos="word" start_char="2154">general</TOKEN>
<TOKEN end_char="2161" id="token-26-16" morph="none" pos="punct" start_char="2161">.</TOKEN>
</SEG>
<SEG end_char="2205" id="segment-27" start_char="2163">
<ORIGINAL_TEXT>The latter thus gave the example of pizzas.</ORIGINAL_TEXT>
<TOKEN end_char="2165" id="token-27-0" morph="none" pos="word" start_char="2163">The</TOKEN>
<TOKEN end_char="2172" id="token-27-1" morph="none" pos="word" start_char="2167">latter</TOKEN>
<TOKEN end_char="2177" id="token-27-2" morph="none" pos="word" start_char="2174">thus</TOKEN>
<TOKEN end_char="2182" id="token-27-3" morph="none" pos="word" start_char="2179">gave</TOKEN>
<TOKEN end_char="2186" id="token-27-4" morph="none" pos="word" start_char="2184">the</TOKEN>
<TOKEN end_char="2194" id="token-27-5" morph="none" pos="word" start_char="2188">example</TOKEN>
<TOKEN end_char="2197" id="token-27-6" morph="none" pos="word" start_char="2196">of</TOKEN>
<TOKEN end_char="2204" id="token-27-7" morph="none" pos="word" start_char="2199">pizzas</TOKEN>
<TOKEN end_char="2205" id="token-27-8" morph="none" pos="punct" start_char="2205">.</TOKEN>
</SEG>
<SEG end_char="2270" id="segment-28" start_char="2207">
<ORIGINAL_TEXT>Just because a restaurant pizza is tasty doesn’t mean it is all.</ORIGINAL_TEXT>
<TOKEN end_char="2210" id="token-28-0" morph="none" pos="word" start_char="2207">Just</TOKEN>
<TOKEN end_char="2218" id="token-28-1" morph="none" pos="word" start_char="2212">because</TOKEN>
<TOKEN end_char="2220" id="token-28-2" morph="none" pos="word" start_char="2220">a</TOKEN>
<TOKEN end_char="2231" id="token-28-3" morph="none" pos="word" start_char="2222">restaurant</TOKEN>
<TOKEN end_char="2237" id="token-28-4" morph="none" pos="word" start_char="2233">pizza</TOKEN>
<TOKEN end_char="2240" id="token-28-5" morph="none" pos="word" start_char="2239">is</TOKEN>
<TOKEN end_char="2246" id="token-28-6" morph="none" pos="word" start_char="2242">tasty</TOKEN>
<TOKEN end_char="2254" id="token-28-7" morph="none" pos="word" start_char="2248">doesn’t</TOKEN>
<TOKEN end_char="2259" id="token-28-8" morph="none" pos="word" start_char="2256">mean</TOKEN>
<TOKEN end_char="2262" id="token-28-9" morph="none" pos="word" start_char="2261">it</TOKEN>
<TOKEN end_char="2265" id="token-28-10" morph="none" pos="word" start_char="2264">is</TOKEN>
<TOKEN end_char="2269" id="token-28-11" morph="none" pos="word" start_char="2267">all</TOKEN>
<TOKEN end_char="2270" id="token-28-12" morph="none" pos="punct" start_char="2270">.</TOKEN>
</SEG>
<SEG end_char="2279" id="segment-29" start_char="2273">
<ORIGINAL_TEXT>Related</ORIGINAL_TEXT>
<TOKEN end_char="2279" id="token-29-0" morph="none" pos="word" start_char="2273">Related</TOKEN>
</SEG>
<SEG end_char="2319" id="segment-30" start_char="2283">
<ORIGINAL_TEXT>Does the coronavirus no longer exist?</ORIGINAL_TEXT>
<TOKEN end_char="2286" id="token-30-0" morph="none" pos="word" start_char="2283">Does</TOKEN>
<TOKEN end_char="2290" id="token-30-1" morph="none" pos="word" start_char="2288">the</TOKEN>
<TOKEN end_char="2302" id="token-30-2" morph="none" pos="word" start_char="2292">coronavirus</TOKEN>
<TOKEN end_char="2305" id="token-30-3" morph="none" pos="word" start_char="2304">no</TOKEN>
<TOKEN end_char="2312" id="token-30-4" morph="none" pos="word" start_char="2307">longer</TOKEN>
<TOKEN end_char="2318" id="token-30-5" morph="none" pos="word" start_char="2314">exist</TOKEN>
<TOKEN end_char="2319" id="token-30-6" morph="none" pos="punct" start_char="2319">?</TOKEN>
</SEG>
<SEG end_char="2387" id="segment-31" start_char="2321">
<ORIGINAL_TEXT>The controversy between an eminence of Italian medicine and the WHO</ORIGINAL_TEXT>
<TOKEN end_char="2323" id="token-31-0" morph="none" pos="word" start_char="2321">The</TOKEN>
<TOKEN end_char="2335" id="token-31-1" morph="none" pos="word" start_char="2325">controversy</TOKEN>
<TOKEN end_char="2343" id="token-31-2" morph="none" pos="word" start_char="2337">between</TOKEN>
<TOKEN end_char="2346" id="token-31-3" morph="none" pos="word" start_char="2345">an</TOKEN>
<TOKEN end_char="2355" id="token-31-4" morph="none" pos="word" start_char="2348">eminence</TOKEN>
<TOKEN end_char="2358" id="token-31-5" morph="none" pos="word" start_char="2357">of</TOKEN>
<TOKEN end_char="2366" id="token-31-6" morph="none" pos="word" start_char="2360">Italian</TOKEN>
<TOKEN end_char="2375" id="token-31-7" morph="none" pos="word" start_char="2368">medicine</TOKEN>
<TOKEN end_char="2379" id="token-31-8" morph="none" pos="word" start_char="2377">and</TOKEN>
<TOKEN end_char="2383" id="token-31-9" morph="none" pos="word" start_char="2381">the</TOKEN>
<TOKEN end_char="2387" id="token-31-10" morph="none" pos="word" start_char="2385">WHO</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
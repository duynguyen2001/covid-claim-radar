<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CABT" lang="spa" raw_text_char_length="5092" raw_text_md5="1cb9bd41f4495c7d30b4cecd3241ea6f" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="110" id="segment-0" start_char="1">
<ORIGINAL_TEXT>The first COVID-19 case originated on November 17, according to Chinese officials searching for 'patient zero'</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">The</TOKEN>
<TOKEN end_char="9" id="token-0-1" morph="none" pos="word" start_char="5">first</TOKEN>
<TOKEN end_char="18" id="token-0-2" morph="none" pos="unknown" start_char="11">COVID-19</TOKEN>
<TOKEN end_char="23" id="token-0-3" morph="none" pos="word" start_char="20">case</TOKEN>
<TOKEN end_char="34" id="token-0-4" morph="none" pos="word" start_char="25">originated</TOKEN>
<TOKEN end_char="37" id="token-0-5" morph="none" pos="word" start_char="36">on</TOKEN>
<TOKEN end_char="46" id="token-0-6" morph="none" pos="word" start_char="39">November</TOKEN>
<TOKEN end_char="49" id="token-0-7" morph="none" pos="word" start_char="48">17</TOKEN>
<TOKEN end_char="50" id="token-0-8" morph="none" pos="punct" start_char="50">,</TOKEN>
<TOKEN end_char="60" id="token-0-9" morph="none" pos="word" start_char="52">according</TOKEN>
<TOKEN end_char="63" id="token-0-10" morph="none" pos="word" start_char="62">to</TOKEN>
<TOKEN end_char="71" id="token-0-11" morph="none" pos="word" start_char="65">Chinese</TOKEN>
<TOKEN end_char="81" id="token-0-12" morph="none" pos="word" start_char="73">officials</TOKEN>
<TOKEN end_char="91" id="token-0-13" morph="none" pos="word" start_char="83">searching</TOKEN>
<TOKEN end_char="95" id="token-0-14" morph="none" pos="word" start_char="93">for</TOKEN>
<TOKEN end_char="97" id="token-0-15" morph="none" pos="punct" start_char="97">'</TOKEN>
<TOKEN end_char="104" id="token-0-16" morph="none" pos="word" start_char="98">patient</TOKEN>
<TOKEN end_char="109" id="token-0-17" morph="none" pos="word" start_char="106">zero</TOKEN>
<TOKEN end_char="110" id="token-0-18" morph="none" pos="punct" start_char="110">'</TOKEN>
</SEG>
<SEG end_char="183" id="segment-1" start_char="115">
<ORIGINAL_TEXT>The novel coronavirus under colored transmission electron microscopy.</ORIGINAL_TEXT>
<TOKEN end_char="117" id="token-1-0" morph="none" pos="word" start_char="115">The</TOKEN>
<TOKEN end_char="123" id="token-1-1" morph="none" pos="word" start_char="119">novel</TOKEN>
<TOKEN end_char="135" id="token-1-2" morph="none" pos="word" start_char="125">coronavirus</TOKEN>
<TOKEN end_char="141" id="token-1-3" morph="none" pos="word" start_char="137">under</TOKEN>
<TOKEN end_char="149" id="token-1-4" morph="none" pos="word" start_char="143">colored</TOKEN>
<TOKEN end_char="162" id="token-1-5" morph="none" pos="word" start_char="151">transmission</TOKEN>
<TOKEN end_char="171" id="token-1-6" morph="none" pos="word" start_char="164">electron</TOKEN>
<TOKEN end_char="182" id="token-1-7" morph="none" pos="word" start_char="173">microscopy</TOKEN>
<TOKEN end_char="183" id="token-1-8" morph="none" pos="punct" start_char="183">.</TOKEN>
</SEG>
<SEG end_char="210" id="segment-2" start_char="186">
<ORIGINAL_TEXT>BSIP/UIG Via Getty Images</ORIGINAL_TEXT>
<TOKEN end_char="193" id="token-2-0" morph="none" pos="unknown" start_char="186">BSIP/UIG</TOKEN>
<TOKEN end_char="197" id="token-2-1" morph="none" pos="word" start_char="195">Via</TOKEN>
<TOKEN end_char="203" id="token-2-2" morph="none" pos="word" start_char="199">Getty</TOKEN>
<TOKEN end_char="210" id="token-2-3" morph="none" pos="word" start_char="205">Images</TOKEN>
</SEG>
<SEG end_char="351" id="segment-3" start_char="214">
<ORIGINAL_TEXT>The first case of the novel coronavirus emerged on November 17, according to Chinese government data reviewed by South China Morning Post.</ORIGINAL_TEXT>
<TOKEN end_char="216" id="token-3-0" morph="none" pos="word" start_char="214">The</TOKEN>
<TOKEN end_char="222" id="token-3-1" morph="none" pos="word" start_char="218">first</TOKEN>
<TOKEN end_char="227" id="token-3-2" morph="none" pos="word" start_char="224">case</TOKEN>
<TOKEN end_char="230" id="token-3-3" morph="none" pos="word" start_char="229">of</TOKEN>
<TOKEN end_char="234" id="token-3-4" morph="none" pos="word" start_char="232">the</TOKEN>
<TOKEN end_char="240" id="token-3-5" morph="none" pos="word" start_char="236">novel</TOKEN>
<TOKEN end_char="252" id="token-3-6" morph="none" pos="word" start_char="242">coronavirus</TOKEN>
<TOKEN end_char="260" id="token-3-7" morph="none" pos="word" start_char="254">emerged</TOKEN>
<TOKEN end_char="263" id="token-3-8" morph="none" pos="word" start_char="262">on</TOKEN>
<TOKEN end_char="272" id="token-3-9" morph="none" pos="word" start_char="265">November</TOKEN>
<TOKEN end_char="275" id="token-3-10" morph="none" pos="word" start_char="274">17</TOKEN>
<TOKEN end_char="276" id="token-3-11" morph="none" pos="punct" start_char="276">,</TOKEN>
<TOKEN end_char="286" id="token-3-12" morph="none" pos="word" start_char="278">according</TOKEN>
<TOKEN end_char="289" id="token-3-13" morph="none" pos="word" start_char="288">to</TOKEN>
<TOKEN end_char="297" id="token-3-14" morph="none" pos="word" start_char="291">Chinese</TOKEN>
<TOKEN end_char="308" id="token-3-15" morph="none" pos="word" start_char="299">government</TOKEN>
<TOKEN end_char="313" id="token-3-16" morph="none" pos="word" start_char="310">data</TOKEN>
<TOKEN end_char="322" id="token-3-17" morph="none" pos="word" start_char="315">reviewed</TOKEN>
<TOKEN end_char="325" id="token-3-18" morph="none" pos="word" start_char="324">by</TOKEN>
<TOKEN end_char="331" id="token-3-19" morph="none" pos="word" start_char="327">South</TOKEN>
<TOKEN end_char="337" id="token-3-20" morph="none" pos="word" start_char="333">China</TOKEN>
<TOKEN end_char="345" id="token-3-21" morph="none" pos="word" start_char="339">Morning</TOKEN>
<TOKEN end_char="350" id="token-3-22" morph="none" pos="word" start_char="347">Post</TOKEN>
<TOKEN end_char="351" id="token-3-23" morph="none" pos="punct" start_char="351">.</TOKEN>
</SEG>
<SEG end_char="478" id="segment-4" start_char="354">
<ORIGINAL_TEXT>The identity of the person has not been confirmed, but it appears to be a 55-year-old from the Hubei province, the Post said.</ORIGINAL_TEXT>
<TOKEN end_char="356" id="token-4-0" morph="none" pos="word" start_char="354">The</TOKEN>
<TOKEN end_char="365" id="token-4-1" morph="none" pos="word" start_char="358">identity</TOKEN>
<TOKEN end_char="368" id="token-4-2" morph="none" pos="word" start_char="367">of</TOKEN>
<TOKEN end_char="372" id="token-4-3" morph="none" pos="word" start_char="370">the</TOKEN>
<TOKEN end_char="379" id="token-4-4" morph="none" pos="word" start_char="374">person</TOKEN>
<TOKEN end_char="383" id="token-4-5" morph="none" pos="word" start_char="381">has</TOKEN>
<TOKEN end_char="387" id="token-4-6" morph="none" pos="word" start_char="385">not</TOKEN>
<TOKEN end_char="392" id="token-4-7" morph="none" pos="word" start_char="389">been</TOKEN>
<TOKEN end_char="402" id="token-4-8" morph="none" pos="word" start_char="394">confirmed</TOKEN>
<TOKEN end_char="403" id="token-4-9" morph="none" pos="punct" start_char="403">,</TOKEN>
<TOKEN end_char="407" id="token-4-10" morph="none" pos="word" start_char="405">but</TOKEN>
<TOKEN end_char="410" id="token-4-11" morph="none" pos="word" start_char="409">it</TOKEN>
<TOKEN end_char="418" id="token-4-12" morph="none" pos="word" start_char="412">appears</TOKEN>
<TOKEN end_char="421" id="token-4-13" morph="none" pos="word" start_char="420">to</TOKEN>
<TOKEN end_char="424" id="token-4-14" morph="none" pos="word" start_char="423">be</TOKEN>
<TOKEN end_char="426" id="token-4-15" morph="none" pos="word" start_char="426">a</TOKEN>
<TOKEN end_char="438" id="token-4-16" morph="none" pos="unknown" start_char="428">55-year-old</TOKEN>
<TOKEN end_char="443" id="token-4-17" morph="none" pos="word" start_char="440">from</TOKEN>
<TOKEN end_char="447" id="token-4-18" morph="none" pos="word" start_char="445">the</TOKEN>
<TOKEN end_char="453" id="token-4-19" morph="none" pos="word" start_char="449">Hubei</TOKEN>
<TOKEN end_char="462" id="token-4-20" morph="none" pos="word" start_char="455">province</TOKEN>
<TOKEN end_char="463" id="token-4-21" morph="none" pos="punct" start_char="463">,</TOKEN>
<TOKEN end_char="467" id="token-4-22" morph="none" pos="word" start_char="465">the</TOKEN>
<TOKEN end_char="472" id="token-4-23" morph="none" pos="word" start_char="469">Post</TOKEN>
<TOKEN end_char="477" id="token-4-24" morph="none" pos="word" start_char="474">said</TOKEN>
<TOKEN end_char="478" id="token-4-25" morph="none" pos="punct" start_char="478">.</TOKEN>
</SEG>
<SEG end_char="583" id="segment-5" start_char="481">
<ORIGINAL_TEXT>It wasn't until December that Chinese authorities realized they had a new type of virus on their hands.</ORIGINAL_TEXT>
<TOKEN end_char="482" id="token-5-0" morph="none" pos="word" start_char="481">It</TOKEN>
<TOKEN end_char="489" id="token-5-1" morph="none" pos="word" start_char="484">wasn't</TOKEN>
<TOKEN end_char="495" id="token-5-2" morph="none" pos="word" start_char="491">until</TOKEN>
<TOKEN end_char="504" id="token-5-3" morph="none" pos="word" start_char="497">December</TOKEN>
<TOKEN end_char="509" id="token-5-4" morph="none" pos="word" start_char="506">that</TOKEN>
<TOKEN end_char="517" id="token-5-5" morph="none" pos="word" start_char="511">Chinese</TOKEN>
<TOKEN end_char="529" id="token-5-6" morph="none" pos="word" start_char="519">authorities</TOKEN>
<TOKEN end_char="538" id="token-5-7" morph="none" pos="word" start_char="531">realized</TOKEN>
<TOKEN end_char="543" id="token-5-8" morph="none" pos="word" start_char="540">they</TOKEN>
<TOKEN end_char="547" id="token-5-9" morph="none" pos="word" start_char="545">had</TOKEN>
<TOKEN end_char="549" id="token-5-10" morph="none" pos="word" start_char="549">a</TOKEN>
<TOKEN end_char="553" id="token-5-11" morph="none" pos="word" start_char="551">new</TOKEN>
<TOKEN end_char="558" id="token-5-12" morph="none" pos="word" start_char="555">type</TOKEN>
<TOKEN end_char="561" id="token-5-13" morph="none" pos="word" start_char="560">of</TOKEN>
<TOKEN end_char="567" id="token-5-14" morph="none" pos="word" start_char="563">virus</TOKEN>
<TOKEN end_char="570" id="token-5-15" morph="none" pos="word" start_char="569">on</TOKEN>
<TOKEN end_char="576" id="token-5-16" morph="none" pos="word" start_char="572">their</TOKEN>
<TOKEN end_char="582" id="token-5-17" morph="none" pos="word" start_char="578">hands</TOKEN>
<TOKEN end_char="583" id="token-5-18" morph="none" pos="punct" start_char="583">.</TOKEN>
</SEG>
<SEG end_char="636" id="segment-6" start_char="586">
<ORIGINAL_TEXT>Visit Business Insider's homepage for more stories.</ORIGINAL_TEXT>
<TOKEN end_char="590" id="token-6-0" morph="none" pos="word" start_char="586">Visit</TOKEN>
<TOKEN end_char="599" id="token-6-1" morph="none" pos="word" start_char="592">Business</TOKEN>
<TOKEN end_char="609" id="token-6-2" morph="none" pos="word" start_char="601">Insider's</TOKEN>
<TOKEN end_char="618" id="token-6-3" morph="none" pos="word" start_char="611">homepage</TOKEN>
<TOKEN end_char="622" id="token-6-4" morph="none" pos="word" start_char="620">for</TOKEN>
<TOKEN end_char="627" id="token-6-5" morph="none" pos="word" start_char="624">more</TOKEN>
<TOKEN end_char="635" id="token-6-6" morph="none" pos="word" start_char="629">stories</TOKEN>
<TOKEN end_char="636" id="token-6-7" morph="none" pos="punct" start_char="636">.</TOKEN>
</SEG>
<SEG end_char="781" id="segment-7" start_char="640">
<ORIGINAL_TEXT>The first case of the novel coronavirus emerged on November 17, according to Chinese government data reviewed by the South China Morning Post.</ORIGINAL_TEXT>
<TOKEN end_char="642" id="token-7-0" morph="none" pos="word" start_char="640">The</TOKEN>
<TOKEN end_char="648" id="token-7-1" morph="none" pos="word" start_char="644">first</TOKEN>
<TOKEN end_char="653" id="token-7-2" morph="none" pos="word" start_char="650">case</TOKEN>
<TOKEN end_char="656" id="token-7-3" morph="none" pos="word" start_char="655">of</TOKEN>
<TOKEN end_char="660" id="token-7-4" morph="none" pos="word" start_char="658">the</TOKEN>
<TOKEN end_char="666" id="token-7-5" morph="none" pos="word" start_char="662">novel</TOKEN>
<TOKEN end_char="678" id="token-7-6" morph="none" pos="word" start_char="668">coronavirus</TOKEN>
<TOKEN end_char="686" id="token-7-7" morph="none" pos="word" start_char="680">emerged</TOKEN>
<TOKEN end_char="689" id="token-7-8" morph="none" pos="word" start_char="688">on</TOKEN>
<TOKEN end_char="698" id="token-7-9" morph="none" pos="word" start_char="691">November</TOKEN>
<TOKEN end_char="701" id="token-7-10" morph="none" pos="word" start_char="700">17</TOKEN>
<TOKEN end_char="702" id="token-7-11" morph="none" pos="punct" start_char="702">,</TOKEN>
<TOKEN end_char="712" id="token-7-12" morph="none" pos="word" start_char="704">according</TOKEN>
<TOKEN end_char="715" id="token-7-13" morph="none" pos="word" start_char="714">to</TOKEN>
<TOKEN end_char="723" id="token-7-14" morph="none" pos="word" start_char="717">Chinese</TOKEN>
<TOKEN end_char="734" id="token-7-15" morph="none" pos="word" start_char="725">government</TOKEN>
<TOKEN end_char="739" id="token-7-16" morph="none" pos="word" start_char="736">data</TOKEN>
<TOKEN end_char="748" id="token-7-17" morph="none" pos="word" start_char="741">reviewed</TOKEN>
<TOKEN end_char="751" id="token-7-18" morph="none" pos="word" start_char="750">by</TOKEN>
<TOKEN end_char="755" id="token-7-19" morph="none" pos="word" start_char="753">the</TOKEN>
<TOKEN end_char="761" id="token-7-20" morph="none" pos="word" start_char="757">South</TOKEN>
<TOKEN end_char="767" id="token-7-21" morph="none" pos="word" start_char="763">China</TOKEN>
<TOKEN end_char="775" id="token-7-22" morph="none" pos="word" start_char="769">Morning</TOKEN>
<TOKEN end_char="780" id="token-7-23" morph="none" pos="word" start_char="777">Post</TOKEN>
<TOKEN end_char="781" id="token-7-24" morph="none" pos="punct" start_char="781">.</TOKEN>
</SEG>
<SEG end_char="881" id="segment-8" start_char="784">
<ORIGINAL_TEXT>It wasn't until late December that Chinese officials realized they had a new virus on their hands.</ORIGINAL_TEXT>
<TOKEN end_char="785" id="token-8-0" morph="none" pos="word" start_char="784">It</TOKEN>
<TOKEN end_char="792" id="token-8-1" morph="none" pos="word" start_char="787">wasn't</TOKEN>
<TOKEN end_char="798" id="token-8-2" morph="none" pos="word" start_char="794">until</TOKEN>
<TOKEN end_char="803" id="token-8-3" morph="none" pos="word" start_char="800">late</TOKEN>
<TOKEN end_char="812" id="token-8-4" morph="none" pos="word" start_char="805">December</TOKEN>
<TOKEN end_char="817" id="token-8-5" morph="none" pos="word" start_char="814">that</TOKEN>
<TOKEN end_char="825" id="token-8-6" morph="none" pos="word" start_char="819">Chinese</TOKEN>
<TOKEN end_char="835" id="token-8-7" morph="none" pos="word" start_char="827">officials</TOKEN>
<TOKEN end_char="844" id="token-8-8" morph="none" pos="word" start_char="837">realized</TOKEN>
<TOKEN end_char="849" id="token-8-9" morph="none" pos="word" start_char="846">they</TOKEN>
<TOKEN end_char="853" id="token-8-10" morph="none" pos="word" start_char="851">had</TOKEN>
<TOKEN end_char="855" id="token-8-11" morph="none" pos="word" start_char="855">a</TOKEN>
<TOKEN end_char="859" id="token-8-12" morph="none" pos="word" start_char="857">new</TOKEN>
<TOKEN end_char="865" id="token-8-13" morph="none" pos="word" start_char="861">virus</TOKEN>
<TOKEN end_char="868" id="token-8-14" morph="none" pos="word" start_char="867">on</TOKEN>
<TOKEN end_char="874" id="token-8-15" morph="none" pos="word" start_char="870">their</TOKEN>
<TOKEN end_char="880" id="token-8-16" morph="none" pos="word" start_char="876">hands</TOKEN>
<TOKEN end_char="881" id="token-8-17" morph="none" pos="punct" start_char="881">.</TOKEN>
</SEG>
<SEG end_char="1015" id="segment-9" start_char="883">
<ORIGINAL_TEXT>But even then, China's government clamped down on sharing information about it with the public, according to The Wall Street Journal.</ORIGINAL_TEXT>
<TOKEN end_char="885" id="token-9-0" morph="none" pos="word" start_char="883">But</TOKEN>
<TOKEN end_char="890" id="token-9-1" morph="none" pos="word" start_char="887">even</TOKEN>
<TOKEN end_char="895" id="token-9-2" morph="none" pos="word" start_char="892">then</TOKEN>
<TOKEN end_char="896" id="token-9-3" morph="none" pos="punct" start_char="896">,</TOKEN>
<TOKEN end_char="904" id="token-9-4" morph="none" pos="word" start_char="898">China's</TOKEN>
<TOKEN end_char="915" id="token-9-5" morph="none" pos="word" start_char="906">government</TOKEN>
<TOKEN end_char="923" id="token-9-6" morph="none" pos="word" start_char="917">clamped</TOKEN>
<TOKEN end_char="928" id="token-9-7" morph="none" pos="word" start_char="925">down</TOKEN>
<TOKEN end_char="931" id="token-9-8" morph="none" pos="word" start_char="930">on</TOKEN>
<TOKEN end_char="939" id="token-9-9" morph="none" pos="word" start_char="933">sharing</TOKEN>
<TOKEN end_char="951" id="token-9-10" morph="none" pos="word" start_char="941">information</TOKEN>
<TOKEN end_char="957" id="token-9-11" morph="none" pos="word" start_char="953">about</TOKEN>
<TOKEN end_char="960" id="token-9-12" morph="none" pos="word" start_char="959">it</TOKEN>
<TOKEN end_char="965" id="token-9-13" morph="none" pos="word" start_char="962">with</TOKEN>
<TOKEN end_char="969" id="token-9-14" morph="none" pos="word" start_char="967">the</TOKEN>
<TOKEN end_char="976" id="token-9-15" morph="none" pos="word" start_char="971">public</TOKEN>
<TOKEN end_char="977" id="token-9-16" morph="none" pos="punct" start_char="977">,</TOKEN>
<TOKEN end_char="987" id="token-9-17" morph="none" pos="word" start_char="979">according</TOKEN>
<TOKEN end_char="990" id="token-9-18" morph="none" pos="word" start_char="989">to</TOKEN>
<TOKEN end_char="994" id="token-9-19" morph="none" pos="word" start_char="992">The</TOKEN>
<TOKEN end_char="999" id="token-9-20" morph="none" pos="word" start_char="996">Wall</TOKEN>
<TOKEN end_char="1006" id="token-9-21" morph="none" pos="word" start_char="1001">Street</TOKEN>
<TOKEN end_char="1014" id="token-9-22" morph="none" pos="word" start_char="1008">Journal</TOKEN>
<TOKEN end_char="1015" id="token-9-23" morph="none" pos="punct" start_char="1015">.</TOKEN>
</SEG>
<SEG end_char="1180" id="segment-10" start_char="1018">
<ORIGINAL_TEXT>The Post said the data it reviewed, which has not been made public, suggested that the virus was first contracted by a 55-year-old man from China's Hubei province.</ORIGINAL_TEXT>
<TOKEN end_char="1020" id="token-10-0" morph="none" pos="word" start_char="1018">The</TOKEN>
<TOKEN end_char="1025" id="token-10-1" morph="none" pos="word" start_char="1022">Post</TOKEN>
<TOKEN end_char="1030" id="token-10-2" morph="none" pos="word" start_char="1027">said</TOKEN>
<TOKEN end_char="1034" id="token-10-3" morph="none" pos="word" start_char="1032">the</TOKEN>
<TOKEN end_char="1039" id="token-10-4" morph="none" pos="word" start_char="1036">data</TOKEN>
<TOKEN end_char="1042" id="token-10-5" morph="none" pos="word" start_char="1041">it</TOKEN>
<TOKEN end_char="1051" id="token-10-6" morph="none" pos="word" start_char="1044">reviewed</TOKEN>
<TOKEN end_char="1052" id="token-10-7" morph="none" pos="punct" start_char="1052">,</TOKEN>
<TOKEN end_char="1058" id="token-10-8" morph="none" pos="word" start_char="1054">which</TOKEN>
<TOKEN end_char="1062" id="token-10-9" morph="none" pos="word" start_char="1060">has</TOKEN>
<TOKEN end_char="1066" id="token-10-10" morph="none" pos="word" start_char="1064">not</TOKEN>
<TOKEN end_char="1071" id="token-10-11" morph="none" pos="word" start_char="1068">been</TOKEN>
<TOKEN end_char="1076" id="token-10-12" morph="none" pos="word" start_char="1073">made</TOKEN>
<TOKEN end_char="1083" id="token-10-13" morph="none" pos="word" start_char="1078">public</TOKEN>
<TOKEN end_char="1084" id="token-10-14" morph="none" pos="punct" start_char="1084">,</TOKEN>
<TOKEN end_char="1094" id="token-10-15" morph="none" pos="word" start_char="1086">suggested</TOKEN>
<TOKEN end_char="1099" id="token-10-16" morph="none" pos="word" start_char="1096">that</TOKEN>
<TOKEN end_char="1103" id="token-10-17" morph="none" pos="word" start_char="1101">the</TOKEN>
<TOKEN end_char="1109" id="token-10-18" morph="none" pos="word" start_char="1105">virus</TOKEN>
<TOKEN end_char="1113" id="token-10-19" morph="none" pos="word" start_char="1111">was</TOKEN>
<TOKEN end_char="1119" id="token-10-20" morph="none" pos="word" start_char="1115">first</TOKEN>
<TOKEN end_char="1130" id="token-10-21" morph="none" pos="word" start_char="1121">contracted</TOKEN>
<TOKEN end_char="1133" id="token-10-22" morph="none" pos="word" start_char="1132">by</TOKEN>
<TOKEN end_char="1135" id="token-10-23" morph="none" pos="word" start_char="1135">a</TOKEN>
<TOKEN end_char="1147" id="token-10-24" morph="none" pos="unknown" start_char="1137">55-year-old</TOKEN>
<TOKEN end_char="1151" id="token-10-25" morph="none" pos="word" start_char="1149">man</TOKEN>
<TOKEN end_char="1156" id="token-10-26" morph="none" pos="word" start_char="1153">from</TOKEN>
<TOKEN end_char="1164" id="token-10-27" morph="none" pos="word" start_char="1158">China's</TOKEN>
<TOKEN end_char="1170" id="token-10-28" morph="none" pos="word" start_char="1166">Hubei</TOKEN>
<TOKEN end_char="1179" id="token-10-29" morph="none" pos="word" start_char="1172">province</TOKEN>
<TOKEN end_char="1180" id="token-10-30" morph="none" pos="punct" start_char="1180">.</TOKEN>
</SEG>
<SEG end_char="1241" id="segment-11" start_char="1183">
<ORIGINAL_TEXT>But as the newspaper noted, the evidence is not conclusive.</ORIGINAL_TEXT>
<TOKEN end_char="1185" id="token-11-0" morph="none" pos="word" start_char="1183">But</TOKEN>
<TOKEN end_char="1188" id="token-11-1" morph="none" pos="word" start_char="1187">as</TOKEN>
<TOKEN end_char="1192" id="token-11-2" morph="none" pos="word" start_char="1190">the</TOKEN>
<TOKEN end_char="1202" id="token-11-3" morph="none" pos="word" start_char="1194">newspaper</TOKEN>
<TOKEN end_char="1208" id="token-11-4" morph="none" pos="word" start_char="1204">noted</TOKEN>
<TOKEN end_char="1209" id="token-11-5" morph="none" pos="punct" start_char="1209">,</TOKEN>
<TOKEN end_char="1213" id="token-11-6" morph="none" pos="word" start_char="1211">the</TOKEN>
<TOKEN end_char="1222" id="token-11-7" morph="none" pos="word" start_char="1215">evidence</TOKEN>
<TOKEN end_char="1225" id="token-11-8" morph="none" pos="word" start_char="1224">is</TOKEN>
<TOKEN end_char="1229" id="token-11-9" morph="none" pos="word" start_char="1227">not</TOKEN>
<TOKEN end_char="1240" id="token-11-10" morph="none" pos="word" start_char="1231">conclusive</TOKEN>
<TOKEN end_char="1241" id="token-11-11" morph="none" pos="punct" start_char="1241">.</TOKEN>
</SEG>
<SEG end_char="1392" id="segment-12" start_char="1243">
<ORIGINAL_TEXT>The identity of "patient zero" — the first human case of the virus — has still not been confirmed, and it's possible that the data set isn't complete.</ORIGINAL_TEXT>
<TOKEN end_char="1245" id="token-12-0" morph="none" pos="word" start_char="1243">The</TOKEN>
<TOKEN end_char="1254" id="token-12-1" morph="none" pos="word" start_char="1247">identity</TOKEN>
<TOKEN end_char="1257" id="token-12-2" morph="none" pos="word" start_char="1256">of</TOKEN>
<TOKEN end_char="1259" id="token-12-3" morph="none" pos="punct" start_char="1259">"</TOKEN>
<TOKEN end_char="1266" id="token-12-4" morph="none" pos="word" start_char="1260">patient</TOKEN>
<TOKEN end_char="1271" id="token-12-5" morph="none" pos="word" start_char="1268">zero</TOKEN>
<TOKEN end_char="1272" id="token-12-6" morph="none" pos="punct" start_char="1272">"</TOKEN>
<TOKEN end_char="1274" id="token-12-7" morph="none" pos="punct" start_char="1274">—</TOKEN>
<TOKEN end_char="1278" id="token-12-8" morph="none" pos="word" start_char="1276">the</TOKEN>
<TOKEN end_char="1284" id="token-12-9" morph="none" pos="word" start_char="1280">first</TOKEN>
<TOKEN end_char="1290" id="token-12-10" morph="none" pos="word" start_char="1286">human</TOKEN>
<TOKEN end_char="1295" id="token-12-11" morph="none" pos="word" start_char="1292">case</TOKEN>
<TOKEN end_char="1298" id="token-12-12" morph="none" pos="word" start_char="1297">of</TOKEN>
<TOKEN end_char="1302" id="token-12-13" morph="none" pos="word" start_char="1300">the</TOKEN>
<TOKEN end_char="1308" id="token-12-14" morph="none" pos="word" start_char="1304">virus</TOKEN>
<TOKEN end_char="1310" id="token-12-15" morph="none" pos="punct" start_char="1310">—</TOKEN>
<TOKEN end_char="1314" id="token-12-16" morph="none" pos="word" start_char="1312">has</TOKEN>
<TOKEN end_char="1320" id="token-12-17" morph="none" pos="word" start_char="1316">still</TOKEN>
<TOKEN end_char="1324" id="token-12-18" morph="none" pos="word" start_char="1322">not</TOKEN>
<TOKEN end_char="1329" id="token-12-19" morph="none" pos="word" start_char="1326">been</TOKEN>
<TOKEN end_char="1339" id="token-12-20" morph="none" pos="word" start_char="1331">confirmed</TOKEN>
<TOKEN end_char="1340" id="token-12-21" morph="none" pos="punct" start_char="1340">,</TOKEN>
<TOKEN end_char="1344" id="token-12-22" morph="none" pos="word" start_char="1342">and</TOKEN>
<TOKEN end_char="1349" id="token-12-23" morph="none" pos="word" start_char="1346">it's</TOKEN>
<TOKEN end_char="1358" id="token-12-24" morph="none" pos="word" start_char="1351">possible</TOKEN>
<TOKEN end_char="1363" id="token-12-25" morph="none" pos="word" start_char="1360">that</TOKEN>
<TOKEN end_char="1367" id="token-12-26" morph="none" pos="word" start_char="1365">the</TOKEN>
<TOKEN end_char="1372" id="token-12-27" morph="none" pos="word" start_char="1369">data</TOKEN>
<TOKEN end_char="1376" id="token-12-28" morph="none" pos="word" start_char="1374">set</TOKEN>
<TOKEN end_char="1382" id="token-12-29" morph="none" pos="word" start_char="1378">isn't</TOKEN>
<TOKEN end_char="1391" id="token-12-30" morph="none" pos="word" start_char="1384">complete</TOKEN>
<TOKEN end_char="1392" id="token-12-31" morph="none" pos="punct" start_char="1392">.</TOKEN>
</SEG>
<SEG end_char="1404" id="segment-13" start_char="1395">
<ORIGINAL_TEXT>Newsletter</ORIGINAL_TEXT>
<TOKEN end_char="1404" id="token-13-0" morph="none" pos="word" start_char="1395">Newsletter</TOKEN>
</SEG>
<SEG end_char="1474" id="segment-14" start_char="1407">
<ORIGINAL_TEXT>Start your day with the biggest stories in politics and the economy.</ORIGINAL_TEXT>
<TOKEN end_char="1411" id="token-14-0" morph="none" pos="word" start_char="1407">Start</TOKEN>
<TOKEN end_char="1416" id="token-14-1" morph="none" pos="word" start_char="1413">your</TOKEN>
<TOKEN end_char="1420" id="token-14-2" morph="none" pos="word" start_char="1418">day</TOKEN>
<TOKEN end_char="1425" id="token-14-3" morph="none" pos="word" start_char="1422">with</TOKEN>
<TOKEN end_char="1429" id="token-14-4" morph="none" pos="word" start_char="1427">the</TOKEN>
<TOKEN end_char="1437" id="token-14-5" morph="none" pos="word" start_char="1431">biggest</TOKEN>
<TOKEN end_char="1445" id="token-14-6" morph="none" pos="word" start_char="1439">stories</TOKEN>
<TOKEN end_char="1448" id="token-14-7" morph="none" pos="word" start_char="1447">in</TOKEN>
<TOKEN end_char="1457" id="token-14-8" morph="none" pos="word" start_char="1450">politics</TOKEN>
<TOKEN end_char="1461" id="token-14-9" morph="none" pos="word" start_char="1459">and</TOKEN>
<TOKEN end_char="1465" id="token-14-10" morph="none" pos="word" start_char="1463">the</TOKEN>
<TOKEN end_char="1473" id="token-14-11" morph="none" pos="word" start_char="1467">economy</TOKEN>
<TOKEN end_char="1474" id="token-14-12" morph="none" pos="punct" start_char="1474">.</TOKEN>
</SEG>
<SEG end_char="1509" id="segment-15" start_char="1476">
<ORIGINAL_TEXT>Sign up for 10 Things in Politics.</ORIGINAL_TEXT>
<TOKEN end_char="1479" id="token-15-0" morph="none" pos="word" start_char="1476">Sign</TOKEN>
<TOKEN end_char="1482" id="token-15-1" morph="none" pos="word" start_char="1481">up</TOKEN>
<TOKEN end_char="1486" id="token-15-2" morph="none" pos="word" start_char="1484">for</TOKEN>
<TOKEN end_char="1489" id="token-15-3" morph="none" pos="word" start_char="1488">10</TOKEN>
<TOKEN end_char="1496" id="token-15-4" morph="none" pos="word" start_char="1491">Things</TOKEN>
<TOKEN end_char="1499" id="token-15-5" morph="none" pos="word" start_char="1498">in</TOKEN>
<TOKEN end_char="1508" id="token-15-6" morph="none" pos="word" start_char="1501">Politics</TOKEN>
<TOKEN end_char="1509" id="token-15-7" morph="none" pos="punct" start_char="1509">.</TOKEN>
</SEG>
<SEG end_char="1532" id="segment-16" start_char="1512">
<ORIGINAL_TEXT>Something is loading.</ORIGINAL_TEXT>
<TOKEN end_char="1520" id="token-16-0" morph="none" pos="word" start_char="1512">Something</TOKEN>
<TOKEN end_char="1523" id="token-16-1" morph="none" pos="word" start_char="1522">is</TOKEN>
<TOKEN end_char="1531" id="token-16-2" morph="none" pos="word" start_char="1525">loading</TOKEN>
<TOKEN end_char="1532" id="token-16-3" morph="none" pos="punct" start_char="1532">.</TOKEN>
</SEG>
<SEG end_char="1548" id="segment-17" start_char="1536">
<ORIGINAL_TEXT>Email address</ORIGINAL_TEXT>
<TOKEN end_char="1540" id="token-17-0" morph="none" pos="word" start_char="1536">Email</TOKEN>
<TOKEN end_char="1548" id="token-17-1" morph="none" pos="word" start_char="1542">address</TOKEN>
<TRANSLATED_TEXT>E-mail address</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="1707" id="segment-18" start_char="1551">
<ORIGINAL_TEXT>By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy Policy.</ORIGINAL_TEXT>
<TOKEN end_char="1552" id="token-18-0" morph="none" pos="word" start_char="1551">By</TOKEN>
<TOKEN end_char="1561" id="token-18-1" morph="none" pos="word" start_char="1554">clicking</TOKEN>
<TOKEN end_char="1563" id="token-18-2" morph="none" pos="punct" start_char="1563">‘</TOKEN>
<TOKEN end_char="1567" id="token-18-3" morph="none" pos="word" start_char="1564">Sign</TOKEN>
<TOKEN end_char="1570" id="token-18-4" morph="none" pos="word" start_char="1569">up</TOKEN>
<TOKEN end_char="1572" id="token-18-5" morph="none" pos="punct" start_char="1571">’,</TOKEN>
<TOKEN end_char="1576" id="token-18-6" morph="none" pos="word" start_char="1574">you</TOKEN>
<TOKEN end_char="1582" id="token-18-7" morph="none" pos="word" start_char="1578">agree</TOKEN>
<TOKEN end_char="1585" id="token-18-8" morph="none" pos="word" start_char="1584">to</TOKEN>
<TOKEN end_char="1593" id="token-18-9" morph="none" pos="word" start_char="1587">receive</TOKEN>
<TOKEN end_char="1603" id="token-18-10" morph="none" pos="word" start_char="1595">marketing</TOKEN>
<TOKEN end_char="1610" id="token-18-11" morph="none" pos="word" start_char="1605">emails</TOKEN>
<TOKEN end_char="1615" id="token-18-12" morph="none" pos="word" start_char="1612">from</TOKEN>
<TOKEN end_char="1623" id="token-18-13" morph="none" pos="word" start_char="1617">Insider</TOKEN>
<TOKEN end_char="1626" id="token-18-14" morph="none" pos="word" start_char="1625">as</TOKEN>
<TOKEN end_char="1631" id="token-18-15" morph="none" pos="word" start_char="1628">well</TOKEN>
<TOKEN end_char="1634" id="token-18-16" morph="none" pos="word" start_char="1633">as</TOKEN>
<TOKEN end_char="1640" id="token-18-17" morph="none" pos="word" start_char="1636">other</TOKEN>
<TOKEN end_char="1648" id="token-18-18" morph="none" pos="word" start_char="1642">partner</TOKEN>
<TOKEN end_char="1655" id="token-18-19" morph="none" pos="word" start_char="1650">offers</TOKEN>
<TOKEN end_char="1659" id="token-18-20" morph="none" pos="word" start_char="1657">and</TOKEN>
<TOKEN end_char="1666" id="token-18-21" morph="none" pos="word" start_char="1661">accept</TOKEN>
<TOKEN end_char="1670" id="token-18-22" morph="none" pos="word" start_char="1668">our</TOKEN>
<TOKEN end_char="1676" id="token-18-23" morph="none" pos="word" start_char="1672">Terms</TOKEN>
<TOKEN end_char="1679" id="token-18-24" morph="none" pos="word" start_char="1678">of</TOKEN>
<TOKEN end_char="1687" id="token-18-25" morph="none" pos="word" start_char="1681">Service</TOKEN>
<TOKEN end_char="1691" id="token-18-26" morph="none" pos="word" start_char="1689">and</TOKEN>
<TOKEN end_char="1699" id="token-18-27" morph="none" pos="word" start_char="1693">Privacy</TOKEN>
<TOKEN end_char="1706" id="token-18-28" morph="none" pos="word" start_char="1701">Policy</TOKEN>
<TOKEN end_char="1707" id="token-18-29" morph="none" pos="punct" start_char="1707">.</TOKEN>
</SEG>
<SEG end_char="1772" id="segment-19" start_char="1710">
<ORIGINAL_TEXT>New data about 'patient zero' is consistent with other research</ORIGINAL_TEXT>
<TOKEN end_char="1712" id="token-19-0" morph="none" pos="word" start_char="1710">New</TOKEN>
<TOKEN end_char="1717" id="token-19-1" morph="none" pos="word" start_char="1714">data</TOKEN>
<TOKEN end_char="1723" id="token-19-2" morph="none" pos="word" start_char="1719">about</TOKEN>
<TOKEN end_char="1725" id="token-19-3" morph="none" pos="punct" start_char="1725">'</TOKEN>
<TOKEN end_char="1732" id="token-19-4" morph="none" pos="word" start_char="1726">patient</TOKEN>
<TOKEN end_char="1737" id="token-19-5" morph="none" pos="word" start_char="1734">zero</TOKEN>
<TOKEN end_char="1738" id="token-19-6" morph="none" pos="punct" start_char="1738">'</TOKEN>
<TOKEN end_char="1741" id="token-19-7" morph="none" pos="word" start_char="1740">is</TOKEN>
<TOKEN end_char="1752" id="token-19-8" morph="none" pos="word" start_char="1743">consistent</TOKEN>
<TOKEN end_char="1757" id="token-19-9" morph="none" pos="word" start_char="1754">with</TOKEN>
<TOKEN end_char="1763" id="token-19-10" morph="none" pos="word" start_char="1759">other</TOKEN>
<TOKEN end_char="1772" id="token-19-11" morph="none" pos="word" start_char="1765">research</TOKEN>
</SEG>
<SEG end_char="1926" id="segment-20" start_char="1776">
<ORIGINAL_TEXT>Chinese health authorities reported the first case of COVID-19, the illness caused by the coronavirus, to the World Health Organization on December 31.</ORIGINAL_TEXT>
<TOKEN end_char="1782" id="token-20-0" morph="none" pos="word" start_char="1776">Chinese</TOKEN>
<TOKEN end_char="1789" id="token-20-1" morph="none" pos="word" start_char="1784">health</TOKEN>
<TOKEN end_char="1801" id="token-20-2" morph="none" pos="word" start_char="1791">authorities</TOKEN>
<TOKEN end_char="1810" id="token-20-3" morph="none" pos="word" start_char="1803">reported</TOKEN>
<TOKEN end_char="1814" id="token-20-4" morph="none" pos="word" start_char="1812">the</TOKEN>
<TOKEN end_char="1820" id="token-20-5" morph="none" pos="word" start_char="1816">first</TOKEN>
<TOKEN end_char="1825" id="token-20-6" morph="none" pos="word" start_char="1822">case</TOKEN>
<TOKEN end_char="1828" id="token-20-7" morph="none" pos="word" start_char="1827">of</TOKEN>
<TOKEN end_char="1837" id="token-20-8" morph="none" pos="unknown" start_char="1830">COVID-19</TOKEN>
<TOKEN end_char="1838" id="token-20-9" morph="none" pos="punct" start_char="1838">,</TOKEN>
<TOKEN end_char="1842" id="token-20-10" morph="none" pos="word" start_char="1840">the</TOKEN>
<TOKEN end_char="1850" id="token-20-11" morph="none" pos="word" start_char="1844">illness</TOKEN>
<TOKEN end_char="1857" id="token-20-12" morph="none" pos="word" start_char="1852">caused</TOKEN>
<TOKEN end_char="1860" id="token-20-13" morph="none" pos="word" start_char="1859">by</TOKEN>
<TOKEN end_char="1864" id="token-20-14" morph="none" pos="word" start_char="1862">the</TOKEN>
<TOKEN end_char="1876" id="token-20-15" morph="none" pos="word" start_char="1866">coronavirus</TOKEN>
<TOKEN end_char="1877" id="token-20-16" morph="none" pos="punct" start_char="1877">,</TOKEN>
<TOKEN end_char="1880" id="token-20-17" morph="none" pos="word" start_char="1879">to</TOKEN>
<TOKEN end_char="1884" id="token-20-18" morph="none" pos="word" start_char="1882">the</TOKEN>
<TOKEN end_char="1890" id="token-20-19" morph="none" pos="word" start_char="1886">World</TOKEN>
<TOKEN end_char="1897" id="token-20-20" morph="none" pos="word" start_char="1892">Health</TOKEN>
<TOKEN end_char="1910" id="token-20-21" morph="none" pos="word" start_char="1899">Organization</TOKEN>
<TOKEN end_char="1913" id="token-20-22" morph="none" pos="word" start_char="1912">on</TOKEN>
<TOKEN end_char="1922" id="token-20-23" morph="none" pos="word" start_char="1915">December</TOKEN>
<TOKEN end_char="1925" id="token-20-24" morph="none" pos="word" start_char="1924">31</TOKEN>
<TOKEN end_char="1926" id="token-20-25" morph="none" pos="punct" start_char="1926">.</TOKEN>
</SEG>
<SEG end_char="2087" id="segment-21" start_char="1929">
<ORIGINAL_TEXT>A team of researchers later published evidence that the first person to test positive was showing symptoms on December 8, the date of the first confirmed case.</ORIGINAL_TEXT>
<TOKEN end_char="1929" id="token-21-0" morph="none" pos="word" start_char="1929">A</TOKEN>
<TOKEN end_char="1934" id="token-21-1" morph="none" pos="word" start_char="1931">team</TOKEN>
<TOKEN end_char="1937" id="token-21-2" morph="none" pos="word" start_char="1936">of</TOKEN>
<TOKEN end_char="1949" id="token-21-3" morph="none" pos="word" start_char="1939">researchers</TOKEN>
<TOKEN end_char="1955" id="token-21-4" morph="none" pos="word" start_char="1951">later</TOKEN>
<TOKEN end_char="1965" id="token-21-5" morph="none" pos="word" start_char="1957">published</TOKEN>
<TOKEN end_char="1974" id="token-21-6" morph="none" pos="word" start_char="1967">evidence</TOKEN>
<TOKEN end_char="1979" id="token-21-7" morph="none" pos="word" start_char="1976">that</TOKEN>
<TOKEN end_char="1983" id="token-21-8" morph="none" pos="word" start_char="1981">the</TOKEN>
<TOKEN end_char="1989" id="token-21-9" morph="none" pos="word" start_char="1985">first</TOKEN>
<TOKEN end_char="1996" id="token-21-10" morph="none" pos="word" start_char="1991">person</TOKEN>
<TOKEN end_char="1999" id="token-21-11" morph="none" pos="word" start_char="1998">to</TOKEN>
<TOKEN end_char="2004" id="token-21-12" morph="none" pos="word" start_char="2001">test</TOKEN>
<TOKEN end_char="2013" id="token-21-13" morph="none" pos="word" start_char="2006">positive</TOKEN>
<TOKEN end_char="2017" id="token-21-14" morph="none" pos="word" start_char="2015">was</TOKEN>
<TOKEN end_char="2025" id="token-21-15" morph="none" pos="word" start_char="2019">showing</TOKEN>
<TOKEN end_char="2034" id="token-21-16" morph="none" pos="word" start_char="2027">symptoms</TOKEN>
<TOKEN end_char="2037" id="token-21-17" morph="none" pos="word" start_char="2036">on</TOKEN>
<TOKEN end_char="2046" id="token-21-18" morph="none" pos="word" start_char="2039">December</TOKEN>
<TOKEN end_char="2048" id="token-21-19" morph="none" pos="word" start_char="2048">8</TOKEN>
<TOKEN end_char="2049" id="token-21-20" morph="none" pos="punct" start_char="2049">,</TOKEN>
<TOKEN end_char="2053" id="token-21-21" morph="none" pos="word" start_char="2051">the</TOKEN>
<TOKEN end_char="2058" id="token-21-22" morph="none" pos="word" start_char="2055">date</TOKEN>
<TOKEN end_char="2061" id="token-21-23" morph="none" pos="word" start_char="2060">of</TOKEN>
<TOKEN end_char="2065" id="token-21-24" morph="none" pos="word" start_char="2063">the</TOKEN>
<TOKEN end_char="2071" id="token-21-25" morph="none" pos="word" start_char="2067">first</TOKEN>
<TOKEN end_char="2081" id="token-21-26" morph="none" pos="word" start_char="2073">confirmed</TOKEN>
<TOKEN end_char="2086" id="token-21-27" morph="none" pos="word" start_char="2083">case</TOKEN>
<TOKEN end_char="2087" id="token-21-28" morph="none" pos="punct" start_char="2087">.</TOKEN>
</SEG>
<SEG end_char="2223" id="segment-22" start_char="2090">
<ORIGINAL_TEXT>Other research published in The Lancet in January found that the first person to test positive was exposed to the virus on December 1.</ORIGINAL_TEXT>
<TOKEN end_char="2094" id="token-22-0" morph="none" pos="word" start_char="2090">Other</TOKEN>
<TOKEN end_char="2103" id="token-22-1" morph="none" pos="word" start_char="2096">research</TOKEN>
<TOKEN end_char="2113" id="token-22-2" morph="none" pos="word" start_char="2105">published</TOKEN>
<TOKEN end_char="2116" id="token-22-3" morph="none" pos="word" start_char="2115">in</TOKEN>
<TOKEN end_char="2120" id="token-22-4" morph="none" pos="word" start_char="2118">The</TOKEN>
<TOKEN end_char="2127" id="token-22-5" morph="none" pos="word" start_char="2122">Lancet</TOKEN>
<TOKEN end_char="2130" id="token-22-6" morph="none" pos="word" start_char="2129">in</TOKEN>
<TOKEN end_char="2138" id="token-22-7" morph="none" pos="word" start_char="2132">January</TOKEN>
<TOKEN end_char="2144" id="token-22-8" morph="none" pos="word" start_char="2140">found</TOKEN>
<TOKEN end_char="2149" id="token-22-9" morph="none" pos="word" start_char="2146">that</TOKEN>
<TOKEN end_char="2153" id="token-22-10" morph="none" pos="word" start_char="2151">the</TOKEN>
<TOKEN end_char="2159" id="token-22-11" morph="none" pos="word" start_char="2155">first</TOKEN>
<TOKEN end_char="2166" id="token-22-12" morph="none" pos="word" start_char="2161">person</TOKEN>
<TOKEN end_char="2169" id="token-22-13" morph="none" pos="word" start_char="2168">to</TOKEN>
<TOKEN end_char="2174" id="token-22-14" morph="none" pos="word" start_char="2171">test</TOKEN>
<TOKEN end_char="2183" id="token-22-15" morph="none" pos="word" start_char="2176">positive</TOKEN>
<TOKEN end_char="2187" id="token-22-16" morph="none" pos="word" start_char="2185">was</TOKEN>
<TOKEN end_char="2195" id="token-22-17" morph="none" pos="word" start_char="2189">exposed</TOKEN>
<TOKEN end_char="2198" id="token-22-18" morph="none" pos="word" start_char="2197">to</TOKEN>
<TOKEN end_char="2202" id="token-22-19" morph="none" pos="word" start_char="2200">the</TOKEN>
<TOKEN end_char="2208" id="token-22-20" morph="none" pos="word" start_char="2204">virus</TOKEN>
<TOKEN end_char="2211" id="token-22-21" morph="none" pos="word" start_char="2210">on</TOKEN>
<TOKEN end_char="2220" id="token-22-22" morph="none" pos="word" start_char="2213">December</TOKEN>
<TOKEN end_char="2222" id="token-22-23" morph="none" pos="word" start_char="2222">1</TOKEN>
<TOKEN end_char="2223" id="token-22-24" morph="none" pos="punct" start_char="2223">.</TOKEN>
</SEG>
<SEG end_char="2473" id="segment-23" start_char="2226">
<ORIGINAL_TEXT>The fact that researchers have continually hiked back the likely date of the earliest infection means there still may not be enough evidence to identify "patient zero," but the new Chinese government data reported by the Post sharpens what we know.</ORIGINAL_TEXT>
<TOKEN end_char="2228" id="token-23-0" morph="none" pos="word" start_char="2226">The</TOKEN>
<TOKEN end_char="2233" id="token-23-1" morph="none" pos="word" start_char="2230">fact</TOKEN>
<TOKEN end_char="2238" id="token-23-2" morph="none" pos="word" start_char="2235">that</TOKEN>
<TOKEN end_char="2250" id="token-23-3" morph="none" pos="word" start_char="2240">researchers</TOKEN>
<TOKEN end_char="2255" id="token-23-4" morph="none" pos="word" start_char="2252">have</TOKEN>
<TOKEN end_char="2267" id="token-23-5" morph="none" pos="word" start_char="2257">continually</TOKEN>
<TOKEN end_char="2273" id="token-23-6" morph="none" pos="word" start_char="2269">hiked</TOKEN>
<TOKEN end_char="2278" id="token-23-7" morph="none" pos="word" start_char="2275">back</TOKEN>
<TOKEN end_char="2282" id="token-23-8" morph="none" pos="word" start_char="2280">the</TOKEN>
<TOKEN end_char="2289" id="token-23-9" morph="none" pos="word" start_char="2284">likely</TOKEN>
<TOKEN end_char="2294" id="token-23-10" morph="none" pos="word" start_char="2291">date</TOKEN>
<TOKEN end_char="2297" id="token-23-11" morph="none" pos="word" start_char="2296">of</TOKEN>
<TOKEN end_char="2301" id="token-23-12" morph="none" pos="word" start_char="2299">the</TOKEN>
<TOKEN end_char="2310" id="token-23-13" morph="none" pos="word" start_char="2303">earliest</TOKEN>
<TOKEN end_char="2320" id="token-23-14" morph="none" pos="word" start_char="2312">infection</TOKEN>
<TOKEN end_char="2326" id="token-23-15" morph="none" pos="word" start_char="2322">means</TOKEN>
<TOKEN end_char="2332" id="token-23-16" morph="none" pos="word" start_char="2328">there</TOKEN>
<TOKEN end_char="2338" id="token-23-17" morph="none" pos="word" start_char="2334">still</TOKEN>
<TOKEN end_char="2342" id="token-23-18" morph="none" pos="word" start_char="2340">may</TOKEN>
<TOKEN end_char="2346" id="token-23-19" morph="none" pos="word" start_char="2344">not</TOKEN>
<TOKEN end_char="2349" id="token-23-20" morph="none" pos="word" start_char="2348">be</TOKEN>
<TOKEN end_char="2356" id="token-23-21" morph="none" pos="word" start_char="2351">enough</TOKEN>
<TOKEN end_char="2365" id="token-23-22" morph="none" pos="word" start_char="2358">evidence</TOKEN>
<TOKEN end_char="2368" id="token-23-23" morph="none" pos="word" start_char="2367">to</TOKEN>
<TOKEN end_char="2377" id="token-23-24" morph="none" pos="word" start_char="2370">identify</TOKEN>
<TOKEN end_char="2379" id="token-23-25" morph="none" pos="punct" start_char="2379">"</TOKEN>
<TOKEN end_char="2386" id="token-23-26" morph="none" pos="word" start_char="2380">patient</TOKEN>
<TOKEN end_char="2391" id="token-23-27" morph="none" pos="word" start_char="2388">zero</TOKEN>
<TOKEN end_char="2393" id="token-23-28" morph="none" pos="punct" start_char="2392">,"</TOKEN>
<TOKEN end_char="2397" id="token-23-29" morph="none" pos="word" start_char="2395">but</TOKEN>
<TOKEN end_char="2401" id="token-23-30" morph="none" pos="word" start_char="2399">the</TOKEN>
<TOKEN end_char="2405" id="token-23-31" morph="none" pos="word" start_char="2403">new</TOKEN>
<TOKEN end_char="2413" id="token-23-32" morph="none" pos="word" start_char="2407">Chinese</TOKEN>
<TOKEN end_char="2424" id="token-23-33" morph="none" pos="word" start_char="2415">government</TOKEN>
<TOKEN end_char="2429" id="token-23-34" morph="none" pos="word" start_char="2426">data</TOKEN>
<TOKEN end_char="2438" id="token-23-35" morph="none" pos="word" start_char="2431">reported</TOKEN>
<TOKEN end_char="2441" id="token-23-36" morph="none" pos="word" start_char="2440">by</TOKEN>
<TOKEN end_char="2445" id="token-23-37" morph="none" pos="word" start_char="2443">the</TOKEN>
<TOKEN end_char="2450" id="token-23-38" morph="none" pos="word" start_char="2447">Post</TOKEN>
<TOKEN end_char="2459" id="token-23-39" morph="none" pos="word" start_char="2452">sharpens</TOKEN>
<TOKEN end_char="2464" id="token-23-40" morph="none" pos="word" start_char="2461">what</TOKEN>
<TOKEN end_char="2467" id="token-23-41" morph="none" pos="word" start_char="2466">we</TOKEN>
<TOKEN end_char="2472" id="token-23-42" morph="none" pos="word" start_char="2469">know</TOKEN>
<TOKEN end_char="2473" id="token-23-43" morph="none" pos="punct" start_char="2473">.</TOKEN>
</SEG>
<SEG end_char="2561" id="segment-24" start_char="2477">
<ORIGINAL_TEXT>A doctor examines a patient with the novel coronavirus at a hospital in Wuhan, China.</ORIGINAL_TEXT>
<TOKEN end_char="2477" id="token-24-0" morph="none" pos="word" start_char="2477">A</TOKEN>
<TOKEN end_char="2484" id="token-24-1" morph="none" pos="word" start_char="2479">doctor</TOKEN>
<TOKEN end_char="2493" id="token-24-2" morph="none" pos="word" start_char="2486">examines</TOKEN>
<TOKEN end_char="2495" id="token-24-3" morph="none" pos="word" start_char="2495">a</TOKEN>
<TOKEN end_char="2503" id="token-24-4" morph="none" pos="word" start_char="2497">patient</TOKEN>
<TOKEN end_char="2508" id="token-24-5" morph="none" pos="word" start_char="2505">with</TOKEN>
<TOKEN end_char="2512" id="token-24-6" morph="none" pos="word" start_char="2510">the</TOKEN>
<TOKEN end_char="2518" id="token-24-7" morph="none" pos="word" start_char="2514">novel</TOKEN>
<TOKEN end_char="2530" id="token-24-8" morph="none" pos="word" start_char="2520">coronavirus</TOKEN>
<TOKEN end_char="2533" id="token-24-9" morph="none" pos="word" start_char="2532">at</TOKEN>
<TOKEN end_char="2535" id="token-24-10" morph="none" pos="word" start_char="2535">a</TOKEN>
<TOKEN end_char="2544" id="token-24-11" morph="none" pos="word" start_char="2537">hospital</TOKEN>
<TOKEN end_char="2547" id="token-24-12" morph="none" pos="word" start_char="2546">in</TOKEN>
<TOKEN end_char="2553" id="token-24-13" morph="none" pos="word" start_char="2549">Wuhan</TOKEN>
<TOKEN end_char="2554" id="token-24-14" morph="none" pos="punct" start_char="2554">,</TOKEN>
<TOKEN end_char="2560" id="token-24-15" morph="none" pos="word" start_char="2556">China</TOKEN>
<TOKEN end_char="2561" id="token-24-16" morph="none" pos="punct" start_char="2561">.</TOKEN>
</SEG>
<SEG end_char="2587" id="segment-25" start_char="2564">
<ORIGINAL_TEXT>STR/AFP via Getty Images</ORIGINAL_TEXT>
<TOKEN end_char="2570" id="token-25-0" morph="none" pos="unknown" start_char="2564">STR/AFP</TOKEN>
<TOKEN end_char="2574" id="token-25-1" morph="none" pos="word" start_char="2572">via</TOKEN>
<TOKEN end_char="2580" id="token-25-2" morph="none" pos="word" start_char="2576">Getty</TOKEN>
<TOKEN end_char="2587" id="token-25-3" morph="none" pos="word" start_char="2582">Images</TOKEN>
</SEG>
<SEG end_char="2823" id="segment-26" start_char="2591">
<ORIGINAL_TEXT>Research published last month by a team of infectious-disease researchers from China found that WeChat users were using terms related to symptoms of the novel coronavirus more than two weeks before officials confirmed the first case.</ORIGINAL_TEXT>
<TOKEN end_char="2598" id="token-26-0" morph="none" pos="word" start_char="2591">Research</TOKEN>
<TOKEN end_char="2608" id="token-26-1" morph="none" pos="word" start_char="2600">published</TOKEN>
<TOKEN end_char="2613" id="token-26-2" morph="none" pos="word" start_char="2610">last</TOKEN>
<TOKEN end_char="2619" id="token-26-3" morph="none" pos="word" start_char="2615">month</TOKEN>
<TOKEN end_char="2622" id="token-26-4" morph="none" pos="word" start_char="2621">by</TOKEN>
<TOKEN end_char="2624" id="token-26-5" morph="none" pos="word" start_char="2624">a</TOKEN>
<TOKEN end_char="2629" id="token-26-6" morph="none" pos="word" start_char="2626">team</TOKEN>
<TOKEN end_char="2632" id="token-26-7" morph="none" pos="word" start_char="2631">of</TOKEN>
<TOKEN end_char="2651" id="token-26-8" morph="none" pos="unknown" start_char="2634">infectious-disease</TOKEN>
<TOKEN end_char="2663" id="token-26-9" morph="none" pos="word" start_char="2653">researchers</TOKEN>
<TOKEN end_char="2668" id="token-26-10" morph="none" pos="word" start_char="2665">from</TOKEN>
<TOKEN end_char="2674" id="token-26-11" morph="none" pos="word" start_char="2670">China</TOKEN>
<TOKEN end_char="2680" id="token-26-12" morph="none" pos="word" start_char="2676">found</TOKEN>
<TOKEN end_char="2685" id="token-26-13" morph="none" pos="word" start_char="2682">that</TOKEN>
<TOKEN end_char="2692" id="token-26-14" morph="none" pos="word" start_char="2687">WeChat</TOKEN>
<TOKEN end_char="2698" id="token-26-15" morph="none" pos="word" start_char="2694">users</TOKEN>
<TOKEN end_char="2703" id="token-26-16" morph="none" pos="word" start_char="2700">were</TOKEN>
<TOKEN end_char="2709" id="token-26-17" morph="none" pos="word" start_char="2705">using</TOKEN>
<TOKEN end_char="2715" id="token-26-18" morph="none" pos="word" start_char="2711">terms</TOKEN>
<TOKEN end_char="2723" id="token-26-19" morph="none" pos="word" start_char="2717">related</TOKEN>
<TOKEN end_char="2726" id="token-26-20" morph="none" pos="word" start_char="2725">to</TOKEN>
<TOKEN end_char="2735" id="token-26-21" morph="none" pos="word" start_char="2728">symptoms</TOKEN>
<TOKEN end_char="2738" id="token-26-22" morph="none" pos="word" start_char="2737">of</TOKEN>
<TOKEN end_char="2742" id="token-26-23" morph="none" pos="word" start_char="2740">the</TOKEN>
<TOKEN end_char="2748" id="token-26-24" morph="none" pos="word" start_char="2744">novel</TOKEN>
<TOKEN end_char="2760" id="token-26-25" morph="none" pos="word" start_char="2750">coronavirus</TOKEN>
<TOKEN end_char="2765" id="token-26-26" morph="none" pos="word" start_char="2762">more</TOKEN>
<TOKEN end_char="2770" id="token-26-27" morph="none" pos="word" start_char="2767">than</TOKEN>
<TOKEN end_char="2774" id="token-26-28" morph="none" pos="word" start_char="2772">two</TOKEN>
<TOKEN end_char="2780" id="token-26-29" morph="none" pos="word" start_char="2776">weeks</TOKEN>
<TOKEN end_char="2787" id="token-26-30" morph="none" pos="word" start_char="2782">before</TOKEN>
<TOKEN end_char="2797" id="token-26-31" morph="none" pos="word" start_char="2789">officials</TOKEN>
<TOKEN end_char="2807" id="token-26-32" morph="none" pos="word" start_char="2799">confirmed</TOKEN>
<TOKEN end_char="2811" id="token-26-33" morph="none" pos="word" start_char="2809">the</TOKEN>
<TOKEN end_char="2817" id="token-26-34" morph="none" pos="word" start_char="2813">first</TOKEN>
<TOKEN end_char="2822" id="token-26-35" morph="none" pos="word" start_char="2819">case</TOKEN>
<TOKEN end_char="2823" id="token-26-36" morph="none" pos="punct" start_char="2823">.</TOKEN>
</SEG>
<SEG end_char="3002" id="segment-27" start_char="2826">
<ORIGINAL_TEXT>"The findings might indicate that the coronavirus started circulating weeks before the first cases were officially diagnosed and reported," Business Insider's Holly Secon wrote.</ORIGINAL_TEXT>
<TOKEN end_char="2826" id="token-27-0" morph="none" pos="punct" start_char="2826">"</TOKEN>
<TOKEN end_char="2829" id="token-27-1" morph="none" pos="word" start_char="2827">The</TOKEN>
<TOKEN end_char="2838" id="token-27-2" morph="none" pos="word" start_char="2831">findings</TOKEN>
<TOKEN end_char="2844" id="token-27-3" morph="none" pos="word" start_char="2840">might</TOKEN>
<TOKEN end_char="2853" id="token-27-4" morph="none" pos="word" start_char="2846">indicate</TOKEN>
<TOKEN end_char="2858" id="token-27-5" morph="none" pos="word" start_char="2855">that</TOKEN>
<TOKEN end_char="2862" id="token-27-6" morph="none" pos="word" start_char="2860">the</TOKEN>
<TOKEN end_char="2874" id="token-27-7" morph="none" pos="word" start_char="2864">coronavirus</TOKEN>
<TOKEN end_char="2882" id="token-27-8" morph="none" pos="word" start_char="2876">started</TOKEN>
<TOKEN end_char="2894" id="token-27-9" morph="none" pos="word" start_char="2884">circulating</TOKEN>
<TOKEN end_char="2900" id="token-27-10" morph="none" pos="word" start_char="2896">weeks</TOKEN>
<TOKEN end_char="2907" id="token-27-11" morph="none" pos="word" start_char="2902">before</TOKEN>
<TOKEN end_char="2911" id="token-27-12" morph="none" pos="word" start_char="2909">the</TOKEN>
<TOKEN end_char="2917" id="token-27-13" morph="none" pos="word" start_char="2913">first</TOKEN>
<TOKEN end_char="2923" id="token-27-14" morph="none" pos="word" start_char="2919">cases</TOKEN>
<TOKEN end_char="2928" id="token-27-15" morph="none" pos="word" start_char="2925">were</TOKEN>
<TOKEN end_char="2939" id="token-27-16" morph="none" pos="word" start_char="2930">officially</TOKEN>
<TOKEN end_char="2949" id="token-27-17" morph="none" pos="word" start_char="2941">diagnosed</TOKEN>
<TOKEN end_char="2953" id="token-27-18" morph="none" pos="word" start_char="2951">and</TOKEN>
<TOKEN end_char="2962" id="token-27-19" morph="none" pos="word" start_char="2955">reported</TOKEN>
<TOKEN end_char="2964" id="token-27-20" morph="none" pos="punct" start_char="2963">,"</TOKEN>
<TOKEN end_char="2973" id="token-27-21" morph="none" pos="word" start_char="2966">Business</TOKEN>
<TOKEN end_char="2983" id="token-27-22" morph="none" pos="word" start_char="2975">Insider's</TOKEN>
<TOKEN end_char="2989" id="token-27-23" morph="none" pos="word" start_char="2985">Holly</TOKEN>
<TOKEN end_char="2995" id="token-27-24" morph="none" pos="word" start_char="2991">Secon</TOKEN>
<TOKEN end_char="3001" id="token-27-25" morph="none" pos="word" start_char="2997">wrote</TOKEN>
<TOKEN end_char="3002" id="token-27-26" morph="none" pos="punct" start_char="3002">.</TOKEN>
</SEG>
<SEG end_char="3139" id="segment-28" start_char="3005">
<ORIGINAL_TEXT>The research lends further support to the finding that the earliest case of the novel coronavirus did indeed originate in mid-November.</ORIGINAL_TEXT>
<TOKEN end_char="3007" id="token-28-0" morph="none" pos="word" start_char="3005">The</TOKEN>
<TOKEN end_char="3016" id="token-28-1" morph="none" pos="word" start_char="3009">research</TOKEN>
<TOKEN end_char="3022" id="token-28-2" morph="none" pos="word" start_char="3018">lends</TOKEN>
<TOKEN end_char="3030" id="token-28-3" morph="none" pos="word" start_char="3024">further</TOKEN>
<TOKEN end_char="3038" id="token-28-4" morph="none" pos="word" start_char="3032">support</TOKEN>
<TOKEN end_char="3041" id="token-28-5" morph="none" pos="word" start_char="3040">to</TOKEN>
<TOKEN end_char="3045" id="token-28-6" morph="none" pos="word" start_char="3043">the</TOKEN>
<TOKEN end_char="3053" id="token-28-7" morph="none" pos="word" start_char="3047">finding</TOKEN>
<TOKEN end_char="3058" id="token-28-8" morph="none" pos="word" start_char="3055">that</TOKEN>
<TOKEN end_char="3062" id="token-28-9" morph="none" pos="word" start_char="3060">the</TOKEN>
<TOKEN end_char="3071" id="token-28-10" morph="none" pos="word" start_char="3064">earliest</TOKEN>
<TOKEN end_char="3076" id="token-28-11" morph="none" pos="word" start_char="3073">case</TOKEN>
<TOKEN end_char="3079" id="token-28-12" morph="none" pos="word" start_char="3078">of</TOKEN>
<TOKEN end_char="3083" id="token-28-13" morph="none" pos="word" start_char="3081">the</TOKEN>
<TOKEN end_char="3089" id="token-28-14" morph="none" pos="word" start_char="3085">novel</TOKEN>
<TOKEN end_char="3101" id="token-28-15" morph="none" pos="word" start_char="3091">coronavirus</TOKEN>
<TOKEN end_char="3105" id="token-28-16" morph="none" pos="word" start_char="3103">did</TOKEN>
<TOKEN end_char="3112" id="token-28-17" morph="none" pos="word" start_char="3107">indeed</TOKEN>
<TOKEN end_char="3122" id="token-28-18" morph="none" pos="word" start_char="3114">originate</TOKEN>
<TOKEN end_char="3125" id="token-28-19" morph="none" pos="word" start_char="3124">in</TOKEN>
<TOKEN end_char="3138" id="token-28-20" morph="none" pos="unknown" start_char="3127">mid-November</TOKEN>
<TOKEN end_char="3139" id="token-28-21" morph="none" pos="punct" start_char="3139">.</TOKEN>
</SEG>
<SEG end_char="3203" id="segment-29" start_char="3142">
<ORIGINAL_TEXT>Identifying patient zero is important for containing the virus</ORIGINAL_TEXT>
<TOKEN end_char="3152" id="token-29-0" morph="none" pos="word" start_char="3142">Identifying</TOKEN>
<TOKEN end_char="3160" id="token-29-1" morph="none" pos="word" start_char="3154">patient</TOKEN>
<TOKEN end_char="3165" id="token-29-2" morph="none" pos="word" start_char="3162">zero</TOKEN>
<TOKEN end_char="3168" id="token-29-3" morph="none" pos="word" start_char="3167">is</TOKEN>
<TOKEN end_char="3178" id="token-29-4" morph="none" pos="word" start_char="3170">important</TOKEN>
<TOKEN end_char="3182" id="token-29-5" morph="none" pos="word" start_char="3180">for</TOKEN>
<TOKEN end_char="3193" id="token-29-6" morph="none" pos="word" start_char="3184">containing</TOKEN>
<TOKEN end_char="3197" id="token-29-7" morph="none" pos="word" start_char="3195">the</TOKEN>
<TOKEN end_char="3203" id="token-29-8" morph="none" pos="word" start_char="3199">virus</TOKEN>
</SEG>
<SEG end_char="3389" id="segment-30" start_char="3207">
<ORIGINAL_TEXT>As officials try to identify patient zero, the new government data reported by the Post provides clues about the emergence and spread of a virus that has thrown the world into tumult.</ORIGINAL_TEXT>
<TOKEN end_char="3208" id="token-30-0" morph="none" pos="word" start_char="3207">As</TOKEN>
<TOKEN end_char="3218" id="token-30-1" morph="none" pos="word" start_char="3210">officials</TOKEN>
<TOKEN end_char="3222" id="token-30-2" morph="none" pos="word" start_char="3220">try</TOKEN>
<TOKEN end_char="3225" id="token-30-3" morph="none" pos="word" start_char="3224">to</TOKEN>
<TOKEN end_char="3234" id="token-30-4" morph="none" pos="word" start_char="3227">identify</TOKEN>
<TOKEN end_char="3242" id="token-30-5" morph="none" pos="word" start_char="3236">patient</TOKEN>
<TOKEN end_char="3247" id="token-30-6" morph="none" pos="word" start_char="3244">zero</TOKEN>
<TOKEN end_char="3248" id="token-30-7" morph="none" pos="punct" start_char="3248">,</TOKEN>
<TOKEN end_char="3252" id="token-30-8" morph="none" pos="word" start_char="3250">the</TOKEN>
<TOKEN end_char="3256" id="token-30-9" morph="none" pos="word" start_char="3254">new</TOKEN>
<TOKEN end_char="3267" id="token-30-10" morph="none" pos="word" start_char="3258">government</TOKEN>
<TOKEN end_char="3272" id="token-30-11" morph="none" pos="word" start_char="3269">data</TOKEN>
<TOKEN end_char="3281" id="token-30-12" morph="none" pos="word" start_char="3274">reported</TOKEN>
<TOKEN end_char="3284" id="token-30-13" morph="none" pos="word" start_char="3283">by</TOKEN>
<TOKEN end_char="3288" id="token-30-14" morph="none" pos="word" start_char="3286">the</TOKEN>
<TOKEN end_char="3293" id="token-30-15" morph="none" pos="word" start_char="3290">Post</TOKEN>
<TOKEN end_char="3302" id="token-30-16" morph="none" pos="word" start_char="3295">provides</TOKEN>
<TOKEN end_char="3308" id="token-30-17" morph="none" pos="word" start_char="3304">clues</TOKEN>
<TOKEN end_char="3314" id="token-30-18" morph="none" pos="word" start_char="3310">about</TOKEN>
<TOKEN end_char="3318" id="token-30-19" morph="none" pos="word" start_char="3316">the</TOKEN>
<TOKEN end_char="3328" id="token-30-20" morph="none" pos="word" start_char="3320">emergence</TOKEN>
<TOKEN end_char="3332" id="token-30-21" morph="none" pos="word" start_char="3330">and</TOKEN>
<TOKEN end_char="3339" id="token-30-22" morph="none" pos="word" start_char="3334">spread</TOKEN>
<TOKEN end_char="3342" id="token-30-23" morph="none" pos="word" start_char="3341">of</TOKEN>
<TOKEN end_char="3344" id="token-30-24" morph="none" pos="word" start_char="3344">a</TOKEN>
<TOKEN end_char="3350" id="token-30-25" morph="none" pos="word" start_char="3346">virus</TOKEN>
<TOKEN end_char="3355" id="token-30-26" morph="none" pos="word" start_char="3352">that</TOKEN>
<TOKEN end_char="3359" id="token-30-27" morph="none" pos="word" start_char="3357">has</TOKEN>
<TOKEN end_char="3366" id="token-30-28" morph="none" pos="word" start_char="3361">thrown</TOKEN>
<TOKEN end_char="3370" id="token-30-29" morph="none" pos="word" start_char="3368">the</TOKEN>
<TOKEN end_char="3376" id="token-30-30" morph="none" pos="word" start_char="3372">world</TOKEN>
<TOKEN end_char="3381" id="token-30-31" morph="none" pos="word" start_char="3378">into</TOKEN>
<TOKEN end_char="3388" id="token-30-32" morph="none" pos="word" start_char="3383">tumult</TOKEN>
<TOKEN end_char="3389" id="token-30-33" morph="none" pos="punct" start_char="3389">.</TOKEN>
</SEG>
<SEG end_char="3668" id="segment-31" start_char="3392">
<ORIGINAL_TEXT>"We don't know who the very first patient zero was, presumably in Wuhan, and that leaves a lot of unanswered questions about how the outbreak started and how it initially spread," Sarah Borwein, a doctor at Hong Kong's Central Health Medical Practice, told the Post last month.</ORIGINAL_TEXT>
<TOKEN end_char="3392" id="token-31-0" morph="none" pos="punct" start_char="3392">"</TOKEN>
<TOKEN end_char="3394" id="token-31-1" morph="none" pos="word" start_char="3393">We</TOKEN>
<TOKEN end_char="3400" id="token-31-2" morph="none" pos="word" start_char="3396">don't</TOKEN>
<TOKEN end_char="3405" id="token-31-3" morph="none" pos="word" start_char="3402">know</TOKEN>
<TOKEN end_char="3409" id="token-31-4" morph="none" pos="word" start_char="3407">who</TOKEN>
<TOKEN end_char="3413" id="token-31-5" morph="none" pos="word" start_char="3411">the</TOKEN>
<TOKEN end_char="3418" id="token-31-6" morph="none" pos="word" start_char="3415">very</TOKEN>
<TOKEN end_char="3424" id="token-31-7" morph="none" pos="word" start_char="3420">first</TOKEN>
<TOKEN end_char="3432" id="token-31-8" morph="none" pos="word" start_char="3426">patient</TOKEN>
<TOKEN end_char="3437" id="token-31-9" morph="none" pos="word" start_char="3434">zero</TOKEN>
<TOKEN end_char="3441" id="token-31-10" morph="none" pos="word" start_char="3439">was</TOKEN>
<TOKEN end_char="3442" id="token-31-11" morph="none" pos="punct" start_char="3442">,</TOKEN>
<TOKEN end_char="3453" id="token-31-12" morph="none" pos="word" start_char="3444">presumably</TOKEN>
<TOKEN end_char="3456" id="token-31-13" morph="none" pos="word" start_char="3455">in</TOKEN>
<TOKEN end_char="3462" id="token-31-14" morph="none" pos="word" start_char="3458">Wuhan</TOKEN>
<TOKEN end_char="3463" id="token-31-15" morph="none" pos="punct" start_char="3463">,</TOKEN>
<TOKEN end_char="3467" id="token-31-16" morph="none" pos="word" start_char="3465">and</TOKEN>
<TOKEN end_char="3472" id="token-31-17" morph="none" pos="word" start_char="3469">that</TOKEN>
<TOKEN end_char="3479" id="token-31-18" morph="none" pos="word" start_char="3474">leaves</TOKEN>
<TOKEN end_char="3481" id="token-31-19" morph="none" pos="word" start_char="3481">a</TOKEN>
<TOKEN end_char="3485" id="token-31-20" morph="none" pos="word" start_char="3483">lot</TOKEN>
<TOKEN end_char="3488" id="token-31-21" morph="none" pos="word" start_char="3487">of</TOKEN>
<TOKEN end_char="3499" id="token-31-22" morph="none" pos="word" start_char="3490">unanswered</TOKEN>
<TOKEN end_char="3509" id="token-31-23" morph="none" pos="word" start_char="3501">questions</TOKEN>
<TOKEN end_char="3515" id="token-31-24" morph="none" pos="word" start_char="3511">about</TOKEN>
<TOKEN end_char="3519" id="token-31-25" morph="none" pos="word" start_char="3517">how</TOKEN>
<TOKEN end_char="3523" id="token-31-26" morph="none" pos="word" start_char="3521">the</TOKEN>
<TOKEN end_char="3532" id="token-31-27" morph="none" pos="word" start_char="3525">outbreak</TOKEN>
<TOKEN end_char="3540" id="token-31-28" morph="none" pos="word" start_char="3534">started</TOKEN>
<TOKEN end_char="3544" id="token-31-29" morph="none" pos="word" start_char="3542">and</TOKEN>
<TOKEN end_char="3548" id="token-31-30" morph="none" pos="word" start_char="3546">how</TOKEN>
<TOKEN end_char="3551" id="token-31-31" morph="none" pos="word" start_char="3550">it</TOKEN>
<TOKEN end_char="3561" id="token-31-32" morph="none" pos="word" start_char="3553">initially</TOKEN>
<TOKEN end_char="3568" id="token-31-33" morph="none" pos="word" start_char="3563">spread</TOKEN>
<TOKEN end_char="3570" id="token-31-34" morph="none" pos="punct" start_char="3569">,"</TOKEN>
<TOKEN end_char="3576" id="token-31-35" morph="none" pos="word" start_char="3572">Sarah</TOKEN>
<TOKEN end_char="3584" id="token-31-36" morph="none" pos="word" start_char="3578">Borwein</TOKEN>
<TOKEN end_char="3585" id="token-31-37" morph="none" pos="punct" start_char="3585">,</TOKEN>
<TOKEN end_char="3587" id="token-31-38" morph="none" pos="word" start_char="3587">a</TOKEN>
<TOKEN end_char="3594" id="token-31-39" morph="none" pos="word" start_char="3589">doctor</TOKEN>
<TOKEN end_char="3597" id="token-31-40" morph="none" pos="word" start_char="3596">at</TOKEN>
<TOKEN end_char="3602" id="token-31-41" morph="none" pos="word" start_char="3599">Hong</TOKEN>
<TOKEN end_char="3609" id="token-31-42" morph="none" pos="word" start_char="3604">Kong's</TOKEN>
<TOKEN end_char="3617" id="token-31-43" morph="none" pos="word" start_char="3611">Central</TOKEN>
<TOKEN end_char="3624" id="token-31-44" morph="none" pos="word" start_char="3619">Health</TOKEN>
<TOKEN end_char="3632" id="token-31-45" morph="none" pos="word" start_char="3626">Medical</TOKEN>
<TOKEN end_char="3641" id="token-31-46" morph="none" pos="word" start_char="3634">Practice</TOKEN>
<TOKEN end_char="3642" id="token-31-47" morph="none" pos="punct" start_char="3642">,</TOKEN>
<TOKEN end_char="3647" id="token-31-48" morph="none" pos="word" start_char="3644">told</TOKEN>
<TOKEN end_char="3651" id="token-31-49" morph="none" pos="word" start_char="3649">the</TOKEN>
<TOKEN end_char="3656" id="token-31-50" morph="none" pos="word" start_char="3653">Post</TOKEN>
<TOKEN end_char="3661" id="token-31-51" morph="none" pos="word" start_char="3658">last</TOKEN>
<TOKEN end_char="3667" id="token-31-52" morph="none" pos="word" start_char="3663">month</TOKEN>
<TOKEN end_char="3668" id="token-31-53" morph="none" pos="punct" start_char="3668">.</TOKEN>
</SEG>
<SEG end_char="3787" id="segment-32" start_char="3672">
<ORIGINAL_TEXT>Members of a police sanitation team spraying disinfectant to prevent the spread of the coronavirus in Bozhou, China.</ORIGINAL_TEXT>
<TOKEN end_char="3678" id="token-32-0" morph="none" pos="word" start_char="3672">Members</TOKEN>
<TOKEN end_char="3681" id="token-32-1" morph="none" pos="word" start_char="3680">of</TOKEN>
<TOKEN end_char="3683" id="token-32-2" morph="none" pos="word" start_char="3683">a</TOKEN>
<TOKEN end_char="3690" id="token-32-3" morph="none" pos="word" start_char="3685">police</TOKEN>
<TOKEN end_char="3701" id="token-32-4" morph="none" pos="word" start_char="3692">sanitation</TOKEN>
<TOKEN end_char="3706" id="token-32-5" morph="none" pos="word" start_char="3703">team</TOKEN>
<TOKEN end_char="3715" id="token-32-6" morph="none" pos="word" start_char="3708">spraying</TOKEN>
<TOKEN end_char="3728" id="token-32-7" morph="none" pos="word" start_char="3717">disinfectant</TOKEN>
<TOKEN end_char="3731" id="token-32-8" morph="none" pos="word" start_char="3730">to</TOKEN>
<TOKEN end_char="3739" id="token-32-9" morph="none" pos="word" start_char="3733">prevent</TOKEN>
<TOKEN end_char="3743" id="token-32-10" morph="none" pos="word" start_char="3741">the</TOKEN>
<TOKEN end_char="3750" id="token-32-11" morph="none" pos="word" start_char="3745">spread</TOKEN>
<TOKEN end_char="3753" id="token-32-12" morph="none" pos="word" start_char="3752">of</TOKEN>
<TOKEN end_char="3757" id="token-32-13" morph="none" pos="word" start_char="3755">the</TOKEN>
<TOKEN end_char="3769" id="token-32-14" morph="none" pos="word" start_char="3759">coronavirus</TOKEN>
<TOKEN end_char="3772" id="token-32-15" morph="none" pos="word" start_char="3771">in</TOKEN>
<TOKEN end_char="3779" id="token-32-16" morph="none" pos="word" start_char="3774">Bozhou</TOKEN>
<TOKEN end_char="3780" id="token-32-17" morph="none" pos="punct" start_char="3780">,</TOKEN>
<TOKEN end_char="3786" id="token-32-18" morph="none" pos="word" start_char="3782">China</TOKEN>
<TOKEN end_char="3787" id="token-32-19" morph="none" pos="punct" start_char="3787">.</TOKEN>
</SEG>
<SEG end_char="3813" id="segment-33" start_char="3790">
<ORIGINAL_TEXT>STR/AFP via Getty Images</ORIGINAL_TEXT>
<TOKEN end_char="3796" id="token-33-0" morph="none" pos="unknown" start_char="3790">STR/AFP</TOKEN>
<TOKEN end_char="3800" id="token-33-1" morph="none" pos="word" start_char="3798">via</TOKEN>
<TOKEN end_char="3806" id="token-33-2" morph="none" pos="word" start_char="3802">Getty</TOKEN>
<TOKEN end_char="3813" id="token-33-3" morph="none" pos="word" start_char="3808">Images</TOKEN>
</SEG>
<SEG end_char="3953" id="segment-34" start_char="3817">
<ORIGINAL_TEXT>For experts, finding patient zero is not simply a matter of digging through data and conducting research — it's a race against the clock.</ORIGINAL_TEXT>
<TOKEN end_char="3819" id="token-34-0" morph="none" pos="word" start_char="3817">For</TOKEN>
<TOKEN end_char="3827" id="token-34-1" morph="none" pos="word" start_char="3821">experts</TOKEN>
<TOKEN end_char="3828" id="token-34-2" morph="none" pos="punct" start_char="3828">,</TOKEN>
<TOKEN end_char="3836" id="token-34-3" morph="none" pos="word" start_char="3830">finding</TOKEN>
<TOKEN end_char="3844" id="token-34-4" morph="none" pos="word" start_char="3838">patient</TOKEN>
<TOKEN end_char="3849" id="token-34-5" morph="none" pos="word" start_char="3846">zero</TOKEN>
<TOKEN end_char="3852" id="token-34-6" morph="none" pos="word" start_char="3851">is</TOKEN>
<TOKEN end_char="3856" id="token-34-7" morph="none" pos="word" start_char="3854">not</TOKEN>
<TOKEN end_char="3863" id="token-34-8" morph="none" pos="word" start_char="3858">simply</TOKEN>
<TOKEN end_char="3865" id="token-34-9" morph="none" pos="word" start_char="3865">a</TOKEN>
<TOKEN end_char="3872" id="token-34-10" morph="none" pos="word" start_char="3867">matter</TOKEN>
<TOKEN end_char="3875" id="token-34-11" morph="none" pos="word" start_char="3874">of</TOKEN>
<TOKEN end_char="3883" id="token-34-12" morph="none" pos="word" start_char="3877">digging</TOKEN>
<TOKEN end_char="3891" id="token-34-13" morph="none" pos="word" start_char="3885">through</TOKEN>
<TOKEN end_char="3896" id="token-34-14" morph="none" pos="word" start_char="3893">data</TOKEN>
<TOKEN end_char="3900" id="token-34-15" morph="none" pos="word" start_char="3898">and</TOKEN>
<TOKEN end_char="3911" id="token-34-16" morph="none" pos="word" start_char="3902">conducting</TOKEN>
<TOKEN end_char="3920" id="token-34-17" morph="none" pos="word" start_char="3913">research</TOKEN>
<TOKEN end_char="3922" id="token-34-18" morph="none" pos="punct" start_char="3922">—</TOKEN>
<TOKEN end_char="3927" id="token-34-19" morph="none" pos="word" start_char="3924">it's</TOKEN>
<TOKEN end_char="3929" id="token-34-20" morph="none" pos="word" start_char="3929">a</TOKEN>
<TOKEN end_char="3934" id="token-34-21" morph="none" pos="word" start_char="3931">race</TOKEN>
<TOKEN end_char="3942" id="token-34-22" morph="none" pos="word" start_char="3936">against</TOKEN>
<TOKEN end_char="3946" id="token-34-23" morph="none" pos="word" start_char="3944">the</TOKEN>
<TOKEN end_char="3952" id="token-34-24" morph="none" pos="word" start_char="3948">clock</TOKEN>
<TOKEN end_char="3953" id="token-34-25" morph="none" pos="punct" start_char="3953">.</TOKEN>
</SEG>
<SEG end_char="4108" id="segment-35" start_char="3956">
<ORIGINAL_TEXT>As the number of infections increases, it becomes more difficult to identify that person — and the areas that have been exposed to the virus the longest.</ORIGINAL_TEXT>
<TOKEN end_char="3957" id="token-35-0" morph="none" pos="word" start_char="3956">As</TOKEN>
<TOKEN end_char="3961" id="token-35-1" morph="none" pos="word" start_char="3959">the</TOKEN>
<TOKEN end_char="3968" id="token-35-2" morph="none" pos="word" start_char="3963">number</TOKEN>
<TOKEN end_char="3971" id="token-35-3" morph="none" pos="word" start_char="3970">of</TOKEN>
<TOKEN end_char="3982" id="token-35-4" morph="none" pos="word" start_char="3973">infections</TOKEN>
<TOKEN end_char="3992" id="token-35-5" morph="none" pos="word" start_char="3984">increases</TOKEN>
<TOKEN end_char="3993" id="token-35-6" morph="none" pos="punct" start_char="3993">,</TOKEN>
<TOKEN end_char="3996" id="token-35-7" morph="none" pos="word" start_char="3995">it</TOKEN>
<TOKEN end_char="4004" id="token-35-8" morph="none" pos="word" start_char="3998">becomes</TOKEN>
<TOKEN end_char="4009" id="token-35-9" morph="none" pos="word" start_char="4006">more</TOKEN>
<TOKEN end_char="4019" id="token-35-10" morph="none" pos="word" start_char="4011">difficult</TOKEN>
<TOKEN end_char="4022" id="token-35-11" morph="none" pos="word" start_char="4021">to</TOKEN>
<TOKEN end_char="4031" id="token-35-12" morph="none" pos="word" start_char="4024">identify</TOKEN>
<TOKEN end_char="4036" id="token-35-13" morph="none" pos="word" start_char="4033">that</TOKEN>
<TOKEN end_char="4043" id="token-35-14" morph="none" pos="word" start_char="4038">person</TOKEN>
<TOKEN end_char="4045" id="token-35-15" morph="none" pos="punct" start_char="4045">—</TOKEN>
<TOKEN end_char="4049" id="token-35-16" morph="none" pos="word" start_char="4047">and</TOKEN>
<TOKEN end_char="4053" id="token-35-17" morph="none" pos="word" start_char="4051">the</TOKEN>
<TOKEN end_char="4059" id="token-35-18" morph="none" pos="word" start_char="4055">areas</TOKEN>
<TOKEN end_char="4064" id="token-35-19" morph="none" pos="word" start_char="4061">that</TOKEN>
<TOKEN end_char="4069" id="token-35-20" morph="none" pos="word" start_char="4066">have</TOKEN>
<TOKEN end_char="4074" id="token-35-21" morph="none" pos="word" start_char="4071">been</TOKEN>
<TOKEN end_char="4082" id="token-35-22" morph="none" pos="word" start_char="4076">exposed</TOKEN>
<TOKEN end_char="4085" id="token-35-23" morph="none" pos="word" start_char="4084">to</TOKEN>
<TOKEN end_char="4089" id="token-35-24" morph="none" pos="word" start_char="4087">the</TOKEN>
<TOKEN end_char="4095" id="token-35-25" morph="none" pos="word" start_char="4091">virus</TOKEN>
<TOKEN end_char="4099" id="token-35-26" morph="none" pos="word" start_char="4097">the</TOKEN>
<TOKEN end_char="4107" id="token-35-27" morph="none" pos="word" start_char="4101">longest</TOKEN>
<TOKEN end_char="4108" id="token-35-28" morph="none" pos="punct" start_char="4108">.</TOKEN>
</SEG>
<SEG end_char="4398" id="segment-36" start_char="4111">
<ORIGINAL_TEXT>"We do feel uncomfortable obviously when we diagnose a patient with the illness and we can't work out where it came from," Dale Fisher, the chair of the WHO's Global Outbreak Alert and Response Network, told Reuters last month, adding that "the containment activities are less effective."</ORIGINAL_TEXT>
<TOKEN end_char="4111" id="token-36-0" morph="none" pos="punct" start_char="4111">"</TOKEN>
<TOKEN end_char="4113" id="token-36-1" morph="none" pos="word" start_char="4112">We</TOKEN>
<TOKEN end_char="4116" id="token-36-2" morph="none" pos="word" start_char="4115">do</TOKEN>
<TOKEN end_char="4121" id="token-36-3" morph="none" pos="word" start_char="4118">feel</TOKEN>
<TOKEN end_char="4135" id="token-36-4" morph="none" pos="word" start_char="4123">uncomfortable</TOKEN>
<TOKEN end_char="4145" id="token-36-5" morph="none" pos="word" start_char="4137">obviously</TOKEN>
<TOKEN end_char="4150" id="token-36-6" morph="none" pos="word" start_char="4147">when</TOKEN>
<TOKEN end_char="4153" id="token-36-7" morph="none" pos="word" start_char="4152">we</TOKEN>
<TOKEN end_char="4162" id="token-36-8" morph="none" pos="word" start_char="4155">diagnose</TOKEN>
<TOKEN end_char="4164" id="token-36-9" morph="none" pos="word" start_char="4164">a</TOKEN>
<TOKEN end_char="4172" id="token-36-10" morph="none" pos="word" start_char="4166">patient</TOKEN>
<TOKEN end_char="4177" id="token-36-11" morph="none" pos="word" start_char="4174">with</TOKEN>
<TOKEN end_char="4181" id="token-36-12" morph="none" pos="word" start_char="4179">the</TOKEN>
<TOKEN end_char="4189" id="token-36-13" morph="none" pos="word" start_char="4183">illness</TOKEN>
<TOKEN end_char="4193" id="token-36-14" morph="none" pos="word" start_char="4191">and</TOKEN>
<TOKEN end_char="4196" id="token-36-15" morph="none" pos="word" start_char="4195">we</TOKEN>
<TOKEN end_char="4202" id="token-36-16" morph="none" pos="word" start_char="4198">can't</TOKEN>
<TOKEN end_char="4207" id="token-36-17" morph="none" pos="word" start_char="4204">work</TOKEN>
<TOKEN end_char="4211" id="token-36-18" morph="none" pos="word" start_char="4209">out</TOKEN>
<TOKEN end_char="4217" id="token-36-19" morph="none" pos="word" start_char="4213">where</TOKEN>
<TOKEN end_char="4220" id="token-36-20" morph="none" pos="word" start_char="4219">it</TOKEN>
<TOKEN end_char="4225" id="token-36-21" morph="none" pos="word" start_char="4222">came</TOKEN>
<TOKEN end_char="4230" id="token-36-22" morph="none" pos="word" start_char="4227">from</TOKEN>
<TOKEN end_char="4232" id="token-36-23" morph="none" pos="punct" start_char="4231">,"</TOKEN>
<TOKEN end_char="4237" id="token-36-24" morph="none" pos="word" start_char="4234">Dale</TOKEN>
<TOKEN end_char="4244" id="token-36-25" morph="none" pos="word" start_char="4239">Fisher</TOKEN>
<TOKEN end_char="4245" id="token-36-26" morph="none" pos="punct" start_char="4245">,</TOKEN>
<TOKEN end_char="4249" id="token-36-27" morph="none" pos="word" start_char="4247">the</TOKEN>
<TOKEN end_char="4255" id="token-36-28" morph="none" pos="word" start_char="4251">chair</TOKEN>
<TOKEN end_char="4258" id="token-36-29" morph="none" pos="word" start_char="4257">of</TOKEN>
<TOKEN end_char="4262" id="token-36-30" morph="none" pos="word" start_char="4260">the</TOKEN>
<TOKEN end_char="4268" id="token-36-31" morph="none" pos="word" start_char="4264">WHO's</TOKEN>
<TOKEN end_char="4275" id="token-36-32" morph="none" pos="word" start_char="4270">Global</TOKEN>
<TOKEN end_char="4284" id="token-36-33" morph="none" pos="word" start_char="4277">Outbreak</TOKEN>
<TOKEN end_char="4290" id="token-36-34" morph="none" pos="word" start_char="4286">Alert</TOKEN>
<TOKEN end_char="4294" id="token-36-35" morph="none" pos="word" start_char="4292">and</TOKEN>
<TOKEN end_char="4303" id="token-36-36" morph="none" pos="word" start_char="4296">Response</TOKEN>
<TOKEN end_char="4311" id="token-36-37" morph="none" pos="word" start_char="4305">Network</TOKEN>
<TOKEN end_char="4312" id="token-36-38" morph="none" pos="punct" start_char="4312">,</TOKEN>
<TOKEN end_char="4317" id="token-36-39" morph="none" pos="word" start_char="4314">told</TOKEN>
<TOKEN end_char="4325" id="token-36-40" morph="none" pos="word" start_char="4319">Reuters</TOKEN>
<TOKEN end_char="4330" id="token-36-41" morph="none" pos="word" start_char="4327">last</TOKEN>
<TOKEN end_char="4336" id="token-36-42" morph="none" pos="word" start_char="4332">month</TOKEN>
<TOKEN end_char="4337" id="token-36-43" morph="none" pos="punct" start_char="4337">,</TOKEN>
<TOKEN end_char="4344" id="token-36-44" morph="none" pos="word" start_char="4339">adding</TOKEN>
<TOKEN end_char="4349" id="token-36-45" morph="none" pos="word" start_char="4346">that</TOKEN>
<TOKEN end_char="4351" id="token-36-46" morph="none" pos="punct" start_char="4351">"</TOKEN>
<TOKEN end_char="4354" id="token-36-47" morph="none" pos="word" start_char="4352">the</TOKEN>
<TOKEN end_char="4366" id="token-36-48" morph="none" pos="word" start_char="4356">containment</TOKEN>
<TOKEN end_char="4377" id="token-36-49" morph="none" pos="word" start_char="4368">activities</TOKEN>
<TOKEN end_char="4381" id="token-36-50" morph="none" pos="word" start_char="4379">are</TOKEN>
<TOKEN end_char="4386" id="token-36-51" morph="none" pos="word" start_char="4383">less</TOKEN>
<TOKEN end_char="4396" id="token-36-52" morph="none" pos="word" start_char="4388">effective</TOKEN>
<TOKEN end_char="4398" id="token-36-53" morph="none" pos="punct" start_char="4397">."</TOKEN>
</SEG>
<SEG end_char="4421" id="segment-37" start_char="4401">
<ORIGINAL_TEXT>Something is loading.</ORIGINAL_TEXT>
<TOKEN end_char="4409" id="token-37-0" morph="none" pos="word" start_char="4401">Something</TOKEN>
<TOKEN end_char="4412" id="token-37-1" morph="none" pos="word" start_char="4411">is</TOKEN>
<TOKEN end_char="4420" id="token-37-2" morph="none" pos="word" start_char="4414">loading</TOKEN>
<TOKEN end_char="4421" id="token-37-3" morph="none" pos="punct" start_char="4421">.</TOKEN>
</SEG>
<SEG end_char="4433" id="segment-38" start_char="4424">
<ORIGINAL_TEXT>Read more:</ORIGINAL_TEXT>
<TOKEN end_char="4427" id="token-38-0" morph="none" pos="word" start_char="4424">Read</TOKEN>
<TOKEN end_char="4432" id="token-38-1" morph="none" pos="word" start_char="4429">more</TOKEN>
<TOKEN end_char="4433" id="token-38-2" morph="none" pos="punct" start_char="4433">:</TOKEN>
</SEG>
<SEG end_char="4472" id="segment-39" start_char="4436">
<ORIGINAL_TEXT>Taiwan has only 50 coronavirus cases.</ORIGINAL_TEXT>
<TOKEN end_char="4441" id="token-39-0" morph="none" pos="word" start_char="4436">Taiwan</TOKEN>
<TOKEN end_char="4445" id="token-39-1" morph="none" pos="word" start_char="4443">has</TOKEN>
<TOKEN end_char="4450" id="token-39-2" morph="none" pos="word" start_char="4447">only</TOKEN>
<TOKEN end_char="4453" id="token-39-3" morph="none" pos="word" start_char="4452">50</TOKEN>
<TOKEN end_char="4465" id="token-39-4" morph="none" pos="word" start_char="4455">coronavirus</TOKEN>
<TOKEN end_char="4471" id="token-39-5" morph="none" pos="word" start_char="4467">cases</TOKEN>
<TOKEN end_char="4472" id="token-39-6" morph="none" pos="punct" start_char="4472">.</TOKEN>
</SEG>
<SEG end_char="4574" id="segment-40" start_char="4474">
<ORIGINAL_TEXT>Its response to the crisis shows that swift action and widespread healthcare can prevent an outbreak.</ORIGINAL_TEXT>
<TOKEN end_char="4476" id="token-40-0" morph="none" pos="word" start_char="4474">Its</TOKEN>
<TOKEN end_char="4485" id="token-40-1" morph="none" pos="word" start_char="4478">response</TOKEN>
<TOKEN end_char="4488" id="token-40-2" morph="none" pos="word" start_char="4487">to</TOKEN>
<TOKEN end_char="4492" id="token-40-3" morph="none" pos="word" start_char="4490">the</TOKEN>
<TOKEN end_char="4499" id="token-40-4" morph="none" pos="word" start_char="4494">crisis</TOKEN>
<TOKEN end_char="4505" id="token-40-5" morph="none" pos="word" start_char="4501">shows</TOKEN>
<TOKEN end_char="4510" id="token-40-6" morph="none" pos="word" start_char="4507">that</TOKEN>
<TOKEN end_char="4516" id="token-40-7" morph="none" pos="word" start_char="4512">swift</TOKEN>
<TOKEN end_char="4523" id="token-40-8" morph="none" pos="word" start_char="4518">action</TOKEN>
<TOKEN end_char="4527" id="token-40-9" morph="none" pos="word" start_char="4525">and</TOKEN>
<TOKEN end_char="4538" id="token-40-10" morph="none" pos="word" start_char="4529">widespread</TOKEN>
<TOKEN end_char="4549" id="token-40-11" morph="none" pos="word" start_char="4540">healthcare</TOKEN>
<TOKEN end_char="4553" id="token-40-12" morph="none" pos="word" start_char="4551">can</TOKEN>
<TOKEN end_char="4561" id="token-40-13" morph="none" pos="word" start_char="4555">prevent</TOKEN>
<TOKEN end_char="4564" id="token-40-14" morph="none" pos="word" start_char="4563">an</TOKEN>
<TOKEN end_char="4573" id="token-40-15" morph="none" pos="word" start_char="4566">outbreak</TOKEN>
<TOKEN end_char="4574" id="token-40-16" morph="none" pos="punct" start_char="4574">.</TOKEN>
</SEG>
<SEG end_char="4657" id="segment-41" start_char="4577">
<ORIGINAL_TEXT>The US is severely under-testing for coronavirus as death toll and new cases rise</ORIGINAL_TEXT>
<TOKEN end_char="4579" id="token-41-0" morph="none" pos="word" start_char="4577">The</TOKEN>
<TOKEN end_char="4582" id="token-41-1" morph="none" pos="word" start_char="4581">US</TOKEN>
<TOKEN end_char="4585" id="token-41-2" morph="none" pos="word" start_char="4584">is</TOKEN>
<TOKEN end_char="4594" id="token-41-3" morph="none" pos="word" start_char="4587">severely</TOKEN>
<TOKEN end_char="4608" id="token-41-4" morph="none" pos="unknown" start_char="4596">under-testing</TOKEN>
<TOKEN end_char="4612" id="token-41-5" morph="none" pos="word" start_char="4610">for</TOKEN>
<TOKEN end_char="4624" id="token-41-6" morph="none" pos="word" start_char="4614">coronavirus</TOKEN>
<TOKEN end_char="4627" id="token-41-7" morph="none" pos="word" start_char="4626">as</TOKEN>
<TOKEN end_char="4633" id="token-41-8" morph="none" pos="word" start_char="4629">death</TOKEN>
<TOKEN end_char="4638" id="token-41-9" morph="none" pos="word" start_char="4635">toll</TOKEN>
<TOKEN end_char="4642" id="token-41-10" morph="none" pos="word" start_char="4640">and</TOKEN>
<TOKEN end_char="4646" id="token-41-11" morph="none" pos="word" start_char="4644">new</TOKEN>
<TOKEN end_char="4652" id="token-41-12" morph="none" pos="word" start_char="4648">cases</TOKEN>
<TOKEN end_char="4657" id="token-41-13" morph="none" pos="word" start_char="4654">rise</TOKEN>
</SEG>
<SEG end_char="4831" id="segment-42" start_char="4660">
<ORIGINAL_TEXT>Chinese social-media platform WeChat saw spikes in the terms 'SARS,' 'coronavirus,' and 'shortness of breath,' weeks before the first cases were confirmed, a study suggests</ORIGINAL_TEXT>
<TOKEN end_char="4666" id="token-42-0" morph="none" pos="word" start_char="4660">Chinese</TOKEN>
<TOKEN end_char="4679" id="token-42-1" morph="none" pos="unknown" start_char="4668">social-media</TOKEN>
<TOKEN end_char="4688" id="token-42-2" morph="none" pos="word" start_char="4681">platform</TOKEN>
<TOKEN end_char="4695" id="token-42-3" morph="none" pos="word" start_char="4690">WeChat</TOKEN>
<TOKEN end_char="4699" id="token-42-4" morph="none" pos="word" start_char="4697">saw</TOKEN>
<TOKEN end_char="4706" id="token-42-5" morph="none" pos="word" start_char="4701">spikes</TOKEN>
<TOKEN end_char="4709" id="token-42-6" morph="none" pos="word" start_char="4708">in</TOKEN>
<TOKEN end_char="4713" id="token-42-7" morph="none" pos="word" start_char="4711">the</TOKEN>
<TOKEN end_char="4719" id="token-42-8" morph="none" pos="word" start_char="4715">terms</TOKEN>
<TOKEN end_char="4721" id="token-42-9" morph="none" pos="punct" start_char="4721">'</TOKEN>
<TOKEN end_char="4725" id="token-42-10" morph="none" pos="word" start_char="4722">SARS</TOKEN>
<TOKEN end_char="4727" id="token-42-11" morph="none" pos="punct" start_char="4726">,'</TOKEN>
<TOKEN end_char="4729" id="token-42-12" morph="none" pos="punct" start_char="4729">'</TOKEN>
<TOKEN end_char="4740" id="token-42-13" morph="none" pos="word" start_char="4730">coronavirus</TOKEN>
<TOKEN end_char="4742" id="token-42-14" morph="none" pos="punct" start_char="4741">,'</TOKEN>
<TOKEN end_char="4746" id="token-42-15" morph="none" pos="word" start_char="4744">and</TOKEN>
<TOKEN end_char="4748" id="token-42-16" morph="none" pos="punct" start_char="4748">'</TOKEN>
<TOKEN end_char="4757" id="token-42-17" morph="none" pos="word" start_char="4749">shortness</TOKEN>
<TOKEN end_char="4760" id="token-42-18" morph="none" pos="word" start_char="4759">of</TOKEN>
<TOKEN end_char="4767" id="token-42-19" morph="none" pos="word" start_char="4762">breath</TOKEN>
<TOKEN end_char="4769" id="token-42-20" morph="none" pos="punct" start_char="4768">,'</TOKEN>
<TOKEN end_char="4775" id="token-42-21" morph="none" pos="word" start_char="4771">weeks</TOKEN>
<TOKEN end_char="4782" id="token-42-22" morph="none" pos="word" start_char="4777">before</TOKEN>
<TOKEN end_char="4786" id="token-42-23" morph="none" pos="word" start_char="4784">the</TOKEN>
<TOKEN end_char="4792" id="token-42-24" morph="none" pos="word" start_char="4788">first</TOKEN>
<TOKEN end_char="4798" id="token-42-25" morph="none" pos="word" start_char="4794">cases</TOKEN>
<TOKEN end_char="4803" id="token-42-26" morph="none" pos="word" start_char="4800">were</TOKEN>
<TOKEN end_char="4813" id="token-42-27" morph="none" pos="word" start_char="4805">confirmed</TOKEN>
<TOKEN end_char="4814" id="token-42-28" morph="none" pos="punct" start_char="4814">,</TOKEN>
<TOKEN end_char="4816" id="token-42-29" morph="none" pos="word" start_char="4816">a</TOKEN>
<TOKEN end_char="4822" id="token-42-30" morph="none" pos="word" start_char="4818">study</TOKEN>
<TOKEN end_char="4831" id="token-42-31" morph="none" pos="word" start_char="4824">suggests</TOKEN>
</SEG>
<SEG end_char="4979" id="segment-43" start_char="4834">
<ORIGINAL_TEXT>Travel bans in Wuhan only delayed the coronavirus' spread in China by 3 to 5 days, and in the rest of the world by a few weeks, new research shows</ORIGINAL_TEXT>
<TOKEN end_char="4839" id="token-43-0" morph="none" pos="word" start_char="4834">Travel</TOKEN>
<TOKEN end_char="4844" id="token-43-1" morph="none" pos="word" start_char="4841">bans</TOKEN>
<TOKEN end_char="4847" id="token-43-2" morph="none" pos="word" start_char="4846">in</TOKEN>
<TOKEN end_char="4853" id="token-43-3" morph="none" pos="word" start_char="4849">Wuhan</TOKEN>
<TOKEN end_char="4858" id="token-43-4" morph="none" pos="word" start_char="4855">only</TOKEN>
<TOKEN end_char="4866" id="token-43-5" morph="none" pos="word" start_char="4860">delayed</TOKEN>
<TOKEN end_char="4870" id="token-43-6" morph="none" pos="word" start_char="4868">the</TOKEN>
<TOKEN end_char="4882" id="token-43-7" morph="none" pos="word" start_char="4872">coronavirus</TOKEN>
<TOKEN end_char="4883" id="token-43-8" morph="none" pos="punct" start_char="4883">'</TOKEN>
<TOKEN end_char="4890" id="token-43-9" morph="none" pos="word" start_char="4885">spread</TOKEN>
<TOKEN end_char="4893" id="token-43-10" morph="none" pos="word" start_char="4892">in</TOKEN>
<TOKEN end_char="4899" id="token-43-11" morph="none" pos="word" start_char="4895">China</TOKEN>
<TOKEN end_char="4902" id="token-43-12" morph="none" pos="word" start_char="4901">by</TOKEN>
<TOKEN end_char="4904" id="token-43-13" morph="none" pos="word" start_char="4904">3</TOKEN>
<TOKEN end_char="4907" id="token-43-14" morph="none" pos="word" start_char="4906">to</TOKEN>
<TOKEN end_char="4909" id="token-43-15" morph="none" pos="word" start_char="4909">5</TOKEN>
<TOKEN end_char="4914" id="token-43-16" morph="none" pos="word" start_char="4911">days</TOKEN>
<TOKEN end_char="4915" id="token-43-17" morph="none" pos="punct" start_char="4915">,</TOKEN>
<TOKEN end_char="4919" id="token-43-18" morph="none" pos="word" start_char="4917">and</TOKEN>
<TOKEN end_char="4922" id="token-43-19" morph="none" pos="word" start_char="4921">in</TOKEN>
<TOKEN end_char="4926" id="token-43-20" morph="none" pos="word" start_char="4924">the</TOKEN>
<TOKEN end_char="4931" id="token-43-21" morph="none" pos="word" start_char="4928">rest</TOKEN>
<TOKEN end_char="4934" id="token-43-22" morph="none" pos="word" start_char="4933">of</TOKEN>
<TOKEN end_char="4938" id="token-43-23" morph="none" pos="word" start_char="4936">the</TOKEN>
<TOKEN end_char="4944" id="token-43-24" morph="none" pos="word" start_char="4940">world</TOKEN>
<TOKEN end_char="4947" id="token-43-25" morph="none" pos="word" start_char="4946">by</TOKEN>
<TOKEN end_char="4949" id="token-43-26" morph="none" pos="word" start_char="4949">a</TOKEN>
<TOKEN end_char="4953" id="token-43-27" morph="none" pos="word" start_char="4951">few</TOKEN>
<TOKEN end_char="4959" id="token-43-28" morph="none" pos="word" start_char="4955">weeks</TOKEN>
<TOKEN end_char="4960" id="token-43-29" morph="none" pos="punct" start_char="4960">,</TOKEN>
<TOKEN end_char="4964" id="token-43-30" morph="none" pos="word" start_char="4962">new</TOKEN>
<TOKEN end_char="4973" id="token-43-31" morph="none" pos="word" start_char="4966">research</TOKEN>
<TOKEN end_char="4979" id="token-43-32" morph="none" pos="word" start_char="4975">shows</TOKEN>
</SEG>
<SEG end_char="5017" id="segment-44" start_char="4983">
<ORIGINAL_TEXT>Two crossed lines that form an 'X'.</ORIGINAL_TEXT>
<TOKEN end_char="4985" id="token-44-0" morph="none" pos="word" start_char="4983">Two</TOKEN>
<TOKEN end_char="4993" id="token-44-1" morph="none" pos="word" start_char="4987">crossed</TOKEN>
<TOKEN end_char="4999" id="token-44-2" morph="none" pos="word" start_char="4995">lines</TOKEN>
<TOKEN end_char="5004" id="token-44-3" morph="none" pos="word" start_char="5001">that</TOKEN>
<TOKEN end_char="5009" id="token-44-4" morph="none" pos="word" start_char="5006">form</TOKEN>
<TOKEN end_char="5012" id="token-44-5" morph="none" pos="word" start_char="5011">an</TOKEN>
<TOKEN end_char="5014" id="token-44-6" morph="none" pos="punct" start_char="5014">'</TOKEN>
<TOKEN end_char="5015" id="token-44-7" morph="none" pos="word" start_char="5015">X</TOKEN>
<TOKEN end_char="5017" id="token-44-8" morph="none" pos="punct" start_char="5016">'.</TOKEN>
</SEG>
<SEG end_char="5088" id="segment-45" start_char="5019">
<ORIGINAL_TEXT>It indicates a way to close an interaction, or dismiss a notification.</ORIGINAL_TEXT>
<TOKEN end_char="5020" id="token-45-0" morph="none" pos="word" start_char="5019">It</TOKEN>
<TOKEN end_char="5030" id="token-45-1" morph="none" pos="word" start_char="5022">indicates</TOKEN>
<TOKEN end_char="5032" id="token-45-2" morph="none" pos="word" start_char="5032">a</TOKEN>
<TOKEN end_char="5036" id="token-45-3" morph="none" pos="word" start_char="5034">way</TOKEN>
<TOKEN end_char="5039" id="token-45-4" morph="none" pos="word" start_char="5038">to</TOKEN>
<TOKEN end_char="5045" id="token-45-5" morph="none" pos="word" start_char="5041">close</TOKEN>
<TOKEN end_char="5048" id="token-45-6" morph="none" pos="word" start_char="5047">an</TOKEN>
<TOKEN end_char="5060" id="token-45-7" morph="none" pos="word" start_char="5050">interaction</TOKEN>
<TOKEN end_char="5061" id="token-45-8" morph="none" pos="punct" start_char="5061">,</TOKEN>
<TOKEN end_char="5064" id="token-45-9" morph="none" pos="word" start_char="5063">or</TOKEN>
<TOKEN end_char="5072" id="token-45-10" morph="none" pos="word" start_char="5066">dismiss</TOKEN>
<TOKEN end_char="5074" id="token-45-11" morph="none" pos="word" start_char="5074">a</TOKEN>
<TOKEN end_char="5087" id="token-45-12" morph="none" pos="word" start_char="5076">notification</TOKEN>
<TOKEN end_char="5088" id="token-45-13" morph="none" pos="punct" start_char="5088">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
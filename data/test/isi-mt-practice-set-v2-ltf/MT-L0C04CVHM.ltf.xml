<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CVHM" lang="spa" raw_text_char_length="3737" raw_text_md5="37ae4235cb62cb0f1fbd2ff3bafd34ae" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="76" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Is India failing the contact tracing test in its battle against coronavirus?</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">Is</TOKEN>
<TOKEN end_char="8" id="token-0-1" morph="none" pos="word" start_char="4">India</TOKEN>
<TOKEN end_char="16" id="token-0-2" morph="none" pos="word" start_char="10">failing</TOKEN>
<TOKEN end_char="20" id="token-0-3" morph="none" pos="word" start_char="18">the</TOKEN>
<TOKEN end_char="28" id="token-0-4" morph="none" pos="word" start_char="22">contact</TOKEN>
<TOKEN end_char="36" id="token-0-5" morph="none" pos="word" start_char="30">tracing</TOKEN>
<TOKEN end_char="41" id="token-0-6" morph="none" pos="word" start_char="38">test</TOKEN>
<TOKEN end_char="44" id="token-0-7" morph="none" pos="word" start_char="43">in</TOKEN>
<TOKEN end_char="48" id="token-0-8" morph="none" pos="word" start_char="46">its</TOKEN>
<TOKEN end_char="55" id="token-0-9" morph="none" pos="word" start_char="50">battle</TOKEN>
<TOKEN end_char="63" id="token-0-10" morph="none" pos="word" start_char="57">against</TOKEN>
<TOKEN end_char="75" id="token-0-11" morph="none" pos="word" start_char="65">coronavirus</TOKEN>
<TOKEN end_char="76" id="token-0-12" morph="none" pos="punct" start_char="76">?</TOKEN>
</SEG>
<SEG end_char="224" id="segment-1" start_char="80">
<ORIGINAL_TEXT>States that did the least testing among contacts of confirmed cases were among those with the highest rates of positive cases among those tested.</ORIGINAL_TEXT>
<TOKEN end_char="85" id="token-1-0" morph="none" pos="word" start_char="80">States</TOKEN>
<TOKEN end_char="90" id="token-1-1" morph="none" pos="word" start_char="87">that</TOKEN>
<TOKEN end_char="94" id="token-1-2" morph="none" pos="word" start_char="92">did</TOKEN>
<TOKEN end_char="98" id="token-1-3" morph="none" pos="word" start_char="96">the</TOKEN>
<TOKEN end_char="104" id="token-1-4" morph="none" pos="word" start_char="100">least</TOKEN>
<TOKEN end_char="112" id="token-1-5" morph="none" pos="word" start_char="106">testing</TOKEN>
<TOKEN end_char="118" id="token-1-6" morph="none" pos="word" start_char="114">among</TOKEN>
<TOKEN end_char="127" id="token-1-7" morph="none" pos="word" start_char="120">contacts</TOKEN>
<TOKEN end_char="130" id="token-1-8" morph="none" pos="word" start_char="129">of</TOKEN>
<TOKEN end_char="140" id="token-1-9" morph="none" pos="word" start_char="132">confirmed</TOKEN>
<TOKEN end_char="146" id="token-1-10" morph="none" pos="word" start_char="142">cases</TOKEN>
<TOKEN end_char="151" id="token-1-11" morph="none" pos="word" start_char="148">were</TOKEN>
<TOKEN end_char="157" id="token-1-12" morph="none" pos="word" start_char="153">among</TOKEN>
<TOKEN end_char="163" id="token-1-13" morph="none" pos="word" start_char="159">those</TOKEN>
<TOKEN end_char="168" id="token-1-14" morph="none" pos="word" start_char="165">with</TOKEN>
<TOKEN end_char="172" id="token-1-15" morph="none" pos="word" start_char="170">the</TOKEN>
<TOKEN end_char="180" id="token-1-16" morph="none" pos="word" start_char="174">highest</TOKEN>
<TOKEN end_char="186" id="token-1-17" morph="none" pos="word" start_char="182">rates</TOKEN>
<TOKEN end_char="189" id="token-1-18" morph="none" pos="word" start_char="188">of</TOKEN>
<TOKEN end_char="198" id="token-1-19" morph="none" pos="word" start_char="191">positive</TOKEN>
<TOKEN end_char="204" id="token-1-20" morph="none" pos="word" start_char="200">cases</TOKEN>
<TOKEN end_char="210" id="token-1-21" morph="none" pos="word" start_char="206">among</TOKEN>
<TOKEN end_char="216" id="token-1-22" morph="none" pos="word" start_char="212">those</TOKEN>
<TOKEN end_char="223" id="token-1-23" morph="none" pos="word" start_char="218">tested</TOKEN>
<TOKEN end_char="224" id="token-1-24" morph="none" pos="punct" start_char="224">.</TOKEN>
</SEG>
<SEG end_char="237" id="segment-2" start_char="226">
<ORIGINAL_TEXT>(Photo: PTI)</ORIGINAL_TEXT>
<TOKEN end_char="226" id="token-2-0" morph="none" pos="punct" start_char="226">(</TOKEN>
<TOKEN end_char="231" id="token-2-1" morph="none" pos="word" start_char="227">Photo</TOKEN>
<TOKEN end_char="232" id="token-2-2" morph="none" pos="punct" start_char="232">:</TOKEN>
<TOKEN end_char="236" id="token-2-3" morph="none" pos="word" start_char="234">PTI</TOKEN>
<TOKEN end_char="237" id="token-2-4" morph="none" pos="punct" start_char="237">)</TOKEN>
</SEG>
<SEG end_char="398" id="segment-3" start_char="241">
<ORIGINAL_TEXT>On May 30, the Indian Journal of Medical Research (IJMR) published the Indian Council of Medical Research’s (ICMR) first analysis of India’s SARS-CoV-2 cases.</ORIGINAL_TEXT>
<TOKEN end_char="242" id="token-3-0" morph="none" pos="word" start_char="241">On</TOKEN>
<TOKEN end_char="246" id="token-3-1" morph="none" pos="word" start_char="244">May</TOKEN>
<TOKEN end_char="249" id="token-3-2" morph="none" pos="word" start_char="248">30</TOKEN>
<TOKEN end_char="250" id="token-3-3" morph="none" pos="punct" start_char="250">,</TOKEN>
<TOKEN end_char="254" id="token-3-4" morph="none" pos="word" start_char="252">the</TOKEN>
<TOKEN end_char="261" id="token-3-5" morph="none" pos="word" start_char="256">Indian</TOKEN>
<TOKEN end_char="269" id="token-3-6" morph="none" pos="word" start_char="263">Journal</TOKEN>
<TOKEN end_char="272" id="token-3-7" morph="none" pos="word" start_char="271">of</TOKEN>
<TOKEN end_char="280" id="token-3-8" morph="none" pos="word" start_char="274">Medical</TOKEN>
<TOKEN end_char="289" id="token-3-9" morph="none" pos="word" start_char="282">Research</TOKEN>
<TOKEN end_char="291" id="token-3-10" morph="none" pos="punct" start_char="291">(</TOKEN>
<TOKEN end_char="295" id="token-3-11" morph="none" pos="word" start_char="292">IJMR</TOKEN>
<TOKEN end_char="296" id="token-3-12" morph="none" pos="punct" start_char="296">)</TOKEN>
<TOKEN end_char="306" id="token-3-13" morph="none" pos="word" start_char="298">published</TOKEN>
<TOKEN end_char="310" id="token-3-14" morph="none" pos="word" start_char="308">the</TOKEN>
<TOKEN end_char="317" id="token-3-15" morph="none" pos="word" start_char="312">Indian</TOKEN>
<TOKEN end_char="325" id="token-3-16" morph="none" pos="word" start_char="319">Council</TOKEN>
<TOKEN end_char="328" id="token-3-17" morph="none" pos="word" start_char="327">of</TOKEN>
<TOKEN end_char="336" id="token-3-18" morph="none" pos="word" start_char="330">Medical</TOKEN>
<TOKEN end_char="347" id="token-3-19" morph="none" pos="word" start_char="338">Research’s</TOKEN>
<TOKEN end_char="349" id="token-3-20" morph="none" pos="punct" start_char="349">(</TOKEN>
<TOKEN end_char="353" id="token-3-21" morph="none" pos="word" start_char="350">ICMR</TOKEN>
<TOKEN end_char="354" id="token-3-22" morph="none" pos="punct" start_char="354">)</TOKEN>
<TOKEN end_char="360" id="token-3-23" morph="none" pos="word" start_char="356">first</TOKEN>
<TOKEN end_char="369" id="token-3-24" morph="none" pos="word" start_char="362">analysis</TOKEN>
<TOKEN end_char="372" id="token-3-25" morph="none" pos="word" start_char="371">of</TOKEN>
<TOKEN end_char="380" id="token-3-26" morph="none" pos="word" start_char="374">India’s</TOKEN>
<TOKEN end_char="391" id="token-3-27" morph="none" pos="unknown" start_char="382">SARS-CoV-2</TOKEN>
<TOKEN end_char="397" id="token-3-28" morph="none" pos="word" start_char="393">cases</TOKEN>
<TOKEN end_char="398" id="token-3-29" morph="none" pos="punct" start_char="398">.</TOKEN>
</SEG>
<SEG end_char="546" id="segment-4" start_char="400">
<ORIGINAL_TEXT>The team of scientists tested over a million people and found more than 40,000 positive cases between January 22 and April 30 all over the country.</ORIGINAL_TEXT>
<TOKEN end_char="402" id="token-4-0" morph="none" pos="word" start_char="400">The</TOKEN>
<TOKEN end_char="407" id="token-4-1" morph="none" pos="word" start_char="404">team</TOKEN>
<TOKEN end_char="410" id="token-4-2" morph="none" pos="word" start_char="409">of</TOKEN>
<TOKEN end_char="421" id="token-4-3" morph="none" pos="word" start_char="412">scientists</TOKEN>
<TOKEN end_char="428" id="token-4-4" morph="none" pos="word" start_char="423">tested</TOKEN>
<TOKEN end_char="433" id="token-4-5" morph="none" pos="word" start_char="430">over</TOKEN>
<TOKEN end_char="435" id="token-4-6" morph="none" pos="word" start_char="435">a</TOKEN>
<TOKEN end_char="443" id="token-4-7" morph="none" pos="word" start_char="437">million</TOKEN>
<TOKEN end_char="450" id="token-4-8" morph="none" pos="word" start_char="445">people</TOKEN>
<TOKEN end_char="454" id="token-4-9" morph="none" pos="word" start_char="452">and</TOKEN>
<TOKEN end_char="460" id="token-4-10" morph="none" pos="word" start_char="456">found</TOKEN>
<TOKEN end_char="465" id="token-4-11" morph="none" pos="word" start_char="462">more</TOKEN>
<TOKEN end_char="470" id="token-4-12" morph="none" pos="word" start_char="467">than</TOKEN>
<TOKEN end_char="477" id="token-4-13" morph="none" pos="unknown" start_char="472">40,000</TOKEN>
<TOKEN end_char="486" id="token-4-14" morph="none" pos="word" start_char="479">positive</TOKEN>
<TOKEN end_char="492" id="token-4-15" morph="none" pos="word" start_char="488">cases</TOKEN>
<TOKEN end_char="500" id="token-4-16" morph="none" pos="word" start_char="494">between</TOKEN>
<TOKEN end_char="508" id="token-4-17" morph="none" pos="word" start_char="502">January</TOKEN>
<TOKEN end_char="511" id="token-4-18" morph="none" pos="word" start_char="510">22</TOKEN>
<TOKEN end_char="515" id="token-4-19" morph="none" pos="word" start_char="513">and</TOKEN>
<TOKEN end_char="521" id="token-4-20" morph="none" pos="word" start_char="517">April</TOKEN>
<TOKEN end_char="524" id="token-4-21" morph="none" pos="word" start_char="523">30</TOKEN>
<TOKEN end_char="528" id="token-4-22" morph="none" pos="word" start_char="526">all</TOKEN>
<TOKEN end_char="533" id="token-4-23" morph="none" pos="word" start_char="530">over</TOKEN>
<TOKEN end_char="537" id="token-4-24" morph="none" pos="word" start_char="535">the</TOKEN>
<TOKEN end_char="545" id="token-4-25" morph="none" pos="word" start_char="539">country</TOKEN>
<TOKEN end_char="546" id="token-4-26" morph="none" pos="punct" start_char="546">.</TOKEN>
</SEG>
<SEG end_char="692" id="segment-5" start_char="549">
<ORIGINAL_TEXT>Data shows India is falling far behind in contact tracing, even though it has emerged as the most important route to contain the virus’s spread.</ORIGINAL_TEXT>
<TOKEN end_char="552" id="token-5-0" morph="none" pos="word" start_char="549">Data</TOKEN>
<TOKEN end_char="558" id="token-5-1" morph="none" pos="word" start_char="554">shows</TOKEN>
<TOKEN end_char="564" id="token-5-2" morph="none" pos="word" start_char="560">India</TOKEN>
<TOKEN end_char="567" id="token-5-3" morph="none" pos="word" start_char="566">is</TOKEN>
<TOKEN end_char="575" id="token-5-4" morph="none" pos="word" start_char="569">falling</TOKEN>
<TOKEN end_char="579" id="token-5-5" morph="none" pos="word" start_char="577">far</TOKEN>
<TOKEN end_char="586" id="token-5-6" morph="none" pos="word" start_char="581">behind</TOKEN>
<TOKEN end_char="589" id="token-5-7" morph="none" pos="word" start_char="588">in</TOKEN>
<TOKEN end_char="597" id="token-5-8" morph="none" pos="word" start_char="591">contact</TOKEN>
<TOKEN end_char="605" id="token-5-9" morph="none" pos="word" start_char="599">tracing</TOKEN>
<TOKEN end_char="606" id="token-5-10" morph="none" pos="punct" start_char="606">,</TOKEN>
<TOKEN end_char="611" id="token-5-11" morph="none" pos="word" start_char="608">even</TOKEN>
<TOKEN end_char="618" id="token-5-12" morph="none" pos="word" start_char="613">though</TOKEN>
<TOKEN end_char="621" id="token-5-13" morph="none" pos="word" start_char="620">it</TOKEN>
<TOKEN end_char="625" id="token-5-14" morph="none" pos="word" start_char="623">has</TOKEN>
<TOKEN end_char="633" id="token-5-15" morph="none" pos="word" start_char="627">emerged</TOKEN>
<TOKEN end_char="636" id="token-5-16" morph="none" pos="word" start_char="635">as</TOKEN>
<TOKEN end_char="640" id="token-5-17" morph="none" pos="word" start_char="638">the</TOKEN>
<TOKEN end_char="645" id="token-5-18" morph="none" pos="word" start_char="642">most</TOKEN>
<TOKEN end_char="655" id="token-5-19" morph="none" pos="word" start_char="647">important</TOKEN>
<TOKEN end_char="661" id="token-5-20" morph="none" pos="word" start_char="657">route</TOKEN>
<TOKEN end_char="664" id="token-5-21" morph="none" pos="word" start_char="663">to</TOKEN>
<TOKEN end_char="672" id="token-5-22" morph="none" pos="word" start_char="666">contain</TOKEN>
<TOKEN end_char="676" id="token-5-23" morph="none" pos="word" start_char="674">the</TOKEN>
<TOKEN end_char="684" id="token-5-24" morph="none" pos="word" start_char="678">virus’s</TOKEN>
<TOKEN end_char="691" id="token-5-25" morph="none" pos="word" start_char="686">spread</TOKEN>
<TOKEN end_char="692" id="token-5-26" morph="none" pos="punct" start_char="692">.</TOKEN>
</SEG>
<SEG end_char="801" id="segment-6" start_char="696">
<ORIGINAL_TEXT>Data shows younger people and men were slightly more likely to get tested than they were to test positive.</ORIGINAL_TEXT>
<TOKEN end_char="699" id="token-6-0" morph="none" pos="word" start_char="696">Data</TOKEN>
<TOKEN end_char="705" id="token-6-1" morph="none" pos="word" start_char="701">shows</TOKEN>
<TOKEN end_char="713" id="token-6-2" morph="none" pos="word" start_char="707">younger</TOKEN>
<TOKEN end_char="720" id="token-6-3" morph="none" pos="word" start_char="715">people</TOKEN>
<TOKEN end_char="724" id="token-6-4" morph="none" pos="word" start_char="722">and</TOKEN>
<TOKEN end_char="728" id="token-6-5" morph="none" pos="word" start_char="726">men</TOKEN>
<TOKEN end_char="733" id="token-6-6" morph="none" pos="word" start_char="730">were</TOKEN>
<TOKEN end_char="742" id="token-6-7" morph="none" pos="word" start_char="735">slightly</TOKEN>
<TOKEN end_char="747" id="token-6-8" morph="none" pos="word" start_char="744">more</TOKEN>
<TOKEN end_char="754" id="token-6-9" morph="none" pos="word" start_char="749">likely</TOKEN>
<TOKEN end_char="757" id="token-6-10" morph="none" pos="word" start_char="756">to</TOKEN>
<TOKEN end_char="761" id="token-6-11" morph="none" pos="word" start_char="759">get</TOKEN>
<TOKEN end_char="768" id="token-6-12" morph="none" pos="word" start_char="763">tested</TOKEN>
<TOKEN end_char="773" id="token-6-13" morph="none" pos="word" start_char="770">than</TOKEN>
<TOKEN end_char="778" id="token-6-14" morph="none" pos="word" start_char="775">they</TOKEN>
<TOKEN end_char="783" id="token-6-15" morph="none" pos="word" start_char="780">were</TOKEN>
<TOKEN end_char="786" id="token-6-16" morph="none" pos="word" start_char="785">to</TOKEN>
<TOKEN end_char="791" id="token-6-17" morph="none" pos="word" start_char="788">test</TOKEN>
<TOKEN end_char="800" id="token-6-18" morph="none" pos="word" start_char="793">positive</TOKEN>
<TOKEN end_char="801" id="token-6-19" morph="none" pos="punct" start_char="801">.</TOKEN>
</SEG>
<SEG end_char="893" id="segment-7" start_char="803">
<ORIGINAL_TEXT>Overall, the age groups of 20-29 and 30-39 have the highest burden of the disease in India.</ORIGINAL_TEXT>
<TOKEN end_char="809" id="token-7-0" morph="none" pos="word" start_char="803">Overall</TOKEN>
<TOKEN end_char="810" id="token-7-1" morph="none" pos="punct" start_char="810">,</TOKEN>
<TOKEN end_char="814" id="token-7-2" morph="none" pos="word" start_char="812">the</TOKEN>
<TOKEN end_char="818" id="token-7-3" morph="none" pos="word" start_char="816">age</TOKEN>
<TOKEN end_char="825" id="token-7-4" morph="none" pos="word" start_char="820">groups</TOKEN>
<TOKEN end_char="828" id="token-7-5" morph="none" pos="word" start_char="827">of</TOKEN>
<TOKEN end_char="834" id="token-7-6" morph="none" pos="unknown" start_char="830">20-29</TOKEN>
<TOKEN end_char="838" id="token-7-7" morph="none" pos="word" start_char="836">and</TOKEN>
<TOKEN end_char="844" id="token-7-8" morph="none" pos="unknown" start_char="840">30-39</TOKEN>
<TOKEN end_char="849" id="token-7-9" morph="none" pos="word" start_char="846">have</TOKEN>
<TOKEN end_char="853" id="token-7-10" morph="none" pos="word" start_char="851">the</TOKEN>
<TOKEN end_char="861" id="token-7-11" morph="none" pos="word" start_char="855">highest</TOKEN>
<TOKEN end_char="868" id="token-7-12" morph="none" pos="word" start_char="863">burden</TOKEN>
<TOKEN end_char="871" id="token-7-13" morph="none" pos="word" start_char="870">of</TOKEN>
<TOKEN end_char="875" id="token-7-14" morph="none" pos="word" start_char="873">the</TOKEN>
<TOKEN end_char="883" id="token-7-15" morph="none" pos="word" start_char="877">disease</TOKEN>
<TOKEN end_char="886" id="token-7-16" morph="none" pos="word" start_char="885">in</TOKEN>
<TOKEN end_char="892" id="token-7-17" morph="none" pos="word" start_char="888">India</TOKEN>
<TOKEN end_char="893" id="token-7-18" morph="none" pos="punct" start_char="893">.</TOKEN>
</SEG>
<SEG end_char="1027" id="segment-8" start_char="895">
<ORIGINAL_TEXT>This is in stark contrast to the experience of developed countries; in the UK, for example, the median positive case is 61 years old.</ORIGINAL_TEXT>
<TOKEN end_char="898" id="token-8-0" morph="none" pos="word" start_char="895">This</TOKEN>
<TOKEN end_char="901" id="token-8-1" morph="none" pos="word" start_char="900">is</TOKEN>
<TOKEN end_char="904" id="token-8-2" morph="none" pos="word" start_char="903">in</TOKEN>
<TOKEN end_char="910" id="token-8-3" morph="none" pos="word" start_char="906">stark</TOKEN>
<TOKEN end_char="919" id="token-8-4" morph="none" pos="word" start_char="912">contrast</TOKEN>
<TOKEN end_char="922" id="token-8-5" morph="none" pos="word" start_char="921">to</TOKEN>
<TOKEN end_char="926" id="token-8-6" morph="none" pos="word" start_char="924">the</TOKEN>
<TOKEN end_char="937" id="token-8-7" morph="none" pos="word" start_char="928">experience</TOKEN>
<TOKEN end_char="940" id="token-8-8" morph="none" pos="word" start_char="939">of</TOKEN>
<TOKEN end_char="950" id="token-8-9" morph="none" pos="word" start_char="942">developed</TOKEN>
<TOKEN end_char="960" id="token-8-10" morph="none" pos="word" start_char="952">countries</TOKEN>
<TOKEN end_char="961" id="token-8-11" morph="none" pos="punct" start_char="961">;</TOKEN>
<TOKEN end_char="964" id="token-8-12" morph="none" pos="word" start_char="963">in</TOKEN>
<TOKEN end_char="968" id="token-8-13" morph="none" pos="word" start_char="966">the</TOKEN>
<TOKEN end_char="971" id="token-8-14" morph="none" pos="word" start_char="970">UK</TOKEN>
<TOKEN end_char="972" id="token-8-15" morph="none" pos="punct" start_char="972">,</TOKEN>
<TOKEN end_char="976" id="token-8-16" morph="none" pos="word" start_char="974">for</TOKEN>
<TOKEN end_char="984" id="token-8-17" morph="none" pos="word" start_char="978">example</TOKEN>
<TOKEN end_char="985" id="token-8-18" morph="none" pos="punct" start_char="985">,</TOKEN>
<TOKEN end_char="989" id="token-8-19" morph="none" pos="word" start_char="987">the</TOKEN>
<TOKEN end_char="996" id="token-8-20" morph="none" pos="word" start_char="991">median</TOKEN>
<TOKEN end_char="1005" id="token-8-21" morph="none" pos="word" start_char="998">positive</TOKEN>
<TOKEN end_char="1010" id="token-8-22" morph="none" pos="word" start_char="1007">case</TOKEN>
<TOKEN end_char="1013" id="token-8-23" morph="none" pos="word" start_char="1012">is</TOKEN>
<TOKEN end_char="1016" id="token-8-24" morph="none" pos="word" start_char="1015">61</TOKEN>
<TOKEN end_char="1022" id="token-8-25" morph="none" pos="word" start_char="1018">years</TOKEN>
<TOKEN end_char="1026" id="token-8-26" morph="none" pos="word" start_char="1024">old</TOKEN>
<TOKEN end_char="1027" id="token-8-27" morph="none" pos="punct" start_char="1027">.</TOKEN>
</SEG>
<SEG end_char="1196" id="segment-9" start_char="1031">
<ORIGINAL_TEXT>Until now, there has been no way to know who exactly is being tested, and what proportion of those persons deemed eligible by ICMR’s testing criteria is being tested.</ORIGINAL_TEXT>
<TOKEN end_char="1035" id="token-9-0" morph="none" pos="word" start_char="1031">Until</TOKEN>
<TOKEN end_char="1039" id="token-9-1" morph="none" pos="word" start_char="1037">now</TOKEN>
<TOKEN end_char="1040" id="token-9-2" morph="none" pos="punct" start_char="1040">,</TOKEN>
<TOKEN end_char="1046" id="token-9-3" morph="none" pos="word" start_char="1042">there</TOKEN>
<TOKEN end_char="1050" id="token-9-4" morph="none" pos="word" start_char="1048">has</TOKEN>
<TOKEN end_char="1055" id="token-9-5" morph="none" pos="word" start_char="1052">been</TOKEN>
<TOKEN end_char="1058" id="token-9-6" morph="none" pos="word" start_char="1057">no</TOKEN>
<TOKEN end_char="1062" id="token-9-7" morph="none" pos="word" start_char="1060">way</TOKEN>
<TOKEN end_char="1065" id="token-9-8" morph="none" pos="word" start_char="1064">to</TOKEN>
<TOKEN end_char="1070" id="token-9-9" morph="none" pos="word" start_char="1067">know</TOKEN>
<TOKEN end_char="1074" id="token-9-10" morph="none" pos="word" start_char="1072">who</TOKEN>
<TOKEN end_char="1082" id="token-9-11" morph="none" pos="word" start_char="1076">exactly</TOKEN>
<TOKEN end_char="1085" id="token-9-12" morph="none" pos="word" start_char="1084">is</TOKEN>
<TOKEN end_char="1091" id="token-9-13" morph="none" pos="word" start_char="1087">being</TOKEN>
<TOKEN end_char="1098" id="token-9-14" morph="none" pos="word" start_char="1093">tested</TOKEN>
<TOKEN end_char="1099" id="token-9-15" morph="none" pos="punct" start_char="1099">,</TOKEN>
<TOKEN end_char="1103" id="token-9-16" morph="none" pos="word" start_char="1101">and</TOKEN>
<TOKEN end_char="1108" id="token-9-17" morph="none" pos="word" start_char="1105">what</TOKEN>
<TOKEN end_char="1119" id="token-9-18" morph="none" pos="word" start_char="1110">proportion</TOKEN>
<TOKEN end_char="1122" id="token-9-19" morph="none" pos="word" start_char="1121">of</TOKEN>
<TOKEN end_char="1128" id="token-9-20" morph="none" pos="word" start_char="1124">those</TOKEN>
<TOKEN end_char="1136" id="token-9-21" morph="none" pos="word" start_char="1130">persons</TOKEN>
<TOKEN end_char="1143" id="token-9-22" morph="none" pos="word" start_char="1138">deemed</TOKEN>
<TOKEN end_char="1152" id="token-9-23" morph="none" pos="word" start_char="1145">eligible</TOKEN>
<TOKEN end_char="1155" id="token-9-24" morph="none" pos="word" start_char="1154">by</TOKEN>
<TOKEN end_char="1162" id="token-9-25" morph="none" pos="word" start_char="1157">ICMR’s</TOKEN>
<TOKEN end_char="1170" id="token-9-26" morph="none" pos="word" start_char="1164">testing</TOKEN>
<TOKEN end_char="1179" id="token-9-27" morph="none" pos="word" start_char="1172">criteria</TOKEN>
<TOKEN end_char="1182" id="token-9-28" morph="none" pos="word" start_char="1181">is</TOKEN>
<TOKEN end_char="1188" id="token-9-29" morph="none" pos="word" start_char="1184">being</TOKEN>
<TOKEN end_char="1195" id="token-9-30" morph="none" pos="word" start_char="1190">tested</TOKEN>
<TOKEN end_char="1196" id="token-9-31" morph="none" pos="punct" start_char="1196">.</TOKEN>
</SEG>
<SEG end_char="1412" id="segment-10" start_char="1199">
<ORIGINAL_TEXT>The new data shows that asymptomatic family members of confirmed cases formed the largest portion of those tested for whom information was available, and made up an even larger proportion of those testing positive.</ORIGINAL_TEXT>
<TOKEN end_char="1201" id="token-10-0" morph="none" pos="word" start_char="1199">The</TOKEN>
<TOKEN end_char="1205" id="token-10-1" morph="none" pos="word" start_char="1203">new</TOKEN>
<TOKEN end_char="1210" id="token-10-2" morph="none" pos="word" start_char="1207">data</TOKEN>
<TOKEN end_char="1216" id="token-10-3" morph="none" pos="word" start_char="1212">shows</TOKEN>
<TOKEN end_char="1221" id="token-10-4" morph="none" pos="word" start_char="1218">that</TOKEN>
<TOKEN end_char="1234" id="token-10-5" morph="none" pos="word" start_char="1223">asymptomatic</TOKEN>
<TOKEN end_char="1241" id="token-10-6" morph="none" pos="word" start_char="1236">family</TOKEN>
<TOKEN end_char="1249" id="token-10-7" morph="none" pos="word" start_char="1243">members</TOKEN>
<TOKEN end_char="1252" id="token-10-8" morph="none" pos="word" start_char="1251">of</TOKEN>
<TOKEN end_char="1262" id="token-10-9" morph="none" pos="word" start_char="1254">confirmed</TOKEN>
<TOKEN end_char="1268" id="token-10-10" morph="none" pos="word" start_char="1264">cases</TOKEN>
<TOKEN end_char="1275" id="token-10-11" morph="none" pos="word" start_char="1270">formed</TOKEN>
<TOKEN end_char="1279" id="token-10-12" morph="none" pos="word" start_char="1277">the</TOKEN>
<TOKEN end_char="1287" id="token-10-13" morph="none" pos="word" start_char="1281">largest</TOKEN>
<TOKEN end_char="1295" id="token-10-14" morph="none" pos="word" start_char="1289">portion</TOKEN>
<TOKEN end_char="1298" id="token-10-15" morph="none" pos="word" start_char="1297">of</TOKEN>
<TOKEN end_char="1304" id="token-10-16" morph="none" pos="word" start_char="1300">those</TOKEN>
<TOKEN end_char="1311" id="token-10-17" morph="none" pos="word" start_char="1306">tested</TOKEN>
<TOKEN end_char="1315" id="token-10-18" morph="none" pos="word" start_char="1313">for</TOKEN>
<TOKEN end_char="1320" id="token-10-19" morph="none" pos="word" start_char="1317">whom</TOKEN>
<TOKEN end_char="1332" id="token-10-20" morph="none" pos="word" start_char="1322">information</TOKEN>
<TOKEN end_char="1336" id="token-10-21" morph="none" pos="word" start_char="1334">was</TOKEN>
<TOKEN end_char="1346" id="token-10-22" morph="none" pos="word" start_char="1338">available</TOKEN>
<TOKEN end_char="1347" id="token-10-23" morph="none" pos="punct" start_char="1347">,</TOKEN>
<TOKEN end_char="1351" id="token-10-24" morph="none" pos="word" start_char="1349">and</TOKEN>
<TOKEN end_char="1356" id="token-10-25" morph="none" pos="word" start_char="1353">made</TOKEN>
<TOKEN end_char="1359" id="token-10-26" morph="none" pos="word" start_char="1358">up</TOKEN>
<TOKEN end_char="1362" id="token-10-27" morph="none" pos="word" start_char="1361">an</TOKEN>
<TOKEN end_char="1367" id="token-10-28" morph="none" pos="word" start_char="1364">even</TOKEN>
<TOKEN end_char="1374" id="token-10-29" morph="none" pos="word" start_char="1369">larger</TOKEN>
<TOKEN end_char="1385" id="token-10-30" morph="none" pos="word" start_char="1376">proportion</TOKEN>
<TOKEN end_char="1388" id="token-10-31" morph="none" pos="word" start_char="1387">of</TOKEN>
<TOKEN end_char="1394" id="token-10-32" morph="none" pos="word" start_char="1390">those</TOKEN>
<TOKEN end_char="1402" id="token-10-33" morph="none" pos="word" start_char="1396">testing</TOKEN>
<TOKEN end_char="1411" id="token-10-34" morph="none" pos="word" start_char="1404">positive</TOKEN>
<TOKEN end_char="1412" id="token-10-35" morph="none" pos="punct" start_char="1412">.</TOKEN>
</SEG>
<SEG end_char="1598" id="segment-11" start_char="1415">
<ORIGINAL_TEXT>The next biggest categories were symptomatic contacts of confirmed cases and those hospitalised with Severe Acute Respiratory Illness who were then tested for Covid and found positive.</ORIGINAL_TEXT>
<TOKEN end_char="1417" id="token-11-0" morph="none" pos="word" start_char="1415">The</TOKEN>
<TOKEN end_char="1422" id="token-11-1" morph="none" pos="word" start_char="1419">next</TOKEN>
<TOKEN end_char="1430" id="token-11-2" morph="none" pos="word" start_char="1424">biggest</TOKEN>
<TOKEN end_char="1441" id="token-11-3" morph="none" pos="word" start_char="1432">categories</TOKEN>
<TOKEN end_char="1446" id="token-11-4" morph="none" pos="word" start_char="1443">were</TOKEN>
<TOKEN end_char="1458" id="token-11-5" morph="none" pos="word" start_char="1448">symptomatic</TOKEN>
<TOKEN end_char="1467" id="token-11-6" morph="none" pos="word" start_char="1460">contacts</TOKEN>
<TOKEN end_char="1470" id="token-11-7" morph="none" pos="word" start_char="1469">of</TOKEN>
<TOKEN end_char="1480" id="token-11-8" morph="none" pos="word" start_char="1472">confirmed</TOKEN>
<TOKEN end_char="1486" id="token-11-9" morph="none" pos="word" start_char="1482">cases</TOKEN>
<TOKEN end_char="1490" id="token-11-10" morph="none" pos="word" start_char="1488">and</TOKEN>
<TOKEN end_char="1496" id="token-11-11" morph="none" pos="word" start_char="1492">those</TOKEN>
<TOKEN end_char="1509" id="token-11-12" morph="none" pos="word" start_char="1498">hospitalised</TOKEN>
<TOKEN end_char="1514" id="token-11-13" morph="none" pos="word" start_char="1511">with</TOKEN>
<TOKEN end_char="1521" id="token-11-14" morph="none" pos="word" start_char="1516">Severe</TOKEN>
<TOKEN end_char="1527" id="token-11-15" morph="none" pos="word" start_char="1523">Acute</TOKEN>
<TOKEN end_char="1539" id="token-11-16" morph="none" pos="word" start_char="1529">Respiratory</TOKEN>
<TOKEN end_char="1547" id="token-11-17" morph="none" pos="word" start_char="1541">Illness</TOKEN>
<TOKEN end_char="1551" id="token-11-18" morph="none" pos="word" start_char="1549">who</TOKEN>
<TOKEN end_char="1556" id="token-11-19" morph="none" pos="word" start_char="1553">were</TOKEN>
<TOKEN end_char="1561" id="token-11-20" morph="none" pos="word" start_char="1558">then</TOKEN>
<TOKEN end_char="1568" id="token-11-21" morph="none" pos="word" start_char="1563">tested</TOKEN>
<TOKEN end_char="1572" id="token-11-22" morph="none" pos="word" start_char="1570">for</TOKEN>
<TOKEN end_char="1578" id="token-11-23" morph="none" pos="word" start_char="1574">Covid</TOKEN>
<TOKEN end_char="1582" id="token-11-24" morph="none" pos="word" start_char="1580">and</TOKEN>
<TOKEN end_char="1588" id="token-11-25" morph="none" pos="word" start_char="1584">found</TOKEN>
<TOKEN end_char="1597" id="token-11-26" morph="none" pos="word" start_char="1590">positive</TOKEN>
<TOKEN end_char="1598" id="token-11-27" morph="none" pos="punct" start_char="1598">.</TOKEN>
</SEG>
<SEG end_char="1899" id="segment-12" start_char="1601">
<ORIGINAL_TEXT>Given that symptomatic contacts and asymptomatic family members of confirmed cases accounted for 65 per cent of all positive cases between them for which data was available, contact tracing would have been the most important measure that states could undertake to quickly identify and isolate cases.</ORIGINAL_TEXT>
<TOKEN end_char="1605" id="token-12-0" morph="none" pos="word" start_char="1601">Given</TOKEN>
<TOKEN end_char="1610" id="token-12-1" morph="none" pos="word" start_char="1607">that</TOKEN>
<TOKEN end_char="1622" id="token-12-2" morph="none" pos="word" start_char="1612">symptomatic</TOKEN>
<TOKEN end_char="1631" id="token-12-3" morph="none" pos="word" start_char="1624">contacts</TOKEN>
<TOKEN end_char="1635" id="token-12-4" morph="none" pos="word" start_char="1633">and</TOKEN>
<TOKEN end_char="1648" id="token-12-5" morph="none" pos="word" start_char="1637">asymptomatic</TOKEN>
<TOKEN end_char="1655" id="token-12-6" morph="none" pos="word" start_char="1650">family</TOKEN>
<TOKEN end_char="1663" id="token-12-7" morph="none" pos="word" start_char="1657">members</TOKEN>
<TOKEN end_char="1666" id="token-12-8" morph="none" pos="word" start_char="1665">of</TOKEN>
<TOKEN end_char="1676" id="token-12-9" morph="none" pos="word" start_char="1668">confirmed</TOKEN>
<TOKEN end_char="1682" id="token-12-10" morph="none" pos="word" start_char="1678">cases</TOKEN>
<TOKEN end_char="1692" id="token-12-11" morph="none" pos="word" start_char="1684">accounted</TOKEN>
<TOKEN end_char="1696" id="token-12-12" morph="none" pos="word" start_char="1694">for</TOKEN>
<TOKEN end_char="1699" id="token-12-13" morph="none" pos="word" start_char="1698">65</TOKEN>
<TOKEN end_char="1703" id="token-12-14" morph="none" pos="word" start_char="1701">per</TOKEN>
<TOKEN end_char="1708" id="token-12-15" morph="none" pos="word" start_char="1705">cent</TOKEN>
<TOKEN end_char="1711" id="token-12-16" morph="none" pos="word" start_char="1710">of</TOKEN>
<TOKEN end_char="1715" id="token-12-17" morph="none" pos="word" start_char="1713">all</TOKEN>
<TOKEN end_char="1724" id="token-12-18" morph="none" pos="word" start_char="1717">positive</TOKEN>
<TOKEN end_char="1730" id="token-12-19" morph="none" pos="word" start_char="1726">cases</TOKEN>
<TOKEN end_char="1738" id="token-12-20" morph="none" pos="word" start_char="1732">between</TOKEN>
<TOKEN end_char="1743" id="token-12-21" morph="none" pos="word" start_char="1740">them</TOKEN>
<TOKEN end_char="1747" id="token-12-22" morph="none" pos="word" start_char="1745">for</TOKEN>
<TOKEN end_char="1753" id="token-12-23" morph="none" pos="word" start_char="1749">which</TOKEN>
<TOKEN end_char="1758" id="token-12-24" morph="none" pos="word" start_char="1755">data</TOKEN>
<TOKEN end_char="1762" id="token-12-25" morph="none" pos="word" start_char="1760">was</TOKEN>
<TOKEN end_char="1772" id="token-12-26" morph="none" pos="word" start_char="1764">available</TOKEN>
<TOKEN end_char="1773" id="token-12-27" morph="none" pos="punct" start_char="1773">,</TOKEN>
<TOKEN end_char="1781" id="token-12-28" morph="none" pos="word" start_char="1775">contact</TOKEN>
<TOKEN end_char="1789" id="token-12-29" morph="none" pos="word" start_char="1783">tracing</TOKEN>
<TOKEN end_char="1795" id="token-12-30" morph="none" pos="word" start_char="1791">would</TOKEN>
<TOKEN end_char="1800" id="token-12-31" morph="none" pos="word" start_char="1797">have</TOKEN>
<TOKEN end_char="1805" id="token-12-32" morph="none" pos="word" start_char="1802">been</TOKEN>
<TOKEN end_char="1809" id="token-12-33" morph="none" pos="word" start_char="1807">the</TOKEN>
<TOKEN end_char="1814" id="token-12-34" morph="none" pos="word" start_char="1811">most</TOKEN>
<TOKEN end_char="1824" id="token-12-35" morph="none" pos="word" start_char="1816">important</TOKEN>
<TOKEN end_char="1832" id="token-12-36" morph="none" pos="word" start_char="1826">measure</TOKEN>
<TOKEN end_char="1837" id="token-12-37" morph="none" pos="word" start_char="1834">that</TOKEN>
<TOKEN end_char="1844" id="token-12-38" morph="none" pos="word" start_char="1839">states</TOKEN>
<TOKEN end_char="1850" id="token-12-39" morph="none" pos="word" start_char="1846">could</TOKEN>
<TOKEN end_char="1860" id="token-12-40" morph="none" pos="word" start_char="1852">undertake</TOKEN>
<TOKEN end_char="1863" id="token-12-41" morph="none" pos="word" start_char="1862">to</TOKEN>
<TOKEN end_char="1871" id="token-12-42" morph="none" pos="word" start_char="1865">quickly</TOKEN>
<TOKEN end_char="1880" id="token-12-43" morph="none" pos="word" start_char="1873">identify</TOKEN>
<TOKEN end_char="1884" id="token-12-44" morph="none" pos="word" start_char="1882">and</TOKEN>
<TOKEN end_char="1892" id="token-12-45" morph="none" pos="word" start_char="1886">isolate</TOKEN>
<TOKEN end_char="1898" id="token-12-46" morph="none" pos="word" start_char="1894">cases</TOKEN>
<TOKEN end_char="1899" id="token-12-47" morph="none" pos="punct" start_char="1899">.</TOKEN>
</SEG>
<SEG end_char="2001" id="segment-13" start_char="1902">
<ORIGINAL_TEXT>Yet, there was large variation between states in the number of contacts of a positive person tested.</ORIGINAL_TEXT>
<TOKEN end_char="1904" id="token-13-0" morph="none" pos="word" start_char="1902">Yet</TOKEN>
<TOKEN end_char="1905" id="token-13-1" morph="none" pos="punct" start_char="1905">,</TOKEN>
<TOKEN end_char="1911" id="token-13-2" morph="none" pos="word" start_char="1907">there</TOKEN>
<TOKEN end_char="1915" id="token-13-3" morph="none" pos="word" start_char="1913">was</TOKEN>
<TOKEN end_char="1921" id="token-13-4" morph="none" pos="word" start_char="1917">large</TOKEN>
<TOKEN end_char="1931" id="token-13-5" morph="none" pos="word" start_char="1923">variation</TOKEN>
<TOKEN end_char="1939" id="token-13-6" morph="none" pos="word" start_char="1933">between</TOKEN>
<TOKEN end_char="1946" id="token-13-7" morph="none" pos="word" start_char="1941">states</TOKEN>
<TOKEN end_char="1949" id="token-13-8" morph="none" pos="word" start_char="1948">in</TOKEN>
<TOKEN end_char="1953" id="token-13-9" morph="none" pos="word" start_char="1951">the</TOKEN>
<TOKEN end_char="1960" id="token-13-10" morph="none" pos="word" start_char="1955">number</TOKEN>
<TOKEN end_char="1963" id="token-13-11" morph="none" pos="word" start_char="1962">of</TOKEN>
<TOKEN end_char="1972" id="token-13-12" morph="none" pos="word" start_char="1965">contacts</TOKEN>
<TOKEN end_char="1975" id="token-13-13" morph="none" pos="word" start_char="1974">of</TOKEN>
<TOKEN end_char="1977" id="token-13-14" morph="none" pos="word" start_char="1977">a</TOKEN>
<TOKEN end_char="1986" id="token-13-15" morph="none" pos="word" start_char="1979">positive</TOKEN>
<TOKEN end_char="1993" id="token-13-16" morph="none" pos="word" start_char="1988">person</TOKEN>
<TOKEN end_char="2000" id="token-13-17" morph="none" pos="word" start_char="1995">tested</TOKEN>
<TOKEN end_char="2001" id="token-13-18" morph="none" pos="punct" start_char="2001">.</TOKEN>
</SEG>
<SEG end_char="2168" id="segment-14" start_char="2003">
<ORIGINAL_TEXT>Smaller states were, as expected, able to test more people, but many high burden states such as Maharashtra and Delhi are testing too few contacts per confirmed case.</ORIGINAL_TEXT>
<TOKEN end_char="2009" id="token-14-0" morph="none" pos="word" start_char="2003">Smaller</TOKEN>
<TOKEN end_char="2016" id="token-14-1" morph="none" pos="word" start_char="2011">states</TOKEN>
<TOKEN end_char="2021" id="token-14-2" morph="none" pos="word" start_char="2018">were</TOKEN>
<TOKEN end_char="2022" id="token-14-3" morph="none" pos="punct" start_char="2022">,</TOKEN>
<TOKEN end_char="2025" id="token-14-4" morph="none" pos="word" start_char="2024">as</TOKEN>
<TOKEN end_char="2034" id="token-14-5" morph="none" pos="word" start_char="2027">expected</TOKEN>
<TOKEN end_char="2035" id="token-14-6" morph="none" pos="punct" start_char="2035">,</TOKEN>
<TOKEN end_char="2040" id="token-14-7" morph="none" pos="word" start_char="2037">able</TOKEN>
<TOKEN end_char="2043" id="token-14-8" morph="none" pos="word" start_char="2042">to</TOKEN>
<TOKEN end_char="2048" id="token-14-9" morph="none" pos="word" start_char="2045">test</TOKEN>
<TOKEN end_char="2053" id="token-14-10" morph="none" pos="word" start_char="2050">more</TOKEN>
<TOKEN end_char="2060" id="token-14-11" morph="none" pos="word" start_char="2055">people</TOKEN>
<TOKEN end_char="2061" id="token-14-12" morph="none" pos="punct" start_char="2061">,</TOKEN>
<TOKEN end_char="2065" id="token-14-13" morph="none" pos="word" start_char="2063">but</TOKEN>
<TOKEN end_char="2070" id="token-14-14" morph="none" pos="word" start_char="2067">many</TOKEN>
<TOKEN end_char="2075" id="token-14-15" morph="none" pos="word" start_char="2072">high</TOKEN>
<TOKEN end_char="2082" id="token-14-16" morph="none" pos="word" start_char="2077">burden</TOKEN>
<TOKEN end_char="2089" id="token-14-17" morph="none" pos="word" start_char="2084">states</TOKEN>
<TOKEN end_char="2094" id="token-14-18" morph="none" pos="word" start_char="2091">such</TOKEN>
<TOKEN end_char="2097" id="token-14-19" morph="none" pos="word" start_char="2096">as</TOKEN>
<TOKEN end_char="2109" id="token-14-20" morph="none" pos="word" start_char="2099">Maharashtra</TOKEN>
<TOKEN end_char="2113" id="token-14-21" morph="none" pos="word" start_char="2111">and</TOKEN>
<TOKEN end_char="2119" id="token-14-22" morph="none" pos="word" start_char="2115">Delhi</TOKEN>
<TOKEN end_char="2123" id="token-14-23" morph="none" pos="word" start_char="2121">are</TOKEN>
<TOKEN end_char="2131" id="token-14-24" morph="none" pos="word" start_char="2125">testing</TOKEN>
<TOKEN end_char="2135" id="token-14-25" morph="none" pos="word" start_char="2133">too</TOKEN>
<TOKEN end_char="2139" id="token-14-26" morph="none" pos="word" start_char="2137">few</TOKEN>
<TOKEN end_char="2148" id="token-14-27" morph="none" pos="word" start_char="2141">contacts</TOKEN>
<TOKEN end_char="2152" id="token-14-28" morph="none" pos="word" start_char="2150">per</TOKEN>
<TOKEN end_char="2162" id="token-14-29" morph="none" pos="word" start_char="2154">confirmed</TOKEN>
<TOKEN end_char="2167" id="token-14-30" morph="none" pos="word" start_char="2164">case</TOKEN>
<TOKEN end_char="2168" id="token-14-31" morph="none" pos="punct" start_char="2168">.</TOKEN>
</SEG>
<SEG end_char="2236" id="segment-15" start_char="2170">
<ORIGINAL_TEXT>Among the major states, Karnataka cast the widest net for contacts.</ORIGINAL_TEXT>
<TOKEN end_char="2174" id="token-15-0" morph="none" pos="word" start_char="2170">Among</TOKEN>
<TOKEN end_char="2178" id="token-15-1" morph="none" pos="word" start_char="2176">the</TOKEN>
<TOKEN end_char="2184" id="token-15-2" morph="none" pos="word" start_char="2180">major</TOKEN>
<TOKEN end_char="2191" id="token-15-3" morph="none" pos="word" start_char="2186">states</TOKEN>
<TOKEN end_char="2192" id="token-15-4" morph="none" pos="punct" start_char="2192">,</TOKEN>
<TOKEN end_char="2202" id="token-15-5" morph="none" pos="word" start_char="2194">Karnataka</TOKEN>
<TOKEN end_char="2207" id="token-15-6" morph="none" pos="word" start_char="2204">cast</TOKEN>
<TOKEN end_char="2211" id="token-15-7" morph="none" pos="word" start_char="2209">the</TOKEN>
<TOKEN end_char="2218" id="token-15-8" morph="none" pos="word" start_char="2213">widest</TOKEN>
<TOKEN end_char="2222" id="token-15-9" morph="none" pos="word" start_char="2220">net</TOKEN>
<TOKEN end_char="2226" id="token-15-10" morph="none" pos="word" start_char="2224">for</TOKEN>
<TOKEN end_char="2235" id="token-15-11" morph="none" pos="word" start_char="2228">contacts</TOKEN>
<TOKEN end_char="2236" id="token-15-12" morph="none" pos="punct" start_char="2236">.</TOKEN>
</SEG>
<SEG end_char="2400" id="segment-16" start_char="2239">
<ORIGINAL_TEXT>Most worryingly, states that did the least testing among contacts of confirmed cases were among those with the highest rates of positive cases among those tested.</ORIGINAL_TEXT>
<TOKEN end_char="2242" id="token-16-0" morph="none" pos="word" start_char="2239">Most</TOKEN>
<TOKEN end_char="2253" id="token-16-1" morph="none" pos="word" start_char="2244">worryingly</TOKEN>
<TOKEN end_char="2254" id="token-16-2" morph="none" pos="punct" start_char="2254">,</TOKEN>
<TOKEN end_char="2261" id="token-16-3" morph="none" pos="word" start_char="2256">states</TOKEN>
<TOKEN end_char="2266" id="token-16-4" morph="none" pos="word" start_char="2263">that</TOKEN>
<TOKEN end_char="2270" id="token-16-5" morph="none" pos="word" start_char="2268">did</TOKEN>
<TOKEN end_char="2274" id="token-16-6" morph="none" pos="word" start_char="2272">the</TOKEN>
<TOKEN end_char="2280" id="token-16-7" morph="none" pos="word" start_char="2276">least</TOKEN>
<TOKEN end_char="2288" id="token-16-8" morph="none" pos="word" start_char="2282">testing</TOKEN>
<TOKEN end_char="2294" id="token-16-9" morph="none" pos="word" start_char="2290">among</TOKEN>
<TOKEN end_char="2303" id="token-16-10" morph="none" pos="word" start_char="2296">contacts</TOKEN>
<TOKEN end_char="2306" id="token-16-11" morph="none" pos="word" start_char="2305">of</TOKEN>
<TOKEN end_char="2316" id="token-16-12" morph="none" pos="word" start_char="2308">confirmed</TOKEN>
<TOKEN end_char="2322" id="token-16-13" morph="none" pos="word" start_char="2318">cases</TOKEN>
<TOKEN end_char="2327" id="token-16-14" morph="none" pos="word" start_char="2324">were</TOKEN>
<TOKEN end_char="2333" id="token-16-15" morph="none" pos="word" start_char="2329">among</TOKEN>
<TOKEN end_char="2339" id="token-16-16" morph="none" pos="word" start_char="2335">those</TOKEN>
<TOKEN end_char="2344" id="token-16-17" morph="none" pos="word" start_char="2341">with</TOKEN>
<TOKEN end_char="2348" id="token-16-18" morph="none" pos="word" start_char="2346">the</TOKEN>
<TOKEN end_char="2356" id="token-16-19" morph="none" pos="word" start_char="2350">highest</TOKEN>
<TOKEN end_char="2362" id="token-16-20" morph="none" pos="word" start_char="2358">rates</TOKEN>
<TOKEN end_char="2365" id="token-16-21" morph="none" pos="word" start_char="2364">of</TOKEN>
<TOKEN end_char="2374" id="token-16-22" morph="none" pos="word" start_char="2367">positive</TOKEN>
<TOKEN end_char="2380" id="token-16-23" morph="none" pos="word" start_char="2376">cases</TOKEN>
<TOKEN end_char="2386" id="token-16-24" morph="none" pos="word" start_char="2382">among</TOKEN>
<TOKEN end_char="2392" id="token-16-25" morph="none" pos="word" start_char="2388">those</TOKEN>
<TOKEN end_char="2399" id="token-16-26" morph="none" pos="word" start_char="2394">tested</TOKEN>
<TOKEN end_char="2400" id="token-16-27" morph="none" pos="punct" start_char="2400">.</TOKEN>
</SEG>
<SEG end_char="2554" id="segment-17" start_char="2402">
<ORIGINAL_TEXT>For instance, Maharashtra tested just two contacts for each confirmed case, yet 13 per cent of those contacts that they tested turned out to be positive.</ORIGINAL_TEXT>
<TOKEN end_char="2404" id="token-17-0" morph="none" pos="word" start_char="2402">For</TOKEN>
<TOKEN end_char="2413" id="token-17-1" morph="none" pos="word" start_char="2406">instance</TOKEN>
<TOKEN end_char="2414" id="token-17-2" morph="none" pos="punct" start_char="2414">,</TOKEN>
<TOKEN end_char="2426" id="token-17-3" morph="none" pos="word" start_char="2416">Maharashtra</TOKEN>
<TOKEN end_char="2433" id="token-17-4" morph="none" pos="word" start_char="2428">tested</TOKEN>
<TOKEN end_char="2438" id="token-17-5" morph="none" pos="word" start_char="2435">just</TOKEN>
<TOKEN end_char="2442" id="token-17-6" morph="none" pos="word" start_char="2440">two</TOKEN>
<TOKEN end_char="2451" id="token-17-7" morph="none" pos="word" start_char="2444">contacts</TOKEN>
<TOKEN end_char="2455" id="token-17-8" morph="none" pos="word" start_char="2453">for</TOKEN>
<TOKEN end_char="2460" id="token-17-9" morph="none" pos="word" start_char="2457">each</TOKEN>
<TOKEN end_char="2470" id="token-17-10" morph="none" pos="word" start_char="2462">confirmed</TOKEN>
<TOKEN end_char="2475" id="token-17-11" morph="none" pos="word" start_char="2472">case</TOKEN>
<TOKEN end_char="2476" id="token-17-12" morph="none" pos="punct" start_char="2476">,</TOKEN>
<TOKEN end_char="2480" id="token-17-13" morph="none" pos="word" start_char="2478">yet</TOKEN>
<TOKEN end_char="2483" id="token-17-14" morph="none" pos="word" start_char="2482">13</TOKEN>
<TOKEN end_char="2487" id="token-17-15" morph="none" pos="word" start_char="2485">per</TOKEN>
<TOKEN end_char="2492" id="token-17-16" morph="none" pos="word" start_char="2489">cent</TOKEN>
<TOKEN end_char="2495" id="token-17-17" morph="none" pos="word" start_char="2494">of</TOKEN>
<TOKEN end_char="2501" id="token-17-18" morph="none" pos="word" start_char="2497">those</TOKEN>
<TOKEN end_char="2510" id="token-17-19" morph="none" pos="word" start_char="2503">contacts</TOKEN>
<TOKEN end_char="2515" id="token-17-20" morph="none" pos="word" start_char="2512">that</TOKEN>
<TOKEN end_char="2520" id="token-17-21" morph="none" pos="word" start_char="2517">they</TOKEN>
<TOKEN end_char="2527" id="token-17-22" morph="none" pos="word" start_char="2522">tested</TOKEN>
<TOKEN end_char="2534" id="token-17-23" morph="none" pos="word" start_char="2529">turned</TOKEN>
<TOKEN end_char="2538" id="token-17-24" morph="none" pos="word" start_char="2536">out</TOKEN>
<TOKEN end_char="2541" id="token-17-25" morph="none" pos="word" start_char="2540">to</TOKEN>
<TOKEN end_char="2544" id="token-17-26" morph="none" pos="word" start_char="2543">be</TOKEN>
<TOKEN end_char="2553" id="token-17-27" morph="none" pos="word" start_char="2546">positive</TOKEN>
<TOKEN end_char="2554" id="token-17-28" morph="none" pos="punct" start_char="2554">.</TOKEN>
</SEG>
<SEG end_char="2673" id="segment-18" start_char="2557">
<ORIGINAL_TEXT>On the other hand, Karnataka tested 47 contacts for each confirmed case, and only 1 per cent of them tested positive.</ORIGINAL_TEXT>
<TOKEN end_char="2558" id="token-18-0" morph="none" pos="word" start_char="2557">On</TOKEN>
<TOKEN end_char="2562" id="token-18-1" morph="none" pos="word" start_char="2560">the</TOKEN>
<TOKEN end_char="2568" id="token-18-2" morph="none" pos="word" start_char="2564">other</TOKEN>
<TOKEN end_char="2573" id="token-18-3" morph="none" pos="word" start_char="2570">hand</TOKEN>
<TOKEN end_char="2574" id="token-18-4" morph="none" pos="punct" start_char="2574">,</TOKEN>
<TOKEN end_char="2584" id="token-18-5" morph="none" pos="word" start_char="2576">Karnataka</TOKEN>
<TOKEN end_char="2591" id="token-18-6" morph="none" pos="word" start_char="2586">tested</TOKEN>
<TOKEN end_char="2594" id="token-18-7" morph="none" pos="word" start_char="2593">47</TOKEN>
<TOKEN end_char="2603" id="token-18-8" morph="none" pos="word" start_char="2596">contacts</TOKEN>
<TOKEN end_char="2607" id="token-18-9" morph="none" pos="word" start_char="2605">for</TOKEN>
<TOKEN end_char="2612" id="token-18-10" morph="none" pos="word" start_char="2609">each</TOKEN>
<TOKEN end_char="2622" id="token-18-11" morph="none" pos="word" start_char="2614">confirmed</TOKEN>
<TOKEN end_char="2627" id="token-18-12" morph="none" pos="word" start_char="2624">case</TOKEN>
<TOKEN end_char="2628" id="token-18-13" morph="none" pos="punct" start_char="2628">,</TOKEN>
<TOKEN end_char="2632" id="token-18-14" morph="none" pos="word" start_char="2630">and</TOKEN>
<TOKEN end_char="2637" id="token-18-15" morph="none" pos="word" start_char="2634">only</TOKEN>
<TOKEN end_char="2639" id="token-18-16" morph="none" pos="word" start_char="2639">1</TOKEN>
<TOKEN end_char="2643" id="token-18-17" morph="none" pos="word" start_char="2641">per</TOKEN>
<TOKEN end_char="2648" id="token-18-18" morph="none" pos="word" start_char="2645">cent</TOKEN>
<TOKEN end_char="2651" id="token-18-19" morph="none" pos="word" start_char="2650">of</TOKEN>
<TOKEN end_char="2656" id="token-18-20" morph="none" pos="word" start_char="2653">them</TOKEN>
<TOKEN end_char="2663" id="token-18-21" morph="none" pos="word" start_char="2658">tested</TOKEN>
<TOKEN end_char="2672" id="token-18-22" morph="none" pos="word" start_char="2665">positive</TOKEN>
<TOKEN end_char="2673" id="token-18-23" morph="none" pos="punct" start_char="2673">.</TOKEN>
</SEG>
<SEG end_char="2843" id="segment-19" start_char="2675">
<ORIGINAL_TEXT>This can only mean that high burden states that are testing few contacts of each confirmed case will need to cast the net far wider to discover the true extent of cases.</ORIGINAL_TEXT>
<TOKEN end_char="2678" id="token-19-0" morph="none" pos="word" start_char="2675">This</TOKEN>
<TOKEN end_char="2682" id="token-19-1" morph="none" pos="word" start_char="2680">can</TOKEN>
<TOKEN end_char="2687" id="token-19-2" morph="none" pos="word" start_char="2684">only</TOKEN>
<TOKEN end_char="2692" id="token-19-3" morph="none" pos="word" start_char="2689">mean</TOKEN>
<TOKEN end_char="2697" id="token-19-4" morph="none" pos="word" start_char="2694">that</TOKEN>
<TOKEN end_char="2702" id="token-19-5" morph="none" pos="word" start_char="2699">high</TOKEN>
<TOKEN end_char="2709" id="token-19-6" morph="none" pos="word" start_char="2704">burden</TOKEN>
<TOKEN end_char="2716" id="token-19-7" morph="none" pos="word" start_char="2711">states</TOKEN>
<TOKEN end_char="2721" id="token-19-8" morph="none" pos="word" start_char="2718">that</TOKEN>
<TOKEN end_char="2725" id="token-19-9" morph="none" pos="word" start_char="2723">are</TOKEN>
<TOKEN end_char="2733" id="token-19-10" morph="none" pos="word" start_char="2727">testing</TOKEN>
<TOKEN end_char="2737" id="token-19-11" morph="none" pos="word" start_char="2735">few</TOKEN>
<TOKEN end_char="2746" id="token-19-12" morph="none" pos="word" start_char="2739">contacts</TOKEN>
<TOKEN end_char="2749" id="token-19-13" morph="none" pos="word" start_char="2748">of</TOKEN>
<TOKEN end_char="2754" id="token-19-14" morph="none" pos="word" start_char="2751">each</TOKEN>
<TOKEN end_char="2764" id="token-19-15" morph="none" pos="word" start_char="2756">confirmed</TOKEN>
<TOKEN end_char="2769" id="token-19-16" morph="none" pos="word" start_char="2766">case</TOKEN>
<TOKEN end_char="2774" id="token-19-17" morph="none" pos="word" start_char="2771">will</TOKEN>
<TOKEN end_char="2779" id="token-19-18" morph="none" pos="word" start_char="2776">need</TOKEN>
<TOKEN end_char="2782" id="token-19-19" morph="none" pos="word" start_char="2781">to</TOKEN>
<TOKEN end_char="2787" id="token-19-20" morph="none" pos="word" start_char="2784">cast</TOKEN>
<TOKEN end_char="2791" id="token-19-21" morph="none" pos="word" start_char="2789">the</TOKEN>
<TOKEN end_char="2795" id="token-19-22" morph="none" pos="word" start_char="2793">net</TOKEN>
<TOKEN end_char="2799" id="token-19-23" morph="none" pos="word" start_char="2797">far</TOKEN>
<TOKEN end_char="2805" id="token-19-24" morph="none" pos="word" start_char="2801">wider</TOKEN>
<TOKEN end_char="2808" id="token-19-25" morph="none" pos="word" start_char="2807">to</TOKEN>
<TOKEN end_char="2817" id="token-19-26" morph="none" pos="word" start_char="2810">discover</TOKEN>
<TOKEN end_char="2821" id="token-19-27" morph="none" pos="word" start_char="2819">the</TOKEN>
<TOKEN end_char="2826" id="token-19-28" morph="none" pos="word" start_char="2823">true</TOKEN>
<TOKEN end_char="2833" id="token-19-29" morph="none" pos="word" start_char="2828">extent</TOKEN>
<TOKEN end_char="2836" id="token-19-30" morph="none" pos="word" start_char="2835">of</TOKEN>
<TOKEN end_char="2842" id="token-19-31" morph="none" pos="word" start_char="2838">cases</TOKEN>
<TOKEN end_char="2843" id="token-19-32" morph="none" pos="punct" start_char="2843">.</TOKEN>
</SEG>
<SEG end_char="3006" id="segment-20" start_char="2846">
<ORIGINAL_TEXT>Moreover, for 44 per cent of those who tested positive, and 57 per cent of those tested in all, their links to known cases were either not known or not recorded.</ORIGINAL_TEXT>
<TOKEN end_char="2853" id="token-20-0" morph="none" pos="word" start_char="2846">Moreover</TOKEN>
<TOKEN end_char="2854" id="token-20-1" morph="none" pos="punct" start_char="2854">,</TOKEN>
<TOKEN end_char="2858" id="token-20-2" morph="none" pos="word" start_char="2856">for</TOKEN>
<TOKEN end_char="2861" id="token-20-3" morph="none" pos="word" start_char="2860">44</TOKEN>
<TOKEN end_char="2865" id="token-20-4" morph="none" pos="word" start_char="2863">per</TOKEN>
<TOKEN end_char="2870" id="token-20-5" morph="none" pos="word" start_char="2867">cent</TOKEN>
<TOKEN end_char="2873" id="token-20-6" morph="none" pos="word" start_char="2872">of</TOKEN>
<TOKEN end_char="2879" id="token-20-7" morph="none" pos="word" start_char="2875">those</TOKEN>
<TOKEN end_char="2883" id="token-20-8" morph="none" pos="word" start_char="2881">who</TOKEN>
<TOKEN end_char="2890" id="token-20-9" morph="none" pos="word" start_char="2885">tested</TOKEN>
<TOKEN end_char="2899" id="token-20-10" morph="none" pos="word" start_char="2892">positive</TOKEN>
<TOKEN end_char="2900" id="token-20-11" morph="none" pos="punct" start_char="2900">,</TOKEN>
<TOKEN end_char="2904" id="token-20-12" morph="none" pos="word" start_char="2902">and</TOKEN>
<TOKEN end_char="2907" id="token-20-13" morph="none" pos="word" start_char="2906">57</TOKEN>
<TOKEN end_char="2911" id="token-20-14" morph="none" pos="word" start_char="2909">per</TOKEN>
<TOKEN end_char="2916" id="token-20-15" morph="none" pos="word" start_char="2913">cent</TOKEN>
<TOKEN end_char="2919" id="token-20-16" morph="none" pos="word" start_char="2918">of</TOKEN>
<TOKEN end_char="2925" id="token-20-17" morph="none" pos="word" start_char="2921">those</TOKEN>
<TOKEN end_char="2932" id="token-20-18" morph="none" pos="word" start_char="2927">tested</TOKEN>
<TOKEN end_char="2935" id="token-20-19" morph="none" pos="word" start_char="2934">in</TOKEN>
<TOKEN end_char="2939" id="token-20-20" morph="none" pos="word" start_char="2937">all</TOKEN>
<TOKEN end_char="2940" id="token-20-21" morph="none" pos="punct" start_char="2940">,</TOKEN>
<TOKEN end_char="2946" id="token-20-22" morph="none" pos="word" start_char="2942">their</TOKEN>
<TOKEN end_char="2952" id="token-20-23" morph="none" pos="word" start_char="2948">links</TOKEN>
<TOKEN end_char="2955" id="token-20-24" morph="none" pos="word" start_char="2954">to</TOKEN>
<TOKEN end_char="2961" id="token-20-25" morph="none" pos="word" start_char="2957">known</TOKEN>
<TOKEN end_char="2967" id="token-20-26" morph="none" pos="word" start_char="2963">cases</TOKEN>
<TOKEN end_char="2972" id="token-20-27" morph="none" pos="word" start_char="2969">were</TOKEN>
<TOKEN end_char="2979" id="token-20-28" morph="none" pos="word" start_char="2974">either</TOKEN>
<TOKEN end_char="2983" id="token-20-29" morph="none" pos="word" start_char="2981">not</TOKEN>
<TOKEN end_char="2989" id="token-20-30" morph="none" pos="word" start_char="2985">known</TOKEN>
<TOKEN end_char="2992" id="token-20-31" morph="none" pos="word" start_char="2991">or</TOKEN>
<TOKEN end_char="2996" id="token-20-32" morph="none" pos="word" start_char="2994">not</TOKEN>
<TOKEN end_char="3005" id="token-20-33" morph="none" pos="word" start_char="2998">recorded</TOKEN>
<TOKEN end_char="3006" id="token-20-34" morph="none" pos="punct" start_char="3006">.</TOKEN>
</SEG>
<SEG end_char="3091" id="segment-21" start_char="3008">
<ORIGINAL_TEXT>ICMR data shows that the number with "unspecified" modes of transmission is growing.</ORIGINAL_TEXT>
<TOKEN end_char="3011" id="token-21-0" morph="none" pos="word" start_char="3008">ICMR</TOKEN>
<TOKEN end_char="3016" id="token-21-1" morph="none" pos="word" start_char="3013">data</TOKEN>
<TOKEN end_char="3022" id="token-21-2" morph="none" pos="word" start_char="3018">shows</TOKEN>
<TOKEN end_char="3027" id="token-21-3" morph="none" pos="word" start_char="3024">that</TOKEN>
<TOKEN end_char="3031" id="token-21-4" morph="none" pos="word" start_char="3029">the</TOKEN>
<TOKEN end_char="3038" id="token-21-5" morph="none" pos="word" start_char="3033">number</TOKEN>
<TOKEN end_char="3043" id="token-21-6" morph="none" pos="word" start_char="3040">with</TOKEN>
<TOKEN end_char="3045" id="token-21-7" morph="none" pos="punct" start_char="3045">"</TOKEN>
<TOKEN end_char="3056" id="token-21-8" morph="none" pos="word" start_char="3046">unspecified</TOKEN>
<TOKEN end_char="3057" id="token-21-9" morph="none" pos="punct" start_char="3057">"</TOKEN>
<TOKEN end_char="3063" id="token-21-10" morph="none" pos="word" start_char="3059">modes</TOKEN>
<TOKEN end_char="3066" id="token-21-11" morph="none" pos="word" start_char="3065">of</TOKEN>
<TOKEN end_char="3079" id="token-21-12" morph="none" pos="word" start_char="3068">transmission</TOKEN>
<TOKEN end_char="3082" id="token-21-13" morph="none" pos="word" start_char="3081">is</TOKEN>
<TOKEN end_char="3090" id="token-21-14" morph="none" pos="word" start_char="3084">growing</TOKEN>
<TOKEN end_char="3091" id="token-21-15" morph="none" pos="punct" start_char="3091">.</TOKEN>
</SEG>
<SEG end_char="3363" id="segment-22" start_char="3094">
<ORIGINAL_TEXT>This is in stark contrast to, say, South Korea where the percentage of patients who test positive after being identified through contact tracing and placed under self-quarantine is near 80 per cent, according to Korea’s Centers for Disease Control and Prevention (KCDC).</ORIGINAL_TEXT>
<TOKEN end_char="3097" id="token-22-0" morph="none" pos="word" start_char="3094">This</TOKEN>
<TOKEN end_char="3100" id="token-22-1" morph="none" pos="word" start_char="3099">is</TOKEN>
<TOKEN end_char="3103" id="token-22-2" morph="none" pos="word" start_char="3102">in</TOKEN>
<TOKEN end_char="3109" id="token-22-3" morph="none" pos="word" start_char="3105">stark</TOKEN>
<TOKEN end_char="3118" id="token-22-4" morph="none" pos="word" start_char="3111">contrast</TOKEN>
<TOKEN end_char="3121" id="token-22-5" morph="none" pos="word" start_char="3120">to</TOKEN>
<TOKEN end_char="3122" id="token-22-6" morph="none" pos="punct" start_char="3122">,</TOKEN>
<TOKEN end_char="3126" id="token-22-7" morph="none" pos="word" start_char="3124">say</TOKEN>
<TOKEN end_char="3127" id="token-22-8" morph="none" pos="punct" start_char="3127">,</TOKEN>
<TOKEN end_char="3133" id="token-22-9" morph="none" pos="word" start_char="3129">South</TOKEN>
<TOKEN end_char="3139" id="token-22-10" morph="none" pos="word" start_char="3135">Korea</TOKEN>
<TOKEN end_char="3145" id="token-22-11" morph="none" pos="word" start_char="3141">where</TOKEN>
<TOKEN end_char="3149" id="token-22-12" morph="none" pos="word" start_char="3147">the</TOKEN>
<TOKEN end_char="3160" id="token-22-13" morph="none" pos="word" start_char="3151">percentage</TOKEN>
<TOKEN end_char="3163" id="token-22-14" morph="none" pos="word" start_char="3162">of</TOKEN>
<TOKEN end_char="3172" id="token-22-15" morph="none" pos="word" start_char="3165">patients</TOKEN>
<TOKEN end_char="3176" id="token-22-16" morph="none" pos="word" start_char="3174">who</TOKEN>
<TOKEN end_char="3181" id="token-22-17" morph="none" pos="word" start_char="3178">test</TOKEN>
<TOKEN end_char="3190" id="token-22-18" morph="none" pos="word" start_char="3183">positive</TOKEN>
<TOKEN end_char="3196" id="token-22-19" morph="none" pos="word" start_char="3192">after</TOKEN>
<TOKEN end_char="3202" id="token-22-20" morph="none" pos="word" start_char="3198">being</TOKEN>
<TOKEN end_char="3213" id="token-22-21" morph="none" pos="word" start_char="3204">identified</TOKEN>
<TOKEN end_char="3221" id="token-22-22" morph="none" pos="word" start_char="3215">through</TOKEN>
<TOKEN end_char="3229" id="token-22-23" morph="none" pos="word" start_char="3223">contact</TOKEN>
<TOKEN end_char="3237" id="token-22-24" morph="none" pos="word" start_char="3231">tracing</TOKEN>
<TOKEN end_char="3241" id="token-22-25" morph="none" pos="word" start_char="3239">and</TOKEN>
<TOKEN end_char="3248" id="token-22-26" morph="none" pos="word" start_char="3243">placed</TOKEN>
<TOKEN end_char="3254" id="token-22-27" morph="none" pos="word" start_char="3250">under</TOKEN>
<TOKEN end_char="3270" id="token-22-28" morph="none" pos="unknown" start_char="3256">self-quarantine</TOKEN>
<TOKEN end_char="3273" id="token-22-29" morph="none" pos="word" start_char="3272">is</TOKEN>
<TOKEN end_char="3278" id="token-22-30" morph="none" pos="word" start_char="3275">near</TOKEN>
<TOKEN end_char="3281" id="token-22-31" morph="none" pos="word" start_char="3280">80</TOKEN>
<TOKEN end_char="3285" id="token-22-32" morph="none" pos="word" start_char="3283">per</TOKEN>
<TOKEN end_char="3290" id="token-22-33" morph="none" pos="word" start_char="3287">cent</TOKEN>
<TOKEN end_char="3291" id="token-22-34" morph="none" pos="punct" start_char="3291">,</TOKEN>
<TOKEN end_char="3301" id="token-22-35" morph="none" pos="word" start_char="3293">according</TOKEN>
<TOKEN end_char="3304" id="token-22-36" morph="none" pos="word" start_char="3303">to</TOKEN>
<TOKEN end_char="3312" id="token-22-37" morph="none" pos="word" start_char="3306">Korea’s</TOKEN>
<TOKEN end_char="3320" id="token-22-38" morph="none" pos="word" start_char="3314">Centers</TOKEN>
<TOKEN end_char="3324" id="token-22-39" morph="none" pos="word" start_char="3322">for</TOKEN>
<TOKEN end_char="3332" id="token-22-40" morph="none" pos="word" start_char="3326">Disease</TOKEN>
<TOKEN end_char="3340" id="token-22-41" morph="none" pos="word" start_char="3334">Control</TOKEN>
<TOKEN end_char="3344" id="token-22-42" morph="none" pos="word" start_char="3342">and</TOKEN>
<TOKEN end_char="3355" id="token-22-43" morph="none" pos="word" start_char="3346">Prevention</TOKEN>
<TOKEN end_char="3357" id="token-22-44" morph="none" pos="punct" start_char="3357">(</TOKEN>
<TOKEN end_char="3361" id="token-22-45" morph="none" pos="word" start_char="3358">KCDC</TOKEN>
<TOKEN end_char="3363" id="token-22-46" morph="none" pos="punct" start_char="3362">).</TOKEN>
</SEG>
<SEG end_char="3587" id="segment-23" start_char="3366">
<ORIGINAL_TEXT>In several key states, including Bihar, Andhra Pradesh, Odisha and Rajasthan, the transmission details of the vast majority of persons tested where they are suspected to have contracted the infection from is not available.</ORIGINAL_TEXT>
<TOKEN end_char="3367" id="token-23-0" morph="none" pos="word" start_char="3366">In</TOKEN>
<TOKEN end_char="3375" id="token-23-1" morph="none" pos="word" start_char="3369">several</TOKEN>
<TOKEN end_char="3379" id="token-23-2" morph="none" pos="word" start_char="3377">key</TOKEN>
<TOKEN end_char="3386" id="token-23-3" morph="none" pos="word" start_char="3381">states</TOKEN>
<TOKEN end_char="3387" id="token-23-4" morph="none" pos="punct" start_char="3387">,</TOKEN>
<TOKEN end_char="3397" id="token-23-5" morph="none" pos="word" start_char="3389">including</TOKEN>
<TOKEN end_char="3403" id="token-23-6" morph="none" pos="word" start_char="3399">Bihar</TOKEN>
<TOKEN end_char="3404" id="token-23-7" morph="none" pos="punct" start_char="3404">,</TOKEN>
<TOKEN end_char="3411" id="token-23-8" morph="none" pos="word" start_char="3406">Andhra</TOKEN>
<TOKEN end_char="3419" id="token-23-9" morph="none" pos="word" start_char="3413">Pradesh</TOKEN>
<TOKEN end_char="3420" id="token-23-10" morph="none" pos="punct" start_char="3420">,</TOKEN>
<TOKEN end_char="3427" id="token-23-11" morph="none" pos="word" start_char="3422">Odisha</TOKEN>
<TOKEN end_char="3431" id="token-23-12" morph="none" pos="word" start_char="3429">and</TOKEN>
<TOKEN end_char="3441" id="token-23-13" morph="none" pos="word" start_char="3433">Rajasthan</TOKEN>
<TOKEN end_char="3442" id="token-23-14" morph="none" pos="punct" start_char="3442">,</TOKEN>
<TOKEN end_char="3446" id="token-23-15" morph="none" pos="word" start_char="3444">the</TOKEN>
<TOKEN end_char="3459" id="token-23-16" morph="none" pos="word" start_char="3448">transmission</TOKEN>
<TOKEN end_char="3467" id="token-23-17" morph="none" pos="word" start_char="3461">details</TOKEN>
<TOKEN end_char="3470" id="token-23-18" morph="none" pos="word" start_char="3469">of</TOKEN>
<TOKEN end_char="3474" id="token-23-19" morph="none" pos="word" start_char="3472">the</TOKEN>
<TOKEN end_char="3479" id="token-23-20" morph="none" pos="word" start_char="3476">vast</TOKEN>
<TOKEN end_char="3488" id="token-23-21" morph="none" pos="word" start_char="3481">majority</TOKEN>
<TOKEN end_char="3491" id="token-23-22" morph="none" pos="word" start_char="3490">of</TOKEN>
<TOKEN end_char="3499" id="token-23-23" morph="none" pos="word" start_char="3493">persons</TOKEN>
<TOKEN end_char="3506" id="token-23-24" morph="none" pos="word" start_char="3501">tested</TOKEN>
<TOKEN end_char="3512" id="token-23-25" morph="none" pos="word" start_char="3508">where</TOKEN>
<TOKEN end_char="3517" id="token-23-26" morph="none" pos="word" start_char="3514">they</TOKEN>
<TOKEN end_char="3521" id="token-23-27" morph="none" pos="word" start_char="3519">are</TOKEN>
<TOKEN end_char="3531" id="token-23-28" morph="none" pos="word" start_char="3523">suspected</TOKEN>
<TOKEN end_char="3534" id="token-23-29" morph="none" pos="word" start_char="3533">to</TOKEN>
<TOKEN end_char="3539" id="token-23-30" morph="none" pos="word" start_char="3536">have</TOKEN>
<TOKEN end_char="3550" id="token-23-31" morph="none" pos="word" start_char="3541">contracted</TOKEN>
<TOKEN end_char="3554" id="token-23-32" morph="none" pos="word" start_char="3552">the</TOKEN>
<TOKEN end_char="3564" id="token-23-33" morph="none" pos="word" start_char="3556">infection</TOKEN>
<TOKEN end_char="3569" id="token-23-34" morph="none" pos="word" start_char="3566">from</TOKEN>
<TOKEN end_char="3572" id="token-23-35" morph="none" pos="word" start_char="3571">is</TOKEN>
<TOKEN end_char="3576" id="token-23-36" morph="none" pos="word" start_char="3574">not</TOKEN>
<TOKEN end_char="3586" id="token-23-37" morph="none" pos="word" start_char="3578">available</TOKEN>
<TOKEN end_char="3587" id="token-23-38" morph="none" pos="punct" start_char="3587">.</TOKEN>
</SEG>
<SEG end_char="3691" id="segment-24" start_char="3589">
<ORIGINAL_TEXT>This could either mean widespread community transmission, or poor recording on the part of authorities.</ORIGINAL_TEXT>
<TOKEN end_char="3592" id="token-24-0" morph="none" pos="word" start_char="3589">This</TOKEN>
<TOKEN end_char="3598" id="token-24-1" morph="none" pos="word" start_char="3594">could</TOKEN>
<TOKEN end_char="3605" id="token-24-2" morph="none" pos="word" start_char="3600">either</TOKEN>
<TOKEN end_char="3610" id="token-24-3" morph="none" pos="word" start_char="3607">mean</TOKEN>
<TOKEN end_char="3621" id="token-24-4" morph="none" pos="word" start_char="3612">widespread</TOKEN>
<TOKEN end_char="3631" id="token-24-5" morph="none" pos="word" start_char="3623">community</TOKEN>
<TOKEN end_char="3644" id="token-24-6" morph="none" pos="word" start_char="3633">transmission</TOKEN>
<TOKEN end_char="3645" id="token-24-7" morph="none" pos="punct" start_char="3645">,</TOKEN>
<TOKEN end_char="3648" id="token-24-8" morph="none" pos="word" start_char="3647">or</TOKEN>
<TOKEN end_char="3653" id="token-24-9" morph="none" pos="word" start_char="3650">poor</TOKEN>
<TOKEN end_char="3663" id="token-24-10" morph="none" pos="word" start_char="3655">recording</TOKEN>
<TOKEN end_char="3666" id="token-24-11" morph="none" pos="word" start_char="3665">on</TOKEN>
<TOKEN end_char="3670" id="token-24-12" morph="none" pos="word" start_char="3668">the</TOKEN>
<TOKEN end_char="3675" id="token-24-13" morph="none" pos="word" start_char="3672">part</TOKEN>
<TOKEN end_char="3678" id="token-24-14" morph="none" pos="word" start_char="3677">of</TOKEN>
<TOKEN end_char="3690" id="token-24-15" morph="none" pos="word" start_char="3680">authorities</TOKEN>
<TOKEN end_char="3691" id="token-24-16" morph="none" pos="punct" start_char="3691">.</TOKEN>
</SEG>
<SEG end_char="3733" id="segment-25" start_char="3693">
<ORIGINAL_TEXT>Either way, it is a worrisome indication.</ORIGINAL_TEXT>
<TOKEN end_char="3698" id="token-25-0" morph="none" pos="word" start_char="3693">Either</TOKEN>
<TOKEN end_char="3702" id="token-25-1" morph="none" pos="word" start_char="3700">way</TOKEN>
<TOKEN end_char="3703" id="token-25-2" morph="none" pos="punct" start_char="3703">,</TOKEN>
<TOKEN end_char="3706" id="token-25-3" morph="none" pos="word" start_char="3705">it</TOKEN>
<TOKEN end_char="3709" id="token-25-4" morph="none" pos="word" start_char="3708">is</TOKEN>
<TOKEN end_char="3711" id="token-25-5" morph="none" pos="word" start_char="3711">a</TOKEN>
<TOKEN end_char="3721" id="token-25-6" morph="none" pos="word" start_char="3713">worrisome</TOKEN>
<TOKEN end_char="3732" id="token-25-7" morph="none" pos="word" start_char="3723">indication</TOKEN>
<TOKEN end_char="3733" id="token-25-8" morph="none" pos="punct" start_char="3733">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="ukr">
<DOC grammar="none" id="L0C049P8E" lang="ukr" raw_text_char_length="4239" raw_text_md5="eddd642c7b35fe5b70ac21f6c917f41b" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="62" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Is China Seeking Approval to Kill 20,000 Coronavirus Patients?</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">Is</TOKEN>
<TOKEN end_char="8" id="token-0-1" morph="none" pos="word" start_char="4">China</TOKEN>
<TOKEN end_char="16" id="token-0-2" morph="none" pos="word" start_char="10">Seeking</TOKEN>
<TOKEN end_char="25" id="token-0-3" morph="none" pos="word" start_char="18">Approval</TOKEN>
<TOKEN end_char="28" id="token-0-4" morph="none" pos="word" start_char="27">to</TOKEN>
<TOKEN end_char="33" id="token-0-5" morph="none" pos="word" start_char="30">Kill</TOKEN>
<TOKEN end_char="40" id="token-0-6" morph="none" pos="unknown" start_char="35">20,000</TOKEN>
<TOKEN end_char="52" id="token-0-7" morph="none" pos="word" start_char="42">Coronavirus</TOKEN>
<TOKEN end_char="61" id="token-0-8" morph="none" pos="word" start_char="54">Patients</TOKEN>
<TOKEN end_char="62" id="token-0-9" morph="none" pos="punct" start_char="62">?</TOKEN>
</SEG>
<SEG end_char="101" id="segment-1" start_char="67">
<ORIGINAL_TEXT>Image via Anthony Kwan/Getty Images</ORIGINAL_TEXT>
<TOKEN end_char="71" id="token-1-0" morph="none" pos="word" start_char="67">Image</TOKEN>
<TOKEN end_char="75" id="token-1-1" morph="none" pos="word" start_char="73">via</TOKEN>
<TOKEN end_char="83" id="token-1-2" morph="none" pos="word" start_char="77">Anthony</TOKEN>
<TOKEN end_char="94" id="token-1-3" morph="none" pos="unknown" start_char="85">Kwan/Getty</TOKEN>
<TOKEN end_char="101" id="token-1-4" morph="none" pos="word" start_char="96">Images</TOKEN>
</SEG>
<SEG end_char="111" id="segment-2" start_char="105">
<ORIGINAL_TEXT>On Feb.</ORIGINAL_TEXT>
<TOKEN end_char="106" id="token-2-0" morph="none" pos="word" start_char="105">On</TOKEN>
<TOKEN end_char="110" id="token-2-1" morph="none" pos="word" start_char="108">Feb</TOKEN>
<TOKEN end_char="111" id="token-2-2" morph="none" pos="punct" start_char="111">.</TOKEN>
</SEG>
<SEG end_char="375" id="segment-3" start_char="113">
<ORIGINAL_TEXT>5, 2020, the website AB-TC (aka City News) published an article that claimed Chinese officials were seeking approval from the Supreme People’s Court to start the mass killing of 20,000 people infected with the new coronavirus in an attempt to contain the disease:</ORIGINAL_TEXT>
<TOKEN end_char="113" id="token-3-0" morph="none" pos="word" start_char="113">5</TOKEN>
<TOKEN end_char="114" id="token-3-1" morph="none" pos="punct" start_char="114">,</TOKEN>
<TOKEN end_char="119" id="token-3-2" morph="none" pos="word" start_char="116">2020</TOKEN>
<TOKEN end_char="120" id="token-3-3" morph="none" pos="punct" start_char="120">,</TOKEN>
<TOKEN end_char="124" id="token-3-4" morph="none" pos="word" start_char="122">the</TOKEN>
<TOKEN end_char="132" id="token-3-5" morph="none" pos="word" start_char="126">website</TOKEN>
<TOKEN end_char="138" id="token-3-6" morph="none" pos="unknown" start_char="134">AB-TC</TOKEN>
<TOKEN end_char="140" id="token-3-7" morph="none" pos="punct" start_char="140">(</TOKEN>
<TOKEN end_char="143" id="token-3-8" morph="none" pos="word" start_char="141">aka</TOKEN>
<TOKEN end_char="148" id="token-3-9" morph="none" pos="word" start_char="145">City</TOKEN>
<TOKEN end_char="153" id="token-3-10" morph="none" pos="word" start_char="150">News</TOKEN>
<TOKEN end_char="154" id="token-3-11" morph="none" pos="punct" start_char="154">)</TOKEN>
<TOKEN end_char="164" id="token-3-12" morph="none" pos="word" start_char="156">published</TOKEN>
<TOKEN end_char="167" id="token-3-13" morph="none" pos="word" start_char="166">an</TOKEN>
<TOKEN end_char="175" id="token-3-14" morph="none" pos="word" start_char="169">article</TOKEN>
<TOKEN end_char="180" id="token-3-15" morph="none" pos="word" start_char="177">that</TOKEN>
<TOKEN end_char="188" id="token-3-16" morph="none" pos="word" start_char="182">claimed</TOKEN>
<TOKEN end_char="196" id="token-3-17" morph="none" pos="word" start_char="190">Chinese</TOKEN>
<TOKEN end_char="206" id="token-3-18" morph="none" pos="word" start_char="198">officials</TOKEN>
<TOKEN end_char="211" id="token-3-19" morph="none" pos="word" start_char="208">were</TOKEN>
<TOKEN end_char="219" id="token-3-20" morph="none" pos="word" start_char="213">seeking</TOKEN>
<TOKEN end_char="228" id="token-3-21" morph="none" pos="word" start_char="221">approval</TOKEN>
<TOKEN end_char="233" id="token-3-22" morph="none" pos="word" start_char="230">from</TOKEN>
<TOKEN end_char="237" id="token-3-23" morph="none" pos="word" start_char="235">the</TOKEN>
<TOKEN end_char="245" id="token-3-24" morph="none" pos="word" start_char="239">Supreme</TOKEN>
<TOKEN end_char="254" id="token-3-25" morph="none" pos="word" start_char="247">People’s</TOKEN>
<TOKEN end_char="260" id="token-3-26" morph="none" pos="word" start_char="256">Court</TOKEN>
<TOKEN end_char="263" id="token-3-27" morph="none" pos="word" start_char="262">to</TOKEN>
<TOKEN end_char="269" id="token-3-28" morph="none" pos="word" start_char="265">start</TOKEN>
<TOKEN end_char="273" id="token-3-29" morph="none" pos="word" start_char="271">the</TOKEN>
<TOKEN end_char="278" id="token-3-30" morph="none" pos="word" start_char="275">mass</TOKEN>
<TOKEN end_char="286" id="token-3-31" morph="none" pos="word" start_char="280">killing</TOKEN>
<TOKEN end_char="289" id="token-3-32" morph="none" pos="word" start_char="288">of</TOKEN>
<TOKEN end_char="296" id="token-3-33" morph="none" pos="unknown" start_char="291">20,000</TOKEN>
<TOKEN end_char="303" id="token-3-34" morph="none" pos="word" start_char="298">people</TOKEN>
<TOKEN end_char="312" id="token-3-35" morph="none" pos="word" start_char="305">infected</TOKEN>
<TOKEN end_char="317" id="token-3-36" morph="none" pos="word" start_char="314">with</TOKEN>
<TOKEN end_char="321" id="token-3-37" morph="none" pos="word" start_char="319">the</TOKEN>
<TOKEN end_char="325" id="token-3-38" morph="none" pos="word" start_char="323">new</TOKEN>
<TOKEN end_char="337" id="token-3-39" morph="none" pos="word" start_char="327">coronavirus</TOKEN>
<TOKEN end_char="340" id="token-3-40" morph="none" pos="word" start_char="339">in</TOKEN>
<TOKEN end_char="343" id="token-3-41" morph="none" pos="word" start_char="342">an</TOKEN>
<TOKEN end_char="351" id="token-3-42" morph="none" pos="word" start_char="345">attempt</TOKEN>
<TOKEN end_char="354" id="token-3-43" morph="none" pos="word" start_char="353">to</TOKEN>
<TOKEN end_char="362" id="token-3-44" morph="none" pos="word" start_char="356">contain</TOKEN>
<TOKEN end_char="366" id="token-3-45" morph="none" pos="word" start_char="364">the</TOKEN>
<TOKEN end_char="374" id="token-3-46" morph="none" pos="word" start_char="368">disease</TOKEN>
<TOKEN end_char="375" id="token-3-47" morph="none" pos="punct" start_char="375">:</TOKEN>
</SEG>
<SEG end_char="715" id="segment-4" start_char="378">
<ORIGINAL_TEXT>China seek for court’s approval to kill the over 20,000 coronavirus patients to avoid further spread of the virus The highest level of court in Chhina [sic], Supreme People’s Court, is expected to give an approval on Friday for the mass killing of coronavirus patients in China as sure means of controlling the spread of the deadly virus.</ORIGINAL_TEXT>
<TOKEN end_char="382" id="token-4-0" morph="none" pos="word" start_char="378">China</TOKEN>
<TOKEN end_char="387" id="token-4-1" morph="none" pos="word" start_char="384">seek</TOKEN>
<TOKEN end_char="391" id="token-4-2" morph="none" pos="word" start_char="389">for</TOKEN>
<TOKEN end_char="399" id="token-4-3" morph="none" pos="word" start_char="393">court’s</TOKEN>
<TOKEN end_char="408" id="token-4-4" morph="none" pos="word" start_char="401">approval</TOKEN>
<TOKEN end_char="411" id="token-4-5" morph="none" pos="word" start_char="410">to</TOKEN>
<TOKEN end_char="416" id="token-4-6" morph="none" pos="word" start_char="413">kill</TOKEN>
<TOKEN end_char="420" id="token-4-7" morph="none" pos="word" start_char="418">the</TOKEN>
<TOKEN end_char="425" id="token-4-8" morph="none" pos="word" start_char="422">over</TOKEN>
<TOKEN end_char="432" id="token-4-9" morph="none" pos="unknown" start_char="427">20,000</TOKEN>
<TOKEN end_char="444" id="token-4-10" morph="none" pos="word" start_char="434">coronavirus</TOKEN>
<TOKEN end_char="453" id="token-4-11" morph="none" pos="word" start_char="446">patients</TOKEN>
<TOKEN end_char="456" id="token-4-12" morph="none" pos="word" start_char="455">to</TOKEN>
<TOKEN end_char="462" id="token-4-13" morph="none" pos="word" start_char="458">avoid</TOKEN>
<TOKEN end_char="470" id="token-4-14" morph="none" pos="word" start_char="464">further</TOKEN>
<TOKEN end_char="477" id="token-4-15" morph="none" pos="word" start_char="472">spread</TOKEN>
<TOKEN end_char="480" id="token-4-16" morph="none" pos="word" start_char="479">of</TOKEN>
<TOKEN end_char="484" id="token-4-17" morph="none" pos="word" start_char="482">the</TOKEN>
<TOKEN end_char="490" id="token-4-18" morph="none" pos="word" start_char="486">virus</TOKEN>
<TOKEN end_char="494" id="token-4-19" morph="none" pos="word" start_char="492">The</TOKEN>
<TOKEN end_char="502" id="token-4-20" morph="none" pos="word" start_char="496">highest</TOKEN>
<TOKEN end_char="508" id="token-4-21" morph="none" pos="word" start_char="504">level</TOKEN>
<TOKEN end_char="511" id="token-4-22" morph="none" pos="word" start_char="510">of</TOKEN>
<TOKEN end_char="517" id="token-4-23" morph="none" pos="word" start_char="513">court</TOKEN>
<TOKEN end_char="520" id="token-4-24" morph="none" pos="word" start_char="519">in</TOKEN>
<TOKEN end_char="527" id="token-4-25" morph="none" pos="word" start_char="522">Chhina</TOKEN>
<TOKEN end_char="529" id="token-4-26" morph="none" pos="punct" start_char="529">[</TOKEN>
<TOKEN end_char="532" id="token-4-27" morph="none" pos="word" start_char="530">sic</TOKEN>
<TOKEN end_char="534" id="token-4-28" morph="none" pos="punct" start_char="533">],</TOKEN>
<TOKEN end_char="542" id="token-4-29" morph="none" pos="word" start_char="536">Supreme</TOKEN>
<TOKEN end_char="551" id="token-4-30" morph="none" pos="word" start_char="544">People’s</TOKEN>
<TOKEN end_char="557" id="token-4-31" morph="none" pos="word" start_char="553">Court</TOKEN>
<TOKEN end_char="558" id="token-4-32" morph="none" pos="punct" start_char="558">,</TOKEN>
<TOKEN end_char="561" id="token-4-33" morph="none" pos="word" start_char="560">is</TOKEN>
<TOKEN end_char="570" id="token-4-34" morph="none" pos="word" start_char="563">expected</TOKEN>
<TOKEN end_char="573" id="token-4-35" morph="none" pos="word" start_char="572">to</TOKEN>
<TOKEN end_char="578" id="token-4-36" morph="none" pos="word" start_char="575">give</TOKEN>
<TOKEN end_char="581" id="token-4-37" morph="none" pos="word" start_char="580">an</TOKEN>
<TOKEN end_char="590" id="token-4-38" morph="none" pos="word" start_char="583">approval</TOKEN>
<TOKEN end_char="593" id="token-4-39" morph="none" pos="word" start_char="592">on</TOKEN>
<TOKEN end_char="600" id="token-4-40" morph="none" pos="word" start_char="595">Friday</TOKEN>
<TOKEN end_char="604" id="token-4-41" morph="none" pos="word" start_char="602">for</TOKEN>
<TOKEN end_char="608" id="token-4-42" morph="none" pos="word" start_char="606">the</TOKEN>
<TOKEN end_char="613" id="token-4-43" morph="none" pos="word" start_char="610">mass</TOKEN>
<TOKEN end_char="621" id="token-4-44" morph="none" pos="word" start_char="615">killing</TOKEN>
<TOKEN end_char="624" id="token-4-45" morph="none" pos="word" start_char="623">of</TOKEN>
<TOKEN end_char="636" id="token-4-46" morph="none" pos="word" start_char="626">coronavirus</TOKEN>
<TOKEN end_char="645" id="token-4-47" morph="none" pos="word" start_char="638">patients</TOKEN>
<TOKEN end_char="648" id="token-4-48" morph="none" pos="word" start_char="647">in</TOKEN>
<TOKEN end_char="654" id="token-4-49" morph="none" pos="word" start_char="650">China</TOKEN>
<TOKEN end_char="657" id="token-4-50" morph="none" pos="word" start_char="656">as</TOKEN>
<TOKEN end_char="662" id="token-4-51" morph="none" pos="word" start_char="659">sure</TOKEN>
<TOKEN end_char="668" id="token-4-52" morph="none" pos="word" start_char="664">means</TOKEN>
<TOKEN end_char="671" id="token-4-53" morph="none" pos="word" start_char="670">of</TOKEN>
<TOKEN end_char="683" id="token-4-54" morph="none" pos="word" start_char="673">controlling</TOKEN>
<TOKEN end_char="687" id="token-4-55" morph="none" pos="word" start_char="685">the</TOKEN>
<TOKEN end_char="694" id="token-4-56" morph="none" pos="word" start_char="689">spread</TOKEN>
<TOKEN end_char="697" id="token-4-57" morph="none" pos="word" start_char="696">of</TOKEN>
<TOKEN end_char="701" id="token-4-58" morph="none" pos="word" start_char="699">the</TOKEN>
<TOKEN end_char="708" id="token-4-59" morph="none" pos="word" start_char="703">deadly</TOKEN>
<TOKEN end_char="714" id="token-4-60" morph="none" pos="word" start_char="710">virus</TOKEN>
<TOKEN end_char="715" id="token-4-61" morph="none" pos="punct" start_char="715">.</TOKEN>
</SEG>
<SEG end_char="868" id="segment-5" start_char="717">
<ORIGINAL_TEXT>The State tells the court that China is on the verge of losing its health workers to Coronavirus as at least 20 health workers contract the virus daily.</ORIGINAL_TEXT>
<TOKEN end_char="719" id="token-5-0" morph="none" pos="word" start_char="717">The</TOKEN>
<TOKEN end_char="725" id="token-5-1" morph="none" pos="word" start_char="721">State</TOKEN>
<TOKEN end_char="731" id="token-5-2" morph="none" pos="word" start_char="727">tells</TOKEN>
<TOKEN end_char="735" id="token-5-3" morph="none" pos="word" start_char="733">the</TOKEN>
<TOKEN end_char="741" id="token-5-4" morph="none" pos="word" start_char="737">court</TOKEN>
<TOKEN end_char="746" id="token-5-5" morph="none" pos="word" start_char="743">that</TOKEN>
<TOKEN end_char="752" id="token-5-6" morph="none" pos="word" start_char="748">China</TOKEN>
<TOKEN end_char="755" id="token-5-7" morph="none" pos="word" start_char="754">is</TOKEN>
<TOKEN end_char="758" id="token-5-8" morph="none" pos="word" start_char="757">on</TOKEN>
<TOKEN end_char="762" id="token-5-9" morph="none" pos="word" start_char="760">the</TOKEN>
<TOKEN end_char="768" id="token-5-10" morph="none" pos="word" start_char="764">verge</TOKEN>
<TOKEN end_char="771" id="token-5-11" morph="none" pos="word" start_char="770">of</TOKEN>
<TOKEN end_char="778" id="token-5-12" morph="none" pos="word" start_char="773">losing</TOKEN>
<TOKEN end_char="782" id="token-5-13" morph="none" pos="word" start_char="780">its</TOKEN>
<TOKEN end_char="789" id="token-5-14" morph="none" pos="word" start_char="784">health</TOKEN>
<TOKEN end_char="797" id="token-5-15" morph="none" pos="word" start_char="791">workers</TOKEN>
<TOKEN end_char="800" id="token-5-16" morph="none" pos="word" start_char="799">to</TOKEN>
<TOKEN end_char="812" id="token-5-17" morph="none" pos="word" start_char="802">Coronavirus</TOKEN>
<TOKEN end_char="815" id="token-5-18" morph="none" pos="word" start_char="814">as</TOKEN>
<TOKEN end_char="818" id="token-5-19" morph="none" pos="word" start_char="817">at</TOKEN>
<TOKEN end_char="824" id="token-5-20" morph="none" pos="word" start_char="820">least</TOKEN>
<TOKEN end_char="827" id="token-5-21" morph="none" pos="word" start_char="826">20</TOKEN>
<TOKEN end_char="834" id="token-5-22" morph="none" pos="word" start_char="829">health</TOKEN>
<TOKEN end_char="842" id="token-5-23" morph="none" pos="word" start_char="836">workers</TOKEN>
<TOKEN end_char="851" id="token-5-24" morph="none" pos="word" start_char="844">contract</TOKEN>
<TOKEN end_char="855" id="token-5-25" morph="none" pos="word" start_char="853">the</TOKEN>
<TOKEN end_char="861" id="token-5-26" morph="none" pos="word" start_char="857">virus</TOKEN>
<TOKEN end_char="867" id="token-5-27" morph="none" pos="word" start_char="863">daily</TOKEN>
<TOKEN end_char="868" id="token-5-28" morph="none" pos="punct" start_char="868">.</TOKEN>
</SEG>
<SEG end_char="905" id="segment-6" start_char="872">
<ORIGINAL_TEXT>This is not a genuine news report.</ORIGINAL_TEXT>
<TOKEN end_char="875" id="token-6-0" morph="none" pos="word" start_char="872">This</TOKEN>
<TOKEN end_char="878" id="token-6-1" morph="none" pos="word" start_char="877">is</TOKEN>
<TOKEN end_char="882" id="token-6-2" morph="none" pos="word" start_char="880">not</TOKEN>
<TOKEN end_char="884" id="token-6-3" morph="none" pos="word" start_char="884">a</TOKEN>
<TOKEN end_char="892" id="token-6-4" morph="none" pos="word" start_char="886">genuine</TOKEN>
<TOKEN end_char="897" id="token-6-5" morph="none" pos="word" start_char="894">news</TOKEN>
<TOKEN end_char="904" id="token-6-6" morph="none" pos="word" start_char="899">report</TOKEN>
<TOKEN end_char="905" id="token-6-7" morph="none" pos="punct" start_char="905">.</TOKEN>
</SEG>
<SEG end_char="1078" id="segment-7" start_char="907">
<ORIGINAL_TEXT>While the AB-TC website does not carry any disclaimers labeling its content as fiction, we found a number of red flags concerning the legitimacy of this outlet’s reporting.</ORIGINAL_TEXT>
<TOKEN end_char="911" id="token-7-0" morph="none" pos="word" start_char="907">While</TOKEN>
<TOKEN end_char="915" id="token-7-1" morph="none" pos="word" start_char="913">the</TOKEN>
<TOKEN end_char="921" id="token-7-2" morph="none" pos="unknown" start_char="917">AB-TC</TOKEN>
<TOKEN end_char="929" id="token-7-3" morph="none" pos="word" start_char="923">website</TOKEN>
<TOKEN end_char="934" id="token-7-4" morph="none" pos="word" start_char="931">does</TOKEN>
<TOKEN end_char="938" id="token-7-5" morph="none" pos="word" start_char="936">not</TOKEN>
<TOKEN end_char="944" id="token-7-6" morph="none" pos="word" start_char="940">carry</TOKEN>
<TOKEN end_char="948" id="token-7-7" morph="none" pos="word" start_char="946">any</TOKEN>
<TOKEN end_char="960" id="token-7-8" morph="none" pos="word" start_char="950">disclaimers</TOKEN>
<TOKEN end_char="969" id="token-7-9" morph="none" pos="word" start_char="962">labeling</TOKEN>
<TOKEN end_char="973" id="token-7-10" morph="none" pos="word" start_char="971">its</TOKEN>
<TOKEN end_char="981" id="token-7-11" morph="none" pos="word" start_char="975">content</TOKEN>
<TOKEN end_char="984" id="token-7-12" morph="none" pos="word" start_char="983">as</TOKEN>
<TOKEN end_char="992" id="token-7-13" morph="none" pos="word" start_char="986">fiction</TOKEN>
<TOKEN end_char="993" id="token-7-14" morph="none" pos="punct" start_char="993">,</TOKEN>
<TOKEN end_char="996" id="token-7-15" morph="none" pos="word" start_char="995">we</TOKEN>
<TOKEN end_char="1002" id="token-7-16" morph="none" pos="word" start_char="998">found</TOKEN>
<TOKEN end_char="1004" id="token-7-17" morph="none" pos="word" start_char="1004">a</TOKEN>
<TOKEN end_char="1011" id="token-7-18" morph="none" pos="word" start_char="1006">number</TOKEN>
<TOKEN end_char="1014" id="token-7-19" morph="none" pos="word" start_char="1013">of</TOKEN>
<TOKEN end_char="1018" id="token-7-20" morph="none" pos="word" start_char="1016">red</TOKEN>
<TOKEN end_char="1024" id="token-7-21" morph="none" pos="word" start_char="1020">flags</TOKEN>
<TOKEN end_char="1035" id="token-7-22" morph="none" pos="word" start_char="1026">concerning</TOKEN>
<TOKEN end_char="1039" id="token-7-23" morph="none" pos="word" start_char="1037">the</TOKEN>
<TOKEN end_char="1050" id="token-7-24" morph="none" pos="word" start_char="1041">legitimacy</TOKEN>
<TOKEN end_char="1053" id="token-7-25" morph="none" pos="word" start_char="1052">of</TOKEN>
<TOKEN end_char="1058" id="token-7-26" morph="none" pos="word" start_char="1055">this</TOKEN>
<TOKEN end_char="1067" id="token-7-27" morph="none" pos="word" start_char="1060">outlet’s</TOKEN>
<TOKEN end_char="1077" id="token-7-28" morph="none" pos="word" start_char="1069">reporting</TOKEN>
<TOKEN end_char="1078" id="token-7-29" morph="none" pos="punct" start_char="1078">.</TOKEN>
</SEG>
<SEG end_char="1136" id="segment-8" start_char="1081">
<ORIGINAL_TEXT>For starters, this website is full of junk news stories.</ORIGINAL_TEXT>
<TOKEN end_char="1083" id="token-8-0" morph="none" pos="word" start_char="1081">For</TOKEN>
<TOKEN end_char="1092" id="token-8-1" morph="none" pos="word" start_char="1085">starters</TOKEN>
<TOKEN end_char="1093" id="token-8-2" morph="none" pos="punct" start_char="1093">,</TOKEN>
<TOKEN end_char="1098" id="token-8-3" morph="none" pos="word" start_char="1095">this</TOKEN>
<TOKEN end_char="1106" id="token-8-4" morph="none" pos="word" start_char="1100">website</TOKEN>
<TOKEN end_char="1109" id="token-8-5" morph="none" pos="word" start_char="1108">is</TOKEN>
<TOKEN end_char="1114" id="token-8-6" morph="none" pos="word" start_char="1111">full</TOKEN>
<TOKEN end_char="1117" id="token-8-7" morph="none" pos="word" start_char="1116">of</TOKEN>
<TOKEN end_char="1122" id="token-8-8" morph="none" pos="word" start_char="1119">junk</TOKEN>
<TOKEN end_char="1127" id="token-8-9" morph="none" pos="word" start_char="1124">news</TOKEN>
<TOKEN end_char="1135" id="token-8-10" morph="none" pos="word" start_char="1129">stories</TOKEN>
<TOKEN end_char="1136" id="token-8-11" morph="none" pos="punct" start_char="1136">.</TOKEN>
</SEG>
<SEG end_char="1281" id="segment-9" start_char="1138">
<ORIGINAL_TEXT>For instance, a July 2010 article (still featured on the homepage) carries the headline, "BREAKING: New York Giants coach Pat Shurmur has died."</ORIGINAL_TEXT>
<TOKEN end_char="1140" id="token-9-0" morph="none" pos="word" start_char="1138">For</TOKEN>
<TOKEN end_char="1149" id="token-9-1" morph="none" pos="word" start_char="1142">instance</TOKEN>
<TOKEN end_char="1150" id="token-9-2" morph="none" pos="punct" start_char="1150">,</TOKEN>
<TOKEN end_char="1152" id="token-9-3" morph="none" pos="word" start_char="1152">a</TOKEN>
<TOKEN end_char="1157" id="token-9-4" morph="none" pos="word" start_char="1154">July</TOKEN>
<TOKEN end_char="1162" id="token-9-5" morph="none" pos="word" start_char="1159">2010</TOKEN>
<TOKEN end_char="1170" id="token-9-6" morph="none" pos="word" start_char="1164">article</TOKEN>
<TOKEN end_char="1172" id="token-9-7" morph="none" pos="punct" start_char="1172">(</TOKEN>
<TOKEN end_char="1177" id="token-9-8" morph="none" pos="word" start_char="1173">still</TOKEN>
<TOKEN end_char="1186" id="token-9-9" morph="none" pos="word" start_char="1179">featured</TOKEN>
<TOKEN end_char="1189" id="token-9-10" morph="none" pos="word" start_char="1188">on</TOKEN>
<TOKEN end_char="1193" id="token-9-11" morph="none" pos="word" start_char="1191">the</TOKEN>
<TOKEN end_char="1202" id="token-9-12" morph="none" pos="word" start_char="1195">homepage</TOKEN>
<TOKEN end_char="1203" id="token-9-13" morph="none" pos="punct" start_char="1203">)</TOKEN>
<TOKEN end_char="1211" id="token-9-14" morph="none" pos="word" start_char="1205">carries</TOKEN>
<TOKEN end_char="1215" id="token-9-15" morph="none" pos="word" start_char="1213">the</TOKEN>
<TOKEN end_char="1224" id="token-9-16" morph="none" pos="word" start_char="1217">headline</TOKEN>
<TOKEN end_char="1225" id="token-9-17" morph="none" pos="punct" start_char="1225">,</TOKEN>
<TOKEN end_char="1227" id="token-9-18" morph="none" pos="punct" start_char="1227">"</TOKEN>
<TOKEN end_char="1235" id="token-9-19" morph="none" pos="word" start_char="1228">BREAKING</TOKEN>
<TOKEN end_char="1236" id="token-9-20" morph="none" pos="punct" start_char="1236">:</TOKEN>
<TOKEN end_char="1240" id="token-9-21" morph="none" pos="word" start_char="1238">New</TOKEN>
<TOKEN end_char="1245" id="token-9-22" morph="none" pos="word" start_char="1242">York</TOKEN>
<TOKEN end_char="1252" id="token-9-23" morph="none" pos="word" start_char="1247">Giants</TOKEN>
<TOKEN end_char="1258" id="token-9-24" morph="none" pos="word" start_char="1254">coach</TOKEN>
<TOKEN end_char="1262" id="token-9-25" morph="none" pos="word" start_char="1260">Pat</TOKEN>
<TOKEN end_char="1270" id="token-9-26" morph="none" pos="word" start_char="1264">Shurmur</TOKEN>
<TOKEN end_char="1274" id="token-9-27" morph="none" pos="word" start_char="1272">has</TOKEN>
<TOKEN end_char="1279" id="token-9-28" morph="none" pos="word" start_char="1276">died</TOKEN>
<TOKEN end_char="1281" id="token-9-29" morph="none" pos="punct" start_char="1280">."</TOKEN>
</SEG>
<SEG end_char="1313" id="segment-10" start_char="1283">
<ORIGINAL_TEXT>But Shurmur didn’t die in 2010.</ORIGINAL_TEXT>
<TOKEN end_char="1285" id="token-10-0" morph="none" pos="word" start_char="1283">But</TOKEN>
<TOKEN end_char="1293" id="token-10-1" morph="none" pos="word" start_char="1287">Shurmur</TOKEN>
<TOKEN end_char="1300" id="token-10-2" morph="none" pos="word" start_char="1295">didn’t</TOKEN>
<TOKEN end_char="1304" id="token-10-3" morph="none" pos="word" start_char="1302">die</TOKEN>
<TOKEN end_char="1307" id="token-10-4" morph="none" pos="word" start_char="1306">in</TOKEN>
<TOKEN end_char="1312" id="token-10-5" morph="none" pos="word" start_char="1309">2010</TOKEN>
<TOKEN end_char="1313" id="token-10-6" morph="none" pos="punct" start_char="1313">.</TOKEN>
<TRANSLATED_TEXT>But Shurmur didn't die in 2010.</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="1442" id="segment-11" start_char="1315">
<ORIGINAL_TEXT>In fact, he is still alive as of this writing and was hired as the offensive coordinator for the Denver Broncos in January 2020.</ORIGINAL_TEXT>
<TOKEN end_char="1316" id="token-11-0" morph="none" pos="word" start_char="1315">In</TOKEN>
<TOKEN end_char="1321" id="token-11-1" morph="none" pos="word" start_char="1318">fact</TOKEN>
<TOKEN end_char="1322" id="token-11-2" morph="none" pos="punct" start_char="1322">,</TOKEN>
<TOKEN end_char="1325" id="token-11-3" morph="none" pos="word" start_char="1324">he</TOKEN>
<TOKEN end_char="1328" id="token-11-4" morph="none" pos="word" start_char="1327">is</TOKEN>
<TOKEN end_char="1334" id="token-11-5" morph="none" pos="word" start_char="1330">still</TOKEN>
<TOKEN end_char="1340" id="token-11-6" morph="none" pos="word" start_char="1336">alive</TOKEN>
<TOKEN end_char="1343" id="token-11-7" morph="none" pos="word" start_char="1342">as</TOKEN>
<TOKEN end_char="1346" id="token-11-8" morph="none" pos="word" start_char="1345">of</TOKEN>
<TOKEN end_char="1351" id="token-11-9" morph="none" pos="word" start_char="1348">this</TOKEN>
<TOKEN end_char="1359" id="token-11-10" morph="none" pos="word" start_char="1353">writing</TOKEN>
<TOKEN end_char="1363" id="token-11-11" morph="none" pos="word" start_char="1361">and</TOKEN>
<TOKEN end_char="1367" id="token-11-12" morph="none" pos="word" start_char="1365">was</TOKEN>
<TOKEN end_char="1373" id="token-11-13" morph="none" pos="word" start_char="1369">hired</TOKEN>
<TOKEN end_char="1376" id="token-11-14" morph="none" pos="word" start_char="1375">as</TOKEN>
<TOKEN end_char="1380" id="token-11-15" morph="none" pos="word" start_char="1378">the</TOKEN>
<TOKEN end_char="1390" id="token-11-16" morph="none" pos="word" start_char="1382">offensive</TOKEN>
<TOKEN end_char="1402" id="token-11-17" morph="none" pos="word" start_char="1392">coordinator</TOKEN>
<TOKEN end_char="1406" id="token-11-18" morph="none" pos="word" start_char="1404">for</TOKEN>
<TOKEN end_char="1410" id="token-11-19" morph="none" pos="word" start_char="1408">the</TOKEN>
<TOKEN end_char="1417" id="token-11-20" morph="none" pos="word" start_char="1412">Denver</TOKEN>
<TOKEN end_char="1425" id="token-11-21" morph="none" pos="word" start_char="1419">Broncos</TOKEN>
<TOKEN end_char="1428" id="token-11-22" morph="none" pos="word" start_char="1427">in</TOKEN>
<TOKEN end_char="1436" id="token-11-23" morph="none" pos="word" start_char="1430">January</TOKEN>
<TOKEN end_char="1441" id="token-11-24" morph="none" pos="word" start_char="1438">2020</TOKEN>
<TOKEN end_char="1442" id="token-11-25" morph="none" pos="punct" start_char="1442">.</TOKEN>
</SEG>
<SEG end_char="1720" id="segment-12" start_char="1445">
<ORIGINAL_TEXT>The website has also published hoax articles about "cannibal restaurants" (debunked here), death hoaxes about celebrity couples (debunked here), doctored tweets from U.S. President Donald Trump, and a junk news article that falsely claimed Prince Andrew had committed suicide.</ORIGINAL_TEXT>
<TOKEN end_char="1447" id="token-12-0" morph="none" pos="word" start_char="1445">The</TOKEN>
<TOKEN end_char="1455" id="token-12-1" morph="none" pos="word" start_char="1449">website</TOKEN>
<TOKEN end_char="1459" id="token-12-2" morph="none" pos="word" start_char="1457">has</TOKEN>
<TOKEN end_char="1464" id="token-12-3" morph="none" pos="word" start_char="1461">also</TOKEN>
<TOKEN end_char="1474" id="token-12-4" morph="none" pos="word" start_char="1466">published</TOKEN>
<TOKEN end_char="1479" id="token-12-5" morph="none" pos="word" start_char="1476">hoax</TOKEN>
<TOKEN end_char="1488" id="token-12-6" morph="none" pos="word" start_char="1481">articles</TOKEN>
<TOKEN end_char="1494" id="token-12-7" morph="none" pos="word" start_char="1490">about</TOKEN>
<TOKEN end_char="1496" id="token-12-8" morph="none" pos="punct" start_char="1496">"</TOKEN>
<TOKEN end_char="1504" id="token-12-9" morph="none" pos="word" start_char="1497">cannibal</TOKEN>
<TOKEN end_char="1516" id="token-12-10" morph="none" pos="word" start_char="1506">restaurants</TOKEN>
<TOKEN end_char="1517" id="token-12-11" morph="none" pos="punct" start_char="1517">"</TOKEN>
<TOKEN end_char="1519" id="token-12-12" morph="none" pos="punct" start_char="1519">(</TOKEN>
<TOKEN end_char="1527" id="token-12-13" morph="none" pos="word" start_char="1520">debunked</TOKEN>
<TOKEN end_char="1532" id="token-12-14" morph="none" pos="word" start_char="1529">here</TOKEN>
<TOKEN end_char="1534" id="token-12-15" morph="none" pos="punct" start_char="1533">),</TOKEN>
<TOKEN end_char="1540" id="token-12-16" morph="none" pos="word" start_char="1536">death</TOKEN>
<TOKEN end_char="1547" id="token-12-17" morph="none" pos="word" start_char="1542">hoaxes</TOKEN>
<TOKEN end_char="1553" id="token-12-18" morph="none" pos="word" start_char="1549">about</TOKEN>
<TOKEN end_char="1563" id="token-12-19" morph="none" pos="word" start_char="1555">celebrity</TOKEN>
<TOKEN end_char="1571" id="token-12-20" morph="none" pos="word" start_char="1565">couples</TOKEN>
<TOKEN end_char="1573" id="token-12-21" morph="none" pos="punct" start_char="1573">(</TOKEN>
<TOKEN end_char="1581" id="token-12-22" morph="none" pos="word" start_char="1574">debunked</TOKEN>
<TOKEN end_char="1586" id="token-12-23" morph="none" pos="word" start_char="1583">here</TOKEN>
<TOKEN end_char="1588" id="token-12-24" morph="none" pos="punct" start_char="1587">),</TOKEN>
<TOKEN end_char="1597" id="token-12-25" morph="none" pos="word" start_char="1590">doctored</TOKEN>
<TOKEN end_char="1604" id="token-12-26" morph="none" pos="word" start_char="1599">tweets</TOKEN>
<TOKEN end_char="1609" id="token-12-27" morph="none" pos="word" start_char="1606">from</TOKEN>
<TOKEN end_char="1613" id="token-12-28" morph="none" pos="unknown" start_char="1611">U.S</TOKEN>
<TOKEN end_char="1614" id="token-12-29" morph="none" pos="punct" start_char="1614">.</TOKEN>
<TOKEN end_char="1624" id="token-12-30" morph="none" pos="word" start_char="1616">President</TOKEN>
<TOKEN end_char="1631" id="token-12-31" morph="none" pos="word" start_char="1626">Donald</TOKEN>
<TOKEN end_char="1637" id="token-12-32" morph="none" pos="word" start_char="1633">Trump</TOKEN>
<TOKEN end_char="1638" id="token-12-33" morph="none" pos="punct" start_char="1638">,</TOKEN>
<TOKEN end_char="1642" id="token-12-34" morph="none" pos="word" start_char="1640">and</TOKEN>
<TOKEN end_char="1644" id="token-12-35" morph="none" pos="word" start_char="1644">a</TOKEN>
<TOKEN end_char="1649" id="token-12-36" morph="none" pos="word" start_char="1646">junk</TOKEN>
<TOKEN end_char="1654" id="token-12-37" morph="none" pos="word" start_char="1651">news</TOKEN>
<TOKEN end_char="1662" id="token-12-38" morph="none" pos="word" start_char="1656">article</TOKEN>
<TOKEN end_char="1667" id="token-12-39" morph="none" pos="word" start_char="1664">that</TOKEN>
<TOKEN end_char="1675" id="token-12-40" morph="none" pos="word" start_char="1669">falsely</TOKEN>
<TOKEN end_char="1683" id="token-12-41" morph="none" pos="word" start_char="1677">claimed</TOKEN>
<TOKEN end_char="1690" id="token-12-42" morph="none" pos="word" start_char="1685">Prince</TOKEN>
<TOKEN end_char="1697" id="token-12-43" morph="none" pos="word" start_char="1692">Andrew</TOKEN>
<TOKEN end_char="1701" id="token-12-44" morph="none" pos="word" start_char="1699">had</TOKEN>
<TOKEN end_char="1711" id="token-12-45" morph="none" pos="word" start_char="1703">committed</TOKEN>
<TOKEN end_char="1719" id="token-12-46" morph="none" pos="word" start_char="1713">suicide</TOKEN>
<TOKEN end_char="1720" id="token-12-47" morph="none" pos="punct" start_char="1720">.</TOKEN>
</SEG>
<SEG end_char="1839" id="segment-13" start_char="1723">
<ORIGINAL_TEXT>This website has also previously spread misinformation about the coronavirus, or 2019-nCoV acute respiratory disease.</ORIGINAL_TEXT>
<TOKEN end_char="1726" id="token-13-0" morph="none" pos="word" start_char="1723">This</TOKEN>
<TOKEN end_char="1734" id="token-13-1" morph="none" pos="word" start_char="1728">website</TOKEN>
<TOKEN end_char="1738" id="token-13-2" morph="none" pos="word" start_char="1736">has</TOKEN>
<TOKEN end_char="1743" id="token-13-3" morph="none" pos="word" start_char="1740">also</TOKEN>
<TOKEN end_char="1754" id="token-13-4" morph="none" pos="word" start_char="1745">previously</TOKEN>
<TOKEN end_char="1761" id="token-13-5" morph="none" pos="word" start_char="1756">spread</TOKEN>
<TOKEN end_char="1776" id="token-13-6" morph="none" pos="word" start_char="1763">misinformation</TOKEN>
<TOKEN end_char="1782" id="token-13-7" morph="none" pos="word" start_char="1778">about</TOKEN>
<TOKEN end_char="1786" id="token-13-8" morph="none" pos="word" start_char="1784">the</TOKEN>
<TOKEN end_char="1798" id="token-13-9" morph="none" pos="word" start_char="1788">coronavirus</TOKEN>
<TOKEN end_char="1799" id="token-13-10" morph="none" pos="punct" start_char="1799">,</TOKEN>
<TOKEN end_char="1802" id="token-13-11" morph="none" pos="word" start_char="1801">or</TOKEN>
<TOKEN end_char="1812" id="token-13-12" morph="none" pos="unknown" start_char="1804">2019-nCoV</TOKEN>
<TOKEN end_char="1818" id="token-13-13" morph="none" pos="word" start_char="1814">acute</TOKEN>
<TOKEN end_char="1830" id="token-13-14" morph="none" pos="word" start_char="1820">respiratory</TOKEN>
<TOKEN end_char="1838" id="token-13-15" morph="none" pos="word" start_char="1832">disease</TOKEN>
<TOKEN end_char="1839" id="token-13-16" morph="none" pos="punct" start_char="1839">.</TOKEN>
</SEG>
<SEG end_char="1896" id="segment-14" start_char="1841">
<ORIGINAL_TEXT>The government of Singapore released a statement on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="1843" id="token-14-0" morph="none" pos="word" start_char="1841">The</TOKEN>
<TOKEN end_char="1854" id="token-14-1" morph="none" pos="word" start_char="1845">government</TOKEN>
<TOKEN end_char="1857" id="token-14-2" morph="none" pos="word" start_char="1856">of</TOKEN>
<TOKEN end_char="1867" id="token-14-3" morph="none" pos="word" start_char="1859">Singapore</TOKEN>
<TOKEN end_char="1876" id="token-14-4" morph="none" pos="word" start_char="1869">released</TOKEN>
<TOKEN end_char="1878" id="token-14-5" morph="none" pos="word" start_char="1878">a</TOKEN>
<TOKEN end_char="1888" id="token-14-6" morph="none" pos="word" start_char="1880">statement</TOKEN>
<TOKEN end_char="1891" id="token-14-7" morph="none" pos="word" start_char="1890">on</TOKEN>
<TOKEN end_char="1895" id="token-14-8" morph="none" pos="word" start_char="1893">Jan</TOKEN>
<TOKEN end_char="1896" id="token-14-9" morph="none" pos="punct" start_char="1896">.</TOKEN>
</SEG>
<SEG end_char="1953" id="segment-15" start_char="1898">
<ORIGINAL_TEXT>30, 2020, to refute claims published in an AB-TC report:</ORIGINAL_TEXT>
<TOKEN end_char="1899" id="token-15-0" morph="none" pos="word" start_char="1898">30</TOKEN>
<TOKEN end_char="1900" id="token-15-1" morph="none" pos="punct" start_char="1900">,</TOKEN>
<TOKEN end_char="1905" id="token-15-2" morph="none" pos="word" start_char="1902">2020</TOKEN>
<TOKEN end_char="1906" id="token-15-3" morph="none" pos="punct" start_char="1906">,</TOKEN>
<TOKEN end_char="1909" id="token-15-4" morph="none" pos="word" start_char="1908">to</TOKEN>
<TOKEN end_char="1916" id="token-15-5" morph="none" pos="word" start_char="1911">refute</TOKEN>
<TOKEN end_char="1923" id="token-15-6" morph="none" pos="word" start_char="1918">claims</TOKEN>
<TOKEN end_char="1933" id="token-15-7" morph="none" pos="word" start_char="1925">published</TOKEN>
<TOKEN end_char="1936" id="token-15-8" morph="none" pos="word" start_char="1935">in</TOKEN>
<TOKEN end_char="1939" id="token-15-9" morph="none" pos="word" start_char="1938">an</TOKEN>
<TOKEN end_char="1945" id="token-15-10" morph="none" pos="unknown" start_char="1941">AB-TC</TOKEN>
<TOKEN end_char="1952" id="token-15-11" morph="none" pos="word" start_char="1947">report</TOKEN>
<TOKEN end_char="1953" id="token-15-12" morph="none" pos="punct" start_char="1953">:</TOKEN>
</SEG>
<SEG end_char="2338" id="segment-16" start_char="1956">
<ORIGINAL_TEXT>Corrections and clarifications regarding falsehoods published by AB-TC City News’ website On 30 Jan 2020, a website called ‘City News’ published an article titled "BREAKING NEWS: Singapore records six more coronavirus case, total of 16 now" (https://ab-tc.com/singapore-coronavirus-cases/) claiming that five Singaporeans have contracted the Wuhan coronavirus without going to China.</ORIGINAL_TEXT>
<TOKEN end_char="1966" id="token-16-0" morph="none" pos="word" start_char="1956">Corrections</TOKEN>
<TOKEN end_char="1970" id="token-16-1" morph="none" pos="word" start_char="1968">and</TOKEN>
<TOKEN end_char="1985" id="token-16-2" morph="none" pos="word" start_char="1972">clarifications</TOKEN>
<TOKEN end_char="1995" id="token-16-3" morph="none" pos="word" start_char="1987">regarding</TOKEN>
<TOKEN end_char="2006" id="token-16-4" morph="none" pos="word" start_char="1997">falsehoods</TOKEN>
<TOKEN end_char="2016" id="token-16-5" morph="none" pos="word" start_char="2008">published</TOKEN>
<TOKEN end_char="2019" id="token-16-6" morph="none" pos="word" start_char="2018">by</TOKEN>
<TOKEN end_char="2025" id="token-16-7" morph="none" pos="unknown" start_char="2021">AB-TC</TOKEN>
<TOKEN end_char="2030" id="token-16-8" morph="none" pos="word" start_char="2027">City</TOKEN>
<TOKEN end_char="2035" id="token-16-9" morph="none" pos="word" start_char="2032">News</TOKEN>
<TOKEN end_char="2036" id="token-16-10" morph="none" pos="punct" start_char="2036">’</TOKEN>
<TOKEN end_char="2044" id="token-16-11" morph="none" pos="word" start_char="2038">website</TOKEN>
<TOKEN end_char="2047" id="token-16-12" morph="none" pos="word" start_char="2046">On</TOKEN>
<TOKEN end_char="2050" id="token-16-13" morph="none" pos="word" start_char="2049">30</TOKEN>
<TOKEN end_char="2054" id="token-16-14" morph="none" pos="word" start_char="2052">Jan</TOKEN>
<TOKEN end_char="2059" id="token-16-15" morph="none" pos="word" start_char="2056">2020</TOKEN>
<TOKEN end_char="2060" id="token-16-16" morph="none" pos="punct" start_char="2060">,</TOKEN>
<TOKEN end_char="2062" id="token-16-17" morph="none" pos="word" start_char="2062">a</TOKEN>
<TOKEN end_char="2070" id="token-16-18" morph="none" pos="word" start_char="2064">website</TOKEN>
<TOKEN end_char="2077" id="token-16-19" morph="none" pos="word" start_char="2072">called</TOKEN>
<TOKEN end_char="2079" id="token-16-20" morph="none" pos="punct" start_char="2079">‘</TOKEN>
<TOKEN end_char="2083" id="token-16-21" morph="none" pos="word" start_char="2080">City</TOKEN>
<TOKEN end_char="2088" id="token-16-22" morph="none" pos="word" start_char="2085">News</TOKEN>
<TOKEN end_char="2089" id="token-16-23" morph="none" pos="punct" start_char="2089">’</TOKEN>
<TOKEN end_char="2099" id="token-16-24" morph="none" pos="word" start_char="2091">published</TOKEN>
<TOKEN end_char="2102" id="token-16-25" morph="none" pos="word" start_char="2101">an</TOKEN>
<TOKEN end_char="2110" id="token-16-26" morph="none" pos="word" start_char="2104">article</TOKEN>
<TOKEN end_char="2117" id="token-16-27" morph="none" pos="word" start_char="2112">titled</TOKEN>
<TOKEN end_char="2119" id="token-16-28" morph="none" pos="punct" start_char="2119">"</TOKEN>
<TOKEN end_char="2127" id="token-16-29" morph="none" pos="word" start_char="2120">BREAKING</TOKEN>
<TOKEN end_char="2132" id="token-16-30" morph="none" pos="word" start_char="2129">NEWS</TOKEN>
<TOKEN end_char="2133" id="token-16-31" morph="none" pos="punct" start_char="2133">:</TOKEN>
<TOKEN end_char="2143" id="token-16-32" morph="none" pos="word" start_char="2135">Singapore</TOKEN>
<TOKEN end_char="2151" id="token-16-33" morph="none" pos="word" start_char="2145">records</TOKEN>
<TOKEN end_char="2155" id="token-16-34" morph="none" pos="word" start_char="2153">six</TOKEN>
<TOKEN end_char="2160" id="token-16-35" morph="none" pos="word" start_char="2157">more</TOKEN>
<TOKEN end_char="2172" id="token-16-36" morph="none" pos="word" start_char="2162">coronavirus</TOKEN>
<TOKEN end_char="2177" id="token-16-37" morph="none" pos="word" start_char="2174">case</TOKEN>
<TOKEN end_char="2178" id="token-16-38" morph="none" pos="punct" start_char="2178">,</TOKEN>
<TOKEN end_char="2184" id="token-16-39" morph="none" pos="word" start_char="2180">total</TOKEN>
<TOKEN end_char="2187" id="token-16-40" morph="none" pos="word" start_char="2186">of</TOKEN>
<TOKEN end_char="2190" id="token-16-41" morph="none" pos="word" start_char="2189">16</TOKEN>
<TOKEN end_char="2194" id="token-16-42" morph="none" pos="word" start_char="2192">now</TOKEN>
<TOKEN end_char="2195" id="token-16-43" morph="none" pos="punct" start_char="2195">"</TOKEN>
<TOKEN end_char="2197" id="token-16-44" morph="none" pos="punct" start_char="2197">(</TOKEN>
<TOKEN end_char="2242" id="token-16-45" morph="none" pos="unknown" start_char="2198">https://ab-tc.com/singapore-coronavirus-cases</TOKEN>
<TOKEN end_char="2244" id="token-16-46" morph="none" pos="punct" start_char="2243">/)</TOKEN>
<TOKEN end_char="2253" id="token-16-47" morph="none" pos="word" start_char="2246">claiming</TOKEN>
<TOKEN end_char="2258" id="token-16-48" morph="none" pos="word" start_char="2255">that</TOKEN>
<TOKEN end_char="2263" id="token-16-49" morph="none" pos="word" start_char="2260">five</TOKEN>
<TOKEN end_char="2276" id="token-16-50" morph="none" pos="word" start_char="2265">Singaporeans</TOKEN>
<TOKEN end_char="2281" id="token-16-51" morph="none" pos="word" start_char="2278">have</TOKEN>
<TOKEN end_char="2292" id="token-16-52" morph="none" pos="word" start_char="2283">contracted</TOKEN>
<TOKEN end_char="2296" id="token-16-53" morph="none" pos="word" start_char="2294">the</TOKEN>
<TOKEN end_char="2302" id="token-16-54" morph="none" pos="word" start_char="2298">Wuhan</TOKEN>
<TOKEN end_char="2314" id="token-16-55" morph="none" pos="word" start_char="2304">coronavirus</TOKEN>
<TOKEN end_char="2322" id="token-16-56" morph="none" pos="word" start_char="2316">without</TOKEN>
<TOKEN end_char="2328" id="token-16-57" morph="none" pos="word" start_char="2324">going</TOKEN>
<TOKEN end_char="2331" id="token-16-58" morph="none" pos="word" start_char="2330">to</TOKEN>
<TOKEN end_char="2337" id="token-16-59" morph="none" pos="word" start_char="2333">China</TOKEN>
<TOKEN end_char="2338" id="token-16-60" morph="none" pos="punct" start_char="2338">.</TOKEN>
</SEG>
<SEG end_char="2428" id="segment-17" start_char="2340">
<ORIGINAL_TEXT>As of 9pm on 30 Jan 2020, there is no local transmission of the Wuhan virus in Singapore.</ORIGINAL_TEXT>
<TOKEN end_char="2341" id="token-17-0" morph="none" pos="word" start_char="2340">As</TOKEN>
<TOKEN end_char="2344" id="token-17-1" morph="none" pos="word" start_char="2343">of</TOKEN>
<TOKEN end_char="2348" id="token-17-2" morph="none" pos="word" start_char="2346">9pm</TOKEN>
<TOKEN end_char="2351" id="token-17-3" morph="none" pos="word" start_char="2350">on</TOKEN>
<TOKEN end_char="2354" id="token-17-4" morph="none" pos="word" start_char="2353">30</TOKEN>
<TOKEN end_char="2358" id="token-17-5" morph="none" pos="word" start_char="2356">Jan</TOKEN>
<TOKEN end_char="2363" id="token-17-6" morph="none" pos="word" start_char="2360">2020</TOKEN>
<TOKEN end_char="2364" id="token-17-7" morph="none" pos="punct" start_char="2364">,</TOKEN>
<TOKEN end_char="2370" id="token-17-8" morph="none" pos="word" start_char="2366">there</TOKEN>
<TOKEN end_char="2373" id="token-17-9" morph="none" pos="word" start_char="2372">is</TOKEN>
<TOKEN end_char="2376" id="token-17-10" morph="none" pos="word" start_char="2375">no</TOKEN>
<TOKEN end_char="2382" id="token-17-11" morph="none" pos="word" start_char="2378">local</TOKEN>
<TOKEN end_char="2395" id="token-17-12" morph="none" pos="word" start_char="2384">transmission</TOKEN>
<TOKEN end_char="2398" id="token-17-13" morph="none" pos="word" start_char="2397">of</TOKEN>
<TOKEN end_char="2402" id="token-17-14" morph="none" pos="word" start_char="2400">the</TOKEN>
<TOKEN end_char="2408" id="token-17-15" morph="none" pos="word" start_char="2404">Wuhan</TOKEN>
<TOKEN end_char="2414" id="token-17-16" morph="none" pos="word" start_char="2410">virus</TOKEN>
<TOKEN end_char="2417" id="token-17-17" morph="none" pos="word" start_char="2416">in</TOKEN>
<TOKEN end_char="2427" id="token-17-18" morph="none" pos="word" start_char="2419">Singapore</TOKEN>
<TOKEN end_char="2428" id="token-17-19" morph="none" pos="punct" start_char="2428">.</TOKEN>
</SEG>
<SEG end_char="2517" id="segment-18" start_char="2430">
<ORIGINAL_TEXT>All confirmed cases in Singapore to date are Chinese nationals who travelled from Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="2432" id="token-18-0" morph="none" pos="word" start_char="2430">All</TOKEN>
<TOKEN end_char="2442" id="token-18-1" morph="none" pos="word" start_char="2434">confirmed</TOKEN>
<TOKEN end_char="2448" id="token-18-2" morph="none" pos="word" start_char="2444">cases</TOKEN>
<TOKEN end_char="2451" id="token-18-3" morph="none" pos="word" start_char="2450">in</TOKEN>
<TOKEN end_char="2461" id="token-18-4" morph="none" pos="word" start_char="2453">Singapore</TOKEN>
<TOKEN end_char="2464" id="token-18-5" morph="none" pos="word" start_char="2463">to</TOKEN>
<TOKEN end_char="2469" id="token-18-6" morph="none" pos="word" start_char="2466">date</TOKEN>
<TOKEN end_char="2473" id="token-18-7" morph="none" pos="word" start_char="2471">are</TOKEN>
<TOKEN end_char="2481" id="token-18-8" morph="none" pos="word" start_char="2475">Chinese</TOKEN>
<TOKEN end_char="2491" id="token-18-9" morph="none" pos="word" start_char="2483">nationals</TOKEN>
<TOKEN end_char="2495" id="token-18-10" morph="none" pos="word" start_char="2493">who</TOKEN>
<TOKEN end_char="2505" id="token-18-11" morph="none" pos="word" start_char="2497">travelled</TOKEN>
<TOKEN end_char="2510" id="token-18-12" morph="none" pos="word" start_char="2507">from</TOKEN>
<TOKEN end_char="2516" id="token-18-13" morph="none" pos="word" start_char="2512">Wuhan</TOKEN>
<TOKEN end_char="2517" id="token-18-14" morph="none" pos="punct" start_char="2517">.</TOKEN>
</SEG>
<SEG end_char="2596" id="segment-19" start_char="2521">
<ORIGINAL_TEXT>None of the AB-TC articles we examined was accompanied by a person’s byline.</ORIGINAL_TEXT>
<TOKEN end_char="2524" id="token-19-0" morph="none" pos="word" start_char="2521">None</TOKEN>
<TOKEN end_char="2527" id="token-19-1" morph="none" pos="word" start_char="2526">of</TOKEN>
<TOKEN end_char="2531" id="token-19-2" morph="none" pos="word" start_char="2529">the</TOKEN>
<TOKEN end_char="2537" id="token-19-3" morph="none" pos="unknown" start_char="2533">AB-TC</TOKEN>
<TOKEN end_char="2546" id="token-19-4" morph="none" pos="word" start_char="2539">articles</TOKEN>
<TOKEN end_char="2549" id="token-19-5" morph="none" pos="word" start_char="2548">we</TOKEN>
<TOKEN end_char="2558" id="token-19-6" morph="none" pos="word" start_char="2551">examined</TOKEN>
<TOKEN end_char="2562" id="token-19-7" morph="none" pos="word" start_char="2560">was</TOKEN>
<TOKEN end_char="2574" id="token-19-8" morph="none" pos="word" start_char="2564">accompanied</TOKEN>
<TOKEN end_char="2577" id="token-19-9" morph="none" pos="word" start_char="2576">by</TOKEN>
<TOKEN end_char="2579" id="token-19-10" morph="none" pos="word" start_char="2579">a</TOKEN>
<TOKEN end_char="2588" id="token-19-11" morph="none" pos="word" start_char="2581">person’s</TOKEN>
<TOKEN end_char="2595" id="token-19-12" morph="none" pos="word" start_char="2590">byline</TOKEN>
<TOKEN end_char="2596" id="token-19-13" morph="none" pos="punct" start_char="2596">.</TOKEN>
</SEG>
<SEG end_char="2663" id="segment-20" start_char="2598">
<ORIGINAL_TEXT>Rather, they were all written by so-called "local correspondents."</ORIGINAL_TEXT>
<TOKEN end_char="2603" id="token-20-0" morph="none" pos="word" start_char="2598">Rather</TOKEN>
<TOKEN end_char="2604" id="token-20-1" morph="none" pos="punct" start_char="2604">,</TOKEN>
<TOKEN end_char="2609" id="token-20-2" morph="none" pos="word" start_char="2606">they</TOKEN>
<TOKEN end_char="2614" id="token-20-3" morph="none" pos="word" start_char="2611">were</TOKEN>
<TOKEN end_char="2618" id="token-20-4" morph="none" pos="word" start_char="2616">all</TOKEN>
<TOKEN end_char="2626" id="token-20-5" morph="none" pos="word" start_char="2620">written</TOKEN>
<TOKEN end_char="2629" id="token-20-6" morph="none" pos="word" start_char="2628">by</TOKEN>
<TOKEN end_char="2639" id="token-20-7" morph="none" pos="unknown" start_char="2631">so-called</TOKEN>
<TOKEN end_char="2641" id="token-20-8" morph="none" pos="punct" start_char="2641">"</TOKEN>
<TOKEN end_char="2646" id="token-20-9" morph="none" pos="word" start_char="2642">local</TOKEN>
<TOKEN end_char="2661" id="token-20-10" morph="none" pos="word" start_char="2648">correspondents</TOKEN>
<TOKEN end_char="2663" id="token-20-11" morph="none" pos="punct" start_char="2662">."</TOKEN>
</SEG>
<SEG end_char="2762" id="segment-21" start_char="2666">
<ORIGINAL_TEXT>In other words, this website doesn’t exactly have a great track record of genuine news reporting.</ORIGINAL_TEXT>
<TOKEN end_char="2667" id="token-21-0" morph="none" pos="word" start_char="2666">In</TOKEN>
<TOKEN end_char="2673" id="token-21-1" morph="none" pos="word" start_char="2669">other</TOKEN>
<TOKEN end_char="2679" id="token-21-2" morph="none" pos="word" start_char="2675">words</TOKEN>
<TOKEN end_char="2680" id="token-21-3" morph="none" pos="punct" start_char="2680">,</TOKEN>
<TOKEN end_char="2685" id="token-21-4" morph="none" pos="word" start_char="2682">this</TOKEN>
<TOKEN end_char="2693" id="token-21-5" morph="none" pos="word" start_char="2687">website</TOKEN>
<TOKEN end_char="2701" id="token-21-6" morph="none" pos="word" start_char="2695">doesn’t</TOKEN>
<TOKEN end_char="2709" id="token-21-7" morph="none" pos="word" start_char="2703">exactly</TOKEN>
<TOKEN end_char="2714" id="token-21-8" morph="none" pos="word" start_char="2711">have</TOKEN>
<TOKEN end_char="2716" id="token-21-9" morph="none" pos="word" start_char="2716">a</TOKEN>
<TOKEN end_char="2722" id="token-21-10" morph="none" pos="word" start_char="2718">great</TOKEN>
<TOKEN end_char="2728" id="token-21-11" morph="none" pos="word" start_char="2724">track</TOKEN>
<TOKEN end_char="2735" id="token-21-12" morph="none" pos="word" start_char="2730">record</TOKEN>
<TOKEN end_char="2738" id="token-21-13" morph="none" pos="word" start_char="2737">of</TOKEN>
<TOKEN end_char="2746" id="token-21-14" morph="none" pos="word" start_char="2740">genuine</TOKEN>
<TOKEN end_char="2751" id="token-21-15" morph="none" pos="word" start_char="2748">news</TOKEN>
<TOKEN end_char="2761" id="token-21-16" morph="none" pos="word" start_char="2753">reporting</TOKEN>
<TOKEN end_char="2762" id="token-21-17" morph="none" pos="punct" start_char="2762">.</TOKEN>
</SEG>
<SEG end_char="2915" id="segment-22" start_char="2765">
<ORIGINAL_TEXT>In addition to its history of pushing misinformation, there are also a few red flags in AB-TC’s article about the mass killing of coronavirus patients.</ORIGINAL_TEXT>
<TOKEN end_char="2766" id="token-22-0" morph="none" pos="word" start_char="2765">In</TOKEN>
<TOKEN end_char="2775" id="token-22-1" morph="none" pos="word" start_char="2768">addition</TOKEN>
<TOKEN end_char="2778" id="token-22-2" morph="none" pos="word" start_char="2777">to</TOKEN>
<TOKEN end_char="2782" id="token-22-3" morph="none" pos="word" start_char="2780">its</TOKEN>
<TOKEN end_char="2790" id="token-22-4" morph="none" pos="word" start_char="2784">history</TOKEN>
<TOKEN end_char="2793" id="token-22-5" morph="none" pos="word" start_char="2792">of</TOKEN>
<TOKEN end_char="2801" id="token-22-6" morph="none" pos="word" start_char="2795">pushing</TOKEN>
<TOKEN end_char="2816" id="token-22-7" morph="none" pos="word" start_char="2803">misinformation</TOKEN>
<TOKEN end_char="2817" id="token-22-8" morph="none" pos="punct" start_char="2817">,</TOKEN>
<TOKEN end_char="2823" id="token-22-9" morph="none" pos="word" start_char="2819">there</TOKEN>
<TOKEN end_char="2827" id="token-22-10" morph="none" pos="word" start_char="2825">are</TOKEN>
<TOKEN end_char="2832" id="token-22-11" morph="none" pos="word" start_char="2829">also</TOKEN>
<TOKEN end_char="2834" id="token-22-12" morph="none" pos="word" start_char="2834">a</TOKEN>
<TOKEN end_char="2838" id="token-22-13" morph="none" pos="word" start_char="2836">few</TOKEN>
<TOKEN end_char="2842" id="token-22-14" morph="none" pos="word" start_char="2840">red</TOKEN>
<TOKEN end_char="2848" id="token-22-15" morph="none" pos="word" start_char="2844">flags</TOKEN>
<TOKEN end_char="2851" id="token-22-16" morph="none" pos="word" start_char="2850">in</TOKEN>
<TOKEN end_char="2859" id="token-22-17" morph="none" pos="unknown" start_char="2853">AB-TC’s</TOKEN>
<TOKEN end_char="2867" id="token-22-18" morph="none" pos="word" start_char="2861">article</TOKEN>
<TOKEN end_char="2873" id="token-22-19" morph="none" pos="word" start_char="2869">about</TOKEN>
<TOKEN end_char="2877" id="token-22-20" morph="none" pos="word" start_char="2875">the</TOKEN>
<TOKEN end_char="2882" id="token-22-21" morph="none" pos="word" start_char="2879">mass</TOKEN>
<TOKEN end_char="2890" id="token-22-22" morph="none" pos="word" start_char="2884">killing</TOKEN>
<TOKEN end_char="2893" id="token-22-23" morph="none" pos="word" start_char="2892">of</TOKEN>
<TOKEN end_char="2905" id="token-22-24" morph="none" pos="word" start_char="2895">coronavirus</TOKEN>
<TOKEN end_char="2914" id="token-22-25" morph="none" pos="word" start_char="2907">patients</TOKEN>
<TOKEN end_char="2915" id="token-22-26" morph="none" pos="punct" start_char="2915">.</TOKEN>
</SEG>
<SEG end_char="3038" id="segment-23" start_char="2917">
<ORIGINAL_TEXT>For instance, like most of the other articles on this website, this article contains no links back to supporting evidence.</ORIGINAL_TEXT>
<TOKEN end_char="2919" id="token-23-0" morph="none" pos="word" start_char="2917">For</TOKEN>
<TOKEN end_char="2928" id="token-23-1" morph="none" pos="word" start_char="2921">instance</TOKEN>
<TOKEN end_char="2929" id="token-23-2" morph="none" pos="punct" start_char="2929">,</TOKEN>
<TOKEN end_char="2934" id="token-23-3" morph="none" pos="word" start_char="2931">like</TOKEN>
<TOKEN end_char="2939" id="token-23-4" morph="none" pos="word" start_char="2936">most</TOKEN>
<TOKEN end_char="2942" id="token-23-5" morph="none" pos="word" start_char="2941">of</TOKEN>
<TOKEN end_char="2946" id="token-23-6" morph="none" pos="word" start_char="2944">the</TOKEN>
<TOKEN end_char="2952" id="token-23-7" morph="none" pos="word" start_char="2948">other</TOKEN>
<TOKEN end_char="2961" id="token-23-8" morph="none" pos="word" start_char="2954">articles</TOKEN>
<TOKEN end_char="2964" id="token-23-9" morph="none" pos="word" start_char="2963">on</TOKEN>
<TOKEN end_char="2969" id="token-23-10" morph="none" pos="word" start_char="2966">this</TOKEN>
<TOKEN end_char="2977" id="token-23-11" morph="none" pos="word" start_char="2971">website</TOKEN>
<TOKEN end_char="2978" id="token-23-12" morph="none" pos="punct" start_char="2978">,</TOKEN>
<TOKEN end_char="2983" id="token-23-13" morph="none" pos="word" start_char="2980">this</TOKEN>
<TOKEN end_char="2991" id="token-23-14" morph="none" pos="word" start_char="2985">article</TOKEN>
<TOKEN end_char="3000" id="token-23-15" morph="none" pos="word" start_char="2993">contains</TOKEN>
<TOKEN end_char="3003" id="token-23-16" morph="none" pos="word" start_char="3002">no</TOKEN>
<TOKEN end_char="3009" id="token-23-17" morph="none" pos="word" start_char="3005">links</TOKEN>
<TOKEN end_char="3014" id="token-23-18" morph="none" pos="word" start_char="3011">back</TOKEN>
<TOKEN end_char="3017" id="token-23-19" morph="none" pos="word" start_char="3016">to</TOKEN>
<TOKEN end_char="3028" id="token-23-20" morph="none" pos="word" start_char="3019">supporting</TOKEN>
<TOKEN end_char="3037" id="token-23-21" morph="none" pos="word" start_char="3030">evidence</TOKEN>
<TOKEN end_char="3038" id="token-23-22" morph="none" pos="punct" start_char="3038">.</TOKEN>
</SEG>
<SEG end_char="3214" id="segment-24" start_char="3040">
<ORIGINAL_TEXT>Even when the article mentions secondary sources, such as a "document" or a "press conference," they provide no evidence to show that these items actually exist or took place.</ORIGINAL_TEXT>
<TOKEN end_char="3043" id="token-24-0" morph="none" pos="word" start_char="3040">Even</TOKEN>
<TOKEN end_char="3048" id="token-24-1" morph="none" pos="word" start_char="3045">when</TOKEN>
<TOKEN end_char="3052" id="token-24-2" morph="none" pos="word" start_char="3050">the</TOKEN>
<TOKEN end_char="3060" id="token-24-3" morph="none" pos="word" start_char="3054">article</TOKEN>
<TOKEN end_char="3069" id="token-24-4" morph="none" pos="word" start_char="3062">mentions</TOKEN>
<TOKEN end_char="3079" id="token-24-5" morph="none" pos="word" start_char="3071">secondary</TOKEN>
<TOKEN end_char="3087" id="token-24-6" morph="none" pos="word" start_char="3081">sources</TOKEN>
<TOKEN end_char="3088" id="token-24-7" morph="none" pos="punct" start_char="3088">,</TOKEN>
<TOKEN end_char="3093" id="token-24-8" morph="none" pos="word" start_char="3090">such</TOKEN>
<TOKEN end_char="3096" id="token-24-9" morph="none" pos="word" start_char="3095">as</TOKEN>
<TOKEN end_char="3098" id="token-24-10" morph="none" pos="word" start_char="3098">a</TOKEN>
<TOKEN end_char="3100" id="token-24-11" morph="none" pos="punct" start_char="3100">"</TOKEN>
<TOKEN end_char="3108" id="token-24-12" morph="none" pos="word" start_char="3101">document</TOKEN>
<TOKEN end_char="3109" id="token-24-13" morph="none" pos="punct" start_char="3109">"</TOKEN>
<TOKEN end_char="3112" id="token-24-14" morph="none" pos="word" start_char="3111">or</TOKEN>
<TOKEN end_char="3114" id="token-24-15" morph="none" pos="word" start_char="3114">a</TOKEN>
<TOKEN end_char="3116" id="token-24-16" morph="none" pos="punct" start_char="3116">"</TOKEN>
<TOKEN end_char="3121" id="token-24-17" morph="none" pos="word" start_char="3117">press</TOKEN>
<TOKEN end_char="3132" id="token-24-18" morph="none" pos="word" start_char="3123">conference</TOKEN>
<TOKEN end_char="3134" id="token-24-19" morph="none" pos="punct" start_char="3133">,"</TOKEN>
<TOKEN end_char="3139" id="token-24-20" morph="none" pos="word" start_char="3136">they</TOKEN>
<TOKEN end_char="3147" id="token-24-21" morph="none" pos="word" start_char="3141">provide</TOKEN>
<TOKEN end_char="3150" id="token-24-22" morph="none" pos="word" start_char="3149">no</TOKEN>
<TOKEN end_char="3159" id="token-24-23" morph="none" pos="word" start_char="3152">evidence</TOKEN>
<TOKEN end_char="3162" id="token-24-24" morph="none" pos="word" start_char="3161">to</TOKEN>
<TOKEN end_char="3167" id="token-24-25" morph="none" pos="word" start_char="3164">show</TOKEN>
<TOKEN end_char="3172" id="token-24-26" morph="none" pos="word" start_char="3169">that</TOKEN>
<TOKEN end_char="3178" id="token-24-27" morph="none" pos="word" start_char="3174">these</TOKEN>
<TOKEN end_char="3184" id="token-24-28" morph="none" pos="word" start_char="3180">items</TOKEN>
<TOKEN end_char="3193" id="token-24-29" morph="none" pos="word" start_char="3186">actually</TOKEN>
<TOKEN end_char="3199" id="token-24-30" morph="none" pos="word" start_char="3195">exist</TOKEN>
<TOKEN end_char="3202" id="token-24-31" morph="none" pos="word" start_char="3201">or</TOKEN>
<TOKEN end_char="3207" id="token-24-32" morph="none" pos="word" start_char="3204">took</TOKEN>
<TOKEN end_char="3213" id="token-24-33" morph="none" pos="word" start_char="3209">place</TOKEN>
<TOKEN end_char="3214" id="token-24-34" morph="none" pos="punct" start_char="3214">.</TOKEN>
</SEG>
<SEG end_char="3266" id="segment-25" start_char="3216">
<ORIGINAL_TEXT>The article is also suspiciously void of specifics.</ORIGINAL_TEXT>
<TOKEN end_char="3218" id="token-25-0" morph="none" pos="word" start_char="3216">The</TOKEN>
<TOKEN end_char="3226" id="token-25-1" morph="none" pos="word" start_char="3220">article</TOKEN>
<TOKEN end_char="3229" id="token-25-2" morph="none" pos="word" start_char="3228">is</TOKEN>
<TOKEN end_char="3234" id="token-25-3" morph="none" pos="word" start_char="3231">also</TOKEN>
<TOKEN end_char="3247" id="token-25-4" morph="none" pos="word" start_char="3236">suspiciously</TOKEN>
<TOKEN end_char="3252" id="token-25-5" morph="none" pos="word" start_char="3249">void</TOKEN>
<TOKEN end_char="3255" id="token-25-6" morph="none" pos="word" start_char="3254">of</TOKEN>
<TOKEN end_char="3265" id="token-25-7" morph="none" pos="word" start_char="3257">specifics</TOKEN>
<TOKEN end_char="3266" id="token-25-8" morph="none" pos="punct" start_char="3266">.</TOKEN>
</SEG>
<SEG end_char="3409" id="segment-26" start_char="3268">
<ORIGINAL_TEXT>AB-TC reports that "the state" or "the court" or an "official" made a statement, but doesn’t provide any direct quotes or names in its report.</ORIGINAL_TEXT>
<TOKEN end_char="3272" id="token-26-0" morph="none" pos="unknown" start_char="3268">AB-TC</TOKEN>
<TOKEN end_char="3280" id="token-26-1" morph="none" pos="word" start_char="3274">reports</TOKEN>
<TOKEN end_char="3285" id="token-26-2" morph="none" pos="word" start_char="3282">that</TOKEN>
<TOKEN end_char="3287" id="token-26-3" morph="none" pos="punct" start_char="3287">"</TOKEN>
<TOKEN end_char="3290" id="token-26-4" morph="none" pos="word" start_char="3288">the</TOKEN>
<TOKEN end_char="3296" id="token-26-5" morph="none" pos="word" start_char="3292">state</TOKEN>
<TOKEN end_char="3297" id="token-26-6" morph="none" pos="punct" start_char="3297">"</TOKEN>
<TOKEN end_char="3300" id="token-26-7" morph="none" pos="word" start_char="3299">or</TOKEN>
<TOKEN end_char="3302" id="token-26-8" morph="none" pos="punct" start_char="3302">"</TOKEN>
<TOKEN end_char="3305" id="token-26-9" morph="none" pos="word" start_char="3303">the</TOKEN>
<TOKEN end_char="3311" id="token-26-10" morph="none" pos="word" start_char="3307">court</TOKEN>
<TOKEN end_char="3312" id="token-26-11" morph="none" pos="punct" start_char="3312">"</TOKEN>
<TOKEN end_char="3315" id="token-26-12" morph="none" pos="word" start_char="3314">or</TOKEN>
<TOKEN end_char="3318" id="token-26-13" morph="none" pos="word" start_char="3317">an</TOKEN>
<TOKEN end_char="3320" id="token-26-14" morph="none" pos="punct" start_char="3320">"</TOKEN>
<TOKEN end_char="3328" id="token-26-15" morph="none" pos="word" start_char="3321">official</TOKEN>
<TOKEN end_char="3329" id="token-26-16" morph="none" pos="punct" start_char="3329">"</TOKEN>
<TOKEN end_char="3334" id="token-26-17" morph="none" pos="word" start_char="3331">made</TOKEN>
<TOKEN end_char="3336" id="token-26-18" morph="none" pos="word" start_char="3336">a</TOKEN>
<TOKEN end_char="3346" id="token-26-19" morph="none" pos="word" start_char="3338">statement</TOKEN>
<TOKEN end_char="3347" id="token-26-20" morph="none" pos="punct" start_char="3347">,</TOKEN>
<TOKEN end_char="3351" id="token-26-21" morph="none" pos="word" start_char="3349">but</TOKEN>
<TOKEN end_char="3359" id="token-26-22" morph="none" pos="word" start_char="3353">doesn’t</TOKEN>
<TOKEN end_char="3367" id="token-26-23" morph="none" pos="word" start_char="3361">provide</TOKEN>
<TOKEN end_char="3371" id="token-26-24" morph="none" pos="word" start_char="3369">any</TOKEN>
<TOKEN end_char="3378" id="token-26-25" morph="none" pos="word" start_char="3373">direct</TOKEN>
<TOKEN end_char="3385" id="token-26-26" morph="none" pos="word" start_char="3380">quotes</TOKEN>
<TOKEN end_char="3388" id="token-26-27" morph="none" pos="word" start_char="3387">or</TOKEN>
<TOKEN end_char="3394" id="token-26-28" morph="none" pos="word" start_char="3390">names</TOKEN>
<TOKEN end_char="3397" id="token-26-29" morph="none" pos="word" start_char="3396">in</TOKEN>
<TOKEN end_char="3401" id="token-26-30" morph="none" pos="word" start_char="3399">its</TOKEN>
<TOKEN end_char="3408" id="token-26-31" morph="none" pos="word" start_char="3403">report</TOKEN>
<TOKEN end_char="3409" id="token-26-32" morph="none" pos="punct" start_char="3409">.</TOKEN>
</SEG>
<SEG end_char="3489" id="segment-27" start_char="3412">
<ORIGINAL_TEXT>Lastly, no credible news outlets have published reports containing this claim.</ORIGINAL_TEXT>
<TOKEN end_char="3417" id="token-27-0" morph="none" pos="word" start_char="3412">Lastly</TOKEN>
<TOKEN end_char="3418" id="token-27-1" morph="none" pos="punct" start_char="3418">,</TOKEN>
<TOKEN end_char="3421" id="token-27-2" morph="none" pos="word" start_char="3420">no</TOKEN>
<TOKEN end_char="3430" id="token-27-3" morph="none" pos="word" start_char="3423">credible</TOKEN>
<TOKEN end_char="3435" id="token-27-4" morph="none" pos="word" start_char="3432">news</TOKEN>
<TOKEN end_char="3443" id="token-27-5" morph="none" pos="word" start_char="3437">outlets</TOKEN>
<TOKEN end_char="3448" id="token-27-6" morph="none" pos="word" start_char="3445">have</TOKEN>
<TOKEN end_char="3458" id="token-27-7" morph="none" pos="word" start_char="3450">published</TOKEN>
<TOKEN end_char="3466" id="token-27-8" morph="none" pos="word" start_char="3460">reports</TOKEN>
<TOKEN end_char="3477" id="token-27-9" morph="none" pos="word" start_char="3468">containing</TOKEN>
<TOKEN end_char="3482" id="token-27-10" morph="none" pos="word" start_char="3479">this</TOKEN>
<TOKEN end_char="3488" id="token-27-11" morph="none" pos="word" start_char="3484">claim</TOKEN>
<TOKEN end_char="3489" id="token-27-12" morph="none" pos="punct" start_char="3489">.</TOKEN>
</SEG>
<SEG end_char="3525" id="segment-28" start_char="3491">
<ORIGINAL_TEXT>The New York Times reported on Feb.</ORIGINAL_TEXT>
<TOKEN end_char="3493" id="token-28-0" morph="none" pos="word" start_char="3491">The</TOKEN>
<TOKEN end_char="3497" id="token-28-1" morph="none" pos="word" start_char="3495">New</TOKEN>
<TOKEN end_char="3502" id="token-28-2" morph="none" pos="word" start_char="3499">York</TOKEN>
<TOKEN end_char="3508" id="token-28-3" morph="none" pos="word" start_char="3504">Times</TOKEN>
<TOKEN end_char="3517" id="token-28-4" morph="none" pos="word" start_char="3510">reported</TOKEN>
<TOKEN end_char="3520" id="token-28-5" morph="none" pos="word" start_char="3519">on</TOKEN>
<TOKEN end_char="3524" id="token-28-6" morph="none" pos="word" start_char="3522">Feb</TOKEN>
<TOKEN end_char="3525" id="token-28-7" morph="none" pos="punct" start_char="3525">.</TOKEN>
</SEG>
<SEG end_char="3760" id="segment-29" start_char="3527">
<ORIGINAL_TEXT>6, 2020, that a senior official in China "ordered the authorities in the city of Wuhan to immediately round up all residents who have been infected with the coronavirus and place them in isolation, quarantine or designated hospitals."</ORIGINAL_TEXT>
<TOKEN end_char="3527" id="token-29-0" morph="none" pos="word" start_char="3527">6</TOKEN>
<TOKEN end_char="3528" id="token-29-1" morph="none" pos="punct" start_char="3528">,</TOKEN>
<TOKEN end_char="3533" id="token-29-2" morph="none" pos="word" start_char="3530">2020</TOKEN>
<TOKEN end_char="3534" id="token-29-3" morph="none" pos="punct" start_char="3534">,</TOKEN>
<TOKEN end_char="3539" id="token-29-4" morph="none" pos="word" start_char="3536">that</TOKEN>
<TOKEN end_char="3541" id="token-29-5" morph="none" pos="word" start_char="3541">a</TOKEN>
<TOKEN end_char="3548" id="token-29-6" morph="none" pos="word" start_char="3543">senior</TOKEN>
<TOKEN end_char="3557" id="token-29-7" morph="none" pos="word" start_char="3550">official</TOKEN>
<TOKEN end_char="3560" id="token-29-8" morph="none" pos="word" start_char="3559">in</TOKEN>
<TOKEN end_char="3566" id="token-29-9" morph="none" pos="word" start_char="3562">China</TOKEN>
<TOKEN end_char="3568" id="token-29-10" morph="none" pos="punct" start_char="3568">"</TOKEN>
<TOKEN end_char="3575" id="token-29-11" morph="none" pos="word" start_char="3569">ordered</TOKEN>
<TOKEN end_char="3579" id="token-29-12" morph="none" pos="word" start_char="3577">the</TOKEN>
<TOKEN end_char="3591" id="token-29-13" morph="none" pos="word" start_char="3581">authorities</TOKEN>
<TOKEN end_char="3594" id="token-29-14" morph="none" pos="word" start_char="3593">in</TOKEN>
<TOKEN end_char="3598" id="token-29-15" morph="none" pos="word" start_char="3596">the</TOKEN>
<TOKEN end_char="3603" id="token-29-16" morph="none" pos="word" start_char="3600">city</TOKEN>
<TOKEN end_char="3606" id="token-29-17" morph="none" pos="word" start_char="3605">of</TOKEN>
<TOKEN end_char="3612" id="token-29-18" morph="none" pos="word" start_char="3608">Wuhan</TOKEN>
<TOKEN end_char="3615" id="token-29-19" morph="none" pos="word" start_char="3614">to</TOKEN>
<TOKEN end_char="3627" id="token-29-20" morph="none" pos="word" start_char="3617">immediately</TOKEN>
<TOKEN end_char="3633" id="token-29-21" morph="none" pos="word" start_char="3629">round</TOKEN>
<TOKEN end_char="3636" id="token-29-22" morph="none" pos="word" start_char="3635">up</TOKEN>
<TOKEN end_char="3640" id="token-29-23" morph="none" pos="word" start_char="3638">all</TOKEN>
<TOKEN end_char="3650" id="token-29-24" morph="none" pos="word" start_char="3642">residents</TOKEN>
<TOKEN end_char="3654" id="token-29-25" morph="none" pos="word" start_char="3652">who</TOKEN>
<TOKEN end_char="3659" id="token-29-26" morph="none" pos="word" start_char="3656">have</TOKEN>
<TOKEN end_char="3664" id="token-29-27" morph="none" pos="word" start_char="3661">been</TOKEN>
<TOKEN end_char="3673" id="token-29-28" morph="none" pos="word" start_char="3666">infected</TOKEN>
<TOKEN end_char="3678" id="token-29-29" morph="none" pos="word" start_char="3675">with</TOKEN>
<TOKEN end_char="3682" id="token-29-30" morph="none" pos="word" start_char="3680">the</TOKEN>
<TOKEN end_char="3694" id="token-29-31" morph="none" pos="word" start_char="3684">coronavirus</TOKEN>
<TOKEN end_char="3698" id="token-29-32" morph="none" pos="word" start_char="3696">and</TOKEN>
<TOKEN end_char="3704" id="token-29-33" morph="none" pos="word" start_char="3700">place</TOKEN>
<TOKEN end_char="3709" id="token-29-34" morph="none" pos="word" start_char="3706">them</TOKEN>
<TOKEN end_char="3712" id="token-29-35" morph="none" pos="word" start_char="3711">in</TOKEN>
<TOKEN end_char="3722" id="token-29-36" morph="none" pos="word" start_char="3714">isolation</TOKEN>
<TOKEN end_char="3723" id="token-29-37" morph="none" pos="punct" start_char="3723">,</TOKEN>
<TOKEN end_char="3734" id="token-29-38" morph="none" pos="word" start_char="3725">quarantine</TOKEN>
<TOKEN end_char="3737" id="token-29-39" morph="none" pos="word" start_char="3736">or</TOKEN>
<TOKEN end_char="3748" id="token-29-40" morph="none" pos="word" start_char="3739">designated</TOKEN>
<TOKEN end_char="3758" id="token-29-41" morph="none" pos="word" start_char="3750">hospitals</TOKEN>
<TOKEN end_char="3760" id="token-29-42" morph="none" pos="punct" start_char="3759">."</TOKEN>
</SEG>
<SEG end_char="3820" id="segment-30" start_char="3762">
<ORIGINAL_TEXT>That report, of course, made no mention of "mass killings."</ORIGINAL_TEXT>
<TOKEN end_char="3765" id="token-30-0" morph="none" pos="word" start_char="3762">That</TOKEN>
<TOKEN end_char="3772" id="token-30-1" morph="none" pos="word" start_char="3767">report</TOKEN>
<TOKEN end_char="3773" id="token-30-2" morph="none" pos="punct" start_char="3773">,</TOKEN>
<TOKEN end_char="3776" id="token-30-3" morph="none" pos="word" start_char="3775">of</TOKEN>
<TOKEN end_char="3783" id="token-30-4" morph="none" pos="word" start_char="3778">course</TOKEN>
<TOKEN end_char="3784" id="token-30-5" morph="none" pos="punct" start_char="3784">,</TOKEN>
<TOKEN end_char="3789" id="token-30-6" morph="none" pos="word" start_char="3786">made</TOKEN>
<TOKEN end_char="3792" id="token-30-7" morph="none" pos="word" start_char="3791">no</TOKEN>
<TOKEN end_char="3800" id="token-30-8" morph="none" pos="word" start_char="3794">mention</TOKEN>
<TOKEN end_char="3803" id="token-30-9" morph="none" pos="word" start_char="3802">of</TOKEN>
<TOKEN end_char="3805" id="token-30-10" morph="none" pos="punct" start_char="3805">"</TOKEN>
<TOKEN end_char="3809" id="token-30-11" morph="none" pos="word" start_char="3806">mass</TOKEN>
<TOKEN end_char="3818" id="token-30-12" morph="none" pos="word" start_char="3811">killings</TOKEN>
<TOKEN end_char="3820" id="token-30-13" morph="none" pos="punct" start_char="3819">."</TOKEN>
</SEG>
<SEG end_char="3951" id="segment-31" start_char="3823">
<ORIGINAL_TEXT>There is also no mention of this supposed court case on the The Supreme People’s Court of the People’s Republic of China website.</ORIGINAL_TEXT>
<TOKEN end_char="3827" id="token-31-0" morph="none" pos="word" start_char="3823">There</TOKEN>
<TOKEN end_char="3830" id="token-31-1" morph="none" pos="word" start_char="3829">is</TOKEN>
<TOKEN end_char="3835" id="token-31-2" morph="none" pos="word" start_char="3832">also</TOKEN>
<TOKEN end_char="3838" id="token-31-3" morph="none" pos="word" start_char="3837">no</TOKEN>
<TOKEN end_char="3846" id="token-31-4" morph="none" pos="word" start_char="3840">mention</TOKEN>
<TOKEN end_char="3849" id="token-31-5" morph="none" pos="word" start_char="3848">of</TOKEN>
<TOKEN end_char="3854" id="token-31-6" morph="none" pos="word" start_char="3851">this</TOKEN>
<TOKEN end_char="3863" id="token-31-7" morph="none" pos="word" start_char="3856">supposed</TOKEN>
<TOKEN end_char="3869" id="token-31-8" morph="none" pos="word" start_char="3865">court</TOKEN>
<TOKEN end_char="3874" id="token-31-9" morph="none" pos="word" start_char="3871">case</TOKEN>
<TOKEN end_char="3877" id="token-31-10" morph="none" pos="word" start_char="3876">on</TOKEN>
<TOKEN end_char="3881" id="token-31-11" morph="none" pos="word" start_char="3879">the</TOKEN>
<TOKEN end_char="3885" id="token-31-12" morph="none" pos="word" start_char="3883">The</TOKEN>
<TOKEN end_char="3893" id="token-31-13" morph="none" pos="word" start_char="3887">Supreme</TOKEN>
<TOKEN end_char="3902" id="token-31-14" morph="none" pos="word" start_char="3895">People’s</TOKEN>
<TOKEN end_char="3908" id="token-31-15" morph="none" pos="word" start_char="3904">Court</TOKEN>
<TOKEN end_char="3911" id="token-31-16" morph="none" pos="word" start_char="3910">of</TOKEN>
<TOKEN end_char="3915" id="token-31-17" morph="none" pos="word" start_char="3913">the</TOKEN>
<TOKEN end_char="3924" id="token-31-18" morph="none" pos="word" start_char="3917">People’s</TOKEN>
<TOKEN end_char="3933" id="token-31-19" morph="none" pos="word" start_char="3926">Republic</TOKEN>
<TOKEN end_char="3936" id="token-31-20" morph="none" pos="word" start_char="3935">of</TOKEN>
<TOKEN end_char="3942" id="token-31-21" morph="none" pos="word" start_char="3938">China</TOKEN>
<TOKEN end_char="3950" id="token-31-22" morph="none" pos="word" start_char="3944">website</TOKEN>
<TOKEN end_char="3951" id="token-31-23" morph="none" pos="punct" start_char="3951">.</TOKEN>
</SEG>
<SEG end_char="3992" id="segment-32" start_char="3954">
<ORIGINAL_TEXT>AB-TC is the sole source of this rumor.</ORIGINAL_TEXT>
<TOKEN end_char="3958" id="token-32-0" morph="none" pos="unknown" start_char="3954">AB-TC</TOKEN>
<TOKEN end_char="3961" id="token-32-1" morph="none" pos="word" start_char="3960">is</TOKEN>
<TOKEN end_char="3965" id="token-32-2" morph="none" pos="word" start_char="3963">the</TOKEN>
<TOKEN end_char="3970" id="token-32-3" morph="none" pos="word" start_char="3967">sole</TOKEN>
<TOKEN end_char="3977" id="token-32-4" morph="none" pos="word" start_char="3972">source</TOKEN>
<TOKEN end_char="3980" id="token-32-5" morph="none" pos="word" start_char="3979">of</TOKEN>
<TOKEN end_char="3985" id="token-32-6" morph="none" pos="word" start_char="3982">this</TOKEN>
<TOKEN end_char="3991" id="token-32-7" morph="none" pos="word" start_char="3987">rumor</TOKEN>
<TOKEN end_char="3992" id="token-32-8" morph="none" pos="punct" start_char="3992">.</TOKEN>
</SEG>
<SEG end_char="4057" id="segment-33" start_char="3994">
<ORIGINAL_TEXT>However, this website provided no evidence to support its claim.</ORIGINAL_TEXT>
<TOKEN end_char="4000" id="token-33-0" morph="none" pos="word" start_char="3994">However</TOKEN>
<TOKEN end_char="4001" id="token-33-1" morph="none" pos="punct" start_char="4001">,</TOKEN>
<TOKEN end_char="4006" id="token-33-2" morph="none" pos="word" start_char="4003">this</TOKEN>
<TOKEN end_char="4014" id="token-33-3" morph="none" pos="word" start_char="4008">website</TOKEN>
<TOKEN end_char="4023" id="token-33-4" morph="none" pos="word" start_char="4016">provided</TOKEN>
<TOKEN end_char="4026" id="token-33-5" morph="none" pos="word" start_char="4025">no</TOKEN>
<TOKEN end_char="4035" id="token-33-6" morph="none" pos="word" start_char="4028">evidence</TOKEN>
<TOKEN end_char="4038" id="token-33-7" morph="none" pos="word" start_char="4037">to</TOKEN>
<TOKEN end_char="4046" id="token-33-8" morph="none" pos="word" start_char="4040">support</TOKEN>
<TOKEN end_char="4050" id="token-33-9" morph="none" pos="word" start_char="4048">its</TOKEN>
<TOKEN end_char="4056" id="token-33-10" morph="none" pos="word" start_char="4052">claim</TOKEN>
<TOKEN end_char="4057" id="token-33-11" morph="none" pos="punct" start_char="4057">.</TOKEN>
</SEG>
<SEG end_char="4118" id="segment-34" start_char="4059">
<ORIGINAL_TEXT>This website also has a history of spreading misinformation.</ORIGINAL_TEXT>
<TOKEN end_char="4062" id="token-34-0" morph="none" pos="word" start_char="4059">This</TOKEN>
<TOKEN end_char="4070" id="token-34-1" morph="none" pos="word" start_char="4064">website</TOKEN>
<TOKEN end_char="4075" id="token-34-2" morph="none" pos="word" start_char="4072">also</TOKEN>
<TOKEN end_char="4079" id="token-34-3" morph="none" pos="word" start_char="4077">has</TOKEN>
<TOKEN end_char="4081" id="token-34-4" morph="none" pos="word" start_char="4081">a</TOKEN>
<TOKEN end_char="4089" id="token-34-5" morph="none" pos="word" start_char="4083">history</TOKEN>
<TOKEN end_char="4092" id="token-34-6" morph="none" pos="word" start_char="4091">of</TOKEN>
<TOKEN end_char="4102" id="token-34-7" morph="none" pos="word" start_char="4094">spreading</TOKEN>
<TOKEN end_char="4117" id="token-34-8" morph="none" pos="word" start_char="4104">misinformation</TOKEN>
<TOKEN end_char="4118" id="token-34-9" morph="none" pos="punct" start_char="4118">.</TOKEN>
</SEG>
<SEG end_char="4235" id="segment-35" start_char="4120">
<ORIGINAL_TEXT>As this claim is not supported by any other credible news reports, we’ve concluded that this report is indeed false.</ORIGINAL_TEXT>
<TOKEN end_char="4121" id="token-35-0" morph="none" pos="word" start_char="4120">As</TOKEN>
<TOKEN end_char="4126" id="token-35-1" morph="none" pos="word" start_char="4123">this</TOKEN>
<TOKEN end_char="4132" id="token-35-2" morph="none" pos="word" start_char="4128">claim</TOKEN>
<TOKEN end_char="4135" id="token-35-3" morph="none" pos="word" start_char="4134">is</TOKEN>
<TOKEN end_char="4139" id="token-35-4" morph="none" pos="word" start_char="4137">not</TOKEN>
<TOKEN end_char="4149" id="token-35-5" morph="none" pos="word" start_char="4141">supported</TOKEN>
<TOKEN end_char="4152" id="token-35-6" morph="none" pos="word" start_char="4151">by</TOKEN>
<TOKEN end_char="4156" id="token-35-7" morph="none" pos="word" start_char="4154">any</TOKEN>
<TOKEN end_char="4162" id="token-35-8" morph="none" pos="word" start_char="4158">other</TOKEN>
<TOKEN end_char="4171" id="token-35-9" morph="none" pos="word" start_char="4164">credible</TOKEN>
<TOKEN end_char="4176" id="token-35-10" morph="none" pos="word" start_char="4173">news</TOKEN>
<TOKEN end_char="4184" id="token-35-11" morph="none" pos="word" start_char="4178">reports</TOKEN>
<TOKEN end_char="4185" id="token-35-12" morph="none" pos="punct" start_char="4185">,</TOKEN>
<TOKEN end_char="4191" id="token-35-13" morph="none" pos="word" start_char="4187">we’ve</TOKEN>
<TOKEN end_char="4201" id="token-35-14" morph="none" pos="word" start_char="4193">concluded</TOKEN>
<TOKEN end_char="4206" id="token-35-15" morph="none" pos="word" start_char="4203">that</TOKEN>
<TOKEN end_char="4211" id="token-35-16" morph="none" pos="word" start_char="4208">this</TOKEN>
<TOKEN end_char="4218" id="token-35-17" morph="none" pos="word" start_char="4213">report</TOKEN>
<TOKEN end_char="4221" id="token-35-18" morph="none" pos="word" start_char="4220">is</TOKEN>
<TOKEN end_char="4228" id="token-35-19" morph="none" pos="word" start_char="4223">indeed</TOKEN>
<TOKEN end_char="4234" id="token-35-20" morph="none" pos="word" start_char="4230">false</TOKEN>
<TOKEN end_char="4235" id="token-35-21" morph="none" pos="punct" start_char="4235">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
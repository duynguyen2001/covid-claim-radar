<LCTL_TEXT lang="eng">
<DOC grammar="none" id="L0C049DZE" lang="eng" raw_text_char_length="8316" raw_text_md5="141d7fe72cdc23c497bc7b7c3a28d906" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="62" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Fact-check: Did Dr. Fauci fund research that created COVID-19?</ORIGINAL_TEXT>
<TOKEN end_char="10" id="token-0-0" morph="none" pos="unknown" start_char="1">Fact-check</TOKEN>
<TOKEN end_char="11" id="token-0-1" morph="none" pos="punct" start_char="11">:</TOKEN>
<TOKEN end_char="15" id="token-0-2" morph="none" pos="word" start_char="13">Did</TOKEN>
<TOKEN end_char="18" id="token-0-3" morph="none" pos="word" start_char="17">Dr</TOKEN>
<TOKEN end_char="19" id="token-0-4" morph="none" pos="punct" start_char="19">.</TOKEN>
<TOKEN end_char="25" id="token-0-5" morph="none" pos="word" start_char="21">Fauci</TOKEN>
<TOKEN end_char="30" id="token-0-6" morph="none" pos="word" start_char="27">fund</TOKEN>
<TOKEN end_char="39" id="token-0-7" morph="none" pos="word" start_char="32">research</TOKEN>
<TOKEN end_char="44" id="token-0-8" morph="none" pos="word" start_char="41">that</TOKEN>
<TOKEN end_char="52" id="token-0-9" morph="none" pos="word" start_char="46">created</TOKEN>
<TOKEN end_char="61" id="token-0-10" morph="none" pos="unknown" start_char="54">COVID-19</TOKEN>
<TOKEN end_char="62" id="token-0-11" morph="none" pos="punct" start_char="62">?</TOKEN>
</SEG>
<SEG end_char="146" id="segment-1" start_char="67">
<ORIGINAL_TEXT>WorldNetDaily: "New evidence ties COVID-19 creation to research funded by Fauci"</ORIGINAL_TEXT>
<TOKEN end_char="79" id="token-1-0" morph="none" pos="word" start_char="67">WorldNetDaily</TOKEN>
<TOKEN end_char="80" id="token-1-1" morph="none" pos="punct" start_char="80">:</TOKEN>
<TOKEN end_char="82" id="token-1-2" morph="none" pos="punct" start_char="82">"</TOKEN>
<TOKEN end_char="85" id="token-1-3" morph="none" pos="word" start_char="83">New</TOKEN>
<TOKEN end_char="94" id="token-1-4" morph="none" pos="word" start_char="87">evidence</TOKEN>
<TOKEN end_char="99" id="token-1-5" morph="none" pos="word" start_char="96">ties</TOKEN>
<TOKEN end_char="108" id="token-1-6" morph="none" pos="unknown" start_char="101">COVID-19</TOKEN>
<TOKEN end_char="117" id="token-1-7" morph="none" pos="word" start_char="110">creation</TOKEN>
<TOKEN end_char="120" id="token-1-8" morph="none" pos="word" start_char="119">to</TOKEN>
<TOKEN end_char="129" id="token-1-9" morph="none" pos="word" start_char="122">research</TOKEN>
<TOKEN end_char="136" id="token-1-10" morph="none" pos="word" start_char="131">funded</TOKEN>
<TOKEN end_char="139" id="token-1-11" morph="none" pos="word" start_char="138">by</TOKEN>
<TOKEN end_char="145" id="token-1-12" morph="none" pos="word" start_char="141">Fauci</TOKEN>
<TOKEN end_char="146" id="token-1-13" morph="none" pos="punct" start_char="146">"</TOKEN>
</SEG>
<SEG end_char="174" id="segment-2" start_char="149">
<ORIGINAL_TEXT>PolitiFact's ruling: False</ORIGINAL_TEXT>
<TOKEN end_char="160" id="token-2-0" morph="none" pos="word" start_char="149">PolitiFact's</TOKEN>
<TOKEN end_char="167" id="token-2-1" morph="none" pos="word" start_char="162">ruling</TOKEN>
<TOKEN end_char="168" id="token-2-2" morph="none" pos="punct" start_char="168">:</TOKEN>
<TOKEN end_char="174" id="token-2-3" morph="none" pos="word" start_char="170">False</TOKEN>
</SEG>
<SEG end_char="421" id="segment-3" start_char="177">
<ORIGINAL_TEXT>Here's why: More than a year after the coronavirus first arrived in the U.S., conspiracy theories continue to spread about a virology lab in Wuhan, China, which has drawn scrutiny throughout the pandemic for research it conducted on bat viruses.</ORIGINAL_TEXT>
<TOKEN end_char="182" id="token-3-0" morph="none" pos="word" start_char="177">Here's</TOKEN>
<TOKEN end_char="186" id="token-3-1" morph="none" pos="word" start_char="184">why</TOKEN>
<TOKEN end_char="187" id="token-3-2" morph="none" pos="punct" start_char="187">:</TOKEN>
<TOKEN end_char="192" id="token-3-3" morph="none" pos="word" start_char="189">More</TOKEN>
<TOKEN end_char="197" id="token-3-4" morph="none" pos="word" start_char="194">than</TOKEN>
<TOKEN end_char="199" id="token-3-5" morph="none" pos="word" start_char="199">a</TOKEN>
<TOKEN end_char="204" id="token-3-6" morph="none" pos="word" start_char="201">year</TOKEN>
<TOKEN end_char="210" id="token-3-7" morph="none" pos="word" start_char="206">after</TOKEN>
<TOKEN end_char="214" id="token-3-8" morph="none" pos="word" start_char="212">the</TOKEN>
<TOKEN end_char="226" id="token-3-9" morph="none" pos="word" start_char="216">coronavirus</TOKEN>
<TOKEN end_char="232" id="token-3-10" morph="none" pos="word" start_char="228">first</TOKEN>
<TOKEN end_char="240" id="token-3-11" morph="none" pos="word" start_char="234">arrived</TOKEN>
<TOKEN end_char="243" id="token-3-12" morph="none" pos="word" start_char="242">in</TOKEN>
<TOKEN end_char="247" id="token-3-13" morph="none" pos="word" start_char="245">the</TOKEN>
<TOKEN end_char="251" id="token-3-14" morph="none" pos="unknown" start_char="249">U.S</TOKEN>
<TOKEN end_char="253" id="token-3-15" morph="none" pos="punct" start_char="252">.,</TOKEN>
<TOKEN end_char="264" id="token-3-16" morph="none" pos="word" start_char="255">conspiracy</TOKEN>
<TOKEN end_char="273" id="token-3-17" morph="none" pos="word" start_char="266">theories</TOKEN>
<TOKEN end_char="282" id="token-3-18" morph="none" pos="word" start_char="275">continue</TOKEN>
<TOKEN end_char="285" id="token-3-19" morph="none" pos="word" start_char="284">to</TOKEN>
<TOKEN end_char="292" id="token-3-20" morph="none" pos="word" start_char="287">spread</TOKEN>
<TOKEN end_char="298" id="token-3-21" morph="none" pos="word" start_char="294">about</TOKEN>
<TOKEN end_char="300" id="token-3-22" morph="none" pos="word" start_char="300">a</TOKEN>
<TOKEN end_char="309" id="token-3-23" morph="none" pos="word" start_char="302">virology</TOKEN>
<TOKEN end_char="313" id="token-3-24" morph="none" pos="word" start_char="311">lab</TOKEN>
<TOKEN end_char="316" id="token-3-25" morph="none" pos="word" start_char="315">in</TOKEN>
<TOKEN end_char="322" id="token-3-26" morph="none" pos="word" start_char="318">Wuhan</TOKEN>
<TOKEN end_char="323" id="token-3-27" morph="none" pos="punct" start_char="323">,</TOKEN>
<TOKEN end_char="329" id="token-3-28" morph="none" pos="word" start_char="325">China</TOKEN>
<TOKEN end_char="330" id="token-3-29" morph="none" pos="punct" start_char="330">,</TOKEN>
<TOKEN end_char="336" id="token-3-30" morph="none" pos="word" start_char="332">which</TOKEN>
<TOKEN end_char="340" id="token-3-31" morph="none" pos="word" start_char="338">has</TOKEN>
<TOKEN end_char="346" id="token-3-32" morph="none" pos="word" start_char="342">drawn</TOKEN>
<TOKEN end_char="355" id="token-3-33" morph="none" pos="word" start_char="348">scrutiny</TOKEN>
<TOKEN end_char="366" id="token-3-34" morph="none" pos="word" start_char="357">throughout</TOKEN>
<TOKEN end_char="370" id="token-3-35" morph="none" pos="word" start_char="368">the</TOKEN>
<TOKEN end_char="379" id="token-3-36" morph="none" pos="word" start_char="372">pandemic</TOKEN>
<TOKEN end_char="383" id="token-3-37" morph="none" pos="word" start_char="381">for</TOKEN>
<TOKEN end_char="392" id="token-3-38" morph="none" pos="word" start_char="385">research</TOKEN>
<TOKEN end_char="395" id="token-3-39" morph="none" pos="word" start_char="394">it</TOKEN>
<TOKEN end_char="405" id="token-3-40" morph="none" pos="word" start_char="397">conducted</TOKEN>
<TOKEN end_char="408" id="token-3-41" morph="none" pos="word" start_char="407">on</TOKEN>
<TOKEN end_char="412" id="token-3-42" morph="none" pos="word" start_char="410">bat</TOKEN>
<TOKEN end_char="420" id="token-3-43" morph="none" pos="word" start_char="414">viruses</TOKEN>
<TOKEN end_char="421" id="token-3-44" morph="none" pos="punct" start_char="421">.</TOKEN>
</SEG>
<SEG end_char="526" id="segment-4" start_char="424">
<ORIGINAL_TEXT>One new claim about the lab comes from conservative news site WorldNetDaily, which tried to connect Dr.</ORIGINAL_TEXT>
<TOKEN end_char="426" id="token-4-0" morph="none" pos="word" start_char="424">One</TOKEN>
<TOKEN end_char="430" id="token-4-1" morph="none" pos="word" start_char="428">new</TOKEN>
<TOKEN end_char="436" id="token-4-2" morph="none" pos="word" start_char="432">claim</TOKEN>
<TOKEN end_char="442" id="token-4-3" morph="none" pos="word" start_char="438">about</TOKEN>
<TOKEN end_char="446" id="token-4-4" morph="none" pos="word" start_char="444">the</TOKEN>
<TOKEN end_char="450" id="token-4-5" morph="none" pos="word" start_char="448">lab</TOKEN>
<TOKEN end_char="456" id="token-4-6" morph="none" pos="word" start_char="452">comes</TOKEN>
<TOKEN end_char="461" id="token-4-7" morph="none" pos="word" start_char="458">from</TOKEN>
<TOKEN end_char="474" id="token-4-8" morph="none" pos="word" start_char="463">conservative</TOKEN>
<TOKEN end_char="479" id="token-4-9" morph="none" pos="word" start_char="476">news</TOKEN>
<TOKEN end_char="484" id="token-4-10" morph="none" pos="word" start_char="481">site</TOKEN>
<TOKEN end_char="498" id="token-4-11" morph="none" pos="word" start_char="486">WorldNetDaily</TOKEN>
<TOKEN end_char="499" id="token-4-12" morph="none" pos="punct" start_char="499">,</TOKEN>
<TOKEN end_char="505" id="token-4-13" morph="none" pos="word" start_char="501">which</TOKEN>
<TOKEN end_char="511" id="token-4-14" morph="none" pos="word" start_char="507">tried</TOKEN>
<TOKEN end_char="514" id="token-4-15" morph="none" pos="word" start_char="513">to</TOKEN>
<TOKEN end_char="522" id="token-4-16" morph="none" pos="word" start_char="516">connect</TOKEN>
<TOKEN end_char="525" id="token-4-17" morph="none" pos="word" start_char="524">Dr</TOKEN>
<TOKEN end_char="526" id="token-4-18" morph="none" pos="punct" start_char="526">.</TOKEN>
</SEG>
<SEG end_char="662" id="segment-5" start_char="528">
<ORIGINAL_TEXT>Anthony Fauci, head of infectious diseases at the National Institutes of Health, to the origin of the coronavirus that causes COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="534" id="token-5-0" morph="none" pos="word" start_char="528">Anthony</TOKEN>
<TOKEN end_char="540" id="token-5-1" morph="none" pos="word" start_char="536">Fauci</TOKEN>
<TOKEN end_char="541" id="token-5-2" morph="none" pos="punct" start_char="541">,</TOKEN>
<TOKEN end_char="546" id="token-5-3" morph="none" pos="word" start_char="543">head</TOKEN>
<TOKEN end_char="549" id="token-5-4" morph="none" pos="word" start_char="548">of</TOKEN>
<TOKEN end_char="560" id="token-5-5" morph="none" pos="word" start_char="551">infectious</TOKEN>
<TOKEN end_char="569" id="token-5-6" morph="none" pos="word" start_char="562">diseases</TOKEN>
<TOKEN end_char="572" id="token-5-7" morph="none" pos="word" start_char="571">at</TOKEN>
<TOKEN end_char="576" id="token-5-8" morph="none" pos="word" start_char="574">the</TOKEN>
<TOKEN end_char="585" id="token-5-9" morph="none" pos="word" start_char="578">National</TOKEN>
<TOKEN end_char="596" id="token-5-10" morph="none" pos="word" start_char="587">Institutes</TOKEN>
<TOKEN end_char="599" id="token-5-11" morph="none" pos="word" start_char="598">of</TOKEN>
<TOKEN end_char="606" id="token-5-12" morph="none" pos="word" start_char="601">Health</TOKEN>
<TOKEN end_char="607" id="token-5-13" morph="none" pos="punct" start_char="607">,</TOKEN>
<TOKEN end_char="610" id="token-5-14" morph="none" pos="word" start_char="609">to</TOKEN>
<TOKEN end_char="614" id="token-5-15" morph="none" pos="word" start_char="612">the</TOKEN>
<TOKEN end_char="621" id="token-5-16" morph="none" pos="word" start_char="616">origin</TOKEN>
<TOKEN end_char="624" id="token-5-17" morph="none" pos="word" start_char="623">of</TOKEN>
<TOKEN end_char="628" id="token-5-18" morph="none" pos="word" start_char="626">the</TOKEN>
<TOKEN end_char="640" id="token-5-19" morph="none" pos="word" start_char="630">coronavirus</TOKEN>
<TOKEN end_char="645" id="token-5-20" morph="none" pos="word" start_char="642">that</TOKEN>
<TOKEN end_char="652" id="token-5-21" morph="none" pos="word" start_char="647">causes</TOKEN>
<TOKEN end_char="661" id="token-5-22" morph="none" pos="unknown" start_char="654">COVID-19</TOKEN>
<TOKEN end_char="662" id="token-5-23" morph="none" pos="punct" start_char="662">.</TOKEN>
</SEG>
<SEG end_char="750" id="segment-6" start_char="665">
<ORIGINAL_TEXT>"New evidence ties COVID-19 creation to research funded by Fauci," reads the headline.</ORIGINAL_TEXT>
<TOKEN end_char="665" id="token-6-0" morph="none" pos="punct" start_char="665">"</TOKEN>
<TOKEN end_char="668" id="token-6-1" morph="none" pos="word" start_char="666">New</TOKEN>
<TOKEN end_char="677" id="token-6-2" morph="none" pos="word" start_char="670">evidence</TOKEN>
<TOKEN end_char="682" id="token-6-3" morph="none" pos="word" start_char="679">ties</TOKEN>
<TOKEN end_char="691" id="token-6-4" morph="none" pos="unknown" start_char="684">COVID-19</TOKEN>
<TOKEN end_char="700" id="token-6-5" morph="none" pos="word" start_char="693">creation</TOKEN>
<TOKEN end_char="703" id="token-6-6" morph="none" pos="word" start_char="702">to</TOKEN>
<TOKEN end_char="712" id="token-6-7" morph="none" pos="word" start_char="705">research</TOKEN>
<TOKEN end_char="719" id="token-6-8" morph="none" pos="word" start_char="714">funded</TOKEN>
<TOKEN end_char="722" id="token-6-9" morph="none" pos="word" start_char="721">by</TOKEN>
<TOKEN end_char="728" id="token-6-10" morph="none" pos="word" start_char="724">Fauci</TOKEN>
<TOKEN end_char="730" id="token-6-11" morph="none" pos="punct" start_char="729">,"</TOKEN>
<TOKEN end_char="736" id="token-6-12" morph="none" pos="word" start_char="732">reads</TOKEN>
<TOKEN end_char="740" id="token-6-13" morph="none" pos="word" start_char="738">the</TOKEN>
<TOKEN end_char="749" id="token-6-14" morph="none" pos="word" start_char="742">headline</TOKEN>
<TOKEN end_char="750" id="token-6-15" morph="none" pos="punct" start_char="750">.</TOKEN>
</SEG>
<SEG end_char="933" id="segment-7" start_char="753">
<ORIGINAL_TEXT>As evidence of its claim, the article cited an investigation by Fox News commentator Steve Hilton, who claims that the coronavirus was created at the Wuhan lab with NIH grant money.</ORIGINAL_TEXT>
<TOKEN end_char="754" id="token-7-0" morph="none" pos="word" start_char="753">As</TOKEN>
<TOKEN end_char="763" id="token-7-1" morph="none" pos="word" start_char="756">evidence</TOKEN>
<TOKEN end_char="766" id="token-7-2" morph="none" pos="word" start_char="765">of</TOKEN>
<TOKEN end_char="770" id="token-7-3" morph="none" pos="word" start_char="768">its</TOKEN>
<TOKEN end_char="776" id="token-7-4" morph="none" pos="word" start_char="772">claim</TOKEN>
<TOKEN end_char="777" id="token-7-5" morph="none" pos="punct" start_char="777">,</TOKEN>
<TOKEN end_char="781" id="token-7-6" morph="none" pos="word" start_char="779">the</TOKEN>
<TOKEN end_char="789" id="token-7-7" morph="none" pos="word" start_char="783">article</TOKEN>
<TOKEN end_char="795" id="token-7-8" morph="none" pos="word" start_char="791">cited</TOKEN>
<TOKEN end_char="798" id="token-7-9" morph="none" pos="word" start_char="797">an</TOKEN>
<TOKEN end_char="812" id="token-7-10" morph="none" pos="word" start_char="800">investigation</TOKEN>
<TOKEN end_char="815" id="token-7-11" morph="none" pos="word" start_char="814">by</TOKEN>
<TOKEN end_char="819" id="token-7-12" morph="none" pos="word" start_char="817">Fox</TOKEN>
<TOKEN end_char="824" id="token-7-13" morph="none" pos="word" start_char="821">News</TOKEN>
<TOKEN end_char="836" id="token-7-14" morph="none" pos="word" start_char="826">commentator</TOKEN>
<TOKEN end_char="842" id="token-7-15" morph="none" pos="word" start_char="838">Steve</TOKEN>
<TOKEN end_char="849" id="token-7-16" morph="none" pos="word" start_char="844">Hilton</TOKEN>
<TOKEN end_char="850" id="token-7-17" morph="none" pos="punct" start_char="850">,</TOKEN>
<TOKEN end_char="854" id="token-7-18" morph="none" pos="word" start_char="852">who</TOKEN>
<TOKEN end_char="861" id="token-7-19" morph="none" pos="word" start_char="856">claims</TOKEN>
<TOKEN end_char="866" id="token-7-20" morph="none" pos="word" start_char="863">that</TOKEN>
<TOKEN end_char="870" id="token-7-21" morph="none" pos="word" start_char="868">the</TOKEN>
<TOKEN end_char="882" id="token-7-22" morph="none" pos="word" start_char="872">coronavirus</TOKEN>
<TOKEN end_char="886" id="token-7-23" morph="none" pos="word" start_char="884">was</TOKEN>
<TOKEN end_char="894" id="token-7-24" morph="none" pos="word" start_char="888">created</TOKEN>
<TOKEN end_char="897" id="token-7-25" morph="none" pos="word" start_char="896">at</TOKEN>
<TOKEN end_char="901" id="token-7-26" morph="none" pos="word" start_char="899">the</TOKEN>
<TOKEN end_char="907" id="token-7-27" morph="none" pos="word" start_char="903">Wuhan</TOKEN>
<TOKEN end_char="911" id="token-7-28" morph="none" pos="word" start_char="909">lab</TOKEN>
<TOKEN end_char="916" id="token-7-29" morph="none" pos="word" start_char="913">with</TOKEN>
<TOKEN end_char="920" id="token-7-30" morph="none" pos="word" start_char="918">NIH</TOKEN>
<TOKEN end_char="926" id="token-7-31" morph="none" pos="word" start_char="922">grant</TOKEN>
<TOKEN end_char="932" id="token-7-32" morph="none" pos="word" start_char="928">money</TOKEN>
<TOKEN end_char="933" id="token-7-33" morph="none" pos="punct" start_char="933">.</TOKEN>
</SEG>
<SEG end_char="1045" id="segment-8" start_char="936">
<ORIGINAL_TEXT>Although the NIH did fund a project at the Wuhan lab, there’s no proof that the coronavirus was bioengineered.</ORIGINAL_TEXT>
<TOKEN end_char="943" id="token-8-0" morph="none" pos="word" start_char="936">Although</TOKEN>
<TOKEN end_char="947" id="token-8-1" morph="none" pos="word" start_char="945">the</TOKEN>
<TOKEN end_char="951" id="token-8-2" morph="none" pos="word" start_char="949">NIH</TOKEN>
<TOKEN end_char="955" id="token-8-3" morph="none" pos="word" start_char="953">did</TOKEN>
<TOKEN end_char="960" id="token-8-4" morph="none" pos="word" start_char="957">fund</TOKEN>
<TOKEN end_char="962" id="token-8-5" morph="none" pos="word" start_char="962">a</TOKEN>
<TOKEN end_char="970" id="token-8-6" morph="none" pos="word" start_char="964">project</TOKEN>
<TOKEN end_char="973" id="token-8-7" morph="none" pos="word" start_char="972">at</TOKEN>
<TOKEN end_char="977" id="token-8-8" morph="none" pos="word" start_char="975">the</TOKEN>
<TOKEN end_char="983" id="token-8-9" morph="none" pos="word" start_char="979">Wuhan</TOKEN>
<TOKEN end_char="987" id="token-8-10" morph="none" pos="word" start_char="985">lab</TOKEN>
<TOKEN end_char="988" id="token-8-11" morph="none" pos="punct" start_char="988">,</TOKEN>
<TOKEN end_char="996" id="token-8-12" morph="none" pos="word" start_char="990">there’s</TOKEN>
<TOKEN end_char="999" id="token-8-13" morph="none" pos="word" start_char="998">no</TOKEN>
<TOKEN end_char="1005" id="token-8-14" morph="none" pos="word" start_char="1001">proof</TOKEN>
<TOKEN end_char="1010" id="token-8-15" morph="none" pos="word" start_char="1007">that</TOKEN>
<TOKEN end_char="1014" id="token-8-16" morph="none" pos="word" start_char="1012">the</TOKEN>
<TOKEN end_char="1026" id="token-8-17" morph="none" pos="word" start_char="1016">coronavirus</TOKEN>
<TOKEN end_char="1030" id="token-8-18" morph="none" pos="word" start_char="1028">was</TOKEN>
<TOKEN end_char="1044" id="token-8-19" morph="none" pos="word" start_char="1032">bioengineered</TOKEN>
<TOKEN end_char="1045" id="token-8-20" morph="none" pos="punct" start_char="1045">.</TOKEN>
</SEG>
<SEG end_char="1211" id="segment-9" start_char="1047">
<ORIGINAL_TEXT>Both the WorldNetDaily article and Hilton’s segment rely on a series of unsubstantiated allegations to spin a conspiracy theory about the virus being a lab creation.</ORIGINAL_TEXT>
<TOKEN end_char="1050" id="token-9-0" morph="none" pos="word" start_char="1047">Both</TOKEN>
<TOKEN end_char="1054" id="token-9-1" morph="none" pos="word" start_char="1052">the</TOKEN>
<TOKEN end_char="1068" id="token-9-2" morph="none" pos="word" start_char="1056">WorldNetDaily</TOKEN>
<TOKEN end_char="1076" id="token-9-3" morph="none" pos="word" start_char="1070">article</TOKEN>
<TOKEN end_char="1080" id="token-9-4" morph="none" pos="word" start_char="1078">and</TOKEN>
<TOKEN end_char="1089" id="token-9-5" morph="none" pos="word" start_char="1082">Hilton’s</TOKEN>
<TOKEN end_char="1097" id="token-9-6" morph="none" pos="word" start_char="1091">segment</TOKEN>
<TOKEN end_char="1102" id="token-9-7" morph="none" pos="word" start_char="1099">rely</TOKEN>
<TOKEN end_char="1105" id="token-9-8" morph="none" pos="word" start_char="1104">on</TOKEN>
<TOKEN end_char="1107" id="token-9-9" morph="none" pos="word" start_char="1107">a</TOKEN>
<TOKEN end_char="1114" id="token-9-10" morph="none" pos="word" start_char="1109">series</TOKEN>
<TOKEN end_char="1117" id="token-9-11" morph="none" pos="word" start_char="1116">of</TOKEN>
<TOKEN end_char="1133" id="token-9-12" morph="none" pos="word" start_char="1119">unsubstantiated</TOKEN>
<TOKEN end_char="1145" id="token-9-13" morph="none" pos="word" start_char="1135">allegations</TOKEN>
<TOKEN end_char="1148" id="token-9-14" morph="none" pos="word" start_char="1147">to</TOKEN>
<TOKEN end_char="1153" id="token-9-15" morph="none" pos="word" start_char="1150">spin</TOKEN>
<TOKEN end_char="1155" id="token-9-16" morph="none" pos="word" start_char="1155">a</TOKEN>
<TOKEN end_char="1166" id="token-9-17" morph="none" pos="word" start_char="1157">conspiracy</TOKEN>
<TOKEN end_char="1173" id="token-9-18" morph="none" pos="word" start_char="1168">theory</TOKEN>
<TOKEN end_char="1179" id="token-9-19" morph="none" pos="word" start_char="1175">about</TOKEN>
<TOKEN end_char="1183" id="token-9-20" morph="none" pos="word" start_char="1181">the</TOKEN>
<TOKEN end_char="1189" id="token-9-21" morph="none" pos="word" start_char="1185">virus</TOKEN>
<TOKEN end_char="1195" id="token-9-22" morph="none" pos="word" start_char="1191">being</TOKEN>
<TOKEN end_char="1197" id="token-9-23" morph="none" pos="word" start_char="1197">a</TOKEN>
<TOKEN end_char="1201" id="token-9-24" morph="none" pos="word" start_char="1199">lab</TOKEN>
<TOKEN end_char="1210" id="token-9-25" morph="none" pos="word" start_char="1203">creation</TOKEN>
<TOKEN end_char="1211" id="token-9-26" morph="none" pos="punct" start_char="1211">.</TOKEN>
</SEG>
<SEG end_char="1392" id="segment-10" start_char="1214">
<ORIGINAL_TEXT>WorldNetDaily has since dialed back on many of its claims, issuing three separate corrections, all of which cite scientists pushing back on the notion that SARS-CoV-2 was manmade.</ORIGINAL_TEXT>
<TOKEN end_char="1226" id="token-10-0" morph="none" pos="word" start_char="1214">WorldNetDaily</TOKEN>
<TOKEN end_char="1230" id="token-10-1" morph="none" pos="word" start_char="1228">has</TOKEN>
<TOKEN end_char="1236" id="token-10-2" morph="none" pos="word" start_char="1232">since</TOKEN>
<TOKEN end_char="1243" id="token-10-3" morph="none" pos="word" start_char="1238">dialed</TOKEN>
<TOKEN end_char="1248" id="token-10-4" morph="none" pos="word" start_char="1245">back</TOKEN>
<TOKEN end_char="1251" id="token-10-5" morph="none" pos="word" start_char="1250">on</TOKEN>
<TOKEN end_char="1256" id="token-10-6" morph="none" pos="word" start_char="1253">many</TOKEN>
<TOKEN end_char="1259" id="token-10-7" morph="none" pos="word" start_char="1258">of</TOKEN>
<TOKEN end_char="1263" id="token-10-8" morph="none" pos="word" start_char="1261">its</TOKEN>
<TOKEN end_char="1270" id="token-10-9" morph="none" pos="word" start_char="1265">claims</TOKEN>
<TOKEN end_char="1271" id="token-10-10" morph="none" pos="punct" start_char="1271">,</TOKEN>
<TOKEN end_char="1279" id="token-10-11" morph="none" pos="word" start_char="1273">issuing</TOKEN>
<TOKEN end_char="1285" id="token-10-12" morph="none" pos="word" start_char="1281">three</TOKEN>
<TOKEN end_char="1294" id="token-10-13" morph="none" pos="word" start_char="1287">separate</TOKEN>
<TOKEN end_char="1306" id="token-10-14" morph="none" pos="word" start_char="1296">corrections</TOKEN>
<TOKEN end_char="1307" id="token-10-15" morph="none" pos="punct" start_char="1307">,</TOKEN>
<TOKEN end_char="1311" id="token-10-16" morph="none" pos="word" start_char="1309">all</TOKEN>
<TOKEN end_char="1314" id="token-10-17" morph="none" pos="word" start_char="1313">of</TOKEN>
<TOKEN end_char="1320" id="token-10-18" morph="none" pos="word" start_char="1316">which</TOKEN>
<TOKEN end_char="1325" id="token-10-19" morph="none" pos="word" start_char="1322">cite</TOKEN>
<TOKEN end_char="1336" id="token-10-20" morph="none" pos="word" start_char="1327">scientists</TOKEN>
<TOKEN end_char="1344" id="token-10-21" morph="none" pos="word" start_char="1338">pushing</TOKEN>
<TOKEN end_char="1349" id="token-10-22" morph="none" pos="word" start_char="1346">back</TOKEN>
<TOKEN end_char="1352" id="token-10-23" morph="none" pos="word" start_char="1351">on</TOKEN>
<TOKEN end_char="1356" id="token-10-24" morph="none" pos="word" start_char="1354">the</TOKEN>
<TOKEN end_char="1363" id="token-10-25" morph="none" pos="word" start_char="1358">notion</TOKEN>
<TOKEN end_char="1368" id="token-10-26" morph="none" pos="word" start_char="1365">that</TOKEN>
<TOKEN end_char="1379" id="token-10-27" morph="none" pos="unknown" start_char="1370">SARS-CoV-2</TOKEN>
<TOKEN end_char="1383" id="token-10-28" morph="none" pos="word" start_char="1381">was</TOKEN>
<TOKEN end_char="1391" id="token-10-29" morph="none" pos="word" start_char="1385">manmade</TOKEN>
<TOKEN end_char="1392" id="token-10-30" morph="none" pos="punct" start_char="1392">.</TOKEN>
</SEG>
<SEG end_char="1464" id="segment-11" start_char="1394">
<ORIGINAL_TEXT>It has also placed a question mark at the end of the original headline.</ORIGINAL_TEXT>
<TOKEN end_char="1395" id="token-11-0" morph="none" pos="word" start_char="1394">It</TOKEN>
<TOKEN end_char="1399" id="token-11-1" morph="none" pos="word" start_char="1397">has</TOKEN>
<TOKEN end_char="1404" id="token-11-2" morph="none" pos="word" start_char="1401">also</TOKEN>
<TOKEN end_char="1411" id="token-11-3" morph="none" pos="word" start_char="1406">placed</TOKEN>
<TOKEN end_char="1413" id="token-11-4" morph="none" pos="word" start_char="1413">a</TOKEN>
<TOKEN end_char="1422" id="token-11-5" morph="none" pos="word" start_char="1415">question</TOKEN>
<TOKEN end_char="1427" id="token-11-6" morph="none" pos="word" start_char="1424">mark</TOKEN>
<TOKEN end_char="1430" id="token-11-7" morph="none" pos="word" start_char="1429">at</TOKEN>
<TOKEN end_char="1434" id="token-11-8" morph="none" pos="word" start_char="1432">the</TOKEN>
<TOKEN end_char="1438" id="token-11-9" morph="none" pos="word" start_char="1436">end</TOKEN>
<TOKEN end_char="1441" id="token-11-10" morph="none" pos="word" start_char="1440">of</TOKEN>
<TOKEN end_char="1445" id="token-11-11" morph="none" pos="word" start_char="1443">the</TOKEN>
<TOKEN end_char="1454" id="token-11-12" morph="none" pos="word" start_char="1447">original</TOKEN>
<TOKEN end_char="1463" id="token-11-13" morph="none" pos="word" start_char="1456">headline</TOKEN>
<TOKEN end_char="1464" id="token-11-14" morph="none" pos="punct" start_char="1464">.</TOKEN>
</SEG>
<SEG end_char="1524" id="segment-12" start_char="1466">
<ORIGINAL_TEXT>However, the bulk of the article text has not been updated.</ORIGINAL_TEXT>
<TOKEN end_char="1472" id="token-12-0" morph="none" pos="word" start_char="1466">However</TOKEN>
<TOKEN end_char="1473" id="token-12-1" morph="none" pos="punct" start_char="1473">,</TOKEN>
<TOKEN end_char="1477" id="token-12-2" morph="none" pos="word" start_char="1475">the</TOKEN>
<TOKEN end_char="1482" id="token-12-3" morph="none" pos="word" start_char="1479">bulk</TOKEN>
<TOKEN end_char="1485" id="token-12-4" morph="none" pos="word" start_char="1484">of</TOKEN>
<TOKEN end_char="1489" id="token-12-5" morph="none" pos="word" start_char="1487">the</TOKEN>
<TOKEN end_char="1497" id="token-12-6" morph="none" pos="word" start_char="1491">article</TOKEN>
<TOKEN end_char="1502" id="token-12-7" morph="none" pos="word" start_char="1499">text</TOKEN>
<TOKEN end_char="1506" id="token-12-8" morph="none" pos="word" start_char="1504">has</TOKEN>
<TOKEN end_char="1510" id="token-12-9" morph="none" pos="word" start_char="1508">not</TOKEN>
<TOKEN end_char="1515" id="token-12-10" morph="none" pos="word" start_char="1512">been</TOKEN>
<TOKEN end_char="1523" id="token-12-11" morph="none" pos="word" start_char="1517">updated</TOKEN>
<TOKEN end_char="1524" id="token-12-12" morph="none" pos="punct" start_char="1524">.</TOKEN>
</SEG>
<SEG end_char="1561" id="segment-13" start_char="1527">
<ORIGINAL_TEXT>The NIH grant to EcoHealth Alliance</ORIGINAL_TEXT>
<TOKEN end_char="1529" id="token-13-0" morph="none" pos="word" start_char="1527">The</TOKEN>
<TOKEN end_char="1533" id="token-13-1" morph="none" pos="word" start_char="1531">NIH</TOKEN>
<TOKEN end_char="1539" id="token-13-2" morph="none" pos="word" start_char="1535">grant</TOKEN>
<TOKEN end_char="1542" id="token-13-3" morph="none" pos="word" start_char="1541">to</TOKEN>
<TOKEN end_char="1552" id="token-13-4" morph="none" pos="word" start_char="1544">EcoHealth</TOKEN>
<TOKEN end_char="1561" id="token-13-5" morph="none" pos="word" start_char="1554">Alliance</TOKEN>
</SEG>
<SEG end_char="1820" id="segment-14" start_char="1565">
<ORIGINAL_TEXT>In 2014, the U.S. National Institute of Allergy and Infectious Disease, the part of the NIH headed by Fauci, awarded a $3.4 million grant to the New York-based EcoHealth Alliance, which aims to protect people from viruses that jump from species to species.</ORIGINAL_TEXT>
<TOKEN end_char="1566" id="token-14-0" morph="none" pos="word" start_char="1565">In</TOKEN>
<TOKEN end_char="1571" id="token-14-1" morph="none" pos="word" start_char="1568">2014</TOKEN>
<TOKEN end_char="1572" id="token-14-2" morph="none" pos="punct" start_char="1572">,</TOKEN>
<TOKEN end_char="1576" id="token-14-3" morph="none" pos="word" start_char="1574">the</TOKEN>
<TOKEN end_char="1580" id="token-14-4" morph="none" pos="unknown" start_char="1578">U.S</TOKEN>
<TOKEN end_char="1581" id="token-14-5" morph="none" pos="punct" start_char="1581">.</TOKEN>
<TOKEN end_char="1590" id="token-14-6" morph="none" pos="word" start_char="1583">National</TOKEN>
<TOKEN end_char="1600" id="token-14-7" morph="none" pos="word" start_char="1592">Institute</TOKEN>
<TOKEN end_char="1603" id="token-14-8" morph="none" pos="word" start_char="1602">of</TOKEN>
<TOKEN end_char="1611" id="token-14-9" morph="none" pos="word" start_char="1605">Allergy</TOKEN>
<TOKEN end_char="1615" id="token-14-10" morph="none" pos="word" start_char="1613">and</TOKEN>
<TOKEN end_char="1626" id="token-14-11" morph="none" pos="word" start_char="1617">Infectious</TOKEN>
<TOKEN end_char="1634" id="token-14-12" morph="none" pos="word" start_char="1628">Disease</TOKEN>
<TOKEN end_char="1635" id="token-14-13" morph="none" pos="punct" start_char="1635">,</TOKEN>
<TOKEN end_char="1639" id="token-14-14" morph="none" pos="word" start_char="1637">the</TOKEN>
<TOKEN end_char="1644" id="token-14-15" morph="none" pos="word" start_char="1641">part</TOKEN>
<TOKEN end_char="1647" id="token-14-16" morph="none" pos="word" start_char="1646">of</TOKEN>
<TOKEN end_char="1651" id="token-14-17" morph="none" pos="word" start_char="1649">the</TOKEN>
<TOKEN end_char="1655" id="token-14-18" morph="none" pos="word" start_char="1653">NIH</TOKEN>
<TOKEN end_char="1662" id="token-14-19" morph="none" pos="word" start_char="1657">headed</TOKEN>
<TOKEN end_char="1665" id="token-14-20" morph="none" pos="word" start_char="1664">by</TOKEN>
<TOKEN end_char="1671" id="token-14-21" morph="none" pos="word" start_char="1667">Fauci</TOKEN>
<TOKEN end_char="1672" id="token-14-22" morph="none" pos="punct" start_char="1672">,</TOKEN>
<TOKEN end_char="1680" id="token-14-23" morph="none" pos="word" start_char="1674">awarded</TOKEN>
<TOKEN end_char="1682" id="token-14-24" morph="none" pos="word" start_char="1682">a</TOKEN>
<TOKEN end_char="1687" id="token-14-25" morph="none" pos="unknown" start_char="1684">$3.4</TOKEN>
<TOKEN end_char="1695" id="token-14-26" morph="none" pos="word" start_char="1689">million</TOKEN>
<TOKEN end_char="1701" id="token-14-27" morph="none" pos="word" start_char="1697">grant</TOKEN>
<TOKEN end_char="1704" id="token-14-28" morph="none" pos="word" start_char="1703">to</TOKEN>
<TOKEN end_char="1708" id="token-14-29" morph="none" pos="word" start_char="1706">the</TOKEN>
<TOKEN end_char="1712" id="token-14-30" morph="none" pos="word" start_char="1710">New</TOKEN>
<TOKEN end_char="1723" id="token-14-31" morph="none" pos="unknown" start_char="1714">York-based</TOKEN>
<TOKEN end_char="1733" id="token-14-32" morph="none" pos="word" start_char="1725">EcoHealth</TOKEN>
<TOKEN end_char="1742" id="token-14-33" morph="none" pos="word" start_char="1735">Alliance</TOKEN>
<TOKEN end_char="1743" id="token-14-34" morph="none" pos="punct" start_char="1743">,</TOKEN>
<TOKEN end_char="1749" id="token-14-35" morph="none" pos="word" start_char="1745">which</TOKEN>
<TOKEN end_char="1754" id="token-14-36" morph="none" pos="word" start_char="1751">aims</TOKEN>
<TOKEN end_char="1757" id="token-14-37" morph="none" pos="word" start_char="1756">to</TOKEN>
<TOKEN end_char="1765" id="token-14-38" morph="none" pos="word" start_char="1759">protect</TOKEN>
<TOKEN end_char="1772" id="token-14-39" morph="none" pos="word" start_char="1767">people</TOKEN>
<TOKEN end_char="1777" id="token-14-40" morph="none" pos="word" start_char="1774">from</TOKEN>
<TOKEN end_char="1785" id="token-14-41" morph="none" pos="word" start_char="1779">viruses</TOKEN>
<TOKEN end_char="1790" id="token-14-42" morph="none" pos="word" start_char="1787">that</TOKEN>
<TOKEN end_char="1795" id="token-14-43" morph="none" pos="word" start_char="1792">jump</TOKEN>
<TOKEN end_char="1800" id="token-14-44" morph="none" pos="word" start_char="1797">from</TOKEN>
<TOKEN end_char="1808" id="token-14-45" morph="none" pos="word" start_char="1802">species</TOKEN>
<TOKEN end_char="1811" id="token-14-46" morph="none" pos="word" start_char="1810">to</TOKEN>
<TOKEN end_char="1819" id="token-14-47" morph="none" pos="word" start_char="1813">species</TOKEN>
<TOKEN end_char="1820" id="token-14-48" morph="none" pos="punct" start_char="1820">.</TOKEN>
</SEG>
<SEG end_char="1978" id="segment-15" start_char="1823">
<ORIGINAL_TEXT>The group hired the virology lab in Wuhan to conduct genetic analyses of bat coronaviruses collected in Yunnan province, about 800 miles southwest of Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="1825" id="token-15-0" morph="none" pos="word" start_char="1823">The</TOKEN>
<TOKEN end_char="1831" id="token-15-1" morph="none" pos="word" start_char="1827">group</TOKEN>
<TOKEN end_char="1837" id="token-15-2" morph="none" pos="word" start_char="1833">hired</TOKEN>
<TOKEN end_char="1841" id="token-15-3" morph="none" pos="word" start_char="1839">the</TOKEN>
<TOKEN end_char="1850" id="token-15-4" morph="none" pos="word" start_char="1843">virology</TOKEN>
<TOKEN end_char="1854" id="token-15-5" morph="none" pos="word" start_char="1852">lab</TOKEN>
<TOKEN end_char="1857" id="token-15-6" morph="none" pos="word" start_char="1856">in</TOKEN>
<TOKEN end_char="1863" id="token-15-7" morph="none" pos="word" start_char="1859">Wuhan</TOKEN>
<TOKEN end_char="1866" id="token-15-8" morph="none" pos="word" start_char="1865">to</TOKEN>
<TOKEN end_char="1874" id="token-15-9" morph="none" pos="word" start_char="1868">conduct</TOKEN>
<TOKEN end_char="1882" id="token-15-10" morph="none" pos="word" start_char="1876">genetic</TOKEN>
<TOKEN end_char="1891" id="token-15-11" morph="none" pos="word" start_char="1884">analyses</TOKEN>
<TOKEN end_char="1894" id="token-15-12" morph="none" pos="word" start_char="1893">of</TOKEN>
<TOKEN end_char="1898" id="token-15-13" morph="none" pos="word" start_char="1896">bat</TOKEN>
<TOKEN end_char="1912" id="token-15-14" morph="none" pos="word" start_char="1900">coronaviruses</TOKEN>
<TOKEN end_char="1922" id="token-15-15" morph="none" pos="word" start_char="1914">collected</TOKEN>
<TOKEN end_char="1925" id="token-15-16" morph="none" pos="word" start_char="1924">in</TOKEN>
<TOKEN end_char="1932" id="token-15-17" morph="none" pos="word" start_char="1927">Yunnan</TOKEN>
<TOKEN end_char="1941" id="token-15-18" morph="none" pos="word" start_char="1934">province</TOKEN>
<TOKEN end_char="1942" id="token-15-19" morph="none" pos="punct" start_char="1942">,</TOKEN>
<TOKEN end_char="1948" id="token-15-20" morph="none" pos="word" start_char="1944">about</TOKEN>
<TOKEN end_char="1952" id="token-15-21" morph="none" pos="word" start_char="1950">800</TOKEN>
<TOKEN end_char="1958" id="token-15-22" morph="none" pos="word" start_char="1954">miles</TOKEN>
<TOKEN end_char="1968" id="token-15-23" morph="none" pos="word" start_char="1960">southwest</TOKEN>
<TOKEN end_char="1971" id="token-15-24" morph="none" pos="word" start_char="1970">of</TOKEN>
<TOKEN end_char="1977" id="token-15-25" morph="none" pos="word" start_char="1973">Wuhan</TOKEN>
<TOKEN end_char="1978" id="token-15-26" morph="none" pos="punct" start_char="1978">.</TOKEN>
</SEG>
<SEG end_char="2036" id="segment-16" start_char="1980">
<ORIGINAL_TEXT>EcoHealth Alliance paid the lab $598,500 over five years.</ORIGINAL_TEXT>
<TOKEN end_char="1988" id="token-16-0" morph="none" pos="word" start_char="1980">EcoHealth</TOKEN>
<TOKEN end_char="1997" id="token-16-1" morph="none" pos="word" start_char="1990">Alliance</TOKEN>
<TOKEN end_char="2002" id="token-16-2" morph="none" pos="word" start_char="1999">paid</TOKEN>
<TOKEN end_char="2006" id="token-16-3" morph="none" pos="word" start_char="2004">the</TOKEN>
<TOKEN end_char="2010" id="token-16-4" morph="none" pos="word" start_char="2008">lab</TOKEN>
<TOKEN end_char="2019" id="token-16-5" morph="none" pos="unknown" start_char="2012">$598,500</TOKEN>
<TOKEN end_char="2024" id="token-16-6" morph="none" pos="word" start_char="2021">over</TOKEN>
<TOKEN end_char="2029" id="token-16-7" morph="none" pos="word" start_char="2026">five</TOKEN>
<TOKEN end_char="2035" id="token-16-8" morph="none" pos="word" start_char="2031">years</TOKEN>
<TOKEN end_char="2036" id="token-16-9" morph="none" pos="punct" start_char="2036">.</TOKEN>
</SEG>
<SEG end_char="2114" id="segment-17" start_char="2038">
<ORIGINAL_TEXT>The lab had secured approval from both the U.S. State Department and the NIH.</ORIGINAL_TEXT>
<TOKEN end_char="2040" id="token-17-0" morph="none" pos="word" start_char="2038">The</TOKEN>
<TOKEN end_char="2044" id="token-17-1" morph="none" pos="word" start_char="2042">lab</TOKEN>
<TOKEN end_char="2048" id="token-17-2" morph="none" pos="word" start_char="2046">had</TOKEN>
<TOKEN end_char="2056" id="token-17-3" morph="none" pos="word" start_char="2050">secured</TOKEN>
<TOKEN end_char="2065" id="token-17-4" morph="none" pos="word" start_char="2058">approval</TOKEN>
<TOKEN end_char="2070" id="token-17-5" morph="none" pos="word" start_char="2067">from</TOKEN>
<TOKEN end_char="2075" id="token-17-6" morph="none" pos="word" start_char="2072">both</TOKEN>
<TOKEN end_char="2079" id="token-17-7" morph="none" pos="word" start_char="2077">the</TOKEN>
<TOKEN end_char="2083" id="token-17-8" morph="none" pos="unknown" start_char="2081">U.S</TOKEN>
<TOKEN end_char="2084" id="token-17-9" morph="none" pos="punct" start_char="2084">.</TOKEN>
<TOKEN end_char="2090" id="token-17-10" morph="none" pos="word" start_char="2086">State</TOKEN>
<TOKEN end_char="2101" id="token-17-11" morph="none" pos="word" start_char="2092">Department</TOKEN>
<TOKEN end_char="2105" id="token-17-12" morph="none" pos="word" start_char="2103">and</TOKEN>
<TOKEN end_char="2109" id="token-17-13" morph="none" pos="word" start_char="2107">the</TOKEN>
<TOKEN end_char="2113" id="token-17-14" morph="none" pos="word" start_char="2111">NIH</TOKEN>
<TOKEN end_char="2114" id="token-17-15" morph="none" pos="punct" start_char="2114">.</TOKEN>
</SEG>
<SEG end_char="2169" id="segment-18" start_char="2117">
<ORIGINAL_TEXT>That the NIAID funded the project is not in question.</ORIGINAL_TEXT>
<TOKEN end_char="2120" id="token-18-0" morph="none" pos="word" start_char="2117">That</TOKEN>
<TOKEN end_char="2124" id="token-18-1" morph="none" pos="word" start_char="2122">the</TOKEN>
<TOKEN end_char="2130" id="token-18-2" morph="none" pos="word" start_char="2126">NIAID</TOKEN>
<TOKEN end_char="2137" id="token-18-3" morph="none" pos="word" start_char="2132">funded</TOKEN>
<TOKEN end_char="2141" id="token-18-4" morph="none" pos="word" start_char="2139">the</TOKEN>
<TOKEN end_char="2149" id="token-18-5" morph="none" pos="word" start_char="2143">project</TOKEN>
<TOKEN end_char="2152" id="token-18-6" morph="none" pos="word" start_char="2151">is</TOKEN>
<TOKEN end_char="2156" id="token-18-7" morph="none" pos="word" start_char="2154">not</TOKEN>
<TOKEN end_char="2159" id="token-18-8" morph="none" pos="word" start_char="2158">in</TOKEN>
<TOKEN end_char="2168" id="token-18-9" morph="none" pos="word" start_char="2161">question</TOKEN>
<TOKEN end_char="2169" id="token-18-10" morph="none" pos="punct" start_char="2169">.</TOKEN>
</SEG>
<SEG end_char="2338" id="segment-19" start_char="2171">
<ORIGINAL_TEXT>However, the WorldNetDaily article goes further than that, claiming that the grant covered "gain of function" research on a bat coronavirus, which "created" SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN end_char="2177" id="token-19-0" morph="none" pos="word" start_char="2171">However</TOKEN>
<TOKEN end_char="2178" id="token-19-1" morph="none" pos="punct" start_char="2178">,</TOKEN>
<TOKEN end_char="2182" id="token-19-2" morph="none" pos="word" start_char="2180">the</TOKEN>
<TOKEN end_char="2196" id="token-19-3" morph="none" pos="word" start_char="2184">WorldNetDaily</TOKEN>
<TOKEN end_char="2204" id="token-19-4" morph="none" pos="word" start_char="2198">article</TOKEN>
<TOKEN end_char="2209" id="token-19-5" morph="none" pos="word" start_char="2206">goes</TOKEN>
<TOKEN end_char="2217" id="token-19-6" morph="none" pos="word" start_char="2211">further</TOKEN>
<TOKEN end_char="2222" id="token-19-7" morph="none" pos="word" start_char="2219">than</TOKEN>
<TOKEN end_char="2227" id="token-19-8" morph="none" pos="word" start_char="2224">that</TOKEN>
<TOKEN end_char="2228" id="token-19-9" morph="none" pos="punct" start_char="2228">,</TOKEN>
<TOKEN end_char="2237" id="token-19-10" morph="none" pos="word" start_char="2230">claiming</TOKEN>
<TOKEN end_char="2242" id="token-19-11" morph="none" pos="word" start_char="2239">that</TOKEN>
<TOKEN end_char="2246" id="token-19-12" morph="none" pos="word" start_char="2244">the</TOKEN>
<TOKEN end_char="2252" id="token-19-13" morph="none" pos="word" start_char="2248">grant</TOKEN>
<TOKEN end_char="2260" id="token-19-14" morph="none" pos="word" start_char="2254">covered</TOKEN>
<TOKEN end_char="2262" id="token-19-15" morph="none" pos="punct" start_char="2262">"</TOKEN>
<TOKEN end_char="2266" id="token-19-16" morph="none" pos="word" start_char="2263">gain</TOKEN>
<TOKEN end_char="2269" id="token-19-17" morph="none" pos="word" start_char="2268">of</TOKEN>
<TOKEN end_char="2278" id="token-19-18" morph="none" pos="word" start_char="2271">function</TOKEN>
<TOKEN end_char="2279" id="token-19-19" morph="none" pos="punct" start_char="2279">"</TOKEN>
<TOKEN end_char="2288" id="token-19-20" morph="none" pos="word" start_char="2281">research</TOKEN>
<TOKEN end_char="2291" id="token-19-21" morph="none" pos="word" start_char="2290">on</TOKEN>
<TOKEN end_char="2293" id="token-19-22" morph="none" pos="word" start_char="2293">a</TOKEN>
<TOKEN end_char="2297" id="token-19-23" morph="none" pos="word" start_char="2295">bat</TOKEN>
<TOKEN end_char="2309" id="token-19-24" morph="none" pos="word" start_char="2299">coronavirus</TOKEN>
<TOKEN end_char="2310" id="token-19-25" morph="none" pos="punct" start_char="2310">,</TOKEN>
<TOKEN end_char="2316" id="token-19-26" morph="none" pos="word" start_char="2312">which</TOKEN>
<TOKEN end_char="2318" id="token-19-27" morph="none" pos="punct" start_char="2318">"</TOKEN>
<TOKEN end_char="2325" id="token-19-28" morph="none" pos="word" start_char="2319">created</TOKEN>
<TOKEN end_char="2326" id="token-19-29" morph="none" pos="punct" start_char="2326">"</TOKEN>
<TOKEN end_char="2337" id="token-19-30" morph="none" pos="unknown" start_char="2328">SARS-CoV-2</TOKEN>
<TOKEN end_char="2338" id="token-19-31" morph="none" pos="punct" start_char="2338">.</TOKEN>
</SEG>
<SEG end_char="2466" id="segment-20" start_char="2341">
<ORIGINAL_TEXT>Gain-of-function research is a controversial form of study that involves boosting the infectivity and lethality of a pathogen.</ORIGINAL_TEXT>
<TOKEN end_char="2356" id="token-20-0" morph="none" pos="unknown" start_char="2341">Gain-of-function</TOKEN>
<TOKEN end_char="2365" id="token-20-1" morph="none" pos="word" start_char="2358">research</TOKEN>
<TOKEN end_char="2368" id="token-20-2" morph="none" pos="word" start_char="2367">is</TOKEN>
<TOKEN end_char="2370" id="token-20-3" morph="none" pos="word" start_char="2370">a</TOKEN>
<TOKEN end_char="2384" id="token-20-4" morph="none" pos="word" start_char="2372">controversial</TOKEN>
<TOKEN end_char="2389" id="token-20-5" morph="none" pos="word" start_char="2386">form</TOKEN>
<TOKEN end_char="2392" id="token-20-6" morph="none" pos="word" start_char="2391">of</TOKEN>
<TOKEN end_char="2398" id="token-20-7" morph="none" pos="word" start_char="2394">study</TOKEN>
<TOKEN end_char="2403" id="token-20-8" morph="none" pos="word" start_char="2400">that</TOKEN>
<TOKEN end_char="2412" id="token-20-9" morph="none" pos="word" start_char="2405">involves</TOKEN>
<TOKEN end_char="2421" id="token-20-10" morph="none" pos="word" start_char="2414">boosting</TOKEN>
<TOKEN end_char="2425" id="token-20-11" morph="none" pos="word" start_char="2423">the</TOKEN>
<TOKEN end_char="2437" id="token-20-12" morph="none" pos="word" start_char="2427">infectivity</TOKEN>
<TOKEN end_char="2441" id="token-20-13" morph="none" pos="word" start_char="2439">and</TOKEN>
<TOKEN end_char="2451" id="token-20-14" morph="none" pos="word" start_char="2443">lethality</TOKEN>
<TOKEN end_char="2454" id="token-20-15" morph="none" pos="word" start_char="2453">of</TOKEN>
<TOKEN end_char="2456" id="token-20-16" morph="none" pos="word" start_char="2456">a</TOKEN>
<TOKEN end_char="2465" id="token-20-17" morph="none" pos="word" start_char="2458">pathogen</TOKEN>
<TOKEN end_char="2466" id="token-20-18" morph="none" pos="punct" start_char="2466">.</TOKEN>
</SEG>
<SEG end_char="2619" id="segment-21" start_char="2468">
<ORIGINAL_TEXT>Proponents of gain-of-function say it helps researchers spot potential threats to human health and allows them to figure out ways to tackle a new virus.</ORIGINAL_TEXT>
<TOKEN end_char="2477" id="token-21-0" morph="none" pos="word" start_char="2468">Proponents</TOKEN>
<TOKEN end_char="2480" id="token-21-1" morph="none" pos="word" start_char="2479">of</TOKEN>
<TOKEN end_char="2497" id="token-21-2" morph="none" pos="unknown" start_char="2482">gain-of-function</TOKEN>
<TOKEN end_char="2501" id="token-21-3" morph="none" pos="word" start_char="2499">say</TOKEN>
<TOKEN end_char="2504" id="token-21-4" morph="none" pos="word" start_char="2503">it</TOKEN>
<TOKEN end_char="2510" id="token-21-5" morph="none" pos="word" start_char="2506">helps</TOKEN>
<TOKEN end_char="2522" id="token-21-6" morph="none" pos="word" start_char="2512">researchers</TOKEN>
<TOKEN end_char="2527" id="token-21-7" morph="none" pos="word" start_char="2524">spot</TOKEN>
<TOKEN end_char="2537" id="token-21-8" morph="none" pos="word" start_char="2529">potential</TOKEN>
<TOKEN end_char="2545" id="token-21-9" morph="none" pos="word" start_char="2539">threats</TOKEN>
<TOKEN end_char="2548" id="token-21-10" morph="none" pos="word" start_char="2547">to</TOKEN>
<TOKEN end_char="2554" id="token-21-11" morph="none" pos="word" start_char="2550">human</TOKEN>
<TOKEN end_char="2561" id="token-21-12" morph="none" pos="word" start_char="2556">health</TOKEN>
<TOKEN end_char="2565" id="token-21-13" morph="none" pos="word" start_char="2563">and</TOKEN>
<TOKEN end_char="2572" id="token-21-14" morph="none" pos="word" start_char="2567">allows</TOKEN>
<TOKEN end_char="2577" id="token-21-15" morph="none" pos="word" start_char="2574">them</TOKEN>
<TOKEN end_char="2580" id="token-21-16" morph="none" pos="word" start_char="2579">to</TOKEN>
<TOKEN end_char="2587" id="token-21-17" morph="none" pos="word" start_char="2582">figure</TOKEN>
<TOKEN end_char="2591" id="token-21-18" morph="none" pos="word" start_char="2589">out</TOKEN>
<TOKEN end_char="2596" id="token-21-19" morph="none" pos="word" start_char="2593">ways</TOKEN>
<TOKEN end_char="2599" id="token-21-20" morph="none" pos="word" start_char="2598">to</TOKEN>
<TOKEN end_char="2606" id="token-21-21" morph="none" pos="word" start_char="2601">tackle</TOKEN>
<TOKEN end_char="2608" id="token-21-22" morph="none" pos="word" start_char="2608">a</TOKEN>
<TOKEN end_char="2612" id="token-21-23" morph="none" pos="word" start_char="2610">new</TOKEN>
<TOKEN end_char="2618" id="token-21-24" morph="none" pos="word" start_char="2614">virus</TOKEN>
<TOKEN end_char="2619" id="token-21-25" morph="none" pos="punct" start_char="2619">.</TOKEN>
</SEG>
<SEG end_char="2682" id="segment-22" start_char="2621">
<ORIGINAL_TEXT>Fauci has advocated for gain-of-function research in the past.</ORIGINAL_TEXT>
<TOKEN end_char="2625" id="token-22-0" morph="none" pos="word" start_char="2621">Fauci</TOKEN>
<TOKEN end_char="2629" id="token-22-1" morph="none" pos="word" start_char="2627">has</TOKEN>
<TOKEN end_char="2639" id="token-22-2" morph="none" pos="word" start_char="2631">advocated</TOKEN>
<TOKEN end_char="2643" id="token-22-3" morph="none" pos="word" start_char="2641">for</TOKEN>
<TOKEN end_char="2660" id="token-22-4" morph="none" pos="unknown" start_char="2645">gain-of-function</TOKEN>
<TOKEN end_char="2669" id="token-22-5" morph="none" pos="word" start_char="2662">research</TOKEN>
<TOKEN end_char="2672" id="token-22-6" morph="none" pos="word" start_char="2671">in</TOKEN>
<TOKEN end_char="2676" id="token-22-7" morph="none" pos="word" start_char="2674">the</TOKEN>
<TOKEN end_char="2681" id="token-22-8" morph="none" pos="word" start_char="2678">past</TOKEN>
<TOKEN end_char="2682" id="token-22-9" morph="none" pos="punct" start_char="2682">.</TOKEN>
</SEG>
<SEG end_char="2791" id="segment-23" start_char="2684">
<ORIGINAL_TEXT>In a 2011 article he co-wrote for the Washington Post, he promoted it as a means to study influenza viruses.</ORIGINAL_TEXT>
<TOKEN end_char="2685" id="token-23-0" morph="none" pos="word" start_char="2684">In</TOKEN>
<TOKEN end_char="2687" id="token-23-1" morph="none" pos="word" start_char="2687">a</TOKEN>
<TOKEN end_char="2692" id="token-23-2" morph="none" pos="word" start_char="2689">2011</TOKEN>
<TOKEN end_char="2700" id="token-23-3" morph="none" pos="word" start_char="2694">article</TOKEN>
<TOKEN end_char="2703" id="token-23-4" morph="none" pos="word" start_char="2702">he</TOKEN>
<TOKEN end_char="2712" id="token-23-5" morph="none" pos="unknown" start_char="2705">co-wrote</TOKEN>
<TOKEN end_char="2716" id="token-23-6" morph="none" pos="word" start_char="2714">for</TOKEN>
<TOKEN end_char="2720" id="token-23-7" morph="none" pos="word" start_char="2718">the</TOKEN>
<TOKEN end_char="2731" id="token-23-8" morph="none" pos="word" start_char="2722">Washington</TOKEN>
<TOKEN end_char="2736" id="token-23-9" morph="none" pos="word" start_char="2733">Post</TOKEN>
<TOKEN end_char="2737" id="token-23-10" morph="none" pos="punct" start_char="2737">,</TOKEN>
<TOKEN end_char="2740" id="token-23-11" morph="none" pos="word" start_char="2739">he</TOKEN>
<TOKEN end_char="2749" id="token-23-12" morph="none" pos="word" start_char="2742">promoted</TOKEN>
<TOKEN end_char="2752" id="token-23-13" morph="none" pos="word" start_char="2751">it</TOKEN>
<TOKEN end_char="2755" id="token-23-14" morph="none" pos="word" start_char="2754">as</TOKEN>
<TOKEN end_char="2757" id="token-23-15" morph="none" pos="word" start_char="2757">a</TOKEN>
<TOKEN end_char="2763" id="token-23-16" morph="none" pos="word" start_char="2759">means</TOKEN>
<TOKEN end_char="2766" id="token-23-17" morph="none" pos="word" start_char="2765">to</TOKEN>
<TOKEN end_char="2772" id="token-23-18" morph="none" pos="word" start_char="2768">study</TOKEN>
<TOKEN end_char="2782" id="token-23-19" morph="none" pos="word" start_char="2774">influenza</TOKEN>
<TOKEN end_char="2790" id="token-23-20" morph="none" pos="word" start_char="2784">viruses</TOKEN>
<TOKEN end_char="2791" id="token-23-21" morph="none" pos="punct" start_char="2791">.</TOKEN>
</SEG>
<SEG end_char="2888" id="segment-24" start_char="2794">
<ORIGINAL_TEXT>However, there’s no hard proof to support the article’s claims about gain-of-function research.</ORIGINAL_TEXT>
<TOKEN end_char="2800" id="token-24-0" morph="none" pos="word" start_char="2794">However</TOKEN>
<TOKEN end_char="2801" id="token-24-1" morph="none" pos="punct" start_char="2801">,</TOKEN>
<TOKEN end_char="2809" id="token-24-2" morph="none" pos="word" start_char="2803">there’s</TOKEN>
<TOKEN end_char="2812" id="token-24-3" morph="none" pos="word" start_char="2811">no</TOKEN>
<TOKEN end_char="2817" id="token-24-4" morph="none" pos="word" start_char="2814">hard</TOKEN>
<TOKEN end_char="2823" id="token-24-5" morph="none" pos="word" start_char="2819">proof</TOKEN>
<TOKEN end_char="2826" id="token-24-6" morph="none" pos="word" start_char="2825">to</TOKEN>
<TOKEN end_char="2834" id="token-24-7" morph="none" pos="word" start_char="2828">support</TOKEN>
<TOKEN end_char="2838" id="token-24-8" morph="none" pos="word" start_char="2836">the</TOKEN>
<TOKEN end_char="2848" id="token-24-9" morph="none" pos="word" start_char="2840">article’s</TOKEN>
<TOKEN end_char="2855" id="token-24-10" morph="none" pos="word" start_char="2850">claims</TOKEN>
<TOKEN end_char="2861" id="token-24-11" morph="none" pos="word" start_char="2857">about</TOKEN>
<TOKEN end_char="2878" id="token-24-12" morph="none" pos="unknown" start_char="2863">gain-of-function</TOKEN>
<TOKEN end_char="2887" id="token-24-13" morph="none" pos="word" start_char="2880">research</TOKEN>
<TOKEN end_char="2888" id="token-24-14" morph="none" pos="punct" start_char="2888">.</TOKEN>
</SEG>
<SEG end_char="3007" id="segment-25" start_char="2890">
<ORIGINAL_TEXT>The overwhelming consensus among public health experts is that the coronavirus that causes COVID-19 evolved naturally.</ORIGINAL_TEXT>
<TOKEN end_char="2892" id="token-25-0" morph="none" pos="word" start_char="2890">The</TOKEN>
<TOKEN end_char="2905" id="token-25-1" morph="none" pos="word" start_char="2894">overwhelming</TOKEN>
<TOKEN end_char="2915" id="token-25-2" morph="none" pos="word" start_char="2907">consensus</TOKEN>
<TOKEN end_char="2921" id="token-25-3" morph="none" pos="word" start_char="2917">among</TOKEN>
<TOKEN end_char="2928" id="token-25-4" morph="none" pos="word" start_char="2923">public</TOKEN>
<TOKEN end_char="2935" id="token-25-5" morph="none" pos="word" start_char="2930">health</TOKEN>
<TOKEN end_char="2943" id="token-25-6" morph="none" pos="word" start_char="2937">experts</TOKEN>
<TOKEN end_char="2946" id="token-25-7" morph="none" pos="word" start_char="2945">is</TOKEN>
<TOKEN end_char="2951" id="token-25-8" morph="none" pos="word" start_char="2948">that</TOKEN>
<TOKEN end_char="2955" id="token-25-9" morph="none" pos="word" start_char="2953">the</TOKEN>
<TOKEN end_char="2967" id="token-25-10" morph="none" pos="word" start_char="2957">coronavirus</TOKEN>
<TOKEN end_char="2972" id="token-25-11" morph="none" pos="word" start_char="2969">that</TOKEN>
<TOKEN end_char="2979" id="token-25-12" morph="none" pos="word" start_char="2974">causes</TOKEN>
<TOKEN end_char="2988" id="token-25-13" morph="none" pos="unknown" start_char="2981">COVID-19</TOKEN>
<TOKEN end_char="2996" id="token-25-14" morph="none" pos="word" start_char="2990">evolved</TOKEN>
<TOKEN end_char="3006" id="token-25-15" morph="none" pos="word" start_char="2998">naturally</TOKEN>
<TOKEN end_char="3007" id="token-25-16" morph="none" pos="punct" start_char="3007">.</TOKEN>
</SEG>
<SEG end_char="3133" id="segment-26" start_char="3010">
<ORIGINAL_TEXT>All parties involved in the grant to the Wuhan Institute of Virology have denied that it involved gain-of-function research.</ORIGINAL_TEXT>
<TOKEN end_char="3012" id="token-26-0" morph="none" pos="word" start_char="3010">All</TOKEN>
<TOKEN end_char="3020" id="token-26-1" morph="none" pos="word" start_char="3014">parties</TOKEN>
<TOKEN end_char="3029" id="token-26-2" morph="none" pos="word" start_char="3022">involved</TOKEN>
<TOKEN end_char="3032" id="token-26-3" morph="none" pos="word" start_char="3031">in</TOKEN>
<TOKEN end_char="3036" id="token-26-4" morph="none" pos="word" start_char="3034">the</TOKEN>
<TOKEN end_char="3042" id="token-26-5" morph="none" pos="word" start_char="3038">grant</TOKEN>
<TOKEN end_char="3045" id="token-26-6" morph="none" pos="word" start_char="3044">to</TOKEN>
<TOKEN end_char="3049" id="token-26-7" morph="none" pos="word" start_char="3047">the</TOKEN>
<TOKEN end_char="3055" id="token-26-8" morph="none" pos="word" start_char="3051">Wuhan</TOKEN>
<TOKEN end_char="3065" id="token-26-9" morph="none" pos="word" start_char="3057">Institute</TOKEN>
<TOKEN end_char="3068" id="token-26-10" morph="none" pos="word" start_char="3067">of</TOKEN>
<TOKEN end_char="3077" id="token-26-11" morph="none" pos="word" start_char="3070">Virology</TOKEN>
<TOKEN end_char="3082" id="token-26-12" morph="none" pos="word" start_char="3079">have</TOKEN>
<TOKEN end_char="3089" id="token-26-13" morph="none" pos="word" start_char="3084">denied</TOKEN>
<TOKEN end_char="3094" id="token-26-14" morph="none" pos="word" start_char="3091">that</TOKEN>
<TOKEN end_char="3097" id="token-26-15" morph="none" pos="word" start_char="3096">it</TOKEN>
<TOKEN end_char="3106" id="token-26-16" morph="none" pos="word" start_char="3099">involved</TOKEN>
<TOKEN end_char="3123" id="token-26-17" morph="none" pos="unknown" start_char="3108">gain-of-function</TOKEN>
<TOKEN end_char="3132" id="token-26-18" morph="none" pos="word" start_char="3125">research</TOKEN>
<TOKEN end_char="3133" id="token-26-19" morph="none" pos="punct" start_char="3133">.</TOKEN>
</SEG>
<SEG end_char="3218" id="segment-27" start_char="3136">
<ORIGINAL_TEXT>The NIH told us: "The research supported under the grant to EcoHealth Alliance Inc.</ORIGINAL_TEXT>
<TOKEN end_char="3138" id="token-27-0" morph="none" pos="word" start_char="3136">The</TOKEN>
<TOKEN end_char="3142" id="token-27-1" morph="none" pos="word" start_char="3140">NIH</TOKEN>
<TOKEN end_char="3147" id="token-27-2" morph="none" pos="word" start_char="3144">told</TOKEN>
<TOKEN end_char="3150" id="token-27-3" morph="none" pos="word" start_char="3149">us</TOKEN>
<TOKEN end_char="3151" id="token-27-4" morph="none" pos="punct" start_char="3151">:</TOKEN>
<TOKEN end_char="3153" id="token-27-5" morph="none" pos="punct" start_char="3153">"</TOKEN>
<TOKEN end_char="3156" id="token-27-6" morph="none" pos="word" start_char="3154">The</TOKEN>
<TOKEN end_char="3165" id="token-27-7" morph="none" pos="word" start_char="3158">research</TOKEN>
<TOKEN end_char="3175" id="token-27-8" morph="none" pos="word" start_char="3167">supported</TOKEN>
<TOKEN end_char="3181" id="token-27-9" morph="none" pos="word" start_char="3177">under</TOKEN>
<TOKEN end_char="3185" id="token-27-10" morph="none" pos="word" start_char="3183">the</TOKEN>
<TOKEN end_char="3191" id="token-27-11" morph="none" pos="word" start_char="3187">grant</TOKEN>
<TOKEN end_char="3194" id="token-27-12" morph="none" pos="word" start_char="3193">to</TOKEN>
<TOKEN end_char="3204" id="token-27-13" morph="none" pos="word" start_char="3196">EcoHealth</TOKEN>
<TOKEN end_char="3213" id="token-27-14" morph="none" pos="word" start_char="3206">Alliance</TOKEN>
<TOKEN end_char="3217" id="token-27-15" morph="none" pos="word" start_char="3215">Inc</TOKEN>
<TOKEN end_char="3218" id="token-27-16" morph="none" pos="punct" start_char="3218">.</TOKEN>
</SEG>
<SEG end_char="3420" id="segment-28" start_char="3220">
<ORIGINAL_TEXT>characterized the function of newly discovered bat spike proteins and naturally occurring pathogens and did not involve the enhancement of the pathogenicity or transmissibility of the viruses studied."</ORIGINAL_TEXT>
<TOKEN end_char="3232" id="token-28-0" morph="none" pos="word" start_char="3220">characterized</TOKEN>
<TOKEN end_char="3236" id="token-28-1" morph="none" pos="word" start_char="3234">the</TOKEN>
<TOKEN end_char="3245" id="token-28-2" morph="none" pos="word" start_char="3238">function</TOKEN>
<TOKEN end_char="3248" id="token-28-3" morph="none" pos="word" start_char="3247">of</TOKEN>
<TOKEN end_char="3254" id="token-28-4" morph="none" pos="word" start_char="3250">newly</TOKEN>
<TOKEN end_char="3265" id="token-28-5" morph="none" pos="word" start_char="3256">discovered</TOKEN>
<TOKEN end_char="3269" id="token-28-6" morph="none" pos="word" start_char="3267">bat</TOKEN>
<TOKEN end_char="3275" id="token-28-7" morph="none" pos="word" start_char="3271">spike</TOKEN>
<TOKEN end_char="3284" id="token-28-8" morph="none" pos="word" start_char="3277">proteins</TOKEN>
<TOKEN end_char="3288" id="token-28-9" morph="none" pos="word" start_char="3286">and</TOKEN>
<TOKEN end_char="3298" id="token-28-10" morph="none" pos="word" start_char="3290">naturally</TOKEN>
<TOKEN end_char="3308" id="token-28-11" morph="none" pos="word" start_char="3300">occurring</TOKEN>
<TOKEN end_char="3318" id="token-28-12" morph="none" pos="word" start_char="3310">pathogens</TOKEN>
<TOKEN end_char="3322" id="token-28-13" morph="none" pos="word" start_char="3320">and</TOKEN>
<TOKEN end_char="3326" id="token-28-14" morph="none" pos="word" start_char="3324">did</TOKEN>
<TOKEN end_char="3330" id="token-28-15" morph="none" pos="word" start_char="3328">not</TOKEN>
<TOKEN end_char="3338" id="token-28-16" morph="none" pos="word" start_char="3332">involve</TOKEN>
<TOKEN end_char="3342" id="token-28-17" morph="none" pos="word" start_char="3340">the</TOKEN>
<TOKEN end_char="3354" id="token-28-18" morph="none" pos="word" start_char="3344">enhancement</TOKEN>
<TOKEN end_char="3357" id="token-28-19" morph="none" pos="word" start_char="3356">of</TOKEN>
<TOKEN end_char="3361" id="token-28-20" morph="none" pos="word" start_char="3359">the</TOKEN>
<TOKEN end_char="3375" id="token-28-21" morph="none" pos="word" start_char="3363">pathogenicity</TOKEN>
<TOKEN end_char="3378" id="token-28-22" morph="none" pos="word" start_char="3377">or</TOKEN>
<TOKEN end_char="3395" id="token-28-23" morph="none" pos="word" start_char="3380">transmissibility</TOKEN>
<TOKEN end_char="3398" id="token-28-24" morph="none" pos="word" start_char="3397">of</TOKEN>
<TOKEN end_char="3402" id="token-28-25" morph="none" pos="word" start_char="3400">the</TOKEN>
<TOKEN end_char="3410" id="token-28-26" morph="none" pos="word" start_char="3404">viruses</TOKEN>
<TOKEN end_char="3418" id="token-28-27" morph="none" pos="word" start_char="3412">studied</TOKEN>
<TOKEN end_char="3420" id="token-28-28" morph="none" pos="punct" start_char="3419">."</TOKEN>
</SEG>
<SEG end_char="3457" id="segment-29" start_char="3423">
<ORIGINAL_TEXT>The grant was approved in May 2014.</ORIGINAL_TEXT>
<TOKEN end_char="3425" id="token-29-0" morph="none" pos="word" start_char="3423">The</TOKEN>
<TOKEN end_char="3431" id="token-29-1" morph="none" pos="word" start_char="3427">grant</TOKEN>
<TOKEN end_char="3435" id="token-29-2" morph="none" pos="word" start_char="3433">was</TOKEN>
<TOKEN end_char="3444" id="token-29-3" morph="none" pos="word" start_char="3437">approved</TOKEN>
<TOKEN end_char="3447" id="token-29-4" morph="none" pos="word" start_char="3446">in</TOKEN>
<TOKEN end_char="3451" id="token-29-5" morph="none" pos="word" start_char="3449">May</TOKEN>
<TOKEN end_char="3456" id="token-29-6" morph="none" pos="word" start_char="3453">2014</TOKEN>
<TOKEN end_char="3457" id="token-29-7" morph="none" pos="punct" start_char="3457">.</TOKEN>
</SEG>
<SEG end_char="3484" id="segment-30" start_char="3459">
<ORIGINAL_TEXT>Five months later, on Oct.</ORIGINAL_TEXT>
<TOKEN end_char="3462" id="token-30-0" morph="none" pos="word" start_char="3459">Five</TOKEN>
<TOKEN end_char="3469" id="token-30-1" morph="none" pos="word" start_char="3464">months</TOKEN>
<TOKEN end_char="3475" id="token-30-2" morph="none" pos="word" start_char="3471">later</TOKEN>
<TOKEN end_char="3476" id="token-30-3" morph="none" pos="punct" start_char="3476">,</TOKEN>
<TOKEN end_char="3479" id="token-30-4" morph="none" pos="word" start_char="3478">on</TOKEN>
<TOKEN end_char="3483" id="token-30-5" morph="none" pos="word" start_char="3481">Oct</TOKEN>
<TOKEN end_char="3484" id="token-30-6" morph="none" pos="punct" start_char="3484">.</TOKEN>
</SEG>
<SEG end_char="3629" id="segment-31" start_char="3486">
<ORIGINAL_TEXT>17, the Obama administration announced it would not fund new projects that involved gain-of-function research, citing safety and security risks.</ORIGINAL_TEXT>
<TOKEN end_char="3487" id="token-31-0" morph="none" pos="word" start_char="3486">17</TOKEN>
<TOKEN end_char="3488" id="token-31-1" morph="none" pos="punct" start_char="3488">,</TOKEN>
<TOKEN end_char="3492" id="token-31-2" morph="none" pos="word" start_char="3490">the</TOKEN>
<TOKEN end_char="3498" id="token-31-3" morph="none" pos="word" start_char="3494">Obama</TOKEN>
<TOKEN end_char="3513" id="token-31-4" morph="none" pos="word" start_char="3500">administration</TOKEN>
<TOKEN end_char="3523" id="token-31-5" morph="none" pos="word" start_char="3515">announced</TOKEN>
<TOKEN end_char="3526" id="token-31-6" morph="none" pos="word" start_char="3525">it</TOKEN>
<TOKEN end_char="3532" id="token-31-7" morph="none" pos="word" start_char="3528">would</TOKEN>
<TOKEN end_char="3536" id="token-31-8" morph="none" pos="word" start_char="3534">not</TOKEN>
<TOKEN end_char="3541" id="token-31-9" morph="none" pos="word" start_char="3538">fund</TOKEN>
<TOKEN end_char="3545" id="token-31-10" morph="none" pos="word" start_char="3543">new</TOKEN>
<TOKEN end_char="3554" id="token-31-11" morph="none" pos="word" start_char="3547">projects</TOKEN>
<TOKEN end_char="3559" id="token-31-12" morph="none" pos="word" start_char="3556">that</TOKEN>
<TOKEN end_char="3568" id="token-31-13" morph="none" pos="word" start_char="3561">involved</TOKEN>
<TOKEN end_char="3585" id="token-31-14" morph="none" pos="unknown" start_char="3570">gain-of-function</TOKEN>
<TOKEN end_char="3594" id="token-31-15" morph="none" pos="word" start_char="3587">research</TOKEN>
<TOKEN end_char="3595" id="token-31-16" morph="none" pos="punct" start_char="3595">,</TOKEN>
<TOKEN end_char="3602" id="token-31-17" morph="none" pos="word" start_char="3597">citing</TOKEN>
<TOKEN end_char="3609" id="token-31-18" morph="none" pos="word" start_char="3604">safety</TOKEN>
<TOKEN end_char="3613" id="token-31-19" morph="none" pos="word" start_char="3611">and</TOKEN>
<TOKEN end_char="3622" id="token-31-20" morph="none" pos="word" start_char="3615">security</TOKEN>
<TOKEN end_char="3628" id="token-31-21" morph="none" pos="word" start_char="3624">risks</TOKEN>
<TOKEN end_char="3629" id="token-31-22" morph="none" pos="punct" start_char="3629">.</TOKEN>
</SEG>
<SEG end_char="3784" id="segment-32" start_char="3632">
<ORIGINAL_TEXT>The NIH told us that it reviewed the EcoHealth Alliance project after the funding pause and determined that it did not involve gain-of-function research.</ORIGINAL_TEXT>
<TOKEN end_char="3634" id="token-32-0" morph="none" pos="word" start_char="3632">The</TOKEN>
<TOKEN end_char="3638" id="token-32-1" morph="none" pos="word" start_char="3636">NIH</TOKEN>
<TOKEN end_char="3643" id="token-32-2" morph="none" pos="word" start_char="3640">told</TOKEN>
<TOKEN end_char="3646" id="token-32-3" morph="none" pos="word" start_char="3645">us</TOKEN>
<TOKEN end_char="3651" id="token-32-4" morph="none" pos="word" start_char="3648">that</TOKEN>
<TOKEN end_char="3654" id="token-32-5" morph="none" pos="word" start_char="3653">it</TOKEN>
<TOKEN end_char="3663" id="token-32-6" morph="none" pos="word" start_char="3656">reviewed</TOKEN>
<TOKEN end_char="3667" id="token-32-7" morph="none" pos="word" start_char="3665">the</TOKEN>
<TOKEN end_char="3677" id="token-32-8" morph="none" pos="word" start_char="3669">EcoHealth</TOKEN>
<TOKEN end_char="3686" id="token-32-9" morph="none" pos="word" start_char="3679">Alliance</TOKEN>
<TOKEN end_char="3694" id="token-32-10" morph="none" pos="word" start_char="3688">project</TOKEN>
<TOKEN end_char="3700" id="token-32-11" morph="none" pos="word" start_char="3696">after</TOKEN>
<TOKEN end_char="3704" id="token-32-12" morph="none" pos="word" start_char="3702">the</TOKEN>
<TOKEN end_char="3712" id="token-32-13" morph="none" pos="word" start_char="3706">funding</TOKEN>
<TOKEN end_char="3718" id="token-32-14" morph="none" pos="word" start_char="3714">pause</TOKEN>
<TOKEN end_char="3722" id="token-32-15" morph="none" pos="word" start_char="3720">and</TOKEN>
<TOKEN end_char="3733" id="token-32-16" morph="none" pos="word" start_char="3724">determined</TOKEN>
<TOKEN end_char="3738" id="token-32-17" morph="none" pos="word" start_char="3735">that</TOKEN>
<TOKEN end_char="3741" id="token-32-18" morph="none" pos="word" start_char="3740">it</TOKEN>
<TOKEN end_char="3745" id="token-32-19" morph="none" pos="word" start_char="3743">did</TOKEN>
<TOKEN end_char="3749" id="token-32-20" morph="none" pos="word" start_char="3747">not</TOKEN>
<TOKEN end_char="3757" id="token-32-21" morph="none" pos="word" start_char="3751">involve</TOKEN>
<TOKEN end_char="3774" id="token-32-22" morph="none" pos="unknown" start_char="3759">gain-of-function</TOKEN>
<TOKEN end_char="3783" id="token-32-23" morph="none" pos="word" start_char="3776">research</TOKEN>
<TOKEN end_char="3784" id="token-32-24" morph="none" pos="punct" start_char="3784">.</TOKEN>
</SEG>
<SEG end_char="3850" id="segment-33" start_char="3786">
<ORIGINAL_TEXT>As a result, it was not affected by the White House’s new policy.</ORIGINAL_TEXT>
<TOKEN end_char="3787" id="token-33-0" morph="none" pos="word" start_char="3786">As</TOKEN>
<TOKEN end_char="3789" id="token-33-1" morph="none" pos="word" start_char="3789">a</TOKEN>
<TOKEN end_char="3796" id="token-33-2" morph="none" pos="word" start_char="3791">result</TOKEN>
<TOKEN end_char="3797" id="token-33-3" morph="none" pos="punct" start_char="3797">,</TOKEN>
<TOKEN end_char="3800" id="token-33-4" morph="none" pos="word" start_char="3799">it</TOKEN>
<TOKEN end_char="3804" id="token-33-5" morph="none" pos="word" start_char="3802">was</TOKEN>
<TOKEN end_char="3808" id="token-33-6" morph="none" pos="word" start_char="3806">not</TOKEN>
<TOKEN end_char="3817" id="token-33-7" morph="none" pos="word" start_char="3810">affected</TOKEN>
<TOKEN end_char="3820" id="token-33-8" morph="none" pos="word" start_char="3819">by</TOKEN>
<TOKEN end_char="3824" id="token-33-9" morph="none" pos="word" start_char="3822">the</TOKEN>
<TOKEN end_char="3830" id="token-33-10" morph="none" pos="word" start_char="3826">White</TOKEN>
<TOKEN end_char="3838" id="token-33-11" morph="none" pos="word" start_char="3832">House’s</TOKEN>
<TOKEN end_char="3842" id="token-33-12" morph="none" pos="word" start_char="3840">new</TOKEN>
<TOKEN end_char="3849" id="token-33-13" morph="none" pos="word" start_char="3844">policy</TOKEN>
<TOKEN end_char="3850" id="token-33-14" morph="none" pos="punct" start_char="3850">.</TOKEN>
</SEG>
<SEG end_char="3950" id="segment-34" start_char="3853">
<ORIGINAL_TEXT>Hilton and WorldNetDaily do not provide evidence that the grant covered gain-of-function research.</ORIGINAL_TEXT>
<TOKEN end_char="3858" id="token-34-0" morph="none" pos="word" start_char="3853">Hilton</TOKEN>
<TOKEN end_char="3862" id="token-34-1" morph="none" pos="word" start_char="3860">and</TOKEN>
<TOKEN end_char="3876" id="token-34-2" morph="none" pos="word" start_char="3864">WorldNetDaily</TOKEN>
<TOKEN end_char="3879" id="token-34-3" morph="none" pos="word" start_char="3878">do</TOKEN>
<TOKEN end_char="3883" id="token-34-4" morph="none" pos="word" start_char="3881">not</TOKEN>
<TOKEN end_char="3891" id="token-34-5" morph="none" pos="word" start_char="3885">provide</TOKEN>
<TOKEN end_char="3900" id="token-34-6" morph="none" pos="word" start_char="3893">evidence</TOKEN>
<TOKEN end_char="3905" id="token-34-7" morph="none" pos="word" start_char="3902">that</TOKEN>
<TOKEN end_char="3909" id="token-34-8" morph="none" pos="word" start_char="3907">the</TOKEN>
<TOKEN end_char="3915" id="token-34-9" morph="none" pos="word" start_char="3911">grant</TOKEN>
<TOKEN end_char="3923" id="token-34-10" morph="none" pos="word" start_char="3917">covered</TOKEN>
<TOKEN end_char="3940" id="token-34-11" morph="none" pos="unknown" start_char="3925">gain-of-function</TOKEN>
<TOKEN end_char="3949" id="token-34-12" morph="none" pos="word" start_char="3942">research</TOKEN>
<TOKEN end_char="3950" id="token-34-13" morph="none" pos="punct" start_char="3950">.</TOKEN>
</SEG>
<SEG end_char="4048" id="segment-35" start_char="3952">
<ORIGINAL_TEXT>When we reached out to Fox News, a spokesperson pointed us to the transcript of Hilton’s segment.</ORIGINAL_TEXT>
<TOKEN end_char="3955" id="token-35-0" morph="none" pos="word" start_char="3952">When</TOKEN>
<TOKEN end_char="3958" id="token-35-1" morph="none" pos="word" start_char="3957">we</TOKEN>
<TOKEN end_char="3966" id="token-35-2" morph="none" pos="word" start_char="3960">reached</TOKEN>
<TOKEN end_char="3970" id="token-35-3" morph="none" pos="word" start_char="3968">out</TOKEN>
<TOKEN end_char="3973" id="token-35-4" morph="none" pos="word" start_char="3972">to</TOKEN>
<TOKEN end_char="3977" id="token-35-5" morph="none" pos="word" start_char="3975">Fox</TOKEN>
<TOKEN end_char="3982" id="token-35-6" morph="none" pos="word" start_char="3979">News</TOKEN>
<TOKEN end_char="3983" id="token-35-7" morph="none" pos="punct" start_char="3983">,</TOKEN>
<TOKEN end_char="3985" id="token-35-8" morph="none" pos="word" start_char="3985">a</TOKEN>
<TOKEN end_char="3998" id="token-35-9" morph="none" pos="word" start_char="3987">spokesperson</TOKEN>
<TOKEN end_char="4006" id="token-35-10" morph="none" pos="word" start_char="4000">pointed</TOKEN>
<TOKEN end_char="4009" id="token-35-11" morph="none" pos="word" start_char="4008">us</TOKEN>
<TOKEN end_char="4012" id="token-35-12" morph="none" pos="word" start_char="4011">to</TOKEN>
<TOKEN end_char="4016" id="token-35-13" morph="none" pos="word" start_char="4014">the</TOKEN>
<TOKEN end_char="4027" id="token-35-14" morph="none" pos="word" start_char="4018">transcript</TOKEN>
<TOKEN end_char="4030" id="token-35-15" morph="none" pos="word" start_char="4029">of</TOKEN>
<TOKEN end_char="4039" id="token-35-16" morph="none" pos="word" start_char="4032">Hilton’s</TOKEN>
<TOKEN end_char="4047" id="token-35-17" morph="none" pos="word" start_char="4041">segment</TOKEN>
<TOKEN end_char="4048" id="token-35-18" morph="none" pos="punct" start_char="4048">.</TOKEN>
</SEG>
<SEG end_char="4171" id="segment-36" start_char="4051">
<ORIGINAL_TEXT>MIT biologist Kevin Esvelt reviewed a paper that appears to have been published with financial assistance from the grant.</ORIGINAL_TEXT>
<TOKEN end_char="4053" id="token-36-0" morph="none" pos="word" start_char="4051">MIT</TOKEN>
<TOKEN end_char="4063" id="token-36-1" morph="none" pos="word" start_char="4055">biologist</TOKEN>
<TOKEN end_char="4069" id="token-36-2" morph="none" pos="word" start_char="4065">Kevin</TOKEN>
<TOKEN end_char="4076" id="token-36-3" morph="none" pos="word" start_char="4071">Esvelt</TOKEN>
<TOKEN end_char="4085" id="token-36-4" morph="none" pos="word" start_char="4078">reviewed</TOKEN>
<TOKEN end_char="4087" id="token-36-5" morph="none" pos="word" start_char="4087">a</TOKEN>
<TOKEN end_char="4093" id="token-36-6" morph="none" pos="word" start_char="4089">paper</TOKEN>
<TOKEN end_char="4098" id="token-36-7" morph="none" pos="word" start_char="4095">that</TOKEN>
<TOKEN end_char="4106" id="token-36-8" morph="none" pos="word" start_char="4100">appears</TOKEN>
<TOKEN end_char="4109" id="token-36-9" morph="none" pos="word" start_char="4108">to</TOKEN>
<TOKEN end_char="4114" id="token-36-10" morph="none" pos="word" start_char="4111">have</TOKEN>
<TOKEN end_char="4119" id="token-36-11" morph="none" pos="word" start_char="4116">been</TOKEN>
<TOKEN end_char="4129" id="token-36-12" morph="none" pos="word" start_char="4121">published</TOKEN>
<TOKEN end_char="4134" id="token-36-13" morph="none" pos="word" start_char="4131">with</TOKEN>
<TOKEN end_char="4144" id="token-36-14" morph="none" pos="word" start_char="4136">financial</TOKEN>
<TOKEN end_char="4155" id="token-36-15" morph="none" pos="word" start_char="4146">assistance</TOKEN>
<TOKEN end_char="4160" id="token-36-16" morph="none" pos="word" start_char="4157">from</TOKEN>
<TOKEN end_char="4164" id="token-36-17" morph="none" pos="word" start_char="4162">the</TOKEN>
<TOKEN end_char="4170" id="token-36-18" morph="none" pos="word" start_char="4166">grant</TOKEN>
<TOKEN end_char="4171" id="token-36-19" morph="none" pos="punct" start_char="4171">.</TOKEN>
</SEG>
<SEG end_char="4297" id="segment-37" start_char="4173">
<ORIGINAL_TEXT>According to Esvelt, certain techniques that the researchers used seemed to meet the definition of gain-of-function research.</ORIGINAL_TEXT>
<TOKEN end_char="4181" id="token-37-0" morph="none" pos="word" start_char="4173">According</TOKEN>
<TOKEN end_char="4184" id="token-37-1" morph="none" pos="word" start_char="4183">to</TOKEN>
<TOKEN end_char="4191" id="token-37-2" morph="none" pos="word" start_char="4186">Esvelt</TOKEN>
<TOKEN end_char="4192" id="token-37-3" morph="none" pos="punct" start_char="4192">,</TOKEN>
<TOKEN end_char="4200" id="token-37-4" morph="none" pos="word" start_char="4194">certain</TOKEN>
<TOKEN end_char="4211" id="token-37-5" morph="none" pos="word" start_char="4202">techniques</TOKEN>
<TOKEN end_char="4216" id="token-37-6" morph="none" pos="word" start_char="4213">that</TOKEN>
<TOKEN end_char="4220" id="token-37-7" morph="none" pos="word" start_char="4218">the</TOKEN>
<TOKEN end_char="4232" id="token-37-8" morph="none" pos="word" start_char="4222">researchers</TOKEN>
<TOKEN end_char="4237" id="token-37-9" morph="none" pos="word" start_char="4234">used</TOKEN>
<TOKEN end_char="4244" id="token-37-10" morph="none" pos="word" start_char="4239">seemed</TOKEN>
<TOKEN end_char="4247" id="token-37-11" morph="none" pos="word" start_char="4246">to</TOKEN>
<TOKEN end_char="4252" id="token-37-12" morph="none" pos="word" start_char="4249">meet</TOKEN>
<TOKEN end_char="4256" id="token-37-13" morph="none" pos="word" start_char="4254">the</TOKEN>
<TOKEN end_char="4267" id="token-37-14" morph="none" pos="word" start_char="4258">definition</TOKEN>
<TOKEN end_char="4270" id="token-37-15" morph="none" pos="word" start_char="4269">of</TOKEN>
<TOKEN end_char="4287" id="token-37-16" morph="none" pos="unknown" start_char="4272">gain-of-function</TOKEN>
<TOKEN end_char="4296" id="token-37-17" morph="none" pos="word" start_char="4289">research</TOKEN>
<TOKEN end_char="4297" id="token-37-18" morph="none" pos="punct" start_char="4297">.</TOKEN>
</SEG>
<SEG end_char="4527" id="segment-38" start_char="4299">
<ORIGINAL_TEXT>But he told PolitiFact that "the work reported in this specific paper definitely did NOT lead to the creation of SARS-CoV-2" because the genetic sequences of the virus studied in the paper differ from that of the new coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="4301" id="token-38-0" morph="none" pos="word" start_char="4299">But</TOKEN>
<TOKEN end_char="4304" id="token-38-1" morph="none" pos="word" start_char="4303">he</TOKEN>
<TOKEN end_char="4309" id="token-38-2" morph="none" pos="word" start_char="4306">told</TOKEN>
<TOKEN end_char="4320" id="token-38-3" morph="none" pos="word" start_char="4311">PolitiFact</TOKEN>
<TOKEN end_char="4325" id="token-38-4" morph="none" pos="word" start_char="4322">that</TOKEN>
<TOKEN end_char="4327" id="token-38-5" morph="none" pos="punct" start_char="4327">"</TOKEN>
<TOKEN end_char="4330" id="token-38-6" morph="none" pos="word" start_char="4328">the</TOKEN>
<TOKEN end_char="4335" id="token-38-7" morph="none" pos="word" start_char="4332">work</TOKEN>
<TOKEN end_char="4344" id="token-38-8" morph="none" pos="word" start_char="4337">reported</TOKEN>
<TOKEN end_char="4347" id="token-38-9" morph="none" pos="word" start_char="4346">in</TOKEN>
<TOKEN end_char="4352" id="token-38-10" morph="none" pos="word" start_char="4349">this</TOKEN>
<TOKEN end_char="4361" id="token-38-11" morph="none" pos="word" start_char="4354">specific</TOKEN>
<TOKEN end_char="4367" id="token-38-12" morph="none" pos="word" start_char="4363">paper</TOKEN>
<TOKEN end_char="4378" id="token-38-13" morph="none" pos="word" start_char="4369">definitely</TOKEN>
<TOKEN end_char="4382" id="token-38-14" morph="none" pos="word" start_char="4380">did</TOKEN>
<TOKEN end_char="4386" id="token-38-15" morph="none" pos="word" start_char="4384">NOT</TOKEN>
<TOKEN end_char="4391" id="token-38-16" morph="none" pos="word" start_char="4388">lead</TOKEN>
<TOKEN end_char="4394" id="token-38-17" morph="none" pos="word" start_char="4393">to</TOKEN>
<TOKEN end_char="4398" id="token-38-18" morph="none" pos="word" start_char="4396">the</TOKEN>
<TOKEN end_char="4407" id="token-38-19" morph="none" pos="word" start_char="4400">creation</TOKEN>
<TOKEN end_char="4410" id="token-38-20" morph="none" pos="word" start_char="4409">of</TOKEN>
<TOKEN end_char="4421" id="token-38-21" morph="none" pos="unknown" start_char="4412">SARS-CoV-2</TOKEN>
<TOKEN end_char="4422" id="token-38-22" morph="none" pos="punct" start_char="4422">"</TOKEN>
<TOKEN end_char="4430" id="token-38-23" morph="none" pos="word" start_char="4424">because</TOKEN>
<TOKEN end_char="4434" id="token-38-24" morph="none" pos="word" start_char="4432">the</TOKEN>
<TOKEN end_char="4442" id="token-38-25" morph="none" pos="word" start_char="4436">genetic</TOKEN>
<TOKEN end_char="4452" id="token-38-26" morph="none" pos="word" start_char="4444">sequences</TOKEN>
<TOKEN end_char="4455" id="token-38-27" morph="none" pos="word" start_char="4454">of</TOKEN>
<TOKEN end_char="4459" id="token-38-28" morph="none" pos="word" start_char="4457">the</TOKEN>
<TOKEN end_char="4465" id="token-38-29" morph="none" pos="word" start_char="4461">virus</TOKEN>
<TOKEN end_char="4473" id="token-38-30" morph="none" pos="word" start_char="4467">studied</TOKEN>
<TOKEN end_char="4476" id="token-38-31" morph="none" pos="word" start_char="4475">in</TOKEN>
<TOKEN end_char="4480" id="token-38-32" morph="none" pos="word" start_char="4478">the</TOKEN>
<TOKEN end_char="4486" id="token-38-33" morph="none" pos="word" start_char="4482">paper</TOKEN>
<TOKEN end_char="4493" id="token-38-34" morph="none" pos="word" start_char="4488">differ</TOKEN>
<TOKEN end_char="4498" id="token-38-35" morph="none" pos="word" start_char="4495">from</TOKEN>
<TOKEN end_char="4503" id="token-38-36" morph="none" pos="word" start_char="4500">that</TOKEN>
<TOKEN end_char="4506" id="token-38-37" morph="none" pos="word" start_char="4505">of</TOKEN>
<TOKEN end_char="4510" id="token-38-38" morph="none" pos="word" start_char="4508">the</TOKEN>
<TOKEN end_char="4514" id="token-38-39" morph="none" pos="word" start_char="4512">new</TOKEN>
<TOKEN end_char="4526" id="token-38-40" morph="none" pos="word" start_char="4516">coronavirus</TOKEN>
<TOKEN end_char="4527" id="token-38-41" morph="none" pos="punct" start_char="4527">.</TOKEN>
</SEG>
<SEG end_char="4610" id="segment-39" start_char="4530">
<ORIGINAL_TEXT>Fact-check:Will Biden’s drilling ban on federal leases 'kill' 120,000 Texas jobs?</ORIGINAL_TEXT>
<TOKEN end_char="4544" id="token-39-0" morph="none" pos="unknown" start_char="4530">Fact-check:Will</TOKEN>
<TOKEN end_char="4552" id="token-39-1" morph="none" pos="word" start_char="4546">Biden’s</TOKEN>
<TOKEN end_char="4561" id="token-39-2" morph="none" pos="word" start_char="4554">drilling</TOKEN>
<TOKEN end_char="4565" id="token-39-3" morph="none" pos="word" start_char="4563">ban</TOKEN>
<TOKEN end_char="4568" id="token-39-4" morph="none" pos="word" start_char="4567">on</TOKEN>
<TOKEN end_char="4576" id="token-39-5" morph="none" pos="word" start_char="4570">federal</TOKEN>
<TOKEN end_char="4583" id="token-39-6" morph="none" pos="word" start_char="4578">leases</TOKEN>
<TOKEN end_char="4585" id="token-39-7" morph="none" pos="punct" start_char="4585">'</TOKEN>
<TOKEN end_char="4589" id="token-39-8" morph="none" pos="word" start_char="4586">kill</TOKEN>
<TOKEN end_char="4590" id="token-39-9" morph="none" pos="punct" start_char="4590">'</TOKEN>
<TOKEN end_char="4598" id="token-39-10" morph="none" pos="unknown" start_char="4592">120,000</TOKEN>
<TOKEN end_char="4604" id="token-39-11" morph="none" pos="word" start_char="4600">Texas</TOKEN>
<TOKEN end_char="4609" id="token-39-12" morph="none" pos="word" start_char="4606">jobs</TOKEN>
<TOKEN end_char="4610" id="token-39-13" morph="none" pos="punct" start_char="4610">?</TOKEN>
</SEG>
<SEG end_char="4656" id="segment-40" start_char="4613">
<ORIGINAL_TEXT>No evidence that the coronavirus was manmade</ORIGINAL_TEXT>
<TOKEN end_char="4614" id="token-40-0" morph="none" pos="word" start_char="4613">No</TOKEN>
<TOKEN end_char="4623" id="token-40-1" morph="none" pos="word" start_char="4616">evidence</TOKEN>
<TOKEN end_char="4628" id="token-40-2" morph="none" pos="word" start_char="4625">that</TOKEN>
<TOKEN end_char="4632" id="token-40-3" morph="none" pos="word" start_char="4630">the</TOKEN>
<TOKEN end_char="4644" id="token-40-4" morph="none" pos="word" start_char="4634">coronavirus</TOKEN>
<TOKEN end_char="4648" id="token-40-5" morph="none" pos="word" start_char="4646">was</TOKEN>
<TOKEN end_char="4656" id="token-40-6" morph="none" pos="word" start_char="4650">manmade</TOKEN>
</SEG>
<SEG end_char="4806" id="segment-41" start_char="4660">
<ORIGINAL_TEXT>The Centers for Disease Control and Prevention, the World Health Organization, and the NIH have all said that the virus was not derived from a lab.</ORIGINAL_TEXT>
<TOKEN end_char="4662" id="token-41-0" morph="none" pos="word" start_char="4660">The</TOKEN>
<TOKEN end_char="4670" id="token-41-1" morph="none" pos="word" start_char="4664">Centers</TOKEN>
<TOKEN end_char="4674" id="token-41-2" morph="none" pos="word" start_char="4672">for</TOKEN>
<TOKEN end_char="4682" id="token-41-3" morph="none" pos="word" start_char="4676">Disease</TOKEN>
<TOKEN end_char="4690" id="token-41-4" morph="none" pos="word" start_char="4684">Control</TOKEN>
<TOKEN end_char="4694" id="token-41-5" morph="none" pos="word" start_char="4692">and</TOKEN>
<TOKEN end_char="4705" id="token-41-6" morph="none" pos="word" start_char="4696">Prevention</TOKEN>
<TOKEN end_char="4706" id="token-41-7" morph="none" pos="punct" start_char="4706">,</TOKEN>
<TOKEN end_char="4710" id="token-41-8" morph="none" pos="word" start_char="4708">the</TOKEN>
<TOKEN end_char="4716" id="token-41-9" morph="none" pos="word" start_char="4712">World</TOKEN>
<TOKEN end_char="4723" id="token-41-10" morph="none" pos="word" start_char="4718">Health</TOKEN>
<TOKEN end_char="4736" id="token-41-11" morph="none" pos="word" start_char="4725">Organization</TOKEN>
<TOKEN end_char="4737" id="token-41-12" morph="none" pos="punct" start_char="4737">,</TOKEN>
<TOKEN end_char="4741" id="token-41-13" morph="none" pos="word" start_char="4739">and</TOKEN>
<TOKEN end_char="4745" id="token-41-14" morph="none" pos="word" start_char="4743">the</TOKEN>
<TOKEN end_char="4749" id="token-41-15" morph="none" pos="word" start_char="4747">NIH</TOKEN>
<TOKEN end_char="4754" id="token-41-16" morph="none" pos="word" start_char="4751">have</TOKEN>
<TOKEN end_char="4758" id="token-41-17" morph="none" pos="word" start_char="4756">all</TOKEN>
<TOKEN end_char="4763" id="token-41-18" morph="none" pos="word" start_char="4760">said</TOKEN>
<TOKEN end_char="4768" id="token-41-19" morph="none" pos="word" start_char="4765">that</TOKEN>
<TOKEN end_char="4772" id="token-41-20" morph="none" pos="word" start_char="4770">the</TOKEN>
<TOKEN end_char="4778" id="token-41-21" morph="none" pos="word" start_char="4774">virus</TOKEN>
<TOKEN end_char="4782" id="token-41-22" morph="none" pos="word" start_char="4780">was</TOKEN>
<TOKEN end_char="4786" id="token-41-23" morph="none" pos="word" start_char="4784">not</TOKEN>
<TOKEN end_char="4794" id="token-41-24" morph="none" pos="word" start_char="4788">derived</TOKEN>
<TOKEN end_char="4799" id="token-41-25" morph="none" pos="word" start_char="4796">from</TOKEN>
<TOKEN end_char="4801" id="token-41-26" morph="none" pos="word" start_char="4801">a</TOKEN>
<TOKEN end_char="4805" id="token-41-27" morph="none" pos="word" start_char="4803">lab</TOKEN>
<TOKEN end_char="4806" id="token-41-28" morph="none" pos="punct" start_char="4806">.</TOKEN>
</SEG>
<SEG end_char="4895" id="segment-42" start_char="4809">
<ORIGINAL_TEXT>If the virus had been altered in a lab, its genomic data would show signs of tampering.</ORIGINAL_TEXT>
<TOKEN end_char="4810" id="token-42-0" morph="none" pos="word" start_char="4809">If</TOKEN>
<TOKEN end_char="4814" id="token-42-1" morph="none" pos="word" start_char="4812">the</TOKEN>
<TOKEN end_char="4820" id="token-42-2" morph="none" pos="word" start_char="4816">virus</TOKEN>
<TOKEN end_char="4824" id="token-42-3" morph="none" pos="word" start_char="4822">had</TOKEN>
<TOKEN end_char="4829" id="token-42-4" morph="none" pos="word" start_char="4826">been</TOKEN>
<TOKEN end_char="4837" id="token-42-5" morph="none" pos="word" start_char="4831">altered</TOKEN>
<TOKEN end_char="4840" id="token-42-6" morph="none" pos="word" start_char="4839">in</TOKEN>
<TOKEN end_char="4842" id="token-42-7" morph="none" pos="word" start_char="4842">a</TOKEN>
<TOKEN end_char="4846" id="token-42-8" morph="none" pos="word" start_char="4844">lab</TOKEN>
<TOKEN end_char="4847" id="token-42-9" morph="none" pos="punct" start_char="4847">,</TOKEN>
<TOKEN end_char="4851" id="token-42-10" morph="none" pos="word" start_char="4849">its</TOKEN>
<TOKEN end_char="4859" id="token-42-11" morph="none" pos="word" start_char="4853">genomic</TOKEN>
<TOKEN end_char="4864" id="token-42-12" morph="none" pos="word" start_char="4861">data</TOKEN>
<TOKEN end_char="4870" id="token-42-13" morph="none" pos="word" start_char="4866">would</TOKEN>
<TOKEN end_char="4875" id="token-42-14" morph="none" pos="word" start_char="4872">show</TOKEN>
<TOKEN end_char="4881" id="token-42-15" morph="none" pos="word" start_char="4877">signs</TOKEN>
<TOKEN end_char="4884" id="token-42-16" morph="none" pos="word" start_char="4883">of</TOKEN>
<TOKEN end_char="4894" id="token-42-17" morph="none" pos="word" start_char="4886">tampering</TOKEN>
<TOKEN end_char="4895" id="token-42-18" morph="none" pos="punct" start_char="4895">.</TOKEN>
</SEG>
<SEG end_char="5064" id="segment-43" start_char="4897">
<ORIGINAL_TEXT>Although scientists from around the world have publicly shared the virus’ genetic makeup thousands of times, there’s still no evidence that the virus was bioengineered.</ORIGINAL_TEXT>
<TOKEN end_char="4904" id="token-43-0" morph="none" pos="word" start_char="4897">Although</TOKEN>
<TOKEN end_char="4915" id="token-43-1" morph="none" pos="word" start_char="4906">scientists</TOKEN>
<TOKEN end_char="4920" id="token-43-2" morph="none" pos="word" start_char="4917">from</TOKEN>
<TOKEN end_char="4927" id="token-43-3" morph="none" pos="word" start_char="4922">around</TOKEN>
<TOKEN end_char="4931" id="token-43-4" morph="none" pos="word" start_char="4929">the</TOKEN>
<TOKEN end_char="4937" id="token-43-5" morph="none" pos="word" start_char="4933">world</TOKEN>
<TOKEN end_char="4942" id="token-43-6" morph="none" pos="word" start_char="4939">have</TOKEN>
<TOKEN end_char="4951" id="token-43-7" morph="none" pos="word" start_char="4944">publicly</TOKEN>
<TOKEN end_char="4958" id="token-43-8" morph="none" pos="word" start_char="4953">shared</TOKEN>
<TOKEN end_char="4962" id="token-43-9" morph="none" pos="word" start_char="4960">the</TOKEN>
<TOKEN end_char="4968" id="token-43-10" morph="none" pos="word" start_char="4964">virus</TOKEN>
<TOKEN end_char="4969" id="token-43-11" morph="none" pos="punct" start_char="4969">’</TOKEN>
<TOKEN end_char="4977" id="token-43-12" morph="none" pos="word" start_char="4971">genetic</TOKEN>
<TOKEN end_char="4984" id="token-43-13" morph="none" pos="word" start_char="4979">makeup</TOKEN>
<TOKEN end_char="4994" id="token-43-14" morph="none" pos="word" start_char="4986">thousands</TOKEN>
<TOKEN end_char="4997" id="token-43-15" morph="none" pos="word" start_char="4996">of</TOKEN>
<TOKEN end_char="5003" id="token-43-16" morph="none" pos="word" start_char="4999">times</TOKEN>
<TOKEN end_char="5004" id="token-43-17" morph="none" pos="punct" start_char="5004">,</TOKEN>
<TOKEN end_char="5012" id="token-43-18" morph="none" pos="word" start_char="5006">there’s</TOKEN>
<TOKEN end_char="5018" id="token-43-19" morph="none" pos="word" start_char="5014">still</TOKEN>
<TOKEN end_char="5021" id="token-43-20" morph="none" pos="word" start_char="5020">no</TOKEN>
<TOKEN end_char="5030" id="token-43-21" morph="none" pos="word" start_char="5023">evidence</TOKEN>
<TOKEN end_char="5035" id="token-43-22" morph="none" pos="word" start_char="5032">that</TOKEN>
<TOKEN end_char="5039" id="token-43-23" morph="none" pos="word" start_char="5037">the</TOKEN>
<TOKEN end_char="5045" id="token-43-24" morph="none" pos="word" start_char="5041">virus</TOKEN>
<TOKEN end_char="5049" id="token-43-25" morph="none" pos="word" start_char="5047">was</TOKEN>
<TOKEN end_char="5063" id="token-43-26" morph="none" pos="word" start_char="5051">bioengineered</TOKEN>
<TOKEN end_char="5064" id="token-43-27" morph="none" pos="punct" start_char="5064">.</TOKEN>
</SEG>
<SEG end_char="5073" id="segment-44" start_char="5067">
<ORIGINAL_TEXT>On Feb.</ORIGINAL_TEXT>
<TOKEN end_char="5068" id="token-44-0" morph="none" pos="word" start_char="5067">On</TOKEN>
<TOKEN end_char="5072" id="token-44-1" morph="none" pos="word" start_char="5070">Feb</TOKEN>
<TOKEN end_char="5073" id="token-44-2" morph="none" pos="punct" start_char="5073">.</TOKEN>
</SEG>
<SEG end_char="5230" id="segment-45" start_char="5075">
<ORIGINAL_TEXT>19, 2020, public health experts signed a public statement to "strongly condemn conspiracy theories suggesting that COVID-19 does not have a natural origin."</ORIGINAL_TEXT>
<TOKEN end_char="5076" id="token-45-0" morph="none" pos="word" start_char="5075">19</TOKEN>
<TOKEN end_char="5077" id="token-45-1" morph="none" pos="punct" start_char="5077">,</TOKEN>
<TOKEN end_char="5082" id="token-45-2" morph="none" pos="word" start_char="5079">2020</TOKEN>
<TOKEN end_char="5083" id="token-45-3" morph="none" pos="punct" start_char="5083">,</TOKEN>
<TOKEN end_char="5090" id="token-45-4" morph="none" pos="word" start_char="5085">public</TOKEN>
<TOKEN end_char="5097" id="token-45-5" morph="none" pos="word" start_char="5092">health</TOKEN>
<TOKEN end_char="5105" id="token-45-6" morph="none" pos="word" start_char="5099">experts</TOKEN>
<TOKEN end_char="5112" id="token-45-7" morph="none" pos="word" start_char="5107">signed</TOKEN>
<TOKEN end_char="5114" id="token-45-8" morph="none" pos="word" start_char="5114">a</TOKEN>
<TOKEN end_char="5121" id="token-45-9" morph="none" pos="word" start_char="5116">public</TOKEN>
<TOKEN end_char="5131" id="token-45-10" morph="none" pos="word" start_char="5123">statement</TOKEN>
<TOKEN end_char="5134" id="token-45-11" morph="none" pos="word" start_char="5133">to</TOKEN>
<TOKEN end_char="5136" id="token-45-12" morph="none" pos="punct" start_char="5136">"</TOKEN>
<TOKEN end_char="5144" id="token-45-13" morph="none" pos="word" start_char="5137">strongly</TOKEN>
<TOKEN end_char="5152" id="token-45-14" morph="none" pos="word" start_char="5146">condemn</TOKEN>
<TOKEN end_char="5163" id="token-45-15" morph="none" pos="word" start_char="5154">conspiracy</TOKEN>
<TOKEN end_char="5172" id="token-45-16" morph="none" pos="word" start_char="5165">theories</TOKEN>
<TOKEN end_char="5183" id="token-45-17" morph="none" pos="word" start_char="5174">suggesting</TOKEN>
<TOKEN end_char="5188" id="token-45-18" morph="none" pos="word" start_char="5185">that</TOKEN>
<TOKEN end_char="5197" id="token-45-19" morph="none" pos="unknown" start_char="5190">COVID-19</TOKEN>
<TOKEN end_char="5202" id="token-45-20" morph="none" pos="word" start_char="5199">does</TOKEN>
<TOKEN end_char="5206" id="token-45-21" morph="none" pos="word" start_char="5204">not</TOKEN>
<TOKEN end_char="5211" id="token-45-22" morph="none" pos="word" start_char="5208">have</TOKEN>
<TOKEN end_char="5213" id="token-45-23" morph="none" pos="word" start_char="5213">a</TOKEN>
<TOKEN end_char="5221" id="token-45-24" morph="none" pos="word" start_char="5215">natural</TOKEN>
<TOKEN end_char="5228" id="token-45-25" morph="none" pos="word" start_char="5223">origin</TOKEN>
<TOKEN end_char="5230" id="token-45-26" morph="none" pos="punct" start_char="5229">."</TOKEN>
</SEG>
<SEG end_char="5452" id="segment-46" start_char="5233">
<ORIGINAL_TEXT>"Scientists from multiple countries have published and analysed genomes" of SARS-CoV-2 "and they overwhelmingly conclude that this coronavirus originated in wildlife," the statement reads, citing nine scientific studies.</ORIGINAL_TEXT>
<TOKEN end_char="5233" id="token-46-0" morph="none" pos="punct" start_char="5233">"</TOKEN>
<TOKEN end_char="5243" id="token-46-1" morph="none" pos="word" start_char="5234">Scientists</TOKEN>
<TOKEN end_char="5248" id="token-46-2" morph="none" pos="word" start_char="5245">from</TOKEN>
<TOKEN end_char="5257" id="token-46-3" morph="none" pos="word" start_char="5250">multiple</TOKEN>
<TOKEN end_char="5267" id="token-46-4" morph="none" pos="word" start_char="5259">countries</TOKEN>
<TOKEN end_char="5272" id="token-46-5" morph="none" pos="word" start_char="5269">have</TOKEN>
<TOKEN end_char="5282" id="token-46-6" morph="none" pos="word" start_char="5274">published</TOKEN>
<TOKEN end_char="5286" id="token-46-7" morph="none" pos="word" start_char="5284">and</TOKEN>
<TOKEN end_char="5295" id="token-46-8" morph="none" pos="word" start_char="5288">analysed</TOKEN>
<TOKEN end_char="5303" id="token-46-9" morph="none" pos="word" start_char="5297">genomes</TOKEN>
<TOKEN end_char="5304" id="token-46-10" morph="none" pos="punct" start_char="5304">"</TOKEN>
<TOKEN end_char="5307" id="token-46-11" morph="none" pos="word" start_char="5306">of</TOKEN>
<TOKEN end_char="5318" id="token-46-12" morph="none" pos="unknown" start_char="5309">SARS-CoV-2</TOKEN>
<TOKEN end_char="5320" id="token-46-13" morph="none" pos="punct" start_char="5320">"</TOKEN>
<TOKEN end_char="5323" id="token-46-14" morph="none" pos="word" start_char="5321">and</TOKEN>
<TOKEN end_char="5328" id="token-46-15" morph="none" pos="word" start_char="5325">they</TOKEN>
<TOKEN end_char="5343" id="token-46-16" morph="none" pos="word" start_char="5330">overwhelmingly</TOKEN>
<TOKEN end_char="5352" id="token-46-17" morph="none" pos="word" start_char="5345">conclude</TOKEN>
<TOKEN end_char="5357" id="token-46-18" morph="none" pos="word" start_char="5354">that</TOKEN>
<TOKEN end_char="5362" id="token-46-19" morph="none" pos="word" start_char="5359">this</TOKEN>
<TOKEN end_char="5374" id="token-46-20" morph="none" pos="word" start_char="5364">coronavirus</TOKEN>
<TOKEN end_char="5385" id="token-46-21" morph="none" pos="word" start_char="5376">originated</TOKEN>
<TOKEN end_char="5388" id="token-46-22" morph="none" pos="word" start_char="5387">in</TOKEN>
<TOKEN end_char="5397" id="token-46-23" morph="none" pos="word" start_char="5390">wildlife</TOKEN>
<TOKEN end_char="5399" id="token-46-24" morph="none" pos="punct" start_char="5398">,"</TOKEN>
<TOKEN end_char="5403" id="token-46-25" morph="none" pos="word" start_char="5401">the</TOKEN>
<TOKEN end_char="5413" id="token-46-26" morph="none" pos="word" start_char="5405">statement</TOKEN>
<TOKEN end_char="5419" id="token-46-27" morph="none" pos="word" start_char="5415">reads</TOKEN>
<TOKEN end_char="5420" id="token-46-28" morph="none" pos="punct" start_char="5420">,</TOKEN>
<TOKEN end_char="5427" id="token-46-29" morph="none" pos="word" start_char="5422">citing</TOKEN>
<TOKEN end_char="5432" id="token-46-30" morph="none" pos="word" start_char="5429">nine</TOKEN>
<TOKEN end_char="5443" id="token-46-31" morph="none" pos="word" start_char="5434">scientific</TOKEN>
<TOKEN end_char="5451" id="token-46-32" morph="none" pos="word" start_char="5445">studies</TOKEN>
<TOKEN end_char="5452" id="token-46-33" morph="none" pos="punct" start_char="5452">.</TOKEN>
</SEG>
<SEG end_char="5606" id="segment-47" start_char="5455">
<ORIGINAL_TEXT>A detailed computational analysis of the coronavirus conducted by five researchers in March found that its genetic makeup showed no signs of alteration.</ORIGINAL_TEXT>
<TOKEN end_char="5455" id="token-47-0" morph="none" pos="word" start_char="5455">A</TOKEN>
<TOKEN end_char="5464" id="token-47-1" morph="none" pos="word" start_char="5457">detailed</TOKEN>
<TOKEN end_char="5478" id="token-47-2" morph="none" pos="word" start_char="5466">computational</TOKEN>
<TOKEN end_char="5487" id="token-47-3" morph="none" pos="word" start_char="5480">analysis</TOKEN>
<TOKEN end_char="5490" id="token-47-4" morph="none" pos="word" start_char="5489">of</TOKEN>
<TOKEN end_char="5494" id="token-47-5" morph="none" pos="word" start_char="5492">the</TOKEN>
<TOKEN end_char="5506" id="token-47-6" morph="none" pos="word" start_char="5496">coronavirus</TOKEN>
<TOKEN end_char="5516" id="token-47-7" morph="none" pos="word" start_char="5508">conducted</TOKEN>
<TOKEN end_char="5519" id="token-47-8" morph="none" pos="word" start_char="5518">by</TOKEN>
<TOKEN end_char="5524" id="token-47-9" morph="none" pos="word" start_char="5521">five</TOKEN>
<TOKEN end_char="5536" id="token-47-10" morph="none" pos="word" start_char="5526">researchers</TOKEN>
<TOKEN end_char="5539" id="token-47-11" morph="none" pos="word" start_char="5538">in</TOKEN>
<TOKEN end_char="5545" id="token-47-12" morph="none" pos="word" start_char="5541">March</TOKEN>
<TOKEN end_char="5551" id="token-47-13" morph="none" pos="word" start_char="5547">found</TOKEN>
<TOKEN end_char="5556" id="token-47-14" morph="none" pos="word" start_char="5553">that</TOKEN>
<TOKEN end_char="5560" id="token-47-15" morph="none" pos="word" start_char="5558">its</TOKEN>
<TOKEN end_char="5568" id="token-47-16" morph="none" pos="word" start_char="5562">genetic</TOKEN>
<TOKEN end_char="5575" id="token-47-17" morph="none" pos="word" start_char="5570">makeup</TOKEN>
<TOKEN end_char="5582" id="token-47-18" morph="none" pos="word" start_char="5577">showed</TOKEN>
<TOKEN end_char="5585" id="token-47-19" morph="none" pos="word" start_char="5584">no</TOKEN>
<TOKEN end_char="5591" id="token-47-20" morph="none" pos="word" start_char="5587">signs</TOKEN>
<TOKEN end_char="5594" id="token-47-21" morph="none" pos="word" start_char="5593">of</TOKEN>
<TOKEN end_char="5605" id="token-47-22" morph="none" pos="word" start_char="5596">alteration</TOKEN>
<TOKEN end_char="5606" id="token-47-23" morph="none" pos="punct" start_char="5606">.</TOKEN>
</SEG>
<SEG end_char="5769" id="segment-48" start_char="5608">
<ORIGINAL_TEXT>The ability of the virus to bind to human cells is most likely the result of natural selection in an animal host or in humans after the virus jumped from animals.</ORIGINAL_TEXT>
<TOKEN end_char="5610" id="token-48-0" morph="none" pos="word" start_char="5608">The</TOKEN>
<TOKEN end_char="5618" id="token-48-1" morph="none" pos="word" start_char="5612">ability</TOKEN>
<TOKEN end_char="5621" id="token-48-2" morph="none" pos="word" start_char="5620">of</TOKEN>
<TOKEN end_char="5625" id="token-48-3" morph="none" pos="word" start_char="5623">the</TOKEN>
<TOKEN end_char="5631" id="token-48-4" morph="none" pos="word" start_char="5627">virus</TOKEN>
<TOKEN end_char="5634" id="token-48-5" morph="none" pos="word" start_char="5633">to</TOKEN>
<TOKEN end_char="5639" id="token-48-6" morph="none" pos="word" start_char="5636">bind</TOKEN>
<TOKEN end_char="5642" id="token-48-7" morph="none" pos="word" start_char="5641">to</TOKEN>
<TOKEN end_char="5648" id="token-48-8" morph="none" pos="word" start_char="5644">human</TOKEN>
<TOKEN end_char="5654" id="token-48-9" morph="none" pos="word" start_char="5650">cells</TOKEN>
<TOKEN end_char="5657" id="token-48-10" morph="none" pos="word" start_char="5656">is</TOKEN>
<TOKEN end_char="5662" id="token-48-11" morph="none" pos="word" start_char="5659">most</TOKEN>
<TOKEN end_char="5669" id="token-48-12" morph="none" pos="word" start_char="5664">likely</TOKEN>
<TOKEN end_char="5673" id="token-48-13" morph="none" pos="word" start_char="5671">the</TOKEN>
<TOKEN end_char="5680" id="token-48-14" morph="none" pos="word" start_char="5675">result</TOKEN>
<TOKEN end_char="5683" id="token-48-15" morph="none" pos="word" start_char="5682">of</TOKEN>
<TOKEN end_char="5691" id="token-48-16" morph="none" pos="word" start_char="5685">natural</TOKEN>
<TOKEN end_char="5701" id="token-48-17" morph="none" pos="word" start_char="5693">selection</TOKEN>
<TOKEN end_char="5704" id="token-48-18" morph="none" pos="word" start_char="5703">in</TOKEN>
<TOKEN end_char="5707" id="token-48-19" morph="none" pos="word" start_char="5706">an</TOKEN>
<TOKEN end_char="5714" id="token-48-20" morph="none" pos="word" start_char="5709">animal</TOKEN>
<TOKEN end_char="5719" id="token-48-21" morph="none" pos="word" start_char="5716">host</TOKEN>
<TOKEN end_char="5722" id="token-48-22" morph="none" pos="word" start_char="5721">or</TOKEN>
<TOKEN end_char="5725" id="token-48-23" morph="none" pos="word" start_char="5724">in</TOKEN>
<TOKEN end_char="5732" id="token-48-24" morph="none" pos="word" start_char="5727">humans</TOKEN>
<TOKEN end_char="5738" id="token-48-25" morph="none" pos="word" start_char="5734">after</TOKEN>
<TOKEN end_char="5742" id="token-48-26" morph="none" pos="word" start_char="5740">the</TOKEN>
<TOKEN end_char="5748" id="token-48-27" morph="none" pos="word" start_char="5744">virus</TOKEN>
<TOKEN end_char="5755" id="token-48-28" morph="none" pos="word" start_char="5750">jumped</TOKEN>
<TOKEN end_char="5760" id="token-48-29" morph="none" pos="word" start_char="5757">from</TOKEN>
<TOKEN end_char="5768" id="token-48-30" morph="none" pos="word" start_char="5762">animals</TOKEN>
<TOKEN end_char="5769" id="token-48-31" morph="none" pos="punct" start_char="5769">.</TOKEN>
</SEG>
<SEG end_char="5781" id="segment-49" start_char="5772">
<ORIGINAL_TEXT>Our ruling</ORIGINAL_TEXT>
<TOKEN end_char="5774" id="token-49-0" morph="none" pos="word" start_char="5772">Our</TOKEN>
<TOKEN end_char="5781" id="token-49-1" morph="none" pos="word" start_char="5776">ruling</TOKEN>
<TRANSLATED_TEXT>Onze uitspraak</TRANSLATED_TEXT><DETECTED_LANGUAGE>ro</DETECTED_LANGUAGE></SEG>
<SEG end_char="5875" id="segment-50" start_char="5785">
<ORIGINAL_TEXT>WorldNetDaily wrote that "New evidence ties COVID-19 creation to research funded by Fauci."</ORIGINAL_TEXT>
<TOKEN end_char="5797" id="token-50-0" morph="none" pos="word" start_char="5785">WorldNetDaily</TOKEN>
<TOKEN end_char="5803" id="token-50-1" morph="none" pos="word" start_char="5799">wrote</TOKEN>
<TOKEN end_char="5808" id="token-50-2" morph="none" pos="word" start_char="5805">that</TOKEN>
<TOKEN end_char="5810" id="token-50-3" morph="none" pos="punct" start_char="5810">"</TOKEN>
<TOKEN end_char="5813" id="token-50-4" morph="none" pos="word" start_char="5811">New</TOKEN>
<TOKEN end_char="5822" id="token-50-5" morph="none" pos="word" start_char="5815">evidence</TOKEN>
<TOKEN end_char="5827" id="token-50-6" morph="none" pos="word" start_char="5824">ties</TOKEN>
<TOKEN end_char="5836" id="token-50-7" morph="none" pos="unknown" start_char="5829">COVID-19</TOKEN>
<TOKEN end_char="5845" id="token-50-8" morph="none" pos="word" start_char="5838">creation</TOKEN>
<TOKEN end_char="5848" id="token-50-9" morph="none" pos="word" start_char="5847">to</TOKEN>
<TOKEN end_char="5857" id="token-50-10" morph="none" pos="word" start_char="5850">research</TOKEN>
<TOKEN end_char="5864" id="token-50-11" morph="none" pos="word" start_char="5859">funded</TOKEN>
<TOKEN end_char="5867" id="token-50-12" morph="none" pos="word" start_char="5866">by</TOKEN>
<TOKEN end_char="5873" id="token-50-13" morph="none" pos="word" start_char="5869">Fauci</TOKEN>
<TOKEN end_char="5875" id="token-50-14" morph="none" pos="punct" start_char="5874">."</TOKEN>
</SEG>
<SEG end_char="6129" id="segment-51" start_char="5878">
<ORIGINAL_TEXT>Both the NIH and EcoHealth Alliance have denied that a grant to the Wuhan lab funded gain-of-function research, though a scientist told us that one paper published with assistance from the grant seems to describe techniques similar to gain-of-function.</ORIGINAL_TEXT>
<TOKEN end_char="5881" id="token-51-0" morph="none" pos="word" start_char="5878">Both</TOKEN>
<TOKEN end_char="5885" id="token-51-1" morph="none" pos="word" start_char="5883">the</TOKEN>
<TOKEN end_char="5889" id="token-51-2" morph="none" pos="word" start_char="5887">NIH</TOKEN>
<TOKEN end_char="5893" id="token-51-3" morph="none" pos="word" start_char="5891">and</TOKEN>
<TOKEN end_char="5903" id="token-51-4" morph="none" pos="word" start_char="5895">EcoHealth</TOKEN>
<TOKEN end_char="5912" id="token-51-5" morph="none" pos="word" start_char="5905">Alliance</TOKEN>
<TOKEN end_char="5917" id="token-51-6" morph="none" pos="word" start_char="5914">have</TOKEN>
<TOKEN end_char="5924" id="token-51-7" morph="none" pos="word" start_char="5919">denied</TOKEN>
<TOKEN end_char="5929" id="token-51-8" morph="none" pos="word" start_char="5926">that</TOKEN>
<TOKEN end_char="5931" id="token-51-9" morph="none" pos="word" start_char="5931">a</TOKEN>
<TOKEN end_char="5937" id="token-51-10" morph="none" pos="word" start_char="5933">grant</TOKEN>
<TOKEN end_char="5940" id="token-51-11" morph="none" pos="word" start_char="5939">to</TOKEN>
<TOKEN end_char="5944" id="token-51-12" morph="none" pos="word" start_char="5942">the</TOKEN>
<TOKEN end_char="5950" id="token-51-13" morph="none" pos="word" start_char="5946">Wuhan</TOKEN>
<TOKEN end_char="5954" id="token-51-14" morph="none" pos="word" start_char="5952">lab</TOKEN>
<TOKEN end_char="5961" id="token-51-15" morph="none" pos="word" start_char="5956">funded</TOKEN>
<TOKEN end_char="5978" id="token-51-16" morph="none" pos="unknown" start_char="5963">gain-of-function</TOKEN>
<TOKEN end_char="5987" id="token-51-17" morph="none" pos="word" start_char="5980">research</TOKEN>
<TOKEN end_char="5988" id="token-51-18" morph="none" pos="punct" start_char="5988">,</TOKEN>
<TOKEN end_char="5995" id="token-51-19" morph="none" pos="word" start_char="5990">though</TOKEN>
<TOKEN end_char="5997" id="token-51-20" morph="none" pos="word" start_char="5997">a</TOKEN>
<TOKEN end_char="6007" id="token-51-21" morph="none" pos="word" start_char="5999">scientist</TOKEN>
<TOKEN end_char="6012" id="token-51-22" morph="none" pos="word" start_char="6009">told</TOKEN>
<TOKEN end_char="6015" id="token-51-23" morph="none" pos="word" start_char="6014">us</TOKEN>
<TOKEN end_char="6020" id="token-51-24" morph="none" pos="word" start_char="6017">that</TOKEN>
<TOKEN end_char="6024" id="token-51-25" morph="none" pos="word" start_char="6022">one</TOKEN>
<TOKEN end_char="6030" id="token-51-26" morph="none" pos="word" start_char="6026">paper</TOKEN>
<TOKEN end_char="6040" id="token-51-27" morph="none" pos="word" start_char="6032">published</TOKEN>
<TOKEN end_char="6045" id="token-51-28" morph="none" pos="word" start_char="6042">with</TOKEN>
<TOKEN end_char="6056" id="token-51-29" morph="none" pos="word" start_char="6047">assistance</TOKEN>
<TOKEN end_char="6061" id="token-51-30" morph="none" pos="word" start_char="6058">from</TOKEN>
<TOKEN end_char="6065" id="token-51-31" morph="none" pos="word" start_char="6063">the</TOKEN>
<TOKEN end_char="6071" id="token-51-32" morph="none" pos="word" start_char="6067">grant</TOKEN>
<TOKEN end_char="6077" id="token-51-33" morph="none" pos="word" start_char="6073">seems</TOKEN>
<TOKEN end_char="6080" id="token-51-34" morph="none" pos="word" start_char="6079">to</TOKEN>
<TOKEN end_char="6089" id="token-51-35" morph="none" pos="word" start_char="6082">describe</TOKEN>
<TOKEN end_char="6100" id="token-51-36" morph="none" pos="word" start_char="6091">techniques</TOKEN>
<TOKEN end_char="6108" id="token-51-37" morph="none" pos="word" start_char="6102">similar</TOKEN>
<TOKEN end_char="6111" id="token-51-38" morph="none" pos="word" start_char="6110">to</TOKEN>
<TOKEN end_char="6128" id="token-51-39" morph="none" pos="unknown" start_char="6113">gain-of-function</TOKEN>
<TOKEN end_char="6129" id="token-51-40" morph="none" pos="punct" start_char="6129">.</TOKEN>
</SEG>
<SEG end_char="6229" id="segment-52" start_char="6132">
<ORIGINAL_TEXT>The CDC, the WHO, and the NIH have all said that the virus that causes COVID-19 evolved naturally.</ORIGINAL_TEXT>
<TOKEN end_char="6134" id="token-52-0" morph="none" pos="word" start_char="6132">The</TOKEN>
<TOKEN end_char="6138" id="token-52-1" morph="none" pos="word" start_char="6136">CDC</TOKEN>
<TOKEN end_char="6139" id="token-52-2" morph="none" pos="punct" start_char="6139">,</TOKEN>
<TOKEN end_char="6143" id="token-52-3" morph="none" pos="word" start_char="6141">the</TOKEN>
<TOKEN end_char="6147" id="token-52-4" morph="none" pos="word" start_char="6145">WHO</TOKEN>
<TOKEN end_char="6148" id="token-52-5" morph="none" pos="punct" start_char="6148">,</TOKEN>
<TOKEN end_char="6152" id="token-52-6" morph="none" pos="word" start_char="6150">and</TOKEN>
<TOKEN end_char="6156" id="token-52-7" morph="none" pos="word" start_char="6154">the</TOKEN>
<TOKEN end_char="6160" id="token-52-8" morph="none" pos="word" start_char="6158">NIH</TOKEN>
<TOKEN end_char="6165" id="token-52-9" morph="none" pos="word" start_char="6162">have</TOKEN>
<TOKEN end_char="6169" id="token-52-10" morph="none" pos="word" start_char="6167">all</TOKEN>
<TOKEN end_char="6174" id="token-52-11" morph="none" pos="word" start_char="6171">said</TOKEN>
<TOKEN end_char="6179" id="token-52-12" morph="none" pos="word" start_char="6176">that</TOKEN>
<TOKEN end_char="6183" id="token-52-13" morph="none" pos="word" start_char="6181">the</TOKEN>
<TOKEN end_char="6189" id="token-52-14" morph="none" pos="word" start_char="6185">virus</TOKEN>
<TOKEN end_char="6194" id="token-52-15" morph="none" pos="word" start_char="6191">that</TOKEN>
<TOKEN end_char="6201" id="token-52-16" morph="none" pos="word" start_char="6196">causes</TOKEN>
<TOKEN end_char="6210" id="token-52-17" morph="none" pos="unknown" start_char="6203">COVID-19</TOKEN>
<TOKEN end_char="6218" id="token-52-18" morph="none" pos="word" start_char="6212">evolved</TOKEN>
<TOKEN end_char="6228" id="token-52-19" morph="none" pos="word" start_char="6220">naturally</TOKEN>
<TOKEN end_char="6229" id="token-52-20" morph="none" pos="punct" start_char="6229">.</TOKEN>
</SEG>
<SEG end_char="6308" id="segment-53" start_char="6231">
<ORIGINAL_TEXT>There is no evidence to support that claim that it was created by researchers.</ORIGINAL_TEXT>
<TOKEN end_char="6235" id="token-53-0" morph="none" pos="word" start_char="6231">There</TOKEN>
<TOKEN end_char="6238" id="token-53-1" morph="none" pos="word" start_char="6237">is</TOKEN>
<TOKEN end_char="6241" id="token-53-2" morph="none" pos="word" start_char="6240">no</TOKEN>
<TOKEN end_char="6250" id="token-53-3" morph="none" pos="word" start_char="6243">evidence</TOKEN>
<TOKEN end_char="6253" id="token-53-4" morph="none" pos="word" start_char="6252">to</TOKEN>
<TOKEN end_char="6261" id="token-53-5" morph="none" pos="word" start_char="6255">support</TOKEN>
<TOKEN end_char="6266" id="token-53-6" morph="none" pos="word" start_char="6263">that</TOKEN>
<TOKEN end_char="6272" id="token-53-7" morph="none" pos="word" start_char="6268">claim</TOKEN>
<TOKEN end_char="6277" id="token-53-8" morph="none" pos="word" start_char="6274">that</TOKEN>
<TOKEN end_char="6280" id="token-53-9" morph="none" pos="word" start_char="6279">it</TOKEN>
<TOKEN end_char="6284" id="token-53-10" morph="none" pos="word" start_char="6282">was</TOKEN>
<TOKEN end_char="6292" id="token-53-11" morph="none" pos="word" start_char="6286">created</TOKEN>
<TOKEN end_char="6295" id="token-53-12" morph="none" pos="word" start_char="6294">by</TOKEN>
<TOKEN end_char="6307" id="token-53-13" morph="none" pos="word" start_char="6297">researchers</TOKEN>
<TOKEN end_char="6308" id="token-53-14" morph="none" pos="punct" start_char="6308">.</TOKEN>
</SEG>
<SEG end_char="6330" id="segment-54" start_char="6311">
<ORIGINAL_TEXT>This claim is False.</ORIGINAL_TEXT>
<TOKEN end_char="6314" id="token-54-0" morph="none" pos="word" start_char="6311">This</TOKEN>
<TOKEN end_char="6320" id="token-54-1" morph="none" pos="word" start_char="6316">claim</TOKEN>
<TOKEN end_char="6323" id="token-54-2" morph="none" pos="word" start_char="6322">is</TOKEN>
<TOKEN end_char="6329" id="token-54-3" morph="none" pos="word" start_char="6325">False</TOKEN>
<TOKEN end_char="6330" id="token-54-4" morph="none" pos="punct" start_char="6330">.</TOKEN>
</SEG>
<SEG end_char="6339" id="segment-55" start_char="6333">
<ORIGINAL_TEXT>Sources</ORIGINAL_TEXT>
<TOKEN end_char="6339" id="token-55-0" morph="none" pos="word" start_char="6333">Sources</TOKEN>
</SEG>
<SEG end_char="6426" id="segment-56" start_char="6343">
<ORIGINAL_TEXT>WorldNetDaily, New evidence ties COVID-19 creation to research funded by Fauci, Feb.</ORIGINAL_TEXT>
<TOKEN end_char="6355" id="token-56-0" morph="none" pos="word" start_char="6343">WorldNetDaily</TOKEN>
<TOKEN end_char="6356" id="token-56-1" morph="none" pos="punct" start_char="6356">,</TOKEN>
<TOKEN end_char="6360" id="token-56-2" morph="none" pos="word" start_char="6358">New</TOKEN>
<TOKEN end_char="6369" id="token-56-3" morph="none" pos="word" start_char="6362">evidence</TOKEN>
<TOKEN end_char="6374" id="token-56-4" morph="none" pos="word" start_char="6371">ties</TOKEN>
<TOKEN end_char="6383" id="token-56-5" morph="none" pos="unknown" start_char="6376">COVID-19</TOKEN>
<TOKEN end_char="6392" id="token-56-6" morph="none" pos="word" start_char="6385">creation</TOKEN>
<TOKEN end_char="6395" id="token-56-7" morph="none" pos="word" start_char="6394">to</TOKEN>
<TOKEN end_char="6404" id="token-56-8" morph="none" pos="word" start_char="6397">research</TOKEN>
<TOKEN end_char="6411" id="token-56-9" morph="none" pos="word" start_char="6406">funded</TOKEN>
<TOKEN end_char="6414" id="token-56-10" morph="none" pos="word" start_char="6413">by</TOKEN>
<TOKEN end_char="6420" id="token-56-11" morph="none" pos="word" start_char="6416">Fauci</TOKEN>
<TOKEN end_char="6421" id="token-56-12" morph="none" pos="punct" start_char="6421">,</TOKEN>
<TOKEN end_char="6425" id="token-56-13" morph="none" pos="word" start_char="6423">Feb</TOKEN>
<TOKEN end_char="6426" id="token-56-14" morph="none" pos="punct" start_char="6426">.</TOKEN>
</SEG>
<SEG end_char="6434" id="segment-57" start_char="6428">
<ORIGINAL_TEXT>1, 2021</ORIGINAL_TEXT>
<TOKEN end_char="6428" id="token-57-0" morph="none" pos="word" start_char="6428">1</TOKEN>
<TOKEN end_char="6429" id="token-57-1" morph="none" pos="punct" start_char="6429">,</TOKEN>
<TOKEN end_char="6434" id="token-57-2" morph="none" pos="word" start_char="6431">2021</TOKEN>
<TRANSLATED_TEXT>1.2021</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="6532" id="segment-58" start_char="6437">
<ORIGINAL_TEXT>The Next Revolution with Steve Hilton, Coronavirus origins: Special investigation - update, Jan.</ORIGINAL_TEXT>
<TOKEN end_char="6439" id="token-58-0" morph="none" pos="word" start_char="6437">The</TOKEN>
<TOKEN end_char="6444" id="token-58-1" morph="none" pos="word" start_char="6441">Next</TOKEN>
<TOKEN end_char="6455" id="token-58-2" morph="none" pos="word" start_char="6446">Revolution</TOKEN>
<TOKEN end_char="6460" id="token-58-3" morph="none" pos="word" start_char="6457">with</TOKEN>
<TOKEN end_char="6466" id="token-58-4" morph="none" pos="word" start_char="6462">Steve</TOKEN>
<TOKEN end_char="6473" id="token-58-5" morph="none" pos="word" start_char="6468">Hilton</TOKEN>
<TOKEN end_char="6474" id="token-58-6" morph="none" pos="punct" start_char="6474">,</TOKEN>
<TOKEN end_char="6486" id="token-58-7" morph="none" pos="word" start_char="6476">Coronavirus</TOKEN>
<TOKEN end_char="6494" id="token-58-8" morph="none" pos="word" start_char="6488">origins</TOKEN>
<TOKEN end_char="6495" id="token-58-9" morph="none" pos="punct" start_char="6495">:</TOKEN>
<TOKEN end_char="6503" id="token-58-10" morph="none" pos="word" start_char="6497">Special</TOKEN>
<TOKEN end_char="6517" id="token-58-11" morph="none" pos="word" start_char="6505">investigation</TOKEN>
<TOKEN end_char="6519" id="token-58-12" morph="none" pos="punct" start_char="6519">-</TOKEN>
<TOKEN end_char="6526" id="token-58-13" morph="none" pos="word" start_char="6521">update</TOKEN>
<TOKEN end_char="6527" id="token-58-14" morph="none" pos="punct" start_char="6527">,</TOKEN>
<TOKEN end_char="6531" id="token-58-15" morph="none" pos="word" start_char="6529">Jan</TOKEN>
<TOKEN end_char="6532" id="token-58-16" morph="none" pos="punct" start_char="6532">.</TOKEN>
</SEG>
<SEG end_char="6541" id="segment-59" start_char="6534">
<ORIGINAL_TEXT>31, 2021</ORIGINAL_TEXT>
<TOKEN end_char="6535" id="token-59-0" morph="none" pos="word" start_char="6534">31</TOKEN>
<TOKEN end_char="6536" id="token-59-1" morph="none" pos="punct" start_char="6536">,</TOKEN>
<TOKEN end_char="6541" id="token-59-2" morph="none" pos="word" start_char="6538">2021</TOKEN>
<TRANSLATED_TEXT>31., 2021</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="6624" id="segment-60" start_char="6544">
<ORIGINAL_TEXT>Email interview with Kevin Esvelt, assistant professor of the MIT Media Lab, Feb.</ORIGINAL_TEXT>
<TOKEN end_char="6548" id="token-60-0" morph="none" pos="word" start_char="6544">Email</TOKEN>
<TOKEN end_char="6558" id="token-60-1" morph="none" pos="word" start_char="6550">interview</TOKEN>
<TOKEN end_char="6563" id="token-60-2" morph="none" pos="word" start_char="6560">with</TOKEN>
<TOKEN end_char="6569" id="token-60-3" morph="none" pos="word" start_char="6565">Kevin</TOKEN>
<TOKEN end_char="6576" id="token-60-4" morph="none" pos="word" start_char="6571">Esvelt</TOKEN>
<TOKEN end_char="6577" id="token-60-5" morph="none" pos="punct" start_char="6577">,</TOKEN>
<TOKEN end_char="6587" id="token-60-6" morph="none" pos="word" start_char="6579">assistant</TOKEN>
<TOKEN end_char="6597" id="token-60-7" morph="none" pos="word" start_char="6589">professor</TOKEN>
<TOKEN end_char="6600" id="token-60-8" morph="none" pos="word" start_char="6599">of</TOKEN>
<TOKEN end_char="6604" id="token-60-9" morph="none" pos="word" start_char="6602">the</TOKEN>
<TOKEN end_char="6608" id="token-60-10" morph="none" pos="word" start_char="6606">MIT</TOKEN>
<TOKEN end_char="6614" id="token-60-11" morph="none" pos="word" start_char="6610">Media</TOKEN>
<TOKEN end_char="6618" id="token-60-12" morph="none" pos="word" start_char="6616">Lab</TOKEN>
<TOKEN end_char="6619" id="token-60-13" morph="none" pos="punct" start_char="6619">,</TOKEN>
<TOKEN end_char="6623" id="token-60-14" morph="none" pos="word" start_char="6621">Feb</TOKEN>
<TOKEN end_char="6624" id="token-60-15" morph="none" pos="punct" start_char="6624">.</TOKEN>
</SEG>
<SEG end_char="6632" id="segment-61" start_char="6626">
<ORIGINAL_TEXT>4, 2021</ORIGINAL_TEXT>
<TOKEN end_char="6626" id="token-61-0" morph="none" pos="word" start_char="6626">4</TOKEN>
<TOKEN end_char="6627" id="token-61-1" morph="none" pos="punct" start_char="6627">,</TOKEN>
<TOKEN end_char="6632" id="token-61-2" morph="none" pos="word" start_char="6629">2021</TOKEN>
<TRANSLATED_TEXT>4.2021</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="6715" id="segment-62" start_char="6635">
<ORIGINAL_TEXT>Email interview with Marc Lipsitch, professor of epidemiology at the Harvard T.H.</ORIGINAL_TEXT>
<TOKEN end_char="6639" id="token-62-0" morph="none" pos="word" start_char="6635">Email</TOKEN>
<TOKEN end_char="6649" id="token-62-1" morph="none" pos="word" start_char="6641">interview</TOKEN>
<TOKEN end_char="6654" id="token-62-2" morph="none" pos="word" start_char="6651">with</TOKEN>
<TOKEN end_char="6659" id="token-62-3" morph="none" pos="word" start_char="6656">Marc</TOKEN>
<TOKEN end_char="6668" id="token-62-4" morph="none" pos="word" start_char="6661">Lipsitch</TOKEN>
<TOKEN end_char="6669" id="token-62-5" morph="none" pos="punct" start_char="6669">,</TOKEN>
<TOKEN end_char="6679" id="token-62-6" morph="none" pos="word" start_char="6671">professor</TOKEN>
<TOKEN end_char="6682" id="token-62-7" morph="none" pos="word" start_char="6681">of</TOKEN>
<TOKEN end_char="6695" id="token-62-8" morph="none" pos="word" start_char="6684">epidemiology</TOKEN>
<TOKEN end_char="6698" id="token-62-9" morph="none" pos="word" start_char="6697">at</TOKEN>
<TOKEN end_char="6702" id="token-62-10" morph="none" pos="word" start_char="6700">the</TOKEN>
<TOKEN end_char="6710" id="token-62-11" morph="none" pos="word" start_char="6704">Harvard</TOKEN>
<TOKEN end_char="6714" id="token-62-12" morph="none" pos="unknown" start_char="6712">T.H</TOKEN>
<TOKEN end_char="6715" id="token-62-13" morph="none" pos="punct" start_char="6715">.</TOKEN>
</SEG>
<SEG end_char="6750" id="segment-63" start_char="6717">
<ORIGINAL_TEXT>Chan School of Public Health, Feb.</ORIGINAL_TEXT>
<TOKEN end_char="6720" id="token-63-0" morph="none" pos="word" start_char="6717">Chan</TOKEN>
<TOKEN end_char="6727" id="token-63-1" morph="none" pos="word" start_char="6722">School</TOKEN>
<TOKEN end_char="6730" id="token-63-2" morph="none" pos="word" start_char="6729">of</TOKEN>
<TOKEN end_char="6737" id="token-63-3" morph="none" pos="word" start_char="6732">Public</TOKEN>
<TOKEN end_char="6744" id="token-63-4" morph="none" pos="word" start_char="6739">Health</TOKEN>
<TOKEN end_char="6745" id="token-63-5" morph="none" pos="punct" start_char="6745">,</TOKEN>
<TOKEN end_char="6749" id="token-63-6" morph="none" pos="word" start_char="6747">Feb</TOKEN>
<TOKEN end_char="6750" id="token-63-7" morph="none" pos="punct" start_char="6750">.</TOKEN>
</SEG>
<SEG end_char="6758" id="segment-64" start_char="6752">
<ORIGINAL_TEXT>4, 2021</ORIGINAL_TEXT>
<TOKEN end_char="6752" id="token-64-0" morph="none" pos="word" start_char="6752">4</TOKEN>
<TOKEN end_char="6753" id="token-64-1" morph="none" pos="punct" start_char="6753">,</TOKEN>
<TOKEN end_char="6758" id="token-64-2" morph="none" pos="word" start_char="6755">2021</TOKEN>
<TRANSLATED_TEXT>4.2021</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="6865" id="segment-65" start_char="6761">
<ORIGINAL_TEXT>PolitiFact, Tucker Carlson guest airs debunked conspiracy theory that COVID-19 was created in a lab, Sep.</ORIGINAL_TEXT>
<TOKEN end_char="6770" id="token-65-0" morph="none" pos="word" start_char="6761">PolitiFact</TOKEN>
<TOKEN end_char="6771" id="token-65-1" morph="none" pos="punct" start_char="6771">,</TOKEN>
<TOKEN end_char="6778" id="token-65-2" morph="none" pos="word" start_char="6773">Tucker</TOKEN>
<TOKEN end_char="6786" id="token-65-3" morph="none" pos="word" start_char="6780">Carlson</TOKEN>
<TOKEN end_char="6792" id="token-65-4" morph="none" pos="word" start_char="6788">guest</TOKEN>
<TOKEN end_char="6797" id="token-65-5" morph="none" pos="word" start_char="6794">airs</TOKEN>
<TOKEN end_char="6806" id="token-65-6" morph="none" pos="word" start_char="6799">debunked</TOKEN>
<TOKEN end_char="6817" id="token-65-7" morph="none" pos="word" start_char="6808">conspiracy</TOKEN>
<TOKEN end_char="6824" id="token-65-8" morph="none" pos="word" start_char="6819">theory</TOKEN>
<TOKEN end_char="6829" id="token-65-9" morph="none" pos="word" start_char="6826">that</TOKEN>
<TOKEN end_char="6838" id="token-65-10" morph="none" pos="unknown" start_char="6831">COVID-19</TOKEN>
<TOKEN end_char="6842" id="token-65-11" morph="none" pos="word" start_char="6840">was</TOKEN>
<TOKEN end_char="6850" id="token-65-12" morph="none" pos="word" start_char="6844">created</TOKEN>
<TOKEN end_char="6853" id="token-65-13" morph="none" pos="word" start_char="6852">in</TOKEN>
<TOKEN end_char="6855" id="token-65-14" morph="none" pos="word" start_char="6855">a</TOKEN>
<TOKEN end_char="6859" id="token-65-15" morph="none" pos="word" start_char="6857">lab</TOKEN>
<TOKEN end_char="6860" id="token-65-16" morph="none" pos="punct" start_char="6860">,</TOKEN>
<TOKEN end_char="6864" id="token-65-17" morph="none" pos="word" start_char="6862">Sep</TOKEN>
<TOKEN end_char="6865" id="token-65-18" morph="none" pos="punct" start_char="6865">.</TOKEN>
</SEG>
<SEG end_char="6874" id="segment-66" start_char="6867">
<ORIGINAL_TEXT>16, 2020</ORIGINAL_TEXT>
<TOKEN end_char="6868" id="token-66-0" morph="none" pos="word" start_char="6867">16</TOKEN>
<TOKEN end_char="6869" id="token-66-1" morph="none" pos="punct" start_char="6869">,</TOKEN>
<TOKEN end_char="6874" id="token-66-2" morph="none" pos="word" start_char="6871">2020</TOKEN>
<TRANSLATED_TEXT>16., 2020</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="6969" id="segment-67" start_char="6877">
<ORIGINAL_TEXT>PolitiFact, Rudy Giuliani wrong about US policy, grant amount to Wuhan virus lab, May 1, 2020</ORIGINAL_TEXT>
<TOKEN end_char="6886" id="token-67-0" morph="none" pos="word" start_char="6877">PolitiFact</TOKEN>
<TOKEN end_char="6887" id="token-67-1" morph="none" pos="punct" start_char="6887">,</TOKEN>
<TOKEN end_char="6892" id="token-67-2" morph="none" pos="word" start_char="6889">Rudy</TOKEN>
<TOKEN end_char="6901" id="token-67-3" morph="none" pos="word" start_char="6894">Giuliani</TOKEN>
<TOKEN end_char="6907" id="token-67-4" morph="none" pos="word" start_char="6903">wrong</TOKEN>
<TOKEN end_char="6913" id="token-67-5" morph="none" pos="word" start_char="6909">about</TOKEN>
<TOKEN end_char="6916" id="token-67-6" morph="none" pos="word" start_char="6915">US</TOKEN>
<TOKEN end_char="6923" id="token-67-7" morph="none" pos="word" start_char="6918">policy</TOKEN>
<TOKEN end_char="6924" id="token-67-8" morph="none" pos="punct" start_char="6924">,</TOKEN>
<TOKEN end_char="6930" id="token-67-9" morph="none" pos="word" start_char="6926">grant</TOKEN>
<TOKEN end_char="6937" id="token-67-10" morph="none" pos="word" start_char="6932">amount</TOKEN>
<TOKEN end_char="6940" id="token-67-11" morph="none" pos="word" start_char="6939">to</TOKEN>
<TOKEN end_char="6946" id="token-67-12" morph="none" pos="word" start_char="6942">Wuhan</TOKEN>
<TOKEN end_char="6952" id="token-67-13" morph="none" pos="word" start_char="6948">virus</TOKEN>
<TOKEN end_char="6956" id="token-67-14" morph="none" pos="word" start_char="6954">lab</TOKEN>
<TOKEN end_char="6957" id="token-67-15" morph="none" pos="punct" start_char="6957">,</TOKEN>
<TOKEN end_char="6961" id="token-67-16" morph="none" pos="word" start_char="6959">May</TOKEN>
<TOKEN end_char="6963" id="token-67-17" morph="none" pos="word" start_char="6963">1</TOKEN>
<TOKEN end_char="6964" id="token-67-18" morph="none" pos="punct" start_char="6964">,</TOKEN>
<TOKEN end_char="6969" id="token-67-19" morph="none" pos="word" start_char="6966">2020</TOKEN>
</SEG>
<SEG end_char="7053" id="segment-68" start_char="6972">
<ORIGINAL_TEXT>PolitiFact, Health misinformation site promotes conspiracy about coronavirus, Feb.</ORIGINAL_TEXT>
<TOKEN end_char="6981" id="token-68-0" morph="none" pos="word" start_char="6972">PolitiFact</TOKEN>
<TOKEN end_char="6982" id="token-68-1" morph="none" pos="punct" start_char="6982">,</TOKEN>
<TOKEN end_char="6989" id="token-68-2" morph="none" pos="word" start_char="6984">Health</TOKEN>
<TOKEN end_char="7004" id="token-68-3" morph="none" pos="word" start_char="6991">misinformation</TOKEN>
<TOKEN end_char="7009" id="token-68-4" morph="none" pos="word" start_char="7006">site</TOKEN>
<TOKEN end_char="7018" id="token-68-5" morph="none" pos="word" start_char="7011">promotes</TOKEN>
<TOKEN end_char="7029" id="token-68-6" morph="none" pos="word" start_char="7020">conspiracy</TOKEN>
<TOKEN end_char="7035" id="token-68-7" morph="none" pos="word" start_char="7031">about</TOKEN>
<TOKEN end_char="7047" id="token-68-8" morph="none" pos="word" start_char="7037">coronavirus</TOKEN>
<TOKEN end_char="7048" id="token-68-9" morph="none" pos="punct" start_char="7048">,</TOKEN>
<TOKEN end_char="7052" id="token-68-10" morph="none" pos="word" start_char="7050">Feb</TOKEN>
<TOKEN end_char="7053" id="token-68-11" morph="none" pos="punct" start_char="7053">.</TOKEN>
</SEG>
<SEG end_char="7062" id="segment-69" start_char="7055">
<ORIGINAL_TEXT>10, 2020</ORIGINAL_TEXT>
<TOKEN end_char="7056" id="token-69-0" morph="none" pos="word" start_char="7055">10</TOKEN>
<TOKEN end_char="7057" id="token-69-1" morph="none" pos="punct" start_char="7057">,</TOKEN>
<TOKEN end_char="7062" id="token-69-2" morph="none" pos="word" start_char="7059">2020</TOKEN>
<TRANSLATED_TEXT>10., 2020</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="7151" id="segment-70" start_char="7065">
<ORIGINAL_TEXT>PolitiFact, "What we know about the source of the coronavirus pandemic," April 17, 2020</ORIGINAL_TEXT>
<TOKEN end_char="7074" id="token-70-0" morph="none" pos="word" start_char="7065">PolitiFact</TOKEN>
<TOKEN end_char="7075" id="token-70-1" morph="none" pos="punct" start_char="7075">,</TOKEN>
<TOKEN end_char="7077" id="token-70-2" morph="none" pos="punct" start_char="7077">"</TOKEN>
<TOKEN end_char="7081" id="token-70-3" morph="none" pos="word" start_char="7078">What</TOKEN>
<TOKEN end_char="7084" id="token-70-4" morph="none" pos="word" start_char="7083">we</TOKEN>
<TOKEN end_char="7089" id="token-70-5" morph="none" pos="word" start_char="7086">know</TOKEN>
<TOKEN end_char="7095" id="token-70-6" morph="none" pos="word" start_char="7091">about</TOKEN>
<TOKEN end_char="7099" id="token-70-7" morph="none" pos="word" start_char="7097">the</TOKEN>
<TOKEN end_char="7106" id="token-70-8" morph="none" pos="word" start_char="7101">source</TOKEN>
<TOKEN end_char="7109" id="token-70-9" morph="none" pos="word" start_char="7108">of</TOKEN>
<TOKEN end_char="7113" id="token-70-10" morph="none" pos="word" start_char="7111">the</TOKEN>
<TOKEN end_char="7125" id="token-70-11" morph="none" pos="word" start_char="7115">coronavirus</TOKEN>
<TOKEN end_char="7134" id="token-70-12" morph="none" pos="word" start_char="7127">pandemic</TOKEN>
<TOKEN end_char="7136" id="token-70-13" morph="none" pos="punct" start_char="7135">,"</TOKEN>
<TOKEN end_char="7142" id="token-70-14" morph="none" pos="word" start_char="7138">April</TOKEN>
<TOKEN end_char="7145" id="token-70-15" morph="none" pos="word" start_char="7144">17</TOKEN>
<TOKEN end_char="7146" id="token-70-16" morph="none" pos="punct" start_char="7146">,</TOKEN>
<TOKEN end_char="7151" id="token-70-17" morph="none" pos="word" start_char="7148">2020</TOKEN>
</SEG>
<SEG end_char="7254" id="segment-71" start_char="7154">
<ORIGINAL_TEXT>Reuters, "Coronavirus very likely of animal origin, no sign of lab manipulation: WHO," April 21, 2020</ORIGINAL_TEXT>
<TOKEN end_char="7160" id="token-71-0" morph="none" pos="word" start_char="7154">Reuters</TOKEN>
<TOKEN end_char="7161" id="token-71-1" morph="none" pos="punct" start_char="7161">,</TOKEN>
<TOKEN end_char="7163" id="token-71-2" morph="none" pos="punct" start_char="7163">"</TOKEN>
<TOKEN end_char="7174" id="token-71-3" morph="none" pos="word" start_char="7164">Coronavirus</TOKEN>
<TOKEN end_char="7179" id="token-71-4" morph="none" pos="word" start_char="7176">very</TOKEN>
<TOKEN end_char="7186" id="token-71-5" morph="none" pos="word" start_char="7181">likely</TOKEN>
<TOKEN end_char="7189" id="token-71-6" morph="none" pos="word" start_char="7188">of</TOKEN>
<TOKEN end_char="7196" id="token-71-7" morph="none" pos="word" start_char="7191">animal</TOKEN>
<TOKEN end_char="7203" id="token-71-8" morph="none" pos="word" start_char="7198">origin</TOKEN>
<TOKEN end_char="7204" id="token-71-9" morph="none" pos="punct" start_char="7204">,</TOKEN>
<TOKEN end_char="7207" id="token-71-10" morph="none" pos="word" start_char="7206">no</TOKEN>
<TOKEN end_char="7212" id="token-71-11" morph="none" pos="word" start_char="7209">sign</TOKEN>
<TOKEN end_char="7215" id="token-71-12" morph="none" pos="word" start_char="7214">of</TOKEN>
<TOKEN end_char="7219" id="token-71-13" morph="none" pos="word" start_char="7217">lab</TOKEN>
<TOKEN end_char="7232" id="token-71-14" morph="none" pos="word" start_char="7221">manipulation</TOKEN>
<TOKEN end_char="7233" id="token-71-15" morph="none" pos="punct" start_char="7233">:</TOKEN>
<TOKEN end_char="7237" id="token-71-16" morph="none" pos="word" start_char="7235">WHO</TOKEN>
<TOKEN end_char="7239" id="token-71-17" morph="none" pos="punct" start_char="7238">,"</TOKEN>
<TOKEN end_char="7245" id="token-71-18" morph="none" pos="word" start_char="7241">April</TOKEN>
<TOKEN end_char="7248" id="token-71-19" morph="none" pos="word" start_char="7247">21</TOKEN>
<TOKEN end_char="7249" id="token-71-20" morph="none" pos="punct" start_char="7249">,</TOKEN>
<TOKEN end_char="7254" id="token-71-21" morph="none" pos="word" start_char="7251">2020</TOKEN>
</SEG>
<SEG end_char="7347" id="segment-72" start_char="7257">
<ORIGINAL_TEXT>Science Alert, "Here's How Scientists Know Coronavirus Wasn't Made in a Lab," July 17, 2020</ORIGINAL_TEXT>
<TOKEN end_char="7263" id="token-72-0" morph="none" pos="word" start_char="7257">Science</TOKEN>
<TOKEN end_char="7269" id="token-72-1" morph="none" pos="word" start_char="7265">Alert</TOKEN>
<TOKEN end_char="7270" id="token-72-2" morph="none" pos="punct" start_char="7270">,</TOKEN>
<TOKEN end_char="7272" id="token-72-3" morph="none" pos="punct" start_char="7272">"</TOKEN>
<TOKEN end_char="7278" id="token-72-4" morph="none" pos="word" start_char="7273">Here's</TOKEN>
<TOKEN end_char="7282" id="token-72-5" morph="none" pos="word" start_char="7280">How</TOKEN>
<TOKEN end_char="7293" id="token-72-6" morph="none" pos="word" start_char="7284">Scientists</TOKEN>
<TOKEN end_char="7298" id="token-72-7" morph="none" pos="word" start_char="7295">Know</TOKEN>
<TOKEN end_char="7310" id="token-72-8" morph="none" pos="word" start_char="7300">Coronavirus</TOKEN>
<TOKEN end_char="7317" id="token-72-9" morph="none" pos="word" start_char="7312">Wasn't</TOKEN>
<TOKEN end_char="7322" id="token-72-10" morph="none" pos="word" start_char="7319">Made</TOKEN>
<TOKEN end_char="7325" id="token-72-11" morph="none" pos="word" start_char="7324">in</TOKEN>
<TOKEN end_char="7327" id="token-72-12" morph="none" pos="word" start_char="7327">a</TOKEN>
<TOKEN end_char="7331" id="token-72-13" morph="none" pos="word" start_char="7329">Lab</TOKEN>
<TOKEN end_char="7333" id="token-72-14" morph="none" pos="punct" start_char="7332">,"</TOKEN>
<TOKEN end_char="7338" id="token-72-15" morph="none" pos="word" start_char="7335">July</TOKEN>
<TOKEN end_char="7341" id="token-72-16" morph="none" pos="word" start_char="7340">17</TOKEN>
<TOKEN end_char="7342" id="token-72-17" morph="none" pos="punct" start_char="7342">,</TOKEN>
<TOKEN end_char="7347" id="token-72-18" morph="none" pos="word" start_char="7344">2020</TOKEN>
</SEG>
<SEG end_char="7414" id="segment-73" start_char="7350">
<ORIGINAL_TEXT>Centers for Disease Control and Prevention, About COVID-19, Sept.</ORIGINAL_TEXT>
<TOKEN end_char="7356" id="token-73-0" morph="none" pos="word" start_char="7350">Centers</TOKEN>
<TOKEN end_char="7360" id="token-73-1" morph="none" pos="word" start_char="7358">for</TOKEN>
<TOKEN end_char="7368" id="token-73-2" morph="none" pos="word" start_char="7362">Disease</TOKEN>
<TOKEN end_char="7376" id="token-73-3" morph="none" pos="word" start_char="7370">Control</TOKEN>
<TOKEN end_char="7380" id="token-73-4" morph="none" pos="word" start_char="7378">and</TOKEN>
<TOKEN end_char="7391" id="token-73-5" morph="none" pos="word" start_char="7382">Prevention</TOKEN>
<TOKEN end_char="7392" id="token-73-6" morph="none" pos="punct" start_char="7392">,</TOKEN>
<TOKEN end_char="7398" id="token-73-7" morph="none" pos="word" start_char="7394">About</TOKEN>
<TOKEN end_char="7407" id="token-73-8" morph="none" pos="unknown" start_char="7400">COVID-19</TOKEN>
<TOKEN end_char="7408" id="token-73-9" morph="none" pos="punct" start_char="7408">,</TOKEN>
<TOKEN end_char="7413" id="token-73-10" morph="none" pos="word" start_char="7410">Sept</TOKEN>
<TOKEN end_char="7414" id="token-73-11" morph="none" pos="punct" start_char="7414">.</TOKEN>
</SEG>
<SEG end_char="7422" id="segment-74" start_char="7416">
<ORIGINAL_TEXT>1, 2020</ORIGINAL_TEXT>
<TOKEN end_char="7416" id="token-74-0" morph="none" pos="word" start_char="7416">1</TOKEN>
<TOKEN end_char="7417" id="token-74-1" morph="none" pos="punct" start_char="7417">,</TOKEN>
<TOKEN end_char="7422" id="token-74-2" morph="none" pos="word" start_char="7419">2020</TOKEN>
<TRANSLATED_TEXT>1.</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="7531" id="segment-75" start_char="7425">
<ORIGINAL_TEXT>National Geographic, "Fauci: No scientific evidence the coronavirus was made in a Chinese lab," May 4, 2020</ORIGINAL_TEXT>
<TOKEN end_char="7432" id="token-75-0" morph="none" pos="word" start_char="7425">National</TOKEN>
<TOKEN end_char="7443" id="token-75-1" morph="none" pos="word" start_char="7434">Geographic</TOKEN>
<TOKEN end_char="7444" id="token-75-2" morph="none" pos="punct" start_char="7444">,</TOKEN>
<TOKEN end_char="7446" id="token-75-3" morph="none" pos="punct" start_char="7446">"</TOKEN>
<TOKEN end_char="7451" id="token-75-4" morph="none" pos="word" start_char="7447">Fauci</TOKEN>
<TOKEN end_char="7452" id="token-75-5" morph="none" pos="punct" start_char="7452">:</TOKEN>
<TOKEN end_char="7455" id="token-75-6" morph="none" pos="word" start_char="7454">No</TOKEN>
<TOKEN end_char="7466" id="token-75-7" morph="none" pos="word" start_char="7457">scientific</TOKEN>
<TOKEN end_char="7475" id="token-75-8" morph="none" pos="word" start_char="7468">evidence</TOKEN>
<TOKEN end_char="7479" id="token-75-9" morph="none" pos="word" start_char="7477">the</TOKEN>
<TOKEN end_char="7491" id="token-75-10" morph="none" pos="word" start_char="7481">coronavirus</TOKEN>
<TOKEN end_char="7495" id="token-75-11" morph="none" pos="word" start_char="7493">was</TOKEN>
<TOKEN end_char="7500" id="token-75-12" morph="none" pos="word" start_char="7497">made</TOKEN>
<TOKEN end_char="7503" id="token-75-13" morph="none" pos="word" start_char="7502">in</TOKEN>
<TOKEN end_char="7505" id="token-75-14" morph="none" pos="word" start_char="7505">a</TOKEN>
<TOKEN end_char="7513" id="token-75-15" morph="none" pos="word" start_char="7507">Chinese</TOKEN>
<TOKEN end_char="7517" id="token-75-16" morph="none" pos="word" start_char="7515">lab</TOKEN>
<TOKEN end_char="7519" id="token-75-17" morph="none" pos="punct" start_char="7518">,"</TOKEN>
<TOKEN end_char="7523" id="token-75-18" morph="none" pos="word" start_char="7521">May</TOKEN>
<TOKEN end_char="7525" id="token-75-19" morph="none" pos="word" start_char="7525">4</TOKEN>
<TOKEN end_char="7526" id="token-75-20" morph="none" pos="punct" start_char="7526">,</TOKEN>
<TOKEN end_char="7531" id="token-75-21" morph="none" pos="word" start_char="7528">2020</TOKEN>
</SEG>
<SEG end_char="7623" id="segment-76" start_char="7534">
<ORIGINAL_TEXT>Vox, Why some labs work on making viruses deadlier — and why they should stop, May 1, 2020</ORIGINAL_TEXT>
<TOKEN end_char="7536" id="token-76-0" morph="none" pos="word" start_char="7534">Vox</TOKEN>
<TOKEN end_char="7537" id="token-76-1" morph="none" pos="punct" start_char="7537">,</TOKEN>
<TOKEN end_char="7541" id="token-76-2" morph="none" pos="word" start_char="7539">Why</TOKEN>
<TOKEN end_char="7546" id="token-76-3" morph="none" pos="word" start_char="7543">some</TOKEN>
<TOKEN end_char="7551" id="token-76-4" morph="none" pos="word" start_char="7548">labs</TOKEN>
<TOKEN end_char="7556" id="token-76-5" morph="none" pos="word" start_char="7553">work</TOKEN>
<TOKEN end_char="7559" id="token-76-6" morph="none" pos="word" start_char="7558">on</TOKEN>
<TOKEN end_char="7566" id="token-76-7" morph="none" pos="word" start_char="7561">making</TOKEN>
<TOKEN end_char="7574" id="token-76-8" morph="none" pos="word" start_char="7568">viruses</TOKEN>
<TOKEN end_char="7583" id="token-76-9" morph="none" pos="word" start_char="7576">deadlier</TOKEN>
<TOKEN end_char="7585" id="token-76-10" morph="none" pos="punct" start_char="7585">—</TOKEN>
<TOKEN end_char="7589" id="token-76-11" morph="none" pos="word" start_char="7587">and</TOKEN>
<TOKEN end_char="7593" id="token-76-12" morph="none" pos="word" start_char="7591">why</TOKEN>
<TOKEN end_char="7598" id="token-76-13" morph="none" pos="word" start_char="7595">they</TOKEN>
<TOKEN end_char="7605" id="token-76-14" morph="none" pos="word" start_char="7600">should</TOKEN>
<TOKEN end_char="7610" id="token-76-15" morph="none" pos="word" start_char="7607">stop</TOKEN>
<TOKEN end_char="7611" id="token-76-16" morph="none" pos="punct" start_char="7611">,</TOKEN>
<TOKEN end_char="7615" id="token-76-17" morph="none" pos="word" start_char="7613">May</TOKEN>
<TOKEN end_char="7617" id="token-76-18" morph="none" pos="word" start_char="7617">1</TOKEN>
<TOKEN end_char="7618" id="token-76-19" morph="none" pos="punct" start_char="7618">,</TOKEN>
<TOKEN end_char="7623" id="token-76-20" morph="none" pos="word" start_char="7620">2020</TOKEN>
</SEG>
<SEG end_char="7677" id="segment-77" start_char="7626">
<ORIGINAL_TEXT>Washington Post, A flu virus risk worth taking, Dec.</ORIGINAL_TEXT>
<TOKEN end_char="7635" id="token-77-0" morph="none" pos="word" start_char="7626">Washington</TOKEN>
<TOKEN end_char="7640" id="token-77-1" morph="none" pos="word" start_char="7637">Post</TOKEN>
<TOKEN end_char="7641" id="token-77-2" morph="none" pos="punct" start_char="7641">,</TOKEN>
<TOKEN end_char="7643" id="token-77-3" morph="none" pos="word" start_char="7643">A</TOKEN>
<TOKEN end_char="7647" id="token-77-4" morph="none" pos="word" start_char="7645">flu</TOKEN>
<TOKEN end_char="7653" id="token-77-5" morph="none" pos="word" start_char="7649">virus</TOKEN>
<TOKEN end_char="7658" id="token-77-6" morph="none" pos="word" start_char="7655">risk</TOKEN>
<TOKEN end_char="7664" id="token-77-7" morph="none" pos="word" start_char="7660">worth</TOKEN>
<TOKEN end_char="7671" id="token-77-8" morph="none" pos="word" start_char="7666">taking</TOKEN>
<TOKEN end_char="7672" id="token-77-9" morph="none" pos="punct" start_char="7672">,</TOKEN>
<TOKEN end_char="7676" id="token-77-10" morph="none" pos="word" start_char="7674">Dec</TOKEN>
<TOKEN end_char="7677" id="token-77-11" morph="none" pos="punct" start_char="7677">.</TOKEN>
</SEG>
<SEG end_char="7686" id="segment-78" start_char="7679">
<ORIGINAL_TEXT>30, 2011</ORIGINAL_TEXT>
<TOKEN end_char="7680" id="token-78-0" morph="none" pos="word" start_char="7679">30</TOKEN>
<TOKEN end_char="7681" id="token-78-1" morph="none" pos="punct" start_char="7681">,</TOKEN>
<TOKEN end_char="7686" id="token-78-2" morph="none" pos="word" start_char="7683">2011</TOKEN>
<TRANSLATED_TEXT>May 30, 2011</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="7856" id="segment-79" start_char="7689">
<ORIGINAL_TEXT>U.S. government gain-of-function deliberative process and research funding pause on selected gain-of-function research involving influenza, MERS, and SARS viruses, Oct.</ORIGINAL_TEXT>
<TOKEN end_char="7691" id="token-79-0" morph="none" pos="unknown" start_char="7689">U.S</TOKEN>
<TOKEN end_char="7692" id="token-79-1" morph="none" pos="punct" start_char="7692">.</TOKEN>
<TOKEN end_char="7703" id="token-79-2" morph="none" pos="word" start_char="7694">government</TOKEN>
<TOKEN end_char="7720" id="token-79-3" morph="none" pos="unknown" start_char="7705">gain-of-function</TOKEN>
<TOKEN end_char="7733" id="token-79-4" morph="none" pos="word" start_char="7722">deliberative</TOKEN>
<TOKEN end_char="7741" id="token-79-5" morph="none" pos="word" start_char="7735">process</TOKEN>
<TOKEN end_char="7745" id="token-79-6" morph="none" pos="word" start_char="7743">and</TOKEN>
<TOKEN end_char="7754" id="token-79-7" morph="none" pos="word" start_char="7747">research</TOKEN>
<TOKEN end_char="7762" id="token-79-8" morph="none" pos="word" start_char="7756">funding</TOKEN>
<TOKEN end_char="7768" id="token-79-9" morph="none" pos="word" start_char="7764">pause</TOKEN>
<TOKEN end_char="7771" id="token-79-10" morph="none" pos="word" start_char="7770">on</TOKEN>
<TOKEN end_char="7780" id="token-79-11" morph="none" pos="word" start_char="7773">selected</TOKEN>
<TOKEN end_char="7797" id="token-79-12" morph="none" pos="unknown" start_char="7782">gain-of-function</TOKEN>
<TOKEN end_char="7806" id="token-79-13" morph="none" pos="word" start_char="7799">research</TOKEN>
<TOKEN end_char="7816" id="token-79-14" morph="none" pos="word" start_char="7808">involving</TOKEN>
<TOKEN end_char="7826" id="token-79-15" morph="none" pos="word" start_char="7818">influenza</TOKEN>
<TOKEN end_char="7827" id="token-79-16" morph="none" pos="punct" start_char="7827">,</TOKEN>
<TOKEN end_char="7832" id="token-79-17" morph="none" pos="word" start_char="7829">MERS</TOKEN>
<TOKEN end_char="7833" id="token-79-18" morph="none" pos="punct" start_char="7833">,</TOKEN>
<TOKEN end_char="7837" id="token-79-19" morph="none" pos="word" start_char="7835">and</TOKEN>
<TOKEN end_char="7842" id="token-79-20" morph="none" pos="word" start_char="7839">SARS</TOKEN>
<TOKEN end_char="7850" id="token-79-21" morph="none" pos="word" start_char="7844">viruses</TOKEN>
<TOKEN end_char="7851" id="token-79-22" morph="none" pos="punct" start_char="7851">,</TOKEN>
<TOKEN end_char="7855" id="token-79-23" morph="none" pos="word" start_char="7853">Oct</TOKEN>
<TOKEN end_char="7856" id="token-79-24" morph="none" pos="punct" start_char="7856">.</TOKEN>
</SEG>
<SEG end_char="7865" id="segment-80" start_char="7858">
<ORIGINAL_TEXT>17, 2014</ORIGINAL_TEXT>
<TOKEN end_char="7859" id="token-80-0" morph="none" pos="word" start_char="7858">17</TOKEN>
<TOKEN end_char="7860" id="token-80-1" morph="none" pos="punct" start_char="7860">,</TOKEN>
<TOKEN end_char="7865" id="token-80-2" morph="none" pos="word" start_char="7862">2014</TOKEN>
<TRANSLATED_TEXT>17., 2014</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="8010" id="segment-81" start_char="7868">
<ORIGINAL_TEXT>Plos Pathogens, Discovery of a rich gene pool of bat SARS-related coronaviruses provides new insights into the origin of SARS coronavirus, Nov.</ORIGINAL_TEXT>
<TOKEN end_char="7871" id="token-81-0" morph="none" pos="word" start_char="7868">Plos</TOKEN>
<TOKEN end_char="7881" id="token-81-1" morph="none" pos="word" start_char="7873">Pathogens</TOKEN>
<TOKEN end_char="7882" id="token-81-2" morph="none" pos="punct" start_char="7882">,</TOKEN>
<TOKEN end_char="7892" id="token-81-3" morph="none" pos="word" start_char="7884">Discovery</TOKEN>
<TOKEN end_char="7895" id="token-81-4" morph="none" pos="word" start_char="7894">of</TOKEN>
<TOKEN end_char="7897" id="token-81-5" morph="none" pos="word" start_char="7897">a</TOKEN>
<TOKEN end_char="7902" id="token-81-6" morph="none" pos="word" start_char="7899">rich</TOKEN>
<TOKEN end_char="7907" id="token-81-7" morph="none" pos="word" start_char="7904">gene</TOKEN>
<TOKEN end_char="7912" id="token-81-8" morph="none" pos="word" start_char="7909">pool</TOKEN>
<TOKEN end_char="7915" id="token-81-9" morph="none" pos="word" start_char="7914">of</TOKEN>
<TOKEN end_char="7919" id="token-81-10" morph="none" pos="word" start_char="7917">bat</TOKEN>
<TOKEN end_char="7932" id="token-81-11" morph="none" pos="unknown" start_char="7921">SARS-related</TOKEN>
<TOKEN end_char="7946" id="token-81-12" morph="none" pos="word" start_char="7934">coronaviruses</TOKEN>
<TOKEN end_char="7955" id="token-81-13" morph="none" pos="word" start_char="7948">provides</TOKEN>
<TOKEN end_char="7959" id="token-81-14" morph="none" pos="word" start_char="7957">new</TOKEN>
<TOKEN end_char="7968" id="token-81-15" morph="none" pos="word" start_char="7961">insights</TOKEN>
<TOKEN end_char="7973" id="token-81-16" morph="none" pos="word" start_char="7970">into</TOKEN>
<TOKEN end_char="7977" id="token-81-17" morph="none" pos="word" start_char="7975">the</TOKEN>
<TOKEN end_char="7984" id="token-81-18" morph="none" pos="word" start_char="7979">origin</TOKEN>
<TOKEN end_char="7987" id="token-81-19" morph="none" pos="word" start_char="7986">of</TOKEN>
<TOKEN end_char="7992" id="token-81-20" morph="none" pos="word" start_char="7989">SARS</TOKEN>
<TOKEN end_char="8004" id="token-81-21" morph="none" pos="word" start_char="7994">coronavirus</TOKEN>
<TOKEN end_char="8005" id="token-81-22" morph="none" pos="punct" start_char="8005">,</TOKEN>
<TOKEN end_char="8009" id="token-81-23" morph="none" pos="word" start_char="8007">Nov</TOKEN>
<TOKEN end_char="8010" id="token-81-24" morph="none" pos="punct" start_char="8010">.</TOKEN>
</SEG>
<SEG end_char="8019" id="segment-82" start_char="8012">
<ORIGINAL_TEXT>30, 2017</ORIGINAL_TEXT>
<TOKEN end_char="8013" id="token-82-0" morph="none" pos="word" start_char="8012">30</TOKEN>
<TOKEN end_char="8014" id="token-82-1" morph="none" pos="punct" start_char="8014">,</TOKEN>
<TOKEN end_char="8019" id="token-82-2" morph="none" pos="word" start_char="8016">2017</TOKEN>
<TRANSLATED_TEXT>30., 2017</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="8091" id="segment-83" start_char="8022">
<ORIGINAL_TEXT>National Library of Medicine, NCBI SARS-CoV-2 Resources, accessed Feb.</ORIGINAL_TEXT>
<TOKEN end_char="8029" id="token-83-0" morph="none" pos="word" start_char="8022">National</TOKEN>
<TOKEN end_char="8037" id="token-83-1" morph="none" pos="word" start_char="8031">Library</TOKEN>
<TOKEN end_char="8040" id="token-83-2" morph="none" pos="word" start_char="8039">of</TOKEN>
<TOKEN end_char="8049" id="token-83-3" morph="none" pos="word" start_char="8042">Medicine</TOKEN>
<TOKEN end_char="8050" id="token-83-4" morph="none" pos="punct" start_char="8050">,</TOKEN>
<TOKEN end_char="8055" id="token-83-5" morph="none" pos="word" start_char="8052">NCBI</TOKEN>
<TOKEN end_char="8066" id="token-83-6" morph="none" pos="unknown" start_char="8057">SARS-CoV-2</TOKEN>
<TOKEN end_char="8076" id="token-83-7" morph="none" pos="word" start_char="8068">Resources</TOKEN>
<TOKEN end_char="8077" id="token-83-8" morph="none" pos="punct" start_char="8077">,</TOKEN>
<TOKEN end_char="8086" id="token-83-9" morph="none" pos="word" start_char="8079">accessed</TOKEN>
<TOKEN end_char="8090" id="token-83-10" morph="none" pos="word" start_char="8088">Feb</TOKEN>
<TOKEN end_char="8091" id="token-83-11" morph="none" pos="punct" start_char="8091">.</TOKEN>
</SEG>
<SEG end_char="8099" id="segment-84" start_char="8093">
<ORIGINAL_TEXT>4, 2021</ORIGINAL_TEXT>
<TOKEN end_char="8093" id="token-84-0" morph="none" pos="word" start_char="8093">4</TOKEN>
<TOKEN end_char="8094" id="token-84-1" morph="none" pos="punct" start_char="8094">,</TOKEN>
<TOKEN end_char="8099" id="token-84-2" morph="none" pos="word" start_char="8096">2021</TOKEN>
<TRANSLATED_TEXT>4.2021</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="8242" id="segment-85" start_char="8102">
<ORIGINAL_TEXT>The Lancet, Statement in support of the scientists, public health professionals, and medical professionals of China combatting COVID-19, Feb.</ORIGINAL_TEXT>
<TOKEN end_char="8104" id="token-85-0" morph="none" pos="word" start_char="8102">The</TOKEN>
<TOKEN end_char="8111" id="token-85-1" morph="none" pos="word" start_char="8106">Lancet</TOKEN>
<TOKEN end_char="8112" id="token-85-2" morph="none" pos="punct" start_char="8112">,</TOKEN>
<TOKEN end_char="8122" id="token-85-3" morph="none" pos="word" start_char="8114">Statement</TOKEN>
<TOKEN end_char="8125" id="token-85-4" morph="none" pos="word" start_char="8124">in</TOKEN>
<TOKEN end_char="8133" id="token-85-5" morph="none" pos="word" start_char="8127">support</TOKEN>
<TOKEN end_char="8136" id="token-85-6" morph="none" pos="word" start_char="8135">of</TOKEN>
<TOKEN end_char="8140" id="token-85-7" morph="none" pos="word" start_char="8138">the</TOKEN>
<TOKEN end_char="8151" id="token-85-8" morph="none" pos="word" start_char="8142">scientists</TOKEN>
<TOKEN end_char="8152" id="token-85-9" morph="none" pos="punct" start_char="8152">,</TOKEN>
<TOKEN end_char="8159" id="token-85-10" morph="none" pos="word" start_char="8154">public</TOKEN>
<TOKEN end_char="8166" id="token-85-11" morph="none" pos="word" start_char="8161">health</TOKEN>
<TOKEN end_char="8180" id="token-85-12" morph="none" pos="word" start_char="8168">professionals</TOKEN>
<TOKEN end_char="8181" id="token-85-13" morph="none" pos="punct" start_char="8181">,</TOKEN>
<TOKEN end_char="8185" id="token-85-14" morph="none" pos="word" start_char="8183">and</TOKEN>
<TOKEN end_char="8193" id="token-85-15" morph="none" pos="word" start_char="8187">medical</TOKEN>
<TOKEN end_char="8207" id="token-85-16" morph="none" pos="word" start_char="8195">professionals</TOKEN>
<TOKEN end_char="8210" id="token-85-17" morph="none" pos="word" start_char="8209">of</TOKEN>
<TOKEN end_char="8216" id="token-85-18" morph="none" pos="word" start_char="8212">China</TOKEN>
<TOKEN end_char="8227" id="token-85-19" morph="none" pos="word" start_char="8218">combatting</TOKEN>
<TOKEN end_char="8236" id="token-85-20" morph="none" pos="unknown" start_char="8229">COVID-19</TOKEN>
<TOKEN end_char="8237" id="token-85-21" morph="none" pos="punct" start_char="8237">,</TOKEN>
<TOKEN end_char="8241" id="token-85-22" morph="none" pos="word" start_char="8239">Feb</TOKEN>
<TOKEN end_char="8242" id="token-85-23" morph="none" pos="punct" start_char="8242">.</TOKEN>
</SEG>
<SEG end_char="8251" id="segment-86" start_char="8244">
<ORIGINAL_TEXT>19, 2020</ORIGINAL_TEXT>
<TOKEN end_char="8245" id="token-86-0" morph="none" pos="word" start_char="8244">19</TOKEN>
<TOKEN end_char="8246" id="token-86-1" morph="none" pos="punct" start_char="8246">,</TOKEN>
<TOKEN end_char="8251" id="token-86-2" morph="none" pos="word" start_char="8248">2020</TOKEN>
<TRANSLATED_TEXT>19., 2020.</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="8312" id="segment-87" start_char="8254">
<ORIGINAL_TEXT>Nature, "The proximal origin of SARS-CoV-2," March 17, 2020</ORIGINAL_TEXT>
<TOKEN end_char="8259" id="token-87-0" morph="none" pos="word" start_char="8254">Nature</TOKEN>
<TOKEN end_char="8260" id="token-87-1" morph="none" pos="punct" start_char="8260">,</TOKEN>
<TOKEN end_char="8262" id="token-87-2" morph="none" pos="punct" start_char="8262">"</TOKEN>
<TOKEN end_char="8265" id="token-87-3" morph="none" pos="word" start_char="8263">The</TOKEN>
<TOKEN end_char="8274" id="token-87-4" morph="none" pos="word" start_char="8267">proximal</TOKEN>
<TOKEN end_char="8281" id="token-87-5" morph="none" pos="word" start_char="8276">origin</TOKEN>
<TOKEN end_char="8284" id="token-87-6" morph="none" pos="word" start_char="8283">of</TOKEN>
<TOKEN end_char="8295" id="token-87-7" morph="none" pos="unknown" start_char="8286">SARS-CoV-2</TOKEN>
<TOKEN end_char="8297" id="token-87-8" morph="none" pos="punct" start_char="8296">,"</TOKEN>
<TOKEN end_char="8303" id="token-87-9" morph="none" pos="word" start_char="8299">March</TOKEN>
<TOKEN end_char="8306" id="token-87-10" morph="none" pos="word" start_char="8305">17</TOKEN>
<TOKEN end_char="8307" id="token-87-11" morph="none" pos="punct" start_char="8307">,</TOKEN>
<TOKEN end_char="8312" id="token-87-12" morph="none" pos="word" start_char="8309">2020</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
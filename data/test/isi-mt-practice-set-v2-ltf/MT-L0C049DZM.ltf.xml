<LCTL_TEXT lang="eng">
<DOC grammar="none" id="L0C049DZM" lang="eng" raw_text_char_length="2947" raw_text_md5="84c9f2fe3f4dd413e65f4a9598cfda12" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="76" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Experts: Accusation that Covid-19 virus originates in lab is false and wrong</ORIGINAL_TEXT>
<TOKEN end_char="7" id="token-0-0" morph="none" pos="word" start_char="1">Experts</TOKEN>
<TOKEN end_char="8" id="token-0-1" morph="none" pos="punct" start_char="8">:</TOKEN>
<TOKEN end_char="19" id="token-0-2" morph="none" pos="word" start_char="10">Accusation</TOKEN>
<TOKEN end_char="24" id="token-0-3" morph="none" pos="word" start_char="21">that</TOKEN>
<TOKEN end_char="33" id="token-0-4" morph="none" pos="unknown" start_char="26">Covid-19</TOKEN>
<TOKEN end_char="39" id="token-0-5" morph="none" pos="word" start_char="35">virus</TOKEN>
<TOKEN end_char="50" id="token-0-6" morph="none" pos="word" start_char="41">originates</TOKEN>
<TOKEN end_char="53" id="token-0-7" morph="none" pos="word" start_char="52">in</TOKEN>
<TOKEN end_char="57" id="token-0-8" morph="none" pos="word" start_char="55">lab</TOKEN>
<TOKEN end_char="60" id="token-0-9" morph="none" pos="word" start_char="59">is</TOKEN>
<TOKEN end_char="66" id="token-0-10" morph="none" pos="word" start_char="62">false</TOKEN>
<TOKEN end_char="70" id="token-0-11" morph="none" pos="word" start_char="68">and</TOKEN>
<TOKEN end_char="76" id="token-0-12" morph="none" pos="word" start_char="72">wrong</TOKEN>
</SEG>
<SEG end_char="102" id="segment-1" start_char="80">
<ORIGINAL_TEXT>file79kl6b2jn4hhgvz3aa1</ORIGINAL_TEXT>
<TOKEN end_char="102" id="token-1-0" morph="none" pos="word" start_char="80">file79kl6b2jn4hhgvz3aa1</TOKEN>
<TRANSLATED_TEXT>File 79kl6b2jn4hhgvz3aa1</TRANSLATED_TEXT><DETECTED_LANGUAGE>et</DETECTED_LANGUAGE></SEG>
<SEG end_char="315" id="segment-2" start_char="106">
<ORIGINAL_TEXT>BEIJING: The accusations that the Covid-19 (coronavirus) outbreak causing the pandemic was created in the laboratory or in a laboratory in China's Wuhan are false and wrong, several French scientists have said.</ORIGINAL_TEXT>
<TOKEN end_char="112" id="token-2-0" morph="none" pos="word" start_char="106">BEIJING</TOKEN>
<TOKEN end_char="113" id="token-2-1" morph="none" pos="punct" start_char="113">:</TOKEN>
<TOKEN end_char="117" id="token-2-2" morph="none" pos="word" start_char="115">The</TOKEN>
<TOKEN end_char="129" id="token-2-3" morph="none" pos="word" start_char="119">accusations</TOKEN>
<TOKEN end_char="134" id="token-2-4" morph="none" pos="word" start_char="131">that</TOKEN>
<TOKEN end_char="138" id="token-2-5" morph="none" pos="word" start_char="136">the</TOKEN>
<TOKEN end_char="147" id="token-2-6" morph="none" pos="unknown" start_char="140">Covid-19</TOKEN>
<TOKEN end_char="149" id="token-2-7" morph="none" pos="punct" start_char="149">(</TOKEN>
<TOKEN end_char="160" id="token-2-8" morph="none" pos="word" start_char="150">coronavirus</TOKEN>
<TOKEN end_char="161" id="token-2-9" morph="none" pos="punct" start_char="161">)</TOKEN>
<TOKEN end_char="170" id="token-2-10" morph="none" pos="word" start_char="163">outbreak</TOKEN>
<TOKEN end_char="178" id="token-2-11" morph="none" pos="word" start_char="172">causing</TOKEN>
<TOKEN end_char="182" id="token-2-12" morph="none" pos="word" start_char="180">the</TOKEN>
<TOKEN end_char="191" id="token-2-13" morph="none" pos="word" start_char="184">pandemic</TOKEN>
<TOKEN end_char="195" id="token-2-14" morph="none" pos="word" start_char="193">was</TOKEN>
<TOKEN end_char="203" id="token-2-15" morph="none" pos="word" start_char="197">created</TOKEN>
<TOKEN end_char="206" id="token-2-16" morph="none" pos="word" start_char="205">in</TOKEN>
<TOKEN end_char="210" id="token-2-17" morph="none" pos="word" start_char="208">the</TOKEN>
<TOKEN end_char="221" id="token-2-18" morph="none" pos="word" start_char="212">laboratory</TOKEN>
<TOKEN end_char="224" id="token-2-19" morph="none" pos="word" start_char="223">or</TOKEN>
<TOKEN end_char="227" id="token-2-20" morph="none" pos="word" start_char="226">in</TOKEN>
<TOKEN end_char="229" id="token-2-21" morph="none" pos="word" start_char="229">a</TOKEN>
<TOKEN end_char="240" id="token-2-22" morph="none" pos="word" start_char="231">laboratory</TOKEN>
<TOKEN end_char="243" id="token-2-23" morph="none" pos="word" start_char="242">in</TOKEN>
<TOKEN end_char="251" id="token-2-24" morph="none" pos="word" start_char="245">China's</TOKEN>
<TOKEN end_char="257" id="token-2-25" morph="none" pos="word" start_char="253">Wuhan</TOKEN>
<TOKEN end_char="261" id="token-2-26" morph="none" pos="word" start_char="259">are</TOKEN>
<TOKEN end_char="267" id="token-2-27" morph="none" pos="word" start_char="263">false</TOKEN>
<TOKEN end_char="271" id="token-2-28" morph="none" pos="word" start_char="269">and</TOKEN>
<TOKEN end_char="277" id="token-2-29" morph="none" pos="word" start_char="273">wrong</TOKEN>
<TOKEN end_char="278" id="token-2-30" morph="none" pos="punct" start_char="278">,</TOKEN>
<TOKEN end_char="286" id="token-2-31" morph="none" pos="word" start_char="280">several</TOKEN>
<TOKEN end_char="293" id="token-2-32" morph="none" pos="word" start_char="288">French</TOKEN>
<TOKEN end_char="304" id="token-2-33" morph="none" pos="word" start_char="295">scientists</TOKEN>
<TOKEN end_char="309" id="token-2-34" morph="none" pos="word" start_char="306">have</TOKEN>
<TOKEN end_char="314" id="token-2-35" morph="none" pos="word" start_char="311">said</TOKEN>
<TOKEN end_char="315" id="token-2-36" morph="none" pos="punct" start_char="315">.</TOKEN>
</SEG>
<SEG end_char="593" id="segment-3" start_char="318">
<ORIGINAL_TEXT>Driven by a malicious intention of scapegoating China to cover up the lax US response to Covid-19, US Secretary of State Mike Pompeo has been repeatedly calling the novel coronavirus "Chinese virus" or "Wuhan virus" in public, largely accountable for the virus disinformation.</ORIGINAL_TEXT>
<TOKEN end_char="323" id="token-3-0" morph="none" pos="word" start_char="318">Driven</TOKEN>
<TOKEN end_char="326" id="token-3-1" morph="none" pos="word" start_char="325">by</TOKEN>
<TOKEN end_char="328" id="token-3-2" morph="none" pos="word" start_char="328">a</TOKEN>
<TOKEN end_char="338" id="token-3-3" morph="none" pos="word" start_char="330">malicious</TOKEN>
<TOKEN end_char="348" id="token-3-4" morph="none" pos="word" start_char="340">intention</TOKEN>
<TOKEN end_char="351" id="token-3-5" morph="none" pos="word" start_char="350">of</TOKEN>
<TOKEN end_char="364" id="token-3-6" morph="none" pos="word" start_char="353">scapegoating</TOKEN>
<TOKEN end_char="370" id="token-3-7" morph="none" pos="word" start_char="366">China</TOKEN>
<TOKEN end_char="373" id="token-3-8" morph="none" pos="word" start_char="372">to</TOKEN>
<TOKEN end_char="379" id="token-3-9" morph="none" pos="word" start_char="375">cover</TOKEN>
<TOKEN end_char="382" id="token-3-10" morph="none" pos="word" start_char="381">up</TOKEN>
<TOKEN end_char="386" id="token-3-11" morph="none" pos="word" start_char="384">the</TOKEN>
<TOKEN end_char="390" id="token-3-12" morph="none" pos="word" start_char="388">lax</TOKEN>
<TOKEN end_char="393" id="token-3-13" morph="none" pos="word" start_char="392">US</TOKEN>
<TOKEN end_char="402" id="token-3-14" morph="none" pos="word" start_char="395">response</TOKEN>
<TOKEN end_char="405" id="token-3-15" morph="none" pos="word" start_char="404">to</TOKEN>
<TOKEN end_char="414" id="token-3-16" morph="none" pos="unknown" start_char="407">Covid-19</TOKEN>
<TOKEN end_char="415" id="token-3-17" morph="none" pos="punct" start_char="415">,</TOKEN>
<TOKEN end_char="418" id="token-3-18" morph="none" pos="word" start_char="417">US</TOKEN>
<TOKEN end_char="428" id="token-3-19" morph="none" pos="word" start_char="420">Secretary</TOKEN>
<TOKEN end_char="431" id="token-3-20" morph="none" pos="word" start_char="430">of</TOKEN>
<TOKEN end_char="437" id="token-3-21" morph="none" pos="word" start_char="433">State</TOKEN>
<TOKEN end_char="442" id="token-3-22" morph="none" pos="word" start_char="439">Mike</TOKEN>
<TOKEN end_char="449" id="token-3-23" morph="none" pos="word" start_char="444">Pompeo</TOKEN>
<TOKEN end_char="453" id="token-3-24" morph="none" pos="word" start_char="451">has</TOKEN>
<TOKEN end_char="458" id="token-3-25" morph="none" pos="word" start_char="455">been</TOKEN>
<TOKEN end_char="469" id="token-3-26" morph="none" pos="word" start_char="460">repeatedly</TOKEN>
<TOKEN end_char="477" id="token-3-27" morph="none" pos="word" start_char="471">calling</TOKEN>
<TOKEN end_char="481" id="token-3-28" morph="none" pos="word" start_char="479">the</TOKEN>
<TOKEN end_char="487" id="token-3-29" morph="none" pos="word" start_char="483">novel</TOKEN>
<TOKEN end_char="499" id="token-3-30" morph="none" pos="word" start_char="489">coronavirus</TOKEN>
<TOKEN end_char="501" id="token-3-31" morph="none" pos="punct" start_char="501">"</TOKEN>
<TOKEN end_char="508" id="token-3-32" morph="none" pos="word" start_char="502">Chinese</TOKEN>
<TOKEN end_char="514" id="token-3-33" morph="none" pos="word" start_char="510">virus</TOKEN>
<TOKEN end_char="515" id="token-3-34" morph="none" pos="punct" start_char="515">"</TOKEN>
<TOKEN end_char="518" id="token-3-35" morph="none" pos="word" start_char="517">or</TOKEN>
<TOKEN end_char="520" id="token-3-36" morph="none" pos="punct" start_char="520">"</TOKEN>
<TOKEN end_char="525" id="token-3-37" morph="none" pos="word" start_char="521">Wuhan</TOKEN>
<TOKEN end_char="531" id="token-3-38" morph="none" pos="word" start_char="527">virus</TOKEN>
<TOKEN end_char="532" id="token-3-39" morph="none" pos="punct" start_char="532">"</TOKEN>
<TOKEN end_char="535" id="token-3-40" morph="none" pos="word" start_char="534">in</TOKEN>
<TOKEN end_char="542" id="token-3-41" morph="none" pos="word" start_char="537">public</TOKEN>
<TOKEN end_char="543" id="token-3-42" morph="none" pos="punct" start_char="543">,</TOKEN>
<TOKEN end_char="551" id="token-3-43" morph="none" pos="word" start_char="545">largely</TOKEN>
<TOKEN end_char="563" id="token-3-44" morph="none" pos="word" start_char="553">accountable</TOKEN>
<TOKEN end_char="567" id="token-3-45" morph="none" pos="word" start_char="565">for</TOKEN>
<TOKEN end_char="571" id="token-3-46" morph="none" pos="word" start_char="569">the</TOKEN>
<TOKEN end_char="577" id="token-3-47" morph="none" pos="word" start_char="573">virus</TOKEN>
<TOKEN end_char="592" id="token-3-48" morph="none" pos="word" start_char="579">disinformation</TOKEN>
<TOKEN end_char="593" id="token-3-49" morph="none" pos="punct" start_char="593">.</TOKEN>
</SEG>
<SEG end_char="719" id="segment-4" start_char="596">
<ORIGINAL_TEXT>"What we do know is we know that this virus originated in Wuhan, China," said Pompeo in a comment requested by the Fox News.</ORIGINAL_TEXT>
<TOKEN end_char="596" id="token-4-0" morph="none" pos="punct" start_char="596">"</TOKEN>
<TOKEN end_char="600" id="token-4-1" morph="none" pos="word" start_char="597">What</TOKEN>
<TOKEN end_char="603" id="token-4-2" morph="none" pos="word" start_char="602">we</TOKEN>
<TOKEN end_char="606" id="token-4-3" morph="none" pos="word" start_char="605">do</TOKEN>
<TOKEN end_char="611" id="token-4-4" morph="none" pos="word" start_char="608">know</TOKEN>
<TOKEN end_char="614" id="token-4-5" morph="none" pos="word" start_char="613">is</TOKEN>
<TOKEN end_char="617" id="token-4-6" morph="none" pos="word" start_char="616">we</TOKEN>
<TOKEN end_char="622" id="token-4-7" morph="none" pos="word" start_char="619">know</TOKEN>
<TOKEN end_char="627" id="token-4-8" morph="none" pos="word" start_char="624">that</TOKEN>
<TOKEN end_char="632" id="token-4-9" morph="none" pos="word" start_char="629">this</TOKEN>
<TOKEN end_char="638" id="token-4-10" morph="none" pos="word" start_char="634">virus</TOKEN>
<TOKEN end_char="649" id="token-4-11" morph="none" pos="word" start_char="640">originated</TOKEN>
<TOKEN end_char="652" id="token-4-12" morph="none" pos="word" start_char="651">in</TOKEN>
<TOKEN end_char="658" id="token-4-13" morph="none" pos="word" start_char="654">Wuhan</TOKEN>
<TOKEN end_char="659" id="token-4-14" morph="none" pos="punct" start_char="659">,</TOKEN>
<TOKEN end_char="665" id="token-4-15" morph="none" pos="word" start_char="661">China</TOKEN>
<TOKEN end_char="667" id="token-4-16" morph="none" pos="punct" start_char="666">,"</TOKEN>
<TOKEN end_char="672" id="token-4-17" morph="none" pos="word" start_char="669">said</TOKEN>
<TOKEN end_char="679" id="token-4-18" morph="none" pos="word" start_char="674">Pompeo</TOKEN>
<TOKEN end_char="682" id="token-4-19" morph="none" pos="word" start_char="681">in</TOKEN>
<TOKEN end_char="684" id="token-4-20" morph="none" pos="word" start_char="684">a</TOKEN>
<TOKEN end_char="692" id="token-4-21" morph="none" pos="word" start_char="686">comment</TOKEN>
<TOKEN end_char="702" id="token-4-22" morph="none" pos="word" start_char="694">requested</TOKEN>
<TOKEN end_char="705" id="token-4-23" morph="none" pos="word" start_char="704">by</TOKEN>
<TOKEN end_char="709" id="token-4-24" morph="none" pos="word" start_char="707">the</TOKEN>
<TOKEN end_char="713" id="token-4-25" morph="none" pos="word" start_char="711">Fox</TOKEN>
<TOKEN end_char="718" id="token-4-26" morph="none" pos="word" start_char="715">News</TOKEN>
<TOKEN end_char="719" id="token-4-27" morph="none" pos="punct" start_char="719">.</TOKEN>
</SEG>
<SEG end_char="779" id="segment-5" start_char="721">
<ORIGINAL_TEXT>"The US government is working diligently to figure it out."</ORIGINAL_TEXT>
<TOKEN end_char="721" id="token-5-0" morph="none" pos="punct" start_char="721">"</TOKEN>
<TOKEN end_char="724" id="token-5-1" morph="none" pos="word" start_char="722">The</TOKEN>
<TOKEN end_char="727" id="token-5-2" morph="none" pos="word" start_char="726">US</TOKEN>
<TOKEN end_char="738" id="token-5-3" morph="none" pos="word" start_char="729">government</TOKEN>
<TOKEN end_char="741" id="token-5-4" morph="none" pos="word" start_char="740">is</TOKEN>
<TOKEN end_char="749" id="token-5-5" morph="none" pos="word" start_char="743">working</TOKEN>
<TOKEN end_char="760" id="token-5-6" morph="none" pos="word" start_char="751">diligently</TOKEN>
<TOKEN end_char="763" id="token-5-7" morph="none" pos="word" start_char="762">to</TOKEN>
<TOKEN end_char="770" id="token-5-8" morph="none" pos="word" start_char="765">figure</TOKEN>
<TOKEN end_char="773" id="token-5-9" morph="none" pos="word" start_char="772">it</TOKEN>
<TOKEN end_char="777" id="token-5-10" morph="none" pos="word" start_char="775">out</TOKEN>
<TOKEN end_char="779" id="token-5-11" morph="none" pos="punct" start_char="778">."</TOKEN>
</SEG>
<SEG end_char="924" id="segment-6" start_char="782">
<ORIGINAL_TEXT>Luc Montagnier, a French Nobel prize winning virologist in 2008, told French media last week that "there was manipulation around this virus ...</ORIGINAL_TEXT>
<TOKEN end_char="784" id="token-6-0" morph="none" pos="word" start_char="782">Luc</TOKEN>
<TOKEN end_char="795" id="token-6-1" morph="none" pos="word" start_char="786">Montagnier</TOKEN>
<TOKEN end_char="796" id="token-6-2" morph="none" pos="punct" start_char="796">,</TOKEN>
<TOKEN end_char="798" id="token-6-3" morph="none" pos="word" start_char="798">a</TOKEN>
<TOKEN end_char="805" id="token-6-4" morph="none" pos="word" start_char="800">French</TOKEN>
<TOKEN end_char="811" id="token-6-5" morph="none" pos="word" start_char="807">Nobel</TOKEN>
<TOKEN end_char="817" id="token-6-6" morph="none" pos="word" start_char="813">prize</TOKEN>
<TOKEN end_char="825" id="token-6-7" morph="none" pos="word" start_char="819">winning</TOKEN>
<TOKEN end_char="836" id="token-6-8" morph="none" pos="word" start_char="827">virologist</TOKEN>
<TOKEN end_char="839" id="token-6-9" morph="none" pos="word" start_char="838">in</TOKEN>
<TOKEN end_char="844" id="token-6-10" morph="none" pos="word" start_char="841">2008</TOKEN>
<TOKEN end_char="845" id="token-6-11" morph="none" pos="punct" start_char="845">,</TOKEN>
<TOKEN end_char="850" id="token-6-12" morph="none" pos="word" start_char="847">told</TOKEN>
<TOKEN end_char="857" id="token-6-13" morph="none" pos="word" start_char="852">French</TOKEN>
<TOKEN end_char="863" id="token-6-14" morph="none" pos="word" start_char="859">media</TOKEN>
<TOKEN end_char="868" id="token-6-15" morph="none" pos="word" start_char="865">last</TOKEN>
<TOKEN end_char="873" id="token-6-16" morph="none" pos="word" start_char="870">week</TOKEN>
<TOKEN end_char="878" id="token-6-17" morph="none" pos="word" start_char="875">that</TOKEN>
<TOKEN end_char="880" id="token-6-18" morph="none" pos="punct" start_char="880">"</TOKEN>
<TOKEN end_char="885" id="token-6-19" morph="none" pos="word" start_char="881">there</TOKEN>
<TOKEN end_char="889" id="token-6-20" morph="none" pos="word" start_char="887">was</TOKEN>
<TOKEN end_char="902" id="token-6-21" morph="none" pos="word" start_char="891">manipulation</TOKEN>
<TOKEN end_char="909" id="token-6-22" morph="none" pos="word" start_char="904">around</TOKEN>
<TOKEN end_char="914" id="token-6-23" morph="none" pos="word" start_char="911">this</TOKEN>
<TOKEN end_char="920" id="token-6-24" morph="none" pos="word" start_char="916">virus</TOKEN>
<TOKEN end_char="924" id="token-6-25" morph="none" pos="punct" start_char="922">...</TOKEN>
</SEG>
<SEG end_char="943" id="segment-7" start_char="926">
<ORIGINAL_TEXT>It is not natural.</ORIGINAL_TEXT>
<TOKEN end_char="927" id="token-7-0" morph="none" pos="word" start_char="926">It</TOKEN>
<TOKEN end_char="930" id="token-7-1" morph="none" pos="word" start_char="929">is</TOKEN>
<TOKEN end_char="934" id="token-7-2" morph="none" pos="word" start_char="932">not</TOKEN>
<TOKEN end_char="942" id="token-7-3" morph="none" pos="word" start_char="936">natural</TOKEN>
<TOKEN end_char="943" id="token-7-4" morph="none" pos="punct" start_char="943">.</TOKEN>
<TRANSLATED_TEXT>Det er ikke naturlig.</TRANSLATED_TEXT><DETECTED_LANGUAGE>tl</DETECTED_LANGUAGE></SEG>
<SEG end_char="1001" id="segment-8" start_char="945">
<ORIGINAL_TEXT>It's the work of professionals, of molecular biologists."</ORIGINAL_TEXT>
<TOKEN end_char="948" id="token-8-0" morph="none" pos="word" start_char="945">It's</TOKEN>
<TOKEN end_char="952" id="token-8-1" morph="none" pos="word" start_char="950">the</TOKEN>
<TOKEN end_char="957" id="token-8-2" morph="none" pos="word" start_char="954">work</TOKEN>
<TOKEN end_char="960" id="token-8-3" morph="none" pos="word" start_char="959">of</TOKEN>
<TOKEN end_char="974" id="token-8-4" morph="none" pos="word" start_char="962">professionals</TOKEN>
<TOKEN end_char="975" id="token-8-5" morph="none" pos="punct" start_char="975">,</TOKEN>
<TOKEN end_char="978" id="token-8-6" morph="none" pos="word" start_char="977">of</TOKEN>
<TOKEN end_char="988" id="token-8-7" morph="none" pos="word" start_char="980">molecular</TOKEN>
<TOKEN end_char="999" id="token-8-8" morph="none" pos="word" start_char="990">biologists</TOKEN>
<TOKEN end_char="1001" id="token-8-9" morph="none" pos="punct" start_char="1000">."</TOKEN>
</SEG>
<SEG end_char="1090" id="segment-9" start_char="1004">
<ORIGINAL_TEXT>In response, several French scientists have recently refuted the remarks by Montagnier.</ORIGINAL_TEXT>
<TOKEN end_char="1005" id="token-9-0" morph="none" pos="word" start_char="1004">In</TOKEN>
<TOKEN end_char="1014" id="token-9-1" morph="none" pos="word" start_char="1007">response</TOKEN>
<TOKEN end_char="1015" id="token-9-2" morph="none" pos="punct" start_char="1015">,</TOKEN>
<TOKEN end_char="1023" id="token-9-3" morph="none" pos="word" start_char="1017">several</TOKEN>
<TOKEN end_char="1030" id="token-9-4" morph="none" pos="word" start_char="1025">French</TOKEN>
<TOKEN end_char="1041" id="token-9-5" morph="none" pos="word" start_char="1032">scientists</TOKEN>
<TOKEN end_char="1046" id="token-9-6" morph="none" pos="word" start_char="1043">have</TOKEN>
<TOKEN end_char="1055" id="token-9-7" morph="none" pos="word" start_char="1048">recently</TOKEN>
<TOKEN end_char="1063" id="token-9-8" morph="none" pos="word" start_char="1057">refuted</TOKEN>
<TOKEN end_char="1067" id="token-9-9" morph="none" pos="word" start_char="1065">the</TOKEN>
<TOKEN end_char="1075" id="token-9-10" morph="none" pos="word" start_char="1069">remarks</TOKEN>
<TOKEN end_char="1078" id="token-9-11" morph="none" pos="word" start_char="1077">by</TOKEN>
<TOKEN end_char="1089" id="token-9-12" morph="none" pos="word" start_char="1080">Montagnier</TOKEN>
<TOKEN end_char="1090" id="token-9-13" morph="none" pos="punct" start_char="1090">.</TOKEN>
</SEG>
<SEG end_char="1410" id="segment-10" start_char="1093">
<ORIGINAL_TEXT>The hypothesis that a virus was created in a lab in Wuhan sounded "a conspiracy vision that does not relate to the real science," said Jean-Francois Delfraissy, an immunologist and head of the scientific council that advises the French government on the Covid-19 pandemic, when interviewed by French television BFM TV.</ORIGINAL_TEXT>
<TOKEN end_char="1095" id="token-10-0" morph="none" pos="word" start_char="1093">The</TOKEN>
<TOKEN end_char="1106" id="token-10-1" morph="none" pos="word" start_char="1097">hypothesis</TOKEN>
<TOKEN end_char="1111" id="token-10-2" morph="none" pos="word" start_char="1108">that</TOKEN>
<TOKEN end_char="1113" id="token-10-3" morph="none" pos="word" start_char="1113">a</TOKEN>
<TOKEN end_char="1119" id="token-10-4" morph="none" pos="word" start_char="1115">virus</TOKEN>
<TOKEN end_char="1123" id="token-10-5" morph="none" pos="word" start_char="1121">was</TOKEN>
<TOKEN end_char="1131" id="token-10-6" morph="none" pos="word" start_char="1125">created</TOKEN>
<TOKEN end_char="1134" id="token-10-7" morph="none" pos="word" start_char="1133">in</TOKEN>
<TOKEN end_char="1136" id="token-10-8" morph="none" pos="word" start_char="1136">a</TOKEN>
<TOKEN end_char="1140" id="token-10-9" morph="none" pos="word" start_char="1138">lab</TOKEN>
<TOKEN end_char="1143" id="token-10-10" morph="none" pos="word" start_char="1142">in</TOKEN>
<TOKEN end_char="1149" id="token-10-11" morph="none" pos="word" start_char="1145">Wuhan</TOKEN>
<TOKEN end_char="1157" id="token-10-12" morph="none" pos="word" start_char="1151">sounded</TOKEN>
<TOKEN end_char="1159" id="token-10-13" morph="none" pos="punct" start_char="1159">"</TOKEN>
<TOKEN end_char="1160" id="token-10-14" morph="none" pos="word" start_char="1160">a</TOKEN>
<TOKEN end_char="1171" id="token-10-15" morph="none" pos="word" start_char="1162">conspiracy</TOKEN>
<TOKEN end_char="1178" id="token-10-16" morph="none" pos="word" start_char="1173">vision</TOKEN>
<TOKEN end_char="1183" id="token-10-17" morph="none" pos="word" start_char="1180">that</TOKEN>
<TOKEN end_char="1188" id="token-10-18" morph="none" pos="word" start_char="1185">does</TOKEN>
<TOKEN end_char="1192" id="token-10-19" morph="none" pos="word" start_char="1190">not</TOKEN>
<TOKEN end_char="1199" id="token-10-20" morph="none" pos="word" start_char="1194">relate</TOKEN>
<TOKEN end_char="1202" id="token-10-21" morph="none" pos="word" start_char="1201">to</TOKEN>
<TOKEN end_char="1206" id="token-10-22" morph="none" pos="word" start_char="1204">the</TOKEN>
<TOKEN end_char="1211" id="token-10-23" morph="none" pos="word" start_char="1208">real</TOKEN>
<TOKEN end_char="1219" id="token-10-24" morph="none" pos="word" start_char="1213">science</TOKEN>
<TOKEN end_char="1221" id="token-10-25" morph="none" pos="punct" start_char="1220">,"</TOKEN>
<TOKEN end_char="1226" id="token-10-26" morph="none" pos="word" start_char="1223">said</TOKEN>
<TOKEN end_char="1240" id="token-10-27" morph="none" pos="unknown" start_char="1228">Jean-Francois</TOKEN>
<TOKEN end_char="1251" id="token-10-28" morph="none" pos="word" start_char="1242">Delfraissy</TOKEN>
<TOKEN end_char="1252" id="token-10-29" morph="none" pos="punct" start_char="1252">,</TOKEN>
<TOKEN end_char="1255" id="token-10-30" morph="none" pos="word" start_char="1254">an</TOKEN>
<TOKEN end_char="1268" id="token-10-31" morph="none" pos="word" start_char="1257">immunologist</TOKEN>
<TOKEN end_char="1272" id="token-10-32" morph="none" pos="word" start_char="1270">and</TOKEN>
<TOKEN end_char="1277" id="token-10-33" morph="none" pos="word" start_char="1274">head</TOKEN>
<TOKEN end_char="1280" id="token-10-34" morph="none" pos="word" start_char="1279">of</TOKEN>
<TOKEN end_char="1284" id="token-10-35" morph="none" pos="word" start_char="1282">the</TOKEN>
<TOKEN end_char="1295" id="token-10-36" morph="none" pos="word" start_char="1286">scientific</TOKEN>
<TOKEN end_char="1303" id="token-10-37" morph="none" pos="word" start_char="1297">council</TOKEN>
<TOKEN end_char="1308" id="token-10-38" morph="none" pos="word" start_char="1305">that</TOKEN>
<TOKEN end_char="1316" id="token-10-39" morph="none" pos="word" start_char="1310">advises</TOKEN>
<TOKEN end_char="1320" id="token-10-40" morph="none" pos="word" start_char="1318">the</TOKEN>
<TOKEN end_char="1327" id="token-10-41" morph="none" pos="word" start_char="1322">French</TOKEN>
<TOKEN end_char="1338" id="token-10-42" morph="none" pos="word" start_char="1329">government</TOKEN>
<TOKEN end_char="1341" id="token-10-43" morph="none" pos="word" start_char="1340">on</TOKEN>
<TOKEN end_char="1345" id="token-10-44" morph="none" pos="word" start_char="1343">the</TOKEN>
<TOKEN end_char="1354" id="token-10-45" morph="none" pos="unknown" start_char="1347">Covid-19</TOKEN>
<TOKEN end_char="1363" id="token-10-46" morph="none" pos="word" start_char="1356">pandemic</TOKEN>
<TOKEN end_char="1364" id="token-10-47" morph="none" pos="punct" start_char="1364">,</TOKEN>
<TOKEN end_char="1369" id="token-10-48" morph="none" pos="word" start_char="1366">when</TOKEN>
<TOKEN end_char="1381" id="token-10-49" morph="none" pos="word" start_char="1371">interviewed</TOKEN>
<TOKEN end_char="1384" id="token-10-50" morph="none" pos="word" start_char="1383">by</TOKEN>
<TOKEN end_char="1391" id="token-10-51" morph="none" pos="word" start_char="1386">French</TOKEN>
<TOKEN end_char="1402" id="token-10-52" morph="none" pos="word" start_char="1393">television</TOKEN>
<TOKEN end_char="1406" id="token-10-53" morph="none" pos="word" start_char="1404">BFM</TOKEN>
<TOKEN end_char="1409" id="token-10-54" morph="none" pos="word" start_char="1408">TV</TOKEN>
<TOKEN end_char="1410" id="token-10-55" morph="none" pos="punct" start_char="1410">.</TOKEN>
</SEG>
<SEG end_char="1488" id="segment-11" start_char="1413">
<ORIGINAL_TEXT>"Everyone in the scientific community agrees that Covid-19 is a coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="1413" id="token-11-0" morph="none" pos="punct" start_char="1413">"</TOKEN>
<TOKEN end_char="1421" id="token-11-1" morph="none" pos="word" start_char="1414">Everyone</TOKEN>
<TOKEN end_char="1424" id="token-11-2" morph="none" pos="word" start_char="1423">in</TOKEN>
<TOKEN end_char="1428" id="token-11-3" morph="none" pos="word" start_char="1426">the</TOKEN>
<TOKEN end_char="1439" id="token-11-4" morph="none" pos="word" start_char="1430">scientific</TOKEN>
<TOKEN end_char="1449" id="token-11-5" morph="none" pos="word" start_char="1441">community</TOKEN>
<TOKEN end_char="1456" id="token-11-6" morph="none" pos="word" start_char="1451">agrees</TOKEN>
<TOKEN end_char="1461" id="token-11-7" morph="none" pos="word" start_char="1458">that</TOKEN>
<TOKEN end_char="1470" id="token-11-8" morph="none" pos="unknown" start_char="1463">Covid-19</TOKEN>
<TOKEN end_char="1473" id="token-11-9" morph="none" pos="word" start_char="1472">is</TOKEN>
<TOKEN end_char="1475" id="token-11-10" morph="none" pos="word" start_char="1475">a</TOKEN>
<TOKEN end_char="1487" id="token-11-11" morph="none" pos="word" start_char="1477">coronavirus</TOKEN>
<TOKEN end_char="1488" id="token-11-12" morph="none" pos="punct" start_char="1488">.</TOKEN>
</SEG>
<SEG end_char="1630" id="segment-12" start_char="1490">
<ORIGINAL_TEXT>From time to time there are coronaviruses different from the others, as are SARS and MERS with a pathogenicity which has appeared," he added.</ORIGINAL_TEXT>
<TOKEN end_char="1493" id="token-12-0" morph="none" pos="word" start_char="1490">From</TOKEN>
<TOKEN end_char="1498" id="token-12-1" morph="none" pos="word" start_char="1495">time</TOKEN>
<TOKEN end_char="1501" id="token-12-2" morph="none" pos="word" start_char="1500">to</TOKEN>
<TOKEN end_char="1506" id="token-12-3" morph="none" pos="word" start_char="1503">time</TOKEN>
<TOKEN end_char="1512" id="token-12-4" morph="none" pos="word" start_char="1508">there</TOKEN>
<TOKEN end_char="1516" id="token-12-5" morph="none" pos="word" start_char="1514">are</TOKEN>
<TOKEN end_char="1530" id="token-12-6" morph="none" pos="word" start_char="1518">coronaviruses</TOKEN>
<TOKEN end_char="1540" id="token-12-7" morph="none" pos="word" start_char="1532">different</TOKEN>
<TOKEN end_char="1545" id="token-12-8" morph="none" pos="word" start_char="1542">from</TOKEN>
<TOKEN end_char="1549" id="token-12-9" morph="none" pos="word" start_char="1547">the</TOKEN>
<TOKEN end_char="1556" id="token-12-10" morph="none" pos="word" start_char="1551">others</TOKEN>
<TOKEN end_char="1557" id="token-12-11" morph="none" pos="punct" start_char="1557">,</TOKEN>
<TOKEN end_char="1560" id="token-12-12" morph="none" pos="word" start_char="1559">as</TOKEN>
<TOKEN end_char="1564" id="token-12-13" morph="none" pos="word" start_char="1562">are</TOKEN>
<TOKEN end_char="1569" id="token-12-14" morph="none" pos="word" start_char="1566">SARS</TOKEN>
<TOKEN end_char="1573" id="token-12-15" morph="none" pos="word" start_char="1571">and</TOKEN>
<TOKEN end_char="1578" id="token-12-16" morph="none" pos="word" start_char="1575">MERS</TOKEN>
<TOKEN end_char="1583" id="token-12-17" morph="none" pos="word" start_char="1580">with</TOKEN>
<TOKEN end_char="1585" id="token-12-18" morph="none" pos="word" start_char="1585">a</TOKEN>
<TOKEN end_char="1599" id="token-12-19" morph="none" pos="word" start_char="1587">pathogenicity</TOKEN>
<TOKEN end_char="1605" id="token-12-20" morph="none" pos="word" start_char="1601">which</TOKEN>
<TOKEN end_char="1609" id="token-12-21" morph="none" pos="word" start_char="1607">has</TOKEN>
<TOKEN end_char="1618" id="token-12-22" morph="none" pos="word" start_char="1611">appeared</TOKEN>
<TOKEN end_char="1620" id="token-12-23" morph="none" pos="punct" start_char="1619">,"</TOKEN>
<TOKEN end_char="1623" id="token-12-24" morph="none" pos="word" start_char="1622">he</TOKEN>
<TOKEN end_char="1629" id="token-12-25" morph="none" pos="word" start_char="1625">added</TOKEN>
<TOKEN end_char="1630" id="token-12-26" morph="none" pos="punct" start_char="1630">.</TOKEN>
</SEG>
<SEG end_char="1802" id="segment-13" start_char="1633">
<ORIGINAL_TEXT>Both Severe Acute Respiratory Syndrome (SARS) and Middle East Respiratory Syndrome (MERS) are caused by coronaviruses, and the Covid-19 virus is also known as SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN end_char="1636" id="token-13-0" morph="none" pos="word" start_char="1633">Both</TOKEN>
<TOKEN end_char="1643" id="token-13-1" morph="none" pos="word" start_char="1638">Severe</TOKEN>
<TOKEN end_char="1649" id="token-13-2" morph="none" pos="word" start_char="1645">Acute</TOKEN>
<TOKEN end_char="1661" id="token-13-3" morph="none" pos="word" start_char="1651">Respiratory</TOKEN>
<TOKEN end_char="1670" id="token-13-4" morph="none" pos="word" start_char="1663">Syndrome</TOKEN>
<TOKEN end_char="1672" id="token-13-5" morph="none" pos="punct" start_char="1672">(</TOKEN>
<TOKEN end_char="1676" id="token-13-6" morph="none" pos="word" start_char="1673">SARS</TOKEN>
<TOKEN end_char="1677" id="token-13-7" morph="none" pos="punct" start_char="1677">)</TOKEN>
<TOKEN end_char="1681" id="token-13-8" morph="none" pos="word" start_char="1679">and</TOKEN>
<TOKEN end_char="1688" id="token-13-9" morph="none" pos="word" start_char="1683">Middle</TOKEN>
<TOKEN end_char="1693" id="token-13-10" morph="none" pos="word" start_char="1690">East</TOKEN>
<TOKEN end_char="1705" id="token-13-11" morph="none" pos="word" start_char="1695">Respiratory</TOKEN>
<TOKEN end_char="1714" id="token-13-12" morph="none" pos="word" start_char="1707">Syndrome</TOKEN>
<TOKEN end_char="1716" id="token-13-13" morph="none" pos="punct" start_char="1716">(</TOKEN>
<TOKEN end_char="1720" id="token-13-14" morph="none" pos="word" start_char="1717">MERS</TOKEN>
<TOKEN end_char="1721" id="token-13-15" morph="none" pos="punct" start_char="1721">)</TOKEN>
<TOKEN end_char="1725" id="token-13-16" morph="none" pos="word" start_char="1723">are</TOKEN>
<TOKEN end_char="1732" id="token-13-17" morph="none" pos="word" start_char="1727">caused</TOKEN>
<TOKEN end_char="1735" id="token-13-18" morph="none" pos="word" start_char="1734">by</TOKEN>
<TOKEN end_char="1749" id="token-13-19" morph="none" pos="word" start_char="1737">coronaviruses</TOKEN>
<TOKEN end_char="1750" id="token-13-20" morph="none" pos="punct" start_char="1750">,</TOKEN>
<TOKEN end_char="1754" id="token-13-21" morph="none" pos="word" start_char="1752">and</TOKEN>
<TOKEN end_char="1758" id="token-13-22" morph="none" pos="word" start_char="1756">the</TOKEN>
<TOKEN end_char="1767" id="token-13-23" morph="none" pos="unknown" start_char="1760">Covid-19</TOKEN>
<TOKEN end_char="1773" id="token-13-24" morph="none" pos="word" start_char="1769">virus</TOKEN>
<TOKEN end_char="1776" id="token-13-25" morph="none" pos="word" start_char="1775">is</TOKEN>
<TOKEN end_char="1781" id="token-13-26" morph="none" pos="word" start_char="1778">also</TOKEN>
<TOKEN end_char="1787" id="token-13-27" morph="none" pos="word" start_char="1783">known</TOKEN>
<TOKEN end_char="1790" id="token-13-28" morph="none" pos="word" start_char="1789">as</TOKEN>
<TOKEN end_char="1801" id="token-13-29" morph="none" pos="unknown" start_char="1792">SARS-CoV-2</TOKEN>
<TOKEN end_char="1802" id="token-13-30" morph="none" pos="punct" start_char="1802">.</TOKEN>
</SEG>
<SEG end_char="1879" id="segment-14" start_char="1805">
<ORIGINAL_TEXT>"The world of viruses is a world in perpetual evolution," Delfraissy noted.</ORIGINAL_TEXT>
<TOKEN end_char="1805" id="token-14-0" morph="none" pos="punct" start_char="1805">"</TOKEN>
<TOKEN end_char="1808" id="token-14-1" morph="none" pos="word" start_char="1806">The</TOKEN>
<TOKEN end_char="1814" id="token-14-2" morph="none" pos="word" start_char="1810">world</TOKEN>
<TOKEN end_char="1817" id="token-14-3" morph="none" pos="word" start_char="1816">of</TOKEN>
<TOKEN end_char="1825" id="token-14-4" morph="none" pos="word" start_char="1819">viruses</TOKEN>
<TOKEN end_char="1828" id="token-14-5" morph="none" pos="word" start_char="1827">is</TOKEN>
<TOKEN end_char="1830" id="token-14-6" morph="none" pos="word" start_char="1830">a</TOKEN>
<TOKEN end_char="1836" id="token-14-7" morph="none" pos="word" start_char="1832">world</TOKEN>
<TOKEN end_char="1839" id="token-14-8" morph="none" pos="word" start_char="1838">in</TOKEN>
<TOKEN end_char="1849" id="token-14-9" morph="none" pos="word" start_char="1841">perpetual</TOKEN>
<TOKEN end_char="1859" id="token-14-10" morph="none" pos="word" start_char="1851">evolution</TOKEN>
<TOKEN end_char="1861" id="token-14-11" morph="none" pos="punct" start_char="1860">,"</TOKEN>
<TOKEN end_char="1872" id="token-14-12" morph="none" pos="word" start_char="1863">Delfraissy</TOKEN>
<TOKEN end_char="1878" id="token-14-13" morph="none" pos="word" start_char="1874">noted</TOKEN>
<TOKEN end_char="1879" id="token-14-14" morph="none" pos="punct" start_char="1879">.</TOKEN>
</SEG>
<SEG end_char="2074" id="segment-15" start_char="1882">
<ORIGINAL_TEXT>According to Olivier Schwartz, head of the virus and immunity department of France's Pasteur Institute, studies have shown clearly that the novel coronavirus was not man-made in the laboratory.</ORIGINAL_TEXT>
<TOKEN end_char="1890" id="token-15-0" morph="none" pos="word" start_char="1882">According</TOKEN>
<TOKEN end_char="1893" id="token-15-1" morph="none" pos="word" start_char="1892">to</TOKEN>
<TOKEN end_char="1901" id="token-15-2" morph="none" pos="word" start_char="1895">Olivier</TOKEN>
<TOKEN end_char="1910" id="token-15-3" morph="none" pos="word" start_char="1903">Schwartz</TOKEN>
<TOKEN end_char="1911" id="token-15-4" morph="none" pos="punct" start_char="1911">,</TOKEN>
<TOKEN end_char="1916" id="token-15-5" morph="none" pos="word" start_char="1913">head</TOKEN>
<TOKEN end_char="1919" id="token-15-6" morph="none" pos="word" start_char="1918">of</TOKEN>
<TOKEN end_char="1923" id="token-15-7" morph="none" pos="word" start_char="1921">the</TOKEN>
<TOKEN end_char="1929" id="token-15-8" morph="none" pos="word" start_char="1925">virus</TOKEN>
<TOKEN end_char="1933" id="token-15-9" morph="none" pos="word" start_char="1931">and</TOKEN>
<TOKEN end_char="1942" id="token-15-10" morph="none" pos="word" start_char="1935">immunity</TOKEN>
<TOKEN end_char="1953" id="token-15-11" morph="none" pos="word" start_char="1944">department</TOKEN>
<TOKEN end_char="1956" id="token-15-12" morph="none" pos="word" start_char="1955">of</TOKEN>
<TOKEN end_char="1965" id="token-15-13" morph="none" pos="word" start_char="1958">France's</TOKEN>
<TOKEN end_char="1973" id="token-15-14" morph="none" pos="word" start_char="1967">Pasteur</TOKEN>
<TOKEN end_char="1983" id="token-15-15" morph="none" pos="word" start_char="1975">Institute</TOKEN>
<TOKEN end_char="1984" id="token-15-16" morph="none" pos="punct" start_char="1984">,</TOKEN>
<TOKEN end_char="1992" id="token-15-17" morph="none" pos="word" start_char="1986">studies</TOKEN>
<TOKEN end_char="1997" id="token-15-18" morph="none" pos="word" start_char="1994">have</TOKEN>
<TOKEN end_char="2003" id="token-15-19" morph="none" pos="word" start_char="1999">shown</TOKEN>
<TOKEN end_char="2011" id="token-15-20" morph="none" pos="word" start_char="2005">clearly</TOKEN>
<TOKEN end_char="2016" id="token-15-21" morph="none" pos="word" start_char="2013">that</TOKEN>
<TOKEN end_char="2020" id="token-15-22" morph="none" pos="word" start_char="2018">the</TOKEN>
<TOKEN end_char="2026" id="token-15-23" morph="none" pos="word" start_char="2022">novel</TOKEN>
<TOKEN end_char="2038" id="token-15-24" morph="none" pos="word" start_char="2028">coronavirus</TOKEN>
<TOKEN end_char="2042" id="token-15-25" morph="none" pos="word" start_char="2040">was</TOKEN>
<TOKEN end_char="2046" id="token-15-26" morph="none" pos="word" start_char="2044">not</TOKEN>
<TOKEN end_char="2055" id="token-15-27" morph="none" pos="unknown" start_char="2048">man-made</TOKEN>
<TOKEN end_char="2058" id="token-15-28" morph="none" pos="word" start_char="2057">in</TOKEN>
<TOKEN end_char="2062" id="token-15-29" morph="none" pos="word" start_char="2060">the</TOKEN>
<TOKEN end_char="2073" id="token-15-30" morph="none" pos="word" start_char="2064">laboratory</TOKEN>
<TOKEN end_char="2074" id="token-15-31" morph="none" pos="punct" start_char="2074">.</TOKEN>
</SEG>
<SEG end_char="2202" id="segment-16" start_char="2077">
<ORIGINAL_TEXT>"Professor Montagnier spreads whimsical theories," he told the French weekly L'Obs, previously known as Le Nouvel Observateur.</ORIGINAL_TEXT>
<TOKEN end_char="2077" id="token-16-0" morph="none" pos="punct" start_char="2077">"</TOKEN>
<TOKEN end_char="2086" id="token-16-1" morph="none" pos="word" start_char="2078">Professor</TOKEN>
<TOKEN end_char="2097" id="token-16-2" morph="none" pos="word" start_char="2088">Montagnier</TOKEN>
<TOKEN end_char="2105" id="token-16-3" morph="none" pos="word" start_char="2099">spreads</TOKEN>
<TOKEN end_char="2115" id="token-16-4" morph="none" pos="word" start_char="2107">whimsical</TOKEN>
<TOKEN end_char="2124" id="token-16-5" morph="none" pos="word" start_char="2117">theories</TOKEN>
<TOKEN end_char="2126" id="token-16-6" morph="none" pos="punct" start_char="2125">,"</TOKEN>
<TOKEN end_char="2129" id="token-16-7" morph="none" pos="word" start_char="2128">he</TOKEN>
<TOKEN end_char="2134" id="token-16-8" morph="none" pos="word" start_char="2131">told</TOKEN>
<TOKEN end_char="2138" id="token-16-9" morph="none" pos="word" start_char="2136">the</TOKEN>
<TOKEN end_char="2145" id="token-16-10" morph="none" pos="word" start_char="2140">French</TOKEN>
<TOKEN end_char="2152" id="token-16-11" morph="none" pos="word" start_char="2147">weekly</TOKEN>
<TOKEN end_char="2158" id="token-16-12" morph="none" pos="word" start_char="2154">L'Obs</TOKEN>
<TOKEN end_char="2159" id="token-16-13" morph="none" pos="punct" start_char="2159">,</TOKEN>
<TOKEN end_char="2170" id="token-16-14" morph="none" pos="word" start_char="2161">previously</TOKEN>
<TOKEN end_char="2176" id="token-16-15" morph="none" pos="word" start_char="2172">known</TOKEN>
<TOKEN end_char="2179" id="token-16-16" morph="none" pos="word" start_char="2178">as</TOKEN>
<TOKEN end_char="2182" id="token-16-17" morph="none" pos="word" start_char="2181">Le</TOKEN>
<TOKEN end_char="2189" id="token-16-18" morph="none" pos="word" start_char="2184">Nouvel</TOKEN>
<TOKEN end_char="2201" id="token-16-19" morph="none" pos="word" start_char="2191">Observateur</TOKEN>
<TOKEN end_char="2202" id="token-16-20" morph="none" pos="punct" start_char="2202">.</TOKEN>
</SEG>
<SEG end_char="2295" id="segment-17" start_char="2205">
<ORIGINAL_TEXT>"Sars-CoV-2, the virus that causes the Covid-19 disease, was not created in the laboratory.</ORIGINAL_TEXT>
<TOKEN end_char="2205" id="token-17-0" morph="none" pos="punct" start_char="2205">"</TOKEN>
<TOKEN end_char="2215" id="token-17-1" morph="none" pos="unknown" start_char="2206">Sars-CoV-2</TOKEN>
<TOKEN end_char="2216" id="token-17-2" morph="none" pos="punct" start_char="2216">,</TOKEN>
<TOKEN end_char="2220" id="token-17-3" morph="none" pos="word" start_char="2218">the</TOKEN>
<TOKEN end_char="2226" id="token-17-4" morph="none" pos="word" start_char="2222">virus</TOKEN>
<TOKEN end_char="2231" id="token-17-5" morph="none" pos="word" start_char="2228">that</TOKEN>
<TOKEN end_char="2238" id="token-17-6" morph="none" pos="word" start_char="2233">causes</TOKEN>
<TOKEN end_char="2242" id="token-17-7" morph="none" pos="word" start_char="2240">the</TOKEN>
<TOKEN end_char="2251" id="token-17-8" morph="none" pos="unknown" start_char="2244">Covid-19</TOKEN>
<TOKEN end_char="2259" id="token-17-9" morph="none" pos="word" start_char="2253">disease</TOKEN>
<TOKEN end_char="2260" id="token-17-10" morph="none" pos="punct" start_char="2260">,</TOKEN>
<TOKEN end_char="2264" id="token-17-11" morph="none" pos="word" start_char="2262">was</TOKEN>
<TOKEN end_char="2268" id="token-17-12" morph="none" pos="word" start_char="2266">not</TOKEN>
<TOKEN end_char="2276" id="token-17-13" morph="none" pos="word" start_char="2270">created</TOKEN>
<TOKEN end_char="2279" id="token-17-14" morph="none" pos="word" start_char="2278">in</TOKEN>
<TOKEN end_char="2283" id="token-17-15" morph="none" pos="word" start_char="2281">the</TOKEN>
<TOKEN end_char="2294" id="token-17-16" morph="none" pos="word" start_char="2285">laboratory</TOKEN>
<TOKEN end_char="2295" id="token-17-17" morph="none" pos="punct" start_char="2295">.</TOKEN>
</SEG>
<SEG end_char="2491" id="segment-18" start_char="2297">
<ORIGINAL_TEXT>We see this by studying the genetic heritage of the virus, which has been sequenced by Chinese teams and then verified in many other laboratories, including the Pasteur Institute," said Schwartz.</ORIGINAL_TEXT>
<TOKEN end_char="2298" id="token-18-0" morph="none" pos="word" start_char="2297">We</TOKEN>
<TOKEN end_char="2302" id="token-18-1" morph="none" pos="word" start_char="2300">see</TOKEN>
<TOKEN end_char="2307" id="token-18-2" morph="none" pos="word" start_char="2304">this</TOKEN>
<TOKEN end_char="2310" id="token-18-3" morph="none" pos="word" start_char="2309">by</TOKEN>
<TOKEN end_char="2319" id="token-18-4" morph="none" pos="word" start_char="2312">studying</TOKEN>
<TOKEN end_char="2323" id="token-18-5" morph="none" pos="word" start_char="2321">the</TOKEN>
<TOKEN end_char="2331" id="token-18-6" morph="none" pos="word" start_char="2325">genetic</TOKEN>
<TOKEN end_char="2340" id="token-18-7" morph="none" pos="word" start_char="2333">heritage</TOKEN>
<TOKEN end_char="2343" id="token-18-8" morph="none" pos="word" start_char="2342">of</TOKEN>
<TOKEN end_char="2347" id="token-18-9" morph="none" pos="word" start_char="2345">the</TOKEN>
<TOKEN end_char="2353" id="token-18-10" morph="none" pos="word" start_char="2349">virus</TOKEN>
<TOKEN end_char="2354" id="token-18-11" morph="none" pos="punct" start_char="2354">,</TOKEN>
<TOKEN end_char="2360" id="token-18-12" morph="none" pos="word" start_char="2356">which</TOKEN>
<TOKEN end_char="2364" id="token-18-13" morph="none" pos="word" start_char="2362">has</TOKEN>
<TOKEN end_char="2369" id="token-18-14" morph="none" pos="word" start_char="2366">been</TOKEN>
<TOKEN end_char="2379" id="token-18-15" morph="none" pos="word" start_char="2371">sequenced</TOKEN>
<TOKEN end_char="2382" id="token-18-16" morph="none" pos="word" start_char="2381">by</TOKEN>
<TOKEN end_char="2390" id="token-18-17" morph="none" pos="word" start_char="2384">Chinese</TOKEN>
<TOKEN end_char="2396" id="token-18-18" morph="none" pos="word" start_char="2392">teams</TOKEN>
<TOKEN end_char="2400" id="token-18-19" morph="none" pos="word" start_char="2398">and</TOKEN>
<TOKEN end_char="2405" id="token-18-20" morph="none" pos="word" start_char="2402">then</TOKEN>
<TOKEN end_char="2414" id="token-18-21" morph="none" pos="word" start_char="2407">verified</TOKEN>
<TOKEN end_char="2417" id="token-18-22" morph="none" pos="word" start_char="2416">in</TOKEN>
<TOKEN end_char="2422" id="token-18-23" morph="none" pos="word" start_char="2419">many</TOKEN>
<TOKEN end_char="2428" id="token-18-24" morph="none" pos="word" start_char="2424">other</TOKEN>
<TOKEN end_char="2441" id="token-18-25" morph="none" pos="word" start_char="2430">laboratories</TOKEN>
<TOKEN end_char="2442" id="token-18-26" morph="none" pos="punct" start_char="2442">,</TOKEN>
<TOKEN end_char="2452" id="token-18-27" morph="none" pos="word" start_char="2444">including</TOKEN>
<TOKEN end_char="2456" id="token-18-28" morph="none" pos="word" start_char="2454">the</TOKEN>
<TOKEN end_char="2464" id="token-18-29" morph="none" pos="word" start_char="2458">Pasteur</TOKEN>
<TOKEN end_char="2474" id="token-18-30" morph="none" pos="word" start_char="2466">Institute</TOKEN>
<TOKEN end_char="2476" id="token-18-31" morph="none" pos="punct" start_char="2475">,"</TOKEN>
<TOKEN end_char="2481" id="token-18-32" morph="none" pos="word" start_char="2478">said</TOKEN>
<TOKEN end_char="2490" id="token-18-33" morph="none" pos="word" start_char="2483">Schwartz</TOKEN>
<TOKEN end_char="2491" id="token-18-34" morph="none" pos="punct" start_char="2491">.</TOKEN>
</SEG>
<SEG end_char="2552" id="segment-19" start_char="2494">
<ORIGINAL_TEXT>"This virus is clearly part of the coronavirus family tree.</ORIGINAL_TEXT>
<TOKEN end_char="2494" id="token-19-0" morph="none" pos="punct" start_char="2494">"</TOKEN>
<TOKEN end_char="2498" id="token-19-1" morph="none" pos="word" start_char="2495">This</TOKEN>
<TOKEN end_char="2504" id="token-19-2" morph="none" pos="word" start_char="2500">virus</TOKEN>
<TOKEN end_char="2507" id="token-19-3" morph="none" pos="word" start_char="2506">is</TOKEN>
<TOKEN end_char="2515" id="token-19-4" morph="none" pos="word" start_char="2509">clearly</TOKEN>
<TOKEN end_char="2520" id="token-19-5" morph="none" pos="word" start_char="2517">part</TOKEN>
<TOKEN end_char="2523" id="token-19-6" morph="none" pos="word" start_char="2522">of</TOKEN>
<TOKEN end_char="2527" id="token-19-7" morph="none" pos="word" start_char="2525">the</TOKEN>
<TOKEN end_char="2539" id="token-19-8" morph="none" pos="word" start_char="2529">coronavirus</TOKEN>
<TOKEN end_char="2546" id="token-19-9" morph="none" pos="word" start_char="2541">family</TOKEN>
<TOKEN end_char="2551" id="token-19-10" morph="none" pos="word" start_char="2548">tree</TOKEN>
<TOKEN end_char="2552" id="token-19-11" morph="none" pos="punct" start_char="2552">.</TOKEN>
</SEG>
<SEG end_char="2626" id="segment-20" start_char="2554">
<ORIGINAL_TEXT>It is close to Sars-CoV-1, with which it has 80% homology," he explained.</ORIGINAL_TEXT>
<TOKEN end_char="2555" id="token-20-0" morph="none" pos="word" start_char="2554">It</TOKEN>
<TOKEN end_char="2558" id="token-20-1" morph="none" pos="word" start_char="2557">is</TOKEN>
<TOKEN end_char="2564" id="token-20-2" morph="none" pos="word" start_char="2560">close</TOKEN>
<TOKEN end_char="2567" id="token-20-3" morph="none" pos="word" start_char="2566">to</TOKEN>
<TOKEN end_char="2578" id="token-20-4" morph="none" pos="unknown" start_char="2569">Sars-CoV-1</TOKEN>
<TOKEN end_char="2579" id="token-20-5" morph="none" pos="punct" start_char="2579">,</TOKEN>
<TOKEN end_char="2584" id="token-20-6" morph="none" pos="word" start_char="2581">with</TOKEN>
<TOKEN end_char="2590" id="token-20-7" morph="none" pos="word" start_char="2586">which</TOKEN>
<TOKEN end_char="2593" id="token-20-8" morph="none" pos="word" start_char="2592">it</TOKEN>
<TOKEN end_char="2597" id="token-20-9" morph="none" pos="word" start_char="2595">has</TOKEN>
<TOKEN end_char="2600" id="token-20-10" morph="none" pos="word" start_char="2599">80</TOKEN>
<TOKEN end_char="2601" id="token-20-11" morph="none" pos="punct" start_char="2601">%</TOKEN>
<TOKEN end_char="2610" id="token-20-12" morph="none" pos="word" start_char="2603">homology</TOKEN>
<TOKEN end_char="2612" id="token-20-13" morph="none" pos="punct" start_char="2611">,"</TOKEN>
<TOKEN end_char="2615" id="token-20-14" morph="none" pos="word" start_char="2614">he</TOKEN>
<TOKEN end_char="2625" id="token-20-15" morph="none" pos="word" start_char="2617">explained</TOKEN>
<TOKEN end_char="2626" id="token-20-16" morph="none" pos="punct" start_char="2626">.</TOKEN>
</SEG>
<SEG end_char="2725" id="segment-21" start_char="2629">
<ORIGINAL_TEXT>"Above all, the same virus is found in different animals, in particular the pangolin and the bat.</ORIGINAL_TEXT>
<TOKEN end_char="2629" id="token-21-0" morph="none" pos="punct" start_char="2629">"</TOKEN>
<TOKEN end_char="2634" id="token-21-1" morph="none" pos="word" start_char="2630">Above</TOKEN>
<TOKEN end_char="2638" id="token-21-2" morph="none" pos="word" start_char="2636">all</TOKEN>
<TOKEN end_char="2639" id="token-21-3" morph="none" pos="punct" start_char="2639">,</TOKEN>
<TOKEN end_char="2643" id="token-21-4" morph="none" pos="word" start_char="2641">the</TOKEN>
<TOKEN end_char="2648" id="token-21-5" morph="none" pos="word" start_char="2645">same</TOKEN>
<TOKEN end_char="2654" id="token-21-6" morph="none" pos="word" start_char="2650">virus</TOKEN>
<TOKEN end_char="2657" id="token-21-7" morph="none" pos="word" start_char="2656">is</TOKEN>
<TOKEN end_char="2663" id="token-21-8" morph="none" pos="word" start_char="2659">found</TOKEN>
<TOKEN end_char="2666" id="token-21-9" morph="none" pos="word" start_char="2665">in</TOKEN>
<TOKEN end_char="2676" id="token-21-10" morph="none" pos="word" start_char="2668">different</TOKEN>
<TOKEN end_char="2684" id="token-21-11" morph="none" pos="word" start_char="2678">animals</TOKEN>
<TOKEN end_char="2685" id="token-21-12" morph="none" pos="punct" start_char="2685">,</TOKEN>
<TOKEN end_char="2688" id="token-21-13" morph="none" pos="word" start_char="2687">in</TOKEN>
<TOKEN end_char="2699" id="token-21-14" morph="none" pos="word" start_char="2690">particular</TOKEN>
<TOKEN end_char="2703" id="token-21-15" morph="none" pos="word" start_char="2701">the</TOKEN>
<TOKEN end_char="2712" id="token-21-16" morph="none" pos="word" start_char="2705">pangolin</TOKEN>
<TOKEN end_char="2716" id="token-21-17" morph="none" pos="word" start_char="2714">and</TOKEN>
<TOKEN end_char="2720" id="token-21-18" morph="none" pos="word" start_char="2718">the</TOKEN>
<TOKEN end_char="2724" id="token-21-19" morph="none" pos="word" start_char="2722">bat</TOKEN>
<TOKEN end_char="2725" id="token-21-20" morph="none" pos="punct" start_char="2725">.</TOKEN>
</SEG>
<SEG end_char="2790" id="segment-22" start_char="2728">
<ORIGINAL_TEXT>"And there, the percentage of similarities is greater than 95%.</ORIGINAL_TEXT>
<TOKEN end_char="2728" id="token-22-0" morph="none" pos="punct" start_char="2728">"</TOKEN>
<TOKEN end_char="2731" id="token-22-1" morph="none" pos="word" start_char="2729">And</TOKEN>
<TOKEN end_char="2737" id="token-22-2" morph="none" pos="word" start_char="2733">there</TOKEN>
<TOKEN end_char="2738" id="token-22-3" morph="none" pos="punct" start_char="2738">,</TOKEN>
<TOKEN end_char="2742" id="token-22-4" morph="none" pos="word" start_char="2740">the</TOKEN>
<TOKEN end_char="2753" id="token-22-5" morph="none" pos="word" start_char="2744">percentage</TOKEN>
<TOKEN end_char="2756" id="token-22-6" morph="none" pos="word" start_char="2755">of</TOKEN>
<TOKEN end_char="2769" id="token-22-7" morph="none" pos="word" start_char="2758">similarities</TOKEN>
<TOKEN end_char="2772" id="token-22-8" morph="none" pos="word" start_char="2771">is</TOKEN>
<TOKEN end_char="2780" id="token-22-9" morph="none" pos="word" start_char="2774">greater</TOKEN>
<TOKEN end_char="2785" id="token-22-10" morph="none" pos="word" start_char="2782">than</TOKEN>
<TOKEN end_char="2788" id="token-22-11" morph="none" pos="word" start_char="2787">95</TOKEN>
<TOKEN end_char="2790" id="token-22-12" morph="none" pos="punct" start_char="2789">%.</TOKEN>
</SEG>
<SEG end_char="2915" id="segment-23" start_char="2792">
<ORIGINAL_TEXT>So, by drawing up the family tree of this virus, we know that it is derived from viruses that circulate in nature," he said.</ORIGINAL_TEXT>
<TOKEN end_char="2793" id="token-23-0" morph="none" pos="word" start_char="2792">So</TOKEN>
<TOKEN end_char="2794" id="token-23-1" morph="none" pos="punct" start_char="2794">,</TOKEN>
<TOKEN end_char="2797" id="token-23-2" morph="none" pos="word" start_char="2796">by</TOKEN>
<TOKEN end_char="2805" id="token-23-3" morph="none" pos="word" start_char="2799">drawing</TOKEN>
<TOKEN end_char="2808" id="token-23-4" morph="none" pos="word" start_char="2807">up</TOKEN>
<TOKEN end_char="2812" id="token-23-5" morph="none" pos="word" start_char="2810">the</TOKEN>
<TOKEN end_char="2819" id="token-23-6" morph="none" pos="word" start_char="2814">family</TOKEN>
<TOKEN end_char="2824" id="token-23-7" morph="none" pos="word" start_char="2821">tree</TOKEN>
<TOKEN end_char="2827" id="token-23-8" morph="none" pos="word" start_char="2826">of</TOKEN>
<TOKEN end_char="2832" id="token-23-9" morph="none" pos="word" start_char="2829">this</TOKEN>
<TOKEN end_char="2838" id="token-23-10" morph="none" pos="word" start_char="2834">virus</TOKEN>
<TOKEN end_char="2839" id="token-23-11" morph="none" pos="punct" start_char="2839">,</TOKEN>
<TOKEN end_char="2842" id="token-23-12" morph="none" pos="word" start_char="2841">we</TOKEN>
<TOKEN end_char="2847" id="token-23-13" morph="none" pos="word" start_char="2844">know</TOKEN>
<TOKEN end_char="2852" id="token-23-14" morph="none" pos="word" start_char="2849">that</TOKEN>
<TOKEN end_char="2855" id="token-23-15" morph="none" pos="word" start_char="2854">it</TOKEN>
<TOKEN end_char="2858" id="token-23-16" morph="none" pos="word" start_char="2857">is</TOKEN>
<TOKEN end_char="2866" id="token-23-17" morph="none" pos="word" start_char="2860">derived</TOKEN>
<TOKEN end_char="2871" id="token-23-18" morph="none" pos="word" start_char="2868">from</TOKEN>
<TOKEN end_char="2879" id="token-23-19" morph="none" pos="word" start_char="2873">viruses</TOKEN>
<TOKEN end_char="2884" id="token-23-20" morph="none" pos="word" start_char="2881">that</TOKEN>
<TOKEN end_char="2894" id="token-23-21" morph="none" pos="word" start_char="2886">circulate</TOKEN>
<TOKEN end_char="2897" id="token-23-22" morph="none" pos="word" start_char="2896">in</TOKEN>
<TOKEN end_char="2904" id="token-23-23" morph="none" pos="word" start_char="2899">nature</TOKEN>
<TOKEN end_char="2906" id="token-23-24" morph="none" pos="punct" start_char="2905">,"</TOKEN>
<TOKEN end_char="2909" id="token-23-25" morph="none" pos="word" start_char="2908">he</TOKEN>
<TOKEN end_char="2914" id="token-23-26" morph="none" pos="word" start_char="2911">said</TOKEN>
<TOKEN end_char="2915" id="token-23-27" morph="none" pos="punct" start_char="2915">.</TOKEN>
</SEG>
<SEG end_char="2943" id="segment-24" start_char="2917">
<ORIGINAL_TEXT>- Xinhua/Asian News Network</ORIGINAL_TEXT>
<TOKEN end_char="2917" id="token-24-0" morph="none" pos="punct" start_char="2917">-</TOKEN>
<TOKEN end_char="2930" id="token-24-1" morph="none" pos="unknown" start_char="2919">Xinhua/Asian</TOKEN>
<TOKEN end_char="2935" id="token-24-2" morph="none" pos="word" start_char="2932">News</TOKEN>
<TOKEN end_char="2943" id="token-24-3" morph="none" pos="word" start_char="2937">Network</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
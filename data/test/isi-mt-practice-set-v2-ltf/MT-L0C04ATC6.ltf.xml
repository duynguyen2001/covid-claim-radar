<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATC6" lang="spa" raw_text_char_length="3675" raw_text_md5="23c4df50d183e0bbf736a26f691c776c" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="68" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Expertos claman contra el estudio sobre perros callejeros y COVID-19</ORIGINAL_TEXT>
<TOKEN end_char="8" id="token-0-0" morph="none" pos="word" start_char="1">Expertos</TOKEN>
<TOKEN end_char="15" id="token-0-1" morph="none" pos="word" start_char="10">claman</TOKEN>
<TOKEN end_char="22" id="token-0-2" morph="none" pos="word" start_char="17">contra</TOKEN>
<TOKEN end_char="25" id="token-0-3" morph="none" pos="word" start_char="24">el</TOKEN>
<TOKEN end_char="33" id="token-0-4" morph="none" pos="word" start_char="27">estudio</TOKEN>
<TOKEN end_char="39" id="token-0-5" morph="none" pos="word" start_char="35">sobre</TOKEN>
<TOKEN end_char="46" id="token-0-6" morph="none" pos="word" start_char="41">perros</TOKEN>
<TOKEN end_char="57" id="token-0-7" morph="none" pos="word" start_char="48">callejeros</TOKEN>
<TOKEN end_char="59" id="token-0-8" morph="none" pos="word" start_char="59">y</TOKEN>
<TOKEN end_char="68" id="token-0-9" morph="none" pos="unknown" start_char="61">COVID-19</TOKEN>
<TRANSLATED_TEXT>Experts clamor against the study on street dogs and COVID-19</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="206" id="segment-1" start_char="72">
<ORIGINAL_TEXT>No ven nada en el estudio que respalde esta suposición y les preocupa que este documento haya sido publicado en una revista científica.</ORIGINAL_TEXT>
<TOKEN end_char="73" id="token-1-0" morph="none" pos="word" start_char="72">No</TOKEN>
<TOKEN end_char="77" id="token-1-1" morph="none" pos="word" start_char="75">ven</TOKEN>
<TOKEN end_char="82" id="token-1-2" morph="none" pos="word" start_char="79">nada</TOKEN>
<TOKEN end_char="85" id="token-1-3" morph="none" pos="word" start_char="84">en</TOKEN>
<TOKEN end_char="88" id="token-1-4" morph="none" pos="word" start_char="87">el</TOKEN>
<TOKEN end_char="96" id="token-1-5" morph="none" pos="word" start_char="90">estudio</TOKEN>
<TOKEN end_char="100" id="token-1-6" morph="none" pos="word" start_char="98">que</TOKEN>
<TOKEN end_char="109" id="token-1-7" morph="none" pos="word" start_char="102">respalde</TOKEN>
<TOKEN end_char="114" id="token-1-8" morph="none" pos="word" start_char="111">esta</TOKEN>
<TOKEN end_char="125" id="token-1-9" morph="none" pos="word" start_char="116">suposición</TOKEN>
<TOKEN end_char="127" id="token-1-10" morph="none" pos="word" start_char="127">y</TOKEN>
<TOKEN end_char="131" id="token-1-11" morph="none" pos="word" start_char="129">les</TOKEN>
<TOKEN end_char="140" id="token-1-12" morph="none" pos="word" start_char="133">preocupa</TOKEN>
<TOKEN end_char="144" id="token-1-13" morph="none" pos="word" start_char="142">que</TOKEN>
<TOKEN end_char="149" id="token-1-14" morph="none" pos="word" start_char="146">este</TOKEN>
<TOKEN end_char="159" id="token-1-15" morph="none" pos="word" start_char="151">documento</TOKEN>
<TOKEN end_char="164" id="token-1-16" morph="none" pos="word" start_char="161">haya</TOKEN>
<TOKEN end_char="169" id="token-1-17" morph="none" pos="word" start_char="166">sido</TOKEN>
<TOKEN end_char="179" id="token-1-18" morph="none" pos="word" start_char="171">publicado</TOKEN>
<TOKEN end_char="182" id="token-1-19" morph="none" pos="word" start_char="181">en</TOKEN>
<TOKEN end_char="186" id="token-1-20" morph="none" pos="word" start_char="184">una</TOKEN>
<TOKEN end_char="194" id="token-1-21" morph="none" pos="word" start_char="188">revista</TOKEN>
<TOKEN end_char="205" id="token-1-22" morph="none" pos="word" start_char="196">científica</TOKEN>
<TOKEN end_char="206" id="token-1-23" morph="none" pos="punct" start_char="206">.</TOKEN>
<TRANSLATED_TEXT>They see nothing in the study that supports this assumption and are concerned that this document has been published in a scientific journal.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="337" id="segment-2" start_char="210">
<ORIGINAL_TEXT>​Numerosos expertos no entienden cómo el autor del estudio ha podido concluir que el coronavirus COVID-19 procede de los perros.</ORIGINAL_TEXT>
<TOKEN end_char="219" id="token-2-0" morph="none" pos="unknown" start_char="210">​Numerosos</TOKEN>
<TOKEN end_char="228" id="token-2-1" morph="none" pos="word" start_char="221">expertos</TOKEN>
<TOKEN end_char="231" id="token-2-2" morph="none" pos="word" start_char="230">no</TOKEN>
<TOKEN end_char="241" id="token-2-3" morph="none" pos="word" start_char="233">entienden</TOKEN>
<TOKEN end_char="246" id="token-2-4" morph="none" pos="word" start_char="243">cómo</TOKEN>
<TOKEN end_char="249" id="token-2-5" morph="none" pos="word" start_char="248">el</TOKEN>
<TOKEN end_char="255" id="token-2-6" morph="none" pos="word" start_char="251">autor</TOKEN>
<TOKEN end_char="259" id="token-2-7" morph="none" pos="word" start_char="257">del</TOKEN>
<TOKEN end_char="267" id="token-2-8" morph="none" pos="word" start_char="261">estudio</TOKEN>
<TOKEN end_char="270" id="token-2-9" morph="none" pos="word" start_char="269">ha</TOKEN>
<TOKEN end_char="277" id="token-2-10" morph="none" pos="word" start_char="272">podido</TOKEN>
<TOKEN end_char="286" id="token-2-11" morph="none" pos="word" start_char="279">concluir</TOKEN>
<TOKEN end_char="290" id="token-2-12" morph="none" pos="word" start_char="288">que</TOKEN>
<TOKEN end_char="293" id="token-2-13" morph="none" pos="word" start_char="292">el</TOKEN>
<TOKEN end_char="305" id="token-2-14" morph="none" pos="word" start_char="295">coronavirus</TOKEN>
<TOKEN end_char="314" id="token-2-15" morph="none" pos="unknown" start_char="307">COVID-19</TOKEN>
<TOKEN end_char="322" id="token-2-16" morph="none" pos="word" start_char="316">procede</TOKEN>
<TOKEN end_char="325" id="token-2-17" morph="none" pos="word" start_char="324">de</TOKEN>
<TOKEN end_char="329" id="token-2-18" morph="none" pos="word" start_char="327">los</TOKEN>
<TOKEN end_char="336" id="token-2-19" morph="none" pos="word" start_char="331">perros</TOKEN>
<TOKEN end_char="337" id="token-2-20" morph="none" pos="punct" start_char="337">.</TOKEN>
<TRANSLATED_TEXT> Many experts do not understand how the author of the study has been able to conclude that COVID-19 coronavirus comes from dogs.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="398" id="segment-3" start_char="339">
<ORIGINAL_TEXT>No ven nada en su investigación que respalde esta suposición</ORIGINAL_TEXT>
<TOKEN end_char="340" id="token-3-0" morph="none" pos="word" start_char="339">No</TOKEN>
<TOKEN end_char="344" id="token-3-1" morph="none" pos="word" start_char="342">ven</TOKEN>
<TOKEN end_char="349" id="token-3-2" morph="none" pos="word" start_char="346">nada</TOKEN>
<TOKEN end_char="352" id="token-3-3" morph="none" pos="word" start_char="351">en</TOKEN>
<TOKEN end_char="355" id="token-3-4" morph="none" pos="word" start_char="354">su</TOKEN>
<TOKEN end_char="369" id="token-3-5" morph="none" pos="word" start_char="357">investigación</TOKEN>
<TOKEN end_char="373" id="token-3-6" morph="none" pos="word" start_char="371">que</TOKEN>
<TOKEN end_char="382" id="token-3-7" morph="none" pos="word" start_char="375">respalde</TOKEN>
<TOKEN end_char="387" id="token-3-8" morph="none" pos="word" start_char="384">esta</TOKEN>
<TOKEN end_char="398" id="token-3-9" morph="none" pos="word" start_char="389">suposición</TOKEN>
<TRANSLATED_TEXT>You see nothing in your research that supports this assumption.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="610" id="segment-4" start_char="401">
<ORIGINAL_TEXT>Muchos medios de comunicación se han hecho eco de un estudio publicado en Molecular Biology and Evolution que sugiere como posible origen del SARS-CoV-2, el virus que causa la COVID-19, a los perros callejeros.</ORIGINAL_TEXT>
<TOKEN end_char="406" id="token-4-0" morph="none" pos="word" start_char="401">Muchos</TOKEN>
<TOKEN end_char="413" id="token-4-1" morph="none" pos="word" start_char="408">medios</TOKEN>
<TOKEN end_char="416" id="token-4-2" morph="none" pos="word" start_char="415">de</TOKEN>
<TOKEN end_char="429" id="token-4-3" morph="none" pos="word" start_char="418">comunicación</TOKEN>
<TOKEN end_char="432" id="token-4-4" morph="none" pos="word" start_char="431">se</TOKEN>
<TOKEN end_char="436" id="token-4-5" morph="none" pos="word" start_char="434">han</TOKEN>
<TOKEN end_char="442" id="token-4-6" morph="none" pos="word" start_char="438">hecho</TOKEN>
<TOKEN end_char="446" id="token-4-7" morph="none" pos="word" start_char="444">eco</TOKEN>
<TOKEN end_char="449" id="token-4-8" morph="none" pos="word" start_char="448">de</TOKEN>
<TOKEN end_char="452" id="token-4-9" morph="none" pos="word" start_char="451">un</TOKEN>
<TOKEN end_char="460" id="token-4-10" morph="none" pos="word" start_char="454">estudio</TOKEN>
<TOKEN end_char="470" id="token-4-11" morph="none" pos="word" start_char="462">publicado</TOKEN>
<TOKEN end_char="473" id="token-4-12" morph="none" pos="word" start_char="472">en</TOKEN>
<TOKEN end_char="483" id="token-4-13" morph="none" pos="word" start_char="475">Molecular</TOKEN>
<TOKEN end_char="491" id="token-4-14" morph="none" pos="word" start_char="485">Biology</TOKEN>
<TOKEN end_char="495" id="token-4-15" morph="none" pos="word" start_char="493">and</TOKEN>
<TOKEN end_char="505" id="token-4-16" morph="none" pos="word" start_char="497">Evolution</TOKEN>
<TOKEN end_char="509" id="token-4-17" morph="none" pos="word" start_char="507">que</TOKEN>
<TOKEN end_char="517" id="token-4-18" morph="none" pos="word" start_char="511">sugiere</TOKEN>
<TOKEN end_char="522" id="token-4-19" morph="none" pos="word" start_char="519">como</TOKEN>
<TOKEN end_char="530" id="token-4-20" morph="none" pos="word" start_char="524">posible</TOKEN>
<TOKEN end_char="537" id="token-4-21" morph="none" pos="word" start_char="532">origen</TOKEN>
<TOKEN end_char="541" id="token-4-22" morph="none" pos="word" start_char="539">del</TOKEN>
<TOKEN end_char="552" id="token-4-23" morph="none" pos="unknown" start_char="543">SARS-CoV-2</TOKEN>
<TOKEN end_char="553" id="token-4-24" morph="none" pos="punct" start_char="553">,</TOKEN>
<TOKEN end_char="556" id="token-4-25" morph="none" pos="word" start_char="555">el</TOKEN>
<TOKEN end_char="562" id="token-4-26" morph="none" pos="word" start_char="558">virus</TOKEN>
<TOKEN end_char="566" id="token-4-27" morph="none" pos="word" start_char="564">que</TOKEN>
<TOKEN end_char="572" id="token-4-28" morph="none" pos="word" start_char="568">causa</TOKEN>
<TOKEN end_char="575" id="token-4-29" morph="none" pos="word" start_char="574">la</TOKEN>
<TOKEN end_char="584" id="token-4-30" morph="none" pos="unknown" start_char="577">COVID-19</TOKEN>
<TOKEN end_char="585" id="token-4-31" morph="none" pos="punct" start_char="585">,</TOKEN>
<TOKEN end_char="587" id="token-4-32" morph="none" pos="word" start_char="587">a</TOKEN>
<TOKEN end_char="591" id="token-4-33" morph="none" pos="word" start_char="589">los</TOKEN>
<TOKEN end_char="598" id="token-4-34" morph="none" pos="word" start_char="593">perros</TOKEN>
<TOKEN end_char="609" id="token-4-35" morph="none" pos="word" start_char="600">callejeros</TOKEN>
<TOKEN end_char="610" id="token-4-36" morph="none" pos="punct" start_char="610">.</TOKEN>
<TRANSLATED_TEXT>Many media outlets have echoed a study published in Molecular Biology and Evolution that suggests the possible origin of SARS-CoV-2, the virus that causes COVID-19, to street dogs.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="847" id="segment-5" start_char="613">
<ORIGINAL_TEXT>Una noticia que ha sorprendido a numerosos expertos, "me resulta difícil entender cómo el autor ha podido concluir de este estudio, o hacer una hipótesis, que el virus que causa COVID-19 puede haber evolucionado a través de los perros.</ORIGINAL_TEXT>
<TOKEN end_char="615" id="token-5-0" morph="none" pos="word" start_char="613">Una</TOKEN>
<TOKEN end_char="623" id="token-5-1" morph="none" pos="word" start_char="617">noticia</TOKEN>
<TOKEN end_char="627" id="token-5-2" morph="none" pos="word" start_char="625">que</TOKEN>
<TOKEN end_char="630" id="token-5-3" morph="none" pos="word" start_char="629">ha</TOKEN>
<TOKEN end_char="642" id="token-5-4" morph="none" pos="word" start_char="632">sorprendido</TOKEN>
<TOKEN end_char="644" id="token-5-5" morph="none" pos="word" start_char="644">a</TOKEN>
<TOKEN end_char="654" id="token-5-6" morph="none" pos="word" start_char="646">numerosos</TOKEN>
<TOKEN end_char="663" id="token-5-7" morph="none" pos="word" start_char="656">expertos</TOKEN>
<TOKEN end_char="664" id="token-5-8" morph="none" pos="punct" start_char="664">,</TOKEN>
<TOKEN end_char="666" id="token-5-9" morph="none" pos="punct" start_char="666">"</TOKEN>
<TOKEN end_char="668" id="token-5-10" morph="none" pos="word" start_char="667">me</TOKEN>
<TOKEN end_char="676" id="token-5-11" morph="none" pos="word" start_char="670">resulta</TOKEN>
<TOKEN end_char="684" id="token-5-12" morph="none" pos="word" start_char="678">difícil</TOKEN>
<TOKEN end_char="693" id="token-5-13" morph="none" pos="word" start_char="686">entender</TOKEN>
<TOKEN end_char="698" id="token-5-14" morph="none" pos="word" start_char="695">cómo</TOKEN>
<TOKEN end_char="701" id="token-5-15" morph="none" pos="word" start_char="700">el</TOKEN>
<TOKEN end_char="707" id="token-5-16" morph="none" pos="word" start_char="703">autor</TOKEN>
<TOKEN end_char="710" id="token-5-17" morph="none" pos="word" start_char="709">ha</TOKEN>
<TOKEN end_char="717" id="token-5-18" morph="none" pos="word" start_char="712">podido</TOKEN>
<TOKEN end_char="726" id="token-5-19" morph="none" pos="word" start_char="719">concluir</TOKEN>
<TOKEN end_char="729" id="token-5-20" morph="none" pos="word" start_char="728">de</TOKEN>
<TOKEN end_char="734" id="token-5-21" morph="none" pos="word" start_char="731">este</TOKEN>
<TOKEN end_char="742" id="token-5-22" morph="none" pos="word" start_char="736">estudio</TOKEN>
<TOKEN end_char="743" id="token-5-23" morph="none" pos="punct" start_char="743">,</TOKEN>
<TOKEN end_char="745" id="token-5-24" morph="none" pos="word" start_char="745">o</TOKEN>
<TOKEN end_char="751" id="token-5-25" morph="none" pos="word" start_char="747">hacer</TOKEN>
<TOKEN end_char="755" id="token-5-26" morph="none" pos="word" start_char="753">una</TOKEN>
<TOKEN end_char="765" id="token-5-27" morph="none" pos="word" start_char="757">hipótesis</TOKEN>
<TOKEN end_char="766" id="token-5-28" morph="none" pos="punct" start_char="766">,</TOKEN>
<TOKEN end_char="770" id="token-5-29" morph="none" pos="word" start_char="768">que</TOKEN>
<TOKEN end_char="773" id="token-5-30" morph="none" pos="word" start_char="772">el</TOKEN>
<TOKEN end_char="779" id="token-5-31" morph="none" pos="word" start_char="775">virus</TOKEN>
<TOKEN end_char="783" id="token-5-32" morph="none" pos="word" start_char="781">que</TOKEN>
<TOKEN end_char="789" id="token-5-33" morph="none" pos="word" start_char="785">causa</TOKEN>
<TOKEN end_char="798" id="token-5-34" morph="none" pos="unknown" start_char="791">COVID-19</TOKEN>
<TOKEN end_char="804" id="token-5-35" morph="none" pos="word" start_char="800">puede</TOKEN>
<TOKEN end_char="810" id="token-5-36" morph="none" pos="word" start_char="806">haber</TOKEN>
<TOKEN end_char="823" id="token-5-37" morph="none" pos="word" start_char="812">evolucionado</TOKEN>
<TOKEN end_char="825" id="token-5-38" morph="none" pos="word" start_char="825">a</TOKEN>
<TOKEN end_char="832" id="token-5-39" morph="none" pos="word" start_char="827">través</TOKEN>
<TOKEN end_char="835" id="token-5-40" morph="none" pos="word" start_char="834">de</TOKEN>
<TOKEN end_char="839" id="token-5-41" morph="none" pos="word" start_char="837">los</TOKEN>
<TOKEN end_char="846" id="token-5-42" morph="none" pos="word" start_char="841">perros</TOKEN>
<TOKEN end_char="847" id="token-5-43" morph="none" pos="punct" start_char="847">.</TOKEN>
<TRANSLATED_TEXT>A news that has surprised many experts, "I find it difficult to understand how the author has been able to conclude from this study, or to make a hypothesis, that the virus that causes COVID-19 may have evolved through dogs.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="900" id="segment-6" start_char="849">
<ORIGINAL_TEXT>Hay demasiada inferencia y muy pocos datos directos.</ORIGINAL_TEXT>
<TOKEN end_char="851" id="token-6-0" morph="none" pos="word" start_char="849">Hay</TOKEN>
<TOKEN end_char="861" id="token-6-1" morph="none" pos="word" start_char="853">demasiada</TOKEN>
<TOKEN end_char="872" id="token-6-2" morph="none" pos="word" start_char="863">inferencia</TOKEN>
<TOKEN end_char="874" id="token-6-3" morph="none" pos="word" start_char="874">y</TOKEN>
<TOKEN end_char="878" id="token-6-4" morph="none" pos="word" start_char="876">muy</TOKEN>
<TOKEN end_char="884" id="token-6-5" morph="none" pos="word" start_char="880">pocos</TOKEN>
<TOKEN end_char="890" id="token-6-6" morph="none" pos="word" start_char="886">datos</TOKEN>
<TOKEN end_char="899" id="token-6-7" morph="none" pos="word" start_char="892">directos</TOKEN>
<TOKEN end_char="900" id="token-6-8" morph="none" pos="punct" start_char="900">.</TOKEN>
<TRANSLATED_TEXT>There is too much inference and too little direct data.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1029" id="segment-7" start_char="902">
<ORIGINAL_TEXT>No veo nada en este documento que respalde esta suposición y me preocupa que este documento haya sido publicado en esta revista.</ORIGINAL_TEXT>
<TOKEN end_char="903" id="token-7-0" morph="none" pos="word" start_char="902">No</TOKEN>
<TOKEN end_char="907" id="token-7-1" morph="none" pos="word" start_char="905">veo</TOKEN>
<TOKEN end_char="912" id="token-7-2" morph="none" pos="word" start_char="909">nada</TOKEN>
<TOKEN end_char="915" id="token-7-3" morph="none" pos="word" start_char="914">en</TOKEN>
<TOKEN end_char="920" id="token-7-4" morph="none" pos="word" start_char="917">este</TOKEN>
<TOKEN end_char="930" id="token-7-5" morph="none" pos="word" start_char="922">documento</TOKEN>
<TOKEN end_char="934" id="token-7-6" morph="none" pos="word" start_char="932">que</TOKEN>
<TOKEN end_char="943" id="token-7-7" morph="none" pos="word" start_char="936">respalde</TOKEN>
<TOKEN end_char="948" id="token-7-8" morph="none" pos="word" start_char="945">esta</TOKEN>
<TOKEN end_char="959" id="token-7-9" morph="none" pos="word" start_char="950">suposición</TOKEN>
<TOKEN end_char="961" id="token-7-10" morph="none" pos="word" start_char="961">y</TOKEN>
<TOKEN end_char="964" id="token-7-11" morph="none" pos="word" start_char="963">me</TOKEN>
<TOKEN end_char="973" id="token-7-12" morph="none" pos="word" start_char="966">preocupa</TOKEN>
<TOKEN end_char="977" id="token-7-13" morph="none" pos="word" start_char="975">que</TOKEN>
<TOKEN end_char="982" id="token-7-14" morph="none" pos="word" start_char="979">este</TOKEN>
<TOKEN end_char="992" id="token-7-15" morph="none" pos="word" start_char="984">documento</TOKEN>
<TOKEN end_char="997" id="token-7-16" morph="none" pos="word" start_char="994">haya</TOKEN>
<TOKEN end_char="1002" id="token-7-17" morph="none" pos="word" start_char="999">sido</TOKEN>
<TOKEN end_char="1012" id="token-7-18" morph="none" pos="word" start_char="1004">publicado</TOKEN>
<TOKEN end_char="1015" id="token-7-19" morph="none" pos="word" start_char="1014">en</TOKEN>
<TOKEN end_char="1020" id="token-7-20" morph="none" pos="word" start_char="1017">esta</TOKEN>
<TOKEN end_char="1028" id="token-7-21" morph="none" pos="word" start_char="1022">revista</TOKEN>
<TOKEN end_char="1029" id="token-7-22" morph="none" pos="punct" start_char="1029">.</TOKEN>
<TRANSLATED_TEXT>I see nothing in this document that supports this assumption and I am concerned that this document has been published in this magazine.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1266" id="segment-8" start_char="1031">
<ORIGINAL_TEXT>No creo que ningún dueño de perro deba preocuparse como resultado de este trabajo", señala James Wood, jefe del Departamento de Medicina Veterinaria e investigador de infecciones y control de enfermedades de la Universidad de Cambridge.</ORIGINAL_TEXT>
<TOKEN end_char="1032" id="token-8-0" morph="none" pos="word" start_char="1031">No</TOKEN>
<TOKEN end_char="1037" id="token-8-1" morph="none" pos="word" start_char="1034">creo</TOKEN>
<TOKEN end_char="1041" id="token-8-2" morph="none" pos="word" start_char="1039">que</TOKEN>
<TOKEN end_char="1048" id="token-8-3" morph="none" pos="word" start_char="1043">ningún</TOKEN>
<TOKEN end_char="1054" id="token-8-4" morph="none" pos="word" start_char="1050">dueño</TOKEN>
<TOKEN end_char="1057" id="token-8-5" morph="none" pos="word" start_char="1056">de</TOKEN>
<TOKEN end_char="1063" id="token-8-6" morph="none" pos="word" start_char="1059">perro</TOKEN>
<TOKEN end_char="1068" id="token-8-7" morph="none" pos="word" start_char="1065">deba</TOKEN>
<TOKEN end_char="1080" id="token-8-8" morph="none" pos="word" start_char="1070">preocuparse</TOKEN>
<TOKEN end_char="1085" id="token-8-9" morph="none" pos="word" start_char="1082">como</TOKEN>
<TOKEN end_char="1095" id="token-8-10" morph="none" pos="word" start_char="1087">resultado</TOKEN>
<TOKEN end_char="1098" id="token-8-11" morph="none" pos="word" start_char="1097">de</TOKEN>
<TOKEN end_char="1103" id="token-8-12" morph="none" pos="word" start_char="1100">este</TOKEN>
<TOKEN end_char="1111" id="token-8-13" morph="none" pos="word" start_char="1105">trabajo</TOKEN>
<TOKEN end_char="1113" id="token-8-14" morph="none" pos="punct" start_char="1112">",</TOKEN>
<TOKEN end_char="1120" id="token-8-15" morph="none" pos="word" start_char="1115">señala</TOKEN>
<TOKEN end_char="1126" id="token-8-16" morph="none" pos="word" start_char="1122">James</TOKEN>
<TOKEN end_char="1131" id="token-8-17" morph="none" pos="word" start_char="1128">Wood</TOKEN>
<TOKEN end_char="1132" id="token-8-18" morph="none" pos="punct" start_char="1132">,</TOKEN>
<TOKEN end_char="1137" id="token-8-19" morph="none" pos="word" start_char="1134">jefe</TOKEN>
<TOKEN end_char="1141" id="token-8-20" morph="none" pos="word" start_char="1139">del</TOKEN>
<TOKEN end_char="1154" id="token-8-21" morph="none" pos="word" start_char="1143">Departamento</TOKEN>
<TOKEN end_char="1157" id="token-8-22" morph="none" pos="word" start_char="1156">de</TOKEN>
<TOKEN end_char="1166" id="token-8-23" morph="none" pos="word" start_char="1159">Medicina</TOKEN>
<TOKEN end_char="1178" id="token-8-24" morph="none" pos="word" start_char="1168">Veterinaria</TOKEN>
<TOKEN end_char="1180" id="token-8-25" morph="none" pos="word" start_char="1180">e</TOKEN>
<TOKEN end_char="1193" id="token-8-26" morph="none" pos="word" start_char="1182">investigador</TOKEN>
<TOKEN end_char="1196" id="token-8-27" morph="none" pos="word" start_char="1195">de</TOKEN>
<TOKEN end_char="1208" id="token-8-28" morph="none" pos="word" start_char="1198">infecciones</TOKEN>
<TOKEN end_char="1210" id="token-8-29" morph="none" pos="word" start_char="1210">y</TOKEN>
<TOKEN end_char="1218" id="token-8-30" morph="none" pos="word" start_char="1212">control</TOKEN>
<TOKEN end_char="1221" id="token-8-31" morph="none" pos="word" start_char="1220">de</TOKEN>
<TOKEN end_char="1234" id="token-8-32" morph="none" pos="word" start_char="1223">enfermedades</TOKEN>
<TOKEN end_char="1237" id="token-8-33" morph="none" pos="word" start_char="1236">de</TOKEN>
<TOKEN end_char="1240" id="token-8-34" morph="none" pos="word" start_char="1239">la</TOKEN>
<TOKEN end_char="1252" id="token-8-35" morph="none" pos="word" start_char="1242">Universidad</TOKEN>
<TOKEN end_char="1255" id="token-8-36" morph="none" pos="word" start_char="1254">de</TOKEN>
<TOKEN end_char="1265" id="token-8-37" morph="none" pos="word" start_char="1257">Cambridge</TOKEN>
<TOKEN end_char="1266" id="token-8-38" morph="none" pos="punct" start_char="1266">.</TOKEN>
<TRANSLATED_TEXT>I don't think any dog owner should worry as a result of this work, "says James Wood, head of the Department of Veterinary Medicine and an infection and disease control researcher at the University of Cambridge.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1607" id="segment-9" start_char="1269">
<ORIGINAL_TEXT>Paul Digard, profesor de Virología del Roslin Institute de la Universidad de Edimburgo, apunta que "la investigación del Dr. Xia adopta un enfoque muy limitado para examinar la secuencia del SARS-CoV-2 en busca de pistas sobre su origen que no brindan un respaldo convincente para la hipótesis de que los perros fueron la fuente del virus.</ORIGINAL_TEXT>
<TOKEN end_char="1272" id="token-9-0" morph="none" pos="word" start_char="1269">Paul</TOKEN>
<TOKEN end_char="1279" id="token-9-1" morph="none" pos="word" start_char="1274">Digard</TOKEN>
<TOKEN end_char="1280" id="token-9-2" morph="none" pos="punct" start_char="1280">,</TOKEN>
<TOKEN end_char="1289" id="token-9-3" morph="none" pos="word" start_char="1282">profesor</TOKEN>
<TOKEN end_char="1292" id="token-9-4" morph="none" pos="word" start_char="1291">de</TOKEN>
<TOKEN end_char="1302" id="token-9-5" morph="none" pos="word" start_char="1294">Virología</TOKEN>
<TOKEN end_char="1306" id="token-9-6" morph="none" pos="word" start_char="1304">del</TOKEN>
<TOKEN end_char="1313" id="token-9-7" morph="none" pos="word" start_char="1308">Roslin</TOKEN>
<TOKEN end_char="1323" id="token-9-8" morph="none" pos="word" start_char="1315">Institute</TOKEN>
<TOKEN end_char="1326" id="token-9-9" morph="none" pos="word" start_char="1325">de</TOKEN>
<TOKEN end_char="1329" id="token-9-10" morph="none" pos="word" start_char="1328">la</TOKEN>
<TOKEN end_char="1341" id="token-9-11" morph="none" pos="word" start_char="1331">Universidad</TOKEN>
<TOKEN end_char="1344" id="token-9-12" morph="none" pos="word" start_char="1343">de</TOKEN>
<TOKEN end_char="1354" id="token-9-13" morph="none" pos="word" start_char="1346">Edimburgo</TOKEN>
<TOKEN end_char="1355" id="token-9-14" morph="none" pos="punct" start_char="1355">,</TOKEN>
<TOKEN end_char="1362" id="token-9-15" morph="none" pos="word" start_char="1357">apunta</TOKEN>
<TOKEN end_char="1366" id="token-9-16" morph="none" pos="word" start_char="1364">que</TOKEN>
<TOKEN end_char="1368" id="token-9-17" morph="none" pos="punct" start_char="1368">"</TOKEN>
<TOKEN end_char="1370" id="token-9-18" morph="none" pos="word" start_char="1369">la</TOKEN>
<TOKEN end_char="1384" id="token-9-19" morph="none" pos="word" start_char="1372">investigación</TOKEN>
<TOKEN end_char="1388" id="token-9-20" morph="none" pos="word" start_char="1386">del</TOKEN>
<TOKEN end_char="1391" id="token-9-21" morph="none" pos="word" start_char="1390">Dr</TOKEN>
<TOKEN end_char="1392" id="token-9-22" morph="none" pos="punct" start_char="1392">.</TOKEN>
<TOKEN end_char="1396" id="token-9-23" morph="none" pos="word" start_char="1394">Xia</TOKEN>
<TOKEN end_char="1403" id="token-9-24" morph="none" pos="word" start_char="1398">adopta</TOKEN>
<TOKEN end_char="1406" id="token-9-25" morph="none" pos="word" start_char="1405">un</TOKEN>
<TOKEN end_char="1414" id="token-9-26" morph="none" pos="word" start_char="1408">enfoque</TOKEN>
<TOKEN end_char="1418" id="token-9-27" morph="none" pos="word" start_char="1416">muy</TOKEN>
<TOKEN end_char="1427" id="token-9-28" morph="none" pos="word" start_char="1420">limitado</TOKEN>
<TOKEN end_char="1432" id="token-9-29" morph="none" pos="word" start_char="1429">para</TOKEN>
<TOKEN end_char="1441" id="token-9-30" morph="none" pos="word" start_char="1434">examinar</TOKEN>
<TOKEN end_char="1444" id="token-9-31" morph="none" pos="word" start_char="1443">la</TOKEN>
<TOKEN end_char="1454" id="token-9-32" morph="none" pos="word" start_char="1446">secuencia</TOKEN>
<TOKEN end_char="1458" id="token-9-33" morph="none" pos="word" start_char="1456">del</TOKEN>
<TOKEN end_char="1469" id="token-9-34" morph="none" pos="unknown" start_char="1460">SARS-CoV-2</TOKEN>
<TOKEN end_char="1472" id="token-9-35" morph="none" pos="word" start_char="1471">en</TOKEN>
<TOKEN end_char="1478" id="token-9-36" morph="none" pos="word" start_char="1474">busca</TOKEN>
<TOKEN end_char="1481" id="token-9-37" morph="none" pos="word" start_char="1480">de</TOKEN>
<TOKEN end_char="1488" id="token-9-38" morph="none" pos="word" start_char="1483">pistas</TOKEN>
<TOKEN end_char="1494" id="token-9-39" morph="none" pos="word" start_char="1490">sobre</TOKEN>
<TOKEN end_char="1497" id="token-9-40" morph="none" pos="word" start_char="1496">su</TOKEN>
<TOKEN end_char="1504" id="token-9-41" morph="none" pos="word" start_char="1499">origen</TOKEN>
<TOKEN end_char="1508" id="token-9-42" morph="none" pos="word" start_char="1506">que</TOKEN>
<TOKEN end_char="1511" id="token-9-43" morph="none" pos="word" start_char="1510">no</TOKEN>
<TOKEN end_char="1519" id="token-9-44" morph="none" pos="word" start_char="1513">brindan</TOKEN>
<TOKEN end_char="1522" id="token-9-45" morph="none" pos="word" start_char="1521">un</TOKEN>
<TOKEN end_char="1531" id="token-9-46" morph="none" pos="word" start_char="1524">respaldo</TOKEN>
<TOKEN end_char="1543" id="token-9-47" morph="none" pos="word" start_char="1533">convincente</TOKEN>
<TOKEN end_char="1548" id="token-9-48" morph="none" pos="word" start_char="1545">para</TOKEN>
<TOKEN end_char="1551" id="token-9-49" morph="none" pos="word" start_char="1550">la</TOKEN>
<TOKEN end_char="1561" id="token-9-50" morph="none" pos="word" start_char="1553">hipótesis</TOKEN>
<TOKEN end_char="1564" id="token-9-51" morph="none" pos="word" start_char="1563">de</TOKEN>
<TOKEN end_char="1568" id="token-9-52" morph="none" pos="word" start_char="1566">que</TOKEN>
<TOKEN end_char="1572" id="token-9-53" morph="none" pos="word" start_char="1570">los</TOKEN>
<TOKEN end_char="1579" id="token-9-54" morph="none" pos="word" start_char="1574">perros</TOKEN>
<TOKEN end_char="1586" id="token-9-55" morph="none" pos="word" start_char="1581">fueron</TOKEN>
<TOKEN end_char="1589" id="token-9-56" morph="none" pos="word" start_char="1588">la</TOKEN>
<TOKEN end_char="1596" id="token-9-57" morph="none" pos="word" start_char="1591">fuente</TOKEN>
<TOKEN end_char="1600" id="token-9-58" morph="none" pos="word" start_char="1598">del</TOKEN>
<TOKEN end_char="1606" id="token-9-59" morph="none" pos="word" start_char="1602">virus</TOKEN>
<TOKEN end_char="1607" id="token-9-60" morph="none" pos="punct" start_char="1607">.</TOKEN>
<TRANSLATED_TEXT>Paul Digard, Professor of Virology at the Roslin Institute at the University of Edinburgh, notes that "Dr. Xia's research takes a very limited approach to examining the SARS-CoV-2 sequence in search of clues about its origin that do not provide convincing support for the hypothesis that dogs were the source of the virus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1754" id="segment-10" start_char="1609">
<ORIGINAL_TEXT>La investigación ciertamente no justifica el titular del comunicado de prensa ("... perros callejeros como el posible origen del SARS-CoV-2 ...")"</ORIGINAL_TEXT>
<TOKEN end_char="1610" id="token-10-0" morph="none" pos="word" start_char="1609">La</TOKEN>
<TOKEN end_char="1624" id="token-10-1" morph="none" pos="word" start_char="1612">investigación</TOKEN>
<TOKEN end_char="1636" id="token-10-2" morph="none" pos="word" start_char="1626">ciertamente</TOKEN>
<TOKEN end_char="1639" id="token-10-3" morph="none" pos="word" start_char="1638">no</TOKEN>
<TOKEN end_char="1649" id="token-10-4" morph="none" pos="word" start_char="1641">justifica</TOKEN>
<TOKEN end_char="1652" id="token-10-5" morph="none" pos="word" start_char="1651">el</TOKEN>
<TOKEN end_char="1660" id="token-10-6" morph="none" pos="word" start_char="1654">titular</TOKEN>
<TOKEN end_char="1664" id="token-10-7" morph="none" pos="word" start_char="1662">del</TOKEN>
<TOKEN end_char="1675" id="token-10-8" morph="none" pos="word" start_char="1666">comunicado</TOKEN>
<TOKEN end_char="1678" id="token-10-9" morph="none" pos="word" start_char="1677">de</TOKEN>
<TOKEN end_char="1685" id="token-10-10" morph="none" pos="word" start_char="1680">prensa</TOKEN>
<TOKEN end_char="1691" id="token-10-11" morph="none" pos="punct" start_char="1687">("...</TOKEN>
<TOKEN end_char="1698" id="token-10-12" morph="none" pos="word" start_char="1693">perros</TOKEN>
<TOKEN end_char="1709" id="token-10-13" morph="none" pos="word" start_char="1700">callejeros</TOKEN>
<TOKEN end_char="1714" id="token-10-14" morph="none" pos="word" start_char="1711">como</TOKEN>
<TOKEN end_char="1717" id="token-10-15" morph="none" pos="word" start_char="1716">el</TOKEN>
<TOKEN end_char="1725" id="token-10-16" morph="none" pos="word" start_char="1719">posible</TOKEN>
<TOKEN end_char="1732" id="token-10-17" morph="none" pos="word" start_char="1727">origen</TOKEN>
<TOKEN end_char="1736" id="token-10-18" morph="none" pos="word" start_char="1734">del</TOKEN>
<TOKEN end_char="1747" id="token-10-19" morph="none" pos="unknown" start_char="1738">SARS-CoV-2</TOKEN>
<TOKEN end_char="1754" id="token-10-20" morph="none" pos="punct" start_char="1749">...")"</TOKEN>
<TRANSLATED_TEXT>The investigation certainly does not justify the holder of the press release (... "street dogs as the possible origin of SARS-CoV-2...") "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2090" id="segment-11" start_char="1757">
<ORIGINAL_TEXT>Por su parte, Ben Neuman, jefe del Departamento de Ciencias Biológicas en la Universidad Texas A y profesor visitante en la Universidad de Reading, asegura que "la conclusión de que los gatos o los perros estuvieron involucrados como huésped intermedio para el SARS-CoV-2 es altamente especulativo y no debe presentarse como un hecho.</ORIGINAL_TEXT>
<TOKEN end_char="1759" id="token-11-0" morph="none" pos="word" start_char="1757">Por</TOKEN>
<TOKEN end_char="1762" id="token-11-1" morph="none" pos="word" start_char="1761">su</TOKEN>
<TOKEN end_char="1768" id="token-11-2" morph="none" pos="word" start_char="1764">parte</TOKEN>
<TOKEN end_char="1769" id="token-11-3" morph="none" pos="punct" start_char="1769">,</TOKEN>
<TOKEN end_char="1773" id="token-11-4" morph="none" pos="word" start_char="1771">Ben</TOKEN>
<TOKEN end_char="1780" id="token-11-5" morph="none" pos="word" start_char="1775">Neuman</TOKEN>
<TOKEN end_char="1781" id="token-11-6" morph="none" pos="punct" start_char="1781">,</TOKEN>
<TOKEN end_char="1786" id="token-11-7" morph="none" pos="word" start_char="1783">jefe</TOKEN>
<TOKEN end_char="1790" id="token-11-8" morph="none" pos="word" start_char="1788">del</TOKEN>
<TOKEN end_char="1803" id="token-11-9" morph="none" pos="word" start_char="1792">Departamento</TOKEN>
<TOKEN end_char="1806" id="token-11-10" morph="none" pos="word" start_char="1805">de</TOKEN>
<TOKEN end_char="1815" id="token-11-11" morph="none" pos="word" start_char="1808">Ciencias</TOKEN>
<TOKEN end_char="1826" id="token-11-12" morph="none" pos="word" start_char="1817">Biológicas</TOKEN>
<TOKEN end_char="1829" id="token-11-13" morph="none" pos="word" start_char="1828">en</TOKEN>
<TOKEN end_char="1832" id="token-11-14" morph="none" pos="word" start_char="1831">la</TOKEN>
<TOKEN end_char="1844" id="token-11-15" morph="none" pos="word" start_char="1834">Universidad</TOKEN>
<TOKEN end_char="1850" id="token-11-16" morph="none" pos="word" start_char="1846">Texas</TOKEN>
<TOKEN end_char="1852" id="token-11-17" morph="none" pos="word" start_char="1852">A</TOKEN>
<TOKEN end_char="1854" id="token-11-18" morph="none" pos="word" start_char="1854">y</TOKEN>
<TOKEN end_char="1863" id="token-11-19" morph="none" pos="word" start_char="1856">profesor</TOKEN>
<TOKEN end_char="1873" id="token-11-20" morph="none" pos="word" start_char="1865">visitante</TOKEN>
<TOKEN end_char="1876" id="token-11-21" morph="none" pos="word" start_char="1875">en</TOKEN>
<TOKEN end_char="1879" id="token-11-22" morph="none" pos="word" start_char="1878">la</TOKEN>
<TOKEN end_char="1891" id="token-11-23" morph="none" pos="word" start_char="1881">Universidad</TOKEN>
<TOKEN end_char="1894" id="token-11-24" morph="none" pos="word" start_char="1893">de</TOKEN>
<TOKEN end_char="1902" id="token-11-25" morph="none" pos="word" start_char="1896">Reading</TOKEN>
<TOKEN end_char="1903" id="token-11-26" morph="none" pos="punct" start_char="1903">,</TOKEN>
<TOKEN end_char="1911" id="token-11-27" morph="none" pos="word" start_char="1905">asegura</TOKEN>
<TOKEN end_char="1915" id="token-11-28" morph="none" pos="word" start_char="1913">que</TOKEN>
<TOKEN end_char="1917" id="token-11-29" morph="none" pos="punct" start_char="1917">"</TOKEN>
<TOKEN end_char="1919" id="token-11-30" morph="none" pos="word" start_char="1918">la</TOKEN>
<TOKEN end_char="1930" id="token-11-31" morph="none" pos="word" start_char="1921">conclusión</TOKEN>
<TOKEN end_char="1933" id="token-11-32" morph="none" pos="word" start_char="1932">de</TOKEN>
<TOKEN end_char="1937" id="token-11-33" morph="none" pos="word" start_char="1935">que</TOKEN>
<TOKEN end_char="1941" id="token-11-34" morph="none" pos="word" start_char="1939">los</TOKEN>
<TOKEN end_char="1947" id="token-11-35" morph="none" pos="word" start_char="1943">gatos</TOKEN>
<TOKEN end_char="1949" id="token-11-36" morph="none" pos="word" start_char="1949">o</TOKEN>
<TOKEN end_char="1953" id="token-11-37" morph="none" pos="word" start_char="1951">los</TOKEN>
<TOKEN end_char="1960" id="token-11-38" morph="none" pos="word" start_char="1955">perros</TOKEN>
<TOKEN end_char="1971" id="token-11-39" morph="none" pos="word" start_char="1962">estuvieron</TOKEN>
<TOKEN end_char="1984" id="token-11-40" morph="none" pos="word" start_char="1973">involucrados</TOKEN>
<TOKEN end_char="1989" id="token-11-41" morph="none" pos="word" start_char="1986">como</TOKEN>
<TOKEN end_char="1997" id="token-11-42" morph="none" pos="word" start_char="1991">huésped</TOKEN>
<TOKEN end_char="2008" id="token-11-43" morph="none" pos="word" start_char="1999">intermedio</TOKEN>
<TOKEN end_char="2013" id="token-11-44" morph="none" pos="word" start_char="2010">para</TOKEN>
<TOKEN end_char="2016" id="token-11-45" morph="none" pos="word" start_char="2015">el</TOKEN>
<TOKEN end_char="2027" id="token-11-46" morph="none" pos="unknown" start_char="2018">SARS-CoV-2</TOKEN>
<TOKEN end_char="2030" id="token-11-47" morph="none" pos="word" start_char="2029">es</TOKEN>
<TOKEN end_char="2040" id="token-11-48" morph="none" pos="word" start_char="2032">altamente</TOKEN>
<TOKEN end_char="2053" id="token-11-49" morph="none" pos="word" start_char="2042">especulativo</TOKEN>
<TOKEN end_char="2055" id="token-11-50" morph="none" pos="word" start_char="2055">y</TOKEN>
<TOKEN end_char="2058" id="token-11-51" morph="none" pos="word" start_char="2057">no</TOKEN>
<TOKEN end_char="2063" id="token-11-52" morph="none" pos="word" start_char="2060">debe</TOKEN>
<TOKEN end_char="2075" id="token-11-53" morph="none" pos="word" start_char="2065">presentarse</TOKEN>
<TOKEN end_char="2080" id="token-11-54" morph="none" pos="word" start_char="2077">como</TOKEN>
<TOKEN end_char="2083" id="token-11-55" morph="none" pos="word" start_char="2082">un</TOKEN>
<TOKEN end_char="2089" id="token-11-56" morph="none" pos="word" start_char="2085">hecho</TOKEN>
<TOKEN end_char="2090" id="token-11-57" morph="none" pos="punct" start_char="2090">.</TOKEN>
<TRANSLATED_TEXT>Ben Neuman, head of the Department of Biological Sciences at Texas A University and visiting professor at the University of Reading, states that "the conclusion that cats or dogs were involved as an intermediate host for SARS-CoV-2 is highly speculative and should not be presented as a fact.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2278" id="segment-12" start_char="2092">
<ORIGINAL_TEXT>Se necesitarán algunos datos nuevos para finalmente resolver el misterio del origen del SARS-CoV-2, pero este estudio se basa en un nuevo análisis de datos antiguos sin ningún dato nuevo.</ORIGINAL_TEXT>
<TOKEN end_char="2093" id="token-12-0" morph="none" pos="word" start_char="2092">Se</TOKEN>
<TOKEN end_char="2105" id="token-12-1" morph="none" pos="word" start_char="2095">necesitarán</TOKEN>
<TOKEN end_char="2113" id="token-12-2" morph="none" pos="word" start_char="2107">algunos</TOKEN>
<TOKEN end_char="2119" id="token-12-3" morph="none" pos="word" start_char="2115">datos</TOKEN>
<TOKEN end_char="2126" id="token-12-4" morph="none" pos="word" start_char="2121">nuevos</TOKEN>
<TOKEN end_char="2131" id="token-12-5" morph="none" pos="word" start_char="2128">para</TOKEN>
<TOKEN end_char="2142" id="token-12-6" morph="none" pos="word" start_char="2133">finalmente</TOKEN>
<TOKEN end_char="2151" id="token-12-7" morph="none" pos="word" start_char="2144">resolver</TOKEN>
<TOKEN end_char="2154" id="token-12-8" morph="none" pos="word" start_char="2153">el</TOKEN>
<TOKEN end_char="2163" id="token-12-9" morph="none" pos="word" start_char="2156">misterio</TOKEN>
<TOKEN end_char="2167" id="token-12-10" morph="none" pos="word" start_char="2165">del</TOKEN>
<TOKEN end_char="2174" id="token-12-11" morph="none" pos="word" start_char="2169">origen</TOKEN>
<TOKEN end_char="2178" id="token-12-12" morph="none" pos="word" start_char="2176">del</TOKEN>
<TOKEN end_char="2189" id="token-12-13" morph="none" pos="unknown" start_char="2180">SARS-CoV-2</TOKEN>
<TOKEN end_char="2190" id="token-12-14" morph="none" pos="punct" start_char="2190">,</TOKEN>
<TOKEN end_char="2195" id="token-12-15" morph="none" pos="word" start_char="2192">pero</TOKEN>
<TOKEN end_char="2200" id="token-12-16" morph="none" pos="word" start_char="2197">este</TOKEN>
<TOKEN end_char="2208" id="token-12-17" morph="none" pos="word" start_char="2202">estudio</TOKEN>
<TOKEN end_char="2211" id="token-12-18" morph="none" pos="word" start_char="2210">se</TOKEN>
<TOKEN end_char="2216" id="token-12-19" morph="none" pos="word" start_char="2213">basa</TOKEN>
<TOKEN end_char="2219" id="token-12-20" morph="none" pos="word" start_char="2218">en</TOKEN>
<TOKEN end_char="2222" id="token-12-21" morph="none" pos="word" start_char="2221">un</TOKEN>
<TOKEN end_char="2228" id="token-12-22" morph="none" pos="word" start_char="2224">nuevo</TOKEN>
<TOKEN end_char="2237" id="token-12-23" morph="none" pos="word" start_char="2230">análisis</TOKEN>
<TOKEN end_char="2240" id="token-12-24" morph="none" pos="word" start_char="2239">de</TOKEN>
<TOKEN end_char="2246" id="token-12-25" morph="none" pos="word" start_char="2242">datos</TOKEN>
<TOKEN end_char="2255" id="token-12-26" morph="none" pos="word" start_char="2248">antiguos</TOKEN>
<TOKEN end_char="2259" id="token-12-27" morph="none" pos="word" start_char="2257">sin</TOKEN>
<TOKEN end_char="2266" id="token-12-28" morph="none" pos="word" start_char="2261">ningún</TOKEN>
<TOKEN end_char="2271" id="token-12-29" morph="none" pos="word" start_char="2268">dato</TOKEN>
<TOKEN end_char="2277" id="token-12-30" morph="none" pos="word" start_char="2273">nuevo</TOKEN>
<TOKEN end_char="2278" id="token-12-31" morph="none" pos="punct" start_char="2278">.</TOKEN>
<TRANSLATED_TEXT>Some new data will be needed to finally solve the mystery of the origin of SARS-CoV-2, but this study is based on a new analysis of old data without any new data.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2412" id="segment-13" start_char="2280">
<ORIGINAL_TEXT>Este estudio tiene similitudes con un artículo anterior que identificaba incorrectamente el origen del SARS-CoV-2 en las serpientes".</ORIGINAL_TEXT>
<TOKEN end_char="2283" id="token-13-0" morph="none" pos="word" start_char="2280">Este</TOKEN>
<TOKEN end_char="2291" id="token-13-1" morph="none" pos="word" start_char="2285">estudio</TOKEN>
<TOKEN end_char="2297" id="token-13-2" morph="none" pos="word" start_char="2293">tiene</TOKEN>
<TOKEN end_char="2309" id="token-13-3" morph="none" pos="word" start_char="2299">similitudes</TOKEN>
<TOKEN end_char="2313" id="token-13-4" morph="none" pos="word" start_char="2311">con</TOKEN>
<TOKEN end_char="2316" id="token-13-5" morph="none" pos="word" start_char="2315">un</TOKEN>
<TOKEN end_char="2325" id="token-13-6" morph="none" pos="word" start_char="2318">artículo</TOKEN>
<TOKEN end_char="2334" id="token-13-7" morph="none" pos="word" start_char="2327">anterior</TOKEN>
<TOKEN end_char="2338" id="token-13-8" morph="none" pos="word" start_char="2336">que</TOKEN>
<TOKEN end_char="2351" id="token-13-9" morph="none" pos="word" start_char="2340">identificaba</TOKEN>
<TOKEN end_char="2367" id="token-13-10" morph="none" pos="word" start_char="2353">incorrectamente</TOKEN>
<TOKEN end_char="2370" id="token-13-11" morph="none" pos="word" start_char="2369">el</TOKEN>
<TOKEN end_char="2377" id="token-13-12" morph="none" pos="word" start_char="2372">origen</TOKEN>
<TOKEN end_char="2381" id="token-13-13" morph="none" pos="word" start_char="2379">del</TOKEN>
<TOKEN end_char="2392" id="token-13-14" morph="none" pos="unknown" start_char="2383">SARS-CoV-2</TOKEN>
<TOKEN end_char="2395" id="token-13-15" morph="none" pos="word" start_char="2394">en</TOKEN>
<TOKEN end_char="2399" id="token-13-16" morph="none" pos="word" start_char="2397">las</TOKEN>
<TOKEN end_char="2410" id="token-13-17" morph="none" pos="word" start_char="2401">serpientes</TOKEN>
<TOKEN end_char="2412" id="token-13-18" morph="none" pos="punct" start_char="2411">".</TOKEN>
<TRANSLATED_TEXT>This study has similarities to an earlier article that incorrectly identified the origin of SARS-CoV-2 in snakes. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2713" id="segment-14" start_char="2415">
<ORIGINAL_TEXT>La presidenta de la Asociación Británica de Veterinaria (BVA, por sus siglas en inglés), Daniella Dos Santos, manifiesta que "esta investigación es puramente teórica y el autor mismo señala que hasta la fecha no hay evidencia de que los perros puedan replicar o eliminar el virus que causa COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="2416" id="token-14-0" morph="none" pos="word" start_char="2415">La</TOKEN>
<TOKEN end_char="2427" id="token-14-1" morph="none" pos="word" start_char="2418">presidenta</TOKEN>
<TOKEN end_char="2430" id="token-14-2" morph="none" pos="word" start_char="2429">de</TOKEN>
<TOKEN end_char="2433" id="token-14-3" morph="none" pos="word" start_char="2432">la</TOKEN>
<TOKEN end_char="2444" id="token-14-4" morph="none" pos="word" start_char="2435">Asociación</TOKEN>
<TOKEN end_char="2454" id="token-14-5" morph="none" pos="word" start_char="2446">Británica</TOKEN>
<TOKEN end_char="2457" id="token-14-6" morph="none" pos="word" start_char="2456">de</TOKEN>
<TOKEN end_char="2469" id="token-14-7" morph="none" pos="word" start_char="2459">Veterinaria</TOKEN>
<TOKEN end_char="2471" id="token-14-8" morph="none" pos="punct" start_char="2471">(</TOKEN>
<TOKEN end_char="2474" id="token-14-9" morph="none" pos="word" start_char="2472">BVA</TOKEN>
<TOKEN end_char="2475" id="token-14-10" morph="none" pos="punct" start_char="2475">,</TOKEN>
<TOKEN end_char="2479" id="token-14-11" morph="none" pos="word" start_char="2477">por</TOKEN>
<TOKEN end_char="2483" id="token-14-12" morph="none" pos="word" start_char="2481">sus</TOKEN>
<TOKEN end_char="2490" id="token-14-13" morph="none" pos="word" start_char="2485">siglas</TOKEN>
<TOKEN end_char="2493" id="token-14-14" morph="none" pos="word" start_char="2492">en</TOKEN>
<TOKEN end_char="2500" id="token-14-15" morph="none" pos="word" start_char="2495">inglés</TOKEN>
<TOKEN end_char="2502" id="token-14-16" morph="none" pos="punct" start_char="2501">),</TOKEN>
<TOKEN end_char="2511" id="token-14-17" morph="none" pos="word" start_char="2504">Daniella</TOKEN>
<TOKEN end_char="2515" id="token-14-18" morph="none" pos="word" start_char="2513">Dos</TOKEN>
<TOKEN end_char="2522" id="token-14-19" morph="none" pos="word" start_char="2517">Santos</TOKEN>
<TOKEN end_char="2523" id="token-14-20" morph="none" pos="punct" start_char="2523">,</TOKEN>
<TOKEN end_char="2534" id="token-14-21" morph="none" pos="word" start_char="2525">manifiesta</TOKEN>
<TOKEN end_char="2538" id="token-14-22" morph="none" pos="word" start_char="2536">que</TOKEN>
<TOKEN end_char="2540" id="token-14-23" morph="none" pos="punct" start_char="2540">"</TOKEN>
<TOKEN end_char="2544" id="token-14-24" morph="none" pos="word" start_char="2541">esta</TOKEN>
<TOKEN end_char="2558" id="token-14-25" morph="none" pos="word" start_char="2546">investigación</TOKEN>
<TOKEN end_char="2561" id="token-14-26" morph="none" pos="word" start_char="2560">es</TOKEN>
<TOKEN end_char="2571" id="token-14-27" morph="none" pos="word" start_char="2563">puramente</TOKEN>
<TOKEN end_char="2579" id="token-14-28" morph="none" pos="word" start_char="2573">teórica</TOKEN>
<TOKEN end_char="2581" id="token-14-29" morph="none" pos="word" start_char="2581">y</TOKEN>
<TOKEN end_char="2584" id="token-14-30" morph="none" pos="word" start_char="2583">el</TOKEN>
<TOKEN end_char="2590" id="token-14-31" morph="none" pos="word" start_char="2586">autor</TOKEN>
<TOKEN end_char="2596" id="token-14-32" morph="none" pos="word" start_char="2592">mismo</TOKEN>
<TOKEN end_char="2603" id="token-14-33" morph="none" pos="word" start_char="2598">señala</TOKEN>
<TOKEN end_char="2607" id="token-14-34" morph="none" pos="word" start_char="2605">que</TOKEN>
<TOKEN end_char="2613" id="token-14-35" morph="none" pos="word" start_char="2609">hasta</TOKEN>
<TOKEN end_char="2616" id="token-14-36" morph="none" pos="word" start_char="2615">la</TOKEN>
<TOKEN end_char="2622" id="token-14-37" morph="none" pos="word" start_char="2618">fecha</TOKEN>
<TOKEN end_char="2625" id="token-14-38" morph="none" pos="word" start_char="2624">no</TOKEN>
<TOKEN end_char="2629" id="token-14-39" morph="none" pos="word" start_char="2627">hay</TOKEN>
<TOKEN end_char="2639" id="token-14-40" morph="none" pos="word" start_char="2631">evidencia</TOKEN>
<TOKEN end_char="2642" id="token-14-41" morph="none" pos="word" start_char="2641">de</TOKEN>
<TOKEN end_char="2646" id="token-14-42" morph="none" pos="word" start_char="2644">que</TOKEN>
<TOKEN end_char="2650" id="token-14-43" morph="none" pos="word" start_char="2648">los</TOKEN>
<TOKEN end_char="2657" id="token-14-44" morph="none" pos="word" start_char="2652">perros</TOKEN>
<TOKEN end_char="2664" id="token-14-45" morph="none" pos="word" start_char="2659">puedan</TOKEN>
<TOKEN end_char="2673" id="token-14-46" morph="none" pos="word" start_char="2666">replicar</TOKEN>
<TOKEN end_char="2675" id="token-14-47" morph="none" pos="word" start_char="2675">o</TOKEN>
<TOKEN end_char="2684" id="token-14-48" morph="none" pos="word" start_char="2677">eliminar</TOKEN>
<TOKEN end_char="2687" id="token-14-49" morph="none" pos="word" start_char="2686">el</TOKEN>
<TOKEN end_char="2693" id="token-14-50" morph="none" pos="word" start_char="2689">virus</TOKEN>
<TOKEN end_char="2697" id="token-14-51" morph="none" pos="word" start_char="2695">que</TOKEN>
<TOKEN end_char="2703" id="token-14-52" morph="none" pos="word" start_char="2699">causa</TOKEN>
<TOKEN end_char="2712" id="token-14-53" morph="none" pos="unknown" start_char="2705">COVID-19</TOKEN>
<TOKEN end_char="2713" id="token-14-54" morph="none" pos="punct" start_char="2713">.</TOKEN>
<TRANSLATED_TEXT>The president of the British Veterinary Association (BVA), Daniella Dos Santos, states that "this research is purely theoretical and the author himself points out that to date there is no evidence that dogs can replicate or eliminate the virus that causes COVID-19.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2864" id="segment-15" start_char="2715">
<ORIGINAL_TEXT>Instamos a la extrema precaución al interpretarlo como algo más que un recordatorio de que se está trabajando para considerar los orígenes del virus".</ORIGINAL_TEXT>
<TOKEN end_char="2722" id="token-15-0" morph="none" pos="word" start_char="2715">Instamos</TOKEN>
<TOKEN end_char="2724" id="token-15-1" morph="none" pos="word" start_char="2724">a</TOKEN>
<TOKEN end_char="2727" id="token-15-2" morph="none" pos="word" start_char="2726">la</TOKEN>
<TOKEN end_char="2735" id="token-15-3" morph="none" pos="word" start_char="2729">extrema</TOKEN>
<TOKEN end_char="2746" id="token-15-4" morph="none" pos="word" start_char="2737">precaución</TOKEN>
<TOKEN end_char="2749" id="token-15-5" morph="none" pos="word" start_char="2748">al</TOKEN>
<TOKEN end_char="2763" id="token-15-6" morph="none" pos="word" start_char="2751">interpretarlo</TOKEN>
<TOKEN end_char="2768" id="token-15-7" morph="none" pos="word" start_char="2765">como</TOKEN>
<TOKEN end_char="2773" id="token-15-8" morph="none" pos="word" start_char="2770">algo</TOKEN>
<TOKEN end_char="2777" id="token-15-9" morph="none" pos="word" start_char="2775">más</TOKEN>
<TOKEN end_char="2781" id="token-15-10" morph="none" pos="word" start_char="2779">que</TOKEN>
<TOKEN end_char="2784" id="token-15-11" morph="none" pos="word" start_char="2783">un</TOKEN>
<TOKEN end_char="2797" id="token-15-12" morph="none" pos="word" start_char="2786">recordatorio</TOKEN>
<TOKEN end_char="2800" id="token-15-13" morph="none" pos="word" start_char="2799">de</TOKEN>
<TOKEN end_char="2804" id="token-15-14" morph="none" pos="word" start_char="2802">que</TOKEN>
<TOKEN end_char="2807" id="token-15-15" morph="none" pos="word" start_char="2806">se</TOKEN>
<TOKEN end_char="2812" id="token-15-16" morph="none" pos="word" start_char="2809">está</TOKEN>
<TOKEN end_char="2823" id="token-15-17" morph="none" pos="word" start_char="2814">trabajando</TOKEN>
<TOKEN end_char="2828" id="token-15-18" morph="none" pos="word" start_char="2825">para</TOKEN>
<TOKEN end_char="2839" id="token-15-19" morph="none" pos="word" start_char="2830">considerar</TOKEN>
<TOKEN end_char="2843" id="token-15-20" morph="none" pos="word" start_char="2841">los</TOKEN>
<TOKEN end_char="2852" id="token-15-21" morph="none" pos="word" start_char="2845">orígenes</TOKEN>
<TOKEN end_char="2856" id="token-15-22" morph="none" pos="word" start_char="2854">del</TOKEN>
<TOKEN end_char="2862" id="token-15-23" morph="none" pos="word" start_char="2858">virus</TOKEN>
<TOKEN end_char="2864" id="token-15-24" morph="none" pos="punct" start_char="2863">".</TOKEN>
<TRANSLATED_TEXT>We urge extreme caution in interpreting it as something more than a reminder that work is being done to consider the origins of the virus. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3057" id="segment-16" start_char="2867">
<ORIGINAL_TEXT>Asimismo, cabe recordar que un estudio reciente en perros descubrió que el virus se replica muy mal en los caninos, lo que indica que es probable que sean un punto muerto para la transmisión.</ORIGINAL_TEXT>
<TOKEN end_char="2874" id="token-16-0" morph="none" pos="word" start_char="2867">Asimismo</TOKEN>
<TOKEN end_char="2875" id="token-16-1" morph="none" pos="punct" start_char="2875">,</TOKEN>
<TOKEN end_char="2880" id="token-16-2" morph="none" pos="word" start_char="2877">cabe</TOKEN>
<TOKEN end_char="2889" id="token-16-3" morph="none" pos="word" start_char="2882">recordar</TOKEN>
<TOKEN end_char="2893" id="token-16-4" morph="none" pos="word" start_char="2891">que</TOKEN>
<TOKEN end_char="2896" id="token-16-5" morph="none" pos="word" start_char="2895">un</TOKEN>
<TOKEN end_char="2904" id="token-16-6" morph="none" pos="word" start_char="2898">estudio</TOKEN>
<TOKEN end_char="2913" id="token-16-7" morph="none" pos="word" start_char="2906">reciente</TOKEN>
<TOKEN end_char="2916" id="token-16-8" morph="none" pos="word" start_char="2915">en</TOKEN>
<TOKEN end_char="2923" id="token-16-9" morph="none" pos="word" start_char="2918">perros</TOKEN>
<TOKEN end_char="2933" id="token-16-10" morph="none" pos="word" start_char="2925">descubrió</TOKEN>
<TOKEN end_char="2937" id="token-16-11" morph="none" pos="word" start_char="2935">que</TOKEN>
<TOKEN end_char="2940" id="token-16-12" morph="none" pos="word" start_char="2939">el</TOKEN>
<TOKEN end_char="2946" id="token-16-13" morph="none" pos="word" start_char="2942">virus</TOKEN>
<TOKEN end_char="2949" id="token-16-14" morph="none" pos="word" start_char="2948">se</TOKEN>
<TOKEN end_char="2957" id="token-16-15" morph="none" pos="word" start_char="2951">replica</TOKEN>
<TOKEN end_char="2961" id="token-16-16" morph="none" pos="word" start_char="2959">muy</TOKEN>
<TOKEN end_char="2965" id="token-16-17" morph="none" pos="word" start_char="2963">mal</TOKEN>
<TOKEN end_char="2968" id="token-16-18" morph="none" pos="word" start_char="2967">en</TOKEN>
<TOKEN end_char="2972" id="token-16-19" morph="none" pos="word" start_char="2970">los</TOKEN>
<TOKEN end_char="2980" id="token-16-20" morph="none" pos="word" start_char="2974">caninos</TOKEN>
<TOKEN end_char="2981" id="token-16-21" morph="none" pos="punct" start_char="2981">,</TOKEN>
<TOKEN end_char="2984" id="token-16-22" morph="none" pos="word" start_char="2983">lo</TOKEN>
<TOKEN end_char="2988" id="token-16-23" morph="none" pos="word" start_char="2986">que</TOKEN>
<TOKEN end_char="2995" id="token-16-24" morph="none" pos="word" start_char="2990">indica</TOKEN>
<TOKEN end_char="2999" id="token-16-25" morph="none" pos="word" start_char="2997">que</TOKEN>
<TOKEN end_char="3002" id="token-16-26" morph="none" pos="word" start_char="3001">es</TOKEN>
<TOKEN end_char="3011" id="token-16-27" morph="none" pos="word" start_char="3004">probable</TOKEN>
<TOKEN end_char="3015" id="token-16-28" morph="none" pos="word" start_char="3013">que</TOKEN>
<TOKEN end_char="3020" id="token-16-29" morph="none" pos="word" start_char="3017">sean</TOKEN>
<TOKEN end_char="3023" id="token-16-30" morph="none" pos="word" start_char="3022">un</TOKEN>
<TOKEN end_char="3029" id="token-16-31" morph="none" pos="word" start_char="3025">punto</TOKEN>
<TOKEN end_char="3036" id="token-16-32" morph="none" pos="word" start_char="3031">muerto</TOKEN>
<TOKEN end_char="3041" id="token-16-33" morph="none" pos="word" start_char="3038">para</TOKEN>
<TOKEN end_char="3044" id="token-16-34" morph="none" pos="word" start_char="3043">la</TOKEN>
<TOKEN end_char="3056" id="token-16-35" morph="none" pos="word" start_char="3046">transmisión</TOKEN>
<TOKEN end_char="3057" id="token-16-36" morph="none" pos="punct" start_char="3057">.</TOKEN>
<TRANSLATED_TEXT>It should also be remembered that a recent study in dogs found that the virus replicates very poorly in dogs, indicating that they are likely to be a dead end for transmission.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3244" id="segment-17" start_char="3060">
<ORIGINAL_TEXT>Por el momento, los principales organismos de la salud animal, como la OIE o la WSAVA, insisten en que no hay razón para preocuparse por la relación entre las mascotas y el coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="3062" id="token-17-0" morph="none" pos="word" start_char="3060">Por</TOKEN>
<TOKEN end_char="3065" id="token-17-1" morph="none" pos="word" start_char="3064">el</TOKEN>
<TOKEN end_char="3073" id="token-17-2" morph="none" pos="word" start_char="3067">momento</TOKEN>
<TOKEN end_char="3074" id="token-17-3" morph="none" pos="punct" start_char="3074">,</TOKEN>
<TOKEN end_char="3078" id="token-17-4" morph="none" pos="word" start_char="3076">los</TOKEN>
<TOKEN end_char="3090" id="token-17-5" morph="none" pos="word" start_char="3080">principales</TOKEN>
<TOKEN end_char="3101" id="token-17-6" morph="none" pos="word" start_char="3092">organismos</TOKEN>
<TOKEN end_char="3104" id="token-17-7" morph="none" pos="word" start_char="3103">de</TOKEN>
<TOKEN end_char="3107" id="token-17-8" morph="none" pos="word" start_char="3106">la</TOKEN>
<TOKEN end_char="3113" id="token-17-9" morph="none" pos="word" start_char="3109">salud</TOKEN>
<TOKEN end_char="3120" id="token-17-10" morph="none" pos="word" start_char="3115">animal</TOKEN>
<TOKEN end_char="3121" id="token-17-11" morph="none" pos="punct" start_char="3121">,</TOKEN>
<TOKEN end_char="3126" id="token-17-12" morph="none" pos="word" start_char="3123">como</TOKEN>
<TOKEN end_char="3129" id="token-17-13" morph="none" pos="word" start_char="3128">la</TOKEN>
<TOKEN end_char="3133" id="token-17-14" morph="none" pos="word" start_char="3131">OIE</TOKEN>
<TOKEN end_char="3135" id="token-17-15" morph="none" pos="word" start_char="3135">o</TOKEN>
<TOKEN end_char="3138" id="token-17-16" morph="none" pos="word" start_char="3137">la</TOKEN>
<TOKEN end_char="3144" id="token-17-17" morph="none" pos="word" start_char="3140">WSAVA</TOKEN>
<TOKEN end_char="3145" id="token-17-18" morph="none" pos="punct" start_char="3145">,</TOKEN>
<TOKEN end_char="3154" id="token-17-19" morph="none" pos="word" start_char="3147">insisten</TOKEN>
<TOKEN end_char="3157" id="token-17-20" morph="none" pos="word" start_char="3156">en</TOKEN>
<TOKEN end_char="3161" id="token-17-21" morph="none" pos="word" start_char="3159">que</TOKEN>
<TOKEN end_char="3164" id="token-17-22" morph="none" pos="word" start_char="3163">no</TOKEN>
<TOKEN end_char="3168" id="token-17-23" morph="none" pos="word" start_char="3166">hay</TOKEN>
<TOKEN end_char="3174" id="token-17-24" morph="none" pos="word" start_char="3170">razón</TOKEN>
<TOKEN end_char="3179" id="token-17-25" morph="none" pos="word" start_char="3176">para</TOKEN>
<TOKEN end_char="3191" id="token-17-26" morph="none" pos="word" start_char="3181">preocuparse</TOKEN>
<TOKEN end_char="3195" id="token-17-27" morph="none" pos="word" start_char="3193">por</TOKEN>
<TOKEN end_char="3198" id="token-17-28" morph="none" pos="word" start_char="3197">la</TOKEN>
<TOKEN end_char="3207" id="token-17-29" morph="none" pos="word" start_char="3200">relación</TOKEN>
<TOKEN end_char="3213" id="token-17-30" morph="none" pos="word" start_char="3209">entre</TOKEN>
<TOKEN end_char="3217" id="token-17-31" morph="none" pos="word" start_char="3215">las</TOKEN>
<TOKEN end_char="3226" id="token-17-32" morph="none" pos="word" start_char="3219">mascotas</TOKEN>
<TOKEN end_char="3228" id="token-17-33" morph="none" pos="word" start_char="3228">y</TOKEN>
<TOKEN end_char="3231" id="token-17-34" morph="none" pos="word" start_char="3230">el</TOKEN>
<TOKEN end_char="3243" id="token-17-35" morph="none" pos="word" start_char="3233">coronavirus</TOKEN>
<TOKEN end_char="3244" id="token-17-36" morph="none" pos="punct" start_char="3244">.</TOKEN>
<TRANSLATED_TEXT>For the time being, major animal health agencies, such as the OIE or WSAVA, insist that there is no reason to worry about the relationship between pets and coronavirus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3447" id="segment-18" start_char="3247">
<ORIGINAL_TEXT>Este viernes 17 tendrá lugar un webinar organizado por la Asociación Mundial de Veterinarios de Pequeños Animales (WSAVA), que contará con el apoyo de Purina, donde se debatirán todas estas cuestiones.</ORIGINAL_TEXT>
<TOKEN end_char="3250" id="token-18-0" morph="none" pos="word" start_char="3247">Este</TOKEN>
<TOKEN end_char="3258" id="token-18-1" morph="none" pos="word" start_char="3252">viernes</TOKEN>
<TOKEN end_char="3261" id="token-18-2" morph="none" pos="word" start_char="3260">17</TOKEN>
<TOKEN end_char="3268" id="token-18-3" morph="none" pos="word" start_char="3263">tendrá</TOKEN>
<TOKEN end_char="3274" id="token-18-4" morph="none" pos="word" start_char="3270">lugar</TOKEN>
<TOKEN end_char="3277" id="token-18-5" morph="none" pos="word" start_char="3276">un</TOKEN>
<TOKEN end_char="3285" id="token-18-6" morph="none" pos="word" start_char="3279">webinar</TOKEN>
<TOKEN end_char="3296" id="token-18-7" morph="none" pos="word" start_char="3287">organizado</TOKEN>
<TOKEN end_char="3300" id="token-18-8" morph="none" pos="word" start_char="3298">por</TOKEN>
<TOKEN end_char="3303" id="token-18-9" morph="none" pos="word" start_char="3302">la</TOKEN>
<TOKEN end_char="3314" id="token-18-10" morph="none" pos="word" start_char="3305">Asociación</TOKEN>
<TOKEN end_char="3322" id="token-18-11" morph="none" pos="word" start_char="3316">Mundial</TOKEN>
<TOKEN end_char="3325" id="token-18-12" morph="none" pos="word" start_char="3324">de</TOKEN>
<TOKEN end_char="3338" id="token-18-13" morph="none" pos="word" start_char="3327">Veterinarios</TOKEN>
<TOKEN end_char="3341" id="token-18-14" morph="none" pos="word" start_char="3340">de</TOKEN>
<TOKEN end_char="3350" id="token-18-15" morph="none" pos="word" start_char="3343">Pequeños</TOKEN>
<TOKEN end_char="3359" id="token-18-16" morph="none" pos="word" start_char="3352">Animales</TOKEN>
<TOKEN end_char="3361" id="token-18-17" morph="none" pos="punct" start_char="3361">(</TOKEN>
<TOKEN end_char="3366" id="token-18-18" morph="none" pos="word" start_char="3362">WSAVA</TOKEN>
<TOKEN end_char="3368" id="token-18-19" morph="none" pos="punct" start_char="3367">),</TOKEN>
<TOKEN end_char="3372" id="token-18-20" morph="none" pos="word" start_char="3370">que</TOKEN>
<TOKEN end_char="3380" id="token-18-21" morph="none" pos="word" start_char="3374">contará</TOKEN>
<TOKEN end_char="3384" id="token-18-22" morph="none" pos="word" start_char="3382">con</TOKEN>
<TOKEN end_char="3387" id="token-18-23" morph="none" pos="word" start_char="3386">el</TOKEN>
<TOKEN end_char="3393" id="token-18-24" morph="none" pos="word" start_char="3389">apoyo</TOKEN>
<TOKEN end_char="3396" id="token-18-25" morph="none" pos="word" start_char="3395">de</TOKEN>
<TOKEN end_char="3403" id="token-18-26" morph="none" pos="word" start_char="3398">Purina</TOKEN>
<TOKEN end_char="3404" id="token-18-27" morph="none" pos="punct" start_char="3404">,</TOKEN>
<TOKEN end_char="3410" id="token-18-28" morph="none" pos="word" start_char="3406">donde</TOKEN>
<TOKEN end_char="3413" id="token-18-29" morph="none" pos="word" start_char="3412">se</TOKEN>
<TOKEN end_char="3423" id="token-18-30" morph="none" pos="word" start_char="3415">debatirán</TOKEN>
<TOKEN end_char="3429" id="token-18-31" morph="none" pos="word" start_char="3425">todas</TOKEN>
<TOKEN end_char="3435" id="token-18-32" morph="none" pos="word" start_char="3431">estas</TOKEN>
<TOKEN end_char="3446" id="token-18-33" morph="none" pos="word" start_char="3437">cuestiones</TOKEN>
<TOKEN end_char="3447" id="token-18-34" morph="none" pos="punct" start_char="3447">.</TOKEN>
<TRANSLATED_TEXT>This Friday 17th will be a webinar organized by the World Association of Small Animal Veterinarians (WSAVA), supported by Purina, where all these issues will be discussed.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3671" id="segment-19" start_char="3450">
<ORIGINAL_TEXT>Los ponentes serán la Dra Vanessa Barrs (catedrática de Salud de Animales de Compañía de la Universidad de Hong Kong), el Dr Michael Lappin (miembro del comité One Health de WSAVA) y el Dr Shane Ryan (presidente de WSAVA).</ORIGINAL_TEXT>
<TOKEN end_char="3452" id="token-19-0" morph="none" pos="word" start_char="3450">Los</TOKEN>
<TOKEN end_char="3461" id="token-19-1" morph="none" pos="word" start_char="3454">ponentes</TOKEN>
<TOKEN end_char="3467" id="token-19-2" morph="none" pos="word" start_char="3463">serán</TOKEN>
<TOKEN end_char="3470" id="token-19-3" morph="none" pos="word" start_char="3469">la</TOKEN>
<TOKEN end_char="3474" id="token-19-4" morph="none" pos="word" start_char="3472">Dra</TOKEN>
<TOKEN end_char="3482" id="token-19-5" morph="none" pos="word" start_char="3476">Vanessa</TOKEN>
<TOKEN end_char="3488" id="token-19-6" morph="none" pos="word" start_char="3484">Barrs</TOKEN>
<TOKEN end_char="3490" id="token-19-7" morph="none" pos="punct" start_char="3490">(</TOKEN>
<TOKEN end_char="3501" id="token-19-8" morph="none" pos="word" start_char="3491">catedrática</TOKEN>
<TOKEN end_char="3504" id="token-19-9" morph="none" pos="word" start_char="3503">de</TOKEN>
<TOKEN end_char="3510" id="token-19-10" morph="none" pos="word" start_char="3506">Salud</TOKEN>
<TOKEN end_char="3513" id="token-19-11" morph="none" pos="word" start_char="3512">de</TOKEN>
<TOKEN end_char="3522" id="token-19-12" morph="none" pos="word" start_char="3515">Animales</TOKEN>
<TOKEN end_char="3525" id="token-19-13" morph="none" pos="word" start_char="3524">de</TOKEN>
<TOKEN end_char="3534" id="token-19-14" morph="none" pos="word" start_char="3527">Compañía</TOKEN>
<TOKEN end_char="3537" id="token-19-15" morph="none" pos="word" start_char="3536">de</TOKEN>
<TOKEN end_char="3540" id="token-19-16" morph="none" pos="word" start_char="3539">la</TOKEN>
<TOKEN end_char="3552" id="token-19-17" morph="none" pos="word" start_char="3542">Universidad</TOKEN>
<TOKEN end_char="3555" id="token-19-18" morph="none" pos="word" start_char="3554">de</TOKEN>
<TOKEN end_char="3560" id="token-19-19" morph="none" pos="word" start_char="3557">Hong</TOKEN>
<TOKEN end_char="3565" id="token-19-20" morph="none" pos="word" start_char="3562">Kong</TOKEN>
<TOKEN end_char="3567" id="token-19-21" morph="none" pos="punct" start_char="3566">),</TOKEN>
<TOKEN end_char="3570" id="token-19-22" morph="none" pos="word" start_char="3569">el</TOKEN>
<TOKEN end_char="3573" id="token-19-23" morph="none" pos="word" start_char="3572">Dr</TOKEN>
<TOKEN end_char="3581" id="token-19-24" morph="none" pos="word" start_char="3575">Michael</TOKEN>
<TOKEN end_char="3588" id="token-19-25" morph="none" pos="word" start_char="3583">Lappin</TOKEN>
<TOKEN end_char="3590" id="token-19-26" morph="none" pos="punct" start_char="3590">(</TOKEN>
<TOKEN end_char="3597" id="token-19-27" morph="none" pos="word" start_char="3591">miembro</TOKEN>
<TOKEN end_char="3601" id="token-19-28" morph="none" pos="word" start_char="3599">del</TOKEN>
<TOKEN end_char="3608" id="token-19-29" morph="none" pos="word" start_char="3603">comité</TOKEN>
<TOKEN end_char="3612" id="token-19-30" morph="none" pos="word" start_char="3610">One</TOKEN>
<TOKEN end_char="3619" id="token-19-31" morph="none" pos="word" start_char="3614">Health</TOKEN>
<TOKEN end_char="3622" id="token-19-32" morph="none" pos="word" start_char="3621">de</TOKEN>
<TOKEN end_char="3628" id="token-19-33" morph="none" pos="word" start_char="3624">WSAVA</TOKEN>
<TOKEN end_char="3629" id="token-19-34" morph="none" pos="punct" start_char="3629">)</TOKEN>
<TOKEN end_char="3631" id="token-19-35" morph="none" pos="word" start_char="3631">y</TOKEN>
<TOKEN end_char="3634" id="token-19-36" morph="none" pos="word" start_char="3633">el</TOKEN>
<TOKEN end_char="3637" id="token-19-37" morph="none" pos="word" start_char="3636">Dr</TOKEN>
<TOKEN end_char="3643" id="token-19-38" morph="none" pos="word" start_char="3639">Shane</TOKEN>
<TOKEN end_char="3648" id="token-19-39" morph="none" pos="word" start_char="3645">Ryan</TOKEN>
<TOKEN end_char="3650" id="token-19-40" morph="none" pos="punct" start_char="3650">(</TOKEN>
<TOKEN end_char="3660" id="token-19-41" morph="none" pos="word" start_char="3651">presidente</TOKEN>
<TOKEN end_char="3663" id="token-19-42" morph="none" pos="word" start_char="3662">de</TOKEN>
<TOKEN end_char="3669" id="token-19-43" morph="none" pos="word" start_char="3665">WSAVA</TOKEN>
<TOKEN end_char="3671" id="token-19-44" morph="none" pos="punct" start_char="3670">).</TOKEN>
<TRANSLATED_TEXT>Speakers will be Dr. Vanessa Barrs (Professor of Animal Health Company, University of Hong Kong), Dr. Michael Lappin (WSAVA One Health Committee member) and Dr. Shane Ryan (WSAVA President).</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
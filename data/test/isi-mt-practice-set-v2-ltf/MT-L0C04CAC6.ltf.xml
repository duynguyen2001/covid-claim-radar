<LCTL_TEXT lang="eng">
<DOC grammar="none" id="L0C04CAC6" lang="eng" raw_text_char_length="2342" raw_text_md5="5343d795095756eca91b4f83c1c488a6" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="74" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Fact check: Rothschild did not patent a test for COVID-19 in 2015 and 2017</ORIGINAL_TEXT>
<TOKEN end_char="4" id="token-0-0" morph="none" pos="word" start_char="1">Fact</TOKEN>
<TOKEN end_char="10" id="token-0-1" morph="none" pos="word" start_char="6">check</TOKEN>
<TOKEN end_char="11" id="token-0-2" morph="none" pos="punct" start_char="11">:</TOKEN>
<TOKEN end_char="22" id="token-0-3" morph="none" pos="word" start_char="13">Rothschild</TOKEN>
<TOKEN end_char="26" id="token-0-4" morph="none" pos="word" start_char="24">did</TOKEN>
<TOKEN end_char="30" id="token-0-5" morph="none" pos="word" start_char="28">not</TOKEN>
<TOKEN end_char="37" id="token-0-6" morph="none" pos="word" start_char="32">patent</TOKEN>
<TOKEN end_char="39" id="token-0-7" morph="none" pos="word" start_char="39">a</TOKEN>
<TOKEN end_char="44" id="token-0-8" morph="none" pos="word" start_char="41">test</TOKEN>
<TOKEN end_char="48" id="token-0-9" morph="none" pos="word" start_char="46">for</TOKEN>
<TOKEN end_char="57" id="token-0-10" morph="none" pos="unknown" start_char="50">COVID-19</TOKEN>
<TOKEN end_char="60" id="token-0-11" morph="none" pos="word" start_char="59">in</TOKEN>
<TOKEN end_char="65" id="token-0-12" morph="none" pos="word" start_char="62">2015</TOKEN>
<TOKEN end_char="69" id="token-0-13" morph="none" pos="word" start_char="67">and</TOKEN>
<TOKEN end_char="74" id="token-0-14" morph="none" pos="word" start_char="71">2017</TOKEN>
</SEG>
<SEG end_char="203" id="segment-1" start_char="78">
<ORIGINAL_TEXT>The false claim that a testing method for COVID-19 was patented by Richard Rothschild in 2015 and 2017 has been shared online.</ORIGINAL_TEXT>
<TOKEN end_char="80" id="token-1-0" morph="none" pos="word" start_char="78">The</TOKEN>
<TOKEN end_char="86" id="token-1-1" morph="none" pos="word" start_char="82">false</TOKEN>
<TOKEN end_char="92" id="token-1-2" morph="none" pos="word" start_char="88">claim</TOKEN>
<TOKEN end_char="97" id="token-1-3" morph="none" pos="word" start_char="94">that</TOKEN>
<TOKEN end_char="99" id="token-1-4" morph="none" pos="word" start_char="99">a</TOKEN>
<TOKEN end_char="107" id="token-1-5" morph="none" pos="word" start_char="101">testing</TOKEN>
<TOKEN end_char="114" id="token-1-6" morph="none" pos="word" start_char="109">method</TOKEN>
<TOKEN end_char="118" id="token-1-7" morph="none" pos="word" start_char="116">for</TOKEN>
<TOKEN end_char="127" id="token-1-8" morph="none" pos="unknown" start_char="120">COVID-19</TOKEN>
<TOKEN end_char="131" id="token-1-9" morph="none" pos="word" start_char="129">was</TOKEN>
<TOKEN end_char="140" id="token-1-10" morph="none" pos="word" start_char="133">patented</TOKEN>
<TOKEN end_char="143" id="token-1-11" morph="none" pos="word" start_char="142">by</TOKEN>
<TOKEN end_char="151" id="token-1-12" morph="none" pos="word" start_char="145">Richard</TOKEN>
<TOKEN end_char="162" id="token-1-13" morph="none" pos="word" start_char="153">Rothschild</TOKEN>
<TOKEN end_char="165" id="token-1-14" morph="none" pos="word" start_char="164">in</TOKEN>
<TOKEN end_char="170" id="token-1-15" morph="none" pos="word" start_char="167">2015</TOKEN>
<TOKEN end_char="174" id="token-1-16" morph="none" pos="word" start_char="172">and</TOKEN>
<TOKEN end_char="179" id="token-1-17" morph="none" pos="word" start_char="176">2017</TOKEN>
<TOKEN end_char="183" id="token-1-18" morph="none" pos="word" start_char="181">has</TOKEN>
<TOKEN end_char="188" id="token-1-19" morph="none" pos="word" start_char="185">been</TOKEN>
<TOKEN end_char="195" id="token-1-20" morph="none" pos="word" start_char="190">shared</TOKEN>
<TOKEN end_char="202" id="token-1-21" morph="none" pos="word" start_char="197">online</TOKEN>
<TOKEN end_char="203" id="token-1-22" morph="none" pos="punct" start_char="203">.</TOKEN>
</SEG>
<SEG end_char="353" id="segment-2" start_char="205">
<ORIGINAL_TEXT>The patent for a system that analyses biometric data to determine whether the user is suffering from COVID-19 was not applied for until May 17, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="207" id="token-2-0" morph="none" pos="word" start_char="205">The</TOKEN>
<TOKEN end_char="214" id="token-2-1" morph="none" pos="word" start_char="209">patent</TOKEN>
<TOKEN end_char="218" id="token-2-2" morph="none" pos="word" start_char="216">for</TOKEN>
<TOKEN end_char="220" id="token-2-3" morph="none" pos="word" start_char="220">a</TOKEN>
<TOKEN end_char="227" id="token-2-4" morph="none" pos="word" start_char="222">system</TOKEN>
<TOKEN end_char="232" id="token-2-5" morph="none" pos="word" start_char="229">that</TOKEN>
<TOKEN end_char="241" id="token-2-6" morph="none" pos="word" start_char="234">analyses</TOKEN>
<TOKEN end_char="251" id="token-2-7" morph="none" pos="word" start_char="243">biometric</TOKEN>
<TOKEN end_char="256" id="token-2-8" morph="none" pos="word" start_char="253">data</TOKEN>
<TOKEN end_char="259" id="token-2-9" morph="none" pos="word" start_char="258">to</TOKEN>
<TOKEN end_char="269" id="token-2-10" morph="none" pos="word" start_char="261">determine</TOKEN>
<TOKEN end_char="277" id="token-2-11" morph="none" pos="word" start_char="271">whether</TOKEN>
<TOKEN end_char="281" id="token-2-12" morph="none" pos="word" start_char="279">the</TOKEN>
<TOKEN end_char="286" id="token-2-13" morph="none" pos="word" start_char="283">user</TOKEN>
<TOKEN end_char="289" id="token-2-14" morph="none" pos="word" start_char="288">is</TOKEN>
<TOKEN end_char="299" id="token-2-15" morph="none" pos="word" start_char="291">suffering</TOKEN>
<TOKEN end_char="304" id="token-2-16" morph="none" pos="word" start_char="301">from</TOKEN>
<TOKEN end_char="313" id="token-2-17" morph="none" pos="unknown" start_char="306">COVID-19</TOKEN>
<TOKEN end_char="317" id="token-2-18" morph="none" pos="word" start_char="315">was</TOKEN>
<TOKEN end_char="321" id="token-2-19" morph="none" pos="word" start_char="319">not</TOKEN>
<TOKEN end_char="329" id="token-2-20" morph="none" pos="word" start_char="323">applied</TOKEN>
<TOKEN end_char="333" id="token-2-21" morph="none" pos="word" start_char="331">for</TOKEN>
<TOKEN end_char="339" id="token-2-22" morph="none" pos="word" start_char="335">until</TOKEN>
<TOKEN end_char="343" id="token-2-23" morph="none" pos="word" start_char="341">May</TOKEN>
<TOKEN end_char="346" id="token-2-24" morph="none" pos="word" start_char="345">17</TOKEN>
<TOKEN end_char="347" id="token-2-25" morph="none" pos="punct" start_char="347">,</TOKEN>
<TOKEN end_char="352" id="token-2-26" morph="none" pos="word" start_char="349">2020</TOKEN>
<TOKEN end_char="353" id="token-2-27" morph="none" pos="punct" start_char="353">.</TOKEN>
</SEG>
<SEG end_char="427" id="segment-3" start_char="357">
<ORIGINAL_TEXT>The allegation is the subject of an article, which can be seen (here) .</ORIGINAL_TEXT>
<TOKEN end_char="359" id="token-3-0" morph="none" pos="word" start_char="357">The</TOKEN>
<TOKEN end_char="370" id="token-3-1" morph="none" pos="word" start_char="361">allegation</TOKEN>
<TOKEN end_char="373" id="token-3-2" morph="none" pos="word" start_char="372">is</TOKEN>
<TOKEN end_char="377" id="token-3-3" morph="none" pos="word" start_char="375">the</TOKEN>
<TOKEN end_char="385" id="token-3-4" morph="none" pos="word" start_char="379">subject</TOKEN>
<TOKEN end_char="388" id="token-3-5" morph="none" pos="word" start_char="387">of</TOKEN>
<TOKEN end_char="391" id="token-3-6" morph="none" pos="word" start_char="390">an</TOKEN>
<TOKEN end_char="399" id="token-3-7" morph="none" pos="word" start_char="393">article</TOKEN>
<TOKEN end_char="400" id="token-3-8" morph="none" pos="punct" start_char="400">,</TOKEN>
<TOKEN end_char="406" id="token-3-9" morph="none" pos="word" start_char="402">which</TOKEN>
<TOKEN end_char="410" id="token-3-10" morph="none" pos="word" start_char="408">can</TOKEN>
<TOKEN end_char="413" id="token-3-11" morph="none" pos="word" start_char="412">be</TOKEN>
<TOKEN end_char="418" id="token-3-12" morph="none" pos="word" start_char="415">seen</TOKEN>
<TOKEN end_char="420" id="token-3-13" morph="none" pos="punct" start_char="420">(</TOKEN>
<TOKEN end_char="424" id="token-3-14" morph="none" pos="word" start_char="421">here</TOKEN>
<TOKEN end_char="425" id="token-3-15" morph="none" pos="punct" start_char="425">)</TOKEN>
<TOKEN end_char="427" id="token-3-16" morph="none" pos="punct" start_char="427">.</TOKEN>
</SEG>
<SEG end_char="546" id="segment-4" start_char="430">
<ORIGINAL_TEXT>The website points to a Dutch website that shows a patent for a "System and Method for Testing for COVID-19" (here) .</ORIGINAL_TEXT>
<TOKEN end_char="432" id="token-4-0" morph="none" pos="word" start_char="430">The</TOKEN>
<TOKEN end_char="440" id="token-4-1" morph="none" pos="word" start_char="434">website</TOKEN>
<TOKEN end_char="447" id="token-4-2" morph="none" pos="word" start_char="442">points</TOKEN>
<TOKEN end_char="450" id="token-4-3" morph="none" pos="word" start_char="449">to</TOKEN>
<TOKEN end_char="452" id="token-4-4" morph="none" pos="word" start_char="452">a</TOKEN>
<TOKEN end_char="458" id="token-4-5" morph="none" pos="word" start_char="454">Dutch</TOKEN>
<TOKEN end_char="466" id="token-4-6" morph="none" pos="word" start_char="460">website</TOKEN>
<TOKEN end_char="471" id="token-4-7" morph="none" pos="word" start_char="468">that</TOKEN>
<TOKEN end_char="477" id="token-4-8" morph="none" pos="word" start_char="473">shows</TOKEN>
<TOKEN end_char="479" id="token-4-9" morph="none" pos="word" start_char="479">a</TOKEN>
<TOKEN end_char="486" id="token-4-10" morph="none" pos="word" start_char="481">patent</TOKEN>
<TOKEN end_char="490" id="token-4-11" morph="none" pos="word" start_char="488">for</TOKEN>
<TOKEN end_char="492" id="token-4-12" morph="none" pos="word" start_char="492">a</TOKEN>
<TOKEN end_char="494" id="token-4-13" morph="none" pos="punct" start_char="494">"</TOKEN>
<TOKEN end_char="500" id="token-4-14" morph="none" pos="word" start_char="495">System</TOKEN>
<TOKEN end_char="504" id="token-4-15" morph="none" pos="word" start_char="502">and</TOKEN>
<TOKEN end_char="511" id="token-4-16" morph="none" pos="word" start_char="506">Method</TOKEN>
<TOKEN end_char="515" id="token-4-17" morph="none" pos="word" start_char="513">for</TOKEN>
<TOKEN end_char="523" id="token-4-18" morph="none" pos="word" start_char="517">Testing</TOKEN>
<TOKEN end_char="527" id="token-4-19" morph="none" pos="word" start_char="525">for</TOKEN>
<TOKEN end_char="536" id="token-4-20" morph="none" pos="unknown" start_char="529">COVID-19</TOKEN>
<TOKEN end_char="537" id="token-4-21" morph="none" pos="punct" start_char="537">"</TOKEN>
<TOKEN end_char="539" id="token-4-22" morph="none" pos="punct" start_char="539">(</TOKEN>
<TOKEN end_char="543" id="token-4-23" morph="none" pos="word" start_char="540">here</TOKEN>
<TOKEN end_char="544" id="token-4-24" morph="none" pos="punct" start_char="544">)</TOKEN>
<TOKEN end_char="546" id="token-4-25" morph="none" pos="punct" start_char="546">.</TOKEN>
</SEG>
<SEG end_char="662" id="segment-5" start_char="549">
<ORIGINAL_TEXT>The patent is numbered ‘US20200279585A1’ and has a "Prioriteitsdatum" (Dutch for "priority date") of "2015-10-13".</ORIGINAL_TEXT>
<TOKEN end_char="551" id="token-5-0" morph="none" pos="word" start_char="549">The</TOKEN>
<TOKEN end_char="558" id="token-5-1" morph="none" pos="word" start_char="553">patent</TOKEN>
<TOKEN end_char="561" id="token-5-2" morph="none" pos="word" start_char="560">is</TOKEN>
<TOKEN end_char="570" id="token-5-3" morph="none" pos="word" start_char="563">numbered</TOKEN>
<TOKEN end_char="572" id="token-5-4" morph="none" pos="punct" start_char="572">‘</TOKEN>
<TOKEN end_char="587" id="token-5-5" morph="none" pos="word" start_char="573">US20200279585A1</TOKEN>
<TOKEN end_char="588" id="token-5-6" morph="none" pos="punct" start_char="588">’</TOKEN>
<TOKEN end_char="592" id="token-5-7" morph="none" pos="word" start_char="590">and</TOKEN>
<TOKEN end_char="596" id="token-5-8" morph="none" pos="word" start_char="594">has</TOKEN>
<TOKEN end_char="598" id="token-5-9" morph="none" pos="word" start_char="598">a</TOKEN>
<TOKEN end_char="600" id="token-5-10" morph="none" pos="punct" start_char="600">"</TOKEN>
<TOKEN end_char="616" id="token-5-11" morph="none" pos="word" start_char="601">Prioriteitsdatum</TOKEN>
<TOKEN end_char="617" id="token-5-12" morph="none" pos="punct" start_char="617">"</TOKEN>
<TOKEN end_char="619" id="token-5-13" morph="none" pos="punct" start_char="619">(</TOKEN>
<TOKEN end_char="624" id="token-5-14" morph="none" pos="word" start_char="620">Dutch</TOKEN>
<TOKEN end_char="628" id="token-5-15" morph="none" pos="word" start_char="626">for</TOKEN>
<TOKEN end_char="630" id="token-5-16" morph="none" pos="punct" start_char="630">"</TOKEN>
<TOKEN end_char="638" id="token-5-17" morph="none" pos="word" start_char="631">priority</TOKEN>
<TOKEN end_char="643" id="token-5-18" morph="none" pos="word" start_char="640">date</TOKEN>
<TOKEN end_char="645" id="token-5-19" morph="none" pos="punct" start_char="644">")</TOKEN>
<TOKEN end_char="648" id="token-5-20" morph="none" pos="word" start_char="647">of</TOKEN>
<TOKEN end_char="650" id="token-5-21" morph="none" pos="punct" start_char="650">"</TOKEN>
<TOKEN end_char="660" id="token-5-22" morph="none" pos="unknown" start_char="651">2015-10-13</TOKEN>
<TOKEN end_char="662" id="token-5-23" morph="none" pos="punct" start_char="661">".</TOKEN>
</SEG>
<SEG end_char="770" id="segment-6" start_char="665">
<ORIGINAL_TEXT>The article claims that the 2015 priority date is evidence that the coronavirus pandemic has been planned.</ORIGINAL_TEXT>
<TOKEN end_char="667" id="token-6-0" morph="none" pos="word" start_char="665">The</TOKEN>
<TOKEN end_char="675" id="token-6-1" morph="none" pos="word" start_char="669">article</TOKEN>
<TOKEN end_char="682" id="token-6-2" morph="none" pos="word" start_char="677">claims</TOKEN>
<TOKEN end_char="687" id="token-6-3" morph="none" pos="word" start_char="684">that</TOKEN>
<TOKEN end_char="691" id="token-6-4" morph="none" pos="word" start_char="689">the</TOKEN>
<TOKEN end_char="696" id="token-6-5" morph="none" pos="word" start_char="693">2015</TOKEN>
<TOKEN end_char="705" id="token-6-6" morph="none" pos="word" start_char="698">priority</TOKEN>
<TOKEN end_char="710" id="token-6-7" morph="none" pos="word" start_char="707">date</TOKEN>
<TOKEN end_char="713" id="token-6-8" morph="none" pos="word" start_char="712">is</TOKEN>
<TOKEN end_char="722" id="token-6-9" morph="none" pos="word" start_char="715">evidence</TOKEN>
<TOKEN end_char="727" id="token-6-10" morph="none" pos="word" start_char="724">that</TOKEN>
<TOKEN end_char="731" id="token-6-11" morph="none" pos="word" start_char="729">the</TOKEN>
<TOKEN end_char="743" id="token-6-12" morph="none" pos="word" start_char="733">coronavirus</TOKEN>
<TOKEN end_char="752" id="token-6-13" morph="none" pos="word" start_char="745">pandemic</TOKEN>
<TOKEN end_char="756" id="token-6-14" morph="none" pos="word" start_char="754">has</TOKEN>
<TOKEN end_char="761" id="token-6-15" morph="none" pos="word" start_char="758">been</TOKEN>
<TOKEN end_char="769" id="token-6-16" morph="none" pos="word" start_char="763">planned</TOKEN>
<TOKEN end_char="770" id="token-6-17" morph="none" pos="punct" start_char="770">.</TOKEN>
</SEG>
<SEG end_char="850" id="segment-7" start_char="773">
<ORIGINAL_TEXT>But the author has conflated the terms "priority date" and "application date".</ORIGINAL_TEXT>
<TOKEN end_char="775" id="token-7-0" morph="none" pos="word" start_char="773">But</TOKEN>
<TOKEN end_char="779" id="token-7-1" morph="none" pos="word" start_char="777">the</TOKEN>
<TOKEN end_char="786" id="token-7-2" morph="none" pos="word" start_char="781">author</TOKEN>
<TOKEN end_char="790" id="token-7-3" morph="none" pos="word" start_char="788">has</TOKEN>
<TOKEN end_char="800" id="token-7-4" morph="none" pos="word" start_char="792">conflated</TOKEN>
<TOKEN end_char="804" id="token-7-5" morph="none" pos="word" start_char="802">the</TOKEN>
<TOKEN end_char="810" id="token-7-6" morph="none" pos="word" start_char="806">terms</TOKEN>
<TOKEN end_char="812" id="token-7-7" morph="none" pos="punct" start_char="812">"</TOKEN>
<TOKEN end_char="820" id="token-7-8" morph="none" pos="word" start_char="813">priority</TOKEN>
<TOKEN end_char="825" id="token-7-9" morph="none" pos="word" start_char="822">date</TOKEN>
<TOKEN end_char="826" id="token-7-10" morph="none" pos="punct" start_char="826">"</TOKEN>
<TOKEN end_char="830" id="token-7-11" morph="none" pos="word" start_char="828">and</TOKEN>
<TOKEN end_char="832" id="token-7-12" morph="none" pos="punct" start_char="832">"</TOKEN>
<TOKEN end_char="843" id="token-7-13" morph="none" pos="word" start_char="833">application</TOKEN>
<TOKEN end_char="848" id="token-7-14" morph="none" pos="word" start_char="845">date</TOKEN>
<TOKEN end_char="850" id="token-7-15" morph="none" pos="punct" start_char="849">".</TOKEN>
</SEG>
<SEG end_char="1031" id="segment-8" start_char="853">
<ORIGINAL_TEXT>The priority date can refer to the earliest filing date in a family of related patent applications, or to the earliest filing date of a particular feature of an invention (here) .</ORIGINAL_TEXT>
<TOKEN end_char="855" id="token-8-0" morph="none" pos="word" start_char="853">The</TOKEN>
<TOKEN end_char="864" id="token-8-1" morph="none" pos="word" start_char="857">priority</TOKEN>
<TOKEN end_char="869" id="token-8-2" morph="none" pos="word" start_char="866">date</TOKEN>
<TOKEN end_char="873" id="token-8-3" morph="none" pos="word" start_char="871">can</TOKEN>
<TOKEN end_char="879" id="token-8-4" morph="none" pos="word" start_char="875">refer</TOKEN>
<TOKEN end_char="882" id="token-8-5" morph="none" pos="word" start_char="881">to</TOKEN>
<TOKEN end_char="886" id="token-8-6" morph="none" pos="word" start_char="884">the</TOKEN>
<TOKEN end_char="895" id="token-8-7" morph="none" pos="word" start_char="888">earliest</TOKEN>
<TOKEN end_char="902" id="token-8-8" morph="none" pos="word" start_char="897">filing</TOKEN>
<TOKEN end_char="907" id="token-8-9" morph="none" pos="word" start_char="904">date</TOKEN>
<TOKEN end_char="910" id="token-8-10" morph="none" pos="word" start_char="909">in</TOKEN>
<TOKEN end_char="912" id="token-8-11" morph="none" pos="word" start_char="912">a</TOKEN>
<TOKEN end_char="919" id="token-8-12" morph="none" pos="word" start_char="914">family</TOKEN>
<TOKEN end_char="922" id="token-8-13" morph="none" pos="word" start_char="921">of</TOKEN>
<TOKEN end_char="930" id="token-8-14" morph="none" pos="word" start_char="924">related</TOKEN>
<TOKEN end_char="937" id="token-8-15" morph="none" pos="word" start_char="932">patent</TOKEN>
<TOKEN end_char="950" id="token-8-16" morph="none" pos="word" start_char="939">applications</TOKEN>
<TOKEN end_char="951" id="token-8-17" morph="none" pos="punct" start_char="951">,</TOKEN>
<TOKEN end_char="954" id="token-8-18" morph="none" pos="word" start_char="953">or</TOKEN>
<TOKEN end_char="957" id="token-8-19" morph="none" pos="word" start_char="956">to</TOKEN>
<TOKEN end_char="961" id="token-8-20" morph="none" pos="word" start_char="959">the</TOKEN>
<TOKEN end_char="970" id="token-8-21" morph="none" pos="word" start_char="963">earliest</TOKEN>
<TOKEN end_char="977" id="token-8-22" morph="none" pos="word" start_char="972">filing</TOKEN>
<TOKEN end_char="982" id="token-8-23" morph="none" pos="word" start_char="979">date</TOKEN>
<TOKEN end_char="985" id="token-8-24" morph="none" pos="word" start_char="984">of</TOKEN>
<TOKEN end_char="987" id="token-8-25" morph="none" pos="word" start_char="987">a</TOKEN>
<TOKEN end_char="998" id="token-8-26" morph="none" pos="word" start_char="989">particular</TOKEN>
<TOKEN end_char="1006" id="token-8-27" morph="none" pos="word" start_char="1000">feature</TOKEN>
<TOKEN end_char="1009" id="token-8-28" morph="none" pos="word" start_char="1008">of</TOKEN>
<TOKEN end_char="1012" id="token-8-29" morph="none" pos="word" start_char="1011">an</TOKEN>
<TOKEN end_char="1022" id="token-8-30" morph="none" pos="word" start_char="1014">invention</TOKEN>
<TOKEN end_char="1024" id="token-8-31" morph="none" pos="punct" start_char="1024">(</TOKEN>
<TOKEN end_char="1028" id="token-8-32" morph="none" pos="word" start_char="1025">here</TOKEN>
<TOKEN end_char="1029" id="token-8-33" morph="none" pos="punct" start_char="1029">)</TOKEN>
<TOKEN end_char="1031" id="token-8-34" morph="none" pos="punct" start_char="1031">.</TOKEN>
</SEG>
<SEG end_char="1051" id="segment-9" start_char="1034">
<ORIGINAL_TEXT>In this case, Oct.</ORIGINAL_TEXT>
<TOKEN end_char="1035" id="token-9-0" morph="none" pos="word" start_char="1034">In</TOKEN>
<TOKEN end_char="1040" id="token-9-1" morph="none" pos="word" start_char="1037">this</TOKEN>
<TOKEN end_char="1045" id="token-9-2" morph="none" pos="word" start_char="1042">case</TOKEN>
<TOKEN end_char="1046" id="token-9-3" morph="none" pos="punct" start_char="1046">,</TOKEN>
<TOKEN end_char="1050" id="token-9-4" morph="none" pos="word" start_char="1048">Oct</TOKEN>
<TOKEN end_char="1051" id="token-9-5" morph="none" pos="punct" start_char="1051">.</TOKEN>
</SEG>
<SEG end_char="1147" id="segment-10" start_char="1053">
<ORIGINAL_TEXT>13, 2015 is when Rothschild first made a provisional application within this family of patents.</ORIGINAL_TEXT>
<TOKEN end_char="1054" id="token-10-0" morph="none" pos="word" start_char="1053">13</TOKEN>
<TOKEN end_char="1055" id="token-10-1" morph="none" pos="punct" start_char="1055">,</TOKEN>
<TOKEN end_char="1060" id="token-10-2" morph="none" pos="word" start_char="1057">2015</TOKEN>
<TOKEN end_char="1063" id="token-10-3" morph="none" pos="word" start_char="1062">is</TOKEN>
<TOKEN end_char="1068" id="token-10-4" morph="none" pos="word" start_char="1065">when</TOKEN>
<TOKEN end_char="1079" id="token-10-5" morph="none" pos="word" start_char="1070">Rothschild</TOKEN>
<TOKEN end_char="1085" id="token-10-6" morph="none" pos="word" start_char="1081">first</TOKEN>
<TOKEN end_char="1090" id="token-10-7" morph="none" pos="word" start_char="1087">made</TOKEN>
<TOKEN end_char="1092" id="token-10-8" morph="none" pos="word" start_char="1092">a</TOKEN>
<TOKEN end_char="1104" id="token-10-9" morph="none" pos="word" start_char="1094">provisional</TOKEN>
<TOKEN end_char="1116" id="token-10-10" morph="none" pos="word" start_char="1106">application</TOKEN>
<TOKEN end_char="1123" id="token-10-11" morph="none" pos="word" start_char="1118">within</TOKEN>
<TOKEN end_char="1128" id="token-10-12" morph="none" pos="word" start_char="1125">this</TOKEN>
<TOKEN end_char="1135" id="token-10-13" morph="none" pos="word" start_char="1130">family</TOKEN>
<TOKEN end_char="1138" id="token-10-14" morph="none" pos="word" start_char="1137">of</TOKEN>
<TOKEN end_char="1146" id="token-10-15" morph="none" pos="word" start_char="1140">patents</TOKEN>
<TOKEN end_char="1147" id="token-10-16" morph="none" pos="punct" start_char="1147">.</TOKEN>
</SEG>
<SEG end_char="1316" id="segment-11" start_char="1150">
<ORIGINAL_TEXT>A series of regular, non-provisional patent applications were subsequently made for a "System and Method For Using, Processing, and Displaying Biometric Data" (here) .</ORIGINAL_TEXT>
<TOKEN end_char="1150" id="token-11-0" morph="none" pos="word" start_char="1150">A</TOKEN>
<TOKEN end_char="1157" id="token-11-1" morph="none" pos="word" start_char="1152">series</TOKEN>
<TOKEN end_char="1160" id="token-11-2" morph="none" pos="word" start_char="1159">of</TOKEN>
<TOKEN end_char="1168" id="token-11-3" morph="none" pos="word" start_char="1162">regular</TOKEN>
<TOKEN end_char="1169" id="token-11-4" morph="none" pos="punct" start_char="1169">,</TOKEN>
<TOKEN end_char="1185" id="token-11-5" morph="none" pos="unknown" start_char="1171">non-provisional</TOKEN>
<TOKEN end_char="1192" id="token-11-6" morph="none" pos="word" start_char="1187">patent</TOKEN>
<TOKEN end_char="1205" id="token-11-7" morph="none" pos="word" start_char="1194">applications</TOKEN>
<TOKEN end_char="1210" id="token-11-8" morph="none" pos="word" start_char="1207">were</TOKEN>
<TOKEN end_char="1223" id="token-11-9" morph="none" pos="word" start_char="1212">subsequently</TOKEN>
<TOKEN end_char="1228" id="token-11-10" morph="none" pos="word" start_char="1225">made</TOKEN>
<TOKEN end_char="1232" id="token-11-11" morph="none" pos="word" start_char="1230">for</TOKEN>
<TOKEN end_char="1234" id="token-11-12" morph="none" pos="word" start_char="1234">a</TOKEN>
<TOKEN end_char="1236" id="token-11-13" morph="none" pos="punct" start_char="1236">"</TOKEN>
<TOKEN end_char="1242" id="token-11-14" morph="none" pos="word" start_char="1237">System</TOKEN>
<TOKEN end_char="1246" id="token-11-15" morph="none" pos="word" start_char="1244">and</TOKEN>
<TOKEN end_char="1253" id="token-11-16" morph="none" pos="word" start_char="1248">Method</TOKEN>
<TOKEN end_char="1257" id="token-11-17" morph="none" pos="word" start_char="1255">For</TOKEN>
<TOKEN end_char="1263" id="token-11-18" morph="none" pos="word" start_char="1259">Using</TOKEN>
<TOKEN end_char="1264" id="token-11-19" morph="none" pos="punct" start_char="1264">,</TOKEN>
<TOKEN end_char="1275" id="token-11-20" morph="none" pos="word" start_char="1266">Processing</TOKEN>
<TOKEN end_char="1276" id="token-11-21" morph="none" pos="punct" start_char="1276">,</TOKEN>
<TOKEN end_char="1280" id="token-11-22" morph="none" pos="word" start_char="1278">and</TOKEN>
<TOKEN end_char="1291" id="token-11-23" morph="none" pos="word" start_char="1282">Displaying</TOKEN>
<TOKEN end_char="1301" id="token-11-24" morph="none" pos="word" start_char="1293">Biometric</TOKEN>
<TOKEN end_char="1306" id="token-11-25" morph="none" pos="word" start_char="1303">Data</TOKEN>
<TOKEN end_char="1307" id="token-11-26" morph="none" pos="punct" start_char="1307">"</TOKEN>
<TOKEN end_char="1309" id="token-11-27" morph="none" pos="punct" start_char="1309">(</TOKEN>
<TOKEN end_char="1313" id="token-11-28" morph="none" pos="word" start_char="1310">here</TOKEN>
<TOKEN end_char="1314" id="token-11-29" morph="none" pos="punct" start_char="1314">)</TOKEN>
<TOKEN end_char="1316" id="token-11-30" morph="none" pos="punct" start_char="1316">.</TOKEN>
</SEG>
<SEG end_char="1474" id="segment-12" start_char="1319">
<ORIGINAL_TEXT>These earlier patents are essentially the predecessors to ‘US20200279585A1’ - and as such share similar features, such as the use of biometric data (here) .</ORIGINAL_TEXT>
<TOKEN end_char="1323" id="token-12-0" morph="none" pos="word" start_char="1319">These</TOKEN>
<TOKEN end_char="1331" id="token-12-1" morph="none" pos="word" start_char="1325">earlier</TOKEN>
<TOKEN end_char="1339" id="token-12-2" morph="none" pos="word" start_char="1333">patents</TOKEN>
<TOKEN end_char="1343" id="token-12-3" morph="none" pos="word" start_char="1341">are</TOKEN>
<TOKEN end_char="1355" id="token-12-4" morph="none" pos="word" start_char="1345">essentially</TOKEN>
<TOKEN end_char="1359" id="token-12-5" morph="none" pos="word" start_char="1357">the</TOKEN>
<TOKEN end_char="1372" id="token-12-6" morph="none" pos="word" start_char="1361">predecessors</TOKEN>
<TOKEN end_char="1375" id="token-12-7" morph="none" pos="word" start_char="1374">to</TOKEN>
<TOKEN end_char="1377" id="token-12-8" morph="none" pos="punct" start_char="1377">‘</TOKEN>
<TOKEN end_char="1392" id="token-12-9" morph="none" pos="word" start_char="1378">US20200279585A1</TOKEN>
<TOKEN end_char="1393" id="token-12-10" morph="none" pos="punct" start_char="1393">’</TOKEN>
<TOKEN end_char="1395" id="token-12-11" morph="none" pos="punct" start_char="1395">-</TOKEN>
<TOKEN end_char="1399" id="token-12-12" morph="none" pos="word" start_char="1397">and</TOKEN>
<TOKEN end_char="1402" id="token-12-13" morph="none" pos="word" start_char="1401">as</TOKEN>
<TOKEN end_char="1407" id="token-12-14" morph="none" pos="word" start_char="1404">such</TOKEN>
<TOKEN end_char="1413" id="token-12-15" morph="none" pos="word" start_char="1409">share</TOKEN>
<TOKEN end_char="1421" id="token-12-16" morph="none" pos="word" start_char="1415">similar</TOKEN>
<TOKEN end_char="1430" id="token-12-17" morph="none" pos="word" start_char="1423">features</TOKEN>
<TOKEN end_char="1431" id="token-12-18" morph="none" pos="punct" start_char="1431">,</TOKEN>
<TOKEN end_char="1436" id="token-12-19" morph="none" pos="word" start_char="1433">such</TOKEN>
<TOKEN end_char="1439" id="token-12-20" morph="none" pos="word" start_char="1438">as</TOKEN>
<TOKEN end_char="1443" id="token-12-21" morph="none" pos="word" start_char="1441">the</TOKEN>
<TOKEN end_char="1447" id="token-12-22" morph="none" pos="word" start_char="1445">use</TOKEN>
<TOKEN end_char="1450" id="token-12-23" morph="none" pos="word" start_char="1449">of</TOKEN>
<TOKEN end_char="1460" id="token-12-24" morph="none" pos="word" start_char="1452">biometric</TOKEN>
<TOKEN end_char="1465" id="token-12-25" morph="none" pos="word" start_char="1462">data</TOKEN>
<TOKEN end_char="1467" id="token-12-26" morph="none" pos="punct" start_char="1467">(</TOKEN>
<TOKEN end_char="1471" id="token-12-27" morph="none" pos="word" start_char="1468">here</TOKEN>
<TOKEN end_char="1472" id="token-12-28" morph="none" pos="punct" start_char="1472">)</TOKEN>
<TOKEN end_char="1474" id="token-12-29" morph="none" pos="punct" start_char="1474">.</TOKEN>
</SEG>
<SEG end_char="1641" id="segment-13" start_char="1477">
<ORIGINAL_TEXT>However, the patent for a system that analyses biometric data to determine whether the user is suffering from COVID-19 was not applied for until May 17, 2020 (here).</ORIGINAL_TEXT>
<TOKEN end_char="1483" id="token-13-0" morph="none" pos="word" start_char="1477">However</TOKEN>
<TOKEN end_char="1484" id="token-13-1" morph="none" pos="punct" start_char="1484">,</TOKEN>
<TOKEN end_char="1488" id="token-13-2" morph="none" pos="word" start_char="1486">the</TOKEN>
<TOKEN end_char="1495" id="token-13-3" morph="none" pos="word" start_char="1490">patent</TOKEN>
<TOKEN end_char="1499" id="token-13-4" morph="none" pos="word" start_char="1497">for</TOKEN>
<TOKEN end_char="1501" id="token-13-5" morph="none" pos="word" start_char="1501">a</TOKEN>
<TOKEN end_char="1508" id="token-13-6" morph="none" pos="word" start_char="1503">system</TOKEN>
<TOKEN end_char="1513" id="token-13-7" morph="none" pos="word" start_char="1510">that</TOKEN>
<TOKEN end_char="1522" id="token-13-8" morph="none" pos="word" start_char="1515">analyses</TOKEN>
<TOKEN end_char="1532" id="token-13-9" morph="none" pos="word" start_char="1524">biometric</TOKEN>
<TOKEN end_char="1537" id="token-13-10" morph="none" pos="word" start_char="1534">data</TOKEN>
<TOKEN end_char="1540" id="token-13-11" morph="none" pos="word" start_char="1539">to</TOKEN>
<TOKEN end_char="1550" id="token-13-12" morph="none" pos="word" start_char="1542">determine</TOKEN>
<TOKEN end_char="1558" id="token-13-13" morph="none" pos="word" start_char="1552">whether</TOKEN>
<TOKEN end_char="1562" id="token-13-14" morph="none" pos="word" start_char="1560">the</TOKEN>
<TOKEN end_char="1567" id="token-13-15" morph="none" pos="word" start_char="1564">user</TOKEN>
<TOKEN end_char="1570" id="token-13-16" morph="none" pos="word" start_char="1569">is</TOKEN>
<TOKEN end_char="1580" id="token-13-17" morph="none" pos="word" start_char="1572">suffering</TOKEN>
<TOKEN end_char="1585" id="token-13-18" morph="none" pos="word" start_char="1582">from</TOKEN>
<TOKEN end_char="1594" id="token-13-19" morph="none" pos="unknown" start_char="1587">COVID-19</TOKEN>
<TOKEN end_char="1598" id="token-13-20" morph="none" pos="word" start_char="1596">was</TOKEN>
<TOKEN end_char="1602" id="token-13-21" morph="none" pos="word" start_char="1600">not</TOKEN>
<TOKEN end_char="1610" id="token-13-22" morph="none" pos="word" start_char="1604">applied</TOKEN>
<TOKEN end_char="1614" id="token-13-23" morph="none" pos="word" start_char="1612">for</TOKEN>
<TOKEN end_char="1620" id="token-13-24" morph="none" pos="word" start_char="1616">until</TOKEN>
<TOKEN end_char="1624" id="token-13-25" morph="none" pos="word" start_char="1622">May</TOKEN>
<TOKEN end_char="1627" id="token-13-26" morph="none" pos="word" start_char="1626">17</TOKEN>
<TOKEN end_char="1628" id="token-13-27" morph="none" pos="punct" start_char="1628">,</TOKEN>
<TOKEN end_char="1633" id="token-13-28" morph="none" pos="word" start_char="1630">2020</TOKEN>
<TOKEN end_char="1635" id="token-13-29" morph="none" pos="punct" start_char="1635">(</TOKEN>
<TOKEN end_char="1639" id="token-13-30" morph="none" pos="word" start_char="1636">here</TOKEN>
<TOKEN end_char="1641" id="token-13-31" morph="none" pos="punct" start_char="1640">).</TOKEN>
</SEG>
<SEG end_char="1744" id="segment-14" start_char="1644">
<ORIGINAL_TEXT>The article also claims to provide evidence of a patent for COVID-19 testing being filed for in 2017.</ORIGINAL_TEXT>
<TOKEN end_char="1646" id="token-14-0" morph="none" pos="word" start_char="1644">The</TOKEN>
<TOKEN end_char="1654" id="token-14-1" morph="none" pos="word" start_char="1648">article</TOKEN>
<TOKEN end_char="1659" id="token-14-2" morph="none" pos="word" start_char="1656">also</TOKEN>
<TOKEN end_char="1666" id="token-14-3" morph="none" pos="word" start_char="1661">claims</TOKEN>
<TOKEN end_char="1669" id="token-14-4" morph="none" pos="word" start_char="1668">to</TOKEN>
<TOKEN end_char="1677" id="token-14-5" morph="none" pos="word" start_char="1671">provide</TOKEN>
<TOKEN end_char="1686" id="token-14-6" morph="none" pos="word" start_char="1679">evidence</TOKEN>
<TOKEN end_char="1689" id="token-14-7" morph="none" pos="word" start_char="1688">of</TOKEN>
<TOKEN end_char="1691" id="token-14-8" morph="none" pos="word" start_char="1691">a</TOKEN>
<TOKEN end_char="1698" id="token-14-9" morph="none" pos="word" start_char="1693">patent</TOKEN>
<TOKEN end_char="1702" id="token-14-10" morph="none" pos="word" start_char="1700">for</TOKEN>
<TOKEN end_char="1711" id="token-14-11" morph="none" pos="unknown" start_char="1704">COVID-19</TOKEN>
<TOKEN end_char="1719" id="token-14-12" morph="none" pos="word" start_char="1713">testing</TOKEN>
<TOKEN end_char="1725" id="token-14-13" morph="none" pos="word" start_char="1721">being</TOKEN>
<TOKEN end_char="1731" id="token-14-14" morph="none" pos="word" start_char="1727">filed</TOKEN>
<TOKEN end_char="1735" id="token-14-15" morph="none" pos="word" start_char="1733">for</TOKEN>
<TOKEN end_char="1738" id="token-14-16" morph="none" pos="word" start_char="1737">in</TOKEN>
<TOKEN end_char="1743" id="token-14-17" morph="none" pos="word" start_char="1740">2017</TOKEN>
<TOKEN end_char="1744" id="token-14-18" morph="none" pos="punct" start_char="1744">.</TOKEN>
</SEG>
<SEG end_char="1895" id="segment-15" start_char="1747">
<ORIGINAL_TEXT>It references the patent for a "System and Method for Using, Biometric, and Displaying Biometric Data" and its filing date of April 24, 2017 (here) .</ORIGINAL_TEXT>
<TOKEN end_char="1748" id="token-15-0" morph="none" pos="word" start_char="1747">It</TOKEN>
<TOKEN end_char="1759" id="token-15-1" morph="none" pos="word" start_char="1750">references</TOKEN>
<TOKEN end_char="1763" id="token-15-2" morph="none" pos="word" start_char="1761">the</TOKEN>
<TOKEN end_char="1770" id="token-15-3" morph="none" pos="word" start_char="1765">patent</TOKEN>
<TOKEN end_char="1774" id="token-15-4" morph="none" pos="word" start_char="1772">for</TOKEN>
<TOKEN end_char="1776" id="token-15-5" morph="none" pos="word" start_char="1776">a</TOKEN>
<TOKEN end_char="1778" id="token-15-6" morph="none" pos="punct" start_char="1778">"</TOKEN>
<TOKEN end_char="1784" id="token-15-7" morph="none" pos="word" start_char="1779">System</TOKEN>
<TOKEN end_char="1788" id="token-15-8" morph="none" pos="word" start_char="1786">and</TOKEN>
<TOKEN end_char="1795" id="token-15-9" morph="none" pos="word" start_char="1790">Method</TOKEN>
<TOKEN end_char="1799" id="token-15-10" morph="none" pos="word" start_char="1797">for</TOKEN>
<TOKEN end_char="1805" id="token-15-11" morph="none" pos="word" start_char="1801">Using</TOKEN>
<TOKEN end_char="1806" id="token-15-12" morph="none" pos="punct" start_char="1806">,</TOKEN>
<TOKEN end_char="1816" id="token-15-13" morph="none" pos="word" start_char="1808">Biometric</TOKEN>
<TOKEN end_char="1817" id="token-15-14" morph="none" pos="punct" start_char="1817">,</TOKEN>
<TOKEN end_char="1821" id="token-15-15" morph="none" pos="word" start_char="1819">and</TOKEN>
<TOKEN end_char="1832" id="token-15-16" morph="none" pos="word" start_char="1823">Displaying</TOKEN>
<TOKEN end_char="1842" id="token-15-17" morph="none" pos="word" start_char="1834">Biometric</TOKEN>
<TOKEN end_char="1847" id="token-15-18" morph="none" pos="word" start_char="1844">Data</TOKEN>
<TOKEN end_char="1848" id="token-15-19" morph="none" pos="punct" start_char="1848">"</TOKEN>
<TOKEN end_char="1852" id="token-15-20" morph="none" pos="word" start_char="1850">and</TOKEN>
<TOKEN end_char="1856" id="token-15-21" morph="none" pos="word" start_char="1854">its</TOKEN>
<TOKEN end_char="1863" id="token-15-22" morph="none" pos="word" start_char="1858">filing</TOKEN>
<TOKEN end_char="1868" id="token-15-23" morph="none" pos="word" start_char="1865">date</TOKEN>
<TOKEN end_char="1871" id="token-15-24" morph="none" pos="word" start_char="1870">of</TOKEN>
<TOKEN end_char="1877" id="token-15-25" morph="none" pos="word" start_char="1873">April</TOKEN>
<TOKEN end_char="1880" id="token-15-26" morph="none" pos="word" start_char="1879">24</TOKEN>
<TOKEN end_char="1881" id="token-15-27" morph="none" pos="punct" start_char="1881">,</TOKEN>
<TOKEN end_char="1886" id="token-15-28" morph="none" pos="word" start_char="1883">2017</TOKEN>
<TOKEN end_char="1888" id="token-15-29" morph="none" pos="punct" start_char="1888">(</TOKEN>
<TOKEN end_char="1892" id="token-15-30" morph="none" pos="word" start_char="1889">here</TOKEN>
<TOKEN end_char="1893" id="token-15-31" morph="none" pos="punct" start_char="1893">)</TOKEN>
<TOKEN end_char="1895" id="token-15-32" morph="none" pos="punct" start_char="1895">.</TOKEN>
</SEG>
<SEG end_char="2027" id="segment-16" start_char="1898">
<ORIGINAL_TEXT>As already discussed, although this patent is indeed a predecessor to ‘US20200279585A1’, it does not mention COVID-19 in any form.</ORIGINAL_TEXT>
<TOKEN end_char="1899" id="token-16-0" morph="none" pos="word" start_char="1898">As</TOKEN>
<TOKEN end_char="1907" id="token-16-1" morph="none" pos="word" start_char="1901">already</TOKEN>
<TOKEN end_char="1917" id="token-16-2" morph="none" pos="word" start_char="1909">discussed</TOKEN>
<TOKEN end_char="1918" id="token-16-3" morph="none" pos="punct" start_char="1918">,</TOKEN>
<TOKEN end_char="1927" id="token-16-4" morph="none" pos="word" start_char="1920">although</TOKEN>
<TOKEN end_char="1932" id="token-16-5" morph="none" pos="word" start_char="1929">this</TOKEN>
<TOKEN end_char="1939" id="token-16-6" morph="none" pos="word" start_char="1934">patent</TOKEN>
<TOKEN end_char="1942" id="token-16-7" morph="none" pos="word" start_char="1941">is</TOKEN>
<TOKEN end_char="1949" id="token-16-8" morph="none" pos="word" start_char="1944">indeed</TOKEN>
<TOKEN end_char="1951" id="token-16-9" morph="none" pos="word" start_char="1951">a</TOKEN>
<TOKEN end_char="1963" id="token-16-10" morph="none" pos="word" start_char="1953">predecessor</TOKEN>
<TOKEN end_char="1966" id="token-16-11" morph="none" pos="word" start_char="1965">to</TOKEN>
<TOKEN end_char="1968" id="token-16-12" morph="none" pos="punct" start_char="1968">‘</TOKEN>
<TOKEN end_char="1983" id="token-16-13" morph="none" pos="word" start_char="1969">US20200279585A1</TOKEN>
<TOKEN end_char="1985" id="token-16-14" morph="none" pos="punct" start_char="1984">’,</TOKEN>
<TOKEN end_char="1988" id="token-16-15" morph="none" pos="word" start_char="1987">it</TOKEN>
<TOKEN end_char="1993" id="token-16-16" morph="none" pos="word" start_char="1990">does</TOKEN>
<TOKEN end_char="1997" id="token-16-17" morph="none" pos="word" start_char="1995">not</TOKEN>
<TOKEN end_char="2005" id="token-16-18" morph="none" pos="word" start_char="1999">mention</TOKEN>
<TOKEN end_char="2014" id="token-16-19" morph="none" pos="unknown" start_char="2007">COVID-19</TOKEN>
<TOKEN end_char="2017" id="token-16-20" morph="none" pos="word" start_char="2016">in</TOKEN>
<TOKEN end_char="2021" id="token-16-21" morph="none" pos="word" start_char="2019">any</TOKEN>
<TOKEN end_char="2026" id="token-16-22" morph="none" pos="word" start_char="2023">form</TOKEN>
<TOKEN end_char="2027" id="token-16-23" morph="none" pos="punct" start_char="2027">.</TOKEN>
</SEG>
<SEG end_char="2036" id="segment-17" start_char="2030">
<ORIGINAL_TEXT>VERDICT</ORIGINAL_TEXT>
<TOKEN end_char="2036" id="token-17-0" morph="none" pos="word" start_char="2030">VERDICT</TOKEN>
</SEG>
<SEG end_char="2045" id="segment-18" start_char="2040">
<ORIGINAL_TEXT>False.</ORIGINAL_TEXT>
<TOKEN end_char="2044" id="token-18-0" morph="none" pos="word" start_char="2040">False</TOKEN>
<TOKEN end_char="2045" id="token-18-1" morph="none" pos="punct" start_char="2045">.</TOKEN>
</SEG>
<SEG end_char="2147" id="segment-19" start_char="2047">
<ORIGINAL_TEXT>The year 2015 was when Rothschild first filed a provisional application within the family of patents.</ORIGINAL_TEXT>
<TOKEN end_char="2049" id="token-19-0" morph="none" pos="word" start_char="2047">The</TOKEN>
<TOKEN end_char="2054" id="token-19-1" morph="none" pos="word" start_char="2051">year</TOKEN>
<TOKEN end_char="2059" id="token-19-2" morph="none" pos="word" start_char="2056">2015</TOKEN>
<TOKEN end_char="2063" id="token-19-3" morph="none" pos="word" start_char="2061">was</TOKEN>
<TOKEN end_char="2068" id="token-19-4" morph="none" pos="word" start_char="2065">when</TOKEN>
<TOKEN end_char="2079" id="token-19-5" morph="none" pos="word" start_char="2070">Rothschild</TOKEN>
<TOKEN end_char="2085" id="token-19-6" morph="none" pos="word" start_char="2081">first</TOKEN>
<TOKEN end_char="2091" id="token-19-7" morph="none" pos="word" start_char="2087">filed</TOKEN>
<TOKEN end_char="2093" id="token-19-8" morph="none" pos="word" start_char="2093">a</TOKEN>
<TOKEN end_char="2105" id="token-19-9" morph="none" pos="word" start_char="2095">provisional</TOKEN>
<TOKEN end_char="2117" id="token-19-10" morph="none" pos="word" start_char="2107">application</TOKEN>
<TOKEN end_char="2124" id="token-19-11" morph="none" pos="word" start_char="2119">within</TOKEN>
<TOKEN end_char="2128" id="token-19-12" morph="none" pos="word" start_char="2126">the</TOKEN>
<TOKEN end_char="2135" id="token-19-13" morph="none" pos="word" start_char="2130">family</TOKEN>
<TOKEN end_char="2138" id="token-19-14" morph="none" pos="word" start_char="2137">of</TOKEN>
<TOKEN end_char="2146" id="token-19-15" morph="none" pos="word" start_char="2140">patents</TOKEN>
<TOKEN end_char="2147" id="token-19-16" morph="none" pos="punct" start_char="2147">.</TOKEN>
</SEG>
<SEG end_char="2233" id="segment-20" start_char="2149">
<ORIGINAL_TEXT>The year 2017 is the filing date of a related, but separate patent within the family.</ORIGINAL_TEXT>
<TOKEN end_char="2151" id="token-20-0" morph="none" pos="word" start_char="2149">The</TOKEN>
<TOKEN end_char="2156" id="token-20-1" morph="none" pos="word" start_char="2153">year</TOKEN>
<TOKEN end_char="2161" id="token-20-2" morph="none" pos="word" start_char="2158">2017</TOKEN>
<TOKEN end_char="2164" id="token-20-3" morph="none" pos="word" start_char="2163">is</TOKEN>
<TOKEN end_char="2168" id="token-20-4" morph="none" pos="word" start_char="2166">the</TOKEN>
<TOKEN end_char="2175" id="token-20-5" morph="none" pos="word" start_char="2170">filing</TOKEN>
<TOKEN end_char="2180" id="token-20-6" morph="none" pos="word" start_char="2177">date</TOKEN>
<TOKEN end_char="2183" id="token-20-7" morph="none" pos="word" start_char="2182">of</TOKEN>
<TOKEN end_char="2185" id="token-20-8" morph="none" pos="word" start_char="2185">a</TOKEN>
<TOKEN end_char="2193" id="token-20-9" morph="none" pos="word" start_char="2187">related</TOKEN>
<TOKEN end_char="2194" id="token-20-10" morph="none" pos="punct" start_char="2194">,</TOKEN>
<TOKEN end_char="2198" id="token-20-11" morph="none" pos="word" start_char="2196">but</TOKEN>
<TOKEN end_char="2207" id="token-20-12" morph="none" pos="word" start_char="2200">separate</TOKEN>
<TOKEN end_char="2214" id="token-20-13" morph="none" pos="word" start_char="2209">patent</TOKEN>
<TOKEN end_char="2221" id="token-20-14" morph="none" pos="word" start_char="2216">within</TOKEN>
<TOKEN end_char="2225" id="token-20-15" morph="none" pos="word" start_char="2223">the</TOKEN>
<TOKEN end_char="2232" id="token-20-16" morph="none" pos="word" start_char="2227">family</TOKEN>
<TOKEN end_char="2233" id="token-20-17" morph="none" pos="punct" start_char="2233">.</TOKEN>
</SEG>
<SEG end_char="2292" id="segment-21" start_char="2236">
<ORIGINAL_TEXT>This article was produced by the Reuters Fact Check team.</ORIGINAL_TEXT>
<TOKEN end_char="2239" id="token-21-0" morph="none" pos="word" start_char="2236">This</TOKEN>
<TOKEN end_char="2247" id="token-21-1" morph="none" pos="word" start_char="2241">article</TOKEN>
<TOKEN end_char="2251" id="token-21-2" morph="none" pos="word" start_char="2249">was</TOKEN>
<TOKEN end_char="2260" id="token-21-3" morph="none" pos="word" start_char="2253">produced</TOKEN>
<TOKEN end_char="2263" id="token-21-4" morph="none" pos="word" start_char="2262">by</TOKEN>
<TOKEN end_char="2267" id="token-21-5" morph="none" pos="word" start_char="2265">the</TOKEN>
<TOKEN end_char="2275" id="token-21-6" morph="none" pos="word" start_char="2269">Reuters</TOKEN>
<TOKEN end_char="2280" id="token-21-7" morph="none" pos="word" start_char="2277">Fact</TOKEN>
<TOKEN end_char="2286" id="token-21-8" morph="none" pos="word" start_char="2282">Check</TOKEN>
<TOKEN end_char="2291" id="token-21-9" morph="none" pos="word" start_char="2288">team</TOKEN>
<TOKEN end_char="2292" id="token-21-10" morph="none" pos="punct" start_char="2292">.</TOKEN>
</SEG>
<SEG end_char="2338" id="segment-22" start_char="2294">
<ORIGINAL_TEXT>Read more about our fact-checking work here .</ORIGINAL_TEXT>
<TOKEN end_char="2297" id="token-22-0" morph="none" pos="word" start_char="2294">Read</TOKEN>
<TOKEN end_char="2302" id="token-22-1" morph="none" pos="word" start_char="2299">more</TOKEN>
<TOKEN end_char="2308" id="token-22-2" morph="none" pos="word" start_char="2304">about</TOKEN>
<TOKEN end_char="2312" id="token-22-3" morph="none" pos="word" start_char="2310">our</TOKEN>
<TOKEN end_char="2326" id="token-22-4" morph="none" pos="unknown" start_char="2314">fact-checking</TOKEN>
<TOKEN end_char="2331" id="token-22-5" morph="none" pos="word" start_char="2328">work</TOKEN>
<TOKEN end_char="2336" id="token-22-6" morph="none" pos="word" start_char="2333">here</TOKEN>
<TOKEN end_char="2338" id="token-22-7" morph="none" pos="punct" start_char="2338">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="eng">
<DOC grammar="none" id="L0C049DQV" lang="eng" raw_text_char_length="6237" raw_text_md5="40f744733f28ef2cbab8dced34277b09" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="49" id="segment-0" start_char="1">
<ORIGINAL_TEXT>COVID- 19 convalescent plasma treatment on hold ?</ORIGINAL_TEXT>
<TOKEN end_char="5" id="token-0-0" morph="none" pos="word" start_char="1">COVID</TOKEN>
<TOKEN end_char="6" id="token-0-1" morph="none" pos="punct" start_char="6">-</TOKEN>
<TOKEN end_char="9" id="token-0-2" morph="none" pos="word" start_char="8">19</TOKEN>
<TOKEN end_char="22" id="token-0-3" morph="none" pos="word" start_char="11">convalescent</TOKEN>
<TOKEN end_char="29" id="token-0-4" morph="none" pos="word" start_char="24">plasma</TOKEN>
<TOKEN end_char="39" id="token-0-5" morph="none" pos="word" start_char="31">treatment</TOKEN>
<TOKEN end_char="42" id="token-0-6" morph="none" pos="word" start_char="41">on</TOKEN>
<TOKEN end_char="47" id="token-0-7" morph="none" pos="word" start_char="44">hold</TOKEN>
<TOKEN end_char="49" id="token-0-8" morph="none" pos="punct" start_char="49">?</TOKEN>
</SEG>
<SEG end_char="238" id="segment-1" start_char="53">
<ORIGINAL_TEXT>I am not sure I understand why the FDA and NIAID are deciding its best to apply the breaks in order to study convalescent plasma instead of rolling it out to hospitals across the nation.</ORIGINAL_TEXT>
<TOKEN end_char="53" id="token-1-0" morph="none" pos="word" start_char="53">I</TOKEN>
<TOKEN end_char="56" id="token-1-1" morph="none" pos="word" start_char="55">am</TOKEN>
<TOKEN end_char="60" id="token-1-2" morph="none" pos="word" start_char="58">not</TOKEN>
<TOKEN end_char="65" id="token-1-3" morph="none" pos="word" start_char="62">sure</TOKEN>
<TOKEN end_char="67" id="token-1-4" morph="none" pos="word" start_char="67">I</TOKEN>
<TOKEN end_char="78" id="token-1-5" morph="none" pos="word" start_char="69">understand</TOKEN>
<TOKEN end_char="82" id="token-1-6" morph="none" pos="word" start_char="80">why</TOKEN>
<TOKEN end_char="86" id="token-1-7" morph="none" pos="word" start_char="84">the</TOKEN>
<TOKEN end_char="90" id="token-1-8" morph="none" pos="word" start_char="88">FDA</TOKEN>
<TOKEN end_char="94" id="token-1-9" morph="none" pos="word" start_char="92">and</TOKEN>
<TOKEN end_char="100" id="token-1-10" morph="none" pos="word" start_char="96">NIAID</TOKEN>
<TOKEN end_char="104" id="token-1-11" morph="none" pos="word" start_char="102">are</TOKEN>
<TOKEN end_char="113" id="token-1-12" morph="none" pos="word" start_char="106">deciding</TOKEN>
<TOKEN end_char="117" id="token-1-13" morph="none" pos="word" start_char="115">its</TOKEN>
<TOKEN end_char="122" id="token-1-14" morph="none" pos="word" start_char="119">best</TOKEN>
<TOKEN end_char="125" id="token-1-15" morph="none" pos="word" start_char="124">to</TOKEN>
<TOKEN end_char="131" id="token-1-16" morph="none" pos="word" start_char="127">apply</TOKEN>
<TOKEN end_char="135" id="token-1-17" morph="none" pos="word" start_char="133">the</TOKEN>
<TOKEN end_char="142" id="token-1-18" morph="none" pos="word" start_char="137">breaks</TOKEN>
<TOKEN end_char="145" id="token-1-19" morph="none" pos="word" start_char="144">in</TOKEN>
<TOKEN end_char="151" id="token-1-20" morph="none" pos="word" start_char="147">order</TOKEN>
<TOKEN end_char="154" id="token-1-21" morph="none" pos="word" start_char="153">to</TOKEN>
<TOKEN end_char="160" id="token-1-22" morph="none" pos="word" start_char="156">study</TOKEN>
<TOKEN end_char="173" id="token-1-23" morph="none" pos="word" start_char="162">convalescent</TOKEN>
<TOKEN end_char="180" id="token-1-24" morph="none" pos="word" start_char="175">plasma</TOKEN>
<TOKEN end_char="188" id="token-1-25" morph="none" pos="word" start_char="182">instead</TOKEN>
<TOKEN end_char="191" id="token-1-26" morph="none" pos="word" start_char="190">of</TOKEN>
<TOKEN end_char="199" id="token-1-27" morph="none" pos="word" start_char="193">rolling</TOKEN>
<TOKEN end_char="202" id="token-1-28" morph="none" pos="word" start_char="201">it</TOKEN>
<TOKEN end_char="206" id="token-1-29" morph="none" pos="word" start_char="204">out</TOKEN>
<TOKEN end_char="209" id="token-1-30" morph="none" pos="word" start_char="208">to</TOKEN>
<TOKEN end_char="219" id="token-1-31" morph="none" pos="word" start_char="211">hospitals</TOKEN>
<TOKEN end_char="226" id="token-1-32" morph="none" pos="word" start_char="221">across</TOKEN>
<TOKEN end_char="230" id="token-1-33" morph="none" pos="word" start_char="228">the</TOKEN>
<TOKEN end_char="237" id="token-1-34" morph="none" pos="word" start_char="232">nation</TOKEN>
<TOKEN end_char="238" id="token-1-35" morph="none" pos="punct" start_char="238">.</TOKEN>
</SEG>
<SEG end_char="318" id="segment-2" start_char="240">
<ORIGINAL_TEXT>It's been used for over a century and doctors and patients seem to swear by it.</ORIGINAL_TEXT>
<TOKEN end_char="243" id="token-2-0" morph="none" pos="word" start_char="240">It's</TOKEN>
<TOKEN end_char="248" id="token-2-1" morph="none" pos="word" start_char="245">been</TOKEN>
<TOKEN end_char="253" id="token-2-2" morph="none" pos="word" start_char="250">used</TOKEN>
<TOKEN end_char="257" id="token-2-3" morph="none" pos="word" start_char="255">for</TOKEN>
<TOKEN end_char="262" id="token-2-4" morph="none" pos="word" start_char="259">over</TOKEN>
<TOKEN end_char="264" id="token-2-5" morph="none" pos="word" start_char="264">a</TOKEN>
<TOKEN end_char="272" id="token-2-6" morph="none" pos="word" start_char="266">century</TOKEN>
<TOKEN end_char="276" id="token-2-7" morph="none" pos="word" start_char="274">and</TOKEN>
<TOKEN end_char="284" id="token-2-8" morph="none" pos="word" start_char="278">doctors</TOKEN>
<TOKEN end_char="288" id="token-2-9" morph="none" pos="word" start_char="286">and</TOKEN>
<TOKEN end_char="297" id="token-2-10" morph="none" pos="word" start_char="290">patients</TOKEN>
<TOKEN end_char="302" id="token-2-11" morph="none" pos="word" start_char="299">seem</TOKEN>
<TOKEN end_char="305" id="token-2-12" morph="none" pos="word" start_char="304">to</TOKEN>
<TOKEN end_char="311" id="token-2-13" morph="none" pos="word" start_char="307">swear</TOKEN>
<TOKEN end_char="314" id="token-2-14" morph="none" pos="word" start_char="313">by</TOKEN>
<TOKEN end_char="317" id="token-2-15" morph="none" pos="word" start_char="316">it</TOKEN>
<TOKEN end_char="318" id="token-2-16" morph="none" pos="punct" start_char="318">.</TOKEN>
</SEG>
<SEG end_char="449" id="segment-3" start_char="320">
<ORIGINAL_TEXT>At worst it seems like it would do no-harm so why deny likely beneficial treatment so all the experts can study just to make sure.</ORIGINAL_TEXT>
<TOKEN end_char="321" id="token-3-0" morph="none" pos="word" start_char="320">At</TOKEN>
<TOKEN end_char="327" id="token-3-1" morph="none" pos="word" start_char="323">worst</TOKEN>
<TOKEN end_char="330" id="token-3-2" morph="none" pos="word" start_char="329">it</TOKEN>
<TOKEN end_char="336" id="token-3-3" morph="none" pos="word" start_char="332">seems</TOKEN>
<TOKEN end_char="341" id="token-3-4" morph="none" pos="word" start_char="338">like</TOKEN>
<TOKEN end_char="344" id="token-3-5" morph="none" pos="word" start_char="343">it</TOKEN>
<TOKEN end_char="350" id="token-3-6" morph="none" pos="word" start_char="346">would</TOKEN>
<TOKEN end_char="353" id="token-3-7" morph="none" pos="word" start_char="352">do</TOKEN>
<TOKEN end_char="361" id="token-3-8" morph="none" pos="unknown" start_char="355">no-harm</TOKEN>
<TOKEN end_char="364" id="token-3-9" morph="none" pos="word" start_char="363">so</TOKEN>
<TOKEN end_char="368" id="token-3-10" morph="none" pos="word" start_char="366">why</TOKEN>
<TOKEN end_char="373" id="token-3-11" morph="none" pos="word" start_char="370">deny</TOKEN>
<TOKEN end_char="380" id="token-3-12" morph="none" pos="word" start_char="375">likely</TOKEN>
<TOKEN end_char="391" id="token-3-13" morph="none" pos="word" start_char="382">beneficial</TOKEN>
<TOKEN end_char="401" id="token-3-14" morph="none" pos="word" start_char="393">treatment</TOKEN>
<TOKEN end_char="404" id="token-3-15" morph="none" pos="word" start_char="403">so</TOKEN>
<TOKEN end_char="408" id="token-3-16" morph="none" pos="word" start_char="406">all</TOKEN>
<TOKEN end_char="412" id="token-3-17" morph="none" pos="word" start_char="410">the</TOKEN>
<TOKEN end_char="420" id="token-3-18" morph="none" pos="word" start_char="414">experts</TOKEN>
<TOKEN end_char="424" id="token-3-19" morph="none" pos="word" start_char="422">can</TOKEN>
<TOKEN end_char="430" id="token-3-20" morph="none" pos="word" start_char="426">study</TOKEN>
<TOKEN end_char="435" id="token-3-21" morph="none" pos="word" start_char="432">just</TOKEN>
<TOKEN end_char="438" id="token-3-22" morph="none" pos="word" start_char="437">to</TOKEN>
<TOKEN end_char="443" id="token-3-23" morph="none" pos="word" start_char="440">make</TOKEN>
<TOKEN end_char="448" id="token-3-24" morph="none" pos="word" start_char="445">sure</TOKEN>
<TOKEN end_char="449" id="token-3-25" morph="none" pos="punct" start_char="449">.</TOKEN>
</SEG>
<SEG end_char="543" id="segment-4" start_char="451">
<ORIGINAL_TEXT>The way this is being handled lends credence to HCQ being torpedoed due to political reasons.</ORIGINAL_TEXT>
<TOKEN end_char="453" id="token-4-0" morph="none" pos="word" start_char="451">The</TOKEN>
<TOKEN end_char="457" id="token-4-1" morph="none" pos="word" start_char="455">way</TOKEN>
<TOKEN end_char="462" id="token-4-2" morph="none" pos="word" start_char="459">this</TOKEN>
<TOKEN end_char="465" id="token-4-3" morph="none" pos="word" start_char="464">is</TOKEN>
<TOKEN end_char="471" id="token-4-4" morph="none" pos="word" start_char="467">being</TOKEN>
<TOKEN end_char="479" id="token-4-5" morph="none" pos="word" start_char="473">handled</TOKEN>
<TOKEN end_char="485" id="token-4-6" morph="none" pos="word" start_char="481">lends</TOKEN>
<TOKEN end_char="494" id="token-4-7" morph="none" pos="word" start_char="487">credence</TOKEN>
<TOKEN end_char="497" id="token-4-8" morph="none" pos="word" start_char="496">to</TOKEN>
<TOKEN end_char="501" id="token-4-9" morph="none" pos="word" start_char="499">HCQ</TOKEN>
<TOKEN end_char="507" id="token-4-10" morph="none" pos="word" start_char="503">being</TOKEN>
<TOKEN end_char="517" id="token-4-11" morph="none" pos="word" start_char="509">torpedoed</TOKEN>
<TOKEN end_char="521" id="token-4-12" morph="none" pos="word" start_char="519">due</TOKEN>
<TOKEN end_char="524" id="token-4-13" morph="none" pos="word" start_char="523">to</TOKEN>
<TOKEN end_char="534" id="token-4-14" morph="none" pos="word" start_char="526">political</TOKEN>
<TOKEN end_char="542" id="token-4-15" morph="none" pos="word" start_char="536">reasons</TOKEN>
<TOKEN end_char="543" id="token-4-16" morph="none" pos="punct" start_char="543">.</TOKEN>
</SEG>
<SEG end_char="651" id="segment-5" start_char="546">
<ORIGINAL_TEXT>https://www.whio.com/news/trending/fda-puts-covid-19-blood-plasma-therapy-hold/A5YW6GGBZ5EDNDAMPY27YRQKNQ/</ORIGINAL_TEXT>
<TOKEN end_char="651" id="token-5-0" morph="none" pos="url" start_char="546">https://www.whio.com/news/trending/fda-puts-covid-19-blood-plasma-therapy-hold/A5YW6GGBZ5EDNDAMPY27YRQKNQ/</TOKEN>
<TRANSLATED_TEXT>https: / / www.whio.com / news / trending / fda-puts-covid-19-blood-plasma-therapy-hold / A5YW6GGBZ5EDNDAMPY27YRQKNQ /</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="868" id="segment-6" start_char="655">
<ORIGINAL_TEXT>Fauci won't be sold on convalescent plasma based on what he feels are weak indications, but he was all about remdesivir based on a study where the endpoint was changed mid-study to produce a faint positive result?!</ORIGINAL_TEXT>
<TOKEN end_char="659" id="token-6-0" morph="none" pos="word" start_char="655">Fauci</TOKEN>
<TOKEN end_char="665" id="token-6-1" morph="none" pos="word" start_char="661">won't</TOKEN>
<TOKEN end_char="668" id="token-6-2" morph="none" pos="word" start_char="667">be</TOKEN>
<TOKEN end_char="673" id="token-6-3" morph="none" pos="word" start_char="670">sold</TOKEN>
<TOKEN end_char="676" id="token-6-4" morph="none" pos="word" start_char="675">on</TOKEN>
<TOKEN end_char="689" id="token-6-5" morph="none" pos="word" start_char="678">convalescent</TOKEN>
<TOKEN end_char="696" id="token-6-6" morph="none" pos="word" start_char="691">plasma</TOKEN>
<TOKEN end_char="702" id="token-6-7" morph="none" pos="word" start_char="698">based</TOKEN>
<TOKEN end_char="705" id="token-6-8" morph="none" pos="word" start_char="704">on</TOKEN>
<TOKEN end_char="710" id="token-6-9" morph="none" pos="word" start_char="707">what</TOKEN>
<TOKEN end_char="713" id="token-6-10" morph="none" pos="word" start_char="712">he</TOKEN>
<TOKEN end_char="719" id="token-6-11" morph="none" pos="word" start_char="715">feels</TOKEN>
<TOKEN end_char="723" id="token-6-12" morph="none" pos="word" start_char="721">are</TOKEN>
<TOKEN end_char="728" id="token-6-13" morph="none" pos="word" start_char="725">weak</TOKEN>
<TOKEN end_char="740" id="token-6-14" morph="none" pos="word" start_char="730">indications</TOKEN>
<TOKEN end_char="741" id="token-6-15" morph="none" pos="punct" start_char="741">,</TOKEN>
<TOKEN end_char="745" id="token-6-16" morph="none" pos="word" start_char="743">but</TOKEN>
<TOKEN end_char="748" id="token-6-17" morph="none" pos="word" start_char="747">he</TOKEN>
<TOKEN end_char="752" id="token-6-18" morph="none" pos="word" start_char="750">was</TOKEN>
<TOKEN end_char="756" id="token-6-19" morph="none" pos="word" start_char="754">all</TOKEN>
<TOKEN end_char="762" id="token-6-20" morph="none" pos="word" start_char="758">about</TOKEN>
<TOKEN end_char="773" id="token-6-21" morph="none" pos="word" start_char="764">remdesivir</TOKEN>
<TOKEN end_char="779" id="token-6-22" morph="none" pos="word" start_char="775">based</TOKEN>
<TOKEN end_char="782" id="token-6-23" morph="none" pos="word" start_char="781">on</TOKEN>
<TOKEN end_char="784" id="token-6-24" morph="none" pos="word" start_char="784">a</TOKEN>
<TOKEN end_char="790" id="token-6-25" morph="none" pos="word" start_char="786">study</TOKEN>
<TOKEN end_char="796" id="token-6-26" morph="none" pos="word" start_char="792">where</TOKEN>
<TOKEN end_char="800" id="token-6-27" morph="none" pos="word" start_char="798">the</TOKEN>
<TOKEN end_char="809" id="token-6-28" morph="none" pos="word" start_char="802">endpoint</TOKEN>
<TOKEN end_char="813" id="token-6-29" morph="none" pos="word" start_char="811">was</TOKEN>
<TOKEN end_char="821" id="token-6-30" morph="none" pos="word" start_char="815">changed</TOKEN>
<TOKEN end_char="831" id="token-6-31" morph="none" pos="unknown" start_char="823">mid-study</TOKEN>
<TOKEN end_char="834" id="token-6-32" morph="none" pos="word" start_char="833">to</TOKEN>
<TOKEN end_char="842" id="token-6-33" morph="none" pos="word" start_char="836">produce</TOKEN>
<TOKEN end_char="844" id="token-6-34" morph="none" pos="word" start_char="844">a</TOKEN>
<TOKEN end_char="850" id="token-6-35" morph="none" pos="word" start_char="846">faint</TOKEN>
<TOKEN end_char="859" id="token-6-36" morph="none" pos="word" start_char="852">positive</TOKEN>
<TOKEN end_char="866" id="token-6-37" morph="none" pos="word" start_char="861">result</TOKEN>
<TOKEN end_char="868" id="token-6-38" morph="none" pos="punct" start_char="867">?!</TOKEN>
</SEG>
<SEG end_char="1041" id="segment-7" start_char="872">
<ORIGINAL_TEXT>Per the Houston Chronicle, the doctors at Houston Methodist aren't happy because they have had success using the plasma to treat patients at it's Medical Center location.</ORIGINAL_TEXT>
<TOKEN end_char="874" id="token-7-0" morph="none" pos="word" start_char="872">Per</TOKEN>
<TOKEN end_char="878" id="token-7-1" morph="none" pos="word" start_char="876">the</TOKEN>
<TOKEN end_char="886" id="token-7-2" morph="none" pos="word" start_char="880">Houston</TOKEN>
<TOKEN end_char="896" id="token-7-3" morph="none" pos="word" start_char="888">Chronicle</TOKEN>
<TOKEN end_char="897" id="token-7-4" morph="none" pos="punct" start_char="897">,</TOKEN>
<TOKEN end_char="901" id="token-7-5" morph="none" pos="word" start_char="899">the</TOKEN>
<TOKEN end_char="909" id="token-7-6" morph="none" pos="word" start_char="903">doctors</TOKEN>
<TOKEN end_char="912" id="token-7-7" morph="none" pos="word" start_char="911">at</TOKEN>
<TOKEN end_char="920" id="token-7-8" morph="none" pos="word" start_char="914">Houston</TOKEN>
<TOKEN end_char="930" id="token-7-9" morph="none" pos="word" start_char="922">Methodist</TOKEN>
<TOKEN end_char="937" id="token-7-10" morph="none" pos="word" start_char="932">aren't</TOKEN>
<TOKEN end_char="943" id="token-7-11" morph="none" pos="word" start_char="939">happy</TOKEN>
<TOKEN end_char="951" id="token-7-12" morph="none" pos="word" start_char="945">because</TOKEN>
<TOKEN end_char="956" id="token-7-13" morph="none" pos="word" start_char="953">they</TOKEN>
<TOKEN end_char="961" id="token-7-14" morph="none" pos="word" start_char="958">have</TOKEN>
<TOKEN end_char="965" id="token-7-15" morph="none" pos="word" start_char="963">had</TOKEN>
<TOKEN end_char="973" id="token-7-16" morph="none" pos="word" start_char="967">success</TOKEN>
<TOKEN end_char="979" id="token-7-17" morph="none" pos="word" start_char="975">using</TOKEN>
<TOKEN end_char="983" id="token-7-18" morph="none" pos="word" start_char="981">the</TOKEN>
<TOKEN end_char="990" id="token-7-19" morph="none" pos="word" start_char="985">plasma</TOKEN>
<TOKEN end_char="993" id="token-7-20" morph="none" pos="word" start_char="992">to</TOKEN>
<TOKEN end_char="999" id="token-7-21" morph="none" pos="word" start_char="995">treat</TOKEN>
<TOKEN end_char="1008" id="token-7-22" morph="none" pos="word" start_char="1001">patients</TOKEN>
<TOKEN end_char="1011" id="token-7-23" morph="none" pos="word" start_char="1010">at</TOKEN>
<TOKEN end_char="1016" id="token-7-24" morph="none" pos="word" start_char="1013">it's</TOKEN>
<TOKEN end_char="1024" id="token-7-25" morph="none" pos="word" start_char="1018">Medical</TOKEN>
<TOKEN end_char="1031" id="token-7-26" morph="none" pos="word" start_char="1026">Center</TOKEN>
<TOKEN end_char="1040" id="token-7-27" morph="none" pos="word" start_char="1033">location</TOKEN>
<TOKEN end_char="1041" id="token-7-28" morph="none" pos="punct" start_char="1041">.</TOKEN>
</SEG>
<SEG end_char="1250" id="segment-8" start_char="1043">
<ORIGINAL_TEXT>Apparently the experimental use was only allowed at teaching hospitals and Houston Methodist was having success and wanted to see it rolled out to the suburban locations outside of the Medical Center as well.</ORIGINAL_TEXT>
<TOKEN end_char="1052" id="token-8-0" morph="none" pos="word" start_char="1043">Apparently</TOKEN>
<TOKEN end_char="1056" id="token-8-1" morph="none" pos="word" start_char="1054">the</TOKEN>
<TOKEN end_char="1069" id="token-8-2" morph="none" pos="word" start_char="1058">experimental</TOKEN>
<TOKEN end_char="1073" id="token-8-3" morph="none" pos="word" start_char="1071">use</TOKEN>
<TOKEN end_char="1077" id="token-8-4" morph="none" pos="word" start_char="1075">was</TOKEN>
<TOKEN end_char="1082" id="token-8-5" morph="none" pos="word" start_char="1079">only</TOKEN>
<TOKEN end_char="1090" id="token-8-6" morph="none" pos="word" start_char="1084">allowed</TOKEN>
<TOKEN end_char="1093" id="token-8-7" morph="none" pos="word" start_char="1092">at</TOKEN>
<TOKEN end_char="1102" id="token-8-8" morph="none" pos="word" start_char="1095">teaching</TOKEN>
<TOKEN end_char="1112" id="token-8-9" morph="none" pos="word" start_char="1104">hospitals</TOKEN>
<TOKEN end_char="1116" id="token-8-10" morph="none" pos="word" start_char="1114">and</TOKEN>
<TOKEN end_char="1124" id="token-8-11" morph="none" pos="word" start_char="1118">Houston</TOKEN>
<TOKEN end_char="1134" id="token-8-12" morph="none" pos="word" start_char="1126">Methodist</TOKEN>
<TOKEN end_char="1138" id="token-8-13" morph="none" pos="word" start_char="1136">was</TOKEN>
<TOKEN end_char="1145" id="token-8-14" morph="none" pos="word" start_char="1140">having</TOKEN>
<TOKEN end_char="1153" id="token-8-15" morph="none" pos="word" start_char="1147">success</TOKEN>
<TOKEN end_char="1157" id="token-8-16" morph="none" pos="word" start_char="1155">and</TOKEN>
<TOKEN end_char="1164" id="token-8-17" morph="none" pos="word" start_char="1159">wanted</TOKEN>
<TOKEN end_char="1167" id="token-8-18" morph="none" pos="word" start_char="1166">to</TOKEN>
<TOKEN end_char="1171" id="token-8-19" morph="none" pos="word" start_char="1169">see</TOKEN>
<TOKEN end_char="1174" id="token-8-20" morph="none" pos="word" start_char="1173">it</TOKEN>
<TOKEN end_char="1181" id="token-8-21" morph="none" pos="word" start_char="1176">rolled</TOKEN>
<TOKEN end_char="1185" id="token-8-22" morph="none" pos="word" start_char="1183">out</TOKEN>
<TOKEN end_char="1188" id="token-8-23" morph="none" pos="word" start_char="1187">to</TOKEN>
<TOKEN end_char="1192" id="token-8-24" morph="none" pos="word" start_char="1190">the</TOKEN>
<TOKEN end_char="1201" id="token-8-25" morph="none" pos="word" start_char="1194">suburban</TOKEN>
<TOKEN end_char="1211" id="token-8-26" morph="none" pos="word" start_char="1203">locations</TOKEN>
<TOKEN end_char="1219" id="token-8-27" morph="none" pos="word" start_char="1213">outside</TOKEN>
<TOKEN end_char="1222" id="token-8-28" morph="none" pos="word" start_char="1221">of</TOKEN>
<TOKEN end_char="1226" id="token-8-29" morph="none" pos="word" start_char="1224">the</TOKEN>
<TOKEN end_char="1234" id="token-8-30" morph="none" pos="word" start_char="1228">Medical</TOKEN>
<TOKEN end_char="1241" id="token-8-31" morph="none" pos="word" start_char="1236">Center</TOKEN>
<TOKEN end_char="1244" id="token-8-32" morph="none" pos="word" start_char="1243">as</TOKEN>
<TOKEN end_char="1249" id="token-8-33" morph="none" pos="word" start_char="1246">well</TOKEN>
<TOKEN end_char="1250" id="token-8-34" morph="none" pos="punct" start_char="1250">.</TOKEN>
</SEG>
<SEG end_char="1409" id="segment-9" start_char="1253">
<ORIGINAL_TEXT>Makes me wonder if "other" hospitals were perhaps giving this plasma to patients who were too far along in this disease and had too many other complications.</ORIGINAL_TEXT>
<TOKEN end_char="1257" id="token-9-0" morph="none" pos="word" start_char="1253">Makes</TOKEN>
<TOKEN end_char="1260" id="token-9-1" morph="none" pos="word" start_char="1259">me</TOKEN>
<TOKEN end_char="1267" id="token-9-2" morph="none" pos="word" start_char="1262">wonder</TOKEN>
<TOKEN end_char="1270" id="token-9-3" morph="none" pos="word" start_char="1269">if</TOKEN>
<TOKEN end_char="1272" id="token-9-4" morph="none" pos="punct" start_char="1272">"</TOKEN>
<TOKEN end_char="1277" id="token-9-5" morph="none" pos="word" start_char="1273">other</TOKEN>
<TOKEN end_char="1278" id="token-9-6" morph="none" pos="punct" start_char="1278">"</TOKEN>
<TOKEN end_char="1288" id="token-9-7" morph="none" pos="word" start_char="1280">hospitals</TOKEN>
<TOKEN end_char="1293" id="token-9-8" morph="none" pos="word" start_char="1290">were</TOKEN>
<TOKEN end_char="1301" id="token-9-9" morph="none" pos="word" start_char="1295">perhaps</TOKEN>
<TOKEN end_char="1308" id="token-9-10" morph="none" pos="word" start_char="1303">giving</TOKEN>
<TOKEN end_char="1313" id="token-9-11" morph="none" pos="word" start_char="1310">this</TOKEN>
<TOKEN end_char="1320" id="token-9-12" morph="none" pos="word" start_char="1315">plasma</TOKEN>
<TOKEN end_char="1323" id="token-9-13" morph="none" pos="word" start_char="1322">to</TOKEN>
<TOKEN end_char="1332" id="token-9-14" morph="none" pos="word" start_char="1325">patients</TOKEN>
<TOKEN end_char="1336" id="token-9-15" morph="none" pos="word" start_char="1334">who</TOKEN>
<TOKEN end_char="1341" id="token-9-16" morph="none" pos="word" start_char="1338">were</TOKEN>
<TOKEN end_char="1345" id="token-9-17" morph="none" pos="word" start_char="1343">too</TOKEN>
<TOKEN end_char="1349" id="token-9-18" morph="none" pos="word" start_char="1347">far</TOKEN>
<TOKEN end_char="1355" id="token-9-19" morph="none" pos="word" start_char="1351">along</TOKEN>
<TOKEN end_char="1358" id="token-9-20" morph="none" pos="word" start_char="1357">in</TOKEN>
<TOKEN end_char="1363" id="token-9-21" morph="none" pos="word" start_char="1360">this</TOKEN>
<TOKEN end_char="1371" id="token-9-22" morph="none" pos="word" start_char="1365">disease</TOKEN>
<TOKEN end_char="1375" id="token-9-23" morph="none" pos="word" start_char="1373">and</TOKEN>
<TOKEN end_char="1379" id="token-9-24" morph="none" pos="word" start_char="1377">had</TOKEN>
<TOKEN end_char="1383" id="token-9-25" morph="none" pos="word" start_char="1381">too</TOKEN>
<TOKEN end_char="1388" id="token-9-26" morph="none" pos="word" start_char="1385">many</TOKEN>
<TOKEN end_char="1394" id="token-9-27" morph="none" pos="word" start_char="1390">other</TOKEN>
<TOKEN end_char="1408" id="token-9-28" morph="none" pos="word" start_char="1396">complications</TOKEN>
<TOKEN end_char="1409" id="token-9-29" morph="none" pos="punct" start_char="1409">.</TOKEN>
</SEG>
<SEG end_char="1547" id="segment-10" start_char="1411">
<ORIGINAL_TEXT>It seems obvious that plasma would most benefit patients early in the course of COVID who didn't have multiple significant complications.</ORIGINAL_TEXT>
<TOKEN end_char="1412" id="token-10-0" morph="none" pos="word" start_char="1411">It</TOKEN>
<TOKEN end_char="1418" id="token-10-1" morph="none" pos="word" start_char="1414">seems</TOKEN>
<TOKEN end_char="1426" id="token-10-2" morph="none" pos="word" start_char="1420">obvious</TOKEN>
<TOKEN end_char="1431" id="token-10-3" morph="none" pos="word" start_char="1428">that</TOKEN>
<TOKEN end_char="1438" id="token-10-4" morph="none" pos="word" start_char="1433">plasma</TOKEN>
<TOKEN end_char="1444" id="token-10-5" morph="none" pos="word" start_char="1440">would</TOKEN>
<TOKEN end_char="1449" id="token-10-6" morph="none" pos="word" start_char="1446">most</TOKEN>
<TOKEN end_char="1457" id="token-10-7" morph="none" pos="word" start_char="1451">benefit</TOKEN>
<TOKEN end_char="1466" id="token-10-8" morph="none" pos="word" start_char="1459">patients</TOKEN>
<TOKEN end_char="1472" id="token-10-9" morph="none" pos="word" start_char="1468">early</TOKEN>
<TOKEN end_char="1475" id="token-10-10" morph="none" pos="word" start_char="1474">in</TOKEN>
<TOKEN end_char="1479" id="token-10-11" morph="none" pos="word" start_char="1477">the</TOKEN>
<TOKEN end_char="1486" id="token-10-12" morph="none" pos="word" start_char="1481">course</TOKEN>
<TOKEN end_char="1489" id="token-10-13" morph="none" pos="word" start_char="1488">of</TOKEN>
<TOKEN end_char="1495" id="token-10-14" morph="none" pos="word" start_char="1491">COVID</TOKEN>
<TOKEN end_char="1499" id="token-10-15" morph="none" pos="word" start_char="1497">who</TOKEN>
<TOKEN end_char="1506" id="token-10-16" morph="none" pos="word" start_char="1501">didn't</TOKEN>
<TOKEN end_char="1511" id="token-10-17" morph="none" pos="word" start_char="1508">have</TOKEN>
<TOKEN end_char="1520" id="token-10-18" morph="none" pos="word" start_char="1513">multiple</TOKEN>
<TOKEN end_char="1532" id="token-10-19" morph="none" pos="word" start_char="1522">significant</TOKEN>
<TOKEN end_char="1546" id="token-10-20" morph="none" pos="word" start_char="1534">complications</TOKEN>
<TOKEN end_char="1547" id="token-10-21" morph="none" pos="punct" start_char="1547">.</TOKEN>
</SEG>
<SEG end_char="1665" id="segment-11" start_char="1550">
<ORIGINAL_TEXT>https://www.houstonchronicle.com/news/health/article/uthealth-baylor-college-houston-covid-plasma-texas-15496877.php</ORIGINAL_TEXT>
<TOKEN end_char="1665" id="token-11-0" morph="none" pos="url" start_char="1550">https://www.houstonchronicle.com/news/health/article/uthealth-baylor-college-houston-covid-plasma-texas-15496877.php</TOKEN>
<TRANSLATED_TEXT>https: / / www.houstonchronicle.com / news / health / article / uthealth- baylor-college-houston-covid-plasma-texas-15496877.php</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="1715" id="segment-12" start_char="1669">
<ORIGINAL_TEXT>Where is the data showing this treatment works?</ORIGINAL_TEXT>
<TOKEN end_char="1673" id="token-12-0" morph="none" pos="word" start_char="1669">Where</TOKEN>
<TOKEN end_char="1676" id="token-12-1" morph="none" pos="word" start_char="1675">is</TOKEN>
<TOKEN end_char="1680" id="token-12-2" morph="none" pos="word" start_char="1678">the</TOKEN>
<TOKEN end_char="1685" id="token-12-3" morph="none" pos="word" start_char="1682">data</TOKEN>
<TOKEN end_char="1693" id="token-12-4" morph="none" pos="word" start_char="1687">showing</TOKEN>
<TOKEN end_char="1698" id="token-12-5" morph="none" pos="word" start_char="1695">this</TOKEN>
<TOKEN end_char="1708" id="token-12-6" morph="none" pos="word" start_char="1700">treatment</TOKEN>
<TOKEN end_char="1714" id="token-12-7" morph="none" pos="word" start_char="1710">works</TOKEN>
<TOKEN end_char="1715" id="token-12-8" morph="none" pos="punct" start_char="1715">?</TOKEN>
</SEG>
<SEG end_char="1859" id="segment-13" start_char="1718">
<ORIGINAL_TEXT>I kind of assumed it would, but with what we know now about the weak B cell response in many patients I'm not so sure how helpful it would be.</ORIGINAL_TEXT>
<TOKEN end_char="1718" id="token-13-0" morph="none" pos="word" start_char="1718">I</TOKEN>
<TOKEN end_char="1723" id="token-13-1" morph="none" pos="word" start_char="1720">kind</TOKEN>
<TOKEN end_char="1726" id="token-13-2" morph="none" pos="word" start_char="1725">of</TOKEN>
<TOKEN end_char="1734" id="token-13-3" morph="none" pos="word" start_char="1728">assumed</TOKEN>
<TOKEN end_char="1737" id="token-13-4" morph="none" pos="word" start_char="1736">it</TOKEN>
<TOKEN end_char="1743" id="token-13-5" morph="none" pos="word" start_char="1739">would</TOKEN>
<TOKEN end_char="1744" id="token-13-6" morph="none" pos="punct" start_char="1744">,</TOKEN>
<TOKEN end_char="1748" id="token-13-7" morph="none" pos="word" start_char="1746">but</TOKEN>
<TOKEN end_char="1753" id="token-13-8" morph="none" pos="word" start_char="1750">with</TOKEN>
<TOKEN end_char="1758" id="token-13-9" morph="none" pos="word" start_char="1755">what</TOKEN>
<TOKEN end_char="1761" id="token-13-10" morph="none" pos="word" start_char="1760">we</TOKEN>
<TOKEN end_char="1766" id="token-13-11" morph="none" pos="word" start_char="1763">know</TOKEN>
<TOKEN end_char="1770" id="token-13-12" morph="none" pos="word" start_char="1768">now</TOKEN>
<TOKEN end_char="1776" id="token-13-13" morph="none" pos="word" start_char="1772">about</TOKEN>
<TOKEN end_char="1780" id="token-13-14" morph="none" pos="word" start_char="1778">the</TOKEN>
<TOKEN end_char="1785" id="token-13-15" morph="none" pos="word" start_char="1782">weak</TOKEN>
<TOKEN end_char="1787" id="token-13-16" morph="none" pos="word" start_char="1787">B</TOKEN>
<TOKEN end_char="1792" id="token-13-17" morph="none" pos="word" start_char="1789">cell</TOKEN>
<TOKEN end_char="1801" id="token-13-18" morph="none" pos="word" start_char="1794">response</TOKEN>
<TOKEN end_char="1804" id="token-13-19" morph="none" pos="word" start_char="1803">in</TOKEN>
<TOKEN end_char="1809" id="token-13-20" morph="none" pos="word" start_char="1806">many</TOKEN>
<TOKEN end_char="1818" id="token-13-21" morph="none" pos="word" start_char="1811">patients</TOKEN>
<TOKEN end_char="1822" id="token-13-22" morph="none" pos="word" start_char="1820">I'm</TOKEN>
<TOKEN end_char="1826" id="token-13-23" morph="none" pos="word" start_char="1824">not</TOKEN>
<TOKEN end_char="1829" id="token-13-24" morph="none" pos="word" start_char="1828">so</TOKEN>
<TOKEN end_char="1834" id="token-13-25" morph="none" pos="word" start_char="1831">sure</TOKEN>
<TOKEN end_char="1838" id="token-13-26" morph="none" pos="word" start_char="1836">how</TOKEN>
<TOKEN end_char="1846" id="token-13-27" morph="none" pos="word" start_char="1840">helpful</TOKEN>
<TOKEN end_char="1849" id="token-13-28" morph="none" pos="word" start_char="1848">it</TOKEN>
<TOKEN end_char="1855" id="token-13-29" morph="none" pos="word" start_char="1851">would</TOKEN>
<TOKEN end_char="1858" id="token-13-30" morph="none" pos="word" start_char="1857">be</TOKEN>
<TOKEN end_char="1859" id="token-13-31" morph="none" pos="punct" start_char="1859">.</TOKEN>
</SEG>
<SEG end_char="1903" id="segment-14" start_char="1862">
<ORIGINAL_TEXT>Also, it's not a scalable solution anyway.</ORIGINAL_TEXT>
<TOKEN end_char="1865" id="token-14-0" morph="none" pos="word" start_char="1862">Also</TOKEN>
<TOKEN end_char="1866" id="token-14-1" morph="none" pos="punct" start_char="1866">,</TOKEN>
<TOKEN end_char="1871" id="token-14-2" morph="none" pos="word" start_char="1868">it's</TOKEN>
<TOKEN end_char="1875" id="token-14-3" morph="none" pos="word" start_char="1873">not</TOKEN>
<TOKEN end_char="1877" id="token-14-4" morph="none" pos="word" start_char="1877">a</TOKEN>
<TOKEN end_char="1886" id="token-14-5" morph="none" pos="word" start_char="1879">scalable</TOKEN>
<TOKEN end_char="1895" id="token-14-6" morph="none" pos="word" start_char="1888">solution</TOKEN>
<TOKEN end_char="1902" id="token-14-7" morph="none" pos="word" start_char="1897">anyway</TOKEN>
<TOKEN end_char="1903" id="token-14-8" morph="none" pos="punct" start_char="1903">.</TOKEN>
</SEG>
<SEG end_char="1995" id="segment-15" start_char="1905">
<ORIGINAL_TEXT>IF passive immunity is the answer, then one of the antibodies cocktails will have to do it.</ORIGINAL_TEXT>
<TOKEN end_char="1906" id="token-15-0" morph="none" pos="word" start_char="1905">IF</TOKEN>
<TOKEN end_char="1914" id="token-15-1" morph="none" pos="word" start_char="1908">passive</TOKEN>
<TOKEN end_char="1923" id="token-15-2" morph="none" pos="word" start_char="1916">immunity</TOKEN>
<TOKEN end_char="1926" id="token-15-3" morph="none" pos="word" start_char="1925">is</TOKEN>
<TOKEN end_char="1930" id="token-15-4" morph="none" pos="word" start_char="1928">the</TOKEN>
<TOKEN end_char="1937" id="token-15-5" morph="none" pos="word" start_char="1932">answer</TOKEN>
<TOKEN end_char="1938" id="token-15-6" morph="none" pos="punct" start_char="1938">,</TOKEN>
<TOKEN end_char="1943" id="token-15-7" morph="none" pos="word" start_char="1940">then</TOKEN>
<TOKEN end_char="1947" id="token-15-8" morph="none" pos="word" start_char="1945">one</TOKEN>
<TOKEN end_char="1950" id="token-15-9" morph="none" pos="word" start_char="1949">of</TOKEN>
<TOKEN end_char="1954" id="token-15-10" morph="none" pos="word" start_char="1952">the</TOKEN>
<TOKEN end_char="1965" id="token-15-11" morph="none" pos="word" start_char="1956">antibodies</TOKEN>
<TOKEN end_char="1975" id="token-15-12" morph="none" pos="word" start_char="1967">cocktails</TOKEN>
<TOKEN end_char="1980" id="token-15-13" morph="none" pos="word" start_char="1977">will</TOKEN>
<TOKEN end_char="1985" id="token-15-14" morph="none" pos="word" start_char="1982">have</TOKEN>
<TOKEN end_char="1988" id="token-15-15" morph="none" pos="word" start_char="1987">to</TOKEN>
<TOKEN end_char="1991" id="token-15-16" morph="none" pos="word" start_char="1990">do</TOKEN>
<TOKEN end_char="1994" id="token-15-17" morph="none" pos="word" start_char="1993">it</TOKEN>
<TOKEN end_char="1995" id="token-15-18" morph="none" pos="punct" start_char="1995">.</TOKEN>
</SEG>
<SEG end_char="2051" id="segment-16" start_char="1999">
<ORIGINAL_TEXT>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362821/</ORIGINAL_TEXT>
<TOKEN end_char="2051" id="token-16-0" morph="none" pos="url" start_char="1999">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362821/</TOKEN>
<TRANSLATED_TEXT>https: / / www.ncbi.nlm.nih.gov / pmc / articles / PMC7362821 /</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="2077" id="segment-17" start_char="2054">
<ORIGINAL_TEXT>best study I could find.</ORIGINAL_TEXT>
<TOKEN end_char="2057" id="token-17-0" morph="none" pos="word" start_char="2054">best</TOKEN>
<TOKEN end_char="2063" id="token-17-1" morph="none" pos="word" start_char="2059">study</TOKEN>
<TOKEN end_char="2065" id="token-17-2" morph="none" pos="word" start_char="2065">I</TOKEN>
<TOKEN end_char="2071" id="token-17-3" morph="none" pos="word" start_char="2067">could</TOKEN>
<TOKEN end_char="2076" id="token-17-4" morph="none" pos="word" start_char="2073">find</TOKEN>
<TOKEN end_char="2077" id="token-17-5" morph="none" pos="punct" start_char="2077">.</TOKEN>
</SEG>
<SEG end_char="2178" id="segment-18" start_char="2079">
<ORIGINAL_TEXT>They acknowledge that the control group wasn't as sick, so that may be a point in the study's favor.</ORIGINAL_TEXT>
<TOKEN end_char="2082" id="token-18-0" morph="none" pos="word" start_char="2079">They</TOKEN>
<TOKEN end_char="2094" id="token-18-1" morph="none" pos="word" start_char="2084">acknowledge</TOKEN>
<TOKEN end_char="2099" id="token-18-2" morph="none" pos="word" start_char="2096">that</TOKEN>
<TOKEN end_char="2103" id="token-18-3" morph="none" pos="word" start_char="2101">the</TOKEN>
<TOKEN end_char="2111" id="token-18-4" morph="none" pos="word" start_char="2105">control</TOKEN>
<TOKEN end_char="2117" id="token-18-5" morph="none" pos="word" start_char="2113">group</TOKEN>
<TOKEN end_char="2124" id="token-18-6" morph="none" pos="word" start_char="2119">wasn't</TOKEN>
<TOKEN end_char="2127" id="token-18-7" morph="none" pos="word" start_char="2126">as</TOKEN>
<TOKEN end_char="2132" id="token-18-8" morph="none" pos="word" start_char="2129">sick</TOKEN>
<TOKEN end_char="2133" id="token-18-9" morph="none" pos="punct" start_char="2133">,</TOKEN>
<TOKEN end_char="2136" id="token-18-10" morph="none" pos="word" start_char="2135">so</TOKEN>
<TOKEN end_char="2141" id="token-18-11" morph="none" pos="word" start_char="2138">that</TOKEN>
<TOKEN end_char="2145" id="token-18-12" morph="none" pos="word" start_char="2143">may</TOKEN>
<TOKEN end_char="2148" id="token-18-13" morph="none" pos="word" start_char="2147">be</TOKEN>
<TOKEN end_char="2150" id="token-18-14" morph="none" pos="word" start_char="2150">a</TOKEN>
<TOKEN end_char="2156" id="token-18-15" morph="none" pos="word" start_char="2152">point</TOKEN>
<TOKEN end_char="2159" id="token-18-16" morph="none" pos="word" start_char="2158">in</TOKEN>
<TOKEN end_char="2163" id="token-18-17" morph="none" pos="word" start_char="2161">the</TOKEN>
<TOKEN end_char="2171" id="token-18-18" morph="none" pos="word" start_char="2165">study's</TOKEN>
<TOKEN end_char="2177" id="token-18-19" morph="none" pos="word" start_char="2173">favor</TOKEN>
<TOKEN end_char="2178" id="token-18-20" morph="none" pos="punct" start_char="2178">.</TOKEN>
</SEG>
<SEG end_char="2321" id="segment-19" start_char="2180">
<ORIGINAL_TEXT>Apparently another European study was stopped because all their admitted COVID patients already had high antibody titers at time of admission.</ORIGINAL_TEXT>
<TOKEN end_char="2189" id="token-19-0" morph="none" pos="word" start_char="2180">Apparently</TOKEN>
<TOKEN end_char="2197" id="token-19-1" morph="none" pos="word" start_char="2191">another</TOKEN>
<TOKEN end_char="2206" id="token-19-2" morph="none" pos="word" start_char="2199">European</TOKEN>
<TOKEN end_char="2212" id="token-19-3" morph="none" pos="word" start_char="2208">study</TOKEN>
<TOKEN end_char="2216" id="token-19-4" morph="none" pos="word" start_char="2214">was</TOKEN>
<TOKEN end_char="2224" id="token-19-5" morph="none" pos="word" start_char="2218">stopped</TOKEN>
<TOKEN end_char="2232" id="token-19-6" morph="none" pos="word" start_char="2226">because</TOKEN>
<TOKEN end_char="2236" id="token-19-7" morph="none" pos="word" start_char="2234">all</TOKEN>
<TOKEN end_char="2242" id="token-19-8" morph="none" pos="word" start_char="2238">their</TOKEN>
<TOKEN end_char="2251" id="token-19-9" morph="none" pos="word" start_char="2244">admitted</TOKEN>
<TOKEN end_char="2257" id="token-19-10" morph="none" pos="word" start_char="2253">COVID</TOKEN>
<TOKEN end_char="2266" id="token-19-11" morph="none" pos="word" start_char="2259">patients</TOKEN>
<TOKEN end_char="2274" id="token-19-12" morph="none" pos="word" start_char="2268">already</TOKEN>
<TOKEN end_char="2278" id="token-19-13" morph="none" pos="word" start_char="2276">had</TOKEN>
<TOKEN end_char="2283" id="token-19-14" morph="none" pos="word" start_char="2280">high</TOKEN>
<TOKEN end_char="2292" id="token-19-15" morph="none" pos="word" start_char="2285">antibody</TOKEN>
<TOKEN end_char="2299" id="token-19-16" morph="none" pos="word" start_char="2294">titers</TOKEN>
<TOKEN end_char="2302" id="token-19-17" morph="none" pos="word" start_char="2301">at</TOKEN>
<TOKEN end_char="2307" id="token-19-18" morph="none" pos="word" start_char="2304">time</TOKEN>
<TOKEN end_char="2310" id="token-19-19" morph="none" pos="word" start_char="2309">of</TOKEN>
<TOKEN end_char="2320" id="token-19-20" morph="none" pos="word" start_char="2312">admission</TOKEN>
<TOKEN end_char="2321" id="token-19-21" morph="none" pos="punct" start_char="2321">.</TOKEN>
</SEG>
<SEG end_char="2363" id="segment-20" start_char="2323">
<ORIGINAL_TEXT>So there wasn't any point in giving more.</ORIGINAL_TEXT>
<TOKEN end_char="2324" id="token-20-0" morph="none" pos="word" start_char="2323">So</TOKEN>
<TOKEN end_char="2330" id="token-20-1" morph="none" pos="word" start_char="2326">there</TOKEN>
<TOKEN end_char="2337" id="token-20-2" morph="none" pos="word" start_char="2332">wasn't</TOKEN>
<TOKEN end_char="2341" id="token-20-3" morph="none" pos="word" start_char="2339">any</TOKEN>
<TOKEN end_char="2347" id="token-20-4" morph="none" pos="word" start_char="2343">point</TOKEN>
<TOKEN end_char="2350" id="token-20-5" morph="none" pos="word" start_char="2349">in</TOKEN>
<TOKEN end_char="2357" id="token-20-6" morph="none" pos="word" start_char="2352">giving</TOKEN>
<TOKEN end_char="2362" id="token-20-7" morph="none" pos="word" start_char="2359">more</TOKEN>
<TOKEN end_char="2363" id="token-20-8" morph="none" pos="punct" start_char="2363">.</TOKEN>
</SEG>
<SEG end_char="2427" id="segment-21" start_char="2366">
<ORIGINAL_TEXT>I was a bit shocked that the FDA came down so hard on its use.</ORIGINAL_TEXT>
<TOKEN end_char="2366" id="token-21-0" morph="none" pos="word" start_char="2366">I</TOKEN>
<TOKEN end_char="2370" id="token-21-1" morph="none" pos="word" start_char="2368">was</TOKEN>
<TOKEN end_char="2372" id="token-21-2" morph="none" pos="word" start_char="2372">a</TOKEN>
<TOKEN end_char="2376" id="token-21-3" morph="none" pos="word" start_char="2374">bit</TOKEN>
<TOKEN end_char="2384" id="token-21-4" morph="none" pos="word" start_char="2378">shocked</TOKEN>
<TOKEN end_char="2389" id="token-21-5" morph="none" pos="word" start_char="2386">that</TOKEN>
<TOKEN end_char="2393" id="token-21-6" morph="none" pos="word" start_char="2391">the</TOKEN>
<TOKEN end_char="2397" id="token-21-7" morph="none" pos="word" start_char="2395">FDA</TOKEN>
<TOKEN end_char="2402" id="token-21-8" morph="none" pos="word" start_char="2399">came</TOKEN>
<TOKEN end_char="2407" id="token-21-9" morph="none" pos="word" start_char="2404">down</TOKEN>
<TOKEN end_char="2410" id="token-21-10" morph="none" pos="word" start_char="2409">so</TOKEN>
<TOKEN end_char="2415" id="token-21-11" morph="none" pos="word" start_char="2412">hard</TOKEN>
<TOKEN end_char="2418" id="token-21-12" morph="none" pos="word" start_char="2417">on</TOKEN>
<TOKEN end_char="2422" id="token-21-13" morph="none" pos="word" start_char="2420">its</TOKEN>
<TOKEN end_char="2426" id="token-21-14" morph="none" pos="word" start_char="2424">use</TOKEN>
<TOKEN end_char="2427" id="token-21-15" morph="none" pos="punct" start_char="2427">.</TOKEN>
</SEG>
<SEG end_char="2541" id="segment-22" start_char="2430">
<ORIGINAL_TEXT>No material on this site is intended to be a substitute for professional medical advice, diagnosis or treatment.</ORIGINAL_TEXT>
<TOKEN end_char="2431" id="token-22-0" morph="none" pos="word" start_char="2430">No</TOKEN>
<TOKEN end_char="2440" id="token-22-1" morph="none" pos="word" start_char="2433">material</TOKEN>
<TOKEN end_char="2443" id="token-22-2" morph="none" pos="word" start_char="2442">on</TOKEN>
<TOKEN end_char="2448" id="token-22-3" morph="none" pos="word" start_char="2445">this</TOKEN>
<TOKEN end_char="2453" id="token-22-4" morph="none" pos="word" start_char="2450">site</TOKEN>
<TOKEN end_char="2456" id="token-22-5" morph="none" pos="word" start_char="2455">is</TOKEN>
<TOKEN end_char="2465" id="token-22-6" morph="none" pos="word" start_char="2458">intended</TOKEN>
<TOKEN end_char="2468" id="token-22-7" morph="none" pos="word" start_char="2467">to</TOKEN>
<TOKEN end_char="2471" id="token-22-8" morph="none" pos="word" start_char="2470">be</TOKEN>
<TOKEN end_char="2473" id="token-22-9" morph="none" pos="word" start_char="2473">a</TOKEN>
<TOKEN end_char="2484" id="token-22-10" morph="none" pos="word" start_char="2475">substitute</TOKEN>
<TOKEN end_char="2488" id="token-22-11" morph="none" pos="word" start_char="2486">for</TOKEN>
<TOKEN end_char="2501" id="token-22-12" morph="none" pos="word" start_char="2490">professional</TOKEN>
<TOKEN end_char="2509" id="token-22-13" morph="none" pos="word" start_char="2503">medical</TOKEN>
<TOKEN end_char="2516" id="token-22-14" morph="none" pos="word" start_char="2511">advice</TOKEN>
<TOKEN end_char="2517" id="token-22-15" morph="none" pos="punct" start_char="2517">,</TOKEN>
<TOKEN end_char="2527" id="token-22-16" morph="none" pos="word" start_char="2519">diagnosis</TOKEN>
<TOKEN end_char="2530" id="token-22-17" morph="none" pos="word" start_char="2529">or</TOKEN>
<TOKEN end_char="2540" id="token-22-18" morph="none" pos="word" start_char="2532">treatment</TOKEN>
<TOKEN end_char="2541" id="token-22-19" morph="none" pos="punct" start_char="2541">.</TOKEN>
</SEG>
<SEG end_char="2570" id="segment-23" start_char="2543">
<ORIGINAL_TEXT>See full Medical Disclaimer.</ORIGINAL_TEXT>
<TOKEN end_char="2545" id="token-23-0" morph="none" pos="word" start_char="2543">See</TOKEN>
<TOKEN end_char="2550" id="token-23-1" morph="none" pos="word" start_char="2547">full</TOKEN>
<TOKEN end_char="2558" id="token-23-2" morph="none" pos="word" start_char="2552">Medical</TOKEN>
<TOKEN end_char="2569" id="token-23-3" morph="none" pos="word" start_char="2560">Disclaimer</TOKEN>
<TOKEN end_char="2570" id="token-23-4" morph="none" pos="punct" start_char="2570">.</TOKEN>
</SEG>
<SEG end_char="2635" id="segment-24" start_char="2574">
<ORIGINAL_TEXT>The FDA is in a tough spot since this has become so political.</ORIGINAL_TEXT>
<TOKEN end_char="2576" id="token-24-0" morph="none" pos="word" start_char="2574">The</TOKEN>
<TOKEN end_char="2580" id="token-24-1" morph="none" pos="word" start_char="2578">FDA</TOKEN>
<TOKEN end_char="2583" id="token-24-2" morph="none" pos="word" start_char="2582">is</TOKEN>
<TOKEN end_char="2586" id="token-24-3" morph="none" pos="word" start_char="2585">in</TOKEN>
<TOKEN end_char="2588" id="token-24-4" morph="none" pos="word" start_char="2588">a</TOKEN>
<TOKEN end_char="2594" id="token-24-5" morph="none" pos="word" start_char="2590">tough</TOKEN>
<TOKEN end_char="2599" id="token-24-6" morph="none" pos="word" start_char="2596">spot</TOKEN>
<TOKEN end_char="2605" id="token-24-7" morph="none" pos="word" start_char="2601">since</TOKEN>
<TOKEN end_char="2610" id="token-24-8" morph="none" pos="word" start_char="2607">this</TOKEN>
<TOKEN end_char="2614" id="token-24-9" morph="none" pos="word" start_char="2612">has</TOKEN>
<TOKEN end_char="2621" id="token-24-10" morph="none" pos="word" start_char="2616">become</TOKEN>
<TOKEN end_char="2624" id="token-24-11" morph="none" pos="word" start_char="2623">so</TOKEN>
<TOKEN end_char="2634" id="token-24-12" morph="none" pos="word" start_char="2626">political</TOKEN>
<TOKEN end_char="2635" id="token-24-13" morph="none" pos="punct" start_char="2635">.</TOKEN>
</SEG>
<SEG end_char="2782" id="segment-25" start_char="2637">
<ORIGINAL_TEXT>They rushed a lot of temporary approvals out in the spring and it really bit them in the ass with tests that were crap and drugs that didn't work.</ORIGINAL_TEXT>
<TOKEN end_char="2640" id="token-25-0" morph="none" pos="word" start_char="2637">They</TOKEN>
<TOKEN end_char="2647" id="token-25-1" morph="none" pos="word" start_char="2642">rushed</TOKEN>
<TOKEN end_char="2649" id="token-25-2" morph="none" pos="word" start_char="2649">a</TOKEN>
<TOKEN end_char="2653" id="token-25-3" morph="none" pos="word" start_char="2651">lot</TOKEN>
<TOKEN end_char="2656" id="token-25-4" morph="none" pos="word" start_char="2655">of</TOKEN>
<TOKEN end_char="2666" id="token-25-5" morph="none" pos="word" start_char="2658">temporary</TOKEN>
<TOKEN end_char="2676" id="token-25-6" morph="none" pos="word" start_char="2668">approvals</TOKEN>
<TOKEN end_char="2680" id="token-25-7" morph="none" pos="word" start_char="2678">out</TOKEN>
<TOKEN end_char="2683" id="token-25-8" morph="none" pos="word" start_char="2682">in</TOKEN>
<TOKEN end_char="2687" id="token-25-9" morph="none" pos="word" start_char="2685">the</TOKEN>
<TOKEN end_char="2694" id="token-25-10" morph="none" pos="word" start_char="2689">spring</TOKEN>
<TOKEN end_char="2698" id="token-25-11" morph="none" pos="word" start_char="2696">and</TOKEN>
<TOKEN end_char="2701" id="token-25-12" morph="none" pos="word" start_char="2700">it</TOKEN>
<TOKEN end_char="2708" id="token-25-13" morph="none" pos="word" start_char="2703">really</TOKEN>
<TOKEN end_char="2712" id="token-25-14" morph="none" pos="word" start_char="2710">bit</TOKEN>
<TOKEN end_char="2717" id="token-25-15" morph="none" pos="word" start_char="2714">them</TOKEN>
<TOKEN end_char="2720" id="token-25-16" morph="none" pos="word" start_char="2719">in</TOKEN>
<TOKEN end_char="2724" id="token-25-17" morph="none" pos="word" start_char="2722">the</TOKEN>
<TOKEN end_char="2728" id="token-25-18" morph="none" pos="word" start_char="2726">ass</TOKEN>
<TOKEN end_char="2733" id="token-25-19" morph="none" pos="word" start_char="2730">with</TOKEN>
<TOKEN end_char="2739" id="token-25-20" morph="none" pos="word" start_char="2735">tests</TOKEN>
<TOKEN end_char="2744" id="token-25-21" morph="none" pos="word" start_char="2741">that</TOKEN>
<TOKEN end_char="2749" id="token-25-22" morph="none" pos="word" start_char="2746">were</TOKEN>
<TOKEN end_char="2754" id="token-25-23" morph="none" pos="word" start_char="2751">crap</TOKEN>
<TOKEN end_char="2758" id="token-25-24" morph="none" pos="word" start_char="2756">and</TOKEN>
<TOKEN end_char="2764" id="token-25-25" morph="none" pos="word" start_char="2760">drugs</TOKEN>
<TOKEN end_char="2769" id="token-25-26" morph="none" pos="word" start_char="2766">that</TOKEN>
<TOKEN end_char="2776" id="token-25-27" morph="none" pos="word" start_char="2771">didn't</TOKEN>
<TOKEN end_char="2781" id="token-25-28" morph="none" pos="word" start_char="2778">work</TOKEN>
<TOKEN end_char="2782" id="token-25-29" morph="none" pos="punct" start_char="2782">.</TOKEN>
</SEG>
<SEG end_char="2881" id="segment-26" start_char="2785">
<ORIGINAL_TEXT>So the easy option now is to go back to the high bar they had for approval in non pandemic times.</ORIGINAL_TEXT>
<TOKEN end_char="2786" id="token-26-0" morph="none" pos="word" start_char="2785">So</TOKEN>
<TOKEN end_char="2790" id="token-26-1" morph="none" pos="word" start_char="2788">the</TOKEN>
<TOKEN end_char="2795" id="token-26-2" morph="none" pos="word" start_char="2792">easy</TOKEN>
<TOKEN end_char="2802" id="token-26-3" morph="none" pos="word" start_char="2797">option</TOKEN>
<TOKEN end_char="2806" id="token-26-4" morph="none" pos="word" start_char="2804">now</TOKEN>
<TOKEN end_char="2809" id="token-26-5" morph="none" pos="word" start_char="2808">is</TOKEN>
<TOKEN end_char="2812" id="token-26-6" morph="none" pos="word" start_char="2811">to</TOKEN>
<TOKEN end_char="2815" id="token-26-7" morph="none" pos="word" start_char="2814">go</TOKEN>
<TOKEN end_char="2820" id="token-26-8" morph="none" pos="word" start_char="2817">back</TOKEN>
<TOKEN end_char="2823" id="token-26-9" morph="none" pos="word" start_char="2822">to</TOKEN>
<TOKEN end_char="2827" id="token-26-10" morph="none" pos="word" start_char="2825">the</TOKEN>
<TOKEN end_char="2832" id="token-26-11" morph="none" pos="word" start_char="2829">high</TOKEN>
<TOKEN end_char="2836" id="token-26-12" morph="none" pos="word" start_char="2834">bar</TOKEN>
<TOKEN end_char="2841" id="token-26-13" morph="none" pos="word" start_char="2838">they</TOKEN>
<TOKEN end_char="2845" id="token-26-14" morph="none" pos="word" start_char="2843">had</TOKEN>
<TOKEN end_char="2849" id="token-26-15" morph="none" pos="word" start_char="2847">for</TOKEN>
<TOKEN end_char="2858" id="token-26-16" morph="none" pos="word" start_char="2851">approval</TOKEN>
<TOKEN end_char="2861" id="token-26-17" morph="none" pos="word" start_char="2860">in</TOKEN>
<TOKEN end_char="2865" id="token-26-18" morph="none" pos="word" start_char="2863">non</TOKEN>
<TOKEN end_char="2874" id="token-26-19" morph="none" pos="word" start_char="2867">pandemic</TOKEN>
<TOKEN end_char="2880" id="token-26-20" morph="none" pos="word" start_char="2876">times</TOKEN>
<TOKEN end_char="2881" id="token-26-21" morph="none" pos="punct" start_char="2881">.</TOKEN>
</SEG>
<SEG end_char="3019" id="segment-27" start_char="2883">
<ORIGINAL_TEXT>They've actually dropped the hammer unexpectedly on a gene therapy for hemophilia and a potential arthritis blockbuster in the last week.</ORIGINAL_TEXT>
<TOKEN end_char="2889" id="token-27-0" morph="none" pos="word" start_char="2883">They've</TOKEN>
<TOKEN end_char="2898" id="token-27-1" morph="none" pos="word" start_char="2891">actually</TOKEN>
<TOKEN end_char="2906" id="token-27-2" morph="none" pos="word" start_char="2900">dropped</TOKEN>
<TOKEN end_char="2910" id="token-27-3" morph="none" pos="word" start_char="2908">the</TOKEN>
<TOKEN end_char="2917" id="token-27-4" morph="none" pos="word" start_char="2912">hammer</TOKEN>
<TOKEN end_char="2930" id="token-27-5" morph="none" pos="word" start_char="2919">unexpectedly</TOKEN>
<TOKEN end_char="2933" id="token-27-6" morph="none" pos="word" start_char="2932">on</TOKEN>
<TOKEN end_char="2935" id="token-27-7" morph="none" pos="word" start_char="2935">a</TOKEN>
<TOKEN end_char="2940" id="token-27-8" morph="none" pos="word" start_char="2937">gene</TOKEN>
<TOKEN end_char="2948" id="token-27-9" morph="none" pos="word" start_char="2942">therapy</TOKEN>
<TOKEN end_char="2952" id="token-27-10" morph="none" pos="word" start_char="2950">for</TOKEN>
<TOKEN end_char="2963" id="token-27-11" morph="none" pos="word" start_char="2954">hemophilia</TOKEN>
<TOKEN end_char="2967" id="token-27-12" morph="none" pos="word" start_char="2965">and</TOKEN>
<TOKEN end_char="2969" id="token-27-13" morph="none" pos="word" start_char="2969">a</TOKEN>
<TOKEN end_char="2979" id="token-27-14" morph="none" pos="word" start_char="2971">potential</TOKEN>
<TOKEN end_char="2989" id="token-27-15" morph="none" pos="word" start_char="2981">arthritis</TOKEN>
<TOKEN end_char="3001" id="token-27-16" morph="none" pos="word" start_char="2991">blockbuster</TOKEN>
<TOKEN end_char="3004" id="token-27-17" morph="none" pos="word" start_char="3003">in</TOKEN>
<TOKEN end_char="3008" id="token-27-18" morph="none" pos="word" start_char="3006">the</TOKEN>
<TOKEN end_char="3013" id="token-27-19" morph="none" pos="word" start_char="3010">last</TOKEN>
<TOKEN end_char="3018" id="token-27-20" morph="none" pos="word" start_char="3015">week</TOKEN>
<TOKEN end_char="3019" id="token-27-21" morph="none" pos="punct" start_char="3019">.</TOKEN>
</SEG>
<SEG end_char="3081" id="segment-28" start_char="3021">
<ORIGINAL_TEXT>So it's not just COVID-19 drugs having a hard time right now.</ORIGINAL_TEXT>
<TOKEN end_char="3022" id="token-28-0" morph="none" pos="word" start_char="3021">So</TOKEN>
<TOKEN end_char="3027" id="token-28-1" morph="none" pos="word" start_char="3024">it's</TOKEN>
<TOKEN end_char="3031" id="token-28-2" morph="none" pos="word" start_char="3029">not</TOKEN>
<TOKEN end_char="3036" id="token-28-3" morph="none" pos="word" start_char="3033">just</TOKEN>
<TOKEN end_char="3045" id="token-28-4" morph="none" pos="unknown" start_char="3038">COVID-19</TOKEN>
<TOKEN end_char="3051" id="token-28-5" morph="none" pos="word" start_char="3047">drugs</TOKEN>
<TOKEN end_char="3058" id="token-28-6" morph="none" pos="word" start_char="3053">having</TOKEN>
<TOKEN end_char="3060" id="token-28-7" morph="none" pos="word" start_char="3060">a</TOKEN>
<TOKEN end_char="3065" id="token-28-8" morph="none" pos="word" start_char="3062">hard</TOKEN>
<TOKEN end_char="3070" id="token-28-9" morph="none" pos="word" start_char="3067">time</TOKEN>
<TOKEN end_char="3076" id="token-28-10" morph="none" pos="word" start_char="3072">right</TOKEN>
<TOKEN end_char="3080" id="token-28-11" morph="none" pos="word" start_char="3078">now</TOKEN>
<TOKEN end_char="3081" id="token-28-12" morph="none" pos="punct" start_char="3081">.</TOKEN>
</SEG>
<SEG end_char="3180" id="segment-29" start_char="3086">
<ORIGINAL_TEXT>ramblin_ag02 said:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362821/best study I could find.</ORIGINAL_TEXT>
<TOKEN end_char="3097" id="token-29-0" morph="none" pos="word" start_char="3086">ramblin_ag02</TOKEN>
<TOKEN end_char="3160" id="token-29-1" morph="none" pos="unknown" start_char="3099">said:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7362821/best</TOKEN>
<TOKEN end_char="3166" id="token-29-2" morph="none" pos="word" start_char="3162">study</TOKEN>
<TOKEN end_char="3168" id="token-29-3" morph="none" pos="word" start_char="3168">I</TOKEN>
<TOKEN end_char="3174" id="token-29-4" morph="none" pos="word" start_char="3170">could</TOKEN>
<TOKEN end_char="3179" id="token-29-5" morph="none" pos="word" start_char="3176">find</TOKEN>
<TOKEN end_char="3180" id="token-29-6" morph="none" pos="punct" start_char="3180">.</TOKEN>
</SEG>
<SEG end_char="3281" id="segment-30" start_char="3182">
<ORIGINAL_TEXT>They acknowledge that the control group wasn't as sick, so that may be a point in the study's favor.</ORIGINAL_TEXT>
<TOKEN end_char="3185" id="token-30-0" morph="none" pos="word" start_char="3182">They</TOKEN>
<TOKEN end_char="3197" id="token-30-1" morph="none" pos="word" start_char="3187">acknowledge</TOKEN>
<TOKEN end_char="3202" id="token-30-2" morph="none" pos="word" start_char="3199">that</TOKEN>
<TOKEN end_char="3206" id="token-30-3" morph="none" pos="word" start_char="3204">the</TOKEN>
<TOKEN end_char="3214" id="token-30-4" morph="none" pos="word" start_char="3208">control</TOKEN>
<TOKEN end_char="3220" id="token-30-5" morph="none" pos="word" start_char="3216">group</TOKEN>
<TOKEN end_char="3227" id="token-30-6" morph="none" pos="word" start_char="3222">wasn't</TOKEN>
<TOKEN end_char="3230" id="token-30-7" morph="none" pos="word" start_char="3229">as</TOKEN>
<TOKEN end_char="3235" id="token-30-8" morph="none" pos="word" start_char="3232">sick</TOKEN>
<TOKEN end_char="3236" id="token-30-9" morph="none" pos="punct" start_char="3236">,</TOKEN>
<TOKEN end_char="3239" id="token-30-10" morph="none" pos="word" start_char="3238">so</TOKEN>
<TOKEN end_char="3244" id="token-30-11" morph="none" pos="word" start_char="3241">that</TOKEN>
<TOKEN end_char="3248" id="token-30-12" morph="none" pos="word" start_char="3246">may</TOKEN>
<TOKEN end_char="3251" id="token-30-13" morph="none" pos="word" start_char="3250">be</TOKEN>
<TOKEN end_char="3253" id="token-30-14" morph="none" pos="word" start_char="3253">a</TOKEN>
<TOKEN end_char="3259" id="token-30-15" morph="none" pos="word" start_char="3255">point</TOKEN>
<TOKEN end_char="3262" id="token-30-16" morph="none" pos="word" start_char="3261">in</TOKEN>
<TOKEN end_char="3266" id="token-30-17" morph="none" pos="word" start_char="3264">the</TOKEN>
<TOKEN end_char="3274" id="token-30-18" morph="none" pos="word" start_char="3268">study's</TOKEN>
<TOKEN end_char="3280" id="token-30-19" morph="none" pos="word" start_char="3276">favor</TOKEN>
<TOKEN end_char="3281" id="token-30-20" morph="none" pos="punct" start_char="3281">.</TOKEN>
</SEG>
<SEG end_char="3424" id="segment-31" start_char="3283">
<ORIGINAL_TEXT>Apparently another European study was stopped because all their admitted COVID patients already had high antibody titers at time of admission.</ORIGINAL_TEXT>
<TOKEN end_char="3292" id="token-31-0" morph="none" pos="word" start_char="3283">Apparently</TOKEN>
<TOKEN end_char="3300" id="token-31-1" morph="none" pos="word" start_char="3294">another</TOKEN>
<TOKEN end_char="3309" id="token-31-2" morph="none" pos="word" start_char="3302">European</TOKEN>
<TOKEN end_char="3315" id="token-31-3" morph="none" pos="word" start_char="3311">study</TOKEN>
<TOKEN end_char="3319" id="token-31-4" morph="none" pos="word" start_char="3317">was</TOKEN>
<TOKEN end_char="3327" id="token-31-5" morph="none" pos="word" start_char="3321">stopped</TOKEN>
<TOKEN end_char="3335" id="token-31-6" morph="none" pos="word" start_char="3329">because</TOKEN>
<TOKEN end_char="3339" id="token-31-7" morph="none" pos="word" start_char="3337">all</TOKEN>
<TOKEN end_char="3345" id="token-31-8" morph="none" pos="word" start_char="3341">their</TOKEN>
<TOKEN end_char="3354" id="token-31-9" morph="none" pos="word" start_char="3347">admitted</TOKEN>
<TOKEN end_char="3360" id="token-31-10" morph="none" pos="word" start_char="3356">COVID</TOKEN>
<TOKEN end_char="3369" id="token-31-11" morph="none" pos="word" start_char="3362">patients</TOKEN>
<TOKEN end_char="3377" id="token-31-12" morph="none" pos="word" start_char="3371">already</TOKEN>
<TOKEN end_char="3381" id="token-31-13" morph="none" pos="word" start_char="3379">had</TOKEN>
<TOKEN end_char="3386" id="token-31-14" morph="none" pos="word" start_char="3383">high</TOKEN>
<TOKEN end_char="3395" id="token-31-15" morph="none" pos="word" start_char="3388">antibody</TOKEN>
<TOKEN end_char="3402" id="token-31-16" morph="none" pos="word" start_char="3397">titers</TOKEN>
<TOKEN end_char="3405" id="token-31-17" morph="none" pos="word" start_char="3404">at</TOKEN>
<TOKEN end_char="3410" id="token-31-18" morph="none" pos="word" start_char="3407">time</TOKEN>
<TOKEN end_char="3413" id="token-31-19" morph="none" pos="word" start_char="3412">of</TOKEN>
<TOKEN end_char="3423" id="token-31-20" morph="none" pos="word" start_char="3415">admission</TOKEN>
<TOKEN end_char="3424" id="token-31-21" morph="none" pos="punct" start_char="3424">.</TOKEN>
</SEG>
<SEG end_char="3528" id="segment-32" start_char="3426">
<ORIGINAL_TEXT>So there wasn't any point in giving more.I was a bit shocked that the FDA came down so hard on its use.</ORIGINAL_TEXT>
<TOKEN end_char="3427" id="token-32-0" morph="none" pos="word" start_char="3426">So</TOKEN>
<TOKEN end_char="3433" id="token-32-1" morph="none" pos="word" start_char="3429">there</TOKEN>
<TOKEN end_char="3440" id="token-32-2" morph="none" pos="word" start_char="3435">wasn't</TOKEN>
<TOKEN end_char="3444" id="token-32-3" morph="none" pos="word" start_char="3442">any</TOKEN>
<TOKEN end_char="3450" id="token-32-4" morph="none" pos="word" start_char="3446">point</TOKEN>
<TOKEN end_char="3453" id="token-32-5" morph="none" pos="word" start_char="3452">in</TOKEN>
<TOKEN end_char="3460" id="token-32-6" morph="none" pos="word" start_char="3455">giving</TOKEN>
<TOKEN end_char="3467" id="token-32-7" morph="none" pos="unknown" start_char="3462">more.I</TOKEN>
<TOKEN end_char="3471" id="token-32-8" morph="none" pos="word" start_char="3469">was</TOKEN>
<TOKEN end_char="3473" id="token-32-9" morph="none" pos="word" start_char="3473">a</TOKEN>
<TOKEN end_char="3477" id="token-32-10" morph="none" pos="word" start_char="3475">bit</TOKEN>
<TOKEN end_char="3485" id="token-32-11" morph="none" pos="word" start_char="3479">shocked</TOKEN>
<TOKEN end_char="3490" id="token-32-12" morph="none" pos="word" start_char="3487">that</TOKEN>
<TOKEN end_char="3494" id="token-32-13" morph="none" pos="word" start_char="3492">the</TOKEN>
<TOKEN end_char="3498" id="token-32-14" morph="none" pos="word" start_char="3496">FDA</TOKEN>
<TOKEN end_char="3503" id="token-32-15" morph="none" pos="word" start_char="3500">came</TOKEN>
<TOKEN end_char="3508" id="token-32-16" morph="none" pos="word" start_char="3505">down</TOKEN>
<TOKEN end_char="3511" id="token-32-17" morph="none" pos="word" start_char="3510">so</TOKEN>
<TOKEN end_char="3516" id="token-32-18" morph="none" pos="word" start_char="3513">hard</TOKEN>
<TOKEN end_char="3519" id="token-32-19" morph="none" pos="word" start_char="3518">on</TOKEN>
<TOKEN end_char="3523" id="token-32-20" morph="none" pos="word" start_char="3521">its</TOKEN>
<TOKEN end_char="3527" id="token-32-21" morph="none" pos="word" start_char="3525">use</TOKEN>
<TOKEN end_char="3528" id="token-32-22" morph="none" pos="punct" start_char="3528">.</TOKEN>
</SEG>
<SEG end_char="3696" id="segment-33" start_char="3531">
<ORIGINAL_TEXT>Thanks for posting that link ramblin ag02. Based on those findings I don't know what Dr. Fauci is looking at because it seems apparent that convalescent plasma helps.</ORIGINAL_TEXT>
<TOKEN end_char="3536" id="token-33-0" morph="none" pos="word" start_char="3531">Thanks</TOKEN>
<TOKEN end_char="3540" id="token-33-1" morph="none" pos="word" start_char="3538">for</TOKEN>
<TOKEN end_char="3548" id="token-33-2" morph="none" pos="word" start_char="3542">posting</TOKEN>
<TOKEN end_char="3553" id="token-33-3" morph="none" pos="word" start_char="3550">that</TOKEN>
<TOKEN end_char="3558" id="token-33-4" morph="none" pos="word" start_char="3555">link</TOKEN>
<TOKEN end_char="3566" id="token-33-5" morph="none" pos="word" start_char="3560">ramblin</TOKEN>
<TOKEN end_char="3571" id="token-33-6" morph="none" pos="word" start_char="3568">ag02</TOKEN>
<TOKEN end_char="3572" id="token-33-7" morph="none" pos="punct" start_char="3572">.</TOKEN>
<TOKEN end_char="3578" id="token-33-8" morph="none" pos="word" start_char="3574">Based</TOKEN>
<TOKEN end_char="3581" id="token-33-9" morph="none" pos="word" start_char="3580">on</TOKEN>
<TOKEN end_char="3587" id="token-33-10" morph="none" pos="word" start_char="3583">those</TOKEN>
<TOKEN end_char="3596" id="token-33-11" morph="none" pos="word" start_char="3589">findings</TOKEN>
<TOKEN end_char="3598" id="token-33-12" morph="none" pos="word" start_char="3598">I</TOKEN>
<TOKEN end_char="3604" id="token-33-13" morph="none" pos="word" start_char="3600">don't</TOKEN>
<TOKEN end_char="3609" id="token-33-14" morph="none" pos="word" start_char="3606">know</TOKEN>
<TOKEN end_char="3614" id="token-33-15" morph="none" pos="word" start_char="3611">what</TOKEN>
<TOKEN end_char="3617" id="token-33-16" morph="none" pos="word" start_char="3616">Dr</TOKEN>
<TOKEN end_char="3618" id="token-33-17" morph="none" pos="punct" start_char="3618">.</TOKEN>
<TOKEN end_char="3624" id="token-33-18" morph="none" pos="word" start_char="3620">Fauci</TOKEN>
<TOKEN end_char="3627" id="token-33-19" morph="none" pos="word" start_char="3626">is</TOKEN>
<TOKEN end_char="3635" id="token-33-20" morph="none" pos="word" start_char="3629">looking</TOKEN>
<TOKEN end_char="3638" id="token-33-21" morph="none" pos="word" start_char="3637">at</TOKEN>
<TOKEN end_char="3646" id="token-33-22" morph="none" pos="word" start_char="3640">because</TOKEN>
<TOKEN end_char="3649" id="token-33-23" morph="none" pos="word" start_char="3648">it</TOKEN>
<TOKEN end_char="3655" id="token-33-24" morph="none" pos="word" start_char="3651">seems</TOKEN>
<TOKEN end_char="3664" id="token-33-25" morph="none" pos="word" start_char="3657">apparent</TOKEN>
<TOKEN end_char="3669" id="token-33-26" morph="none" pos="word" start_char="3666">that</TOKEN>
<TOKEN end_char="3682" id="token-33-27" morph="none" pos="word" start_char="3671">convalescent</TOKEN>
<TOKEN end_char="3689" id="token-33-28" morph="none" pos="word" start_char="3684">plasma</TOKEN>
<TOKEN end_char="3695" id="token-33-29" morph="none" pos="word" start_char="3691">helps</TOKEN>
<TOKEN end_char="3696" id="token-33-30" morph="none" pos="punct" start_char="3696">.</TOKEN>
</SEG>
<SEG end_char="3778" id="segment-34" start_char="3698">
<ORIGINAL_TEXT>I wish everyone could remove all of the politics and simply utilize common sense.</ORIGINAL_TEXT>
<TOKEN end_char="3698" id="token-34-0" morph="none" pos="word" start_char="3698">I</TOKEN>
<TOKEN end_char="3703" id="token-34-1" morph="none" pos="word" start_char="3700">wish</TOKEN>
<TOKEN end_char="3712" id="token-34-2" morph="none" pos="word" start_char="3705">everyone</TOKEN>
<TOKEN end_char="3718" id="token-34-3" morph="none" pos="word" start_char="3714">could</TOKEN>
<TOKEN end_char="3725" id="token-34-4" morph="none" pos="word" start_char="3720">remove</TOKEN>
<TOKEN end_char="3729" id="token-34-5" morph="none" pos="word" start_char="3727">all</TOKEN>
<TOKEN end_char="3732" id="token-34-6" morph="none" pos="word" start_char="3731">of</TOKEN>
<TOKEN end_char="3736" id="token-34-7" morph="none" pos="word" start_char="3734">the</TOKEN>
<TOKEN end_char="3745" id="token-34-8" morph="none" pos="word" start_char="3738">politics</TOKEN>
<TOKEN end_char="3749" id="token-34-9" morph="none" pos="word" start_char="3747">and</TOKEN>
<TOKEN end_char="3756" id="token-34-10" morph="none" pos="word" start_char="3751">simply</TOKEN>
<TOKEN end_char="3764" id="token-34-11" morph="none" pos="word" start_char="3758">utilize</TOKEN>
<TOKEN end_char="3771" id="token-34-12" morph="none" pos="word" start_char="3766">common</TOKEN>
<TOKEN end_char="3777" id="token-34-13" morph="none" pos="word" start_char="3773">sense</TOKEN>
<TOKEN end_char="3778" id="token-34-14" morph="none" pos="punct" start_char="3778">.</TOKEN>
</SEG>
<SEG end_char="3934" id="segment-35" start_char="3783">
<ORIGINAL_TEXT>I think we're still in the equipoise phase where we really don't know if it helps or not, but it's not like we have a ton of other fantastic treatments.</ORIGINAL_TEXT>
<TOKEN end_char="3783" id="token-35-0" morph="none" pos="word" start_char="3783">I</TOKEN>
<TOKEN end_char="3789" id="token-35-1" morph="none" pos="word" start_char="3785">think</TOKEN>
<TOKEN end_char="3795" id="token-35-2" morph="none" pos="word" start_char="3791">we're</TOKEN>
<TOKEN end_char="3801" id="token-35-3" morph="none" pos="word" start_char="3797">still</TOKEN>
<TOKEN end_char="3804" id="token-35-4" morph="none" pos="word" start_char="3803">in</TOKEN>
<TOKEN end_char="3808" id="token-35-5" morph="none" pos="word" start_char="3806">the</TOKEN>
<TOKEN end_char="3818" id="token-35-6" morph="none" pos="word" start_char="3810">equipoise</TOKEN>
<TOKEN end_char="3824" id="token-35-7" morph="none" pos="word" start_char="3820">phase</TOKEN>
<TOKEN end_char="3830" id="token-35-8" morph="none" pos="word" start_char="3826">where</TOKEN>
<TOKEN end_char="3833" id="token-35-9" morph="none" pos="word" start_char="3832">we</TOKEN>
<TOKEN end_char="3840" id="token-35-10" morph="none" pos="word" start_char="3835">really</TOKEN>
<TOKEN end_char="3846" id="token-35-11" morph="none" pos="word" start_char="3842">don't</TOKEN>
<TOKEN end_char="3851" id="token-35-12" morph="none" pos="word" start_char="3848">know</TOKEN>
<TOKEN end_char="3854" id="token-35-13" morph="none" pos="word" start_char="3853">if</TOKEN>
<TOKEN end_char="3857" id="token-35-14" morph="none" pos="word" start_char="3856">it</TOKEN>
<TOKEN end_char="3863" id="token-35-15" morph="none" pos="word" start_char="3859">helps</TOKEN>
<TOKEN end_char="3866" id="token-35-16" morph="none" pos="word" start_char="3865">or</TOKEN>
<TOKEN end_char="3870" id="token-35-17" morph="none" pos="word" start_char="3868">not</TOKEN>
<TOKEN end_char="3871" id="token-35-18" morph="none" pos="punct" start_char="3871">,</TOKEN>
<TOKEN end_char="3875" id="token-35-19" morph="none" pos="word" start_char="3873">but</TOKEN>
<TOKEN end_char="3880" id="token-35-20" morph="none" pos="word" start_char="3877">it's</TOKEN>
<TOKEN end_char="3884" id="token-35-21" morph="none" pos="word" start_char="3882">not</TOKEN>
<TOKEN end_char="3889" id="token-35-22" morph="none" pos="word" start_char="3886">like</TOKEN>
<TOKEN end_char="3892" id="token-35-23" morph="none" pos="word" start_char="3891">we</TOKEN>
<TOKEN end_char="3897" id="token-35-24" morph="none" pos="word" start_char="3894">have</TOKEN>
<TOKEN end_char="3899" id="token-35-25" morph="none" pos="word" start_char="3899">a</TOKEN>
<TOKEN end_char="3903" id="token-35-26" morph="none" pos="word" start_char="3901">ton</TOKEN>
<TOKEN end_char="3906" id="token-35-27" morph="none" pos="word" start_char="3905">of</TOKEN>
<TOKEN end_char="3912" id="token-35-28" morph="none" pos="word" start_char="3908">other</TOKEN>
<TOKEN end_char="3922" id="token-35-29" morph="none" pos="word" start_char="3914">fantastic</TOKEN>
<TOKEN end_char="3933" id="token-35-30" morph="none" pos="word" start_char="3924">treatments</TOKEN>
<TOKEN end_char="3934" id="token-35-31" morph="none" pos="punct" start_char="3934">.</TOKEN>
</SEG>
<SEG end_char="4042" id="segment-36" start_char="3936">
<ORIGINAL_TEXT>Also agree with the point above that lots of things like remdesivir are getting approval despite weak data.</ORIGINAL_TEXT>
<TOKEN end_char="3939" id="token-36-0" morph="none" pos="word" start_char="3936">Also</TOKEN>
<TOKEN end_char="3945" id="token-36-1" morph="none" pos="word" start_char="3941">agree</TOKEN>
<TOKEN end_char="3950" id="token-36-2" morph="none" pos="word" start_char="3947">with</TOKEN>
<TOKEN end_char="3954" id="token-36-3" morph="none" pos="word" start_char="3952">the</TOKEN>
<TOKEN end_char="3960" id="token-36-4" morph="none" pos="word" start_char="3956">point</TOKEN>
<TOKEN end_char="3966" id="token-36-5" morph="none" pos="word" start_char="3962">above</TOKEN>
<TOKEN end_char="3971" id="token-36-6" morph="none" pos="word" start_char="3968">that</TOKEN>
<TOKEN end_char="3976" id="token-36-7" morph="none" pos="word" start_char="3973">lots</TOKEN>
<TOKEN end_char="3979" id="token-36-8" morph="none" pos="word" start_char="3978">of</TOKEN>
<TOKEN end_char="3986" id="token-36-9" morph="none" pos="word" start_char="3981">things</TOKEN>
<TOKEN end_char="3991" id="token-36-10" morph="none" pos="word" start_char="3988">like</TOKEN>
<TOKEN end_char="4002" id="token-36-11" morph="none" pos="word" start_char="3993">remdesivir</TOKEN>
<TOKEN end_char="4006" id="token-36-12" morph="none" pos="word" start_char="4004">are</TOKEN>
<TOKEN end_char="4014" id="token-36-13" morph="none" pos="word" start_char="4008">getting</TOKEN>
<TOKEN end_char="4023" id="token-36-14" morph="none" pos="word" start_char="4016">approval</TOKEN>
<TOKEN end_char="4031" id="token-36-15" morph="none" pos="word" start_char="4025">despite</TOKEN>
<TOKEN end_char="4036" id="token-36-16" morph="none" pos="word" start_char="4033">weak</TOKEN>
<TOKEN end_char="4041" id="token-36-17" morph="none" pos="word" start_char="4038">data</TOKEN>
<TOKEN end_char="4042" id="token-36-18" morph="none" pos="punct" start_char="4042">.</TOKEN>
</SEG>
<SEG end_char="4153" id="segment-37" start_char="4044">
<ORIGINAL_TEXT>Seems like a weird choice to shut down first since supply will limit use anyway and it's pretty well tolerated</ORIGINAL_TEXT>
<TOKEN end_char="4048" id="token-37-0" morph="none" pos="word" start_char="4044">Seems</TOKEN>
<TOKEN end_char="4053" id="token-37-1" morph="none" pos="word" start_char="4050">like</TOKEN>
<TOKEN end_char="4055" id="token-37-2" morph="none" pos="word" start_char="4055">a</TOKEN>
<TOKEN end_char="4061" id="token-37-3" morph="none" pos="word" start_char="4057">weird</TOKEN>
<TOKEN end_char="4068" id="token-37-4" morph="none" pos="word" start_char="4063">choice</TOKEN>
<TOKEN end_char="4071" id="token-37-5" morph="none" pos="word" start_char="4070">to</TOKEN>
<TOKEN end_char="4076" id="token-37-6" morph="none" pos="word" start_char="4073">shut</TOKEN>
<TOKEN end_char="4081" id="token-37-7" morph="none" pos="word" start_char="4078">down</TOKEN>
<TOKEN end_char="4087" id="token-37-8" morph="none" pos="word" start_char="4083">first</TOKEN>
<TOKEN end_char="4093" id="token-37-9" morph="none" pos="word" start_char="4089">since</TOKEN>
<TOKEN end_char="4100" id="token-37-10" morph="none" pos="word" start_char="4095">supply</TOKEN>
<TOKEN end_char="4105" id="token-37-11" morph="none" pos="word" start_char="4102">will</TOKEN>
<TOKEN end_char="4111" id="token-37-12" morph="none" pos="word" start_char="4107">limit</TOKEN>
<TOKEN end_char="4115" id="token-37-13" morph="none" pos="word" start_char="4113">use</TOKEN>
<TOKEN end_char="4122" id="token-37-14" morph="none" pos="word" start_char="4117">anyway</TOKEN>
<TOKEN end_char="4126" id="token-37-15" morph="none" pos="word" start_char="4124">and</TOKEN>
<TOKEN end_char="4131" id="token-37-16" morph="none" pos="word" start_char="4128">it's</TOKEN>
<TOKEN end_char="4138" id="token-37-17" morph="none" pos="word" start_char="4133">pretty</TOKEN>
<TOKEN end_char="4143" id="token-37-18" morph="none" pos="word" start_char="4140">well</TOKEN>
<TOKEN end_char="4153" id="token-37-19" morph="none" pos="word" start_char="4145">tolerated</TOKEN>
</SEG>
<SEG end_char="4267" id="segment-38" start_char="4156">
<ORIGINAL_TEXT>No material on this site is intended to be a substitute for professional medical advice, diagnosis or treatment.</ORIGINAL_TEXT>
<TOKEN end_char="4157" id="token-38-0" morph="none" pos="word" start_char="4156">No</TOKEN>
<TOKEN end_char="4166" id="token-38-1" morph="none" pos="word" start_char="4159">material</TOKEN>
<TOKEN end_char="4169" id="token-38-2" morph="none" pos="word" start_char="4168">on</TOKEN>
<TOKEN end_char="4174" id="token-38-3" morph="none" pos="word" start_char="4171">this</TOKEN>
<TOKEN end_char="4179" id="token-38-4" morph="none" pos="word" start_char="4176">site</TOKEN>
<TOKEN end_char="4182" id="token-38-5" morph="none" pos="word" start_char="4181">is</TOKEN>
<TOKEN end_char="4191" id="token-38-6" morph="none" pos="word" start_char="4184">intended</TOKEN>
<TOKEN end_char="4194" id="token-38-7" morph="none" pos="word" start_char="4193">to</TOKEN>
<TOKEN end_char="4197" id="token-38-8" morph="none" pos="word" start_char="4196">be</TOKEN>
<TOKEN end_char="4199" id="token-38-9" morph="none" pos="word" start_char="4199">a</TOKEN>
<TOKEN end_char="4210" id="token-38-10" morph="none" pos="word" start_char="4201">substitute</TOKEN>
<TOKEN end_char="4214" id="token-38-11" morph="none" pos="word" start_char="4212">for</TOKEN>
<TOKEN end_char="4227" id="token-38-12" morph="none" pos="word" start_char="4216">professional</TOKEN>
<TOKEN end_char="4235" id="token-38-13" morph="none" pos="word" start_char="4229">medical</TOKEN>
<TOKEN end_char="4242" id="token-38-14" morph="none" pos="word" start_char="4237">advice</TOKEN>
<TOKEN end_char="4243" id="token-38-15" morph="none" pos="punct" start_char="4243">,</TOKEN>
<TOKEN end_char="4253" id="token-38-16" morph="none" pos="word" start_char="4245">diagnosis</TOKEN>
<TOKEN end_char="4256" id="token-38-17" morph="none" pos="word" start_char="4255">or</TOKEN>
<TOKEN end_char="4266" id="token-38-18" morph="none" pos="word" start_char="4258">treatment</TOKEN>
<TOKEN end_char="4267" id="token-38-19" morph="none" pos="punct" start_char="4267">.</TOKEN>
</SEG>
<SEG end_char="4296" id="segment-39" start_char="4269">
<ORIGINAL_TEXT>See full Medical Disclaimer.</ORIGINAL_TEXT>
<TOKEN end_char="4271" id="token-39-0" morph="none" pos="word" start_char="4269">See</TOKEN>
<TOKEN end_char="4276" id="token-39-1" morph="none" pos="word" start_char="4273">full</TOKEN>
<TOKEN end_char="4284" id="token-39-2" morph="none" pos="word" start_char="4278">Medical</TOKEN>
<TOKEN end_char="4295" id="token-39-3" morph="none" pos="word" start_char="4286">Disclaimer</TOKEN>
<TOKEN end_char="4296" id="token-39-4" morph="none" pos="punct" start_char="4296">.</TOKEN>
<TRANSLATED_TEXT>Zie volledige medisch disclaimer.</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="4345" id="segment-40" start_char="4300">
<ORIGINAL_TEXT>I think the news articles are a bit confusing.</ORIGINAL_TEXT>
<TOKEN end_char="4300" id="token-40-0" morph="none" pos="word" start_char="4300">I</TOKEN>
<TOKEN end_char="4306" id="token-40-1" morph="none" pos="word" start_char="4302">think</TOKEN>
<TOKEN end_char="4310" id="token-40-2" morph="none" pos="word" start_char="4308">the</TOKEN>
<TOKEN end_char="4315" id="token-40-3" morph="none" pos="word" start_char="4312">news</TOKEN>
<TOKEN end_char="4324" id="token-40-4" morph="none" pos="word" start_char="4317">articles</TOKEN>
<TOKEN end_char="4328" id="token-40-5" morph="none" pos="word" start_char="4326">are</TOKEN>
<TOKEN end_char="4330" id="token-40-6" morph="none" pos="word" start_char="4330">a</TOKEN>
<TOKEN end_char="4334" id="token-40-7" morph="none" pos="word" start_char="4332">bit</TOKEN>
<TOKEN end_char="4344" id="token-40-8" morph="none" pos="word" start_char="4336">confusing</TOKEN>
<TOKEN end_char="4345" id="token-40-9" morph="none" pos="punct" start_char="4345">.</TOKEN>
</SEG>
<SEG end_char="4490" id="segment-41" start_char="4348">
<ORIGINAL_TEXT>Hospitals are ordering as much as ever, and we are actively working to build a national stockpile of the product once we have local demand met.</ORIGINAL_TEXT>
<TOKEN end_char="4356" id="token-41-0" morph="none" pos="word" start_char="4348">Hospitals</TOKEN>
<TOKEN end_char="4360" id="token-41-1" morph="none" pos="word" start_char="4358">are</TOKEN>
<TOKEN end_char="4369" id="token-41-2" morph="none" pos="word" start_char="4362">ordering</TOKEN>
<TOKEN end_char="4372" id="token-41-3" morph="none" pos="word" start_char="4371">as</TOKEN>
<TOKEN end_char="4377" id="token-41-4" morph="none" pos="word" start_char="4374">much</TOKEN>
<TOKEN end_char="4380" id="token-41-5" morph="none" pos="word" start_char="4379">as</TOKEN>
<TOKEN end_char="4385" id="token-41-6" morph="none" pos="word" start_char="4382">ever</TOKEN>
<TOKEN end_char="4386" id="token-41-7" morph="none" pos="punct" start_char="4386">,</TOKEN>
<TOKEN end_char="4390" id="token-41-8" morph="none" pos="word" start_char="4388">and</TOKEN>
<TOKEN end_char="4393" id="token-41-9" morph="none" pos="word" start_char="4392">we</TOKEN>
<TOKEN end_char="4397" id="token-41-10" morph="none" pos="word" start_char="4395">are</TOKEN>
<TOKEN end_char="4406" id="token-41-11" morph="none" pos="word" start_char="4399">actively</TOKEN>
<TOKEN end_char="4414" id="token-41-12" morph="none" pos="word" start_char="4408">working</TOKEN>
<TOKEN end_char="4417" id="token-41-13" morph="none" pos="word" start_char="4416">to</TOKEN>
<TOKEN end_char="4423" id="token-41-14" morph="none" pos="word" start_char="4419">build</TOKEN>
<TOKEN end_char="4425" id="token-41-15" morph="none" pos="word" start_char="4425">a</TOKEN>
<TOKEN end_char="4434" id="token-41-16" morph="none" pos="word" start_char="4427">national</TOKEN>
<TOKEN end_char="4444" id="token-41-17" morph="none" pos="word" start_char="4436">stockpile</TOKEN>
<TOKEN end_char="4447" id="token-41-18" morph="none" pos="word" start_char="4446">of</TOKEN>
<TOKEN end_char="4451" id="token-41-19" morph="none" pos="word" start_char="4449">the</TOKEN>
<TOKEN end_char="4459" id="token-41-20" morph="none" pos="word" start_char="4453">product</TOKEN>
<TOKEN end_char="4464" id="token-41-21" morph="none" pos="word" start_char="4461">once</TOKEN>
<TOKEN end_char="4467" id="token-41-22" morph="none" pos="word" start_char="4466">we</TOKEN>
<TOKEN end_char="4472" id="token-41-23" morph="none" pos="word" start_char="4469">have</TOKEN>
<TOKEN end_char="4478" id="token-41-24" morph="none" pos="word" start_char="4474">local</TOKEN>
<TOKEN end_char="4485" id="token-41-25" morph="none" pos="word" start_char="4480">demand</TOKEN>
<TOKEN end_char="4489" id="token-41-26" morph="none" pos="word" start_char="4487">met</TOKEN>
<TOKEN end_char="4490" id="token-41-27" morph="none" pos="punct" start_char="4490">.</TOKEN>
</SEG>
<SEG end_char="4628" id="segment-42" start_char="4493">
<ORIGINAL_TEXT>The fda really didn't change much in the current guidance, they just decided to not expand its usage at this time beyond current access.</ORIGINAL_TEXT>
<TOKEN end_char="4495" id="token-42-0" morph="none" pos="word" start_char="4493">The</TOKEN>
<TOKEN end_char="4499" id="token-42-1" morph="none" pos="word" start_char="4497">fda</TOKEN>
<TOKEN end_char="4506" id="token-42-2" morph="none" pos="word" start_char="4501">really</TOKEN>
<TOKEN end_char="4513" id="token-42-3" morph="none" pos="word" start_char="4508">didn't</TOKEN>
<TOKEN end_char="4520" id="token-42-4" morph="none" pos="word" start_char="4515">change</TOKEN>
<TOKEN end_char="4525" id="token-42-5" morph="none" pos="word" start_char="4522">much</TOKEN>
<TOKEN end_char="4528" id="token-42-6" morph="none" pos="word" start_char="4527">in</TOKEN>
<TOKEN end_char="4532" id="token-42-7" morph="none" pos="word" start_char="4530">the</TOKEN>
<TOKEN end_char="4540" id="token-42-8" morph="none" pos="word" start_char="4534">current</TOKEN>
<TOKEN end_char="4549" id="token-42-9" morph="none" pos="word" start_char="4542">guidance</TOKEN>
<TOKEN end_char="4550" id="token-42-10" morph="none" pos="punct" start_char="4550">,</TOKEN>
<TOKEN end_char="4555" id="token-42-11" morph="none" pos="word" start_char="4552">they</TOKEN>
<TOKEN end_char="4560" id="token-42-12" morph="none" pos="word" start_char="4557">just</TOKEN>
<TOKEN end_char="4568" id="token-42-13" morph="none" pos="word" start_char="4562">decided</TOKEN>
<TOKEN end_char="4571" id="token-42-14" morph="none" pos="word" start_char="4570">to</TOKEN>
<TOKEN end_char="4575" id="token-42-15" morph="none" pos="word" start_char="4573">not</TOKEN>
<TOKEN end_char="4582" id="token-42-16" morph="none" pos="word" start_char="4577">expand</TOKEN>
<TOKEN end_char="4586" id="token-42-17" morph="none" pos="word" start_char="4584">its</TOKEN>
<TOKEN end_char="4592" id="token-42-18" morph="none" pos="word" start_char="4588">usage</TOKEN>
<TOKEN end_char="4595" id="token-42-19" morph="none" pos="word" start_char="4594">at</TOKEN>
<TOKEN end_char="4600" id="token-42-20" morph="none" pos="word" start_char="4597">this</TOKEN>
<TOKEN end_char="4605" id="token-42-21" morph="none" pos="word" start_char="4602">time</TOKEN>
<TOKEN end_char="4612" id="token-42-22" morph="none" pos="word" start_char="4607">beyond</TOKEN>
<TOKEN end_char="4620" id="token-42-23" morph="none" pos="word" start_char="4614">current</TOKEN>
<TOKEN end_char="4627" id="token-42-24" morph="none" pos="word" start_char="4622">access</TOKEN>
<TOKEN end_char="4628" id="token-42-25" morph="none" pos="punct" start_char="4628">.</TOKEN>
</SEG>
<SEG end_char="4770" id="segment-43" start_char="4631">
<ORIGINAL_TEXT>But any hospital willing to work through the investigational access can enroll (through the Mayo program) and be eligible to receive plasma.</ORIGINAL_TEXT>
<TOKEN end_char="4633" id="token-43-0" morph="none" pos="word" start_char="4631">But</TOKEN>
<TOKEN end_char="4637" id="token-43-1" morph="none" pos="word" start_char="4635">any</TOKEN>
<TOKEN end_char="4646" id="token-43-2" morph="none" pos="word" start_char="4639">hospital</TOKEN>
<TOKEN end_char="4654" id="token-43-3" morph="none" pos="word" start_char="4648">willing</TOKEN>
<TOKEN end_char="4657" id="token-43-4" morph="none" pos="word" start_char="4656">to</TOKEN>
<TOKEN end_char="4662" id="token-43-5" morph="none" pos="word" start_char="4659">work</TOKEN>
<TOKEN end_char="4670" id="token-43-6" morph="none" pos="word" start_char="4664">through</TOKEN>
<TOKEN end_char="4674" id="token-43-7" morph="none" pos="word" start_char="4672">the</TOKEN>
<TOKEN end_char="4690" id="token-43-8" morph="none" pos="word" start_char="4676">investigational</TOKEN>
<TOKEN end_char="4697" id="token-43-9" morph="none" pos="word" start_char="4692">access</TOKEN>
<TOKEN end_char="4701" id="token-43-10" morph="none" pos="word" start_char="4699">can</TOKEN>
<TOKEN end_char="4708" id="token-43-11" morph="none" pos="word" start_char="4703">enroll</TOKEN>
<TOKEN end_char="4710" id="token-43-12" morph="none" pos="punct" start_char="4710">(</TOKEN>
<TOKEN end_char="4717" id="token-43-13" morph="none" pos="word" start_char="4711">through</TOKEN>
<TOKEN end_char="4721" id="token-43-14" morph="none" pos="word" start_char="4719">the</TOKEN>
<TOKEN end_char="4726" id="token-43-15" morph="none" pos="word" start_char="4723">Mayo</TOKEN>
<TOKEN end_char="4734" id="token-43-16" morph="none" pos="word" start_char="4728">program</TOKEN>
<TOKEN end_char="4735" id="token-43-17" morph="none" pos="punct" start_char="4735">)</TOKEN>
<TOKEN end_char="4739" id="token-43-18" morph="none" pos="word" start_char="4737">and</TOKEN>
<TOKEN end_char="4742" id="token-43-19" morph="none" pos="word" start_char="4741">be</TOKEN>
<TOKEN end_char="4751" id="token-43-20" morph="none" pos="word" start_char="4744">eligible</TOKEN>
<TOKEN end_char="4754" id="token-43-21" morph="none" pos="word" start_char="4753">to</TOKEN>
<TOKEN end_char="4762" id="token-43-22" morph="none" pos="word" start_char="4756">receive</TOKEN>
<TOKEN end_char="4769" id="token-43-23" morph="none" pos="word" start_char="4764">plasma</TOKEN>
<TOKEN end_char="4770" id="token-43-24" morph="none" pos="punct" start_char="4770">.</TOKEN>
</SEG>
<SEG end_char="4924" id="segment-44" start_char="4773">
<ORIGINAL_TEXT>There are also multiple studies on going, one in my backyard that is working to determine efficacy and the best protocol for transfusion as a treatment.</ORIGINAL_TEXT>
<TOKEN end_char="4777" id="token-44-0" morph="none" pos="word" start_char="4773">There</TOKEN>
<TOKEN end_char="4781" id="token-44-1" morph="none" pos="word" start_char="4779">are</TOKEN>
<TOKEN end_char="4786" id="token-44-2" morph="none" pos="word" start_char="4783">also</TOKEN>
<TOKEN end_char="4795" id="token-44-3" morph="none" pos="word" start_char="4788">multiple</TOKEN>
<TOKEN end_char="4803" id="token-44-4" morph="none" pos="word" start_char="4797">studies</TOKEN>
<TOKEN end_char="4806" id="token-44-5" morph="none" pos="word" start_char="4805">on</TOKEN>
<TOKEN end_char="4812" id="token-44-6" morph="none" pos="word" start_char="4808">going</TOKEN>
<TOKEN end_char="4813" id="token-44-7" morph="none" pos="punct" start_char="4813">,</TOKEN>
<TOKEN end_char="4817" id="token-44-8" morph="none" pos="word" start_char="4815">one</TOKEN>
<TOKEN end_char="4820" id="token-44-9" morph="none" pos="word" start_char="4819">in</TOKEN>
<TOKEN end_char="4823" id="token-44-10" morph="none" pos="word" start_char="4822">my</TOKEN>
<TOKEN end_char="4832" id="token-44-11" morph="none" pos="word" start_char="4825">backyard</TOKEN>
<TOKEN end_char="4837" id="token-44-12" morph="none" pos="word" start_char="4834">that</TOKEN>
<TOKEN end_char="4840" id="token-44-13" morph="none" pos="word" start_char="4839">is</TOKEN>
<TOKEN end_char="4848" id="token-44-14" morph="none" pos="word" start_char="4842">working</TOKEN>
<TOKEN end_char="4851" id="token-44-15" morph="none" pos="word" start_char="4850">to</TOKEN>
<TOKEN end_char="4861" id="token-44-16" morph="none" pos="word" start_char="4853">determine</TOKEN>
<TOKEN end_char="4870" id="token-44-17" morph="none" pos="word" start_char="4863">efficacy</TOKEN>
<TOKEN end_char="4874" id="token-44-18" morph="none" pos="word" start_char="4872">and</TOKEN>
<TOKEN end_char="4878" id="token-44-19" morph="none" pos="word" start_char="4876">the</TOKEN>
<TOKEN end_char="4883" id="token-44-20" morph="none" pos="word" start_char="4880">best</TOKEN>
<TOKEN end_char="4892" id="token-44-21" morph="none" pos="word" start_char="4885">protocol</TOKEN>
<TOKEN end_char="4896" id="token-44-22" morph="none" pos="word" start_char="4894">for</TOKEN>
<TOKEN end_char="4908" id="token-44-23" morph="none" pos="word" start_char="4898">transfusion</TOKEN>
<TOKEN end_char="4911" id="token-44-24" morph="none" pos="word" start_char="4910">as</TOKEN>
<TOKEN end_char="4913" id="token-44-25" morph="none" pos="word" start_char="4913">a</TOKEN>
<TOKEN end_char="4923" id="token-44-26" morph="none" pos="word" start_char="4915">treatment</TOKEN>
<TOKEN end_char="4924" id="token-44-27" morph="none" pos="punct" start_char="4924">.</TOKEN>
</SEG>
<SEG end_char="4971" id="segment-45" start_char="4927">
<ORIGINAL_TEXT>Eta: link to fda protocol released yesterday.</ORIGINAL_TEXT>
<TOKEN end_char="4929" id="token-45-0" morph="none" pos="word" start_char="4927">Eta</TOKEN>
<TOKEN end_char="4930" id="token-45-1" morph="none" pos="punct" start_char="4930">:</TOKEN>
<TOKEN end_char="4935" id="token-45-2" morph="none" pos="word" start_char="4932">link</TOKEN>
<TOKEN end_char="4938" id="token-45-3" morph="none" pos="word" start_char="4937">to</TOKEN>
<TOKEN end_char="4942" id="token-45-4" morph="none" pos="word" start_char="4940">fda</TOKEN>
<TOKEN end_char="4951" id="token-45-5" morph="none" pos="word" start_char="4944">protocol</TOKEN>
<TOKEN end_char="4960" id="token-45-6" morph="none" pos="word" start_char="4953">released</TOKEN>
<TOKEN end_char="4970" id="token-45-7" morph="none" pos="word" start_char="4962">yesterday</TOKEN>
<TOKEN end_char="4971" id="token-45-8" morph="none" pos="punct" start_char="4971">.</TOKEN>
</SEG>
<SEG end_char="5144" id="segment-46" start_char="4974">
<ORIGINAL_TEXT>https://www.fda.gov/vaccines-blood-biologics/investigational-new-drug-ind-or-device-exemption-ide-process-cber/recommendations-investigational-covid-19-convalescent-plasma</ORIGINAL_TEXT>
<TOKEN end_char="5144" id="token-46-0" morph="none" pos="url" start_char="4974">https://www.fda.gov/vaccines-blood-biologics/investigational-new-drug-ind-or-device-exemption-ide-process-cber/recommendations-investigational-covid-19-convalescent-plasma</TOKEN>
<TRANSLATED_TEXT>https: / / www.fda.gov / vaccins-blood-biologics / investigational-new-drug-in-or-device-exemption-ide-process-cber / recommendations-investigational-covid-19-convalescent-plasma</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="5263" id="segment-47" start_char="5147">
<ORIGINAL_TEXT>It doesn't change any of the current usage treatment, simply not opening up usage to uncontrolled or non studied use.</ORIGINAL_TEXT>
<TOKEN end_char="5148" id="token-47-0" morph="none" pos="word" start_char="5147">It</TOKEN>
<TOKEN end_char="5156" id="token-47-1" morph="none" pos="word" start_char="5150">doesn't</TOKEN>
<TOKEN end_char="5163" id="token-47-2" morph="none" pos="word" start_char="5158">change</TOKEN>
<TOKEN end_char="5167" id="token-47-3" morph="none" pos="word" start_char="5165">any</TOKEN>
<TOKEN end_char="5170" id="token-47-4" morph="none" pos="word" start_char="5169">of</TOKEN>
<TOKEN end_char="5174" id="token-47-5" morph="none" pos="word" start_char="5172">the</TOKEN>
<TOKEN end_char="5182" id="token-47-6" morph="none" pos="word" start_char="5176">current</TOKEN>
<TOKEN end_char="5188" id="token-47-7" morph="none" pos="word" start_char="5184">usage</TOKEN>
<TOKEN end_char="5198" id="token-47-8" morph="none" pos="word" start_char="5190">treatment</TOKEN>
<TOKEN end_char="5199" id="token-47-9" morph="none" pos="punct" start_char="5199">,</TOKEN>
<TOKEN end_char="5206" id="token-47-10" morph="none" pos="word" start_char="5201">simply</TOKEN>
<TOKEN end_char="5210" id="token-47-11" morph="none" pos="word" start_char="5208">not</TOKEN>
<TOKEN end_char="5218" id="token-47-12" morph="none" pos="word" start_char="5212">opening</TOKEN>
<TOKEN end_char="5221" id="token-47-13" morph="none" pos="word" start_char="5220">up</TOKEN>
<TOKEN end_char="5227" id="token-47-14" morph="none" pos="word" start_char="5223">usage</TOKEN>
<TOKEN end_char="5230" id="token-47-15" morph="none" pos="word" start_char="5229">to</TOKEN>
<TOKEN end_char="5243" id="token-47-16" morph="none" pos="word" start_char="5232">uncontrolled</TOKEN>
<TOKEN end_char="5246" id="token-47-17" morph="none" pos="word" start_char="5245">or</TOKEN>
<TOKEN end_char="5250" id="token-47-18" morph="none" pos="word" start_char="5248">non</TOKEN>
<TOKEN end_char="5258" id="token-47-19" morph="none" pos="word" start_char="5252">studied</TOKEN>
<TOKEN end_char="5262" id="token-47-20" morph="none" pos="word" start_char="5260">use</TOKEN>
<TOKEN end_char="5263" id="token-47-21" morph="none" pos="punct" start_char="5263">.</TOKEN>
</SEG>
<SEG end_char="5339" id="segment-48" start_char="5267">
<ORIGINAL_TEXT>The Medcram Update #103 was released today and discusses this very topic.</ORIGINAL_TEXT>
<TOKEN end_char="5269" id="token-48-0" morph="none" pos="word" start_char="5267">The</TOKEN>
<TOKEN end_char="5277" id="token-48-1" morph="none" pos="word" start_char="5271">Medcram</TOKEN>
<TOKEN end_char="5284" id="token-48-2" morph="none" pos="word" start_char="5279">Update</TOKEN>
<TOKEN end_char="5289" id="token-48-3" morph="none" pos="tag" start_char="5286">#103</TOKEN>
<TOKEN end_char="5293" id="token-48-4" morph="none" pos="word" start_char="5291">was</TOKEN>
<TOKEN end_char="5302" id="token-48-5" morph="none" pos="word" start_char="5295">released</TOKEN>
<TOKEN end_char="5308" id="token-48-6" morph="none" pos="word" start_char="5304">today</TOKEN>
<TOKEN end_char="5312" id="token-48-7" morph="none" pos="word" start_char="5310">and</TOKEN>
<TOKEN end_char="5322" id="token-48-8" morph="none" pos="word" start_char="5314">discusses</TOKEN>
<TOKEN end_char="5327" id="token-48-9" morph="none" pos="word" start_char="5324">this</TOKEN>
<TOKEN end_char="5332" id="token-48-10" morph="none" pos="word" start_char="5329">very</TOKEN>
<TOKEN end_char="5338" id="token-48-11" morph="none" pos="word" start_char="5334">topic</TOKEN>
<TOKEN end_char="5339" id="token-48-12" morph="none" pos="punct" start_char="5339">.</TOKEN>
</SEG>
<SEG end_char="5550" id="segment-49" start_char="5343">
<ORIGINAL_TEXT>As I suspected it looks like hospitals have been giving it to patients who are too far along (&gt; 4 days from onset of symptoms) and then noting that its not helping a large enough percentage of these patients.</ORIGINAL_TEXT>
<TOKEN end_char="5344" id="token-49-0" morph="none" pos="word" start_char="5343">As</TOKEN>
<TOKEN end_char="5346" id="token-49-1" morph="none" pos="word" start_char="5346">I</TOKEN>
<TOKEN end_char="5356" id="token-49-2" morph="none" pos="word" start_char="5348">suspected</TOKEN>
<TOKEN end_char="5359" id="token-49-3" morph="none" pos="word" start_char="5358">it</TOKEN>
<TOKEN end_char="5365" id="token-49-4" morph="none" pos="word" start_char="5361">looks</TOKEN>
<TOKEN end_char="5370" id="token-49-5" morph="none" pos="word" start_char="5367">like</TOKEN>
<TOKEN end_char="5380" id="token-49-6" morph="none" pos="word" start_char="5372">hospitals</TOKEN>
<TOKEN end_char="5385" id="token-49-7" morph="none" pos="word" start_char="5382">have</TOKEN>
<TOKEN end_char="5390" id="token-49-8" morph="none" pos="word" start_char="5387">been</TOKEN>
<TOKEN end_char="5397" id="token-49-9" morph="none" pos="word" start_char="5392">giving</TOKEN>
<TOKEN end_char="5400" id="token-49-10" morph="none" pos="word" start_char="5399">it</TOKEN>
<TOKEN end_char="5403" id="token-49-11" morph="none" pos="word" start_char="5402">to</TOKEN>
<TOKEN end_char="5412" id="token-49-12" morph="none" pos="word" start_char="5405">patients</TOKEN>
<TOKEN end_char="5416" id="token-49-13" morph="none" pos="word" start_char="5414">who</TOKEN>
<TOKEN end_char="5420" id="token-49-14" morph="none" pos="word" start_char="5418">are</TOKEN>
<TOKEN end_char="5424" id="token-49-15" morph="none" pos="word" start_char="5422">too</TOKEN>
<TOKEN end_char="5428" id="token-49-16" morph="none" pos="word" start_char="5426">far</TOKEN>
<TOKEN end_char="5434" id="token-49-17" morph="none" pos="word" start_char="5430">along</TOKEN>
<TOKEN end_char="5437" id="token-49-18" morph="none" pos="unknown" start_char="5436">(&gt;</TOKEN>
<TOKEN end_char="5439" id="token-49-19" morph="none" pos="word" start_char="5439">4</TOKEN>
<TOKEN end_char="5444" id="token-49-20" morph="none" pos="word" start_char="5441">days</TOKEN>
<TOKEN end_char="5449" id="token-49-21" morph="none" pos="word" start_char="5446">from</TOKEN>
<TOKEN end_char="5455" id="token-49-22" morph="none" pos="word" start_char="5451">onset</TOKEN>
<TOKEN end_char="5458" id="token-49-23" morph="none" pos="word" start_char="5457">of</TOKEN>
<TOKEN end_char="5467" id="token-49-24" morph="none" pos="word" start_char="5460">symptoms</TOKEN>
<TOKEN end_char="5468" id="token-49-25" morph="none" pos="punct" start_char="5468">)</TOKEN>
<TOKEN end_char="5472" id="token-49-26" morph="none" pos="word" start_char="5470">and</TOKEN>
<TOKEN end_char="5477" id="token-49-27" morph="none" pos="word" start_char="5474">then</TOKEN>
<TOKEN end_char="5484" id="token-49-28" morph="none" pos="word" start_char="5479">noting</TOKEN>
<TOKEN end_char="5489" id="token-49-29" morph="none" pos="word" start_char="5486">that</TOKEN>
<TOKEN end_char="5493" id="token-49-30" morph="none" pos="word" start_char="5491">its</TOKEN>
<TOKEN end_char="5497" id="token-49-31" morph="none" pos="word" start_char="5495">not</TOKEN>
<TOKEN end_char="5505" id="token-49-32" morph="none" pos="word" start_char="5499">helping</TOKEN>
<TOKEN end_char="5507" id="token-49-33" morph="none" pos="word" start_char="5507">a</TOKEN>
<TOKEN end_char="5513" id="token-49-34" morph="none" pos="word" start_char="5509">large</TOKEN>
<TOKEN end_char="5520" id="token-49-35" morph="none" pos="word" start_char="5515">enough</TOKEN>
<TOKEN end_char="5531" id="token-49-36" morph="none" pos="word" start_char="5522">percentage</TOKEN>
<TOKEN end_char="5534" id="token-49-37" morph="none" pos="word" start_char="5533">of</TOKEN>
<TOKEN end_char="5540" id="token-49-38" morph="none" pos="word" start_char="5536">these</TOKEN>
<TOKEN end_char="5549" id="token-49-39" morph="none" pos="word" start_char="5542">patients</TOKEN>
<TOKEN end_char="5550" id="token-49-40" morph="none" pos="punct" start_char="5550">.</TOKEN>
</SEG>
<SEG end_char="5715" id="segment-50" start_char="5552">
<ORIGINAL_TEXT>However as expected, the patients who received the plasma in 3 or less days showed statistically significant improvement, thus meaning its validated for this group.</ORIGINAL_TEXT>
<TOKEN end_char="5558" id="token-50-0" morph="none" pos="word" start_char="5552">However</TOKEN>
<TOKEN end_char="5561" id="token-50-1" morph="none" pos="word" start_char="5560">as</TOKEN>
<TOKEN end_char="5570" id="token-50-2" morph="none" pos="word" start_char="5563">expected</TOKEN>
<TOKEN end_char="5571" id="token-50-3" morph="none" pos="punct" start_char="5571">,</TOKEN>
<TOKEN end_char="5575" id="token-50-4" morph="none" pos="word" start_char="5573">the</TOKEN>
<TOKEN end_char="5584" id="token-50-5" morph="none" pos="word" start_char="5577">patients</TOKEN>
<TOKEN end_char="5588" id="token-50-6" morph="none" pos="word" start_char="5586">who</TOKEN>
<TOKEN end_char="5597" id="token-50-7" morph="none" pos="word" start_char="5590">received</TOKEN>
<TOKEN end_char="5601" id="token-50-8" morph="none" pos="word" start_char="5599">the</TOKEN>
<TOKEN end_char="5608" id="token-50-9" morph="none" pos="word" start_char="5603">plasma</TOKEN>
<TOKEN end_char="5611" id="token-50-10" morph="none" pos="word" start_char="5610">in</TOKEN>
<TOKEN end_char="5613" id="token-50-11" morph="none" pos="word" start_char="5613">3</TOKEN>
<TOKEN end_char="5616" id="token-50-12" morph="none" pos="word" start_char="5615">or</TOKEN>
<TOKEN end_char="5621" id="token-50-13" morph="none" pos="word" start_char="5618">less</TOKEN>
<TOKEN end_char="5626" id="token-50-14" morph="none" pos="word" start_char="5623">days</TOKEN>
<TOKEN end_char="5633" id="token-50-15" morph="none" pos="word" start_char="5628">showed</TOKEN>
<TOKEN end_char="5647" id="token-50-16" morph="none" pos="word" start_char="5635">statistically</TOKEN>
<TOKEN end_char="5659" id="token-50-17" morph="none" pos="word" start_char="5649">significant</TOKEN>
<TOKEN end_char="5671" id="token-50-18" morph="none" pos="word" start_char="5661">improvement</TOKEN>
<TOKEN end_char="5672" id="token-50-19" morph="none" pos="punct" start_char="5672">,</TOKEN>
<TOKEN end_char="5677" id="token-50-20" morph="none" pos="word" start_char="5674">thus</TOKEN>
<TOKEN end_char="5685" id="token-50-21" morph="none" pos="word" start_char="5679">meaning</TOKEN>
<TOKEN end_char="5689" id="token-50-22" morph="none" pos="word" start_char="5687">its</TOKEN>
<TOKEN end_char="5699" id="token-50-23" morph="none" pos="word" start_char="5691">validated</TOKEN>
<TOKEN end_char="5703" id="token-50-24" morph="none" pos="word" start_char="5701">for</TOKEN>
<TOKEN end_char="5708" id="token-50-25" morph="none" pos="word" start_char="5705">this</TOKEN>
<TOKEN end_char="5714" id="token-50-26" morph="none" pos="word" start_char="5710">group</TOKEN>
<TOKEN end_char="5715" id="token-50-27" morph="none" pos="punct" start_char="5715">.</TOKEN>
</SEG>
<SEG end_char="5874" id="segment-51" start_char="5717">
<ORIGINAL_TEXT>Unfortunately when these 2 populations are combined, the results of the 3 day patients are watered down and the data no longer shows statistical significance.</ORIGINAL_TEXT>
<TOKEN end_char="5729" id="token-51-0" morph="none" pos="word" start_char="5717">Unfortunately</TOKEN>
<TOKEN end_char="5734" id="token-51-1" morph="none" pos="word" start_char="5731">when</TOKEN>
<TOKEN end_char="5740" id="token-51-2" morph="none" pos="word" start_char="5736">these</TOKEN>
<TOKEN end_char="5742" id="token-51-3" morph="none" pos="word" start_char="5742">2</TOKEN>
<TOKEN end_char="5754" id="token-51-4" morph="none" pos="word" start_char="5744">populations</TOKEN>
<TOKEN end_char="5758" id="token-51-5" morph="none" pos="word" start_char="5756">are</TOKEN>
<TOKEN end_char="5767" id="token-51-6" morph="none" pos="word" start_char="5760">combined</TOKEN>
<TOKEN end_char="5768" id="token-51-7" morph="none" pos="punct" start_char="5768">,</TOKEN>
<TOKEN end_char="5772" id="token-51-8" morph="none" pos="word" start_char="5770">the</TOKEN>
<TOKEN end_char="5780" id="token-51-9" morph="none" pos="word" start_char="5774">results</TOKEN>
<TOKEN end_char="5783" id="token-51-10" morph="none" pos="word" start_char="5782">of</TOKEN>
<TOKEN end_char="5787" id="token-51-11" morph="none" pos="word" start_char="5785">the</TOKEN>
<TOKEN end_char="5789" id="token-51-12" morph="none" pos="word" start_char="5789">3</TOKEN>
<TOKEN end_char="5793" id="token-51-13" morph="none" pos="word" start_char="5791">day</TOKEN>
<TOKEN end_char="5802" id="token-51-14" morph="none" pos="word" start_char="5795">patients</TOKEN>
<TOKEN end_char="5806" id="token-51-15" morph="none" pos="word" start_char="5804">are</TOKEN>
<TOKEN end_char="5814" id="token-51-16" morph="none" pos="word" start_char="5808">watered</TOKEN>
<TOKEN end_char="5819" id="token-51-17" morph="none" pos="word" start_char="5816">down</TOKEN>
<TOKEN end_char="5823" id="token-51-18" morph="none" pos="word" start_char="5821">and</TOKEN>
<TOKEN end_char="5827" id="token-51-19" morph="none" pos="word" start_char="5825">the</TOKEN>
<TOKEN end_char="5832" id="token-51-20" morph="none" pos="word" start_char="5829">data</TOKEN>
<TOKEN end_char="5835" id="token-51-21" morph="none" pos="word" start_char="5834">no</TOKEN>
<TOKEN end_char="5842" id="token-51-22" morph="none" pos="word" start_char="5837">longer</TOKEN>
<TOKEN end_char="5848" id="token-51-23" morph="none" pos="word" start_char="5844">shows</TOKEN>
<TOKEN end_char="5860" id="token-51-24" morph="none" pos="word" start_char="5850">statistical</TOKEN>
<TOKEN end_char="5873" id="token-51-25" morph="none" pos="word" start_char="5862">significance</TOKEN>
<TOKEN end_char="5874" id="token-51-26" morph="none" pos="punct" start_char="5874">.</TOKEN>
</SEG>
<SEG end_char="6023" id="segment-52" start_char="5876">
<ORIGINAL_TEXT>As a result the FDA raises red flags and informs the medical community to tap the breaks and is now requesting a another study with a control group.</ORIGINAL_TEXT>
<TOKEN end_char="5877" id="token-52-0" morph="none" pos="word" start_char="5876">As</TOKEN>
<TOKEN end_char="5879" id="token-52-1" morph="none" pos="word" start_char="5879">a</TOKEN>
<TOKEN end_char="5886" id="token-52-2" morph="none" pos="word" start_char="5881">result</TOKEN>
<TOKEN end_char="5890" id="token-52-3" morph="none" pos="word" start_char="5888">the</TOKEN>
<TOKEN end_char="5894" id="token-52-4" morph="none" pos="word" start_char="5892">FDA</TOKEN>
<TOKEN end_char="5901" id="token-52-5" morph="none" pos="word" start_char="5896">raises</TOKEN>
<TOKEN end_char="5905" id="token-52-6" morph="none" pos="word" start_char="5903">red</TOKEN>
<TOKEN end_char="5911" id="token-52-7" morph="none" pos="word" start_char="5907">flags</TOKEN>
<TOKEN end_char="5915" id="token-52-8" morph="none" pos="word" start_char="5913">and</TOKEN>
<TOKEN end_char="5923" id="token-52-9" morph="none" pos="word" start_char="5917">informs</TOKEN>
<TOKEN end_char="5927" id="token-52-10" morph="none" pos="word" start_char="5925">the</TOKEN>
<TOKEN end_char="5935" id="token-52-11" morph="none" pos="word" start_char="5929">medical</TOKEN>
<TOKEN end_char="5945" id="token-52-12" morph="none" pos="word" start_char="5937">community</TOKEN>
<TOKEN end_char="5948" id="token-52-13" morph="none" pos="word" start_char="5947">to</TOKEN>
<TOKEN end_char="5952" id="token-52-14" morph="none" pos="word" start_char="5950">tap</TOKEN>
<TOKEN end_char="5956" id="token-52-15" morph="none" pos="word" start_char="5954">the</TOKEN>
<TOKEN end_char="5963" id="token-52-16" morph="none" pos="word" start_char="5958">breaks</TOKEN>
<TOKEN end_char="5967" id="token-52-17" morph="none" pos="word" start_char="5965">and</TOKEN>
<TOKEN end_char="5970" id="token-52-18" morph="none" pos="word" start_char="5969">is</TOKEN>
<TOKEN end_char="5974" id="token-52-19" morph="none" pos="word" start_char="5972">now</TOKEN>
<TOKEN end_char="5985" id="token-52-20" morph="none" pos="word" start_char="5976">requesting</TOKEN>
<TOKEN end_char="5987" id="token-52-21" morph="none" pos="word" start_char="5987">a</TOKEN>
<TOKEN end_char="5995" id="token-52-22" morph="none" pos="word" start_char="5989">another</TOKEN>
<TOKEN end_char="6001" id="token-52-23" morph="none" pos="word" start_char="5997">study</TOKEN>
<TOKEN end_char="6006" id="token-52-24" morph="none" pos="word" start_char="6003">with</TOKEN>
<TOKEN end_char="6008" id="token-52-25" morph="none" pos="word" start_char="6008">a</TOKEN>
<TOKEN end_char="6016" id="token-52-26" morph="none" pos="word" start_char="6010">control</TOKEN>
<TOKEN end_char="6022" id="token-52-27" morph="none" pos="word" start_char="6018">group</TOKEN>
<TOKEN end_char="6023" id="token-52-28" morph="none" pos="punct" start_char="6023">.</TOKEN>
</SEG>
<SEG end_char="6090" id="segment-53" start_char="6026">
<ORIGINAL_TEXT>Wow, I don't see how all of this isn't obvious to these eggheads!</ORIGINAL_TEXT>
<TOKEN end_char="6028" id="token-53-0" morph="none" pos="word" start_char="6026">Wow</TOKEN>
<TOKEN end_char="6029" id="token-53-1" morph="none" pos="punct" start_char="6029">,</TOKEN>
<TOKEN end_char="6031" id="token-53-2" morph="none" pos="word" start_char="6031">I</TOKEN>
<TOKEN end_char="6037" id="token-53-3" morph="none" pos="word" start_char="6033">don't</TOKEN>
<TOKEN end_char="6041" id="token-53-4" morph="none" pos="word" start_char="6039">see</TOKEN>
<TOKEN end_char="6045" id="token-53-5" morph="none" pos="word" start_char="6043">how</TOKEN>
<TOKEN end_char="6049" id="token-53-6" morph="none" pos="word" start_char="6047">all</TOKEN>
<TOKEN end_char="6052" id="token-53-7" morph="none" pos="word" start_char="6051">of</TOKEN>
<TOKEN end_char="6057" id="token-53-8" morph="none" pos="word" start_char="6054">this</TOKEN>
<TOKEN end_char="6063" id="token-53-9" morph="none" pos="word" start_char="6059">isn't</TOKEN>
<TOKEN end_char="6071" id="token-53-10" morph="none" pos="word" start_char="6065">obvious</TOKEN>
<TOKEN end_char="6074" id="token-53-11" morph="none" pos="word" start_char="6073">to</TOKEN>
<TOKEN end_char="6080" id="token-53-12" morph="none" pos="word" start_char="6076">these</TOKEN>
<TOKEN end_char="6089" id="token-53-13" morph="none" pos="word" start_char="6082">eggheads</TOKEN>
<TOKEN end_char="6090" id="token-53-14" morph="none" pos="punct" start_char="6090">!</TOKEN>
</SEG>
<SEG end_char="6193" id="segment-54" start_char="6092">
<ORIGINAL_TEXT>At worst convalescent plasma does no harm and has been shown to be beneficial when administered early.</ORIGINAL_TEXT>
<TOKEN end_char="6093" id="token-54-0" morph="none" pos="word" start_char="6092">At</TOKEN>
<TOKEN end_char="6099" id="token-54-1" morph="none" pos="word" start_char="6095">worst</TOKEN>
<TOKEN end_char="6112" id="token-54-2" morph="none" pos="word" start_char="6101">convalescent</TOKEN>
<TOKEN end_char="6119" id="token-54-3" morph="none" pos="word" start_char="6114">plasma</TOKEN>
<TOKEN end_char="6124" id="token-54-4" morph="none" pos="word" start_char="6121">does</TOKEN>
<TOKEN end_char="6127" id="token-54-5" morph="none" pos="word" start_char="6126">no</TOKEN>
<TOKEN end_char="6132" id="token-54-6" morph="none" pos="word" start_char="6129">harm</TOKEN>
<TOKEN end_char="6136" id="token-54-7" morph="none" pos="word" start_char="6134">and</TOKEN>
<TOKEN end_char="6140" id="token-54-8" morph="none" pos="word" start_char="6138">has</TOKEN>
<TOKEN end_char="6145" id="token-54-9" morph="none" pos="word" start_char="6142">been</TOKEN>
<TOKEN end_char="6151" id="token-54-10" morph="none" pos="word" start_char="6147">shown</TOKEN>
<TOKEN end_char="6154" id="token-54-11" morph="none" pos="word" start_char="6153">to</TOKEN>
<TOKEN end_char="6157" id="token-54-12" morph="none" pos="word" start_char="6156">be</TOKEN>
<TOKEN end_char="6168" id="token-54-13" morph="none" pos="word" start_char="6159">beneficial</TOKEN>
<TOKEN end_char="6173" id="token-54-14" morph="none" pos="word" start_char="6170">when</TOKEN>
<TOKEN end_char="6186" id="token-54-15" morph="none" pos="word" start_char="6175">administered</TOKEN>
<TOKEN end_char="6192" id="token-54-16" morph="none" pos="word" start_char="6188">early</TOKEN>
<TOKEN end_char="6193" id="token-54-17" morph="none" pos="punct" start_char="6193">.</TOKEN>
</SEG>
<SEG end_char="6233" id="segment-55" start_char="6195">
<ORIGINAL_TEXT>Do these guys chew on lead paint chips?</ORIGINAL_TEXT>
<TOKEN end_char="6196" id="token-55-0" morph="none" pos="word" start_char="6195">Do</TOKEN>
<TOKEN end_char="6202" id="token-55-1" morph="none" pos="word" start_char="6198">these</TOKEN>
<TOKEN end_char="6207" id="token-55-2" morph="none" pos="word" start_char="6204">guys</TOKEN>
<TOKEN end_char="6212" id="token-55-3" morph="none" pos="word" start_char="6209">chew</TOKEN>
<TOKEN end_char="6215" id="token-55-4" morph="none" pos="word" start_char="6214">on</TOKEN>
<TOKEN end_char="6220" id="token-55-5" morph="none" pos="word" start_char="6217">lead</TOKEN>
<TOKEN end_char="6226" id="token-55-6" morph="none" pos="word" start_char="6222">paint</TOKEN>
<TOKEN end_char="6232" id="token-55-7" morph="none" pos="word" start_char="6228">chips</TOKEN>
<TOKEN end_char="6233" id="token-55-8" morph="none" pos="punct" start_char="6233">?</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
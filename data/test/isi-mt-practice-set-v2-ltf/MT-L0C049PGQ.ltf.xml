<LCTL_TEXT lang="ukr">
<DOC grammar="none" id="L0C049PGQ" lang="ukr" raw_text_char_length="6356" raw_text_md5="2ef077e02870df6a0b2fa3f1dac2a792" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="94" id="segment-0" start_char="1">
<ORIGINAL_TEXT>No, Coronavirus Was Not Caused by 'Bat Soup'–But Here's What Researchers Think May Be to Blame</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">No</TOKEN>
<TOKEN end_char="3" id="token-0-1" morph="none" pos="punct" start_char="3">,</TOKEN>
<TOKEN end_char="15" id="token-0-2" morph="none" pos="word" start_char="5">Coronavirus</TOKEN>
<TOKEN end_char="19" id="token-0-3" morph="none" pos="word" start_char="17">Was</TOKEN>
<TOKEN end_char="23" id="token-0-4" morph="none" pos="word" start_char="21">Not</TOKEN>
<TOKEN end_char="30" id="token-0-5" morph="none" pos="word" start_char="25">Caused</TOKEN>
<TOKEN end_char="33" id="token-0-6" morph="none" pos="word" start_char="32">by</TOKEN>
<TOKEN end_char="35" id="token-0-7" morph="none" pos="punct" start_char="35">'</TOKEN>
<TOKEN end_char="38" id="token-0-8" morph="none" pos="word" start_char="36">Bat</TOKEN>
<TOKEN end_char="48" id="token-0-9" morph="none" pos="unknown" start_char="40">Soup'–But</TOKEN>
<TOKEN end_char="55" id="token-0-10" morph="none" pos="word" start_char="50">Here's</TOKEN>
<TOKEN end_char="60" id="token-0-11" morph="none" pos="word" start_char="57">What</TOKEN>
<TOKEN end_char="72" id="token-0-12" morph="none" pos="word" start_char="62">Researchers</TOKEN>
<TOKEN end_char="78" id="token-0-13" morph="none" pos="word" start_char="74">Think</TOKEN>
<TOKEN end_char="82" id="token-0-14" morph="none" pos="word" start_char="80">May</TOKEN>
<TOKEN end_char="85" id="token-0-15" morph="none" pos="word" start_char="84">Be</TOKEN>
<TOKEN end_char="88" id="token-0-16" morph="none" pos="word" start_char="87">to</TOKEN>
<TOKEN end_char="94" id="token-0-17" morph="none" pos="word" start_char="90">Blame</TOKEN>
</SEG>
<SEG end_char="288" id="segment-1" start_char="99">
<ORIGINAL_TEXT>When news of any new, fast-spreading virus starts making the rounds, two things happen: public panic ensues and misinformation starts to proliferate—and the new coronavirus has sparked both.</ORIGINAL_TEXT>
<TOKEN end_char="102" id="token-1-0" morph="none" pos="word" start_char="99">When</TOKEN>
<TOKEN end_char="107" id="token-1-1" morph="none" pos="word" start_char="104">news</TOKEN>
<TOKEN end_char="110" id="token-1-2" morph="none" pos="word" start_char="109">of</TOKEN>
<TOKEN end_char="114" id="token-1-3" morph="none" pos="word" start_char="112">any</TOKEN>
<TOKEN end_char="118" id="token-1-4" morph="none" pos="word" start_char="116">new</TOKEN>
<TOKEN end_char="119" id="token-1-5" morph="none" pos="punct" start_char="119">,</TOKEN>
<TOKEN end_char="134" id="token-1-6" morph="none" pos="unknown" start_char="121">fast-spreading</TOKEN>
<TOKEN end_char="140" id="token-1-7" morph="none" pos="word" start_char="136">virus</TOKEN>
<TOKEN end_char="147" id="token-1-8" morph="none" pos="word" start_char="142">starts</TOKEN>
<TOKEN end_char="154" id="token-1-9" morph="none" pos="word" start_char="149">making</TOKEN>
<TOKEN end_char="158" id="token-1-10" morph="none" pos="word" start_char="156">the</TOKEN>
<TOKEN end_char="165" id="token-1-11" morph="none" pos="word" start_char="160">rounds</TOKEN>
<TOKEN end_char="166" id="token-1-12" morph="none" pos="punct" start_char="166">,</TOKEN>
<TOKEN end_char="170" id="token-1-13" morph="none" pos="word" start_char="168">two</TOKEN>
<TOKEN end_char="177" id="token-1-14" morph="none" pos="word" start_char="172">things</TOKEN>
<TOKEN end_char="184" id="token-1-15" morph="none" pos="word" start_char="179">happen</TOKEN>
<TOKEN end_char="185" id="token-1-16" morph="none" pos="punct" start_char="185">:</TOKEN>
<TOKEN end_char="192" id="token-1-17" morph="none" pos="word" start_char="187">public</TOKEN>
<TOKEN end_char="198" id="token-1-18" morph="none" pos="word" start_char="194">panic</TOKEN>
<TOKEN end_char="205" id="token-1-19" morph="none" pos="word" start_char="200">ensues</TOKEN>
<TOKEN end_char="209" id="token-1-20" morph="none" pos="word" start_char="207">and</TOKEN>
<TOKEN end_char="224" id="token-1-21" morph="none" pos="word" start_char="211">misinformation</TOKEN>
<TOKEN end_char="231" id="token-1-22" morph="none" pos="word" start_char="226">starts</TOKEN>
<TOKEN end_char="234" id="token-1-23" morph="none" pos="word" start_char="233">to</TOKEN>
<TOKEN end_char="250" id="token-1-24" morph="none" pos="unknown" start_char="236">proliferate—and</TOKEN>
<TOKEN end_char="254" id="token-1-25" morph="none" pos="word" start_char="252">the</TOKEN>
<TOKEN end_char="258" id="token-1-26" morph="none" pos="word" start_char="256">new</TOKEN>
<TOKEN end_char="270" id="token-1-27" morph="none" pos="word" start_char="260">coronavirus</TOKEN>
<TOKEN end_char="274" id="token-1-28" morph="none" pos="word" start_char="272">has</TOKEN>
<TOKEN end_char="282" id="token-1-29" morph="none" pos="word" start_char="276">sparked</TOKEN>
<TOKEN end_char="287" id="token-1-30" morph="none" pos="word" start_char="284">both</TOKEN>
<TOKEN end_char="288" id="token-1-31" morph="none" pos="punct" start_char="288">.</TOKEN>
</SEG>
<SEG end_char="458" id="segment-2" start_char="291">
<ORIGINAL_TEXT>In December 2019, an outbreak of a novel coronavirus—now known as SAR-CoV-2 (initially named 2019-nCoV)—was detected in Wuhan, a city in Central China's Hubei province.</ORIGINAL_TEXT>
<TOKEN end_char="292" id="token-2-0" morph="none" pos="word" start_char="291">In</TOKEN>
<TOKEN end_char="301" id="token-2-1" morph="none" pos="word" start_char="294">December</TOKEN>
<TOKEN end_char="306" id="token-2-2" morph="none" pos="word" start_char="303">2019</TOKEN>
<TOKEN end_char="307" id="token-2-3" morph="none" pos="punct" start_char="307">,</TOKEN>
<TOKEN end_char="310" id="token-2-4" morph="none" pos="word" start_char="309">an</TOKEN>
<TOKEN end_char="319" id="token-2-5" morph="none" pos="word" start_char="312">outbreak</TOKEN>
<TOKEN end_char="322" id="token-2-6" morph="none" pos="word" start_char="321">of</TOKEN>
<TOKEN end_char="324" id="token-2-7" morph="none" pos="word" start_char="324">a</TOKEN>
<TOKEN end_char="330" id="token-2-8" morph="none" pos="word" start_char="326">novel</TOKEN>
<TOKEN end_char="346" id="token-2-9" morph="none" pos="unknown" start_char="332">coronavirus—now</TOKEN>
<TOKEN end_char="352" id="token-2-10" morph="none" pos="word" start_char="348">known</TOKEN>
<TOKEN end_char="355" id="token-2-11" morph="none" pos="word" start_char="354">as</TOKEN>
<TOKEN end_char="365" id="token-2-12" morph="none" pos="unknown" start_char="357">SAR-CoV-2</TOKEN>
<TOKEN end_char="367" id="token-2-13" morph="none" pos="punct" start_char="367">(</TOKEN>
<TOKEN end_char="376" id="token-2-14" morph="none" pos="word" start_char="368">initially</TOKEN>
<TOKEN end_char="382" id="token-2-15" morph="none" pos="word" start_char="378">named</TOKEN>
<TOKEN end_char="397" id="token-2-16" morph="none" pos="unknown" start_char="384">2019-nCoV)—was</TOKEN>
<TOKEN end_char="406" id="token-2-17" morph="none" pos="word" start_char="399">detected</TOKEN>
<TOKEN end_char="409" id="token-2-18" morph="none" pos="word" start_char="408">in</TOKEN>
<TOKEN end_char="415" id="token-2-19" morph="none" pos="word" start_char="411">Wuhan</TOKEN>
<TOKEN end_char="416" id="token-2-20" morph="none" pos="punct" start_char="416">,</TOKEN>
<TOKEN end_char="418" id="token-2-21" morph="none" pos="word" start_char="418">a</TOKEN>
<TOKEN end_char="423" id="token-2-22" morph="none" pos="word" start_char="420">city</TOKEN>
<TOKEN end_char="426" id="token-2-23" morph="none" pos="word" start_char="425">in</TOKEN>
<TOKEN end_char="434" id="token-2-24" morph="none" pos="word" start_char="428">Central</TOKEN>
<TOKEN end_char="442" id="token-2-25" morph="none" pos="word" start_char="436">China's</TOKEN>
<TOKEN end_char="448" id="token-2-26" morph="none" pos="word" start_char="444">Hubei</TOKEN>
<TOKEN end_char="457" id="token-2-27" morph="none" pos="word" start_char="450">province</TOKEN>
<TOKEN end_char="458" id="token-2-28" morph="none" pos="punct" start_char="458">.</TOKEN>
</SEG>
<SEG end_char="704" id="segment-3" start_char="460">
<ORIGINAL_TEXT>Since then, more than 9.6 million people worldwide have developed the infection, and at least 490,000 people have died, according to Johns Hopkins University's real-time tracker, which maps confirmed cases of the illness we now know as COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="464" id="token-3-0" morph="none" pos="word" start_char="460">Since</TOKEN>
<TOKEN end_char="469" id="token-3-1" morph="none" pos="word" start_char="466">then</TOKEN>
<TOKEN end_char="470" id="token-3-2" morph="none" pos="punct" start_char="470">,</TOKEN>
<TOKEN end_char="475" id="token-3-3" morph="none" pos="word" start_char="472">more</TOKEN>
<TOKEN end_char="480" id="token-3-4" morph="none" pos="word" start_char="477">than</TOKEN>
<TOKEN end_char="484" id="token-3-5" morph="none" pos="word" start_char="482">9.6</TOKEN>
<TOKEN end_char="492" id="token-3-6" morph="none" pos="word" start_char="486">million</TOKEN>
<TOKEN end_char="499" id="token-3-7" morph="none" pos="word" start_char="494">people</TOKEN>
<TOKEN end_char="509" id="token-3-8" morph="none" pos="word" start_char="501">worldwide</TOKEN>
<TOKEN end_char="514" id="token-3-9" morph="none" pos="word" start_char="511">have</TOKEN>
<TOKEN end_char="524" id="token-3-10" morph="none" pos="word" start_char="516">developed</TOKEN>
<TOKEN end_char="528" id="token-3-11" morph="none" pos="word" start_char="526">the</TOKEN>
<TOKEN end_char="538" id="token-3-12" morph="none" pos="word" start_char="530">infection</TOKEN>
<TOKEN end_char="539" id="token-3-13" morph="none" pos="punct" start_char="539">,</TOKEN>
<TOKEN end_char="543" id="token-3-14" morph="none" pos="word" start_char="541">and</TOKEN>
<TOKEN end_char="546" id="token-3-15" morph="none" pos="word" start_char="545">at</TOKEN>
<TOKEN end_char="552" id="token-3-16" morph="none" pos="word" start_char="548">least</TOKEN>
<TOKEN end_char="560" id="token-3-17" morph="none" pos="unknown" start_char="554">490,000</TOKEN>
<TOKEN end_char="567" id="token-3-18" morph="none" pos="word" start_char="562">people</TOKEN>
<TOKEN end_char="572" id="token-3-19" morph="none" pos="word" start_char="569">have</TOKEN>
<TOKEN end_char="577" id="token-3-20" morph="none" pos="word" start_char="574">died</TOKEN>
<TOKEN end_char="578" id="token-3-21" morph="none" pos="punct" start_char="578">,</TOKEN>
<TOKEN end_char="588" id="token-3-22" morph="none" pos="word" start_char="580">according</TOKEN>
<TOKEN end_char="591" id="token-3-23" morph="none" pos="word" start_char="590">to</TOKEN>
<TOKEN end_char="597" id="token-3-24" morph="none" pos="word" start_char="593">Johns</TOKEN>
<TOKEN end_char="605" id="token-3-25" morph="none" pos="word" start_char="599">Hopkins</TOKEN>
<TOKEN end_char="618" id="token-3-26" morph="none" pos="word" start_char="607">University's</TOKEN>
<TOKEN end_char="628" id="token-3-27" morph="none" pos="unknown" start_char="620">real-time</TOKEN>
<TOKEN end_char="636" id="token-3-28" morph="none" pos="word" start_char="630">tracker</TOKEN>
<TOKEN end_char="637" id="token-3-29" morph="none" pos="punct" start_char="637">,</TOKEN>
<TOKEN end_char="643" id="token-3-30" morph="none" pos="word" start_char="639">which</TOKEN>
<TOKEN end_char="648" id="token-3-31" morph="none" pos="word" start_char="645">maps</TOKEN>
<TOKEN end_char="658" id="token-3-32" morph="none" pos="word" start_char="650">confirmed</TOKEN>
<TOKEN end_char="664" id="token-3-33" morph="none" pos="word" start_char="660">cases</TOKEN>
<TOKEN end_char="667" id="token-3-34" morph="none" pos="word" start_char="666">of</TOKEN>
<TOKEN end_char="671" id="token-3-35" morph="none" pos="word" start_char="669">the</TOKEN>
<TOKEN end_char="679" id="token-3-36" morph="none" pos="word" start_char="673">illness</TOKEN>
<TOKEN end_char="682" id="token-3-37" morph="none" pos="word" start_char="681">we</TOKEN>
<TOKEN end_char="686" id="token-3-38" morph="none" pos="word" start_char="684">now</TOKEN>
<TOKEN end_char="691" id="token-3-39" morph="none" pos="word" start_char="688">know</TOKEN>
<TOKEN end_char="694" id="token-3-40" morph="none" pos="word" start_char="693">as</TOKEN>
<TOKEN end_char="703" id="token-3-41" morph="none" pos="unknown" start_char="696">COVID-19</TOKEN>
<TOKEN end_char="704" id="token-3-42" morph="none" pos="punct" start_char="704">.</TOKEN>
</SEG>
<SEG end_char="788" id="segment-4" start_char="706">
<ORIGINAL_TEXT>The US accounts for more than 2.4 million of those cases and nearly 125,000 deaths.</ORIGINAL_TEXT>
<TOKEN end_char="708" id="token-4-0" morph="none" pos="word" start_char="706">The</TOKEN>
<TOKEN end_char="711" id="token-4-1" morph="none" pos="word" start_char="710">US</TOKEN>
<TOKEN end_char="720" id="token-4-2" morph="none" pos="word" start_char="713">accounts</TOKEN>
<TOKEN end_char="724" id="token-4-3" morph="none" pos="word" start_char="722">for</TOKEN>
<TOKEN end_char="729" id="token-4-4" morph="none" pos="word" start_char="726">more</TOKEN>
<TOKEN end_char="734" id="token-4-5" morph="none" pos="word" start_char="731">than</TOKEN>
<TOKEN end_char="738" id="token-4-6" morph="none" pos="word" start_char="736">2.4</TOKEN>
<TOKEN end_char="746" id="token-4-7" morph="none" pos="word" start_char="740">million</TOKEN>
<TOKEN end_char="749" id="token-4-8" morph="none" pos="word" start_char="748">of</TOKEN>
<TOKEN end_char="755" id="token-4-9" morph="none" pos="word" start_char="751">those</TOKEN>
<TOKEN end_char="761" id="token-4-10" morph="none" pos="word" start_char="757">cases</TOKEN>
<TOKEN end_char="765" id="token-4-11" morph="none" pos="word" start_char="763">and</TOKEN>
<TOKEN end_char="772" id="token-4-12" morph="none" pos="word" start_char="767">nearly</TOKEN>
<TOKEN end_char="780" id="token-4-13" morph="none" pos="unknown" start_char="774">125,000</TOKEN>
<TOKEN end_char="787" id="token-4-14" morph="none" pos="word" start_char="782">deaths</TOKEN>
<TOKEN end_char="788" id="token-4-15" morph="none" pos="punct" start_char="788">.</TOKEN>
</SEG>
<SEG end_char="947" id="segment-5" start_char="791">
<ORIGINAL_TEXT>While health officials across the world—and, honestly, the entire world in general—try to figure out what exactly the new coronavirus is (Where did it start?</ORIGINAL_TEXT>
<TOKEN end_char="795" id="token-5-0" morph="none" pos="word" start_char="791">While</TOKEN>
<TOKEN end_char="802" id="token-5-1" morph="none" pos="word" start_char="797">health</TOKEN>
<TOKEN end_char="812" id="token-5-2" morph="none" pos="word" start_char="804">officials</TOKEN>
<TOKEN end_char="819" id="token-5-3" morph="none" pos="word" start_char="814">across</TOKEN>
<TOKEN end_char="823" id="token-5-4" morph="none" pos="word" start_char="821">the</TOKEN>
<TOKEN end_char="833" id="token-5-5" morph="none" pos="unknown" start_char="825">world—and</TOKEN>
<TOKEN end_char="834" id="token-5-6" morph="none" pos="punct" start_char="834">,</TOKEN>
<TOKEN end_char="843" id="token-5-7" morph="none" pos="word" start_char="836">honestly</TOKEN>
<TOKEN end_char="844" id="token-5-8" morph="none" pos="punct" start_char="844">,</TOKEN>
<TOKEN end_char="848" id="token-5-9" morph="none" pos="word" start_char="846">the</TOKEN>
<TOKEN end_char="855" id="token-5-10" morph="none" pos="word" start_char="850">entire</TOKEN>
<TOKEN end_char="861" id="token-5-11" morph="none" pos="word" start_char="857">world</TOKEN>
<TOKEN end_char="864" id="token-5-12" morph="none" pos="word" start_char="863">in</TOKEN>
<TOKEN end_char="876" id="token-5-13" morph="none" pos="unknown" start_char="866">general—try</TOKEN>
<TOKEN end_char="879" id="token-5-14" morph="none" pos="word" start_char="878">to</TOKEN>
<TOKEN end_char="886" id="token-5-15" morph="none" pos="word" start_char="881">figure</TOKEN>
<TOKEN end_char="890" id="token-5-16" morph="none" pos="word" start_char="888">out</TOKEN>
<TOKEN end_char="895" id="token-5-17" morph="none" pos="word" start_char="892">what</TOKEN>
<TOKEN end_char="903" id="token-5-18" morph="none" pos="word" start_char="897">exactly</TOKEN>
<TOKEN end_char="907" id="token-5-19" morph="none" pos="word" start_char="905">the</TOKEN>
<TOKEN end_char="911" id="token-5-20" morph="none" pos="word" start_char="909">new</TOKEN>
<TOKEN end_char="923" id="token-5-21" morph="none" pos="word" start_char="913">coronavirus</TOKEN>
<TOKEN end_char="926" id="token-5-22" morph="none" pos="word" start_char="925">is</TOKEN>
<TOKEN end_char="928" id="token-5-23" morph="none" pos="punct" start_char="928">(</TOKEN>
<TOKEN end_char="933" id="token-5-24" morph="none" pos="word" start_char="929">Where</TOKEN>
<TOKEN end_char="937" id="token-5-25" morph="none" pos="word" start_char="935">did</TOKEN>
<TOKEN end_char="940" id="token-5-26" morph="none" pos="word" start_char="939">it</TOKEN>
<TOKEN end_char="946" id="token-5-27" morph="none" pos="word" start_char="942">start</TOKEN>
<TOKEN end_char="947" id="token-5-28" morph="none" pos="punct" start_char="947">?</TOKEN>
</SEG>
<SEG end_char="970" id="segment-6" start_char="949">
<ORIGINAL_TEXT>How is it transmitted?</ORIGINAL_TEXT>
<TOKEN end_char="951" id="token-6-0" morph="none" pos="word" start_char="949">How</TOKEN>
<TOKEN end_char="954" id="token-6-1" morph="none" pos="word" start_char="953">is</TOKEN>
<TOKEN end_char="957" id="token-6-2" morph="none" pos="word" start_char="956">it</TOKEN>
<TOKEN end_char="969" id="token-6-3" morph="none" pos="word" start_char="959">transmitted</TOKEN>
<TOKEN end_char="970" id="token-6-4" morph="none" pos="punct" start_char="970">?</TOKEN>
</SEG>
<SEG end_char="1002" id="segment-7" start_char="972">
<ORIGINAL_TEXT>What's making it so infectious?</ORIGINAL_TEXT>
<TOKEN end_char="977" id="token-7-0" morph="none" pos="word" start_char="972">What's</TOKEN>
<TOKEN end_char="984" id="token-7-1" morph="none" pos="word" start_char="979">making</TOKEN>
<TOKEN end_char="987" id="token-7-2" morph="none" pos="word" start_char="986">it</TOKEN>
<TOKEN end_char="990" id="token-7-3" morph="none" pos="word" start_char="989">so</TOKEN>
<TOKEN end_char="1001" id="token-7-4" morph="none" pos="word" start_char="992">infectious</TOKEN>
<TOKEN end_char="1002" id="token-7-5" morph="none" pos="punct" start_char="1002">?</TOKEN>
</SEG>
<SEG end_char="1042" id="segment-8" start_char="1004">
<ORIGINAL_TEXT>), one thing in particular is certainly</ORIGINAL_TEXT>
<TOKEN end_char="1005" id="token-8-0" morph="none" pos="punct" start_char="1004">),</TOKEN>
<TOKEN end_char="1009" id="token-8-1" morph="none" pos="word" start_char="1007">one</TOKEN>
<TOKEN end_char="1015" id="token-8-2" morph="none" pos="word" start_char="1011">thing</TOKEN>
<TOKEN end_char="1018" id="token-8-3" morph="none" pos="word" start_char="1017">in</TOKEN>
<TOKEN end_char="1029" id="token-8-4" morph="none" pos="word" start_char="1020">particular</TOKEN>
<TOKEN end_char="1032" id="token-8-5" morph="none" pos="word" start_char="1031">is</TOKEN>
<TOKEN end_char="1042" id="token-8-6" morph="none" pos="word" start_char="1034">certainly</TOKEN>
</SEG>
<SEG end_char="1047" id="segment-9" start_char="1045">
<ORIGINAL_TEXT>not</ORIGINAL_TEXT>
<TOKEN end_char="1047" id="token-9-0" morph="none" pos="word" start_char="1045">not</TOKEN>
<TRANSLATED_TEXT>ei ole</TRANSLATED_TEXT><DETECTED_LANGUAGE>lv</DETECTED_LANGUAGE></SEG>
<SEG end_char="1169" id="segment-10" start_char="1050">
<ORIGINAL_TEXT>helping anyone: Claims that it somehow originated with one woman eating something people are referring to as "bat soup."</ORIGINAL_TEXT>
<TOKEN end_char="1056" id="token-10-0" morph="none" pos="word" start_char="1050">helping</TOKEN>
<TOKEN end_char="1063" id="token-10-1" morph="none" pos="word" start_char="1058">anyone</TOKEN>
<TOKEN end_char="1064" id="token-10-2" morph="none" pos="punct" start_char="1064">:</TOKEN>
<TOKEN end_char="1071" id="token-10-3" morph="none" pos="word" start_char="1066">Claims</TOKEN>
<TOKEN end_char="1076" id="token-10-4" morph="none" pos="word" start_char="1073">that</TOKEN>
<TOKEN end_char="1079" id="token-10-5" morph="none" pos="word" start_char="1078">it</TOKEN>
<TOKEN end_char="1087" id="token-10-6" morph="none" pos="word" start_char="1081">somehow</TOKEN>
<TOKEN end_char="1098" id="token-10-7" morph="none" pos="word" start_char="1089">originated</TOKEN>
<TOKEN end_char="1103" id="token-10-8" morph="none" pos="word" start_char="1100">with</TOKEN>
<TOKEN end_char="1107" id="token-10-9" morph="none" pos="word" start_char="1105">one</TOKEN>
<TOKEN end_char="1113" id="token-10-10" morph="none" pos="word" start_char="1109">woman</TOKEN>
<TOKEN end_char="1120" id="token-10-11" morph="none" pos="word" start_char="1115">eating</TOKEN>
<TOKEN end_char="1130" id="token-10-12" morph="none" pos="word" start_char="1122">something</TOKEN>
<TOKEN end_char="1137" id="token-10-13" morph="none" pos="word" start_char="1132">people</TOKEN>
<TOKEN end_char="1141" id="token-10-14" morph="none" pos="word" start_char="1139">are</TOKEN>
<TOKEN end_char="1151" id="token-10-15" morph="none" pos="word" start_char="1143">referring</TOKEN>
<TOKEN end_char="1154" id="token-10-16" morph="none" pos="word" start_char="1153">to</TOKEN>
<TOKEN end_char="1157" id="token-10-17" morph="none" pos="word" start_char="1156">as</TOKEN>
<TOKEN end_char="1159" id="token-10-18" morph="none" pos="punct" start_char="1159">"</TOKEN>
<TOKEN end_char="1162" id="token-10-19" morph="none" pos="word" start_char="1160">bat</TOKEN>
<TOKEN end_char="1167" id="token-10-20" morph="none" pos="word" start_char="1164">soup</TOKEN>
<TOKEN end_char="1169" id="token-10-21" morph="none" pos="punct" start_char="1168">."</TOKEN>
</SEG>
<SEG end_char="1245" id="segment-11" start_char="1171">
<ORIGINAL_TEXT>(Seriously—the searches for "bat soup" in Google Trends truly skyrocketed).</ORIGINAL_TEXT>
<TOKEN end_char="1171" id="token-11-0" morph="none" pos="punct" start_char="1171">(</TOKEN>
<TOKEN end_char="1184" id="token-11-1" morph="none" pos="unknown" start_char="1172">Seriously—the</TOKEN>
<TOKEN end_char="1193" id="token-11-2" morph="none" pos="word" start_char="1186">searches</TOKEN>
<TOKEN end_char="1197" id="token-11-3" morph="none" pos="word" start_char="1195">for</TOKEN>
<TOKEN end_char="1199" id="token-11-4" morph="none" pos="punct" start_char="1199">"</TOKEN>
<TOKEN end_char="1202" id="token-11-5" morph="none" pos="word" start_char="1200">bat</TOKEN>
<TOKEN end_char="1207" id="token-11-6" morph="none" pos="word" start_char="1204">soup</TOKEN>
<TOKEN end_char="1208" id="token-11-7" morph="none" pos="punct" start_char="1208">"</TOKEN>
<TOKEN end_char="1211" id="token-11-8" morph="none" pos="word" start_char="1210">in</TOKEN>
<TOKEN end_char="1218" id="token-11-9" morph="none" pos="word" start_char="1213">Google</TOKEN>
<TOKEN end_char="1225" id="token-11-10" morph="none" pos="word" start_char="1220">Trends</TOKEN>
<TOKEN end_char="1231" id="token-11-11" morph="none" pos="word" start_char="1227">truly</TOKEN>
<TOKEN end_char="1243" id="token-11-12" morph="none" pos="word" start_char="1233">skyrocketed</TOKEN>
<TOKEN end_char="1245" id="token-11-13" morph="none" pos="punct" start_char="1244">).</TOKEN>
</SEG>
<SEG end_char="1296" id="segment-12" start_char="1248">
<ORIGINAL_TEXT>Where exactly did the "bat soup" claim come from?</ORIGINAL_TEXT>
<TOKEN end_char="1252" id="token-12-0" morph="none" pos="word" start_char="1248">Where</TOKEN>
<TOKEN end_char="1260" id="token-12-1" morph="none" pos="word" start_char="1254">exactly</TOKEN>
<TOKEN end_char="1264" id="token-12-2" morph="none" pos="word" start_char="1262">did</TOKEN>
<TOKEN end_char="1268" id="token-12-3" morph="none" pos="word" start_char="1266">the</TOKEN>
<TOKEN end_char="1270" id="token-12-4" morph="none" pos="punct" start_char="1270">"</TOKEN>
<TOKEN end_char="1273" id="token-12-5" morph="none" pos="word" start_char="1271">bat</TOKEN>
<TOKEN end_char="1278" id="token-12-6" morph="none" pos="word" start_char="1275">soup</TOKEN>
<TOKEN end_char="1279" id="token-12-7" morph="none" pos="punct" start_char="1279">"</TOKEN>
<TOKEN end_char="1285" id="token-12-8" morph="none" pos="word" start_char="1281">claim</TOKEN>
<TOKEN end_char="1290" id="token-12-9" morph="none" pos="word" start_char="1287">come</TOKEN>
<TOKEN end_char="1295" id="token-12-10" morph="none" pos="word" start_char="1292">from</TOKEN>
<TOKEN end_char="1296" id="token-12-11" morph="none" pos="punct" start_char="1296">?</TOKEN>
</SEG>
<SEG end_char="1311" id="segment-13" start_char="1300">
<ORIGINAL_TEXT>According to</ORIGINAL_TEXT>
<TOKEN end_char="1308" id="token-13-0" morph="none" pos="word" start_char="1300">According</TOKEN>
<TOKEN end_char="1311" id="token-13-1" morph="none" pos="word" start_char="1310">to</TOKEN>
</SEG>
<SEG end_char="1327" id="segment-14" start_char="1314">
<ORIGINAL_TEXT>Foreign Policy</ORIGINAL_TEXT>
<TOKEN end_char="1320" id="token-14-0" morph="none" pos="word" start_char="1314">Foreign</TOKEN>
<TOKEN end_char="1327" id="token-14-1" morph="none" pos="word" start_char="1322">Policy</TOKEN>
<TRANSLATED_TEXT>Udenrigspolitik</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="1455" id="segment-15" start_char="1330">
<ORIGINAL_TEXT>, a video recently surfaced of a Chinese woman holding an entire bat with chopsticks, appearing to eat the creature in a soup.</ORIGINAL_TEXT>
<TOKEN end_char="1330" id="token-15-0" morph="none" pos="punct" start_char="1330">,</TOKEN>
<TOKEN end_char="1332" id="token-15-1" morph="none" pos="word" start_char="1332">a</TOKEN>
<TOKEN end_char="1338" id="token-15-2" morph="none" pos="word" start_char="1334">video</TOKEN>
<TOKEN end_char="1347" id="token-15-3" morph="none" pos="word" start_char="1340">recently</TOKEN>
<TOKEN end_char="1356" id="token-15-4" morph="none" pos="word" start_char="1349">surfaced</TOKEN>
<TOKEN end_char="1359" id="token-15-5" morph="none" pos="word" start_char="1358">of</TOKEN>
<TOKEN end_char="1361" id="token-15-6" morph="none" pos="word" start_char="1361">a</TOKEN>
<TOKEN end_char="1369" id="token-15-7" morph="none" pos="word" start_char="1363">Chinese</TOKEN>
<TOKEN end_char="1375" id="token-15-8" morph="none" pos="word" start_char="1371">woman</TOKEN>
<TOKEN end_char="1383" id="token-15-9" morph="none" pos="word" start_char="1377">holding</TOKEN>
<TOKEN end_char="1386" id="token-15-10" morph="none" pos="word" start_char="1385">an</TOKEN>
<TOKEN end_char="1393" id="token-15-11" morph="none" pos="word" start_char="1388">entire</TOKEN>
<TOKEN end_char="1397" id="token-15-12" morph="none" pos="word" start_char="1395">bat</TOKEN>
<TOKEN end_char="1402" id="token-15-13" morph="none" pos="word" start_char="1399">with</TOKEN>
<TOKEN end_char="1413" id="token-15-14" morph="none" pos="word" start_char="1404">chopsticks</TOKEN>
<TOKEN end_char="1414" id="token-15-15" morph="none" pos="punct" start_char="1414">,</TOKEN>
<TOKEN end_char="1424" id="token-15-16" morph="none" pos="word" start_char="1416">appearing</TOKEN>
<TOKEN end_char="1427" id="token-15-17" morph="none" pos="word" start_char="1426">to</TOKEN>
<TOKEN end_char="1431" id="token-15-18" morph="none" pos="word" start_char="1429">eat</TOKEN>
<TOKEN end_char="1435" id="token-15-19" morph="none" pos="word" start_char="1433">the</TOKEN>
<TOKEN end_char="1444" id="token-15-20" morph="none" pos="word" start_char="1437">creature</TOKEN>
<TOKEN end_char="1447" id="token-15-21" morph="none" pos="word" start_char="1446">in</TOKEN>
<TOKEN end_char="1449" id="token-15-22" morph="none" pos="word" start_char="1449">a</TOKEN>
<TOKEN end_char="1454" id="token-15-23" morph="none" pos="word" start_char="1451">soup</TOKEN>
<TOKEN end_char="1455" id="token-15-24" morph="none" pos="punct" start_char="1455">.</TOKEN>
</SEG>
<SEG end_char="1459" id="segment-16" start_char="1457">
<ORIGINAL_TEXT>The</ORIGINAL_TEXT>
<TOKEN end_char="1459" id="token-16-0" morph="none" pos="word" start_char="1457">The</TOKEN>
</SEG>
<SEG end_char="1471" id="segment-17" start_char="1462">
<ORIGINAL_TEXT>Daily Mail</ORIGINAL_TEXT>
<TOKEN end_char="1466" id="token-17-0" morph="none" pos="word" start_char="1462">Daily</TOKEN>
<TOKEN end_char="1471" id="token-17-1" morph="none" pos="word" start_char="1468">Mail</TOKEN>
</SEG>
<SEG end_char="1543" id="segment-18" start_char="1474">
<ORIGINAL_TEXT>also reported on the video, and YouTube channel RT shared the footage.</ORIGINAL_TEXT>
<TOKEN end_char="1477" id="token-18-0" morph="none" pos="word" start_char="1474">also</TOKEN>
<TOKEN end_char="1486" id="token-18-1" morph="none" pos="word" start_char="1479">reported</TOKEN>
<TOKEN end_char="1489" id="token-18-2" morph="none" pos="word" start_char="1488">on</TOKEN>
<TOKEN end_char="1493" id="token-18-3" morph="none" pos="word" start_char="1491">the</TOKEN>
<TOKEN end_char="1499" id="token-18-4" morph="none" pos="word" start_char="1495">video</TOKEN>
<TOKEN end_char="1500" id="token-18-5" morph="none" pos="punct" start_char="1500">,</TOKEN>
<TOKEN end_char="1504" id="token-18-6" morph="none" pos="word" start_char="1502">and</TOKEN>
<TOKEN end_char="1512" id="token-18-7" morph="none" pos="word" start_char="1506">YouTube</TOKEN>
<TOKEN end_char="1520" id="token-18-8" morph="none" pos="word" start_char="1514">channel</TOKEN>
<TOKEN end_char="1523" id="token-18-9" morph="none" pos="word" start_char="1522">RT</TOKEN>
<TOKEN end_char="1530" id="token-18-10" morph="none" pos="word" start_char="1525">shared</TOKEN>
<TOKEN end_char="1534" id="token-18-11" morph="none" pos="word" start_char="1532">the</TOKEN>
<TOKEN end_char="1542" id="token-18-12" morph="none" pos="word" start_char="1536">footage</TOKEN>
<TOKEN end_char="1543" id="token-18-13" morph="none" pos="punct" start_char="1543">.</TOKEN>
</SEG>
<SEG end_char="1686" id="segment-19" start_char="1545">
<ORIGINAL_TEXT>The clip was reportedly met with outrage from Twitter users, who quickly began calling out Chinese eating habits as the cause of the outbreak.</ORIGINAL_TEXT>
<TOKEN end_char="1547" id="token-19-0" morph="none" pos="word" start_char="1545">The</TOKEN>
<TOKEN end_char="1552" id="token-19-1" morph="none" pos="word" start_char="1549">clip</TOKEN>
<TOKEN end_char="1556" id="token-19-2" morph="none" pos="word" start_char="1554">was</TOKEN>
<TOKEN end_char="1567" id="token-19-3" morph="none" pos="word" start_char="1558">reportedly</TOKEN>
<TOKEN end_char="1571" id="token-19-4" morph="none" pos="word" start_char="1569">met</TOKEN>
<TOKEN end_char="1576" id="token-19-5" morph="none" pos="word" start_char="1573">with</TOKEN>
<TOKEN end_char="1584" id="token-19-6" morph="none" pos="word" start_char="1578">outrage</TOKEN>
<TOKEN end_char="1589" id="token-19-7" morph="none" pos="word" start_char="1586">from</TOKEN>
<TOKEN end_char="1597" id="token-19-8" morph="none" pos="word" start_char="1591">Twitter</TOKEN>
<TOKEN end_char="1603" id="token-19-9" morph="none" pos="word" start_char="1599">users</TOKEN>
<TOKEN end_char="1604" id="token-19-10" morph="none" pos="punct" start_char="1604">,</TOKEN>
<TOKEN end_char="1608" id="token-19-11" morph="none" pos="word" start_char="1606">who</TOKEN>
<TOKEN end_char="1616" id="token-19-12" morph="none" pos="word" start_char="1610">quickly</TOKEN>
<TOKEN end_char="1622" id="token-19-13" morph="none" pos="word" start_char="1618">began</TOKEN>
<TOKEN end_char="1630" id="token-19-14" morph="none" pos="word" start_char="1624">calling</TOKEN>
<TOKEN end_char="1634" id="token-19-15" morph="none" pos="word" start_char="1632">out</TOKEN>
<TOKEN end_char="1642" id="token-19-16" morph="none" pos="word" start_char="1636">Chinese</TOKEN>
<TOKEN end_char="1649" id="token-19-17" morph="none" pos="word" start_char="1644">eating</TOKEN>
<TOKEN end_char="1656" id="token-19-18" morph="none" pos="word" start_char="1651">habits</TOKEN>
<TOKEN end_char="1659" id="token-19-19" morph="none" pos="word" start_char="1658">as</TOKEN>
<TOKEN end_char="1663" id="token-19-20" morph="none" pos="word" start_char="1661">the</TOKEN>
<TOKEN end_char="1669" id="token-19-21" morph="none" pos="word" start_char="1665">cause</TOKEN>
<TOKEN end_char="1672" id="token-19-22" morph="none" pos="word" start_char="1671">of</TOKEN>
<TOKEN end_char="1676" id="token-19-23" morph="none" pos="word" start_char="1674">the</TOKEN>
<TOKEN end_char="1685" id="token-19-24" morph="none" pos="word" start_char="1678">outbreak</TOKEN>
<TOKEN end_char="1686" id="token-19-25" morph="none" pos="punct" start_char="1686">.</TOKEN>
</SEG>
<SEG end_char="1713" id="segment-20" start_char="1689">
<ORIGINAL_TEXT>But here's the thing, per</ORIGINAL_TEXT>
<TOKEN end_char="1691" id="token-20-0" morph="none" pos="word" start_char="1689">But</TOKEN>
<TOKEN end_char="1698" id="token-20-1" morph="none" pos="word" start_char="1693">here's</TOKEN>
<TOKEN end_char="1702" id="token-20-2" morph="none" pos="word" start_char="1700">the</TOKEN>
<TOKEN end_char="1708" id="token-20-3" morph="none" pos="word" start_char="1704">thing</TOKEN>
<TOKEN end_char="1709" id="token-20-4" morph="none" pos="punct" start_char="1709">,</TOKEN>
<TOKEN end_char="1713" id="token-20-5" morph="none" pos="word" start_char="1711">per</TOKEN>
</SEG>
<SEG end_char="1729" id="segment-21" start_char="1716">
<ORIGINAL_TEXT>Foreign Policy</ORIGINAL_TEXT>
<TOKEN end_char="1722" id="token-21-0" morph="none" pos="word" start_char="1716">Foreign</TOKEN>
<TOKEN end_char="1729" id="token-21-1" morph="none" pos="word" start_char="1724">Policy</TOKEN>
<TRANSLATED_TEXT>Udenrigspolitik</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="2015" id="segment-22" start_char="1732">
<ORIGINAL_TEXT>: That video in question reportedly wasn't filmed in Wuhan or China in general—the woman in the video, who news outlets have identified as Wang Mengyun, is a host of an online travel show who was actually eating a dish in Palau, an island country located in the western Pacific ocean.</ORIGINAL_TEXT>
<TOKEN end_char="1732" id="token-22-0" morph="none" pos="punct" start_char="1732">:</TOKEN>
<TOKEN end_char="1737" id="token-22-1" morph="none" pos="word" start_char="1734">That</TOKEN>
<TOKEN end_char="1743" id="token-22-2" morph="none" pos="word" start_char="1739">video</TOKEN>
<TOKEN end_char="1746" id="token-22-3" morph="none" pos="word" start_char="1745">in</TOKEN>
<TOKEN end_char="1755" id="token-22-4" morph="none" pos="word" start_char="1748">question</TOKEN>
<TOKEN end_char="1766" id="token-22-5" morph="none" pos="word" start_char="1757">reportedly</TOKEN>
<TOKEN end_char="1773" id="token-22-6" morph="none" pos="word" start_char="1768">wasn't</TOKEN>
<TOKEN end_char="1780" id="token-22-7" morph="none" pos="word" start_char="1775">filmed</TOKEN>
<TOKEN end_char="1783" id="token-22-8" morph="none" pos="word" start_char="1782">in</TOKEN>
<TOKEN end_char="1789" id="token-22-9" morph="none" pos="word" start_char="1785">Wuhan</TOKEN>
<TOKEN end_char="1792" id="token-22-10" morph="none" pos="word" start_char="1791">or</TOKEN>
<TOKEN end_char="1798" id="token-22-11" morph="none" pos="word" start_char="1794">China</TOKEN>
<TOKEN end_char="1801" id="token-22-12" morph="none" pos="word" start_char="1800">in</TOKEN>
<TOKEN end_char="1813" id="token-22-13" morph="none" pos="unknown" start_char="1803">general—the</TOKEN>
<TOKEN end_char="1819" id="token-22-14" morph="none" pos="word" start_char="1815">woman</TOKEN>
<TOKEN end_char="1822" id="token-22-15" morph="none" pos="word" start_char="1821">in</TOKEN>
<TOKEN end_char="1826" id="token-22-16" morph="none" pos="word" start_char="1824">the</TOKEN>
<TOKEN end_char="1832" id="token-22-17" morph="none" pos="word" start_char="1828">video</TOKEN>
<TOKEN end_char="1833" id="token-22-18" morph="none" pos="punct" start_char="1833">,</TOKEN>
<TOKEN end_char="1837" id="token-22-19" morph="none" pos="word" start_char="1835">who</TOKEN>
<TOKEN end_char="1842" id="token-22-20" morph="none" pos="word" start_char="1839">news</TOKEN>
<TOKEN end_char="1850" id="token-22-21" morph="none" pos="word" start_char="1844">outlets</TOKEN>
<TOKEN end_char="1855" id="token-22-22" morph="none" pos="word" start_char="1852">have</TOKEN>
<TOKEN end_char="1866" id="token-22-23" morph="none" pos="word" start_char="1857">identified</TOKEN>
<TOKEN end_char="1869" id="token-22-24" morph="none" pos="word" start_char="1868">as</TOKEN>
<TOKEN end_char="1874" id="token-22-25" morph="none" pos="word" start_char="1871">Wang</TOKEN>
<TOKEN end_char="1882" id="token-22-26" morph="none" pos="word" start_char="1876">Mengyun</TOKEN>
<TOKEN end_char="1883" id="token-22-27" morph="none" pos="punct" start_char="1883">,</TOKEN>
<TOKEN end_char="1886" id="token-22-28" morph="none" pos="word" start_char="1885">is</TOKEN>
<TOKEN end_char="1888" id="token-22-29" morph="none" pos="word" start_char="1888">a</TOKEN>
<TOKEN end_char="1893" id="token-22-30" morph="none" pos="word" start_char="1890">host</TOKEN>
<TOKEN end_char="1896" id="token-22-31" morph="none" pos="word" start_char="1895">of</TOKEN>
<TOKEN end_char="1899" id="token-22-32" morph="none" pos="word" start_char="1898">an</TOKEN>
<TOKEN end_char="1906" id="token-22-33" morph="none" pos="word" start_char="1901">online</TOKEN>
<TOKEN end_char="1913" id="token-22-34" morph="none" pos="word" start_char="1908">travel</TOKEN>
<TOKEN end_char="1918" id="token-22-35" morph="none" pos="word" start_char="1915">show</TOKEN>
<TOKEN end_char="1922" id="token-22-36" morph="none" pos="word" start_char="1920">who</TOKEN>
<TOKEN end_char="1926" id="token-22-37" morph="none" pos="word" start_char="1924">was</TOKEN>
<TOKEN end_char="1935" id="token-22-38" morph="none" pos="word" start_char="1928">actually</TOKEN>
<TOKEN end_char="1942" id="token-22-39" morph="none" pos="word" start_char="1937">eating</TOKEN>
<TOKEN end_char="1944" id="token-22-40" morph="none" pos="word" start_char="1944">a</TOKEN>
<TOKEN end_char="1949" id="token-22-41" morph="none" pos="word" start_char="1946">dish</TOKEN>
<TOKEN end_char="1952" id="token-22-42" morph="none" pos="word" start_char="1951">in</TOKEN>
<TOKEN end_char="1958" id="token-22-43" morph="none" pos="word" start_char="1954">Palau</TOKEN>
<TOKEN end_char="1959" id="token-22-44" morph="none" pos="punct" start_char="1959">,</TOKEN>
<TOKEN end_char="1962" id="token-22-45" morph="none" pos="word" start_char="1961">an</TOKEN>
<TOKEN end_char="1969" id="token-22-46" morph="none" pos="word" start_char="1964">island</TOKEN>
<TOKEN end_char="1977" id="token-22-47" morph="none" pos="word" start_char="1971">country</TOKEN>
<TOKEN end_char="1985" id="token-22-48" morph="none" pos="word" start_char="1979">located</TOKEN>
<TOKEN end_char="1988" id="token-22-49" morph="none" pos="word" start_char="1987">in</TOKEN>
<TOKEN end_char="1992" id="token-22-50" morph="none" pos="word" start_char="1990">the</TOKEN>
<TOKEN end_char="2000" id="token-22-51" morph="none" pos="word" start_char="1994">western</TOKEN>
<TOKEN end_char="2008" id="token-22-52" morph="none" pos="word" start_char="2002">Pacific</TOKEN>
<TOKEN end_char="2014" id="token-22-53" morph="none" pos="word" start_char="2010">ocean</TOKEN>
<TOKEN end_char="2015" id="token-22-54" morph="none" pos="punct" start_char="2015">.</TOKEN>
</SEG>
<SEG end_char="2107" id="segment-23" start_char="2017">
<ORIGINAL_TEXT>The video was also reportedly filmed in 2016—well before the coronavirus outbreak in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="2019" id="token-23-0" morph="none" pos="word" start_char="2017">The</TOKEN>
<TOKEN end_char="2025" id="token-23-1" morph="none" pos="word" start_char="2021">video</TOKEN>
<TOKEN end_char="2029" id="token-23-2" morph="none" pos="word" start_char="2027">was</TOKEN>
<TOKEN end_char="2034" id="token-23-3" morph="none" pos="word" start_char="2031">also</TOKEN>
<TOKEN end_char="2045" id="token-23-4" morph="none" pos="word" start_char="2036">reportedly</TOKEN>
<TOKEN end_char="2052" id="token-23-5" morph="none" pos="word" start_char="2047">filmed</TOKEN>
<TOKEN end_char="2055" id="token-23-6" morph="none" pos="word" start_char="2054">in</TOKEN>
<TOKEN end_char="2065" id="token-23-7" morph="none" pos="unknown" start_char="2057">2016—well</TOKEN>
<TOKEN end_char="2072" id="token-23-8" morph="none" pos="word" start_char="2067">before</TOKEN>
<TOKEN end_char="2076" id="token-23-9" morph="none" pos="word" start_char="2074">the</TOKEN>
<TOKEN end_char="2088" id="token-23-10" morph="none" pos="word" start_char="2078">coronavirus</TOKEN>
<TOKEN end_char="2097" id="token-23-11" morph="none" pos="word" start_char="2090">outbreak</TOKEN>
<TOKEN end_char="2100" id="token-23-12" morph="none" pos="word" start_char="2099">in</TOKEN>
<TOKEN end_char="2106" id="token-23-13" morph="none" pos="word" start_char="2102">Wuhan</TOKEN>
<TOKEN end_char="2107" id="token-23-14" morph="none" pos="punct" start_char="2107">.</TOKEN>
</SEG>
<SEG end_char="2163" id="segment-24" start_char="2109">
<ORIGINAL_TEXT>Mengyun has also reportedly apologized for the footage.</ORIGINAL_TEXT>
<TOKEN end_char="2115" id="token-24-0" morph="none" pos="word" start_char="2109">Mengyun</TOKEN>
<TOKEN end_char="2119" id="token-24-1" morph="none" pos="word" start_char="2117">has</TOKEN>
<TOKEN end_char="2124" id="token-24-2" morph="none" pos="word" start_char="2121">also</TOKEN>
<TOKEN end_char="2135" id="token-24-3" morph="none" pos="word" start_char="2126">reportedly</TOKEN>
<TOKEN end_char="2146" id="token-24-4" morph="none" pos="word" start_char="2137">apologized</TOKEN>
<TOKEN end_char="2150" id="token-24-5" morph="none" pos="word" start_char="2148">for</TOKEN>
<TOKEN end_char="2154" id="token-24-6" morph="none" pos="word" start_char="2152">the</TOKEN>
<TOKEN end_char="2162" id="token-24-7" morph="none" pos="word" start_char="2156">footage</TOKEN>
<TOKEN end_char="2163" id="token-24-8" morph="none" pos="punct" start_char="2163">.</TOKEN>
</SEG>
<SEG end_char="2185" id="segment-25" start_char="2165">
<ORIGINAL_TEXT>"I am sorry everyone.</ORIGINAL_TEXT>
<TOKEN end_char="2165" id="token-25-0" morph="none" pos="punct" start_char="2165">"</TOKEN>
<TOKEN end_char="2166" id="token-25-1" morph="none" pos="word" start_char="2166">I</TOKEN>
<TOKEN end_char="2169" id="token-25-2" morph="none" pos="word" start_char="2168">am</TOKEN>
<TOKEN end_char="2175" id="token-25-3" morph="none" pos="word" start_char="2171">sorry</TOKEN>
<TOKEN end_char="2184" id="token-25-4" morph="none" pos="word" start_char="2177">everyone</TOKEN>
<TOKEN end_char="2185" id="token-25-5" morph="none" pos="punct" start_char="2185">.</TOKEN>
</SEG>
<SEG end_char="2244" id="segment-26" start_char="2187">
<ORIGINAL_TEXT>I should not have eaten a bat," she said, according to the</ORIGINAL_TEXT>
<TOKEN end_char="2187" id="token-26-0" morph="none" pos="word" start_char="2187">I</TOKEN>
<TOKEN end_char="2194" id="token-26-1" morph="none" pos="word" start_char="2189">should</TOKEN>
<TOKEN end_char="2198" id="token-26-2" morph="none" pos="word" start_char="2196">not</TOKEN>
<TOKEN end_char="2203" id="token-26-3" morph="none" pos="word" start_char="2200">have</TOKEN>
<TOKEN end_char="2209" id="token-26-4" morph="none" pos="word" start_char="2205">eaten</TOKEN>
<TOKEN end_char="2211" id="token-26-5" morph="none" pos="word" start_char="2211">a</TOKEN>
<TOKEN end_char="2215" id="token-26-6" morph="none" pos="word" start_char="2213">bat</TOKEN>
<TOKEN end_char="2217" id="token-26-7" morph="none" pos="punct" start_char="2216">,"</TOKEN>
<TOKEN end_char="2221" id="token-26-8" morph="none" pos="word" start_char="2219">she</TOKEN>
<TOKEN end_char="2226" id="token-26-9" morph="none" pos="word" start_char="2223">said</TOKEN>
<TOKEN end_char="2227" id="token-26-10" morph="none" pos="punct" start_char="2227">,</TOKEN>
<TOKEN end_char="2237" id="token-26-11" morph="none" pos="word" start_char="2229">according</TOKEN>
<TOKEN end_char="2240" id="token-26-12" morph="none" pos="word" start_char="2239">to</TOKEN>
<TOKEN end_char="2244" id="token-26-13" morph="none" pos="word" start_char="2242">the</TOKEN>
</SEG>
<SEG end_char="2270" id="segment-27" start_char="2247">
<ORIGINAL_TEXT>South China Morning Post</ORIGINAL_TEXT>
<TOKEN end_char="2251" id="token-27-0" morph="none" pos="word" start_char="2247">South</TOKEN>
<TOKEN end_char="2257" id="token-27-1" morph="none" pos="word" start_char="2253">China</TOKEN>
<TOKEN end_char="2265" id="token-27-2" morph="none" pos="word" start_char="2259">Morning</TOKEN>
<TOKEN end_char="2270" id="token-27-3" morph="none" pos="word" start_char="2267">Post</TOKEN>
</SEG>
<SEG end_char="2273" id="segment-28" start_char="2273">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="2273" id="token-28-0" morph="none" pos="punct" start_char="2273">.</TOKEN>
</SEG>
<SEG end_char="2350" id="segment-29" start_char="2275">
<ORIGINAL_TEXT>"[I] had no idea during filming that there was such a virus," she continued.</ORIGINAL_TEXT>
<TOKEN end_char="2276" id="token-29-0" morph="none" pos="punct" start_char="2275">"[</TOKEN>
<TOKEN end_char="2277" id="token-29-1" morph="none" pos="word" start_char="2277">I</TOKEN>
<TOKEN end_char="2278" id="token-29-2" morph="none" pos="punct" start_char="2278">]</TOKEN>
<TOKEN end_char="2282" id="token-29-3" morph="none" pos="word" start_char="2280">had</TOKEN>
<TOKEN end_char="2285" id="token-29-4" morph="none" pos="word" start_char="2284">no</TOKEN>
<TOKEN end_char="2290" id="token-29-5" morph="none" pos="word" start_char="2287">idea</TOKEN>
<TOKEN end_char="2297" id="token-29-6" morph="none" pos="word" start_char="2292">during</TOKEN>
<TOKEN end_char="2305" id="token-29-7" morph="none" pos="word" start_char="2299">filming</TOKEN>
<TOKEN end_char="2310" id="token-29-8" morph="none" pos="word" start_char="2307">that</TOKEN>
<TOKEN end_char="2316" id="token-29-9" morph="none" pos="word" start_char="2312">there</TOKEN>
<TOKEN end_char="2320" id="token-29-10" morph="none" pos="word" start_char="2318">was</TOKEN>
<TOKEN end_char="2325" id="token-29-11" morph="none" pos="word" start_char="2322">such</TOKEN>
<TOKEN end_char="2327" id="token-29-12" morph="none" pos="word" start_char="2327">a</TOKEN>
<TOKEN end_char="2333" id="token-29-13" morph="none" pos="word" start_char="2329">virus</TOKEN>
<TOKEN end_char="2335" id="token-29-14" morph="none" pos="punct" start_char="2334">,"</TOKEN>
<TOKEN end_char="2339" id="token-29-15" morph="none" pos="word" start_char="2337">she</TOKEN>
<TOKEN end_char="2349" id="token-29-16" morph="none" pos="word" start_char="2341">continued</TOKEN>
<TOKEN end_char="2350" id="token-29-17" morph="none" pos="punct" start_char="2350">.</TOKEN>
</SEG>
<SEG end_char="2381" id="segment-30" start_char="2352">
<ORIGINAL_TEXT>"I realized it only recently."</ORIGINAL_TEXT>
<TOKEN end_char="2352" id="token-30-0" morph="none" pos="punct" start_char="2352">"</TOKEN>
<TOKEN end_char="2353" id="token-30-1" morph="none" pos="word" start_char="2353">I</TOKEN>
<TOKEN end_char="2362" id="token-30-2" morph="none" pos="word" start_char="2355">realized</TOKEN>
<TOKEN end_char="2365" id="token-30-3" morph="none" pos="word" start_char="2364">it</TOKEN>
<TOKEN end_char="2370" id="token-30-4" morph="none" pos="word" start_char="2367">only</TOKEN>
<TOKEN end_char="2379" id="token-30-5" morph="none" pos="word" start_char="2372">recently</TOKEN>
<TOKEN end_char="2381" id="token-30-6" morph="none" pos="punct" start_char="2380">."</TOKEN>
</SEG>
<SEG end_char="2450" id="segment-31" start_char="2384">
<ORIGINAL_TEXT>So where did coronavirus originate—and is it linked to bats at all?</ORIGINAL_TEXT>
<TOKEN end_char="2385" id="token-31-0" morph="none" pos="word" start_char="2384">So</TOKEN>
<TOKEN end_char="2391" id="token-31-1" morph="none" pos="word" start_char="2387">where</TOKEN>
<TOKEN end_char="2395" id="token-31-2" morph="none" pos="word" start_char="2393">did</TOKEN>
<TOKEN end_char="2407" id="token-31-3" morph="none" pos="word" start_char="2397">coronavirus</TOKEN>
<TOKEN end_char="2421" id="token-31-4" morph="none" pos="unknown" start_char="2409">originate—and</TOKEN>
<TOKEN end_char="2424" id="token-31-5" morph="none" pos="word" start_char="2423">is</TOKEN>
<TOKEN end_char="2427" id="token-31-6" morph="none" pos="word" start_char="2426">it</TOKEN>
<TOKEN end_char="2434" id="token-31-7" morph="none" pos="word" start_char="2429">linked</TOKEN>
<TOKEN end_char="2437" id="token-31-8" morph="none" pos="word" start_char="2436">to</TOKEN>
<TOKEN end_char="2442" id="token-31-9" morph="none" pos="word" start_char="2439">bats</TOKEN>
<TOKEN end_char="2445" id="token-31-10" morph="none" pos="word" start_char="2444">at</TOKEN>
<TOKEN end_char="2449" id="token-31-11" morph="none" pos="word" start_char="2447">all</TOKEN>
<TOKEN end_char="2450" id="token-31-12" morph="none" pos="punct" start_char="2450">?</TOKEN>
</SEG>
<SEG end_char="2691" id="segment-32" start_char="2454">
<ORIGINAL_TEXT>This is where it gets tricky: Coronaviruses in general are a large family of viruses that can affect many different species of animals, including camels, cattle, and bats, according to the Centers for Disease Control and Prevention (CDC).</ORIGINAL_TEXT>
<TOKEN end_char="2457" id="token-32-0" morph="none" pos="word" start_char="2454">This</TOKEN>
<TOKEN end_char="2460" id="token-32-1" morph="none" pos="word" start_char="2459">is</TOKEN>
<TOKEN end_char="2466" id="token-32-2" morph="none" pos="word" start_char="2462">where</TOKEN>
<TOKEN end_char="2469" id="token-32-3" morph="none" pos="word" start_char="2468">it</TOKEN>
<TOKEN end_char="2474" id="token-32-4" morph="none" pos="word" start_char="2471">gets</TOKEN>
<TOKEN end_char="2481" id="token-32-5" morph="none" pos="word" start_char="2476">tricky</TOKEN>
<TOKEN end_char="2482" id="token-32-6" morph="none" pos="punct" start_char="2482">:</TOKEN>
<TOKEN end_char="2496" id="token-32-7" morph="none" pos="word" start_char="2484">Coronaviruses</TOKEN>
<TOKEN end_char="2499" id="token-32-8" morph="none" pos="word" start_char="2498">in</TOKEN>
<TOKEN end_char="2507" id="token-32-9" morph="none" pos="word" start_char="2501">general</TOKEN>
<TOKEN end_char="2511" id="token-32-10" morph="none" pos="word" start_char="2509">are</TOKEN>
<TOKEN end_char="2513" id="token-32-11" morph="none" pos="word" start_char="2513">a</TOKEN>
<TOKEN end_char="2519" id="token-32-12" morph="none" pos="word" start_char="2515">large</TOKEN>
<TOKEN end_char="2526" id="token-32-13" morph="none" pos="word" start_char="2521">family</TOKEN>
<TOKEN end_char="2529" id="token-32-14" morph="none" pos="word" start_char="2528">of</TOKEN>
<TOKEN end_char="2537" id="token-32-15" morph="none" pos="word" start_char="2531">viruses</TOKEN>
<TOKEN end_char="2542" id="token-32-16" morph="none" pos="word" start_char="2539">that</TOKEN>
<TOKEN end_char="2546" id="token-32-17" morph="none" pos="word" start_char="2544">can</TOKEN>
<TOKEN end_char="2553" id="token-32-18" morph="none" pos="word" start_char="2548">affect</TOKEN>
<TOKEN end_char="2558" id="token-32-19" morph="none" pos="word" start_char="2555">many</TOKEN>
<TOKEN end_char="2568" id="token-32-20" morph="none" pos="word" start_char="2560">different</TOKEN>
<TOKEN end_char="2576" id="token-32-21" morph="none" pos="word" start_char="2570">species</TOKEN>
<TOKEN end_char="2579" id="token-32-22" morph="none" pos="word" start_char="2578">of</TOKEN>
<TOKEN end_char="2587" id="token-32-23" morph="none" pos="word" start_char="2581">animals</TOKEN>
<TOKEN end_char="2588" id="token-32-24" morph="none" pos="punct" start_char="2588">,</TOKEN>
<TOKEN end_char="2598" id="token-32-25" morph="none" pos="word" start_char="2590">including</TOKEN>
<TOKEN end_char="2605" id="token-32-26" morph="none" pos="word" start_char="2600">camels</TOKEN>
<TOKEN end_char="2606" id="token-32-27" morph="none" pos="punct" start_char="2606">,</TOKEN>
<TOKEN end_char="2613" id="token-32-28" morph="none" pos="word" start_char="2608">cattle</TOKEN>
<TOKEN end_char="2614" id="token-32-29" morph="none" pos="punct" start_char="2614">,</TOKEN>
<TOKEN end_char="2618" id="token-32-30" morph="none" pos="word" start_char="2616">and</TOKEN>
<TOKEN end_char="2623" id="token-32-31" morph="none" pos="word" start_char="2620">bats</TOKEN>
<TOKEN end_char="2624" id="token-32-32" morph="none" pos="punct" start_char="2624">,</TOKEN>
<TOKEN end_char="2634" id="token-32-33" morph="none" pos="word" start_char="2626">according</TOKEN>
<TOKEN end_char="2637" id="token-32-34" morph="none" pos="word" start_char="2636">to</TOKEN>
<TOKEN end_char="2641" id="token-32-35" morph="none" pos="word" start_char="2639">the</TOKEN>
<TOKEN end_char="2649" id="token-32-36" morph="none" pos="word" start_char="2643">Centers</TOKEN>
<TOKEN end_char="2653" id="token-32-37" morph="none" pos="word" start_char="2651">for</TOKEN>
<TOKEN end_char="2661" id="token-32-38" morph="none" pos="word" start_char="2655">Disease</TOKEN>
<TOKEN end_char="2669" id="token-32-39" morph="none" pos="word" start_char="2663">Control</TOKEN>
<TOKEN end_char="2673" id="token-32-40" morph="none" pos="word" start_char="2671">and</TOKEN>
<TOKEN end_char="2684" id="token-32-41" morph="none" pos="word" start_char="2675">Prevention</TOKEN>
<TOKEN end_char="2686" id="token-32-42" morph="none" pos="punct" start_char="2686">(</TOKEN>
<TOKEN end_char="2689" id="token-32-43" morph="none" pos="word" start_char="2687">CDC</TOKEN>
<TOKEN end_char="2691" id="token-32-44" morph="none" pos="punct" start_char="2690">).</TOKEN>
</SEG>
<SEG end_char="2933" id="segment-33" start_char="2693">
<ORIGINAL_TEXT>In rare cases, those viruses are also zoonotic, which means they can pass between humans and animals—as was the case with Middle East respiratory syndrome (MERS) and severe acute respiratory system (SARS), two severe coronaviruses in people.</ORIGINAL_TEXT>
<TOKEN end_char="2694" id="token-33-0" morph="none" pos="word" start_char="2693">In</TOKEN>
<TOKEN end_char="2699" id="token-33-1" morph="none" pos="word" start_char="2696">rare</TOKEN>
<TOKEN end_char="2705" id="token-33-2" morph="none" pos="word" start_char="2701">cases</TOKEN>
<TOKEN end_char="2706" id="token-33-3" morph="none" pos="punct" start_char="2706">,</TOKEN>
<TOKEN end_char="2712" id="token-33-4" morph="none" pos="word" start_char="2708">those</TOKEN>
<TOKEN end_char="2720" id="token-33-5" morph="none" pos="word" start_char="2714">viruses</TOKEN>
<TOKEN end_char="2724" id="token-33-6" morph="none" pos="word" start_char="2722">are</TOKEN>
<TOKEN end_char="2729" id="token-33-7" morph="none" pos="word" start_char="2726">also</TOKEN>
<TOKEN end_char="2738" id="token-33-8" morph="none" pos="word" start_char="2731">zoonotic</TOKEN>
<TOKEN end_char="2739" id="token-33-9" morph="none" pos="punct" start_char="2739">,</TOKEN>
<TOKEN end_char="2745" id="token-33-10" morph="none" pos="word" start_char="2741">which</TOKEN>
<TOKEN end_char="2751" id="token-33-11" morph="none" pos="word" start_char="2747">means</TOKEN>
<TOKEN end_char="2756" id="token-33-12" morph="none" pos="word" start_char="2753">they</TOKEN>
<TOKEN end_char="2760" id="token-33-13" morph="none" pos="word" start_char="2758">can</TOKEN>
<TOKEN end_char="2765" id="token-33-14" morph="none" pos="word" start_char="2762">pass</TOKEN>
<TOKEN end_char="2773" id="token-33-15" morph="none" pos="word" start_char="2767">between</TOKEN>
<TOKEN end_char="2780" id="token-33-16" morph="none" pos="word" start_char="2775">humans</TOKEN>
<TOKEN end_char="2784" id="token-33-17" morph="none" pos="word" start_char="2782">and</TOKEN>
<TOKEN end_char="2795" id="token-33-18" morph="none" pos="unknown" start_char="2786">animals—as</TOKEN>
<TOKEN end_char="2799" id="token-33-19" morph="none" pos="word" start_char="2797">was</TOKEN>
<TOKEN end_char="2803" id="token-33-20" morph="none" pos="word" start_char="2801">the</TOKEN>
<TOKEN end_char="2808" id="token-33-21" morph="none" pos="word" start_char="2805">case</TOKEN>
<TOKEN end_char="2813" id="token-33-22" morph="none" pos="word" start_char="2810">with</TOKEN>
<TOKEN end_char="2820" id="token-33-23" morph="none" pos="word" start_char="2815">Middle</TOKEN>
<TOKEN end_char="2825" id="token-33-24" morph="none" pos="word" start_char="2822">East</TOKEN>
<TOKEN end_char="2837" id="token-33-25" morph="none" pos="word" start_char="2827">respiratory</TOKEN>
<TOKEN end_char="2846" id="token-33-26" morph="none" pos="word" start_char="2839">syndrome</TOKEN>
<TOKEN end_char="2848" id="token-33-27" morph="none" pos="punct" start_char="2848">(</TOKEN>
<TOKEN end_char="2852" id="token-33-28" morph="none" pos="word" start_char="2849">MERS</TOKEN>
<TOKEN end_char="2853" id="token-33-29" morph="none" pos="punct" start_char="2853">)</TOKEN>
<TOKEN end_char="2857" id="token-33-30" morph="none" pos="word" start_char="2855">and</TOKEN>
<TOKEN end_char="2864" id="token-33-31" morph="none" pos="word" start_char="2859">severe</TOKEN>
<TOKEN end_char="2870" id="token-33-32" morph="none" pos="word" start_char="2866">acute</TOKEN>
<TOKEN end_char="2882" id="token-33-33" morph="none" pos="word" start_char="2872">respiratory</TOKEN>
<TOKEN end_char="2889" id="token-33-34" morph="none" pos="word" start_char="2884">system</TOKEN>
<TOKEN end_char="2891" id="token-33-35" morph="none" pos="punct" start_char="2891">(</TOKEN>
<TOKEN end_char="2895" id="token-33-36" morph="none" pos="word" start_char="2892">SARS</TOKEN>
<TOKEN end_char="2897" id="token-33-37" morph="none" pos="punct" start_char="2896">),</TOKEN>
<TOKEN end_char="2901" id="token-33-38" morph="none" pos="word" start_char="2899">two</TOKEN>
<TOKEN end_char="2908" id="token-33-39" morph="none" pos="word" start_char="2903">severe</TOKEN>
<TOKEN end_char="2922" id="token-33-40" morph="none" pos="word" start_char="2910">coronaviruses</TOKEN>
<TOKEN end_char="2925" id="token-33-41" morph="none" pos="word" start_char="2924">in</TOKEN>
<TOKEN end_char="2932" id="token-33-42" morph="none" pos="word" start_char="2927">people</TOKEN>
<TOKEN end_char="2933" id="token-33-43" morph="none" pos="punct" start_char="2933">.</TOKEN>
</SEG>
<SEG end_char="3089" id="segment-34" start_char="2936">
<ORIGINAL_TEXT>Initially, this novel coronavirus was believed to have started in a large seafood or wet market, suggesting animal-to-person spread, according to the CDC.</ORIGINAL_TEXT>
<TOKEN end_char="2944" id="token-34-0" morph="none" pos="word" start_char="2936">Initially</TOKEN>
<TOKEN end_char="2945" id="token-34-1" morph="none" pos="punct" start_char="2945">,</TOKEN>
<TOKEN end_char="2950" id="token-34-2" morph="none" pos="word" start_char="2947">this</TOKEN>
<TOKEN end_char="2956" id="token-34-3" morph="none" pos="word" start_char="2952">novel</TOKEN>
<TOKEN end_char="2968" id="token-34-4" morph="none" pos="word" start_char="2958">coronavirus</TOKEN>
<TOKEN end_char="2972" id="token-34-5" morph="none" pos="word" start_char="2970">was</TOKEN>
<TOKEN end_char="2981" id="token-34-6" morph="none" pos="word" start_char="2974">believed</TOKEN>
<TOKEN end_char="2984" id="token-34-7" morph="none" pos="word" start_char="2983">to</TOKEN>
<TOKEN end_char="2989" id="token-34-8" morph="none" pos="word" start_char="2986">have</TOKEN>
<TOKEN end_char="2997" id="token-34-9" morph="none" pos="word" start_char="2991">started</TOKEN>
<TOKEN end_char="3000" id="token-34-10" morph="none" pos="word" start_char="2999">in</TOKEN>
<TOKEN end_char="3002" id="token-34-11" morph="none" pos="word" start_char="3002">a</TOKEN>
<TOKEN end_char="3008" id="token-34-12" morph="none" pos="word" start_char="3004">large</TOKEN>
<TOKEN end_char="3016" id="token-34-13" morph="none" pos="word" start_char="3010">seafood</TOKEN>
<TOKEN end_char="3019" id="token-34-14" morph="none" pos="word" start_char="3018">or</TOKEN>
<TOKEN end_char="3023" id="token-34-15" morph="none" pos="word" start_char="3021">wet</TOKEN>
<TOKEN end_char="3030" id="token-34-16" morph="none" pos="word" start_char="3025">market</TOKEN>
<TOKEN end_char="3031" id="token-34-17" morph="none" pos="punct" start_char="3031">,</TOKEN>
<TOKEN end_char="3042" id="token-34-18" morph="none" pos="word" start_char="3033">suggesting</TOKEN>
<TOKEN end_char="3059" id="token-34-19" morph="none" pos="unknown" start_char="3044">animal-to-person</TOKEN>
<TOKEN end_char="3066" id="token-34-20" morph="none" pos="word" start_char="3061">spread</TOKEN>
<TOKEN end_char="3067" id="token-34-21" morph="none" pos="punct" start_char="3067">,</TOKEN>
<TOKEN end_char="3077" id="token-34-22" morph="none" pos="word" start_char="3069">according</TOKEN>
<TOKEN end_char="3080" id="token-34-23" morph="none" pos="word" start_char="3079">to</TOKEN>
<TOKEN end_char="3084" id="token-34-24" morph="none" pos="word" start_char="3082">the</TOKEN>
<TOKEN end_char="3088" id="token-34-25" morph="none" pos="word" start_char="3086">CDC</TOKEN>
<TOKEN end_char="3089" id="token-34-26" morph="none" pos="punct" start_char="3089">.</TOKEN>
</SEG>
<SEG end_char="3284" id="segment-35" start_char="3091">
<ORIGINAL_TEXT>But a large number of people diagnosed with the virus reportedly didn't have exposure to the wet markets, and now it's clear that the virus is primarily spreading person-to-person, says the CDC.</ORIGINAL_TEXT>
<TOKEN end_char="3093" id="token-35-0" morph="none" pos="word" start_char="3091">But</TOKEN>
<TOKEN end_char="3095" id="token-35-1" morph="none" pos="word" start_char="3095">a</TOKEN>
<TOKEN end_char="3101" id="token-35-2" morph="none" pos="word" start_char="3097">large</TOKEN>
<TOKEN end_char="3108" id="token-35-3" morph="none" pos="word" start_char="3103">number</TOKEN>
<TOKEN end_char="3111" id="token-35-4" morph="none" pos="word" start_char="3110">of</TOKEN>
<TOKEN end_char="3118" id="token-35-5" morph="none" pos="word" start_char="3113">people</TOKEN>
<TOKEN end_char="3128" id="token-35-6" morph="none" pos="word" start_char="3120">diagnosed</TOKEN>
<TOKEN end_char="3133" id="token-35-7" morph="none" pos="word" start_char="3130">with</TOKEN>
<TOKEN end_char="3137" id="token-35-8" morph="none" pos="word" start_char="3135">the</TOKEN>
<TOKEN end_char="3143" id="token-35-9" morph="none" pos="word" start_char="3139">virus</TOKEN>
<TOKEN end_char="3154" id="token-35-10" morph="none" pos="word" start_char="3145">reportedly</TOKEN>
<TOKEN end_char="3161" id="token-35-11" morph="none" pos="word" start_char="3156">didn't</TOKEN>
<TOKEN end_char="3166" id="token-35-12" morph="none" pos="word" start_char="3163">have</TOKEN>
<TOKEN end_char="3175" id="token-35-13" morph="none" pos="word" start_char="3168">exposure</TOKEN>
<TOKEN end_char="3178" id="token-35-14" morph="none" pos="word" start_char="3177">to</TOKEN>
<TOKEN end_char="3182" id="token-35-15" morph="none" pos="word" start_char="3180">the</TOKEN>
<TOKEN end_char="3186" id="token-35-16" morph="none" pos="word" start_char="3184">wet</TOKEN>
<TOKEN end_char="3194" id="token-35-17" morph="none" pos="word" start_char="3188">markets</TOKEN>
<TOKEN end_char="3195" id="token-35-18" morph="none" pos="punct" start_char="3195">,</TOKEN>
<TOKEN end_char="3199" id="token-35-19" morph="none" pos="word" start_char="3197">and</TOKEN>
<TOKEN end_char="3203" id="token-35-20" morph="none" pos="word" start_char="3201">now</TOKEN>
<TOKEN end_char="3208" id="token-35-21" morph="none" pos="word" start_char="3205">it's</TOKEN>
<TOKEN end_char="3214" id="token-35-22" morph="none" pos="word" start_char="3210">clear</TOKEN>
<TOKEN end_char="3219" id="token-35-23" morph="none" pos="word" start_char="3216">that</TOKEN>
<TOKEN end_char="3223" id="token-35-24" morph="none" pos="word" start_char="3221">the</TOKEN>
<TOKEN end_char="3229" id="token-35-25" morph="none" pos="word" start_char="3225">virus</TOKEN>
<TOKEN end_char="3232" id="token-35-26" morph="none" pos="word" start_char="3231">is</TOKEN>
<TOKEN end_char="3242" id="token-35-27" morph="none" pos="word" start_char="3234">primarily</TOKEN>
<TOKEN end_char="3252" id="token-35-28" morph="none" pos="word" start_char="3244">spreading</TOKEN>
<TOKEN end_char="3269" id="token-35-29" morph="none" pos="unknown" start_char="3254">person-to-person</TOKEN>
<TOKEN end_char="3270" id="token-35-30" morph="none" pos="punct" start_char="3270">,</TOKEN>
<TOKEN end_char="3275" id="token-35-31" morph="none" pos="word" start_char="3272">says</TOKEN>
<TOKEN end_char="3279" id="token-35-32" morph="none" pos="word" start_char="3277">the</TOKEN>
<TOKEN end_char="3283" id="token-35-33" morph="none" pos="word" start_char="3281">CDC</TOKEN>
<TOKEN end_char="3284" id="token-35-34" morph="none" pos="punct" start_char="3284">.</TOKEN>
</SEG>
<SEG end_char="3448" id="segment-36" start_char="3287">
<ORIGINAL_TEXT>Is it possible that the novel coronavirus began with an infected animal at the market—and then went on to person-to-person transmission once people were infected?</ORIGINAL_TEXT>
<TOKEN end_char="3288" id="token-36-0" morph="none" pos="word" start_char="3287">Is</TOKEN>
<TOKEN end_char="3291" id="token-36-1" morph="none" pos="word" start_char="3290">it</TOKEN>
<TOKEN end_char="3300" id="token-36-2" morph="none" pos="word" start_char="3293">possible</TOKEN>
<TOKEN end_char="3305" id="token-36-3" morph="none" pos="word" start_char="3302">that</TOKEN>
<TOKEN end_char="3309" id="token-36-4" morph="none" pos="word" start_char="3307">the</TOKEN>
<TOKEN end_char="3315" id="token-36-5" morph="none" pos="word" start_char="3311">novel</TOKEN>
<TOKEN end_char="3327" id="token-36-6" morph="none" pos="word" start_char="3317">coronavirus</TOKEN>
<TOKEN end_char="3333" id="token-36-7" morph="none" pos="word" start_char="3329">began</TOKEN>
<TOKEN end_char="3338" id="token-36-8" morph="none" pos="word" start_char="3335">with</TOKEN>
<TOKEN end_char="3341" id="token-36-9" morph="none" pos="word" start_char="3340">an</TOKEN>
<TOKEN end_char="3350" id="token-36-10" morph="none" pos="word" start_char="3343">infected</TOKEN>
<TOKEN end_char="3357" id="token-36-11" morph="none" pos="word" start_char="3352">animal</TOKEN>
<TOKEN end_char="3360" id="token-36-12" morph="none" pos="word" start_char="3359">at</TOKEN>
<TOKEN end_char="3364" id="token-36-13" morph="none" pos="word" start_char="3362">the</TOKEN>
<TOKEN end_char="3375" id="token-36-14" morph="none" pos="unknown" start_char="3366">market—and</TOKEN>
<TOKEN end_char="3380" id="token-36-15" morph="none" pos="word" start_char="3377">then</TOKEN>
<TOKEN end_char="3385" id="token-36-16" morph="none" pos="word" start_char="3382">went</TOKEN>
<TOKEN end_char="3388" id="token-36-17" morph="none" pos="word" start_char="3387">on</TOKEN>
<TOKEN end_char="3391" id="token-36-18" morph="none" pos="word" start_char="3390">to</TOKEN>
<TOKEN end_char="3408" id="token-36-19" morph="none" pos="unknown" start_char="3393">person-to-person</TOKEN>
<TOKEN end_char="3421" id="token-36-20" morph="none" pos="word" start_char="3410">transmission</TOKEN>
<TOKEN end_char="3426" id="token-36-21" morph="none" pos="word" start_char="3423">once</TOKEN>
<TOKEN end_char="3433" id="token-36-22" morph="none" pos="word" start_char="3428">people</TOKEN>
<TOKEN end_char="3438" id="token-36-23" morph="none" pos="word" start_char="3435">were</TOKEN>
<TOKEN end_char="3447" id="token-36-24" morph="none" pos="word" start_char="3440">infected</TOKEN>
<TOKEN end_char="3448" id="token-36-25" morph="none" pos="punct" start_char="3448">?</TOKEN>
</SEG>
<SEG end_char="3732" id="segment-37" start_char="3450">
<ORIGINAL_TEXT>While experts still haven't pinpointed the actual source, new research released online by the CDC on April 21 concludes that SARS-CoV-2 "is probably a novel recombinant virus"—one that has features closely related to coronaviruses found in bats and pangolins (scaly-skinned mammals).</ORIGINAL_TEXT>
<TOKEN end_char="3454" id="token-37-0" morph="none" pos="word" start_char="3450">While</TOKEN>
<TOKEN end_char="3462" id="token-37-1" morph="none" pos="word" start_char="3456">experts</TOKEN>
<TOKEN end_char="3468" id="token-37-2" morph="none" pos="word" start_char="3464">still</TOKEN>
<TOKEN end_char="3476" id="token-37-3" morph="none" pos="word" start_char="3470">haven't</TOKEN>
<TOKEN end_char="3487" id="token-37-4" morph="none" pos="word" start_char="3478">pinpointed</TOKEN>
<TOKEN end_char="3491" id="token-37-5" morph="none" pos="word" start_char="3489">the</TOKEN>
<TOKEN end_char="3498" id="token-37-6" morph="none" pos="word" start_char="3493">actual</TOKEN>
<TOKEN end_char="3505" id="token-37-7" morph="none" pos="word" start_char="3500">source</TOKEN>
<TOKEN end_char="3506" id="token-37-8" morph="none" pos="punct" start_char="3506">,</TOKEN>
<TOKEN end_char="3510" id="token-37-9" morph="none" pos="word" start_char="3508">new</TOKEN>
<TOKEN end_char="3519" id="token-37-10" morph="none" pos="word" start_char="3512">research</TOKEN>
<TOKEN end_char="3528" id="token-37-11" morph="none" pos="word" start_char="3521">released</TOKEN>
<TOKEN end_char="3535" id="token-37-12" morph="none" pos="word" start_char="3530">online</TOKEN>
<TOKEN end_char="3538" id="token-37-13" morph="none" pos="word" start_char="3537">by</TOKEN>
<TOKEN end_char="3542" id="token-37-14" morph="none" pos="word" start_char="3540">the</TOKEN>
<TOKEN end_char="3546" id="token-37-15" morph="none" pos="word" start_char="3544">CDC</TOKEN>
<TOKEN end_char="3549" id="token-37-16" morph="none" pos="word" start_char="3548">on</TOKEN>
<TOKEN end_char="3555" id="token-37-17" morph="none" pos="word" start_char="3551">April</TOKEN>
<TOKEN end_char="3558" id="token-37-18" morph="none" pos="word" start_char="3557">21</TOKEN>
<TOKEN end_char="3568" id="token-37-19" morph="none" pos="word" start_char="3560">concludes</TOKEN>
<TOKEN end_char="3573" id="token-37-20" morph="none" pos="word" start_char="3570">that</TOKEN>
<TOKEN end_char="3584" id="token-37-21" morph="none" pos="unknown" start_char="3575">SARS-CoV-2</TOKEN>
<TOKEN end_char="3586" id="token-37-22" morph="none" pos="punct" start_char="3586">"</TOKEN>
<TOKEN end_char="3588" id="token-37-23" morph="none" pos="word" start_char="3587">is</TOKEN>
<TOKEN end_char="3597" id="token-37-24" morph="none" pos="word" start_char="3590">probably</TOKEN>
<TOKEN end_char="3599" id="token-37-25" morph="none" pos="word" start_char="3599">a</TOKEN>
<TOKEN end_char="3605" id="token-37-26" morph="none" pos="word" start_char="3601">novel</TOKEN>
<TOKEN end_char="3617" id="token-37-27" morph="none" pos="word" start_char="3607">recombinant</TOKEN>
<TOKEN end_char="3628" id="token-37-28" morph="none" pos="unknown" start_char="3619">virus"—one</TOKEN>
<TOKEN end_char="3633" id="token-37-29" morph="none" pos="word" start_char="3630">that</TOKEN>
<TOKEN end_char="3637" id="token-37-30" morph="none" pos="word" start_char="3635">has</TOKEN>
<TOKEN end_char="3646" id="token-37-31" morph="none" pos="word" start_char="3639">features</TOKEN>
<TOKEN end_char="3654" id="token-37-32" morph="none" pos="word" start_char="3648">closely</TOKEN>
<TOKEN end_char="3662" id="token-37-33" morph="none" pos="word" start_char="3656">related</TOKEN>
<TOKEN end_char="3665" id="token-37-34" morph="none" pos="word" start_char="3664">to</TOKEN>
<TOKEN end_char="3679" id="token-37-35" morph="none" pos="word" start_char="3667">coronaviruses</TOKEN>
<TOKEN end_char="3685" id="token-37-36" morph="none" pos="word" start_char="3681">found</TOKEN>
<TOKEN end_char="3688" id="token-37-37" morph="none" pos="word" start_char="3687">in</TOKEN>
<TOKEN end_char="3693" id="token-37-38" morph="none" pos="word" start_char="3690">bats</TOKEN>
<TOKEN end_char="3697" id="token-37-39" morph="none" pos="word" start_char="3695">and</TOKEN>
<TOKEN end_char="3707" id="token-37-40" morph="none" pos="word" start_char="3699">pangolins</TOKEN>
<TOKEN end_char="3709" id="token-37-41" morph="none" pos="punct" start_char="3709">(</TOKEN>
<TOKEN end_char="3722" id="token-37-42" morph="none" pos="unknown" start_char="3710">scaly-skinned</TOKEN>
<TOKEN end_char="3730" id="token-37-43" morph="none" pos="word" start_char="3724">mammals</TOKEN>
<TOKEN end_char="3732" id="token-37-44" morph="none" pos="punct" start_char="3731">).</TOKEN>
</SEG>
<SEG end_char="3966" id="segment-38" start_char="3735">
<ORIGINAL_TEXT>However, none of the existing coronaviruses represents its immediate ancestor, notes Susanna K. P. Lau, MBBS, MD, head of microbiology at the University of Hong Kong, and colleagues, who analyzed the genome of the novel coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="3741" id="token-38-0" morph="none" pos="word" start_char="3735">However</TOKEN>
<TOKEN end_char="3742" id="token-38-1" morph="none" pos="punct" start_char="3742">,</TOKEN>
<TOKEN end_char="3747" id="token-38-2" morph="none" pos="word" start_char="3744">none</TOKEN>
<TOKEN end_char="3750" id="token-38-3" morph="none" pos="word" start_char="3749">of</TOKEN>
<TOKEN end_char="3754" id="token-38-4" morph="none" pos="word" start_char="3752">the</TOKEN>
<TOKEN end_char="3763" id="token-38-5" morph="none" pos="word" start_char="3756">existing</TOKEN>
<TOKEN end_char="3777" id="token-38-6" morph="none" pos="word" start_char="3765">coronaviruses</TOKEN>
<TOKEN end_char="3788" id="token-38-7" morph="none" pos="word" start_char="3779">represents</TOKEN>
<TOKEN end_char="3792" id="token-38-8" morph="none" pos="word" start_char="3790">its</TOKEN>
<TOKEN end_char="3802" id="token-38-9" morph="none" pos="word" start_char="3794">immediate</TOKEN>
<TOKEN end_char="3811" id="token-38-10" morph="none" pos="word" start_char="3804">ancestor</TOKEN>
<TOKEN end_char="3812" id="token-38-11" morph="none" pos="punct" start_char="3812">,</TOKEN>
<TOKEN end_char="3818" id="token-38-12" morph="none" pos="word" start_char="3814">notes</TOKEN>
<TOKEN end_char="3826" id="token-38-13" morph="none" pos="word" start_char="3820">Susanna</TOKEN>
<TOKEN end_char="3828" id="token-38-14" morph="none" pos="word" start_char="3828">K</TOKEN>
<TOKEN end_char="3829" id="token-38-15" morph="none" pos="punct" start_char="3829">.</TOKEN>
<TOKEN end_char="3831" id="token-38-16" morph="none" pos="word" start_char="3831">P</TOKEN>
<TOKEN end_char="3832" id="token-38-17" morph="none" pos="punct" start_char="3832">.</TOKEN>
<TOKEN end_char="3836" id="token-38-18" morph="none" pos="word" start_char="3834">Lau</TOKEN>
<TOKEN end_char="3837" id="token-38-19" morph="none" pos="punct" start_char="3837">,</TOKEN>
<TOKEN end_char="3842" id="token-38-20" morph="none" pos="word" start_char="3839">MBBS</TOKEN>
<TOKEN end_char="3843" id="token-38-21" morph="none" pos="punct" start_char="3843">,</TOKEN>
<TOKEN end_char="3846" id="token-38-22" morph="none" pos="word" start_char="3845">MD</TOKEN>
<TOKEN end_char="3847" id="token-38-23" morph="none" pos="punct" start_char="3847">,</TOKEN>
<TOKEN end_char="3852" id="token-38-24" morph="none" pos="word" start_char="3849">head</TOKEN>
<TOKEN end_char="3855" id="token-38-25" morph="none" pos="word" start_char="3854">of</TOKEN>
<TOKEN end_char="3868" id="token-38-26" morph="none" pos="word" start_char="3857">microbiology</TOKEN>
<TOKEN end_char="3871" id="token-38-27" morph="none" pos="word" start_char="3870">at</TOKEN>
<TOKEN end_char="3875" id="token-38-28" morph="none" pos="word" start_char="3873">the</TOKEN>
<TOKEN end_char="3886" id="token-38-29" morph="none" pos="word" start_char="3877">University</TOKEN>
<TOKEN end_char="3889" id="token-38-30" morph="none" pos="word" start_char="3888">of</TOKEN>
<TOKEN end_char="3894" id="token-38-31" morph="none" pos="word" start_char="3891">Hong</TOKEN>
<TOKEN end_char="3899" id="token-38-32" morph="none" pos="word" start_char="3896">Kong</TOKEN>
<TOKEN end_char="3900" id="token-38-33" morph="none" pos="punct" start_char="3900">,</TOKEN>
<TOKEN end_char="3904" id="token-38-34" morph="none" pos="word" start_char="3902">and</TOKEN>
<TOKEN end_char="3915" id="token-38-35" morph="none" pos="word" start_char="3906">colleagues</TOKEN>
<TOKEN end_char="3916" id="token-38-36" morph="none" pos="punct" start_char="3916">,</TOKEN>
<TOKEN end_char="3920" id="token-38-37" morph="none" pos="word" start_char="3918">who</TOKEN>
<TOKEN end_char="3929" id="token-38-38" morph="none" pos="word" start_char="3922">analyzed</TOKEN>
<TOKEN end_char="3933" id="token-38-39" morph="none" pos="word" start_char="3931">the</TOKEN>
<TOKEN end_char="3940" id="token-38-40" morph="none" pos="word" start_char="3935">genome</TOKEN>
<TOKEN end_char="3943" id="token-38-41" morph="none" pos="word" start_char="3942">of</TOKEN>
<TOKEN end_char="3947" id="token-38-42" morph="none" pos="word" start_char="3945">the</TOKEN>
<TOKEN end_char="3953" id="token-38-43" morph="none" pos="word" start_char="3949">novel</TOKEN>
<TOKEN end_char="3965" id="token-38-44" morph="none" pos="word" start_char="3955">coronavirus</TOKEN>
<TOKEN end_char="3966" id="token-38-45" morph="none" pos="punct" start_char="3966">.</TOKEN>
</SEG>
<SEG end_char="4098" id="segment-39" start_char="3969">
<ORIGINAL_TEXT>"Although the Wuhan market was initially suspected to be the epicenter of the epidemic, the immediate source remains elusive," Dr.</ORIGINAL_TEXT>
<TOKEN end_char="3969" id="token-39-0" morph="none" pos="punct" start_char="3969">"</TOKEN>
<TOKEN end_char="3977" id="token-39-1" morph="none" pos="word" start_char="3970">Although</TOKEN>
<TOKEN end_char="3981" id="token-39-2" morph="none" pos="word" start_char="3979">the</TOKEN>
<TOKEN end_char="3987" id="token-39-3" morph="none" pos="word" start_char="3983">Wuhan</TOKEN>
<TOKEN end_char="3994" id="token-39-4" morph="none" pos="word" start_char="3989">market</TOKEN>
<TOKEN end_char="3998" id="token-39-5" morph="none" pos="word" start_char="3996">was</TOKEN>
<TOKEN end_char="4008" id="token-39-6" morph="none" pos="word" start_char="4000">initially</TOKEN>
<TOKEN end_char="4018" id="token-39-7" morph="none" pos="word" start_char="4010">suspected</TOKEN>
<TOKEN end_char="4021" id="token-39-8" morph="none" pos="word" start_char="4020">to</TOKEN>
<TOKEN end_char="4024" id="token-39-9" morph="none" pos="word" start_char="4023">be</TOKEN>
<TOKEN end_char="4028" id="token-39-10" morph="none" pos="word" start_char="4026">the</TOKEN>
<TOKEN end_char="4038" id="token-39-11" morph="none" pos="word" start_char="4030">epicenter</TOKEN>
<TOKEN end_char="4041" id="token-39-12" morph="none" pos="word" start_char="4040">of</TOKEN>
<TOKEN end_char="4045" id="token-39-13" morph="none" pos="word" start_char="4043">the</TOKEN>
<TOKEN end_char="4054" id="token-39-14" morph="none" pos="word" start_char="4047">epidemic</TOKEN>
<TOKEN end_char="4055" id="token-39-15" morph="none" pos="punct" start_char="4055">,</TOKEN>
<TOKEN end_char="4059" id="token-39-16" morph="none" pos="word" start_char="4057">the</TOKEN>
<TOKEN end_char="4069" id="token-39-17" morph="none" pos="word" start_char="4061">immediate</TOKEN>
<TOKEN end_char="4076" id="token-39-18" morph="none" pos="word" start_char="4071">source</TOKEN>
<TOKEN end_char="4084" id="token-39-19" morph="none" pos="word" start_char="4078">remains</TOKEN>
<TOKEN end_char="4092" id="token-39-20" morph="none" pos="word" start_char="4086">elusive</TOKEN>
<TOKEN end_char="4094" id="token-39-21" morph="none" pos="punct" start_char="4093">,"</TOKEN>
<TOKEN end_char="4097" id="token-39-22" morph="none" pos="word" start_char="4096">Dr</TOKEN>
<TOKEN end_char="4098" id="token-39-23" morph="none" pos="punct" start_char="4098">.</TOKEN>
</SEG>
<SEG end_char="4124" id="segment-40" start_char="4100">
<ORIGINAL_TEXT>Lau and colleagues write.</ORIGINAL_TEXT>
<TOKEN end_char="4102" id="token-40-0" morph="none" pos="word" start_char="4100">Lau</TOKEN>
<TOKEN end_char="4106" id="token-40-1" morph="none" pos="word" start_char="4104">and</TOKEN>
<TOKEN end_char="4117" id="token-40-2" morph="none" pos="word" start_char="4108">colleagues</TOKEN>
<TOKEN end_char="4123" id="token-40-3" morph="none" pos="word" start_char="4119">write</TOKEN>
<TOKEN end_char="4124" id="token-40-4" morph="none" pos="punct" start_char="4124">.</TOKEN>
</SEG>
<SEG end_char="4296" id="segment-41" start_char="4126">
<ORIGINAL_TEXT>If the Wuhan market were the source, it's possible, they say, that bats carrying the bat coronavirus were mixed in the market, enabling a new combination virus to develop.</ORIGINAL_TEXT>
<TOKEN end_char="4127" id="token-41-0" morph="none" pos="word" start_char="4126">If</TOKEN>
<TOKEN end_char="4131" id="token-41-1" morph="none" pos="word" start_char="4129">the</TOKEN>
<TOKEN end_char="4137" id="token-41-2" morph="none" pos="word" start_char="4133">Wuhan</TOKEN>
<TOKEN end_char="4144" id="token-41-3" morph="none" pos="word" start_char="4139">market</TOKEN>
<TOKEN end_char="4149" id="token-41-4" morph="none" pos="word" start_char="4146">were</TOKEN>
<TOKEN end_char="4153" id="token-41-5" morph="none" pos="word" start_char="4151">the</TOKEN>
<TOKEN end_char="4160" id="token-41-6" morph="none" pos="word" start_char="4155">source</TOKEN>
<TOKEN end_char="4161" id="token-41-7" morph="none" pos="punct" start_char="4161">,</TOKEN>
<TOKEN end_char="4166" id="token-41-8" morph="none" pos="word" start_char="4163">it's</TOKEN>
<TOKEN end_char="4175" id="token-41-9" morph="none" pos="word" start_char="4168">possible</TOKEN>
<TOKEN end_char="4176" id="token-41-10" morph="none" pos="punct" start_char="4176">,</TOKEN>
<TOKEN end_char="4181" id="token-41-11" morph="none" pos="word" start_char="4178">they</TOKEN>
<TOKEN end_char="4185" id="token-41-12" morph="none" pos="word" start_char="4183">say</TOKEN>
<TOKEN end_char="4186" id="token-41-13" morph="none" pos="punct" start_char="4186">,</TOKEN>
<TOKEN end_char="4191" id="token-41-14" morph="none" pos="word" start_char="4188">that</TOKEN>
<TOKEN end_char="4196" id="token-41-15" morph="none" pos="word" start_char="4193">bats</TOKEN>
<TOKEN end_char="4205" id="token-41-16" morph="none" pos="word" start_char="4198">carrying</TOKEN>
<TOKEN end_char="4209" id="token-41-17" morph="none" pos="word" start_char="4207">the</TOKEN>
<TOKEN end_char="4213" id="token-41-18" morph="none" pos="word" start_char="4211">bat</TOKEN>
<TOKEN end_char="4225" id="token-41-19" morph="none" pos="word" start_char="4215">coronavirus</TOKEN>
<TOKEN end_char="4230" id="token-41-20" morph="none" pos="word" start_char="4227">were</TOKEN>
<TOKEN end_char="4236" id="token-41-21" morph="none" pos="word" start_char="4232">mixed</TOKEN>
<TOKEN end_char="4239" id="token-41-22" morph="none" pos="word" start_char="4238">in</TOKEN>
<TOKEN end_char="4243" id="token-41-23" morph="none" pos="word" start_char="4241">the</TOKEN>
<TOKEN end_char="4250" id="token-41-24" morph="none" pos="word" start_char="4245">market</TOKEN>
<TOKEN end_char="4251" id="token-41-25" morph="none" pos="punct" start_char="4251">,</TOKEN>
<TOKEN end_char="4260" id="token-41-26" morph="none" pos="word" start_char="4253">enabling</TOKEN>
<TOKEN end_char="4262" id="token-41-27" morph="none" pos="word" start_char="4262">a</TOKEN>
<TOKEN end_char="4266" id="token-41-28" morph="none" pos="word" start_char="4264">new</TOKEN>
<TOKEN end_char="4278" id="token-41-29" morph="none" pos="word" start_char="4268">combination</TOKEN>
<TOKEN end_char="4284" id="token-41-30" morph="none" pos="word" start_char="4280">virus</TOKEN>
<TOKEN end_char="4287" id="token-41-31" morph="none" pos="word" start_char="4286">to</TOKEN>
<TOKEN end_char="4295" id="token-41-32" morph="none" pos="word" start_char="4289">develop</TOKEN>
<TOKEN end_char="4296" id="token-41-33" morph="none" pos="punct" start_char="4296">.</TOKEN>
</SEG>
<SEG end_char="4392" id="segment-42" start_char="4298">
<ORIGINAL_TEXT>"However, no animal samples from the market were reported to be positive," the team points out.</ORIGINAL_TEXT>
<TOKEN end_char="4298" id="token-42-0" morph="none" pos="punct" start_char="4298">"</TOKEN>
<TOKEN end_char="4305" id="token-42-1" morph="none" pos="word" start_char="4299">However</TOKEN>
<TOKEN end_char="4306" id="token-42-2" morph="none" pos="punct" start_char="4306">,</TOKEN>
<TOKEN end_char="4309" id="token-42-3" morph="none" pos="word" start_char="4308">no</TOKEN>
<TOKEN end_char="4316" id="token-42-4" morph="none" pos="word" start_char="4311">animal</TOKEN>
<TOKEN end_char="4324" id="token-42-5" morph="none" pos="word" start_char="4318">samples</TOKEN>
<TOKEN end_char="4329" id="token-42-6" morph="none" pos="word" start_char="4326">from</TOKEN>
<TOKEN end_char="4333" id="token-42-7" morph="none" pos="word" start_char="4331">the</TOKEN>
<TOKEN end_char="4340" id="token-42-8" morph="none" pos="word" start_char="4335">market</TOKEN>
<TOKEN end_char="4345" id="token-42-9" morph="none" pos="word" start_char="4342">were</TOKEN>
<TOKEN end_char="4354" id="token-42-10" morph="none" pos="word" start_char="4347">reported</TOKEN>
<TOKEN end_char="4357" id="token-42-11" morph="none" pos="word" start_char="4356">to</TOKEN>
<TOKEN end_char="4360" id="token-42-12" morph="none" pos="word" start_char="4359">be</TOKEN>
<TOKEN end_char="4369" id="token-42-13" morph="none" pos="word" start_char="4362">positive</TOKEN>
<TOKEN end_char="4371" id="token-42-14" morph="none" pos="punct" start_char="4370">,"</TOKEN>
<TOKEN end_char="4375" id="token-42-15" morph="none" pos="word" start_char="4373">the</TOKEN>
<TOKEN end_char="4380" id="token-42-16" morph="none" pos="word" start_char="4377">team</TOKEN>
<TOKEN end_char="4387" id="token-42-17" morph="none" pos="word" start_char="4382">points</TOKEN>
<TOKEN end_char="4391" id="token-42-18" morph="none" pos="word" start_char="4389">out</TOKEN>
<TOKEN end_char="4392" id="token-42-19" morph="none" pos="punct" start_char="4392">.</TOKEN>
</SEG>
<SEG end_char="4554" id="segment-43" start_char="4394">
<ORIGINAL_TEXT>What's more, neither the first identified case in a human nor other early patients had visited the market, "suggesting the possibility of an alternative source."</ORIGINAL_TEXT>
<TOKEN end_char="4399" id="token-43-0" morph="none" pos="word" start_char="4394">What's</TOKEN>
<TOKEN end_char="4404" id="token-43-1" morph="none" pos="word" start_char="4401">more</TOKEN>
<TOKEN end_char="4405" id="token-43-2" morph="none" pos="punct" start_char="4405">,</TOKEN>
<TOKEN end_char="4413" id="token-43-3" morph="none" pos="word" start_char="4407">neither</TOKEN>
<TOKEN end_char="4417" id="token-43-4" morph="none" pos="word" start_char="4415">the</TOKEN>
<TOKEN end_char="4423" id="token-43-5" morph="none" pos="word" start_char="4419">first</TOKEN>
<TOKEN end_char="4434" id="token-43-6" morph="none" pos="word" start_char="4425">identified</TOKEN>
<TOKEN end_char="4439" id="token-43-7" morph="none" pos="word" start_char="4436">case</TOKEN>
<TOKEN end_char="4442" id="token-43-8" morph="none" pos="word" start_char="4441">in</TOKEN>
<TOKEN end_char="4444" id="token-43-9" morph="none" pos="word" start_char="4444">a</TOKEN>
<TOKEN end_char="4450" id="token-43-10" morph="none" pos="word" start_char="4446">human</TOKEN>
<TOKEN end_char="4454" id="token-43-11" morph="none" pos="word" start_char="4452">nor</TOKEN>
<TOKEN end_char="4460" id="token-43-12" morph="none" pos="word" start_char="4456">other</TOKEN>
<TOKEN end_char="4466" id="token-43-13" morph="none" pos="word" start_char="4462">early</TOKEN>
<TOKEN end_char="4475" id="token-43-14" morph="none" pos="word" start_char="4468">patients</TOKEN>
<TOKEN end_char="4479" id="token-43-15" morph="none" pos="word" start_char="4477">had</TOKEN>
<TOKEN end_char="4487" id="token-43-16" morph="none" pos="word" start_char="4481">visited</TOKEN>
<TOKEN end_char="4491" id="token-43-17" morph="none" pos="word" start_char="4489">the</TOKEN>
<TOKEN end_char="4498" id="token-43-18" morph="none" pos="word" start_char="4493">market</TOKEN>
<TOKEN end_char="4499" id="token-43-19" morph="none" pos="punct" start_char="4499">,</TOKEN>
<TOKEN end_char="4501" id="token-43-20" morph="none" pos="punct" start_char="4501">"</TOKEN>
<TOKEN end_char="4511" id="token-43-21" morph="none" pos="word" start_char="4502">suggesting</TOKEN>
<TOKEN end_char="4515" id="token-43-22" morph="none" pos="word" start_char="4513">the</TOKEN>
<TOKEN end_char="4527" id="token-43-23" morph="none" pos="word" start_char="4517">possibility</TOKEN>
<TOKEN end_char="4530" id="token-43-24" morph="none" pos="word" start_char="4529">of</TOKEN>
<TOKEN end_char="4533" id="token-43-25" morph="none" pos="word" start_char="4532">an</TOKEN>
<TOKEN end_char="4545" id="token-43-26" morph="none" pos="word" start_char="4535">alternative</TOKEN>
<TOKEN end_char="4552" id="token-43-27" morph="none" pos="word" start_char="4547">source</TOKEN>
<TOKEN end_char="4554" id="token-43-28" morph="none" pos="punct" start_char="4553">."</TOKEN>
</SEG>
<SEG end_char="4559" id="segment-44" start_char="4557">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN end_char="4558" id="token-44-0" morph="none" pos="word" start_char="4557">Dr</TOKEN>
<TOKEN end_char="4559" id="token-44-1" morph="none" pos="punct" start_char="4559">.</TOKEN>
<TRANSLATED_TEXT>dr.</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="4635" id="segment-45" start_char="4561">
<ORIGINAL_TEXT>Lau and colleagues' study, released ahead of publication in the CDC journal</ORIGINAL_TEXT>
<TOKEN end_char="4563" id="token-45-0" morph="none" pos="word" start_char="4561">Lau</TOKEN>
<TOKEN end_char="4567" id="token-45-1" morph="none" pos="word" start_char="4565">and</TOKEN>
<TOKEN end_char="4578" id="token-45-2" morph="none" pos="word" start_char="4569">colleagues</TOKEN>
<TOKEN end_char="4579" id="token-45-3" morph="none" pos="punct" start_char="4579">'</TOKEN>
<TOKEN end_char="4585" id="token-45-4" morph="none" pos="word" start_char="4581">study</TOKEN>
<TOKEN end_char="4586" id="token-45-5" morph="none" pos="punct" start_char="4586">,</TOKEN>
<TOKEN end_char="4595" id="token-45-6" morph="none" pos="word" start_char="4588">released</TOKEN>
<TOKEN end_char="4601" id="token-45-7" morph="none" pos="word" start_char="4597">ahead</TOKEN>
<TOKEN end_char="4604" id="token-45-8" morph="none" pos="word" start_char="4603">of</TOKEN>
<TOKEN end_char="4616" id="token-45-9" morph="none" pos="word" start_char="4606">publication</TOKEN>
<TOKEN end_char="4619" id="token-45-10" morph="none" pos="word" start_char="4618">in</TOKEN>
<TOKEN end_char="4623" id="token-45-11" morph="none" pos="word" start_char="4621">the</TOKEN>
<TOKEN end_char="4627" id="token-45-12" morph="none" pos="word" start_char="4625">CDC</TOKEN>
<TOKEN end_char="4635" id="token-45-13" morph="none" pos="word" start_char="4629">journal</TOKEN>
</SEG>
<SEG end_char="4665" id="segment-46" start_char="4638">
<ORIGINAL_TEXT>Emerging Infectious Diseases</ORIGINAL_TEXT>
<TOKEN end_char="4645" id="token-46-0" morph="none" pos="word" start_char="4638">Emerging</TOKEN>
<TOKEN end_char="4656" id="token-46-1" morph="none" pos="word" start_char="4647">Infectious</TOKEN>
<TOKEN end_char="4665" id="token-46-2" morph="none" pos="word" start_char="4658">Diseases</TOKEN>
</SEG>
<SEG end_char="4846" id="segment-47" start_char="4668">
<ORIGINAL_TEXT>, also throws cold water on an Internet rumor that the virus may have been created in a lab: "there is currently no evidence showing that SARS-CoV-2 is an artificial recombinant."</ORIGINAL_TEXT>
<TOKEN end_char="4668" id="token-47-0" morph="none" pos="punct" start_char="4668">,</TOKEN>
<TOKEN end_char="4673" id="token-47-1" morph="none" pos="word" start_char="4670">also</TOKEN>
<TOKEN end_char="4680" id="token-47-2" morph="none" pos="word" start_char="4675">throws</TOKEN>
<TOKEN end_char="4685" id="token-47-3" morph="none" pos="word" start_char="4682">cold</TOKEN>
<TOKEN end_char="4691" id="token-47-4" morph="none" pos="word" start_char="4687">water</TOKEN>
<TOKEN end_char="4694" id="token-47-5" morph="none" pos="word" start_char="4693">on</TOKEN>
<TOKEN end_char="4697" id="token-47-6" morph="none" pos="word" start_char="4696">an</TOKEN>
<TOKEN end_char="4706" id="token-47-7" morph="none" pos="word" start_char="4699">Internet</TOKEN>
<TOKEN end_char="4712" id="token-47-8" morph="none" pos="word" start_char="4708">rumor</TOKEN>
<TOKEN end_char="4717" id="token-47-9" morph="none" pos="word" start_char="4714">that</TOKEN>
<TOKEN end_char="4721" id="token-47-10" morph="none" pos="word" start_char="4719">the</TOKEN>
<TOKEN end_char="4727" id="token-47-11" morph="none" pos="word" start_char="4723">virus</TOKEN>
<TOKEN end_char="4731" id="token-47-12" morph="none" pos="word" start_char="4729">may</TOKEN>
<TOKEN end_char="4736" id="token-47-13" morph="none" pos="word" start_char="4733">have</TOKEN>
<TOKEN end_char="4741" id="token-47-14" morph="none" pos="word" start_char="4738">been</TOKEN>
<TOKEN end_char="4749" id="token-47-15" morph="none" pos="word" start_char="4743">created</TOKEN>
<TOKEN end_char="4752" id="token-47-16" morph="none" pos="word" start_char="4751">in</TOKEN>
<TOKEN end_char="4754" id="token-47-17" morph="none" pos="word" start_char="4754">a</TOKEN>
<TOKEN end_char="4758" id="token-47-18" morph="none" pos="word" start_char="4756">lab</TOKEN>
<TOKEN end_char="4759" id="token-47-19" morph="none" pos="punct" start_char="4759">:</TOKEN>
<TOKEN end_char="4761" id="token-47-20" morph="none" pos="punct" start_char="4761">"</TOKEN>
<TOKEN end_char="4766" id="token-47-21" morph="none" pos="word" start_char="4762">there</TOKEN>
<TOKEN end_char="4769" id="token-47-22" morph="none" pos="word" start_char="4768">is</TOKEN>
<TOKEN end_char="4779" id="token-47-23" morph="none" pos="word" start_char="4771">currently</TOKEN>
<TOKEN end_char="4782" id="token-47-24" morph="none" pos="word" start_char="4781">no</TOKEN>
<TOKEN end_char="4791" id="token-47-25" morph="none" pos="word" start_char="4784">evidence</TOKEN>
<TOKEN end_char="4799" id="token-47-26" morph="none" pos="word" start_char="4793">showing</TOKEN>
<TOKEN end_char="4804" id="token-47-27" morph="none" pos="word" start_char="4801">that</TOKEN>
<TOKEN end_char="4815" id="token-47-28" morph="none" pos="unknown" start_char="4806">SARS-CoV-2</TOKEN>
<TOKEN end_char="4818" id="token-47-29" morph="none" pos="word" start_char="4817">is</TOKEN>
<TOKEN end_char="4821" id="token-47-30" morph="none" pos="word" start_char="4820">an</TOKEN>
<TOKEN end_char="4832" id="token-47-31" morph="none" pos="word" start_char="4823">artificial</TOKEN>
<TOKEN end_char="4844" id="token-47-32" morph="none" pos="word" start_char="4834">recombinant</TOKEN>
<TOKEN end_char="4846" id="token-47-33" morph="none" pos="punct" start_char="4845">."</TOKEN>
</SEG>
<SEG end_char="4871" id="segment-48" start_char="4849">
<ORIGINAL_TEXT>Another recent paper in</ORIGINAL_TEXT>
<TOKEN end_char="4855" id="token-48-0" morph="none" pos="word" start_char="4849">Another</TOKEN>
<TOKEN end_char="4862" id="token-48-1" morph="none" pos="word" start_char="4857">recent</TOKEN>
<TOKEN end_char="4868" id="token-48-2" morph="none" pos="word" start_char="4864">paper</TOKEN>
<TOKEN end_char="4871" id="token-48-3" morph="none" pos="word" start_char="4870">in</TOKEN>
</SEG>
<SEG end_char="4888" id="segment-49" start_char="4874">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN end_char="4879" id="token-49-0" morph="none" pos="word" start_char="4874">Nature</TOKEN>
<TOKEN end_char="4888" id="token-49-1" morph="none" pos="word" start_char="4881">Medicine</TOKEN>
<TRANSLATED_TEXT>Naturmedicin</TRANSLATED_TEXT><DETECTED_LANGUAGE>ro</DETECTED_LANGUAGE></SEG>
<SEG end_char="4913" id="segment-50" start_char="4891">
<ORIGINAL_TEXT>underscores that point.</ORIGINAL_TEXT>
<TOKEN end_char="4901" id="token-50-0" morph="none" pos="word" start_char="4891">underscores</TOKEN>
<TOKEN end_char="4906" id="token-50-1" morph="none" pos="word" start_char="4903">that</TOKEN>
<TOKEN end_char="4912" id="token-50-2" morph="none" pos="word" start_char="4908">point</TOKEN>
<TOKEN end_char="4913" id="token-50-3" morph="none" pos="punct" start_char="4913">.</TOKEN>
</SEG>
<SEG end_char="5230" id="segment-51" start_char="4915">
<ORIGINAL_TEXT>"By comparing the available genome sequence data for known coronavirus strains, we can firmly determine that SARS-CoV-2 originated through natural processes," Kristian Andersen, PhD, an associate professor of immunology and microbiology at Scripps Research and corresponding author on the paper, said in a statement.</ORIGINAL_TEXT>
<TOKEN end_char="4915" id="token-51-0" morph="none" pos="punct" start_char="4915">"</TOKEN>
<TOKEN end_char="4917" id="token-51-1" morph="none" pos="word" start_char="4916">By</TOKEN>
<TOKEN end_char="4927" id="token-51-2" morph="none" pos="word" start_char="4919">comparing</TOKEN>
<TOKEN end_char="4931" id="token-51-3" morph="none" pos="word" start_char="4929">the</TOKEN>
<TOKEN end_char="4941" id="token-51-4" morph="none" pos="word" start_char="4933">available</TOKEN>
<TOKEN end_char="4948" id="token-51-5" morph="none" pos="word" start_char="4943">genome</TOKEN>
<TOKEN end_char="4957" id="token-51-6" morph="none" pos="word" start_char="4950">sequence</TOKEN>
<TOKEN end_char="4962" id="token-51-7" morph="none" pos="word" start_char="4959">data</TOKEN>
<TOKEN end_char="4966" id="token-51-8" morph="none" pos="word" start_char="4964">for</TOKEN>
<TOKEN end_char="4972" id="token-51-9" morph="none" pos="word" start_char="4968">known</TOKEN>
<TOKEN end_char="4984" id="token-51-10" morph="none" pos="word" start_char="4974">coronavirus</TOKEN>
<TOKEN end_char="4992" id="token-51-11" morph="none" pos="word" start_char="4986">strains</TOKEN>
<TOKEN end_char="4993" id="token-51-12" morph="none" pos="punct" start_char="4993">,</TOKEN>
<TOKEN end_char="4996" id="token-51-13" morph="none" pos="word" start_char="4995">we</TOKEN>
<TOKEN end_char="5000" id="token-51-14" morph="none" pos="word" start_char="4998">can</TOKEN>
<TOKEN end_char="5007" id="token-51-15" morph="none" pos="word" start_char="5002">firmly</TOKEN>
<TOKEN end_char="5017" id="token-51-16" morph="none" pos="word" start_char="5009">determine</TOKEN>
<TOKEN end_char="5022" id="token-51-17" morph="none" pos="word" start_char="5019">that</TOKEN>
<TOKEN end_char="5033" id="token-51-18" morph="none" pos="unknown" start_char="5024">SARS-CoV-2</TOKEN>
<TOKEN end_char="5044" id="token-51-19" morph="none" pos="word" start_char="5035">originated</TOKEN>
<TOKEN end_char="5052" id="token-51-20" morph="none" pos="word" start_char="5046">through</TOKEN>
<TOKEN end_char="5060" id="token-51-21" morph="none" pos="word" start_char="5054">natural</TOKEN>
<TOKEN end_char="5070" id="token-51-22" morph="none" pos="word" start_char="5062">processes</TOKEN>
<TOKEN end_char="5072" id="token-51-23" morph="none" pos="punct" start_char="5071">,"</TOKEN>
<TOKEN end_char="5081" id="token-51-24" morph="none" pos="word" start_char="5074">Kristian</TOKEN>
<TOKEN end_char="5090" id="token-51-25" morph="none" pos="word" start_char="5083">Andersen</TOKEN>
<TOKEN end_char="5091" id="token-51-26" morph="none" pos="punct" start_char="5091">,</TOKEN>
<TOKEN end_char="5095" id="token-51-27" morph="none" pos="word" start_char="5093">PhD</TOKEN>
<TOKEN end_char="5096" id="token-51-28" morph="none" pos="punct" start_char="5096">,</TOKEN>
<TOKEN end_char="5099" id="token-51-29" morph="none" pos="word" start_char="5098">an</TOKEN>
<TOKEN end_char="5109" id="token-51-30" morph="none" pos="word" start_char="5101">associate</TOKEN>
<TOKEN end_char="5119" id="token-51-31" morph="none" pos="word" start_char="5111">professor</TOKEN>
<TOKEN end_char="5122" id="token-51-32" morph="none" pos="word" start_char="5121">of</TOKEN>
<TOKEN end_char="5133" id="token-51-33" morph="none" pos="word" start_char="5124">immunology</TOKEN>
<TOKEN end_char="5137" id="token-51-34" morph="none" pos="word" start_char="5135">and</TOKEN>
<TOKEN end_char="5150" id="token-51-35" morph="none" pos="word" start_char="5139">microbiology</TOKEN>
<TOKEN end_char="5153" id="token-51-36" morph="none" pos="word" start_char="5152">at</TOKEN>
<TOKEN end_char="5161" id="token-51-37" morph="none" pos="word" start_char="5155">Scripps</TOKEN>
<TOKEN end_char="5170" id="token-51-38" morph="none" pos="word" start_char="5163">Research</TOKEN>
<TOKEN end_char="5174" id="token-51-39" morph="none" pos="word" start_char="5172">and</TOKEN>
<TOKEN end_char="5188" id="token-51-40" morph="none" pos="word" start_char="5176">corresponding</TOKEN>
<TOKEN end_char="5195" id="token-51-41" morph="none" pos="word" start_char="5190">author</TOKEN>
<TOKEN end_char="5198" id="token-51-42" morph="none" pos="word" start_char="5197">on</TOKEN>
<TOKEN end_char="5202" id="token-51-43" morph="none" pos="word" start_char="5200">the</TOKEN>
<TOKEN end_char="5208" id="token-51-44" morph="none" pos="word" start_char="5204">paper</TOKEN>
<TOKEN end_char="5209" id="token-51-45" morph="none" pos="punct" start_char="5209">,</TOKEN>
<TOKEN end_char="5214" id="token-51-46" morph="none" pos="word" start_char="5211">said</TOKEN>
<TOKEN end_char="5217" id="token-51-47" morph="none" pos="word" start_char="5216">in</TOKEN>
<TOKEN end_char="5219" id="token-51-48" morph="none" pos="word" start_char="5219">a</TOKEN>
<TOKEN end_char="5229" id="token-51-49" morph="none" pos="word" start_char="5221">statement</TOKEN>
<TOKEN end_char="5230" id="token-51-50" morph="none" pos="punct" start_char="5230">.</TOKEN>
</SEG>
<SEG end_char="5304" id="segment-52" start_char="5232">
<ORIGINAL_TEXT>Andersen and colleagues' research implicates bats and possibly pangolins.</ORIGINAL_TEXT>
<TOKEN end_char="5239" id="token-52-0" morph="none" pos="word" start_char="5232">Andersen</TOKEN>
<TOKEN end_char="5243" id="token-52-1" morph="none" pos="word" start_char="5241">and</TOKEN>
<TOKEN end_char="5254" id="token-52-2" morph="none" pos="word" start_char="5245">colleagues</TOKEN>
<TOKEN end_char="5255" id="token-52-3" morph="none" pos="punct" start_char="5255">'</TOKEN>
<TOKEN end_char="5264" id="token-52-4" morph="none" pos="word" start_char="5257">research</TOKEN>
<TOKEN end_char="5275" id="token-52-5" morph="none" pos="word" start_char="5266">implicates</TOKEN>
<TOKEN end_char="5280" id="token-52-6" morph="none" pos="word" start_char="5277">bats</TOKEN>
<TOKEN end_char="5284" id="token-52-7" morph="none" pos="word" start_char="5282">and</TOKEN>
<TOKEN end_char="5293" id="token-52-8" morph="none" pos="word" start_char="5286">possibly</TOKEN>
<TOKEN end_char="5303" id="token-52-9" morph="none" pos="word" start_char="5295">pangolins</TOKEN>
<TOKEN end_char="5304" id="token-52-10" morph="none" pos="punct" start_char="5304">.</TOKEN>
</SEG>
<SEG end_char="5371" id="segment-53" start_char="5307">
<ORIGINAL_TEXT>Overall, the origin of the novel coronavirus is still filled with</ORIGINAL_TEXT>
<TOKEN end_char="5313" id="token-53-0" morph="none" pos="word" start_char="5307">Overall</TOKEN>
<TOKEN end_char="5314" id="token-53-1" morph="none" pos="punct" start_char="5314">,</TOKEN>
<TOKEN end_char="5318" id="token-53-2" morph="none" pos="word" start_char="5316">the</TOKEN>
<TOKEN end_char="5325" id="token-53-3" morph="none" pos="word" start_char="5320">origin</TOKEN>
<TOKEN end_char="5328" id="token-53-4" morph="none" pos="word" start_char="5327">of</TOKEN>
<TOKEN end_char="5332" id="token-53-5" morph="none" pos="word" start_char="5330">the</TOKEN>
<TOKEN end_char="5338" id="token-53-6" morph="none" pos="word" start_char="5334">novel</TOKEN>
<TOKEN end_char="5350" id="token-53-7" morph="none" pos="word" start_char="5340">coronavirus</TOKEN>
<TOKEN end_char="5353" id="token-53-8" morph="none" pos="word" start_char="5352">is</TOKEN>
<TOKEN end_char="5359" id="token-53-9" morph="none" pos="word" start_char="5355">still</TOKEN>
<TOKEN end_char="5366" id="token-53-10" morph="none" pos="word" start_char="5361">filled</TOKEN>
<TOKEN end_char="5371" id="token-53-11" morph="none" pos="word" start_char="5368">with</TOKEN>
</SEG>
<SEG end_char="5381" id="segment-54" start_char="5374">
<ORIGINAL_TEXT>what-ifs</ORIGINAL_TEXT>
<TOKEN end_char="5381" id="token-54-0" morph="none" pos="unknown" start_char="5374">what-ifs</TOKEN>
</SEG>
<SEG end_char="5386" id="segment-55" start_char="5384">
<ORIGINAL_TEXT>and</ORIGINAL_TEXT>
<TOKEN end_char="5386" id="token-55-0" morph="none" pos="word" start_char="5384">and</TOKEN>
</SEG>
<SEG end_char="5394" id="segment-56" start_char="5389">
<ORIGINAL_TEXT>maybes</ORIGINAL_TEXT>
<TOKEN end_char="5394" id="token-56-0" morph="none" pos="word" start_char="5389">maybes</TOKEN>
<TRANSLATED_TEXT>Maybes</TRANSLATED_TEXT><DETECTED_LANGUAGE>tl</DETECTED_LANGUAGE></SEG>
<SEG end_char="5549" id="segment-57" start_char="5397">
<ORIGINAL_TEXT>, but even if bats are partly to blame, the likelihood that "bat soup" played a role is just an extremely misinformed (and potentially xenophobic) rumor.</ORIGINAL_TEXT>
<TOKEN end_char="5397" id="token-57-0" morph="none" pos="punct" start_char="5397">,</TOKEN>
<TOKEN end_char="5401" id="token-57-1" morph="none" pos="word" start_char="5399">but</TOKEN>
<TOKEN end_char="5406" id="token-57-2" morph="none" pos="word" start_char="5403">even</TOKEN>
<TOKEN end_char="5409" id="token-57-3" morph="none" pos="word" start_char="5408">if</TOKEN>
<TOKEN end_char="5414" id="token-57-4" morph="none" pos="word" start_char="5411">bats</TOKEN>
<TOKEN end_char="5418" id="token-57-5" morph="none" pos="word" start_char="5416">are</TOKEN>
<TOKEN end_char="5425" id="token-57-6" morph="none" pos="word" start_char="5420">partly</TOKEN>
<TOKEN end_char="5428" id="token-57-7" morph="none" pos="word" start_char="5427">to</TOKEN>
<TOKEN end_char="5434" id="token-57-8" morph="none" pos="word" start_char="5430">blame</TOKEN>
<TOKEN end_char="5435" id="token-57-9" morph="none" pos="punct" start_char="5435">,</TOKEN>
<TOKEN end_char="5439" id="token-57-10" morph="none" pos="word" start_char="5437">the</TOKEN>
<TOKEN end_char="5450" id="token-57-11" morph="none" pos="word" start_char="5441">likelihood</TOKEN>
<TOKEN end_char="5455" id="token-57-12" morph="none" pos="word" start_char="5452">that</TOKEN>
<TOKEN end_char="5457" id="token-57-13" morph="none" pos="punct" start_char="5457">"</TOKEN>
<TOKEN end_char="5460" id="token-57-14" morph="none" pos="word" start_char="5458">bat</TOKEN>
<TOKEN end_char="5465" id="token-57-15" morph="none" pos="word" start_char="5462">soup</TOKEN>
<TOKEN end_char="5466" id="token-57-16" morph="none" pos="punct" start_char="5466">"</TOKEN>
<TOKEN end_char="5473" id="token-57-17" morph="none" pos="word" start_char="5468">played</TOKEN>
<TOKEN end_char="5475" id="token-57-18" morph="none" pos="word" start_char="5475">a</TOKEN>
<TOKEN end_char="5480" id="token-57-19" morph="none" pos="word" start_char="5477">role</TOKEN>
<TOKEN end_char="5483" id="token-57-20" morph="none" pos="word" start_char="5482">is</TOKEN>
<TOKEN end_char="5488" id="token-57-21" morph="none" pos="word" start_char="5485">just</TOKEN>
<TOKEN end_char="5491" id="token-57-22" morph="none" pos="word" start_char="5490">an</TOKEN>
<TOKEN end_char="5501" id="token-57-23" morph="none" pos="word" start_char="5493">extremely</TOKEN>
<TOKEN end_char="5513" id="token-57-24" morph="none" pos="word" start_char="5503">misinformed</TOKEN>
<TOKEN end_char="5515" id="token-57-25" morph="none" pos="punct" start_char="5515">(</TOKEN>
<TOKEN end_char="5518" id="token-57-26" morph="none" pos="word" start_char="5516">and</TOKEN>
<TOKEN end_char="5530" id="token-57-27" morph="none" pos="word" start_char="5520">potentially</TOKEN>
<TOKEN end_char="5541" id="token-57-28" morph="none" pos="word" start_char="5532">xenophobic</TOKEN>
<TOKEN end_char="5542" id="token-57-29" morph="none" pos="punct" start_char="5542">)</TOKEN>
<TOKEN end_char="5548" id="token-57-30" morph="none" pos="word" start_char="5544">rumor</TOKEN>
<TOKEN end_char="5549" id="token-57-31" morph="none" pos="punct" start_char="5549">.</TOKEN>
</SEG>
<SEG end_char="5610" id="segment-58" start_char="5552">
<ORIGINAL_TEXT>The information in this story is accurate as of press time.</ORIGINAL_TEXT>
<TOKEN end_char="5554" id="token-58-0" morph="none" pos="word" start_char="5552">The</TOKEN>
<TOKEN end_char="5566" id="token-58-1" morph="none" pos="word" start_char="5556">information</TOKEN>
<TOKEN end_char="5569" id="token-58-2" morph="none" pos="word" start_char="5568">in</TOKEN>
<TOKEN end_char="5574" id="token-58-3" morph="none" pos="word" start_char="5571">this</TOKEN>
<TOKEN end_char="5580" id="token-58-4" morph="none" pos="word" start_char="5576">story</TOKEN>
<TOKEN end_char="5583" id="token-58-5" morph="none" pos="word" start_char="5582">is</TOKEN>
<TOKEN end_char="5592" id="token-58-6" morph="none" pos="word" start_char="5585">accurate</TOKEN>
<TOKEN end_char="5595" id="token-58-7" morph="none" pos="word" start_char="5594">as</TOKEN>
<TOKEN end_char="5598" id="token-58-8" morph="none" pos="word" start_char="5597">of</TOKEN>
<TOKEN end_char="5604" id="token-58-9" morph="none" pos="word" start_char="5600">press</TOKEN>
<TOKEN end_char="5609" id="token-58-10" morph="none" pos="word" start_char="5606">time</TOKEN>
<TOKEN end_char="5610" id="token-58-11" morph="none" pos="punct" start_char="5610">.</TOKEN>
</SEG>
<SEG end_char="5739" id="segment-59" start_char="5612">
<ORIGINAL_TEXT>However, as the situation surrounding COVID-19 continues to evolve, it's possible that some data have changed since publication.</ORIGINAL_TEXT>
<TOKEN end_char="5618" id="token-59-0" morph="none" pos="word" start_char="5612">However</TOKEN>
<TOKEN end_char="5619" id="token-59-1" morph="none" pos="punct" start_char="5619">,</TOKEN>
<TOKEN end_char="5622" id="token-59-2" morph="none" pos="word" start_char="5621">as</TOKEN>
<TOKEN end_char="5626" id="token-59-3" morph="none" pos="word" start_char="5624">the</TOKEN>
<TOKEN end_char="5636" id="token-59-4" morph="none" pos="word" start_char="5628">situation</TOKEN>
<TOKEN end_char="5648" id="token-59-5" morph="none" pos="word" start_char="5638">surrounding</TOKEN>
<TOKEN end_char="5657" id="token-59-6" morph="none" pos="unknown" start_char="5650">COVID-19</TOKEN>
<TOKEN end_char="5667" id="token-59-7" morph="none" pos="word" start_char="5659">continues</TOKEN>
<TOKEN end_char="5670" id="token-59-8" morph="none" pos="word" start_char="5669">to</TOKEN>
<TOKEN end_char="5677" id="token-59-9" morph="none" pos="word" start_char="5672">evolve</TOKEN>
<TOKEN end_char="5678" id="token-59-10" morph="none" pos="punct" start_char="5678">,</TOKEN>
<TOKEN end_char="5683" id="token-59-11" morph="none" pos="word" start_char="5680">it's</TOKEN>
<TOKEN end_char="5692" id="token-59-12" morph="none" pos="word" start_char="5685">possible</TOKEN>
<TOKEN end_char="5697" id="token-59-13" morph="none" pos="word" start_char="5694">that</TOKEN>
<TOKEN end_char="5702" id="token-59-14" morph="none" pos="word" start_char="5699">some</TOKEN>
<TOKEN end_char="5707" id="token-59-15" morph="none" pos="word" start_char="5704">data</TOKEN>
<TOKEN end_char="5712" id="token-59-16" morph="none" pos="word" start_char="5709">have</TOKEN>
<TOKEN end_char="5720" id="token-59-17" morph="none" pos="word" start_char="5714">changed</TOKEN>
<TOKEN end_char="5726" id="token-59-18" morph="none" pos="word" start_char="5722">since</TOKEN>
<TOKEN end_char="5738" id="token-59-19" morph="none" pos="word" start_char="5728">publication</TOKEN>
<TOKEN end_char="5739" id="token-59-20" morph="none" pos="punct" start_char="5739">.</TOKEN>
</SEG>
<SEG end_char="5984" id="segment-60" start_char="5741">
<ORIGINAL_TEXT>While Health is trying to keep our stories as up-to-date as possible, we also encourage readers to stay informed on news and recommendations for their own communities by using the CDC, WHO, and their local public health department as resources.</ORIGINAL_TEXT>
<TOKEN end_char="5745" id="token-60-0" morph="none" pos="word" start_char="5741">While</TOKEN>
<TOKEN end_char="5752" id="token-60-1" morph="none" pos="word" start_char="5747">Health</TOKEN>
<TOKEN end_char="5755" id="token-60-2" morph="none" pos="word" start_char="5754">is</TOKEN>
<TOKEN end_char="5762" id="token-60-3" morph="none" pos="word" start_char="5757">trying</TOKEN>
<TOKEN end_char="5765" id="token-60-4" morph="none" pos="word" start_char="5764">to</TOKEN>
<TOKEN end_char="5770" id="token-60-5" morph="none" pos="word" start_char="5767">keep</TOKEN>
<TOKEN end_char="5774" id="token-60-6" morph="none" pos="word" start_char="5772">our</TOKEN>
<TOKEN end_char="5782" id="token-60-7" morph="none" pos="word" start_char="5776">stories</TOKEN>
<TOKEN end_char="5785" id="token-60-8" morph="none" pos="word" start_char="5784">as</TOKEN>
<TOKEN end_char="5796" id="token-60-9" morph="none" pos="unknown" start_char="5787">up-to-date</TOKEN>
<TOKEN end_char="5799" id="token-60-10" morph="none" pos="word" start_char="5798">as</TOKEN>
<TOKEN end_char="5808" id="token-60-11" morph="none" pos="word" start_char="5801">possible</TOKEN>
<TOKEN end_char="5809" id="token-60-12" morph="none" pos="punct" start_char="5809">,</TOKEN>
<TOKEN end_char="5812" id="token-60-13" morph="none" pos="word" start_char="5811">we</TOKEN>
<TOKEN end_char="5817" id="token-60-14" morph="none" pos="word" start_char="5814">also</TOKEN>
<TOKEN end_char="5827" id="token-60-15" morph="none" pos="word" start_char="5819">encourage</TOKEN>
<TOKEN end_char="5835" id="token-60-16" morph="none" pos="word" start_char="5829">readers</TOKEN>
<TOKEN end_char="5838" id="token-60-17" morph="none" pos="word" start_char="5837">to</TOKEN>
<TOKEN end_char="5843" id="token-60-18" morph="none" pos="word" start_char="5840">stay</TOKEN>
<TOKEN end_char="5852" id="token-60-19" morph="none" pos="word" start_char="5845">informed</TOKEN>
<TOKEN end_char="5855" id="token-60-20" morph="none" pos="word" start_char="5854">on</TOKEN>
<TOKEN end_char="5860" id="token-60-21" morph="none" pos="word" start_char="5857">news</TOKEN>
<TOKEN end_char="5864" id="token-60-22" morph="none" pos="word" start_char="5862">and</TOKEN>
<TOKEN end_char="5880" id="token-60-23" morph="none" pos="word" start_char="5866">recommendations</TOKEN>
<TOKEN end_char="5884" id="token-60-24" morph="none" pos="word" start_char="5882">for</TOKEN>
<TOKEN end_char="5890" id="token-60-25" morph="none" pos="word" start_char="5886">their</TOKEN>
<TOKEN end_char="5894" id="token-60-26" morph="none" pos="word" start_char="5892">own</TOKEN>
<TOKEN end_char="5906" id="token-60-27" morph="none" pos="word" start_char="5896">communities</TOKEN>
<TOKEN end_char="5909" id="token-60-28" morph="none" pos="word" start_char="5908">by</TOKEN>
<TOKEN end_char="5915" id="token-60-29" morph="none" pos="word" start_char="5911">using</TOKEN>
<TOKEN end_char="5919" id="token-60-30" morph="none" pos="word" start_char="5917">the</TOKEN>
<TOKEN end_char="5923" id="token-60-31" morph="none" pos="word" start_char="5921">CDC</TOKEN>
<TOKEN end_char="5924" id="token-60-32" morph="none" pos="punct" start_char="5924">,</TOKEN>
<TOKEN end_char="5928" id="token-60-33" morph="none" pos="word" start_char="5926">WHO</TOKEN>
<TOKEN end_char="5929" id="token-60-34" morph="none" pos="punct" start_char="5929">,</TOKEN>
<TOKEN end_char="5933" id="token-60-35" morph="none" pos="word" start_char="5931">and</TOKEN>
<TOKEN end_char="5939" id="token-60-36" morph="none" pos="word" start_char="5935">their</TOKEN>
<TOKEN end_char="5945" id="token-60-37" morph="none" pos="word" start_char="5941">local</TOKEN>
<TOKEN end_char="5952" id="token-60-38" morph="none" pos="word" start_char="5947">public</TOKEN>
<TOKEN end_char="5959" id="token-60-39" morph="none" pos="word" start_char="5954">health</TOKEN>
<TOKEN end_char="5970" id="token-60-40" morph="none" pos="word" start_char="5961">department</TOKEN>
<TOKEN end_char="5973" id="token-60-41" morph="none" pos="word" start_char="5972">as</TOKEN>
<TOKEN end_char="5983" id="token-60-42" morph="none" pos="word" start_char="5975">resources</TOKEN>
<TOKEN end_char="5984" id="token-60-43" morph="none" pos="punct" start_char="5984">.</TOKEN>
</SEG>
<SEG end_char="6032" id="segment-61" start_char="5988">
<ORIGINAL_TEXT>Quiz: How Much Do You Know About Coronavirus?</ORIGINAL_TEXT>
<TOKEN end_char="5991" id="token-61-0" morph="none" pos="word" start_char="5988">Quiz</TOKEN>
<TOKEN end_char="5992" id="token-61-1" morph="none" pos="punct" start_char="5992">:</TOKEN>
<TOKEN end_char="5996" id="token-61-2" morph="none" pos="word" start_char="5994">How</TOKEN>
<TOKEN end_char="6001" id="token-61-3" morph="none" pos="word" start_char="5998">Much</TOKEN>
<TOKEN end_char="6004" id="token-61-4" morph="none" pos="word" start_char="6003">Do</TOKEN>
<TOKEN end_char="6008" id="token-61-5" morph="none" pos="word" start_char="6006">You</TOKEN>
<TOKEN end_char="6013" id="token-61-6" morph="none" pos="word" start_char="6010">Know</TOKEN>
<TOKEN end_char="6019" id="token-61-7" morph="none" pos="word" start_char="6015">About</TOKEN>
<TOKEN end_char="6031" id="token-61-8" morph="none" pos="word" start_char="6021">Coronavirus</TOKEN>
<TOKEN end_char="6032" id="token-61-9" morph="none" pos="punct" start_char="6032">?</TOKEN>
</SEG>
<SEG end_char="6255" id="segment-62" start_char="6036">
<ORIGINAL_TEXT>News about the novel coronavirus is breaking nearly 24-7, which makes it challenging at best to keep up with the latest scientific evidence, especially when you’re bombarded by false or misleading claims on social media.</ORIGINAL_TEXT>
<TOKEN end_char="6039" id="token-62-0" morph="none" pos="word" start_char="6036">News</TOKEN>
<TOKEN end_char="6045" id="token-62-1" morph="none" pos="word" start_char="6041">about</TOKEN>
<TOKEN end_char="6049" id="token-62-2" morph="none" pos="word" start_char="6047">the</TOKEN>
<TOKEN end_char="6055" id="token-62-3" morph="none" pos="word" start_char="6051">novel</TOKEN>
<TOKEN end_char="6067" id="token-62-4" morph="none" pos="word" start_char="6057">coronavirus</TOKEN>
<TOKEN end_char="6070" id="token-62-5" morph="none" pos="word" start_char="6069">is</TOKEN>
<TOKEN end_char="6079" id="token-62-6" morph="none" pos="word" start_char="6072">breaking</TOKEN>
<TOKEN end_char="6086" id="token-62-7" morph="none" pos="word" start_char="6081">nearly</TOKEN>
<TOKEN end_char="6091" id="token-62-8" morph="none" pos="unknown" start_char="6088">24-7</TOKEN>
<TOKEN end_char="6092" id="token-62-9" morph="none" pos="punct" start_char="6092">,</TOKEN>
<TOKEN end_char="6098" id="token-62-10" morph="none" pos="word" start_char="6094">which</TOKEN>
<TOKEN end_char="6104" id="token-62-11" morph="none" pos="word" start_char="6100">makes</TOKEN>
<TOKEN end_char="6107" id="token-62-12" morph="none" pos="word" start_char="6106">it</TOKEN>
<TOKEN end_char="6119" id="token-62-13" morph="none" pos="word" start_char="6109">challenging</TOKEN>
<TOKEN end_char="6122" id="token-62-14" morph="none" pos="word" start_char="6121">at</TOKEN>
<TOKEN end_char="6127" id="token-62-15" morph="none" pos="word" start_char="6124">best</TOKEN>
<TOKEN end_char="6130" id="token-62-16" morph="none" pos="word" start_char="6129">to</TOKEN>
<TOKEN end_char="6135" id="token-62-17" morph="none" pos="word" start_char="6132">keep</TOKEN>
<TOKEN end_char="6138" id="token-62-18" morph="none" pos="word" start_char="6137">up</TOKEN>
<TOKEN end_char="6143" id="token-62-19" morph="none" pos="word" start_char="6140">with</TOKEN>
<TOKEN end_char="6147" id="token-62-20" morph="none" pos="word" start_char="6145">the</TOKEN>
<TOKEN end_char="6154" id="token-62-21" morph="none" pos="word" start_char="6149">latest</TOKEN>
<TOKEN end_char="6165" id="token-62-22" morph="none" pos="word" start_char="6156">scientific</TOKEN>
<TOKEN end_char="6174" id="token-62-23" morph="none" pos="word" start_char="6167">evidence</TOKEN>
<TOKEN end_char="6175" id="token-62-24" morph="none" pos="punct" start_char="6175">,</TOKEN>
<TOKEN end_char="6186" id="token-62-25" morph="none" pos="word" start_char="6177">especially</TOKEN>
<TOKEN end_char="6191" id="token-62-26" morph="none" pos="word" start_char="6188">when</TOKEN>
<TOKEN end_char="6198" id="token-62-27" morph="none" pos="word" start_char="6193">you’re</TOKEN>
<TOKEN end_char="6208" id="token-62-28" morph="none" pos="word" start_char="6200">bombarded</TOKEN>
<TOKEN end_char="6211" id="token-62-29" morph="none" pos="word" start_char="6210">by</TOKEN>
<TOKEN end_char="6217" id="token-62-30" morph="none" pos="word" start_char="6213">false</TOKEN>
<TOKEN end_char="6220" id="token-62-31" morph="none" pos="word" start_char="6219">or</TOKEN>
<TOKEN end_char="6231" id="token-62-32" morph="none" pos="word" start_char="6222">misleading</TOKEN>
<TOKEN end_char="6238" id="token-62-33" morph="none" pos="word" start_char="6233">claims</TOKEN>
<TOKEN end_char="6241" id="token-62-34" morph="none" pos="word" start_char="6240">on</TOKEN>
<TOKEN end_char="6248" id="token-62-35" morph="none" pos="word" start_char="6243">social</TOKEN>
<TOKEN end_char="6254" id="token-62-36" morph="none" pos="word" start_char="6250">media</TOKEN>
<TOKEN end_char="6255" id="token-62-37" morph="none" pos="punct" start_char="6255">.</TOKEN>
</SEG>
<SEG end_char="6302" id="segment-63" start_char="6257">
<ORIGINAL_TEXT>So how much do you really know about COVID-19?</ORIGINAL_TEXT>
<TOKEN end_char="6258" id="token-63-0" morph="none" pos="word" start_char="6257">So</TOKEN>
<TOKEN end_char="6262" id="token-63-1" morph="none" pos="word" start_char="6260">how</TOKEN>
<TOKEN end_char="6267" id="token-63-2" morph="none" pos="word" start_char="6264">much</TOKEN>
<TOKEN end_char="6270" id="token-63-3" morph="none" pos="word" start_char="6269">do</TOKEN>
<TOKEN end_char="6274" id="token-63-4" morph="none" pos="word" start_char="6272">you</TOKEN>
<TOKEN end_char="6281" id="token-63-5" morph="none" pos="word" start_char="6276">really</TOKEN>
<TOKEN end_char="6286" id="token-63-6" morph="none" pos="word" start_char="6283">know</TOKEN>
<TOKEN end_char="6292" id="token-63-7" morph="none" pos="word" start_char="6288">about</TOKEN>
<TOKEN end_char="6301" id="token-63-8" morph="none" pos="unknown" start_char="6294">COVID-19</TOKEN>
<TOKEN end_char="6302" id="token-63-9" morph="none" pos="punct" start_char="6302">?</TOKEN>
</SEG>
<SEG end_char="6352" id="segment-64" start_char="6304">
<ORIGINAL_TEXT>Take our quiz to gauge how knowledgeable you are.</ORIGINAL_TEXT>
<TOKEN end_char="6307" id="token-64-0" morph="none" pos="word" start_char="6304">Take</TOKEN>
<TOKEN end_char="6311" id="token-64-1" morph="none" pos="word" start_char="6309">our</TOKEN>
<TOKEN end_char="6316" id="token-64-2" morph="none" pos="word" start_char="6313">quiz</TOKEN>
<TOKEN end_char="6319" id="token-64-3" morph="none" pos="word" start_char="6318">to</TOKEN>
<TOKEN end_char="6325" id="token-64-4" morph="none" pos="word" start_char="6321">gauge</TOKEN>
<TOKEN end_char="6329" id="token-64-5" morph="none" pos="word" start_char="6327">how</TOKEN>
<TOKEN end_char="6343" id="token-64-6" morph="none" pos="word" start_char="6331">knowledgeable</TOKEN>
<TOKEN end_char="6347" id="token-64-7" morph="none" pos="word" start_char="6345">you</TOKEN>
<TOKEN end_char="6351" id="token-64-8" morph="none" pos="word" start_char="6349">are</TOKEN>
<TOKEN end_char="6352" id="token-64-9" morph="none" pos="punct" start_char="6352">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
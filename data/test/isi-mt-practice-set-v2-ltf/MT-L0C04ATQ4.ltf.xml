<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATQ4" lang="spa" raw_text_char_length="6242" raw_text_md5="1bdc36d88dd43de63f81ba4221be007f" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="80" id="segment-0" start_char="1">
<ORIGINAL_TEXT>El coronavirus comenzó a circular en China en octubre de 2019, afirma un estudio</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">El</TOKEN>
<TOKEN end_char="14" id="token-0-1" morph="none" pos="word" start_char="4">coronavirus</TOKEN>
<TOKEN end_char="22" id="token-0-2" morph="none" pos="word" start_char="16">comenzó</TOKEN>
<TOKEN end_char="24" id="token-0-3" morph="none" pos="word" start_char="24">a</TOKEN>
<TOKEN end_char="33" id="token-0-4" morph="none" pos="word" start_char="26">circular</TOKEN>
<TOKEN end_char="36" id="token-0-5" morph="none" pos="word" start_char="35">en</TOKEN>
<TOKEN end_char="42" id="token-0-6" morph="none" pos="word" start_char="38">China</TOKEN>
<TOKEN end_char="45" id="token-0-7" morph="none" pos="word" start_char="44">en</TOKEN>
<TOKEN end_char="53" id="token-0-8" morph="none" pos="word" start_char="47">octubre</TOKEN>
<TOKEN end_char="56" id="token-0-9" morph="none" pos="word" start_char="55">de</TOKEN>
<TOKEN end_char="61" id="token-0-10" morph="none" pos="word" start_char="58">2019</TOKEN>
<TOKEN end_char="62" id="token-0-11" morph="none" pos="punct" start_char="62">,</TOKEN>
<TOKEN end_char="69" id="token-0-12" morph="none" pos="word" start_char="64">afirma</TOKEN>
<TOKEN end_char="72" id="token-0-13" morph="none" pos="word" start_char="71">un</TOKEN>
<TOKEN end_char="80" id="token-0-14" morph="none" pos="word" start_char="74">estudio</TOKEN>
<TRANSLATED_TEXT>The coronavirus began circulating in China in October 2019, says a study</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="211" id="segment-1" start_char="85">
<ORIGINAL_TEXT>El coronavirus surgió en China ‘ya en octubre de 2019’, dos meses ANTES de los primeros casos diagnosticados, afirma un estudio</ORIGINAL_TEXT>
<TOKEN end_char="86" id="token-1-0" morph="none" pos="word" start_char="85">El</TOKEN>
<TOKEN end_char="98" id="token-1-1" morph="none" pos="word" start_char="88">coronavirus</TOKEN>
<TOKEN end_char="105" id="token-1-2" morph="none" pos="word" start_char="100">surgió</TOKEN>
<TOKEN end_char="108" id="token-1-3" morph="none" pos="word" start_char="107">en</TOKEN>
<TOKEN end_char="114" id="token-1-4" morph="none" pos="word" start_char="110">China</TOKEN>
<TOKEN end_char="116" id="token-1-5" morph="none" pos="punct" start_char="116">‘</TOKEN>
<TOKEN end_char="118" id="token-1-6" morph="none" pos="word" start_char="117">ya</TOKEN>
<TOKEN end_char="121" id="token-1-7" morph="none" pos="word" start_char="120">en</TOKEN>
<TOKEN end_char="129" id="token-1-8" morph="none" pos="word" start_char="123">octubre</TOKEN>
<TOKEN end_char="132" id="token-1-9" morph="none" pos="word" start_char="131">de</TOKEN>
<TOKEN end_char="137" id="token-1-10" morph="none" pos="word" start_char="134">2019</TOKEN>
<TOKEN end_char="139" id="token-1-11" morph="none" pos="punct" start_char="138">’,</TOKEN>
<TOKEN end_char="143" id="token-1-12" morph="none" pos="word" start_char="141">dos</TOKEN>
<TOKEN end_char="149" id="token-1-13" morph="none" pos="word" start_char="145">meses</TOKEN>
<TOKEN end_char="155" id="token-1-14" morph="none" pos="word" start_char="151">ANTES</TOKEN>
<TOKEN end_char="158" id="token-1-15" morph="none" pos="word" start_char="157">de</TOKEN>
<TOKEN end_char="162" id="token-1-16" morph="none" pos="word" start_char="160">los</TOKEN>
<TOKEN end_char="171" id="token-1-17" morph="none" pos="word" start_char="164">primeros</TOKEN>
<TOKEN end_char="177" id="token-1-18" morph="none" pos="word" start_char="173">casos</TOKEN>
<TOKEN end_char="192" id="token-1-19" morph="none" pos="word" start_char="179">diagnosticados</TOKEN>
<TOKEN end_char="193" id="token-1-20" morph="none" pos="punct" start_char="193">,</TOKEN>
<TOKEN end_char="200" id="token-1-21" morph="none" pos="word" start_char="195">afirma</TOKEN>
<TOKEN end_char="203" id="token-1-22" morph="none" pos="word" start_char="202">un</TOKEN>
<TOKEN end_char="211" id="token-1-23" morph="none" pos="word" start_char="205">estudio</TOKEN>
<TRANSLATED_TEXT>Coronavirus emerged in China 'as early as October 2019', two months BEFORE the first cases diagnosed, says a study</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="304" id="segment-2" start_char="216">
<ORIGINAL_TEXT>Los investigadores rastrearon los orígenes del SARS-CoV-2 en la provincia de Hubei, China</ORIGINAL_TEXT>
<TOKEN end_char="218" id="token-2-0" morph="none" pos="word" start_char="216">Los</TOKEN>
<TOKEN end_char="233" id="token-2-1" morph="none" pos="word" start_char="220">investigadores</TOKEN>
<TOKEN end_char="244" id="token-2-2" morph="none" pos="word" start_char="235">rastrearon</TOKEN>
<TOKEN end_char="248" id="token-2-3" morph="none" pos="word" start_char="246">los</TOKEN>
<TOKEN end_char="257" id="token-2-4" morph="none" pos="word" start_char="250">orígenes</TOKEN>
<TOKEN end_char="261" id="token-2-5" morph="none" pos="word" start_char="259">del</TOKEN>
<TOKEN end_char="272" id="token-2-6" morph="none" pos="unknown" start_char="263">SARS-CoV-2</TOKEN>
<TOKEN end_char="275" id="token-2-7" morph="none" pos="word" start_char="274">en</TOKEN>
<TOKEN end_char="278" id="token-2-8" morph="none" pos="word" start_char="277">la</TOKEN>
<TOKEN end_char="288" id="token-2-9" morph="none" pos="word" start_char="280">provincia</TOKEN>
<TOKEN end_char="291" id="token-2-10" morph="none" pos="word" start_char="290">de</TOKEN>
<TOKEN end_char="297" id="token-2-11" morph="none" pos="word" start_char="293">Hubei</TOKEN>
<TOKEN end_char="298" id="token-2-12" morph="none" pos="punct" start_char="298">,</TOKEN>
<TOKEN end_char="304" id="token-2-13" morph="none" pos="word" start_char="300">China</TOKEN>
<TRANSLATED_TEXT>Researchers traced the origins of SARS-CoV-2 in Hubei Province, China</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="388" id="segment-3" start_char="308">
<ORIGINAL_TEXT>Encontrado el antepasado genético común de 583 casos se remonta al 9 de diciembre</ORIGINAL_TEXT>
<TOKEN end_char="317" id="token-3-0" morph="none" pos="word" start_char="308">Encontrado</TOKEN>
<TOKEN end_char="320" id="token-3-1" morph="none" pos="word" start_char="319">el</TOKEN>
<TOKEN end_char="331" id="token-3-2" morph="none" pos="word" start_char="322">antepasado</TOKEN>
<TOKEN end_char="340" id="token-3-3" morph="none" pos="word" start_char="333">genético</TOKEN>
<TOKEN end_char="346" id="token-3-4" morph="none" pos="word" start_char="342">común</TOKEN>
<TOKEN end_char="349" id="token-3-5" morph="none" pos="word" start_char="348">de</TOKEN>
<TOKEN end_char="353" id="token-3-6" morph="none" pos="word" start_char="351">583</TOKEN>
<TOKEN end_char="359" id="token-3-7" morph="none" pos="word" start_char="355">casos</TOKEN>
<TOKEN end_char="362" id="token-3-8" morph="none" pos="word" start_char="361">se</TOKEN>
<TOKEN end_char="370" id="token-3-9" morph="none" pos="word" start_char="364">remonta</TOKEN>
<TOKEN end_char="373" id="token-3-10" morph="none" pos="word" start_char="372">al</TOKEN>
<TOKEN end_char="375" id="token-3-11" morph="none" pos="word" start_char="375">9</TOKEN>
<TOKEN end_char="378" id="token-3-12" morph="none" pos="word" start_char="377">de</TOKEN>
<TOKEN end_char="388" id="token-3-13" morph="none" pos="word" start_char="380">diciembre</TOKEN>
<TRANSLATED_TEXT>Found the common genetic ancestor of 583 cases goes back to December 9</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="494" id="segment-4" start_char="392">
<ORIGINAL_TEXT>Pero los investigadores dicen que esto es de la cepa de coronavirus que primero se propagó rápidamente.</ORIGINAL_TEXT>
<TOKEN end_char="395" id="token-4-0" morph="none" pos="word" start_char="392">Pero</TOKEN>
<TOKEN end_char="399" id="token-4-1" morph="none" pos="word" start_char="397">los</TOKEN>
<TOKEN end_char="414" id="token-4-2" morph="none" pos="word" start_char="401">investigadores</TOKEN>
<TOKEN end_char="420" id="token-4-3" morph="none" pos="word" start_char="416">dicen</TOKEN>
<TOKEN end_char="424" id="token-4-4" morph="none" pos="word" start_char="422">que</TOKEN>
<TOKEN end_char="429" id="token-4-5" morph="none" pos="word" start_char="426">esto</TOKEN>
<TOKEN end_char="432" id="token-4-6" morph="none" pos="word" start_char="431">es</TOKEN>
<TOKEN end_char="435" id="token-4-7" morph="none" pos="word" start_char="434">de</TOKEN>
<TOKEN end_char="438" id="token-4-8" morph="none" pos="word" start_char="437">la</TOKEN>
<TOKEN end_char="443" id="token-4-9" morph="none" pos="word" start_char="440">cepa</TOKEN>
<TOKEN end_char="446" id="token-4-10" morph="none" pos="word" start_char="445">de</TOKEN>
<TOKEN end_char="458" id="token-4-11" morph="none" pos="word" start_char="448">coronavirus</TOKEN>
<TOKEN end_char="462" id="token-4-12" morph="none" pos="word" start_char="460">que</TOKEN>
<TOKEN end_char="470" id="token-4-13" morph="none" pos="word" start_char="464">primero</TOKEN>
<TOKEN end_char="473" id="token-4-14" morph="none" pos="word" start_char="472">se</TOKEN>
<TOKEN end_char="481" id="token-4-15" morph="none" pos="word" start_char="475">propagó</TOKEN>
<TOKEN end_char="493" id="token-4-16" morph="none" pos="word" start_char="483">rápidamente</TOKEN>
<TOKEN end_char="494" id="token-4-17" morph="none" pos="punct" start_char="494">.</TOKEN>
<TRANSLATED_TEXT>But researchers say this is from the coronavirus strain that first spread rapidly.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="589" id="segment-5" start_char="498">
<ORIGINAL_TEXT>El primer caso documentado de una versión más débil probablemente ocurrió el 17 de noviembre</ORIGINAL_TEXT>
<TOKEN end_char="499" id="token-5-0" morph="none" pos="word" start_char="498">El</TOKEN>
<TOKEN end_char="506" id="token-5-1" morph="none" pos="word" start_char="501">primer</TOKEN>
<TOKEN end_char="511" id="token-5-2" morph="none" pos="word" start_char="508">caso</TOKEN>
<TOKEN end_char="523" id="token-5-3" morph="none" pos="word" start_char="513">documentado</TOKEN>
<TOKEN end_char="526" id="token-5-4" morph="none" pos="word" start_char="525">de</TOKEN>
<TOKEN end_char="530" id="token-5-5" morph="none" pos="word" start_char="528">una</TOKEN>
<TOKEN end_char="538" id="token-5-6" morph="none" pos="word" start_char="532">versión</TOKEN>
<TOKEN end_char="542" id="token-5-7" morph="none" pos="word" start_char="540">más</TOKEN>
<TOKEN end_char="548" id="token-5-8" morph="none" pos="word" start_char="544">débil</TOKEN>
<TOKEN end_char="562" id="token-5-9" morph="none" pos="word" start_char="550">probablemente</TOKEN>
<TOKEN end_char="570" id="token-5-10" morph="none" pos="word" start_char="564">ocurrió</TOKEN>
<TOKEN end_char="573" id="token-5-11" morph="none" pos="word" start_char="572">el</TOKEN>
<TOKEN end_char="576" id="token-5-12" morph="none" pos="word" start_char="575">17</TOKEN>
<TOKEN end_char="579" id="token-5-13" morph="none" pos="word" start_char="578">de</TOKEN>
<TOKEN end_char="589" id="token-5-14" morph="none" pos="word" start_char="581">noviembre</TOKEN>
<TRANSLATED_TEXT>The first documented case of a weaker version probably occurred on November 17.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="704" id="segment-6" start_char="593">
<ORIGINAL_TEXT>Al tener en cuenta un retraso en los informes, es probable que esta persona se haya infectado el 4 de noviembre.</ORIGINAL_TEXT>
<TOKEN end_char="594" id="token-6-0" morph="none" pos="word" start_char="593">Al</TOKEN>
<TOKEN end_char="600" id="token-6-1" morph="none" pos="word" start_char="596">tener</TOKEN>
<TOKEN end_char="603" id="token-6-2" morph="none" pos="word" start_char="602">en</TOKEN>
<TOKEN end_char="610" id="token-6-3" morph="none" pos="word" start_char="605">cuenta</TOKEN>
<TOKEN end_char="613" id="token-6-4" morph="none" pos="word" start_char="612">un</TOKEN>
<TOKEN end_char="621" id="token-6-5" morph="none" pos="word" start_char="615">retraso</TOKEN>
<TOKEN end_char="624" id="token-6-6" morph="none" pos="word" start_char="623">en</TOKEN>
<TOKEN end_char="628" id="token-6-7" morph="none" pos="word" start_char="626">los</TOKEN>
<TOKEN end_char="637" id="token-6-8" morph="none" pos="word" start_char="630">informes</TOKEN>
<TOKEN end_char="638" id="token-6-9" morph="none" pos="punct" start_char="638">,</TOKEN>
<TOKEN end_char="641" id="token-6-10" morph="none" pos="word" start_char="640">es</TOKEN>
<TOKEN end_char="650" id="token-6-11" morph="none" pos="word" start_char="643">probable</TOKEN>
<TOKEN end_char="654" id="token-6-12" morph="none" pos="word" start_char="652">que</TOKEN>
<TOKEN end_char="659" id="token-6-13" morph="none" pos="word" start_char="656">esta</TOKEN>
<TOKEN end_char="667" id="token-6-14" morph="none" pos="word" start_char="661">persona</TOKEN>
<TOKEN end_char="670" id="token-6-15" morph="none" pos="word" start_char="669">se</TOKEN>
<TOKEN end_char="675" id="token-6-16" morph="none" pos="word" start_char="672">haya</TOKEN>
<TOKEN end_char="685" id="token-6-17" morph="none" pos="word" start_char="677">infectado</TOKEN>
<TOKEN end_char="688" id="token-6-18" morph="none" pos="word" start_char="687">el</TOKEN>
<TOKEN end_char="690" id="token-6-19" morph="none" pos="word" start_char="690">4</TOKEN>
<TOKEN end_char="693" id="token-6-20" morph="none" pos="word" start_char="692">de</TOKEN>
<TOKEN end_char="703" id="token-6-21" morph="none" pos="word" start_char="695">noviembre</TOKEN>
<TOKEN end_char="704" id="token-6-22" morph="none" pos="punct" start_char="704">.</TOKEN>
<TRANSLATED_TEXT>Given a delay in reporting, it is likely that this person became infected on 4 November.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="799" id="segment-7" start_char="708">
<ORIGINAL_TEXT>Pero los investigadores dicen que esta cifra podría ser confiable a partir del 7 de octubre.</ORIGINAL_TEXT>
<TOKEN end_char="711" id="token-7-0" morph="none" pos="word" start_char="708">Pero</TOKEN>
<TOKEN end_char="715" id="token-7-1" morph="none" pos="word" start_char="713">los</TOKEN>
<TOKEN end_char="730" id="token-7-2" morph="none" pos="word" start_char="717">investigadores</TOKEN>
<TOKEN end_char="736" id="token-7-3" morph="none" pos="word" start_char="732">dicen</TOKEN>
<TOKEN end_char="740" id="token-7-4" morph="none" pos="word" start_char="738">que</TOKEN>
<TOKEN end_char="745" id="token-7-5" morph="none" pos="word" start_char="742">esta</TOKEN>
<TOKEN end_char="751" id="token-7-6" morph="none" pos="word" start_char="747">cifra</TOKEN>
<TOKEN end_char="758" id="token-7-7" morph="none" pos="word" start_char="753">podría</TOKEN>
<TOKEN end_char="762" id="token-7-8" morph="none" pos="word" start_char="760">ser</TOKEN>
<TOKEN end_char="772" id="token-7-9" morph="none" pos="word" start_char="764">confiable</TOKEN>
<TOKEN end_char="774" id="token-7-10" morph="none" pos="word" start_char="774">a</TOKEN>
<TOKEN end_char="781" id="token-7-11" morph="none" pos="word" start_char="776">partir</TOKEN>
<TOKEN end_char="785" id="token-7-12" morph="none" pos="word" start_char="783">del</TOKEN>
<TOKEN end_char="787" id="token-7-13" morph="none" pos="word" start_char="787">7</TOKEN>
<TOKEN end_char="790" id="token-7-14" morph="none" pos="word" start_char="789">de</TOKEN>
<TOKEN end_char="798" id="token-7-15" morph="none" pos="word" start_char="792">octubre</TOKEN>
<TOKEN end_char="799" id="token-7-16" morph="none" pos="punct" start_char="799">.</TOKEN>
<TRANSLATED_TEXT>But researchers say this figure could be reliable as of October 7.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="964" id="segment-8" start_char="804">
<ORIGINAL_TEXT>El primer caso de un humano infectado con SARS-CoV-2, el virus que causa el Covid-19, pudo haber ocurrido en la provincia china de Hubei el 7 de octubre de 2019.</ORIGINAL_TEXT>
<TOKEN end_char="805" id="token-8-0" morph="none" pos="word" start_char="804">El</TOKEN>
<TOKEN end_char="812" id="token-8-1" morph="none" pos="word" start_char="807">primer</TOKEN>
<TOKEN end_char="817" id="token-8-2" morph="none" pos="word" start_char="814">caso</TOKEN>
<TOKEN end_char="820" id="token-8-3" morph="none" pos="word" start_char="819">de</TOKEN>
<TOKEN end_char="823" id="token-8-4" morph="none" pos="word" start_char="822">un</TOKEN>
<TOKEN end_char="830" id="token-8-5" morph="none" pos="word" start_char="825">humano</TOKEN>
<TOKEN end_char="840" id="token-8-6" morph="none" pos="word" start_char="832">infectado</TOKEN>
<TOKEN end_char="844" id="token-8-7" morph="none" pos="word" start_char="842">con</TOKEN>
<TOKEN end_char="855" id="token-8-8" morph="none" pos="unknown" start_char="846">SARS-CoV-2</TOKEN>
<TOKEN end_char="856" id="token-8-9" morph="none" pos="punct" start_char="856">,</TOKEN>
<TOKEN end_char="859" id="token-8-10" morph="none" pos="word" start_char="858">el</TOKEN>
<TOKEN end_char="865" id="token-8-11" morph="none" pos="word" start_char="861">virus</TOKEN>
<TOKEN end_char="869" id="token-8-12" morph="none" pos="word" start_char="867">que</TOKEN>
<TOKEN end_char="875" id="token-8-13" morph="none" pos="word" start_char="871">causa</TOKEN>
<TOKEN end_char="878" id="token-8-14" morph="none" pos="word" start_char="877">el</TOKEN>
<TOKEN end_char="887" id="token-8-15" morph="none" pos="unknown" start_char="880">Covid-19</TOKEN>
<TOKEN end_char="888" id="token-8-16" morph="none" pos="punct" start_char="888">,</TOKEN>
<TOKEN end_char="893" id="token-8-17" morph="none" pos="word" start_char="890">pudo</TOKEN>
<TOKEN end_char="899" id="token-8-18" morph="none" pos="word" start_char="895">haber</TOKEN>
<TOKEN end_char="908" id="token-8-19" morph="none" pos="word" start_char="901">ocurrido</TOKEN>
<TOKEN end_char="911" id="token-8-20" morph="none" pos="word" start_char="910">en</TOKEN>
<TOKEN end_char="914" id="token-8-21" morph="none" pos="word" start_char="913">la</TOKEN>
<TOKEN end_char="924" id="token-8-22" morph="none" pos="word" start_char="916">provincia</TOKEN>
<TOKEN end_char="930" id="token-8-23" morph="none" pos="word" start_char="926">china</TOKEN>
<TOKEN end_char="933" id="token-8-24" morph="none" pos="word" start_char="932">de</TOKEN>
<TOKEN end_char="939" id="token-8-25" morph="none" pos="word" start_char="935">Hubei</TOKEN>
<TOKEN end_char="942" id="token-8-26" morph="none" pos="word" start_char="941">el</TOKEN>
<TOKEN end_char="944" id="token-8-27" morph="none" pos="word" start_char="944">7</TOKEN>
<TOKEN end_char="947" id="token-8-28" morph="none" pos="word" start_char="946">de</TOKEN>
<TOKEN end_char="955" id="token-8-29" morph="none" pos="word" start_char="949">octubre</TOKEN>
<TOKEN end_char="958" id="token-8-30" morph="none" pos="word" start_char="957">de</TOKEN>
<TOKEN end_char="963" id="token-8-31" morph="none" pos="word" start_char="960">2019</TOKEN>
<TOKEN end_char="964" id="token-8-32" morph="none" pos="punct" start_char="964">.</TOKEN>
<TRANSLATED_TEXT>The first case of a human infected with SARS-CoV-2, the virus that causes Covid-19, may have occurred in the Chinese province of Hubei on October 7, 2019.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1117" id="segment-9" start_char="967">
<ORIGINAL_TEXT>Solo a mediados de diciembre, dos meses después, se describieron oficialmente los primeros casos en Wuhan en el ahora notorio mercado húmedo de Huanan.</ORIGINAL_TEXT>
<TOKEN end_char="970" id="token-9-0" morph="none" pos="word" start_char="967">Solo</TOKEN>
<TOKEN end_char="972" id="token-9-1" morph="none" pos="word" start_char="972">a</TOKEN>
<TOKEN end_char="981" id="token-9-2" morph="none" pos="word" start_char="974">mediados</TOKEN>
<TOKEN end_char="984" id="token-9-3" morph="none" pos="word" start_char="983">de</TOKEN>
<TOKEN end_char="994" id="token-9-4" morph="none" pos="word" start_char="986">diciembre</TOKEN>
<TOKEN end_char="995" id="token-9-5" morph="none" pos="punct" start_char="995">,</TOKEN>
<TOKEN end_char="999" id="token-9-6" morph="none" pos="word" start_char="997">dos</TOKEN>
<TOKEN end_char="1005" id="token-9-7" morph="none" pos="word" start_char="1001">meses</TOKEN>
<TOKEN end_char="1013" id="token-9-8" morph="none" pos="word" start_char="1007">después</TOKEN>
<TOKEN end_char="1014" id="token-9-9" morph="none" pos="punct" start_char="1014">,</TOKEN>
<TOKEN end_char="1017" id="token-9-10" morph="none" pos="word" start_char="1016">se</TOKEN>
<TOKEN end_char="1030" id="token-9-11" morph="none" pos="word" start_char="1019">describieron</TOKEN>
<TOKEN end_char="1043" id="token-9-12" morph="none" pos="word" start_char="1032">oficialmente</TOKEN>
<TOKEN end_char="1047" id="token-9-13" morph="none" pos="word" start_char="1045">los</TOKEN>
<TOKEN end_char="1056" id="token-9-14" morph="none" pos="word" start_char="1049">primeros</TOKEN>
<TOKEN end_char="1062" id="token-9-15" morph="none" pos="word" start_char="1058">casos</TOKEN>
<TOKEN end_char="1065" id="token-9-16" morph="none" pos="word" start_char="1064">en</TOKEN>
<TOKEN end_char="1071" id="token-9-17" morph="none" pos="word" start_char="1067">Wuhan</TOKEN>
<TOKEN end_char="1074" id="token-9-18" morph="none" pos="word" start_char="1073">en</TOKEN>
<TOKEN end_char="1077" id="token-9-19" morph="none" pos="word" start_char="1076">el</TOKEN>
<TOKEN end_char="1083" id="token-9-20" morph="none" pos="word" start_char="1079">ahora</TOKEN>
<TOKEN end_char="1091" id="token-9-21" morph="none" pos="word" start_char="1085">notorio</TOKEN>
<TOKEN end_char="1099" id="token-9-22" morph="none" pos="word" start_char="1093">mercado</TOKEN>
<TOKEN end_char="1106" id="token-9-23" morph="none" pos="word" start_char="1101">húmedo</TOKEN>
<TOKEN end_char="1109" id="token-9-24" morph="none" pos="word" start_char="1108">de</TOKEN>
<TOKEN end_char="1116" id="token-9-25" morph="none" pos="word" start_char="1111">Huanan</TOKEN>
<TOKEN end_char="1117" id="token-9-26" morph="none" pos="punct" start_char="1117">.</TOKEN>
<TRANSLATED_TEXT>Only in mid-December, two months later, the first cases in Wuhan were officially described in the now notorious Huanan wet market.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1382" id="segment-10" start_char="1120">
<ORIGINAL_TEXT>Un nuevo análisis de la propagación del virus y su ‘reloj molecular’ reveló que probablemente ya estaba establecido en Wuhan en este punto y había estado circulando en Hubei en niveles bajos a principios de noviembre de 2019, y posiblemente a mediados de octubre.</ORIGINAL_TEXT>
<TOKEN end_char="1121" id="token-10-0" morph="none" pos="word" start_char="1120">Un</TOKEN>
<TOKEN end_char="1127" id="token-10-1" morph="none" pos="word" start_char="1123">nuevo</TOKEN>
<TOKEN end_char="1136" id="token-10-2" morph="none" pos="word" start_char="1129">análisis</TOKEN>
<TOKEN end_char="1139" id="token-10-3" morph="none" pos="word" start_char="1138">de</TOKEN>
<TOKEN end_char="1142" id="token-10-4" morph="none" pos="word" start_char="1141">la</TOKEN>
<TOKEN end_char="1154" id="token-10-5" morph="none" pos="word" start_char="1144">propagación</TOKEN>
<TOKEN end_char="1158" id="token-10-6" morph="none" pos="word" start_char="1156">del</TOKEN>
<TOKEN end_char="1164" id="token-10-7" morph="none" pos="word" start_char="1160">virus</TOKEN>
<TOKEN end_char="1166" id="token-10-8" morph="none" pos="word" start_char="1166">y</TOKEN>
<TOKEN end_char="1169" id="token-10-9" morph="none" pos="word" start_char="1168">su</TOKEN>
<TOKEN end_char="1171" id="token-10-10" morph="none" pos="punct" start_char="1171">‘</TOKEN>
<TOKEN end_char="1176" id="token-10-11" morph="none" pos="word" start_char="1172">reloj</TOKEN>
<TOKEN end_char="1186" id="token-10-12" morph="none" pos="word" start_char="1178">molecular</TOKEN>
<TOKEN end_char="1187" id="token-10-13" morph="none" pos="punct" start_char="1187">’</TOKEN>
<TOKEN end_char="1194" id="token-10-14" morph="none" pos="word" start_char="1189">reveló</TOKEN>
<TOKEN end_char="1198" id="token-10-15" morph="none" pos="word" start_char="1196">que</TOKEN>
<TOKEN end_char="1212" id="token-10-16" morph="none" pos="word" start_char="1200">probablemente</TOKEN>
<TOKEN end_char="1215" id="token-10-17" morph="none" pos="word" start_char="1214">ya</TOKEN>
<TOKEN end_char="1222" id="token-10-18" morph="none" pos="word" start_char="1217">estaba</TOKEN>
<TOKEN end_char="1234" id="token-10-19" morph="none" pos="word" start_char="1224">establecido</TOKEN>
<TOKEN end_char="1237" id="token-10-20" morph="none" pos="word" start_char="1236">en</TOKEN>
<TOKEN end_char="1243" id="token-10-21" morph="none" pos="word" start_char="1239">Wuhan</TOKEN>
<TOKEN end_char="1246" id="token-10-22" morph="none" pos="word" start_char="1245">en</TOKEN>
<TOKEN end_char="1251" id="token-10-23" morph="none" pos="word" start_char="1248">este</TOKEN>
<TOKEN end_char="1257" id="token-10-24" morph="none" pos="word" start_char="1253">punto</TOKEN>
<TOKEN end_char="1259" id="token-10-25" morph="none" pos="word" start_char="1259">y</TOKEN>
<TOKEN end_char="1265" id="token-10-26" morph="none" pos="word" start_char="1261">había</TOKEN>
<TOKEN end_char="1272" id="token-10-27" morph="none" pos="word" start_char="1267">estado</TOKEN>
<TOKEN end_char="1283" id="token-10-28" morph="none" pos="word" start_char="1274">circulando</TOKEN>
<TOKEN end_char="1286" id="token-10-29" morph="none" pos="word" start_char="1285">en</TOKEN>
<TOKEN end_char="1292" id="token-10-30" morph="none" pos="word" start_char="1288">Hubei</TOKEN>
<TOKEN end_char="1295" id="token-10-31" morph="none" pos="word" start_char="1294">en</TOKEN>
<TOKEN end_char="1303" id="token-10-32" morph="none" pos="word" start_char="1297">niveles</TOKEN>
<TOKEN end_char="1309" id="token-10-33" morph="none" pos="word" start_char="1305">bajos</TOKEN>
<TOKEN end_char="1311" id="token-10-34" morph="none" pos="word" start_char="1311">a</TOKEN>
<TOKEN end_char="1322" id="token-10-35" morph="none" pos="word" start_char="1313">principios</TOKEN>
<TOKEN end_char="1325" id="token-10-36" morph="none" pos="word" start_char="1324">de</TOKEN>
<TOKEN end_char="1335" id="token-10-37" morph="none" pos="word" start_char="1327">noviembre</TOKEN>
<TOKEN end_char="1338" id="token-10-38" morph="none" pos="word" start_char="1337">de</TOKEN>
<TOKEN end_char="1343" id="token-10-39" morph="none" pos="word" start_char="1340">2019</TOKEN>
<TOKEN end_char="1344" id="token-10-40" morph="none" pos="punct" start_char="1344">,</TOKEN>
<TOKEN end_char="1346" id="token-10-41" morph="none" pos="word" start_char="1346">y</TOKEN>
<TOKEN end_char="1359" id="token-10-42" morph="none" pos="word" start_char="1348">posiblemente</TOKEN>
<TOKEN end_char="1361" id="token-10-43" morph="none" pos="word" start_char="1361">a</TOKEN>
<TOKEN end_char="1370" id="token-10-44" morph="none" pos="word" start_char="1363">mediados</TOKEN>
<TOKEN end_char="1373" id="token-10-45" morph="none" pos="word" start_char="1372">de</TOKEN>
<TOKEN end_char="1381" id="token-10-46" morph="none" pos="word" start_char="1375">octubre</TOKEN>
<TOKEN end_char="1382" id="token-10-47" morph="none" pos="punct" start_char="1382">.</TOKEN>
<TRANSLATED_TEXT>A new analysis of the virus's spread and its' molecular clock 'revealed that it was probably already established in Wuhan at this point and had been circulating in Hubei at low levels by early November 2019, and possibly by mid-October.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1424" id="segment-11" start_char="1385">
<ORIGINAL_TEXT>Desplácese hacia abajo para ver el video</ORIGINAL_TEXT>
<TOKEN end_char="1394" id="token-11-0" morph="none" pos="word" start_char="1385">Desplácese</TOKEN>
<TOKEN end_char="1400" id="token-11-1" morph="none" pos="word" start_char="1396">hacia</TOKEN>
<TOKEN end_char="1406" id="token-11-2" morph="none" pos="word" start_char="1402">abajo</TOKEN>
<TOKEN end_char="1411" id="token-11-3" morph="none" pos="word" start_char="1408">para</TOKEN>
<TOKEN end_char="1415" id="token-11-4" morph="none" pos="word" start_char="1413">ver</TOKEN>
<TOKEN end_char="1418" id="token-11-5" morph="none" pos="word" start_char="1417">el</TOKEN>
<TOKEN end_char="1424" id="token-11-6" morph="none" pos="word" start_char="1420">video</TOKEN>
<TRANSLATED_TEXT>Scroll down to see the video</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1562" id="segment-12" start_char="1427">
<ORIGINAL_TEXT>Pero debido a los nuevos síntomas de Covid-19 y a una cantidad inicialmente pequeña de infecciones, fue difícil identificar el patógeno.</ORIGINAL_TEXT>
<TOKEN end_char="1430" id="token-12-0" morph="none" pos="word" start_char="1427">Pero</TOKEN>
<TOKEN end_char="1437" id="token-12-1" morph="none" pos="word" start_char="1432">debido</TOKEN>
<TOKEN end_char="1439" id="token-12-2" morph="none" pos="word" start_char="1439">a</TOKEN>
<TOKEN end_char="1443" id="token-12-3" morph="none" pos="word" start_char="1441">los</TOKEN>
<TOKEN end_char="1450" id="token-12-4" morph="none" pos="word" start_char="1445">nuevos</TOKEN>
<TOKEN end_char="1459" id="token-12-5" morph="none" pos="word" start_char="1452">síntomas</TOKEN>
<TOKEN end_char="1462" id="token-12-6" morph="none" pos="word" start_char="1461">de</TOKEN>
<TOKEN end_char="1471" id="token-12-7" morph="none" pos="unknown" start_char="1464">Covid-19</TOKEN>
<TOKEN end_char="1473" id="token-12-8" morph="none" pos="word" start_char="1473">y</TOKEN>
<TOKEN end_char="1475" id="token-12-9" morph="none" pos="word" start_char="1475">a</TOKEN>
<TOKEN end_char="1479" id="token-12-10" morph="none" pos="word" start_char="1477">una</TOKEN>
<TOKEN end_char="1488" id="token-12-11" morph="none" pos="word" start_char="1481">cantidad</TOKEN>
<TOKEN end_char="1501" id="token-12-12" morph="none" pos="word" start_char="1490">inicialmente</TOKEN>
<TOKEN end_char="1509" id="token-12-13" morph="none" pos="word" start_char="1503">pequeña</TOKEN>
<TOKEN end_char="1512" id="token-12-14" morph="none" pos="word" start_char="1511">de</TOKEN>
<TOKEN end_char="1524" id="token-12-15" morph="none" pos="word" start_char="1514">infecciones</TOKEN>
<TOKEN end_char="1525" id="token-12-16" morph="none" pos="punct" start_char="1525">,</TOKEN>
<TOKEN end_char="1529" id="token-12-17" morph="none" pos="word" start_char="1527">fue</TOKEN>
<TOKEN end_char="1537" id="token-12-18" morph="none" pos="word" start_char="1531">difícil</TOKEN>
<TOKEN end_char="1549" id="token-12-19" morph="none" pos="word" start_char="1539">identificar</TOKEN>
<TOKEN end_char="1552" id="token-12-20" morph="none" pos="word" start_char="1551">el</TOKEN>
<TOKEN end_char="1561" id="token-12-21" morph="none" pos="word" start_char="1554">patógeno</TOKEN>
<TOKEN end_char="1562" id="token-12-22" morph="none" pos="punct" start_char="1562">.</TOKEN>
<TRANSLATED_TEXT>But due to the new symptoms of Covid-19 and an initially small number of infections, it was difficult to identify the pathogen.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1745" id="segment-13" start_char="1565">
<ORIGINAL_TEXT>Como resultado, el virus solo llamó la atención de las autoridades cuando en diciembre se observó un grupo de síntomas misteriosos relacionados con el mercado de mariscos de Huanan.</ORIGINAL_TEXT>
<TOKEN end_char="1568" id="token-13-0" morph="none" pos="word" start_char="1565">Como</TOKEN>
<TOKEN end_char="1578" id="token-13-1" morph="none" pos="word" start_char="1570">resultado</TOKEN>
<TOKEN end_char="1579" id="token-13-2" morph="none" pos="punct" start_char="1579">,</TOKEN>
<TOKEN end_char="1582" id="token-13-3" morph="none" pos="word" start_char="1581">el</TOKEN>
<TOKEN end_char="1588" id="token-13-4" morph="none" pos="word" start_char="1584">virus</TOKEN>
<TOKEN end_char="1593" id="token-13-5" morph="none" pos="word" start_char="1590">solo</TOKEN>
<TOKEN end_char="1599" id="token-13-6" morph="none" pos="word" start_char="1595">llamó</TOKEN>
<TOKEN end_char="1602" id="token-13-7" morph="none" pos="word" start_char="1601">la</TOKEN>
<TOKEN end_char="1611" id="token-13-8" morph="none" pos="word" start_char="1604">atención</TOKEN>
<TOKEN end_char="1614" id="token-13-9" morph="none" pos="word" start_char="1613">de</TOKEN>
<TOKEN end_char="1618" id="token-13-10" morph="none" pos="word" start_char="1616">las</TOKEN>
<TOKEN end_char="1630" id="token-13-11" morph="none" pos="word" start_char="1620">autoridades</TOKEN>
<TOKEN end_char="1637" id="token-13-12" morph="none" pos="word" start_char="1632">cuando</TOKEN>
<TOKEN end_char="1640" id="token-13-13" morph="none" pos="word" start_char="1639">en</TOKEN>
<TOKEN end_char="1650" id="token-13-14" morph="none" pos="word" start_char="1642">diciembre</TOKEN>
<TOKEN end_char="1653" id="token-13-15" morph="none" pos="word" start_char="1652">se</TOKEN>
<TOKEN end_char="1661" id="token-13-16" morph="none" pos="word" start_char="1655">observó</TOKEN>
<TOKEN end_char="1664" id="token-13-17" morph="none" pos="word" start_char="1663">un</TOKEN>
<TOKEN end_char="1670" id="token-13-18" morph="none" pos="word" start_char="1666">grupo</TOKEN>
<TOKEN end_char="1673" id="token-13-19" morph="none" pos="word" start_char="1672">de</TOKEN>
<TOKEN end_char="1682" id="token-13-20" morph="none" pos="word" start_char="1675">síntomas</TOKEN>
<TOKEN end_char="1694" id="token-13-21" morph="none" pos="word" start_char="1684">misteriosos</TOKEN>
<TOKEN end_char="1707" id="token-13-22" morph="none" pos="word" start_char="1696">relacionados</TOKEN>
<TOKEN end_char="1711" id="token-13-23" morph="none" pos="word" start_char="1709">con</TOKEN>
<TOKEN end_char="1714" id="token-13-24" morph="none" pos="word" start_char="1713">el</TOKEN>
<TOKEN end_char="1722" id="token-13-25" morph="none" pos="word" start_char="1716">mercado</TOKEN>
<TOKEN end_char="1725" id="token-13-26" morph="none" pos="word" start_char="1724">de</TOKEN>
<TOKEN end_char="1734" id="token-13-27" morph="none" pos="word" start_char="1727">mariscos</TOKEN>
<TOKEN end_char="1737" id="token-13-28" morph="none" pos="word" start_char="1736">de</TOKEN>
<TOKEN end_char="1744" id="token-13-29" morph="none" pos="word" start_char="1739">Huanan</TOKEN>
<TOKEN end_char="1745" id="token-13-30" morph="none" pos="punct" start_char="1745">.</TOKEN>
<TRANSLATED_TEXT>As a result, the virus only caught the attention of the authorities when a group of mysterious symptoms related to the Huanan seafood market were observed in December.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1913" id="segment-14" start_char="1748">
<ORIGINAL_TEXT>Esto llevó a la teoría ahora desacreditada de que el mercado húmedo, donde se vende una amplia variedad de animales vivos y muertos, fue donde se originó la pandemia.</ORIGINAL_TEXT>
<TOKEN end_char="1751" id="token-14-0" morph="none" pos="word" start_char="1748">Esto</TOKEN>
<TOKEN end_char="1757" id="token-14-1" morph="none" pos="word" start_char="1753">llevó</TOKEN>
<TOKEN end_char="1759" id="token-14-2" morph="none" pos="word" start_char="1759">a</TOKEN>
<TOKEN end_char="1762" id="token-14-3" morph="none" pos="word" start_char="1761">la</TOKEN>
<TOKEN end_char="1769" id="token-14-4" morph="none" pos="word" start_char="1764">teoría</TOKEN>
<TOKEN end_char="1775" id="token-14-5" morph="none" pos="word" start_char="1771">ahora</TOKEN>
<TOKEN end_char="1789" id="token-14-6" morph="none" pos="word" start_char="1777">desacreditada</TOKEN>
<TOKEN end_char="1792" id="token-14-7" morph="none" pos="word" start_char="1791">de</TOKEN>
<TOKEN end_char="1796" id="token-14-8" morph="none" pos="word" start_char="1794">que</TOKEN>
<TOKEN end_char="1799" id="token-14-9" morph="none" pos="word" start_char="1798">el</TOKEN>
<TOKEN end_char="1807" id="token-14-10" morph="none" pos="word" start_char="1801">mercado</TOKEN>
<TOKEN end_char="1814" id="token-14-11" morph="none" pos="word" start_char="1809">húmedo</TOKEN>
<TOKEN end_char="1815" id="token-14-12" morph="none" pos="punct" start_char="1815">,</TOKEN>
<TOKEN end_char="1821" id="token-14-13" morph="none" pos="word" start_char="1817">donde</TOKEN>
<TOKEN end_char="1824" id="token-14-14" morph="none" pos="word" start_char="1823">se</TOKEN>
<TOKEN end_char="1830" id="token-14-15" morph="none" pos="word" start_char="1826">vende</TOKEN>
<TOKEN end_char="1834" id="token-14-16" morph="none" pos="word" start_char="1832">una</TOKEN>
<TOKEN end_char="1841" id="token-14-17" morph="none" pos="word" start_char="1836">amplia</TOKEN>
<TOKEN end_char="1850" id="token-14-18" morph="none" pos="word" start_char="1843">variedad</TOKEN>
<TOKEN end_char="1853" id="token-14-19" morph="none" pos="word" start_char="1852">de</TOKEN>
<TOKEN end_char="1862" id="token-14-20" morph="none" pos="word" start_char="1855">animales</TOKEN>
<TOKEN end_char="1868" id="token-14-21" morph="none" pos="word" start_char="1864">vivos</TOKEN>
<TOKEN end_char="1870" id="token-14-22" morph="none" pos="word" start_char="1870">y</TOKEN>
<TOKEN end_char="1878" id="token-14-23" morph="none" pos="word" start_char="1872">muertos</TOKEN>
<TOKEN end_char="1879" id="token-14-24" morph="none" pos="punct" start_char="1879">,</TOKEN>
<TOKEN end_char="1883" id="token-14-25" morph="none" pos="word" start_char="1881">fue</TOKEN>
<TOKEN end_char="1889" id="token-14-26" morph="none" pos="word" start_char="1885">donde</TOKEN>
<TOKEN end_char="1892" id="token-14-27" morph="none" pos="word" start_char="1891">se</TOKEN>
<TOKEN end_char="1900" id="token-14-28" morph="none" pos="word" start_char="1894">originó</TOKEN>
<TOKEN end_char="1903" id="token-14-29" morph="none" pos="word" start_char="1902">la</TOKEN>
<TOKEN end_char="1912" id="token-14-30" morph="none" pos="word" start_char="1905">pandemia</TOKEN>
<TOKEN end_char="1913" id="token-14-31" morph="none" pos="punct" start_char="1913">.</TOKEN>
<TRANSLATED_TEXT>This led to the now discredited theory that the wet market, where a wide variety of live and dead animals are sold, was where the pandemic originated.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2060" id="segment-15" start_char="1916">
<ORIGINAL_TEXT>El Dr. Jonathan Pekar de la Universidad de California en San Diego realizó un estudio matemático para determinar cuándo y dónde surgió realmente.</ORIGINAL_TEXT>
<TOKEN end_char="1917" id="token-15-0" morph="none" pos="word" start_char="1916">El</TOKEN>
<TOKEN end_char="1920" id="token-15-1" morph="none" pos="word" start_char="1919">Dr</TOKEN>
<TOKEN end_char="1921" id="token-15-2" morph="none" pos="punct" start_char="1921">.</TOKEN>
<TOKEN end_char="1930" id="token-15-3" morph="none" pos="word" start_char="1923">Jonathan</TOKEN>
<TOKEN end_char="1936" id="token-15-4" morph="none" pos="word" start_char="1932">Pekar</TOKEN>
<TOKEN end_char="1939" id="token-15-5" morph="none" pos="word" start_char="1938">de</TOKEN>
<TOKEN end_char="1942" id="token-15-6" morph="none" pos="word" start_char="1941">la</TOKEN>
<TOKEN end_char="1954" id="token-15-7" morph="none" pos="word" start_char="1944">Universidad</TOKEN>
<TOKEN end_char="1957" id="token-15-8" morph="none" pos="word" start_char="1956">de</TOKEN>
<TOKEN end_char="1968" id="token-15-9" morph="none" pos="word" start_char="1959">California</TOKEN>
<TOKEN end_char="1971" id="token-15-10" morph="none" pos="word" start_char="1970">en</TOKEN>
<TOKEN end_char="1975" id="token-15-11" morph="none" pos="word" start_char="1973">San</TOKEN>
<TOKEN end_char="1981" id="token-15-12" morph="none" pos="word" start_char="1977">Diego</TOKEN>
<TOKEN end_char="1989" id="token-15-13" morph="none" pos="word" start_char="1983">realizó</TOKEN>
<TOKEN end_char="1992" id="token-15-14" morph="none" pos="word" start_char="1991">un</TOKEN>
<TOKEN end_char="2000" id="token-15-15" morph="none" pos="word" start_char="1994">estudio</TOKEN>
<TOKEN end_char="2011" id="token-15-16" morph="none" pos="word" start_char="2002">matemático</TOKEN>
<TOKEN end_char="2016" id="token-15-17" morph="none" pos="word" start_char="2013">para</TOKEN>
<TOKEN end_char="2027" id="token-15-18" morph="none" pos="word" start_char="2018">determinar</TOKEN>
<TOKEN end_char="2034" id="token-15-19" morph="none" pos="word" start_char="2029">cuándo</TOKEN>
<TOKEN end_char="2036" id="token-15-20" morph="none" pos="word" start_char="2036">y</TOKEN>
<TOKEN end_char="2042" id="token-15-21" morph="none" pos="word" start_char="2038">dónde</TOKEN>
<TOKEN end_char="2049" id="token-15-22" morph="none" pos="word" start_char="2044">surgió</TOKEN>
<TOKEN end_char="2059" id="token-15-23" morph="none" pos="word" start_char="2051">realmente</TOKEN>
<TOKEN end_char="2060" id="token-15-24" morph="none" pos="punct" start_char="2060">.</TOKEN>
<TRANSLATED_TEXT>Dr. Jonathan Pekar of the University of California, San Diego conducted a mathematical study to determine when and where it actually arose.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2264" id="segment-16" start_char="2064">
<ORIGINAL_TEXT>‘En nuestro análisis principal, asumimos que el 17 de noviembre [thick dotted line] representa el primer caso documentado de Covid-19 ‘, escriben los investigadores en su estudio, publicado en Science.</ORIGINAL_TEXT>
<TOKEN end_char="2064" id="token-16-0" morph="none" pos="punct" start_char="2064">‘</TOKEN>
<TOKEN end_char="2066" id="token-16-1" morph="none" pos="word" start_char="2065">En</TOKEN>
<TOKEN end_char="2074" id="token-16-2" morph="none" pos="word" start_char="2068">nuestro</TOKEN>
<TOKEN end_char="2083" id="token-16-3" morph="none" pos="word" start_char="2076">análisis</TOKEN>
<TOKEN end_char="2093" id="token-16-4" morph="none" pos="word" start_char="2085">principal</TOKEN>
<TOKEN end_char="2094" id="token-16-5" morph="none" pos="punct" start_char="2094">,</TOKEN>
<TOKEN end_char="2103" id="token-16-6" morph="none" pos="word" start_char="2096">asumimos</TOKEN>
<TOKEN end_char="2107" id="token-16-7" morph="none" pos="word" start_char="2105">que</TOKEN>
<TOKEN end_char="2110" id="token-16-8" morph="none" pos="word" start_char="2109">el</TOKEN>
<TOKEN end_char="2113" id="token-16-9" morph="none" pos="word" start_char="2112">17</TOKEN>
<TOKEN end_char="2116" id="token-16-10" morph="none" pos="word" start_char="2115">de</TOKEN>
<TOKEN end_char="2126" id="token-16-11" morph="none" pos="word" start_char="2118">noviembre</TOKEN>
<TOKEN end_char="2128" id="token-16-12" morph="none" pos="punct" start_char="2128">[</TOKEN>
<TOKEN end_char="2133" id="token-16-13" morph="none" pos="word" start_char="2129">thick</TOKEN>
<TOKEN end_char="2140" id="token-16-14" morph="none" pos="word" start_char="2135">dotted</TOKEN>
<TOKEN end_char="2145" id="token-16-15" morph="none" pos="word" start_char="2142">line</TOKEN>
<TOKEN end_char="2146" id="token-16-16" morph="none" pos="punct" start_char="2146">]</TOKEN>
<TOKEN end_char="2157" id="token-16-17" morph="none" pos="word" start_char="2148">representa</TOKEN>
<TOKEN end_char="2160" id="token-16-18" morph="none" pos="word" start_char="2159">el</TOKEN>
<TOKEN end_char="2167" id="token-16-19" morph="none" pos="word" start_char="2162">primer</TOKEN>
<TOKEN end_char="2172" id="token-16-20" morph="none" pos="word" start_char="2169">caso</TOKEN>
<TOKEN end_char="2184" id="token-16-21" morph="none" pos="word" start_char="2174">documentado</TOKEN>
<TOKEN end_char="2187" id="token-16-22" morph="none" pos="word" start_char="2186">de</TOKEN>
<TOKEN end_char="2196" id="token-16-23" morph="none" pos="unknown" start_char="2189">Covid-19</TOKEN>
<TOKEN end_char="2199" id="token-16-24" morph="none" pos="punct" start_char="2198">‘,</TOKEN>
<TOKEN end_char="2208" id="token-16-25" morph="none" pos="word" start_char="2201">escriben</TOKEN>
<TOKEN end_char="2212" id="token-16-26" morph="none" pos="word" start_char="2210">los</TOKEN>
<TOKEN end_char="2227" id="token-16-27" morph="none" pos="word" start_char="2214">investigadores</TOKEN>
<TOKEN end_char="2230" id="token-16-28" morph="none" pos="word" start_char="2229">en</TOKEN>
<TOKEN end_char="2233" id="token-16-29" morph="none" pos="word" start_char="2232">su</TOKEN>
<TOKEN end_char="2241" id="token-16-30" morph="none" pos="word" start_char="2235">estudio</TOKEN>
<TOKEN end_char="2242" id="token-16-31" morph="none" pos="punct" start_char="2242">,</TOKEN>
<TOKEN end_char="2252" id="token-16-32" morph="none" pos="word" start_char="2244">publicado</TOKEN>
<TOKEN end_char="2255" id="token-16-33" morph="none" pos="word" start_char="2254">en</TOKEN>
<TOKEN end_char="2263" id="token-16-34" morph="none" pos="word" start_char="2257">Science</TOKEN>
<TOKEN end_char="2264" id="token-16-35" morph="none" pos="punct" start_char="2264">.</TOKEN>
<TRANSLATED_TEXT>In our main analysis, we assume that November 17 [thick dotted line] represents the first documented case of Covid-19 ', the researchers write in their study, published in Science.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2325" id="segment-17" start_char="2266">
<ORIGINAL_TEXT>Llevaron a cabo un análisis más detallado bajo este supuesto</ORIGINAL_TEXT>
<TOKEN end_char="2273" id="token-17-0" morph="none" pos="word" start_char="2266">Llevaron</TOKEN>
<TOKEN end_char="2275" id="token-17-1" morph="none" pos="word" start_char="2275">a</TOKEN>
<TOKEN end_char="2280" id="token-17-2" morph="none" pos="word" start_char="2277">cabo</TOKEN>
<TOKEN end_char="2283" id="token-17-3" morph="none" pos="word" start_char="2282">un</TOKEN>
<TOKEN end_char="2292" id="token-17-4" morph="none" pos="word" start_char="2285">análisis</TOKEN>
<TOKEN end_char="2296" id="token-17-5" morph="none" pos="word" start_char="2294">más</TOKEN>
<TOKEN end_char="2306" id="token-17-6" morph="none" pos="word" start_char="2298">detallado</TOKEN>
<TOKEN end_char="2311" id="token-17-7" morph="none" pos="word" start_char="2308">bajo</TOKEN>
<TOKEN end_char="2316" id="token-17-8" morph="none" pos="word" start_char="2313">este</TOKEN>
<TOKEN end_char="2325" id="token-17-9" morph="none" pos="word" start_char="2318">supuesto</TOKEN>
<TRANSLATED_TEXT>They carried out a more detailed analysis under this assumption.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2481" id="segment-18" start_char="2329">
<ORIGINAL_TEXT>Los investigadores creen que la fecha del 17 de noviembre [dashed line] fue la primera infección de la cepa SARS-CoV-2 que se extendió por todo el mundo.</ORIGINAL_TEXT>
<TOKEN end_char="2331" id="token-18-0" morph="none" pos="word" start_char="2329">Los</TOKEN>
<TOKEN end_char="2346" id="token-18-1" morph="none" pos="word" start_char="2333">investigadores</TOKEN>
<TOKEN end_char="2352" id="token-18-2" morph="none" pos="word" start_char="2348">creen</TOKEN>
<TOKEN end_char="2356" id="token-18-3" morph="none" pos="word" start_char="2354">que</TOKEN>
<TOKEN end_char="2359" id="token-18-4" morph="none" pos="word" start_char="2358">la</TOKEN>
<TOKEN end_char="2365" id="token-18-5" morph="none" pos="word" start_char="2361">fecha</TOKEN>
<TOKEN end_char="2369" id="token-18-6" morph="none" pos="word" start_char="2367">del</TOKEN>
<TOKEN end_char="2372" id="token-18-7" morph="none" pos="word" start_char="2371">17</TOKEN>
<TOKEN end_char="2375" id="token-18-8" morph="none" pos="word" start_char="2374">de</TOKEN>
<TOKEN end_char="2385" id="token-18-9" morph="none" pos="word" start_char="2377">noviembre</TOKEN>
<TOKEN end_char="2387" id="token-18-10" morph="none" pos="punct" start_char="2387">[</TOKEN>
<TOKEN end_char="2393" id="token-18-11" morph="none" pos="word" start_char="2388">dashed</TOKEN>
<TOKEN end_char="2398" id="token-18-12" morph="none" pos="word" start_char="2395">line</TOKEN>
<TOKEN end_char="2399" id="token-18-13" morph="none" pos="punct" start_char="2399">]</TOKEN>
<TOKEN end_char="2403" id="token-18-14" morph="none" pos="word" start_char="2401">fue</TOKEN>
<TOKEN end_char="2406" id="token-18-15" morph="none" pos="word" start_char="2405">la</TOKEN>
<TOKEN end_char="2414" id="token-18-16" morph="none" pos="word" start_char="2408">primera</TOKEN>
<TOKEN end_char="2424" id="token-18-17" morph="none" pos="word" start_char="2416">infección</TOKEN>
<TOKEN end_char="2427" id="token-18-18" morph="none" pos="word" start_char="2426">de</TOKEN>
<TOKEN end_char="2430" id="token-18-19" morph="none" pos="word" start_char="2429">la</TOKEN>
<TOKEN end_char="2435" id="token-18-20" morph="none" pos="word" start_char="2432">cepa</TOKEN>
<TOKEN end_char="2446" id="token-18-21" morph="none" pos="unknown" start_char="2437">SARS-CoV-2</TOKEN>
<TOKEN end_char="2450" id="token-18-22" morph="none" pos="word" start_char="2448">que</TOKEN>
<TOKEN end_char="2453" id="token-18-23" morph="none" pos="word" start_char="2452">se</TOKEN>
<TOKEN end_char="2462" id="token-18-24" morph="none" pos="word" start_char="2455">extendió</TOKEN>
<TOKEN end_char="2466" id="token-18-25" morph="none" pos="word" start_char="2464">por</TOKEN>
<TOKEN end_char="2471" id="token-18-26" morph="none" pos="word" start_char="2468">todo</TOKEN>
<TOKEN end_char="2474" id="token-18-27" morph="none" pos="word" start_char="2473">el</TOKEN>
<TOKEN end_char="2480" id="token-18-28" morph="none" pos="word" start_char="2476">mundo</TOKEN>
<TOKEN end_char="2481" id="token-18-29" morph="none" pos="punct" start_char="2481">.</TOKEN>
<TRANSLATED_TEXT>Researchers believe the date of November 17 [dashed line] was the first infection of the SARS-CoV-2 strain to spread around the world.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2608" id="segment-19" start_char="2483">
<ORIGINAL_TEXT>Pero es probable que existiera una versión más débil de antemano y es esta la que primero saltó de los animales a los humanos.</ORIGINAL_TEXT>
<TOKEN end_char="2486" id="token-19-0" morph="none" pos="word" start_char="2483">Pero</TOKEN>
<TOKEN end_char="2489" id="token-19-1" morph="none" pos="word" start_char="2488">es</TOKEN>
<TOKEN end_char="2498" id="token-19-2" morph="none" pos="word" start_char="2491">probable</TOKEN>
<TOKEN end_char="2502" id="token-19-3" morph="none" pos="word" start_char="2500">que</TOKEN>
<TOKEN end_char="2512" id="token-19-4" morph="none" pos="word" start_char="2504">existiera</TOKEN>
<TOKEN end_char="2516" id="token-19-5" morph="none" pos="word" start_char="2514">una</TOKEN>
<TOKEN end_char="2524" id="token-19-6" morph="none" pos="word" start_char="2518">versión</TOKEN>
<TOKEN end_char="2528" id="token-19-7" morph="none" pos="word" start_char="2526">más</TOKEN>
<TOKEN end_char="2534" id="token-19-8" morph="none" pos="word" start_char="2530">débil</TOKEN>
<TOKEN end_char="2537" id="token-19-9" morph="none" pos="word" start_char="2536">de</TOKEN>
<TOKEN end_char="2546" id="token-19-10" morph="none" pos="word" start_char="2539">antemano</TOKEN>
<TOKEN end_char="2548" id="token-19-11" morph="none" pos="word" start_char="2548">y</TOKEN>
<TOKEN end_char="2551" id="token-19-12" morph="none" pos="word" start_char="2550">es</TOKEN>
<TOKEN end_char="2556" id="token-19-13" morph="none" pos="word" start_char="2553">esta</TOKEN>
<TOKEN end_char="2559" id="token-19-14" morph="none" pos="word" start_char="2558">la</TOKEN>
<TOKEN end_char="2563" id="token-19-15" morph="none" pos="word" start_char="2561">que</TOKEN>
<TOKEN end_char="2571" id="token-19-16" morph="none" pos="word" start_char="2565">primero</TOKEN>
<TOKEN end_char="2577" id="token-19-17" morph="none" pos="word" start_char="2573">saltó</TOKEN>
<TOKEN end_char="2580" id="token-19-18" morph="none" pos="word" start_char="2579">de</TOKEN>
<TOKEN end_char="2584" id="token-19-19" morph="none" pos="word" start_char="2582">los</TOKEN>
<TOKEN end_char="2593" id="token-19-20" morph="none" pos="word" start_char="2586">animales</TOKEN>
<TOKEN end_char="2595" id="token-19-21" morph="none" pos="word" start_char="2595">a</TOKEN>
<TOKEN end_char="2599" id="token-19-22" morph="none" pos="word" start_char="2597">los</TOKEN>
<TOKEN end_char="2607" id="token-19-23" morph="none" pos="word" start_char="2601">humanos</TOKEN>
<TOKEN end_char="2608" id="token-19-24" morph="none" pos="punct" start_char="2608">.</TOKEN>
<TRANSLATED_TEXT>But it is likely that a weaker version existed in advance, and this is the one that first jumped from animals to humans.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2722" id="segment-20" start_char="2610">
<ORIGINAL_TEXT>Creen que esta infección transespecífica podría haber ocurrido ya el 7 de octubre (inicio de la pendiente rosada)</ORIGINAL_TEXT>
<TOKEN end_char="2614" id="token-20-0" morph="none" pos="word" start_char="2610">Creen</TOKEN>
<TOKEN end_char="2618" id="token-20-1" morph="none" pos="word" start_char="2616">que</TOKEN>
<TOKEN end_char="2623" id="token-20-2" morph="none" pos="word" start_char="2620">esta</TOKEN>
<TOKEN end_char="2633" id="token-20-3" morph="none" pos="word" start_char="2625">infección</TOKEN>
<TOKEN end_char="2649" id="token-20-4" morph="none" pos="word" start_char="2635">transespecífica</TOKEN>
<TOKEN end_char="2656" id="token-20-5" morph="none" pos="word" start_char="2651">podría</TOKEN>
<TOKEN end_char="2662" id="token-20-6" morph="none" pos="word" start_char="2658">haber</TOKEN>
<TOKEN end_char="2671" id="token-20-7" morph="none" pos="word" start_char="2664">ocurrido</TOKEN>
<TOKEN end_char="2674" id="token-20-8" morph="none" pos="word" start_char="2673">ya</TOKEN>
<TOKEN end_char="2677" id="token-20-9" morph="none" pos="word" start_char="2676">el</TOKEN>
<TOKEN end_char="2679" id="token-20-10" morph="none" pos="word" start_char="2679">7</TOKEN>
<TOKEN end_char="2682" id="token-20-11" morph="none" pos="word" start_char="2681">de</TOKEN>
<TOKEN end_char="2690" id="token-20-12" morph="none" pos="word" start_char="2684">octubre</TOKEN>
<TOKEN end_char="2692" id="token-20-13" morph="none" pos="punct" start_char="2692">(</TOKEN>
<TOKEN end_char="2698" id="token-20-14" morph="none" pos="word" start_char="2693">inicio</TOKEN>
<TOKEN end_char="2701" id="token-20-15" morph="none" pos="word" start_char="2700">de</TOKEN>
<TOKEN end_char="2704" id="token-20-16" morph="none" pos="word" start_char="2703">la</TOKEN>
<TOKEN end_char="2714" id="token-20-17" morph="none" pos="word" start_char="2706">pendiente</TOKEN>
<TOKEN end_char="2721" id="token-20-18" morph="none" pos="word" start_char="2716">rosada</TOKEN>
<TOKEN end_char="2722" id="token-20-19" morph="none" pos="punct" start_char="2722">)</TOKEN>
<TRANSLATED_TEXT>They believe this transspecific infection could have occurred as early as October 7 (start of rosy slope).</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2815" id="segment-21" start_char="2725">
<ORIGINAL_TEXT>La teoría del laboratorio de Wuhan es ABANDONADA por el equipo conjunto de la OMS y Beijing</ORIGINAL_TEXT>
<TOKEN end_char="2726" id="token-21-0" morph="none" pos="word" start_char="2725">La</TOKEN>
<TOKEN end_char="2733" id="token-21-1" morph="none" pos="word" start_char="2728">teoría</TOKEN>
<TOKEN end_char="2737" id="token-21-2" morph="none" pos="word" start_char="2735">del</TOKEN>
<TOKEN end_char="2749" id="token-21-3" morph="none" pos="word" start_char="2739">laboratorio</TOKEN>
<TOKEN end_char="2752" id="token-21-4" morph="none" pos="word" start_char="2751">de</TOKEN>
<TOKEN end_char="2758" id="token-21-5" morph="none" pos="word" start_char="2754">Wuhan</TOKEN>
<TOKEN end_char="2761" id="token-21-6" morph="none" pos="word" start_char="2760">es</TOKEN>
<TOKEN end_char="2772" id="token-21-7" morph="none" pos="word" start_char="2763">ABANDONADA</TOKEN>
<TOKEN end_char="2776" id="token-21-8" morph="none" pos="word" start_char="2774">por</TOKEN>
<TOKEN end_char="2779" id="token-21-9" morph="none" pos="word" start_char="2778">el</TOKEN>
<TOKEN end_char="2786" id="token-21-10" morph="none" pos="word" start_char="2781">equipo</TOKEN>
<TOKEN end_char="2795" id="token-21-11" morph="none" pos="word" start_char="2788">conjunto</TOKEN>
<TOKEN end_char="2798" id="token-21-12" morph="none" pos="word" start_char="2797">de</TOKEN>
<TOKEN end_char="2801" id="token-21-13" morph="none" pos="word" start_char="2800">la</TOKEN>
<TOKEN end_char="2805" id="token-21-14" morph="none" pos="word" start_char="2803">OMS</TOKEN>
<TOKEN end_char="2807" id="token-21-15" morph="none" pos="word" start_char="2807">y</TOKEN>
<TOKEN end_char="2815" id="token-21-16" morph="none" pos="word" start_char="2809">Beijing</TOKEN>
<TRANSLATED_TEXT>Wuhan laboratory theory is ABANDONED by the WHO / Beijing joint team</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2996" id="segment-22" start_char="2819">
<ORIGINAL_TEXT>La teoría de que Covid-19 se filtró de un laboratorio de Wuhan ha sido abandonada por los expertos de la OMS que investigan los orígenes de la pandemia, dice un científico chino.</ORIGINAL_TEXT>
<TOKEN end_char="2820" id="token-22-0" morph="none" pos="word" start_char="2819">La</TOKEN>
<TOKEN end_char="2827" id="token-22-1" morph="none" pos="word" start_char="2822">teoría</TOKEN>
<TOKEN end_char="2830" id="token-22-2" morph="none" pos="word" start_char="2829">de</TOKEN>
<TOKEN end_char="2834" id="token-22-3" morph="none" pos="word" start_char="2832">que</TOKEN>
<TOKEN end_char="2843" id="token-22-4" morph="none" pos="unknown" start_char="2836">Covid-19</TOKEN>
<TOKEN end_char="2846" id="token-22-5" morph="none" pos="word" start_char="2845">se</TOKEN>
<TOKEN end_char="2853" id="token-22-6" morph="none" pos="word" start_char="2848">filtró</TOKEN>
<TOKEN end_char="2856" id="token-22-7" morph="none" pos="word" start_char="2855">de</TOKEN>
<TOKEN end_char="2859" id="token-22-8" morph="none" pos="word" start_char="2858">un</TOKEN>
<TOKEN end_char="2871" id="token-22-9" morph="none" pos="word" start_char="2861">laboratorio</TOKEN>
<TOKEN end_char="2874" id="token-22-10" morph="none" pos="word" start_char="2873">de</TOKEN>
<TOKEN end_char="2880" id="token-22-11" morph="none" pos="word" start_char="2876">Wuhan</TOKEN>
<TOKEN end_char="2883" id="token-22-12" morph="none" pos="word" start_char="2882">ha</TOKEN>
<TOKEN end_char="2888" id="token-22-13" morph="none" pos="word" start_char="2885">sido</TOKEN>
<TOKEN end_char="2899" id="token-22-14" morph="none" pos="word" start_char="2890">abandonada</TOKEN>
<TOKEN end_char="2903" id="token-22-15" morph="none" pos="word" start_char="2901">por</TOKEN>
<TOKEN end_char="2907" id="token-22-16" morph="none" pos="word" start_char="2905">los</TOKEN>
<TOKEN end_char="2916" id="token-22-17" morph="none" pos="word" start_char="2909">expertos</TOKEN>
<TOKEN end_char="2919" id="token-22-18" morph="none" pos="word" start_char="2918">de</TOKEN>
<TOKEN end_char="2922" id="token-22-19" morph="none" pos="word" start_char="2921">la</TOKEN>
<TOKEN end_char="2926" id="token-22-20" morph="none" pos="word" start_char="2924">OMS</TOKEN>
<TOKEN end_char="2930" id="token-22-21" morph="none" pos="word" start_char="2928">que</TOKEN>
<TOKEN end_char="2941" id="token-22-22" morph="none" pos="word" start_char="2932">investigan</TOKEN>
<TOKEN end_char="2945" id="token-22-23" morph="none" pos="word" start_char="2943">los</TOKEN>
<TOKEN end_char="2954" id="token-22-24" morph="none" pos="word" start_char="2947">orígenes</TOKEN>
<TOKEN end_char="2957" id="token-22-25" morph="none" pos="word" start_char="2956">de</TOKEN>
<TOKEN end_char="2960" id="token-22-26" morph="none" pos="word" start_char="2959">la</TOKEN>
<TOKEN end_char="2969" id="token-22-27" morph="none" pos="word" start_char="2962">pandemia</TOKEN>
<TOKEN end_char="2970" id="token-22-28" morph="none" pos="punct" start_char="2970">,</TOKEN>
<TOKEN end_char="2975" id="token-22-29" morph="none" pos="word" start_char="2972">dice</TOKEN>
<TOKEN end_char="2978" id="token-22-30" morph="none" pos="word" start_char="2977">un</TOKEN>
<TOKEN end_char="2989" id="token-22-31" morph="none" pos="word" start_char="2980">científico</TOKEN>
<TOKEN end_char="2995" id="token-22-32" morph="none" pos="word" start_char="2991">chino</TOKEN>
<TOKEN end_char="2996" id="token-22-33" morph="none" pos="punct" start_char="2996">.</TOKEN>
<TRANSLATED_TEXT>The theory that Covid-19 leaked from a Wuhan laboratory has been abandoned by WHO experts investigating the origins of the pandemic, says a Chinese scientist.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3197" id="segment-23" start_char="2999">
<ORIGINAL_TEXT>El panel conjunto OMS-Beijing debe emitir su informe políticamente sensible la próxima semana luego de una visita a Wuhan en enero y febrero, que generó más preguntas sobre la transparencia de China.</ORIGINAL_TEXT>
<TOKEN end_char="3000" id="token-23-0" morph="none" pos="word" start_char="2999">El</TOKEN>
<TOKEN end_char="3006" id="token-23-1" morph="none" pos="word" start_char="3002">panel</TOKEN>
<TOKEN end_char="3015" id="token-23-2" morph="none" pos="word" start_char="3008">conjunto</TOKEN>
<TOKEN end_char="3027" id="token-23-3" morph="none" pos="unknown" start_char="3017">OMS-Beijing</TOKEN>
<TOKEN end_char="3032" id="token-23-4" morph="none" pos="word" start_char="3029">debe</TOKEN>
<TOKEN end_char="3039" id="token-23-5" morph="none" pos="word" start_char="3034">emitir</TOKEN>
<TOKEN end_char="3042" id="token-23-6" morph="none" pos="word" start_char="3041">su</TOKEN>
<TOKEN end_char="3050" id="token-23-7" morph="none" pos="word" start_char="3044">informe</TOKEN>
<TOKEN end_char="3064" id="token-23-8" morph="none" pos="word" start_char="3052">políticamente</TOKEN>
<TOKEN end_char="3073" id="token-23-9" morph="none" pos="word" start_char="3066">sensible</TOKEN>
<TOKEN end_char="3076" id="token-23-10" morph="none" pos="word" start_char="3075">la</TOKEN>
<TOKEN end_char="3084" id="token-23-11" morph="none" pos="word" start_char="3078">próxima</TOKEN>
<TOKEN end_char="3091" id="token-23-12" morph="none" pos="word" start_char="3086">semana</TOKEN>
<TOKEN end_char="3097" id="token-23-13" morph="none" pos="word" start_char="3093">luego</TOKEN>
<TOKEN end_char="3100" id="token-23-14" morph="none" pos="word" start_char="3099">de</TOKEN>
<TOKEN end_char="3104" id="token-23-15" morph="none" pos="word" start_char="3102">una</TOKEN>
<TOKEN end_char="3111" id="token-23-16" morph="none" pos="word" start_char="3106">visita</TOKEN>
<TOKEN end_char="3113" id="token-23-17" morph="none" pos="word" start_char="3113">a</TOKEN>
<TOKEN end_char="3119" id="token-23-18" morph="none" pos="word" start_char="3115">Wuhan</TOKEN>
<TOKEN end_char="3122" id="token-23-19" morph="none" pos="word" start_char="3121">en</TOKEN>
<TOKEN end_char="3128" id="token-23-20" morph="none" pos="word" start_char="3124">enero</TOKEN>
<TOKEN end_char="3130" id="token-23-21" morph="none" pos="word" start_char="3130">y</TOKEN>
<TOKEN end_char="3138" id="token-23-22" morph="none" pos="word" start_char="3132">febrero</TOKEN>
<TOKEN end_char="3139" id="token-23-23" morph="none" pos="punct" start_char="3139">,</TOKEN>
<TOKEN end_char="3143" id="token-23-24" morph="none" pos="word" start_char="3141">que</TOKEN>
<TOKEN end_char="3150" id="token-23-25" morph="none" pos="word" start_char="3145">generó</TOKEN>
<TOKEN end_char="3154" id="token-23-26" morph="none" pos="word" start_char="3152">más</TOKEN>
<TOKEN end_char="3164" id="token-23-27" morph="none" pos="word" start_char="3156">preguntas</TOKEN>
<TOKEN end_char="3170" id="token-23-28" morph="none" pos="word" start_char="3166">sobre</TOKEN>
<TOKEN end_char="3173" id="token-23-29" morph="none" pos="word" start_char="3172">la</TOKEN>
<TOKEN end_char="3187" id="token-23-30" morph="none" pos="word" start_char="3175">transparencia</TOKEN>
<TOKEN end_char="3190" id="token-23-31" morph="none" pos="word" start_char="3189">de</TOKEN>
<TOKEN end_char="3196" id="token-23-32" morph="none" pos="word" start_char="3192">China</TOKEN>
<TOKEN end_char="3197" id="token-23-33" morph="none" pos="punct" start_char="3197">.</TOKEN>
<TRANSLATED_TEXT>The WHO-Beijing joint panel is due to issue its politically sensitive report next week, following a visit to Wuhan in January and February, which raised more questions about China's transparency.............</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3444" id="segment-24" start_char="3200">
<ORIGINAL_TEXT>La OMS dice que el informe aún no está terminado, pero Liang Wannian, el jefe del ala china del panel, dijo a los medios estatales que la teoría de la fuga de laboratorio se había considerado «extremadamente improbable» y no se investigaría más.</ORIGINAL_TEXT>
<TOKEN end_char="3201" id="token-24-0" morph="none" pos="word" start_char="3200">La</TOKEN>
<TOKEN end_char="3205" id="token-24-1" morph="none" pos="word" start_char="3203">OMS</TOKEN>
<TOKEN end_char="3210" id="token-24-2" morph="none" pos="word" start_char="3207">dice</TOKEN>
<TOKEN end_char="3214" id="token-24-3" morph="none" pos="word" start_char="3212">que</TOKEN>
<TOKEN end_char="3217" id="token-24-4" morph="none" pos="word" start_char="3216">el</TOKEN>
<TOKEN end_char="3225" id="token-24-5" morph="none" pos="word" start_char="3219">informe</TOKEN>
<TOKEN end_char="3229" id="token-24-6" morph="none" pos="word" start_char="3227">aún</TOKEN>
<TOKEN end_char="3232" id="token-24-7" morph="none" pos="word" start_char="3231">no</TOKEN>
<TOKEN end_char="3237" id="token-24-8" morph="none" pos="word" start_char="3234">está</TOKEN>
<TOKEN end_char="3247" id="token-24-9" morph="none" pos="word" start_char="3239">terminado</TOKEN>
<TOKEN end_char="3248" id="token-24-10" morph="none" pos="punct" start_char="3248">,</TOKEN>
<TOKEN end_char="3253" id="token-24-11" morph="none" pos="word" start_char="3250">pero</TOKEN>
<TOKEN end_char="3259" id="token-24-12" morph="none" pos="word" start_char="3255">Liang</TOKEN>
<TOKEN end_char="3267" id="token-24-13" morph="none" pos="word" start_char="3261">Wannian</TOKEN>
<TOKEN end_char="3268" id="token-24-14" morph="none" pos="punct" start_char="3268">,</TOKEN>
<TOKEN end_char="3271" id="token-24-15" morph="none" pos="word" start_char="3270">el</TOKEN>
<TOKEN end_char="3276" id="token-24-16" morph="none" pos="word" start_char="3273">jefe</TOKEN>
<TOKEN end_char="3280" id="token-24-17" morph="none" pos="word" start_char="3278">del</TOKEN>
<TOKEN end_char="3284" id="token-24-18" morph="none" pos="word" start_char="3282">ala</TOKEN>
<TOKEN end_char="3290" id="token-24-19" morph="none" pos="word" start_char="3286">china</TOKEN>
<TOKEN end_char="3294" id="token-24-20" morph="none" pos="word" start_char="3292">del</TOKEN>
<TOKEN end_char="3300" id="token-24-21" morph="none" pos="word" start_char="3296">panel</TOKEN>
<TOKEN end_char="3301" id="token-24-22" morph="none" pos="punct" start_char="3301">,</TOKEN>
<TOKEN end_char="3306" id="token-24-23" morph="none" pos="word" start_char="3303">dijo</TOKEN>
<TOKEN end_char="3308" id="token-24-24" morph="none" pos="word" start_char="3308">a</TOKEN>
<TOKEN end_char="3312" id="token-24-25" morph="none" pos="word" start_char="3310">los</TOKEN>
<TOKEN end_char="3319" id="token-24-26" morph="none" pos="word" start_char="3314">medios</TOKEN>
<TOKEN end_char="3329" id="token-24-27" morph="none" pos="word" start_char="3321">estatales</TOKEN>
<TOKEN end_char="3333" id="token-24-28" morph="none" pos="word" start_char="3331">que</TOKEN>
<TOKEN end_char="3336" id="token-24-29" morph="none" pos="word" start_char="3335">la</TOKEN>
<TOKEN end_char="3343" id="token-24-30" morph="none" pos="word" start_char="3338">teoría</TOKEN>
<TOKEN end_char="3346" id="token-24-31" morph="none" pos="word" start_char="3345">de</TOKEN>
<TOKEN end_char="3349" id="token-24-32" morph="none" pos="word" start_char="3348">la</TOKEN>
<TOKEN end_char="3354" id="token-24-33" morph="none" pos="word" start_char="3351">fuga</TOKEN>
<TOKEN end_char="3357" id="token-24-34" morph="none" pos="word" start_char="3356">de</TOKEN>
<TOKEN end_char="3369" id="token-24-35" morph="none" pos="word" start_char="3359">laboratorio</TOKEN>
<TOKEN end_char="3372" id="token-24-36" morph="none" pos="word" start_char="3371">se</TOKEN>
<TOKEN end_char="3378" id="token-24-37" morph="none" pos="word" start_char="3374">había</TOKEN>
<TOKEN end_char="3390" id="token-24-38" morph="none" pos="word" start_char="3380">considerado</TOKEN>
<TOKEN end_char="3392" id="token-24-39" morph="none" pos="punct" start_char="3392">«</TOKEN>
<TOKEN end_char="3406" id="token-24-40" morph="none" pos="word" start_char="3393">extremadamente</TOKEN>
<TOKEN end_char="3417" id="token-24-41" morph="none" pos="word" start_char="3408">improbable</TOKEN>
<TOKEN end_char="3418" id="token-24-42" morph="none" pos="punct" start_char="3418">»</TOKEN>
<TOKEN end_char="3420" id="token-24-43" morph="none" pos="word" start_char="3420">y</TOKEN>
<TOKEN end_char="3423" id="token-24-44" morph="none" pos="word" start_char="3422">no</TOKEN>
<TOKEN end_char="3426" id="token-24-45" morph="none" pos="word" start_char="3425">se</TOKEN>
<TOKEN end_char="3439" id="token-24-46" morph="none" pos="word" start_char="3428">investigaría</TOKEN>
<TOKEN end_char="3443" id="token-24-47" morph="none" pos="word" start_char="3441">más</TOKEN>
<TOKEN end_char="3444" id="token-24-48" morph="none" pos="punct" start_char="3444">.</TOKEN>
<TRANSLATED_TEXT>The WHO says the report is not yet finished, but Liang Wannian, the head of the Chinese wing of the panel, told state media that the lab leak theory had been deemed "extremely unlikely" and would not be investigated further.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3581" id="segment-25" start_char="3447">
<ORIGINAL_TEXT>«Las futuras misiones de rastreo del origen de los virus ya no se centrarán en esta área, a menos que haya nuevas pruebas», dijo Liang.</ORIGINAL_TEXT>
<TOKEN end_char="3447" id="token-25-0" morph="none" pos="punct" start_char="3447">«</TOKEN>
<TOKEN end_char="3450" id="token-25-1" morph="none" pos="word" start_char="3448">Las</TOKEN>
<TOKEN end_char="3458" id="token-25-2" morph="none" pos="word" start_char="3452">futuras</TOKEN>
<TOKEN end_char="3467" id="token-25-3" morph="none" pos="word" start_char="3460">misiones</TOKEN>
<TOKEN end_char="3470" id="token-25-4" morph="none" pos="word" start_char="3469">de</TOKEN>
<TOKEN end_char="3478" id="token-25-5" morph="none" pos="word" start_char="3472">rastreo</TOKEN>
<TOKEN end_char="3482" id="token-25-6" morph="none" pos="word" start_char="3480">del</TOKEN>
<TOKEN end_char="3489" id="token-25-7" morph="none" pos="word" start_char="3484">origen</TOKEN>
<TOKEN end_char="3492" id="token-25-8" morph="none" pos="word" start_char="3491">de</TOKEN>
<TOKEN end_char="3496" id="token-25-9" morph="none" pos="word" start_char="3494">los</TOKEN>
<TOKEN end_char="3502" id="token-25-10" morph="none" pos="word" start_char="3498">virus</TOKEN>
<TOKEN end_char="3505" id="token-25-11" morph="none" pos="word" start_char="3504">ya</TOKEN>
<TOKEN end_char="3508" id="token-25-12" morph="none" pos="word" start_char="3507">no</TOKEN>
<TOKEN end_char="3511" id="token-25-13" morph="none" pos="word" start_char="3510">se</TOKEN>
<TOKEN end_char="3521" id="token-25-14" morph="none" pos="word" start_char="3513">centrarán</TOKEN>
<TOKEN end_char="3524" id="token-25-15" morph="none" pos="word" start_char="3523">en</TOKEN>
<TOKEN end_char="3529" id="token-25-16" morph="none" pos="word" start_char="3526">esta</TOKEN>
<TOKEN end_char="3534" id="token-25-17" morph="none" pos="word" start_char="3531">área</TOKEN>
<TOKEN end_char="3535" id="token-25-18" morph="none" pos="punct" start_char="3535">,</TOKEN>
<TOKEN end_char="3537" id="token-25-19" morph="none" pos="word" start_char="3537">a</TOKEN>
<TOKEN end_char="3543" id="token-25-20" morph="none" pos="word" start_char="3539">menos</TOKEN>
<TOKEN end_char="3547" id="token-25-21" morph="none" pos="word" start_char="3545">que</TOKEN>
<TOKEN end_char="3552" id="token-25-22" morph="none" pos="word" start_char="3549">haya</TOKEN>
<TOKEN end_char="3559" id="token-25-23" morph="none" pos="word" start_char="3554">nuevas</TOKEN>
<TOKEN end_char="3567" id="token-25-24" morph="none" pos="word" start_char="3561">pruebas</TOKEN>
<TOKEN end_char="3569" id="token-25-25" morph="none" pos="punct" start_char="3568">»,</TOKEN>
<TOKEN end_char="3574" id="token-25-26" morph="none" pos="word" start_char="3571">dijo</TOKEN>
<TOKEN end_char="3580" id="token-25-27" morph="none" pos="word" start_char="3576">Liang</TOKEN>
<TOKEN end_char="3581" id="token-25-28" morph="none" pos="punct" start_char="3581">.</TOKEN>
<TRANSLATED_TEXT>"Future virus origin tracking missions will no longer focus on this area unless there is further evidence," Liang said.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3745" id="segment-26" start_char="3583">
<ORIGINAL_TEXT>Añadió que los hallazgos fueron el ‘consenso’ de la OMS y los científicos chinos, negando que el informe se haya retrasado debido a desacuerdos entre los expertos.</ORIGINAL_TEXT>
<TOKEN end_char="3588" id="token-26-0" morph="none" pos="word" start_char="3583">Añadió</TOKEN>
<TOKEN end_char="3592" id="token-26-1" morph="none" pos="word" start_char="3590">que</TOKEN>
<TOKEN end_char="3596" id="token-26-2" morph="none" pos="word" start_char="3594">los</TOKEN>
<TOKEN end_char="3606" id="token-26-3" morph="none" pos="word" start_char="3598">hallazgos</TOKEN>
<TOKEN end_char="3613" id="token-26-4" morph="none" pos="word" start_char="3608">fueron</TOKEN>
<TOKEN end_char="3616" id="token-26-5" morph="none" pos="word" start_char="3615">el</TOKEN>
<TOKEN end_char="3618" id="token-26-6" morph="none" pos="punct" start_char="3618">‘</TOKEN>
<TOKEN end_char="3626" id="token-26-7" morph="none" pos="word" start_char="3619">consenso</TOKEN>
<TOKEN end_char="3627" id="token-26-8" morph="none" pos="punct" start_char="3627">’</TOKEN>
<TOKEN end_char="3630" id="token-26-9" morph="none" pos="word" start_char="3629">de</TOKEN>
<TOKEN end_char="3633" id="token-26-10" morph="none" pos="word" start_char="3632">la</TOKEN>
<TOKEN end_char="3637" id="token-26-11" morph="none" pos="word" start_char="3635">OMS</TOKEN>
<TOKEN end_char="3639" id="token-26-12" morph="none" pos="word" start_char="3639">y</TOKEN>
<TOKEN end_char="3643" id="token-26-13" morph="none" pos="word" start_char="3641">los</TOKEN>
<TOKEN end_char="3655" id="token-26-14" morph="none" pos="word" start_char="3645">científicos</TOKEN>
<TOKEN end_char="3662" id="token-26-15" morph="none" pos="word" start_char="3657">chinos</TOKEN>
<TOKEN end_char="3663" id="token-26-16" morph="none" pos="punct" start_char="3663">,</TOKEN>
<TOKEN end_char="3671" id="token-26-17" morph="none" pos="word" start_char="3665">negando</TOKEN>
<TOKEN end_char="3675" id="token-26-18" morph="none" pos="word" start_char="3673">que</TOKEN>
<TOKEN end_char="3678" id="token-26-19" morph="none" pos="word" start_char="3677">el</TOKEN>
<TOKEN end_char="3686" id="token-26-20" morph="none" pos="word" start_char="3680">informe</TOKEN>
<TOKEN end_char="3689" id="token-26-21" morph="none" pos="word" start_char="3688">se</TOKEN>
<TOKEN end_char="3694" id="token-26-22" morph="none" pos="word" start_char="3691">haya</TOKEN>
<TOKEN end_char="3704" id="token-26-23" morph="none" pos="word" start_char="3696">retrasado</TOKEN>
<TOKEN end_char="3711" id="token-26-24" morph="none" pos="word" start_char="3706">debido</TOKEN>
<TOKEN end_char="3713" id="token-26-25" morph="none" pos="word" start_char="3713">a</TOKEN>
<TOKEN end_char="3725" id="token-26-26" morph="none" pos="word" start_char="3715">desacuerdos</TOKEN>
<TOKEN end_char="3731" id="token-26-27" morph="none" pos="word" start_char="3727">entre</TOKEN>
<TOKEN end_char="3735" id="token-26-28" morph="none" pos="word" start_char="3733">los</TOKEN>
<TOKEN end_char="3744" id="token-26-29" morph="none" pos="word" start_char="3737">expertos</TOKEN>
<TOKEN end_char="3745" id="token-26-30" morph="none" pos="punct" start_char="3745">.</TOKEN>
<TRANSLATED_TEXT>He added that the findings were the 'consensus' of WHO and Chinese scientists, denying that the report was delayed due to disagreements among experts.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3936" id="segment-27" start_char="3748">
<ORIGINAL_TEXT>El informe tan esperado debe examinar una variedad de teorías sobre cómo el virus saltó por primera vez de los animales a los humanos, con los murciélagos entre los principales sospechosos.</ORIGINAL_TEXT>
<TOKEN end_char="3749" id="token-27-0" morph="none" pos="word" start_char="3748">El</TOKEN>
<TOKEN end_char="3757" id="token-27-1" morph="none" pos="word" start_char="3751">informe</TOKEN>
<TOKEN end_char="3761" id="token-27-2" morph="none" pos="word" start_char="3759">tan</TOKEN>
<TOKEN end_char="3770" id="token-27-3" morph="none" pos="word" start_char="3763">esperado</TOKEN>
<TOKEN end_char="3775" id="token-27-4" morph="none" pos="word" start_char="3772">debe</TOKEN>
<TOKEN end_char="3784" id="token-27-5" morph="none" pos="word" start_char="3777">examinar</TOKEN>
<TOKEN end_char="3788" id="token-27-6" morph="none" pos="word" start_char="3786">una</TOKEN>
<TOKEN end_char="3797" id="token-27-7" morph="none" pos="word" start_char="3790">variedad</TOKEN>
<TOKEN end_char="3800" id="token-27-8" morph="none" pos="word" start_char="3799">de</TOKEN>
<TOKEN end_char="3808" id="token-27-9" morph="none" pos="word" start_char="3802">teorías</TOKEN>
<TOKEN end_char="3814" id="token-27-10" morph="none" pos="word" start_char="3810">sobre</TOKEN>
<TOKEN end_char="3819" id="token-27-11" morph="none" pos="word" start_char="3816">cómo</TOKEN>
<TOKEN end_char="3822" id="token-27-12" morph="none" pos="word" start_char="3821">el</TOKEN>
<TOKEN end_char="3828" id="token-27-13" morph="none" pos="word" start_char="3824">virus</TOKEN>
<TOKEN end_char="3834" id="token-27-14" morph="none" pos="word" start_char="3830">saltó</TOKEN>
<TOKEN end_char="3838" id="token-27-15" morph="none" pos="word" start_char="3836">por</TOKEN>
<TOKEN end_char="3846" id="token-27-16" morph="none" pos="word" start_char="3840">primera</TOKEN>
<TOKEN end_char="3850" id="token-27-17" morph="none" pos="word" start_char="3848">vez</TOKEN>
<TOKEN end_char="3853" id="token-27-18" morph="none" pos="word" start_char="3852">de</TOKEN>
<TOKEN end_char="3857" id="token-27-19" morph="none" pos="word" start_char="3855">los</TOKEN>
<TOKEN end_char="3866" id="token-27-20" morph="none" pos="word" start_char="3859">animales</TOKEN>
<TOKEN end_char="3868" id="token-27-21" morph="none" pos="word" start_char="3868">a</TOKEN>
<TOKEN end_char="3872" id="token-27-22" morph="none" pos="word" start_char="3870">los</TOKEN>
<TOKEN end_char="3880" id="token-27-23" morph="none" pos="word" start_char="3874">humanos</TOKEN>
<TOKEN end_char="3881" id="token-27-24" morph="none" pos="punct" start_char="3881">,</TOKEN>
<TOKEN end_char="3885" id="token-27-25" morph="none" pos="word" start_char="3883">con</TOKEN>
<TOKEN end_char="3889" id="token-27-26" morph="none" pos="word" start_char="3887">los</TOKEN>
<TOKEN end_char="3901" id="token-27-27" morph="none" pos="word" start_char="3891">murciélagos</TOKEN>
<TOKEN end_char="3907" id="token-27-28" morph="none" pos="word" start_char="3903">entre</TOKEN>
<TOKEN end_char="3911" id="token-27-29" morph="none" pos="word" start_char="3909">los</TOKEN>
<TOKEN end_char="3923" id="token-27-30" morph="none" pos="word" start_char="3913">principales</TOKEN>
<TOKEN end_char="3935" id="token-27-31" morph="none" pos="word" start_char="3925">sospechosos</TOKEN>
<TOKEN end_char="3936" id="token-27-32" morph="none" pos="punct" start_char="3936">.</TOKEN>
<TRANSLATED_TEXT>The long-awaited report must examine a variety of theories about how the virus first jumped from animals to humans, with bats among the main suspects.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4117" id="segment-28" start_char="3939">
<ORIGINAL_TEXT>Pero Washington y otros han promocionado teorías de que el brote no fue causado por la naturaleza sino por una fuga o un accidente en un laboratorio de virología secreto de Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="3942" id="token-28-0" morph="none" pos="word" start_char="3939">Pero</TOKEN>
<TOKEN end_char="3953" id="token-28-1" morph="none" pos="word" start_char="3944">Washington</TOKEN>
<TOKEN end_char="3955" id="token-28-2" morph="none" pos="word" start_char="3955">y</TOKEN>
<TOKEN end_char="3961" id="token-28-3" morph="none" pos="word" start_char="3957">otros</TOKEN>
<TOKEN end_char="3965" id="token-28-4" morph="none" pos="word" start_char="3963">han</TOKEN>
<TOKEN end_char="3978" id="token-28-5" morph="none" pos="word" start_char="3967">promocionado</TOKEN>
<TOKEN end_char="3986" id="token-28-6" morph="none" pos="word" start_char="3980">teorías</TOKEN>
<TOKEN end_char="3989" id="token-28-7" morph="none" pos="word" start_char="3988">de</TOKEN>
<TOKEN end_char="3993" id="token-28-8" morph="none" pos="word" start_char="3991">que</TOKEN>
<TOKEN end_char="3996" id="token-28-9" morph="none" pos="word" start_char="3995">el</TOKEN>
<TOKEN end_char="4002" id="token-28-10" morph="none" pos="word" start_char="3998">brote</TOKEN>
<TOKEN end_char="4005" id="token-28-11" morph="none" pos="word" start_char="4004">no</TOKEN>
<TOKEN end_char="4009" id="token-28-12" morph="none" pos="word" start_char="4007">fue</TOKEN>
<TOKEN end_char="4017" id="token-28-13" morph="none" pos="word" start_char="4011">causado</TOKEN>
<TOKEN end_char="4021" id="token-28-14" morph="none" pos="word" start_char="4019">por</TOKEN>
<TOKEN end_char="4024" id="token-28-15" morph="none" pos="word" start_char="4023">la</TOKEN>
<TOKEN end_char="4035" id="token-28-16" morph="none" pos="word" start_char="4026">naturaleza</TOKEN>
<TOKEN end_char="4040" id="token-28-17" morph="none" pos="word" start_char="4037">sino</TOKEN>
<TOKEN end_char="4044" id="token-28-18" morph="none" pos="word" start_char="4042">por</TOKEN>
<TOKEN end_char="4048" id="token-28-19" morph="none" pos="word" start_char="4046">una</TOKEN>
<TOKEN end_char="4053" id="token-28-20" morph="none" pos="word" start_char="4050">fuga</TOKEN>
<TOKEN end_char="4055" id="token-28-21" morph="none" pos="word" start_char="4055">o</TOKEN>
<TOKEN end_char="4058" id="token-28-22" morph="none" pos="word" start_char="4057">un</TOKEN>
<TOKEN end_char="4068" id="token-28-23" morph="none" pos="word" start_char="4060">accidente</TOKEN>
<TOKEN end_char="4071" id="token-28-24" morph="none" pos="word" start_char="4070">en</TOKEN>
<TOKEN end_char="4074" id="token-28-25" morph="none" pos="word" start_char="4073">un</TOKEN>
<TOKEN end_char="4086" id="token-28-26" morph="none" pos="word" start_char="4076">laboratorio</TOKEN>
<TOKEN end_char="4089" id="token-28-27" morph="none" pos="word" start_char="4088">de</TOKEN>
<TOKEN end_char="4099" id="token-28-28" morph="none" pos="word" start_char="4091">virología</TOKEN>
<TOKEN end_char="4107" id="token-28-29" morph="none" pos="word" start_char="4101">secreto</TOKEN>
<TOKEN end_char="4110" id="token-28-30" morph="none" pos="word" start_char="4109">de</TOKEN>
<TOKEN end_char="4116" id="token-28-31" morph="none" pos="word" start_char="4112">Wuhan</TOKEN>
<TOKEN end_char="4117" id="token-28-32" morph="none" pos="punct" start_char="4117">.</TOKEN>
<TRANSLATED_TEXT>But Washington and others have promoted theories that the outbreak was not caused by nature but by a leak or accident at a secret virology laboratory in Wuhan.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4245" id="segment-29" start_char="4120">
<ORIGINAL_TEXT>Su equipo analizó 583 muestras de virus tempranas de Hubei para encontrar su último ancestro común del que todos descendieron.</ORIGINAL_TEXT>
<TOKEN end_char="4121" id="token-29-0" morph="none" pos="word" start_char="4120">Su</TOKEN>
<TOKEN end_char="4128" id="token-29-1" morph="none" pos="word" start_char="4123">equipo</TOKEN>
<TOKEN end_char="4136" id="token-29-2" morph="none" pos="word" start_char="4130">analizó</TOKEN>
<TOKEN end_char="4140" id="token-29-3" morph="none" pos="word" start_char="4138">583</TOKEN>
<TOKEN end_char="4149" id="token-29-4" morph="none" pos="word" start_char="4142">muestras</TOKEN>
<TOKEN end_char="4152" id="token-29-5" morph="none" pos="word" start_char="4151">de</TOKEN>
<TOKEN end_char="4158" id="token-29-6" morph="none" pos="word" start_char="4154">virus</TOKEN>
<TOKEN end_char="4168" id="token-29-7" morph="none" pos="word" start_char="4160">tempranas</TOKEN>
<TOKEN end_char="4171" id="token-29-8" morph="none" pos="word" start_char="4170">de</TOKEN>
<TOKEN end_char="4177" id="token-29-9" morph="none" pos="word" start_char="4173">Hubei</TOKEN>
<TOKEN end_char="4182" id="token-29-10" morph="none" pos="word" start_char="4179">para</TOKEN>
<TOKEN end_char="4192" id="token-29-11" morph="none" pos="word" start_char="4184">encontrar</TOKEN>
<TOKEN end_char="4195" id="token-29-12" morph="none" pos="word" start_char="4194">su</TOKEN>
<TOKEN end_char="4202" id="token-29-13" morph="none" pos="word" start_char="4197">último</TOKEN>
<TOKEN end_char="4211" id="token-29-14" morph="none" pos="word" start_char="4204">ancestro</TOKEN>
<TOKEN end_char="4217" id="token-29-15" morph="none" pos="word" start_char="4213">común</TOKEN>
<TOKEN end_char="4221" id="token-29-16" morph="none" pos="word" start_char="4219">del</TOKEN>
<TOKEN end_char="4225" id="token-29-17" morph="none" pos="word" start_char="4223">que</TOKEN>
<TOKEN end_char="4231" id="token-29-18" morph="none" pos="word" start_char="4227">todos</TOKEN>
<TOKEN end_char="4244" id="token-29-19" morph="none" pos="word" start_char="4233">descendieron</TOKEN>
<TOKEN end_char="4245" id="token-29-20" morph="none" pos="punct" start_char="4245">.</TOKEN>
<TRANSLATED_TEXT>His team analyzed 583 samples of early Hubei viruses to find their last common ancestor from which they all descended.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4311" id="segment-30" start_char="4247">
<ORIGINAL_TEXT>Descubrieron que se remontaban aproximadamente al 9 de diciembre.</ORIGINAL_TEXT>
<TOKEN end_char="4258" id="token-30-0" morph="none" pos="word" start_char="4247">Descubrieron</TOKEN>
<TOKEN end_char="4262" id="token-30-1" morph="none" pos="word" start_char="4260">que</TOKEN>
<TOKEN end_char="4265" id="token-30-2" morph="none" pos="word" start_char="4264">se</TOKEN>
<TOKEN end_char="4276" id="token-30-3" morph="none" pos="word" start_char="4267">remontaban</TOKEN>
<TOKEN end_char="4292" id="token-30-4" morph="none" pos="word" start_char="4278">aproximadamente</TOKEN>
<TOKEN end_char="4295" id="token-30-5" morph="none" pos="word" start_char="4294">al</TOKEN>
<TOKEN end_char="4297" id="token-30-6" morph="none" pos="word" start_char="4297">9</TOKEN>
<TOKEN end_char="4300" id="token-30-7" morph="none" pos="word" start_char="4299">de</TOKEN>
<TOKEN end_char="4310" id="token-30-8" morph="none" pos="word" start_char="4302">diciembre</TOKEN>
<TOKEN end_char="4311" id="token-30-9" morph="none" pos="punct" start_char="4311">.</TOKEN>
<TRANSLATED_TEXT>They found that they dated back to about December 9.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4417" id="segment-31" start_char="4314">
<ORIGINAL_TEXT>Pero los medios chinos informaron sobre una condición inusual similar a la neumonía antes de esta fecha.</ORIGINAL_TEXT>
<TOKEN end_char="4317" id="token-31-0" morph="none" pos="word" start_char="4314">Pero</TOKEN>
<TOKEN end_char="4321" id="token-31-1" morph="none" pos="word" start_char="4319">los</TOKEN>
<TOKEN end_char="4328" id="token-31-2" morph="none" pos="word" start_char="4323">medios</TOKEN>
<TOKEN end_char="4335" id="token-31-3" morph="none" pos="word" start_char="4330">chinos</TOKEN>
<TOKEN end_char="4346" id="token-31-4" morph="none" pos="word" start_char="4337">informaron</TOKEN>
<TOKEN end_char="4352" id="token-31-5" morph="none" pos="word" start_char="4348">sobre</TOKEN>
<TOKEN end_char="4356" id="token-31-6" morph="none" pos="word" start_char="4354">una</TOKEN>
<TOKEN end_char="4366" id="token-31-7" morph="none" pos="word" start_char="4358">condición</TOKEN>
<TOKEN end_char="4374" id="token-31-8" morph="none" pos="word" start_char="4368">inusual</TOKEN>
<TOKEN end_char="4382" id="token-31-9" morph="none" pos="word" start_char="4376">similar</TOKEN>
<TOKEN end_char="4384" id="token-31-10" morph="none" pos="word" start_char="4384">a</TOKEN>
<TOKEN end_char="4387" id="token-31-11" morph="none" pos="word" start_char="4386">la</TOKEN>
<TOKEN end_char="4396" id="token-31-12" morph="none" pos="word" start_char="4389">neumonía</TOKEN>
<TOKEN end_char="4402" id="token-31-13" morph="none" pos="word" start_char="4398">antes</TOKEN>
<TOKEN end_char="4405" id="token-31-14" morph="none" pos="word" start_char="4404">de</TOKEN>
<TOKEN end_char="4410" id="token-31-15" morph="none" pos="word" start_char="4407">esta</TOKEN>
<TOKEN end_char="4416" id="token-31-16" morph="none" pos="word" start_char="4412">fecha</TOKEN>
<TOKEN end_char="4417" id="token-31-17" morph="none" pos="punct" start_char="4417">.</TOKEN>
<TRANSLATED_TEXT>But the Chinese media reported an unusual condition similar to pneumonia before this date.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4617" id="segment-32" start_char="4420">
<ORIGINAL_TEXT>Como resultado de esto, los investigadores dicen que la única explicación lógica es que la primera forma del virus que saltó de un animal a un humano fue una cepa débil que se extinguió rápidamente.</ORIGINAL_TEXT>
<TOKEN end_char="4423" id="token-32-0" morph="none" pos="word" start_char="4420">Como</TOKEN>
<TOKEN end_char="4433" id="token-32-1" morph="none" pos="word" start_char="4425">resultado</TOKEN>
<TOKEN end_char="4436" id="token-32-2" morph="none" pos="word" start_char="4435">de</TOKEN>
<TOKEN end_char="4441" id="token-32-3" morph="none" pos="word" start_char="4438">esto</TOKEN>
<TOKEN end_char="4442" id="token-32-4" morph="none" pos="punct" start_char="4442">,</TOKEN>
<TOKEN end_char="4446" id="token-32-5" morph="none" pos="word" start_char="4444">los</TOKEN>
<TOKEN end_char="4461" id="token-32-6" morph="none" pos="word" start_char="4448">investigadores</TOKEN>
<TOKEN end_char="4467" id="token-32-7" morph="none" pos="word" start_char="4463">dicen</TOKEN>
<TOKEN end_char="4471" id="token-32-8" morph="none" pos="word" start_char="4469">que</TOKEN>
<TOKEN end_char="4474" id="token-32-9" morph="none" pos="word" start_char="4473">la</TOKEN>
<TOKEN end_char="4480" id="token-32-10" morph="none" pos="word" start_char="4476">única</TOKEN>
<TOKEN end_char="4492" id="token-32-11" morph="none" pos="word" start_char="4482">explicación</TOKEN>
<TOKEN end_char="4499" id="token-32-12" morph="none" pos="word" start_char="4494">lógica</TOKEN>
<TOKEN end_char="4502" id="token-32-13" morph="none" pos="word" start_char="4501">es</TOKEN>
<TOKEN end_char="4506" id="token-32-14" morph="none" pos="word" start_char="4504">que</TOKEN>
<TOKEN end_char="4509" id="token-32-15" morph="none" pos="word" start_char="4508">la</TOKEN>
<TOKEN end_char="4517" id="token-32-16" morph="none" pos="word" start_char="4511">primera</TOKEN>
<TOKEN end_char="4523" id="token-32-17" morph="none" pos="word" start_char="4519">forma</TOKEN>
<TOKEN end_char="4527" id="token-32-18" morph="none" pos="word" start_char="4525">del</TOKEN>
<TOKEN end_char="4533" id="token-32-19" morph="none" pos="word" start_char="4529">virus</TOKEN>
<TOKEN end_char="4537" id="token-32-20" morph="none" pos="word" start_char="4535">que</TOKEN>
<TOKEN end_char="4543" id="token-32-21" morph="none" pos="word" start_char="4539">saltó</TOKEN>
<TOKEN end_char="4546" id="token-32-22" morph="none" pos="word" start_char="4545">de</TOKEN>
<TOKEN end_char="4549" id="token-32-23" morph="none" pos="word" start_char="4548">un</TOKEN>
<TOKEN end_char="4556" id="token-32-24" morph="none" pos="word" start_char="4551">animal</TOKEN>
<TOKEN end_char="4558" id="token-32-25" morph="none" pos="word" start_char="4558">a</TOKEN>
<TOKEN end_char="4561" id="token-32-26" morph="none" pos="word" start_char="4560">un</TOKEN>
<TOKEN end_char="4568" id="token-32-27" morph="none" pos="word" start_char="4563">humano</TOKEN>
<TOKEN end_char="4572" id="token-32-28" morph="none" pos="word" start_char="4570">fue</TOKEN>
<TOKEN end_char="4576" id="token-32-29" morph="none" pos="word" start_char="4574">una</TOKEN>
<TOKEN end_char="4581" id="token-32-30" morph="none" pos="word" start_char="4578">cepa</TOKEN>
<TOKEN end_char="4587" id="token-32-31" morph="none" pos="word" start_char="4583">débil</TOKEN>
<TOKEN end_char="4591" id="token-32-32" morph="none" pos="word" start_char="4589">que</TOKEN>
<TOKEN end_char="4594" id="token-32-33" morph="none" pos="word" start_char="4593">se</TOKEN>
<TOKEN end_char="4604" id="token-32-34" morph="none" pos="word" start_char="4596">extinguió</TOKEN>
<TOKEN end_char="4616" id="token-32-35" morph="none" pos="word" start_char="4606">rápidamente</TOKEN>
<TOKEN end_char="4617" id="token-32-36" morph="none" pos="punct" start_char="4617">.</TOKEN>
<TRANSLATED_TEXT>As a result, researchers say the only logical explanation is that the first form of the virus that jumped from an animal to a human was a weak strain that quickly became extinct.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4790" id="segment-33" start_char="4620">
<ORIGINAL_TEXT>Pero antes de que desapareciera, los investigadores especulan que mutó para volverse más potente y esta variante luego se extendió por Wuhan y más tarde por todo el mundo.</ORIGINAL_TEXT>
<TOKEN end_char="4623" id="token-33-0" morph="none" pos="word" start_char="4620">Pero</TOKEN>
<TOKEN end_char="4629" id="token-33-1" morph="none" pos="word" start_char="4625">antes</TOKEN>
<TOKEN end_char="4632" id="token-33-2" morph="none" pos="word" start_char="4631">de</TOKEN>
<TOKEN end_char="4636" id="token-33-3" morph="none" pos="word" start_char="4634">que</TOKEN>
<TOKEN end_char="4650" id="token-33-4" morph="none" pos="word" start_char="4638">desapareciera</TOKEN>
<TOKEN end_char="4651" id="token-33-5" morph="none" pos="punct" start_char="4651">,</TOKEN>
<TOKEN end_char="4655" id="token-33-6" morph="none" pos="word" start_char="4653">los</TOKEN>
<TOKEN end_char="4670" id="token-33-7" morph="none" pos="word" start_char="4657">investigadores</TOKEN>
<TOKEN end_char="4680" id="token-33-8" morph="none" pos="word" start_char="4672">especulan</TOKEN>
<TOKEN end_char="4684" id="token-33-9" morph="none" pos="word" start_char="4682">que</TOKEN>
<TOKEN end_char="4689" id="token-33-10" morph="none" pos="word" start_char="4686">mutó</TOKEN>
<TOKEN end_char="4694" id="token-33-11" morph="none" pos="word" start_char="4691">para</TOKEN>
<TOKEN end_char="4703" id="token-33-12" morph="none" pos="word" start_char="4696">volverse</TOKEN>
<TOKEN end_char="4707" id="token-33-13" morph="none" pos="word" start_char="4705">más</TOKEN>
<TOKEN end_char="4715" id="token-33-14" morph="none" pos="word" start_char="4709">potente</TOKEN>
<TOKEN end_char="4717" id="token-33-15" morph="none" pos="word" start_char="4717">y</TOKEN>
<TOKEN end_char="4722" id="token-33-16" morph="none" pos="word" start_char="4719">esta</TOKEN>
<TOKEN end_char="4731" id="token-33-17" morph="none" pos="word" start_char="4724">variante</TOKEN>
<TOKEN end_char="4737" id="token-33-18" morph="none" pos="word" start_char="4733">luego</TOKEN>
<TOKEN end_char="4740" id="token-33-19" morph="none" pos="word" start_char="4739">se</TOKEN>
<TOKEN end_char="4749" id="token-33-20" morph="none" pos="word" start_char="4742">extendió</TOKEN>
<TOKEN end_char="4753" id="token-33-21" morph="none" pos="word" start_char="4751">por</TOKEN>
<TOKEN end_char="4759" id="token-33-22" morph="none" pos="word" start_char="4755">Wuhan</TOKEN>
<TOKEN end_char="4761" id="token-33-23" morph="none" pos="word" start_char="4761">y</TOKEN>
<TOKEN end_char="4765" id="token-33-24" morph="none" pos="word" start_char="4763">más</TOKEN>
<TOKEN end_char="4771" id="token-33-25" morph="none" pos="word" start_char="4767">tarde</TOKEN>
<TOKEN end_char="4775" id="token-33-26" morph="none" pos="word" start_char="4773">por</TOKEN>
<TOKEN end_char="4780" id="token-33-27" morph="none" pos="word" start_char="4777">todo</TOKEN>
<TOKEN end_char="4783" id="token-33-28" morph="none" pos="word" start_char="4782">el</TOKEN>
<TOKEN end_char="4789" id="token-33-29" morph="none" pos="word" start_char="4785">mundo</TOKEN>
<TOKEN end_char="4790" id="token-33-30" morph="none" pos="punct" start_char="4790">.</TOKEN>
<TRANSLATED_TEXT>But before it disappeared, researchers speculate that it mutated to become more powerful and this variant then spread throughout Wuhan and later around the world.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4975" id="segment-34" start_char="4793">
<ORIGINAL_TEXT>« En nuestro análisis principal, asumimos que el 17 de noviembre representa el primer caso documentado de Covid-19 », escriben los investigadores en su estudio, publicado en Ciencias.</ORIGINAL_TEXT>
<TOKEN end_char="4793" id="token-34-0" morph="none" pos="punct" start_char="4793">«</TOKEN>
<TOKEN end_char="4796" id="token-34-1" morph="none" pos="word" start_char="4795">En</TOKEN>
<TOKEN end_char="4804" id="token-34-2" morph="none" pos="word" start_char="4798">nuestro</TOKEN>
<TOKEN end_char="4813" id="token-34-3" morph="none" pos="word" start_char="4806">análisis</TOKEN>
<TOKEN end_char="4823" id="token-34-4" morph="none" pos="word" start_char="4815">principal</TOKEN>
<TOKEN end_char="4824" id="token-34-5" morph="none" pos="punct" start_char="4824">,</TOKEN>
<TOKEN end_char="4833" id="token-34-6" morph="none" pos="word" start_char="4826">asumimos</TOKEN>
<TOKEN end_char="4837" id="token-34-7" morph="none" pos="word" start_char="4835">que</TOKEN>
<TOKEN end_char="4840" id="token-34-8" morph="none" pos="word" start_char="4839">el</TOKEN>
<TOKEN end_char="4843" id="token-34-9" morph="none" pos="word" start_char="4842">17</TOKEN>
<TOKEN end_char="4846" id="token-34-10" morph="none" pos="word" start_char="4845">de</TOKEN>
<TOKEN end_char="4856" id="token-34-11" morph="none" pos="word" start_char="4848">noviembre</TOKEN>
<TOKEN end_char="4867" id="token-34-12" morph="none" pos="word" start_char="4858">representa</TOKEN>
<TOKEN end_char="4870" id="token-34-13" morph="none" pos="word" start_char="4869">el</TOKEN>
<TOKEN end_char="4877" id="token-34-14" morph="none" pos="word" start_char="4872">primer</TOKEN>
<TOKEN end_char="4882" id="token-34-15" morph="none" pos="word" start_char="4879">caso</TOKEN>
<TOKEN end_char="4894" id="token-34-16" morph="none" pos="word" start_char="4884">documentado</TOKEN>
<TOKEN end_char="4897" id="token-34-17" morph="none" pos="word" start_char="4896">de</TOKEN>
<TOKEN end_char="4906" id="token-34-18" morph="none" pos="unknown" start_char="4899">Covid-19</TOKEN>
<TOKEN end_char="4909" id="token-34-19" morph="none" pos="punct" start_char="4908">»,</TOKEN>
<TOKEN end_char="4918" id="token-34-20" morph="none" pos="word" start_char="4911">escriben</TOKEN>
<TOKEN end_char="4922" id="token-34-21" morph="none" pos="word" start_char="4920">los</TOKEN>
<TOKEN end_char="4937" id="token-34-22" morph="none" pos="word" start_char="4924">investigadores</TOKEN>
<TOKEN end_char="4940" id="token-34-23" morph="none" pos="word" start_char="4939">en</TOKEN>
<TOKEN end_char="4943" id="token-34-24" morph="none" pos="word" start_char="4942">su</TOKEN>
<TOKEN end_char="4951" id="token-34-25" morph="none" pos="word" start_char="4945">estudio</TOKEN>
<TOKEN end_char="4952" id="token-34-26" morph="none" pos="punct" start_char="4952">,</TOKEN>
<TOKEN end_char="4962" id="token-34-27" morph="none" pos="word" start_char="4954">publicado</TOKEN>
<TOKEN end_char="4965" id="token-34-28" morph="none" pos="word" start_char="4964">en</TOKEN>
<TOKEN end_char="4974" id="token-34-29" morph="none" pos="word" start_char="4967">Ciencias</TOKEN>
<TOKEN end_char="4975" id="token-34-30" morph="none" pos="punct" start_char="4975">.</TOKEN>
<TRANSLATED_TEXT>"In our main analysis, we assume that November 17 represents the first documented case of Covid-19," the researchers write in their study, published in Science.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5071" id="segment-35" start_char="4978">
<ORIGINAL_TEXT>Llevaron a cabo un análisis más detallado bajo este supuesto utilizando un modelo informático.</ORIGINAL_TEXT>
<TOKEN end_char="4985" id="token-35-0" morph="none" pos="word" start_char="4978">Llevaron</TOKEN>
<TOKEN end_char="4987" id="token-35-1" morph="none" pos="word" start_char="4987">a</TOKEN>
<TOKEN end_char="4992" id="token-35-2" morph="none" pos="word" start_char="4989">cabo</TOKEN>
<TOKEN end_char="4995" id="token-35-3" morph="none" pos="word" start_char="4994">un</TOKEN>
<TOKEN end_char="5004" id="token-35-4" morph="none" pos="word" start_char="4997">análisis</TOKEN>
<TOKEN end_char="5008" id="token-35-5" morph="none" pos="word" start_char="5006">más</TOKEN>
<TOKEN end_char="5018" id="token-35-6" morph="none" pos="word" start_char="5010">detallado</TOKEN>
<TOKEN end_char="5023" id="token-35-7" morph="none" pos="word" start_char="5020">bajo</TOKEN>
<TOKEN end_char="5028" id="token-35-8" morph="none" pos="word" start_char="5025">este</TOKEN>
<TOKEN end_char="5037" id="token-35-9" morph="none" pos="word" start_char="5030">supuesto</TOKEN>
<TOKEN end_char="5048" id="token-35-10" morph="none" pos="word" start_char="5039">utilizando</TOKEN>
<TOKEN end_char="5051" id="token-35-11" morph="none" pos="word" start_char="5050">un</TOKEN>
<TOKEN end_char="5058" id="token-35-12" morph="none" pos="word" start_char="5053">modelo</TOKEN>
<TOKEN end_char="5070" id="token-35-13" morph="none" pos="word" start_char="5060">informático</TOKEN>
<TOKEN end_char="5071" id="token-35-14" morph="none" pos="punct" start_char="5071">.</TOKEN>
<TRANSLATED_TEXT>They carried out a more detailed analysis under this assumption using a computer model.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5306" id="segment-36" start_char="5074">
<ORIGINAL_TEXT>Al tener en cuenta un retraso en la transmisión, la detección y el desarrollo de los síntomas, el primer caso de infección por Covid-19 ocurrió en Hubei el 4 de noviembre de 2019 o alrededor de esa fecha, calculan los investigadores.</ORIGINAL_TEXT>
<TOKEN end_char="5075" id="token-36-0" morph="none" pos="word" start_char="5074">Al</TOKEN>
<TOKEN end_char="5081" id="token-36-1" morph="none" pos="word" start_char="5077">tener</TOKEN>
<TOKEN end_char="5084" id="token-36-2" morph="none" pos="word" start_char="5083">en</TOKEN>
<TOKEN end_char="5091" id="token-36-3" morph="none" pos="word" start_char="5086">cuenta</TOKEN>
<TOKEN end_char="5094" id="token-36-4" morph="none" pos="word" start_char="5093">un</TOKEN>
<TOKEN end_char="5102" id="token-36-5" morph="none" pos="word" start_char="5096">retraso</TOKEN>
<TOKEN end_char="5105" id="token-36-6" morph="none" pos="word" start_char="5104">en</TOKEN>
<TOKEN end_char="5108" id="token-36-7" morph="none" pos="word" start_char="5107">la</TOKEN>
<TOKEN end_char="5120" id="token-36-8" morph="none" pos="word" start_char="5110">transmisión</TOKEN>
<TOKEN end_char="5121" id="token-36-9" morph="none" pos="punct" start_char="5121">,</TOKEN>
<TOKEN end_char="5124" id="token-36-10" morph="none" pos="word" start_char="5123">la</TOKEN>
<TOKEN end_char="5134" id="token-36-11" morph="none" pos="word" start_char="5126">detección</TOKEN>
<TOKEN end_char="5136" id="token-36-12" morph="none" pos="word" start_char="5136">y</TOKEN>
<TOKEN end_char="5139" id="token-36-13" morph="none" pos="word" start_char="5138">el</TOKEN>
<TOKEN end_char="5150" id="token-36-14" morph="none" pos="word" start_char="5141">desarrollo</TOKEN>
<TOKEN end_char="5153" id="token-36-15" morph="none" pos="word" start_char="5152">de</TOKEN>
<TOKEN end_char="5157" id="token-36-16" morph="none" pos="word" start_char="5155">los</TOKEN>
<TOKEN end_char="5166" id="token-36-17" morph="none" pos="word" start_char="5159">síntomas</TOKEN>
<TOKEN end_char="5167" id="token-36-18" morph="none" pos="punct" start_char="5167">,</TOKEN>
<TOKEN end_char="5170" id="token-36-19" morph="none" pos="word" start_char="5169">el</TOKEN>
<TOKEN end_char="5177" id="token-36-20" morph="none" pos="word" start_char="5172">primer</TOKEN>
<TOKEN end_char="5182" id="token-36-21" morph="none" pos="word" start_char="5179">caso</TOKEN>
<TOKEN end_char="5185" id="token-36-22" morph="none" pos="word" start_char="5184">de</TOKEN>
<TOKEN end_char="5195" id="token-36-23" morph="none" pos="word" start_char="5187">infección</TOKEN>
<TOKEN end_char="5199" id="token-36-24" morph="none" pos="word" start_char="5197">por</TOKEN>
<TOKEN end_char="5208" id="token-36-25" morph="none" pos="unknown" start_char="5201">Covid-19</TOKEN>
<TOKEN end_char="5216" id="token-36-26" morph="none" pos="word" start_char="5210">ocurrió</TOKEN>
<TOKEN end_char="5219" id="token-36-27" morph="none" pos="word" start_char="5218">en</TOKEN>
<TOKEN end_char="5225" id="token-36-28" morph="none" pos="word" start_char="5221">Hubei</TOKEN>
<TOKEN end_char="5228" id="token-36-29" morph="none" pos="word" start_char="5227">el</TOKEN>
<TOKEN end_char="5230" id="token-36-30" morph="none" pos="word" start_char="5230">4</TOKEN>
<TOKEN end_char="5233" id="token-36-31" morph="none" pos="word" start_char="5232">de</TOKEN>
<TOKEN end_char="5243" id="token-36-32" morph="none" pos="word" start_char="5235">noviembre</TOKEN>
<TOKEN end_char="5246" id="token-36-33" morph="none" pos="word" start_char="5245">de</TOKEN>
<TOKEN end_char="5251" id="token-36-34" morph="none" pos="word" start_char="5248">2019</TOKEN>
<TOKEN end_char="5253" id="token-36-35" morph="none" pos="word" start_char="5253">o</TOKEN>
<TOKEN end_char="5263" id="token-36-36" morph="none" pos="word" start_char="5255">alrededor</TOKEN>
<TOKEN end_char="5266" id="token-36-37" morph="none" pos="word" start_char="5265">de</TOKEN>
<TOKEN end_char="5270" id="token-36-38" morph="none" pos="word" start_char="5268">esa</TOKEN>
<TOKEN end_char="5276" id="token-36-39" morph="none" pos="word" start_char="5272">fecha</TOKEN>
<TOKEN end_char="5277" id="token-36-40" morph="none" pos="punct" start_char="5277">,</TOKEN>
<TOKEN end_char="5286" id="token-36-41" morph="none" pos="word" start_char="5279">calculan</TOKEN>
<TOKEN end_char="5290" id="token-36-42" morph="none" pos="word" start_char="5288">los</TOKEN>
<TOKEN end_char="5305" id="token-36-43" morph="none" pos="word" start_char="5292">investigadores</TOKEN>
<TOKEN end_char="5306" id="token-36-44" morph="none" pos="punct" start_char="5306">.</TOKEN>
<TRANSLATED_TEXT>Considering a delay in the transmission, detection, and development of symptoms, the first case of Covid-19 infection occurred in Hubei on or around 4 November 2019, researchers estimate.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5404" id="segment-37" start_char="5309">
<ORIGINAL_TEXT>Sin embargo, esta cifra podría ser tan temprana como el 7 de octubre, añaden los investigadores.</ORIGINAL_TEXT>
<TOKEN end_char="5311" id="token-37-0" morph="none" pos="word" start_char="5309">Sin</TOKEN>
<TOKEN end_char="5319" id="token-37-1" morph="none" pos="word" start_char="5313">embargo</TOKEN>
<TOKEN end_char="5320" id="token-37-2" morph="none" pos="punct" start_char="5320">,</TOKEN>
<TOKEN end_char="5325" id="token-37-3" morph="none" pos="word" start_char="5322">esta</TOKEN>
<TOKEN end_char="5331" id="token-37-4" morph="none" pos="word" start_char="5327">cifra</TOKEN>
<TOKEN end_char="5338" id="token-37-5" morph="none" pos="word" start_char="5333">podría</TOKEN>
<TOKEN end_char="5342" id="token-37-6" morph="none" pos="word" start_char="5340">ser</TOKEN>
<TOKEN end_char="5346" id="token-37-7" morph="none" pos="word" start_char="5344">tan</TOKEN>
<TOKEN end_char="5355" id="token-37-8" morph="none" pos="word" start_char="5348">temprana</TOKEN>
<TOKEN end_char="5360" id="token-37-9" morph="none" pos="word" start_char="5357">como</TOKEN>
<TOKEN end_char="5363" id="token-37-10" morph="none" pos="word" start_char="5362">el</TOKEN>
<TOKEN end_char="5365" id="token-37-11" morph="none" pos="word" start_char="5365">7</TOKEN>
<TOKEN end_char="5368" id="token-37-12" morph="none" pos="word" start_char="5367">de</TOKEN>
<TOKEN end_char="5376" id="token-37-13" morph="none" pos="word" start_char="5370">octubre</TOKEN>
<TOKEN end_char="5377" id="token-37-14" morph="none" pos="punct" start_char="5377">,</TOKEN>
<TOKEN end_char="5384" id="token-37-15" morph="none" pos="word" start_char="5379">añaden</TOKEN>
<TOKEN end_char="5388" id="token-37-16" morph="none" pos="word" start_char="5386">los</TOKEN>
<TOKEN end_char="5403" id="token-37-17" morph="none" pos="word" start_char="5390">investigadores</TOKEN>
<TOKEN end_char="5404" id="token-37-18" morph="none" pos="punct" start_char="5404">.</TOKEN>
<TRANSLATED_TEXT>However, this figure could be as early as October 7, researchers add.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5712" id="segment-38" start_char="5407">
<ORIGINAL_TEXT>Los investigadores lucharon por identificar una ubicación geográfica para el origen del virus, pero dicen que si la cepa inicial, que era más débil que la variante de Wuhan y todas las mutaciones posteriores, surgiera en una ubicación rural, habría tenido que migrar a una ubicación urbana para sobrevivir.</ORIGINAL_TEXT>
<TOKEN end_char="5409" id="token-38-0" morph="none" pos="word" start_char="5407">Los</TOKEN>
<TOKEN end_char="5424" id="token-38-1" morph="none" pos="word" start_char="5411">investigadores</TOKEN>
<TOKEN end_char="5433" id="token-38-2" morph="none" pos="word" start_char="5426">lucharon</TOKEN>
<TOKEN end_char="5437" id="token-38-3" morph="none" pos="word" start_char="5435">por</TOKEN>
<TOKEN end_char="5449" id="token-38-4" morph="none" pos="word" start_char="5439">identificar</TOKEN>
<TOKEN end_char="5453" id="token-38-5" morph="none" pos="word" start_char="5451">una</TOKEN>
<TOKEN end_char="5463" id="token-38-6" morph="none" pos="word" start_char="5455">ubicación</TOKEN>
<TOKEN end_char="5474" id="token-38-7" morph="none" pos="word" start_char="5465">geográfica</TOKEN>
<TOKEN end_char="5479" id="token-38-8" morph="none" pos="word" start_char="5476">para</TOKEN>
<TOKEN end_char="5482" id="token-38-9" morph="none" pos="word" start_char="5481">el</TOKEN>
<TOKEN end_char="5489" id="token-38-10" morph="none" pos="word" start_char="5484">origen</TOKEN>
<TOKEN end_char="5493" id="token-38-11" morph="none" pos="word" start_char="5491">del</TOKEN>
<TOKEN end_char="5499" id="token-38-12" morph="none" pos="word" start_char="5495">virus</TOKEN>
<TOKEN end_char="5500" id="token-38-13" morph="none" pos="punct" start_char="5500">,</TOKEN>
<TOKEN end_char="5505" id="token-38-14" morph="none" pos="word" start_char="5502">pero</TOKEN>
<TOKEN end_char="5511" id="token-38-15" morph="none" pos="word" start_char="5507">dicen</TOKEN>
<TOKEN end_char="5515" id="token-38-16" morph="none" pos="word" start_char="5513">que</TOKEN>
<TOKEN end_char="5518" id="token-38-17" morph="none" pos="word" start_char="5517">si</TOKEN>
<TOKEN end_char="5521" id="token-38-18" morph="none" pos="word" start_char="5520">la</TOKEN>
<TOKEN end_char="5526" id="token-38-19" morph="none" pos="word" start_char="5523">cepa</TOKEN>
<TOKEN end_char="5534" id="token-38-20" morph="none" pos="word" start_char="5528">inicial</TOKEN>
<TOKEN end_char="5535" id="token-38-21" morph="none" pos="punct" start_char="5535">,</TOKEN>
<TOKEN end_char="5539" id="token-38-22" morph="none" pos="word" start_char="5537">que</TOKEN>
<TOKEN end_char="5543" id="token-38-23" morph="none" pos="word" start_char="5541">era</TOKEN>
<TOKEN end_char="5547" id="token-38-24" morph="none" pos="word" start_char="5545">más</TOKEN>
<TOKEN end_char="5553" id="token-38-25" morph="none" pos="word" start_char="5549">débil</TOKEN>
<TOKEN end_char="5557" id="token-38-26" morph="none" pos="word" start_char="5555">que</TOKEN>
<TOKEN end_char="5560" id="token-38-27" morph="none" pos="word" start_char="5559">la</TOKEN>
<TOKEN end_char="5569" id="token-38-28" morph="none" pos="word" start_char="5562">variante</TOKEN>
<TOKEN end_char="5572" id="token-38-29" morph="none" pos="word" start_char="5571">de</TOKEN>
<TOKEN end_char="5578" id="token-38-30" morph="none" pos="word" start_char="5574">Wuhan</TOKEN>
<TOKEN end_char="5580" id="token-38-31" morph="none" pos="word" start_char="5580">y</TOKEN>
<TOKEN end_char="5586" id="token-38-32" morph="none" pos="word" start_char="5582">todas</TOKEN>
<TOKEN end_char="5590" id="token-38-33" morph="none" pos="word" start_char="5588">las</TOKEN>
<TOKEN end_char="5601" id="token-38-34" morph="none" pos="word" start_char="5592">mutaciones</TOKEN>
<TOKEN end_char="5613" id="token-38-35" morph="none" pos="word" start_char="5603">posteriores</TOKEN>
<TOKEN end_char="5614" id="token-38-36" morph="none" pos="punct" start_char="5614">,</TOKEN>
<TOKEN end_char="5623" id="token-38-37" morph="none" pos="word" start_char="5616">surgiera</TOKEN>
<TOKEN end_char="5626" id="token-38-38" morph="none" pos="word" start_char="5625">en</TOKEN>
<TOKEN end_char="5630" id="token-38-39" morph="none" pos="word" start_char="5628">una</TOKEN>
<TOKEN end_char="5640" id="token-38-40" morph="none" pos="word" start_char="5632">ubicación</TOKEN>
<TOKEN end_char="5646" id="token-38-41" morph="none" pos="word" start_char="5642">rural</TOKEN>
<TOKEN end_char="5647" id="token-38-42" morph="none" pos="punct" start_char="5647">,</TOKEN>
<TOKEN end_char="5654" id="token-38-43" morph="none" pos="word" start_char="5649">habría</TOKEN>
<TOKEN end_char="5661" id="token-38-44" morph="none" pos="word" start_char="5656">tenido</TOKEN>
<TOKEN end_char="5665" id="token-38-45" morph="none" pos="word" start_char="5663">que</TOKEN>
<TOKEN end_char="5672" id="token-38-46" morph="none" pos="word" start_char="5667">migrar</TOKEN>
<TOKEN end_char="5674" id="token-38-47" morph="none" pos="word" start_char="5674">a</TOKEN>
<TOKEN end_char="5678" id="token-38-48" morph="none" pos="word" start_char="5676">una</TOKEN>
<TOKEN end_char="5688" id="token-38-49" morph="none" pos="word" start_char="5680">ubicación</TOKEN>
<TOKEN end_char="5695" id="token-38-50" morph="none" pos="word" start_char="5690">urbana</TOKEN>
<TOKEN end_char="5700" id="token-38-51" morph="none" pos="word" start_char="5697">para</TOKEN>
<TOKEN end_char="5711" id="token-38-52" morph="none" pos="word" start_char="5702">sobrevivir</TOKEN>
<TOKEN end_char="5712" id="token-38-53" morph="none" pos="punct" start_char="5712">.</TOKEN>
<TRANSLATED_TEXT>Researchers struggled to identify a geographic location for the virus's origin, but say that if the initial strain, which was weaker than the Wuhan variant and all subsequent mutations, arose in a rural location, it would have had to migrate to an urban location to survive.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5714" id="segment-39" start_char="5714">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="5714" id="token-39-0" morph="none" pos="punct" start_char="5714">.</TOKEN>
</SEG>
<SEG end_char="5961" id="segment-40" start_char="5717">
<ORIGINAL_TEXT>«La falta de informes de Covid-19 en otras partes de China en noviembre y principios de diciembre sugiere que la provincia de Hubei es el lugar donde se establecieron las cadenas de transmisión de persona a persona», escriben los investigadores.</ORIGINAL_TEXT>
<TOKEN end_char="5717" id="token-40-0" morph="none" pos="punct" start_char="5717">«</TOKEN>
<TOKEN end_char="5719" id="token-40-1" morph="none" pos="word" start_char="5718">La</TOKEN>
<TOKEN end_char="5725" id="token-40-2" morph="none" pos="word" start_char="5721">falta</TOKEN>
<TOKEN end_char="5728" id="token-40-3" morph="none" pos="word" start_char="5727">de</TOKEN>
<TOKEN end_char="5737" id="token-40-4" morph="none" pos="word" start_char="5730">informes</TOKEN>
<TOKEN end_char="5740" id="token-40-5" morph="none" pos="word" start_char="5739">de</TOKEN>
<TOKEN end_char="5749" id="token-40-6" morph="none" pos="unknown" start_char="5742">Covid-19</TOKEN>
<TOKEN end_char="5752" id="token-40-7" morph="none" pos="word" start_char="5751">en</TOKEN>
<TOKEN end_char="5758" id="token-40-8" morph="none" pos="word" start_char="5754">otras</TOKEN>
<TOKEN end_char="5765" id="token-40-9" morph="none" pos="word" start_char="5760">partes</TOKEN>
<TOKEN end_char="5768" id="token-40-10" morph="none" pos="word" start_char="5767">de</TOKEN>
<TOKEN end_char="5774" id="token-40-11" morph="none" pos="word" start_char="5770">China</TOKEN>
<TOKEN end_char="5777" id="token-40-12" morph="none" pos="word" start_char="5776">en</TOKEN>
<TOKEN end_char="5787" id="token-40-13" morph="none" pos="word" start_char="5779">noviembre</TOKEN>
<TOKEN end_char="5789" id="token-40-14" morph="none" pos="word" start_char="5789">y</TOKEN>
<TOKEN end_char="5800" id="token-40-15" morph="none" pos="word" start_char="5791">principios</TOKEN>
<TOKEN end_char="5803" id="token-40-16" morph="none" pos="word" start_char="5802">de</TOKEN>
<TOKEN end_char="5813" id="token-40-17" morph="none" pos="word" start_char="5805">diciembre</TOKEN>
<TOKEN end_char="5821" id="token-40-18" morph="none" pos="word" start_char="5815">sugiere</TOKEN>
<TOKEN end_char="5825" id="token-40-19" morph="none" pos="word" start_char="5823">que</TOKEN>
<TOKEN end_char="5828" id="token-40-20" morph="none" pos="word" start_char="5827">la</TOKEN>
<TOKEN end_char="5838" id="token-40-21" morph="none" pos="word" start_char="5830">provincia</TOKEN>
<TOKEN end_char="5841" id="token-40-22" morph="none" pos="word" start_char="5840">de</TOKEN>
<TOKEN end_char="5847" id="token-40-23" morph="none" pos="word" start_char="5843">Hubei</TOKEN>
<TOKEN end_char="5850" id="token-40-24" morph="none" pos="word" start_char="5849">es</TOKEN>
<TOKEN end_char="5853" id="token-40-25" morph="none" pos="word" start_char="5852">el</TOKEN>
<TOKEN end_char="5859" id="token-40-26" morph="none" pos="word" start_char="5855">lugar</TOKEN>
<TOKEN end_char="5865" id="token-40-27" morph="none" pos="word" start_char="5861">donde</TOKEN>
<TOKEN end_char="5868" id="token-40-28" morph="none" pos="word" start_char="5867">se</TOKEN>
<TOKEN end_char="5882" id="token-40-29" morph="none" pos="word" start_char="5870">establecieron</TOKEN>
<TOKEN end_char="5886" id="token-40-30" morph="none" pos="word" start_char="5884">las</TOKEN>
<TOKEN end_char="5894" id="token-40-31" morph="none" pos="word" start_char="5888">cadenas</TOKEN>
<TOKEN end_char="5897" id="token-40-32" morph="none" pos="word" start_char="5896">de</TOKEN>
<TOKEN end_char="5909" id="token-40-33" morph="none" pos="word" start_char="5899">transmisión</TOKEN>
<TOKEN end_char="5912" id="token-40-34" morph="none" pos="word" start_char="5911">de</TOKEN>
<TOKEN end_char="5920" id="token-40-35" morph="none" pos="word" start_char="5914">persona</TOKEN>
<TOKEN end_char="5922" id="token-40-36" morph="none" pos="word" start_char="5922">a</TOKEN>
<TOKEN end_char="5930" id="token-40-37" morph="none" pos="word" start_char="5924">persona</TOKEN>
<TOKEN end_char="5932" id="token-40-38" morph="none" pos="punct" start_char="5931">»,</TOKEN>
<TOKEN end_char="5941" id="token-40-39" morph="none" pos="word" start_char="5934">escriben</TOKEN>
<TOKEN end_char="5945" id="token-40-40" morph="none" pos="word" start_char="5943">los</TOKEN>
<TOKEN end_char="5960" id="token-40-41" morph="none" pos="word" start_char="5947">investigadores</TOKEN>
<TOKEN end_char="5961" id="token-40-42" morph="none" pos="punct" start_char="5961">.</TOKEN>
<TRANSLATED_TEXT>"The lack of Covid-19 reports in other parts of China in November and early December suggests that Hubei Province is the place where the person-to-person transmission chains were established," researchers write.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6216" id="segment-41" start_char="5964">
<ORIGINAL_TEXT>Los investigadores añaden que sus hallazgos no arrojan luz sobre si el primer caso contrajo el virus directamente de los murciélagos o a través de un huésped intermedio, pero sí «aleja aún más» el primer caso del mercado mayorista de mariscos de Huanan.</ORIGINAL_TEXT>
<TOKEN end_char="5966" id="token-41-0" morph="none" pos="word" start_char="5964">Los</TOKEN>
<TOKEN end_char="5981" id="token-41-1" morph="none" pos="word" start_char="5968">investigadores</TOKEN>
<TOKEN end_char="5988" id="token-41-2" morph="none" pos="word" start_char="5983">añaden</TOKEN>
<TOKEN end_char="5992" id="token-41-3" morph="none" pos="word" start_char="5990">que</TOKEN>
<TOKEN end_char="5996" id="token-41-4" morph="none" pos="word" start_char="5994">sus</TOKEN>
<TOKEN end_char="6006" id="token-41-5" morph="none" pos="word" start_char="5998">hallazgos</TOKEN>
<TOKEN end_char="6009" id="token-41-6" morph="none" pos="word" start_char="6008">no</TOKEN>
<TOKEN end_char="6017" id="token-41-7" morph="none" pos="word" start_char="6011">arrojan</TOKEN>
<TOKEN end_char="6021" id="token-41-8" morph="none" pos="word" start_char="6019">luz</TOKEN>
<TOKEN end_char="6027" id="token-41-9" morph="none" pos="word" start_char="6023">sobre</TOKEN>
<TOKEN end_char="6030" id="token-41-10" morph="none" pos="word" start_char="6029">si</TOKEN>
<TOKEN end_char="6033" id="token-41-11" morph="none" pos="word" start_char="6032">el</TOKEN>
<TOKEN end_char="6040" id="token-41-12" morph="none" pos="word" start_char="6035">primer</TOKEN>
<TOKEN end_char="6045" id="token-41-13" morph="none" pos="word" start_char="6042">caso</TOKEN>
<TOKEN end_char="6054" id="token-41-14" morph="none" pos="word" start_char="6047">contrajo</TOKEN>
<TOKEN end_char="6057" id="token-41-15" morph="none" pos="word" start_char="6056">el</TOKEN>
<TOKEN end_char="6063" id="token-41-16" morph="none" pos="word" start_char="6059">virus</TOKEN>
<TOKEN end_char="6076" id="token-41-17" morph="none" pos="word" start_char="6065">directamente</TOKEN>
<TOKEN end_char="6079" id="token-41-18" morph="none" pos="word" start_char="6078">de</TOKEN>
<TOKEN end_char="6083" id="token-41-19" morph="none" pos="word" start_char="6081">los</TOKEN>
<TOKEN end_char="6095" id="token-41-20" morph="none" pos="word" start_char="6085">murciélagos</TOKEN>
<TOKEN end_char="6097" id="token-41-21" morph="none" pos="word" start_char="6097">o</TOKEN>
<TOKEN end_char="6099" id="token-41-22" morph="none" pos="word" start_char="6099">a</TOKEN>
<TOKEN end_char="6106" id="token-41-23" morph="none" pos="word" start_char="6101">través</TOKEN>
<TOKEN end_char="6109" id="token-41-24" morph="none" pos="word" start_char="6108">de</TOKEN>
<TOKEN end_char="6112" id="token-41-25" morph="none" pos="word" start_char="6111">un</TOKEN>
<TOKEN end_char="6120" id="token-41-26" morph="none" pos="word" start_char="6114">huésped</TOKEN>
<TOKEN end_char="6131" id="token-41-27" morph="none" pos="word" start_char="6122">intermedio</TOKEN>
<TOKEN end_char="6132" id="token-41-28" morph="none" pos="punct" start_char="6132">,</TOKEN>
<TOKEN end_char="6137" id="token-41-29" morph="none" pos="word" start_char="6134">pero</TOKEN>
<TOKEN end_char="6140" id="token-41-30" morph="none" pos="word" start_char="6139">sí</TOKEN>
<TOKEN end_char="6142" id="token-41-31" morph="none" pos="punct" start_char="6142">«</TOKEN>
<TOKEN end_char="6147" id="token-41-32" morph="none" pos="word" start_char="6143">aleja</TOKEN>
<TOKEN end_char="6151" id="token-41-33" morph="none" pos="word" start_char="6149">aún</TOKEN>
<TOKEN end_char="6155" id="token-41-34" morph="none" pos="word" start_char="6153">más</TOKEN>
<TOKEN end_char="6156" id="token-41-35" morph="none" pos="punct" start_char="6156">»</TOKEN>
<TOKEN end_char="6159" id="token-41-36" morph="none" pos="word" start_char="6158">el</TOKEN>
<TOKEN end_char="6166" id="token-41-37" morph="none" pos="word" start_char="6161">primer</TOKEN>
<TOKEN end_char="6171" id="token-41-38" morph="none" pos="word" start_char="6168">caso</TOKEN>
<TOKEN end_char="6175" id="token-41-39" morph="none" pos="word" start_char="6173">del</TOKEN>
<TOKEN end_char="6183" id="token-41-40" morph="none" pos="word" start_char="6177">mercado</TOKEN>
<TOKEN end_char="6193" id="token-41-41" morph="none" pos="word" start_char="6185">mayorista</TOKEN>
<TOKEN end_char="6196" id="token-41-42" morph="none" pos="word" start_char="6195">de</TOKEN>
<TOKEN end_char="6205" id="token-41-43" morph="none" pos="word" start_char="6198">mariscos</TOKEN>
<TOKEN end_char="6208" id="token-41-44" morph="none" pos="word" start_char="6207">de</TOKEN>
<TOKEN end_char="6215" id="token-41-45" morph="none" pos="word" start_char="6210">Huanan</TOKEN>
<TOKEN end_char="6216" id="token-41-46" morph="none" pos="punct" start_char="6216">.</TOKEN>
<TRANSLATED_TEXT>Researchers add that their findings do not shed light on whether the first case contracted the virus directly from bats or through an intermediate host, but "further away" the first case from Huanan's wholesale seafood market.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6238" id="segment-42" start_char="6219">
<ORIGINAL_TEXT>Anuncio publicitario</ORIGINAL_TEXT>
<TOKEN end_char="6225" id="token-42-0" morph="none" pos="word" start_char="6219">Anuncio</TOKEN>
<TOKEN end_char="6238" id="token-42-1" morph="none" pos="word" start_char="6227">publicitario</TOKEN>
<TRANSLATED_TEXT>Advertising notice</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
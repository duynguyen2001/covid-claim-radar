<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATCE" lang="spa" raw_text_char_length="2610" raw_text_md5="a311b01ba75fffbc06cd2ce27ee163fa" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="62" id="segment-0" start_char="1">
<ORIGINAL_TEXT>La teoría ‘conspiranoica’ de Frank Cuesta sobre el coronavirus</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">La</TOKEN>
<TOKEN end_char="9" id="token-0-1" morph="none" pos="word" start_char="4">teoría</TOKEN>
<TOKEN end_char="11" id="token-0-2" morph="none" pos="punct" start_char="11">‘</TOKEN>
<TOKEN end_char="24" id="token-0-3" morph="none" pos="word" start_char="12">conspiranoica</TOKEN>
<TOKEN end_char="25" id="token-0-4" morph="none" pos="punct" start_char="25">’</TOKEN>
<TOKEN end_char="28" id="token-0-5" morph="none" pos="word" start_char="27">de</TOKEN>
<TOKEN end_char="34" id="token-0-6" morph="none" pos="word" start_char="30">Frank</TOKEN>
<TOKEN end_char="41" id="token-0-7" morph="none" pos="word" start_char="36">Cuesta</TOKEN>
<TOKEN end_char="47" id="token-0-8" morph="none" pos="word" start_char="43">sobre</TOKEN>
<TOKEN end_char="50" id="token-0-9" morph="none" pos="word" start_char="49">el</TOKEN>
<TOKEN end_char="62" id="token-0-10" morph="none" pos="word" start_char="52">coronavirus</TOKEN>
<TRANSLATED_TEXT>Frank Cuesta's' conspiracy theory 'about coronavirus</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="77" id="segment-1" start_char="66">
<ORIGINAL_TEXT>Frank Cuesta</ORIGINAL_TEXT>
<TOKEN end_char="70" id="token-1-0" morph="none" pos="word" start_char="66">Frank</TOKEN>
<TOKEN end_char="77" id="token-1-1" morph="none" pos="word" start_char="72">Cuesta</TOKEN>
<TRANSLATED_TEXT>Frank Cuesta.</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="148" id="segment-2" start_char="81">
<ORIGINAL_TEXT>Frank Cuesta sigue dejando titulares cada vez que da una entrevista.</ORIGINAL_TEXT>
<TOKEN end_char="85" id="token-2-0" morph="none" pos="word" start_char="81">Frank</TOKEN>
<TOKEN end_char="92" id="token-2-1" morph="none" pos="word" start_char="87">Cuesta</TOKEN>
<TOKEN end_char="98" id="token-2-2" morph="none" pos="word" start_char="94">sigue</TOKEN>
<TOKEN end_char="106" id="token-2-3" morph="none" pos="word" start_char="100">dejando</TOKEN>
<TOKEN end_char="116" id="token-2-4" morph="none" pos="word" start_char="108">titulares</TOKEN>
<TOKEN end_char="121" id="token-2-5" morph="none" pos="word" start_char="118">cada</TOKEN>
<TOKEN end_char="125" id="token-2-6" morph="none" pos="word" start_char="123">vez</TOKEN>
<TOKEN end_char="129" id="token-2-7" morph="none" pos="word" start_char="127">que</TOKEN>
<TOKEN end_char="132" id="token-2-8" morph="none" pos="word" start_char="131">da</TOKEN>
<TOKEN end_char="136" id="token-2-9" morph="none" pos="word" start_char="134">una</TOKEN>
<TOKEN end_char="147" id="token-2-10" morph="none" pos="word" start_char="138">entrevista</TOKEN>
<TOKEN end_char="148" id="token-2-11" morph="none" pos="punct" start_char="148">.</TOKEN>
<TRANSLATED_TEXT>Frank Cuesta continues to make headlines every time he gives an interview.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="397" id="segment-3" start_char="150">
<ORIGINAL_TEXT>En esta ocasión, y preguntado sobre el coronavirus Covid-19 , no ha dudado en lanzar una teoría sobre los contagios y su propagación, que según el animalista se remontaría al mes de agosto y no a principios de este año como reza la versión oficial.</ORIGINAL_TEXT>
<TOKEN end_char="151" id="token-3-0" morph="none" pos="word" start_char="150">En</TOKEN>
<TOKEN end_char="156" id="token-3-1" morph="none" pos="word" start_char="153">esta</TOKEN>
<TOKEN end_char="164" id="token-3-2" morph="none" pos="word" start_char="158">ocasión</TOKEN>
<TOKEN end_char="165" id="token-3-3" morph="none" pos="punct" start_char="165">,</TOKEN>
<TOKEN end_char="167" id="token-3-4" morph="none" pos="word" start_char="167">y</TOKEN>
<TOKEN end_char="178" id="token-3-5" morph="none" pos="word" start_char="169">preguntado</TOKEN>
<TOKEN end_char="184" id="token-3-6" morph="none" pos="word" start_char="180">sobre</TOKEN>
<TOKEN end_char="187" id="token-3-7" morph="none" pos="word" start_char="186">el</TOKEN>
<TOKEN end_char="199" id="token-3-8" morph="none" pos="word" start_char="189">coronavirus</TOKEN>
<TOKEN end_char="208" id="token-3-9" morph="none" pos="unknown" start_char="201">Covid-19</TOKEN>
<TOKEN end_char="210" id="token-3-10" morph="none" pos="punct" start_char="210">,</TOKEN>
<TOKEN end_char="213" id="token-3-11" morph="none" pos="word" start_char="212">no</TOKEN>
<TOKEN end_char="216" id="token-3-12" morph="none" pos="word" start_char="215">ha</TOKEN>
<TOKEN end_char="223" id="token-3-13" morph="none" pos="word" start_char="218">dudado</TOKEN>
<TOKEN end_char="226" id="token-3-14" morph="none" pos="word" start_char="225">en</TOKEN>
<TOKEN end_char="233" id="token-3-15" morph="none" pos="word" start_char="228">lanzar</TOKEN>
<TOKEN end_char="237" id="token-3-16" morph="none" pos="word" start_char="235">una</TOKEN>
<TOKEN end_char="244" id="token-3-17" morph="none" pos="word" start_char="239">teoría</TOKEN>
<TOKEN end_char="250" id="token-3-18" morph="none" pos="word" start_char="246">sobre</TOKEN>
<TOKEN end_char="254" id="token-3-19" morph="none" pos="word" start_char="252">los</TOKEN>
<TOKEN end_char="264" id="token-3-20" morph="none" pos="word" start_char="256">contagios</TOKEN>
<TOKEN end_char="266" id="token-3-21" morph="none" pos="word" start_char="266">y</TOKEN>
<TOKEN end_char="269" id="token-3-22" morph="none" pos="word" start_char="268">su</TOKEN>
<TOKEN end_char="281" id="token-3-23" morph="none" pos="word" start_char="271">propagación</TOKEN>
<TOKEN end_char="282" id="token-3-24" morph="none" pos="punct" start_char="282">,</TOKEN>
<TOKEN end_char="286" id="token-3-25" morph="none" pos="word" start_char="284">que</TOKEN>
<TOKEN end_char="292" id="token-3-26" morph="none" pos="word" start_char="288">según</TOKEN>
<TOKEN end_char="295" id="token-3-27" morph="none" pos="word" start_char="294">el</TOKEN>
<TOKEN end_char="306" id="token-3-28" morph="none" pos="word" start_char="297">animalista</TOKEN>
<TOKEN end_char="309" id="token-3-29" morph="none" pos="word" start_char="308">se</TOKEN>
<TOKEN end_char="320" id="token-3-30" morph="none" pos="word" start_char="311">remontaría</TOKEN>
<TOKEN end_char="323" id="token-3-31" morph="none" pos="word" start_char="322">al</TOKEN>
<TOKEN end_char="327" id="token-3-32" morph="none" pos="word" start_char="325">mes</TOKEN>
<TOKEN end_char="330" id="token-3-33" morph="none" pos="word" start_char="329">de</TOKEN>
<TOKEN end_char="337" id="token-3-34" morph="none" pos="word" start_char="332">agosto</TOKEN>
<TOKEN end_char="339" id="token-3-35" morph="none" pos="word" start_char="339">y</TOKEN>
<TOKEN end_char="342" id="token-3-36" morph="none" pos="word" start_char="341">no</TOKEN>
<TOKEN end_char="344" id="token-3-37" morph="none" pos="word" start_char="344">a</TOKEN>
<TOKEN end_char="355" id="token-3-38" morph="none" pos="word" start_char="346">principios</TOKEN>
<TOKEN end_char="358" id="token-3-39" morph="none" pos="word" start_char="357">de</TOKEN>
<TOKEN end_char="363" id="token-3-40" morph="none" pos="word" start_char="360">este</TOKEN>
<TOKEN end_char="367" id="token-3-41" morph="none" pos="word" start_char="365">año</TOKEN>
<TOKEN end_char="372" id="token-3-42" morph="none" pos="word" start_char="369">como</TOKEN>
<TOKEN end_char="377" id="token-3-43" morph="none" pos="word" start_char="374">reza</TOKEN>
<TOKEN end_char="380" id="token-3-44" morph="none" pos="word" start_char="379">la</TOKEN>
<TOKEN end_char="388" id="token-3-45" morph="none" pos="word" start_char="382">versión</TOKEN>
<TOKEN end_char="396" id="token-3-46" morph="none" pos="word" start_char="390">oficial</TOKEN>
<TOKEN end_char="397" id="token-3-47" morph="none" pos="punct" start_char="397">.</TOKEN>
<TRANSLATED_TEXT>On this occasion, and asked about the coronavirus Covid-19, he has not hesitated to launch a theory on contagion and its spread, which according to the animalist would go back to August and not early this year as the official version says.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="566" id="segment-4" start_char="400">
<ORIGINAL_TEXT>Lo ha hecho en una entrevista a Federico Jiménez Losantos, donde Cuesta ha abordado la "histeria" por la actual epidemia de coronavirus en España y el resto del mundo.</ORIGINAL_TEXT>
<TOKEN end_char="401" id="token-4-0" morph="none" pos="word" start_char="400">Lo</TOKEN>
<TOKEN end_char="404" id="token-4-1" morph="none" pos="word" start_char="403">ha</TOKEN>
<TOKEN end_char="410" id="token-4-2" morph="none" pos="word" start_char="406">hecho</TOKEN>
<TOKEN end_char="413" id="token-4-3" morph="none" pos="word" start_char="412">en</TOKEN>
<TOKEN end_char="417" id="token-4-4" morph="none" pos="word" start_char="415">una</TOKEN>
<TOKEN end_char="428" id="token-4-5" morph="none" pos="word" start_char="419">entrevista</TOKEN>
<TOKEN end_char="430" id="token-4-6" morph="none" pos="word" start_char="430">a</TOKEN>
<TOKEN end_char="439" id="token-4-7" morph="none" pos="word" start_char="432">Federico</TOKEN>
<TOKEN end_char="447" id="token-4-8" morph="none" pos="word" start_char="441">Jiménez</TOKEN>
<TOKEN end_char="456" id="token-4-9" morph="none" pos="word" start_char="449">Losantos</TOKEN>
<TOKEN end_char="457" id="token-4-10" morph="none" pos="punct" start_char="457">,</TOKEN>
<TOKEN end_char="463" id="token-4-11" morph="none" pos="word" start_char="459">donde</TOKEN>
<TOKEN end_char="470" id="token-4-12" morph="none" pos="word" start_char="465">Cuesta</TOKEN>
<TOKEN end_char="473" id="token-4-13" morph="none" pos="word" start_char="472">ha</TOKEN>
<TOKEN end_char="482" id="token-4-14" morph="none" pos="word" start_char="475">abordado</TOKEN>
<TOKEN end_char="485" id="token-4-15" morph="none" pos="word" start_char="484">la</TOKEN>
<TOKEN end_char="487" id="token-4-16" morph="none" pos="punct" start_char="487">"</TOKEN>
<TOKEN end_char="495" id="token-4-17" morph="none" pos="word" start_char="488">histeria</TOKEN>
<TOKEN end_char="496" id="token-4-18" morph="none" pos="punct" start_char="496">"</TOKEN>
<TOKEN end_char="500" id="token-4-19" morph="none" pos="word" start_char="498">por</TOKEN>
<TOKEN end_char="503" id="token-4-20" morph="none" pos="word" start_char="502">la</TOKEN>
<TOKEN end_char="510" id="token-4-21" morph="none" pos="word" start_char="505">actual</TOKEN>
<TOKEN end_char="519" id="token-4-22" morph="none" pos="word" start_char="512">epidemia</TOKEN>
<TOKEN end_char="522" id="token-4-23" morph="none" pos="word" start_char="521">de</TOKEN>
<TOKEN end_char="534" id="token-4-24" morph="none" pos="word" start_char="524">coronavirus</TOKEN>
<TOKEN end_char="537" id="token-4-25" morph="none" pos="word" start_char="536">en</TOKEN>
<TOKEN end_char="544" id="token-4-26" morph="none" pos="word" start_char="539">España</TOKEN>
<TOKEN end_char="546" id="token-4-27" morph="none" pos="word" start_char="546">y</TOKEN>
<TOKEN end_char="549" id="token-4-28" morph="none" pos="word" start_char="548">el</TOKEN>
<TOKEN end_char="555" id="token-4-29" morph="none" pos="word" start_char="551">resto</TOKEN>
<TOKEN end_char="559" id="token-4-30" morph="none" pos="word" start_char="557">del</TOKEN>
<TOKEN end_char="565" id="token-4-31" morph="none" pos="word" start_char="561">mundo</TOKEN>
<TOKEN end_char="566" id="token-4-32" morph="none" pos="punct" start_char="566">.</TOKEN>
<TRANSLATED_TEXT>He has done so in an interview with Federico Jiménez Losantos, where Cuesta has addressed the "hysteria" of the current coronavirus epidemic in Spain and the rest of the world.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="735" id="segment-5" start_char="568">
<ORIGINAL_TEXT>Sin embargo, y contrariamente a lo que se ha publicado hasta ahora, el presentador asegura haber presenciado sus inicios en Tailandia hace ya unos meses, en pleno 2019.</ORIGINAL_TEXT>
<TOKEN end_char="570" id="token-5-0" morph="none" pos="word" start_char="568">Sin</TOKEN>
<TOKEN end_char="578" id="token-5-1" morph="none" pos="word" start_char="572">embargo</TOKEN>
<TOKEN end_char="579" id="token-5-2" morph="none" pos="punct" start_char="579">,</TOKEN>
<TOKEN end_char="581" id="token-5-3" morph="none" pos="word" start_char="581">y</TOKEN>
<TOKEN end_char="596" id="token-5-4" morph="none" pos="word" start_char="583">contrariamente</TOKEN>
<TOKEN end_char="598" id="token-5-5" morph="none" pos="word" start_char="598">a</TOKEN>
<TOKEN end_char="601" id="token-5-6" morph="none" pos="word" start_char="600">lo</TOKEN>
<TOKEN end_char="605" id="token-5-7" morph="none" pos="word" start_char="603">que</TOKEN>
<TOKEN end_char="608" id="token-5-8" morph="none" pos="word" start_char="607">se</TOKEN>
<TOKEN end_char="611" id="token-5-9" morph="none" pos="word" start_char="610">ha</TOKEN>
<TOKEN end_char="621" id="token-5-10" morph="none" pos="word" start_char="613">publicado</TOKEN>
<TOKEN end_char="627" id="token-5-11" morph="none" pos="word" start_char="623">hasta</TOKEN>
<TOKEN end_char="633" id="token-5-12" morph="none" pos="word" start_char="629">ahora</TOKEN>
<TOKEN end_char="634" id="token-5-13" morph="none" pos="punct" start_char="634">,</TOKEN>
<TOKEN end_char="637" id="token-5-14" morph="none" pos="word" start_char="636">el</TOKEN>
<TOKEN end_char="649" id="token-5-15" morph="none" pos="word" start_char="639">presentador</TOKEN>
<TOKEN end_char="657" id="token-5-16" morph="none" pos="word" start_char="651">asegura</TOKEN>
<TOKEN end_char="663" id="token-5-17" morph="none" pos="word" start_char="659">haber</TOKEN>
<TOKEN end_char="675" id="token-5-18" morph="none" pos="word" start_char="665">presenciado</TOKEN>
<TOKEN end_char="679" id="token-5-19" morph="none" pos="word" start_char="677">sus</TOKEN>
<TOKEN end_char="687" id="token-5-20" morph="none" pos="word" start_char="681">inicios</TOKEN>
<TOKEN end_char="690" id="token-5-21" morph="none" pos="word" start_char="689">en</TOKEN>
<TOKEN end_char="700" id="token-5-22" morph="none" pos="word" start_char="692">Tailandia</TOKEN>
<TOKEN end_char="705" id="token-5-23" morph="none" pos="word" start_char="702">hace</TOKEN>
<TOKEN end_char="708" id="token-5-24" morph="none" pos="word" start_char="707">ya</TOKEN>
<TOKEN end_char="713" id="token-5-25" morph="none" pos="word" start_char="710">unos</TOKEN>
<TOKEN end_char="719" id="token-5-26" morph="none" pos="word" start_char="715">meses</TOKEN>
<TOKEN end_char="720" id="token-5-27" morph="none" pos="punct" start_char="720">,</TOKEN>
<TOKEN end_char="723" id="token-5-28" morph="none" pos="word" start_char="722">en</TOKEN>
<TOKEN end_char="729" id="token-5-29" morph="none" pos="word" start_char="725">pleno</TOKEN>
<TOKEN end_char="734" id="token-5-30" morph="none" pos="word" start_char="731">2019</TOKEN>
<TOKEN end_char="735" id="token-5-31" morph="none" pos="punct" start_char="735">.</TOKEN>
<TRANSLATED_TEXT>However, contrary to what has been published so far, the presenter claims to have witnessed its beginnings in Thailand a few months ago, in the middle of 2019.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="752" id="segment-6" start_char="738">
<ORIGINAL_TEXT>Frank Cuesta FB</ORIGINAL_TEXT>
<TOKEN end_char="742" id="token-6-0" morph="none" pos="word" start_char="738">Frank</TOKEN>
<TOKEN end_char="749" id="token-6-1" morph="none" pos="word" start_char="744">Cuesta</TOKEN>
<TOKEN end_char="752" id="token-6-2" morph="none" pos="word" start_char="751">FB</TOKEN>
</SEG>
<SEG end_char="775" id="segment-7" start_char="756">
<ORIGINAL_TEXT>Frank Cuesta Twitter</ORIGINAL_TEXT>
<TOKEN end_char="760" id="token-7-0" morph="none" pos="word" start_char="756">Frank</TOKEN>
<TOKEN end_char="767" id="token-7-1" morph="none" pos="word" start_char="762">Cuesta</TOKEN>
<TOKEN end_char="775" id="token-7-2" morph="none" pos="word" start_char="769">Twitter</TOKEN>
</SEG>
<SEG end_char="925" id="segment-8" start_char="779">
<ORIGINAL_TEXT>Su teoría se basa en el pangolín, un animal en el que se había puesto el foco del primer contagio entre animales y humanos pero que fue descartado.</ORIGINAL_TEXT>
<TOKEN end_char="780" id="token-8-0" morph="none" pos="word" start_char="779">Su</TOKEN>
<TOKEN end_char="787" id="token-8-1" morph="none" pos="word" start_char="782">teoría</TOKEN>
<TOKEN end_char="790" id="token-8-2" morph="none" pos="word" start_char="789">se</TOKEN>
<TOKEN end_char="795" id="token-8-3" morph="none" pos="word" start_char="792">basa</TOKEN>
<TOKEN end_char="798" id="token-8-4" morph="none" pos="word" start_char="797">en</TOKEN>
<TOKEN end_char="801" id="token-8-5" morph="none" pos="word" start_char="800">el</TOKEN>
<TOKEN end_char="810" id="token-8-6" morph="none" pos="word" start_char="803">pangolín</TOKEN>
<TOKEN end_char="811" id="token-8-7" morph="none" pos="punct" start_char="811">,</TOKEN>
<TOKEN end_char="814" id="token-8-8" morph="none" pos="word" start_char="813">un</TOKEN>
<TOKEN end_char="821" id="token-8-9" morph="none" pos="word" start_char="816">animal</TOKEN>
<TOKEN end_char="824" id="token-8-10" morph="none" pos="word" start_char="823">en</TOKEN>
<TOKEN end_char="827" id="token-8-11" morph="none" pos="word" start_char="826">el</TOKEN>
<TOKEN end_char="831" id="token-8-12" morph="none" pos="word" start_char="829">que</TOKEN>
<TOKEN end_char="834" id="token-8-13" morph="none" pos="word" start_char="833">se</TOKEN>
<TOKEN end_char="840" id="token-8-14" morph="none" pos="word" start_char="836">había</TOKEN>
<TOKEN end_char="847" id="token-8-15" morph="none" pos="word" start_char="842">puesto</TOKEN>
<TOKEN end_char="850" id="token-8-16" morph="none" pos="word" start_char="849">el</TOKEN>
<TOKEN end_char="855" id="token-8-17" morph="none" pos="word" start_char="852">foco</TOKEN>
<TOKEN end_char="859" id="token-8-18" morph="none" pos="word" start_char="857">del</TOKEN>
<TOKEN end_char="866" id="token-8-19" morph="none" pos="word" start_char="861">primer</TOKEN>
<TOKEN end_char="875" id="token-8-20" morph="none" pos="word" start_char="868">contagio</TOKEN>
<TOKEN end_char="881" id="token-8-21" morph="none" pos="word" start_char="877">entre</TOKEN>
<TOKEN end_char="890" id="token-8-22" morph="none" pos="word" start_char="883">animales</TOKEN>
<TOKEN end_char="892" id="token-8-23" morph="none" pos="word" start_char="892">y</TOKEN>
<TOKEN end_char="900" id="token-8-24" morph="none" pos="word" start_char="894">humanos</TOKEN>
<TOKEN end_char="905" id="token-8-25" morph="none" pos="word" start_char="902">pero</TOKEN>
<TOKEN end_char="909" id="token-8-26" morph="none" pos="word" start_char="907">que</TOKEN>
<TOKEN end_char="913" id="token-8-27" morph="none" pos="word" start_char="911">fue</TOKEN>
<TOKEN end_char="924" id="token-8-28" morph="none" pos="word" start_char="915">descartado</TOKEN>
<TOKEN end_char="925" id="token-8-29" morph="none" pos="punct" start_char="925">.</TOKEN>
<TRANSLATED_TEXT>His theory is based on pangolin, an animal that had been the focus of the first animal-human contagion but was discarded.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1116" id="segment-9" start_char="927">
<ORIGINAL_TEXT>Aún así, Cuesta sigue apuntando a esta posibilidad y la argumenta diciendo que "sabemos que se pillan una media de cincuenta a cien pangolines todas las semanas que salen a Vietnam o China".</ORIGINAL_TEXT>
<TOKEN end_char="929" id="token-9-0" morph="none" pos="word" start_char="927">Aún</TOKEN>
<TOKEN end_char="933" id="token-9-1" morph="none" pos="word" start_char="931">así</TOKEN>
<TOKEN end_char="934" id="token-9-2" morph="none" pos="punct" start_char="934">,</TOKEN>
<TOKEN end_char="941" id="token-9-3" morph="none" pos="word" start_char="936">Cuesta</TOKEN>
<TOKEN end_char="947" id="token-9-4" morph="none" pos="word" start_char="943">sigue</TOKEN>
<TOKEN end_char="957" id="token-9-5" morph="none" pos="word" start_char="949">apuntando</TOKEN>
<TOKEN end_char="959" id="token-9-6" morph="none" pos="word" start_char="959">a</TOKEN>
<TOKEN end_char="964" id="token-9-7" morph="none" pos="word" start_char="961">esta</TOKEN>
<TOKEN end_char="976" id="token-9-8" morph="none" pos="word" start_char="966">posibilidad</TOKEN>
<TOKEN end_char="978" id="token-9-9" morph="none" pos="word" start_char="978">y</TOKEN>
<TOKEN end_char="981" id="token-9-10" morph="none" pos="word" start_char="980">la</TOKEN>
<TOKEN end_char="991" id="token-9-11" morph="none" pos="word" start_char="983">argumenta</TOKEN>
<TOKEN end_char="1000" id="token-9-12" morph="none" pos="word" start_char="993">diciendo</TOKEN>
<TOKEN end_char="1004" id="token-9-13" morph="none" pos="word" start_char="1002">que</TOKEN>
<TOKEN end_char="1006" id="token-9-14" morph="none" pos="punct" start_char="1006">"</TOKEN>
<TOKEN end_char="1013" id="token-9-15" morph="none" pos="word" start_char="1007">sabemos</TOKEN>
<TOKEN end_char="1017" id="token-9-16" morph="none" pos="word" start_char="1015">que</TOKEN>
<TOKEN end_char="1020" id="token-9-17" morph="none" pos="word" start_char="1019">se</TOKEN>
<TOKEN end_char="1027" id="token-9-18" morph="none" pos="word" start_char="1022">pillan</TOKEN>
<TOKEN end_char="1031" id="token-9-19" morph="none" pos="word" start_char="1029">una</TOKEN>
<TOKEN end_char="1037" id="token-9-20" morph="none" pos="word" start_char="1033">media</TOKEN>
<TOKEN end_char="1040" id="token-9-21" morph="none" pos="word" start_char="1039">de</TOKEN>
<TOKEN end_char="1050" id="token-9-22" morph="none" pos="word" start_char="1042">cincuenta</TOKEN>
<TOKEN end_char="1052" id="token-9-23" morph="none" pos="word" start_char="1052">a</TOKEN>
<TOKEN end_char="1057" id="token-9-24" morph="none" pos="word" start_char="1054">cien</TOKEN>
<TOKEN end_char="1068" id="token-9-25" morph="none" pos="word" start_char="1059">pangolines</TOKEN>
<TOKEN end_char="1074" id="token-9-26" morph="none" pos="word" start_char="1070">todas</TOKEN>
<TOKEN end_char="1078" id="token-9-27" morph="none" pos="word" start_char="1076">las</TOKEN>
<TOKEN end_char="1086" id="token-9-28" morph="none" pos="word" start_char="1080">semanas</TOKEN>
<TOKEN end_char="1090" id="token-9-29" morph="none" pos="word" start_char="1088">que</TOKEN>
<TOKEN end_char="1096" id="token-9-30" morph="none" pos="word" start_char="1092">salen</TOKEN>
<TOKEN end_char="1098" id="token-9-31" morph="none" pos="word" start_char="1098">a</TOKEN>
<TOKEN end_char="1106" id="token-9-32" morph="none" pos="word" start_char="1100">Vietnam</TOKEN>
<TOKEN end_char="1108" id="token-9-33" morph="none" pos="word" start_char="1108">o</TOKEN>
<TOKEN end_char="1114" id="token-9-34" morph="none" pos="word" start_char="1110">China</TOKEN>
<TOKEN end_char="1116" id="token-9-35" morph="none" pos="punct" start_char="1115">".</TOKEN>
<TRANSLATED_TEXT>Still, Cuesta continues to point to this possibility and argues that "we know that an average of fifty to one hundred pangolins are discovered every week that they go to Vietnam or China."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1204" id="segment-10" start_char="1119">
<ORIGINAL_TEXT>"La segunda semana de agosto se dejó de pillar, y también de murciélago y de musaraña.</ORIGINAL_TEXT>
<TOKEN end_char="1119" id="token-10-0" morph="none" pos="punct" start_char="1119">"</TOKEN>
<TOKEN end_char="1121" id="token-10-1" morph="none" pos="word" start_char="1120">La</TOKEN>
<TOKEN end_char="1129" id="token-10-2" morph="none" pos="word" start_char="1123">segunda</TOKEN>
<TOKEN end_char="1136" id="token-10-3" morph="none" pos="word" start_char="1131">semana</TOKEN>
<TOKEN end_char="1139" id="token-10-4" morph="none" pos="word" start_char="1138">de</TOKEN>
<TOKEN end_char="1146" id="token-10-5" morph="none" pos="word" start_char="1141">agosto</TOKEN>
<TOKEN end_char="1149" id="token-10-6" morph="none" pos="word" start_char="1148">se</TOKEN>
<TOKEN end_char="1154" id="token-10-7" morph="none" pos="word" start_char="1151">dejó</TOKEN>
<TOKEN end_char="1157" id="token-10-8" morph="none" pos="word" start_char="1156">de</TOKEN>
<TOKEN end_char="1164" id="token-10-9" morph="none" pos="word" start_char="1159">pillar</TOKEN>
<TOKEN end_char="1165" id="token-10-10" morph="none" pos="punct" start_char="1165">,</TOKEN>
<TOKEN end_char="1167" id="token-10-11" morph="none" pos="word" start_char="1167">y</TOKEN>
<TOKEN end_char="1175" id="token-10-12" morph="none" pos="word" start_char="1169">también</TOKEN>
<TOKEN end_char="1178" id="token-10-13" morph="none" pos="word" start_char="1177">de</TOKEN>
<TOKEN end_char="1189" id="token-10-14" morph="none" pos="word" start_char="1180">murciélago</TOKEN>
<TOKEN end_char="1191" id="token-10-15" morph="none" pos="word" start_char="1191">y</TOKEN>
<TOKEN end_char="1194" id="token-10-16" morph="none" pos="word" start_char="1193">de</TOKEN>
<TOKEN end_char="1203" id="token-10-17" morph="none" pos="word" start_char="1196">musaraña</TOKEN>
<TOKEN end_char="1204" id="token-10-18" morph="none" pos="punct" start_char="1204">.</TOKEN>
<TRANSLATED_TEXT>The second week of August was over from pillar, and also from bat and shrew.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1253" id="segment-11" start_char="1206">
<ORIGINAL_TEXT>No hemos encontrado ni un cargamento, cosa rara.</ORIGINAL_TEXT>
<TOKEN end_char="1207" id="token-11-0" morph="none" pos="word" start_char="1206">No</TOKEN>
<TOKEN end_char="1213" id="token-11-1" morph="none" pos="word" start_char="1209">hemos</TOKEN>
<TOKEN end_char="1224" id="token-11-2" morph="none" pos="word" start_char="1215">encontrado</TOKEN>
<TOKEN end_char="1227" id="token-11-3" morph="none" pos="word" start_char="1226">ni</TOKEN>
<TOKEN end_char="1230" id="token-11-4" morph="none" pos="word" start_char="1229">un</TOKEN>
<TOKEN end_char="1241" id="token-11-5" morph="none" pos="word" start_char="1232">cargamento</TOKEN>
<TOKEN end_char="1242" id="token-11-6" morph="none" pos="punct" start_char="1242">,</TOKEN>
<TOKEN end_char="1247" id="token-11-7" morph="none" pos="word" start_char="1244">cosa</TOKEN>
<TOKEN end_char="1252" id="token-11-8" morph="none" pos="word" start_char="1249">rara</TOKEN>
<TOKEN end_char="1253" id="token-11-9" morph="none" pos="punct" start_char="1253">.</TOKEN>
<TRANSLATED_TEXT>We haven't found a shipment, which is rare.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1454" id="segment-12" start_char="1255">
<ORIGINAL_TEXT>Te estoy hablando del mes de agosto", ha asegurado antes de plantear la conclusión de lo ocurrido: "¿Cómo puedes coger cien pangolines a la semana y salir de las mismas zonas y luego dejar de hacerlo?</ORIGINAL_TEXT>
<TOKEN end_char="1256" id="token-12-0" morph="none" pos="word" start_char="1255">Te</TOKEN>
<TOKEN end_char="1262" id="token-12-1" morph="none" pos="word" start_char="1258">estoy</TOKEN>
<TOKEN end_char="1271" id="token-12-2" morph="none" pos="word" start_char="1264">hablando</TOKEN>
<TOKEN end_char="1275" id="token-12-3" morph="none" pos="word" start_char="1273">del</TOKEN>
<TOKEN end_char="1279" id="token-12-4" morph="none" pos="word" start_char="1277">mes</TOKEN>
<TOKEN end_char="1282" id="token-12-5" morph="none" pos="word" start_char="1281">de</TOKEN>
<TOKEN end_char="1289" id="token-12-6" morph="none" pos="word" start_char="1284">agosto</TOKEN>
<TOKEN end_char="1291" id="token-12-7" morph="none" pos="punct" start_char="1290">",</TOKEN>
<TOKEN end_char="1294" id="token-12-8" morph="none" pos="word" start_char="1293">ha</TOKEN>
<TOKEN end_char="1304" id="token-12-9" morph="none" pos="word" start_char="1296">asegurado</TOKEN>
<TOKEN end_char="1310" id="token-12-10" morph="none" pos="word" start_char="1306">antes</TOKEN>
<TOKEN end_char="1313" id="token-12-11" morph="none" pos="word" start_char="1312">de</TOKEN>
<TOKEN end_char="1322" id="token-12-12" morph="none" pos="word" start_char="1315">plantear</TOKEN>
<TOKEN end_char="1325" id="token-12-13" morph="none" pos="word" start_char="1324">la</TOKEN>
<TOKEN end_char="1336" id="token-12-14" morph="none" pos="word" start_char="1327">conclusión</TOKEN>
<TOKEN end_char="1339" id="token-12-15" morph="none" pos="word" start_char="1338">de</TOKEN>
<TOKEN end_char="1342" id="token-12-16" morph="none" pos="word" start_char="1341">lo</TOKEN>
<TOKEN end_char="1351" id="token-12-17" morph="none" pos="word" start_char="1344">ocurrido</TOKEN>
<TOKEN end_char="1352" id="token-12-18" morph="none" pos="punct" start_char="1352">:</TOKEN>
<TOKEN end_char="1355" id="token-12-19" morph="none" pos="punct" start_char="1354">"¿</TOKEN>
<TOKEN end_char="1359" id="token-12-20" morph="none" pos="word" start_char="1356">Cómo</TOKEN>
<TOKEN end_char="1366" id="token-12-21" morph="none" pos="word" start_char="1361">puedes</TOKEN>
<TOKEN end_char="1372" id="token-12-22" morph="none" pos="word" start_char="1368">coger</TOKEN>
<TOKEN end_char="1377" id="token-12-23" morph="none" pos="word" start_char="1374">cien</TOKEN>
<TOKEN end_char="1388" id="token-12-24" morph="none" pos="word" start_char="1379">pangolines</TOKEN>
<TOKEN end_char="1390" id="token-12-25" morph="none" pos="word" start_char="1390">a</TOKEN>
<TOKEN end_char="1393" id="token-12-26" morph="none" pos="word" start_char="1392">la</TOKEN>
<TOKEN end_char="1400" id="token-12-27" morph="none" pos="word" start_char="1395">semana</TOKEN>
<TOKEN end_char="1402" id="token-12-28" morph="none" pos="word" start_char="1402">y</TOKEN>
<TOKEN end_char="1408" id="token-12-29" morph="none" pos="word" start_char="1404">salir</TOKEN>
<TOKEN end_char="1411" id="token-12-30" morph="none" pos="word" start_char="1410">de</TOKEN>
<TOKEN end_char="1415" id="token-12-31" morph="none" pos="word" start_char="1413">las</TOKEN>
<TOKEN end_char="1422" id="token-12-32" morph="none" pos="word" start_char="1417">mismas</TOKEN>
<TOKEN end_char="1428" id="token-12-33" morph="none" pos="word" start_char="1424">zonas</TOKEN>
<TOKEN end_char="1430" id="token-12-34" morph="none" pos="word" start_char="1430">y</TOKEN>
<TOKEN end_char="1436" id="token-12-35" morph="none" pos="word" start_char="1432">luego</TOKEN>
<TOKEN end_char="1442" id="token-12-36" morph="none" pos="word" start_char="1438">dejar</TOKEN>
<TOKEN end_char="1445" id="token-12-37" morph="none" pos="word" start_char="1444">de</TOKEN>
<TOKEN end_char="1453" id="token-12-38" morph="none" pos="word" start_char="1447">hacerlo</TOKEN>
<TOKEN end_char="1454" id="token-12-39" morph="none" pos="punct" start_char="1454">?</TOKEN>
<TRANSLATED_TEXT>I'm talking to you about the month of August, "he assured before coming to the conclusion of what happened:" How can you take a hundred pangolins a week and leave the same areas and then stop doing it?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1457" id="segment-13" start_char="1456">
<ORIGINAL_TEXT>".</ORIGINAL_TEXT>
<TOKEN end_char="1457" id="token-13-0" morph="none" pos="punct" start_char="1456">".</TOKEN>
</SEG>
<SEG end_char="1472" id="segment-14" start_char="1460">
<ORIGINAL_TEXT>Frank Cuesta.</ORIGINAL_TEXT>
<TOKEN end_char="1464" id="token-14-0" morph="none" pos="word" start_char="1460">Frank</TOKEN>
<TOKEN end_char="1471" id="token-14-1" morph="none" pos="word" start_char="1466">Cuesta</TOKEN>
<TOKEN end_char="1472" id="token-14-2" morph="none" pos="punct" start_char="1472">.</TOKEN>
</SEG>
<SEG end_char="1474" id="segment-15" start_char="1474">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1474" id="token-15-0" morph="none" pos="punct" start_char="1474">.</TOKEN>
</SEG>
<SEG end_char="1490" id="segment-16" start_char="1478">
<ORIGINAL_TEXT>Frank Cuesta.</ORIGINAL_TEXT>
<TOKEN end_char="1482" id="token-16-0" morph="none" pos="word" start_char="1478">Frank</TOKEN>
<TOKEN end_char="1489" id="token-16-1" morph="none" pos="word" start_char="1484">Cuesta</TOKEN>
<TOKEN end_char="1490" id="token-16-2" morph="none" pos="punct" start_char="1490">.</TOKEN>
</SEG>
<SEG end_char="1492" id="segment-17" start_char="1492">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1492" id="token-17-0" morph="none" pos="punct" start_char="1492">.</TOKEN>
</SEG>
<SEG end_char="1610" id="segment-18" start_char="1496">
<ORIGINAL_TEXT>La conclusión para Cuesta es clara: "En agosto ya pasaba algo ahí" pero no se hizo público hasta medio año después.</ORIGINAL_TEXT>
<TOKEN end_char="1497" id="token-18-0" morph="none" pos="word" start_char="1496">La</TOKEN>
<TOKEN end_char="1508" id="token-18-1" morph="none" pos="word" start_char="1499">conclusión</TOKEN>
<TOKEN end_char="1513" id="token-18-2" morph="none" pos="word" start_char="1510">para</TOKEN>
<TOKEN end_char="1520" id="token-18-3" morph="none" pos="word" start_char="1515">Cuesta</TOKEN>
<TOKEN end_char="1523" id="token-18-4" morph="none" pos="word" start_char="1522">es</TOKEN>
<TOKEN end_char="1529" id="token-18-5" morph="none" pos="word" start_char="1525">clara</TOKEN>
<TOKEN end_char="1530" id="token-18-6" morph="none" pos="punct" start_char="1530">:</TOKEN>
<TOKEN end_char="1532" id="token-18-7" morph="none" pos="punct" start_char="1532">"</TOKEN>
<TOKEN end_char="1534" id="token-18-8" morph="none" pos="word" start_char="1533">En</TOKEN>
<TOKEN end_char="1541" id="token-18-9" morph="none" pos="word" start_char="1536">agosto</TOKEN>
<TOKEN end_char="1544" id="token-18-10" morph="none" pos="word" start_char="1543">ya</TOKEN>
<TOKEN end_char="1551" id="token-18-11" morph="none" pos="word" start_char="1546">pasaba</TOKEN>
<TOKEN end_char="1556" id="token-18-12" morph="none" pos="word" start_char="1553">algo</TOKEN>
<TOKEN end_char="1560" id="token-18-13" morph="none" pos="word" start_char="1558">ahí</TOKEN>
<TOKEN end_char="1561" id="token-18-14" morph="none" pos="punct" start_char="1561">"</TOKEN>
<TOKEN end_char="1566" id="token-18-15" morph="none" pos="word" start_char="1563">pero</TOKEN>
<TOKEN end_char="1569" id="token-18-16" morph="none" pos="word" start_char="1568">no</TOKEN>
<TOKEN end_char="1572" id="token-18-17" morph="none" pos="word" start_char="1571">se</TOKEN>
<TOKEN end_char="1577" id="token-18-18" morph="none" pos="word" start_char="1574">hizo</TOKEN>
<TOKEN end_char="1585" id="token-18-19" morph="none" pos="word" start_char="1579">público</TOKEN>
<TOKEN end_char="1591" id="token-18-20" morph="none" pos="word" start_char="1587">hasta</TOKEN>
<TOKEN end_char="1597" id="token-18-21" morph="none" pos="word" start_char="1593">medio</TOKEN>
<TOKEN end_char="1601" id="token-18-22" morph="none" pos="word" start_char="1599">año</TOKEN>
<TOKEN end_char="1609" id="token-18-23" morph="none" pos="word" start_char="1603">después</TOKEN>
<TOKEN end_char="1610" id="token-18-24" morph="none" pos="punct" start_char="1610">.</TOKEN>
<TRANSLATED_TEXT>The conclusion for Cuesta is clear: "In August something was already going on there," but it was not made public until half a year later.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1781" id="segment-19" start_char="1612">
<ORIGINAL_TEXT>Jiménez Losantos se ha apuntado al carro conspiranoico y ha asegurado que "hubo un médico que sí lo denunció y lo metieron en la cárcel, y después lo sacaron para morir".</ORIGINAL_TEXT>
<TOKEN end_char="1618" id="token-19-0" morph="none" pos="word" start_char="1612">Jiménez</TOKEN>
<TOKEN end_char="1627" id="token-19-1" morph="none" pos="word" start_char="1620">Losantos</TOKEN>
<TOKEN end_char="1630" id="token-19-2" morph="none" pos="word" start_char="1629">se</TOKEN>
<TOKEN end_char="1633" id="token-19-3" morph="none" pos="word" start_char="1632">ha</TOKEN>
<TOKEN end_char="1642" id="token-19-4" morph="none" pos="word" start_char="1635">apuntado</TOKEN>
<TOKEN end_char="1645" id="token-19-5" morph="none" pos="word" start_char="1644">al</TOKEN>
<TOKEN end_char="1651" id="token-19-6" morph="none" pos="word" start_char="1647">carro</TOKEN>
<TOKEN end_char="1665" id="token-19-7" morph="none" pos="word" start_char="1653">conspiranoico</TOKEN>
<TOKEN end_char="1667" id="token-19-8" morph="none" pos="word" start_char="1667">y</TOKEN>
<TOKEN end_char="1670" id="token-19-9" morph="none" pos="word" start_char="1669">ha</TOKEN>
<TOKEN end_char="1680" id="token-19-10" morph="none" pos="word" start_char="1672">asegurado</TOKEN>
<TOKEN end_char="1684" id="token-19-11" morph="none" pos="word" start_char="1682">que</TOKEN>
<TOKEN end_char="1686" id="token-19-12" morph="none" pos="punct" start_char="1686">"</TOKEN>
<TOKEN end_char="1690" id="token-19-13" morph="none" pos="word" start_char="1687">hubo</TOKEN>
<TOKEN end_char="1693" id="token-19-14" morph="none" pos="word" start_char="1692">un</TOKEN>
<TOKEN end_char="1700" id="token-19-15" morph="none" pos="word" start_char="1695">médico</TOKEN>
<TOKEN end_char="1704" id="token-19-16" morph="none" pos="word" start_char="1702">que</TOKEN>
<TOKEN end_char="1707" id="token-19-17" morph="none" pos="word" start_char="1706">sí</TOKEN>
<TOKEN end_char="1710" id="token-19-18" morph="none" pos="word" start_char="1709">lo</TOKEN>
<TOKEN end_char="1719" id="token-19-19" morph="none" pos="word" start_char="1712">denunció</TOKEN>
<TOKEN end_char="1721" id="token-19-20" morph="none" pos="word" start_char="1721">y</TOKEN>
<TOKEN end_char="1724" id="token-19-21" morph="none" pos="word" start_char="1723">lo</TOKEN>
<TOKEN end_char="1733" id="token-19-22" morph="none" pos="word" start_char="1726">metieron</TOKEN>
<TOKEN end_char="1736" id="token-19-23" morph="none" pos="word" start_char="1735">en</TOKEN>
<TOKEN end_char="1739" id="token-19-24" morph="none" pos="word" start_char="1738">la</TOKEN>
<TOKEN end_char="1746" id="token-19-25" morph="none" pos="word" start_char="1741">cárcel</TOKEN>
<TOKEN end_char="1747" id="token-19-26" morph="none" pos="punct" start_char="1747">,</TOKEN>
<TOKEN end_char="1749" id="token-19-27" morph="none" pos="word" start_char="1749">y</TOKEN>
<TOKEN end_char="1757" id="token-19-28" morph="none" pos="word" start_char="1751">después</TOKEN>
<TOKEN end_char="1760" id="token-19-29" morph="none" pos="word" start_char="1759">lo</TOKEN>
<TOKEN end_char="1768" id="token-19-30" morph="none" pos="word" start_char="1762">sacaron</TOKEN>
<TOKEN end_char="1773" id="token-19-31" morph="none" pos="word" start_char="1770">para</TOKEN>
<TOKEN end_char="1779" id="token-19-32" morph="none" pos="word" start_char="1775">morir</TOKEN>
<TOKEN end_char="1781" id="token-19-33" morph="none" pos="punct" start_char="1780">".</TOKEN>
<TRANSLATED_TEXT>Jiménez Losantos has pointed to the conspiracy car and has claimed that "there was a doctor who did report him and put him in jail, and then took him out to die."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1948" id="segment-20" start_char="1784">
<ORIGINAL_TEXT>Sobre el pangolín, Cuesta explicaba que "se usan hasta las escamas para ponerselas en las heridas… Y que se lo comen casi crudo, lo meten unos segundos en agua y ya.</ORIGINAL_TEXT>
<TOKEN end_char="1788" id="token-20-0" morph="none" pos="word" start_char="1784">Sobre</TOKEN>
<TOKEN end_char="1791" id="token-20-1" morph="none" pos="word" start_char="1790">el</TOKEN>
<TOKEN end_char="1800" id="token-20-2" morph="none" pos="word" start_char="1793">pangolín</TOKEN>
<TOKEN end_char="1801" id="token-20-3" morph="none" pos="punct" start_char="1801">,</TOKEN>
<TOKEN end_char="1808" id="token-20-4" morph="none" pos="word" start_char="1803">Cuesta</TOKEN>
<TOKEN end_char="1818" id="token-20-5" morph="none" pos="word" start_char="1810">explicaba</TOKEN>
<TOKEN end_char="1822" id="token-20-6" morph="none" pos="word" start_char="1820">que</TOKEN>
<TOKEN end_char="1824" id="token-20-7" morph="none" pos="punct" start_char="1824">"</TOKEN>
<TOKEN end_char="1826" id="token-20-8" morph="none" pos="word" start_char="1825">se</TOKEN>
<TOKEN end_char="1831" id="token-20-9" morph="none" pos="word" start_char="1828">usan</TOKEN>
<TOKEN end_char="1837" id="token-20-10" morph="none" pos="word" start_char="1833">hasta</TOKEN>
<TOKEN end_char="1841" id="token-20-11" morph="none" pos="word" start_char="1839">las</TOKEN>
<TOKEN end_char="1849" id="token-20-12" morph="none" pos="word" start_char="1843">escamas</TOKEN>
<TOKEN end_char="1854" id="token-20-13" morph="none" pos="word" start_char="1851">para</TOKEN>
<TOKEN end_char="1865" id="token-20-14" morph="none" pos="word" start_char="1856">ponerselas</TOKEN>
<TOKEN end_char="1868" id="token-20-15" morph="none" pos="word" start_char="1867">en</TOKEN>
<TOKEN end_char="1872" id="token-20-16" morph="none" pos="word" start_char="1870">las</TOKEN>
<TOKEN end_char="1880" id="token-20-17" morph="none" pos="word" start_char="1874">heridas</TOKEN>
<TOKEN end_char="1881" id="token-20-18" morph="none" pos="punct" start_char="1881">…</TOKEN>
<TOKEN end_char="1883" id="token-20-19" morph="none" pos="word" start_char="1883">Y</TOKEN>
<TOKEN end_char="1887" id="token-20-20" morph="none" pos="word" start_char="1885">que</TOKEN>
<TOKEN end_char="1890" id="token-20-21" morph="none" pos="word" start_char="1889">se</TOKEN>
<TOKEN end_char="1893" id="token-20-22" morph="none" pos="word" start_char="1892">lo</TOKEN>
<TOKEN end_char="1899" id="token-20-23" morph="none" pos="word" start_char="1895">comen</TOKEN>
<TOKEN end_char="1904" id="token-20-24" morph="none" pos="word" start_char="1901">casi</TOKEN>
<TOKEN end_char="1910" id="token-20-25" morph="none" pos="word" start_char="1906">crudo</TOKEN>
<TOKEN end_char="1911" id="token-20-26" morph="none" pos="punct" start_char="1911">,</TOKEN>
<TOKEN end_char="1914" id="token-20-27" morph="none" pos="word" start_char="1913">lo</TOKEN>
<TOKEN end_char="1920" id="token-20-28" morph="none" pos="word" start_char="1916">meten</TOKEN>
<TOKEN end_char="1925" id="token-20-29" morph="none" pos="word" start_char="1922">unos</TOKEN>
<TOKEN end_char="1934" id="token-20-30" morph="none" pos="word" start_char="1927">segundos</TOKEN>
<TOKEN end_char="1937" id="token-20-31" morph="none" pos="word" start_char="1936">en</TOKEN>
<TOKEN end_char="1942" id="token-20-32" morph="none" pos="word" start_char="1939">agua</TOKEN>
<TOKEN end_char="1944" id="token-20-33" morph="none" pos="word" start_char="1944">y</TOKEN>
<TOKEN end_char="1947" id="token-20-34" morph="none" pos="word" start_char="1946">ya</TOKEN>
<TOKEN end_char="1948" id="token-20-35" morph="none" pos="punct" start_char="1948">.</TOKEN>
<TRANSLATED_TEXT>On pangolin, Cuesta explained that "they are used up to the scales to put them on wounds... and that they eat it almost raw, put it a few seconds in water and already.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1966" id="segment-21" start_char="1950">
<ORIGINAL_TEXT>Es una especie de</ORIGINAL_TEXT>
<TOKEN end_char="1951" id="token-21-0" morph="none" pos="word" start_char="1950">Es</TOKEN>
<TOKEN end_char="1955" id="token-21-1" morph="none" pos="word" start_char="1953">una</TOKEN>
<TOKEN end_char="1963" id="token-21-2" morph="none" pos="word" start_char="1957">especie</TOKEN>
<TOKEN end_char="1966" id="token-21-3" morph="none" pos="word" start_char="1965">de</TOKEN>
<TRANSLATED_TEXT>It's a kind of</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1973" id="segment-22" start_char="1969">
<ORIGINAL_TEXT>sushi</ORIGINAL_TEXT>
<TOKEN end_char="1973" id="token-22-0" morph="none" pos="word" start_char="1969">sushi</TOKEN>
<TRANSLATED_TEXT>Sushi</TRANSLATED_TEXT><DETECTED_LANGUAGE>et</DETECTED_LANGUAGE></SEG>
<SEG end_char="1976" id="segment-23" start_char="1976">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1976" id="token-23-0" morph="none" pos="punct" start_char="1976">.</TOKEN>
</SEG>
<SEG end_char="2038" id="segment-24" start_char="1978">
<ORIGINAL_TEXT>Es el mamífero mas castigado del mundo, han acabado con él...</ORIGINAL_TEXT>
<TOKEN end_char="1979" id="token-24-0" morph="none" pos="word" start_char="1978">Es</TOKEN>
<TOKEN end_char="1982" id="token-24-1" morph="none" pos="word" start_char="1981">el</TOKEN>
<TOKEN end_char="1991" id="token-24-2" morph="none" pos="word" start_char="1984">mamífero</TOKEN>
<TOKEN end_char="1995" id="token-24-3" morph="none" pos="word" start_char="1993">mas</TOKEN>
<TOKEN end_char="2005" id="token-24-4" morph="none" pos="word" start_char="1997">castigado</TOKEN>
<TOKEN end_char="2009" id="token-24-5" morph="none" pos="word" start_char="2007">del</TOKEN>
<TOKEN end_char="2015" id="token-24-6" morph="none" pos="word" start_char="2011">mundo</TOKEN>
<TOKEN end_char="2016" id="token-24-7" morph="none" pos="punct" start_char="2016">,</TOKEN>
<TOKEN end_char="2020" id="token-24-8" morph="none" pos="word" start_char="2018">han</TOKEN>
<TOKEN end_char="2028" id="token-24-9" morph="none" pos="word" start_char="2022">acabado</TOKEN>
<TOKEN end_char="2032" id="token-24-10" morph="none" pos="word" start_char="2030">con</TOKEN>
<TOKEN end_char="2035" id="token-24-11" morph="none" pos="word" start_char="2034">él</TOKEN>
<TOKEN end_char="2038" id="token-24-12" morph="none" pos="punct" start_char="2036">...</TOKEN>
<TRANSLATED_TEXT>He's the most punished mammal in the world, they've finished him...</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2132" id="segment-25" start_char="2040">
<ORIGINAL_TEXT>El problema no es el pangolín: es que se lo han comido y no han dicho lo que estaba pasando".</ORIGINAL_TEXT>
<TOKEN end_char="2041" id="token-25-0" morph="none" pos="word" start_char="2040">El</TOKEN>
<TOKEN end_char="2050" id="token-25-1" morph="none" pos="word" start_char="2043">problema</TOKEN>
<TOKEN end_char="2053" id="token-25-2" morph="none" pos="word" start_char="2052">no</TOKEN>
<TOKEN end_char="2056" id="token-25-3" morph="none" pos="word" start_char="2055">es</TOKEN>
<TOKEN end_char="2059" id="token-25-4" morph="none" pos="word" start_char="2058">el</TOKEN>
<TOKEN end_char="2068" id="token-25-5" morph="none" pos="word" start_char="2061">pangolín</TOKEN>
<TOKEN end_char="2069" id="token-25-6" morph="none" pos="punct" start_char="2069">:</TOKEN>
<TOKEN end_char="2072" id="token-25-7" morph="none" pos="word" start_char="2071">es</TOKEN>
<TOKEN end_char="2076" id="token-25-8" morph="none" pos="word" start_char="2074">que</TOKEN>
<TOKEN end_char="2079" id="token-25-9" morph="none" pos="word" start_char="2078">se</TOKEN>
<TOKEN end_char="2082" id="token-25-10" morph="none" pos="word" start_char="2081">lo</TOKEN>
<TOKEN end_char="2086" id="token-25-11" morph="none" pos="word" start_char="2084">han</TOKEN>
<TOKEN end_char="2093" id="token-25-12" morph="none" pos="word" start_char="2088">comido</TOKEN>
<TOKEN end_char="2095" id="token-25-13" morph="none" pos="word" start_char="2095">y</TOKEN>
<TOKEN end_char="2098" id="token-25-14" morph="none" pos="word" start_char="2097">no</TOKEN>
<TOKEN end_char="2102" id="token-25-15" morph="none" pos="word" start_char="2100">han</TOKEN>
<TOKEN end_char="2108" id="token-25-16" morph="none" pos="word" start_char="2104">dicho</TOKEN>
<TOKEN end_char="2111" id="token-25-17" morph="none" pos="word" start_char="2110">lo</TOKEN>
<TOKEN end_char="2115" id="token-25-18" morph="none" pos="word" start_char="2113">que</TOKEN>
<TOKEN end_char="2122" id="token-25-19" morph="none" pos="word" start_char="2117">estaba</TOKEN>
<TOKEN end_char="2130" id="token-25-20" morph="none" pos="word" start_char="2124">pasando</TOKEN>
<TOKEN end_char="2132" id="token-25-21" morph="none" pos="punct" start_char="2131">".</TOKEN>
<TRANSLATED_TEXT>The problem is not pangolin: it is that they ate it and did not say what was going on. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2375" id="segment-26" start_char="2135">
<ORIGINAL_TEXT>Para rematar el tema, Cuesta considera que en Tailandia, en realidad casi todo el mundo ya ha pasado en los meses de agosto, septiembre u octubre de 2019 el coronavirus, apuntando a que la epidemia lleva en realidad varios meses sin control.</ORIGINAL_TEXT>
<TOKEN end_char="2138" id="token-26-0" morph="none" pos="word" start_char="2135">Para</TOKEN>
<TOKEN end_char="2146" id="token-26-1" morph="none" pos="word" start_char="2140">rematar</TOKEN>
<TOKEN end_char="2149" id="token-26-2" morph="none" pos="word" start_char="2148">el</TOKEN>
<TOKEN end_char="2154" id="token-26-3" morph="none" pos="word" start_char="2151">tema</TOKEN>
<TOKEN end_char="2155" id="token-26-4" morph="none" pos="punct" start_char="2155">,</TOKEN>
<TOKEN end_char="2162" id="token-26-5" morph="none" pos="word" start_char="2157">Cuesta</TOKEN>
<TOKEN end_char="2172" id="token-26-6" morph="none" pos="word" start_char="2164">considera</TOKEN>
<TOKEN end_char="2176" id="token-26-7" morph="none" pos="word" start_char="2174">que</TOKEN>
<TOKEN end_char="2179" id="token-26-8" morph="none" pos="word" start_char="2178">en</TOKEN>
<TOKEN end_char="2189" id="token-26-9" morph="none" pos="word" start_char="2181">Tailandia</TOKEN>
<TOKEN end_char="2190" id="token-26-10" morph="none" pos="punct" start_char="2190">,</TOKEN>
<TOKEN end_char="2193" id="token-26-11" morph="none" pos="word" start_char="2192">en</TOKEN>
<TOKEN end_char="2202" id="token-26-12" morph="none" pos="word" start_char="2195">realidad</TOKEN>
<TOKEN end_char="2207" id="token-26-13" morph="none" pos="word" start_char="2204">casi</TOKEN>
<TOKEN end_char="2212" id="token-26-14" morph="none" pos="word" start_char="2209">todo</TOKEN>
<TOKEN end_char="2215" id="token-26-15" morph="none" pos="word" start_char="2214">el</TOKEN>
<TOKEN end_char="2221" id="token-26-16" morph="none" pos="word" start_char="2217">mundo</TOKEN>
<TOKEN end_char="2224" id="token-26-17" morph="none" pos="word" start_char="2223">ya</TOKEN>
<TOKEN end_char="2227" id="token-26-18" morph="none" pos="word" start_char="2226">ha</TOKEN>
<TOKEN end_char="2234" id="token-26-19" morph="none" pos="word" start_char="2229">pasado</TOKEN>
<TOKEN end_char="2237" id="token-26-20" morph="none" pos="word" start_char="2236">en</TOKEN>
<TOKEN end_char="2241" id="token-26-21" morph="none" pos="word" start_char="2239">los</TOKEN>
<TOKEN end_char="2247" id="token-26-22" morph="none" pos="word" start_char="2243">meses</TOKEN>
<TOKEN end_char="2250" id="token-26-23" morph="none" pos="word" start_char="2249">de</TOKEN>
<TOKEN end_char="2257" id="token-26-24" morph="none" pos="word" start_char="2252">agosto</TOKEN>
<TOKEN end_char="2258" id="token-26-25" morph="none" pos="punct" start_char="2258">,</TOKEN>
<TOKEN end_char="2269" id="token-26-26" morph="none" pos="word" start_char="2260">septiembre</TOKEN>
<TOKEN end_char="2271" id="token-26-27" morph="none" pos="word" start_char="2271">u</TOKEN>
<TOKEN end_char="2279" id="token-26-28" morph="none" pos="word" start_char="2273">octubre</TOKEN>
<TOKEN end_char="2282" id="token-26-29" morph="none" pos="word" start_char="2281">de</TOKEN>
<TOKEN end_char="2287" id="token-26-30" morph="none" pos="word" start_char="2284">2019</TOKEN>
<TOKEN end_char="2290" id="token-26-31" morph="none" pos="word" start_char="2289">el</TOKEN>
<TOKEN end_char="2302" id="token-26-32" morph="none" pos="word" start_char="2292">coronavirus</TOKEN>
<TOKEN end_char="2303" id="token-26-33" morph="none" pos="punct" start_char="2303">,</TOKEN>
<TOKEN end_char="2313" id="token-26-34" morph="none" pos="word" start_char="2305">apuntando</TOKEN>
<TOKEN end_char="2315" id="token-26-35" morph="none" pos="word" start_char="2315">a</TOKEN>
<TOKEN end_char="2319" id="token-26-36" morph="none" pos="word" start_char="2317">que</TOKEN>
<TOKEN end_char="2322" id="token-26-37" morph="none" pos="word" start_char="2321">la</TOKEN>
<TOKEN end_char="2331" id="token-26-38" morph="none" pos="word" start_char="2324">epidemia</TOKEN>
<TOKEN end_char="2337" id="token-26-39" morph="none" pos="word" start_char="2333">lleva</TOKEN>
<TOKEN end_char="2340" id="token-26-40" morph="none" pos="word" start_char="2339">en</TOKEN>
<TOKEN end_char="2349" id="token-26-41" morph="none" pos="word" start_char="2342">realidad</TOKEN>
<TOKEN end_char="2356" id="token-26-42" morph="none" pos="word" start_char="2351">varios</TOKEN>
<TOKEN end_char="2362" id="token-26-43" morph="none" pos="word" start_char="2358">meses</TOKEN>
<TOKEN end_char="2366" id="token-26-44" morph="none" pos="word" start_char="2364">sin</TOKEN>
<TOKEN end_char="2374" id="token-26-45" morph="none" pos="word" start_char="2368">control</TOKEN>
<TOKEN end_char="2375" id="token-26-46" morph="none" pos="punct" start_char="2375">.</TOKEN>
<TRANSLATED_TEXT>To conclude, Cuesta considers that in Thailand, in fact almost everyone has already passed the coronavirus in August, September or October 2019, pointing out that the epidemic has actually been out of control for several months.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2429" id="segment-27" start_char="2377">
<ORIGINAL_TEXT>"En agosto, por allí, ya hemos pasado todos el virus.</ORIGINAL_TEXT>
<TOKEN end_char="2377" id="token-27-0" morph="none" pos="punct" start_char="2377">"</TOKEN>
<TOKEN end_char="2379" id="token-27-1" morph="none" pos="word" start_char="2378">En</TOKEN>
<TOKEN end_char="2386" id="token-27-2" morph="none" pos="word" start_char="2381">agosto</TOKEN>
<TOKEN end_char="2387" id="token-27-3" morph="none" pos="punct" start_char="2387">,</TOKEN>
<TOKEN end_char="2391" id="token-27-4" morph="none" pos="word" start_char="2389">por</TOKEN>
<TOKEN end_char="2396" id="token-27-5" morph="none" pos="word" start_char="2393">allí</TOKEN>
<TOKEN end_char="2397" id="token-27-6" morph="none" pos="punct" start_char="2397">,</TOKEN>
<TOKEN end_char="2400" id="token-27-7" morph="none" pos="word" start_char="2399">ya</TOKEN>
<TOKEN end_char="2406" id="token-27-8" morph="none" pos="word" start_char="2402">hemos</TOKEN>
<TOKEN end_char="2413" id="token-27-9" morph="none" pos="word" start_char="2408">pasado</TOKEN>
<TOKEN end_char="2419" id="token-27-10" morph="none" pos="word" start_char="2415">todos</TOKEN>
<TOKEN end_char="2422" id="token-27-11" morph="none" pos="word" start_char="2421">el</TOKEN>
<TOKEN end_char="2428" id="token-27-12" morph="none" pos="word" start_char="2424">virus</TOKEN>
<TOKEN end_char="2429" id="token-27-13" morph="none" pos="punct" start_char="2429">.</TOKEN>
<TRANSLATED_TEXT>In August, through there, we have all passed the virus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2451" id="segment-28" start_char="2431">
<ORIGINAL_TEXT>Hemos pasado catarro.</ORIGINAL_TEXT>
<TOKEN end_char="2435" id="token-28-0" morph="none" pos="word" start_char="2431">Hemos</TOKEN>
<TOKEN end_char="2442" id="token-28-1" morph="none" pos="word" start_char="2437">pasado</TOKEN>
<TOKEN end_char="2450" id="token-28-2" morph="none" pos="word" start_char="2444">catarro</TOKEN>
<TOKEN end_char="2451" id="token-28-3" morph="none" pos="punct" start_char="2451">.</TOKEN>
<TRANSLATED_TEXT>We've passed the cataract.</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="2477" id="segment-29" start_char="2453">
<ORIGINAL_TEXT>Lo cogimos en casa todos.</ORIGINAL_TEXT>
<TOKEN end_char="2454" id="token-29-0" morph="none" pos="word" start_char="2453">Lo</TOKEN>
<TOKEN end_char="2462" id="token-29-1" morph="none" pos="word" start_char="2456">cogimos</TOKEN>
<TOKEN end_char="2465" id="token-29-2" morph="none" pos="word" start_char="2464">en</TOKEN>
<TOKEN end_char="2470" id="token-29-3" morph="none" pos="word" start_char="2467">casa</TOKEN>
<TOKEN end_char="2476" id="token-29-4" morph="none" pos="word" start_char="2472">todos</TOKEN>
<TOKEN end_char="2477" id="token-29-5" morph="none" pos="punct" start_char="2477">.</TOKEN>
<TRANSLATED_TEXT>We all took it at home.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2606" id="segment-30" start_char="2479">
<ORIGINAL_TEXT>Y ahora, empiezas a dar marchas atrás y piensas qué ha estado pasando desde septiembre, octubre y nadie entonces se dio cuenta".</ORIGINAL_TEXT>
<TOKEN end_char="2479" id="token-30-0" morph="none" pos="word" start_char="2479">Y</TOKEN>
<TOKEN end_char="2485" id="token-30-1" morph="none" pos="word" start_char="2481">ahora</TOKEN>
<TOKEN end_char="2486" id="token-30-2" morph="none" pos="punct" start_char="2486">,</TOKEN>
<TOKEN end_char="2495" id="token-30-3" morph="none" pos="word" start_char="2488">empiezas</TOKEN>
<TOKEN end_char="2497" id="token-30-4" morph="none" pos="word" start_char="2497">a</TOKEN>
<TOKEN end_char="2501" id="token-30-5" morph="none" pos="word" start_char="2499">dar</TOKEN>
<TOKEN end_char="2509" id="token-30-6" morph="none" pos="word" start_char="2503">marchas</TOKEN>
<TOKEN end_char="2515" id="token-30-7" morph="none" pos="word" start_char="2511">atrás</TOKEN>
<TOKEN end_char="2517" id="token-30-8" morph="none" pos="word" start_char="2517">y</TOKEN>
<TOKEN end_char="2525" id="token-30-9" morph="none" pos="word" start_char="2519">piensas</TOKEN>
<TOKEN end_char="2529" id="token-30-10" morph="none" pos="word" start_char="2527">qué</TOKEN>
<TOKEN end_char="2532" id="token-30-11" morph="none" pos="word" start_char="2531">ha</TOKEN>
<TOKEN end_char="2539" id="token-30-12" morph="none" pos="word" start_char="2534">estado</TOKEN>
<TOKEN end_char="2547" id="token-30-13" morph="none" pos="word" start_char="2541">pasando</TOKEN>
<TOKEN end_char="2553" id="token-30-14" morph="none" pos="word" start_char="2549">desde</TOKEN>
<TOKEN end_char="2564" id="token-30-15" morph="none" pos="word" start_char="2555">septiembre</TOKEN>
<TOKEN end_char="2565" id="token-30-16" morph="none" pos="punct" start_char="2565">,</TOKEN>
<TOKEN end_char="2573" id="token-30-17" morph="none" pos="word" start_char="2567">octubre</TOKEN>
<TOKEN end_char="2575" id="token-30-18" morph="none" pos="word" start_char="2575">y</TOKEN>
<TOKEN end_char="2581" id="token-30-19" morph="none" pos="word" start_char="2577">nadie</TOKEN>
<TOKEN end_char="2590" id="token-30-20" morph="none" pos="word" start_char="2583">entonces</TOKEN>
<TOKEN end_char="2593" id="token-30-21" morph="none" pos="word" start_char="2592">se</TOKEN>
<TOKEN end_char="2597" id="token-30-22" morph="none" pos="word" start_char="2595">dio</TOKEN>
<TOKEN end_char="2604" id="token-30-23" morph="none" pos="word" start_char="2599">cuenta</TOKEN>
<TOKEN end_char="2606" id="token-30-24" morph="none" pos="punct" start_char="2605">".</TOKEN>
<TRANSLATED_TEXT>And now, you start walking back and thinking about what has been going on since September, October and nobody then realized. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CA9S" lang="spa" raw_text_char_length="7079" raw_text_md5="b1623e5e83f3f273480e12ba3ce35bd0" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="60" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Chinese State Media Echoes Claims COVID-19 Originated Abroad</ORIGINAL_TEXT>
<TOKEN end_char="7" id="token-0-0" morph="none" pos="word" start_char="1">Chinese</TOKEN>
<TOKEN end_char="13" id="token-0-1" morph="none" pos="word" start_char="9">State</TOKEN>
<TOKEN end_char="19" id="token-0-2" morph="none" pos="word" start_char="15">Media</TOKEN>
<TOKEN end_char="26" id="token-0-3" morph="none" pos="word" start_char="21">Echoes</TOKEN>
<TOKEN end_char="33" id="token-0-4" morph="none" pos="word" start_char="28">Claims</TOKEN>
<TOKEN end_char="42" id="token-0-5" morph="none" pos="unknown" start_char="35">COVID-19</TOKEN>
<TOKEN end_char="53" id="token-0-6" morph="none" pos="word" start_char="44">Originated</TOKEN>
<TOKEN end_char="60" id="token-0-7" morph="none" pos="word" start_char="55">Abroad</TOKEN>
</SEG>
<SEG end_char="267" id="segment-1" start_char="64">
<ORIGINAL_TEXT>In recent days Chinese state media has returned to the claim that coronavirus did not emerge in Wuhan, the latest attempt to shape the public narrative and global memory of China’s coronavirus experience.</ORIGINAL_TEXT>
<TOKEN end_char="65" id="token-1-0" morph="none" pos="word" start_char="64">In</TOKEN>
<TOKEN end_char="72" id="token-1-1" morph="none" pos="word" start_char="67">recent</TOKEN>
<TOKEN end_char="77" id="token-1-2" morph="none" pos="word" start_char="74">days</TOKEN>
<TOKEN end_char="85" id="token-1-3" morph="none" pos="word" start_char="79">Chinese</TOKEN>
<TOKEN end_char="91" id="token-1-4" morph="none" pos="word" start_char="87">state</TOKEN>
<TOKEN end_char="97" id="token-1-5" morph="none" pos="word" start_char="93">media</TOKEN>
<TOKEN end_char="101" id="token-1-6" morph="none" pos="word" start_char="99">has</TOKEN>
<TOKEN end_char="110" id="token-1-7" morph="none" pos="word" start_char="103">returned</TOKEN>
<TOKEN end_char="113" id="token-1-8" morph="none" pos="word" start_char="112">to</TOKEN>
<TOKEN end_char="117" id="token-1-9" morph="none" pos="word" start_char="115">the</TOKEN>
<TOKEN end_char="123" id="token-1-10" morph="none" pos="word" start_char="119">claim</TOKEN>
<TOKEN end_char="128" id="token-1-11" morph="none" pos="word" start_char="125">that</TOKEN>
<TOKEN end_char="140" id="token-1-12" morph="none" pos="word" start_char="130">coronavirus</TOKEN>
<TOKEN end_char="144" id="token-1-13" morph="none" pos="word" start_char="142">did</TOKEN>
<TOKEN end_char="148" id="token-1-14" morph="none" pos="word" start_char="146">not</TOKEN>
<TOKEN end_char="155" id="token-1-15" morph="none" pos="word" start_char="150">emerge</TOKEN>
<TOKEN end_char="158" id="token-1-16" morph="none" pos="word" start_char="157">in</TOKEN>
<TOKEN end_char="164" id="token-1-17" morph="none" pos="word" start_char="160">Wuhan</TOKEN>
<TOKEN end_char="165" id="token-1-18" morph="none" pos="punct" start_char="165">,</TOKEN>
<TOKEN end_char="169" id="token-1-19" morph="none" pos="word" start_char="167">the</TOKEN>
<TOKEN end_char="176" id="token-1-20" morph="none" pos="word" start_char="171">latest</TOKEN>
<TOKEN end_char="184" id="token-1-21" morph="none" pos="word" start_char="178">attempt</TOKEN>
<TOKEN end_char="187" id="token-1-22" morph="none" pos="word" start_char="186">to</TOKEN>
<TOKEN end_char="193" id="token-1-23" morph="none" pos="word" start_char="189">shape</TOKEN>
<TOKEN end_char="197" id="token-1-24" morph="none" pos="word" start_char="195">the</TOKEN>
<TOKEN end_char="204" id="token-1-25" morph="none" pos="word" start_char="199">public</TOKEN>
<TOKEN end_char="214" id="token-1-26" morph="none" pos="word" start_char="206">narrative</TOKEN>
<TOKEN end_char="218" id="token-1-27" morph="none" pos="word" start_char="216">and</TOKEN>
<TOKEN end_char="225" id="token-1-28" morph="none" pos="word" start_char="220">global</TOKEN>
<TOKEN end_char="232" id="token-1-29" morph="none" pos="word" start_char="227">memory</TOKEN>
<TOKEN end_char="235" id="token-1-30" morph="none" pos="word" start_char="234">of</TOKEN>
<TOKEN end_char="243" id="token-1-31" morph="none" pos="word" start_char="237">China’s</TOKEN>
<TOKEN end_char="255" id="token-1-32" morph="none" pos="word" start_char="245">coronavirus</TOKEN>
<TOKEN end_char="266" id="token-1-33" morph="none" pos="word" start_char="257">experience</TOKEN>
<TOKEN end_char="267" id="token-1-34" morph="none" pos="punct" start_char="267">.</TOKEN>
</SEG>
<SEG end_char="469" id="segment-2" start_char="269">
<ORIGINAL_TEXT>In English-language posts on Facebook (a platform long blocked in China), Party mouthpiece People’s Daily quoted two top Chinese scientists who both claimed the coronavirus was imported from elsewhere:</ORIGINAL_TEXT>
<TOKEN end_char="270" id="token-2-0" morph="none" pos="word" start_char="269">In</TOKEN>
<TOKEN end_char="287" id="token-2-1" morph="none" pos="unknown" start_char="272">English-language</TOKEN>
<TOKEN end_char="293" id="token-2-2" morph="none" pos="word" start_char="289">posts</TOKEN>
<TOKEN end_char="296" id="token-2-3" morph="none" pos="word" start_char="295">on</TOKEN>
<TOKEN end_char="305" id="token-2-4" morph="none" pos="word" start_char="298">Facebook</TOKEN>
<TOKEN end_char="307" id="token-2-5" morph="none" pos="punct" start_char="307">(</TOKEN>
<TOKEN end_char="308" id="token-2-6" morph="none" pos="word" start_char="308">a</TOKEN>
<TOKEN end_char="317" id="token-2-7" morph="none" pos="word" start_char="310">platform</TOKEN>
<TOKEN end_char="322" id="token-2-8" morph="none" pos="word" start_char="319">long</TOKEN>
<TOKEN end_char="330" id="token-2-9" morph="none" pos="word" start_char="324">blocked</TOKEN>
<TOKEN end_char="333" id="token-2-10" morph="none" pos="word" start_char="332">in</TOKEN>
<TOKEN end_char="339" id="token-2-11" morph="none" pos="word" start_char="335">China</TOKEN>
<TOKEN end_char="341" id="token-2-12" morph="none" pos="punct" start_char="340">),</TOKEN>
<TOKEN end_char="347" id="token-2-13" morph="none" pos="word" start_char="343">Party</TOKEN>
<TOKEN end_char="358" id="token-2-14" morph="none" pos="word" start_char="349">mouthpiece</TOKEN>
<TOKEN end_char="367" id="token-2-15" morph="none" pos="word" start_char="360">People’s</TOKEN>
<TOKEN end_char="373" id="token-2-16" morph="none" pos="word" start_char="369">Daily</TOKEN>
<TOKEN end_char="380" id="token-2-17" morph="none" pos="word" start_char="375">quoted</TOKEN>
<TOKEN end_char="384" id="token-2-18" morph="none" pos="word" start_char="382">two</TOKEN>
<TOKEN end_char="388" id="token-2-19" morph="none" pos="word" start_char="386">top</TOKEN>
<TOKEN end_char="396" id="token-2-20" morph="none" pos="word" start_char="390">Chinese</TOKEN>
<TOKEN end_char="407" id="token-2-21" morph="none" pos="word" start_char="398">scientists</TOKEN>
<TOKEN end_char="411" id="token-2-22" morph="none" pos="word" start_char="409">who</TOKEN>
<TOKEN end_char="416" id="token-2-23" morph="none" pos="word" start_char="413">both</TOKEN>
<TOKEN end_char="424" id="token-2-24" morph="none" pos="word" start_char="418">claimed</TOKEN>
<TOKEN end_char="428" id="token-2-25" morph="none" pos="word" start_char="426">the</TOKEN>
<TOKEN end_char="440" id="token-2-26" morph="none" pos="word" start_char="430">coronavirus</TOKEN>
<TOKEN end_char="444" id="token-2-27" morph="none" pos="word" start_char="442">was</TOKEN>
<TOKEN end_char="453" id="token-2-28" morph="none" pos="word" start_char="446">imported</TOKEN>
<TOKEN end_char="458" id="token-2-29" morph="none" pos="word" start_char="455">from</TOKEN>
<TOKEN end_char="468" id="token-2-30" morph="none" pos="word" start_char="460">elsewhere</TOKEN>
<TOKEN end_char="469" id="token-2-31" morph="none" pos="punct" start_char="469">:</TOKEN>
</SEG>
<SEG end_char="762" id="segment-3" start_char="472">
<ORIGINAL_TEXT>#COVID19 did not start in central China’s Wuhan but may come through imported frozen food and packaging: experts All available evidence suggests that the coronavirus, which has infected more than 59 million people in 190 countries, did not start in central China’s Wuhan, experts reiterated.</ORIGINAL_TEXT>
<TOKEN end_char="479" id="token-3-0" morph="none" pos="tag" start_char="472">#COVID19</TOKEN>
<TOKEN end_char="483" id="token-3-1" morph="none" pos="word" start_char="481">did</TOKEN>
<TOKEN end_char="487" id="token-3-2" morph="none" pos="word" start_char="485">not</TOKEN>
<TOKEN end_char="493" id="token-3-3" morph="none" pos="word" start_char="489">start</TOKEN>
<TOKEN end_char="496" id="token-3-4" morph="none" pos="word" start_char="495">in</TOKEN>
<TOKEN end_char="504" id="token-3-5" morph="none" pos="word" start_char="498">central</TOKEN>
<TOKEN end_char="512" id="token-3-6" morph="none" pos="word" start_char="506">China’s</TOKEN>
<TOKEN end_char="518" id="token-3-7" morph="none" pos="word" start_char="514">Wuhan</TOKEN>
<TOKEN end_char="522" id="token-3-8" morph="none" pos="word" start_char="520">but</TOKEN>
<TOKEN end_char="526" id="token-3-9" morph="none" pos="word" start_char="524">may</TOKEN>
<TOKEN end_char="531" id="token-3-10" morph="none" pos="word" start_char="528">come</TOKEN>
<TOKEN end_char="539" id="token-3-11" morph="none" pos="word" start_char="533">through</TOKEN>
<TOKEN end_char="548" id="token-3-12" morph="none" pos="word" start_char="541">imported</TOKEN>
<TOKEN end_char="555" id="token-3-13" morph="none" pos="word" start_char="550">frozen</TOKEN>
<TOKEN end_char="560" id="token-3-14" morph="none" pos="word" start_char="557">food</TOKEN>
<TOKEN end_char="564" id="token-3-15" morph="none" pos="word" start_char="562">and</TOKEN>
<TOKEN end_char="574" id="token-3-16" morph="none" pos="word" start_char="566">packaging</TOKEN>
<TOKEN end_char="575" id="token-3-17" morph="none" pos="punct" start_char="575">:</TOKEN>
<TOKEN end_char="583" id="token-3-18" morph="none" pos="word" start_char="577">experts</TOKEN>
<TOKEN end_char="587" id="token-3-19" morph="none" pos="word" start_char="585">All</TOKEN>
<TOKEN end_char="597" id="token-3-20" morph="none" pos="word" start_char="589">available</TOKEN>
<TOKEN end_char="606" id="token-3-21" morph="none" pos="word" start_char="599">evidence</TOKEN>
<TOKEN end_char="615" id="token-3-22" morph="none" pos="word" start_char="608">suggests</TOKEN>
<TOKEN end_char="620" id="token-3-23" morph="none" pos="word" start_char="617">that</TOKEN>
<TOKEN end_char="624" id="token-3-24" morph="none" pos="word" start_char="622">the</TOKEN>
<TOKEN end_char="636" id="token-3-25" morph="none" pos="word" start_char="626">coronavirus</TOKEN>
<TOKEN end_char="637" id="token-3-26" morph="none" pos="punct" start_char="637">,</TOKEN>
<TOKEN end_char="643" id="token-3-27" morph="none" pos="word" start_char="639">which</TOKEN>
<TOKEN end_char="647" id="token-3-28" morph="none" pos="word" start_char="645">has</TOKEN>
<TOKEN end_char="656" id="token-3-29" morph="none" pos="word" start_char="649">infected</TOKEN>
<TOKEN end_char="661" id="token-3-30" morph="none" pos="word" start_char="658">more</TOKEN>
<TOKEN end_char="666" id="token-3-31" morph="none" pos="word" start_char="663">than</TOKEN>
<TOKEN end_char="669" id="token-3-32" morph="none" pos="word" start_char="668">59</TOKEN>
<TOKEN end_char="677" id="token-3-33" morph="none" pos="word" start_char="671">million</TOKEN>
<TOKEN end_char="684" id="token-3-34" morph="none" pos="word" start_char="679">people</TOKEN>
<TOKEN end_char="687" id="token-3-35" morph="none" pos="word" start_char="686">in</TOKEN>
<TOKEN end_char="691" id="token-3-36" morph="none" pos="word" start_char="689">190</TOKEN>
<TOKEN end_char="701" id="token-3-37" morph="none" pos="word" start_char="693">countries</TOKEN>
<TOKEN end_char="702" id="token-3-38" morph="none" pos="punct" start_char="702">,</TOKEN>
<TOKEN end_char="706" id="token-3-39" morph="none" pos="word" start_char="704">did</TOKEN>
<TOKEN end_char="710" id="token-3-40" morph="none" pos="word" start_char="708">not</TOKEN>
<TOKEN end_char="716" id="token-3-41" morph="none" pos="word" start_char="712">start</TOKEN>
<TOKEN end_char="719" id="token-3-42" morph="none" pos="word" start_char="718">in</TOKEN>
<TOKEN end_char="727" id="token-3-43" morph="none" pos="word" start_char="721">central</TOKEN>
<TOKEN end_char="735" id="token-3-44" morph="none" pos="word" start_char="729">China’s</TOKEN>
<TOKEN end_char="741" id="token-3-45" morph="none" pos="word" start_char="737">Wuhan</TOKEN>
<TOKEN end_char="742" id="token-3-46" morph="none" pos="punct" start_char="742">,</TOKEN>
<TOKEN end_char="750" id="token-3-47" morph="none" pos="word" start_char="744">experts</TOKEN>
<TOKEN end_char="761" id="token-3-48" morph="none" pos="word" start_char="752">reiterated</TOKEN>
<TOKEN end_char="762" id="token-3-49" morph="none" pos="punct" start_char="762">.</TOKEN>
</SEG>
<SEG end_char="1001" id="segment-4" start_char="764">
<ORIGINAL_TEXT>"Wuhan was where the coronavirus was first detected but it was not where it originated," Zeng Guang, former chief epidemiologist of the Chinese Centre for Disease Control and Prevention (CDC), told an online academic conference on Nov 19.</ORIGINAL_TEXT>
<TOKEN end_char="764" id="token-4-0" morph="none" pos="punct" start_char="764">"</TOKEN>
<TOKEN end_char="769" id="token-4-1" morph="none" pos="word" start_char="765">Wuhan</TOKEN>
<TOKEN end_char="773" id="token-4-2" morph="none" pos="word" start_char="771">was</TOKEN>
<TOKEN end_char="779" id="token-4-3" morph="none" pos="word" start_char="775">where</TOKEN>
<TOKEN end_char="783" id="token-4-4" morph="none" pos="word" start_char="781">the</TOKEN>
<TOKEN end_char="795" id="token-4-5" morph="none" pos="word" start_char="785">coronavirus</TOKEN>
<TOKEN end_char="799" id="token-4-6" morph="none" pos="word" start_char="797">was</TOKEN>
<TOKEN end_char="805" id="token-4-7" morph="none" pos="word" start_char="801">first</TOKEN>
<TOKEN end_char="814" id="token-4-8" morph="none" pos="word" start_char="807">detected</TOKEN>
<TOKEN end_char="818" id="token-4-9" morph="none" pos="word" start_char="816">but</TOKEN>
<TOKEN end_char="821" id="token-4-10" morph="none" pos="word" start_char="820">it</TOKEN>
<TOKEN end_char="825" id="token-4-11" morph="none" pos="word" start_char="823">was</TOKEN>
<TOKEN end_char="829" id="token-4-12" morph="none" pos="word" start_char="827">not</TOKEN>
<TOKEN end_char="835" id="token-4-13" morph="none" pos="word" start_char="831">where</TOKEN>
<TOKEN end_char="838" id="token-4-14" morph="none" pos="word" start_char="837">it</TOKEN>
<TOKEN end_char="849" id="token-4-15" morph="none" pos="word" start_char="840">originated</TOKEN>
<TOKEN end_char="851" id="token-4-16" morph="none" pos="punct" start_char="850">,"</TOKEN>
<TOKEN end_char="856" id="token-4-17" morph="none" pos="word" start_char="853">Zeng</TOKEN>
<TOKEN end_char="862" id="token-4-18" morph="none" pos="word" start_char="858">Guang</TOKEN>
<TOKEN end_char="863" id="token-4-19" morph="none" pos="punct" start_char="863">,</TOKEN>
<TOKEN end_char="870" id="token-4-20" morph="none" pos="word" start_char="865">former</TOKEN>
<TOKEN end_char="876" id="token-4-21" morph="none" pos="word" start_char="872">chief</TOKEN>
<TOKEN end_char="891" id="token-4-22" morph="none" pos="word" start_char="878">epidemiologist</TOKEN>
<TOKEN end_char="894" id="token-4-23" morph="none" pos="word" start_char="893">of</TOKEN>
<TOKEN end_char="898" id="token-4-24" morph="none" pos="word" start_char="896">the</TOKEN>
<TOKEN end_char="906" id="token-4-25" morph="none" pos="word" start_char="900">Chinese</TOKEN>
<TOKEN end_char="913" id="token-4-26" morph="none" pos="word" start_char="908">Centre</TOKEN>
<TOKEN end_char="917" id="token-4-27" morph="none" pos="word" start_char="915">for</TOKEN>
<TOKEN end_char="925" id="token-4-28" morph="none" pos="word" start_char="919">Disease</TOKEN>
<TOKEN end_char="933" id="token-4-29" morph="none" pos="word" start_char="927">Control</TOKEN>
<TOKEN end_char="937" id="token-4-30" morph="none" pos="word" start_char="935">and</TOKEN>
<TOKEN end_char="948" id="token-4-31" morph="none" pos="word" start_char="939">Prevention</TOKEN>
<TOKEN end_char="950" id="token-4-32" morph="none" pos="punct" start_char="950">(</TOKEN>
<TOKEN end_char="953" id="token-4-33" morph="none" pos="word" start_char="951">CDC</TOKEN>
<TOKEN end_char="955" id="token-4-34" morph="none" pos="punct" start_char="954">),</TOKEN>
<TOKEN end_char="960" id="token-4-35" morph="none" pos="word" start_char="957">told</TOKEN>
<TOKEN end_char="963" id="token-4-36" morph="none" pos="word" start_char="962">an</TOKEN>
<TOKEN end_char="970" id="token-4-37" morph="none" pos="word" start_char="965">online</TOKEN>
<TOKEN end_char="979" id="token-4-38" morph="none" pos="word" start_char="972">academic</TOKEN>
<TOKEN end_char="990" id="token-4-39" morph="none" pos="word" start_char="981">conference</TOKEN>
<TOKEN end_char="993" id="token-4-40" morph="none" pos="word" start_char="992">on</TOKEN>
<TOKEN end_char="997" id="token-4-41" morph="none" pos="word" start_char="995">Nov</TOKEN>
<TOKEN end_char="1000" id="token-4-42" morph="none" pos="word" start_char="999">19</TOKEN>
<TOKEN end_char="1001" id="token-4-43" morph="none" pos="punct" start_char="1001">.</TOKEN>
</SEG>
<SEG end_char="1247" id="segment-5" start_char="1003">
<ORIGINAL_TEXT>Wu Zunyou, the CDC’s present chief epidemiologist, also gave a similar judgment recently, saying the pathogen could have come into China through imported frozen seafood or meat products and their packaging, reported the South China Morning Post.</ORIGINAL_TEXT>
<TOKEN end_char="1004" id="token-5-0" morph="none" pos="word" start_char="1003">Wu</TOKEN>
<TOKEN end_char="1011" id="token-5-1" morph="none" pos="word" start_char="1006">Zunyou</TOKEN>
<TOKEN end_char="1012" id="token-5-2" morph="none" pos="punct" start_char="1012">,</TOKEN>
<TOKEN end_char="1016" id="token-5-3" morph="none" pos="word" start_char="1014">the</TOKEN>
<TOKEN end_char="1022" id="token-5-4" morph="none" pos="word" start_char="1018">CDC’s</TOKEN>
<TOKEN end_char="1030" id="token-5-5" morph="none" pos="word" start_char="1024">present</TOKEN>
<TOKEN end_char="1036" id="token-5-6" morph="none" pos="word" start_char="1032">chief</TOKEN>
<TOKEN end_char="1051" id="token-5-7" morph="none" pos="word" start_char="1038">epidemiologist</TOKEN>
<TOKEN end_char="1052" id="token-5-8" morph="none" pos="punct" start_char="1052">,</TOKEN>
<TOKEN end_char="1057" id="token-5-9" morph="none" pos="word" start_char="1054">also</TOKEN>
<TOKEN end_char="1062" id="token-5-10" morph="none" pos="word" start_char="1059">gave</TOKEN>
<TOKEN end_char="1064" id="token-5-11" morph="none" pos="word" start_char="1064">a</TOKEN>
<TOKEN end_char="1072" id="token-5-12" morph="none" pos="word" start_char="1066">similar</TOKEN>
<TOKEN end_char="1081" id="token-5-13" morph="none" pos="word" start_char="1074">judgment</TOKEN>
<TOKEN end_char="1090" id="token-5-14" morph="none" pos="word" start_char="1083">recently</TOKEN>
<TOKEN end_char="1091" id="token-5-15" morph="none" pos="punct" start_char="1091">,</TOKEN>
<TOKEN end_char="1098" id="token-5-16" morph="none" pos="word" start_char="1093">saying</TOKEN>
<TOKEN end_char="1102" id="token-5-17" morph="none" pos="word" start_char="1100">the</TOKEN>
<TOKEN end_char="1111" id="token-5-18" morph="none" pos="word" start_char="1104">pathogen</TOKEN>
<TOKEN end_char="1117" id="token-5-19" morph="none" pos="word" start_char="1113">could</TOKEN>
<TOKEN end_char="1122" id="token-5-20" morph="none" pos="word" start_char="1119">have</TOKEN>
<TOKEN end_char="1127" id="token-5-21" morph="none" pos="word" start_char="1124">come</TOKEN>
<TOKEN end_char="1132" id="token-5-22" morph="none" pos="word" start_char="1129">into</TOKEN>
<TOKEN end_char="1138" id="token-5-23" morph="none" pos="word" start_char="1134">China</TOKEN>
<TOKEN end_char="1146" id="token-5-24" morph="none" pos="word" start_char="1140">through</TOKEN>
<TOKEN end_char="1155" id="token-5-25" morph="none" pos="word" start_char="1148">imported</TOKEN>
<TOKEN end_char="1162" id="token-5-26" morph="none" pos="word" start_char="1157">frozen</TOKEN>
<TOKEN end_char="1170" id="token-5-27" morph="none" pos="word" start_char="1164">seafood</TOKEN>
<TOKEN end_char="1173" id="token-5-28" morph="none" pos="word" start_char="1172">or</TOKEN>
<TOKEN end_char="1178" id="token-5-29" morph="none" pos="word" start_char="1175">meat</TOKEN>
<TOKEN end_char="1187" id="token-5-30" morph="none" pos="word" start_char="1180">products</TOKEN>
<TOKEN end_char="1191" id="token-5-31" morph="none" pos="word" start_char="1189">and</TOKEN>
<TOKEN end_char="1197" id="token-5-32" morph="none" pos="word" start_char="1193">their</TOKEN>
<TOKEN end_char="1207" id="token-5-33" morph="none" pos="word" start_char="1199">packaging</TOKEN>
<TOKEN end_char="1208" id="token-5-34" morph="none" pos="punct" start_char="1208">,</TOKEN>
<TOKEN end_char="1217" id="token-5-35" morph="none" pos="word" start_char="1210">reported</TOKEN>
<TOKEN end_char="1221" id="token-5-36" morph="none" pos="word" start_char="1219">the</TOKEN>
<TOKEN end_char="1227" id="token-5-37" morph="none" pos="word" start_char="1223">South</TOKEN>
<TOKEN end_char="1233" id="token-5-38" morph="none" pos="word" start_char="1229">China</TOKEN>
<TOKEN end_char="1241" id="token-5-39" morph="none" pos="word" start_char="1235">Morning</TOKEN>
<TOKEN end_char="1246" id="token-5-40" morph="none" pos="word" start_char="1243">Post</TOKEN>
<TOKEN end_char="1247" id="token-5-41" morph="none" pos="punct" start_char="1247">.</TOKEN>
</SEG>
<SEG end_char="1256" id="segment-6" start_char="1249">
<ORIGINAL_TEXT>[Source]</ORIGINAL_TEXT>
<TOKEN end_char="1249" id="token-6-0" morph="none" pos="punct" start_char="1249">[</TOKEN>
<TOKEN end_char="1255" id="token-6-1" morph="none" pos="word" start_char="1250">Source</TOKEN>
<TOKEN end_char="1256" id="token-6-2" morph="none" pos="punct" start_char="1256">]</TOKEN>
</SEG>
<SEG end_char="1540" id="segment-7" start_char="1261">
<ORIGINAL_TEXT>All available evidence suggests that #COVID19 did not start in central China’s Wuhan, but may come into China through imported frozen food products and their packaging: experts https://t.co/PPakQ6vJzW pic.twitter.com/540HQNrrr1 — People's Daily, China (@PDChina) November 25, 2020</ORIGINAL_TEXT>
<TOKEN end_char="1263" id="token-7-0" morph="none" pos="word" start_char="1261">All</TOKEN>
<TOKEN end_char="1273" id="token-7-1" morph="none" pos="word" start_char="1265">available</TOKEN>
<TOKEN end_char="1282" id="token-7-2" morph="none" pos="word" start_char="1275">evidence</TOKEN>
<TOKEN end_char="1291" id="token-7-3" morph="none" pos="word" start_char="1284">suggests</TOKEN>
<TOKEN end_char="1296" id="token-7-4" morph="none" pos="word" start_char="1293">that</TOKEN>
<TOKEN end_char="1305" id="token-7-5" morph="none" pos="tag" start_char="1298">#COVID19</TOKEN>
<TOKEN end_char="1309" id="token-7-6" morph="none" pos="word" start_char="1307">did</TOKEN>
<TOKEN end_char="1313" id="token-7-7" morph="none" pos="word" start_char="1311">not</TOKEN>
<TOKEN end_char="1319" id="token-7-8" morph="none" pos="word" start_char="1315">start</TOKEN>
<TOKEN end_char="1322" id="token-7-9" morph="none" pos="word" start_char="1321">in</TOKEN>
<TOKEN end_char="1330" id="token-7-10" morph="none" pos="word" start_char="1324">central</TOKEN>
<TOKEN end_char="1338" id="token-7-11" morph="none" pos="word" start_char="1332">China’s</TOKEN>
<TOKEN end_char="1344" id="token-7-12" morph="none" pos="word" start_char="1340">Wuhan</TOKEN>
<TOKEN end_char="1345" id="token-7-13" morph="none" pos="punct" start_char="1345">,</TOKEN>
<TOKEN end_char="1349" id="token-7-14" morph="none" pos="word" start_char="1347">but</TOKEN>
<TOKEN end_char="1353" id="token-7-15" morph="none" pos="word" start_char="1351">may</TOKEN>
<TOKEN end_char="1358" id="token-7-16" morph="none" pos="word" start_char="1355">come</TOKEN>
<TOKEN end_char="1363" id="token-7-17" morph="none" pos="word" start_char="1360">into</TOKEN>
<TOKEN end_char="1369" id="token-7-18" morph="none" pos="word" start_char="1365">China</TOKEN>
<TOKEN end_char="1377" id="token-7-19" morph="none" pos="word" start_char="1371">through</TOKEN>
<TOKEN end_char="1386" id="token-7-20" morph="none" pos="word" start_char="1379">imported</TOKEN>
<TOKEN end_char="1393" id="token-7-21" morph="none" pos="word" start_char="1388">frozen</TOKEN>
<TOKEN end_char="1398" id="token-7-22" morph="none" pos="word" start_char="1395">food</TOKEN>
<TOKEN end_char="1407" id="token-7-23" morph="none" pos="word" start_char="1400">products</TOKEN>
<TOKEN end_char="1411" id="token-7-24" morph="none" pos="word" start_char="1409">and</TOKEN>
<TOKEN end_char="1417" id="token-7-25" morph="none" pos="word" start_char="1413">their</TOKEN>
<TOKEN end_char="1427" id="token-7-26" morph="none" pos="word" start_char="1419">packaging</TOKEN>
<TOKEN end_char="1428" id="token-7-27" morph="none" pos="punct" start_char="1428">:</TOKEN>
<TOKEN end_char="1436" id="token-7-28" morph="none" pos="word" start_char="1430">experts</TOKEN>
<TOKEN end_char="1460" id="token-7-29" morph="none" pos="url" start_char="1438">https://t.co/PPakQ6vJzW</TOKEN>
<TOKEN end_char="1487" id="token-7-30" morph="none" pos="unknown" start_char="1462">pic.twitter.com/540HQNrrr1</TOKEN>
<TOKEN end_char="1489" id="token-7-31" morph="none" pos="punct" start_char="1489">—</TOKEN>
<TOKEN end_char="1498" id="token-7-32" morph="none" pos="word" start_char="1491">People's</TOKEN>
<TOKEN end_char="1504" id="token-7-33" morph="none" pos="word" start_char="1500">Daily</TOKEN>
<TOKEN end_char="1505" id="token-7-34" morph="none" pos="punct" start_char="1505">,</TOKEN>
<TOKEN end_char="1511" id="token-7-35" morph="none" pos="word" start_char="1507">China</TOKEN>
<TOKEN end_char="1514" id="token-7-36" morph="none" pos="punct" start_char="1513">(@</TOKEN>
<TOKEN end_char="1521" id="token-7-37" morph="none" pos="word" start_char="1515">PDChina</TOKEN>
<TOKEN end_char="1522" id="token-7-38" morph="none" pos="punct" start_char="1522">)</TOKEN>
<TOKEN end_char="1531" id="token-7-39" morph="none" pos="word" start_char="1524">November</TOKEN>
<TOKEN end_char="1534" id="token-7-40" morph="none" pos="word" start_char="1533">25</TOKEN>
<TOKEN end_char="1535" id="token-7-41" morph="none" pos="punct" start_char="1535">,</TOKEN>
<TOKEN end_char="1540" id="token-7-42" morph="none" pos="word" start_char="1537">2020</TOKEN>
</SEG>
<SEG end_char="1625" id="segment-8" start_char="1545">
<ORIGINAL_TEXT>— Michael "In A Move Likely To Anger China" Mazza (@mike_mazza) November 25, 2020</ORIGINAL_TEXT>
<TOKEN end_char="1545" id="token-8-0" morph="none" pos="punct" start_char="1545">—</TOKEN>
<TOKEN end_char="1553" id="token-8-1" morph="none" pos="word" start_char="1547">Michael</TOKEN>
<TOKEN end_char="1555" id="token-8-2" morph="none" pos="punct" start_char="1555">"</TOKEN>
<TOKEN end_char="1557" id="token-8-3" morph="none" pos="word" start_char="1556">In</TOKEN>
<TOKEN end_char="1559" id="token-8-4" morph="none" pos="word" start_char="1559">A</TOKEN>
<TOKEN end_char="1564" id="token-8-5" morph="none" pos="word" start_char="1561">Move</TOKEN>
<TOKEN end_char="1571" id="token-8-6" morph="none" pos="word" start_char="1566">Likely</TOKEN>
<TOKEN end_char="1574" id="token-8-7" morph="none" pos="word" start_char="1573">To</TOKEN>
<TOKEN end_char="1580" id="token-8-8" morph="none" pos="word" start_char="1576">Anger</TOKEN>
<TOKEN end_char="1586" id="token-8-9" morph="none" pos="word" start_char="1582">China</TOKEN>
<TOKEN end_char="1587" id="token-8-10" morph="none" pos="punct" start_char="1587">"</TOKEN>
<TOKEN end_char="1593" id="token-8-11" morph="none" pos="word" start_char="1589">Mazza</TOKEN>
<TOKEN end_char="1596" id="token-8-12" morph="none" pos="punct" start_char="1595">(@</TOKEN>
<TOKEN end_char="1606" id="token-8-13" morph="none" pos="word" start_char="1597">mike_mazza</TOKEN>
<TOKEN end_char="1607" id="token-8-14" morph="none" pos="punct" start_char="1607">)</TOKEN>
<TOKEN end_char="1616" id="token-8-15" morph="none" pos="word" start_char="1609">November</TOKEN>
<TOKEN end_char="1619" id="token-8-16" morph="none" pos="word" start_char="1618">25</TOKEN>
<TOKEN end_char="1620" id="token-8-17" morph="none" pos="punct" start_char="1620">,</TOKEN>
<TOKEN end_char="1625" id="token-8-18" morph="none" pos="word" start_char="1622">2020</TOKEN>
<TRANSLATED_TEXT>Michael "In A Move Probably To Anger China" Mazza (@mike _ mazza) November 25, 2020</TRANSLATED_TEXT><DETECTED_LANGUAGE>hu</DETECTED_LANGUAGE></SEG>
<SEG end_char="1761" id="segment-9" start_char="1630">
<ORIGINAL_TEXT>They’ve been preparing the way for several weeks already with state media reports of coronavirus found on imported food / packaging.</ORIGINAL_TEXT>
<TOKEN end_char="1636" id="token-9-0" morph="none" pos="word" start_char="1630">They’ve</TOKEN>
<TOKEN end_char="1641" id="token-9-1" morph="none" pos="word" start_char="1638">been</TOKEN>
<TOKEN end_char="1651" id="token-9-2" morph="none" pos="word" start_char="1643">preparing</TOKEN>
<TOKEN end_char="1655" id="token-9-3" morph="none" pos="word" start_char="1653">the</TOKEN>
<TOKEN end_char="1659" id="token-9-4" morph="none" pos="word" start_char="1657">way</TOKEN>
<TOKEN end_char="1663" id="token-9-5" morph="none" pos="word" start_char="1661">for</TOKEN>
<TOKEN end_char="1671" id="token-9-6" morph="none" pos="word" start_char="1665">several</TOKEN>
<TOKEN end_char="1677" id="token-9-7" morph="none" pos="word" start_char="1673">weeks</TOKEN>
<TOKEN end_char="1685" id="token-9-8" morph="none" pos="word" start_char="1679">already</TOKEN>
<TOKEN end_char="1690" id="token-9-9" morph="none" pos="word" start_char="1687">with</TOKEN>
<TOKEN end_char="1696" id="token-9-10" morph="none" pos="word" start_char="1692">state</TOKEN>
<TOKEN end_char="1702" id="token-9-11" morph="none" pos="word" start_char="1698">media</TOKEN>
<TOKEN end_char="1710" id="token-9-12" morph="none" pos="word" start_char="1704">reports</TOKEN>
<TOKEN end_char="1713" id="token-9-13" morph="none" pos="word" start_char="1712">of</TOKEN>
<TOKEN end_char="1725" id="token-9-14" morph="none" pos="word" start_char="1715">coronavirus</TOKEN>
<TOKEN end_char="1731" id="token-9-15" morph="none" pos="word" start_char="1727">found</TOKEN>
<TOKEN end_char="1734" id="token-9-16" morph="none" pos="word" start_char="1733">on</TOKEN>
<TOKEN end_char="1743" id="token-9-17" morph="none" pos="word" start_char="1736">imported</TOKEN>
<TOKEN end_char="1748" id="token-9-18" morph="none" pos="word" start_char="1745">food</TOKEN>
<TOKEN end_char="1750" id="token-9-19" morph="none" pos="punct" start_char="1750">/</TOKEN>
<TOKEN end_char="1760" id="token-9-20" morph="none" pos="word" start_char="1752">packaging</TOKEN>
<TOKEN end_char="1761" id="token-9-21" morph="none" pos="punct" start_char="1761">.</TOKEN>
</SEG>
<SEG end_char="1833" id="segment-10" start_char="1763">
<ORIGINAL_TEXT>https://t.co/3Splcix1Lf — Jeremy Goldkorn (@goldkorn) November 25, 2020</ORIGINAL_TEXT>
<TOKEN end_char="1785" id="token-10-0" morph="none" pos="url" start_char="1763">https://t.co/3Splcix1Lf</TOKEN>
<TOKEN end_char="1787" id="token-10-1" morph="none" pos="punct" start_char="1787">—</TOKEN>
<TOKEN end_char="1794" id="token-10-2" morph="none" pos="word" start_char="1789">Jeremy</TOKEN>
<TOKEN end_char="1803" id="token-10-3" morph="none" pos="word" start_char="1796">Goldkorn</TOKEN>
<TOKEN end_char="1806" id="token-10-4" morph="none" pos="punct" start_char="1805">(@</TOKEN>
<TOKEN end_char="1814" id="token-10-5" morph="none" pos="word" start_char="1807">goldkorn</TOKEN>
<TOKEN end_char="1815" id="token-10-6" morph="none" pos="punct" start_char="1815">)</TOKEN>
<TOKEN end_char="1824" id="token-10-7" morph="none" pos="word" start_char="1817">November</TOKEN>
<TOKEN end_char="1827" id="token-10-8" morph="none" pos="word" start_char="1826">25</TOKEN>
<TOKEN end_char="1828" id="token-10-9" morph="none" pos="punct" start_char="1828">,</TOKEN>
<TOKEN end_char="1833" id="token-10-10" morph="none" pos="word" start_char="1830">2020</TOKEN>
<TRANSLATED_TEXT>https: / / t.co / 3Splcix1Lf - Jeremy Goldkorn (@ goldkorn) November 25, 2020</TRANSLATED_TEXT><DETECTED_LANGUAGE>da</DETECTED_LANGUAGE></SEG>
<SEG end_char="1961" id="segment-11" start_char="1838">
<ORIGINAL_TEXT>State media has yet to explain how, if Covid started in another place, the first exponential-growth outbreak began in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="1842" id="token-11-0" morph="none" pos="word" start_char="1838">State</TOKEN>
<TOKEN end_char="1848" id="token-11-1" morph="none" pos="word" start_char="1844">media</TOKEN>
<TOKEN end_char="1852" id="token-11-2" morph="none" pos="word" start_char="1850">has</TOKEN>
<TOKEN end_char="1856" id="token-11-3" morph="none" pos="word" start_char="1854">yet</TOKEN>
<TOKEN end_char="1859" id="token-11-4" morph="none" pos="word" start_char="1858">to</TOKEN>
<TOKEN end_char="1867" id="token-11-5" morph="none" pos="word" start_char="1861">explain</TOKEN>
<TOKEN end_char="1871" id="token-11-6" morph="none" pos="word" start_char="1869">how</TOKEN>
<TOKEN end_char="1872" id="token-11-7" morph="none" pos="punct" start_char="1872">,</TOKEN>
<TOKEN end_char="1875" id="token-11-8" morph="none" pos="word" start_char="1874">if</TOKEN>
<TOKEN end_char="1881" id="token-11-9" morph="none" pos="word" start_char="1877">Covid</TOKEN>
<TOKEN end_char="1889" id="token-11-10" morph="none" pos="word" start_char="1883">started</TOKEN>
<TOKEN end_char="1892" id="token-11-11" morph="none" pos="word" start_char="1891">in</TOKEN>
<TOKEN end_char="1900" id="token-11-12" morph="none" pos="word" start_char="1894">another</TOKEN>
<TOKEN end_char="1906" id="token-11-13" morph="none" pos="word" start_char="1902">place</TOKEN>
<TOKEN end_char="1907" id="token-11-14" morph="none" pos="punct" start_char="1907">,</TOKEN>
<TOKEN end_char="1911" id="token-11-15" morph="none" pos="word" start_char="1909">the</TOKEN>
<TOKEN end_char="1917" id="token-11-16" morph="none" pos="word" start_char="1913">first</TOKEN>
<TOKEN end_char="1936" id="token-11-17" morph="none" pos="unknown" start_char="1919">exponential-growth</TOKEN>
<TOKEN end_char="1945" id="token-11-18" morph="none" pos="word" start_char="1938">outbreak</TOKEN>
<TOKEN end_char="1951" id="token-11-19" morph="none" pos="word" start_char="1947">began</TOKEN>
<TOKEN end_char="1954" id="token-11-20" morph="none" pos="word" start_char="1953">in</TOKEN>
<TOKEN end_char="1960" id="token-11-21" morph="none" pos="word" start_char="1956">Wuhan</TOKEN>
<TOKEN end_char="1961" id="token-11-22" morph="none" pos="punct" start_char="1961">.</TOKEN>
</SEG>
<SEG end_char="2026" id="segment-12" start_char="1963">
<ORIGINAL_TEXT>Why weren’t there big outbreaks in other countries before Wuhan?</ORIGINAL_TEXT>
<TOKEN end_char="1965" id="token-12-0" morph="none" pos="word" start_char="1963">Why</TOKEN>
<TOKEN end_char="1973" id="token-12-1" morph="none" pos="word" start_char="1967">weren’t</TOKEN>
<TOKEN end_char="1979" id="token-12-2" morph="none" pos="word" start_char="1975">there</TOKEN>
<TOKEN end_char="1983" id="token-12-3" morph="none" pos="word" start_char="1981">big</TOKEN>
<TOKEN end_char="1993" id="token-12-4" morph="none" pos="word" start_char="1985">outbreaks</TOKEN>
<TOKEN end_char="1996" id="token-12-5" morph="none" pos="word" start_char="1995">in</TOKEN>
<TOKEN end_char="2002" id="token-12-6" morph="none" pos="word" start_char="1998">other</TOKEN>
<TOKEN end_char="2012" id="token-12-7" morph="none" pos="word" start_char="2004">countries</TOKEN>
<TOKEN end_char="2019" id="token-12-8" morph="none" pos="word" start_char="2014">before</TOKEN>
<TOKEN end_char="2025" id="token-12-9" morph="none" pos="word" start_char="2021">Wuhan</TOKEN>
<TOKEN end_char="2026" id="token-12-10" morph="none" pos="punct" start_char="2026">?</TOKEN>
</SEG>
<SEG end_char="2190" id="segment-13" start_char="2028">
<ORIGINAL_TEXT>Depressingly, this cold-chain theory is widely believed here in China, which is the point https://t.co/WKT3B1FnuP — David Rennie 任大伟 (@DSORennie) November 25, 2020</ORIGINAL_TEXT>
<TOKEN end_char="2039" id="token-13-0" morph="none" pos="word" start_char="2028">Depressingly</TOKEN>
<TOKEN end_char="2040" id="token-13-1" morph="none" pos="punct" start_char="2040">,</TOKEN>
<TOKEN end_char="2045" id="token-13-2" morph="none" pos="word" start_char="2042">this</TOKEN>
<TOKEN end_char="2056" id="token-13-3" morph="none" pos="unknown" start_char="2047">cold-chain</TOKEN>
<TOKEN end_char="2063" id="token-13-4" morph="none" pos="word" start_char="2058">theory</TOKEN>
<TOKEN end_char="2066" id="token-13-5" morph="none" pos="word" start_char="2065">is</TOKEN>
<TOKEN end_char="2073" id="token-13-6" morph="none" pos="word" start_char="2068">widely</TOKEN>
<TOKEN end_char="2082" id="token-13-7" morph="none" pos="word" start_char="2075">believed</TOKEN>
<TOKEN end_char="2087" id="token-13-8" morph="none" pos="word" start_char="2084">here</TOKEN>
<TOKEN end_char="2090" id="token-13-9" morph="none" pos="word" start_char="2089">in</TOKEN>
<TOKEN end_char="2096" id="token-13-10" morph="none" pos="word" start_char="2092">China</TOKEN>
<TOKEN end_char="2097" id="token-13-11" morph="none" pos="punct" start_char="2097">,</TOKEN>
<TOKEN end_char="2103" id="token-13-12" morph="none" pos="word" start_char="2099">which</TOKEN>
<TOKEN end_char="2106" id="token-13-13" morph="none" pos="word" start_char="2105">is</TOKEN>
<TOKEN end_char="2110" id="token-13-14" morph="none" pos="word" start_char="2108">the</TOKEN>
<TOKEN end_char="2116" id="token-13-15" morph="none" pos="word" start_char="2112">point</TOKEN>
<TOKEN end_char="2140" id="token-13-16" morph="none" pos="url" start_char="2118">https://t.co/WKT3B1FnuP</TOKEN>
<TOKEN end_char="2142" id="token-13-17" morph="none" pos="punct" start_char="2142">—</TOKEN>
<TOKEN end_char="2148" id="token-13-18" morph="none" pos="word" start_char="2144">David</TOKEN>
<TOKEN end_char="2155" id="token-13-19" morph="none" pos="word" start_char="2150">Rennie</TOKEN>
<TOKEN end_char="2159" id="token-13-20" morph="none" pos="word" start_char="2157">任大伟</TOKEN>
<TOKEN end_char="2162" id="token-13-21" morph="none" pos="punct" start_char="2161">(@</TOKEN>
<TOKEN end_char="2171" id="token-13-22" morph="none" pos="word" start_char="2163">DSORennie</TOKEN>
<TOKEN end_char="2172" id="token-13-23" morph="none" pos="punct" start_char="2172">)</TOKEN>
<TOKEN end_char="2181" id="token-13-24" morph="none" pos="word" start_char="2174">November</TOKEN>
<TOKEN end_char="2184" id="token-13-25" morph="none" pos="word" start_char="2183">25</TOKEN>
<TOKEN end_char="2185" id="token-13-26" morph="none" pos="punct" start_char="2185">,</TOKEN>
<TOKEN end_char="2190" id="token-13-27" morph="none" pos="word" start_char="2187">2020</TOKEN>
</SEG>
<SEG end_char="2421" id="segment-14" start_char="2194">
<ORIGINAL_TEXT>While making the claim that would be echoed by state media, Beijing’s former top epidemiologist Zeng Guang cited a recent Italian study that claimed coronavirus was spreading asymptomatically in Italy as early as September 2019.</ORIGINAL_TEXT>
<TOKEN end_char="2198" id="token-14-0" morph="none" pos="word" start_char="2194">While</TOKEN>
<TOKEN end_char="2205" id="token-14-1" morph="none" pos="word" start_char="2200">making</TOKEN>
<TOKEN end_char="2209" id="token-14-2" morph="none" pos="word" start_char="2207">the</TOKEN>
<TOKEN end_char="2215" id="token-14-3" morph="none" pos="word" start_char="2211">claim</TOKEN>
<TOKEN end_char="2220" id="token-14-4" morph="none" pos="word" start_char="2217">that</TOKEN>
<TOKEN end_char="2226" id="token-14-5" morph="none" pos="word" start_char="2222">would</TOKEN>
<TOKEN end_char="2229" id="token-14-6" morph="none" pos="word" start_char="2228">be</TOKEN>
<TOKEN end_char="2236" id="token-14-7" morph="none" pos="word" start_char="2231">echoed</TOKEN>
<TOKEN end_char="2239" id="token-14-8" morph="none" pos="word" start_char="2238">by</TOKEN>
<TOKEN end_char="2245" id="token-14-9" morph="none" pos="word" start_char="2241">state</TOKEN>
<TOKEN end_char="2251" id="token-14-10" morph="none" pos="word" start_char="2247">media</TOKEN>
<TOKEN end_char="2252" id="token-14-11" morph="none" pos="punct" start_char="2252">,</TOKEN>
<TOKEN end_char="2262" id="token-14-12" morph="none" pos="word" start_char="2254">Beijing’s</TOKEN>
<TOKEN end_char="2269" id="token-14-13" morph="none" pos="word" start_char="2264">former</TOKEN>
<TOKEN end_char="2273" id="token-14-14" morph="none" pos="word" start_char="2271">top</TOKEN>
<TOKEN end_char="2288" id="token-14-15" morph="none" pos="word" start_char="2275">epidemiologist</TOKEN>
<TOKEN end_char="2293" id="token-14-16" morph="none" pos="word" start_char="2290">Zeng</TOKEN>
<TOKEN end_char="2299" id="token-14-17" morph="none" pos="word" start_char="2295">Guang</TOKEN>
<TOKEN end_char="2305" id="token-14-18" morph="none" pos="word" start_char="2301">cited</TOKEN>
<TOKEN end_char="2307" id="token-14-19" morph="none" pos="word" start_char="2307">a</TOKEN>
<TOKEN end_char="2314" id="token-14-20" morph="none" pos="word" start_char="2309">recent</TOKEN>
<TOKEN end_char="2322" id="token-14-21" morph="none" pos="word" start_char="2316">Italian</TOKEN>
<TOKEN end_char="2328" id="token-14-22" morph="none" pos="word" start_char="2324">study</TOKEN>
<TOKEN end_char="2333" id="token-14-23" morph="none" pos="word" start_char="2330">that</TOKEN>
<TOKEN end_char="2341" id="token-14-24" morph="none" pos="word" start_char="2335">claimed</TOKEN>
<TOKEN end_char="2353" id="token-14-25" morph="none" pos="word" start_char="2343">coronavirus</TOKEN>
<TOKEN end_char="2357" id="token-14-26" morph="none" pos="word" start_char="2355">was</TOKEN>
<TOKEN end_char="2367" id="token-14-27" morph="none" pos="word" start_char="2359">spreading</TOKEN>
<TOKEN end_char="2384" id="token-14-28" morph="none" pos="word" start_char="2369">asymptomatically</TOKEN>
<TOKEN end_char="2387" id="token-14-29" morph="none" pos="word" start_char="2386">in</TOKEN>
<TOKEN end_char="2393" id="token-14-30" morph="none" pos="word" start_char="2389">Italy</TOKEN>
<TOKEN end_char="2396" id="token-14-31" morph="none" pos="word" start_char="2395">as</TOKEN>
<TOKEN end_char="2402" id="token-14-32" morph="none" pos="word" start_char="2398">early</TOKEN>
<TOKEN end_char="2405" id="token-14-33" morph="none" pos="word" start_char="2404">as</TOKEN>
<TOKEN end_char="2415" id="token-14-34" morph="none" pos="word" start_char="2407">September</TOKEN>
<TOKEN end_char="2420" id="token-14-35" morph="none" pos="word" start_char="2417">2019</TOKEN>
<TOKEN end_char="2421" id="token-14-36" morph="none" pos="punct" start_char="2421">.</TOKEN>
</SEG>
<SEG end_char="2593" id="segment-15" start_char="2423">
<ORIGINAL_TEXT>But the researchers behind the study contend that it "simply [documented] that the epidemic in China was not detected in time," not that Italy was the origin of the virus.</ORIGINAL_TEXT>
<TOKEN end_char="2425" id="token-15-0" morph="none" pos="word" start_char="2423">But</TOKEN>
<TOKEN end_char="2429" id="token-15-1" morph="none" pos="word" start_char="2427">the</TOKEN>
<TOKEN end_char="2441" id="token-15-2" morph="none" pos="word" start_char="2431">researchers</TOKEN>
<TOKEN end_char="2448" id="token-15-3" morph="none" pos="word" start_char="2443">behind</TOKEN>
<TOKEN end_char="2452" id="token-15-4" morph="none" pos="word" start_char="2450">the</TOKEN>
<TOKEN end_char="2458" id="token-15-5" morph="none" pos="word" start_char="2454">study</TOKEN>
<TOKEN end_char="2466" id="token-15-6" morph="none" pos="word" start_char="2460">contend</TOKEN>
<TOKEN end_char="2471" id="token-15-7" morph="none" pos="word" start_char="2468">that</TOKEN>
<TOKEN end_char="2474" id="token-15-8" morph="none" pos="word" start_char="2473">it</TOKEN>
<TOKEN end_char="2476" id="token-15-9" morph="none" pos="punct" start_char="2476">"</TOKEN>
<TOKEN end_char="2482" id="token-15-10" morph="none" pos="word" start_char="2477">simply</TOKEN>
<TOKEN end_char="2484" id="token-15-11" morph="none" pos="punct" start_char="2484">[</TOKEN>
<TOKEN end_char="2494" id="token-15-12" morph="none" pos="word" start_char="2485">documented</TOKEN>
<TOKEN end_char="2495" id="token-15-13" morph="none" pos="punct" start_char="2495">]</TOKEN>
<TOKEN end_char="2500" id="token-15-14" morph="none" pos="word" start_char="2497">that</TOKEN>
<TOKEN end_char="2504" id="token-15-15" morph="none" pos="word" start_char="2502">the</TOKEN>
<TOKEN end_char="2513" id="token-15-16" morph="none" pos="word" start_char="2506">epidemic</TOKEN>
<TOKEN end_char="2516" id="token-15-17" morph="none" pos="word" start_char="2515">in</TOKEN>
<TOKEN end_char="2522" id="token-15-18" morph="none" pos="word" start_char="2518">China</TOKEN>
<TOKEN end_char="2526" id="token-15-19" morph="none" pos="word" start_char="2524">was</TOKEN>
<TOKEN end_char="2530" id="token-15-20" morph="none" pos="word" start_char="2528">not</TOKEN>
<TOKEN end_char="2539" id="token-15-21" morph="none" pos="word" start_char="2532">detected</TOKEN>
<TOKEN end_char="2542" id="token-15-22" morph="none" pos="word" start_char="2541">in</TOKEN>
<TOKEN end_char="2547" id="token-15-23" morph="none" pos="word" start_char="2544">time</TOKEN>
<TOKEN end_char="2549" id="token-15-24" morph="none" pos="punct" start_char="2548">,"</TOKEN>
<TOKEN end_char="2553" id="token-15-25" morph="none" pos="word" start_char="2551">not</TOKEN>
<TOKEN end_char="2558" id="token-15-26" morph="none" pos="word" start_char="2555">that</TOKEN>
<TOKEN end_char="2564" id="token-15-27" morph="none" pos="word" start_char="2560">Italy</TOKEN>
<TOKEN end_char="2568" id="token-15-28" morph="none" pos="word" start_char="2566">was</TOKEN>
<TOKEN end_char="2572" id="token-15-29" morph="none" pos="word" start_char="2570">the</TOKEN>
<TOKEN end_char="2579" id="token-15-30" morph="none" pos="word" start_char="2574">origin</TOKEN>
<TOKEN end_char="2582" id="token-15-31" morph="none" pos="word" start_char="2581">of</TOKEN>
<TOKEN end_char="2586" id="token-15-32" morph="none" pos="word" start_char="2584">the</TOKEN>
<TOKEN end_char="2592" id="token-15-33" morph="none" pos="word" start_char="2588">virus</TOKEN>
<TOKEN end_char="2593" id="token-15-34" morph="none" pos="punct" start_char="2593">.</TOKEN>
</SEG>
<SEG end_char="2794" id="segment-16" start_char="2595">
<ORIGINAL_TEXT>Current top epidemiologist Wu Zunyou claimed earlier in the month that "[g]rowing evidence [shows]frozen seafood or meat may have introduced the virus from the epidemic-affected countries into China."</ORIGINAL_TEXT>
<TOKEN end_char="2601" id="token-16-0" morph="none" pos="word" start_char="2595">Current</TOKEN>
<TOKEN end_char="2605" id="token-16-1" morph="none" pos="word" start_char="2603">top</TOKEN>
<TOKEN end_char="2620" id="token-16-2" morph="none" pos="word" start_char="2607">epidemiologist</TOKEN>
<TOKEN end_char="2623" id="token-16-3" morph="none" pos="word" start_char="2622">Wu</TOKEN>
<TOKEN end_char="2630" id="token-16-4" morph="none" pos="word" start_char="2625">Zunyou</TOKEN>
<TOKEN end_char="2638" id="token-16-5" morph="none" pos="word" start_char="2632">claimed</TOKEN>
<TOKEN end_char="2646" id="token-16-6" morph="none" pos="word" start_char="2640">earlier</TOKEN>
<TOKEN end_char="2649" id="token-16-7" morph="none" pos="word" start_char="2648">in</TOKEN>
<TOKEN end_char="2653" id="token-16-8" morph="none" pos="word" start_char="2651">the</TOKEN>
<TOKEN end_char="2659" id="token-16-9" morph="none" pos="word" start_char="2655">month</TOKEN>
<TOKEN end_char="2664" id="token-16-10" morph="none" pos="word" start_char="2661">that</TOKEN>
<TOKEN end_char="2667" id="token-16-11" morph="none" pos="punct" start_char="2666">"[</TOKEN>
<TOKEN end_char="2675" id="token-16-12" morph="none" pos="unknown" start_char="2668">g]rowing</TOKEN>
<TOKEN end_char="2684" id="token-16-13" morph="none" pos="word" start_char="2677">evidence</TOKEN>
<TOKEN end_char="2686" id="token-16-14" morph="none" pos="punct" start_char="2686">[</TOKEN>
<TOKEN end_char="2698" id="token-16-15" morph="none" pos="unknown" start_char="2687">shows]frozen</TOKEN>
<TOKEN end_char="2706" id="token-16-16" morph="none" pos="word" start_char="2700">seafood</TOKEN>
<TOKEN end_char="2709" id="token-16-17" morph="none" pos="word" start_char="2708">or</TOKEN>
<TOKEN end_char="2714" id="token-16-18" morph="none" pos="word" start_char="2711">meat</TOKEN>
<TOKEN end_char="2718" id="token-16-19" morph="none" pos="word" start_char="2716">may</TOKEN>
<TOKEN end_char="2723" id="token-16-20" morph="none" pos="word" start_char="2720">have</TOKEN>
<TOKEN end_char="2734" id="token-16-21" morph="none" pos="word" start_char="2725">introduced</TOKEN>
<TOKEN end_char="2738" id="token-16-22" morph="none" pos="word" start_char="2736">the</TOKEN>
<TOKEN end_char="2744" id="token-16-23" morph="none" pos="word" start_char="2740">virus</TOKEN>
<TOKEN end_char="2749" id="token-16-24" morph="none" pos="word" start_char="2746">from</TOKEN>
<TOKEN end_char="2753" id="token-16-25" morph="none" pos="word" start_char="2751">the</TOKEN>
<TOKEN end_char="2771" id="token-16-26" morph="none" pos="unknown" start_char="2755">epidemic-affected</TOKEN>
<TOKEN end_char="2781" id="token-16-27" morph="none" pos="word" start_char="2773">countries</TOKEN>
<TOKEN end_char="2786" id="token-16-28" morph="none" pos="word" start_char="2783">into</TOKEN>
<TOKEN end_char="2792" id="token-16-29" morph="none" pos="word" start_char="2788">China</TOKEN>
<TOKEN end_char="2794" id="token-16-30" morph="none" pos="punct" start_char="2793">."</TOKEN>
</SEG>
<SEG end_char="2877" id="segment-17" start_char="2797">
<ORIGINAL_TEXT>Authorities have tied recent outbreaks in Tianjin and Shanghai to imported goods.</ORIGINAL_TEXT>
<TOKEN end_char="2807" id="token-17-0" morph="none" pos="word" start_char="2797">Authorities</TOKEN>
<TOKEN end_char="2812" id="token-17-1" morph="none" pos="word" start_char="2809">have</TOKEN>
<TOKEN end_char="2817" id="token-17-2" morph="none" pos="word" start_char="2814">tied</TOKEN>
<TOKEN end_char="2824" id="token-17-3" morph="none" pos="word" start_char="2819">recent</TOKEN>
<TOKEN end_char="2834" id="token-17-4" morph="none" pos="word" start_char="2826">outbreaks</TOKEN>
<TOKEN end_char="2837" id="token-17-5" morph="none" pos="word" start_char="2836">in</TOKEN>
<TOKEN end_char="2845" id="token-17-6" morph="none" pos="word" start_char="2839">Tianjin</TOKEN>
<TOKEN end_char="2849" id="token-17-7" morph="none" pos="word" start_char="2847">and</TOKEN>
<TOKEN end_char="2858" id="token-17-8" morph="none" pos="word" start_char="2851">Shanghai</TOKEN>
<TOKEN end_char="2861" id="token-17-9" morph="none" pos="word" start_char="2860">to</TOKEN>
<TOKEN end_char="2870" id="token-17-10" morph="none" pos="word" start_char="2863">imported</TOKEN>
<TOKEN end_char="2876" id="token-17-11" morph="none" pos="word" start_char="2872">goods</TOKEN>
<TOKEN end_char="2877" id="token-17-12" morph="none" pos="punct" start_char="2877">.</TOKEN>
</SEG>
<SEG end_char="3005" id="segment-18" start_char="2879">
<ORIGINAL_TEXT>Videos of panicked workers fleeing the Shanghai airport after a snap decision to rapid-test 17,000 workers went viral recently.</ORIGINAL_TEXT>
<TOKEN end_char="2884" id="token-18-0" morph="none" pos="word" start_char="2879">Videos</TOKEN>
<TOKEN end_char="2887" id="token-18-1" morph="none" pos="word" start_char="2886">of</TOKEN>
<TOKEN end_char="2896" id="token-18-2" morph="none" pos="word" start_char="2889">panicked</TOKEN>
<TOKEN end_char="2904" id="token-18-3" morph="none" pos="word" start_char="2898">workers</TOKEN>
<TOKEN end_char="2912" id="token-18-4" morph="none" pos="word" start_char="2906">fleeing</TOKEN>
<TOKEN end_char="2916" id="token-18-5" morph="none" pos="word" start_char="2914">the</TOKEN>
<TOKEN end_char="2925" id="token-18-6" morph="none" pos="word" start_char="2918">Shanghai</TOKEN>
<TOKEN end_char="2933" id="token-18-7" morph="none" pos="word" start_char="2927">airport</TOKEN>
<TOKEN end_char="2939" id="token-18-8" morph="none" pos="word" start_char="2935">after</TOKEN>
<TOKEN end_char="2941" id="token-18-9" morph="none" pos="word" start_char="2941">a</TOKEN>
<TOKEN end_char="2946" id="token-18-10" morph="none" pos="word" start_char="2943">snap</TOKEN>
<TOKEN end_char="2955" id="token-18-11" morph="none" pos="word" start_char="2948">decision</TOKEN>
<TOKEN end_char="2958" id="token-18-12" morph="none" pos="word" start_char="2957">to</TOKEN>
<TOKEN end_char="2969" id="token-18-13" morph="none" pos="unknown" start_char="2960">rapid-test</TOKEN>
<TOKEN end_char="2976" id="token-18-14" morph="none" pos="unknown" start_char="2971">17,000</TOKEN>
<TOKEN end_char="2984" id="token-18-15" morph="none" pos="word" start_char="2978">workers</TOKEN>
<TOKEN end_char="2989" id="token-18-16" morph="none" pos="word" start_char="2986">went</TOKEN>
<TOKEN end_char="2995" id="token-18-17" morph="none" pos="word" start_char="2991">viral</TOKEN>
<TOKEN end_char="3004" id="token-18-18" morph="none" pos="word" start_char="2997">recently</TOKEN>
<TOKEN end_char="3005" id="token-18-19" morph="none" pos="punct" start_char="3005">.</TOKEN>
</SEG>
<SEG end_char="3251" id="segment-19" start_char="3007">
<ORIGINAL_TEXT>While the scenes in Shanghai and Tianjin have been used to bolster claims of a foreign origin for the virus, the South China Morning Post’s Linda Lew and Nadia Lam detailed the global scientific community’s skepticism about Zeng and Wu’s claims:</ORIGINAL_TEXT>
<TOKEN end_char="3011" id="token-19-0" morph="none" pos="word" start_char="3007">While</TOKEN>
<TOKEN end_char="3015" id="token-19-1" morph="none" pos="word" start_char="3013">the</TOKEN>
<TOKEN end_char="3022" id="token-19-2" morph="none" pos="word" start_char="3017">scenes</TOKEN>
<TOKEN end_char="3025" id="token-19-3" morph="none" pos="word" start_char="3024">in</TOKEN>
<TOKEN end_char="3034" id="token-19-4" morph="none" pos="word" start_char="3027">Shanghai</TOKEN>
<TOKEN end_char="3038" id="token-19-5" morph="none" pos="word" start_char="3036">and</TOKEN>
<TOKEN end_char="3046" id="token-19-6" morph="none" pos="word" start_char="3040">Tianjin</TOKEN>
<TOKEN end_char="3051" id="token-19-7" morph="none" pos="word" start_char="3048">have</TOKEN>
<TOKEN end_char="3056" id="token-19-8" morph="none" pos="word" start_char="3053">been</TOKEN>
<TOKEN end_char="3061" id="token-19-9" morph="none" pos="word" start_char="3058">used</TOKEN>
<TOKEN end_char="3064" id="token-19-10" morph="none" pos="word" start_char="3063">to</TOKEN>
<TOKEN end_char="3072" id="token-19-11" morph="none" pos="word" start_char="3066">bolster</TOKEN>
<TOKEN end_char="3079" id="token-19-12" morph="none" pos="word" start_char="3074">claims</TOKEN>
<TOKEN end_char="3082" id="token-19-13" morph="none" pos="word" start_char="3081">of</TOKEN>
<TOKEN end_char="3084" id="token-19-14" morph="none" pos="word" start_char="3084">a</TOKEN>
<TOKEN end_char="3092" id="token-19-15" morph="none" pos="word" start_char="3086">foreign</TOKEN>
<TOKEN end_char="3099" id="token-19-16" morph="none" pos="word" start_char="3094">origin</TOKEN>
<TOKEN end_char="3103" id="token-19-17" morph="none" pos="word" start_char="3101">for</TOKEN>
<TOKEN end_char="3107" id="token-19-18" morph="none" pos="word" start_char="3105">the</TOKEN>
<TOKEN end_char="3113" id="token-19-19" morph="none" pos="word" start_char="3109">virus</TOKEN>
<TOKEN end_char="3114" id="token-19-20" morph="none" pos="punct" start_char="3114">,</TOKEN>
<TOKEN end_char="3118" id="token-19-21" morph="none" pos="word" start_char="3116">the</TOKEN>
<TOKEN end_char="3124" id="token-19-22" morph="none" pos="word" start_char="3120">South</TOKEN>
<TOKEN end_char="3130" id="token-19-23" morph="none" pos="word" start_char="3126">China</TOKEN>
<TOKEN end_char="3138" id="token-19-24" morph="none" pos="word" start_char="3132">Morning</TOKEN>
<TOKEN end_char="3145" id="token-19-25" morph="none" pos="word" start_char="3140">Post’s</TOKEN>
<TOKEN end_char="3151" id="token-19-26" morph="none" pos="word" start_char="3147">Linda</TOKEN>
<TOKEN end_char="3155" id="token-19-27" morph="none" pos="word" start_char="3153">Lew</TOKEN>
<TOKEN end_char="3159" id="token-19-28" morph="none" pos="word" start_char="3157">and</TOKEN>
<TOKEN end_char="3165" id="token-19-29" morph="none" pos="word" start_char="3161">Nadia</TOKEN>
<TOKEN end_char="3169" id="token-19-30" morph="none" pos="word" start_char="3167">Lam</TOKEN>
<TOKEN end_char="3178" id="token-19-31" morph="none" pos="word" start_char="3171">detailed</TOKEN>
<TOKEN end_char="3182" id="token-19-32" morph="none" pos="word" start_char="3180">the</TOKEN>
<TOKEN end_char="3189" id="token-19-33" morph="none" pos="word" start_char="3184">global</TOKEN>
<TOKEN end_char="3200" id="token-19-34" morph="none" pos="word" start_char="3191">scientific</TOKEN>
<TOKEN end_char="3212" id="token-19-35" morph="none" pos="word" start_char="3202">community’s</TOKEN>
<TOKEN end_char="3223" id="token-19-36" morph="none" pos="word" start_char="3214">skepticism</TOKEN>
<TOKEN end_char="3229" id="token-19-37" morph="none" pos="word" start_char="3225">about</TOKEN>
<TOKEN end_char="3234" id="token-19-38" morph="none" pos="word" start_char="3231">Zeng</TOKEN>
<TOKEN end_char="3238" id="token-19-39" morph="none" pos="word" start_char="3236">and</TOKEN>
<TOKEN end_char="3243" id="token-19-40" morph="none" pos="word" start_char="3240">Wu’s</TOKEN>
<TOKEN end_char="3250" id="token-19-41" morph="none" pos="word" start_char="3245">claims</TOKEN>
<TOKEN end_char="3251" id="token-19-42" morph="none" pos="punct" start_char="3251">:</TOKEN>
</SEG>
<SEG end_char="3478" id="segment-20" start_char="3254">
<ORIGINAL_TEXT>Wuhan University virology professor Yang Zhanqiu said suggestions the virus entered the country on imported frozen food were just guesses "that do not have supporting evidence ", according to nationalist tabloid Global Times.</ORIGINAL_TEXT>
<TOKEN end_char="3258" id="token-20-0" morph="none" pos="word" start_char="3254">Wuhan</TOKEN>
<TOKEN end_char="3269" id="token-20-1" morph="none" pos="word" start_char="3260">University</TOKEN>
<TOKEN end_char="3278" id="token-20-2" morph="none" pos="word" start_char="3271">virology</TOKEN>
<TOKEN end_char="3288" id="token-20-3" morph="none" pos="word" start_char="3280">professor</TOKEN>
<TOKEN end_char="3293" id="token-20-4" morph="none" pos="word" start_char="3290">Yang</TOKEN>
<TOKEN end_char="3301" id="token-20-5" morph="none" pos="word" start_char="3295">Zhanqiu</TOKEN>
<TOKEN end_char="3306" id="token-20-6" morph="none" pos="word" start_char="3303">said</TOKEN>
<TOKEN end_char="3318" id="token-20-7" morph="none" pos="word" start_char="3308">suggestions</TOKEN>
<TOKEN end_char="3322" id="token-20-8" morph="none" pos="word" start_char="3320">the</TOKEN>
<TOKEN end_char="3328" id="token-20-9" morph="none" pos="word" start_char="3324">virus</TOKEN>
<TOKEN end_char="3336" id="token-20-10" morph="none" pos="word" start_char="3330">entered</TOKEN>
<TOKEN end_char="3340" id="token-20-11" morph="none" pos="word" start_char="3338">the</TOKEN>
<TOKEN end_char="3348" id="token-20-12" morph="none" pos="word" start_char="3342">country</TOKEN>
<TOKEN end_char="3351" id="token-20-13" morph="none" pos="word" start_char="3350">on</TOKEN>
<TOKEN end_char="3360" id="token-20-14" morph="none" pos="word" start_char="3353">imported</TOKEN>
<TOKEN end_char="3367" id="token-20-15" morph="none" pos="word" start_char="3362">frozen</TOKEN>
<TOKEN end_char="3372" id="token-20-16" morph="none" pos="word" start_char="3369">food</TOKEN>
<TOKEN end_char="3377" id="token-20-17" morph="none" pos="word" start_char="3374">were</TOKEN>
<TOKEN end_char="3382" id="token-20-18" morph="none" pos="word" start_char="3379">just</TOKEN>
<TOKEN end_char="3390" id="token-20-19" morph="none" pos="word" start_char="3384">guesses</TOKEN>
<TOKEN end_char="3392" id="token-20-20" morph="none" pos="punct" start_char="3392">"</TOKEN>
<TOKEN end_char="3396" id="token-20-21" morph="none" pos="word" start_char="3393">that</TOKEN>
<TOKEN end_char="3399" id="token-20-22" morph="none" pos="word" start_char="3398">do</TOKEN>
<TOKEN end_char="3403" id="token-20-23" morph="none" pos="word" start_char="3401">not</TOKEN>
<TOKEN end_char="3408" id="token-20-24" morph="none" pos="word" start_char="3405">have</TOKEN>
<TOKEN end_char="3419" id="token-20-25" morph="none" pos="word" start_char="3410">supporting</TOKEN>
<TOKEN end_char="3428" id="token-20-26" morph="none" pos="word" start_char="3421">evidence</TOKEN>
<TOKEN end_char="3431" id="token-20-27" morph="none" pos="punct" start_char="3430">",</TOKEN>
<TOKEN end_char="3441" id="token-20-28" morph="none" pos="word" start_char="3433">according</TOKEN>
<TOKEN end_char="3444" id="token-20-29" morph="none" pos="word" start_char="3443">to</TOKEN>
<TOKEN end_char="3456" id="token-20-30" morph="none" pos="word" start_char="3446">nationalist</TOKEN>
<TOKEN end_char="3464" id="token-20-31" morph="none" pos="word" start_char="3458">tabloid</TOKEN>
<TOKEN end_char="3471" id="token-20-32" morph="none" pos="word" start_char="3466">Global</TOKEN>
<TOKEN end_char="3477" id="token-20-33" morph="none" pos="word" start_char="3473">Times</TOKEN>
<TOKEN end_char="3478" id="token-20-34" morph="none" pos="punct" start_char="3478">.</TOKEN>
</SEG>
<SEG end_char="3695" id="segment-21" start_char="3480">
<ORIGINAL_TEXT>[…] Yuen Kwok-yung, chairman of infectious diseases at the University of Hong Kong’s department of microbiology, said there were questions about the Italian study and it could be a case of a "false positive" reading.</ORIGINAL_TEXT>
<TOKEN end_char="3482" id="token-21-0" morph="none" pos="punct" start_char="3480">[…]</TOKEN>
<TOKEN end_char="3487" id="token-21-1" morph="none" pos="word" start_char="3484">Yuen</TOKEN>
<TOKEN end_char="3497" id="token-21-2" morph="none" pos="unknown" start_char="3489">Kwok-yung</TOKEN>
<TOKEN end_char="3498" id="token-21-3" morph="none" pos="punct" start_char="3498">,</TOKEN>
<TOKEN end_char="3507" id="token-21-4" morph="none" pos="word" start_char="3500">chairman</TOKEN>
<TOKEN end_char="3510" id="token-21-5" morph="none" pos="word" start_char="3509">of</TOKEN>
<TOKEN end_char="3521" id="token-21-6" morph="none" pos="word" start_char="3512">infectious</TOKEN>
<TOKEN end_char="3530" id="token-21-7" morph="none" pos="word" start_char="3523">diseases</TOKEN>
<TOKEN end_char="3533" id="token-21-8" morph="none" pos="word" start_char="3532">at</TOKEN>
<TOKEN end_char="3537" id="token-21-9" morph="none" pos="word" start_char="3535">the</TOKEN>
<TOKEN end_char="3548" id="token-21-10" morph="none" pos="word" start_char="3539">University</TOKEN>
<TOKEN end_char="3551" id="token-21-11" morph="none" pos="word" start_char="3550">of</TOKEN>
<TOKEN end_char="3556" id="token-21-12" morph="none" pos="word" start_char="3553">Hong</TOKEN>
<TOKEN end_char="3563" id="token-21-13" morph="none" pos="word" start_char="3558">Kong’s</TOKEN>
<TOKEN end_char="3574" id="token-21-14" morph="none" pos="word" start_char="3565">department</TOKEN>
<TOKEN end_char="3577" id="token-21-15" morph="none" pos="word" start_char="3576">of</TOKEN>
<TOKEN end_char="3590" id="token-21-16" morph="none" pos="word" start_char="3579">microbiology</TOKEN>
<TOKEN end_char="3591" id="token-21-17" morph="none" pos="punct" start_char="3591">,</TOKEN>
<TOKEN end_char="3596" id="token-21-18" morph="none" pos="word" start_char="3593">said</TOKEN>
<TOKEN end_char="3602" id="token-21-19" morph="none" pos="word" start_char="3598">there</TOKEN>
<TOKEN end_char="3607" id="token-21-20" morph="none" pos="word" start_char="3604">were</TOKEN>
<TOKEN end_char="3617" id="token-21-21" morph="none" pos="word" start_char="3609">questions</TOKEN>
<TOKEN end_char="3623" id="token-21-22" morph="none" pos="word" start_char="3619">about</TOKEN>
<TOKEN end_char="3627" id="token-21-23" morph="none" pos="word" start_char="3625">the</TOKEN>
<TOKEN end_char="3635" id="token-21-24" morph="none" pos="word" start_char="3629">Italian</TOKEN>
<TOKEN end_char="3641" id="token-21-25" morph="none" pos="word" start_char="3637">study</TOKEN>
<TOKEN end_char="3645" id="token-21-26" morph="none" pos="word" start_char="3643">and</TOKEN>
<TOKEN end_char="3648" id="token-21-27" morph="none" pos="word" start_char="3647">it</TOKEN>
<TOKEN end_char="3654" id="token-21-28" morph="none" pos="word" start_char="3650">could</TOKEN>
<TOKEN end_char="3657" id="token-21-29" morph="none" pos="word" start_char="3656">be</TOKEN>
<TOKEN end_char="3659" id="token-21-30" morph="none" pos="word" start_char="3659">a</TOKEN>
<TOKEN end_char="3664" id="token-21-31" morph="none" pos="word" start_char="3661">case</TOKEN>
<TOKEN end_char="3667" id="token-21-32" morph="none" pos="word" start_char="3666">of</TOKEN>
<TOKEN end_char="3669" id="token-21-33" morph="none" pos="word" start_char="3669">a</TOKEN>
<TOKEN end_char="3671" id="token-21-34" morph="none" pos="punct" start_char="3671">"</TOKEN>
<TOKEN end_char="3676" id="token-21-35" morph="none" pos="word" start_char="3672">false</TOKEN>
<TOKEN end_char="3685" id="token-21-36" morph="none" pos="word" start_char="3678">positive</TOKEN>
<TOKEN end_char="3686" id="token-21-37" morph="none" pos="punct" start_char="3686">"</TOKEN>
<TOKEN end_char="3694" id="token-21-38" morph="none" pos="word" start_char="3688">reading</TOKEN>
<TOKEN end_char="3695" id="token-21-39" morph="none" pos="punct" start_char="3695">.</TOKEN>
</SEG>
<SEG end_char="3893" id="segment-22" start_char="3697">
<ORIGINAL_TEXT>The specific antibodies found in the Italian study were insufficient to prove that the patient had Covid-19, he said at a forum organised by Hong Kong media platform Master Insight Media on Friday.</ORIGINAL_TEXT>
<TOKEN end_char="3699" id="token-22-0" morph="none" pos="word" start_char="3697">The</TOKEN>
<TOKEN end_char="3708" id="token-22-1" morph="none" pos="word" start_char="3701">specific</TOKEN>
<TOKEN end_char="3719" id="token-22-2" morph="none" pos="word" start_char="3710">antibodies</TOKEN>
<TOKEN end_char="3725" id="token-22-3" morph="none" pos="word" start_char="3721">found</TOKEN>
<TOKEN end_char="3728" id="token-22-4" morph="none" pos="word" start_char="3727">in</TOKEN>
<TOKEN end_char="3732" id="token-22-5" morph="none" pos="word" start_char="3730">the</TOKEN>
<TOKEN end_char="3740" id="token-22-6" morph="none" pos="word" start_char="3734">Italian</TOKEN>
<TOKEN end_char="3746" id="token-22-7" morph="none" pos="word" start_char="3742">study</TOKEN>
<TOKEN end_char="3751" id="token-22-8" morph="none" pos="word" start_char="3748">were</TOKEN>
<TOKEN end_char="3764" id="token-22-9" morph="none" pos="word" start_char="3753">insufficient</TOKEN>
<TOKEN end_char="3767" id="token-22-10" morph="none" pos="word" start_char="3766">to</TOKEN>
<TOKEN end_char="3773" id="token-22-11" morph="none" pos="word" start_char="3769">prove</TOKEN>
<TOKEN end_char="3778" id="token-22-12" morph="none" pos="word" start_char="3775">that</TOKEN>
<TOKEN end_char="3782" id="token-22-13" morph="none" pos="word" start_char="3780">the</TOKEN>
<TOKEN end_char="3790" id="token-22-14" morph="none" pos="word" start_char="3784">patient</TOKEN>
<TOKEN end_char="3794" id="token-22-15" morph="none" pos="word" start_char="3792">had</TOKEN>
<TOKEN end_char="3803" id="token-22-16" morph="none" pos="unknown" start_char="3796">Covid-19</TOKEN>
<TOKEN end_char="3804" id="token-22-17" morph="none" pos="punct" start_char="3804">,</TOKEN>
<TOKEN end_char="3807" id="token-22-18" morph="none" pos="word" start_char="3806">he</TOKEN>
<TOKEN end_char="3812" id="token-22-19" morph="none" pos="word" start_char="3809">said</TOKEN>
<TOKEN end_char="3815" id="token-22-20" morph="none" pos="word" start_char="3814">at</TOKEN>
<TOKEN end_char="3817" id="token-22-21" morph="none" pos="word" start_char="3817">a</TOKEN>
<TOKEN end_char="3823" id="token-22-22" morph="none" pos="word" start_char="3819">forum</TOKEN>
<TOKEN end_char="3833" id="token-22-23" morph="none" pos="word" start_char="3825">organised</TOKEN>
<TOKEN end_char="3836" id="token-22-24" morph="none" pos="word" start_char="3835">by</TOKEN>
<TOKEN end_char="3841" id="token-22-25" morph="none" pos="word" start_char="3838">Hong</TOKEN>
<TOKEN end_char="3846" id="token-22-26" morph="none" pos="word" start_char="3843">Kong</TOKEN>
<TOKEN end_char="3852" id="token-22-27" morph="none" pos="word" start_char="3848">media</TOKEN>
<TOKEN end_char="3861" id="token-22-28" morph="none" pos="word" start_char="3854">platform</TOKEN>
<TOKEN end_char="3868" id="token-22-29" morph="none" pos="word" start_char="3863">Master</TOKEN>
<TOKEN end_char="3876" id="token-22-30" morph="none" pos="word" start_char="3870">Insight</TOKEN>
<TOKEN end_char="3882" id="token-22-31" morph="none" pos="word" start_char="3878">Media</TOKEN>
<TOKEN end_char="3885" id="token-22-32" morph="none" pos="word" start_char="3884">on</TOKEN>
<TOKEN end_char="3892" id="token-22-33" morph="none" pos="word" start_char="3887">Friday</TOKEN>
<TOKEN end_char="3893" id="token-22-34" morph="none" pos="punct" start_char="3893">.</TOKEN>
</SEG>
<SEG end_char="3902" id="segment-23" start_char="3895">
<ORIGINAL_TEXT>[Source]</ORIGINAL_TEXT>
<TOKEN end_char="3895" id="token-23-0" morph="none" pos="punct" start_char="3895">[</TOKEN>
<TOKEN end_char="3901" id="token-23-1" morph="none" pos="word" start_char="3896">Source</TOKEN>
<TOKEN end_char="3902" id="token-23-2" morph="none" pos="punct" start_char="3902">]</TOKEN>
</SEG>
<SEG end_char="3975" id="segment-24" start_char="3906">
<ORIGINAL_TEXT>Government-endorsed conspiracies about the virus’ origins are not new.</ORIGINAL_TEXT>
<TOKEN end_char="3924" id="token-24-0" morph="none" pos="unknown" start_char="3906">Government-endorsed</TOKEN>
<TOKEN end_char="3937" id="token-24-1" morph="none" pos="word" start_char="3926">conspiracies</TOKEN>
<TOKEN end_char="3943" id="token-24-2" morph="none" pos="word" start_char="3939">about</TOKEN>
<TOKEN end_char="3947" id="token-24-3" morph="none" pos="word" start_char="3945">the</TOKEN>
<TOKEN end_char="3953" id="token-24-4" morph="none" pos="word" start_char="3949">virus</TOKEN>
<TOKEN end_char="3954" id="token-24-5" morph="none" pos="punct" start_char="3954">’</TOKEN>
<TOKEN end_char="3962" id="token-24-6" morph="none" pos="word" start_char="3956">origins</TOKEN>
<TOKEN end_char="3966" id="token-24-7" morph="none" pos="word" start_char="3964">are</TOKEN>
<TOKEN end_char="3970" id="token-24-8" morph="none" pos="word" start_char="3968">not</TOKEN>
<TOKEN end_char="3974" id="token-24-9" morph="none" pos="word" start_char="3972">new</TOKEN>
<TOKEN end_char="3975" id="token-24-10" morph="none" pos="punct" start_char="3975">.</TOKEN>
</SEG>
<SEG end_char="4205" id="segment-25" start_char="3977">
<ORIGINAL_TEXT>In March, Ministry of Foreign Affairs Spokesperson Zhao Lijian promoted a false theory that COVID-19 started in Fort Detrick, Maryland, and may have been brought to Wuhan by American participants in the 2019 Military World Games.</ORIGINAL_TEXT>
<TOKEN end_char="3978" id="token-25-0" morph="none" pos="word" start_char="3977">In</TOKEN>
<TOKEN end_char="3984" id="token-25-1" morph="none" pos="word" start_char="3980">March</TOKEN>
<TOKEN end_char="3985" id="token-25-2" morph="none" pos="punct" start_char="3985">,</TOKEN>
<TOKEN end_char="3994" id="token-25-3" morph="none" pos="word" start_char="3987">Ministry</TOKEN>
<TOKEN end_char="3997" id="token-25-4" morph="none" pos="word" start_char="3996">of</TOKEN>
<TOKEN end_char="4005" id="token-25-5" morph="none" pos="word" start_char="3999">Foreign</TOKEN>
<TOKEN end_char="4013" id="token-25-6" morph="none" pos="word" start_char="4007">Affairs</TOKEN>
<TOKEN end_char="4026" id="token-25-7" morph="none" pos="word" start_char="4015">Spokesperson</TOKEN>
<TOKEN end_char="4031" id="token-25-8" morph="none" pos="word" start_char="4028">Zhao</TOKEN>
<TOKEN end_char="4038" id="token-25-9" morph="none" pos="word" start_char="4033">Lijian</TOKEN>
<TOKEN end_char="4047" id="token-25-10" morph="none" pos="word" start_char="4040">promoted</TOKEN>
<TOKEN end_char="4049" id="token-25-11" morph="none" pos="word" start_char="4049">a</TOKEN>
<TOKEN end_char="4055" id="token-25-12" morph="none" pos="word" start_char="4051">false</TOKEN>
<TOKEN end_char="4062" id="token-25-13" morph="none" pos="word" start_char="4057">theory</TOKEN>
<TOKEN end_char="4067" id="token-25-14" morph="none" pos="word" start_char="4064">that</TOKEN>
<TOKEN end_char="4076" id="token-25-15" morph="none" pos="unknown" start_char="4069">COVID-19</TOKEN>
<TOKEN end_char="4084" id="token-25-16" morph="none" pos="word" start_char="4078">started</TOKEN>
<TOKEN end_char="4087" id="token-25-17" morph="none" pos="word" start_char="4086">in</TOKEN>
<TOKEN end_char="4092" id="token-25-18" morph="none" pos="word" start_char="4089">Fort</TOKEN>
<TOKEN end_char="4100" id="token-25-19" morph="none" pos="word" start_char="4094">Detrick</TOKEN>
<TOKEN end_char="4101" id="token-25-20" morph="none" pos="punct" start_char="4101">,</TOKEN>
<TOKEN end_char="4110" id="token-25-21" morph="none" pos="word" start_char="4103">Maryland</TOKEN>
<TOKEN end_char="4111" id="token-25-22" morph="none" pos="punct" start_char="4111">,</TOKEN>
<TOKEN end_char="4115" id="token-25-23" morph="none" pos="word" start_char="4113">and</TOKEN>
<TOKEN end_char="4119" id="token-25-24" morph="none" pos="word" start_char="4117">may</TOKEN>
<TOKEN end_char="4124" id="token-25-25" morph="none" pos="word" start_char="4121">have</TOKEN>
<TOKEN end_char="4129" id="token-25-26" morph="none" pos="word" start_char="4126">been</TOKEN>
<TOKEN end_char="4137" id="token-25-27" morph="none" pos="word" start_char="4131">brought</TOKEN>
<TOKEN end_char="4140" id="token-25-28" morph="none" pos="word" start_char="4139">to</TOKEN>
<TOKEN end_char="4146" id="token-25-29" morph="none" pos="word" start_char="4142">Wuhan</TOKEN>
<TOKEN end_char="4149" id="token-25-30" morph="none" pos="word" start_char="4148">by</TOKEN>
<TOKEN end_char="4158" id="token-25-31" morph="none" pos="word" start_char="4151">American</TOKEN>
<TOKEN end_char="4171" id="token-25-32" morph="none" pos="word" start_char="4160">participants</TOKEN>
<TOKEN end_char="4174" id="token-25-33" morph="none" pos="word" start_char="4173">in</TOKEN>
<TOKEN end_char="4178" id="token-25-34" morph="none" pos="word" start_char="4176">the</TOKEN>
<TOKEN end_char="4183" id="token-25-35" morph="none" pos="word" start_char="4180">2019</TOKEN>
<TOKEN end_char="4192" id="token-25-36" morph="none" pos="word" start_char="4185">Military</TOKEN>
<TOKEN end_char="4198" id="token-25-37" morph="none" pos="word" start_char="4194">World</TOKEN>
<TOKEN end_char="4204" id="token-25-38" morph="none" pos="word" start_char="4200">Games</TOKEN>
<TOKEN end_char="4205" id="token-25-39" morph="none" pos="punct" start_char="4205">.</TOKEN>
</SEG>
<SEG end_char="4319" id="segment-26" start_char="4207">
<ORIGINAL_TEXT>Hundreds of Chinese state-connected accounts including, diplomatic outposts and media outlets, echoed his claims.</ORIGINAL_TEXT>
<TOKEN end_char="4214" id="token-26-0" morph="none" pos="word" start_char="4207">Hundreds</TOKEN>
<TOKEN end_char="4217" id="token-26-1" morph="none" pos="word" start_char="4216">of</TOKEN>
<TOKEN end_char="4225" id="token-26-2" morph="none" pos="word" start_char="4219">Chinese</TOKEN>
<TOKEN end_char="4241" id="token-26-3" morph="none" pos="unknown" start_char="4227">state-connected</TOKEN>
<TOKEN end_char="4250" id="token-26-4" morph="none" pos="word" start_char="4243">accounts</TOKEN>
<TOKEN end_char="4260" id="token-26-5" morph="none" pos="word" start_char="4252">including</TOKEN>
<TOKEN end_char="4261" id="token-26-6" morph="none" pos="punct" start_char="4261">,</TOKEN>
<TOKEN end_char="4272" id="token-26-7" morph="none" pos="word" start_char="4263">diplomatic</TOKEN>
<TOKEN end_char="4281" id="token-26-8" morph="none" pos="word" start_char="4274">outposts</TOKEN>
<TOKEN end_char="4285" id="token-26-9" morph="none" pos="word" start_char="4283">and</TOKEN>
<TOKEN end_char="4291" id="token-26-10" morph="none" pos="word" start_char="4287">media</TOKEN>
<TOKEN end_char="4299" id="token-26-11" morph="none" pos="word" start_char="4293">outlets</TOKEN>
<TOKEN end_char="4300" id="token-26-12" morph="none" pos="punct" start_char="4300">,</TOKEN>
<TOKEN end_char="4307" id="token-26-13" morph="none" pos="word" start_char="4302">echoed</TOKEN>
<TOKEN end_char="4311" id="token-26-14" morph="none" pos="word" start_char="4309">his</TOKEN>
<TOKEN end_char="4318" id="token-26-15" morph="none" pos="word" start_char="4313">claims</TOKEN>
<TOKEN end_char="4319" id="token-26-16" morph="none" pos="punct" start_char="4319">.</TOKEN>
</SEG>
<SEG end_char="4327" id="segment-27" start_char="4321">
<ORIGINAL_TEXT>Dali L.</ORIGINAL_TEXT>
<TOKEN end_char="4324" id="token-27-0" morph="none" pos="word" start_char="4321">Dali</TOKEN>
<TOKEN end_char="4326" id="token-27-1" morph="none" pos="word" start_char="4326">L</TOKEN>
<TOKEN end_char="4327" id="token-27-2" morph="none" pos="punct" start_char="4327">.</TOKEN>
</SEG>
<SEG end_char="4618" id="segment-28" start_char="4329">
<ORIGINAL_TEXT>Yang, an eminent sinologist at The University of Chicago, wrote that Zhao’s amplification of conspiracies served to make "such ‘theories’ appear more credible to ordinary Chinese and further helped them to spread virally on Chinese social media," thus relieving internal political pressure.</ORIGINAL_TEXT>
<TOKEN end_char="4332" id="token-28-0" morph="none" pos="word" start_char="4329">Yang</TOKEN>
<TOKEN end_char="4333" id="token-28-1" morph="none" pos="punct" start_char="4333">,</TOKEN>
<TOKEN end_char="4336" id="token-28-2" morph="none" pos="word" start_char="4335">an</TOKEN>
<TOKEN end_char="4344" id="token-28-3" morph="none" pos="word" start_char="4338">eminent</TOKEN>
<TOKEN end_char="4355" id="token-28-4" morph="none" pos="word" start_char="4346">sinologist</TOKEN>
<TOKEN end_char="4358" id="token-28-5" morph="none" pos="word" start_char="4357">at</TOKEN>
<TOKEN end_char="4362" id="token-28-6" morph="none" pos="word" start_char="4360">The</TOKEN>
<TOKEN end_char="4373" id="token-28-7" morph="none" pos="word" start_char="4364">University</TOKEN>
<TOKEN end_char="4376" id="token-28-8" morph="none" pos="word" start_char="4375">of</TOKEN>
<TOKEN end_char="4384" id="token-28-9" morph="none" pos="word" start_char="4378">Chicago</TOKEN>
<TOKEN end_char="4385" id="token-28-10" morph="none" pos="punct" start_char="4385">,</TOKEN>
<TOKEN end_char="4391" id="token-28-11" morph="none" pos="word" start_char="4387">wrote</TOKEN>
<TOKEN end_char="4396" id="token-28-12" morph="none" pos="word" start_char="4393">that</TOKEN>
<TOKEN end_char="4403" id="token-28-13" morph="none" pos="word" start_char="4398">Zhao’s</TOKEN>
<TOKEN end_char="4417" id="token-28-14" morph="none" pos="word" start_char="4405">amplification</TOKEN>
<TOKEN end_char="4420" id="token-28-15" morph="none" pos="word" start_char="4419">of</TOKEN>
<TOKEN end_char="4433" id="token-28-16" morph="none" pos="word" start_char="4422">conspiracies</TOKEN>
<TOKEN end_char="4440" id="token-28-17" morph="none" pos="word" start_char="4435">served</TOKEN>
<TOKEN end_char="4443" id="token-28-18" morph="none" pos="word" start_char="4442">to</TOKEN>
<TOKEN end_char="4448" id="token-28-19" morph="none" pos="word" start_char="4445">make</TOKEN>
<TOKEN end_char="4450" id="token-28-20" morph="none" pos="punct" start_char="4450">"</TOKEN>
<TOKEN end_char="4454" id="token-28-21" morph="none" pos="word" start_char="4451">such</TOKEN>
<TOKEN end_char="4456" id="token-28-22" morph="none" pos="punct" start_char="4456">‘</TOKEN>
<TOKEN end_char="4464" id="token-28-23" morph="none" pos="word" start_char="4457">theories</TOKEN>
<TOKEN end_char="4465" id="token-28-24" morph="none" pos="punct" start_char="4465">’</TOKEN>
<TOKEN end_char="4472" id="token-28-25" morph="none" pos="word" start_char="4467">appear</TOKEN>
<TOKEN end_char="4477" id="token-28-26" morph="none" pos="word" start_char="4474">more</TOKEN>
<TOKEN end_char="4486" id="token-28-27" morph="none" pos="word" start_char="4479">credible</TOKEN>
<TOKEN end_char="4489" id="token-28-28" morph="none" pos="word" start_char="4488">to</TOKEN>
<TOKEN end_char="4498" id="token-28-29" morph="none" pos="word" start_char="4491">ordinary</TOKEN>
<TOKEN end_char="4506" id="token-28-30" morph="none" pos="word" start_char="4500">Chinese</TOKEN>
<TOKEN end_char="4510" id="token-28-31" morph="none" pos="word" start_char="4508">and</TOKEN>
<TOKEN end_char="4518" id="token-28-32" morph="none" pos="word" start_char="4512">further</TOKEN>
<TOKEN end_char="4525" id="token-28-33" morph="none" pos="word" start_char="4520">helped</TOKEN>
<TOKEN end_char="4530" id="token-28-34" morph="none" pos="word" start_char="4527">them</TOKEN>
<TOKEN end_char="4533" id="token-28-35" morph="none" pos="word" start_char="4532">to</TOKEN>
<TOKEN end_char="4540" id="token-28-36" morph="none" pos="word" start_char="4535">spread</TOKEN>
<TOKEN end_char="4548" id="token-28-37" morph="none" pos="word" start_char="4542">virally</TOKEN>
<TOKEN end_char="4551" id="token-28-38" morph="none" pos="word" start_char="4550">on</TOKEN>
<TOKEN end_char="4559" id="token-28-39" morph="none" pos="word" start_char="4553">Chinese</TOKEN>
<TOKEN end_char="4566" id="token-28-40" morph="none" pos="word" start_char="4561">social</TOKEN>
<TOKEN end_char="4572" id="token-28-41" morph="none" pos="word" start_char="4568">media</TOKEN>
<TOKEN end_char="4574" id="token-28-42" morph="none" pos="punct" start_char="4573">,"</TOKEN>
<TOKEN end_char="4579" id="token-28-43" morph="none" pos="word" start_char="4576">thus</TOKEN>
<TOKEN end_char="4589" id="token-28-44" morph="none" pos="word" start_char="4581">relieving</TOKEN>
<TOKEN end_char="4598" id="token-28-45" morph="none" pos="word" start_char="4591">internal</TOKEN>
<TOKEN end_char="4608" id="token-28-46" morph="none" pos="word" start_char="4600">political</TOKEN>
<TOKEN end_char="4617" id="token-28-47" morph="none" pos="word" start_char="4610">pressure</TOKEN>
<TOKEN end_char="4618" id="token-28-48" morph="none" pos="punct" start_char="4618">.</TOKEN>
</SEG>
<SEG end_char="4773" id="segment-29" start_char="4621">
<ORIGINAL_TEXT>Beijing has resisted international investigations into the coronavirus’ origins, stymieing World Health Organization investigators access to the country.</ORIGINAL_TEXT>
<TOKEN end_char="4627" id="token-29-0" morph="none" pos="word" start_char="4621">Beijing</TOKEN>
<TOKEN end_char="4631" id="token-29-1" morph="none" pos="word" start_char="4629">has</TOKEN>
<TOKEN end_char="4640" id="token-29-2" morph="none" pos="word" start_char="4633">resisted</TOKEN>
<TOKEN end_char="4654" id="token-29-3" morph="none" pos="word" start_char="4642">international</TOKEN>
<TOKEN end_char="4669" id="token-29-4" morph="none" pos="word" start_char="4656">investigations</TOKEN>
<TOKEN end_char="4674" id="token-29-5" morph="none" pos="word" start_char="4671">into</TOKEN>
<TOKEN end_char="4678" id="token-29-6" morph="none" pos="word" start_char="4676">the</TOKEN>
<TOKEN end_char="4690" id="token-29-7" morph="none" pos="word" start_char="4680">coronavirus</TOKEN>
<TOKEN end_char="4691" id="token-29-8" morph="none" pos="punct" start_char="4691">’</TOKEN>
<TOKEN end_char="4699" id="token-29-9" morph="none" pos="word" start_char="4693">origins</TOKEN>
<TOKEN end_char="4700" id="token-29-10" morph="none" pos="punct" start_char="4700">,</TOKEN>
<TOKEN end_char="4710" id="token-29-11" morph="none" pos="word" start_char="4702">stymieing</TOKEN>
<TOKEN end_char="4716" id="token-29-12" morph="none" pos="word" start_char="4712">World</TOKEN>
<TOKEN end_char="4723" id="token-29-13" morph="none" pos="word" start_char="4718">Health</TOKEN>
<TOKEN end_char="4736" id="token-29-14" morph="none" pos="word" start_char="4725">Organization</TOKEN>
<TOKEN end_char="4750" id="token-29-15" morph="none" pos="word" start_char="4738">investigators</TOKEN>
<TOKEN end_char="4757" id="token-29-16" morph="none" pos="word" start_char="4752">access</TOKEN>
<TOKEN end_char="4760" id="token-29-17" morph="none" pos="word" start_char="4759">to</TOKEN>
<TOKEN end_char="4764" id="token-29-18" morph="none" pos="word" start_char="4762">the</TOKEN>
<TOKEN end_char="4772" id="token-29-19" morph="none" pos="word" start_char="4766">country</TOKEN>
<TOKEN end_char="4773" id="token-29-20" morph="none" pos="punct" start_char="4773">.</TOKEN>
</SEG>
<SEG end_char="4915" id="segment-30" start_char="4775">
<ORIGINAL_TEXT>On Wednesday, the WHO announced the long-delayed assembly of a 10-person coronavirus investigation team, selected in consultation with China.</ORIGINAL_TEXT>
<TOKEN end_char="4776" id="token-30-0" morph="none" pos="word" start_char="4775">On</TOKEN>
<TOKEN end_char="4786" id="token-30-1" morph="none" pos="word" start_char="4778">Wednesday</TOKEN>
<TOKEN end_char="4787" id="token-30-2" morph="none" pos="punct" start_char="4787">,</TOKEN>
<TOKEN end_char="4791" id="token-30-3" morph="none" pos="word" start_char="4789">the</TOKEN>
<TOKEN end_char="4795" id="token-30-4" morph="none" pos="word" start_char="4793">WHO</TOKEN>
<TOKEN end_char="4805" id="token-30-5" morph="none" pos="word" start_char="4797">announced</TOKEN>
<TOKEN end_char="4809" id="token-30-6" morph="none" pos="word" start_char="4807">the</TOKEN>
<TOKEN end_char="4822" id="token-30-7" morph="none" pos="unknown" start_char="4811">long-delayed</TOKEN>
<TOKEN end_char="4831" id="token-30-8" morph="none" pos="word" start_char="4824">assembly</TOKEN>
<TOKEN end_char="4834" id="token-30-9" morph="none" pos="word" start_char="4833">of</TOKEN>
<TOKEN end_char="4836" id="token-30-10" morph="none" pos="word" start_char="4836">a</TOKEN>
<TOKEN end_char="4846" id="token-30-11" morph="none" pos="unknown" start_char="4838">10-person</TOKEN>
<TOKEN end_char="4858" id="token-30-12" morph="none" pos="word" start_char="4848">coronavirus</TOKEN>
<TOKEN end_char="4872" id="token-30-13" morph="none" pos="word" start_char="4860">investigation</TOKEN>
<TOKEN end_char="4877" id="token-30-14" morph="none" pos="word" start_char="4874">team</TOKEN>
<TOKEN end_char="4878" id="token-30-15" morph="none" pos="punct" start_char="4878">,</TOKEN>
<TOKEN end_char="4887" id="token-30-16" morph="none" pos="word" start_char="4880">selected</TOKEN>
<TOKEN end_char="4890" id="token-30-17" morph="none" pos="word" start_char="4889">in</TOKEN>
<TOKEN end_char="4903" id="token-30-18" morph="none" pos="word" start_char="4892">consultation</TOKEN>
<TOKEN end_char="4908" id="token-30-19" morph="none" pos="word" start_char="4905">with</TOKEN>
<TOKEN end_char="4914" id="token-30-20" morph="none" pos="word" start_char="4910">China</TOKEN>
<TOKEN end_char="4915" id="token-30-21" morph="none" pos="punct" start_char="4915">.</TOKEN>
</SEG>
<SEG end_char="5064" id="segment-31" start_char="4917">
<ORIGINAL_TEXT>At the South China Morning Post, Simone McCarthy reported on the team’s research goals, and concerns that they might be denied full access to Wuhan:</ORIGINAL_TEXT>
<TOKEN end_char="4918" id="token-31-0" morph="none" pos="word" start_char="4917">At</TOKEN>
<TOKEN end_char="4922" id="token-31-1" morph="none" pos="word" start_char="4920">the</TOKEN>
<TOKEN end_char="4928" id="token-31-2" morph="none" pos="word" start_char="4924">South</TOKEN>
<TOKEN end_char="4934" id="token-31-3" morph="none" pos="word" start_char="4930">China</TOKEN>
<TOKEN end_char="4942" id="token-31-4" morph="none" pos="word" start_char="4936">Morning</TOKEN>
<TOKEN end_char="4947" id="token-31-5" morph="none" pos="word" start_char="4944">Post</TOKEN>
<TOKEN end_char="4948" id="token-31-6" morph="none" pos="punct" start_char="4948">,</TOKEN>
<TOKEN end_char="4955" id="token-31-7" morph="none" pos="word" start_char="4950">Simone</TOKEN>
<TOKEN end_char="4964" id="token-31-8" morph="none" pos="word" start_char="4957">McCarthy</TOKEN>
<TOKEN end_char="4973" id="token-31-9" morph="none" pos="word" start_char="4966">reported</TOKEN>
<TOKEN end_char="4976" id="token-31-10" morph="none" pos="word" start_char="4975">on</TOKEN>
<TOKEN end_char="4980" id="token-31-11" morph="none" pos="word" start_char="4978">the</TOKEN>
<TOKEN end_char="4987" id="token-31-12" morph="none" pos="word" start_char="4982">team’s</TOKEN>
<TOKEN end_char="4996" id="token-31-13" morph="none" pos="word" start_char="4989">research</TOKEN>
<TOKEN end_char="5002" id="token-31-14" morph="none" pos="word" start_char="4998">goals</TOKEN>
<TOKEN end_char="5003" id="token-31-15" morph="none" pos="punct" start_char="5003">,</TOKEN>
<TOKEN end_char="5007" id="token-31-16" morph="none" pos="word" start_char="5005">and</TOKEN>
<TOKEN end_char="5016" id="token-31-17" morph="none" pos="word" start_char="5009">concerns</TOKEN>
<TOKEN end_char="5021" id="token-31-18" morph="none" pos="word" start_char="5018">that</TOKEN>
<TOKEN end_char="5026" id="token-31-19" morph="none" pos="word" start_char="5023">they</TOKEN>
<TOKEN end_char="5032" id="token-31-20" morph="none" pos="word" start_char="5028">might</TOKEN>
<TOKEN end_char="5035" id="token-31-21" morph="none" pos="word" start_char="5034">be</TOKEN>
<TOKEN end_char="5042" id="token-31-22" morph="none" pos="word" start_char="5037">denied</TOKEN>
<TOKEN end_char="5047" id="token-31-23" morph="none" pos="word" start_char="5044">full</TOKEN>
<TOKEN end_char="5054" id="token-31-24" morph="none" pos="word" start_char="5049">access</TOKEN>
<TOKEN end_char="5057" id="token-31-25" morph="none" pos="word" start_char="5056">to</TOKEN>
<TOKEN end_char="5063" id="token-31-26" morph="none" pos="word" start_char="5059">Wuhan</TOKEN>
<TOKEN end_char="5064" id="token-31-27" morph="none" pos="punct" start_char="5064">:</TOKEN>
</SEG>
<SEG end_char="5295" id="segment-32" start_char="5067">
<ORIGINAL_TEXT>One hanging question is when the international team will join field studies on the ground in China, considered a critical part of the mission, which was called for by over 130 nations at a May meeting of the WHO’s governing body.</ORIGINAL_TEXT>
<TOKEN end_char="5069" id="token-32-0" morph="none" pos="word" start_char="5067">One</TOKEN>
<TOKEN end_char="5077" id="token-32-1" morph="none" pos="word" start_char="5071">hanging</TOKEN>
<TOKEN end_char="5086" id="token-32-2" morph="none" pos="word" start_char="5079">question</TOKEN>
<TOKEN end_char="5089" id="token-32-3" morph="none" pos="word" start_char="5088">is</TOKEN>
<TOKEN end_char="5094" id="token-32-4" morph="none" pos="word" start_char="5091">when</TOKEN>
<TOKEN end_char="5098" id="token-32-5" morph="none" pos="word" start_char="5096">the</TOKEN>
<TOKEN end_char="5112" id="token-32-6" morph="none" pos="word" start_char="5100">international</TOKEN>
<TOKEN end_char="5117" id="token-32-7" morph="none" pos="word" start_char="5114">team</TOKEN>
<TOKEN end_char="5122" id="token-32-8" morph="none" pos="word" start_char="5119">will</TOKEN>
<TOKEN end_char="5127" id="token-32-9" morph="none" pos="word" start_char="5124">join</TOKEN>
<TOKEN end_char="5133" id="token-32-10" morph="none" pos="word" start_char="5129">field</TOKEN>
<TOKEN end_char="5141" id="token-32-11" morph="none" pos="word" start_char="5135">studies</TOKEN>
<TOKEN end_char="5144" id="token-32-12" morph="none" pos="word" start_char="5143">on</TOKEN>
<TOKEN end_char="5148" id="token-32-13" morph="none" pos="word" start_char="5146">the</TOKEN>
<TOKEN end_char="5155" id="token-32-14" morph="none" pos="word" start_char="5150">ground</TOKEN>
<TOKEN end_char="5158" id="token-32-15" morph="none" pos="word" start_char="5157">in</TOKEN>
<TOKEN end_char="5164" id="token-32-16" morph="none" pos="word" start_char="5160">China</TOKEN>
<TOKEN end_char="5165" id="token-32-17" morph="none" pos="punct" start_char="5165">,</TOKEN>
<TOKEN end_char="5176" id="token-32-18" morph="none" pos="word" start_char="5167">considered</TOKEN>
<TOKEN end_char="5178" id="token-32-19" morph="none" pos="word" start_char="5178">a</TOKEN>
<TOKEN end_char="5187" id="token-32-20" morph="none" pos="word" start_char="5180">critical</TOKEN>
<TOKEN end_char="5192" id="token-32-21" morph="none" pos="word" start_char="5189">part</TOKEN>
<TOKEN end_char="5195" id="token-32-22" morph="none" pos="word" start_char="5194">of</TOKEN>
<TOKEN end_char="5199" id="token-32-23" morph="none" pos="word" start_char="5197">the</TOKEN>
<TOKEN end_char="5207" id="token-32-24" morph="none" pos="word" start_char="5201">mission</TOKEN>
<TOKEN end_char="5208" id="token-32-25" morph="none" pos="punct" start_char="5208">,</TOKEN>
<TOKEN end_char="5214" id="token-32-26" morph="none" pos="word" start_char="5210">which</TOKEN>
<TOKEN end_char="5218" id="token-32-27" morph="none" pos="word" start_char="5216">was</TOKEN>
<TOKEN end_char="5225" id="token-32-28" morph="none" pos="word" start_char="5220">called</TOKEN>
<TOKEN end_char="5229" id="token-32-29" morph="none" pos="word" start_char="5227">for</TOKEN>
<TOKEN end_char="5232" id="token-32-30" morph="none" pos="word" start_char="5231">by</TOKEN>
<TOKEN end_char="5237" id="token-32-31" morph="none" pos="word" start_char="5234">over</TOKEN>
<TOKEN end_char="5241" id="token-32-32" morph="none" pos="word" start_char="5239">130</TOKEN>
<TOKEN end_char="5249" id="token-32-33" morph="none" pos="word" start_char="5243">nations</TOKEN>
<TOKEN end_char="5252" id="token-32-34" morph="none" pos="word" start_char="5251">at</TOKEN>
<TOKEN end_char="5254" id="token-32-35" morph="none" pos="word" start_char="5254">a</TOKEN>
<TOKEN end_char="5258" id="token-32-36" morph="none" pos="word" start_char="5256">May</TOKEN>
<TOKEN end_char="5266" id="token-32-37" morph="none" pos="word" start_char="5260">meeting</TOKEN>
<TOKEN end_char="5269" id="token-32-38" morph="none" pos="word" start_char="5268">of</TOKEN>
<TOKEN end_char="5273" id="token-32-39" morph="none" pos="word" start_char="5271">the</TOKEN>
<TOKEN end_char="5279" id="token-32-40" morph="none" pos="word" start_char="5275">WHO’s</TOKEN>
<TOKEN end_char="5289" id="token-32-41" morph="none" pos="word" start_char="5281">governing</TOKEN>
<TOKEN end_char="5294" id="token-32-42" morph="none" pos="word" start_char="5291">body</TOKEN>
<TOKEN end_char="5295" id="token-32-43" morph="none" pos="punct" start_char="5295">.</TOKEN>
</SEG>
<SEG end_char="5443" id="segment-33" start_char="5297">
<ORIGINAL_TEXT>[…] Groundwork for the mission was originally done in July and the WHO at the time said the international team would arrive "in a matter of weeks".</ORIGINAL_TEXT>
<TOKEN end_char="5299" id="token-33-0" morph="none" pos="punct" start_char="5297">[…]</TOKEN>
<TOKEN end_char="5310" id="token-33-1" morph="none" pos="word" start_char="5301">Groundwork</TOKEN>
<TOKEN end_char="5314" id="token-33-2" morph="none" pos="word" start_char="5312">for</TOKEN>
<TOKEN end_char="5318" id="token-33-3" morph="none" pos="word" start_char="5316">the</TOKEN>
<TOKEN end_char="5326" id="token-33-4" morph="none" pos="word" start_char="5320">mission</TOKEN>
<TOKEN end_char="5330" id="token-33-5" morph="none" pos="word" start_char="5328">was</TOKEN>
<TOKEN end_char="5341" id="token-33-6" morph="none" pos="word" start_char="5332">originally</TOKEN>
<TOKEN end_char="5346" id="token-33-7" morph="none" pos="word" start_char="5343">done</TOKEN>
<TOKEN end_char="5349" id="token-33-8" morph="none" pos="word" start_char="5348">in</TOKEN>
<TOKEN end_char="5354" id="token-33-9" morph="none" pos="word" start_char="5351">July</TOKEN>
<TOKEN end_char="5358" id="token-33-10" morph="none" pos="word" start_char="5356">and</TOKEN>
<TOKEN end_char="5362" id="token-33-11" morph="none" pos="word" start_char="5360">the</TOKEN>
<TOKEN end_char="5366" id="token-33-12" morph="none" pos="word" start_char="5364">WHO</TOKEN>
<TOKEN end_char="5369" id="token-33-13" morph="none" pos="word" start_char="5368">at</TOKEN>
<TOKEN end_char="5373" id="token-33-14" morph="none" pos="word" start_char="5371">the</TOKEN>
<TOKEN end_char="5378" id="token-33-15" morph="none" pos="word" start_char="5375">time</TOKEN>
<TOKEN end_char="5383" id="token-33-16" morph="none" pos="word" start_char="5380">said</TOKEN>
<TOKEN end_char="5387" id="token-33-17" morph="none" pos="word" start_char="5385">the</TOKEN>
<TOKEN end_char="5401" id="token-33-18" morph="none" pos="word" start_char="5389">international</TOKEN>
<TOKEN end_char="5406" id="token-33-19" morph="none" pos="word" start_char="5403">team</TOKEN>
<TOKEN end_char="5412" id="token-33-20" morph="none" pos="word" start_char="5408">would</TOKEN>
<TOKEN end_char="5419" id="token-33-21" morph="none" pos="word" start_char="5414">arrive</TOKEN>
<TOKEN end_char="5421" id="token-33-22" morph="none" pos="punct" start_char="5421">"</TOKEN>
<TOKEN end_char="5423" id="token-33-23" morph="none" pos="word" start_char="5422">in</TOKEN>
<TOKEN end_char="5425" id="token-33-24" morph="none" pos="word" start_char="5425">a</TOKEN>
<TOKEN end_char="5432" id="token-33-25" morph="none" pos="word" start_char="5427">matter</TOKEN>
<TOKEN end_char="5435" id="token-33-26" morph="none" pos="word" start_char="5434">of</TOKEN>
<TOKEN end_char="5441" id="token-33-27" morph="none" pos="word" start_char="5437">weeks</TOKEN>
<TOKEN end_char="5443" id="token-33-28" morph="none" pos="punct" start_char="5442">".</TOKEN>
</SEG>
<SEG end_char="5609" id="segment-34" start_char="5445">
<ORIGINAL_TEXT>The United States and the European Union have called for more transparency around the mission in recent meetings of the WHO’s executive board and its governing body.</ORIGINAL_TEXT>
<TOKEN end_char="5447" id="token-34-0" morph="none" pos="word" start_char="5445">The</TOKEN>
<TOKEN end_char="5454" id="token-34-1" morph="none" pos="word" start_char="5449">United</TOKEN>
<TOKEN end_char="5461" id="token-34-2" morph="none" pos="word" start_char="5456">States</TOKEN>
<TOKEN end_char="5465" id="token-34-3" morph="none" pos="word" start_char="5463">and</TOKEN>
<TOKEN end_char="5469" id="token-34-4" morph="none" pos="word" start_char="5467">the</TOKEN>
<TOKEN end_char="5478" id="token-34-5" morph="none" pos="word" start_char="5471">European</TOKEN>
<TOKEN end_char="5484" id="token-34-6" morph="none" pos="word" start_char="5480">Union</TOKEN>
<TOKEN end_char="5489" id="token-34-7" morph="none" pos="word" start_char="5486">have</TOKEN>
<TOKEN end_char="5496" id="token-34-8" morph="none" pos="word" start_char="5491">called</TOKEN>
<TOKEN end_char="5500" id="token-34-9" morph="none" pos="word" start_char="5498">for</TOKEN>
<TOKEN end_char="5505" id="token-34-10" morph="none" pos="word" start_char="5502">more</TOKEN>
<TOKEN end_char="5518" id="token-34-11" morph="none" pos="word" start_char="5507">transparency</TOKEN>
<TOKEN end_char="5525" id="token-34-12" morph="none" pos="word" start_char="5520">around</TOKEN>
<TOKEN end_char="5529" id="token-34-13" morph="none" pos="word" start_char="5527">the</TOKEN>
<TOKEN end_char="5537" id="token-34-14" morph="none" pos="word" start_char="5531">mission</TOKEN>
<TOKEN end_char="5540" id="token-34-15" morph="none" pos="word" start_char="5539">in</TOKEN>
<TOKEN end_char="5547" id="token-34-16" morph="none" pos="word" start_char="5542">recent</TOKEN>
<TOKEN end_char="5556" id="token-34-17" morph="none" pos="word" start_char="5549">meetings</TOKEN>
<TOKEN end_char="5559" id="token-34-18" morph="none" pos="word" start_char="5558">of</TOKEN>
<TOKEN end_char="5563" id="token-34-19" morph="none" pos="word" start_char="5561">the</TOKEN>
<TOKEN end_char="5569" id="token-34-20" morph="none" pos="word" start_char="5565">WHO’s</TOKEN>
<TOKEN end_char="5579" id="token-34-21" morph="none" pos="word" start_char="5571">executive</TOKEN>
<TOKEN end_char="5585" id="token-34-22" morph="none" pos="word" start_char="5581">board</TOKEN>
<TOKEN end_char="5589" id="token-34-23" morph="none" pos="word" start_char="5587">and</TOKEN>
<TOKEN end_char="5593" id="token-34-24" morph="none" pos="word" start_char="5591">its</TOKEN>
<TOKEN end_char="5603" id="token-34-25" morph="none" pos="word" start_char="5595">governing</TOKEN>
<TOKEN end_char="5608" id="token-34-26" morph="none" pos="word" start_char="5605">body</TOKEN>
<TOKEN end_char="5609" id="token-34-27" morph="none" pos="punct" start_char="5609">.</TOKEN>
</SEG>
<SEG end_char="5733" id="segment-35" start_char="5611">
<ORIGINAL_TEXT>[…] The scientific mission’s phase one work centres around Wuhan, the city where the first cluster of cases was identified.</ORIGINAL_TEXT>
<TOKEN end_char="5613" id="token-35-0" morph="none" pos="punct" start_char="5611">[…]</TOKEN>
<TOKEN end_char="5617" id="token-35-1" morph="none" pos="word" start_char="5615">The</TOKEN>
<TOKEN end_char="5628" id="token-35-2" morph="none" pos="word" start_char="5619">scientific</TOKEN>
<TOKEN end_char="5638" id="token-35-3" morph="none" pos="word" start_char="5630">mission’s</TOKEN>
<TOKEN end_char="5644" id="token-35-4" morph="none" pos="word" start_char="5640">phase</TOKEN>
<TOKEN end_char="5648" id="token-35-5" morph="none" pos="word" start_char="5646">one</TOKEN>
<TOKEN end_char="5653" id="token-35-6" morph="none" pos="word" start_char="5650">work</TOKEN>
<TOKEN end_char="5661" id="token-35-7" morph="none" pos="word" start_char="5655">centres</TOKEN>
<TOKEN end_char="5668" id="token-35-8" morph="none" pos="word" start_char="5663">around</TOKEN>
<TOKEN end_char="5674" id="token-35-9" morph="none" pos="word" start_char="5670">Wuhan</TOKEN>
<TOKEN end_char="5675" id="token-35-10" morph="none" pos="punct" start_char="5675">,</TOKEN>
<TOKEN end_char="5679" id="token-35-11" morph="none" pos="word" start_char="5677">the</TOKEN>
<TOKEN end_char="5684" id="token-35-12" morph="none" pos="word" start_char="5681">city</TOKEN>
<TOKEN end_char="5690" id="token-35-13" morph="none" pos="word" start_char="5686">where</TOKEN>
<TOKEN end_char="5694" id="token-35-14" morph="none" pos="word" start_char="5692">the</TOKEN>
<TOKEN end_char="5700" id="token-35-15" morph="none" pos="word" start_char="5696">first</TOKEN>
<TOKEN end_char="5708" id="token-35-16" morph="none" pos="word" start_char="5702">cluster</TOKEN>
<TOKEN end_char="5711" id="token-35-17" morph="none" pos="word" start_char="5710">of</TOKEN>
<TOKEN end_char="5717" id="token-35-18" morph="none" pos="word" start_char="5713">cases</TOKEN>
<TOKEN end_char="5721" id="token-35-19" morph="none" pos="word" start_char="5719">was</TOKEN>
<TOKEN end_char="5732" id="token-35-20" morph="none" pos="word" start_char="5723">identified</TOKEN>
<TOKEN end_char="5733" id="token-35-21" morph="none" pos="punct" start_char="5733">.</TOKEN>
</SEG>
<SEG end_char="5954" id="segment-36" start_char="5735">
<ORIGINAL_TEXT>Though a number of these early cases were linked to a wet market in the city, the role of the market remains unclear due to a lack of "analytical epidemiological study", according to the WHO mission’s terms of reference.</ORIGINAL_TEXT>
<TOKEN end_char="5740" id="token-36-0" morph="none" pos="word" start_char="5735">Though</TOKEN>
<TOKEN end_char="5742" id="token-36-1" morph="none" pos="word" start_char="5742">a</TOKEN>
<TOKEN end_char="5749" id="token-36-2" morph="none" pos="word" start_char="5744">number</TOKEN>
<TOKEN end_char="5752" id="token-36-3" morph="none" pos="word" start_char="5751">of</TOKEN>
<TOKEN end_char="5758" id="token-36-4" morph="none" pos="word" start_char="5754">these</TOKEN>
<TOKEN end_char="5764" id="token-36-5" morph="none" pos="word" start_char="5760">early</TOKEN>
<TOKEN end_char="5770" id="token-36-6" morph="none" pos="word" start_char="5766">cases</TOKEN>
<TOKEN end_char="5775" id="token-36-7" morph="none" pos="word" start_char="5772">were</TOKEN>
<TOKEN end_char="5782" id="token-36-8" morph="none" pos="word" start_char="5777">linked</TOKEN>
<TOKEN end_char="5785" id="token-36-9" morph="none" pos="word" start_char="5784">to</TOKEN>
<TOKEN end_char="5787" id="token-36-10" morph="none" pos="word" start_char="5787">a</TOKEN>
<TOKEN end_char="5791" id="token-36-11" morph="none" pos="word" start_char="5789">wet</TOKEN>
<TOKEN end_char="5798" id="token-36-12" morph="none" pos="word" start_char="5793">market</TOKEN>
<TOKEN end_char="5801" id="token-36-13" morph="none" pos="word" start_char="5800">in</TOKEN>
<TOKEN end_char="5805" id="token-36-14" morph="none" pos="word" start_char="5803">the</TOKEN>
<TOKEN end_char="5810" id="token-36-15" morph="none" pos="word" start_char="5807">city</TOKEN>
<TOKEN end_char="5811" id="token-36-16" morph="none" pos="punct" start_char="5811">,</TOKEN>
<TOKEN end_char="5815" id="token-36-17" morph="none" pos="word" start_char="5813">the</TOKEN>
<TOKEN end_char="5820" id="token-36-18" morph="none" pos="word" start_char="5817">role</TOKEN>
<TOKEN end_char="5823" id="token-36-19" morph="none" pos="word" start_char="5822">of</TOKEN>
<TOKEN end_char="5827" id="token-36-20" morph="none" pos="word" start_char="5825">the</TOKEN>
<TOKEN end_char="5834" id="token-36-21" morph="none" pos="word" start_char="5829">market</TOKEN>
<TOKEN end_char="5842" id="token-36-22" morph="none" pos="word" start_char="5836">remains</TOKEN>
<TOKEN end_char="5850" id="token-36-23" morph="none" pos="word" start_char="5844">unclear</TOKEN>
<TOKEN end_char="5854" id="token-36-24" morph="none" pos="word" start_char="5852">due</TOKEN>
<TOKEN end_char="5857" id="token-36-25" morph="none" pos="word" start_char="5856">to</TOKEN>
<TOKEN end_char="5859" id="token-36-26" morph="none" pos="word" start_char="5859">a</TOKEN>
<TOKEN end_char="5864" id="token-36-27" morph="none" pos="word" start_char="5861">lack</TOKEN>
<TOKEN end_char="5867" id="token-36-28" morph="none" pos="word" start_char="5866">of</TOKEN>
<TOKEN end_char="5869" id="token-36-29" morph="none" pos="punct" start_char="5869">"</TOKEN>
<TOKEN end_char="5879" id="token-36-30" morph="none" pos="word" start_char="5870">analytical</TOKEN>
<TOKEN end_char="5895" id="token-36-31" morph="none" pos="word" start_char="5881">epidemiological</TOKEN>
<TOKEN end_char="5901" id="token-36-32" morph="none" pos="word" start_char="5897">study</TOKEN>
<TOKEN end_char="5903" id="token-36-33" morph="none" pos="punct" start_char="5902">",</TOKEN>
<TOKEN end_char="5913" id="token-36-34" morph="none" pos="word" start_char="5905">according</TOKEN>
<TOKEN end_char="5916" id="token-36-35" morph="none" pos="word" start_char="5915">to</TOKEN>
<TOKEN end_char="5920" id="token-36-36" morph="none" pos="word" start_char="5918">the</TOKEN>
<TOKEN end_char="5924" id="token-36-37" morph="none" pos="word" start_char="5922">WHO</TOKEN>
<TOKEN end_char="5934" id="token-36-38" morph="none" pos="word" start_char="5926">mission’s</TOKEN>
<TOKEN end_char="5940" id="token-36-39" morph="none" pos="word" start_char="5936">terms</TOKEN>
<TOKEN end_char="5943" id="token-36-40" morph="none" pos="word" start_char="5942">of</TOKEN>
<TOKEN end_char="5953" id="token-36-41" morph="none" pos="word" start_char="5945">reference</TOKEN>
<TOKEN end_char="5954" id="token-36-42" morph="none" pos="punct" start_char="5954">.</TOKEN>
</SEG>
<SEG end_char="5963" id="segment-37" start_char="5956">
<ORIGINAL_TEXT>[Source]</ORIGINAL_TEXT>
<TOKEN end_char="5956" id="token-37-0" morph="none" pos="punct" start_char="5956">[</TOKEN>
<TOKEN end_char="5962" id="token-37-1" morph="none" pos="word" start_char="5957">Source</TOKEN>
<TOKEN end_char="5963" id="token-37-2" morph="none" pos="punct" start_char="5963">]</TOKEN>
</SEG>
<SEG end_char="6089" id="segment-38" start_char="5967">
<ORIGINAL_TEXT>Contentions over the virus’ origin are part of the Chinese state’s ongoing battle to control the narrative on the pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="5977" id="token-38-0" morph="none" pos="word" start_char="5967">Contentions</TOKEN>
<TOKEN end_char="5982" id="token-38-1" morph="none" pos="word" start_char="5979">over</TOKEN>
<TOKEN end_char="5986" id="token-38-2" morph="none" pos="word" start_char="5984">the</TOKEN>
<TOKEN end_char="5992" id="token-38-3" morph="none" pos="word" start_char="5988">virus</TOKEN>
<TOKEN end_char="5993" id="token-38-4" morph="none" pos="punct" start_char="5993">’</TOKEN>
<TOKEN end_char="6000" id="token-38-5" morph="none" pos="word" start_char="5995">origin</TOKEN>
<TOKEN end_char="6004" id="token-38-6" morph="none" pos="word" start_char="6002">are</TOKEN>
<TOKEN end_char="6009" id="token-38-7" morph="none" pos="word" start_char="6006">part</TOKEN>
<TOKEN end_char="6012" id="token-38-8" morph="none" pos="word" start_char="6011">of</TOKEN>
<TOKEN end_char="6016" id="token-38-9" morph="none" pos="word" start_char="6014">the</TOKEN>
<TOKEN end_char="6024" id="token-38-10" morph="none" pos="word" start_char="6018">Chinese</TOKEN>
<TOKEN end_char="6032" id="token-38-11" morph="none" pos="word" start_char="6026">state’s</TOKEN>
<TOKEN end_char="6040" id="token-38-12" morph="none" pos="word" start_char="6034">ongoing</TOKEN>
<TOKEN end_char="6047" id="token-38-13" morph="none" pos="word" start_char="6042">battle</TOKEN>
<TOKEN end_char="6050" id="token-38-14" morph="none" pos="word" start_char="6049">to</TOKEN>
<TOKEN end_char="6058" id="token-38-15" morph="none" pos="word" start_char="6052">control</TOKEN>
<TOKEN end_char="6062" id="token-38-16" morph="none" pos="word" start_char="6060">the</TOKEN>
<TOKEN end_char="6072" id="token-38-17" morph="none" pos="word" start_char="6064">narrative</TOKEN>
<TOKEN end_char="6075" id="token-38-18" morph="none" pos="word" start_char="6074">on</TOKEN>
<TOKEN end_char="6079" id="token-38-19" morph="none" pos="word" start_char="6077">the</TOKEN>
<TOKEN end_char="6088" id="token-38-20" morph="none" pos="word" start_char="6081">pandemic</TOKEN>
<TOKEN end_char="6089" id="token-38-21" morph="none" pos="punct" start_char="6089">.</TOKEN>
</SEG>
<SEG end_char="6258" id="segment-39" start_char="6091">
<ORIGINAL_TEXT>Just last week citizen journalist Zhang Zhan, who covered the Wuhan outbreak on her vlog, was indicted on charges that allow authorities to imprison her for five years.</ORIGINAL_TEXT>
<TOKEN end_char="6094" id="token-39-0" morph="none" pos="word" start_char="6091">Just</TOKEN>
<TOKEN end_char="6099" id="token-39-1" morph="none" pos="word" start_char="6096">last</TOKEN>
<TOKEN end_char="6104" id="token-39-2" morph="none" pos="word" start_char="6101">week</TOKEN>
<TOKEN end_char="6112" id="token-39-3" morph="none" pos="word" start_char="6106">citizen</TOKEN>
<TOKEN end_char="6123" id="token-39-4" morph="none" pos="word" start_char="6114">journalist</TOKEN>
<TOKEN end_char="6129" id="token-39-5" morph="none" pos="word" start_char="6125">Zhang</TOKEN>
<TOKEN end_char="6134" id="token-39-6" morph="none" pos="word" start_char="6131">Zhan</TOKEN>
<TOKEN end_char="6135" id="token-39-7" morph="none" pos="punct" start_char="6135">,</TOKEN>
<TOKEN end_char="6139" id="token-39-8" morph="none" pos="word" start_char="6137">who</TOKEN>
<TOKEN end_char="6147" id="token-39-9" morph="none" pos="word" start_char="6141">covered</TOKEN>
<TOKEN end_char="6151" id="token-39-10" morph="none" pos="word" start_char="6149">the</TOKEN>
<TOKEN end_char="6157" id="token-39-11" morph="none" pos="word" start_char="6153">Wuhan</TOKEN>
<TOKEN end_char="6166" id="token-39-12" morph="none" pos="word" start_char="6159">outbreak</TOKEN>
<TOKEN end_char="6169" id="token-39-13" morph="none" pos="word" start_char="6168">on</TOKEN>
<TOKEN end_char="6173" id="token-39-14" morph="none" pos="word" start_char="6171">her</TOKEN>
<TOKEN end_char="6178" id="token-39-15" morph="none" pos="word" start_char="6175">vlog</TOKEN>
<TOKEN end_char="6179" id="token-39-16" morph="none" pos="punct" start_char="6179">,</TOKEN>
<TOKEN end_char="6183" id="token-39-17" morph="none" pos="word" start_char="6181">was</TOKEN>
<TOKEN end_char="6192" id="token-39-18" morph="none" pos="word" start_char="6185">indicted</TOKEN>
<TOKEN end_char="6195" id="token-39-19" morph="none" pos="word" start_char="6194">on</TOKEN>
<TOKEN end_char="6203" id="token-39-20" morph="none" pos="word" start_char="6197">charges</TOKEN>
<TOKEN end_char="6208" id="token-39-21" morph="none" pos="word" start_char="6205">that</TOKEN>
<TOKEN end_char="6214" id="token-39-22" morph="none" pos="word" start_char="6210">allow</TOKEN>
<TOKEN end_char="6226" id="token-39-23" morph="none" pos="word" start_char="6216">authorities</TOKEN>
<TOKEN end_char="6229" id="token-39-24" morph="none" pos="word" start_char="6228">to</TOKEN>
<TOKEN end_char="6238" id="token-39-25" morph="none" pos="word" start_char="6231">imprison</TOKEN>
<TOKEN end_char="6242" id="token-39-26" morph="none" pos="word" start_char="6240">her</TOKEN>
<TOKEN end_char="6246" id="token-39-27" morph="none" pos="word" start_char="6244">for</TOKEN>
<TOKEN end_char="6251" id="token-39-28" morph="none" pos="word" start_char="6248">five</TOKEN>
<TOKEN end_char="6257" id="token-39-29" morph="none" pos="word" start_char="6253">years</TOKEN>
<TOKEN end_char="6258" id="token-39-30" morph="none" pos="punct" start_char="6258">.</TOKEN>
</SEG>
<SEG end_char="6369" id="segment-40" start_char="6260">
<ORIGINAL_TEXT>Fellow citizen journalists Chen Qiushi, Li Zehua, and Fang Bin were also detained for their coverage of Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="6265" id="token-40-0" morph="none" pos="word" start_char="6260">Fellow</TOKEN>
<TOKEN end_char="6273" id="token-40-1" morph="none" pos="word" start_char="6267">citizen</TOKEN>
<TOKEN end_char="6285" id="token-40-2" morph="none" pos="word" start_char="6275">journalists</TOKEN>
<TOKEN end_char="6290" id="token-40-3" morph="none" pos="word" start_char="6287">Chen</TOKEN>
<TOKEN end_char="6297" id="token-40-4" morph="none" pos="word" start_char="6292">Qiushi</TOKEN>
<TOKEN end_char="6298" id="token-40-5" morph="none" pos="punct" start_char="6298">,</TOKEN>
<TOKEN end_char="6301" id="token-40-6" morph="none" pos="word" start_char="6300">Li</TOKEN>
<TOKEN end_char="6307" id="token-40-7" morph="none" pos="word" start_char="6303">Zehua</TOKEN>
<TOKEN end_char="6308" id="token-40-8" morph="none" pos="punct" start_char="6308">,</TOKEN>
<TOKEN end_char="6312" id="token-40-9" morph="none" pos="word" start_char="6310">and</TOKEN>
<TOKEN end_char="6317" id="token-40-10" morph="none" pos="word" start_char="6314">Fang</TOKEN>
<TOKEN end_char="6321" id="token-40-11" morph="none" pos="word" start_char="6319">Bin</TOKEN>
<TOKEN end_char="6326" id="token-40-12" morph="none" pos="word" start_char="6323">were</TOKEN>
<TOKEN end_char="6331" id="token-40-13" morph="none" pos="word" start_char="6328">also</TOKEN>
<TOKEN end_char="6340" id="token-40-14" morph="none" pos="word" start_char="6333">detained</TOKEN>
<TOKEN end_char="6344" id="token-40-15" morph="none" pos="word" start_char="6342">for</TOKEN>
<TOKEN end_char="6350" id="token-40-16" morph="none" pos="word" start_char="6346">their</TOKEN>
<TOKEN end_char="6359" id="token-40-17" morph="none" pos="word" start_char="6352">coverage</TOKEN>
<TOKEN end_char="6362" id="token-40-18" morph="none" pos="word" start_char="6361">of</TOKEN>
<TOKEN end_char="6368" id="token-40-19" morph="none" pos="word" start_char="6364">Wuhan</TOKEN>
<TOKEN end_char="6369" id="token-40-20" morph="none" pos="punct" start_char="6369">.</TOKEN>
</SEG>
<SEG end_char="6443" id="segment-41" start_char="6371">
<ORIGINAL_TEXT>Meanwhile, Chinese authorities allowed other narratives to spread freely.</ORIGINAL_TEXT>
<TOKEN end_char="6379" id="token-41-0" morph="none" pos="word" start_char="6371">Meanwhile</TOKEN>
<TOKEN end_char="6380" id="token-41-1" morph="none" pos="punct" start_char="6380">,</TOKEN>
<TOKEN end_char="6388" id="token-41-2" morph="none" pos="word" start_char="6382">Chinese</TOKEN>
<TOKEN end_char="6400" id="token-41-3" morph="none" pos="word" start_char="6390">authorities</TOKEN>
<TOKEN end_char="6408" id="token-41-4" morph="none" pos="word" start_char="6402">allowed</TOKEN>
<TOKEN end_char="6414" id="token-41-5" morph="none" pos="word" start_char="6410">other</TOKEN>
<TOKEN end_char="6425" id="token-41-6" morph="none" pos="word" start_char="6416">narratives</TOKEN>
<TOKEN end_char="6428" id="token-41-7" morph="none" pos="word" start_char="6427">to</TOKEN>
<TOKEN end_char="6435" id="token-41-8" morph="none" pos="word" start_char="6430">spread</TOKEN>
<TOKEN end_char="6442" id="token-41-9" morph="none" pos="word" start_char="6437">freely</TOKEN>
<TOKEN end_char="6443" id="token-41-10" morph="none" pos="punct" start_char="6443">.</TOKEN>
</SEG>
<SEG end_char="6586" id="segment-42" start_char="6445">
<ORIGINAL_TEXT>At The Financial Times, Christian Shepherd covered a provocative speech that tied nationalism to revisionist histories of the crisis in Wuhan:</ORIGINAL_TEXT>
<TOKEN end_char="6446" id="token-42-0" morph="none" pos="word" start_char="6445">At</TOKEN>
<TOKEN end_char="6450" id="token-42-1" morph="none" pos="word" start_char="6448">The</TOKEN>
<TOKEN end_char="6460" id="token-42-2" morph="none" pos="word" start_char="6452">Financial</TOKEN>
<TOKEN end_char="6466" id="token-42-3" morph="none" pos="word" start_char="6462">Times</TOKEN>
<TOKEN end_char="6467" id="token-42-4" morph="none" pos="punct" start_char="6467">,</TOKEN>
<TOKEN end_char="6477" id="token-42-5" morph="none" pos="word" start_char="6469">Christian</TOKEN>
<TOKEN end_char="6486" id="token-42-6" morph="none" pos="word" start_char="6479">Shepherd</TOKEN>
<TOKEN end_char="6494" id="token-42-7" morph="none" pos="word" start_char="6488">covered</TOKEN>
<TOKEN end_char="6496" id="token-42-8" morph="none" pos="word" start_char="6496">a</TOKEN>
<TOKEN end_char="6508" id="token-42-9" morph="none" pos="word" start_char="6498">provocative</TOKEN>
<TOKEN end_char="6515" id="token-42-10" morph="none" pos="word" start_char="6510">speech</TOKEN>
<TOKEN end_char="6520" id="token-42-11" morph="none" pos="word" start_char="6517">that</TOKEN>
<TOKEN end_char="6525" id="token-42-12" morph="none" pos="word" start_char="6522">tied</TOKEN>
<TOKEN end_char="6537" id="token-42-13" morph="none" pos="word" start_char="6527">nationalism</TOKEN>
<TOKEN end_char="6540" id="token-42-14" morph="none" pos="word" start_char="6539">to</TOKEN>
<TOKEN end_char="6552" id="token-42-15" morph="none" pos="word" start_char="6542">revisionist</TOKEN>
<TOKEN end_char="6562" id="token-42-16" morph="none" pos="word" start_char="6554">histories</TOKEN>
<TOKEN end_char="6565" id="token-42-17" morph="none" pos="word" start_char="6564">of</TOKEN>
<TOKEN end_char="6569" id="token-42-18" morph="none" pos="word" start_char="6567">the</TOKEN>
<TOKEN end_char="6576" id="token-42-19" morph="none" pos="word" start_char="6571">crisis</TOKEN>
<TOKEN end_char="6579" id="token-42-20" morph="none" pos="word" start_char="6578">in</TOKEN>
<TOKEN end_char="6585" id="token-42-21" morph="none" pos="word" start_char="6581">Wuhan</TOKEN>
<TOKEN end_char="6586" id="token-42-22" morph="none" pos="punct" start_char="6586">:</TOKEN>
</SEG>
<SEG end_char="6783" id="segment-43" start_char="6589">
<ORIGINAL_TEXT>Li Yi, a nationalist commentator, told a conference in Shenzhen that, compared with the number of people who had died in the US, thousands of people dying in China was "the same as no one dying".</ORIGINAL_TEXT>
<TOKEN end_char="6590" id="token-43-0" morph="none" pos="word" start_char="6589">Li</TOKEN>
<TOKEN end_char="6593" id="token-43-1" morph="none" pos="word" start_char="6592">Yi</TOKEN>
<TOKEN end_char="6594" id="token-43-2" morph="none" pos="punct" start_char="6594">,</TOKEN>
<TOKEN end_char="6596" id="token-43-3" morph="none" pos="word" start_char="6596">a</TOKEN>
<TOKEN end_char="6608" id="token-43-4" morph="none" pos="word" start_char="6598">nationalist</TOKEN>
<TOKEN end_char="6620" id="token-43-5" morph="none" pos="word" start_char="6610">commentator</TOKEN>
<TOKEN end_char="6621" id="token-43-6" morph="none" pos="punct" start_char="6621">,</TOKEN>
<TOKEN end_char="6626" id="token-43-7" morph="none" pos="word" start_char="6623">told</TOKEN>
<TOKEN end_char="6628" id="token-43-8" morph="none" pos="word" start_char="6628">a</TOKEN>
<TOKEN end_char="6639" id="token-43-9" morph="none" pos="word" start_char="6630">conference</TOKEN>
<TOKEN end_char="6642" id="token-43-10" morph="none" pos="word" start_char="6641">in</TOKEN>
<TOKEN end_char="6651" id="token-43-11" morph="none" pos="word" start_char="6644">Shenzhen</TOKEN>
<TOKEN end_char="6656" id="token-43-12" morph="none" pos="word" start_char="6653">that</TOKEN>
<TOKEN end_char="6657" id="token-43-13" morph="none" pos="punct" start_char="6657">,</TOKEN>
<TOKEN end_char="6666" id="token-43-14" morph="none" pos="word" start_char="6659">compared</TOKEN>
<TOKEN end_char="6671" id="token-43-15" morph="none" pos="word" start_char="6668">with</TOKEN>
<TOKEN end_char="6675" id="token-43-16" morph="none" pos="word" start_char="6673">the</TOKEN>
<TOKEN end_char="6682" id="token-43-17" morph="none" pos="word" start_char="6677">number</TOKEN>
<TOKEN end_char="6685" id="token-43-18" morph="none" pos="word" start_char="6684">of</TOKEN>
<TOKEN end_char="6692" id="token-43-19" morph="none" pos="word" start_char="6687">people</TOKEN>
<TOKEN end_char="6696" id="token-43-20" morph="none" pos="word" start_char="6694">who</TOKEN>
<TOKEN end_char="6700" id="token-43-21" morph="none" pos="word" start_char="6698">had</TOKEN>
<TOKEN end_char="6705" id="token-43-22" morph="none" pos="word" start_char="6702">died</TOKEN>
<TOKEN end_char="6708" id="token-43-23" morph="none" pos="word" start_char="6707">in</TOKEN>
<TOKEN end_char="6712" id="token-43-24" morph="none" pos="word" start_char="6710">the</TOKEN>
<TOKEN end_char="6715" id="token-43-25" morph="none" pos="word" start_char="6714">US</TOKEN>
<TOKEN end_char="6716" id="token-43-26" morph="none" pos="punct" start_char="6716">,</TOKEN>
<TOKEN end_char="6726" id="token-43-27" morph="none" pos="word" start_char="6718">thousands</TOKEN>
<TOKEN end_char="6729" id="token-43-28" morph="none" pos="word" start_char="6728">of</TOKEN>
<TOKEN end_char="6736" id="token-43-29" morph="none" pos="word" start_char="6731">people</TOKEN>
<TOKEN end_char="6742" id="token-43-30" morph="none" pos="word" start_char="6738">dying</TOKEN>
<TOKEN end_char="6745" id="token-43-31" morph="none" pos="word" start_char="6744">in</TOKEN>
<TOKEN end_char="6751" id="token-43-32" morph="none" pos="word" start_char="6747">China</TOKEN>
<TOKEN end_char="6755" id="token-43-33" morph="none" pos="word" start_char="6753">was</TOKEN>
<TOKEN end_char="6757" id="token-43-34" morph="none" pos="punct" start_char="6757">"</TOKEN>
<TOKEN end_char="6760" id="token-43-35" morph="none" pos="word" start_char="6758">the</TOKEN>
<TOKEN end_char="6765" id="token-43-36" morph="none" pos="word" start_char="6762">same</TOKEN>
<TOKEN end_char="6768" id="token-43-37" morph="none" pos="word" start_char="6767">as</TOKEN>
<TOKEN end_char="6771" id="token-43-38" morph="none" pos="word" start_char="6770">no</TOKEN>
<TOKEN end_char="6775" id="token-43-39" morph="none" pos="word" start_char="6773">one</TOKEN>
<TOKEN end_char="6781" id="token-43-40" morph="none" pos="word" start_char="6777">dying</TOKEN>
<TOKEN end_char="6783" id="token-43-41" morph="none" pos="punct" start_char="6782">".</TOKEN>
</SEG>
<SEG end_char="7029" id="segment-44" start_char="6785">
<ORIGINAL_TEXT>Mr Li later defended himself against critics, writing on Weibo that the thrust of his speech was "patriotic" and had been "to extol the splendid success of China’s struggle against the epidemic, and to criticise the major failures of America’s".</ORIGINAL_TEXT>
<TOKEN end_char="6786" id="token-44-0" morph="none" pos="word" start_char="6785">Mr</TOKEN>
<TOKEN end_char="6789" id="token-44-1" morph="none" pos="word" start_char="6788">Li</TOKEN>
<TOKEN end_char="6795" id="token-44-2" morph="none" pos="word" start_char="6791">later</TOKEN>
<TOKEN end_char="6804" id="token-44-3" morph="none" pos="word" start_char="6797">defended</TOKEN>
<TOKEN end_char="6812" id="token-44-4" morph="none" pos="word" start_char="6806">himself</TOKEN>
<TOKEN end_char="6820" id="token-44-5" morph="none" pos="word" start_char="6814">against</TOKEN>
<TOKEN end_char="6828" id="token-44-6" morph="none" pos="word" start_char="6822">critics</TOKEN>
<TOKEN end_char="6829" id="token-44-7" morph="none" pos="punct" start_char="6829">,</TOKEN>
<TOKEN end_char="6837" id="token-44-8" morph="none" pos="word" start_char="6831">writing</TOKEN>
<TOKEN end_char="6840" id="token-44-9" morph="none" pos="word" start_char="6839">on</TOKEN>
<TOKEN end_char="6846" id="token-44-10" morph="none" pos="word" start_char="6842">Weibo</TOKEN>
<TOKEN end_char="6851" id="token-44-11" morph="none" pos="word" start_char="6848">that</TOKEN>
<TOKEN end_char="6855" id="token-44-12" morph="none" pos="word" start_char="6853">the</TOKEN>
<TOKEN end_char="6862" id="token-44-13" morph="none" pos="word" start_char="6857">thrust</TOKEN>
<TOKEN end_char="6865" id="token-44-14" morph="none" pos="word" start_char="6864">of</TOKEN>
<TOKEN end_char="6869" id="token-44-15" morph="none" pos="word" start_char="6867">his</TOKEN>
<TOKEN end_char="6876" id="token-44-16" morph="none" pos="word" start_char="6871">speech</TOKEN>
<TOKEN end_char="6880" id="token-44-17" morph="none" pos="word" start_char="6878">was</TOKEN>
<TOKEN end_char="6882" id="token-44-18" morph="none" pos="punct" start_char="6882">"</TOKEN>
<TOKEN end_char="6891" id="token-44-19" morph="none" pos="word" start_char="6883">patriotic</TOKEN>
<TOKEN end_char="6892" id="token-44-20" morph="none" pos="punct" start_char="6892">"</TOKEN>
<TOKEN end_char="6896" id="token-44-21" morph="none" pos="word" start_char="6894">and</TOKEN>
<TOKEN end_char="6900" id="token-44-22" morph="none" pos="word" start_char="6898">had</TOKEN>
<TOKEN end_char="6905" id="token-44-23" morph="none" pos="word" start_char="6902">been</TOKEN>
<TOKEN end_char="6907" id="token-44-24" morph="none" pos="punct" start_char="6907">"</TOKEN>
<TOKEN end_char="6909" id="token-44-25" morph="none" pos="word" start_char="6908">to</TOKEN>
<TOKEN end_char="6915" id="token-44-26" morph="none" pos="word" start_char="6911">extol</TOKEN>
<TOKEN end_char="6919" id="token-44-27" morph="none" pos="word" start_char="6917">the</TOKEN>
<TOKEN end_char="6928" id="token-44-28" morph="none" pos="word" start_char="6921">splendid</TOKEN>
<TOKEN end_char="6936" id="token-44-29" morph="none" pos="word" start_char="6930">success</TOKEN>
<TOKEN end_char="6939" id="token-44-30" morph="none" pos="word" start_char="6938">of</TOKEN>
<TOKEN end_char="6947" id="token-44-31" morph="none" pos="word" start_char="6941">China’s</TOKEN>
<TOKEN end_char="6956" id="token-44-32" morph="none" pos="word" start_char="6949">struggle</TOKEN>
<TOKEN end_char="6964" id="token-44-33" morph="none" pos="word" start_char="6958">against</TOKEN>
<TOKEN end_char="6968" id="token-44-34" morph="none" pos="word" start_char="6966">the</TOKEN>
<TOKEN end_char="6977" id="token-44-35" morph="none" pos="word" start_char="6970">epidemic</TOKEN>
<TOKEN end_char="6978" id="token-44-36" morph="none" pos="punct" start_char="6978">,</TOKEN>
<TOKEN end_char="6982" id="token-44-37" morph="none" pos="word" start_char="6980">and</TOKEN>
<TOKEN end_char="6985" id="token-44-38" morph="none" pos="word" start_char="6984">to</TOKEN>
<TOKEN end_char="6995" id="token-44-39" morph="none" pos="word" start_char="6987">criticise</TOKEN>
<TOKEN end_char="6999" id="token-44-40" morph="none" pos="word" start_char="6997">the</TOKEN>
<TOKEN end_char="7005" id="token-44-41" morph="none" pos="word" start_char="7001">major</TOKEN>
<TOKEN end_char="7014" id="token-44-42" morph="none" pos="word" start_char="7007">failures</TOKEN>
<TOKEN end_char="7017" id="token-44-43" morph="none" pos="word" start_char="7016">of</TOKEN>
<TOKEN end_char="7027" id="token-44-44" morph="none" pos="word" start_char="7019">America’s</TOKEN>
<TOKEN end_char="7029" id="token-44-45" morph="none" pos="punct" start_char="7028">".</TOKEN>
</SEG>
<SEG end_char="7066" id="segment-45" start_char="7031">
<ORIGINAL_TEXT>His comments have not been censored.</ORIGINAL_TEXT>
<TOKEN end_char="7033" id="token-45-0" morph="none" pos="word" start_char="7031">His</TOKEN>
<TOKEN end_char="7042" id="token-45-1" morph="none" pos="word" start_char="7035">comments</TOKEN>
<TOKEN end_char="7047" id="token-45-2" morph="none" pos="word" start_char="7044">have</TOKEN>
<TOKEN end_char="7051" id="token-45-3" morph="none" pos="word" start_char="7049">not</TOKEN>
<TOKEN end_char="7056" id="token-45-4" morph="none" pos="word" start_char="7053">been</TOKEN>
<TOKEN end_char="7065" id="token-45-5" morph="none" pos="word" start_char="7058">censored</TOKEN>
<TOKEN end_char="7066" id="token-45-6" morph="none" pos="punct" start_char="7066">.</TOKEN>
</SEG>
<SEG end_char="7075" id="segment-46" start_char="7068">
<ORIGINAL_TEXT>[Source]</ORIGINAL_TEXT>
<TOKEN end_char="7068" id="token-46-0" morph="none" pos="punct" start_char="7068">[</TOKEN>
<TOKEN end_char="7074" id="token-46-1" morph="none" pos="word" start_char="7069">Source</TOKEN>
<TOKEN end_char="7075" id="token-46-2" morph="none" pos="punct" start_char="7075">]</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
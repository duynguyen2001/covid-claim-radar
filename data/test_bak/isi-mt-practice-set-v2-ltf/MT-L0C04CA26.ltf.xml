<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CA26" lang="spa" raw_text_char_length="4498" raw_text_md5="5bd49d403ca7fc41b84540ed179021b2" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="95" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Evidence that the COVID-19 virus existed in March 2019 would be ‘highly surprising’ says expert</ORIGINAL_TEXT>
<TOKEN end_char="8" id="token-0-0" morph="none" pos="word" start_char="1">Evidence</TOKEN>
<TOKEN end_char="13" id="token-0-1" morph="none" pos="word" start_char="10">that</TOKEN>
<TOKEN end_char="17" id="token-0-2" morph="none" pos="word" start_char="15">the</TOKEN>
<TOKEN end_char="26" id="token-0-3" morph="none" pos="unknown" start_char="19">COVID-19</TOKEN>
<TOKEN end_char="32" id="token-0-4" morph="none" pos="word" start_char="28">virus</TOKEN>
<TOKEN end_char="40" id="token-0-5" morph="none" pos="word" start_char="34">existed</TOKEN>
<TOKEN end_char="43" id="token-0-6" morph="none" pos="word" start_char="42">in</TOKEN>
<TOKEN end_char="49" id="token-0-7" morph="none" pos="word" start_char="45">March</TOKEN>
<TOKEN end_char="54" id="token-0-8" morph="none" pos="word" start_char="51">2019</TOKEN>
<TOKEN end_char="60" id="token-0-9" morph="none" pos="word" start_char="56">would</TOKEN>
<TOKEN end_char="63" id="token-0-10" morph="none" pos="word" start_char="62">be</TOKEN>
<TOKEN end_char="65" id="token-0-11" morph="none" pos="punct" start_char="65">‘</TOKEN>
<TOKEN end_char="71" id="token-0-12" morph="none" pos="word" start_char="66">highly</TOKEN>
<TOKEN end_char="82" id="token-0-13" morph="none" pos="word" start_char="73">surprising</TOKEN>
<TOKEN end_char="83" id="token-0-14" morph="none" pos="punct" start_char="83">’</TOKEN>
<TOKEN end_char="88" id="token-0-15" morph="none" pos="word" start_char="85">says</TOKEN>
<TOKEN end_char="95" id="token-0-16" morph="none" pos="word" start_char="90">expert</TOKEN>
</SEG>
<SEG end_char="211" id="segment-1" start_char="99">
<ORIGINAL_TEXT>Earlier this month, an Oxford University professor claimed that the coronavirus may not have originated in China.</ORIGINAL_TEXT>
<TOKEN end_char="105" id="token-1-0" morph="none" pos="word" start_char="99">Earlier</TOKEN>
<TOKEN end_char="110" id="token-1-1" morph="none" pos="word" start_char="107">this</TOKEN>
<TOKEN end_char="116" id="token-1-2" morph="none" pos="word" start_char="112">month</TOKEN>
<TOKEN end_char="117" id="token-1-3" morph="none" pos="punct" start_char="117">,</TOKEN>
<TOKEN end_char="120" id="token-1-4" morph="none" pos="word" start_char="119">an</TOKEN>
<TOKEN end_char="127" id="token-1-5" morph="none" pos="word" start_char="122">Oxford</TOKEN>
<TOKEN end_char="138" id="token-1-6" morph="none" pos="word" start_char="129">University</TOKEN>
<TOKEN end_char="148" id="token-1-7" morph="none" pos="word" start_char="140">professor</TOKEN>
<TOKEN end_char="156" id="token-1-8" morph="none" pos="word" start_char="150">claimed</TOKEN>
<TOKEN end_char="161" id="token-1-9" morph="none" pos="word" start_char="158">that</TOKEN>
<TOKEN end_char="165" id="token-1-10" morph="none" pos="word" start_char="163">the</TOKEN>
<TOKEN end_char="177" id="token-1-11" morph="none" pos="word" start_char="167">coronavirus</TOKEN>
<TOKEN end_char="181" id="token-1-12" morph="none" pos="word" start_char="179">may</TOKEN>
<TOKEN end_char="185" id="token-1-13" morph="none" pos="word" start_char="183">not</TOKEN>
<TOKEN end_char="190" id="token-1-14" morph="none" pos="word" start_char="187">have</TOKEN>
<TOKEN end_char="201" id="token-1-15" morph="none" pos="word" start_char="192">originated</TOKEN>
<TOKEN end_char="204" id="token-1-16" morph="none" pos="word" start_char="203">in</TOKEN>
<TOKEN end_char="210" id="token-1-17" morph="none" pos="word" start_char="206">China</TOKEN>
<TOKEN end_char="211" id="token-1-18" morph="none" pos="punct" start_char="211">.</TOKEN>
</SEG>
<SEG end_char="368" id="segment-2" start_char="213">
<ORIGINAL_TEXT>Instead, Dr Tom Jefferson suggested that SARS-CoV-2 could have been lying dormant across the world until emerging under favourable environmental conditions.</ORIGINAL_TEXT>
<TOKEN end_char="219" id="token-2-0" morph="none" pos="word" start_char="213">Instead</TOKEN>
<TOKEN end_char="220" id="token-2-1" morph="none" pos="punct" start_char="220">,</TOKEN>
<TOKEN end_char="223" id="token-2-2" morph="none" pos="word" start_char="222">Dr</TOKEN>
<TOKEN end_char="227" id="token-2-3" morph="none" pos="word" start_char="225">Tom</TOKEN>
<TOKEN end_char="237" id="token-2-4" morph="none" pos="word" start_char="229">Jefferson</TOKEN>
<TOKEN end_char="247" id="token-2-5" morph="none" pos="word" start_char="239">suggested</TOKEN>
<TOKEN end_char="252" id="token-2-6" morph="none" pos="word" start_char="249">that</TOKEN>
<TOKEN end_char="263" id="token-2-7" morph="none" pos="unknown" start_char="254">SARS-CoV-2</TOKEN>
<TOKEN end_char="269" id="token-2-8" morph="none" pos="word" start_char="265">could</TOKEN>
<TOKEN end_char="274" id="token-2-9" morph="none" pos="word" start_char="271">have</TOKEN>
<TOKEN end_char="279" id="token-2-10" morph="none" pos="word" start_char="276">been</TOKEN>
<TOKEN end_char="285" id="token-2-11" morph="none" pos="word" start_char="281">lying</TOKEN>
<TOKEN end_char="293" id="token-2-12" morph="none" pos="word" start_char="287">dormant</TOKEN>
<TOKEN end_char="300" id="token-2-13" morph="none" pos="word" start_char="295">across</TOKEN>
<TOKEN end_char="304" id="token-2-14" morph="none" pos="word" start_char="302">the</TOKEN>
<TOKEN end_char="310" id="token-2-15" morph="none" pos="word" start_char="306">world</TOKEN>
<TOKEN end_char="316" id="token-2-16" morph="none" pos="word" start_char="312">until</TOKEN>
<TOKEN end_char="325" id="token-2-17" morph="none" pos="word" start_char="318">emerging</TOKEN>
<TOKEN end_char="331" id="token-2-18" morph="none" pos="word" start_char="327">under</TOKEN>
<TOKEN end_char="342" id="token-2-19" morph="none" pos="word" start_char="333">favourable</TOKEN>
<TOKEN end_char="356" id="token-2-20" morph="none" pos="word" start_char="344">environmental</TOKEN>
<TOKEN end_char="367" id="token-2-21" morph="none" pos="word" start_char="358">conditions</TOKEN>
<TOKEN end_char="368" id="token-2-22" morph="none" pos="punct" start_char="368">.</TOKEN>
</SEG>
<SEG end_char="546" id="segment-3" start_char="371">
<ORIGINAL_TEXT>In a recent interview Dr Jefferson pointed to studies that found traces of COVID-19 in sewage samples from Spain, Italy and Brazil all of which pre-date its discovery in China.</ORIGINAL_TEXT>
<TOKEN end_char="372" id="token-3-0" morph="none" pos="word" start_char="371">In</TOKEN>
<TOKEN end_char="374" id="token-3-1" morph="none" pos="word" start_char="374">a</TOKEN>
<TOKEN end_char="381" id="token-3-2" morph="none" pos="word" start_char="376">recent</TOKEN>
<TOKEN end_char="391" id="token-3-3" morph="none" pos="word" start_char="383">interview</TOKEN>
<TOKEN end_char="394" id="token-3-4" morph="none" pos="word" start_char="393">Dr</TOKEN>
<TOKEN end_char="404" id="token-3-5" morph="none" pos="word" start_char="396">Jefferson</TOKEN>
<TOKEN end_char="412" id="token-3-6" morph="none" pos="word" start_char="406">pointed</TOKEN>
<TOKEN end_char="415" id="token-3-7" morph="none" pos="word" start_char="414">to</TOKEN>
<TOKEN end_char="423" id="token-3-8" morph="none" pos="word" start_char="417">studies</TOKEN>
<TOKEN end_char="428" id="token-3-9" morph="none" pos="word" start_char="425">that</TOKEN>
<TOKEN end_char="434" id="token-3-10" morph="none" pos="word" start_char="430">found</TOKEN>
<TOKEN end_char="441" id="token-3-11" morph="none" pos="word" start_char="436">traces</TOKEN>
<TOKEN end_char="444" id="token-3-12" morph="none" pos="word" start_char="443">of</TOKEN>
<TOKEN end_char="453" id="token-3-13" morph="none" pos="unknown" start_char="446">COVID-19</TOKEN>
<TOKEN end_char="456" id="token-3-14" morph="none" pos="word" start_char="455">in</TOKEN>
<TOKEN end_char="463" id="token-3-15" morph="none" pos="word" start_char="458">sewage</TOKEN>
<TOKEN end_char="471" id="token-3-16" morph="none" pos="word" start_char="465">samples</TOKEN>
<TOKEN end_char="476" id="token-3-17" morph="none" pos="word" start_char="473">from</TOKEN>
<TOKEN end_char="482" id="token-3-18" morph="none" pos="word" start_char="478">Spain</TOKEN>
<TOKEN end_char="483" id="token-3-19" morph="none" pos="punct" start_char="483">,</TOKEN>
<TOKEN end_char="489" id="token-3-20" morph="none" pos="word" start_char="485">Italy</TOKEN>
<TOKEN end_char="493" id="token-3-21" morph="none" pos="word" start_char="491">and</TOKEN>
<TOKEN end_char="500" id="token-3-22" morph="none" pos="word" start_char="495">Brazil</TOKEN>
<TOKEN end_char="504" id="token-3-23" morph="none" pos="word" start_char="502">all</TOKEN>
<TOKEN end_char="507" id="token-3-24" morph="none" pos="word" start_char="506">of</TOKEN>
<TOKEN end_char="513" id="token-3-25" morph="none" pos="word" start_char="509">which</TOKEN>
<TOKEN end_char="522" id="token-3-26" morph="none" pos="unknown" start_char="515">pre-date</TOKEN>
<TOKEN end_char="526" id="token-3-27" morph="none" pos="word" start_char="524">its</TOKEN>
<TOKEN end_char="536" id="token-3-28" morph="none" pos="word" start_char="528">discovery</TOKEN>
<TOKEN end_char="539" id="token-3-29" morph="none" pos="word" start_char="538">in</TOKEN>
<TOKEN end_char="545" id="token-3-30" morph="none" pos="word" start_char="541">China</TOKEN>
<TOKEN end_char="546" id="token-3-31" morph="none" pos="punct" start_char="546">.</TOKEN>
</SEG>
<SEG end_char="724" id="segment-4" start_char="548">
<ORIGINAL_TEXT>This included one preprint study, which has not been peer reviewed, that claims to have found the presence of SARS-CoV-2 genomes in a Barcelona sewage sample from 12 March 2019.</ORIGINAL_TEXT>
<TOKEN end_char="551" id="token-4-0" morph="none" pos="word" start_char="548">This</TOKEN>
<TOKEN end_char="560" id="token-4-1" morph="none" pos="word" start_char="553">included</TOKEN>
<TOKEN end_char="564" id="token-4-2" morph="none" pos="word" start_char="562">one</TOKEN>
<TOKEN end_char="573" id="token-4-3" morph="none" pos="word" start_char="566">preprint</TOKEN>
<TOKEN end_char="579" id="token-4-4" morph="none" pos="word" start_char="575">study</TOKEN>
<TOKEN end_char="580" id="token-4-5" morph="none" pos="punct" start_char="580">,</TOKEN>
<TOKEN end_char="586" id="token-4-6" morph="none" pos="word" start_char="582">which</TOKEN>
<TOKEN end_char="590" id="token-4-7" morph="none" pos="word" start_char="588">has</TOKEN>
<TOKEN end_char="594" id="token-4-8" morph="none" pos="word" start_char="592">not</TOKEN>
<TOKEN end_char="599" id="token-4-9" morph="none" pos="word" start_char="596">been</TOKEN>
<TOKEN end_char="604" id="token-4-10" morph="none" pos="word" start_char="601">peer</TOKEN>
<TOKEN end_char="613" id="token-4-11" morph="none" pos="word" start_char="606">reviewed</TOKEN>
<TOKEN end_char="614" id="token-4-12" morph="none" pos="punct" start_char="614">,</TOKEN>
<TOKEN end_char="619" id="token-4-13" morph="none" pos="word" start_char="616">that</TOKEN>
<TOKEN end_char="626" id="token-4-14" morph="none" pos="word" start_char="621">claims</TOKEN>
<TOKEN end_char="629" id="token-4-15" morph="none" pos="word" start_char="628">to</TOKEN>
<TOKEN end_char="634" id="token-4-16" morph="none" pos="word" start_char="631">have</TOKEN>
<TOKEN end_char="640" id="token-4-17" morph="none" pos="word" start_char="636">found</TOKEN>
<TOKEN end_char="644" id="token-4-18" morph="none" pos="word" start_char="642">the</TOKEN>
<TOKEN end_char="653" id="token-4-19" morph="none" pos="word" start_char="646">presence</TOKEN>
<TOKEN end_char="656" id="token-4-20" morph="none" pos="word" start_char="655">of</TOKEN>
<TOKEN end_char="667" id="token-4-21" morph="none" pos="unknown" start_char="658">SARS-CoV-2</TOKEN>
<TOKEN end_char="675" id="token-4-22" morph="none" pos="word" start_char="669">genomes</TOKEN>
<TOKEN end_char="678" id="token-4-23" morph="none" pos="word" start_char="677">in</TOKEN>
<TOKEN end_char="680" id="token-4-24" morph="none" pos="word" start_char="680">a</TOKEN>
<TOKEN end_char="690" id="token-4-25" morph="none" pos="word" start_char="682">Barcelona</TOKEN>
<TOKEN end_char="697" id="token-4-26" morph="none" pos="word" start_char="692">sewage</TOKEN>
<TOKEN end_char="704" id="token-4-27" morph="none" pos="word" start_char="699">sample</TOKEN>
<TOKEN end_char="709" id="token-4-28" morph="none" pos="word" start_char="706">from</TOKEN>
<TOKEN end_char="712" id="token-4-29" morph="none" pos="word" start_char="711">12</TOKEN>
<TOKEN end_char="718" id="token-4-30" morph="none" pos="word" start_char="714">March</TOKEN>
<TOKEN end_char="723" id="token-4-31" morph="none" pos="word" start_char="720">2019</TOKEN>
<TOKEN end_char="724" id="token-4-32" morph="none" pos="punct" start_char="724">.</TOKEN>
</SEG>
<SEG end_char="750" id="segment-5" start_char="727">
<ORIGINAL_TEXT>Can viruses lie dormant?</ORIGINAL_TEXT>
<TOKEN end_char="729" id="token-5-0" morph="none" pos="word" start_char="727">Can</TOKEN>
<TOKEN end_char="737" id="token-5-1" morph="none" pos="word" start_char="731">viruses</TOKEN>
<TOKEN end_char="741" id="token-5-2" morph="none" pos="word" start_char="739">lie</TOKEN>
<TOKEN end_char="749" id="token-5-3" morph="none" pos="word" start_char="743">dormant</TOKEN>
<TOKEN end_char="750" id="token-5-4" morph="none" pos="punct" start_char="750">?</TOKEN>
<TRANSLATED_TEXT>Kan virussen slammen?</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="965" id="segment-6" start_char="754">
<ORIGINAL_TEXT>"There are some viruses (such as herpes viruses) that can infect cells, establish a latent infection and then be reactivated at a later date," explains Dr Jeremy Rossman, a virologist from the University of Kent.</ORIGINAL_TEXT>
<TOKEN end_char="754" id="token-6-0" morph="none" pos="punct" start_char="754">"</TOKEN>
<TOKEN end_char="759" id="token-6-1" morph="none" pos="word" start_char="755">There</TOKEN>
<TOKEN end_char="763" id="token-6-2" morph="none" pos="word" start_char="761">are</TOKEN>
<TOKEN end_char="768" id="token-6-3" morph="none" pos="word" start_char="765">some</TOKEN>
<TOKEN end_char="776" id="token-6-4" morph="none" pos="word" start_char="770">viruses</TOKEN>
<TOKEN end_char="778" id="token-6-5" morph="none" pos="punct" start_char="778">(</TOKEN>
<TOKEN end_char="782" id="token-6-6" morph="none" pos="word" start_char="779">such</TOKEN>
<TOKEN end_char="785" id="token-6-7" morph="none" pos="word" start_char="784">as</TOKEN>
<TOKEN end_char="792" id="token-6-8" morph="none" pos="word" start_char="787">herpes</TOKEN>
<TOKEN end_char="800" id="token-6-9" morph="none" pos="word" start_char="794">viruses</TOKEN>
<TOKEN end_char="801" id="token-6-10" morph="none" pos="punct" start_char="801">)</TOKEN>
<TOKEN end_char="806" id="token-6-11" morph="none" pos="word" start_char="803">that</TOKEN>
<TOKEN end_char="810" id="token-6-12" morph="none" pos="word" start_char="808">can</TOKEN>
<TOKEN end_char="817" id="token-6-13" morph="none" pos="word" start_char="812">infect</TOKEN>
<TOKEN end_char="823" id="token-6-14" morph="none" pos="word" start_char="819">cells</TOKEN>
<TOKEN end_char="824" id="token-6-15" morph="none" pos="punct" start_char="824">,</TOKEN>
<TOKEN end_char="834" id="token-6-16" morph="none" pos="word" start_char="826">establish</TOKEN>
<TOKEN end_char="836" id="token-6-17" morph="none" pos="word" start_char="836">a</TOKEN>
<TOKEN end_char="843" id="token-6-18" morph="none" pos="word" start_char="838">latent</TOKEN>
<TOKEN end_char="853" id="token-6-19" morph="none" pos="word" start_char="845">infection</TOKEN>
<TOKEN end_char="857" id="token-6-20" morph="none" pos="word" start_char="855">and</TOKEN>
<TOKEN end_char="862" id="token-6-21" morph="none" pos="word" start_char="859">then</TOKEN>
<TOKEN end_char="865" id="token-6-22" morph="none" pos="word" start_char="864">be</TOKEN>
<TOKEN end_char="877" id="token-6-23" morph="none" pos="word" start_char="867">reactivated</TOKEN>
<TOKEN end_char="880" id="token-6-24" morph="none" pos="word" start_char="879">at</TOKEN>
<TOKEN end_char="882" id="token-6-25" morph="none" pos="word" start_char="882">a</TOKEN>
<TOKEN end_char="888" id="token-6-26" morph="none" pos="word" start_char="884">later</TOKEN>
<TOKEN end_char="893" id="token-6-27" morph="none" pos="word" start_char="890">date</TOKEN>
<TOKEN end_char="895" id="token-6-28" morph="none" pos="punct" start_char="894">,"</TOKEN>
<TOKEN end_char="904" id="token-6-29" morph="none" pos="word" start_char="897">explains</TOKEN>
<TOKEN end_char="907" id="token-6-30" morph="none" pos="word" start_char="906">Dr</TOKEN>
<TOKEN end_char="914" id="token-6-31" morph="none" pos="word" start_char="909">Jeremy</TOKEN>
<TOKEN end_char="922" id="token-6-32" morph="none" pos="word" start_char="916">Rossman</TOKEN>
<TOKEN end_char="923" id="token-6-33" morph="none" pos="punct" start_char="923">,</TOKEN>
<TOKEN end_char="925" id="token-6-34" morph="none" pos="word" start_char="925">a</TOKEN>
<TOKEN end_char="936" id="token-6-35" morph="none" pos="word" start_char="927">virologist</TOKEN>
<TOKEN end_char="941" id="token-6-36" morph="none" pos="word" start_char="938">from</TOKEN>
<TOKEN end_char="945" id="token-6-37" morph="none" pos="word" start_char="943">the</TOKEN>
<TOKEN end_char="956" id="token-6-38" morph="none" pos="word" start_char="947">University</TOKEN>
<TOKEN end_char="959" id="token-6-39" morph="none" pos="word" start_char="958">of</TOKEN>
<TOKEN end_char="964" id="token-6-40" morph="none" pos="word" start_char="961">Kent</TOKEN>
<TOKEN end_char="965" id="token-6-41" morph="none" pos="punct" start_char="965">.</TOKEN>
</SEG>
<SEG end_char="1044" id="segment-7" start_char="967">
<ORIGINAL_TEXT>"However, it is unlikely that coronaviruses establish any latency or dormancy.</ORIGINAL_TEXT>
<TOKEN end_char="967" id="token-7-0" morph="none" pos="punct" start_char="967">"</TOKEN>
<TOKEN end_char="974" id="token-7-1" morph="none" pos="word" start_char="968">However</TOKEN>
<TOKEN end_char="975" id="token-7-2" morph="none" pos="punct" start_char="975">,</TOKEN>
<TOKEN end_char="978" id="token-7-3" morph="none" pos="word" start_char="977">it</TOKEN>
<TOKEN end_char="981" id="token-7-4" morph="none" pos="word" start_char="980">is</TOKEN>
<TOKEN end_char="990" id="token-7-5" morph="none" pos="word" start_char="983">unlikely</TOKEN>
<TOKEN end_char="995" id="token-7-6" morph="none" pos="word" start_char="992">that</TOKEN>
<TOKEN end_char="1009" id="token-7-7" morph="none" pos="word" start_char="997">coronaviruses</TOKEN>
<TOKEN end_char="1019" id="token-7-8" morph="none" pos="word" start_char="1011">establish</TOKEN>
<TOKEN end_char="1023" id="token-7-9" morph="none" pos="word" start_char="1021">any</TOKEN>
<TOKEN end_char="1031" id="token-7-10" morph="none" pos="word" start_char="1025">latency</TOKEN>
<TOKEN end_char="1034" id="token-7-11" morph="none" pos="word" start_char="1033">or</TOKEN>
<TOKEN end_char="1043" id="token-7-12" morph="none" pos="word" start_char="1036">dormancy</TOKEN>
<TOKEN end_char="1044" id="token-7-13" morph="none" pos="punct" start_char="1044">.</TOKEN>
</SEG>
<SEG end_char="1145" id="segment-8" start_char="1047">
<ORIGINAL_TEXT>"There is no evidence that SARS-CoV-2 can lie dormant or be activated by environmental conditions."</ORIGINAL_TEXT>
<TOKEN end_char="1047" id="token-8-0" morph="none" pos="punct" start_char="1047">"</TOKEN>
<TOKEN end_char="1052" id="token-8-1" morph="none" pos="word" start_char="1048">There</TOKEN>
<TOKEN end_char="1055" id="token-8-2" morph="none" pos="word" start_char="1054">is</TOKEN>
<TOKEN end_char="1058" id="token-8-3" morph="none" pos="word" start_char="1057">no</TOKEN>
<TOKEN end_char="1067" id="token-8-4" morph="none" pos="word" start_char="1060">evidence</TOKEN>
<TOKEN end_char="1072" id="token-8-5" morph="none" pos="word" start_char="1069">that</TOKEN>
<TOKEN end_char="1083" id="token-8-6" morph="none" pos="unknown" start_char="1074">SARS-CoV-2</TOKEN>
<TOKEN end_char="1087" id="token-8-7" morph="none" pos="word" start_char="1085">can</TOKEN>
<TOKEN end_char="1091" id="token-8-8" morph="none" pos="word" start_char="1089">lie</TOKEN>
<TOKEN end_char="1099" id="token-8-9" morph="none" pos="word" start_char="1093">dormant</TOKEN>
<TOKEN end_char="1102" id="token-8-10" morph="none" pos="word" start_char="1101">or</TOKEN>
<TOKEN end_char="1105" id="token-8-11" morph="none" pos="word" start_char="1104">be</TOKEN>
<TOKEN end_char="1115" id="token-8-12" morph="none" pos="word" start_char="1107">activated</TOKEN>
<TOKEN end_char="1118" id="token-8-13" morph="none" pos="word" start_char="1117">by</TOKEN>
<TOKEN end_char="1132" id="token-8-14" morph="none" pos="word" start_char="1120">environmental</TOKEN>
<TOKEN end_char="1143" id="token-8-15" morph="none" pos="word" start_char="1134">conditions</TOKEN>
<TOKEN end_char="1145" id="token-8-16" morph="none" pos="punct" start_char="1144">."</TOKEN>
</SEG>
<SEG end_char="1167" id="segment-9" start_char="1148">
<ORIGINAL_TEXT>In an interview with</ORIGINAL_TEXT>
<TOKEN end_char="1149" id="token-9-0" morph="none" pos="word" start_char="1148">In</TOKEN>
<TOKEN end_char="1152" id="token-9-1" morph="none" pos="word" start_char="1151">an</TOKEN>
<TOKEN end_char="1162" id="token-9-2" morph="none" pos="word" start_char="1154">interview</TOKEN>
<TOKEN end_char="1167" id="token-9-3" morph="none" pos="word" start_char="1164">with</TOKEN>
</SEG>
<SEG end_char="1188" id="segment-10" start_char="1170">
<ORIGINAL_TEXT>The Daily Telegraph</ORIGINAL_TEXT>
<TOKEN end_char="1172" id="token-10-0" morph="none" pos="word" start_char="1170">The</TOKEN>
<TOKEN end_char="1178" id="token-10-1" morph="none" pos="word" start_char="1174">Daily</TOKEN>
<TOKEN end_char="1188" id="token-10-2" morph="none" pos="word" start_char="1180">Telegraph</TOKEN>
</SEG>
<SEG end_char="1330" id="segment-11" start_char="1191">
<ORIGINAL_TEXT>, Dr Jefferson said of the studies finding SARS-CoV-2 in sewage, "the explanation could only be that these agents don’t come or go anywhere.</ORIGINAL_TEXT>
<TOKEN end_char="1191" id="token-11-0" morph="none" pos="punct" start_char="1191">,</TOKEN>
<TOKEN end_char="1194" id="token-11-1" morph="none" pos="word" start_char="1193">Dr</TOKEN>
<TOKEN end_char="1204" id="token-11-2" morph="none" pos="word" start_char="1196">Jefferson</TOKEN>
<TOKEN end_char="1209" id="token-11-3" morph="none" pos="word" start_char="1206">said</TOKEN>
<TOKEN end_char="1212" id="token-11-4" morph="none" pos="word" start_char="1211">of</TOKEN>
<TOKEN end_char="1216" id="token-11-5" morph="none" pos="word" start_char="1214">the</TOKEN>
<TOKEN end_char="1224" id="token-11-6" morph="none" pos="word" start_char="1218">studies</TOKEN>
<TOKEN end_char="1232" id="token-11-7" morph="none" pos="word" start_char="1226">finding</TOKEN>
<TOKEN end_char="1243" id="token-11-8" morph="none" pos="unknown" start_char="1234">SARS-CoV-2</TOKEN>
<TOKEN end_char="1246" id="token-11-9" morph="none" pos="word" start_char="1245">in</TOKEN>
<TOKEN end_char="1253" id="token-11-10" morph="none" pos="word" start_char="1248">sewage</TOKEN>
<TOKEN end_char="1254" id="token-11-11" morph="none" pos="punct" start_char="1254">,</TOKEN>
<TOKEN end_char="1256" id="token-11-12" morph="none" pos="punct" start_char="1256">"</TOKEN>
<TOKEN end_char="1259" id="token-11-13" morph="none" pos="word" start_char="1257">the</TOKEN>
<TOKEN end_char="1271" id="token-11-14" morph="none" pos="word" start_char="1261">explanation</TOKEN>
<TOKEN end_char="1277" id="token-11-15" morph="none" pos="word" start_char="1273">could</TOKEN>
<TOKEN end_char="1282" id="token-11-16" morph="none" pos="word" start_char="1279">only</TOKEN>
<TOKEN end_char="1285" id="token-11-17" morph="none" pos="word" start_char="1284">be</TOKEN>
<TOKEN end_char="1290" id="token-11-18" morph="none" pos="word" start_char="1287">that</TOKEN>
<TOKEN end_char="1296" id="token-11-19" morph="none" pos="word" start_char="1292">these</TOKEN>
<TOKEN end_char="1303" id="token-11-20" morph="none" pos="word" start_char="1298">agents</TOKEN>
<TOKEN end_char="1309" id="token-11-21" morph="none" pos="word" start_char="1305">don’t</TOKEN>
<TOKEN end_char="1314" id="token-11-22" morph="none" pos="word" start_char="1311">come</TOKEN>
<TOKEN end_char="1317" id="token-11-23" morph="none" pos="word" start_char="1316">or</TOKEN>
<TOKEN end_char="1320" id="token-11-24" morph="none" pos="word" start_char="1319">go</TOKEN>
<TOKEN end_char="1329" id="token-11-25" morph="none" pos="word" start_char="1322">anywhere</TOKEN>
<TOKEN end_char="1330" id="token-11-26" morph="none" pos="punct" start_char="1330">.</TOKEN>
</SEG>
<SEG end_char="1380" id="segment-12" start_char="1332">
<ORIGINAL_TEXT>They are always here and something ignites them."</ORIGINAL_TEXT>
<TOKEN end_char="1335" id="token-12-0" morph="none" pos="word" start_char="1332">They</TOKEN>
<TOKEN end_char="1339" id="token-12-1" morph="none" pos="word" start_char="1337">are</TOKEN>
<TOKEN end_char="1346" id="token-12-2" morph="none" pos="word" start_char="1341">always</TOKEN>
<TOKEN end_char="1351" id="token-12-3" morph="none" pos="word" start_char="1348">here</TOKEN>
<TOKEN end_char="1355" id="token-12-4" morph="none" pos="word" start_char="1353">and</TOKEN>
<TOKEN end_char="1365" id="token-12-5" morph="none" pos="word" start_char="1357">something</TOKEN>
<TOKEN end_char="1373" id="token-12-6" morph="none" pos="word" start_char="1367">ignites</TOKEN>
<TOKEN end_char="1378" id="token-12-7" morph="none" pos="word" start_char="1375">them</TOKEN>
<TOKEN end_char="1380" id="token-12-8" morph="none" pos="punct" start_char="1379">."</TOKEN>
</SEG>
<SEG end_char="1395" id="segment-13" start_char="1382">
<ORIGINAL_TEXT>© Getty Images</ORIGINAL_TEXT>
<TOKEN end_char="1382" id="token-13-0" morph="none" pos="unknown" start_char="1382">©</TOKEN>
<TOKEN end_char="1388" id="token-13-1" morph="none" pos="word" start_char="1384">Getty</TOKEN>
<TOKEN end_char="1395" id="token-13-2" morph="none" pos="word" start_char="1390">Images</TOKEN>
</SEG>
<SEG end_char="1606" id="segment-14" start_char="1398">
<ORIGINAL_TEXT>Dr Rossman adds that "we know the SARS-CoV-2 virus rapidly degrades in the environment (such as on contaminated surfaces) and so it is very unlikely that the virus would be able to persist in the environment."</ORIGINAL_TEXT>
<TOKEN end_char="1399" id="token-14-0" morph="none" pos="word" start_char="1398">Dr</TOKEN>
<TOKEN end_char="1407" id="token-14-1" morph="none" pos="word" start_char="1401">Rossman</TOKEN>
<TOKEN end_char="1412" id="token-14-2" morph="none" pos="word" start_char="1409">adds</TOKEN>
<TOKEN end_char="1417" id="token-14-3" morph="none" pos="word" start_char="1414">that</TOKEN>
<TOKEN end_char="1419" id="token-14-4" morph="none" pos="punct" start_char="1419">"</TOKEN>
<TOKEN end_char="1421" id="token-14-5" morph="none" pos="word" start_char="1420">we</TOKEN>
<TOKEN end_char="1426" id="token-14-6" morph="none" pos="word" start_char="1423">know</TOKEN>
<TOKEN end_char="1430" id="token-14-7" morph="none" pos="word" start_char="1428">the</TOKEN>
<TOKEN end_char="1441" id="token-14-8" morph="none" pos="unknown" start_char="1432">SARS-CoV-2</TOKEN>
<TOKEN end_char="1447" id="token-14-9" morph="none" pos="word" start_char="1443">virus</TOKEN>
<TOKEN end_char="1455" id="token-14-10" morph="none" pos="word" start_char="1449">rapidly</TOKEN>
<TOKEN end_char="1464" id="token-14-11" morph="none" pos="word" start_char="1457">degrades</TOKEN>
<TOKEN end_char="1467" id="token-14-12" morph="none" pos="word" start_char="1466">in</TOKEN>
<TOKEN end_char="1471" id="token-14-13" morph="none" pos="word" start_char="1469">the</TOKEN>
<TOKEN end_char="1483" id="token-14-14" morph="none" pos="word" start_char="1473">environment</TOKEN>
<TOKEN end_char="1485" id="token-14-15" morph="none" pos="punct" start_char="1485">(</TOKEN>
<TOKEN end_char="1489" id="token-14-16" morph="none" pos="word" start_char="1486">such</TOKEN>
<TOKEN end_char="1492" id="token-14-17" morph="none" pos="word" start_char="1491">as</TOKEN>
<TOKEN end_char="1495" id="token-14-18" morph="none" pos="word" start_char="1494">on</TOKEN>
<TOKEN end_char="1508" id="token-14-19" morph="none" pos="word" start_char="1497">contaminated</TOKEN>
<TOKEN end_char="1517" id="token-14-20" morph="none" pos="word" start_char="1510">surfaces</TOKEN>
<TOKEN end_char="1518" id="token-14-21" morph="none" pos="punct" start_char="1518">)</TOKEN>
<TOKEN end_char="1522" id="token-14-22" morph="none" pos="word" start_char="1520">and</TOKEN>
<TOKEN end_char="1525" id="token-14-23" morph="none" pos="word" start_char="1524">so</TOKEN>
<TOKEN end_char="1528" id="token-14-24" morph="none" pos="word" start_char="1527">it</TOKEN>
<TOKEN end_char="1531" id="token-14-25" morph="none" pos="word" start_char="1530">is</TOKEN>
<TOKEN end_char="1536" id="token-14-26" morph="none" pos="word" start_char="1533">very</TOKEN>
<TOKEN end_char="1545" id="token-14-27" morph="none" pos="word" start_char="1538">unlikely</TOKEN>
<TOKEN end_char="1550" id="token-14-28" morph="none" pos="word" start_char="1547">that</TOKEN>
<TOKEN end_char="1554" id="token-14-29" morph="none" pos="word" start_char="1552">the</TOKEN>
<TOKEN end_char="1560" id="token-14-30" morph="none" pos="word" start_char="1556">virus</TOKEN>
<TOKEN end_char="1566" id="token-14-31" morph="none" pos="word" start_char="1562">would</TOKEN>
<TOKEN end_char="1569" id="token-14-32" morph="none" pos="word" start_char="1568">be</TOKEN>
<TOKEN end_char="1574" id="token-14-33" morph="none" pos="word" start_char="1571">able</TOKEN>
<TOKEN end_char="1577" id="token-14-34" morph="none" pos="word" start_char="1576">to</TOKEN>
<TOKEN end_char="1585" id="token-14-35" morph="none" pos="word" start_char="1579">persist</TOKEN>
<TOKEN end_char="1588" id="token-14-36" morph="none" pos="word" start_char="1587">in</TOKEN>
<TOKEN end_char="1592" id="token-14-37" morph="none" pos="word" start_char="1590">the</TOKEN>
<TOKEN end_char="1604" id="token-14-38" morph="none" pos="word" start_char="1594">environment</TOKEN>
<TOKEN end_char="1606" id="token-14-39" morph="none" pos="punct" start_char="1605">."</TOKEN>
</SEG>
<SEG end_char="1656" id="segment-15" start_char="1609">
<ORIGINAL_TEXT>What about the virus genomes found in Barcelona?</ORIGINAL_TEXT>
<TOKEN end_char="1612" id="token-15-0" morph="none" pos="word" start_char="1609">What</TOKEN>
<TOKEN end_char="1618" id="token-15-1" morph="none" pos="word" start_char="1614">about</TOKEN>
<TOKEN end_char="1622" id="token-15-2" morph="none" pos="word" start_char="1620">the</TOKEN>
<TOKEN end_char="1628" id="token-15-3" morph="none" pos="word" start_char="1624">virus</TOKEN>
<TOKEN end_char="1636" id="token-15-4" morph="none" pos="word" start_char="1630">genomes</TOKEN>
<TOKEN end_char="1642" id="token-15-5" morph="none" pos="word" start_char="1638">found</TOKEN>
<TOKEN end_char="1645" id="token-15-6" morph="none" pos="word" start_char="1644">in</TOKEN>
<TOKEN end_char="1655" id="token-15-7" morph="none" pos="word" start_char="1647">Barcelona</TOKEN>
<TOKEN end_char="1656" id="token-15-8" morph="none" pos="punct" start_char="1656">?</TOKEN>
</SEG>
<SEG end_char="1789" id="segment-16" start_char="1660">
<ORIGINAL_TEXT>The only suggested evidence for very early presence of the virus comes from a pre-print study that has not yet been peer reviewed.</ORIGINAL_TEXT>
<TOKEN end_char="1662" id="token-16-0" morph="none" pos="word" start_char="1660">The</TOKEN>
<TOKEN end_char="1667" id="token-16-1" morph="none" pos="word" start_char="1664">only</TOKEN>
<TOKEN end_char="1677" id="token-16-2" morph="none" pos="word" start_char="1669">suggested</TOKEN>
<TOKEN end_char="1686" id="token-16-3" morph="none" pos="word" start_char="1679">evidence</TOKEN>
<TOKEN end_char="1690" id="token-16-4" morph="none" pos="word" start_char="1688">for</TOKEN>
<TOKEN end_char="1695" id="token-16-5" morph="none" pos="word" start_char="1692">very</TOKEN>
<TOKEN end_char="1701" id="token-16-6" morph="none" pos="word" start_char="1697">early</TOKEN>
<TOKEN end_char="1710" id="token-16-7" morph="none" pos="word" start_char="1703">presence</TOKEN>
<TOKEN end_char="1713" id="token-16-8" morph="none" pos="word" start_char="1712">of</TOKEN>
<TOKEN end_char="1717" id="token-16-9" morph="none" pos="word" start_char="1715">the</TOKEN>
<TOKEN end_char="1723" id="token-16-10" morph="none" pos="word" start_char="1719">virus</TOKEN>
<TOKEN end_char="1729" id="token-16-11" morph="none" pos="word" start_char="1725">comes</TOKEN>
<TOKEN end_char="1734" id="token-16-12" morph="none" pos="word" start_char="1731">from</TOKEN>
<TOKEN end_char="1736" id="token-16-13" morph="none" pos="word" start_char="1736">a</TOKEN>
<TOKEN end_char="1746" id="token-16-14" morph="none" pos="unknown" start_char="1738">pre-print</TOKEN>
<TOKEN end_char="1752" id="token-16-15" morph="none" pos="word" start_char="1748">study</TOKEN>
<TOKEN end_char="1757" id="token-16-16" morph="none" pos="word" start_char="1754">that</TOKEN>
<TOKEN end_char="1761" id="token-16-17" morph="none" pos="word" start_char="1759">has</TOKEN>
<TOKEN end_char="1765" id="token-16-18" morph="none" pos="word" start_char="1763">not</TOKEN>
<TOKEN end_char="1769" id="token-16-19" morph="none" pos="word" start_char="1767">yet</TOKEN>
<TOKEN end_char="1774" id="token-16-20" morph="none" pos="word" start_char="1771">been</TOKEN>
<TOKEN end_char="1779" id="token-16-21" morph="none" pos="word" start_char="1776">peer</TOKEN>
<TOKEN end_char="1788" id="token-16-22" morph="none" pos="word" start_char="1781">reviewed</TOKEN>
<TOKEN end_char="1789" id="token-16-23" morph="none" pos="punct" start_char="1789">.</TOKEN>
</SEG>
<SEG end_char="1939" id="segment-17" start_char="1792">
<ORIGINAL_TEXT>"Without full peer review of the study it is premature to make any conclusions, as other factors may have influenced the results," warns Dr Rossman.</ORIGINAL_TEXT>
<TOKEN end_char="1792" id="token-17-0" morph="none" pos="punct" start_char="1792">"</TOKEN>
<TOKEN end_char="1799" id="token-17-1" morph="none" pos="word" start_char="1793">Without</TOKEN>
<TOKEN end_char="1804" id="token-17-2" morph="none" pos="word" start_char="1801">full</TOKEN>
<TOKEN end_char="1809" id="token-17-3" morph="none" pos="word" start_char="1806">peer</TOKEN>
<TOKEN end_char="1816" id="token-17-4" morph="none" pos="word" start_char="1811">review</TOKEN>
<TOKEN end_char="1819" id="token-17-5" morph="none" pos="word" start_char="1818">of</TOKEN>
<TOKEN end_char="1823" id="token-17-6" morph="none" pos="word" start_char="1821">the</TOKEN>
<TOKEN end_char="1829" id="token-17-7" morph="none" pos="word" start_char="1825">study</TOKEN>
<TOKEN end_char="1832" id="token-17-8" morph="none" pos="word" start_char="1831">it</TOKEN>
<TOKEN end_char="1835" id="token-17-9" morph="none" pos="word" start_char="1834">is</TOKEN>
<TOKEN end_char="1845" id="token-17-10" morph="none" pos="word" start_char="1837">premature</TOKEN>
<TOKEN end_char="1848" id="token-17-11" morph="none" pos="word" start_char="1847">to</TOKEN>
<TOKEN end_char="1853" id="token-17-12" morph="none" pos="word" start_char="1850">make</TOKEN>
<TOKEN end_char="1857" id="token-17-13" morph="none" pos="word" start_char="1855">any</TOKEN>
<TOKEN end_char="1869" id="token-17-14" morph="none" pos="word" start_char="1859">conclusions</TOKEN>
<TOKEN end_char="1870" id="token-17-15" morph="none" pos="punct" start_char="1870">,</TOKEN>
<TOKEN end_char="1873" id="token-17-16" morph="none" pos="word" start_char="1872">as</TOKEN>
<TOKEN end_char="1879" id="token-17-17" morph="none" pos="word" start_char="1875">other</TOKEN>
<TOKEN end_char="1887" id="token-17-18" morph="none" pos="word" start_char="1881">factors</TOKEN>
<TOKEN end_char="1891" id="token-17-19" morph="none" pos="word" start_char="1889">may</TOKEN>
<TOKEN end_char="1896" id="token-17-20" morph="none" pos="word" start_char="1893">have</TOKEN>
<TOKEN end_char="1907" id="token-17-21" morph="none" pos="word" start_char="1898">influenced</TOKEN>
<TOKEN end_char="1911" id="token-17-22" morph="none" pos="word" start_char="1909">the</TOKEN>
<TOKEN end_char="1919" id="token-17-23" morph="none" pos="word" start_char="1913">results</TOKEN>
<TOKEN end_char="1921" id="token-17-24" morph="none" pos="punct" start_char="1920">,"</TOKEN>
<TOKEN end_char="1927" id="token-17-25" morph="none" pos="word" start_char="1923">warns</TOKEN>
<TOKEN end_char="1930" id="token-17-26" morph="none" pos="word" start_char="1929">Dr</TOKEN>
<TOKEN end_char="1938" id="token-17-27" morph="none" pos="word" start_char="1932">Rossman</TOKEN>
<TOKEN end_char="1939" id="token-17-28" morph="none" pos="punct" start_char="1939">.</TOKEN>
</SEG>
<SEG end_char="1973" id="segment-18" start_char="1942">
<ORIGINAL_TEXT>Read more about the coronavirus:</ORIGINAL_TEXT>
<TOKEN end_char="1945" id="token-18-0" morph="none" pos="word" start_char="1942">Read</TOKEN>
<TOKEN end_char="1950" id="token-18-1" morph="none" pos="word" start_char="1947">more</TOKEN>
<TOKEN end_char="1956" id="token-18-2" morph="none" pos="word" start_char="1952">about</TOKEN>
<TOKEN end_char="1960" id="token-18-3" morph="none" pos="word" start_char="1958">the</TOKEN>
<TOKEN end_char="1972" id="token-18-4" morph="none" pos="word" start_char="1962">coronavirus</TOKEN>
<TOKEN end_char="1973" id="token-18-5" morph="none" pos="punct" start_char="1973">:</TOKEN>
</SEG>
<SEG end_char="2119" id="segment-19" start_char="1976">
<ORIGINAL_TEXT>"Of note, in the single early sample deemed positive, the virus genome was only detected in 2 out of 5 [tests] and at very low detection levels.</ORIGINAL_TEXT>
<TOKEN end_char="1976" id="token-19-0" morph="none" pos="punct" start_char="1976">"</TOKEN>
<TOKEN end_char="1978" id="token-19-1" morph="none" pos="word" start_char="1977">Of</TOKEN>
<TOKEN end_char="1983" id="token-19-2" morph="none" pos="word" start_char="1980">note</TOKEN>
<TOKEN end_char="1984" id="token-19-3" morph="none" pos="punct" start_char="1984">,</TOKEN>
<TOKEN end_char="1987" id="token-19-4" morph="none" pos="word" start_char="1986">in</TOKEN>
<TOKEN end_char="1991" id="token-19-5" morph="none" pos="word" start_char="1989">the</TOKEN>
<TOKEN end_char="1998" id="token-19-6" morph="none" pos="word" start_char="1993">single</TOKEN>
<TOKEN end_char="2004" id="token-19-7" morph="none" pos="word" start_char="2000">early</TOKEN>
<TOKEN end_char="2011" id="token-19-8" morph="none" pos="word" start_char="2006">sample</TOKEN>
<TOKEN end_char="2018" id="token-19-9" morph="none" pos="word" start_char="2013">deemed</TOKEN>
<TOKEN end_char="2027" id="token-19-10" morph="none" pos="word" start_char="2020">positive</TOKEN>
<TOKEN end_char="2028" id="token-19-11" morph="none" pos="punct" start_char="2028">,</TOKEN>
<TOKEN end_char="2032" id="token-19-12" morph="none" pos="word" start_char="2030">the</TOKEN>
<TOKEN end_char="2038" id="token-19-13" morph="none" pos="word" start_char="2034">virus</TOKEN>
<TOKEN end_char="2045" id="token-19-14" morph="none" pos="word" start_char="2040">genome</TOKEN>
<TOKEN end_char="2049" id="token-19-15" morph="none" pos="word" start_char="2047">was</TOKEN>
<TOKEN end_char="2054" id="token-19-16" morph="none" pos="word" start_char="2051">only</TOKEN>
<TOKEN end_char="2063" id="token-19-17" morph="none" pos="word" start_char="2056">detected</TOKEN>
<TOKEN end_char="2066" id="token-19-18" morph="none" pos="word" start_char="2065">in</TOKEN>
<TOKEN end_char="2068" id="token-19-19" morph="none" pos="word" start_char="2068">2</TOKEN>
<TOKEN end_char="2072" id="token-19-20" morph="none" pos="word" start_char="2070">out</TOKEN>
<TOKEN end_char="2075" id="token-19-21" morph="none" pos="word" start_char="2074">of</TOKEN>
<TOKEN end_char="2077" id="token-19-22" morph="none" pos="word" start_char="2077">5</TOKEN>
<TOKEN end_char="2079" id="token-19-23" morph="none" pos="punct" start_char="2079">[</TOKEN>
<TOKEN end_char="2084" id="token-19-24" morph="none" pos="word" start_char="2080">tests</TOKEN>
<TOKEN end_char="2085" id="token-19-25" morph="none" pos="punct" start_char="2085">]</TOKEN>
<TOKEN end_char="2089" id="token-19-26" morph="none" pos="word" start_char="2087">and</TOKEN>
<TOKEN end_char="2092" id="token-19-27" morph="none" pos="word" start_char="2091">at</TOKEN>
<TOKEN end_char="2097" id="token-19-28" morph="none" pos="word" start_char="2094">very</TOKEN>
<TOKEN end_char="2101" id="token-19-29" morph="none" pos="word" start_char="2099">low</TOKEN>
<TOKEN end_char="2111" id="token-19-30" morph="none" pos="word" start_char="2103">detection</TOKEN>
<TOKEN end_char="2118" id="token-19-31" morph="none" pos="word" start_char="2113">levels</TOKEN>
<TOKEN end_char="2119" id="token-19-32" morph="none" pos="punct" start_char="2119">.</TOKEN>
</SEG>
<SEG end_char="2260" id="segment-20" start_char="2122">
<ORIGINAL_TEXT>"This raises the possibility that it was not SARS-CoV-2 that was detected, but could be cross-reactivity with another virus or contaminant.</ORIGINAL_TEXT>
<TOKEN end_char="2122" id="token-20-0" morph="none" pos="punct" start_char="2122">"</TOKEN>
<TOKEN end_char="2126" id="token-20-1" morph="none" pos="word" start_char="2123">This</TOKEN>
<TOKEN end_char="2133" id="token-20-2" morph="none" pos="word" start_char="2128">raises</TOKEN>
<TOKEN end_char="2137" id="token-20-3" morph="none" pos="word" start_char="2135">the</TOKEN>
<TOKEN end_char="2149" id="token-20-4" morph="none" pos="word" start_char="2139">possibility</TOKEN>
<TOKEN end_char="2154" id="token-20-5" morph="none" pos="word" start_char="2151">that</TOKEN>
<TOKEN end_char="2157" id="token-20-6" morph="none" pos="word" start_char="2156">it</TOKEN>
<TOKEN end_char="2161" id="token-20-7" morph="none" pos="word" start_char="2159">was</TOKEN>
<TOKEN end_char="2165" id="token-20-8" morph="none" pos="word" start_char="2163">not</TOKEN>
<TOKEN end_char="2176" id="token-20-9" morph="none" pos="unknown" start_char="2167">SARS-CoV-2</TOKEN>
<TOKEN end_char="2181" id="token-20-10" morph="none" pos="word" start_char="2178">that</TOKEN>
<TOKEN end_char="2185" id="token-20-11" morph="none" pos="word" start_char="2183">was</TOKEN>
<TOKEN end_char="2194" id="token-20-12" morph="none" pos="word" start_char="2187">detected</TOKEN>
<TOKEN end_char="2195" id="token-20-13" morph="none" pos="punct" start_char="2195">,</TOKEN>
<TOKEN end_char="2199" id="token-20-14" morph="none" pos="word" start_char="2197">but</TOKEN>
<TOKEN end_char="2205" id="token-20-15" morph="none" pos="word" start_char="2201">could</TOKEN>
<TOKEN end_char="2208" id="token-20-16" morph="none" pos="word" start_char="2207">be</TOKEN>
<TOKEN end_char="2225" id="token-20-17" morph="none" pos="unknown" start_char="2210">cross-reactivity</TOKEN>
<TOKEN end_char="2230" id="token-20-18" morph="none" pos="word" start_char="2227">with</TOKEN>
<TOKEN end_char="2238" id="token-20-19" morph="none" pos="word" start_char="2232">another</TOKEN>
<TOKEN end_char="2244" id="token-20-20" morph="none" pos="word" start_char="2240">virus</TOKEN>
<TOKEN end_char="2247" id="token-20-21" morph="none" pos="word" start_char="2246">or</TOKEN>
<TOKEN end_char="2259" id="token-20-22" morph="none" pos="word" start_char="2249">contaminant</TOKEN>
<TOKEN end_char="2260" id="token-20-23" morph="none" pos="punct" start_char="2260">.</TOKEN>
</SEG>
<SEG end_char="2457" id="segment-21" start_char="2262">
<ORIGINAL_TEXT>For example, perhaps a local outbreak of another, related coronavirus occurred during that time period and some of the [tests] could not fully distinguish between that coronavirus and SARS-CoV-2."</ORIGINAL_TEXT>
<TOKEN end_char="2264" id="token-21-0" morph="none" pos="word" start_char="2262">For</TOKEN>
<TOKEN end_char="2272" id="token-21-1" morph="none" pos="word" start_char="2266">example</TOKEN>
<TOKEN end_char="2273" id="token-21-2" morph="none" pos="punct" start_char="2273">,</TOKEN>
<TOKEN end_char="2281" id="token-21-3" morph="none" pos="word" start_char="2275">perhaps</TOKEN>
<TOKEN end_char="2283" id="token-21-4" morph="none" pos="word" start_char="2283">a</TOKEN>
<TOKEN end_char="2289" id="token-21-5" morph="none" pos="word" start_char="2285">local</TOKEN>
<TOKEN end_char="2298" id="token-21-6" morph="none" pos="word" start_char="2291">outbreak</TOKEN>
<TOKEN end_char="2301" id="token-21-7" morph="none" pos="word" start_char="2300">of</TOKEN>
<TOKEN end_char="2309" id="token-21-8" morph="none" pos="word" start_char="2303">another</TOKEN>
<TOKEN end_char="2310" id="token-21-9" morph="none" pos="punct" start_char="2310">,</TOKEN>
<TOKEN end_char="2318" id="token-21-10" morph="none" pos="word" start_char="2312">related</TOKEN>
<TOKEN end_char="2330" id="token-21-11" morph="none" pos="word" start_char="2320">coronavirus</TOKEN>
<TOKEN end_char="2339" id="token-21-12" morph="none" pos="word" start_char="2332">occurred</TOKEN>
<TOKEN end_char="2346" id="token-21-13" morph="none" pos="word" start_char="2341">during</TOKEN>
<TOKEN end_char="2351" id="token-21-14" morph="none" pos="word" start_char="2348">that</TOKEN>
<TOKEN end_char="2356" id="token-21-15" morph="none" pos="word" start_char="2353">time</TOKEN>
<TOKEN end_char="2363" id="token-21-16" morph="none" pos="word" start_char="2358">period</TOKEN>
<TOKEN end_char="2367" id="token-21-17" morph="none" pos="word" start_char="2365">and</TOKEN>
<TOKEN end_char="2372" id="token-21-18" morph="none" pos="word" start_char="2369">some</TOKEN>
<TOKEN end_char="2375" id="token-21-19" morph="none" pos="word" start_char="2374">of</TOKEN>
<TOKEN end_char="2379" id="token-21-20" morph="none" pos="word" start_char="2377">the</TOKEN>
<TOKEN end_char="2381" id="token-21-21" morph="none" pos="punct" start_char="2381">[</TOKEN>
<TOKEN end_char="2386" id="token-21-22" morph="none" pos="word" start_char="2382">tests</TOKEN>
<TOKEN end_char="2387" id="token-21-23" morph="none" pos="punct" start_char="2387">]</TOKEN>
<TOKEN end_char="2393" id="token-21-24" morph="none" pos="word" start_char="2389">could</TOKEN>
<TOKEN end_char="2397" id="token-21-25" morph="none" pos="word" start_char="2395">not</TOKEN>
<TOKEN end_char="2403" id="token-21-26" morph="none" pos="word" start_char="2399">fully</TOKEN>
<TOKEN end_char="2415" id="token-21-27" morph="none" pos="word" start_char="2405">distinguish</TOKEN>
<TOKEN end_char="2423" id="token-21-28" morph="none" pos="word" start_char="2417">between</TOKEN>
<TOKEN end_char="2428" id="token-21-29" morph="none" pos="word" start_char="2425">that</TOKEN>
<TOKEN end_char="2440" id="token-21-30" morph="none" pos="word" start_char="2430">coronavirus</TOKEN>
<TOKEN end_char="2444" id="token-21-31" morph="none" pos="word" start_char="2442">and</TOKEN>
<TOKEN end_char="2455" id="token-21-32" morph="none" pos="unknown" start_char="2446">SARS-CoV-2</TOKEN>
<TOKEN end_char="2457" id="token-21-33" morph="none" pos="punct" start_char="2456">."</TOKEN>
</SEG>
<SEG end_char="2517" id="segment-22" start_char="2460">
<ORIGINAL_TEXT>What evidence is there that the virus originated in China?</ORIGINAL_TEXT>
<TOKEN end_char="2463" id="token-22-0" morph="none" pos="word" start_char="2460">What</TOKEN>
<TOKEN end_char="2472" id="token-22-1" morph="none" pos="word" start_char="2465">evidence</TOKEN>
<TOKEN end_char="2475" id="token-22-2" morph="none" pos="word" start_char="2474">is</TOKEN>
<TOKEN end_char="2481" id="token-22-3" morph="none" pos="word" start_char="2477">there</TOKEN>
<TOKEN end_char="2486" id="token-22-4" morph="none" pos="word" start_char="2483">that</TOKEN>
<TOKEN end_char="2490" id="token-22-5" morph="none" pos="word" start_char="2488">the</TOKEN>
<TOKEN end_char="2496" id="token-22-6" morph="none" pos="word" start_char="2492">virus</TOKEN>
<TOKEN end_char="2507" id="token-22-7" morph="none" pos="word" start_char="2498">originated</TOKEN>
<TOKEN end_char="2510" id="token-22-8" morph="none" pos="word" start_char="2509">in</TOKEN>
<TOKEN end_char="2516" id="token-22-9" morph="none" pos="word" start_char="2512">China</TOKEN>
<TOKEN end_char="2517" id="token-22-10" morph="none" pos="punct" start_char="2517">?</TOKEN>
</SEG>
<SEG end_char="2851" id="segment-23" start_char="2521">
<ORIGINAL_TEXT>Dr Rossman says that currently, the best evidence for the location and date of SARS-CoV-2 emergence into the human population comes from the early detection of positive cases in China and from the determination of cases presumed to be caused by SARS-Cov-2 through the symptoms exhibited (the study of which is called symptomology).</ORIGINAL_TEXT>
<TOKEN end_char="2522" id="token-23-0" morph="none" pos="word" start_char="2521">Dr</TOKEN>
<TOKEN end_char="2530" id="token-23-1" morph="none" pos="word" start_char="2524">Rossman</TOKEN>
<TOKEN end_char="2535" id="token-23-2" morph="none" pos="word" start_char="2532">says</TOKEN>
<TOKEN end_char="2540" id="token-23-3" morph="none" pos="word" start_char="2537">that</TOKEN>
<TOKEN end_char="2550" id="token-23-4" morph="none" pos="word" start_char="2542">currently</TOKEN>
<TOKEN end_char="2551" id="token-23-5" morph="none" pos="punct" start_char="2551">,</TOKEN>
<TOKEN end_char="2555" id="token-23-6" morph="none" pos="word" start_char="2553">the</TOKEN>
<TOKEN end_char="2560" id="token-23-7" morph="none" pos="word" start_char="2557">best</TOKEN>
<TOKEN end_char="2569" id="token-23-8" morph="none" pos="word" start_char="2562">evidence</TOKEN>
<TOKEN end_char="2573" id="token-23-9" morph="none" pos="word" start_char="2571">for</TOKEN>
<TOKEN end_char="2577" id="token-23-10" morph="none" pos="word" start_char="2575">the</TOKEN>
<TOKEN end_char="2586" id="token-23-11" morph="none" pos="word" start_char="2579">location</TOKEN>
<TOKEN end_char="2590" id="token-23-12" morph="none" pos="word" start_char="2588">and</TOKEN>
<TOKEN end_char="2595" id="token-23-13" morph="none" pos="word" start_char="2592">date</TOKEN>
<TOKEN end_char="2598" id="token-23-14" morph="none" pos="word" start_char="2597">of</TOKEN>
<TOKEN end_char="2609" id="token-23-15" morph="none" pos="unknown" start_char="2600">SARS-CoV-2</TOKEN>
<TOKEN end_char="2619" id="token-23-16" morph="none" pos="word" start_char="2611">emergence</TOKEN>
<TOKEN end_char="2624" id="token-23-17" morph="none" pos="word" start_char="2621">into</TOKEN>
<TOKEN end_char="2628" id="token-23-18" morph="none" pos="word" start_char="2626">the</TOKEN>
<TOKEN end_char="2634" id="token-23-19" morph="none" pos="word" start_char="2630">human</TOKEN>
<TOKEN end_char="2645" id="token-23-20" morph="none" pos="word" start_char="2636">population</TOKEN>
<TOKEN end_char="2651" id="token-23-21" morph="none" pos="word" start_char="2647">comes</TOKEN>
<TOKEN end_char="2656" id="token-23-22" morph="none" pos="word" start_char="2653">from</TOKEN>
<TOKEN end_char="2660" id="token-23-23" morph="none" pos="word" start_char="2658">the</TOKEN>
<TOKEN end_char="2666" id="token-23-24" morph="none" pos="word" start_char="2662">early</TOKEN>
<TOKEN end_char="2676" id="token-23-25" morph="none" pos="word" start_char="2668">detection</TOKEN>
<TOKEN end_char="2679" id="token-23-26" morph="none" pos="word" start_char="2678">of</TOKEN>
<TOKEN end_char="2688" id="token-23-27" morph="none" pos="word" start_char="2681">positive</TOKEN>
<TOKEN end_char="2694" id="token-23-28" morph="none" pos="word" start_char="2690">cases</TOKEN>
<TOKEN end_char="2697" id="token-23-29" morph="none" pos="word" start_char="2696">in</TOKEN>
<TOKEN end_char="2703" id="token-23-30" morph="none" pos="word" start_char="2699">China</TOKEN>
<TOKEN end_char="2707" id="token-23-31" morph="none" pos="word" start_char="2705">and</TOKEN>
<TOKEN end_char="2712" id="token-23-32" morph="none" pos="word" start_char="2709">from</TOKEN>
<TOKEN end_char="2716" id="token-23-33" morph="none" pos="word" start_char="2714">the</TOKEN>
<TOKEN end_char="2730" id="token-23-34" morph="none" pos="word" start_char="2718">determination</TOKEN>
<TOKEN end_char="2733" id="token-23-35" morph="none" pos="word" start_char="2732">of</TOKEN>
<TOKEN end_char="2739" id="token-23-36" morph="none" pos="word" start_char="2735">cases</TOKEN>
<TOKEN end_char="2748" id="token-23-37" morph="none" pos="word" start_char="2741">presumed</TOKEN>
<TOKEN end_char="2751" id="token-23-38" morph="none" pos="word" start_char="2750">to</TOKEN>
<TOKEN end_char="2754" id="token-23-39" morph="none" pos="word" start_char="2753">be</TOKEN>
<TOKEN end_char="2761" id="token-23-40" morph="none" pos="word" start_char="2756">caused</TOKEN>
<TOKEN end_char="2764" id="token-23-41" morph="none" pos="word" start_char="2763">by</TOKEN>
<TOKEN end_char="2775" id="token-23-42" morph="none" pos="unknown" start_char="2766">SARS-Cov-2</TOKEN>
<TOKEN end_char="2783" id="token-23-43" morph="none" pos="word" start_char="2777">through</TOKEN>
<TOKEN end_char="2787" id="token-23-44" morph="none" pos="word" start_char="2785">the</TOKEN>
<TOKEN end_char="2796" id="token-23-45" morph="none" pos="word" start_char="2789">symptoms</TOKEN>
<TOKEN end_char="2806" id="token-23-46" morph="none" pos="word" start_char="2798">exhibited</TOKEN>
<TOKEN end_char="2808" id="token-23-47" morph="none" pos="punct" start_char="2808">(</TOKEN>
<TOKEN end_char="2811" id="token-23-48" morph="none" pos="word" start_char="2809">the</TOKEN>
<TOKEN end_char="2817" id="token-23-49" morph="none" pos="word" start_char="2813">study</TOKEN>
<TOKEN end_char="2820" id="token-23-50" morph="none" pos="word" start_char="2819">of</TOKEN>
<TOKEN end_char="2826" id="token-23-51" morph="none" pos="word" start_char="2822">which</TOKEN>
<TOKEN end_char="2829" id="token-23-52" morph="none" pos="word" start_char="2828">is</TOKEN>
<TOKEN end_char="2836" id="token-23-53" morph="none" pos="word" start_char="2831">called</TOKEN>
<TOKEN end_char="2849" id="token-23-54" morph="none" pos="word" start_char="2838">symptomology</TOKEN>
<TOKEN end_char="2851" id="token-23-55" morph="none" pos="punct" start_char="2850">).</TOKEN>
</SEG>
<SEG end_char="3020" id="segment-24" start_char="2853">
<ORIGINAL_TEXT>It’s also possible to use molecular dating when forming a timeline for viral emergence, using human samples and analysing the different mutations of the virus’s genome.</ORIGINAL_TEXT>
<TOKEN end_char="2856" id="token-24-0" morph="none" pos="word" start_char="2853">It’s</TOKEN>
<TOKEN end_char="2861" id="token-24-1" morph="none" pos="word" start_char="2858">also</TOKEN>
<TOKEN end_char="2870" id="token-24-2" morph="none" pos="word" start_char="2863">possible</TOKEN>
<TOKEN end_char="2873" id="token-24-3" morph="none" pos="word" start_char="2872">to</TOKEN>
<TOKEN end_char="2877" id="token-24-4" morph="none" pos="word" start_char="2875">use</TOKEN>
<TOKEN end_char="2887" id="token-24-5" morph="none" pos="word" start_char="2879">molecular</TOKEN>
<TOKEN end_char="2894" id="token-24-6" morph="none" pos="word" start_char="2889">dating</TOKEN>
<TOKEN end_char="2899" id="token-24-7" morph="none" pos="word" start_char="2896">when</TOKEN>
<TOKEN end_char="2907" id="token-24-8" morph="none" pos="word" start_char="2901">forming</TOKEN>
<TOKEN end_char="2909" id="token-24-9" morph="none" pos="word" start_char="2909">a</TOKEN>
<TOKEN end_char="2918" id="token-24-10" morph="none" pos="word" start_char="2911">timeline</TOKEN>
<TOKEN end_char="2922" id="token-24-11" morph="none" pos="word" start_char="2920">for</TOKEN>
<TOKEN end_char="2928" id="token-24-12" morph="none" pos="word" start_char="2924">viral</TOKEN>
<TOKEN end_char="2938" id="token-24-13" morph="none" pos="word" start_char="2930">emergence</TOKEN>
<TOKEN end_char="2939" id="token-24-14" morph="none" pos="punct" start_char="2939">,</TOKEN>
<TOKEN end_char="2945" id="token-24-15" morph="none" pos="word" start_char="2941">using</TOKEN>
<TOKEN end_char="2951" id="token-24-16" morph="none" pos="word" start_char="2947">human</TOKEN>
<TOKEN end_char="2959" id="token-24-17" morph="none" pos="word" start_char="2953">samples</TOKEN>
<TOKEN end_char="2963" id="token-24-18" morph="none" pos="word" start_char="2961">and</TOKEN>
<TOKEN end_char="2973" id="token-24-19" morph="none" pos="word" start_char="2965">analysing</TOKEN>
<TOKEN end_char="2977" id="token-24-20" morph="none" pos="word" start_char="2975">the</TOKEN>
<TOKEN end_char="2987" id="token-24-21" morph="none" pos="word" start_char="2979">different</TOKEN>
<TOKEN end_char="2997" id="token-24-22" morph="none" pos="word" start_char="2989">mutations</TOKEN>
<TOKEN end_char="3000" id="token-24-23" morph="none" pos="word" start_char="2999">of</TOKEN>
<TOKEN end_char="3004" id="token-24-24" morph="none" pos="word" start_char="3002">the</TOKEN>
<TOKEN end_char="3012" id="token-24-25" morph="none" pos="word" start_char="3006">virus’s</TOKEN>
<TOKEN end_char="3019" id="token-24-26" morph="none" pos="word" start_char="3014">genome</TOKEN>
<TOKEN end_char="3020" id="token-24-27" morph="none" pos="punct" start_char="3020">.</TOKEN>
</SEG>
<SEG end_char="3157" id="segment-25" start_char="3023">
<ORIGINAL_TEXT>In Scotland, sewage is being tested for traces of COVID-19 in a trial aimed at helping monitor the spread of coronavirus © Getty Images</ORIGINAL_TEXT>
<TOKEN end_char="3024" id="token-25-0" morph="none" pos="word" start_char="3023">In</TOKEN>
<TOKEN end_char="3033" id="token-25-1" morph="none" pos="word" start_char="3026">Scotland</TOKEN>
<TOKEN end_char="3034" id="token-25-2" morph="none" pos="punct" start_char="3034">,</TOKEN>
<TOKEN end_char="3041" id="token-25-3" morph="none" pos="word" start_char="3036">sewage</TOKEN>
<TOKEN end_char="3044" id="token-25-4" morph="none" pos="word" start_char="3043">is</TOKEN>
<TOKEN end_char="3050" id="token-25-5" morph="none" pos="word" start_char="3046">being</TOKEN>
<TOKEN end_char="3057" id="token-25-6" morph="none" pos="word" start_char="3052">tested</TOKEN>
<TOKEN end_char="3061" id="token-25-7" morph="none" pos="word" start_char="3059">for</TOKEN>
<TOKEN end_char="3068" id="token-25-8" morph="none" pos="word" start_char="3063">traces</TOKEN>
<TOKEN end_char="3071" id="token-25-9" morph="none" pos="word" start_char="3070">of</TOKEN>
<TOKEN end_char="3080" id="token-25-10" morph="none" pos="unknown" start_char="3073">COVID-19</TOKEN>
<TOKEN end_char="3083" id="token-25-11" morph="none" pos="word" start_char="3082">in</TOKEN>
<TOKEN end_char="3085" id="token-25-12" morph="none" pos="word" start_char="3085">a</TOKEN>
<TOKEN end_char="3091" id="token-25-13" morph="none" pos="word" start_char="3087">trial</TOKEN>
<TOKEN end_char="3097" id="token-25-14" morph="none" pos="word" start_char="3093">aimed</TOKEN>
<TOKEN end_char="3100" id="token-25-15" morph="none" pos="word" start_char="3099">at</TOKEN>
<TOKEN end_char="3108" id="token-25-16" morph="none" pos="word" start_char="3102">helping</TOKEN>
<TOKEN end_char="3116" id="token-25-17" morph="none" pos="word" start_char="3110">monitor</TOKEN>
<TOKEN end_char="3120" id="token-25-18" morph="none" pos="word" start_char="3118">the</TOKEN>
<TOKEN end_char="3127" id="token-25-19" morph="none" pos="word" start_char="3122">spread</TOKEN>
<TOKEN end_char="3130" id="token-25-20" morph="none" pos="word" start_char="3129">of</TOKEN>
<TOKEN end_char="3142" id="token-25-21" morph="none" pos="word" start_char="3132">coronavirus</TOKEN>
<TOKEN end_char="3144" id="token-25-22" morph="none" pos="unknown" start_char="3144">©</TOKEN>
<TOKEN end_char="3150" id="token-25-23" morph="none" pos="word" start_char="3146">Getty</TOKEN>
<TOKEN end_char="3157" id="token-25-24" morph="none" pos="word" start_char="3152">Images</TOKEN>
</SEG>
<SEG end_char="3252" id="segment-26" start_char="3160">
<ORIGINAL_TEXT>"This combination of data puts viral emergence in China between October and December of 2019.</ORIGINAL_TEXT>
<TOKEN end_char="3160" id="token-26-0" morph="none" pos="punct" start_char="3160">"</TOKEN>
<TOKEN end_char="3164" id="token-26-1" morph="none" pos="word" start_char="3161">This</TOKEN>
<TOKEN end_char="3176" id="token-26-2" morph="none" pos="word" start_char="3166">combination</TOKEN>
<TOKEN end_char="3179" id="token-26-3" morph="none" pos="word" start_char="3178">of</TOKEN>
<TOKEN end_char="3184" id="token-26-4" morph="none" pos="word" start_char="3181">data</TOKEN>
<TOKEN end_char="3189" id="token-26-5" morph="none" pos="word" start_char="3186">puts</TOKEN>
<TOKEN end_char="3195" id="token-26-6" morph="none" pos="word" start_char="3191">viral</TOKEN>
<TOKEN end_char="3205" id="token-26-7" morph="none" pos="word" start_char="3197">emergence</TOKEN>
<TOKEN end_char="3208" id="token-26-8" morph="none" pos="word" start_char="3207">in</TOKEN>
<TOKEN end_char="3214" id="token-26-9" morph="none" pos="word" start_char="3210">China</TOKEN>
<TOKEN end_char="3222" id="token-26-10" morph="none" pos="word" start_char="3216">between</TOKEN>
<TOKEN end_char="3230" id="token-26-11" morph="none" pos="word" start_char="3224">October</TOKEN>
<TOKEN end_char="3234" id="token-26-12" morph="none" pos="word" start_char="3232">and</TOKEN>
<TOKEN end_char="3243" id="token-26-13" morph="none" pos="word" start_char="3236">December</TOKEN>
<TOKEN end_char="3246" id="token-26-14" morph="none" pos="word" start_char="3245">of</TOKEN>
<TOKEN end_char="3251" id="token-26-15" morph="none" pos="word" start_char="3248">2019</TOKEN>
<TOKEN end_char="3252" id="token-26-16" morph="none" pos="punct" start_char="3252">.</TOKEN>
</SEG>
<SEG end_char="3527" id="segment-27" start_char="3255">
<ORIGINAL_TEXT>"Our current data does not specifically pinpoint the geographical area where the virus emerged, so we cannot specifically confirm emergence in Wuhan; however, the number of early case reports and diagnostic testing is highly convincing for emergence in China in late 2019."</ORIGINAL_TEXT>
<TOKEN end_char="3255" id="token-27-0" morph="none" pos="punct" start_char="3255">"</TOKEN>
<TOKEN end_char="3258" id="token-27-1" morph="none" pos="word" start_char="3256">Our</TOKEN>
<TOKEN end_char="3266" id="token-27-2" morph="none" pos="word" start_char="3260">current</TOKEN>
<TOKEN end_char="3271" id="token-27-3" morph="none" pos="word" start_char="3268">data</TOKEN>
<TOKEN end_char="3276" id="token-27-4" morph="none" pos="word" start_char="3273">does</TOKEN>
<TOKEN end_char="3280" id="token-27-5" morph="none" pos="word" start_char="3278">not</TOKEN>
<TOKEN end_char="3293" id="token-27-6" morph="none" pos="word" start_char="3282">specifically</TOKEN>
<TOKEN end_char="3302" id="token-27-7" morph="none" pos="word" start_char="3295">pinpoint</TOKEN>
<TOKEN end_char="3306" id="token-27-8" morph="none" pos="word" start_char="3304">the</TOKEN>
<TOKEN end_char="3319" id="token-27-9" morph="none" pos="word" start_char="3308">geographical</TOKEN>
<TOKEN end_char="3324" id="token-27-10" morph="none" pos="word" start_char="3321">area</TOKEN>
<TOKEN end_char="3330" id="token-27-11" morph="none" pos="word" start_char="3326">where</TOKEN>
<TOKEN end_char="3334" id="token-27-12" morph="none" pos="word" start_char="3332">the</TOKEN>
<TOKEN end_char="3340" id="token-27-13" morph="none" pos="word" start_char="3336">virus</TOKEN>
<TOKEN end_char="3348" id="token-27-14" morph="none" pos="word" start_char="3342">emerged</TOKEN>
<TOKEN end_char="3349" id="token-27-15" morph="none" pos="punct" start_char="3349">,</TOKEN>
<TOKEN end_char="3352" id="token-27-16" morph="none" pos="word" start_char="3351">so</TOKEN>
<TOKEN end_char="3355" id="token-27-17" morph="none" pos="word" start_char="3354">we</TOKEN>
<TOKEN end_char="3362" id="token-27-18" morph="none" pos="word" start_char="3357">cannot</TOKEN>
<TOKEN end_char="3375" id="token-27-19" morph="none" pos="word" start_char="3364">specifically</TOKEN>
<TOKEN end_char="3383" id="token-27-20" morph="none" pos="word" start_char="3377">confirm</TOKEN>
<TOKEN end_char="3393" id="token-27-21" morph="none" pos="word" start_char="3385">emergence</TOKEN>
<TOKEN end_char="3396" id="token-27-22" morph="none" pos="word" start_char="3395">in</TOKEN>
<TOKEN end_char="3402" id="token-27-23" morph="none" pos="word" start_char="3398">Wuhan</TOKEN>
<TOKEN end_char="3403" id="token-27-24" morph="none" pos="punct" start_char="3403">;</TOKEN>
<TOKEN end_char="3411" id="token-27-25" morph="none" pos="word" start_char="3405">however</TOKEN>
<TOKEN end_char="3412" id="token-27-26" morph="none" pos="punct" start_char="3412">,</TOKEN>
<TOKEN end_char="3416" id="token-27-27" morph="none" pos="word" start_char="3414">the</TOKEN>
<TOKEN end_char="3423" id="token-27-28" morph="none" pos="word" start_char="3418">number</TOKEN>
<TOKEN end_char="3426" id="token-27-29" morph="none" pos="word" start_char="3425">of</TOKEN>
<TOKEN end_char="3432" id="token-27-30" morph="none" pos="word" start_char="3428">early</TOKEN>
<TOKEN end_char="3437" id="token-27-31" morph="none" pos="word" start_char="3434">case</TOKEN>
<TOKEN end_char="3445" id="token-27-32" morph="none" pos="word" start_char="3439">reports</TOKEN>
<TOKEN end_char="3449" id="token-27-33" morph="none" pos="word" start_char="3447">and</TOKEN>
<TOKEN end_char="3460" id="token-27-34" morph="none" pos="word" start_char="3451">diagnostic</TOKEN>
<TOKEN end_char="3468" id="token-27-35" morph="none" pos="word" start_char="3462">testing</TOKEN>
<TOKEN end_char="3471" id="token-27-36" morph="none" pos="word" start_char="3470">is</TOKEN>
<TOKEN end_char="3478" id="token-27-37" morph="none" pos="word" start_char="3473">highly</TOKEN>
<TOKEN end_char="3489" id="token-27-38" morph="none" pos="word" start_char="3480">convincing</TOKEN>
<TOKEN end_char="3493" id="token-27-39" morph="none" pos="word" start_char="3491">for</TOKEN>
<TOKEN end_char="3503" id="token-27-40" morph="none" pos="word" start_char="3495">emergence</TOKEN>
<TOKEN end_char="3506" id="token-27-41" morph="none" pos="word" start_char="3505">in</TOKEN>
<TOKEN end_char="3512" id="token-27-42" morph="none" pos="word" start_char="3508">China</TOKEN>
<TOKEN end_char="3515" id="token-27-43" morph="none" pos="word" start_char="3514">in</TOKEN>
<TOKEN end_char="3520" id="token-27-44" morph="none" pos="word" start_char="3517">late</TOKEN>
<TOKEN end_char="3525" id="token-27-45" morph="none" pos="word" start_char="3522">2019</TOKEN>
<TOKEN end_char="3527" id="token-27-46" morph="none" pos="punct" start_char="3526">."</TOKEN>
</SEG>
<SEG end_char="3663" id="segment-28" start_char="3530">
<ORIGINAL_TEXT>"Finding evidence of the virus in humans (or human samples such as sewage) in March 2019 would be highly surprising," says Dr Rossman.</ORIGINAL_TEXT>
<TOKEN end_char="3530" id="token-28-0" morph="none" pos="punct" start_char="3530">"</TOKEN>
<TOKEN end_char="3537" id="token-28-1" morph="none" pos="word" start_char="3531">Finding</TOKEN>
<TOKEN end_char="3546" id="token-28-2" morph="none" pos="word" start_char="3539">evidence</TOKEN>
<TOKEN end_char="3549" id="token-28-3" morph="none" pos="word" start_char="3548">of</TOKEN>
<TOKEN end_char="3553" id="token-28-4" morph="none" pos="word" start_char="3551">the</TOKEN>
<TOKEN end_char="3559" id="token-28-5" morph="none" pos="word" start_char="3555">virus</TOKEN>
<TOKEN end_char="3562" id="token-28-6" morph="none" pos="word" start_char="3561">in</TOKEN>
<TOKEN end_char="3569" id="token-28-7" morph="none" pos="word" start_char="3564">humans</TOKEN>
<TOKEN end_char="3571" id="token-28-8" morph="none" pos="punct" start_char="3571">(</TOKEN>
<TOKEN end_char="3573" id="token-28-9" morph="none" pos="word" start_char="3572">or</TOKEN>
<TOKEN end_char="3579" id="token-28-10" morph="none" pos="word" start_char="3575">human</TOKEN>
<TOKEN end_char="3587" id="token-28-11" morph="none" pos="word" start_char="3581">samples</TOKEN>
<TOKEN end_char="3592" id="token-28-12" morph="none" pos="word" start_char="3589">such</TOKEN>
<TOKEN end_char="3595" id="token-28-13" morph="none" pos="word" start_char="3594">as</TOKEN>
<TOKEN end_char="3602" id="token-28-14" morph="none" pos="word" start_char="3597">sewage</TOKEN>
<TOKEN end_char="3603" id="token-28-15" morph="none" pos="punct" start_char="3603">)</TOKEN>
<TOKEN end_char="3606" id="token-28-16" morph="none" pos="word" start_char="3605">in</TOKEN>
<TOKEN end_char="3612" id="token-28-17" morph="none" pos="word" start_char="3608">March</TOKEN>
<TOKEN end_char="3617" id="token-28-18" morph="none" pos="word" start_char="3614">2019</TOKEN>
<TOKEN end_char="3623" id="token-28-19" morph="none" pos="word" start_char="3619">would</TOKEN>
<TOKEN end_char="3626" id="token-28-20" morph="none" pos="word" start_char="3625">be</TOKEN>
<TOKEN end_char="3633" id="token-28-21" morph="none" pos="word" start_char="3628">highly</TOKEN>
<TOKEN end_char="3644" id="token-28-22" morph="none" pos="word" start_char="3635">surprising</TOKEN>
<TOKEN end_char="3646" id="token-28-23" morph="none" pos="punct" start_char="3645">,"</TOKEN>
<TOKEN end_char="3651" id="token-28-24" morph="none" pos="word" start_char="3648">says</TOKEN>
<TOKEN end_char="3654" id="token-28-25" morph="none" pos="word" start_char="3653">Dr</TOKEN>
<TOKEN end_char="3662" id="token-28-26" morph="none" pos="word" start_char="3656">Rossman</TOKEN>
<TOKEN end_char="3663" id="token-28-27" morph="none" pos="punct" start_char="3663">.</TOKEN>
</SEG>
<SEG end_char="3715" id="segment-29" start_char="3666">
<ORIGINAL_TEXT>Reader Q How long can a virus live outside a body?</ORIGINAL_TEXT>
<TOKEN end_char="3671" id="token-29-0" morph="none" pos="word" start_char="3666">Reader</TOKEN>
<TOKEN end_char="3673" id="token-29-1" morph="none" pos="word" start_char="3673">Q</TOKEN>
<TOKEN end_char="3677" id="token-29-2" morph="none" pos="word" start_char="3675">How</TOKEN>
<TOKEN end_char="3682" id="token-29-3" morph="none" pos="word" start_char="3679">long</TOKEN>
<TOKEN end_char="3686" id="token-29-4" morph="none" pos="word" start_char="3684">can</TOKEN>
<TOKEN end_char="3688" id="token-29-5" morph="none" pos="word" start_char="3688">a</TOKEN>
<TOKEN end_char="3694" id="token-29-6" morph="none" pos="word" start_char="3690">virus</TOKEN>
<TOKEN end_char="3699" id="token-29-7" morph="none" pos="word" start_char="3696">live</TOKEN>
<TOKEN end_char="3707" id="token-29-8" morph="none" pos="word" start_char="3701">outside</TOKEN>
<TOKEN end_char="3709" id="token-29-9" morph="none" pos="word" start_char="3709">a</TOKEN>
<TOKEN end_char="3714" id="token-29-10" morph="none" pos="word" start_char="3711">body</TOKEN>
<TOKEN end_char="3715" id="token-29-11" morph="none" pos="punct" start_char="3715">?</TOKEN>
</SEG>
<SEG end_char="3750" id="segment-30" start_char="3719">
<ORIGINAL_TEXT>Asked by: Chaudhary Nikul, India</ORIGINAL_TEXT>
<TOKEN end_char="3723" id="token-30-0" morph="none" pos="word" start_char="3719">Asked</TOKEN>
<TOKEN end_char="3726" id="token-30-1" morph="none" pos="word" start_char="3725">by</TOKEN>
<TOKEN end_char="3727" id="token-30-2" morph="none" pos="punct" start_char="3727">:</TOKEN>
<TOKEN end_char="3737" id="token-30-3" morph="none" pos="word" start_char="3729">Chaudhary</TOKEN>
<TOKEN end_char="3743" id="token-30-4" morph="none" pos="word" start_char="3739">Nikul</TOKEN>
<TOKEN end_char="3744" id="token-30-5" morph="none" pos="punct" start_char="3744">,</TOKEN>
<TOKEN end_char="3750" id="token-30-6" morph="none" pos="word" start_char="3746">India</TOKEN>
</SEG>
<SEG end_char="3874" id="segment-31" start_char="3753">
<ORIGINAL_TEXT>Viruses can live for a surprisingly long time outside of a body, depending on conditions such as moisture and temperature.</ORIGINAL_TEXT>
<TOKEN end_char="3759" id="token-31-0" morph="none" pos="word" start_char="3753">Viruses</TOKEN>
<TOKEN end_char="3763" id="token-31-1" morph="none" pos="word" start_char="3761">can</TOKEN>
<TOKEN end_char="3768" id="token-31-2" morph="none" pos="word" start_char="3765">live</TOKEN>
<TOKEN end_char="3772" id="token-31-3" morph="none" pos="word" start_char="3770">for</TOKEN>
<TOKEN end_char="3774" id="token-31-4" morph="none" pos="word" start_char="3774">a</TOKEN>
<TOKEN end_char="3787" id="token-31-5" morph="none" pos="word" start_char="3776">surprisingly</TOKEN>
<TOKEN end_char="3792" id="token-31-6" morph="none" pos="word" start_char="3789">long</TOKEN>
<TOKEN end_char="3797" id="token-31-7" morph="none" pos="word" start_char="3794">time</TOKEN>
<TOKEN end_char="3805" id="token-31-8" morph="none" pos="word" start_char="3799">outside</TOKEN>
<TOKEN end_char="3808" id="token-31-9" morph="none" pos="word" start_char="3807">of</TOKEN>
<TOKEN end_char="3810" id="token-31-10" morph="none" pos="word" start_char="3810">a</TOKEN>
<TOKEN end_char="3815" id="token-31-11" morph="none" pos="word" start_char="3812">body</TOKEN>
<TOKEN end_char="3816" id="token-31-12" morph="none" pos="punct" start_char="3816">,</TOKEN>
<TOKEN end_char="3826" id="token-31-13" morph="none" pos="word" start_char="3818">depending</TOKEN>
<TOKEN end_char="3829" id="token-31-14" morph="none" pos="word" start_char="3828">on</TOKEN>
<TOKEN end_char="3840" id="token-31-15" morph="none" pos="word" start_char="3831">conditions</TOKEN>
<TOKEN end_char="3845" id="token-31-16" morph="none" pos="word" start_char="3842">such</TOKEN>
<TOKEN end_char="3848" id="token-31-17" morph="none" pos="word" start_char="3847">as</TOKEN>
<TOKEN end_char="3857" id="token-31-18" morph="none" pos="word" start_char="3850">moisture</TOKEN>
<TOKEN end_char="3861" id="token-31-19" morph="none" pos="word" start_char="3859">and</TOKEN>
<TOKEN end_char="3873" id="token-31-20" morph="none" pos="word" start_char="3863">temperature</TOKEN>
<TOKEN end_char="3874" id="token-31-21" morph="none" pos="punct" start_char="3874">.</TOKEN>
</SEG>
<SEG end_char="3966" id="segment-32" start_char="3876">
<ORIGINAL_TEXT>They tend to live longer on water-resistant surfaces, such as stainless steel and plastics.</ORIGINAL_TEXT>
<TOKEN end_char="3879" id="token-32-0" morph="none" pos="word" start_char="3876">They</TOKEN>
<TOKEN end_char="3884" id="token-32-1" morph="none" pos="word" start_char="3881">tend</TOKEN>
<TOKEN end_char="3887" id="token-32-2" morph="none" pos="word" start_char="3886">to</TOKEN>
<TOKEN end_char="3892" id="token-32-3" morph="none" pos="word" start_char="3889">live</TOKEN>
<TOKEN end_char="3899" id="token-32-4" morph="none" pos="word" start_char="3894">longer</TOKEN>
<TOKEN end_char="3902" id="token-32-5" morph="none" pos="word" start_char="3901">on</TOKEN>
<TOKEN end_char="3918" id="token-32-6" morph="none" pos="unknown" start_char="3904">water-resistant</TOKEN>
<TOKEN end_char="3927" id="token-32-7" morph="none" pos="word" start_char="3920">surfaces</TOKEN>
<TOKEN end_char="3928" id="token-32-8" morph="none" pos="punct" start_char="3928">,</TOKEN>
<TOKEN end_char="3933" id="token-32-9" morph="none" pos="word" start_char="3930">such</TOKEN>
<TOKEN end_char="3936" id="token-32-10" morph="none" pos="word" start_char="3935">as</TOKEN>
<TOKEN end_char="3946" id="token-32-11" morph="none" pos="word" start_char="3938">stainless</TOKEN>
<TOKEN end_char="3952" id="token-32-12" morph="none" pos="word" start_char="3948">steel</TOKEN>
<TOKEN end_char="3956" id="token-32-13" morph="none" pos="word" start_char="3954">and</TOKEN>
<TOKEN end_char="3965" id="token-32-14" morph="none" pos="word" start_char="3958">plastics</TOKEN>
<TOKEN end_char="3966" id="token-32-15" morph="none" pos="punct" start_char="3966">.</TOKEN>
</SEG>
<SEG end_char="4109" id="segment-33" start_char="3969">
<ORIGINAL_TEXT>A cold virus can sometimes survive on indoor surfaces for several days, although its ability to cause infection drops dramatically over time.</ORIGINAL_TEXT>
<TOKEN end_char="3969" id="token-33-0" morph="none" pos="word" start_char="3969">A</TOKEN>
<TOKEN end_char="3974" id="token-33-1" morph="none" pos="word" start_char="3971">cold</TOKEN>
<TOKEN end_char="3980" id="token-33-2" morph="none" pos="word" start_char="3976">virus</TOKEN>
<TOKEN end_char="3984" id="token-33-3" morph="none" pos="word" start_char="3982">can</TOKEN>
<TOKEN end_char="3994" id="token-33-4" morph="none" pos="word" start_char="3986">sometimes</TOKEN>
<TOKEN end_char="4002" id="token-33-5" morph="none" pos="word" start_char="3996">survive</TOKEN>
<TOKEN end_char="4005" id="token-33-6" morph="none" pos="word" start_char="4004">on</TOKEN>
<TOKEN end_char="4012" id="token-33-7" morph="none" pos="word" start_char="4007">indoor</TOKEN>
<TOKEN end_char="4021" id="token-33-8" morph="none" pos="word" start_char="4014">surfaces</TOKEN>
<TOKEN end_char="4025" id="token-33-9" morph="none" pos="word" start_char="4023">for</TOKEN>
<TOKEN end_char="4033" id="token-33-10" morph="none" pos="word" start_char="4027">several</TOKEN>
<TOKEN end_char="4038" id="token-33-11" morph="none" pos="word" start_char="4035">days</TOKEN>
<TOKEN end_char="4039" id="token-33-12" morph="none" pos="punct" start_char="4039">,</TOKEN>
<TOKEN end_char="4048" id="token-33-13" morph="none" pos="word" start_char="4041">although</TOKEN>
<TOKEN end_char="4052" id="token-33-14" morph="none" pos="word" start_char="4050">its</TOKEN>
<TOKEN end_char="4060" id="token-33-15" morph="none" pos="word" start_char="4054">ability</TOKEN>
<TOKEN end_char="4063" id="token-33-16" morph="none" pos="word" start_char="4062">to</TOKEN>
<TOKEN end_char="4069" id="token-33-17" morph="none" pos="word" start_char="4065">cause</TOKEN>
<TOKEN end_char="4079" id="token-33-18" morph="none" pos="word" start_char="4071">infection</TOKEN>
<TOKEN end_char="4085" id="token-33-19" morph="none" pos="word" start_char="4081">drops</TOKEN>
<TOKEN end_char="4098" id="token-33-20" morph="none" pos="word" start_char="4087">dramatically</TOKEN>
<TOKEN end_char="4103" id="token-33-21" morph="none" pos="word" start_char="4100">over</TOKEN>
<TOKEN end_char="4108" id="token-33-22" morph="none" pos="word" start_char="4105">time</TOKEN>
<TOKEN end_char="4109" id="token-33-23" morph="none" pos="punct" start_char="4109">.</TOKEN>
</SEG>
<SEG end_char="4272" id="segment-34" start_char="4112">
<ORIGINAL_TEXT>Flu viruses can survive in the air for several hours, especially at lower temperatures, and on hard surfaces they can survive and remain infectious for 24 hours.</ORIGINAL_TEXT>
<TOKEN end_char="4114" id="token-34-0" morph="none" pos="word" start_char="4112">Flu</TOKEN>
<TOKEN end_char="4122" id="token-34-1" morph="none" pos="word" start_char="4116">viruses</TOKEN>
<TOKEN end_char="4126" id="token-34-2" morph="none" pos="word" start_char="4124">can</TOKEN>
<TOKEN end_char="4134" id="token-34-3" morph="none" pos="word" start_char="4128">survive</TOKEN>
<TOKEN end_char="4137" id="token-34-4" morph="none" pos="word" start_char="4136">in</TOKEN>
<TOKEN end_char="4141" id="token-34-5" morph="none" pos="word" start_char="4139">the</TOKEN>
<TOKEN end_char="4145" id="token-34-6" morph="none" pos="word" start_char="4143">air</TOKEN>
<TOKEN end_char="4149" id="token-34-7" morph="none" pos="word" start_char="4147">for</TOKEN>
<TOKEN end_char="4157" id="token-34-8" morph="none" pos="word" start_char="4151">several</TOKEN>
<TOKEN end_char="4163" id="token-34-9" morph="none" pos="word" start_char="4159">hours</TOKEN>
<TOKEN end_char="4164" id="token-34-10" morph="none" pos="punct" start_char="4164">,</TOKEN>
<TOKEN end_char="4175" id="token-34-11" morph="none" pos="word" start_char="4166">especially</TOKEN>
<TOKEN end_char="4178" id="token-34-12" morph="none" pos="word" start_char="4177">at</TOKEN>
<TOKEN end_char="4184" id="token-34-13" morph="none" pos="word" start_char="4180">lower</TOKEN>
<TOKEN end_char="4197" id="token-34-14" morph="none" pos="word" start_char="4186">temperatures</TOKEN>
<TOKEN end_char="4198" id="token-34-15" morph="none" pos="punct" start_char="4198">,</TOKEN>
<TOKEN end_char="4202" id="token-34-16" morph="none" pos="word" start_char="4200">and</TOKEN>
<TOKEN end_char="4205" id="token-34-17" morph="none" pos="word" start_char="4204">on</TOKEN>
<TOKEN end_char="4210" id="token-34-18" morph="none" pos="word" start_char="4207">hard</TOKEN>
<TOKEN end_char="4219" id="token-34-19" morph="none" pos="word" start_char="4212">surfaces</TOKEN>
<TOKEN end_char="4224" id="token-34-20" morph="none" pos="word" start_char="4221">they</TOKEN>
<TOKEN end_char="4228" id="token-34-21" morph="none" pos="word" start_char="4226">can</TOKEN>
<TOKEN end_char="4236" id="token-34-22" morph="none" pos="word" start_char="4230">survive</TOKEN>
<TOKEN end_char="4240" id="token-34-23" morph="none" pos="word" start_char="4238">and</TOKEN>
<TOKEN end_char="4247" id="token-34-24" morph="none" pos="word" start_char="4242">remain</TOKEN>
<TOKEN end_char="4258" id="token-34-25" morph="none" pos="word" start_char="4249">infectious</TOKEN>
<TOKEN end_char="4262" id="token-34-26" morph="none" pos="word" start_char="4260">for</TOKEN>
<TOKEN end_char="4265" id="token-34-27" morph="none" pos="word" start_char="4264">24</TOKEN>
<TOKEN end_char="4271" id="token-34-28" morph="none" pos="word" start_char="4267">hours</TOKEN>
<TOKEN end_char="4272" id="token-34-29" morph="none" pos="punct" start_char="4272">.</TOKEN>
</SEG>
<SEG end_char="4388" id="segment-35" start_char="4275">
<ORIGINAL_TEXT>Enteric viruses, such as norovirus and hepatitis A, can survive for weeks on a surface if conditions are suitable.</ORIGINAL_TEXT>
<TOKEN end_char="4281" id="token-35-0" morph="none" pos="word" start_char="4275">Enteric</TOKEN>
<TOKEN end_char="4289" id="token-35-1" morph="none" pos="word" start_char="4283">viruses</TOKEN>
<TOKEN end_char="4290" id="token-35-2" morph="none" pos="punct" start_char="4290">,</TOKEN>
<TOKEN end_char="4295" id="token-35-3" morph="none" pos="word" start_char="4292">such</TOKEN>
<TOKEN end_char="4298" id="token-35-4" morph="none" pos="word" start_char="4297">as</TOKEN>
<TOKEN end_char="4308" id="token-35-5" morph="none" pos="word" start_char="4300">norovirus</TOKEN>
<TOKEN end_char="4312" id="token-35-6" morph="none" pos="word" start_char="4310">and</TOKEN>
<TOKEN end_char="4322" id="token-35-7" morph="none" pos="word" start_char="4314">hepatitis</TOKEN>
<TOKEN end_char="4324" id="token-35-8" morph="none" pos="word" start_char="4324">A</TOKEN>
<TOKEN end_char="4325" id="token-35-9" morph="none" pos="punct" start_char="4325">,</TOKEN>
<TOKEN end_char="4329" id="token-35-10" morph="none" pos="word" start_char="4327">can</TOKEN>
<TOKEN end_char="4337" id="token-35-11" morph="none" pos="word" start_char="4331">survive</TOKEN>
<TOKEN end_char="4341" id="token-35-12" morph="none" pos="word" start_char="4339">for</TOKEN>
<TOKEN end_char="4347" id="token-35-13" morph="none" pos="word" start_char="4343">weeks</TOKEN>
<TOKEN end_char="4350" id="token-35-14" morph="none" pos="word" start_char="4349">on</TOKEN>
<TOKEN end_char="4352" id="token-35-15" morph="none" pos="word" start_char="4352">a</TOKEN>
<TOKEN end_char="4360" id="token-35-16" morph="none" pos="word" start_char="4354">surface</TOKEN>
<TOKEN end_char="4363" id="token-35-17" morph="none" pos="word" start_char="4362">if</TOKEN>
<TOKEN end_char="4374" id="token-35-18" morph="none" pos="word" start_char="4365">conditions</TOKEN>
<TOKEN end_char="4378" id="token-35-19" morph="none" pos="word" start_char="4376">are</TOKEN>
<TOKEN end_char="4387" id="token-35-20" morph="none" pos="word" start_char="4380">suitable</TOKEN>
<TOKEN end_char="4388" id="token-35-21" morph="none" pos="punct" start_char="4388">.</TOKEN>
</SEG>
<SEG end_char="4482" id="segment-36" start_char="4390">
<ORIGINAL_TEXT>The norovirus is known for causing sickness outbreaks in schools, cruise ships and hospitals.</ORIGINAL_TEXT>
<TOKEN end_char="4392" id="token-36-0" morph="none" pos="word" start_char="4390">The</TOKEN>
<TOKEN end_char="4402" id="token-36-1" morph="none" pos="word" start_char="4394">norovirus</TOKEN>
<TOKEN end_char="4405" id="token-36-2" morph="none" pos="word" start_char="4404">is</TOKEN>
<TOKEN end_char="4411" id="token-36-3" morph="none" pos="word" start_char="4407">known</TOKEN>
<TOKEN end_char="4415" id="token-36-4" morph="none" pos="word" start_char="4413">for</TOKEN>
<TOKEN end_char="4423" id="token-36-5" morph="none" pos="word" start_char="4417">causing</TOKEN>
<TOKEN end_char="4432" id="token-36-6" morph="none" pos="word" start_char="4425">sickness</TOKEN>
<TOKEN end_char="4442" id="token-36-7" morph="none" pos="word" start_char="4434">outbreaks</TOKEN>
<TOKEN end_char="4445" id="token-36-8" morph="none" pos="word" start_char="4444">in</TOKEN>
<TOKEN end_char="4453" id="token-36-9" morph="none" pos="word" start_char="4447">schools</TOKEN>
<TOKEN end_char="4454" id="token-36-10" morph="none" pos="punct" start_char="4454">,</TOKEN>
<TOKEN end_char="4461" id="token-36-11" morph="none" pos="word" start_char="4456">cruise</TOKEN>
<TOKEN end_char="4467" id="token-36-12" morph="none" pos="word" start_char="4463">ships</TOKEN>
<TOKEN end_char="4471" id="token-36-13" morph="none" pos="word" start_char="4469">and</TOKEN>
<TOKEN end_char="4481" id="token-36-14" morph="none" pos="word" start_char="4473">hospitals</TOKEN>
<TOKEN end_char="4482" id="token-36-15" morph="none" pos="punct" start_char="4482">.</TOKEN>
</SEG>
<SEG end_char="4494" id="segment-37" start_char="4485">
<ORIGINAL_TEXT>Read more:</ORIGINAL_TEXT>
<TOKEN end_char="4488" id="token-37-0" morph="none" pos="word" start_char="4485">Read</TOKEN>
<TOKEN end_char="4493" id="token-37-1" morph="none" pos="word" start_char="4490">more</TOKEN>
<TOKEN end_char="4494" id="token-37-2" morph="none" pos="punct" start_char="4494">:</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
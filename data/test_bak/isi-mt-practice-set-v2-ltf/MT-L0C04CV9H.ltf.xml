<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CV9H" lang="spa" raw_text_char_length="7529" raw_text_md5="303126968af7ed0b30f3ce222ac37ce3" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="99" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Estudio del CDS (versión mejorada del MMS, dióxido de cloro) en 104 humanos infectados por COVID-19</ORIGINAL_TEXT>
<TOKEN end_char="7" id="token-0-0" morph="none" pos="word" start_char="1">Estudio</TOKEN>
<TOKEN end_char="11" id="token-0-1" morph="none" pos="word" start_char="9">del</TOKEN>
<TOKEN end_char="15" id="token-0-2" morph="none" pos="word" start_char="13">CDS</TOKEN>
<TOKEN end_char="17" id="token-0-3" morph="none" pos="punct" start_char="17">(</TOKEN>
<TOKEN end_char="24" id="token-0-4" morph="none" pos="word" start_char="18">versión</TOKEN>
<TOKEN end_char="33" id="token-0-5" morph="none" pos="word" start_char="26">mejorada</TOKEN>
<TOKEN end_char="37" id="token-0-6" morph="none" pos="word" start_char="35">del</TOKEN>
<TOKEN end_char="41" id="token-0-7" morph="none" pos="word" start_char="39">MMS</TOKEN>
<TOKEN end_char="42" id="token-0-8" morph="none" pos="punct" start_char="42">,</TOKEN>
<TOKEN end_char="50" id="token-0-9" morph="none" pos="word" start_char="44">dióxido</TOKEN>
<TOKEN end_char="53" id="token-0-10" morph="none" pos="word" start_char="52">de</TOKEN>
<TOKEN end_char="59" id="token-0-11" morph="none" pos="word" start_char="55">cloro</TOKEN>
<TOKEN end_char="60" id="token-0-12" morph="none" pos="punct" start_char="60">)</TOKEN>
<TOKEN end_char="63" id="token-0-13" morph="none" pos="word" start_char="62">en</TOKEN>
<TOKEN end_char="67" id="token-0-14" morph="none" pos="word" start_char="65">104</TOKEN>
<TOKEN end_char="75" id="token-0-15" morph="none" pos="word" start_char="69">humanos</TOKEN>
<TOKEN end_char="86" id="token-0-16" morph="none" pos="word" start_char="77">infectados</TOKEN>
<TOKEN end_char="90" id="token-0-17" morph="none" pos="word" start_char="88">por</TOKEN>
<TOKEN end_char="99" id="token-0-18" morph="none" pos="unknown" start_char="92">COVID-19</TOKEN>
<TRANSLATED_TEXT>Study of CDS (improved version of MMS, chlorine dioxide) in 104 humans infected with COVID-19</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="203" id="segment-1" start_char="103">
<ORIGINAL_TEXT>Supongo que automáticamente este post será reducido a la nada o enviado al subforo de conspiraciones.</ORIGINAL_TEXT>
<TOKEN end_char="109" id="token-1-0" morph="none" pos="word" start_char="103">Supongo</TOKEN>
<TOKEN end_char="113" id="token-1-1" morph="none" pos="word" start_char="111">que</TOKEN>
<TOKEN end_char="129" id="token-1-2" morph="none" pos="word" start_char="115">automáticamente</TOKEN>
<TOKEN end_char="134" id="token-1-3" morph="none" pos="word" start_char="131">este</TOKEN>
<TOKEN end_char="139" id="token-1-4" morph="none" pos="word" start_char="136">post</TOKEN>
<TOKEN end_char="144" id="token-1-5" morph="none" pos="word" start_char="141">será</TOKEN>
<TOKEN end_char="153" id="token-1-6" morph="none" pos="word" start_char="146">reducido</TOKEN>
<TOKEN end_char="155" id="token-1-7" morph="none" pos="word" start_char="155">a</TOKEN>
<TOKEN end_char="158" id="token-1-8" morph="none" pos="word" start_char="157">la</TOKEN>
<TOKEN end_char="163" id="token-1-9" morph="none" pos="word" start_char="160">nada</TOKEN>
<TOKEN end_char="165" id="token-1-10" morph="none" pos="word" start_char="165">o</TOKEN>
<TOKEN end_char="173" id="token-1-11" morph="none" pos="word" start_char="167">enviado</TOKEN>
<TOKEN end_char="176" id="token-1-12" morph="none" pos="word" start_char="175">al</TOKEN>
<TOKEN end_char="184" id="token-1-13" morph="none" pos="word" start_char="178">subforo</TOKEN>
<TOKEN end_char="187" id="token-1-14" morph="none" pos="word" start_char="186">de</TOKEN>
<TOKEN end_char="202" id="token-1-15" morph="none" pos="word" start_char="189">conspiraciones</TOKEN>
<TOKEN end_char="203" id="token-1-16" morph="none" pos="punct" start_char="203">.</TOKEN>
<TRANSLATED_TEXT>I guess this post will automatically be reduced to nothing or sent to the conspiracy sub-forum.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="258" id="segment-2" start_char="205">
<ORIGINAL_TEXT>Pero lo que aqui les mostrare no es magia, es ciencia.</ORIGINAL_TEXT>
<TOKEN end_char="208" id="token-2-0" morph="none" pos="word" start_char="205">Pero</TOKEN>
<TOKEN end_char="211" id="token-2-1" morph="none" pos="word" start_char="210">lo</TOKEN>
<TOKEN end_char="215" id="token-2-2" morph="none" pos="word" start_char="213">que</TOKEN>
<TOKEN end_char="220" id="token-2-3" morph="none" pos="word" start_char="217">aqui</TOKEN>
<TOKEN end_char="224" id="token-2-4" morph="none" pos="word" start_char="222">les</TOKEN>
<TOKEN end_char="233" id="token-2-5" morph="none" pos="word" start_char="226">mostrare</TOKEN>
<TOKEN end_char="236" id="token-2-6" morph="none" pos="word" start_char="235">no</TOKEN>
<TOKEN end_char="239" id="token-2-7" morph="none" pos="word" start_char="238">es</TOKEN>
<TOKEN end_char="245" id="token-2-8" morph="none" pos="word" start_char="241">magia</TOKEN>
<TOKEN end_char="246" id="token-2-9" morph="none" pos="punct" start_char="246">,</TOKEN>
<TOKEN end_char="249" id="token-2-10" morph="none" pos="word" start_char="248">es</TOKEN>
<TOKEN end_char="257" id="token-2-11" morph="none" pos="word" start_char="251">ciencia</TOKEN>
<TOKEN end_char="258" id="token-2-12" morph="none" pos="punct" start_char="258">.</TOKEN>
<TRANSLATED_TEXT>But what we 're showing you here is not magic, it' s science.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="401" id="segment-3" start_char="260">
<ORIGINAL_TEXT>Se trata del primer estudio bien documentado de tratamiento del virus SarsCoV2 mediante el uso de dióxido de cloro vía oral y vía intravenosa.</ORIGINAL_TEXT>
<TOKEN end_char="261" id="token-3-0" morph="none" pos="word" start_char="260">Se</TOKEN>
<TOKEN end_char="267" id="token-3-1" morph="none" pos="word" start_char="263">trata</TOKEN>
<TOKEN end_char="271" id="token-3-2" morph="none" pos="word" start_char="269">del</TOKEN>
<TOKEN end_char="278" id="token-3-3" morph="none" pos="word" start_char="273">primer</TOKEN>
<TOKEN end_char="286" id="token-3-4" morph="none" pos="word" start_char="280">estudio</TOKEN>
<TOKEN end_char="291" id="token-3-5" morph="none" pos="word" start_char="288">bien</TOKEN>
<TOKEN end_char="303" id="token-3-6" morph="none" pos="word" start_char="293">documentado</TOKEN>
<TOKEN end_char="306" id="token-3-7" morph="none" pos="word" start_char="305">de</TOKEN>
<TOKEN end_char="318" id="token-3-8" morph="none" pos="word" start_char="308">tratamiento</TOKEN>
<TOKEN end_char="322" id="token-3-9" morph="none" pos="word" start_char="320">del</TOKEN>
<TOKEN end_char="328" id="token-3-10" morph="none" pos="word" start_char="324">virus</TOKEN>
<TOKEN end_char="337" id="token-3-11" morph="none" pos="word" start_char="330">SarsCoV2</TOKEN>
<TOKEN end_char="346" id="token-3-12" morph="none" pos="word" start_char="339">mediante</TOKEN>
<TOKEN end_char="349" id="token-3-13" morph="none" pos="word" start_char="348">el</TOKEN>
<TOKEN end_char="353" id="token-3-14" morph="none" pos="word" start_char="351">uso</TOKEN>
<TOKEN end_char="356" id="token-3-15" morph="none" pos="word" start_char="355">de</TOKEN>
<TOKEN end_char="364" id="token-3-16" morph="none" pos="word" start_char="358">dióxido</TOKEN>
<TOKEN end_char="367" id="token-3-17" morph="none" pos="word" start_char="366">de</TOKEN>
<TOKEN end_char="373" id="token-3-18" morph="none" pos="word" start_char="369">cloro</TOKEN>
<TOKEN end_char="377" id="token-3-19" morph="none" pos="word" start_char="375">vía</TOKEN>
<TOKEN end_char="382" id="token-3-20" morph="none" pos="word" start_char="379">oral</TOKEN>
<TOKEN end_char="384" id="token-3-21" morph="none" pos="word" start_char="384">y</TOKEN>
<TOKEN end_char="388" id="token-3-22" morph="none" pos="word" start_char="386">vía</TOKEN>
<TOKEN end_char="400" id="token-3-23" morph="none" pos="word" start_char="390">intravenosa</TOKEN>
<TOKEN end_char="401" id="token-3-24" morph="none" pos="punct" start_char="401">.</TOKEN>
<TRANSLATED_TEXT>This is the first well-documented study of SarsCoV2 virus treatment using chlorine dioxide orally and intravenously.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="503" id="segment-4" start_char="404">
<ORIGINAL_TEXT>Estudio del CDS (versión mejorada del MMS, dióxido de cloro) en 104 humanos infectados por COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="410" id="token-4-0" morph="none" pos="word" start_char="404">Estudio</TOKEN>
<TOKEN end_char="414" id="token-4-1" morph="none" pos="word" start_char="412">del</TOKEN>
<TOKEN end_char="418" id="token-4-2" morph="none" pos="word" start_char="416">CDS</TOKEN>
<TOKEN end_char="420" id="token-4-3" morph="none" pos="punct" start_char="420">(</TOKEN>
<TOKEN end_char="427" id="token-4-4" morph="none" pos="word" start_char="421">versión</TOKEN>
<TOKEN end_char="436" id="token-4-5" morph="none" pos="word" start_char="429">mejorada</TOKEN>
<TOKEN end_char="440" id="token-4-6" morph="none" pos="word" start_char="438">del</TOKEN>
<TOKEN end_char="444" id="token-4-7" morph="none" pos="word" start_char="442">MMS</TOKEN>
<TOKEN end_char="445" id="token-4-8" morph="none" pos="punct" start_char="445">,</TOKEN>
<TOKEN end_char="453" id="token-4-9" morph="none" pos="word" start_char="447">dióxido</TOKEN>
<TOKEN end_char="456" id="token-4-10" morph="none" pos="word" start_char="455">de</TOKEN>
<TOKEN end_char="462" id="token-4-11" morph="none" pos="word" start_char="458">cloro</TOKEN>
<TOKEN end_char="463" id="token-4-12" morph="none" pos="punct" start_char="463">)</TOKEN>
<TOKEN end_char="466" id="token-4-13" morph="none" pos="word" start_char="465">en</TOKEN>
<TOKEN end_char="470" id="token-4-14" morph="none" pos="word" start_char="468">104</TOKEN>
<TOKEN end_char="478" id="token-4-15" morph="none" pos="word" start_char="472">humanos</TOKEN>
<TOKEN end_char="489" id="token-4-16" morph="none" pos="word" start_char="480">infectados</TOKEN>
<TOKEN end_char="493" id="token-4-17" morph="none" pos="word" start_char="491">por</TOKEN>
<TOKEN end_char="502" id="token-4-18" morph="none" pos="unknown" start_char="495">COVID-19</TOKEN>
<TOKEN end_char="503" id="token-4-19" morph="none" pos="punct" start_char="503">.</TOKEN>
<TRANSLATED_TEXT>Study of CDS (improved version of MMS, chlorine dioxide) in 104 humans infected with COVID-19.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="829" id="segment-5" start_char="506">
<ORIGINAL_TEXT>Aquí tenéis el documento oficial de ensayo clínico preliminar en Ecuador de CDS Oral e intravenoso de la asociación médica de AEMEMI con acta notarial firmada y datos fidedignos que demuestran la eficacia del Dióxido de cloro tanto Oral como Parenteral como sustancia eficaz contra el coronavirus con una eficacia de un 97%.</ORIGINAL_TEXT>
<TOKEN end_char="509" id="token-5-0" morph="none" pos="word" start_char="506">Aquí</TOKEN>
<TOKEN end_char="516" id="token-5-1" morph="none" pos="word" start_char="511">tenéis</TOKEN>
<TOKEN end_char="519" id="token-5-2" morph="none" pos="word" start_char="518">el</TOKEN>
<TOKEN end_char="529" id="token-5-3" morph="none" pos="word" start_char="521">documento</TOKEN>
<TOKEN end_char="537" id="token-5-4" morph="none" pos="word" start_char="531">oficial</TOKEN>
<TOKEN end_char="540" id="token-5-5" morph="none" pos="word" start_char="539">de</TOKEN>
<TOKEN end_char="547" id="token-5-6" morph="none" pos="word" start_char="542">ensayo</TOKEN>
<TOKEN end_char="555" id="token-5-7" morph="none" pos="word" start_char="549">clínico</TOKEN>
<TOKEN end_char="566" id="token-5-8" morph="none" pos="word" start_char="557">preliminar</TOKEN>
<TOKEN end_char="569" id="token-5-9" morph="none" pos="word" start_char="568">en</TOKEN>
<TOKEN end_char="577" id="token-5-10" morph="none" pos="word" start_char="571">Ecuador</TOKEN>
<TOKEN end_char="580" id="token-5-11" morph="none" pos="word" start_char="579">de</TOKEN>
<TOKEN end_char="584" id="token-5-12" morph="none" pos="word" start_char="582">CDS</TOKEN>
<TOKEN end_char="589" id="token-5-13" morph="none" pos="word" start_char="586">Oral</TOKEN>
<TOKEN end_char="591" id="token-5-14" morph="none" pos="word" start_char="591">e</TOKEN>
<TOKEN end_char="603" id="token-5-15" morph="none" pos="word" start_char="593">intravenoso</TOKEN>
<TOKEN end_char="606" id="token-5-16" morph="none" pos="word" start_char="605">de</TOKEN>
<TOKEN end_char="609" id="token-5-17" morph="none" pos="word" start_char="608">la</TOKEN>
<TOKEN end_char="620" id="token-5-18" morph="none" pos="word" start_char="611">asociación</TOKEN>
<TOKEN end_char="627" id="token-5-19" morph="none" pos="word" start_char="622">médica</TOKEN>
<TOKEN end_char="630" id="token-5-20" morph="none" pos="word" start_char="629">de</TOKEN>
<TOKEN end_char="637" id="token-5-21" morph="none" pos="word" start_char="632">AEMEMI</TOKEN>
<TOKEN end_char="641" id="token-5-22" morph="none" pos="word" start_char="639">con</TOKEN>
<TOKEN end_char="646" id="token-5-23" morph="none" pos="word" start_char="643">acta</TOKEN>
<TOKEN end_char="655" id="token-5-24" morph="none" pos="word" start_char="648">notarial</TOKEN>
<TOKEN end_char="663" id="token-5-25" morph="none" pos="word" start_char="657">firmada</TOKEN>
<TOKEN end_char="665" id="token-5-26" morph="none" pos="word" start_char="665">y</TOKEN>
<TOKEN end_char="671" id="token-5-27" morph="none" pos="word" start_char="667">datos</TOKEN>
<TOKEN end_char="682" id="token-5-28" morph="none" pos="word" start_char="673">fidedignos</TOKEN>
<TOKEN end_char="686" id="token-5-29" morph="none" pos="word" start_char="684">que</TOKEN>
<TOKEN end_char="697" id="token-5-30" morph="none" pos="word" start_char="688">demuestran</TOKEN>
<TOKEN end_char="700" id="token-5-31" morph="none" pos="word" start_char="699">la</TOKEN>
<TOKEN end_char="709" id="token-5-32" morph="none" pos="word" start_char="702">eficacia</TOKEN>
<TOKEN end_char="713" id="token-5-33" morph="none" pos="word" start_char="711">del</TOKEN>
<TOKEN end_char="721" id="token-5-34" morph="none" pos="word" start_char="715">Dióxido</TOKEN>
<TOKEN end_char="724" id="token-5-35" morph="none" pos="word" start_char="723">de</TOKEN>
<TOKEN end_char="730" id="token-5-36" morph="none" pos="word" start_char="726">cloro</TOKEN>
<TOKEN end_char="736" id="token-5-37" morph="none" pos="word" start_char="732">tanto</TOKEN>
<TOKEN end_char="741" id="token-5-38" morph="none" pos="word" start_char="738">Oral</TOKEN>
<TOKEN end_char="746" id="token-5-39" morph="none" pos="word" start_char="743">como</TOKEN>
<TOKEN end_char="757" id="token-5-40" morph="none" pos="word" start_char="748">Parenteral</TOKEN>
<TOKEN end_char="762" id="token-5-41" morph="none" pos="word" start_char="759">como</TOKEN>
<TOKEN end_char="772" id="token-5-42" morph="none" pos="word" start_char="764">sustancia</TOKEN>
<TOKEN end_char="779" id="token-5-43" morph="none" pos="word" start_char="774">eficaz</TOKEN>
<TOKEN end_char="786" id="token-5-44" morph="none" pos="word" start_char="781">contra</TOKEN>
<TOKEN end_char="789" id="token-5-45" morph="none" pos="word" start_char="788">el</TOKEN>
<TOKEN end_char="801" id="token-5-46" morph="none" pos="word" start_char="791">coronavirus</TOKEN>
<TOKEN end_char="805" id="token-5-47" morph="none" pos="word" start_char="803">con</TOKEN>
<TOKEN end_char="809" id="token-5-48" morph="none" pos="word" start_char="807">una</TOKEN>
<TOKEN end_char="818" id="token-5-49" morph="none" pos="word" start_char="811">eficacia</TOKEN>
<TOKEN end_char="821" id="token-5-50" morph="none" pos="word" start_char="820">de</TOKEN>
<TOKEN end_char="824" id="token-5-51" morph="none" pos="word" start_char="823">un</TOKEN>
<TOKEN end_char="827" id="token-5-52" morph="none" pos="word" start_char="826">97</TOKEN>
<TOKEN end_char="829" id="token-5-53" morph="none" pos="punct" start_char="828">%.</TOKEN>
<TRANSLATED_TEXT>Here you have the official preliminary clinical trial document in Ecuador of Oral and Intravenous CDS of the medical association of AEMEMI with signed notarial deed and reliable data demonstrating the efficacy of both Oral and Parenteral chlorine dioxide as an effective substance against coronavirus with an effectiveness of 97%.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="985" id="segment-6" start_char="832">
<ORIGINAL_TEXT>¿Cuánto tardarán los medios convencionales en hablar de esta solución barata, inocua y no patentable a la supuesta pandemia actual, entre otras dolencias?</ORIGINAL_TEXT>
<TOKEN end_char="832" id="token-6-0" morph="none" pos="punct" start_char="832">¿</TOKEN>
<TOKEN end_char="838" id="token-6-1" morph="none" pos="word" start_char="833">Cuánto</TOKEN>
<TOKEN end_char="847" id="token-6-2" morph="none" pos="word" start_char="840">tardarán</TOKEN>
<TOKEN end_char="851" id="token-6-3" morph="none" pos="word" start_char="849">los</TOKEN>
<TOKEN end_char="858" id="token-6-4" morph="none" pos="word" start_char="853">medios</TOKEN>
<TOKEN end_char="873" id="token-6-5" morph="none" pos="word" start_char="860">convencionales</TOKEN>
<TOKEN end_char="876" id="token-6-6" morph="none" pos="word" start_char="875">en</TOKEN>
<TOKEN end_char="883" id="token-6-7" morph="none" pos="word" start_char="878">hablar</TOKEN>
<TOKEN end_char="886" id="token-6-8" morph="none" pos="word" start_char="885">de</TOKEN>
<TOKEN end_char="891" id="token-6-9" morph="none" pos="word" start_char="888">esta</TOKEN>
<TOKEN end_char="900" id="token-6-10" morph="none" pos="word" start_char="893">solución</TOKEN>
<TOKEN end_char="907" id="token-6-11" morph="none" pos="word" start_char="902">barata</TOKEN>
<TOKEN end_char="908" id="token-6-12" morph="none" pos="punct" start_char="908">,</TOKEN>
<TOKEN end_char="915" id="token-6-13" morph="none" pos="word" start_char="910">inocua</TOKEN>
<TOKEN end_char="917" id="token-6-14" morph="none" pos="word" start_char="917">y</TOKEN>
<TOKEN end_char="920" id="token-6-15" morph="none" pos="word" start_char="919">no</TOKEN>
<TOKEN end_char="931" id="token-6-16" morph="none" pos="word" start_char="922">patentable</TOKEN>
<TOKEN end_char="933" id="token-6-17" morph="none" pos="word" start_char="933">a</TOKEN>
<TOKEN end_char="936" id="token-6-18" morph="none" pos="word" start_char="935">la</TOKEN>
<TOKEN end_char="945" id="token-6-19" morph="none" pos="word" start_char="938">supuesta</TOKEN>
<TOKEN end_char="954" id="token-6-20" morph="none" pos="word" start_char="947">pandemia</TOKEN>
<TOKEN end_char="961" id="token-6-21" morph="none" pos="word" start_char="956">actual</TOKEN>
<TOKEN end_char="962" id="token-6-22" morph="none" pos="punct" start_char="962">,</TOKEN>
<TOKEN end_char="968" id="token-6-23" morph="none" pos="word" start_char="964">entre</TOKEN>
<TOKEN end_char="974" id="token-6-24" morph="none" pos="word" start_char="970">otras</TOKEN>
<TOKEN end_char="984" id="token-6-25" morph="none" pos="word" start_char="976">dolencias</TOKEN>
<TOKEN end_char="985" id="token-6-26" morph="none" pos="punct" start_char="985">?</TOKEN>
<TRANSLATED_TEXT>How long will it take the conventional media to talk about this cheap, innocuous and unpatentable solution to the current supposed pandemic, among other ills?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1119" id="segment-7" start_char="988">
<ORIGINAL_TEXT>El ensayo fue hecho en Guayaquil Ecuador y es de dominio público para ser distribuido libremente mientras no se altere el contenido.</ORIGINAL_TEXT>
<TOKEN end_char="989" id="token-7-0" morph="none" pos="word" start_char="988">El</TOKEN>
<TOKEN end_char="996" id="token-7-1" morph="none" pos="word" start_char="991">ensayo</TOKEN>
<TOKEN end_char="1000" id="token-7-2" morph="none" pos="word" start_char="998">fue</TOKEN>
<TOKEN end_char="1006" id="token-7-3" morph="none" pos="word" start_char="1002">hecho</TOKEN>
<TOKEN end_char="1009" id="token-7-4" morph="none" pos="word" start_char="1008">en</TOKEN>
<TOKEN end_char="1019" id="token-7-5" morph="none" pos="word" start_char="1011">Guayaquil</TOKEN>
<TOKEN end_char="1027" id="token-7-6" morph="none" pos="word" start_char="1021">Ecuador</TOKEN>
<TOKEN end_char="1029" id="token-7-7" morph="none" pos="word" start_char="1029">y</TOKEN>
<TOKEN end_char="1032" id="token-7-8" morph="none" pos="word" start_char="1031">es</TOKEN>
<TOKEN end_char="1035" id="token-7-9" morph="none" pos="word" start_char="1034">de</TOKEN>
<TOKEN end_char="1043" id="token-7-10" morph="none" pos="word" start_char="1037">dominio</TOKEN>
<TOKEN end_char="1051" id="token-7-11" morph="none" pos="word" start_char="1045">público</TOKEN>
<TOKEN end_char="1056" id="token-7-12" morph="none" pos="word" start_char="1053">para</TOKEN>
<TOKEN end_char="1060" id="token-7-13" morph="none" pos="word" start_char="1058">ser</TOKEN>
<TOKEN end_char="1072" id="token-7-14" morph="none" pos="word" start_char="1062">distribuido</TOKEN>
<TOKEN end_char="1083" id="token-7-15" morph="none" pos="word" start_char="1074">libremente</TOKEN>
<TOKEN end_char="1092" id="token-7-16" morph="none" pos="word" start_char="1085">mientras</TOKEN>
<TOKEN end_char="1095" id="token-7-17" morph="none" pos="word" start_char="1094">no</TOKEN>
<TOKEN end_char="1098" id="token-7-18" morph="none" pos="word" start_char="1097">se</TOKEN>
<TOKEN end_char="1105" id="token-7-19" morph="none" pos="word" start_char="1100">altere</TOKEN>
<TOKEN end_char="1108" id="token-7-20" morph="none" pos="word" start_char="1107">el</TOKEN>
<TOKEN end_char="1118" id="token-7-21" morph="none" pos="word" start_char="1110">contenido</TOKEN>
<TOKEN end_char="1119" id="token-7-22" morph="none" pos="punct" start_char="1119">.</TOKEN>
<TRANSLATED_TEXT>The essay was made in Guayaquil Ecuador and is in the public domain to be distributed freely as long as the content is not altered.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1156" id="segment-8" start_char="1122">
<ORIGINAL_TEXT>Se facilita en el siguiente enlace:</ORIGINAL_TEXT>
<TOKEN end_char="1123" id="token-8-0" morph="none" pos="word" start_char="1122">Se</TOKEN>
<TOKEN end_char="1132" id="token-8-1" morph="none" pos="word" start_char="1125">facilita</TOKEN>
<TOKEN end_char="1135" id="token-8-2" morph="none" pos="word" start_char="1134">en</TOKEN>
<TOKEN end_char="1138" id="token-8-3" morph="none" pos="word" start_char="1137">el</TOKEN>
<TOKEN end_char="1148" id="token-8-4" morph="none" pos="word" start_char="1140">siguiente</TOKEN>
<TOKEN end_char="1155" id="token-8-5" morph="none" pos="word" start_char="1150">enlace</TOKEN>
<TOKEN end_char="1156" id="token-8-6" morph="none" pos="punct" start_char="1156">:</TOKEN>
<TRANSLATED_TEXT>It is provided on the following link:</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1241" id="segment-9" start_char="1159">
<ORIGINAL_TEXT>https://cdn.lbryplayer.xyz/content/...af59ac186a8c3645280de725dc5/stream?download=1</ORIGINAL_TEXT>
<TOKEN end_char="1241" id="token-9-0" morph="none" pos="url" start_char="1159">https://cdn.lbryplayer.xyz/content/...af59ac186a8c3645280de725dc5/stream?download=1</TOKEN>
<TRANSLATED_TEXT>https: / / cdn.lfryplayer.xyz / content /... af59ac186a8c3645280de7 25dc5 / stream? download = 1</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="1296" id="segment-10" start_char="1244">
<ORIGINAL_TEXT>Hablamos de un estudio elaborado y firmado 7 médicos.</ORIGINAL_TEXT>
<TOKEN end_char="1251" id="token-10-0" morph="none" pos="word" start_char="1244">Hablamos</TOKEN>
<TOKEN end_char="1254" id="token-10-1" morph="none" pos="word" start_char="1253">de</TOKEN>
<TOKEN end_char="1257" id="token-10-2" morph="none" pos="word" start_char="1256">un</TOKEN>
<TOKEN end_char="1265" id="token-10-3" morph="none" pos="word" start_char="1259">estudio</TOKEN>
<TOKEN end_char="1275" id="token-10-4" morph="none" pos="word" start_char="1267">elaborado</TOKEN>
<TOKEN end_char="1277" id="token-10-5" morph="none" pos="word" start_char="1277">y</TOKEN>
<TOKEN end_char="1285" id="token-10-6" morph="none" pos="word" start_char="1279">firmado</TOKEN>
<TOKEN end_char="1287" id="token-10-7" morph="none" pos="word" start_char="1287">7</TOKEN>
<TOKEN end_char="1295" id="token-10-8" morph="none" pos="word" start_char="1289">médicos</TOKEN>
<TOKEN end_char="1296" id="token-10-9" morph="none" pos="punct" start_char="1296">.</TOKEN>
<TRANSLATED_TEXT>We are talking about an elaborate and signed study of 7 doctors.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1359" id="segment-11" start_char="1298">
<ORIGINAL_TEXT>Por favor tenganlo en cuenta antes de directamente censurarlo.</ORIGINAL_TEXT>
<TOKEN end_char="1300" id="token-11-0" morph="none" pos="word" start_char="1298">Por</TOKEN>
<TOKEN end_char="1306" id="token-11-1" morph="none" pos="word" start_char="1302">favor</TOKEN>
<TOKEN end_char="1315" id="token-11-2" morph="none" pos="word" start_char="1308">tenganlo</TOKEN>
<TOKEN end_char="1318" id="token-11-3" morph="none" pos="word" start_char="1317">en</TOKEN>
<TOKEN end_char="1325" id="token-11-4" morph="none" pos="word" start_char="1320">cuenta</TOKEN>
<TOKEN end_char="1331" id="token-11-5" morph="none" pos="word" start_char="1327">antes</TOKEN>
<TOKEN end_char="1334" id="token-11-6" morph="none" pos="word" start_char="1333">de</TOKEN>
<TOKEN end_char="1347" id="token-11-7" morph="none" pos="word" start_char="1336">directamente</TOKEN>
<TOKEN end_char="1358" id="token-11-8" morph="none" pos="word" start_char="1349">censurarlo</TOKEN>
<TOKEN end_char="1359" id="token-11-9" morph="none" pos="punct" start_char="1359">.</TOKEN>
<TRANSLATED_TEXT>Please take it into account before you directly censor it.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1429" id="segment-12" start_char="1371">
<ORIGINAL_TEXT>Opinión de Andreas Kalcker sobre este estudio de Guayaquil.</ORIGINAL_TEXT>
<TOKEN end_char="1377" id="token-12-0" morph="none" pos="word" start_char="1371">Opinión</TOKEN>
<TOKEN end_char="1380" id="token-12-1" morph="none" pos="word" start_char="1379">de</TOKEN>
<TOKEN end_char="1388" id="token-12-2" morph="none" pos="word" start_char="1382">Andreas</TOKEN>
<TOKEN end_char="1396" id="token-12-3" morph="none" pos="word" start_char="1390">Kalcker</TOKEN>
<TOKEN end_char="1402" id="token-12-4" morph="none" pos="word" start_char="1398">sobre</TOKEN>
<TOKEN end_char="1407" id="token-12-5" morph="none" pos="word" start_char="1404">este</TOKEN>
<TOKEN end_char="1415" id="token-12-6" morph="none" pos="word" start_char="1409">estudio</TOKEN>
<TOKEN end_char="1418" id="token-12-7" morph="none" pos="word" start_char="1417">de</TOKEN>
<TOKEN end_char="1428" id="token-12-8" morph="none" pos="word" start_char="1420">Guayaquil</TOKEN>
<TOKEN end_char="1429" id="token-12-9" morph="none" pos="punct" start_char="1429">.</TOKEN>
<TRANSLATED_TEXT>Opinion of Andreas Kalcker on this study of Guayaquil.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1470" id="segment-13" start_char="1433">
<ORIGINAL_TEXT>Resume es demasiada información diaria</ORIGINAL_TEXT>
<TOKEN end_char="1438" id="token-13-0" morph="none" pos="word" start_char="1433">Resume</TOKEN>
<TOKEN end_char="1441" id="token-13-1" morph="none" pos="word" start_char="1440">es</TOKEN>
<TOKEN end_char="1451" id="token-13-2" morph="none" pos="word" start_char="1443">demasiada</TOKEN>
<TOKEN end_char="1463" id="token-13-3" morph="none" pos="word" start_char="1453">información</TOKEN>
<TOKEN end_char="1470" id="token-13-4" morph="none" pos="word" start_char="1465">diaria</TOKEN>
<TRANSLATED_TEXT>Summary is too much daily information</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1544" id="segment-14" start_char="1474">
<ORIGINAL_TEXT>Por favor, como dije se trata de un estudio realizado en 104 pacientes.</ORIGINAL_TEXT>
<TOKEN end_char="1476" id="token-14-0" morph="none" pos="word" start_char="1474">Por</TOKEN>
<TOKEN end_char="1482" id="token-14-1" morph="none" pos="word" start_char="1478">favor</TOKEN>
<TOKEN end_char="1483" id="token-14-2" morph="none" pos="punct" start_char="1483">,</TOKEN>
<TOKEN end_char="1488" id="token-14-3" morph="none" pos="word" start_char="1485">como</TOKEN>
<TOKEN end_char="1493" id="token-14-4" morph="none" pos="word" start_char="1490">dije</TOKEN>
<TOKEN end_char="1496" id="token-14-5" morph="none" pos="word" start_char="1495">se</TOKEN>
<TOKEN end_char="1502" id="token-14-6" morph="none" pos="word" start_char="1498">trata</TOKEN>
<TOKEN end_char="1505" id="token-14-7" morph="none" pos="word" start_char="1504">de</TOKEN>
<TOKEN end_char="1508" id="token-14-8" morph="none" pos="word" start_char="1507">un</TOKEN>
<TOKEN end_char="1516" id="token-14-9" morph="none" pos="word" start_char="1510">estudio</TOKEN>
<TOKEN end_char="1526" id="token-14-10" morph="none" pos="word" start_char="1518">realizado</TOKEN>
<TOKEN end_char="1529" id="token-14-11" morph="none" pos="word" start_char="1528">en</TOKEN>
<TOKEN end_char="1533" id="token-14-12" morph="none" pos="word" start_char="1531">104</TOKEN>
<TOKEN end_char="1543" id="token-14-13" morph="none" pos="word" start_char="1535">pacientes</TOKEN>
<TOKEN end_char="1544" id="token-14-14" morph="none" pos="punct" start_char="1544">.</TOKEN>
<TRANSLATED_TEXT>Please, as I said, this is a study done on 104 patients.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1636" id="segment-15" start_char="1546">
<ORIGINAL_TEXT>Tienen los consentimientos informados, diversas pruebas PCR y otras dentro del PDF anexado.</ORIGINAL_TEXT>
<TOKEN end_char="1551" id="token-15-0" morph="none" pos="word" start_char="1546">Tienen</TOKEN>
<TOKEN end_char="1555" id="token-15-1" morph="none" pos="word" start_char="1553">los</TOKEN>
<TOKEN end_char="1571" id="token-15-2" morph="none" pos="word" start_char="1557">consentimientos</TOKEN>
<TOKEN end_char="1582" id="token-15-3" morph="none" pos="word" start_char="1573">informados</TOKEN>
<TOKEN end_char="1583" id="token-15-4" morph="none" pos="punct" start_char="1583">,</TOKEN>
<TOKEN end_char="1592" id="token-15-5" morph="none" pos="word" start_char="1585">diversas</TOKEN>
<TOKEN end_char="1600" id="token-15-6" morph="none" pos="word" start_char="1594">pruebas</TOKEN>
<TOKEN end_char="1604" id="token-15-7" morph="none" pos="word" start_char="1602">PCR</TOKEN>
<TOKEN end_char="1606" id="token-15-8" morph="none" pos="word" start_char="1606">y</TOKEN>
<TOKEN end_char="1612" id="token-15-9" morph="none" pos="word" start_char="1608">otras</TOKEN>
<TOKEN end_char="1619" id="token-15-10" morph="none" pos="word" start_char="1614">dentro</TOKEN>
<TOKEN end_char="1623" id="token-15-11" morph="none" pos="word" start_char="1621">del</TOKEN>
<TOKEN end_char="1627" id="token-15-12" morph="none" pos="word" start_char="1625">PDF</TOKEN>
<TOKEN end_char="1635" id="token-15-13" morph="none" pos="word" start_char="1629">anexado</TOKEN>
<TOKEN end_char="1636" id="token-15-14" morph="none" pos="punct" start_char="1636">.</TOKEN>
<TRANSLATED_TEXT>They have informed consent, various PCR tests and others within the attached PDF.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1745" id="segment-16" start_char="1639">
<ORIGINAL_TEXT>No deberiamos cerrarnos ante nuevos problemas...ya que los nuevos problemas necesitan de nuevas soluciones.</ORIGINAL_TEXT>
<TOKEN end_char="1640" id="token-16-0" morph="none" pos="word" start_char="1639">No</TOKEN>
<TOKEN end_char="1651" id="token-16-1" morph="none" pos="word" start_char="1642">deberiamos</TOKEN>
<TOKEN end_char="1661" id="token-16-2" morph="none" pos="word" start_char="1653">cerrarnos</TOKEN>
<TOKEN end_char="1666" id="token-16-3" morph="none" pos="word" start_char="1663">ante</TOKEN>
<TOKEN end_char="1673" id="token-16-4" morph="none" pos="word" start_char="1668">nuevos</TOKEN>
<TOKEN end_char="1688" id="token-16-5" morph="none" pos="unknown" start_char="1675">problemas...ya</TOKEN>
<TOKEN end_char="1692" id="token-16-6" morph="none" pos="word" start_char="1690">que</TOKEN>
<TOKEN end_char="1696" id="token-16-7" morph="none" pos="word" start_char="1694">los</TOKEN>
<TOKEN end_char="1703" id="token-16-8" morph="none" pos="word" start_char="1698">nuevos</TOKEN>
<TOKEN end_char="1713" id="token-16-9" morph="none" pos="word" start_char="1705">problemas</TOKEN>
<TOKEN end_char="1723" id="token-16-10" morph="none" pos="word" start_char="1715">necesitan</TOKEN>
<TOKEN end_char="1726" id="token-16-11" morph="none" pos="word" start_char="1725">de</TOKEN>
<TOKEN end_char="1733" id="token-16-12" morph="none" pos="word" start_char="1728">nuevas</TOKEN>
<TOKEN end_char="1744" id="token-16-13" morph="none" pos="word" start_char="1735">soluciones</TOKEN>
<TOKEN end_char="1745" id="token-16-14" morph="none" pos="punct" start_char="1745">.</TOKEN>
<TRANSLATED_TEXT>We should not close ourselves to new problems... because new problems need new solutions.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1858" id="segment-17" start_char="1749">
<ORIGINAL_TEXT>Mientras aqui no se buscan soluciones, el viceministro de salud de Ecuador ha estado presente en este estudio.</ORIGINAL_TEXT>
<TOKEN end_char="1756" id="token-17-0" morph="none" pos="word" start_char="1749">Mientras</TOKEN>
<TOKEN end_char="1761" id="token-17-1" morph="none" pos="word" start_char="1758">aqui</TOKEN>
<TOKEN end_char="1764" id="token-17-2" morph="none" pos="word" start_char="1763">no</TOKEN>
<TOKEN end_char="1767" id="token-17-3" morph="none" pos="word" start_char="1766">se</TOKEN>
<TOKEN end_char="1774" id="token-17-4" morph="none" pos="word" start_char="1769">buscan</TOKEN>
<TOKEN end_char="1785" id="token-17-5" morph="none" pos="word" start_char="1776">soluciones</TOKEN>
<TOKEN end_char="1786" id="token-17-6" morph="none" pos="punct" start_char="1786">,</TOKEN>
<TOKEN end_char="1789" id="token-17-7" morph="none" pos="word" start_char="1788">el</TOKEN>
<TOKEN end_char="1802" id="token-17-8" morph="none" pos="word" start_char="1791">viceministro</TOKEN>
<TOKEN end_char="1805" id="token-17-9" morph="none" pos="word" start_char="1804">de</TOKEN>
<TOKEN end_char="1811" id="token-17-10" morph="none" pos="word" start_char="1807">salud</TOKEN>
<TOKEN end_char="1814" id="token-17-11" morph="none" pos="word" start_char="1813">de</TOKEN>
<TOKEN end_char="1822" id="token-17-12" morph="none" pos="word" start_char="1816">Ecuador</TOKEN>
<TOKEN end_char="1825" id="token-17-13" morph="none" pos="word" start_char="1824">ha</TOKEN>
<TOKEN end_char="1832" id="token-17-14" morph="none" pos="word" start_char="1827">estado</TOKEN>
<TOKEN end_char="1841" id="token-17-15" morph="none" pos="word" start_char="1834">presente</TOKEN>
<TOKEN end_char="1844" id="token-17-16" morph="none" pos="word" start_char="1843">en</TOKEN>
<TOKEN end_char="1849" id="token-17-17" morph="none" pos="word" start_char="1846">este</TOKEN>
<TOKEN end_char="1857" id="token-17-18" morph="none" pos="word" start_char="1851">estudio</TOKEN>
<TOKEN end_char="1858" id="token-17-19" morph="none" pos="punct" start_char="1858">.</TOKEN>
<TRANSLATED_TEXT>While solutions are not being sought here, Ecuador's Deputy Minister of Health has been present at this study.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1917" id="segment-18" start_char="1862">
<ORIGINAL_TEXT>manutartufo dijo: Resume es demasiada información diaria</ORIGINAL_TEXT>
<TOKEN end_char="1872" id="token-18-0" morph="none" pos="word" start_char="1862">manutartufo</TOKEN>
<TOKEN end_char="1877" id="token-18-1" morph="none" pos="word" start_char="1874">dijo</TOKEN>
<TOKEN end_char="1878" id="token-18-2" morph="none" pos="punct" start_char="1878">:</TOKEN>
<TOKEN end_char="1885" id="token-18-3" morph="none" pos="word" start_char="1880">Resume</TOKEN>
<TOKEN end_char="1888" id="token-18-4" morph="none" pos="word" start_char="1887">es</TOKEN>
<TOKEN end_char="1898" id="token-18-5" morph="none" pos="word" start_char="1890">demasiada</TOKEN>
<TOKEN end_char="1910" id="token-18-6" morph="none" pos="word" start_char="1900">información</TOKEN>
<TOKEN end_char="1917" id="token-18-7" morph="none" pos="word" start_char="1912">diaria</TOKEN>
<TRANSLATED_TEXT>Mantarufo said: Resume is too much daily information</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1951" id="segment-19" start_char="1921">
<ORIGINAL_TEXT>La ultima imagen es el resumen.</ORIGINAL_TEXT>
<TOKEN end_char="1922" id="token-19-0" morph="none" pos="word" start_char="1921">La</TOKEN>
<TOKEN end_char="1929" id="token-19-1" morph="none" pos="word" start_char="1924">ultima</TOKEN>
<TOKEN end_char="1936" id="token-19-2" morph="none" pos="word" start_char="1931">imagen</TOKEN>
<TOKEN end_char="1939" id="token-19-3" morph="none" pos="word" start_char="1938">es</TOKEN>
<TOKEN end_char="1942" id="token-19-4" morph="none" pos="word" start_char="1941">el</TOKEN>
<TOKEN end_char="1950" id="token-19-5" morph="none" pos="word" start_char="1944">resumen</TOKEN>
<TOKEN end_char="1951" id="token-19-6" morph="none" pos="punct" start_char="1951">.</TOKEN>
<TRANSLATED_TEXT>The last image is the summary.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="2131" id="segment-20" start_char="1955">
<ORIGINAL_TEXT>Tranquilo AUNQUE YA SABEMOS QUE FUNCIONA contra el COVID, AQUI LOS FENOMENOS te van a pedir Estudios DOBLE CIEGO esos que NO TIENEN las VACUNA DE FAUCI y KILL GATES jojojojojojo</ORIGINAL_TEXT>
<TOKEN end_char="1963" id="token-20-0" morph="none" pos="word" start_char="1955">Tranquilo</TOKEN>
<TOKEN end_char="1970" id="token-20-1" morph="none" pos="word" start_char="1965">AUNQUE</TOKEN>
<TOKEN end_char="1973" id="token-20-2" morph="none" pos="word" start_char="1972">YA</TOKEN>
<TOKEN end_char="1981" id="token-20-3" morph="none" pos="word" start_char="1975">SABEMOS</TOKEN>
<TOKEN end_char="1985" id="token-20-4" morph="none" pos="word" start_char="1983">QUE</TOKEN>
<TOKEN end_char="1994" id="token-20-5" morph="none" pos="word" start_char="1987">FUNCIONA</TOKEN>
<TOKEN end_char="2001" id="token-20-6" morph="none" pos="word" start_char="1996">contra</TOKEN>
<TOKEN end_char="2004" id="token-20-7" morph="none" pos="word" start_char="2003">el</TOKEN>
<TOKEN end_char="2010" id="token-20-8" morph="none" pos="word" start_char="2006">COVID</TOKEN>
<TOKEN end_char="2011" id="token-20-9" morph="none" pos="punct" start_char="2011">,</TOKEN>
<TOKEN end_char="2016" id="token-20-10" morph="none" pos="word" start_char="2013">AQUI</TOKEN>
<TOKEN end_char="2020" id="token-20-11" morph="none" pos="word" start_char="2018">LOS</TOKEN>
<TOKEN end_char="2030" id="token-20-12" morph="none" pos="word" start_char="2022">FENOMENOS</TOKEN>
<TOKEN end_char="2033" id="token-20-13" morph="none" pos="word" start_char="2032">te</TOKEN>
<TOKEN end_char="2037" id="token-20-14" morph="none" pos="word" start_char="2035">van</TOKEN>
<TOKEN end_char="2039" id="token-20-15" morph="none" pos="word" start_char="2039">a</TOKEN>
<TOKEN end_char="2045" id="token-20-16" morph="none" pos="word" start_char="2041">pedir</TOKEN>
<TOKEN end_char="2054" id="token-20-17" morph="none" pos="word" start_char="2047">Estudios</TOKEN>
<TOKEN end_char="2060" id="token-20-18" morph="none" pos="word" start_char="2056">DOBLE</TOKEN>
<TOKEN end_char="2066" id="token-20-19" morph="none" pos="word" start_char="2062">CIEGO</TOKEN>
<TOKEN end_char="2071" id="token-20-20" morph="none" pos="word" start_char="2068">esos</TOKEN>
<TOKEN end_char="2075" id="token-20-21" morph="none" pos="word" start_char="2073">que</TOKEN>
<TOKEN end_char="2078" id="token-20-22" morph="none" pos="word" start_char="2077">NO</TOKEN>
<TOKEN end_char="2085" id="token-20-23" morph="none" pos="word" start_char="2080">TIENEN</TOKEN>
<TOKEN end_char="2089" id="token-20-24" morph="none" pos="word" start_char="2087">las</TOKEN>
<TOKEN end_char="2096" id="token-20-25" morph="none" pos="word" start_char="2091">VACUNA</TOKEN>
<TOKEN end_char="2099" id="token-20-26" morph="none" pos="word" start_char="2098">DE</TOKEN>
<TOKEN end_char="2105" id="token-20-27" morph="none" pos="word" start_char="2101">FAUCI</TOKEN>
<TOKEN end_char="2107" id="token-20-28" morph="none" pos="word" start_char="2107">y</TOKEN>
<TOKEN end_char="2112" id="token-20-29" morph="none" pos="word" start_char="2109">KILL</TOKEN>
<TOKEN end_char="2118" id="token-20-30" morph="none" pos="word" start_char="2114">GATES</TOKEN>
<TOKEN end_char="2131" id="token-20-31" morph="none" pos="word" start_char="2120">jojojojojojo</TOKEN>
<TRANSLATED_TEXT>Tranquilo ALSO AS WE KNOW IT WORKS AGAINST COVID, THESE WINDOWS ARE GOING TO ASK YOU FOR DOUBLE STUDIES THAT DON'T HAVE THE FAUCI VACUANA AND KILL GATES I JOJOJOJOJOJO</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2150" id="segment-21" start_char="2134">
<ORIGINAL_TEXT>Y NINGUNA VACUNA.</ORIGINAL_TEXT>
<TOKEN end_char="2134" id="token-21-0" morph="none" pos="word" start_char="2134">Y</TOKEN>
<TOKEN end_char="2142" id="token-21-1" morph="none" pos="word" start_char="2136">NINGUNA</TOKEN>
<TOKEN end_char="2149" id="token-21-2" morph="none" pos="word" start_char="2144">VACUNA</TOKEN>
<TOKEN end_char="2150" id="token-21-3" morph="none" pos="punct" start_char="2150">.</TOKEN>
<TRANSLATED_TEXT>AND NO VACUANA.</TRANSLATED_TEXT><DETECTED_LANGUAGE>hu</DETECTED_LANGUAGE></SEG>
<SEG end_char="2209" id="segment-22" start_char="2154">
<ORIGINAL_TEXT>manutartufo dijo: Resume es demasiada información diaria</ORIGINAL_TEXT>
<TOKEN end_char="2164" id="token-22-0" morph="none" pos="word" start_char="2154">manutartufo</TOKEN>
<TOKEN end_char="2169" id="token-22-1" morph="none" pos="word" start_char="2166">dijo</TOKEN>
<TOKEN end_char="2170" id="token-22-2" morph="none" pos="punct" start_char="2170">:</TOKEN>
<TOKEN end_char="2177" id="token-22-3" morph="none" pos="word" start_char="2172">Resume</TOKEN>
<TOKEN end_char="2180" id="token-22-4" morph="none" pos="word" start_char="2179">es</TOKEN>
<TOKEN end_char="2190" id="token-22-5" morph="none" pos="word" start_char="2182">demasiada</TOKEN>
<TOKEN end_char="2202" id="token-22-6" morph="none" pos="word" start_char="2192">información</TOKEN>
<TOKEN end_char="2209" id="token-22-7" morph="none" pos="word" start_char="2204">diaria</TOKEN>
<TRANSLATED_TEXT>Mantarufo said: Resume is too much daily information</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2255" id="segment-23" start_char="2213">
<ORIGINAL_TEXT>¿Demasiada información, 15 líneas de texto?</ORIGINAL_TEXT>
<TOKEN end_char="2213" id="token-23-0" morph="none" pos="punct" start_char="2213">¿</TOKEN>
<TOKEN end_char="2222" id="token-23-1" morph="none" pos="word" start_char="2214">Demasiada</TOKEN>
<TOKEN end_char="2234" id="token-23-2" morph="none" pos="word" start_char="2224">información</TOKEN>
<TOKEN end_char="2235" id="token-23-3" morph="none" pos="punct" start_char="2235">,</TOKEN>
<TOKEN end_char="2238" id="token-23-4" morph="none" pos="word" start_char="2237">15</TOKEN>
<TOKEN end_char="2245" id="token-23-5" morph="none" pos="word" start_char="2240">líneas</TOKEN>
<TOKEN end_char="2248" id="token-23-6" morph="none" pos="word" start_char="2247">de</TOKEN>
<TOKEN end_char="2254" id="token-23-7" morph="none" pos="word" start_char="2250">texto</TOKEN>
<TOKEN end_char="2255" id="token-23-8" morph="none" pos="punct" start_char="2255">?</TOKEN>
<TRANSLATED_TEXT>Too much information, 15 lines of text?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2301" id="segment-24" start_char="2259">
<ORIGINAL_TEXT>Muchas gracias por la información, Técnico.</ORIGINAL_TEXT>
<TOKEN end_char="2264" id="token-24-0" morph="none" pos="word" start_char="2259">Muchas</TOKEN>
<TOKEN end_char="2272" id="token-24-1" morph="none" pos="word" start_char="2266">gracias</TOKEN>
<TOKEN end_char="2276" id="token-24-2" morph="none" pos="word" start_char="2274">por</TOKEN>
<TOKEN end_char="2279" id="token-24-3" morph="none" pos="word" start_char="2278">la</TOKEN>
<TOKEN end_char="2291" id="token-24-4" morph="none" pos="word" start_char="2281">información</TOKEN>
<TOKEN end_char="2292" id="token-24-5" morph="none" pos="punct" start_char="2292">,</TOKEN>
<TOKEN end_char="2300" id="token-24-6" morph="none" pos="word" start_char="2294">Técnico</TOKEN>
<TOKEN end_char="2301" id="token-24-7" morph="none" pos="punct" start_char="2301">.</TOKEN>
<TRANSLATED_TEXT>Thank you very much for the information, Technical.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2350" id="segment-25" start_char="2303">
<ORIGINAL_TEXT>Espero que con el informe que adjuntas los Sres.</ORIGINAL_TEXT>
<TOKEN end_char="2308" id="token-25-0" morph="none" pos="word" start_char="2303">Espero</TOKEN>
<TOKEN end_char="2312" id="token-25-1" morph="none" pos="word" start_char="2310">que</TOKEN>
<TOKEN end_char="2316" id="token-25-2" morph="none" pos="word" start_char="2314">con</TOKEN>
<TOKEN end_char="2319" id="token-25-3" morph="none" pos="word" start_char="2318">el</TOKEN>
<TOKEN end_char="2327" id="token-25-4" morph="none" pos="word" start_char="2321">informe</TOKEN>
<TOKEN end_char="2331" id="token-25-5" morph="none" pos="word" start_char="2329">que</TOKEN>
<TOKEN end_char="2340" id="token-25-6" morph="none" pos="word" start_char="2333">adjuntas</TOKEN>
<TOKEN end_char="2344" id="token-25-7" morph="none" pos="word" start_char="2342">los</TOKEN>
<TOKEN end_char="2349" id="token-25-8" morph="none" pos="word" start_char="2346">Sres</TOKEN>
<TOKEN end_char="2350" id="token-25-9" morph="none" pos="punct" start_char="2350">.</TOKEN>
<TRANSLATED_TEXT>I hope that with the report you attach the Sres.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2423" id="segment-26" start_char="2352">
<ORIGINAL_TEXT>Inquisidores del foro se den por satisfechos y dejen el hilo donde está.</ORIGINAL_TEXT>
<TOKEN end_char="2363" id="token-26-0" morph="none" pos="word" start_char="2352">Inquisidores</TOKEN>
<TOKEN end_char="2367" id="token-26-1" morph="none" pos="word" start_char="2365">del</TOKEN>
<TOKEN end_char="2372" id="token-26-2" morph="none" pos="word" start_char="2369">foro</TOKEN>
<TOKEN end_char="2375" id="token-26-3" morph="none" pos="word" start_char="2374">se</TOKEN>
<TOKEN end_char="2379" id="token-26-4" morph="none" pos="word" start_char="2377">den</TOKEN>
<TOKEN end_char="2383" id="token-26-5" morph="none" pos="word" start_char="2381">por</TOKEN>
<TOKEN end_char="2395" id="token-26-6" morph="none" pos="word" start_char="2385">satisfechos</TOKEN>
<TOKEN end_char="2397" id="token-26-7" morph="none" pos="word" start_char="2397">y</TOKEN>
<TOKEN end_char="2403" id="token-26-8" morph="none" pos="word" start_char="2399">dejen</TOKEN>
<TOKEN end_char="2406" id="token-26-9" morph="none" pos="word" start_char="2405">el</TOKEN>
<TOKEN end_char="2411" id="token-26-10" morph="none" pos="word" start_char="2408">hilo</TOKEN>
<TOKEN end_char="2417" id="token-26-11" morph="none" pos="word" start_char="2413">donde</TOKEN>
<TOKEN end_char="2422" id="token-26-12" morph="none" pos="word" start_char="2419">está</TOKEN>
<TOKEN end_char="2423" id="token-26-13" morph="none" pos="punct" start_char="2423">.</TOKEN>
<TRANSLATED_TEXT>Inquisitors of the forum are satisfied and leave the thread where it is.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2506" id="segment-27" start_char="2427">
<ORIGINAL_TEXT>Estamos hablando de un estudio médico de 84 páginas...autentificado por notario.</ORIGINAL_TEXT>
<TOKEN end_char="2433" id="token-27-0" morph="none" pos="word" start_char="2427">Estamos</TOKEN>
<TOKEN end_char="2442" id="token-27-1" morph="none" pos="word" start_char="2435">hablando</TOKEN>
<TOKEN end_char="2445" id="token-27-2" morph="none" pos="word" start_char="2444">de</TOKEN>
<TOKEN end_char="2448" id="token-27-3" morph="none" pos="word" start_char="2447">un</TOKEN>
<TOKEN end_char="2456" id="token-27-4" morph="none" pos="word" start_char="2450">estudio</TOKEN>
<TOKEN end_char="2463" id="token-27-5" morph="none" pos="word" start_char="2458">médico</TOKEN>
<TOKEN end_char="2466" id="token-27-6" morph="none" pos="word" start_char="2465">de</TOKEN>
<TOKEN end_char="2469" id="token-27-7" morph="none" pos="word" start_char="2468">84</TOKEN>
<TOKEN end_char="2493" id="token-27-8" morph="none" pos="unknown" start_char="2471">páginas...autentificado</TOKEN>
<TOKEN end_char="2497" id="token-27-9" morph="none" pos="word" start_char="2495">por</TOKEN>
<TOKEN end_char="2505" id="token-27-10" morph="none" pos="word" start_char="2499">notario</TOKEN>
<TOKEN end_char="2506" id="token-27-11" morph="none" pos="punct" start_char="2506">.</TOKEN>
<TRANSLATED_TEXT>We're talking about an 84-page medical study... authenticated by a notary.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2752" id="segment-28" start_char="2508">
<ORIGINAL_TEXT>Con los DNIs del médico investigador principal y los datos de los otros 6, con los consentimientos informados de los pacientes sometidos al estudio, con datos histiológicos, con analiticas, con la aportación de los positivos por prueba PCR, etc.</ORIGINAL_TEXT>
<TOKEN end_char="2510" id="token-28-0" morph="none" pos="word" start_char="2508">Con</TOKEN>
<TOKEN end_char="2514" id="token-28-1" morph="none" pos="word" start_char="2512">los</TOKEN>
<TOKEN end_char="2519" id="token-28-2" morph="none" pos="word" start_char="2516">DNIs</TOKEN>
<TOKEN end_char="2523" id="token-28-3" morph="none" pos="word" start_char="2521">del</TOKEN>
<TOKEN end_char="2530" id="token-28-4" morph="none" pos="word" start_char="2525">médico</TOKEN>
<TOKEN end_char="2543" id="token-28-5" morph="none" pos="word" start_char="2532">investigador</TOKEN>
<TOKEN end_char="2553" id="token-28-6" morph="none" pos="word" start_char="2545">principal</TOKEN>
<TOKEN end_char="2555" id="token-28-7" morph="none" pos="word" start_char="2555">y</TOKEN>
<TOKEN end_char="2559" id="token-28-8" morph="none" pos="word" start_char="2557">los</TOKEN>
<TOKEN end_char="2565" id="token-28-9" morph="none" pos="word" start_char="2561">datos</TOKEN>
<TOKEN end_char="2568" id="token-28-10" morph="none" pos="word" start_char="2567">de</TOKEN>
<TOKEN end_char="2572" id="token-28-11" morph="none" pos="word" start_char="2570">los</TOKEN>
<TOKEN end_char="2578" id="token-28-12" morph="none" pos="word" start_char="2574">otros</TOKEN>
<TOKEN end_char="2580" id="token-28-13" morph="none" pos="word" start_char="2580">6</TOKEN>
<TOKEN end_char="2581" id="token-28-14" morph="none" pos="punct" start_char="2581">,</TOKEN>
<TOKEN end_char="2585" id="token-28-15" morph="none" pos="word" start_char="2583">con</TOKEN>
<TOKEN end_char="2589" id="token-28-16" morph="none" pos="word" start_char="2587">los</TOKEN>
<TOKEN end_char="2605" id="token-28-17" morph="none" pos="word" start_char="2591">consentimientos</TOKEN>
<TOKEN end_char="2616" id="token-28-18" morph="none" pos="word" start_char="2607">informados</TOKEN>
<TOKEN end_char="2619" id="token-28-19" morph="none" pos="word" start_char="2618">de</TOKEN>
<TOKEN end_char="2623" id="token-28-20" morph="none" pos="word" start_char="2621">los</TOKEN>
<TOKEN end_char="2633" id="token-28-21" morph="none" pos="word" start_char="2625">pacientes</TOKEN>
<TOKEN end_char="2643" id="token-28-22" morph="none" pos="word" start_char="2635">sometidos</TOKEN>
<TOKEN end_char="2646" id="token-28-23" morph="none" pos="word" start_char="2645">al</TOKEN>
<TOKEN end_char="2654" id="token-28-24" morph="none" pos="word" start_char="2648">estudio</TOKEN>
<TOKEN end_char="2655" id="token-28-25" morph="none" pos="punct" start_char="2655">,</TOKEN>
<TOKEN end_char="2659" id="token-28-26" morph="none" pos="word" start_char="2657">con</TOKEN>
<TOKEN end_char="2665" id="token-28-27" morph="none" pos="word" start_char="2661">datos</TOKEN>
<TOKEN end_char="2679" id="token-28-28" morph="none" pos="word" start_char="2667">histiológicos</TOKEN>
<TOKEN end_char="2680" id="token-28-29" morph="none" pos="punct" start_char="2680">,</TOKEN>
<TOKEN end_char="2684" id="token-28-30" morph="none" pos="word" start_char="2682">con</TOKEN>
<TOKEN end_char="2695" id="token-28-31" morph="none" pos="word" start_char="2686">analiticas</TOKEN>
<TOKEN end_char="2696" id="token-28-32" morph="none" pos="punct" start_char="2696">,</TOKEN>
<TOKEN end_char="2700" id="token-28-33" morph="none" pos="word" start_char="2698">con</TOKEN>
<TOKEN end_char="2703" id="token-28-34" morph="none" pos="word" start_char="2702">la</TOKEN>
<TOKEN end_char="2714" id="token-28-35" morph="none" pos="word" start_char="2705">aportación</TOKEN>
<TOKEN end_char="2717" id="token-28-36" morph="none" pos="word" start_char="2716">de</TOKEN>
<TOKEN end_char="2721" id="token-28-37" morph="none" pos="word" start_char="2719">los</TOKEN>
<TOKEN end_char="2731" id="token-28-38" morph="none" pos="word" start_char="2723">positivos</TOKEN>
<TOKEN end_char="2735" id="token-28-39" morph="none" pos="word" start_char="2733">por</TOKEN>
<TOKEN end_char="2742" id="token-28-40" morph="none" pos="word" start_char="2737">prueba</TOKEN>
<TOKEN end_char="2746" id="token-28-41" morph="none" pos="word" start_char="2744">PCR</TOKEN>
<TOKEN end_char="2747" id="token-28-42" morph="none" pos="punct" start_char="2747">,</TOKEN>
<TOKEN end_char="2751" id="token-28-43" morph="none" pos="word" start_char="2749">etc</TOKEN>
<TOKEN end_char="2752" id="token-28-44" morph="none" pos="punct" start_char="2752">.</TOKEN>
<TRANSLATED_TEXT>With the DNIs of the principal investigator and the data of the other 6, with the informed consent of the patients subjected to the study, with histological data, with analysts, with the contribution of PCR test positives, etc.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2778" id="segment-29" start_char="2756">
<ORIGINAL_TEXT>¿Y el grupo de control?</ORIGINAL_TEXT>
<TOKEN end_char="2756" id="token-29-0" morph="none" pos="punct" start_char="2756">¿</TOKEN>
<TOKEN end_char="2757" id="token-29-1" morph="none" pos="word" start_char="2757">Y</TOKEN>
<TOKEN end_char="2760" id="token-29-2" morph="none" pos="word" start_char="2759">el</TOKEN>
<TOKEN end_char="2766" id="token-29-3" morph="none" pos="word" start_char="2762">grupo</TOKEN>
<TOKEN end_char="2769" id="token-29-4" morph="none" pos="word" start_char="2768">de</TOKEN>
<TOKEN end_char="2777" id="token-29-5" morph="none" pos="word" start_char="2771">control</TOKEN>
<TOKEN end_char="2778" id="token-29-6" morph="none" pos="punct" start_char="2778">?</TOKEN>
<TRANSLATED_TEXT>What about the control group?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2925" id="segment-30" start_char="2780">
<ORIGINAL_TEXT>¿A qué grupo equivalente no le dieron MMS estos discípulos del charlatán Kalcker para comprobar que sea el MMS lo que causa algún efecto positivo?</ORIGINAL_TEXT>
<TOKEN end_char="2780" id="token-30-0" morph="none" pos="punct" start_char="2780">¿</TOKEN>
<TOKEN end_char="2781" id="token-30-1" morph="none" pos="word" start_char="2781">A</TOKEN>
<TOKEN end_char="2785" id="token-30-2" morph="none" pos="word" start_char="2783">qué</TOKEN>
<TOKEN end_char="2791" id="token-30-3" morph="none" pos="word" start_char="2787">grupo</TOKEN>
<TOKEN end_char="2803" id="token-30-4" morph="none" pos="word" start_char="2793">equivalente</TOKEN>
<TOKEN end_char="2806" id="token-30-5" morph="none" pos="word" start_char="2805">no</TOKEN>
<TOKEN end_char="2809" id="token-30-6" morph="none" pos="word" start_char="2808">le</TOKEN>
<TOKEN end_char="2816" id="token-30-7" morph="none" pos="word" start_char="2811">dieron</TOKEN>
<TOKEN end_char="2820" id="token-30-8" morph="none" pos="word" start_char="2818">MMS</TOKEN>
<TOKEN end_char="2826" id="token-30-9" morph="none" pos="word" start_char="2822">estos</TOKEN>
<TOKEN end_char="2837" id="token-30-10" morph="none" pos="word" start_char="2828">discípulos</TOKEN>
<TOKEN end_char="2841" id="token-30-11" morph="none" pos="word" start_char="2839">del</TOKEN>
<TOKEN end_char="2851" id="token-30-12" morph="none" pos="word" start_char="2843">charlatán</TOKEN>
<TOKEN end_char="2859" id="token-30-13" morph="none" pos="word" start_char="2853">Kalcker</TOKEN>
<TOKEN end_char="2864" id="token-30-14" morph="none" pos="word" start_char="2861">para</TOKEN>
<TOKEN end_char="2874" id="token-30-15" morph="none" pos="word" start_char="2866">comprobar</TOKEN>
<TOKEN end_char="2878" id="token-30-16" morph="none" pos="word" start_char="2876">que</TOKEN>
<TOKEN end_char="2882" id="token-30-17" morph="none" pos="word" start_char="2880">sea</TOKEN>
<TOKEN end_char="2885" id="token-30-18" morph="none" pos="word" start_char="2884">el</TOKEN>
<TOKEN end_char="2889" id="token-30-19" morph="none" pos="word" start_char="2887">MMS</TOKEN>
<TOKEN end_char="2892" id="token-30-20" morph="none" pos="word" start_char="2891">lo</TOKEN>
<TOKEN end_char="2896" id="token-30-21" morph="none" pos="word" start_char="2894">que</TOKEN>
<TOKEN end_char="2902" id="token-30-22" morph="none" pos="word" start_char="2898">causa</TOKEN>
<TOKEN end_char="2908" id="token-30-23" morph="none" pos="word" start_char="2904">algún</TOKEN>
<TOKEN end_char="2915" id="token-30-24" morph="none" pos="word" start_char="2910">efecto</TOKEN>
<TOKEN end_char="2924" id="token-30-25" morph="none" pos="word" start_char="2917">positivo</TOKEN>
<TOKEN end_char="2925" id="token-30-26" morph="none" pos="punct" start_char="2925">?</TOKEN>
<TRANSLATED_TEXT>To which equivalent group did these disciples of the Kalcker charlatan not give MMS to check that it is MMS that causes some positive effect?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3188" id="segment-31" start_char="2928">
<ORIGINAL_TEXT>Obviamente, si les das cualquier cosa suficientemente inocua como para no matarles directamente a un grupo de personas entre 30 y 50 años con un virus que en la gran mayoría de casos no mata en ese grupo de edad, no es ningún misterio que se acaben recuperando.</ORIGINAL_TEXT>
<TOKEN end_char="2937" id="token-31-0" morph="none" pos="word" start_char="2928">Obviamente</TOKEN>
<TOKEN end_char="2938" id="token-31-1" morph="none" pos="punct" start_char="2938">,</TOKEN>
<TOKEN end_char="2941" id="token-31-2" morph="none" pos="word" start_char="2940">si</TOKEN>
<TOKEN end_char="2945" id="token-31-3" morph="none" pos="word" start_char="2943">les</TOKEN>
<TOKEN end_char="2949" id="token-31-4" morph="none" pos="word" start_char="2947">das</TOKEN>
<TOKEN end_char="2959" id="token-31-5" morph="none" pos="word" start_char="2951">cualquier</TOKEN>
<TOKEN end_char="2964" id="token-31-6" morph="none" pos="word" start_char="2961">cosa</TOKEN>
<TOKEN end_char="2980" id="token-31-7" morph="none" pos="word" start_char="2966">suficientemente</TOKEN>
<TOKEN end_char="2987" id="token-31-8" morph="none" pos="word" start_char="2982">inocua</TOKEN>
<TOKEN end_char="2992" id="token-31-9" morph="none" pos="word" start_char="2989">como</TOKEN>
<TOKEN end_char="2997" id="token-31-10" morph="none" pos="word" start_char="2994">para</TOKEN>
<TOKEN end_char="3000" id="token-31-11" morph="none" pos="word" start_char="2999">no</TOKEN>
<TOKEN end_char="3009" id="token-31-12" morph="none" pos="word" start_char="3002">matarles</TOKEN>
<TOKEN end_char="3022" id="token-31-13" morph="none" pos="word" start_char="3011">directamente</TOKEN>
<TOKEN end_char="3024" id="token-31-14" morph="none" pos="word" start_char="3024">a</TOKEN>
<TOKEN end_char="3027" id="token-31-15" morph="none" pos="word" start_char="3026">un</TOKEN>
<TOKEN end_char="3033" id="token-31-16" morph="none" pos="word" start_char="3029">grupo</TOKEN>
<TOKEN end_char="3036" id="token-31-17" morph="none" pos="word" start_char="3035">de</TOKEN>
<TOKEN end_char="3045" id="token-31-18" morph="none" pos="word" start_char="3038">personas</TOKEN>
<TOKEN end_char="3051" id="token-31-19" morph="none" pos="word" start_char="3047">entre</TOKEN>
<TOKEN end_char="3054" id="token-31-20" morph="none" pos="word" start_char="3053">30</TOKEN>
<TOKEN end_char="3056" id="token-31-21" morph="none" pos="word" start_char="3056">y</TOKEN>
<TOKEN end_char="3059" id="token-31-22" morph="none" pos="word" start_char="3058">50</TOKEN>
<TOKEN end_char="3064" id="token-31-23" morph="none" pos="word" start_char="3061">años</TOKEN>
<TOKEN end_char="3068" id="token-31-24" morph="none" pos="word" start_char="3066">con</TOKEN>
<TOKEN end_char="3071" id="token-31-25" morph="none" pos="word" start_char="3070">un</TOKEN>
<TOKEN end_char="3077" id="token-31-26" morph="none" pos="word" start_char="3073">virus</TOKEN>
<TOKEN end_char="3081" id="token-31-27" morph="none" pos="word" start_char="3079">que</TOKEN>
<TOKEN end_char="3084" id="token-31-28" morph="none" pos="word" start_char="3083">en</TOKEN>
<TOKEN end_char="3087" id="token-31-29" morph="none" pos="word" start_char="3086">la</TOKEN>
<TOKEN end_char="3092" id="token-31-30" morph="none" pos="word" start_char="3089">gran</TOKEN>
<TOKEN end_char="3100" id="token-31-31" morph="none" pos="word" start_char="3094">mayoría</TOKEN>
<TOKEN end_char="3103" id="token-31-32" morph="none" pos="word" start_char="3102">de</TOKEN>
<TOKEN end_char="3109" id="token-31-33" morph="none" pos="word" start_char="3105">casos</TOKEN>
<TOKEN end_char="3112" id="token-31-34" morph="none" pos="word" start_char="3111">no</TOKEN>
<TOKEN end_char="3117" id="token-31-35" morph="none" pos="word" start_char="3114">mata</TOKEN>
<TOKEN end_char="3120" id="token-31-36" morph="none" pos="word" start_char="3119">en</TOKEN>
<TOKEN end_char="3124" id="token-31-37" morph="none" pos="word" start_char="3122">ese</TOKEN>
<TOKEN end_char="3130" id="token-31-38" morph="none" pos="word" start_char="3126">grupo</TOKEN>
<TOKEN end_char="3133" id="token-31-39" morph="none" pos="word" start_char="3132">de</TOKEN>
<TOKEN end_char="3138" id="token-31-40" morph="none" pos="word" start_char="3135">edad</TOKEN>
<TOKEN end_char="3139" id="token-31-41" morph="none" pos="punct" start_char="3139">,</TOKEN>
<TOKEN end_char="3142" id="token-31-42" morph="none" pos="word" start_char="3141">no</TOKEN>
<TOKEN end_char="3145" id="token-31-43" morph="none" pos="word" start_char="3144">es</TOKEN>
<TOKEN end_char="3152" id="token-31-44" morph="none" pos="word" start_char="3147">ningún</TOKEN>
<TOKEN end_char="3161" id="token-31-45" morph="none" pos="word" start_char="3154">misterio</TOKEN>
<TOKEN end_char="3165" id="token-31-46" morph="none" pos="word" start_char="3163">que</TOKEN>
<TOKEN end_char="3168" id="token-31-47" morph="none" pos="word" start_char="3167">se</TOKEN>
<TOKEN end_char="3175" id="token-31-48" morph="none" pos="word" start_char="3170">acaben</TOKEN>
<TOKEN end_char="3187" id="token-31-49" morph="none" pos="word" start_char="3177">recuperando</TOKEN>
<TOKEN end_char="3188" id="token-31-50" morph="none" pos="punct" start_char="3188">.</TOKEN>
<TRANSLATED_TEXT>Obviously, if you give them anything innocuous enough not to kill you directly to a group of people between 30 and 50 years old with a virus that in the vast majority of cases doesn 't kill in that age group, it' s no mystery that they end up recovering.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3330" id="segment-32" start_char="3191">
<ORIGINAL_TEXT>Yo podría hacer un estudio exactamente igual diciendo que el agua cura el Coronavirus, porque seguro que además de MMS también tomaron agua.</ORIGINAL_TEXT>
<TOKEN end_char="3192" id="token-32-0" morph="none" pos="word" start_char="3191">Yo</TOKEN>
<TOKEN end_char="3199" id="token-32-1" morph="none" pos="word" start_char="3194">podría</TOKEN>
<TOKEN end_char="3205" id="token-32-2" morph="none" pos="word" start_char="3201">hacer</TOKEN>
<TOKEN end_char="3208" id="token-32-3" morph="none" pos="word" start_char="3207">un</TOKEN>
<TOKEN end_char="3216" id="token-32-4" morph="none" pos="word" start_char="3210">estudio</TOKEN>
<TOKEN end_char="3228" id="token-32-5" morph="none" pos="word" start_char="3218">exactamente</TOKEN>
<TOKEN end_char="3234" id="token-32-6" morph="none" pos="word" start_char="3230">igual</TOKEN>
<TOKEN end_char="3243" id="token-32-7" morph="none" pos="word" start_char="3236">diciendo</TOKEN>
<TOKEN end_char="3247" id="token-32-8" morph="none" pos="word" start_char="3245">que</TOKEN>
<TOKEN end_char="3250" id="token-32-9" morph="none" pos="word" start_char="3249">el</TOKEN>
<TOKEN end_char="3255" id="token-32-10" morph="none" pos="word" start_char="3252">agua</TOKEN>
<TOKEN end_char="3260" id="token-32-11" morph="none" pos="word" start_char="3257">cura</TOKEN>
<TOKEN end_char="3263" id="token-32-12" morph="none" pos="word" start_char="3262">el</TOKEN>
<TOKEN end_char="3275" id="token-32-13" morph="none" pos="word" start_char="3265">Coronavirus</TOKEN>
<TOKEN end_char="3276" id="token-32-14" morph="none" pos="punct" start_char="3276">,</TOKEN>
<TOKEN end_char="3283" id="token-32-15" morph="none" pos="word" start_char="3278">porque</TOKEN>
<TOKEN end_char="3290" id="token-32-16" morph="none" pos="word" start_char="3285">seguro</TOKEN>
<TOKEN end_char="3294" id="token-32-17" morph="none" pos="word" start_char="3292">que</TOKEN>
<TOKEN end_char="3301" id="token-32-18" morph="none" pos="word" start_char="3296">además</TOKEN>
<TOKEN end_char="3304" id="token-32-19" morph="none" pos="word" start_char="3303">de</TOKEN>
<TOKEN end_char="3308" id="token-32-20" morph="none" pos="word" start_char="3306">MMS</TOKEN>
<TOKEN end_char="3316" id="token-32-21" morph="none" pos="word" start_char="3310">también</TOKEN>
<TOKEN end_char="3324" id="token-32-22" morph="none" pos="word" start_char="3318">tomaron</TOKEN>
<TOKEN end_char="3329" id="token-32-23" morph="none" pos="word" start_char="3326">agua</TOKEN>
<TOKEN end_char="3330" id="token-32-24" morph="none" pos="punct" start_char="3330">.</TOKEN>
<TRANSLATED_TEXT>I could do a study exactly the same by saying that water cures Coronavirus, because I 'm sure that in addition to MMS they also took water.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3408" id="segment-33" start_char="3333">
<ORIGINAL_TEXT>¿En qué publicación científica seria dices que van a intentar publicar esto?</ORIGINAL_TEXT>
<TOKEN end_char="3333" id="token-33-0" morph="none" pos="punct" start_char="3333">¿</TOKEN>
<TOKEN end_char="3335" id="token-33-1" morph="none" pos="word" start_char="3334">En</TOKEN>
<TOKEN end_char="3339" id="token-33-2" morph="none" pos="word" start_char="3337">qué</TOKEN>
<TOKEN end_char="3351" id="token-33-3" morph="none" pos="word" start_char="3341">publicación</TOKEN>
<TOKEN end_char="3362" id="token-33-4" morph="none" pos="word" start_char="3353">científica</TOKEN>
<TOKEN end_char="3368" id="token-33-5" morph="none" pos="word" start_char="3364">seria</TOKEN>
<TOKEN end_char="3374" id="token-33-6" morph="none" pos="word" start_char="3370">dices</TOKEN>
<TOKEN end_char="3378" id="token-33-7" morph="none" pos="word" start_char="3376">que</TOKEN>
<TOKEN end_char="3382" id="token-33-8" morph="none" pos="word" start_char="3380">van</TOKEN>
<TOKEN end_char="3384" id="token-33-9" morph="none" pos="word" start_char="3384">a</TOKEN>
<TOKEN end_char="3393" id="token-33-10" morph="none" pos="word" start_char="3386">intentar</TOKEN>
<TOKEN end_char="3402" id="token-33-11" morph="none" pos="word" start_char="3395">publicar</TOKEN>
<TOKEN end_char="3407" id="token-33-12" morph="none" pos="word" start_char="3404">esto</TOKEN>
<TOKEN end_char="3408" id="token-33-13" morph="none" pos="punct" start_char="3408">?</TOKEN>
<TRANSLATED_TEXT>In what scientific publication would you say they 're going to try to publish this?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3589" id="segment-34" start_char="3412">
<ORIGINAL_TEXT>Gracias @un tecnico preocupado me he mirado el informe por encima y en general los síntomas se reducen en un 82% al cuarto día si he leído bien, sin necesidad de hospitalización.</ORIGINAL_TEXT>
<TOKEN end_char="3418" id="token-34-0" morph="none" pos="word" start_char="3412">Gracias</TOKEN>
<TOKEN end_char="3422" id="token-34-1" morph="none" pos="tag" start_char="3420">@un</TOKEN>
<TOKEN end_char="3430" id="token-34-2" morph="none" pos="word" start_char="3424">tecnico</TOKEN>
<TOKEN end_char="3441" id="token-34-3" morph="none" pos="word" start_char="3432">preocupado</TOKEN>
<TOKEN end_char="3444" id="token-34-4" morph="none" pos="word" start_char="3443">me</TOKEN>
<TOKEN end_char="3447" id="token-34-5" morph="none" pos="word" start_char="3446">he</TOKEN>
<TOKEN end_char="3454" id="token-34-6" morph="none" pos="word" start_char="3449">mirado</TOKEN>
<TOKEN end_char="3457" id="token-34-7" morph="none" pos="word" start_char="3456">el</TOKEN>
<TOKEN end_char="3465" id="token-34-8" morph="none" pos="word" start_char="3459">informe</TOKEN>
<TOKEN end_char="3469" id="token-34-9" morph="none" pos="word" start_char="3467">por</TOKEN>
<TOKEN end_char="3476" id="token-34-10" morph="none" pos="word" start_char="3471">encima</TOKEN>
<TOKEN end_char="3478" id="token-34-11" morph="none" pos="word" start_char="3478">y</TOKEN>
<TOKEN end_char="3481" id="token-34-12" morph="none" pos="word" start_char="3480">en</TOKEN>
<TOKEN end_char="3489" id="token-34-13" morph="none" pos="word" start_char="3483">general</TOKEN>
<TOKEN end_char="3493" id="token-34-14" morph="none" pos="word" start_char="3491">los</TOKEN>
<TOKEN end_char="3502" id="token-34-15" morph="none" pos="word" start_char="3495">síntomas</TOKEN>
<TOKEN end_char="3505" id="token-34-16" morph="none" pos="word" start_char="3504">se</TOKEN>
<TOKEN end_char="3513" id="token-34-17" morph="none" pos="word" start_char="3507">reducen</TOKEN>
<TOKEN end_char="3516" id="token-34-18" morph="none" pos="word" start_char="3515">en</TOKEN>
<TOKEN end_char="3519" id="token-34-19" morph="none" pos="word" start_char="3518">un</TOKEN>
<TOKEN end_char="3522" id="token-34-20" morph="none" pos="word" start_char="3521">82</TOKEN>
<TOKEN end_char="3523" id="token-34-21" morph="none" pos="punct" start_char="3523">%</TOKEN>
<TOKEN end_char="3526" id="token-34-22" morph="none" pos="word" start_char="3525">al</TOKEN>
<TOKEN end_char="3533" id="token-34-23" morph="none" pos="word" start_char="3528">cuarto</TOKEN>
<TOKEN end_char="3537" id="token-34-24" morph="none" pos="word" start_char="3535">día</TOKEN>
<TOKEN end_char="3540" id="token-34-25" morph="none" pos="word" start_char="3539">si</TOKEN>
<TOKEN end_char="3543" id="token-34-26" morph="none" pos="word" start_char="3542">he</TOKEN>
<TOKEN end_char="3549" id="token-34-27" morph="none" pos="word" start_char="3545">leído</TOKEN>
<TOKEN end_char="3554" id="token-34-28" morph="none" pos="word" start_char="3551">bien</TOKEN>
<TOKEN end_char="3555" id="token-34-29" morph="none" pos="punct" start_char="3555">,</TOKEN>
<TOKEN end_char="3559" id="token-34-30" morph="none" pos="word" start_char="3557">sin</TOKEN>
<TOKEN end_char="3569" id="token-34-31" morph="none" pos="word" start_char="3561">necesidad</TOKEN>
<TOKEN end_char="3572" id="token-34-32" morph="none" pos="word" start_char="3571">de</TOKEN>
<TOKEN end_char="3588" id="token-34-33" morph="none" pos="word" start_char="3574">hospitalización</TOKEN>
<TOKEN end_char="3589" id="token-34-34" morph="none" pos="punct" start_char="3589">.</TOKEN>
<TRANSLATED_TEXT>Thank you @ a concerned technician I looked at the report above and in general the symptoms are reduced by 82% to the fourth day if I read well, without need of hospitalization.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3717" id="segment-35" start_char="3591">
<ORIGINAL_TEXT>Si no hace falta decir nada más, lo primero que muere en las guerras es la verdad, viendo lo que censuran se deduce lo que hay.</ORIGINAL_TEXT>
<TOKEN end_char="3592" id="token-35-0" morph="none" pos="word" start_char="3591">Si</TOKEN>
<TOKEN end_char="3595" id="token-35-1" morph="none" pos="word" start_char="3594">no</TOKEN>
<TOKEN end_char="3600" id="token-35-2" morph="none" pos="word" start_char="3597">hace</TOKEN>
<TOKEN end_char="3606" id="token-35-3" morph="none" pos="word" start_char="3602">falta</TOKEN>
<TOKEN end_char="3612" id="token-35-4" morph="none" pos="word" start_char="3608">decir</TOKEN>
<TOKEN end_char="3617" id="token-35-5" morph="none" pos="word" start_char="3614">nada</TOKEN>
<TOKEN end_char="3621" id="token-35-6" morph="none" pos="word" start_char="3619">más</TOKEN>
<TOKEN end_char="3622" id="token-35-7" morph="none" pos="punct" start_char="3622">,</TOKEN>
<TOKEN end_char="3625" id="token-35-8" morph="none" pos="word" start_char="3624">lo</TOKEN>
<TOKEN end_char="3633" id="token-35-9" morph="none" pos="word" start_char="3627">primero</TOKEN>
<TOKEN end_char="3637" id="token-35-10" morph="none" pos="word" start_char="3635">que</TOKEN>
<TOKEN end_char="3643" id="token-35-11" morph="none" pos="word" start_char="3639">muere</TOKEN>
<TOKEN end_char="3646" id="token-35-12" morph="none" pos="word" start_char="3645">en</TOKEN>
<TOKEN end_char="3650" id="token-35-13" morph="none" pos="word" start_char="3648">las</TOKEN>
<TOKEN end_char="3658" id="token-35-14" morph="none" pos="word" start_char="3652">guerras</TOKEN>
<TOKEN end_char="3661" id="token-35-15" morph="none" pos="word" start_char="3660">es</TOKEN>
<TOKEN end_char="3664" id="token-35-16" morph="none" pos="word" start_char="3663">la</TOKEN>
<TOKEN end_char="3671" id="token-35-17" morph="none" pos="word" start_char="3666">verdad</TOKEN>
<TOKEN end_char="3672" id="token-35-18" morph="none" pos="punct" start_char="3672">,</TOKEN>
<TOKEN end_char="3679" id="token-35-19" morph="none" pos="word" start_char="3674">viendo</TOKEN>
<TOKEN end_char="3682" id="token-35-20" morph="none" pos="word" start_char="3681">lo</TOKEN>
<TOKEN end_char="3686" id="token-35-21" morph="none" pos="word" start_char="3684">que</TOKEN>
<TOKEN end_char="3695" id="token-35-22" morph="none" pos="word" start_char="3688">censuran</TOKEN>
<TOKEN end_char="3698" id="token-35-23" morph="none" pos="word" start_char="3697">se</TOKEN>
<TOKEN end_char="3705" id="token-35-24" morph="none" pos="word" start_char="3700">deduce</TOKEN>
<TOKEN end_char="3708" id="token-35-25" morph="none" pos="word" start_char="3707">lo</TOKEN>
<TOKEN end_char="3712" id="token-35-26" morph="none" pos="word" start_char="3710">que</TOKEN>
<TOKEN end_char="3716" id="token-35-27" morph="none" pos="word" start_char="3714">hay</TOKEN>
<TOKEN end_char="3717" id="token-35-28" morph="none" pos="punct" start_char="3717">.</TOKEN>
<TRANSLATED_TEXT>If there is nothing else to say, the first thing that dies in wars is the truth, seeing what they censor deduces what is there.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3823" id="segment-36" start_char="3723">
<ORIGINAL_TEXT>Bueno, al final Youtube me ha censurado el único vídeo que tenía en mi canal de Youtube sobre el MMS.</ORIGINAL_TEXT>
<TOKEN end_char="3727" id="token-36-0" morph="none" pos="word" start_char="3723">Bueno</TOKEN>
<TOKEN end_char="3728" id="token-36-1" morph="none" pos="punct" start_char="3728">,</TOKEN>
<TOKEN end_char="3731" id="token-36-2" morph="none" pos="word" start_char="3730">al</TOKEN>
<TOKEN end_char="3737" id="token-36-3" morph="none" pos="word" start_char="3733">final</TOKEN>
<TOKEN end_char="3745" id="token-36-4" morph="none" pos="word" start_char="3739">Youtube</TOKEN>
<TOKEN end_char="3748" id="token-36-5" morph="none" pos="word" start_char="3747">me</TOKEN>
<TOKEN end_char="3751" id="token-36-6" morph="none" pos="word" start_char="3750">ha</TOKEN>
<TOKEN end_char="3761" id="token-36-7" morph="none" pos="word" start_char="3753">censurado</TOKEN>
<TOKEN end_char="3764" id="token-36-8" morph="none" pos="word" start_char="3763">el</TOKEN>
<TOKEN end_char="3770" id="token-36-9" morph="none" pos="word" start_char="3766">único</TOKEN>
<TOKEN end_char="3776" id="token-36-10" morph="none" pos="word" start_char="3772">vídeo</TOKEN>
<TOKEN end_char="3780" id="token-36-11" morph="none" pos="word" start_char="3778">que</TOKEN>
<TOKEN end_char="3786" id="token-36-12" morph="none" pos="word" start_char="3782">tenía</TOKEN>
<TOKEN end_char="3789" id="token-36-13" morph="none" pos="word" start_char="3788">en</TOKEN>
<TOKEN end_char="3792" id="token-36-14" morph="none" pos="word" start_char="3791">mi</TOKEN>
<TOKEN end_char="3798" id="token-36-15" morph="none" pos="word" start_char="3794">canal</TOKEN>
<TOKEN end_char="3801" id="token-36-16" morph="none" pos="word" start_char="3800">de</TOKEN>
<TOKEN end_char="3809" id="token-36-17" morph="none" pos="word" start_char="3803">Youtube</TOKEN>
<TOKEN end_char="3815" id="token-36-18" morph="none" pos="word" start_char="3811">sobre</TOKEN>
<TOKEN end_char="3818" id="token-36-19" morph="none" pos="word" start_char="3817">el</TOKEN>
<TOKEN end_char="3822" id="token-36-20" morph="none" pos="word" start_char="3820">MMS</TOKEN>
<TOKEN end_char="3823" id="token-36-21" morph="none" pos="punct" start_char="3823">.</TOKEN>
<TRANSLATED_TEXT>Well, at the end YouTube censored me the only video I had on my YouTube channel about MMS.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3900" id="segment-37" start_char="3826">
<ORIGINAL_TEXT>Curiosamente se trataba de un corte de 6 minutos del canal uno de Colombia.</ORIGINAL_TEXT>
<TOKEN end_char="3837" id="token-37-0" morph="none" pos="word" start_char="3826">Curiosamente</TOKEN>
<TOKEN end_char="3840" id="token-37-1" morph="none" pos="word" start_char="3839">se</TOKEN>
<TOKEN end_char="3848" id="token-37-2" morph="none" pos="word" start_char="3842">trataba</TOKEN>
<TOKEN end_char="3851" id="token-37-3" morph="none" pos="word" start_char="3850">de</TOKEN>
<TOKEN end_char="3854" id="token-37-4" morph="none" pos="word" start_char="3853">un</TOKEN>
<TOKEN end_char="3860" id="token-37-5" morph="none" pos="word" start_char="3856">corte</TOKEN>
<TOKEN end_char="3863" id="token-37-6" morph="none" pos="word" start_char="3862">de</TOKEN>
<TOKEN end_char="3865" id="token-37-7" morph="none" pos="word" start_char="3865">6</TOKEN>
<TOKEN end_char="3873" id="token-37-8" morph="none" pos="word" start_char="3867">minutos</TOKEN>
<TOKEN end_char="3877" id="token-37-9" morph="none" pos="word" start_char="3875">del</TOKEN>
<TOKEN end_char="3883" id="token-37-10" morph="none" pos="word" start_char="3879">canal</TOKEN>
<TOKEN end_char="3887" id="token-37-11" morph="none" pos="word" start_char="3885">uno</TOKEN>
<TOKEN end_char="3890" id="token-37-12" morph="none" pos="word" start_char="3889">de</TOKEN>
<TOKEN end_char="3899" id="token-37-13" morph="none" pos="word" start_char="3892">Colombia</TOKEN>
<TOKEN end_char="3900" id="token-37-14" morph="none" pos="punct" start_char="3900">.</TOKEN>
<TRANSLATED_TEXT>It was a six-minute cut from Channel One in Colombia.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4000" id="segment-38" start_char="3902">
<ORIGINAL_TEXT>O sea, era algo oficial que aún estará en Youtube...pero mis 6 minutos sin ninguna modificación no.</ORIGINAL_TEXT>
<TOKEN end_char="3902" id="token-38-0" morph="none" pos="word" start_char="3902">O</TOKEN>
<TOKEN end_char="3906" id="token-38-1" morph="none" pos="word" start_char="3904">sea</TOKEN>
<TOKEN end_char="3907" id="token-38-2" morph="none" pos="punct" start_char="3907">,</TOKEN>
<TOKEN end_char="3911" id="token-38-3" morph="none" pos="word" start_char="3909">era</TOKEN>
<TOKEN end_char="3916" id="token-38-4" morph="none" pos="word" start_char="3913">algo</TOKEN>
<TOKEN end_char="3924" id="token-38-5" morph="none" pos="word" start_char="3918">oficial</TOKEN>
<TOKEN end_char="3928" id="token-38-6" morph="none" pos="word" start_char="3926">que</TOKEN>
<TOKEN end_char="3932" id="token-38-7" morph="none" pos="word" start_char="3930">aún</TOKEN>
<TOKEN end_char="3939" id="token-38-8" morph="none" pos="word" start_char="3934">estará</TOKEN>
<TOKEN end_char="3942" id="token-38-9" morph="none" pos="word" start_char="3941">en</TOKEN>
<TOKEN end_char="3957" id="token-38-10" morph="none" pos="unknown" start_char="3944">Youtube...pero</TOKEN>
<TOKEN end_char="3961" id="token-38-11" morph="none" pos="word" start_char="3959">mis</TOKEN>
<TOKEN end_char="3963" id="token-38-12" morph="none" pos="word" start_char="3963">6</TOKEN>
<TOKEN end_char="3971" id="token-38-13" morph="none" pos="word" start_char="3965">minutos</TOKEN>
<TOKEN end_char="3975" id="token-38-14" morph="none" pos="word" start_char="3973">sin</TOKEN>
<TOKEN end_char="3983" id="token-38-15" morph="none" pos="word" start_char="3977">ninguna</TOKEN>
<TOKEN end_char="3996" id="token-38-16" morph="none" pos="word" start_char="3985">modificación</TOKEN>
<TOKEN end_char="3999" id="token-38-17" morph="none" pos="word" start_char="3998">no</TOKEN>
<TOKEN end_char="4000" id="token-38-18" morph="none" pos="punct" start_char="4000">.</TOKEN>
<TRANSLATED_TEXT>I mean, it was an official thing that's still going to be on YouTube... but my 6 minutes without any modification is not.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4063" id="segment-39" start_char="4004">
<ORIGINAL_TEXT>Afortunadamente hice una copia y la guarde en este servidor.</ORIGINAL_TEXT>
<TOKEN end_char="4018" id="token-39-0" morph="none" pos="word" start_char="4004">Afortunadamente</TOKEN>
<TOKEN end_char="4023" id="token-39-1" morph="none" pos="word" start_char="4020">hice</TOKEN>
<TOKEN end_char="4027" id="token-39-2" morph="none" pos="word" start_char="4025">una</TOKEN>
<TOKEN end_char="4033" id="token-39-3" morph="none" pos="word" start_char="4029">copia</TOKEN>
<TOKEN end_char="4035" id="token-39-4" morph="none" pos="word" start_char="4035">y</TOKEN>
<TOKEN end_char="4038" id="token-39-5" morph="none" pos="word" start_char="4037">la</TOKEN>
<TOKEN end_char="4045" id="token-39-6" morph="none" pos="word" start_char="4040">guarde</TOKEN>
<TOKEN end_char="4048" id="token-39-7" morph="none" pos="word" start_char="4047">en</TOKEN>
<TOKEN end_char="4053" id="token-39-8" morph="none" pos="word" start_char="4050">este</TOKEN>
<TOKEN end_char="4062" id="token-39-9" morph="none" pos="word" start_char="4055">servidor</TOKEN>
<TOKEN end_char="4063" id="token-39-10" morph="none" pos="punct" start_char="4063">.</TOKEN>
<TRANSLATED_TEXT>Fortunately I made a copy and save it on this server.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4139" id="segment-40" start_char="4066">
<ORIGINAL_TEXT>Noticias Uno-Colombia-2-5-2020 dióxido de cloro tratamiento COVID1902.mp4</ORIGINAL_TEXT>
<TOKEN end_char="4073" id="token-40-0" morph="none" pos="word" start_char="4066">Noticias</TOKEN>
<TOKEN end_char="4095" id="token-40-1" morph="none" pos="unknown" start_char="4075">Uno-Colombia-2-5-2020</TOKEN>
<TOKEN end_char="4104" id="token-40-2" morph="none" pos="word" start_char="4097">dióxido</TOKEN>
<TOKEN end_char="4107" id="token-40-3" morph="none" pos="word" start_char="4106">de</TOKEN>
<TOKEN end_char="4113" id="token-40-4" morph="none" pos="word" start_char="4109">cloro</TOKEN>
<TOKEN end_char="4125" id="token-40-5" morph="none" pos="word" start_char="4115">tratamiento</TOKEN>
<TOKEN end_char="4139" id="token-40-6" morph="none" pos="unknown" start_char="4127">COVID1902.mp4</TOKEN>
<TRANSLATED_TEXT>News 1-Colombia-2-5-2020 chlorine dioxide treatment COVID1902.mp4</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4353" id="segment-41" start_char="4142">
<ORIGINAL_TEXT>En el vídeo podréis ver el patético intento de esta cadena de televisión por ridiculizar el proyecto de investigación de un posible tratamiento del COVID19 con dióxido de cloro efectuado por un médico colombiano.</ORIGINAL_TEXT>
<TOKEN end_char="4143" id="token-41-0" morph="none" pos="word" start_char="4142">En</TOKEN>
<TOKEN end_char="4146" id="token-41-1" morph="none" pos="word" start_char="4145">el</TOKEN>
<TOKEN end_char="4152" id="token-41-2" morph="none" pos="word" start_char="4148">vídeo</TOKEN>
<TOKEN end_char="4160" id="token-41-3" morph="none" pos="word" start_char="4154">podréis</TOKEN>
<TOKEN end_char="4164" id="token-41-4" morph="none" pos="word" start_char="4162">ver</TOKEN>
<TOKEN end_char="4167" id="token-41-5" morph="none" pos="word" start_char="4166">el</TOKEN>
<TOKEN end_char="4176" id="token-41-6" morph="none" pos="word" start_char="4169">patético</TOKEN>
<TOKEN end_char="4184" id="token-41-7" morph="none" pos="word" start_char="4178">intento</TOKEN>
<TOKEN end_char="4187" id="token-41-8" morph="none" pos="word" start_char="4186">de</TOKEN>
<TOKEN end_char="4192" id="token-41-9" morph="none" pos="word" start_char="4189">esta</TOKEN>
<TOKEN end_char="4199" id="token-41-10" morph="none" pos="word" start_char="4194">cadena</TOKEN>
<TOKEN end_char="4202" id="token-41-11" morph="none" pos="word" start_char="4201">de</TOKEN>
<TOKEN end_char="4213" id="token-41-12" morph="none" pos="word" start_char="4204">televisión</TOKEN>
<TOKEN end_char="4217" id="token-41-13" morph="none" pos="word" start_char="4215">por</TOKEN>
<TOKEN end_char="4229" id="token-41-14" morph="none" pos="word" start_char="4219">ridiculizar</TOKEN>
<TOKEN end_char="4232" id="token-41-15" morph="none" pos="word" start_char="4231">el</TOKEN>
<TOKEN end_char="4241" id="token-41-16" morph="none" pos="word" start_char="4234">proyecto</TOKEN>
<TOKEN end_char="4244" id="token-41-17" morph="none" pos="word" start_char="4243">de</TOKEN>
<TOKEN end_char="4258" id="token-41-18" morph="none" pos="word" start_char="4246">investigación</TOKEN>
<TOKEN end_char="4261" id="token-41-19" morph="none" pos="word" start_char="4260">de</TOKEN>
<TOKEN end_char="4264" id="token-41-20" morph="none" pos="word" start_char="4263">un</TOKEN>
<TOKEN end_char="4272" id="token-41-21" morph="none" pos="word" start_char="4266">posible</TOKEN>
<TOKEN end_char="4284" id="token-41-22" morph="none" pos="word" start_char="4274">tratamiento</TOKEN>
<TOKEN end_char="4288" id="token-41-23" morph="none" pos="word" start_char="4286">del</TOKEN>
<TOKEN end_char="4296" id="token-41-24" morph="none" pos="word" start_char="4290">COVID19</TOKEN>
<TOKEN end_char="4300" id="token-41-25" morph="none" pos="word" start_char="4298">con</TOKEN>
<TOKEN end_char="4308" id="token-41-26" morph="none" pos="word" start_char="4302">dióxido</TOKEN>
<TOKEN end_char="4311" id="token-41-27" morph="none" pos="word" start_char="4310">de</TOKEN>
<TOKEN end_char="4317" id="token-41-28" morph="none" pos="word" start_char="4313">cloro</TOKEN>
<TOKEN end_char="4327" id="token-41-29" morph="none" pos="word" start_char="4319">efectuado</TOKEN>
<TOKEN end_char="4331" id="token-41-30" morph="none" pos="word" start_char="4329">por</TOKEN>
<TOKEN end_char="4334" id="token-41-31" morph="none" pos="word" start_char="4333">un</TOKEN>
<TOKEN end_char="4341" id="token-41-32" morph="none" pos="word" start_char="4336">médico</TOKEN>
<TOKEN end_char="4352" id="token-41-33" morph="none" pos="word" start_char="4343">colombiano</TOKEN>
<TOKEN end_char="4353" id="token-41-34" morph="none" pos="punct" start_char="4353">.</TOKEN>
<TRANSLATED_TEXT>In the video you can see the pathetic attempt of this television network to ridicule the research project of a possible treatment of COVID19 with chlorine dioxide by a Colombian doctor.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4445" id="segment-42" start_char="4356">
<ORIGINAL_TEXT>Ya me diréis que tiene de malo mostrar 6 minutos de un reportaje que se ha emitido por TV.</ORIGINAL_TEXT>
<TOKEN end_char="4357" id="token-42-0" morph="none" pos="word" start_char="4356">Ya</TOKEN>
<TOKEN end_char="4360" id="token-42-1" morph="none" pos="word" start_char="4359">me</TOKEN>
<TOKEN end_char="4367" id="token-42-2" morph="none" pos="word" start_char="4362">diréis</TOKEN>
<TOKEN end_char="4371" id="token-42-3" morph="none" pos="word" start_char="4369">que</TOKEN>
<TOKEN end_char="4377" id="token-42-4" morph="none" pos="word" start_char="4373">tiene</TOKEN>
<TOKEN end_char="4380" id="token-42-5" morph="none" pos="word" start_char="4379">de</TOKEN>
<TOKEN end_char="4385" id="token-42-6" morph="none" pos="word" start_char="4382">malo</TOKEN>
<TOKEN end_char="4393" id="token-42-7" morph="none" pos="word" start_char="4387">mostrar</TOKEN>
<TOKEN end_char="4395" id="token-42-8" morph="none" pos="word" start_char="4395">6</TOKEN>
<TOKEN end_char="4403" id="token-42-9" morph="none" pos="word" start_char="4397">minutos</TOKEN>
<TOKEN end_char="4406" id="token-42-10" morph="none" pos="word" start_char="4405">de</TOKEN>
<TOKEN end_char="4409" id="token-42-11" morph="none" pos="word" start_char="4408">un</TOKEN>
<TOKEN end_char="4419" id="token-42-12" morph="none" pos="word" start_char="4411">reportaje</TOKEN>
<TOKEN end_char="4423" id="token-42-13" morph="none" pos="word" start_char="4421">que</TOKEN>
<TOKEN end_char="4426" id="token-42-14" morph="none" pos="word" start_char="4425">se</TOKEN>
<TOKEN end_char="4429" id="token-42-15" morph="none" pos="word" start_char="4428">ha</TOKEN>
<TOKEN end_char="4437" id="token-42-16" morph="none" pos="word" start_char="4431">emitido</TOKEN>
<TOKEN end_char="4441" id="token-42-17" morph="none" pos="word" start_char="4439">por</TOKEN>
<TOKEN end_char="4444" id="token-42-18" morph="none" pos="word" start_char="4443">TV</TOKEN>
<TOKEN end_char="4445" id="token-42-19" morph="none" pos="punct" start_char="4445">.</TOKEN>
<TRANSLATED_TEXT>You will tell me that it is wrong to show 6 minutes of a report that has been on TV.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4547" id="segment-43" start_char="4448">
<ORIGINAL_TEXT>Este tipo de censura es una especie de miguitas de pan que nos muestra que vamos por el buen camino.</ORIGINAL_TEXT>
<TOKEN end_char="4451" id="token-43-0" morph="none" pos="word" start_char="4448">Este</TOKEN>
<TOKEN end_char="4456" id="token-43-1" morph="none" pos="word" start_char="4453">tipo</TOKEN>
<TOKEN end_char="4459" id="token-43-2" morph="none" pos="word" start_char="4458">de</TOKEN>
<TOKEN end_char="4467" id="token-43-3" morph="none" pos="word" start_char="4461">censura</TOKEN>
<TOKEN end_char="4470" id="token-43-4" morph="none" pos="word" start_char="4469">es</TOKEN>
<TOKEN end_char="4474" id="token-43-5" morph="none" pos="word" start_char="4472">una</TOKEN>
<TOKEN end_char="4482" id="token-43-6" morph="none" pos="word" start_char="4476">especie</TOKEN>
<TOKEN end_char="4485" id="token-43-7" morph="none" pos="word" start_char="4484">de</TOKEN>
<TOKEN end_char="4494" id="token-43-8" morph="none" pos="word" start_char="4487">miguitas</TOKEN>
<TOKEN end_char="4497" id="token-43-9" morph="none" pos="word" start_char="4496">de</TOKEN>
<TOKEN end_char="4501" id="token-43-10" morph="none" pos="word" start_char="4499">pan</TOKEN>
<TOKEN end_char="4505" id="token-43-11" morph="none" pos="word" start_char="4503">que</TOKEN>
<TOKEN end_char="4509" id="token-43-12" morph="none" pos="word" start_char="4507">nos</TOKEN>
<TOKEN end_char="4517" id="token-43-13" morph="none" pos="word" start_char="4511">muestra</TOKEN>
<TOKEN end_char="4521" id="token-43-14" morph="none" pos="word" start_char="4519">que</TOKEN>
<TOKEN end_char="4527" id="token-43-15" morph="none" pos="word" start_char="4523">vamos</TOKEN>
<TOKEN end_char="4531" id="token-43-16" morph="none" pos="word" start_char="4529">por</TOKEN>
<TOKEN end_char="4534" id="token-43-17" morph="none" pos="word" start_char="4533">el</TOKEN>
<TOKEN end_char="4539" id="token-43-18" morph="none" pos="word" start_char="4536">buen</TOKEN>
<TOKEN end_char="4546" id="token-43-19" morph="none" pos="word" start_char="4541">camino</TOKEN>
<TOKEN end_char="4547" id="token-43-20" morph="none" pos="punct" start_char="4547">.</TOKEN>
<TRANSLATED_TEXT>This kind of censorship is a kind of bread crumb that shows us that we 're going the right way.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4658" id="segment-44" start_char="4551">
<ORIGINAL_TEXT>un tecnico preocupado dijo: Estamos hablando de un estudio médico de 84 páginas...autentificado por notario.</ORIGINAL_TEXT>
<TOKEN end_char="4552" id="token-44-0" morph="none" pos="word" start_char="4551">un</TOKEN>
<TOKEN end_char="4560" id="token-44-1" morph="none" pos="word" start_char="4554">tecnico</TOKEN>
<TOKEN end_char="4571" id="token-44-2" morph="none" pos="word" start_char="4562">preocupado</TOKEN>
<TOKEN end_char="4576" id="token-44-3" morph="none" pos="word" start_char="4573">dijo</TOKEN>
<TOKEN end_char="4577" id="token-44-4" morph="none" pos="punct" start_char="4577">:</TOKEN>
<TOKEN end_char="4585" id="token-44-5" morph="none" pos="word" start_char="4579">Estamos</TOKEN>
<TOKEN end_char="4594" id="token-44-6" morph="none" pos="word" start_char="4587">hablando</TOKEN>
<TOKEN end_char="4597" id="token-44-7" morph="none" pos="word" start_char="4596">de</TOKEN>
<TOKEN end_char="4600" id="token-44-8" morph="none" pos="word" start_char="4599">un</TOKEN>
<TOKEN end_char="4608" id="token-44-9" morph="none" pos="word" start_char="4602">estudio</TOKEN>
<TOKEN end_char="4615" id="token-44-10" morph="none" pos="word" start_char="4610">médico</TOKEN>
<TOKEN end_char="4618" id="token-44-11" morph="none" pos="word" start_char="4617">de</TOKEN>
<TOKEN end_char="4621" id="token-44-12" morph="none" pos="word" start_char="4620">84</TOKEN>
<TOKEN end_char="4645" id="token-44-13" morph="none" pos="unknown" start_char="4623">páginas...autentificado</TOKEN>
<TOKEN end_char="4649" id="token-44-14" morph="none" pos="word" start_char="4647">por</TOKEN>
<TOKEN end_char="4657" id="token-44-15" morph="none" pos="word" start_char="4651">notario</TOKEN>
<TOKEN end_char="4658" id="token-44-16" morph="none" pos="punct" start_char="4658">.</TOKEN>
<TRANSLATED_TEXT>A concerned technician said: We are talking about an 84-page medical study... authenticated by a notary.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4904" id="segment-45" start_char="4660">
<ORIGINAL_TEXT>Con los DNIs del médico investigador principal y los datos de los otros 6, con los consentimientos informados de los pacientes sometidos al estudio, con datos histiológicos, con analiticas, con la aportación de los positivos por prueba PCR, etc.</ORIGINAL_TEXT>
<TOKEN end_char="4662" id="token-45-0" morph="none" pos="word" start_char="4660">Con</TOKEN>
<TOKEN end_char="4666" id="token-45-1" morph="none" pos="word" start_char="4664">los</TOKEN>
<TOKEN end_char="4671" id="token-45-2" morph="none" pos="word" start_char="4668">DNIs</TOKEN>
<TOKEN end_char="4675" id="token-45-3" morph="none" pos="word" start_char="4673">del</TOKEN>
<TOKEN end_char="4682" id="token-45-4" morph="none" pos="word" start_char="4677">médico</TOKEN>
<TOKEN end_char="4695" id="token-45-5" morph="none" pos="word" start_char="4684">investigador</TOKEN>
<TOKEN end_char="4705" id="token-45-6" morph="none" pos="word" start_char="4697">principal</TOKEN>
<TOKEN end_char="4707" id="token-45-7" morph="none" pos="word" start_char="4707">y</TOKEN>
<TOKEN end_char="4711" id="token-45-8" morph="none" pos="word" start_char="4709">los</TOKEN>
<TOKEN end_char="4717" id="token-45-9" morph="none" pos="word" start_char="4713">datos</TOKEN>
<TOKEN end_char="4720" id="token-45-10" morph="none" pos="word" start_char="4719">de</TOKEN>
<TOKEN end_char="4724" id="token-45-11" morph="none" pos="word" start_char="4722">los</TOKEN>
<TOKEN end_char="4730" id="token-45-12" morph="none" pos="word" start_char="4726">otros</TOKEN>
<TOKEN end_char="4732" id="token-45-13" morph="none" pos="word" start_char="4732">6</TOKEN>
<TOKEN end_char="4733" id="token-45-14" morph="none" pos="punct" start_char="4733">,</TOKEN>
<TOKEN end_char="4737" id="token-45-15" morph="none" pos="word" start_char="4735">con</TOKEN>
<TOKEN end_char="4741" id="token-45-16" morph="none" pos="word" start_char="4739">los</TOKEN>
<TOKEN end_char="4757" id="token-45-17" morph="none" pos="word" start_char="4743">consentimientos</TOKEN>
<TOKEN end_char="4768" id="token-45-18" morph="none" pos="word" start_char="4759">informados</TOKEN>
<TOKEN end_char="4771" id="token-45-19" morph="none" pos="word" start_char="4770">de</TOKEN>
<TOKEN end_char="4775" id="token-45-20" morph="none" pos="word" start_char="4773">los</TOKEN>
<TOKEN end_char="4785" id="token-45-21" morph="none" pos="word" start_char="4777">pacientes</TOKEN>
<TOKEN end_char="4795" id="token-45-22" morph="none" pos="word" start_char="4787">sometidos</TOKEN>
<TOKEN end_char="4798" id="token-45-23" morph="none" pos="word" start_char="4797">al</TOKEN>
<TOKEN end_char="4806" id="token-45-24" morph="none" pos="word" start_char="4800">estudio</TOKEN>
<TOKEN end_char="4807" id="token-45-25" morph="none" pos="punct" start_char="4807">,</TOKEN>
<TOKEN end_char="4811" id="token-45-26" morph="none" pos="word" start_char="4809">con</TOKEN>
<TOKEN end_char="4817" id="token-45-27" morph="none" pos="word" start_char="4813">datos</TOKEN>
<TOKEN end_char="4831" id="token-45-28" morph="none" pos="word" start_char="4819">histiológicos</TOKEN>
<TOKEN end_char="4832" id="token-45-29" morph="none" pos="punct" start_char="4832">,</TOKEN>
<TOKEN end_char="4836" id="token-45-30" morph="none" pos="word" start_char="4834">con</TOKEN>
<TOKEN end_char="4847" id="token-45-31" morph="none" pos="word" start_char="4838">analiticas</TOKEN>
<TOKEN end_char="4848" id="token-45-32" morph="none" pos="punct" start_char="4848">,</TOKEN>
<TOKEN end_char="4852" id="token-45-33" morph="none" pos="word" start_char="4850">con</TOKEN>
<TOKEN end_char="4855" id="token-45-34" morph="none" pos="word" start_char="4854">la</TOKEN>
<TOKEN end_char="4866" id="token-45-35" morph="none" pos="word" start_char="4857">aportación</TOKEN>
<TOKEN end_char="4869" id="token-45-36" morph="none" pos="word" start_char="4868">de</TOKEN>
<TOKEN end_char="4873" id="token-45-37" morph="none" pos="word" start_char="4871">los</TOKEN>
<TOKEN end_char="4883" id="token-45-38" morph="none" pos="word" start_char="4875">positivos</TOKEN>
<TOKEN end_char="4887" id="token-45-39" morph="none" pos="word" start_char="4885">por</TOKEN>
<TOKEN end_char="4894" id="token-45-40" morph="none" pos="word" start_char="4889">prueba</TOKEN>
<TOKEN end_char="4898" id="token-45-41" morph="none" pos="word" start_char="4896">PCR</TOKEN>
<TOKEN end_char="4899" id="token-45-42" morph="none" pos="punct" start_char="4899">,</TOKEN>
<TOKEN end_char="4903" id="token-45-43" morph="none" pos="word" start_char="4901">etc</TOKEN>
<TOKEN end_char="4904" id="token-45-44" morph="none" pos="punct" start_char="4904">.</TOKEN>
<TRANSLATED_TEXT>With the DNIs of the principal investigator and the data of the other 6, with the informed consent of the patients subjected to the study, with histological data, with analysts, with the contribution of PCR test positives, etc.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5265" id="segment-46" start_char="4908">
<ORIGINAL_TEXT>No hace falta saber mucho sobre medicina o estudios científicos para darse cuenta de que un estudio en el que coges a un grupo de personas en una franja de edad en la que la gran mayoría de la gente supera el virus, les das cualquier cosa que no les mate, y luego te asombras de que la mayoría efectivamente se curen, es un estudio que vale para muy poquito.</ORIGINAL_TEXT>
<TOKEN end_char="4909" id="token-46-0" morph="none" pos="word" start_char="4908">No</TOKEN>
<TOKEN end_char="4914" id="token-46-1" morph="none" pos="word" start_char="4911">hace</TOKEN>
<TOKEN end_char="4920" id="token-46-2" morph="none" pos="word" start_char="4916">falta</TOKEN>
<TOKEN end_char="4926" id="token-46-3" morph="none" pos="word" start_char="4922">saber</TOKEN>
<TOKEN end_char="4932" id="token-46-4" morph="none" pos="word" start_char="4928">mucho</TOKEN>
<TOKEN end_char="4938" id="token-46-5" morph="none" pos="word" start_char="4934">sobre</TOKEN>
<TOKEN end_char="4947" id="token-46-6" morph="none" pos="word" start_char="4940">medicina</TOKEN>
<TOKEN end_char="4949" id="token-46-7" morph="none" pos="word" start_char="4949">o</TOKEN>
<TOKEN end_char="4958" id="token-46-8" morph="none" pos="word" start_char="4951">estudios</TOKEN>
<TOKEN end_char="4970" id="token-46-9" morph="none" pos="word" start_char="4960">científicos</TOKEN>
<TOKEN end_char="4975" id="token-46-10" morph="none" pos="word" start_char="4972">para</TOKEN>
<TOKEN end_char="4981" id="token-46-11" morph="none" pos="word" start_char="4977">darse</TOKEN>
<TOKEN end_char="4988" id="token-46-12" morph="none" pos="word" start_char="4983">cuenta</TOKEN>
<TOKEN end_char="4991" id="token-46-13" morph="none" pos="word" start_char="4990">de</TOKEN>
<TOKEN end_char="4995" id="token-46-14" morph="none" pos="word" start_char="4993">que</TOKEN>
<TOKEN end_char="4998" id="token-46-15" morph="none" pos="word" start_char="4997">un</TOKEN>
<TOKEN end_char="5006" id="token-46-16" morph="none" pos="word" start_char="5000">estudio</TOKEN>
<TOKEN end_char="5009" id="token-46-17" morph="none" pos="word" start_char="5008">en</TOKEN>
<TOKEN end_char="5012" id="token-46-18" morph="none" pos="word" start_char="5011">el</TOKEN>
<TOKEN end_char="5016" id="token-46-19" morph="none" pos="word" start_char="5014">que</TOKEN>
<TOKEN end_char="5022" id="token-46-20" morph="none" pos="word" start_char="5018">coges</TOKEN>
<TOKEN end_char="5024" id="token-46-21" morph="none" pos="word" start_char="5024">a</TOKEN>
<TOKEN end_char="5027" id="token-46-22" morph="none" pos="word" start_char="5026">un</TOKEN>
<TOKEN end_char="5033" id="token-46-23" morph="none" pos="word" start_char="5029">grupo</TOKEN>
<TOKEN end_char="5036" id="token-46-24" morph="none" pos="word" start_char="5035">de</TOKEN>
<TOKEN end_char="5045" id="token-46-25" morph="none" pos="word" start_char="5038">personas</TOKEN>
<TOKEN end_char="5048" id="token-46-26" morph="none" pos="word" start_char="5047">en</TOKEN>
<TOKEN end_char="5052" id="token-46-27" morph="none" pos="word" start_char="5050">una</TOKEN>
<TOKEN end_char="5059" id="token-46-28" morph="none" pos="word" start_char="5054">franja</TOKEN>
<TOKEN end_char="5062" id="token-46-29" morph="none" pos="word" start_char="5061">de</TOKEN>
<TOKEN end_char="5067" id="token-46-30" morph="none" pos="word" start_char="5064">edad</TOKEN>
<TOKEN end_char="5070" id="token-46-31" morph="none" pos="word" start_char="5069">en</TOKEN>
<TOKEN end_char="5073" id="token-46-32" morph="none" pos="word" start_char="5072">la</TOKEN>
<TOKEN end_char="5077" id="token-46-33" morph="none" pos="word" start_char="5075">que</TOKEN>
<TOKEN end_char="5080" id="token-46-34" morph="none" pos="word" start_char="5079">la</TOKEN>
<TOKEN end_char="5085" id="token-46-35" morph="none" pos="word" start_char="5082">gran</TOKEN>
<TOKEN end_char="5093" id="token-46-36" morph="none" pos="word" start_char="5087">mayoría</TOKEN>
<TOKEN end_char="5096" id="token-46-37" morph="none" pos="word" start_char="5095">de</TOKEN>
<TOKEN end_char="5099" id="token-46-38" morph="none" pos="word" start_char="5098">la</TOKEN>
<TOKEN end_char="5105" id="token-46-39" morph="none" pos="word" start_char="5101">gente</TOKEN>
<TOKEN end_char="5112" id="token-46-40" morph="none" pos="word" start_char="5107">supera</TOKEN>
<TOKEN end_char="5115" id="token-46-41" morph="none" pos="word" start_char="5114">el</TOKEN>
<TOKEN end_char="5121" id="token-46-42" morph="none" pos="word" start_char="5117">virus</TOKEN>
<TOKEN end_char="5122" id="token-46-43" morph="none" pos="punct" start_char="5122">,</TOKEN>
<TOKEN end_char="5126" id="token-46-44" morph="none" pos="word" start_char="5124">les</TOKEN>
<TOKEN end_char="5130" id="token-46-45" morph="none" pos="word" start_char="5128">das</TOKEN>
<TOKEN end_char="5140" id="token-46-46" morph="none" pos="word" start_char="5132">cualquier</TOKEN>
<TOKEN end_char="5145" id="token-46-47" morph="none" pos="word" start_char="5142">cosa</TOKEN>
<TOKEN end_char="5149" id="token-46-48" morph="none" pos="word" start_char="5147">que</TOKEN>
<TOKEN end_char="5152" id="token-46-49" morph="none" pos="word" start_char="5151">no</TOKEN>
<TOKEN end_char="5156" id="token-46-50" morph="none" pos="word" start_char="5154">les</TOKEN>
<TOKEN end_char="5161" id="token-46-51" morph="none" pos="word" start_char="5158">mate</TOKEN>
<TOKEN end_char="5162" id="token-46-52" morph="none" pos="punct" start_char="5162">,</TOKEN>
<TOKEN end_char="5164" id="token-46-53" morph="none" pos="word" start_char="5164">y</TOKEN>
<TOKEN end_char="5170" id="token-46-54" morph="none" pos="word" start_char="5166">luego</TOKEN>
<TOKEN end_char="5173" id="token-46-55" morph="none" pos="word" start_char="5172">te</TOKEN>
<TOKEN end_char="5182" id="token-46-56" morph="none" pos="word" start_char="5175">asombras</TOKEN>
<TOKEN end_char="5185" id="token-46-57" morph="none" pos="word" start_char="5184">de</TOKEN>
<TOKEN end_char="5189" id="token-46-58" morph="none" pos="word" start_char="5187">que</TOKEN>
<TOKEN end_char="5192" id="token-46-59" morph="none" pos="word" start_char="5191">la</TOKEN>
<TOKEN end_char="5200" id="token-46-60" morph="none" pos="word" start_char="5194">mayoría</TOKEN>
<TOKEN end_char="5214" id="token-46-61" morph="none" pos="word" start_char="5202">efectivamente</TOKEN>
<TOKEN end_char="5217" id="token-46-62" morph="none" pos="word" start_char="5216">se</TOKEN>
<TOKEN end_char="5223" id="token-46-63" morph="none" pos="word" start_char="5219">curen</TOKEN>
<TOKEN end_char="5224" id="token-46-64" morph="none" pos="punct" start_char="5224">,</TOKEN>
<TOKEN end_char="5227" id="token-46-65" morph="none" pos="word" start_char="5226">es</TOKEN>
<TOKEN end_char="5230" id="token-46-66" morph="none" pos="word" start_char="5229">un</TOKEN>
<TOKEN end_char="5238" id="token-46-67" morph="none" pos="word" start_char="5232">estudio</TOKEN>
<TOKEN end_char="5242" id="token-46-68" morph="none" pos="word" start_char="5240">que</TOKEN>
<TOKEN end_char="5247" id="token-46-69" morph="none" pos="word" start_char="5244">vale</TOKEN>
<TOKEN end_char="5252" id="token-46-70" morph="none" pos="word" start_char="5249">para</TOKEN>
<TOKEN end_char="5256" id="token-46-71" morph="none" pos="word" start_char="5254">muy</TOKEN>
<TOKEN end_char="5264" id="token-46-72" morph="none" pos="word" start_char="5258">poquito</TOKEN>
<TOKEN end_char="5265" id="token-46-73" morph="none" pos="punct" start_char="5265">.</TOKEN>
<TRANSLATED_TEXT>You don 't need to know a lot about medicine or scientific studies to realize that a study in which you take a group of people in an age range in which the vast majority of people get over the virus, you give them anything that doesn' t kill them, and then you 're amazed that most people actually cure, is a study that' s worth a little bit.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5297" id="segment-47" start_char="5268">
<ORIGINAL_TEXT>¿Cuál era el grupo de control?</ORIGINAL_TEXT>
<TOKEN end_char="5268" id="token-47-0" morph="none" pos="punct" start_char="5268">¿</TOKEN>
<TOKEN end_char="5272" id="token-47-1" morph="none" pos="word" start_char="5269">Cuál</TOKEN>
<TOKEN end_char="5276" id="token-47-2" morph="none" pos="word" start_char="5274">era</TOKEN>
<TOKEN end_char="5279" id="token-47-3" morph="none" pos="word" start_char="5278">el</TOKEN>
<TOKEN end_char="5285" id="token-47-4" morph="none" pos="word" start_char="5281">grupo</TOKEN>
<TOKEN end_char="5288" id="token-47-5" morph="none" pos="word" start_char="5287">de</TOKEN>
<TOKEN end_char="5296" id="token-47-6" morph="none" pos="word" start_char="5290">control</TOKEN>
<TOKEN end_char="5297" id="token-47-7" morph="none" pos="punct" start_char="5297">?</TOKEN>
<TRANSLATED_TEXT>What was the control group?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5419" id="segment-48" start_char="5300">
<ORIGINAL_TEXT>Y por cierto, la bondad de un estudios científico no la valida un notario Has escuchado hablar de la revisión por pares?</ORIGINAL_TEXT>
<TOKEN end_char="5300" id="token-48-0" morph="none" pos="word" start_char="5300">Y</TOKEN>
<TOKEN end_char="5304" id="token-48-1" morph="none" pos="word" start_char="5302">por</TOKEN>
<TOKEN end_char="5311" id="token-48-2" morph="none" pos="word" start_char="5306">cierto</TOKEN>
<TOKEN end_char="5312" id="token-48-3" morph="none" pos="punct" start_char="5312">,</TOKEN>
<TOKEN end_char="5315" id="token-48-4" morph="none" pos="word" start_char="5314">la</TOKEN>
<TOKEN end_char="5322" id="token-48-5" morph="none" pos="word" start_char="5317">bondad</TOKEN>
<TOKEN end_char="5325" id="token-48-6" morph="none" pos="word" start_char="5324">de</TOKEN>
<TOKEN end_char="5328" id="token-48-7" morph="none" pos="word" start_char="5327">un</TOKEN>
<TOKEN end_char="5337" id="token-48-8" morph="none" pos="word" start_char="5330">estudios</TOKEN>
<TOKEN end_char="5348" id="token-48-9" morph="none" pos="word" start_char="5339">científico</TOKEN>
<TOKEN end_char="5351" id="token-48-10" morph="none" pos="word" start_char="5350">no</TOKEN>
<TOKEN end_char="5354" id="token-48-11" morph="none" pos="word" start_char="5353">la</TOKEN>
<TOKEN end_char="5361" id="token-48-12" morph="none" pos="word" start_char="5356">valida</TOKEN>
<TOKEN end_char="5364" id="token-48-13" morph="none" pos="word" start_char="5363">un</TOKEN>
<TOKEN end_char="5372" id="token-48-14" morph="none" pos="word" start_char="5366">notario</TOKEN>
<TOKEN end_char="5376" id="token-48-15" morph="none" pos="word" start_char="5374">Has</TOKEN>
<TOKEN end_char="5386" id="token-48-16" morph="none" pos="word" start_char="5378">escuchado</TOKEN>
<TOKEN end_char="5393" id="token-48-17" morph="none" pos="word" start_char="5388">hablar</TOKEN>
<TOKEN end_char="5396" id="token-48-18" morph="none" pos="word" start_char="5395">de</TOKEN>
<TOKEN end_char="5399" id="token-48-19" morph="none" pos="word" start_char="5398">la</TOKEN>
<TOKEN end_char="5408" id="token-48-20" morph="none" pos="word" start_char="5401">revisión</TOKEN>
<TOKEN end_char="5412" id="token-48-21" morph="none" pos="word" start_char="5410">por</TOKEN>
<TOKEN end_char="5418" id="token-48-22" morph="none" pos="word" start_char="5414">pares</TOKEN>
<TOKEN end_char="5419" id="token-48-23" morph="none" pos="punct" start_char="5419">?</TOKEN>
<TRANSLATED_TEXT>And by the way, the goodness of scientific research doesn 't validate a notary. Have you heard of peer review?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5552" id="segment-49" start_char="5424">
<ORIGINAL_TEXT>un tecnico preocupado dijo: Supongo que automáticamente este post será reducido a la nada o enviado al subforo de conspiraciones.</ORIGINAL_TEXT>
<TOKEN end_char="5425" id="token-49-0" morph="none" pos="word" start_char="5424">un</TOKEN>
<TOKEN end_char="5433" id="token-49-1" morph="none" pos="word" start_char="5427">tecnico</TOKEN>
<TOKEN end_char="5444" id="token-49-2" morph="none" pos="word" start_char="5435">preocupado</TOKEN>
<TOKEN end_char="5449" id="token-49-3" morph="none" pos="word" start_char="5446">dijo</TOKEN>
<TOKEN end_char="5450" id="token-49-4" morph="none" pos="punct" start_char="5450">:</TOKEN>
<TOKEN end_char="5458" id="token-49-5" morph="none" pos="word" start_char="5452">Supongo</TOKEN>
<TOKEN end_char="5462" id="token-49-6" morph="none" pos="word" start_char="5460">que</TOKEN>
<TOKEN end_char="5478" id="token-49-7" morph="none" pos="word" start_char="5464">automáticamente</TOKEN>
<TOKEN end_char="5483" id="token-49-8" morph="none" pos="word" start_char="5480">este</TOKEN>
<TOKEN end_char="5488" id="token-49-9" morph="none" pos="word" start_char="5485">post</TOKEN>
<TOKEN end_char="5493" id="token-49-10" morph="none" pos="word" start_char="5490">será</TOKEN>
<TOKEN end_char="5502" id="token-49-11" morph="none" pos="word" start_char="5495">reducido</TOKEN>
<TOKEN end_char="5504" id="token-49-12" morph="none" pos="word" start_char="5504">a</TOKEN>
<TOKEN end_char="5507" id="token-49-13" morph="none" pos="word" start_char="5506">la</TOKEN>
<TOKEN end_char="5512" id="token-49-14" morph="none" pos="word" start_char="5509">nada</TOKEN>
<TOKEN end_char="5514" id="token-49-15" morph="none" pos="word" start_char="5514">o</TOKEN>
<TOKEN end_char="5522" id="token-49-16" morph="none" pos="word" start_char="5516">enviado</TOKEN>
<TOKEN end_char="5525" id="token-49-17" morph="none" pos="word" start_char="5524">al</TOKEN>
<TOKEN end_char="5533" id="token-49-18" morph="none" pos="word" start_char="5527">subforo</TOKEN>
<TOKEN end_char="5536" id="token-49-19" morph="none" pos="word" start_char="5535">de</TOKEN>
<TOKEN end_char="5551" id="token-49-20" morph="none" pos="word" start_char="5538">conspiraciones</TOKEN>
<TOKEN end_char="5552" id="token-49-21" morph="none" pos="punct" start_char="5552">.</TOKEN>
<TRANSLATED_TEXT>a concerned technician said: I assume that this post will automatically be reduced to nothing or sent to the conspiracy sub.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5607" id="segment-50" start_char="5554">
<ORIGINAL_TEXT>Pero lo que aqui les mostrare no es magia, es ciencia.</ORIGINAL_TEXT>
<TOKEN end_char="5557" id="token-50-0" morph="none" pos="word" start_char="5554">Pero</TOKEN>
<TOKEN end_char="5560" id="token-50-1" morph="none" pos="word" start_char="5559">lo</TOKEN>
<TOKEN end_char="5564" id="token-50-2" morph="none" pos="word" start_char="5562">que</TOKEN>
<TOKEN end_char="5569" id="token-50-3" morph="none" pos="word" start_char="5566">aqui</TOKEN>
<TOKEN end_char="5573" id="token-50-4" morph="none" pos="word" start_char="5571">les</TOKEN>
<TOKEN end_char="5582" id="token-50-5" morph="none" pos="word" start_char="5575">mostrare</TOKEN>
<TOKEN end_char="5585" id="token-50-6" morph="none" pos="word" start_char="5584">no</TOKEN>
<TOKEN end_char="5588" id="token-50-7" morph="none" pos="word" start_char="5587">es</TOKEN>
<TOKEN end_char="5594" id="token-50-8" morph="none" pos="word" start_char="5590">magia</TOKEN>
<TOKEN end_char="5595" id="token-50-9" morph="none" pos="punct" start_char="5595">,</TOKEN>
<TOKEN end_char="5598" id="token-50-10" morph="none" pos="word" start_char="5597">es</TOKEN>
<TOKEN end_char="5606" id="token-50-11" morph="none" pos="word" start_char="5600">ciencia</TOKEN>
<TOKEN end_char="5607" id="token-50-12" morph="none" pos="punct" start_char="5607">.</TOKEN>
<TRANSLATED_TEXT>But what we 're showing you here is not magic, it' s science.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5750" id="segment-51" start_char="5609">
<ORIGINAL_TEXT>Se trata del primer estudio bien documentado de tratamiento del virus SarsCoV2 mediante el uso de dióxido de cloro vía oral y vía intravenosa.</ORIGINAL_TEXT>
<TOKEN end_char="5610" id="token-51-0" morph="none" pos="word" start_char="5609">Se</TOKEN>
<TOKEN end_char="5616" id="token-51-1" morph="none" pos="word" start_char="5612">trata</TOKEN>
<TOKEN end_char="5620" id="token-51-2" morph="none" pos="word" start_char="5618">del</TOKEN>
<TOKEN end_char="5627" id="token-51-3" morph="none" pos="word" start_char="5622">primer</TOKEN>
<TOKEN end_char="5635" id="token-51-4" morph="none" pos="word" start_char="5629">estudio</TOKEN>
<TOKEN end_char="5640" id="token-51-5" morph="none" pos="word" start_char="5637">bien</TOKEN>
<TOKEN end_char="5652" id="token-51-6" morph="none" pos="word" start_char="5642">documentado</TOKEN>
<TOKEN end_char="5655" id="token-51-7" morph="none" pos="word" start_char="5654">de</TOKEN>
<TOKEN end_char="5667" id="token-51-8" morph="none" pos="word" start_char="5657">tratamiento</TOKEN>
<TOKEN end_char="5671" id="token-51-9" morph="none" pos="word" start_char="5669">del</TOKEN>
<TOKEN end_char="5677" id="token-51-10" morph="none" pos="word" start_char="5673">virus</TOKEN>
<TOKEN end_char="5686" id="token-51-11" morph="none" pos="word" start_char="5679">SarsCoV2</TOKEN>
<TOKEN end_char="5695" id="token-51-12" morph="none" pos="word" start_char="5688">mediante</TOKEN>
<TOKEN end_char="5698" id="token-51-13" morph="none" pos="word" start_char="5697">el</TOKEN>
<TOKEN end_char="5702" id="token-51-14" morph="none" pos="word" start_char="5700">uso</TOKEN>
<TOKEN end_char="5705" id="token-51-15" morph="none" pos="word" start_char="5704">de</TOKEN>
<TOKEN end_char="5713" id="token-51-16" morph="none" pos="word" start_char="5707">dióxido</TOKEN>
<TOKEN end_char="5716" id="token-51-17" morph="none" pos="word" start_char="5715">de</TOKEN>
<TOKEN end_char="5722" id="token-51-18" morph="none" pos="word" start_char="5718">cloro</TOKEN>
<TOKEN end_char="5726" id="token-51-19" morph="none" pos="word" start_char="5724">vía</TOKEN>
<TOKEN end_char="5731" id="token-51-20" morph="none" pos="word" start_char="5728">oral</TOKEN>
<TOKEN end_char="5733" id="token-51-21" morph="none" pos="word" start_char="5733">y</TOKEN>
<TOKEN end_char="5737" id="token-51-22" morph="none" pos="word" start_char="5735">vía</TOKEN>
<TOKEN end_char="5749" id="token-51-23" morph="none" pos="word" start_char="5739">intravenosa</TOKEN>
<TOKEN end_char="5750" id="token-51-24" morph="none" pos="punct" start_char="5750">.</TOKEN>
<TRANSLATED_TEXT>This is the first well-documented study of SarsCoV2 virus treatment using chlorine dioxide orally and intravenously.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5851" id="segment-52" start_char="5752">
<ORIGINAL_TEXT>Estudio del CDS (versión mejorada del MMS, dióxido de cloro) en 104 humanos infectados por COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="5758" id="token-52-0" morph="none" pos="word" start_char="5752">Estudio</TOKEN>
<TOKEN end_char="5762" id="token-52-1" morph="none" pos="word" start_char="5760">del</TOKEN>
<TOKEN end_char="5766" id="token-52-2" morph="none" pos="word" start_char="5764">CDS</TOKEN>
<TOKEN end_char="5768" id="token-52-3" morph="none" pos="punct" start_char="5768">(</TOKEN>
<TOKEN end_char="5775" id="token-52-4" morph="none" pos="word" start_char="5769">versión</TOKEN>
<TOKEN end_char="5784" id="token-52-5" morph="none" pos="word" start_char="5777">mejorada</TOKEN>
<TOKEN end_char="5788" id="token-52-6" morph="none" pos="word" start_char="5786">del</TOKEN>
<TOKEN end_char="5792" id="token-52-7" morph="none" pos="word" start_char="5790">MMS</TOKEN>
<TOKEN end_char="5793" id="token-52-8" morph="none" pos="punct" start_char="5793">,</TOKEN>
<TOKEN end_char="5801" id="token-52-9" morph="none" pos="word" start_char="5795">dióxido</TOKEN>
<TOKEN end_char="5804" id="token-52-10" morph="none" pos="word" start_char="5803">de</TOKEN>
<TOKEN end_char="5810" id="token-52-11" morph="none" pos="word" start_char="5806">cloro</TOKEN>
<TOKEN end_char="5811" id="token-52-12" morph="none" pos="punct" start_char="5811">)</TOKEN>
<TOKEN end_char="5814" id="token-52-13" morph="none" pos="word" start_char="5813">en</TOKEN>
<TOKEN end_char="5818" id="token-52-14" morph="none" pos="word" start_char="5816">104</TOKEN>
<TOKEN end_char="5826" id="token-52-15" morph="none" pos="word" start_char="5820">humanos</TOKEN>
<TOKEN end_char="5837" id="token-52-16" morph="none" pos="word" start_char="5828">infectados</TOKEN>
<TOKEN end_char="5841" id="token-52-17" morph="none" pos="word" start_char="5839">por</TOKEN>
<TOKEN end_char="5850" id="token-52-18" morph="none" pos="unknown" start_char="5843">COVID-19</TOKEN>
<TOKEN end_char="5851" id="token-52-19" morph="none" pos="punct" start_char="5851">.</TOKEN>
<TRANSLATED_TEXT>Study of CDS (improved version of MMS, chlorine dioxide) in 104 humans infected with COVID-19.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6176" id="segment-53" start_char="5853">
<ORIGINAL_TEXT>Aquí tenéis el documento oficial de ensayo clínico preliminar en Ecuador de CDS Oral e intravenoso de la asociación médica de AEMEMI con acta notarial firmada y datos fidedignos que demuestran la eficacia del Dióxido de cloro tanto Oral como Parenteral como sustancia eficaz contra el coronavirus con una eficacia de un 97%.</ORIGINAL_TEXT>
<TOKEN end_char="5856" id="token-53-0" morph="none" pos="word" start_char="5853">Aquí</TOKEN>
<TOKEN end_char="5863" id="token-53-1" morph="none" pos="word" start_char="5858">tenéis</TOKEN>
<TOKEN end_char="5866" id="token-53-2" morph="none" pos="word" start_char="5865">el</TOKEN>
<TOKEN end_char="5876" id="token-53-3" morph="none" pos="word" start_char="5868">documento</TOKEN>
<TOKEN end_char="5884" id="token-53-4" morph="none" pos="word" start_char="5878">oficial</TOKEN>
<TOKEN end_char="5887" id="token-53-5" morph="none" pos="word" start_char="5886">de</TOKEN>
<TOKEN end_char="5894" id="token-53-6" morph="none" pos="word" start_char="5889">ensayo</TOKEN>
<TOKEN end_char="5902" id="token-53-7" morph="none" pos="word" start_char="5896">clínico</TOKEN>
<TOKEN end_char="5913" id="token-53-8" morph="none" pos="word" start_char="5904">preliminar</TOKEN>
<TOKEN end_char="5916" id="token-53-9" morph="none" pos="word" start_char="5915">en</TOKEN>
<TOKEN end_char="5924" id="token-53-10" morph="none" pos="word" start_char="5918">Ecuador</TOKEN>
<TOKEN end_char="5927" id="token-53-11" morph="none" pos="word" start_char="5926">de</TOKEN>
<TOKEN end_char="5931" id="token-53-12" morph="none" pos="word" start_char="5929">CDS</TOKEN>
<TOKEN end_char="5936" id="token-53-13" morph="none" pos="word" start_char="5933">Oral</TOKEN>
<TOKEN end_char="5938" id="token-53-14" morph="none" pos="word" start_char="5938">e</TOKEN>
<TOKEN end_char="5950" id="token-53-15" morph="none" pos="word" start_char="5940">intravenoso</TOKEN>
<TOKEN end_char="5953" id="token-53-16" morph="none" pos="word" start_char="5952">de</TOKEN>
<TOKEN end_char="5956" id="token-53-17" morph="none" pos="word" start_char="5955">la</TOKEN>
<TOKEN end_char="5967" id="token-53-18" morph="none" pos="word" start_char="5958">asociación</TOKEN>
<TOKEN end_char="5974" id="token-53-19" morph="none" pos="word" start_char="5969">médica</TOKEN>
<TOKEN end_char="5977" id="token-53-20" morph="none" pos="word" start_char="5976">de</TOKEN>
<TOKEN end_char="5984" id="token-53-21" morph="none" pos="word" start_char="5979">AEMEMI</TOKEN>
<TOKEN end_char="5988" id="token-53-22" morph="none" pos="word" start_char="5986">con</TOKEN>
<TOKEN end_char="5993" id="token-53-23" morph="none" pos="word" start_char="5990">acta</TOKEN>
<TOKEN end_char="6002" id="token-53-24" morph="none" pos="word" start_char="5995">notarial</TOKEN>
<TOKEN end_char="6010" id="token-53-25" morph="none" pos="word" start_char="6004">firmada</TOKEN>
<TOKEN end_char="6012" id="token-53-26" morph="none" pos="word" start_char="6012">y</TOKEN>
<TOKEN end_char="6018" id="token-53-27" morph="none" pos="word" start_char="6014">datos</TOKEN>
<TOKEN end_char="6029" id="token-53-28" morph="none" pos="word" start_char="6020">fidedignos</TOKEN>
<TOKEN end_char="6033" id="token-53-29" morph="none" pos="word" start_char="6031">que</TOKEN>
<TOKEN end_char="6044" id="token-53-30" morph="none" pos="word" start_char="6035">demuestran</TOKEN>
<TOKEN end_char="6047" id="token-53-31" morph="none" pos="word" start_char="6046">la</TOKEN>
<TOKEN end_char="6056" id="token-53-32" morph="none" pos="word" start_char="6049">eficacia</TOKEN>
<TOKEN end_char="6060" id="token-53-33" morph="none" pos="word" start_char="6058">del</TOKEN>
<TOKEN end_char="6068" id="token-53-34" morph="none" pos="word" start_char="6062">Dióxido</TOKEN>
<TOKEN end_char="6071" id="token-53-35" morph="none" pos="word" start_char="6070">de</TOKEN>
<TOKEN end_char="6077" id="token-53-36" morph="none" pos="word" start_char="6073">cloro</TOKEN>
<TOKEN end_char="6083" id="token-53-37" morph="none" pos="word" start_char="6079">tanto</TOKEN>
<TOKEN end_char="6088" id="token-53-38" morph="none" pos="word" start_char="6085">Oral</TOKEN>
<TOKEN end_char="6093" id="token-53-39" morph="none" pos="word" start_char="6090">como</TOKEN>
<TOKEN end_char="6104" id="token-53-40" morph="none" pos="word" start_char="6095">Parenteral</TOKEN>
<TOKEN end_char="6109" id="token-53-41" morph="none" pos="word" start_char="6106">como</TOKEN>
<TOKEN end_char="6119" id="token-53-42" morph="none" pos="word" start_char="6111">sustancia</TOKEN>
<TOKEN end_char="6126" id="token-53-43" morph="none" pos="word" start_char="6121">eficaz</TOKEN>
<TOKEN end_char="6133" id="token-53-44" morph="none" pos="word" start_char="6128">contra</TOKEN>
<TOKEN end_char="6136" id="token-53-45" morph="none" pos="word" start_char="6135">el</TOKEN>
<TOKEN end_char="6148" id="token-53-46" morph="none" pos="word" start_char="6138">coronavirus</TOKEN>
<TOKEN end_char="6152" id="token-53-47" morph="none" pos="word" start_char="6150">con</TOKEN>
<TOKEN end_char="6156" id="token-53-48" morph="none" pos="word" start_char="6154">una</TOKEN>
<TOKEN end_char="6165" id="token-53-49" morph="none" pos="word" start_char="6158">eficacia</TOKEN>
<TOKEN end_char="6168" id="token-53-50" morph="none" pos="word" start_char="6167">de</TOKEN>
<TOKEN end_char="6171" id="token-53-51" morph="none" pos="word" start_char="6170">un</TOKEN>
<TOKEN end_char="6174" id="token-53-52" morph="none" pos="word" start_char="6173">97</TOKEN>
<TOKEN end_char="6176" id="token-53-53" morph="none" pos="punct" start_char="6175">%.</TOKEN>
<TRANSLATED_TEXT>Here you have the official preliminary clinical trial document in Ecuador of Oral and Intravenous CDS of the medical association of AEMEMI with signed notarial deed and reliable data demonstrating the efficacy of both Oral and Parenteral chlorine dioxide as an effective substance against coronavirus with an effectiveness of 97%.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6331" id="segment-54" start_char="6178">
<ORIGINAL_TEXT>¿Cuánto tardarán los medios convencionales en hablar de esta solución barata, inocua y no patentable a la supuesta pandemia actual, entre otras dolencias?</ORIGINAL_TEXT>
<TOKEN end_char="6178" id="token-54-0" morph="none" pos="punct" start_char="6178">¿</TOKEN>
<TOKEN end_char="6184" id="token-54-1" morph="none" pos="word" start_char="6179">Cuánto</TOKEN>
<TOKEN end_char="6193" id="token-54-2" morph="none" pos="word" start_char="6186">tardarán</TOKEN>
<TOKEN end_char="6197" id="token-54-3" morph="none" pos="word" start_char="6195">los</TOKEN>
<TOKEN end_char="6204" id="token-54-4" morph="none" pos="word" start_char="6199">medios</TOKEN>
<TOKEN end_char="6219" id="token-54-5" morph="none" pos="word" start_char="6206">convencionales</TOKEN>
<TOKEN end_char="6222" id="token-54-6" morph="none" pos="word" start_char="6221">en</TOKEN>
<TOKEN end_char="6229" id="token-54-7" morph="none" pos="word" start_char="6224">hablar</TOKEN>
<TOKEN end_char="6232" id="token-54-8" morph="none" pos="word" start_char="6231">de</TOKEN>
<TOKEN end_char="6237" id="token-54-9" morph="none" pos="word" start_char="6234">esta</TOKEN>
<TOKEN end_char="6246" id="token-54-10" morph="none" pos="word" start_char="6239">solución</TOKEN>
<TOKEN end_char="6253" id="token-54-11" morph="none" pos="word" start_char="6248">barata</TOKEN>
<TOKEN end_char="6254" id="token-54-12" morph="none" pos="punct" start_char="6254">,</TOKEN>
<TOKEN end_char="6261" id="token-54-13" morph="none" pos="word" start_char="6256">inocua</TOKEN>
<TOKEN end_char="6263" id="token-54-14" morph="none" pos="word" start_char="6263">y</TOKEN>
<TOKEN end_char="6266" id="token-54-15" morph="none" pos="word" start_char="6265">no</TOKEN>
<TOKEN end_char="6277" id="token-54-16" morph="none" pos="word" start_char="6268">patentable</TOKEN>
<TOKEN end_char="6279" id="token-54-17" morph="none" pos="word" start_char="6279">a</TOKEN>
<TOKEN end_char="6282" id="token-54-18" morph="none" pos="word" start_char="6281">la</TOKEN>
<TOKEN end_char="6291" id="token-54-19" morph="none" pos="word" start_char="6284">supuesta</TOKEN>
<TOKEN end_char="6300" id="token-54-20" morph="none" pos="word" start_char="6293">pandemia</TOKEN>
<TOKEN end_char="6307" id="token-54-21" morph="none" pos="word" start_char="6302">actual</TOKEN>
<TOKEN end_char="6308" id="token-54-22" morph="none" pos="punct" start_char="6308">,</TOKEN>
<TOKEN end_char="6314" id="token-54-23" morph="none" pos="word" start_char="6310">entre</TOKEN>
<TOKEN end_char="6320" id="token-54-24" morph="none" pos="word" start_char="6316">otras</TOKEN>
<TOKEN end_char="6330" id="token-54-25" morph="none" pos="word" start_char="6322">dolencias</TOKEN>
<TOKEN end_char="6331" id="token-54-26" morph="none" pos="punct" start_char="6331">?</TOKEN>
<TRANSLATED_TEXT>How long will it take the conventional media to talk about this cheap, innocuous and unpatentable solution to the current supposed pandemic, among other ills?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6464" id="segment-55" start_char="6333">
<ORIGINAL_TEXT>El ensayo fue hecho en Guayaquil Ecuador y es de dominio público para ser distribuido libremente mientras no se altere el contenido.</ORIGINAL_TEXT>
<TOKEN end_char="6334" id="token-55-0" morph="none" pos="word" start_char="6333">El</TOKEN>
<TOKEN end_char="6341" id="token-55-1" morph="none" pos="word" start_char="6336">ensayo</TOKEN>
<TOKEN end_char="6345" id="token-55-2" morph="none" pos="word" start_char="6343">fue</TOKEN>
<TOKEN end_char="6351" id="token-55-3" morph="none" pos="word" start_char="6347">hecho</TOKEN>
<TOKEN end_char="6354" id="token-55-4" morph="none" pos="word" start_char="6353">en</TOKEN>
<TOKEN end_char="6364" id="token-55-5" morph="none" pos="word" start_char="6356">Guayaquil</TOKEN>
<TOKEN end_char="6372" id="token-55-6" morph="none" pos="word" start_char="6366">Ecuador</TOKEN>
<TOKEN end_char="6374" id="token-55-7" morph="none" pos="word" start_char="6374">y</TOKEN>
<TOKEN end_char="6377" id="token-55-8" morph="none" pos="word" start_char="6376">es</TOKEN>
<TOKEN end_char="6380" id="token-55-9" morph="none" pos="word" start_char="6379">de</TOKEN>
<TOKEN end_char="6388" id="token-55-10" morph="none" pos="word" start_char="6382">dominio</TOKEN>
<TOKEN end_char="6396" id="token-55-11" morph="none" pos="word" start_char="6390">público</TOKEN>
<TOKEN end_char="6401" id="token-55-12" morph="none" pos="word" start_char="6398">para</TOKEN>
<TOKEN end_char="6405" id="token-55-13" morph="none" pos="word" start_char="6403">ser</TOKEN>
<TOKEN end_char="6417" id="token-55-14" morph="none" pos="word" start_char="6407">distribuido</TOKEN>
<TOKEN end_char="6428" id="token-55-15" morph="none" pos="word" start_char="6419">libremente</TOKEN>
<TOKEN end_char="6437" id="token-55-16" morph="none" pos="word" start_char="6430">mientras</TOKEN>
<TOKEN end_char="6440" id="token-55-17" morph="none" pos="word" start_char="6439">no</TOKEN>
<TOKEN end_char="6443" id="token-55-18" morph="none" pos="word" start_char="6442">se</TOKEN>
<TOKEN end_char="6450" id="token-55-19" morph="none" pos="word" start_char="6445">altere</TOKEN>
<TOKEN end_char="6453" id="token-55-20" morph="none" pos="word" start_char="6452">el</TOKEN>
<TOKEN end_char="6463" id="token-55-21" morph="none" pos="word" start_char="6455">contenido</TOKEN>
<TOKEN end_char="6464" id="token-55-22" morph="none" pos="punct" start_char="6464">.</TOKEN>
<TRANSLATED_TEXT>The essay was made in Guayaquil Ecuador and is in the public domain to be distributed freely as long as the content is not altered.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6638" id="segment-56" start_char="6466">
<ORIGINAL_TEXT>Se facilita en el siguiente enlace: https://cdn.lbryplayer.xyz/content/...af59ac186a8c3645280de725dc5/stream?download=1 Hablamos de un estudio elaborado y firmado 7 médicos.</ORIGINAL_TEXT>
<TOKEN end_char="6467" id="token-56-0" morph="none" pos="word" start_char="6466">Se</TOKEN>
<TOKEN end_char="6476" id="token-56-1" morph="none" pos="word" start_char="6469">facilita</TOKEN>
<TOKEN end_char="6479" id="token-56-2" morph="none" pos="word" start_char="6478">en</TOKEN>
<TOKEN end_char="6482" id="token-56-3" morph="none" pos="word" start_char="6481">el</TOKEN>
<TOKEN end_char="6492" id="token-56-4" morph="none" pos="word" start_char="6484">siguiente</TOKEN>
<TOKEN end_char="6499" id="token-56-5" morph="none" pos="word" start_char="6494">enlace</TOKEN>
<TOKEN end_char="6500" id="token-56-6" morph="none" pos="punct" start_char="6500">:</TOKEN>
<TOKEN end_char="6584" id="token-56-7" morph="none" pos="url" start_char="6502">https://cdn.lbryplayer.xyz/content/...af59ac186a8c3645280de725dc5/stream?download=1</TOKEN>
<TOKEN end_char="6593" id="token-56-8" morph="none" pos="word" start_char="6586">Hablamos</TOKEN>
<TOKEN end_char="6596" id="token-56-9" morph="none" pos="word" start_char="6595">de</TOKEN>
<TOKEN end_char="6599" id="token-56-10" morph="none" pos="word" start_char="6598">un</TOKEN>
<TOKEN end_char="6607" id="token-56-11" morph="none" pos="word" start_char="6601">estudio</TOKEN>
<TOKEN end_char="6617" id="token-56-12" morph="none" pos="word" start_char="6609">elaborado</TOKEN>
<TOKEN end_char="6619" id="token-56-13" morph="none" pos="word" start_char="6619">y</TOKEN>
<TOKEN end_char="6627" id="token-56-14" morph="none" pos="word" start_char="6621">firmado</TOKEN>
<TOKEN end_char="6629" id="token-56-15" morph="none" pos="word" start_char="6629">7</TOKEN>
<TOKEN end_char="6637" id="token-56-16" morph="none" pos="word" start_char="6631">médicos</TOKEN>
<TOKEN end_char="6638" id="token-56-17" morph="none" pos="punct" start_char="6638">.</TOKEN>
<TRANSLATED_TEXT>It is available on the following link: https: / / cdn.lblyplayer.xyz / content /... af59ac186a8c3645280de7.25dc5 / stream? download = 1 We are talking about an elaborate and signed study 7 doctors.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6701" id="segment-57" start_char="6640">
<ORIGINAL_TEXT>Por favor tenganlo en cuenta antes de directamente censurarlo.</ORIGINAL_TEXT>
<TOKEN end_char="6642" id="token-57-0" morph="none" pos="word" start_char="6640">Por</TOKEN>
<TOKEN end_char="6648" id="token-57-1" morph="none" pos="word" start_char="6644">favor</TOKEN>
<TOKEN end_char="6657" id="token-57-2" morph="none" pos="word" start_char="6650">tenganlo</TOKEN>
<TOKEN end_char="6660" id="token-57-3" morph="none" pos="word" start_char="6659">en</TOKEN>
<TOKEN end_char="6667" id="token-57-4" morph="none" pos="word" start_char="6662">cuenta</TOKEN>
<TOKEN end_char="6673" id="token-57-5" morph="none" pos="word" start_char="6669">antes</TOKEN>
<TOKEN end_char="6676" id="token-57-6" morph="none" pos="word" start_char="6675">de</TOKEN>
<TOKEN end_char="6689" id="token-57-7" morph="none" pos="word" start_char="6678">directamente</TOKEN>
<TOKEN end_char="6700" id="token-57-8" morph="none" pos="word" start_char="6691">censurarlo</TOKEN>
<TOKEN end_char="6701" id="token-57-9" morph="none" pos="punct" start_char="6701">.</TOKEN>
<TRANSLATED_TEXT>Please take it into account before you directly censor it.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6972" id="segment-58" start_char="6703">
<ORIGINAL_TEXT>Ver archivo adjunto 321837 Ver archivo adjunto 321838 Ver archivo adjunto 321839 Ver archivo adjunto 321841 Ver archivo adjunto 321842 Ver archivo adjunto 321843 Ver archivo adjunto 321845 Ver archivo adjunto 321846 Ver archivo adjunto 321848 Hacer clic para expandir...</ORIGINAL_TEXT>
<TOKEN end_char="6705" id="token-58-0" morph="none" pos="word" start_char="6703">Ver</TOKEN>
<TOKEN end_char="6713" id="token-58-1" morph="none" pos="word" start_char="6707">archivo</TOKEN>
<TOKEN end_char="6721" id="token-58-2" morph="none" pos="word" start_char="6715">adjunto</TOKEN>
<TOKEN end_char="6728" id="token-58-3" morph="none" pos="word" start_char="6723">321837</TOKEN>
<TOKEN end_char="6732" id="token-58-4" morph="none" pos="word" start_char="6730">Ver</TOKEN>
<TOKEN end_char="6740" id="token-58-5" morph="none" pos="word" start_char="6734">archivo</TOKEN>
<TOKEN end_char="6748" id="token-58-6" morph="none" pos="word" start_char="6742">adjunto</TOKEN>
<TOKEN end_char="6755" id="token-58-7" morph="none" pos="word" start_char="6750">321838</TOKEN>
<TOKEN end_char="6759" id="token-58-8" morph="none" pos="word" start_char="6757">Ver</TOKEN>
<TOKEN end_char="6767" id="token-58-9" morph="none" pos="word" start_char="6761">archivo</TOKEN>
<TOKEN end_char="6775" id="token-58-10" morph="none" pos="word" start_char="6769">adjunto</TOKEN>
<TOKEN end_char="6782" id="token-58-11" morph="none" pos="word" start_char="6777">321839</TOKEN>
<TOKEN end_char="6786" id="token-58-12" morph="none" pos="word" start_char="6784">Ver</TOKEN>
<TOKEN end_char="6794" id="token-58-13" morph="none" pos="word" start_char="6788">archivo</TOKEN>
<TOKEN end_char="6802" id="token-58-14" morph="none" pos="word" start_char="6796">adjunto</TOKEN>
<TOKEN end_char="6809" id="token-58-15" morph="none" pos="word" start_char="6804">321841</TOKEN>
<TOKEN end_char="6813" id="token-58-16" morph="none" pos="word" start_char="6811">Ver</TOKEN>
<TOKEN end_char="6821" id="token-58-17" morph="none" pos="word" start_char="6815">archivo</TOKEN>
<TOKEN end_char="6829" id="token-58-18" morph="none" pos="word" start_char="6823">adjunto</TOKEN>
<TOKEN end_char="6836" id="token-58-19" morph="none" pos="word" start_char="6831">321842</TOKEN>
<TOKEN end_char="6840" id="token-58-20" morph="none" pos="word" start_char="6838">Ver</TOKEN>
<TOKEN end_char="6848" id="token-58-21" morph="none" pos="word" start_char="6842">archivo</TOKEN>
<TOKEN end_char="6856" id="token-58-22" morph="none" pos="word" start_char="6850">adjunto</TOKEN>
<TOKEN end_char="6863" id="token-58-23" morph="none" pos="word" start_char="6858">321843</TOKEN>
<TOKEN end_char="6867" id="token-58-24" morph="none" pos="word" start_char="6865">Ver</TOKEN>
<TOKEN end_char="6875" id="token-58-25" morph="none" pos="word" start_char="6869">archivo</TOKEN>
<TOKEN end_char="6883" id="token-58-26" morph="none" pos="word" start_char="6877">adjunto</TOKEN>
<TOKEN end_char="6890" id="token-58-27" morph="none" pos="word" start_char="6885">321845</TOKEN>
<TOKEN end_char="6894" id="token-58-28" morph="none" pos="word" start_char="6892">Ver</TOKEN>
<TOKEN end_char="6902" id="token-58-29" morph="none" pos="word" start_char="6896">archivo</TOKEN>
<TOKEN end_char="6910" id="token-58-30" morph="none" pos="word" start_char="6904">adjunto</TOKEN>
<TOKEN end_char="6917" id="token-58-31" morph="none" pos="word" start_char="6912">321846</TOKEN>
<TOKEN end_char="6921" id="token-58-32" morph="none" pos="word" start_char="6919">Ver</TOKEN>
<TOKEN end_char="6929" id="token-58-33" morph="none" pos="word" start_char="6923">archivo</TOKEN>
<TOKEN end_char="6937" id="token-58-34" morph="none" pos="word" start_char="6931">adjunto</TOKEN>
<TOKEN end_char="6944" id="token-58-35" morph="none" pos="word" start_char="6939">321848</TOKEN>
<TOKEN end_char="6950" id="token-58-36" morph="none" pos="word" start_char="6946">Hacer</TOKEN>
<TOKEN end_char="6955" id="token-58-37" morph="none" pos="word" start_char="6952">clic</TOKEN>
<TOKEN end_char="6960" id="token-58-38" morph="none" pos="word" start_char="6957">para</TOKEN>
<TOKEN end_char="6969" id="token-58-39" morph="none" pos="word" start_char="6962">expandir</TOKEN>
<TOKEN end_char="6972" id="token-58-40" morph="none" pos="punct" start_char="6970">...</TOKEN>
<TRANSLATED_TEXT>See attachment 321837 See attachment 321838 See attachment 321839 See attachment 321841 See attachment 321842 See attachment 321843 See attachment 321845 See attachment 321846 See attachment 321848 Click to expand...</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6998" id="segment-59" start_char="6975">
<ORIGINAL_TEXT>Todo un éxito sin dudas.</ORIGINAL_TEXT>
<TOKEN end_char="6978" id="token-59-0" morph="none" pos="word" start_char="6975">Todo</TOKEN>
<TOKEN end_char="6981" id="token-59-1" morph="none" pos="word" start_char="6980">un</TOKEN>
<TOKEN end_char="6987" id="token-59-2" morph="none" pos="word" start_char="6983">éxito</TOKEN>
<TOKEN end_char="6991" id="token-59-3" morph="none" pos="word" start_char="6989">sin</TOKEN>
<TOKEN end_char="6997" id="token-59-4" morph="none" pos="word" start_char="6993">dudas</TOKEN>
<TOKEN end_char="6998" id="token-59-5" morph="none" pos="punct" start_char="6998">.</TOKEN>
<TRANSLATED_TEXT>A complete success.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7128" id="segment-60" start_char="7000">
<ORIGINAL_TEXT>Una muestra de 104 pacientes con alteraciones de la formula leucocitaria y ferritina, vamos lo que se ve en el supuesto Covid 19.</ORIGINAL_TEXT>
<TOKEN end_char="7002" id="token-60-0" morph="none" pos="word" start_char="7000">Una</TOKEN>
<TOKEN end_char="7010" id="token-60-1" morph="none" pos="word" start_char="7004">muestra</TOKEN>
<TOKEN end_char="7013" id="token-60-2" morph="none" pos="word" start_char="7012">de</TOKEN>
<TOKEN end_char="7017" id="token-60-3" morph="none" pos="word" start_char="7015">104</TOKEN>
<TOKEN end_char="7027" id="token-60-4" morph="none" pos="word" start_char="7019">pacientes</TOKEN>
<TOKEN end_char="7031" id="token-60-5" morph="none" pos="word" start_char="7029">con</TOKEN>
<TOKEN end_char="7044" id="token-60-6" morph="none" pos="word" start_char="7033">alteraciones</TOKEN>
<TOKEN end_char="7047" id="token-60-7" morph="none" pos="word" start_char="7046">de</TOKEN>
<TOKEN end_char="7050" id="token-60-8" morph="none" pos="word" start_char="7049">la</TOKEN>
<TOKEN end_char="7058" id="token-60-9" morph="none" pos="word" start_char="7052">formula</TOKEN>
<TOKEN end_char="7071" id="token-60-10" morph="none" pos="word" start_char="7060">leucocitaria</TOKEN>
<TOKEN end_char="7073" id="token-60-11" morph="none" pos="word" start_char="7073">y</TOKEN>
<TOKEN end_char="7083" id="token-60-12" morph="none" pos="word" start_char="7075">ferritina</TOKEN>
<TOKEN end_char="7084" id="token-60-13" morph="none" pos="punct" start_char="7084">,</TOKEN>
<TOKEN end_char="7090" id="token-60-14" morph="none" pos="word" start_char="7086">vamos</TOKEN>
<TOKEN end_char="7093" id="token-60-15" morph="none" pos="word" start_char="7092">lo</TOKEN>
<TOKEN end_char="7097" id="token-60-16" morph="none" pos="word" start_char="7095">que</TOKEN>
<TOKEN end_char="7100" id="token-60-17" morph="none" pos="word" start_char="7099">se</TOKEN>
<TOKEN end_char="7103" id="token-60-18" morph="none" pos="word" start_char="7102">ve</TOKEN>
<TOKEN end_char="7106" id="token-60-19" morph="none" pos="word" start_char="7105">en</TOKEN>
<TOKEN end_char="7109" id="token-60-20" morph="none" pos="word" start_char="7108">el</TOKEN>
<TOKEN end_char="7118" id="token-60-21" morph="none" pos="word" start_char="7111">supuesto</TOKEN>
<TOKEN end_char="7124" id="token-60-22" morph="none" pos="word" start_char="7120">Covid</TOKEN>
<TOKEN end_char="7127" id="token-60-23" morph="none" pos="word" start_char="7126">19</TOKEN>
<TOKEN end_char="7128" id="token-60-24" morph="none" pos="punct" start_char="7128">.</TOKEN>
<TRANSLATED_TEXT>A sample of 104 patients with alterations of the leukocyte and ferritin formula, let's go what we see in the assumed Covid 19.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7179" id="segment-61" start_char="7131">
<ORIGINAL_TEXT>A los 4 días remisión de síntomas, ni una muerte.</ORIGINAL_TEXT>
<TOKEN end_char="7131" id="token-61-0" morph="none" pos="word" start_char="7131">A</TOKEN>
<TOKEN end_char="7135" id="token-61-1" morph="none" pos="word" start_char="7133">los</TOKEN>
<TOKEN end_char="7137" id="token-61-2" morph="none" pos="word" start_char="7137">4</TOKEN>
<TOKEN end_char="7142" id="token-61-3" morph="none" pos="word" start_char="7139">días</TOKEN>
<TOKEN end_char="7151" id="token-61-4" morph="none" pos="word" start_char="7144">remisión</TOKEN>
<TOKEN end_char="7154" id="token-61-5" morph="none" pos="word" start_char="7153">de</TOKEN>
<TOKEN end_char="7163" id="token-61-6" morph="none" pos="word" start_char="7156">síntomas</TOKEN>
<TOKEN end_char="7164" id="token-61-7" morph="none" pos="punct" start_char="7164">,</TOKEN>
<TOKEN end_char="7167" id="token-61-8" morph="none" pos="word" start_char="7166">ni</TOKEN>
<TOKEN end_char="7171" id="token-61-9" morph="none" pos="word" start_char="7169">una</TOKEN>
<TOKEN end_char="7178" id="token-61-10" morph="none" pos="word" start_char="7173">muerte</TOKEN>
<TOKEN end_char="7179" id="token-61-11" morph="none" pos="punct" start_char="7179">.</TOKEN>
<TRANSLATED_TEXT>At 4 days remission of symptoms, not one death.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7238" id="segment-62" start_char="7181">
<ORIGINAL_TEXT>La toxicidad queda clara que no tiene discusión, no tiene.</ORIGINAL_TEXT>
<TOKEN end_char="7182" id="token-62-0" morph="none" pos="word" start_char="7181">La</TOKEN>
<TOKEN end_char="7192" id="token-62-1" morph="none" pos="word" start_char="7184">toxicidad</TOKEN>
<TOKEN end_char="7198" id="token-62-2" morph="none" pos="word" start_char="7194">queda</TOKEN>
<TOKEN end_char="7204" id="token-62-3" morph="none" pos="word" start_char="7200">clara</TOKEN>
<TOKEN end_char="7208" id="token-62-4" morph="none" pos="word" start_char="7206">que</TOKEN>
<TOKEN end_char="7211" id="token-62-5" morph="none" pos="word" start_char="7210">no</TOKEN>
<TOKEN end_char="7217" id="token-62-6" morph="none" pos="word" start_char="7213">tiene</TOKEN>
<TOKEN end_char="7227" id="token-62-7" morph="none" pos="word" start_char="7219">discusión</TOKEN>
<TOKEN end_char="7228" id="token-62-8" morph="none" pos="punct" start_char="7228">,</TOKEN>
<TOKEN end_char="7231" id="token-62-9" morph="none" pos="word" start_char="7230">no</TOKEN>
<TOKEN end_char="7237" id="token-62-10" morph="none" pos="word" start_char="7233">tiene</TOKEN>
<TOKEN end_char="7238" id="token-62-11" morph="none" pos="punct" start_char="7238">.</TOKEN>
<TRANSLATED_TEXT>Toxicity is clear that there is no argument, no argument.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7290" id="segment-63" start_char="7241">
<ORIGINAL_TEXT>Muy buenas noticias con este estudio sin dudas.!!!</ORIGINAL_TEXT>
<TOKEN end_char="7243" id="token-63-0" morph="none" pos="word" start_char="7241">Muy</TOKEN>
<TOKEN end_char="7250" id="token-63-1" morph="none" pos="word" start_char="7245">buenas</TOKEN>
<TOKEN end_char="7259" id="token-63-2" morph="none" pos="word" start_char="7252">noticias</TOKEN>
<TOKEN end_char="7263" id="token-63-3" morph="none" pos="word" start_char="7261">con</TOKEN>
<TOKEN end_char="7268" id="token-63-4" morph="none" pos="word" start_char="7265">este</TOKEN>
<TOKEN end_char="7276" id="token-63-5" morph="none" pos="word" start_char="7270">estudio</TOKEN>
<TOKEN end_char="7280" id="token-63-6" morph="none" pos="word" start_char="7278">sin</TOKEN>
<TOKEN end_char="7286" id="token-63-7" morph="none" pos="word" start_char="7282">dudas</TOKEN>
<TOKEN end_char="7290" id="token-63-8" morph="none" pos="punct" start_char="7287">.!!!</TOKEN>
<TRANSLATED_TEXT>Very good news with this studio without a doubt!!!</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7325" id="segment-64" start_char="7293">
<ORIGINAL_TEXT>Felicidades a los investigadores.</ORIGINAL_TEXT>
<TOKEN end_char="7303" id="token-64-0" morph="none" pos="word" start_char="7293">Felicidades</TOKEN>
<TOKEN end_char="7305" id="token-64-1" morph="none" pos="word" start_char="7305">a</TOKEN>
<TOKEN end_char="7309" id="token-64-2" morph="none" pos="word" start_char="7307">los</TOKEN>
<TOKEN end_char="7324" id="token-64-3" morph="none" pos="word" start_char="7311">investigadores</TOKEN>
<TOKEN end_char="7325" id="token-64-4" morph="none" pos="punct" start_char="7325">.</TOKEN>
<TRANSLATED_TEXT>Congratulations to the researchers.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7409" id="segment-65" start_char="7330">
<ORIGINAL_TEXT>Esta claro que a la farmaindustria no le interesa curar si no que hacer negocio.</ORIGINAL_TEXT>
<TOKEN end_char="7333" id="token-65-0" morph="none" pos="word" start_char="7330">Esta</TOKEN>
<TOKEN end_char="7339" id="token-65-1" morph="none" pos="word" start_char="7335">claro</TOKEN>
<TOKEN end_char="7343" id="token-65-2" morph="none" pos="word" start_char="7341">que</TOKEN>
<TOKEN end_char="7345" id="token-65-3" morph="none" pos="word" start_char="7345">a</TOKEN>
<TOKEN end_char="7348" id="token-65-4" morph="none" pos="word" start_char="7347">la</TOKEN>
<TOKEN end_char="7363" id="token-65-5" morph="none" pos="word" start_char="7350">farmaindustria</TOKEN>
<TOKEN end_char="7366" id="token-65-6" morph="none" pos="word" start_char="7365">no</TOKEN>
<TOKEN end_char="7369" id="token-65-7" morph="none" pos="word" start_char="7368">le</TOKEN>
<TOKEN end_char="7378" id="token-65-8" morph="none" pos="word" start_char="7371">interesa</TOKEN>
<TOKEN end_char="7384" id="token-65-9" morph="none" pos="word" start_char="7380">curar</TOKEN>
<TOKEN end_char="7387" id="token-65-10" morph="none" pos="word" start_char="7386">si</TOKEN>
<TOKEN end_char="7390" id="token-65-11" morph="none" pos="word" start_char="7389">no</TOKEN>
<TOKEN end_char="7394" id="token-65-12" morph="none" pos="word" start_char="7392">que</TOKEN>
<TOKEN end_char="7400" id="token-65-13" morph="none" pos="word" start_char="7396">hacer</TOKEN>
<TOKEN end_char="7408" id="token-65-14" morph="none" pos="word" start_char="7402">negocio</TOKEN>
<TOKEN end_char="7409" id="token-65-15" morph="none" pos="punct" start_char="7409">.</TOKEN>
<TRANSLATED_TEXT>It is clear that the pharmaceutical industry is not interested in curing or doing business.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7482" id="segment-66" start_char="7411">
<ORIGINAL_TEXT>De ahí vienen todos los ataques a esta solución buena barata y efectiva.</ORIGINAL_TEXT>
<TOKEN end_char="7412" id="token-66-0" morph="none" pos="word" start_char="7411">De</TOKEN>
<TOKEN end_char="7416" id="token-66-1" morph="none" pos="word" start_char="7414">ahí</TOKEN>
<TOKEN end_char="7423" id="token-66-2" morph="none" pos="word" start_char="7418">vienen</TOKEN>
<TOKEN end_char="7429" id="token-66-3" morph="none" pos="word" start_char="7425">todos</TOKEN>
<TOKEN end_char="7433" id="token-66-4" morph="none" pos="word" start_char="7431">los</TOKEN>
<TOKEN end_char="7441" id="token-66-5" morph="none" pos="word" start_char="7435">ataques</TOKEN>
<TOKEN end_char="7443" id="token-66-6" morph="none" pos="word" start_char="7443">a</TOKEN>
<TOKEN end_char="7448" id="token-66-7" morph="none" pos="word" start_char="7445">esta</TOKEN>
<TOKEN end_char="7457" id="token-66-8" morph="none" pos="word" start_char="7450">solución</TOKEN>
<TOKEN end_char="7463" id="token-66-9" morph="none" pos="word" start_char="7459">buena</TOKEN>
<TOKEN end_char="7470" id="token-66-10" morph="none" pos="word" start_char="7465">barata</TOKEN>
<TOKEN end_char="7472" id="token-66-11" morph="none" pos="word" start_char="7472">y</TOKEN>
<TOKEN end_char="7481" id="token-66-12" morph="none" pos="word" start_char="7474">efectiva</TOKEN>
<TOKEN end_char="7482" id="token-66-13" morph="none" pos="punct" start_char="7482">.</TOKEN>
<TRANSLATED_TEXT>Hence all attacks on this good, cheap and effective solution.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7525" id="segment-67" start_char="7486">
<ORIGINAL_TEXT>Gracias por esta noticia, importantísima</ORIGINAL_TEXT>
<TOKEN end_char="7492" id="token-67-0" morph="none" pos="word" start_char="7486">Gracias</TOKEN>
<TOKEN end_char="7496" id="token-67-1" morph="none" pos="word" start_char="7494">por</TOKEN>
<TOKEN end_char="7501" id="token-67-2" morph="none" pos="word" start_char="7498">esta</TOKEN>
<TOKEN end_char="7509" id="token-67-3" morph="none" pos="word" start_char="7503">noticia</TOKEN>
<TOKEN end_char="7510" id="token-67-4" morph="none" pos="punct" start_char="7510">,</TOKEN>
<TOKEN end_char="7525" id="token-67-5" morph="none" pos="word" start_char="7512">importantísima</TOKEN>
<TRANSLATED_TEXT>Thank you for this very important news.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
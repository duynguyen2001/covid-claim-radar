<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CA23" lang="spa" raw_text_char_length="2334" raw_text_md5="28c616f55dd6b096c08a865763d76748" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="76" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Chinese researchers now claim coronavirus originated in India in summer 2019</ORIGINAL_TEXT>
<TOKEN end_char="7" id="token-0-0" morph="none" pos="word" start_char="1">Chinese</TOKEN>
<TOKEN end_char="19" id="token-0-1" morph="none" pos="word" start_char="9">researchers</TOKEN>
<TOKEN end_char="23" id="token-0-2" morph="none" pos="word" start_char="21">now</TOKEN>
<TOKEN end_char="29" id="token-0-3" morph="none" pos="word" start_char="25">claim</TOKEN>
<TOKEN end_char="41" id="token-0-4" morph="none" pos="word" start_char="31">coronavirus</TOKEN>
<TOKEN end_char="52" id="token-0-5" morph="none" pos="word" start_char="43">originated</TOKEN>
<TOKEN end_char="55" id="token-0-6" morph="none" pos="word" start_char="54">in</TOKEN>
<TOKEN end_char="61" id="token-0-7" morph="none" pos="word" start_char="57">India</TOKEN>
<TOKEN end_char="64" id="token-0-8" morph="none" pos="word" start_char="63">in</TOKEN>
<TOKEN end_char="71" id="token-0-9" morph="none" pos="word" start_char="66">summer</TOKEN>
<TOKEN end_char="76" id="token-0-10" morph="none" pos="word" start_char="73">2019</TOKEN>
</SEG>
<SEG end_char="99" id="segment-1" start_char="80">
<ORIGINAL_TEXT>Representative image</ORIGINAL_TEXT>
<TOKEN end_char="93" id="token-1-0" morph="none" pos="word" start_char="80">Representative</TOKEN>
<TOKEN end_char="99" id="token-1-1" morph="none" pos="word" start_char="95">image</TOKEN>
<TRANSLATED_TEXT>Representante imagen</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="122" id="segment-2" start_char="103">
<ORIGINAL_TEXT>Representative image</ORIGINAL_TEXT>
<TOKEN end_char="116" id="token-2-0" morph="none" pos="word" start_char="103">Representative</TOKEN>
<TOKEN end_char="122" id="token-2-1" morph="none" pos="word" start_char="118">image</TOKEN>
<TRANSLATED_TEXT>Representante imagen</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="270" id="segment-3" start_char="126">
<ORIGINAL_TEXT>Battling global adversity over COVID-19, Chinese scientists are now arguing that the novel coronavirus originated in India in the summer of 2019.</ORIGINAL_TEXT>
<TOKEN end_char="133" id="token-3-0" morph="none" pos="word" start_char="126">Battling</TOKEN>
<TOKEN end_char="140" id="token-3-1" morph="none" pos="word" start_char="135">global</TOKEN>
<TOKEN end_char="150" id="token-3-2" morph="none" pos="word" start_char="142">adversity</TOKEN>
<TOKEN end_char="155" id="token-3-3" morph="none" pos="word" start_char="152">over</TOKEN>
<TOKEN end_char="164" id="token-3-4" morph="none" pos="unknown" start_char="157">COVID-19</TOKEN>
<TOKEN end_char="165" id="token-3-5" morph="none" pos="punct" start_char="165">,</TOKEN>
<TOKEN end_char="173" id="token-3-6" morph="none" pos="word" start_char="167">Chinese</TOKEN>
<TOKEN end_char="184" id="token-3-7" morph="none" pos="word" start_char="175">scientists</TOKEN>
<TOKEN end_char="188" id="token-3-8" morph="none" pos="word" start_char="186">are</TOKEN>
<TOKEN end_char="192" id="token-3-9" morph="none" pos="word" start_char="190">now</TOKEN>
<TOKEN end_char="200" id="token-3-10" morph="none" pos="word" start_char="194">arguing</TOKEN>
<TOKEN end_char="205" id="token-3-11" morph="none" pos="word" start_char="202">that</TOKEN>
<TOKEN end_char="209" id="token-3-12" morph="none" pos="word" start_char="207">the</TOKEN>
<TOKEN end_char="215" id="token-3-13" morph="none" pos="word" start_char="211">novel</TOKEN>
<TOKEN end_char="227" id="token-3-14" morph="none" pos="word" start_char="217">coronavirus</TOKEN>
<TOKEN end_char="238" id="token-3-15" morph="none" pos="word" start_char="229">originated</TOKEN>
<TOKEN end_char="241" id="token-3-16" morph="none" pos="word" start_char="240">in</TOKEN>
<TOKEN end_char="247" id="token-3-17" morph="none" pos="word" start_char="243">India</TOKEN>
<TOKEN end_char="250" id="token-3-18" morph="none" pos="word" start_char="249">in</TOKEN>
<TOKEN end_char="254" id="token-3-19" morph="none" pos="word" start_char="252">the</TOKEN>
<TOKEN end_char="261" id="token-3-20" morph="none" pos="word" start_char="256">summer</TOKEN>
<TOKEN end_char="264" id="token-3-21" morph="none" pos="word" start_char="263">of</TOKEN>
<TOKEN end_char="269" id="token-3-22" morph="none" pos="word" start_char="266">2019</TOKEN>
<TOKEN end_char="270" id="token-3-23" morph="none" pos="punct" start_char="270">.</TOKEN>
</SEG>
<SEG end_char="518" id="segment-4" start_char="273">
<ORIGINAL_TEXT>A team of researchers from the Chinese Academy of Sciences claimed that the deadly virus emerged by transferring from animals to humans via contaminated water before travelling unnoticed to Wuhan, where it was first detected, reported Daily mail.</ORIGINAL_TEXT>
<TOKEN end_char="273" id="token-4-0" morph="none" pos="word" start_char="273">A</TOKEN>
<TOKEN end_char="278" id="token-4-1" morph="none" pos="word" start_char="275">team</TOKEN>
<TOKEN end_char="281" id="token-4-2" morph="none" pos="word" start_char="280">of</TOKEN>
<TOKEN end_char="293" id="token-4-3" morph="none" pos="word" start_char="283">researchers</TOKEN>
<TOKEN end_char="298" id="token-4-4" morph="none" pos="word" start_char="295">from</TOKEN>
<TOKEN end_char="302" id="token-4-5" morph="none" pos="word" start_char="300">the</TOKEN>
<TOKEN end_char="310" id="token-4-6" morph="none" pos="word" start_char="304">Chinese</TOKEN>
<TOKEN end_char="318" id="token-4-7" morph="none" pos="word" start_char="312">Academy</TOKEN>
<TOKEN end_char="321" id="token-4-8" morph="none" pos="word" start_char="320">of</TOKEN>
<TOKEN end_char="330" id="token-4-9" morph="none" pos="word" start_char="323">Sciences</TOKEN>
<TOKEN end_char="338" id="token-4-10" morph="none" pos="word" start_char="332">claimed</TOKEN>
<TOKEN end_char="343" id="token-4-11" morph="none" pos="word" start_char="340">that</TOKEN>
<TOKEN end_char="347" id="token-4-12" morph="none" pos="word" start_char="345">the</TOKEN>
<TOKEN end_char="354" id="token-4-13" morph="none" pos="word" start_char="349">deadly</TOKEN>
<TOKEN end_char="360" id="token-4-14" morph="none" pos="word" start_char="356">virus</TOKEN>
<TOKEN end_char="368" id="token-4-15" morph="none" pos="word" start_char="362">emerged</TOKEN>
<TOKEN end_char="371" id="token-4-16" morph="none" pos="word" start_char="370">by</TOKEN>
<TOKEN end_char="384" id="token-4-17" morph="none" pos="word" start_char="373">transferring</TOKEN>
<TOKEN end_char="389" id="token-4-18" morph="none" pos="word" start_char="386">from</TOKEN>
<TOKEN end_char="397" id="token-4-19" morph="none" pos="word" start_char="391">animals</TOKEN>
<TOKEN end_char="400" id="token-4-20" morph="none" pos="word" start_char="399">to</TOKEN>
<TOKEN end_char="407" id="token-4-21" morph="none" pos="word" start_char="402">humans</TOKEN>
<TOKEN end_char="411" id="token-4-22" morph="none" pos="word" start_char="409">via</TOKEN>
<TOKEN end_char="424" id="token-4-23" morph="none" pos="word" start_char="413">contaminated</TOKEN>
<TOKEN end_char="430" id="token-4-24" morph="none" pos="word" start_char="426">water</TOKEN>
<TOKEN end_char="437" id="token-4-25" morph="none" pos="word" start_char="432">before</TOKEN>
<TOKEN end_char="448" id="token-4-26" morph="none" pos="word" start_char="439">travelling</TOKEN>
<TOKEN end_char="458" id="token-4-27" morph="none" pos="word" start_char="450">unnoticed</TOKEN>
<TOKEN end_char="461" id="token-4-28" morph="none" pos="word" start_char="460">to</TOKEN>
<TOKEN end_char="467" id="token-4-29" morph="none" pos="word" start_char="463">Wuhan</TOKEN>
<TOKEN end_char="468" id="token-4-30" morph="none" pos="punct" start_char="468">,</TOKEN>
<TOKEN end_char="474" id="token-4-31" morph="none" pos="word" start_char="470">where</TOKEN>
<TOKEN end_char="477" id="token-4-32" morph="none" pos="word" start_char="476">it</TOKEN>
<TOKEN end_char="481" id="token-4-33" morph="none" pos="word" start_char="479">was</TOKEN>
<TOKEN end_char="487" id="token-4-34" morph="none" pos="word" start_char="483">first</TOKEN>
<TOKEN end_char="496" id="token-4-35" morph="none" pos="word" start_char="489">detected</TOKEN>
<TOKEN end_char="497" id="token-4-36" morph="none" pos="punct" start_char="497">,</TOKEN>
<TOKEN end_char="506" id="token-4-37" morph="none" pos="word" start_char="499">reported</TOKEN>
<TOKEN end_char="512" id="token-4-38" morph="none" pos="word" start_char="508">Daily</TOKEN>
<TOKEN end_char="517" id="token-4-39" morph="none" pos="word" start_char="514">mail</TOKEN>
<TOKEN end_char="518" id="token-4-40" morph="none" pos="punct" start_char="518">.</TOKEN>
</SEG>
<SEG end_char="613" id="segment-5" start_char="521">
<ORIGINAL_TEXT>It is not the first time that Chinese authorities have pointed the finger of blame elsewhere.</ORIGINAL_TEXT>
<TOKEN end_char="522" id="token-5-0" morph="none" pos="word" start_char="521">It</TOKEN>
<TOKEN end_char="525" id="token-5-1" morph="none" pos="word" start_char="524">is</TOKEN>
<TOKEN end_char="529" id="token-5-2" morph="none" pos="word" start_char="527">not</TOKEN>
<TOKEN end_char="533" id="token-5-3" morph="none" pos="word" start_char="531">the</TOKEN>
<TOKEN end_char="539" id="token-5-4" morph="none" pos="word" start_char="535">first</TOKEN>
<TOKEN end_char="544" id="token-5-5" morph="none" pos="word" start_char="541">time</TOKEN>
<TOKEN end_char="549" id="token-5-6" morph="none" pos="word" start_char="546">that</TOKEN>
<TOKEN end_char="557" id="token-5-7" morph="none" pos="word" start_char="551">Chinese</TOKEN>
<TOKEN end_char="569" id="token-5-8" morph="none" pos="word" start_char="559">authorities</TOKEN>
<TOKEN end_char="574" id="token-5-9" morph="none" pos="word" start_char="571">have</TOKEN>
<TOKEN end_char="582" id="token-5-10" morph="none" pos="word" start_char="576">pointed</TOKEN>
<TOKEN end_char="586" id="token-5-11" morph="none" pos="word" start_char="584">the</TOKEN>
<TOKEN end_char="593" id="token-5-12" morph="none" pos="word" start_char="588">finger</TOKEN>
<TOKEN end_char="596" id="token-5-13" morph="none" pos="word" start_char="595">of</TOKEN>
<TOKEN end_char="602" id="token-5-14" morph="none" pos="word" start_char="598">blame</TOKEN>
<TOKEN end_char="612" id="token-5-15" morph="none" pos="word" start_char="604">elsewhere</TOKEN>
<TOKEN end_char="613" id="token-5-16" morph="none" pos="punct" start_char="613">.</TOKEN>
</SEG>
<SEG end_char="723" id="segment-6" start_char="615">
<ORIGINAL_TEXT>Earlier, it blamed Italy and the United States, largely without evidence, for the novel coronavirus outbreak.</ORIGINAL_TEXT>
<TOKEN end_char="621" id="token-6-0" morph="none" pos="word" start_char="615">Earlier</TOKEN>
<TOKEN end_char="622" id="token-6-1" morph="none" pos="punct" start_char="622">,</TOKEN>
<TOKEN end_char="625" id="token-6-2" morph="none" pos="word" start_char="624">it</TOKEN>
<TOKEN end_char="632" id="token-6-3" morph="none" pos="word" start_char="627">blamed</TOKEN>
<TOKEN end_char="638" id="token-6-4" morph="none" pos="word" start_char="634">Italy</TOKEN>
<TOKEN end_char="642" id="token-6-5" morph="none" pos="word" start_char="640">and</TOKEN>
<TOKEN end_char="646" id="token-6-6" morph="none" pos="word" start_char="644">the</TOKEN>
<TOKEN end_char="653" id="token-6-7" morph="none" pos="word" start_char="648">United</TOKEN>
<TOKEN end_char="660" id="token-6-8" morph="none" pos="word" start_char="655">States</TOKEN>
<TOKEN end_char="661" id="token-6-9" morph="none" pos="punct" start_char="661">,</TOKEN>
<TOKEN end_char="669" id="token-6-10" morph="none" pos="word" start_char="663">largely</TOKEN>
<TOKEN end_char="677" id="token-6-11" morph="none" pos="word" start_char="671">without</TOKEN>
<TOKEN end_char="686" id="token-6-12" morph="none" pos="word" start_char="679">evidence</TOKEN>
<TOKEN end_char="687" id="token-6-13" morph="none" pos="punct" start_char="687">,</TOKEN>
<TOKEN end_char="691" id="token-6-14" morph="none" pos="word" start_char="689">for</TOKEN>
<TOKEN end_char="695" id="token-6-15" morph="none" pos="word" start_char="693">the</TOKEN>
<TOKEN end_char="701" id="token-6-16" morph="none" pos="word" start_char="697">novel</TOKEN>
<TOKEN end_char="713" id="token-6-17" morph="none" pos="word" start_char="703">coronavirus</TOKEN>
<TOKEN end_char="722" id="token-6-18" morph="none" pos="word" start_char="715">outbreak</TOKEN>
<TOKEN end_char="723" id="token-6-19" morph="none" pos="punct" start_char="723">.</TOKEN>
</SEG>
<SEG end_char="801" id="segment-7" start_char="726">
<ORIGINAL_TEXT>The researchers used phylogenetic analysis to trace the origins of COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="728" id="token-7-0" morph="none" pos="word" start_char="726">The</TOKEN>
<TOKEN end_char="740" id="token-7-1" morph="none" pos="word" start_char="730">researchers</TOKEN>
<TOKEN end_char="745" id="token-7-2" morph="none" pos="word" start_char="742">used</TOKEN>
<TOKEN end_char="758" id="token-7-3" morph="none" pos="word" start_char="747">phylogenetic</TOKEN>
<TOKEN end_char="767" id="token-7-4" morph="none" pos="word" start_char="760">analysis</TOKEN>
<TOKEN end_char="770" id="token-7-5" morph="none" pos="word" start_char="769">to</TOKEN>
<TOKEN end_char="776" id="token-7-6" morph="none" pos="word" start_char="772">trace</TOKEN>
<TOKEN end_char="780" id="token-7-7" morph="none" pos="word" start_char="778">the</TOKEN>
<TOKEN end_char="788" id="token-7-8" morph="none" pos="word" start_char="782">origins</TOKEN>
<TOKEN end_char="791" id="token-7-9" morph="none" pos="word" start_char="790">of</TOKEN>
<TOKEN end_char="800" id="token-7-10" morph="none" pos="unknown" start_char="793">COVID-19</TOKEN>
<TOKEN end_char="801" id="token-7-11" morph="none" pos="punct" start_char="801">.</TOKEN>
</SEG>
<SEG end_char="929" id="segment-8" start_char="803">
<ORIGINAL_TEXT>Viruses, like all cells, mutate as they reproduce, meaning tiny changes occur in their DNA each time they replicate themselves.</ORIGINAL_TEXT>
<TOKEN end_char="809" id="token-8-0" morph="none" pos="word" start_char="803">Viruses</TOKEN>
<TOKEN end_char="810" id="token-8-1" morph="none" pos="punct" start_char="810">,</TOKEN>
<TOKEN end_char="815" id="token-8-2" morph="none" pos="word" start_char="812">like</TOKEN>
<TOKEN end_char="819" id="token-8-3" morph="none" pos="word" start_char="817">all</TOKEN>
<TOKEN end_char="825" id="token-8-4" morph="none" pos="word" start_char="821">cells</TOKEN>
<TOKEN end_char="826" id="token-8-5" morph="none" pos="punct" start_char="826">,</TOKEN>
<TOKEN end_char="833" id="token-8-6" morph="none" pos="word" start_char="828">mutate</TOKEN>
<TOKEN end_char="836" id="token-8-7" morph="none" pos="word" start_char="835">as</TOKEN>
<TOKEN end_char="841" id="token-8-8" morph="none" pos="word" start_char="838">they</TOKEN>
<TOKEN end_char="851" id="token-8-9" morph="none" pos="word" start_char="843">reproduce</TOKEN>
<TOKEN end_char="852" id="token-8-10" morph="none" pos="punct" start_char="852">,</TOKEN>
<TOKEN end_char="860" id="token-8-11" morph="none" pos="word" start_char="854">meaning</TOKEN>
<TOKEN end_char="865" id="token-8-12" morph="none" pos="word" start_char="862">tiny</TOKEN>
<TOKEN end_char="873" id="token-8-13" morph="none" pos="word" start_char="867">changes</TOKEN>
<TOKEN end_char="879" id="token-8-14" morph="none" pos="word" start_char="875">occur</TOKEN>
<TOKEN end_char="882" id="token-8-15" morph="none" pos="word" start_char="881">in</TOKEN>
<TOKEN end_char="888" id="token-8-16" morph="none" pos="word" start_char="884">their</TOKEN>
<TOKEN end_char="892" id="token-8-17" morph="none" pos="word" start_char="890">DNA</TOKEN>
<TOKEN end_char="897" id="token-8-18" morph="none" pos="word" start_char="894">each</TOKEN>
<TOKEN end_char="902" id="token-8-19" morph="none" pos="word" start_char="899">time</TOKEN>
<TOKEN end_char="907" id="token-8-20" morph="none" pos="word" start_char="904">they</TOKEN>
<TOKEN end_char="917" id="token-8-21" morph="none" pos="word" start_char="909">replicate</TOKEN>
<TOKEN end_char="928" id="token-8-22" morph="none" pos="word" start_char="919">themselves</TOKEN>
<TOKEN end_char="929" id="token-8-23" morph="none" pos="punct" start_char="929">.</TOKEN>
</SEG>
<SEG end_char="1070" id="segment-9" start_char="931">
<ORIGINAL_TEXT>Therefore, it should be possible to track down the original version of the virus by finding the sample with the fewest mutations, they said.</ORIGINAL_TEXT>
<TOKEN end_char="939" id="token-9-0" morph="none" pos="word" start_char="931">Therefore</TOKEN>
<TOKEN end_char="940" id="token-9-1" morph="none" pos="punct" start_char="940">,</TOKEN>
<TOKEN end_char="943" id="token-9-2" morph="none" pos="word" start_char="942">it</TOKEN>
<TOKEN end_char="950" id="token-9-3" morph="none" pos="word" start_char="945">should</TOKEN>
<TOKEN end_char="953" id="token-9-4" morph="none" pos="word" start_char="952">be</TOKEN>
<TOKEN end_char="962" id="token-9-5" morph="none" pos="word" start_char="955">possible</TOKEN>
<TOKEN end_char="965" id="token-9-6" morph="none" pos="word" start_char="964">to</TOKEN>
<TOKEN end_char="971" id="token-9-7" morph="none" pos="word" start_char="967">track</TOKEN>
<TOKEN end_char="976" id="token-9-8" morph="none" pos="word" start_char="973">down</TOKEN>
<TOKEN end_char="980" id="token-9-9" morph="none" pos="word" start_char="978">the</TOKEN>
<TOKEN end_char="989" id="token-9-10" morph="none" pos="word" start_char="982">original</TOKEN>
<TOKEN end_char="997" id="token-9-11" morph="none" pos="word" start_char="991">version</TOKEN>
<TOKEN end_char="1000" id="token-9-12" morph="none" pos="word" start_char="999">of</TOKEN>
<TOKEN end_char="1004" id="token-9-13" morph="none" pos="word" start_char="1002">the</TOKEN>
<TOKEN end_char="1010" id="token-9-14" morph="none" pos="word" start_char="1006">virus</TOKEN>
<TOKEN end_char="1013" id="token-9-15" morph="none" pos="word" start_char="1012">by</TOKEN>
<TOKEN end_char="1021" id="token-9-16" morph="none" pos="word" start_char="1015">finding</TOKEN>
<TOKEN end_char="1025" id="token-9-17" morph="none" pos="word" start_char="1023">the</TOKEN>
<TOKEN end_char="1032" id="token-9-18" morph="none" pos="word" start_char="1027">sample</TOKEN>
<TOKEN end_char="1037" id="token-9-19" morph="none" pos="word" start_char="1034">with</TOKEN>
<TOKEN end_char="1041" id="token-9-20" morph="none" pos="word" start_char="1039">the</TOKEN>
<TOKEN end_char="1048" id="token-9-21" morph="none" pos="word" start_char="1043">fewest</TOKEN>
<TOKEN end_char="1058" id="token-9-22" morph="none" pos="word" start_char="1050">mutations</TOKEN>
<TOKEN end_char="1059" id="token-9-23" morph="none" pos="punct" start_char="1059">,</TOKEN>
<TOKEN end_char="1064" id="token-9-24" morph="none" pos="word" start_char="1061">they</TOKEN>
<TOKEN end_char="1069" id="token-9-25" morph="none" pos="word" start_char="1066">said</TOKEN>
<TOKEN end_char="1070" id="token-9-26" morph="none" pos="punct" start_char="1070">.</TOKEN>
</SEG>
<SEG end_char="1149" id="segment-10" start_char="1073">
<ORIGINAL_TEXT>Follow our LIVE blog for the latest updates of the novel coronavirus pandemic</ORIGINAL_TEXT>
<TOKEN end_char="1078" id="token-10-0" morph="none" pos="word" start_char="1073">Follow</TOKEN>
<TOKEN end_char="1082" id="token-10-1" morph="none" pos="word" start_char="1080">our</TOKEN>
<TOKEN end_char="1087" id="token-10-2" morph="none" pos="word" start_char="1084">LIVE</TOKEN>
<TOKEN end_char="1092" id="token-10-3" morph="none" pos="word" start_char="1089">blog</TOKEN>
<TOKEN end_char="1096" id="token-10-4" morph="none" pos="word" start_char="1094">for</TOKEN>
<TOKEN end_char="1100" id="token-10-5" morph="none" pos="word" start_char="1098">the</TOKEN>
<TOKEN end_char="1107" id="token-10-6" morph="none" pos="word" start_char="1102">latest</TOKEN>
<TOKEN end_char="1115" id="token-10-7" morph="none" pos="word" start_char="1109">updates</TOKEN>
<TOKEN end_char="1118" id="token-10-8" morph="none" pos="word" start_char="1117">of</TOKEN>
<TOKEN end_char="1122" id="token-10-9" morph="none" pos="word" start_char="1120">the</TOKEN>
<TOKEN end_char="1128" id="token-10-10" morph="none" pos="word" start_char="1124">novel</TOKEN>
<TOKEN end_char="1140" id="token-10-11" morph="none" pos="word" start_char="1130">coronavirus</TOKEN>
<TOKEN end_char="1149" id="token-10-12" morph="none" pos="word" start_char="1142">pandemic</TOKEN>
</SEG>
<SEG end_char="1287" id="segment-11" start_char="1153">
<ORIGINAL_TEXT>According to the report, the scientists further said that using this method rules out the virus found in Wuhan as the 'original' virus.</ORIGINAL_TEXT>
<TOKEN end_char="1161" id="token-11-0" morph="none" pos="word" start_char="1153">According</TOKEN>
<TOKEN end_char="1164" id="token-11-1" morph="none" pos="word" start_char="1163">to</TOKEN>
<TOKEN end_char="1168" id="token-11-2" morph="none" pos="word" start_char="1166">the</TOKEN>
<TOKEN end_char="1175" id="token-11-3" morph="none" pos="word" start_char="1170">report</TOKEN>
<TOKEN end_char="1176" id="token-11-4" morph="none" pos="punct" start_char="1176">,</TOKEN>
<TOKEN end_char="1180" id="token-11-5" morph="none" pos="word" start_char="1178">the</TOKEN>
<TOKEN end_char="1191" id="token-11-6" morph="none" pos="word" start_char="1182">scientists</TOKEN>
<TOKEN end_char="1199" id="token-11-7" morph="none" pos="word" start_char="1193">further</TOKEN>
<TOKEN end_char="1204" id="token-11-8" morph="none" pos="word" start_char="1201">said</TOKEN>
<TOKEN end_char="1209" id="token-11-9" morph="none" pos="word" start_char="1206">that</TOKEN>
<TOKEN end_char="1215" id="token-11-10" morph="none" pos="word" start_char="1211">using</TOKEN>
<TOKEN end_char="1220" id="token-11-11" morph="none" pos="word" start_char="1217">this</TOKEN>
<TOKEN end_char="1227" id="token-11-12" morph="none" pos="word" start_char="1222">method</TOKEN>
<TOKEN end_char="1233" id="token-11-13" morph="none" pos="word" start_char="1229">rules</TOKEN>
<TOKEN end_char="1237" id="token-11-14" morph="none" pos="word" start_char="1235">out</TOKEN>
<TOKEN end_char="1241" id="token-11-15" morph="none" pos="word" start_char="1239">the</TOKEN>
<TOKEN end_char="1247" id="token-11-16" morph="none" pos="word" start_char="1243">virus</TOKEN>
<TOKEN end_char="1253" id="token-11-17" morph="none" pos="word" start_char="1249">found</TOKEN>
<TOKEN end_char="1256" id="token-11-18" morph="none" pos="word" start_char="1255">in</TOKEN>
<TOKEN end_char="1262" id="token-11-19" morph="none" pos="word" start_char="1258">Wuhan</TOKEN>
<TOKEN end_char="1265" id="token-11-20" morph="none" pos="word" start_char="1264">as</TOKEN>
<TOKEN end_char="1269" id="token-11-21" morph="none" pos="word" start_char="1267">the</TOKEN>
<TOKEN end_char="1271" id="token-11-22" morph="none" pos="punct" start_char="1271">'</TOKEN>
<TOKEN end_char="1279" id="token-11-23" morph="none" pos="word" start_char="1272">original</TOKEN>
<TOKEN end_char="1280" id="token-11-24" morph="none" pos="punct" start_char="1280">'</TOKEN>
<TOKEN end_char="1286" id="token-11-25" morph="none" pos="word" start_char="1282">virus</TOKEN>
<TOKEN end_char="1287" id="token-11-26" morph="none" pos="punct" start_char="1287">.</TOKEN>
</SEG>
<SEG end_char="1421" id="segment-12" start_char="1289">
<ORIGINAL_TEXT>They instead points to eight other countries: Bangladesh, the USA, Greece, Australia, India, Italy, Czech Republic, Russia or Serbia.</ORIGINAL_TEXT>
<TOKEN end_char="1292" id="token-12-0" morph="none" pos="word" start_char="1289">They</TOKEN>
<TOKEN end_char="1300" id="token-12-1" morph="none" pos="word" start_char="1294">instead</TOKEN>
<TOKEN end_char="1307" id="token-12-2" morph="none" pos="word" start_char="1302">points</TOKEN>
<TOKEN end_char="1310" id="token-12-3" morph="none" pos="word" start_char="1309">to</TOKEN>
<TOKEN end_char="1316" id="token-12-4" morph="none" pos="word" start_char="1312">eight</TOKEN>
<TOKEN end_char="1322" id="token-12-5" morph="none" pos="word" start_char="1318">other</TOKEN>
<TOKEN end_char="1332" id="token-12-6" morph="none" pos="word" start_char="1324">countries</TOKEN>
<TOKEN end_char="1333" id="token-12-7" morph="none" pos="punct" start_char="1333">:</TOKEN>
<TOKEN end_char="1344" id="token-12-8" morph="none" pos="word" start_char="1335">Bangladesh</TOKEN>
<TOKEN end_char="1345" id="token-12-9" morph="none" pos="punct" start_char="1345">,</TOKEN>
<TOKEN end_char="1349" id="token-12-10" morph="none" pos="word" start_char="1347">the</TOKEN>
<TOKEN end_char="1353" id="token-12-11" morph="none" pos="word" start_char="1351">USA</TOKEN>
<TOKEN end_char="1354" id="token-12-12" morph="none" pos="punct" start_char="1354">,</TOKEN>
<TOKEN end_char="1361" id="token-12-13" morph="none" pos="word" start_char="1356">Greece</TOKEN>
<TOKEN end_char="1362" id="token-12-14" morph="none" pos="punct" start_char="1362">,</TOKEN>
<TOKEN end_char="1372" id="token-12-15" morph="none" pos="word" start_char="1364">Australia</TOKEN>
<TOKEN end_char="1373" id="token-12-16" morph="none" pos="punct" start_char="1373">,</TOKEN>
<TOKEN end_char="1379" id="token-12-17" morph="none" pos="word" start_char="1375">India</TOKEN>
<TOKEN end_char="1380" id="token-12-18" morph="none" pos="punct" start_char="1380">,</TOKEN>
<TOKEN end_char="1386" id="token-12-19" morph="none" pos="word" start_char="1382">Italy</TOKEN>
<TOKEN end_char="1387" id="token-12-20" morph="none" pos="punct" start_char="1387">,</TOKEN>
<TOKEN end_char="1393" id="token-12-21" morph="none" pos="word" start_char="1389">Czech</TOKEN>
<TOKEN end_char="1402" id="token-12-22" morph="none" pos="word" start_char="1395">Republic</TOKEN>
<TOKEN end_char="1403" id="token-12-23" morph="none" pos="punct" start_char="1403">,</TOKEN>
<TOKEN end_char="1410" id="token-12-24" morph="none" pos="word" start_char="1405">Russia</TOKEN>
<TOKEN end_char="1413" id="token-12-25" morph="none" pos="word" start_char="1412">or</TOKEN>
<TOKEN end_char="1420" id="token-12-26" morph="none" pos="word" start_char="1415">Serbia</TOKEN>
<TOKEN end_char="1421" id="token-12-27" morph="none" pos="punct" start_char="1421">.</TOKEN>
</SEG>
<SEG end_char="1558" id="segment-13" start_char="1424">
<ORIGINAL_TEXT>The blame comes against a backdrop of increased political tensions between India and China amid their border dispute in eastern Ladakh.</ORIGINAL_TEXT>
<TOKEN end_char="1426" id="token-13-0" morph="none" pos="word" start_char="1424">The</TOKEN>
<TOKEN end_char="1432" id="token-13-1" morph="none" pos="word" start_char="1428">blame</TOKEN>
<TOKEN end_char="1438" id="token-13-2" morph="none" pos="word" start_char="1434">comes</TOKEN>
<TOKEN end_char="1446" id="token-13-3" morph="none" pos="word" start_char="1440">against</TOKEN>
<TOKEN end_char="1448" id="token-13-4" morph="none" pos="word" start_char="1448">a</TOKEN>
<TOKEN end_char="1457" id="token-13-5" morph="none" pos="word" start_char="1450">backdrop</TOKEN>
<TOKEN end_char="1460" id="token-13-6" morph="none" pos="word" start_char="1459">of</TOKEN>
<TOKEN end_char="1470" id="token-13-7" morph="none" pos="word" start_char="1462">increased</TOKEN>
<TOKEN end_char="1480" id="token-13-8" morph="none" pos="word" start_char="1472">political</TOKEN>
<TOKEN end_char="1489" id="token-13-9" morph="none" pos="word" start_char="1482">tensions</TOKEN>
<TOKEN end_char="1497" id="token-13-10" morph="none" pos="word" start_char="1491">between</TOKEN>
<TOKEN end_char="1503" id="token-13-11" morph="none" pos="word" start_char="1499">India</TOKEN>
<TOKEN end_char="1507" id="token-13-12" morph="none" pos="word" start_char="1505">and</TOKEN>
<TOKEN end_char="1513" id="token-13-13" morph="none" pos="word" start_char="1509">China</TOKEN>
<TOKEN end_char="1518" id="token-13-14" morph="none" pos="word" start_char="1515">amid</TOKEN>
<TOKEN end_char="1524" id="token-13-15" morph="none" pos="word" start_char="1520">their</TOKEN>
<TOKEN end_char="1531" id="token-13-16" morph="none" pos="word" start_char="1526">border</TOKEN>
<TOKEN end_char="1539" id="token-13-17" morph="none" pos="word" start_char="1533">dispute</TOKEN>
<TOKEN end_char="1542" id="token-13-18" morph="none" pos="word" start_char="1541">in</TOKEN>
<TOKEN end_char="1550" id="token-13-19" morph="none" pos="word" start_char="1544">eastern</TOKEN>
<TOKEN end_char="1557" id="token-13-20" morph="none" pos="word" start_char="1552">Ladakh</TOKEN>
<TOKEN end_char="1558" id="token-13-21" morph="none" pos="punct" start_char="1558">.</TOKEN>
</SEG>
<SEG end_char="1763" id="segment-14" start_char="1561">
<ORIGINAL_TEXT>The unproven theory further said that from May to June 2019, the second-longest recorded heatwave had rampaged in northern-central India and Pakistan, which created a serious water crisis in this region.</ORIGINAL_TEXT>
<TOKEN end_char="1563" id="token-14-0" morph="none" pos="word" start_char="1561">The</TOKEN>
<TOKEN end_char="1572" id="token-14-1" morph="none" pos="word" start_char="1565">unproven</TOKEN>
<TOKEN end_char="1579" id="token-14-2" morph="none" pos="word" start_char="1574">theory</TOKEN>
<TOKEN end_char="1587" id="token-14-3" morph="none" pos="word" start_char="1581">further</TOKEN>
<TOKEN end_char="1592" id="token-14-4" morph="none" pos="word" start_char="1589">said</TOKEN>
<TOKEN end_char="1597" id="token-14-5" morph="none" pos="word" start_char="1594">that</TOKEN>
<TOKEN end_char="1602" id="token-14-6" morph="none" pos="word" start_char="1599">from</TOKEN>
<TOKEN end_char="1606" id="token-14-7" morph="none" pos="word" start_char="1604">May</TOKEN>
<TOKEN end_char="1609" id="token-14-8" morph="none" pos="word" start_char="1608">to</TOKEN>
<TOKEN end_char="1614" id="token-14-9" morph="none" pos="word" start_char="1611">June</TOKEN>
<TOKEN end_char="1619" id="token-14-10" morph="none" pos="word" start_char="1616">2019</TOKEN>
<TOKEN end_char="1620" id="token-14-11" morph="none" pos="punct" start_char="1620">,</TOKEN>
<TOKEN end_char="1624" id="token-14-12" morph="none" pos="word" start_char="1622">the</TOKEN>
<TOKEN end_char="1639" id="token-14-13" morph="none" pos="unknown" start_char="1626">second-longest</TOKEN>
<TOKEN end_char="1648" id="token-14-14" morph="none" pos="word" start_char="1641">recorded</TOKEN>
<TOKEN end_char="1657" id="token-14-15" morph="none" pos="word" start_char="1650">heatwave</TOKEN>
<TOKEN end_char="1661" id="token-14-16" morph="none" pos="word" start_char="1659">had</TOKEN>
<TOKEN end_char="1670" id="token-14-17" morph="none" pos="word" start_char="1663">rampaged</TOKEN>
<TOKEN end_char="1673" id="token-14-18" morph="none" pos="word" start_char="1672">in</TOKEN>
<TOKEN end_char="1690" id="token-14-19" morph="none" pos="unknown" start_char="1675">northern-central</TOKEN>
<TOKEN end_char="1696" id="token-14-20" morph="none" pos="word" start_char="1692">India</TOKEN>
<TOKEN end_char="1700" id="token-14-21" morph="none" pos="word" start_char="1698">and</TOKEN>
<TOKEN end_char="1709" id="token-14-22" morph="none" pos="word" start_char="1702">Pakistan</TOKEN>
<TOKEN end_char="1710" id="token-14-23" morph="none" pos="punct" start_char="1710">,</TOKEN>
<TOKEN end_char="1716" id="token-14-24" morph="none" pos="word" start_char="1712">which</TOKEN>
<TOKEN end_char="1724" id="token-14-25" morph="none" pos="word" start_char="1718">created</TOKEN>
<TOKEN end_char="1726" id="token-14-26" morph="none" pos="word" start_char="1726">a</TOKEN>
<TOKEN end_char="1734" id="token-14-27" morph="none" pos="word" start_char="1728">serious</TOKEN>
<TOKEN end_char="1740" id="token-14-28" morph="none" pos="word" start_char="1736">water</TOKEN>
<TOKEN end_char="1747" id="token-14-29" morph="none" pos="word" start_char="1742">crisis</TOKEN>
<TOKEN end_char="1750" id="token-14-30" morph="none" pos="word" start_char="1749">in</TOKEN>
<TOKEN end_char="1755" id="token-14-31" morph="none" pos="word" start_char="1752">this</TOKEN>
<TOKEN end_char="1762" id="token-14-32" morph="none" pos="word" start_char="1757">region</TOKEN>
<TOKEN end_char="1763" id="token-14-33" morph="none" pos="punct" start_char="1763">.</TOKEN>
</SEG>
<SEG end_char="1873" id="segment-15" start_char="1766">
<ORIGINAL_TEXT>The water shortage made wild animals such as monkeys engage in the deadly fight over water among each other.</ORIGINAL_TEXT>
<TOKEN end_char="1768" id="token-15-0" morph="none" pos="word" start_char="1766">The</TOKEN>
<TOKEN end_char="1774" id="token-15-1" morph="none" pos="word" start_char="1770">water</TOKEN>
<TOKEN end_char="1783" id="token-15-2" morph="none" pos="word" start_char="1776">shortage</TOKEN>
<TOKEN end_char="1788" id="token-15-3" morph="none" pos="word" start_char="1785">made</TOKEN>
<TOKEN end_char="1793" id="token-15-4" morph="none" pos="word" start_char="1790">wild</TOKEN>
<TOKEN end_char="1801" id="token-15-5" morph="none" pos="word" start_char="1795">animals</TOKEN>
<TOKEN end_char="1806" id="token-15-6" morph="none" pos="word" start_char="1803">such</TOKEN>
<TOKEN end_char="1809" id="token-15-7" morph="none" pos="word" start_char="1808">as</TOKEN>
<TOKEN end_char="1817" id="token-15-8" morph="none" pos="word" start_char="1811">monkeys</TOKEN>
<TOKEN end_char="1824" id="token-15-9" morph="none" pos="word" start_char="1819">engage</TOKEN>
<TOKEN end_char="1827" id="token-15-10" morph="none" pos="word" start_char="1826">in</TOKEN>
<TOKEN end_char="1831" id="token-15-11" morph="none" pos="word" start_char="1829">the</TOKEN>
<TOKEN end_char="1838" id="token-15-12" morph="none" pos="word" start_char="1833">deadly</TOKEN>
<TOKEN end_char="1844" id="token-15-13" morph="none" pos="word" start_char="1840">fight</TOKEN>
<TOKEN end_char="1849" id="token-15-14" morph="none" pos="word" start_char="1846">over</TOKEN>
<TOKEN end_char="1855" id="token-15-15" morph="none" pos="word" start_char="1851">water</TOKEN>
<TOKEN end_char="1861" id="token-15-16" morph="none" pos="word" start_char="1857">among</TOKEN>
<TOKEN end_char="1866" id="token-15-17" morph="none" pos="word" start_char="1863">each</TOKEN>
<TOKEN end_char="1872" id="token-15-18" morph="none" pos="word" start_char="1868">other</TOKEN>
<TOKEN end_char="1873" id="token-15-19" morph="none" pos="punct" start_char="1873">.</TOKEN>
</SEG>
<SEG end_char="2097" id="segment-16" start_char="1875">
<ORIGINAL_TEXT>This would have surely increased the chance of human-wild animal interactions, the researchers said, as they speculated that "the [animal to human] transmission of SARS-CoV-2 might be associated with this unusual heatwave."</ORIGINAL_TEXT>
<TOKEN end_char="1878" id="token-16-0" morph="none" pos="word" start_char="1875">This</TOKEN>
<TOKEN end_char="1884" id="token-16-1" morph="none" pos="word" start_char="1880">would</TOKEN>
<TOKEN end_char="1889" id="token-16-2" morph="none" pos="word" start_char="1886">have</TOKEN>
<TOKEN end_char="1896" id="token-16-3" morph="none" pos="word" start_char="1891">surely</TOKEN>
<TOKEN end_char="1906" id="token-16-4" morph="none" pos="word" start_char="1898">increased</TOKEN>
<TOKEN end_char="1910" id="token-16-5" morph="none" pos="word" start_char="1908">the</TOKEN>
<TOKEN end_char="1917" id="token-16-6" morph="none" pos="word" start_char="1912">chance</TOKEN>
<TOKEN end_char="1920" id="token-16-7" morph="none" pos="word" start_char="1919">of</TOKEN>
<TOKEN end_char="1931" id="token-16-8" morph="none" pos="unknown" start_char="1922">human-wild</TOKEN>
<TOKEN end_char="1938" id="token-16-9" morph="none" pos="word" start_char="1933">animal</TOKEN>
<TOKEN end_char="1951" id="token-16-10" morph="none" pos="word" start_char="1940">interactions</TOKEN>
<TOKEN end_char="1952" id="token-16-11" morph="none" pos="punct" start_char="1952">,</TOKEN>
<TOKEN end_char="1956" id="token-16-12" morph="none" pos="word" start_char="1954">the</TOKEN>
<TOKEN end_char="1968" id="token-16-13" morph="none" pos="word" start_char="1958">researchers</TOKEN>
<TOKEN end_char="1973" id="token-16-14" morph="none" pos="word" start_char="1970">said</TOKEN>
<TOKEN end_char="1974" id="token-16-15" morph="none" pos="punct" start_char="1974">,</TOKEN>
<TOKEN end_char="1977" id="token-16-16" morph="none" pos="word" start_char="1976">as</TOKEN>
<TOKEN end_char="1982" id="token-16-17" morph="none" pos="word" start_char="1979">they</TOKEN>
<TOKEN end_char="1993" id="token-16-18" morph="none" pos="word" start_char="1984">speculated</TOKEN>
<TOKEN end_char="1998" id="token-16-19" morph="none" pos="word" start_char="1995">that</TOKEN>
<TOKEN end_char="2000" id="token-16-20" morph="none" pos="punct" start_char="2000">"</TOKEN>
<TOKEN end_char="2003" id="token-16-21" morph="none" pos="word" start_char="2001">the</TOKEN>
<TOKEN end_char="2005" id="token-16-22" morph="none" pos="punct" start_char="2005">[</TOKEN>
<TOKEN end_char="2011" id="token-16-23" morph="none" pos="word" start_char="2006">animal</TOKEN>
<TOKEN end_char="2014" id="token-16-24" morph="none" pos="word" start_char="2013">to</TOKEN>
<TOKEN end_char="2020" id="token-16-25" morph="none" pos="word" start_char="2016">human</TOKEN>
<TOKEN end_char="2021" id="token-16-26" morph="none" pos="punct" start_char="2021">]</TOKEN>
<TOKEN end_char="2034" id="token-16-27" morph="none" pos="word" start_char="2023">transmission</TOKEN>
<TOKEN end_char="2037" id="token-16-28" morph="none" pos="word" start_char="2036">of</TOKEN>
<TOKEN end_char="2048" id="token-16-29" morph="none" pos="unknown" start_char="2039">SARS-CoV-2</TOKEN>
<TOKEN end_char="2054" id="token-16-30" morph="none" pos="word" start_char="2050">might</TOKEN>
<TOKEN end_char="2057" id="token-16-31" morph="none" pos="word" start_char="2056">be</TOKEN>
<TOKEN end_char="2068" id="token-16-32" morph="none" pos="word" start_char="2059">associated</TOKEN>
<TOKEN end_char="2073" id="token-16-33" morph="none" pos="word" start_char="2070">with</TOKEN>
<TOKEN end_char="2078" id="token-16-34" morph="none" pos="word" start_char="2075">this</TOKEN>
<TOKEN end_char="2086" id="token-16-35" morph="none" pos="word" start_char="2080">unusual</TOKEN>
<TOKEN end_char="2095" id="token-16-36" morph="none" pos="word" start_char="2088">heatwave</TOKEN>
<TOKEN end_char="2097" id="token-16-37" morph="none" pos="punct" start_char="2096">."</TOKEN>
</SEG>
<SEG end_char="2183" id="segment-17" start_char="2100">
<ORIGINAL_TEXT>The claim, however, rejected by David Robertson, and expert from Glasgow University.</ORIGINAL_TEXT>
<TOKEN end_char="2102" id="token-17-0" morph="none" pos="word" start_char="2100">The</TOKEN>
<TOKEN end_char="2108" id="token-17-1" morph="none" pos="word" start_char="2104">claim</TOKEN>
<TOKEN end_char="2109" id="token-17-2" morph="none" pos="punct" start_char="2109">,</TOKEN>
<TOKEN end_char="2117" id="token-17-3" morph="none" pos="word" start_char="2111">however</TOKEN>
<TOKEN end_char="2118" id="token-17-4" morph="none" pos="punct" start_char="2118">,</TOKEN>
<TOKEN end_char="2127" id="token-17-5" morph="none" pos="word" start_char="2120">rejected</TOKEN>
<TOKEN end_char="2130" id="token-17-6" morph="none" pos="word" start_char="2129">by</TOKEN>
<TOKEN end_char="2136" id="token-17-7" morph="none" pos="word" start_char="2132">David</TOKEN>
<TOKEN end_char="2146" id="token-17-8" morph="none" pos="word" start_char="2138">Robertson</TOKEN>
<TOKEN end_char="2147" id="token-17-9" morph="none" pos="punct" start_char="2147">,</TOKEN>
<TOKEN end_char="2151" id="token-17-10" morph="none" pos="word" start_char="2149">and</TOKEN>
<TOKEN end_char="2158" id="token-17-11" morph="none" pos="word" start_char="2153">expert</TOKEN>
<TOKEN end_char="2163" id="token-17-12" morph="none" pos="word" start_char="2160">from</TOKEN>
<TOKEN end_char="2171" id="token-17-13" morph="none" pos="word" start_char="2165">Glasgow</TOKEN>
<TOKEN end_char="2182" id="token-17-14" morph="none" pos="word" start_char="2173">University</TOKEN>
<TOKEN end_char="2183" id="token-17-15" morph="none" pos="punct" start_char="2183">.</TOKEN>
</SEG>
<SEG end_char="2286" id="segment-18" start_char="2185">
<ORIGINAL_TEXT>He called the paper 'very flawed' and concluded 'it adds nothing to our understanding of coronavirus'.</ORIGINAL_TEXT>
<TOKEN end_char="2186" id="token-18-0" morph="none" pos="word" start_char="2185">He</TOKEN>
<TOKEN end_char="2193" id="token-18-1" morph="none" pos="word" start_char="2188">called</TOKEN>
<TOKEN end_char="2197" id="token-18-2" morph="none" pos="word" start_char="2195">the</TOKEN>
<TOKEN end_char="2203" id="token-18-3" morph="none" pos="word" start_char="2199">paper</TOKEN>
<TOKEN end_char="2205" id="token-18-4" morph="none" pos="punct" start_char="2205">'</TOKEN>
<TOKEN end_char="2209" id="token-18-5" morph="none" pos="word" start_char="2206">very</TOKEN>
<TOKEN end_char="2216" id="token-18-6" morph="none" pos="word" start_char="2211">flawed</TOKEN>
<TOKEN end_char="2217" id="token-18-7" morph="none" pos="punct" start_char="2217">'</TOKEN>
<TOKEN end_char="2221" id="token-18-8" morph="none" pos="word" start_char="2219">and</TOKEN>
<TOKEN end_char="2231" id="token-18-9" morph="none" pos="word" start_char="2223">concluded</TOKEN>
<TOKEN end_char="2233" id="token-18-10" morph="none" pos="punct" start_char="2233">'</TOKEN>
<TOKEN end_char="2235" id="token-18-11" morph="none" pos="word" start_char="2234">it</TOKEN>
<TOKEN end_char="2240" id="token-18-12" morph="none" pos="word" start_char="2237">adds</TOKEN>
<TOKEN end_char="2248" id="token-18-13" morph="none" pos="word" start_char="2242">nothing</TOKEN>
<TOKEN end_char="2251" id="token-18-14" morph="none" pos="word" start_char="2250">to</TOKEN>
<TOKEN end_char="2255" id="token-18-15" morph="none" pos="word" start_char="2253">our</TOKEN>
<TOKEN end_char="2269" id="token-18-16" morph="none" pos="word" start_char="2257">understanding</TOKEN>
<TOKEN end_char="2272" id="token-18-17" morph="none" pos="word" start_char="2271">of</TOKEN>
<TOKEN end_char="2284" id="token-18-18" morph="none" pos="word" start_char="2274">coronavirus</TOKEN>
<TOKEN end_char="2286" id="token-18-19" morph="none" pos="punct" start_char="2285">'.</TOKEN>
</SEG>
<SEG end_char="2330" id="segment-19" start_char="2289">
<ORIGINAL_TEXT>Follow our full coverage on COVID-19 here.</ORIGINAL_TEXT>
<TOKEN end_char="2294" id="token-19-0" morph="none" pos="word" start_char="2289">Follow</TOKEN>
<TOKEN end_char="2298" id="token-19-1" morph="none" pos="word" start_char="2296">our</TOKEN>
<TOKEN end_char="2303" id="token-19-2" morph="none" pos="word" start_char="2300">full</TOKEN>
<TOKEN end_char="2312" id="token-19-3" morph="none" pos="word" start_char="2305">coverage</TOKEN>
<TOKEN end_char="2315" id="token-19-4" morph="none" pos="word" start_char="2314">on</TOKEN>
<TOKEN end_char="2324" id="token-19-5" morph="none" pos="unknown" start_char="2317">COVID-19</TOKEN>
<TOKEN end_char="2329" id="token-19-6" morph="none" pos="word" start_char="2326">here</TOKEN>
<TOKEN end_char="2330" id="token-19-7" morph="none" pos="punct" start_char="2330">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
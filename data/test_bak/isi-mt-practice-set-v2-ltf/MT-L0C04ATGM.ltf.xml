<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATGM" lang="spa" raw_text_char_length="3655" raw_text_md5="b86580aba387ed95f15496f38d76aa81" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="65" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Coronavirus Found on Food Packaging, but Likely of Little Concern</ORIGINAL_TEXT>
<TOKEN end_char="11" id="token-0-0" morph="none" pos="word" start_char="1">Coronavirus</TOKEN>
<TOKEN end_char="17" id="token-0-1" morph="none" pos="word" start_char="13">Found</TOKEN>
<TOKEN end_char="20" id="token-0-2" morph="none" pos="word" start_char="19">on</TOKEN>
<TOKEN end_char="25" id="token-0-3" morph="none" pos="word" start_char="22">Food</TOKEN>
<TOKEN end_char="35" id="token-0-4" morph="none" pos="word" start_char="27">Packaging</TOKEN>
<TOKEN end_char="36" id="token-0-5" morph="none" pos="punct" start_char="36">,</TOKEN>
<TOKEN end_char="40" id="token-0-6" morph="none" pos="word" start_char="38">but</TOKEN>
<TOKEN end_char="47" id="token-0-7" morph="none" pos="word" start_char="42">Likely</TOKEN>
<TOKEN end_char="50" id="token-0-8" morph="none" pos="word" start_char="49">of</TOKEN>
<TOKEN end_char="57" id="token-0-9" morph="none" pos="word" start_char="52">Little</TOKEN>
<TOKEN end_char="65" id="token-0-10" morph="none" pos="word" start_char="59">Concern</TOKEN>
</SEG>
<SEG end_char="170" id="segment-1" start_char="69">
<ORIGINAL_TEXT>There is growing evidence that food packaging is transporting SARS-CoV-2 across international borders.</ORIGINAL_TEXT>
<TOKEN end_char="73" id="token-1-0" morph="none" pos="word" start_char="69">There</TOKEN>
<TOKEN end_char="76" id="token-1-1" morph="none" pos="word" start_char="75">is</TOKEN>
<TOKEN end_char="84" id="token-1-2" morph="none" pos="word" start_char="78">growing</TOKEN>
<TOKEN end_char="93" id="token-1-3" morph="none" pos="word" start_char="86">evidence</TOKEN>
<TOKEN end_char="98" id="token-1-4" morph="none" pos="word" start_char="95">that</TOKEN>
<TOKEN end_char="103" id="token-1-5" morph="none" pos="word" start_char="100">food</TOKEN>
<TOKEN end_char="113" id="token-1-6" morph="none" pos="word" start_char="105">packaging</TOKEN>
<TOKEN end_char="116" id="token-1-7" morph="none" pos="word" start_char="115">is</TOKEN>
<TOKEN end_char="129" id="token-1-8" morph="none" pos="word" start_char="118">transporting</TOKEN>
<TOKEN end_char="140" id="token-1-9" morph="none" pos="unknown" start_char="131">SARS-CoV-2</TOKEN>
<TOKEN end_char="147" id="token-1-10" morph="none" pos="word" start_char="142">across</TOKEN>
<TOKEN end_char="161" id="token-1-11" morph="none" pos="word" start_char="149">international</TOKEN>
<TOKEN end_char="169" id="token-1-12" morph="none" pos="word" start_char="163">borders</TOKEN>
<TOKEN end_char="170" id="token-1-13" morph="none" pos="punct" start_char="170">.</TOKEN>
</SEG>
<SEG end_char="401" id="segment-2" start_char="172">
<ORIGINAL_TEXT>Several countries are linked to either exported or imported frozen food that tested positive for traces of the virus, but experts say they believe the risk of developing COVID-19 from handling these products remains extremely low.</ORIGINAL_TEXT>
<TOKEN end_char="178" id="token-2-0" morph="none" pos="word" start_char="172">Several</TOKEN>
<TOKEN end_char="188" id="token-2-1" morph="none" pos="word" start_char="180">countries</TOKEN>
<TOKEN end_char="192" id="token-2-2" morph="none" pos="word" start_char="190">are</TOKEN>
<TOKEN end_char="199" id="token-2-3" morph="none" pos="word" start_char="194">linked</TOKEN>
<TOKEN end_char="202" id="token-2-4" morph="none" pos="word" start_char="201">to</TOKEN>
<TOKEN end_char="209" id="token-2-5" morph="none" pos="word" start_char="204">either</TOKEN>
<TOKEN end_char="218" id="token-2-6" morph="none" pos="word" start_char="211">exported</TOKEN>
<TOKEN end_char="221" id="token-2-7" morph="none" pos="word" start_char="220">or</TOKEN>
<TOKEN end_char="230" id="token-2-8" morph="none" pos="word" start_char="223">imported</TOKEN>
<TOKEN end_char="237" id="token-2-9" morph="none" pos="word" start_char="232">frozen</TOKEN>
<TOKEN end_char="242" id="token-2-10" morph="none" pos="word" start_char="239">food</TOKEN>
<TOKEN end_char="247" id="token-2-11" morph="none" pos="word" start_char="244">that</TOKEN>
<TOKEN end_char="254" id="token-2-12" morph="none" pos="word" start_char="249">tested</TOKEN>
<TOKEN end_char="263" id="token-2-13" morph="none" pos="word" start_char="256">positive</TOKEN>
<TOKEN end_char="267" id="token-2-14" morph="none" pos="word" start_char="265">for</TOKEN>
<TOKEN end_char="274" id="token-2-15" morph="none" pos="word" start_char="269">traces</TOKEN>
<TOKEN end_char="277" id="token-2-16" morph="none" pos="word" start_char="276">of</TOKEN>
<TOKEN end_char="281" id="token-2-17" morph="none" pos="word" start_char="279">the</TOKEN>
<TOKEN end_char="287" id="token-2-18" morph="none" pos="word" start_char="283">virus</TOKEN>
<TOKEN end_char="288" id="token-2-19" morph="none" pos="punct" start_char="288">,</TOKEN>
<TOKEN end_char="292" id="token-2-20" morph="none" pos="word" start_char="290">but</TOKEN>
<TOKEN end_char="300" id="token-2-21" morph="none" pos="word" start_char="294">experts</TOKEN>
<TOKEN end_char="304" id="token-2-22" morph="none" pos="word" start_char="302">say</TOKEN>
<TOKEN end_char="309" id="token-2-23" morph="none" pos="word" start_char="306">they</TOKEN>
<TOKEN end_char="317" id="token-2-24" morph="none" pos="word" start_char="311">believe</TOKEN>
<TOKEN end_char="321" id="token-2-25" morph="none" pos="word" start_char="319">the</TOKEN>
<TOKEN end_char="326" id="token-2-26" morph="none" pos="word" start_char="323">risk</TOKEN>
<TOKEN end_char="329" id="token-2-27" morph="none" pos="word" start_char="328">of</TOKEN>
<TOKEN end_char="340" id="token-2-28" morph="none" pos="word" start_char="331">developing</TOKEN>
<TOKEN end_char="349" id="token-2-29" morph="none" pos="unknown" start_char="342">COVID-19</TOKEN>
<TOKEN end_char="354" id="token-2-30" morph="none" pos="word" start_char="351">from</TOKEN>
<TOKEN end_char="363" id="token-2-31" morph="none" pos="word" start_char="356">handling</TOKEN>
<TOKEN end_char="369" id="token-2-32" morph="none" pos="word" start_char="365">these</TOKEN>
<TOKEN end_char="378" id="token-2-33" morph="none" pos="word" start_char="371">products</TOKEN>
<TOKEN end_char="386" id="token-2-34" morph="none" pos="word" start_char="380">remains</TOKEN>
<TOKEN end_char="396" id="token-2-35" morph="none" pos="word" start_char="388">extremely</TOKEN>
<TOKEN end_char="400" id="token-2-36" morph="none" pos="word" start_char="398">low</TOKEN>
<TOKEN end_char="401" id="token-2-37" morph="none" pos="punct" start_char="401">.</TOKEN>
</SEG>
<SEG end_char="586" id="segment-3" start_char="404">
<ORIGINAL_TEXT>"The number of virus particles coming out a person’s mouth or nose is far greater than a few virus particles remaining on frozen foods, somebody touching it and then spreading it," T.</ORIGINAL_TEXT>
<TOKEN end_char="404" id="token-3-0" morph="none" pos="punct" start_char="404">"</TOKEN>
<TOKEN end_char="407" id="token-3-1" morph="none" pos="word" start_char="405">The</TOKEN>
<TOKEN end_char="414" id="token-3-2" morph="none" pos="word" start_char="409">number</TOKEN>
<TOKEN end_char="417" id="token-3-3" morph="none" pos="word" start_char="416">of</TOKEN>
<TOKEN end_char="423" id="token-3-4" morph="none" pos="word" start_char="419">virus</TOKEN>
<TOKEN end_char="433" id="token-3-5" morph="none" pos="word" start_char="425">particles</TOKEN>
<TOKEN end_char="440" id="token-3-6" morph="none" pos="word" start_char="435">coming</TOKEN>
<TOKEN end_char="444" id="token-3-7" morph="none" pos="word" start_char="442">out</TOKEN>
<TOKEN end_char="446" id="token-3-8" morph="none" pos="word" start_char="446">a</TOKEN>
<TOKEN end_char="455" id="token-3-9" morph="none" pos="word" start_char="448">person’s</TOKEN>
<TOKEN end_char="461" id="token-3-10" morph="none" pos="word" start_char="457">mouth</TOKEN>
<TOKEN end_char="464" id="token-3-11" morph="none" pos="word" start_char="463">or</TOKEN>
<TOKEN end_char="469" id="token-3-12" morph="none" pos="word" start_char="466">nose</TOKEN>
<TOKEN end_char="472" id="token-3-13" morph="none" pos="word" start_char="471">is</TOKEN>
<TOKEN end_char="476" id="token-3-14" morph="none" pos="word" start_char="474">far</TOKEN>
<TOKEN end_char="484" id="token-3-15" morph="none" pos="word" start_char="478">greater</TOKEN>
<TOKEN end_char="489" id="token-3-16" morph="none" pos="word" start_char="486">than</TOKEN>
<TOKEN end_char="491" id="token-3-17" morph="none" pos="word" start_char="491">a</TOKEN>
<TOKEN end_char="495" id="token-3-18" morph="none" pos="word" start_char="493">few</TOKEN>
<TOKEN end_char="501" id="token-3-19" morph="none" pos="word" start_char="497">virus</TOKEN>
<TOKEN end_char="511" id="token-3-20" morph="none" pos="word" start_char="503">particles</TOKEN>
<TOKEN end_char="521" id="token-3-21" morph="none" pos="word" start_char="513">remaining</TOKEN>
<TOKEN end_char="524" id="token-3-22" morph="none" pos="word" start_char="523">on</TOKEN>
<TOKEN end_char="531" id="token-3-23" morph="none" pos="word" start_char="526">frozen</TOKEN>
<TOKEN end_char="537" id="token-3-24" morph="none" pos="word" start_char="533">foods</TOKEN>
<TOKEN end_char="538" id="token-3-25" morph="none" pos="punct" start_char="538">,</TOKEN>
<TOKEN end_char="547" id="token-3-26" morph="none" pos="word" start_char="540">somebody</TOKEN>
<TOKEN end_char="556" id="token-3-27" morph="none" pos="word" start_char="549">touching</TOKEN>
<TOKEN end_char="559" id="token-3-28" morph="none" pos="word" start_char="558">it</TOKEN>
<TOKEN end_char="563" id="token-3-29" morph="none" pos="word" start_char="561">and</TOKEN>
<TOKEN end_char="568" id="token-3-30" morph="none" pos="word" start_char="565">then</TOKEN>
<TOKEN end_char="578" id="token-3-31" morph="none" pos="word" start_char="570">spreading</TOKEN>
<TOKEN end_char="581" id="token-3-32" morph="none" pos="word" start_char="580">it</TOKEN>
<TOKEN end_char="583" id="token-3-33" morph="none" pos="punct" start_char="582">,"</TOKEN>
<TOKEN end_char="585" id="token-3-34" morph="none" pos="word" start_char="585">T</TOKEN>
<TOKEN end_char="586" id="token-3-35" morph="none" pos="punct" start_char="586">.</TOKEN>
</SEG>
<SEG end_char="664" id="segment-4" start_char="588">
<ORIGINAL_TEXT>Jacob John, a retired virologist at Christian Medical College, tells Reuters.</ORIGINAL_TEXT>
<TOKEN end_char="592" id="token-4-0" morph="none" pos="word" start_char="588">Jacob</TOKEN>
<TOKEN end_char="597" id="token-4-1" morph="none" pos="word" start_char="594">John</TOKEN>
<TOKEN end_char="598" id="token-4-2" morph="none" pos="punct" start_char="598">,</TOKEN>
<TOKEN end_char="600" id="token-4-3" morph="none" pos="word" start_char="600">a</TOKEN>
<TOKEN end_char="608" id="token-4-4" morph="none" pos="word" start_char="602">retired</TOKEN>
<TOKEN end_char="619" id="token-4-5" morph="none" pos="word" start_char="610">virologist</TOKEN>
<TOKEN end_char="622" id="token-4-6" morph="none" pos="word" start_char="621">at</TOKEN>
<TOKEN end_char="632" id="token-4-7" morph="none" pos="word" start_char="624">Christian</TOKEN>
<TOKEN end_char="640" id="token-4-8" morph="none" pos="word" start_char="634">Medical</TOKEN>
<TOKEN end_char="648" id="token-4-9" morph="none" pos="word" start_char="642">College</TOKEN>
<TOKEN end_char="649" id="token-4-10" morph="none" pos="punct" start_char="649">,</TOKEN>
<TOKEN end_char="655" id="token-4-11" morph="none" pos="word" start_char="651">tells</TOKEN>
<TOKEN end_char="663" id="token-4-12" morph="none" pos="word" start_char="657">Reuters</TOKEN>
<TOKEN end_char="664" id="token-4-13" morph="none" pos="punct" start_char="664">.</TOKEN>
</SEG>
<SEG end_char="721" id="segment-5" start_char="666">
<ORIGINAL_TEXT>"Among all the risks, I think these are very low risks."</ORIGINAL_TEXT>
<TOKEN end_char="666" id="token-5-0" morph="none" pos="punct" start_char="666">"</TOKEN>
<TOKEN end_char="671" id="token-5-1" morph="none" pos="word" start_char="667">Among</TOKEN>
<TOKEN end_char="675" id="token-5-2" morph="none" pos="word" start_char="673">all</TOKEN>
<TOKEN end_char="679" id="token-5-3" morph="none" pos="word" start_char="677">the</TOKEN>
<TOKEN end_char="685" id="token-5-4" morph="none" pos="word" start_char="681">risks</TOKEN>
<TOKEN end_char="686" id="token-5-5" morph="none" pos="punct" start_char="686">,</TOKEN>
<TOKEN end_char="688" id="token-5-6" morph="none" pos="word" start_char="688">I</TOKEN>
<TOKEN end_char="694" id="token-5-7" morph="none" pos="word" start_char="690">think</TOKEN>
<TOKEN end_char="700" id="token-5-8" morph="none" pos="word" start_char="696">these</TOKEN>
<TOKEN end_char="704" id="token-5-9" morph="none" pos="word" start_char="702">are</TOKEN>
<TOKEN end_char="709" id="token-5-10" morph="none" pos="word" start_char="706">very</TOKEN>
<TOKEN end_char="713" id="token-5-11" morph="none" pos="word" start_char="711">low</TOKEN>
<TOKEN end_char="719" id="token-5-12" morph="none" pos="word" start_char="715">risks</TOKEN>
<TOKEN end_char="721" id="token-5-13" morph="none" pos="punct" start_char="720">."</TOKEN>
</SEG>
<SEG end_char="797" id="segment-6" start_char="724">
<ORIGINAL_TEXT>China has reported the most cases of packaging contamination, according to</ORIGINAL_TEXT>
<TOKEN end_char="728" id="token-6-0" morph="none" pos="word" start_char="724">China</TOKEN>
<TOKEN end_char="732" id="token-6-1" morph="none" pos="word" start_char="730">has</TOKEN>
<TOKEN end_char="741" id="token-6-2" morph="none" pos="word" start_char="734">reported</TOKEN>
<TOKEN end_char="745" id="token-6-3" morph="none" pos="word" start_char="743">the</TOKEN>
<TOKEN end_char="750" id="token-6-4" morph="none" pos="word" start_char="747">most</TOKEN>
<TOKEN end_char="756" id="token-6-5" morph="none" pos="word" start_char="752">cases</TOKEN>
<TOKEN end_char="759" id="token-6-6" morph="none" pos="word" start_char="758">of</TOKEN>
<TOKEN end_char="769" id="token-6-7" morph="none" pos="word" start_char="761">packaging</TOKEN>
<TOKEN end_char="783" id="token-6-8" morph="none" pos="word" start_char="771">contamination</TOKEN>
<TOKEN end_char="784" id="token-6-9" morph="none" pos="punct" start_char="784">,</TOKEN>
<TOKEN end_char="794" id="token-6-10" morph="none" pos="word" start_char="786">according</TOKEN>
<TOKEN end_char="797" id="token-6-11" morph="none" pos="word" start_char="796">to</TOKEN>
</SEG>
<SEG end_char="807" id="segment-7" start_char="800">
<ORIGINAL_TEXT>NBC News</ORIGINAL_TEXT>
<TOKEN end_char="802" id="token-7-0" morph="none" pos="word" start_char="800">NBC</TOKEN>
<TOKEN end_char="807" id="token-7-1" morph="none" pos="word" start_char="804">News</TOKEN>
</SEG>
<SEG end_char="897" id="segment-8" start_char="810">
<ORIGINAL_TEXT>, due in part to a massive screening effort targeting imported goods across the country.</ORIGINAL_TEXT>
<TOKEN end_char="810" id="token-8-0" morph="none" pos="punct" start_char="810">,</TOKEN>
<TOKEN end_char="814" id="token-8-1" morph="none" pos="word" start_char="812">due</TOKEN>
<TOKEN end_char="817" id="token-8-2" morph="none" pos="word" start_char="816">in</TOKEN>
<TOKEN end_char="822" id="token-8-3" morph="none" pos="word" start_char="819">part</TOKEN>
<TOKEN end_char="825" id="token-8-4" morph="none" pos="word" start_char="824">to</TOKEN>
<TOKEN end_char="827" id="token-8-5" morph="none" pos="word" start_char="827">a</TOKEN>
<TOKEN end_char="835" id="token-8-6" morph="none" pos="word" start_char="829">massive</TOKEN>
<TOKEN end_char="845" id="token-8-7" morph="none" pos="word" start_char="837">screening</TOKEN>
<TOKEN end_char="852" id="token-8-8" morph="none" pos="word" start_char="847">effort</TOKEN>
<TOKEN end_char="862" id="token-8-9" morph="none" pos="word" start_char="854">targeting</TOKEN>
<TOKEN end_char="871" id="token-8-10" morph="none" pos="word" start_char="864">imported</TOKEN>
<TOKEN end_char="877" id="token-8-11" morph="none" pos="word" start_char="873">goods</TOKEN>
<TOKEN end_char="884" id="token-8-12" morph="none" pos="word" start_char="879">across</TOKEN>
<TOKEN end_char="888" id="token-8-13" morph="none" pos="word" start_char="886">the</TOKEN>
<TOKEN end_char="896" id="token-8-14" morph="none" pos="word" start_char="890">country</TOKEN>
<TOKEN end_char="897" id="token-8-15" morph="none" pos="punct" start_char="897">.</TOKEN>
</SEG>
<SEG end_char="1041" id="segment-9" start_char="899">
<ORIGINAL_TEXT>Last month, Chinese health officials found traces of the coronavirus on frozen goods imported into the cities of Dalian, Xiamen, and Pingxiang.</ORIGINAL_TEXT>
<TOKEN end_char="902" id="token-9-0" morph="none" pos="word" start_char="899">Last</TOKEN>
<TOKEN end_char="908" id="token-9-1" morph="none" pos="word" start_char="904">month</TOKEN>
<TOKEN end_char="909" id="token-9-2" morph="none" pos="punct" start_char="909">,</TOKEN>
<TOKEN end_char="917" id="token-9-3" morph="none" pos="word" start_char="911">Chinese</TOKEN>
<TOKEN end_char="924" id="token-9-4" morph="none" pos="word" start_char="919">health</TOKEN>
<TOKEN end_char="934" id="token-9-5" morph="none" pos="word" start_char="926">officials</TOKEN>
<TOKEN end_char="940" id="token-9-6" morph="none" pos="word" start_char="936">found</TOKEN>
<TOKEN end_char="947" id="token-9-7" morph="none" pos="word" start_char="942">traces</TOKEN>
<TOKEN end_char="950" id="token-9-8" morph="none" pos="word" start_char="949">of</TOKEN>
<TOKEN end_char="954" id="token-9-9" morph="none" pos="word" start_char="952">the</TOKEN>
<TOKEN end_char="966" id="token-9-10" morph="none" pos="word" start_char="956">coronavirus</TOKEN>
<TOKEN end_char="969" id="token-9-11" morph="none" pos="word" start_char="968">on</TOKEN>
<TOKEN end_char="976" id="token-9-12" morph="none" pos="word" start_char="971">frozen</TOKEN>
<TOKEN end_char="982" id="token-9-13" morph="none" pos="word" start_char="978">goods</TOKEN>
<TOKEN end_char="991" id="token-9-14" morph="none" pos="word" start_char="984">imported</TOKEN>
<TOKEN end_char="996" id="token-9-15" morph="none" pos="word" start_char="993">into</TOKEN>
<TOKEN end_char="1000" id="token-9-16" morph="none" pos="word" start_char="998">the</TOKEN>
<TOKEN end_char="1007" id="token-9-17" morph="none" pos="word" start_char="1002">cities</TOKEN>
<TOKEN end_char="1010" id="token-9-18" morph="none" pos="word" start_char="1009">of</TOKEN>
<TOKEN end_char="1017" id="token-9-19" morph="none" pos="word" start_char="1012">Dalian</TOKEN>
<TOKEN end_char="1018" id="token-9-20" morph="none" pos="punct" start_char="1018">,</TOKEN>
<TOKEN end_char="1025" id="token-9-21" morph="none" pos="word" start_char="1020">Xiamen</TOKEN>
<TOKEN end_char="1026" id="token-9-22" morph="none" pos="punct" start_char="1026">,</TOKEN>
<TOKEN end_char="1030" id="token-9-23" morph="none" pos="word" start_char="1028">and</TOKEN>
<TOKEN end_char="1040" id="token-9-24" morph="none" pos="word" start_char="1032">Pingxiang</TOKEN>
<TOKEN end_char="1041" id="token-9-25" morph="none" pos="punct" start_char="1041">.</TOKEN>
</SEG>
<SEG end_char="1290" id="segment-10" start_char="1043">
<ORIGINAL_TEXT>In the last four days, similar findings have been reported in Wuhu and Shenzhen, linked to frozen shrimp and chicken wings imported from Ecuador and Brazil, respectively, and to frozen seafood of unnamed origins arriving in the port city of Yantai.</ORIGINAL_TEXT>
<TOKEN end_char="1044" id="token-10-0" morph="none" pos="word" start_char="1043">In</TOKEN>
<TOKEN end_char="1048" id="token-10-1" morph="none" pos="word" start_char="1046">the</TOKEN>
<TOKEN end_char="1053" id="token-10-2" morph="none" pos="word" start_char="1050">last</TOKEN>
<TOKEN end_char="1058" id="token-10-3" morph="none" pos="word" start_char="1055">four</TOKEN>
<TOKEN end_char="1063" id="token-10-4" morph="none" pos="word" start_char="1060">days</TOKEN>
<TOKEN end_char="1064" id="token-10-5" morph="none" pos="punct" start_char="1064">,</TOKEN>
<TOKEN end_char="1072" id="token-10-6" morph="none" pos="word" start_char="1066">similar</TOKEN>
<TOKEN end_char="1081" id="token-10-7" morph="none" pos="word" start_char="1074">findings</TOKEN>
<TOKEN end_char="1086" id="token-10-8" morph="none" pos="word" start_char="1083">have</TOKEN>
<TOKEN end_char="1091" id="token-10-9" morph="none" pos="word" start_char="1088">been</TOKEN>
<TOKEN end_char="1100" id="token-10-10" morph="none" pos="word" start_char="1093">reported</TOKEN>
<TOKEN end_char="1103" id="token-10-11" morph="none" pos="word" start_char="1102">in</TOKEN>
<TOKEN end_char="1108" id="token-10-12" morph="none" pos="word" start_char="1105">Wuhu</TOKEN>
<TOKEN end_char="1112" id="token-10-13" morph="none" pos="word" start_char="1110">and</TOKEN>
<TOKEN end_char="1121" id="token-10-14" morph="none" pos="word" start_char="1114">Shenzhen</TOKEN>
<TOKEN end_char="1122" id="token-10-15" morph="none" pos="punct" start_char="1122">,</TOKEN>
<TOKEN end_char="1129" id="token-10-16" morph="none" pos="word" start_char="1124">linked</TOKEN>
<TOKEN end_char="1132" id="token-10-17" morph="none" pos="word" start_char="1131">to</TOKEN>
<TOKEN end_char="1139" id="token-10-18" morph="none" pos="word" start_char="1134">frozen</TOKEN>
<TOKEN end_char="1146" id="token-10-19" morph="none" pos="word" start_char="1141">shrimp</TOKEN>
<TOKEN end_char="1150" id="token-10-20" morph="none" pos="word" start_char="1148">and</TOKEN>
<TOKEN end_char="1158" id="token-10-21" morph="none" pos="word" start_char="1152">chicken</TOKEN>
<TOKEN end_char="1164" id="token-10-22" morph="none" pos="word" start_char="1160">wings</TOKEN>
<TOKEN end_char="1173" id="token-10-23" morph="none" pos="word" start_char="1166">imported</TOKEN>
<TOKEN end_char="1178" id="token-10-24" morph="none" pos="word" start_char="1175">from</TOKEN>
<TOKEN end_char="1186" id="token-10-25" morph="none" pos="word" start_char="1180">Ecuador</TOKEN>
<TOKEN end_char="1190" id="token-10-26" morph="none" pos="word" start_char="1188">and</TOKEN>
<TOKEN end_char="1197" id="token-10-27" morph="none" pos="word" start_char="1192">Brazil</TOKEN>
<TOKEN end_char="1198" id="token-10-28" morph="none" pos="punct" start_char="1198">,</TOKEN>
<TOKEN end_char="1211" id="token-10-29" morph="none" pos="word" start_char="1200">respectively</TOKEN>
<TOKEN end_char="1212" id="token-10-30" morph="none" pos="punct" start_char="1212">,</TOKEN>
<TOKEN end_char="1216" id="token-10-31" morph="none" pos="word" start_char="1214">and</TOKEN>
<TOKEN end_char="1219" id="token-10-32" morph="none" pos="word" start_char="1218">to</TOKEN>
<TOKEN end_char="1226" id="token-10-33" morph="none" pos="word" start_char="1221">frozen</TOKEN>
<TOKEN end_char="1234" id="token-10-34" morph="none" pos="word" start_char="1228">seafood</TOKEN>
<TOKEN end_char="1237" id="token-10-35" morph="none" pos="word" start_char="1236">of</TOKEN>
<TOKEN end_char="1245" id="token-10-36" morph="none" pos="word" start_char="1239">unnamed</TOKEN>
<TOKEN end_char="1253" id="token-10-37" morph="none" pos="word" start_char="1247">origins</TOKEN>
<TOKEN end_char="1262" id="token-10-38" morph="none" pos="word" start_char="1255">arriving</TOKEN>
<TOKEN end_char="1265" id="token-10-39" morph="none" pos="word" start_char="1264">in</TOKEN>
<TOKEN end_char="1269" id="token-10-40" morph="none" pos="word" start_char="1267">the</TOKEN>
<TOKEN end_char="1274" id="token-10-41" morph="none" pos="word" start_char="1271">port</TOKEN>
<TOKEN end_char="1279" id="token-10-42" morph="none" pos="word" start_char="1276">city</TOKEN>
<TOKEN end_char="1282" id="token-10-43" morph="none" pos="word" start_char="1281">of</TOKEN>
<TOKEN end_char="1289" id="token-10-44" morph="none" pos="word" start_char="1284">Yantai</TOKEN>
<TOKEN end_char="1290" id="token-10-45" morph="none" pos="punct" start_char="1290">.</TOKEN>
</SEG>
<SEG end_char="1474" id="segment-11" start_char="1293">
<ORIGINAL_TEXT>After New Zealand reported its first new cases of COVID-19 in more than three months, contact tracing revealed that one of the infected people worked in an import receiving facility,</ORIGINAL_TEXT>
<TOKEN end_char="1297" id="token-11-0" morph="none" pos="word" start_char="1293">After</TOKEN>
<TOKEN end_char="1301" id="token-11-1" morph="none" pos="word" start_char="1299">New</TOKEN>
<TOKEN end_char="1309" id="token-11-2" morph="none" pos="word" start_char="1303">Zealand</TOKEN>
<TOKEN end_char="1318" id="token-11-3" morph="none" pos="word" start_char="1311">reported</TOKEN>
<TOKEN end_char="1322" id="token-11-4" morph="none" pos="word" start_char="1320">its</TOKEN>
<TOKEN end_char="1328" id="token-11-5" morph="none" pos="word" start_char="1324">first</TOKEN>
<TOKEN end_char="1332" id="token-11-6" morph="none" pos="word" start_char="1330">new</TOKEN>
<TOKEN end_char="1338" id="token-11-7" morph="none" pos="word" start_char="1334">cases</TOKEN>
<TOKEN end_char="1341" id="token-11-8" morph="none" pos="word" start_char="1340">of</TOKEN>
<TOKEN end_char="1350" id="token-11-9" morph="none" pos="unknown" start_char="1343">COVID-19</TOKEN>
<TOKEN end_char="1353" id="token-11-10" morph="none" pos="word" start_char="1352">in</TOKEN>
<TOKEN end_char="1358" id="token-11-11" morph="none" pos="word" start_char="1355">more</TOKEN>
<TOKEN end_char="1363" id="token-11-12" morph="none" pos="word" start_char="1360">than</TOKEN>
<TOKEN end_char="1369" id="token-11-13" morph="none" pos="word" start_char="1365">three</TOKEN>
<TOKEN end_char="1376" id="token-11-14" morph="none" pos="word" start_char="1371">months</TOKEN>
<TOKEN end_char="1377" id="token-11-15" morph="none" pos="punct" start_char="1377">,</TOKEN>
<TOKEN end_char="1385" id="token-11-16" morph="none" pos="word" start_char="1379">contact</TOKEN>
<TOKEN end_char="1393" id="token-11-17" morph="none" pos="word" start_char="1387">tracing</TOKEN>
<TOKEN end_char="1402" id="token-11-18" morph="none" pos="word" start_char="1395">revealed</TOKEN>
<TOKEN end_char="1407" id="token-11-19" morph="none" pos="word" start_char="1404">that</TOKEN>
<TOKEN end_char="1411" id="token-11-20" morph="none" pos="word" start_char="1409">one</TOKEN>
<TOKEN end_char="1414" id="token-11-21" morph="none" pos="word" start_char="1413">of</TOKEN>
<TOKEN end_char="1418" id="token-11-22" morph="none" pos="word" start_char="1416">the</TOKEN>
<TOKEN end_char="1427" id="token-11-23" morph="none" pos="word" start_char="1420">infected</TOKEN>
<TOKEN end_char="1434" id="token-11-24" morph="none" pos="word" start_char="1429">people</TOKEN>
<TOKEN end_char="1441" id="token-11-25" morph="none" pos="word" start_char="1436">worked</TOKEN>
<TOKEN end_char="1444" id="token-11-26" morph="none" pos="word" start_char="1443">in</TOKEN>
<TOKEN end_char="1447" id="token-11-27" morph="none" pos="word" start_char="1446">an</TOKEN>
<TOKEN end_char="1454" id="token-11-28" morph="none" pos="word" start_char="1449">import</TOKEN>
<TOKEN end_char="1464" id="token-11-29" morph="none" pos="word" start_char="1456">receiving</TOKEN>
<TOKEN end_char="1473" id="token-11-30" morph="none" pos="word" start_char="1466">facility</TOKEN>
<TOKEN end_char="1474" id="token-11-31" morph="none" pos="punct" start_char="1474">,</TOKEN>
</SEG>
<SEG end_char="1488" id="segment-12" start_char="1477">
<ORIGINAL_TEXT>The Guardian</ORIGINAL_TEXT>
<TOKEN end_char="1479" id="token-12-0" morph="none" pos="word" start_char="1477">The</TOKEN>
<TOKEN end_char="1488" id="token-12-1" morph="none" pos="word" start_char="1481">Guardian</TOKEN>
</SEG>
<SEG end_char="1498" id="segment-13" start_char="1491">
<ORIGINAL_TEXT>reports.</ORIGINAL_TEXT>
<TOKEN end_char="1497" id="token-13-0" morph="none" pos="word" start_char="1491">reports</TOKEN>
<TOKEN end_char="1498" id="token-13-1" morph="none" pos="punct" start_char="1498">.</TOKEN>
<TRANSLATED_TEXT>relazioni.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="1610" id="segment-14" start_char="1500">
<ORIGINAL_TEXT>As a result, public officials are considering the possibility that the virus arrived in the country on freight.</ORIGINAL_TEXT>
<TOKEN end_char="1501" id="token-14-0" morph="none" pos="word" start_char="1500">As</TOKEN>
<TOKEN end_char="1503" id="token-14-1" morph="none" pos="word" start_char="1503">a</TOKEN>
<TOKEN end_char="1510" id="token-14-2" morph="none" pos="word" start_char="1505">result</TOKEN>
<TOKEN end_char="1511" id="token-14-3" morph="none" pos="punct" start_char="1511">,</TOKEN>
<TOKEN end_char="1518" id="token-14-4" morph="none" pos="word" start_char="1513">public</TOKEN>
<TOKEN end_char="1528" id="token-14-5" morph="none" pos="word" start_char="1520">officials</TOKEN>
<TOKEN end_char="1532" id="token-14-6" morph="none" pos="word" start_char="1530">are</TOKEN>
<TOKEN end_char="1544" id="token-14-7" morph="none" pos="word" start_char="1534">considering</TOKEN>
<TOKEN end_char="1548" id="token-14-8" morph="none" pos="word" start_char="1546">the</TOKEN>
<TOKEN end_char="1560" id="token-14-9" morph="none" pos="word" start_char="1550">possibility</TOKEN>
<TOKEN end_char="1565" id="token-14-10" morph="none" pos="word" start_char="1562">that</TOKEN>
<TOKEN end_char="1569" id="token-14-11" morph="none" pos="word" start_char="1567">the</TOKEN>
<TOKEN end_char="1575" id="token-14-12" morph="none" pos="word" start_char="1571">virus</TOKEN>
<TOKEN end_char="1583" id="token-14-13" morph="none" pos="word" start_char="1577">arrived</TOKEN>
<TOKEN end_char="1586" id="token-14-14" morph="none" pos="word" start_char="1585">in</TOKEN>
<TOKEN end_char="1590" id="token-14-15" morph="none" pos="word" start_char="1588">the</TOKEN>
<TOKEN end_char="1598" id="token-14-16" morph="none" pos="word" start_char="1592">country</TOKEN>
<TOKEN end_char="1601" id="token-14-17" morph="none" pos="word" start_char="1600">on</TOKEN>
<TOKEN end_char="1609" id="token-14-18" morph="none" pos="word" start_char="1603">freight</TOKEN>
<TOKEN end_char="1610" id="token-14-19" morph="none" pos="punct" start_char="1610">.</TOKEN>
</SEG>
<SEG end_char="1665" id="segment-15" start_char="1612">
<ORIGINAL_TEXT>The facility is currently being tested to rule it out.</ORIGINAL_TEXT>
<TOKEN end_char="1614" id="token-15-0" morph="none" pos="word" start_char="1612">The</TOKEN>
<TOKEN end_char="1623" id="token-15-1" morph="none" pos="word" start_char="1616">facility</TOKEN>
<TOKEN end_char="1626" id="token-15-2" morph="none" pos="word" start_char="1625">is</TOKEN>
<TOKEN end_char="1636" id="token-15-3" morph="none" pos="word" start_char="1628">currently</TOKEN>
<TOKEN end_char="1642" id="token-15-4" morph="none" pos="word" start_char="1638">being</TOKEN>
<TOKEN end_char="1649" id="token-15-5" morph="none" pos="word" start_char="1644">tested</TOKEN>
<TOKEN end_char="1652" id="token-15-6" morph="none" pos="word" start_char="1651">to</TOKEN>
<TOKEN end_char="1657" id="token-15-7" morph="none" pos="word" start_char="1654">rule</TOKEN>
<TOKEN end_char="1660" id="token-15-8" morph="none" pos="word" start_char="1659">it</TOKEN>
<TOKEN end_char="1664" id="token-15-9" morph="none" pos="word" start_char="1662">out</TOKEN>
<TOKEN end_char="1665" id="token-15-10" morph="none" pos="punct" start_char="1665">.</TOKEN>
</SEG>
<SEG end_char="1779" id="segment-16" start_char="1667">
<ORIGINAL_TEXT>"We can see the seriousness of the situation we are in," Prime Minister Jacinda Ardern said in a news conference.</ORIGINAL_TEXT>
<TOKEN end_char="1667" id="token-16-0" morph="none" pos="punct" start_char="1667">"</TOKEN>
<TOKEN end_char="1669" id="token-16-1" morph="none" pos="word" start_char="1668">We</TOKEN>
<TOKEN end_char="1673" id="token-16-2" morph="none" pos="word" start_char="1671">can</TOKEN>
<TOKEN end_char="1677" id="token-16-3" morph="none" pos="word" start_char="1675">see</TOKEN>
<TOKEN end_char="1681" id="token-16-4" morph="none" pos="word" start_char="1679">the</TOKEN>
<TOKEN end_char="1693" id="token-16-5" morph="none" pos="word" start_char="1683">seriousness</TOKEN>
<TOKEN end_char="1696" id="token-16-6" morph="none" pos="word" start_char="1695">of</TOKEN>
<TOKEN end_char="1700" id="token-16-7" morph="none" pos="word" start_char="1698">the</TOKEN>
<TOKEN end_char="1710" id="token-16-8" morph="none" pos="word" start_char="1702">situation</TOKEN>
<TOKEN end_char="1713" id="token-16-9" morph="none" pos="word" start_char="1712">we</TOKEN>
<TOKEN end_char="1717" id="token-16-10" morph="none" pos="word" start_char="1715">are</TOKEN>
<TOKEN end_char="1720" id="token-16-11" morph="none" pos="word" start_char="1719">in</TOKEN>
<TOKEN end_char="1722" id="token-16-12" morph="none" pos="punct" start_char="1721">,"</TOKEN>
<TOKEN end_char="1728" id="token-16-13" morph="none" pos="word" start_char="1724">Prime</TOKEN>
<TOKEN end_char="1737" id="token-16-14" morph="none" pos="word" start_char="1730">Minister</TOKEN>
<TOKEN end_char="1745" id="token-16-15" morph="none" pos="word" start_char="1739">Jacinda</TOKEN>
<TOKEN end_char="1752" id="token-16-16" morph="none" pos="word" start_char="1747">Ardern</TOKEN>
<TOKEN end_char="1757" id="token-16-17" morph="none" pos="word" start_char="1754">said</TOKEN>
<TOKEN end_char="1760" id="token-16-18" morph="none" pos="word" start_char="1759">in</TOKEN>
<TOKEN end_char="1762" id="token-16-19" morph="none" pos="word" start_char="1762">a</TOKEN>
<TOKEN end_char="1767" id="token-16-20" morph="none" pos="word" start_char="1764">news</TOKEN>
<TOKEN end_char="1778" id="token-16-21" morph="none" pos="word" start_char="1769">conference</TOKEN>
<TOKEN end_char="1779" id="token-16-22" morph="none" pos="punct" start_char="1779">.</TOKEN>
</SEG>
<SEG end_char="1845" id="segment-17" start_char="1781">
<ORIGINAL_TEXT>"It’s being dealt with in an urgent but calm and methodical way."</ORIGINAL_TEXT>
<TOKEN end_char="1781" id="token-17-0" morph="none" pos="punct" start_char="1781">"</TOKEN>
<TOKEN end_char="1785" id="token-17-1" morph="none" pos="word" start_char="1782">It’s</TOKEN>
<TOKEN end_char="1791" id="token-17-2" morph="none" pos="word" start_char="1787">being</TOKEN>
<TOKEN end_char="1797" id="token-17-3" morph="none" pos="word" start_char="1793">dealt</TOKEN>
<TOKEN end_char="1802" id="token-17-4" morph="none" pos="word" start_char="1799">with</TOKEN>
<TOKEN end_char="1805" id="token-17-5" morph="none" pos="word" start_char="1804">in</TOKEN>
<TOKEN end_char="1808" id="token-17-6" morph="none" pos="word" start_char="1807">an</TOKEN>
<TOKEN end_char="1815" id="token-17-7" morph="none" pos="word" start_char="1810">urgent</TOKEN>
<TOKEN end_char="1819" id="token-17-8" morph="none" pos="word" start_char="1817">but</TOKEN>
<TOKEN end_char="1824" id="token-17-9" morph="none" pos="word" start_char="1821">calm</TOKEN>
<TOKEN end_char="1828" id="token-17-10" morph="none" pos="word" start_char="1826">and</TOKEN>
<TOKEN end_char="1839" id="token-17-11" morph="none" pos="word" start_char="1830">methodical</TOKEN>
<TOKEN end_char="1843" id="token-17-12" morph="none" pos="word" start_char="1841">way</TOKEN>
<TOKEN end_char="1845" id="token-17-13" morph="none" pos="punct" start_char="1844">."</TOKEN>
</SEG>
<SEG end_char="1999" id="segment-18" start_char="1848">
<ORIGINAL_TEXT>Previous research has shown that the virus can remain on packaging for hours or even days, depending on the type of material and the ambient conditions.</ORIGINAL_TEXT>
<TOKEN end_char="1855" id="token-18-0" morph="none" pos="word" start_char="1848">Previous</TOKEN>
<TOKEN end_char="1864" id="token-18-1" morph="none" pos="word" start_char="1857">research</TOKEN>
<TOKEN end_char="1868" id="token-18-2" morph="none" pos="word" start_char="1866">has</TOKEN>
<TOKEN end_char="1874" id="token-18-3" morph="none" pos="word" start_char="1870">shown</TOKEN>
<TOKEN end_char="1879" id="token-18-4" morph="none" pos="word" start_char="1876">that</TOKEN>
<TOKEN end_char="1883" id="token-18-5" morph="none" pos="word" start_char="1881">the</TOKEN>
<TOKEN end_char="1889" id="token-18-6" morph="none" pos="word" start_char="1885">virus</TOKEN>
<TOKEN end_char="1893" id="token-18-7" morph="none" pos="word" start_char="1891">can</TOKEN>
<TOKEN end_char="1900" id="token-18-8" morph="none" pos="word" start_char="1895">remain</TOKEN>
<TOKEN end_char="1903" id="token-18-9" morph="none" pos="word" start_char="1902">on</TOKEN>
<TOKEN end_char="1913" id="token-18-10" morph="none" pos="word" start_char="1905">packaging</TOKEN>
<TOKEN end_char="1917" id="token-18-11" morph="none" pos="word" start_char="1915">for</TOKEN>
<TOKEN end_char="1923" id="token-18-12" morph="none" pos="word" start_char="1919">hours</TOKEN>
<TOKEN end_char="1926" id="token-18-13" morph="none" pos="word" start_char="1925">or</TOKEN>
<TOKEN end_char="1931" id="token-18-14" morph="none" pos="word" start_char="1928">even</TOKEN>
<TOKEN end_char="1936" id="token-18-15" morph="none" pos="word" start_char="1933">days</TOKEN>
<TOKEN end_char="1937" id="token-18-16" morph="none" pos="punct" start_char="1937">,</TOKEN>
<TOKEN end_char="1947" id="token-18-17" morph="none" pos="word" start_char="1939">depending</TOKEN>
<TOKEN end_char="1950" id="token-18-18" morph="none" pos="word" start_char="1949">on</TOKEN>
<TOKEN end_char="1954" id="token-18-19" morph="none" pos="word" start_char="1952">the</TOKEN>
<TOKEN end_char="1959" id="token-18-20" morph="none" pos="word" start_char="1956">type</TOKEN>
<TOKEN end_char="1962" id="token-18-21" morph="none" pos="word" start_char="1961">of</TOKEN>
<TOKEN end_char="1971" id="token-18-22" morph="none" pos="word" start_char="1964">material</TOKEN>
<TOKEN end_char="1975" id="token-18-23" morph="none" pos="word" start_char="1973">and</TOKEN>
<TOKEN end_char="1979" id="token-18-24" morph="none" pos="word" start_char="1977">the</TOKEN>
<TOKEN end_char="1987" id="token-18-25" morph="none" pos="word" start_char="1981">ambient</TOKEN>
<TOKEN end_char="1998" id="token-18-26" morph="none" pos="word" start_char="1989">conditions</TOKEN>
<TOKEN end_char="1999" id="token-18-27" morph="none" pos="punct" start_char="1999">.</TOKEN>
</SEG>
<SEG end_char="2185" id="segment-19" start_char="2001">
<ORIGINAL_TEXT>For paper and plastic, the materials related to the most recent reports, that time varies between four to five days, Reuters reports, although other studies have given different ranges.</ORIGINAL_TEXT>
<TOKEN end_char="2003" id="token-19-0" morph="none" pos="word" start_char="2001">For</TOKEN>
<TOKEN end_char="2009" id="token-19-1" morph="none" pos="word" start_char="2005">paper</TOKEN>
<TOKEN end_char="2013" id="token-19-2" morph="none" pos="word" start_char="2011">and</TOKEN>
<TOKEN end_char="2021" id="token-19-3" morph="none" pos="word" start_char="2015">plastic</TOKEN>
<TOKEN end_char="2022" id="token-19-4" morph="none" pos="punct" start_char="2022">,</TOKEN>
<TOKEN end_char="2026" id="token-19-5" morph="none" pos="word" start_char="2024">the</TOKEN>
<TOKEN end_char="2036" id="token-19-6" morph="none" pos="word" start_char="2028">materials</TOKEN>
<TOKEN end_char="2044" id="token-19-7" morph="none" pos="word" start_char="2038">related</TOKEN>
<TOKEN end_char="2047" id="token-19-8" morph="none" pos="word" start_char="2046">to</TOKEN>
<TOKEN end_char="2051" id="token-19-9" morph="none" pos="word" start_char="2049">the</TOKEN>
<TOKEN end_char="2056" id="token-19-10" morph="none" pos="word" start_char="2053">most</TOKEN>
<TOKEN end_char="2063" id="token-19-11" morph="none" pos="word" start_char="2058">recent</TOKEN>
<TOKEN end_char="2071" id="token-19-12" morph="none" pos="word" start_char="2065">reports</TOKEN>
<TOKEN end_char="2072" id="token-19-13" morph="none" pos="punct" start_char="2072">,</TOKEN>
<TOKEN end_char="2077" id="token-19-14" morph="none" pos="word" start_char="2074">that</TOKEN>
<TOKEN end_char="2082" id="token-19-15" morph="none" pos="word" start_char="2079">time</TOKEN>
<TOKEN end_char="2089" id="token-19-16" morph="none" pos="word" start_char="2084">varies</TOKEN>
<TOKEN end_char="2097" id="token-19-17" morph="none" pos="word" start_char="2091">between</TOKEN>
<TOKEN end_char="2102" id="token-19-18" morph="none" pos="word" start_char="2099">four</TOKEN>
<TOKEN end_char="2105" id="token-19-19" morph="none" pos="word" start_char="2104">to</TOKEN>
<TOKEN end_char="2110" id="token-19-20" morph="none" pos="word" start_char="2107">five</TOKEN>
<TOKEN end_char="2115" id="token-19-21" morph="none" pos="word" start_char="2112">days</TOKEN>
<TOKEN end_char="2116" id="token-19-22" morph="none" pos="punct" start_char="2116">,</TOKEN>
<TOKEN end_char="2124" id="token-19-23" morph="none" pos="word" start_char="2118">Reuters</TOKEN>
<TOKEN end_char="2132" id="token-19-24" morph="none" pos="word" start_char="2126">reports</TOKEN>
<TOKEN end_char="2133" id="token-19-25" morph="none" pos="punct" start_char="2133">,</TOKEN>
<TOKEN end_char="2142" id="token-19-26" morph="none" pos="word" start_char="2135">although</TOKEN>
<TOKEN end_char="2148" id="token-19-27" morph="none" pos="word" start_char="2144">other</TOKEN>
<TOKEN end_char="2156" id="token-19-28" morph="none" pos="word" start_char="2150">studies</TOKEN>
<TOKEN end_char="2161" id="token-19-29" morph="none" pos="word" start_char="2158">have</TOKEN>
<TOKEN end_char="2167" id="token-19-30" morph="none" pos="word" start_char="2163">given</TOKEN>
<TOKEN end_char="2177" id="token-19-31" morph="none" pos="word" start_char="2169">different</TOKEN>
<TOKEN end_char="2184" id="token-19-32" morph="none" pos="word" start_char="2179">ranges</TOKEN>
<TOKEN end_char="2185" id="token-19-33" morph="none" pos="punct" start_char="2185">.</TOKEN>
</SEG>
<SEG end_char="2317" id="segment-20" start_char="2187">
<ORIGINAL_TEXT>Among the cases in China and New Zealand, it’s difficult to know just when the virus was introduced onto the contaminated surfaces.</ORIGINAL_TEXT>
<TOKEN end_char="2191" id="token-20-0" morph="none" pos="word" start_char="2187">Among</TOKEN>
<TOKEN end_char="2195" id="token-20-1" morph="none" pos="word" start_char="2193">the</TOKEN>
<TOKEN end_char="2201" id="token-20-2" morph="none" pos="word" start_char="2197">cases</TOKEN>
<TOKEN end_char="2204" id="token-20-3" morph="none" pos="word" start_char="2203">in</TOKEN>
<TOKEN end_char="2210" id="token-20-4" morph="none" pos="word" start_char="2206">China</TOKEN>
<TOKEN end_char="2214" id="token-20-5" morph="none" pos="word" start_char="2212">and</TOKEN>
<TOKEN end_char="2218" id="token-20-6" morph="none" pos="word" start_char="2216">New</TOKEN>
<TOKEN end_char="2226" id="token-20-7" morph="none" pos="word" start_char="2220">Zealand</TOKEN>
<TOKEN end_char="2227" id="token-20-8" morph="none" pos="punct" start_char="2227">,</TOKEN>
<TOKEN end_char="2232" id="token-20-9" morph="none" pos="word" start_char="2229">it’s</TOKEN>
<TOKEN end_char="2242" id="token-20-10" morph="none" pos="word" start_char="2234">difficult</TOKEN>
<TOKEN end_char="2245" id="token-20-11" morph="none" pos="word" start_char="2244">to</TOKEN>
<TOKEN end_char="2250" id="token-20-12" morph="none" pos="word" start_char="2247">know</TOKEN>
<TOKEN end_char="2255" id="token-20-13" morph="none" pos="word" start_char="2252">just</TOKEN>
<TOKEN end_char="2260" id="token-20-14" morph="none" pos="word" start_char="2257">when</TOKEN>
<TOKEN end_char="2264" id="token-20-15" morph="none" pos="word" start_char="2262">the</TOKEN>
<TOKEN end_char="2270" id="token-20-16" morph="none" pos="word" start_char="2266">virus</TOKEN>
<TOKEN end_char="2274" id="token-20-17" morph="none" pos="word" start_char="2272">was</TOKEN>
<TOKEN end_char="2285" id="token-20-18" morph="none" pos="word" start_char="2276">introduced</TOKEN>
<TOKEN end_char="2290" id="token-20-19" morph="none" pos="word" start_char="2287">onto</TOKEN>
<TOKEN end_char="2294" id="token-20-20" morph="none" pos="word" start_char="2292">the</TOKEN>
<TOKEN end_char="2307" id="token-20-21" morph="none" pos="word" start_char="2296">contaminated</TOKEN>
<TOKEN end_char="2316" id="token-20-22" morph="none" pos="word" start_char="2309">surfaces</TOKEN>
<TOKEN end_char="2317" id="token-20-23" morph="none" pos="punct" start_char="2317">.</TOKEN>
</SEG>
<SEG end_char="2380" id="segment-21" start_char="2319">
<ORIGINAL_TEXT>It could have happened at any point along the transport chain.</ORIGINAL_TEXT>
<TOKEN end_char="2320" id="token-21-0" morph="none" pos="word" start_char="2319">It</TOKEN>
<TOKEN end_char="2326" id="token-21-1" morph="none" pos="word" start_char="2322">could</TOKEN>
<TOKEN end_char="2331" id="token-21-2" morph="none" pos="word" start_char="2328">have</TOKEN>
<TOKEN end_char="2340" id="token-21-3" morph="none" pos="word" start_char="2333">happened</TOKEN>
<TOKEN end_char="2343" id="token-21-4" morph="none" pos="word" start_char="2342">at</TOKEN>
<TOKEN end_char="2347" id="token-21-5" morph="none" pos="word" start_char="2345">any</TOKEN>
<TOKEN end_char="2353" id="token-21-6" morph="none" pos="word" start_char="2349">point</TOKEN>
<TOKEN end_char="2359" id="token-21-7" morph="none" pos="word" start_char="2355">along</TOKEN>
<TOKEN end_char="2363" id="token-21-8" morph="none" pos="word" start_char="2361">the</TOKEN>
<TOKEN end_char="2373" id="token-21-9" morph="none" pos="word" start_char="2365">transport</TOKEN>
<TOKEN end_char="2379" id="token-21-10" morph="none" pos="word" start_char="2375">chain</TOKEN>
<TOKEN end_char="2380" id="token-21-11" morph="none" pos="punct" start_char="2380">.</TOKEN>
</SEG>
<SEG end_char="2560" id="segment-22" start_char="2383">
<ORIGINAL_TEXT>Both the World Health Organization (WHO) and the US Centers for Disease Control and Prevention (CDC) dismiss the idea that disease transmission on packaging is a serious concern.</ORIGINAL_TEXT>
<TOKEN end_char="2386" id="token-22-0" morph="none" pos="word" start_char="2383">Both</TOKEN>
<TOKEN end_char="2390" id="token-22-1" morph="none" pos="word" start_char="2388">the</TOKEN>
<TOKEN end_char="2396" id="token-22-2" morph="none" pos="word" start_char="2392">World</TOKEN>
<TOKEN end_char="2403" id="token-22-3" morph="none" pos="word" start_char="2398">Health</TOKEN>
<TOKEN end_char="2416" id="token-22-4" morph="none" pos="word" start_char="2405">Organization</TOKEN>
<TOKEN end_char="2418" id="token-22-5" morph="none" pos="punct" start_char="2418">(</TOKEN>
<TOKEN end_char="2421" id="token-22-6" morph="none" pos="word" start_char="2419">WHO</TOKEN>
<TOKEN end_char="2422" id="token-22-7" morph="none" pos="punct" start_char="2422">)</TOKEN>
<TOKEN end_char="2426" id="token-22-8" morph="none" pos="word" start_char="2424">and</TOKEN>
<TOKEN end_char="2430" id="token-22-9" morph="none" pos="word" start_char="2428">the</TOKEN>
<TOKEN end_char="2433" id="token-22-10" morph="none" pos="word" start_char="2432">US</TOKEN>
<TOKEN end_char="2441" id="token-22-11" morph="none" pos="word" start_char="2435">Centers</TOKEN>
<TOKEN end_char="2445" id="token-22-12" morph="none" pos="word" start_char="2443">for</TOKEN>
<TOKEN end_char="2453" id="token-22-13" morph="none" pos="word" start_char="2447">Disease</TOKEN>
<TOKEN end_char="2461" id="token-22-14" morph="none" pos="word" start_char="2455">Control</TOKEN>
<TOKEN end_char="2465" id="token-22-15" morph="none" pos="word" start_char="2463">and</TOKEN>
<TOKEN end_char="2476" id="token-22-16" morph="none" pos="word" start_char="2467">Prevention</TOKEN>
<TOKEN end_char="2478" id="token-22-17" morph="none" pos="punct" start_char="2478">(</TOKEN>
<TOKEN end_char="2481" id="token-22-18" morph="none" pos="word" start_char="2479">CDC</TOKEN>
<TOKEN end_char="2482" id="token-22-19" morph="none" pos="punct" start_char="2482">)</TOKEN>
<TOKEN end_char="2490" id="token-22-20" morph="none" pos="word" start_char="2484">dismiss</TOKEN>
<TOKEN end_char="2494" id="token-22-21" morph="none" pos="word" start_char="2492">the</TOKEN>
<TOKEN end_char="2499" id="token-22-22" morph="none" pos="word" start_char="2496">idea</TOKEN>
<TOKEN end_char="2504" id="token-22-23" morph="none" pos="word" start_char="2501">that</TOKEN>
<TOKEN end_char="2512" id="token-22-24" morph="none" pos="word" start_char="2506">disease</TOKEN>
<TOKEN end_char="2525" id="token-22-25" morph="none" pos="word" start_char="2514">transmission</TOKEN>
<TOKEN end_char="2528" id="token-22-26" morph="none" pos="word" start_char="2527">on</TOKEN>
<TOKEN end_char="2538" id="token-22-27" morph="none" pos="word" start_char="2530">packaging</TOKEN>
<TOKEN end_char="2541" id="token-22-28" morph="none" pos="word" start_char="2540">is</TOKEN>
<TOKEN end_char="2543" id="token-22-29" morph="none" pos="word" start_char="2543">a</TOKEN>
<TOKEN end_char="2551" id="token-22-30" morph="none" pos="word" start_char="2545">serious</TOKEN>
<TOKEN end_char="2559" id="token-22-31" morph="none" pos="word" start_char="2553">concern</TOKEN>
<TOKEN end_char="2560" id="token-22-32" morph="none" pos="punct" start_char="2560">.</TOKEN>
</SEG>
<SEG end_char="2731" id="segment-23" start_char="2563">
<ORIGINAL_TEXT>The WHO says it is "highly unlikely that people can contract Covid-19 from food or food packaging," due to the fact that coronaviruses require a living host to multiply.</ORIGINAL_TEXT>
<TOKEN end_char="2565" id="token-23-0" morph="none" pos="word" start_char="2563">The</TOKEN>
<TOKEN end_char="2569" id="token-23-1" morph="none" pos="word" start_char="2567">WHO</TOKEN>
<TOKEN end_char="2574" id="token-23-2" morph="none" pos="word" start_char="2571">says</TOKEN>
<TOKEN end_char="2577" id="token-23-3" morph="none" pos="word" start_char="2576">it</TOKEN>
<TOKEN end_char="2580" id="token-23-4" morph="none" pos="word" start_char="2579">is</TOKEN>
<TOKEN end_char="2582" id="token-23-5" morph="none" pos="punct" start_char="2582">"</TOKEN>
<TOKEN end_char="2588" id="token-23-6" morph="none" pos="word" start_char="2583">highly</TOKEN>
<TOKEN end_char="2597" id="token-23-7" morph="none" pos="word" start_char="2590">unlikely</TOKEN>
<TOKEN end_char="2602" id="token-23-8" morph="none" pos="word" start_char="2599">that</TOKEN>
<TOKEN end_char="2609" id="token-23-9" morph="none" pos="word" start_char="2604">people</TOKEN>
<TOKEN end_char="2613" id="token-23-10" morph="none" pos="word" start_char="2611">can</TOKEN>
<TOKEN end_char="2622" id="token-23-11" morph="none" pos="word" start_char="2615">contract</TOKEN>
<TOKEN end_char="2631" id="token-23-12" morph="none" pos="unknown" start_char="2624">Covid-19</TOKEN>
<TOKEN end_char="2636" id="token-23-13" morph="none" pos="word" start_char="2633">from</TOKEN>
<TOKEN end_char="2641" id="token-23-14" morph="none" pos="word" start_char="2638">food</TOKEN>
<TOKEN end_char="2644" id="token-23-15" morph="none" pos="word" start_char="2643">or</TOKEN>
<TOKEN end_char="2649" id="token-23-16" morph="none" pos="word" start_char="2646">food</TOKEN>
<TOKEN end_char="2659" id="token-23-17" morph="none" pos="word" start_char="2651">packaging</TOKEN>
<TOKEN end_char="2661" id="token-23-18" morph="none" pos="punct" start_char="2660">,"</TOKEN>
<TOKEN end_char="2665" id="token-23-19" morph="none" pos="word" start_char="2663">due</TOKEN>
<TOKEN end_char="2668" id="token-23-20" morph="none" pos="word" start_char="2667">to</TOKEN>
<TOKEN end_char="2672" id="token-23-21" morph="none" pos="word" start_char="2670">the</TOKEN>
<TOKEN end_char="2677" id="token-23-22" morph="none" pos="word" start_char="2674">fact</TOKEN>
<TOKEN end_char="2682" id="token-23-23" morph="none" pos="word" start_char="2679">that</TOKEN>
<TOKEN end_char="2696" id="token-23-24" morph="none" pos="word" start_char="2684">coronaviruses</TOKEN>
<TOKEN end_char="2704" id="token-23-25" morph="none" pos="word" start_char="2698">require</TOKEN>
<TOKEN end_char="2706" id="token-23-26" morph="none" pos="word" start_char="2706">a</TOKEN>
<TOKEN end_char="2713" id="token-23-27" morph="none" pos="word" start_char="2708">living</TOKEN>
<TOKEN end_char="2718" id="token-23-28" morph="none" pos="word" start_char="2715">host</TOKEN>
<TOKEN end_char="2721" id="token-23-29" morph="none" pos="word" start_char="2720">to</TOKEN>
<TOKEN end_char="2730" id="token-23-30" morph="none" pos="word" start_char="2723">multiply</TOKEN>
<TOKEN end_char="2731" id="token-23-31" morph="none" pos="punct" start_char="2731">.</TOKEN>
</SEG>
<SEG end_char="2817" id="segment-24" start_char="2733">
<ORIGINAL_TEXT>Outside a body, they gradually become weaker and lose the ability to actively infect.</ORIGINAL_TEXT>
<TOKEN end_char="2739" id="token-24-0" morph="none" pos="word" start_char="2733">Outside</TOKEN>
<TOKEN end_char="2741" id="token-24-1" morph="none" pos="word" start_char="2741">a</TOKEN>
<TOKEN end_char="2746" id="token-24-2" morph="none" pos="word" start_char="2743">body</TOKEN>
<TOKEN end_char="2747" id="token-24-3" morph="none" pos="punct" start_char="2747">,</TOKEN>
<TOKEN end_char="2752" id="token-24-4" morph="none" pos="word" start_char="2749">they</TOKEN>
<TOKEN end_char="2762" id="token-24-5" morph="none" pos="word" start_char="2754">gradually</TOKEN>
<TOKEN end_char="2769" id="token-24-6" morph="none" pos="word" start_char="2764">become</TOKEN>
<TOKEN end_char="2776" id="token-24-7" morph="none" pos="word" start_char="2771">weaker</TOKEN>
<TOKEN end_char="2780" id="token-24-8" morph="none" pos="word" start_char="2778">and</TOKEN>
<TOKEN end_char="2785" id="token-24-9" morph="none" pos="word" start_char="2782">lose</TOKEN>
<TOKEN end_char="2789" id="token-24-10" morph="none" pos="word" start_char="2787">the</TOKEN>
<TOKEN end_char="2797" id="token-24-11" morph="none" pos="word" start_char="2791">ability</TOKEN>
<TOKEN end_char="2800" id="token-24-12" morph="none" pos="word" start_char="2799">to</TOKEN>
<TOKEN end_char="2809" id="token-24-13" morph="none" pos="word" start_char="2802">actively</TOKEN>
<TOKEN end_char="2816" id="token-24-14" morph="none" pos="word" start_char="2811">infect</TOKEN>
<TOKEN end_char="2817" id="token-24-15" morph="none" pos="punct" start_char="2817">.</TOKEN>
</SEG>
<SEG end_char="2942" id="segment-25" start_char="2819">
<ORIGINAL_TEXT>In a June memo, the CDC similarly claimed that the risk of infection from food products or bags is "thought to be very low."</ORIGINAL_TEXT>
<TOKEN end_char="2820" id="token-25-0" morph="none" pos="word" start_char="2819">In</TOKEN>
<TOKEN end_char="2822" id="token-25-1" morph="none" pos="word" start_char="2822">a</TOKEN>
<TOKEN end_char="2827" id="token-25-2" morph="none" pos="word" start_char="2824">June</TOKEN>
<TOKEN end_char="2832" id="token-25-3" morph="none" pos="word" start_char="2829">memo</TOKEN>
<TOKEN end_char="2833" id="token-25-4" morph="none" pos="punct" start_char="2833">,</TOKEN>
<TOKEN end_char="2837" id="token-25-5" morph="none" pos="word" start_char="2835">the</TOKEN>
<TOKEN end_char="2841" id="token-25-6" morph="none" pos="word" start_char="2839">CDC</TOKEN>
<TOKEN end_char="2851" id="token-25-7" morph="none" pos="word" start_char="2843">similarly</TOKEN>
<TOKEN end_char="2859" id="token-25-8" morph="none" pos="word" start_char="2853">claimed</TOKEN>
<TOKEN end_char="2864" id="token-25-9" morph="none" pos="word" start_char="2861">that</TOKEN>
<TOKEN end_char="2868" id="token-25-10" morph="none" pos="word" start_char="2866">the</TOKEN>
<TOKEN end_char="2873" id="token-25-11" morph="none" pos="word" start_char="2870">risk</TOKEN>
<TOKEN end_char="2876" id="token-25-12" morph="none" pos="word" start_char="2875">of</TOKEN>
<TOKEN end_char="2886" id="token-25-13" morph="none" pos="word" start_char="2878">infection</TOKEN>
<TOKEN end_char="2891" id="token-25-14" morph="none" pos="word" start_char="2888">from</TOKEN>
<TOKEN end_char="2896" id="token-25-15" morph="none" pos="word" start_char="2893">food</TOKEN>
<TOKEN end_char="2905" id="token-25-16" morph="none" pos="word" start_char="2898">products</TOKEN>
<TOKEN end_char="2908" id="token-25-17" morph="none" pos="word" start_char="2907">or</TOKEN>
<TOKEN end_char="2913" id="token-25-18" morph="none" pos="word" start_char="2910">bags</TOKEN>
<TOKEN end_char="2916" id="token-25-19" morph="none" pos="word" start_char="2915">is</TOKEN>
<TOKEN end_char="2918" id="token-25-20" morph="none" pos="punct" start_char="2918">"</TOKEN>
<TOKEN end_char="2925" id="token-25-21" morph="none" pos="word" start_char="2919">thought</TOKEN>
<TOKEN end_char="2928" id="token-25-22" morph="none" pos="word" start_char="2927">to</TOKEN>
<TOKEN end_char="2931" id="token-25-23" morph="none" pos="word" start_char="2930">be</TOKEN>
<TOKEN end_char="2936" id="token-25-24" morph="none" pos="word" start_char="2933">very</TOKEN>
<TOKEN end_char="2940" id="token-25-25" morph="none" pos="word" start_char="2938">low</TOKEN>
<TOKEN end_char="2942" id="token-25-26" morph="none" pos="punct" start_char="2941">."</TOKEN>
</SEG>
<SEG end_char="3036" id="segment-26" start_char="2944">
<ORIGINAL_TEXT>Remnants of dead virus have been known to cause false positive results in recovered patients,</ORIGINAL_TEXT>
<TOKEN end_char="2951" id="token-26-0" morph="none" pos="word" start_char="2944">Remnants</TOKEN>
<TOKEN end_char="2954" id="token-26-1" morph="none" pos="word" start_char="2953">of</TOKEN>
<TOKEN end_char="2959" id="token-26-2" morph="none" pos="word" start_char="2956">dead</TOKEN>
<TOKEN end_char="2965" id="token-26-3" morph="none" pos="word" start_char="2961">virus</TOKEN>
<TOKEN end_char="2970" id="token-26-4" morph="none" pos="word" start_char="2967">have</TOKEN>
<TOKEN end_char="2975" id="token-26-5" morph="none" pos="word" start_char="2972">been</TOKEN>
<TOKEN end_char="2981" id="token-26-6" morph="none" pos="word" start_char="2977">known</TOKEN>
<TOKEN end_char="2984" id="token-26-7" morph="none" pos="word" start_char="2983">to</TOKEN>
<TOKEN end_char="2990" id="token-26-8" morph="none" pos="word" start_char="2986">cause</TOKEN>
<TOKEN end_char="2996" id="token-26-9" morph="none" pos="word" start_char="2992">false</TOKEN>
<TOKEN end_char="3005" id="token-26-10" morph="none" pos="word" start_char="2998">positive</TOKEN>
<TOKEN end_char="3013" id="token-26-11" morph="none" pos="word" start_char="3007">results</TOKEN>
<TOKEN end_char="3016" id="token-26-12" morph="none" pos="word" start_char="3015">in</TOKEN>
<TOKEN end_char="3026" id="token-26-13" morph="none" pos="word" start_char="3018">recovered</TOKEN>
<TOKEN end_char="3035" id="token-26-14" morph="none" pos="word" start_char="3028">patients</TOKEN>
<TOKEN end_char="3036" id="token-26-15" morph="none" pos="punct" start_char="3036">,</TOKEN>
</SEG>
<SEG end_char="3041" id="segment-27" start_char="3039">
<ORIGINAL_TEXT>CNN</ORIGINAL_TEXT>
<TOKEN end_char="3041" id="token-27-0" morph="none" pos="word" start_char="3039">CNN</TOKEN>
</SEG>
<SEG end_char="3051" id="segment-28" start_char="3044">
<ORIGINAL_TEXT>reports.</ORIGINAL_TEXT>
<TOKEN end_char="3050" id="token-28-0" morph="none" pos="word" start_char="3044">reports</TOKEN>
<TOKEN end_char="3051" id="token-28-1" morph="none" pos="punct" start_char="3051">.</TOKEN>
<TRANSLATED_TEXT>relazioni.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="3171" id="segment-29" start_char="3054">
<ORIGINAL_TEXT>Researchers have taken to scientific journals to downplay transmission by fomites, a term for the surfaces themselves.</ORIGINAL_TEXT>
<TOKEN end_char="3064" id="token-29-0" morph="none" pos="word" start_char="3054">Researchers</TOKEN>
<TOKEN end_char="3069" id="token-29-1" morph="none" pos="word" start_char="3066">have</TOKEN>
<TOKEN end_char="3075" id="token-29-2" morph="none" pos="word" start_char="3071">taken</TOKEN>
<TOKEN end_char="3078" id="token-29-3" morph="none" pos="word" start_char="3077">to</TOKEN>
<TOKEN end_char="3089" id="token-29-4" morph="none" pos="word" start_char="3080">scientific</TOKEN>
<TOKEN end_char="3098" id="token-29-5" morph="none" pos="word" start_char="3091">journals</TOKEN>
<TOKEN end_char="3101" id="token-29-6" morph="none" pos="word" start_char="3100">to</TOKEN>
<TOKEN end_char="3110" id="token-29-7" morph="none" pos="word" start_char="3103">downplay</TOKEN>
<TOKEN end_char="3123" id="token-29-8" morph="none" pos="word" start_char="3112">transmission</TOKEN>
<TOKEN end_char="3126" id="token-29-9" morph="none" pos="word" start_char="3125">by</TOKEN>
<TOKEN end_char="3134" id="token-29-10" morph="none" pos="word" start_char="3128">fomites</TOKEN>
<TOKEN end_char="3135" id="token-29-11" morph="none" pos="punct" start_char="3135">,</TOKEN>
<TOKEN end_char="3137" id="token-29-12" morph="none" pos="word" start_char="3137">a</TOKEN>
<TOKEN end_char="3142" id="token-29-13" morph="none" pos="word" start_char="3139">term</TOKEN>
<TOKEN end_char="3146" id="token-29-14" morph="none" pos="word" start_char="3144">for</TOKEN>
<TOKEN end_char="3150" id="token-29-15" morph="none" pos="word" start_char="3148">the</TOKEN>
<TOKEN end_char="3159" id="token-29-16" morph="none" pos="word" start_char="3152">surfaces</TOKEN>
<TOKEN end_char="3170" id="token-29-17" morph="none" pos="word" start_char="3161">themselves</TOKEN>
<TOKEN end_char="3171" id="token-29-18" morph="none" pos="punct" start_char="3171">.</TOKEN>
</SEG>
<SEG end_char="3197" id="segment-30" start_char="3173">
<ORIGINAL_TEXT>In a recent commentary in</ORIGINAL_TEXT>
<TOKEN end_char="3174" id="token-30-0" morph="none" pos="word" start_char="3173">In</TOKEN>
<TOKEN end_char="3176" id="token-30-1" morph="none" pos="word" start_char="3176">a</TOKEN>
<TOKEN end_char="3183" id="token-30-2" morph="none" pos="word" start_char="3178">recent</TOKEN>
<TOKEN end_char="3194" id="token-30-3" morph="none" pos="word" start_char="3185">commentary</TOKEN>
<TOKEN end_char="3197" id="token-30-4" morph="none" pos="word" start_char="3196">in</TOKEN>
</SEG>
<SEG end_char="3209" id="segment-31" start_char="3200">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN end_char="3202" id="token-31-0" morph="none" pos="word" start_char="3200">The</TOKEN>
<TOKEN end_char="3209" id="token-31-1" morph="none" pos="word" start_char="3204">Lancet</TOKEN>
</SEG>
<SEG end_char="3492" id="segment-32" start_char="3212">
<ORIGINAL_TEXT>, Emanuel Goldman, a microbiologist at Rutgers New Jersey Medical School, said, "the chance of transmission through inanimate surfaces is very small, and only in instances where an infected person coughs or sneezes on the surface, and someone else touches that surface soon after."</ORIGINAL_TEXT>
<TOKEN end_char="3212" id="token-32-0" morph="none" pos="punct" start_char="3212">,</TOKEN>
<TOKEN end_char="3220" id="token-32-1" morph="none" pos="word" start_char="3214">Emanuel</TOKEN>
<TOKEN end_char="3228" id="token-32-2" morph="none" pos="word" start_char="3222">Goldman</TOKEN>
<TOKEN end_char="3229" id="token-32-3" morph="none" pos="punct" start_char="3229">,</TOKEN>
<TOKEN end_char="3231" id="token-32-4" morph="none" pos="word" start_char="3231">a</TOKEN>
<TOKEN end_char="3246" id="token-32-5" morph="none" pos="word" start_char="3233">microbiologist</TOKEN>
<TOKEN end_char="3249" id="token-32-6" morph="none" pos="word" start_char="3248">at</TOKEN>
<TOKEN end_char="3257" id="token-32-7" morph="none" pos="word" start_char="3251">Rutgers</TOKEN>
<TOKEN end_char="3261" id="token-32-8" morph="none" pos="word" start_char="3259">New</TOKEN>
<TOKEN end_char="3268" id="token-32-9" morph="none" pos="word" start_char="3263">Jersey</TOKEN>
<TOKEN end_char="3276" id="token-32-10" morph="none" pos="word" start_char="3270">Medical</TOKEN>
<TOKEN end_char="3283" id="token-32-11" morph="none" pos="word" start_char="3278">School</TOKEN>
<TOKEN end_char="3284" id="token-32-12" morph="none" pos="punct" start_char="3284">,</TOKEN>
<TOKEN end_char="3289" id="token-32-13" morph="none" pos="word" start_char="3286">said</TOKEN>
<TOKEN end_char="3290" id="token-32-14" morph="none" pos="punct" start_char="3290">,</TOKEN>
<TOKEN end_char="3292" id="token-32-15" morph="none" pos="punct" start_char="3292">"</TOKEN>
<TOKEN end_char="3295" id="token-32-16" morph="none" pos="word" start_char="3293">the</TOKEN>
<TOKEN end_char="3302" id="token-32-17" morph="none" pos="word" start_char="3297">chance</TOKEN>
<TOKEN end_char="3305" id="token-32-18" morph="none" pos="word" start_char="3304">of</TOKEN>
<TOKEN end_char="3318" id="token-32-19" morph="none" pos="word" start_char="3307">transmission</TOKEN>
<TOKEN end_char="3326" id="token-32-20" morph="none" pos="word" start_char="3320">through</TOKEN>
<TOKEN end_char="3336" id="token-32-21" morph="none" pos="word" start_char="3328">inanimate</TOKEN>
<TOKEN end_char="3345" id="token-32-22" morph="none" pos="word" start_char="3338">surfaces</TOKEN>
<TOKEN end_char="3348" id="token-32-23" morph="none" pos="word" start_char="3347">is</TOKEN>
<TOKEN end_char="3353" id="token-32-24" morph="none" pos="word" start_char="3350">very</TOKEN>
<TOKEN end_char="3359" id="token-32-25" morph="none" pos="word" start_char="3355">small</TOKEN>
<TOKEN end_char="3360" id="token-32-26" morph="none" pos="punct" start_char="3360">,</TOKEN>
<TOKEN end_char="3364" id="token-32-27" morph="none" pos="word" start_char="3362">and</TOKEN>
<TOKEN end_char="3369" id="token-32-28" morph="none" pos="word" start_char="3366">only</TOKEN>
<TOKEN end_char="3372" id="token-32-29" morph="none" pos="word" start_char="3371">in</TOKEN>
<TOKEN end_char="3382" id="token-32-30" morph="none" pos="word" start_char="3374">instances</TOKEN>
<TOKEN end_char="3388" id="token-32-31" morph="none" pos="word" start_char="3384">where</TOKEN>
<TOKEN end_char="3391" id="token-32-32" morph="none" pos="word" start_char="3390">an</TOKEN>
<TOKEN end_char="3400" id="token-32-33" morph="none" pos="word" start_char="3393">infected</TOKEN>
<TOKEN end_char="3407" id="token-32-34" morph="none" pos="word" start_char="3402">person</TOKEN>
<TOKEN end_char="3414" id="token-32-35" morph="none" pos="word" start_char="3409">coughs</TOKEN>
<TOKEN end_char="3417" id="token-32-36" morph="none" pos="word" start_char="3416">or</TOKEN>
<TOKEN end_char="3425" id="token-32-37" morph="none" pos="word" start_char="3419">sneezes</TOKEN>
<TOKEN end_char="3428" id="token-32-38" morph="none" pos="word" start_char="3427">on</TOKEN>
<TOKEN end_char="3432" id="token-32-39" morph="none" pos="word" start_char="3430">the</TOKEN>
<TOKEN end_char="3440" id="token-32-40" morph="none" pos="word" start_char="3434">surface</TOKEN>
<TOKEN end_char="3441" id="token-32-41" morph="none" pos="punct" start_char="3441">,</TOKEN>
<TOKEN end_char="3445" id="token-32-42" morph="none" pos="word" start_char="3443">and</TOKEN>
<TOKEN end_char="3453" id="token-32-43" morph="none" pos="word" start_char="3447">someone</TOKEN>
<TOKEN end_char="3458" id="token-32-44" morph="none" pos="word" start_char="3455">else</TOKEN>
<TOKEN end_char="3466" id="token-32-45" morph="none" pos="word" start_char="3460">touches</TOKEN>
<TOKEN end_char="3471" id="token-32-46" morph="none" pos="word" start_char="3468">that</TOKEN>
<TOKEN end_char="3479" id="token-32-47" morph="none" pos="word" start_char="3473">surface</TOKEN>
<TOKEN end_char="3484" id="token-32-48" morph="none" pos="word" start_char="3481">soon</TOKEN>
<TOKEN end_char="3490" id="token-32-49" morph="none" pos="word" start_char="3486">after</TOKEN>
<TOKEN end_char="3492" id="token-32-50" morph="none" pos="punct" start_char="3491">."</TOKEN>
</SEG>
<SEG end_char="3505" id="segment-33" start_char="3495">
<ORIGINAL_TEXT>Speaking to</ORIGINAL_TEXT>
<TOKEN end_char="3502" id="token-33-0" morph="none" pos="word" start_char="3495">Speaking</TOKEN>
<TOKEN end_char="3505" id="token-33-1" morph="none" pos="word" start_char="3504">to</TOKEN>
</SEG>
<SEG end_char="3519" id="segment-34" start_char="3508">
<ORIGINAL_TEXT>The Atlantic</ORIGINAL_TEXT>
<TOKEN end_char="3510" id="token-34-0" morph="none" pos="word" start_char="3508">The</TOKEN>
<TOKEN end_char="3519" id="token-34-1" morph="none" pos="word" start_char="3512">Atlantic</TOKEN>
</SEG>
<SEG end_char="3651" id="segment-35" start_char="3522">
<ORIGINAL_TEXT>in July, Goldman stated his position more emphatically: "Surface transmission of COVID-19 is not justified at all by the science."</ORIGINAL_TEXT>
<TOKEN end_char="3523" id="token-35-0" morph="none" pos="word" start_char="3522">in</TOKEN>
<TOKEN end_char="3528" id="token-35-1" morph="none" pos="word" start_char="3525">July</TOKEN>
<TOKEN end_char="3529" id="token-35-2" morph="none" pos="punct" start_char="3529">,</TOKEN>
<TOKEN end_char="3537" id="token-35-3" morph="none" pos="word" start_char="3531">Goldman</TOKEN>
<TOKEN end_char="3544" id="token-35-4" morph="none" pos="word" start_char="3539">stated</TOKEN>
<TOKEN end_char="3548" id="token-35-5" morph="none" pos="word" start_char="3546">his</TOKEN>
<TOKEN end_char="3557" id="token-35-6" morph="none" pos="word" start_char="3550">position</TOKEN>
<TOKEN end_char="3562" id="token-35-7" morph="none" pos="word" start_char="3559">more</TOKEN>
<TOKEN end_char="3575" id="token-35-8" morph="none" pos="word" start_char="3564">emphatically</TOKEN>
<TOKEN end_char="3576" id="token-35-9" morph="none" pos="punct" start_char="3576">:</TOKEN>
<TOKEN end_char="3578" id="token-35-10" morph="none" pos="punct" start_char="3578">"</TOKEN>
<TOKEN end_char="3585" id="token-35-11" morph="none" pos="word" start_char="3579">Surface</TOKEN>
<TOKEN end_char="3598" id="token-35-12" morph="none" pos="word" start_char="3587">transmission</TOKEN>
<TOKEN end_char="3601" id="token-35-13" morph="none" pos="word" start_char="3600">of</TOKEN>
<TOKEN end_char="3610" id="token-35-14" morph="none" pos="unknown" start_char="3603">COVID-19</TOKEN>
<TOKEN end_char="3613" id="token-35-15" morph="none" pos="word" start_char="3612">is</TOKEN>
<TOKEN end_char="3617" id="token-35-16" morph="none" pos="word" start_char="3615">not</TOKEN>
<TOKEN end_char="3627" id="token-35-17" morph="none" pos="word" start_char="3619">justified</TOKEN>
<TOKEN end_char="3630" id="token-35-18" morph="none" pos="word" start_char="3629">at</TOKEN>
<TOKEN end_char="3634" id="token-35-19" morph="none" pos="word" start_char="3632">all</TOKEN>
<TOKEN end_char="3637" id="token-35-20" morph="none" pos="word" start_char="3636">by</TOKEN>
<TOKEN end_char="3641" id="token-35-21" morph="none" pos="word" start_char="3639">the</TOKEN>
<TOKEN end_char="3649" id="token-35-22" morph="none" pos="word" start_char="3643">science</TOKEN>
<TOKEN end_char="3651" id="token-35-23" morph="none" pos="punct" start_char="3650">."</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C049DRI" lang="spa" raw_text_char_length="2518" raw_text_md5="c453a18ebdb81682193f1d33aef69704" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="73" id="segment-0" start_char="1">
<ORIGINAL_TEXT>El bulo de que el coronavirus se creó en un laboratorio de Estados Unidos</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">El</TOKEN>
<TOKEN end_char="7" id="token-0-1" morph="none" pos="word" start_char="4">bulo</TOKEN>
<TOKEN end_char="10" id="token-0-2" morph="none" pos="word" start_char="9">de</TOKEN>
<TOKEN end_char="14" id="token-0-3" morph="none" pos="word" start_char="12">que</TOKEN>
<TOKEN end_char="17" id="token-0-4" morph="none" pos="word" start_char="16">el</TOKEN>
<TOKEN end_char="29" id="token-0-5" morph="none" pos="word" start_char="19">coronavirus</TOKEN>
<TOKEN end_char="32" id="token-0-6" morph="none" pos="word" start_char="31">se</TOKEN>
<TOKEN end_char="37" id="token-0-7" morph="none" pos="word" start_char="34">creó</TOKEN>
<TOKEN end_char="40" id="token-0-8" morph="none" pos="word" start_char="39">en</TOKEN>
<TOKEN end_char="43" id="token-0-9" morph="none" pos="word" start_char="42">un</TOKEN>
<TOKEN end_char="55" id="token-0-10" morph="none" pos="word" start_char="45">laboratorio</TOKEN>
<TOKEN end_char="58" id="token-0-11" morph="none" pos="word" start_char="57">de</TOKEN>
<TOKEN end_char="66" id="token-0-12" morph="none" pos="word" start_char="60">Estados</TOKEN>
<TOKEN end_char="73" id="token-0-13" morph="none" pos="word" start_char="68">Unidos</TOKEN>
<TRANSLATED_TEXT>The Myth That Coronavirus Was Created in an American Laboratory</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="135" id="segment-1" start_char="77">
<ORIGINAL_TEXT>Esto de los bulos sobre el coronavirus parece no tener fin.</ORIGINAL_TEXT>
<TOKEN end_char="80" id="token-1-0" morph="none" pos="word" start_char="77">Esto</TOKEN>
<TOKEN end_char="83" id="token-1-1" morph="none" pos="word" start_char="82">de</TOKEN>
<TOKEN end_char="87" id="token-1-2" morph="none" pos="word" start_char="85">los</TOKEN>
<TOKEN end_char="93" id="token-1-3" morph="none" pos="word" start_char="89">bulos</TOKEN>
<TOKEN end_char="99" id="token-1-4" morph="none" pos="word" start_char="95">sobre</TOKEN>
<TOKEN end_char="102" id="token-1-5" morph="none" pos="word" start_char="101">el</TOKEN>
<TOKEN end_char="114" id="token-1-6" morph="none" pos="word" start_char="104">coronavirus</TOKEN>
<TOKEN end_char="121" id="token-1-7" morph="none" pos="word" start_char="116">parece</TOKEN>
<TOKEN end_char="124" id="token-1-8" morph="none" pos="word" start_char="123">no</TOKEN>
<TOKEN end_char="130" id="token-1-9" morph="none" pos="word" start_char="126">tener</TOKEN>
<TOKEN end_char="134" id="token-1-10" morph="none" pos="word" start_char="132">fin</TOKEN>
<TOKEN end_char="135" id="token-1-11" morph="none" pos="punct" start_char="135">.</TOKEN>
<TRANSLATED_TEXT>This of the cells on coronavirus seems to have no end.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="256" id="segment-2" start_char="137">
<ORIGINAL_TEXT>Casi cada día aparece alguno que nos pone sobre aviso y al que tenemos que desenmascarar para que no engañe a más gente.</ORIGINAL_TEXT>
<TOKEN end_char="140" id="token-2-0" morph="none" pos="word" start_char="137">Casi</TOKEN>
<TOKEN end_char="145" id="token-2-1" morph="none" pos="word" start_char="142">cada</TOKEN>
<TOKEN end_char="149" id="token-2-2" morph="none" pos="word" start_char="147">día</TOKEN>
<TOKEN end_char="157" id="token-2-3" morph="none" pos="word" start_char="151">aparece</TOKEN>
<TOKEN end_char="164" id="token-2-4" morph="none" pos="word" start_char="159">alguno</TOKEN>
<TOKEN end_char="168" id="token-2-5" morph="none" pos="word" start_char="166">que</TOKEN>
<TOKEN end_char="172" id="token-2-6" morph="none" pos="word" start_char="170">nos</TOKEN>
<TOKEN end_char="177" id="token-2-7" morph="none" pos="word" start_char="174">pone</TOKEN>
<TOKEN end_char="183" id="token-2-8" morph="none" pos="word" start_char="179">sobre</TOKEN>
<TOKEN end_char="189" id="token-2-9" morph="none" pos="word" start_char="185">aviso</TOKEN>
<TOKEN end_char="191" id="token-2-10" morph="none" pos="word" start_char="191">y</TOKEN>
<TOKEN end_char="194" id="token-2-11" morph="none" pos="word" start_char="193">al</TOKEN>
<TOKEN end_char="198" id="token-2-12" morph="none" pos="word" start_char="196">que</TOKEN>
<TOKEN end_char="206" id="token-2-13" morph="none" pos="word" start_char="200">tenemos</TOKEN>
<TOKEN end_char="210" id="token-2-14" morph="none" pos="word" start_char="208">que</TOKEN>
<TOKEN end_char="224" id="token-2-15" morph="none" pos="word" start_char="212">desenmascarar</TOKEN>
<TOKEN end_char="229" id="token-2-16" morph="none" pos="word" start_char="226">para</TOKEN>
<TOKEN end_char="233" id="token-2-17" morph="none" pos="word" start_char="231">que</TOKEN>
<TOKEN end_char="236" id="token-2-18" morph="none" pos="word" start_char="235">no</TOKEN>
<TOKEN end_char="243" id="token-2-19" morph="none" pos="word" start_char="238">engañe</TOKEN>
<TOKEN end_char="245" id="token-2-20" morph="none" pos="word" start_char="245">a</TOKEN>
<TOKEN end_char="249" id="token-2-21" morph="none" pos="word" start_char="247">más</TOKEN>
<TOKEN end_char="255" id="token-2-22" morph="none" pos="word" start_char="251">gente</TOKEN>
<TOKEN end_char="256" id="token-2-23" morph="none" pos="punct" start_char="256">.</TOKEN>
<TRANSLATED_TEXT>Almost every day someone appears who puts us on notice and who we have to unmask so he doesn't fool more people.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="295" id="segment-3" start_char="258">
<ORIGINAL_TEXT>A veces resulta complicado, porque las</ORIGINAL_TEXT>
<TOKEN end_char="258" id="token-3-0" morph="none" pos="word" start_char="258">A</TOKEN>
<TOKEN end_char="264" id="token-3-1" morph="none" pos="word" start_char="260">veces</TOKEN>
<TOKEN end_char="272" id="token-3-2" morph="none" pos="word" start_char="266">resulta</TOKEN>
<TOKEN end_char="283" id="token-3-3" morph="none" pos="word" start_char="274">complicado</TOKEN>
<TOKEN end_char="284" id="token-3-4" morph="none" pos="punct" start_char="284">,</TOKEN>
<TOKEN end_char="291" id="token-3-5" morph="none" pos="word" start_char="286">porque</TOKEN>
<TOKEN end_char="295" id="token-3-6" morph="none" pos="word" start_char="293">las</TOKEN>
<TRANSLATED_TEXT>Sometimes it 's complicated, because</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="306" id="segment-4" start_char="298">
<ORIGINAL_TEXT>fake news</ORIGINAL_TEXT>
<TOKEN end_char="301" id="token-4-0" morph="none" pos="word" start_char="298">fake</TOKEN>
<TOKEN end_char="306" id="token-4-1" morph="none" pos="word" start_char="303">news</TOKEN>
</SEG>
<SEG end_char="386" id="segment-5" start_char="309">
<ORIGINAL_TEXT>en cuestión se sirven de algunos datos verdaderos para despistar a más de uno.</ORIGINAL_TEXT>
<TOKEN end_char="310" id="token-5-0" morph="none" pos="word" start_char="309">en</TOKEN>
<TOKEN end_char="319" id="token-5-1" morph="none" pos="word" start_char="312">cuestión</TOKEN>
<TOKEN end_char="322" id="token-5-2" morph="none" pos="word" start_char="321">se</TOKEN>
<TOKEN end_char="329" id="token-5-3" morph="none" pos="word" start_char="324">sirven</TOKEN>
<TOKEN end_char="332" id="token-5-4" morph="none" pos="word" start_char="331">de</TOKEN>
<TOKEN end_char="340" id="token-5-5" morph="none" pos="word" start_char="334">algunos</TOKEN>
<TOKEN end_char="346" id="token-5-6" morph="none" pos="word" start_char="342">datos</TOKEN>
<TOKEN end_char="357" id="token-5-7" morph="none" pos="word" start_char="348">verdaderos</TOKEN>
<TOKEN end_char="362" id="token-5-8" morph="none" pos="word" start_char="359">para</TOKEN>
<TOKEN end_char="372" id="token-5-9" morph="none" pos="word" start_char="364">despistar</TOKEN>
<TOKEN end_char="374" id="token-5-10" morph="none" pos="word" start_char="374">a</TOKEN>
<TOKEN end_char="378" id="token-5-11" morph="none" pos="word" start_char="376">más</TOKEN>
<TOKEN end_char="381" id="token-5-12" morph="none" pos="word" start_char="380">de</TOKEN>
<TOKEN end_char="385" id="token-5-13" morph="none" pos="word" start_char="383">uno</TOKEN>
<TOKEN end_char="386" id="token-5-14" morph="none" pos="punct" start_char="386">.</TOKEN>
<TRANSLATED_TEXT>in question are used some true data to trace more than one.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="612" id="segment-6" start_char="388">
<ORIGINAL_TEXT>Suerte que hay medios de comunicación e instituciones como la Guardia Civil y la Policía Nacional que nos alertan de estas mentiras que, día sí y día también, inundan nuestras redes sociales y de las que podemos ser víctimas.</ORIGINAL_TEXT>
<TOKEN end_char="393" id="token-6-0" morph="none" pos="word" start_char="388">Suerte</TOKEN>
<TOKEN end_char="397" id="token-6-1" morph="none" pos="word" start_char="395">que</TOKEN>
<TOKEN end_char="401" id="token-6-2" morph="none" pos="word" start_char="399">hay</TOKEN>
<TOKEN end_char="408" id="token-6-3" morph="none" pos="word" start_char="403">medios</TOKEN>
<TOKEN end_char="411" id="token-6-4" morph="none" pos="word" start_char="410">de</TOKEN>
<TOKEN end_char="424" id="token-6-5" morph="none" pos="word" start_char="413">comunicación</TOKEN>
<TOKEN end_char="426" id="token-6-6" morph="none" pos="word" start_char="426">e</TOKEN>
<TOKEN end_char="440" id="token-6-7" morph="none" pos="word" start_char="428">instituciones</TOKEN>
<TOKEN end_char="445" id="token-6-8" morph="none" pos="word" start_char="442">como</TOKEN>
<TOKEN end_char="448" id="token-6-9" morph="none" pos="word" start_char="447">la</TOKEN>
<TOKEN end_char="456" id="token-6-10" morph="none" pos="word" start_char="450">Guardia</TOKEN>
<TOKEN end_char="462" id="token-6-11" morph="none" pos="word" start_char="458">Civil</TOKEN>
<TOKEN end_char="464" id="token-6-12" morph="none" pos="word" start_char="464">y</TOKEN>
<TOKEN end_char="467" id="token-6-13" morph="none" pos="word" start_char="466">la</TOKEN>
<TOKEN end_char="475" id="token-6-14" morph="none" pos="word" start_char="469">Policía</TOKEN>
<TOKEN end_char="484" id="token-6-15" morph="none" pos="word" start_char="477">Nacional</TOKEN>
<TOKEN end_char="488" id="token-6-16" morph="none" pos="word" start_char="486">que</TOKEN>
<TOKEN end_char="492" id="token-6-17" morph="none" pos="word" start_char="490">nos</TOKEN>
<TOKEN end_char="500" id="token-6-18" morph="none" pos="word" start_char="494">alertan</TOKEN>
<TOKEN end_char="503" id="token-6-19" morph="none" pos="word" start_char="502">de</TOKEN>
<TOKEN end_char="509" id="token-6-20" morph="none" pos="word" start_char="505">estas</TOKEN>
<TOKEN end_char="518" id="token-6-21" morph="none" pos="word" start_char="511">mentiras</TOKEN>
<TOKEN end_char="522" id="token-6-22" morph="none" pos="word" start_char="520">que</TOKEN>
<TOKEN end_char="523" id="token-6-23" morph="none" pos="punct" start_char="523">,</TOKEN>
<TOKEN end_char="527" id="token-6-24" morph="none" pos="word" start_char="525">día</TOKEN>
<TOKEN end_char="530" id="token-6-25" morph="none" pos="word" start_char="529">sí</TOKEN>
<TOKEN end_char="532" id="token-6-26" morph="none" pos="word" start_char="532">y</TOKEN>
<TOKEN end_char="536" id="token-6-27" morph="none" pos="word" start_char="534">día</TOKEN>
<TOKEN end_char="544" id="token-6-28" morph="none" pos="word" start_char="538">también</TOKEN>
<TOKEN end_char="545" id="token-6-29" morph="none" pos="punct" start_char="545">,</TOKEN>
<TOKEN end_char="553" id="token-6-30" morph="none" pos="word" start_char="547">inundan</TOKEN>
<TOKEN end_char="562" id="token-6-31" morph="none" pos="word" start_char="555">nuestras</TOKEN>
<TOKEN end_char="568" id="token-6-32" morph="none" pos="word" start_char="564">redes</TOKEN>
<TOKEN end_char="577" id="token-6-33" morph="none" pos="word" start_char="570">sociales</TOKEN>
<TOKEN end_char="579" id="token-6-34" morph="none" pos="word" start_char="579">y</TOKEN>
<TOKEN end_char="582" id="token-6-35" morph="none" pos="word" start_char="581">de</TOKEN>
<TOKEN end_char="586" id="token-6-36" morph="none" pos="word" start_char="584">las</TOKEN>
<TOKEN end_char="590" id="token-6-37" morph="none" pos="word" start_char="588">que</TOKEN>
<TOKEN end_char="598" id="token-6-38" morph="none" pos="word" start_char="592">podemos</TOKEN>
<TOKEN end_char="602" id="token-6-39" morph="none" pos="word" start_char="600">ser</TOKEN>
<TOKEN end_char="611" id="token-6-40" morph="none" pos="word" start_char="604">víctimas</TOKEN>
<TOKEN end_char="612" id="token-6-41" morph="none" pos="punct" start_char="612">.</TOKEN>
<TRANSLATED_TEXT>Fortunately, there are media outlets and institutions such as the Civil Guard and the National Police that alert us to these lies that, day after day as well, flood our social networks and to which we may be victims.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="848" id="segment-7" start_char="615">
<ORIGINAL_TEXT>Corre desde hace unos días una noticia falsa que asegura que el Covid-19 fue creada en un laboratorio de Fort Detrick (Estados Unidos) con el objetivo de frenar el desarrollo de la tecnología 5G y para acabar con las personas mayores.</ORIGINAL_TEXT>
<TOKEN end_char="619" id="token-7-0" morph="none" pos="word" start_char="615">Corre</TOKEN>
<TOKEN end_char="625" id="token-7-1" morph="none" pos="word" start_char="621">desde</TOKEN>
<TOKEN end_char="630" id="token-7-2" morph="none" pos="word" start_char="627">hace</TOKEN>
<TOKEN end_char="635" id="token-7-3" morph="none" pos="word" start_char="632">unos</TOKEN>
<TOKEN end_char="640" id="token-7-4" morph="none" pos="word" start_char="637">días</TOKEN>
<TOKEN end_char="644" id="token-7-5" morph="none" pos="word" start_char="642">una</TOKEN>
<TOKEN end_char="652" id="token-7-6" morph="none" pos="word" start_char="646">noticia</TOKEN>
<TOKEN end_char="658" id="token-7-7" morph="none" pos="word" start_char="654">falsa</TOKEN>
<TOKEN end_char="662" id="token-7-8" morph="none" pos="word" start_char="660">que</TOKEN>
<TOKEN end_char="670" id="token-7-9" morph="none" pos="word" start_char="664">asegura</TOKEN>
<TOKEN end_char="674" id="token-7-10" morph="none" pos="word" start_char="672">que</TOKEN>
<TOKEN end_char="677" id="token-7-11" morph="none" pos="word" start_char="676">el</TOKEN>
<TOKEN end_char="686" id="token-7-12" morph="none" pos="unknown" start_char="679">Covid-19</TOKEN>
<TOKEN end_char="690" id="token-7-13" morph="none" pos="word" start_char="688">fue</TOKEN>
<TOKEN end_char="697" id="token-7-14" morph="none" pos="word" start_char="692">creada</TOKEN>
<TOKEN end_char="700" id="token-7-15" morph="none" pos="word" start_char="699">en</TOKEN>
<TOKEN end_char="703" id="token-7-16" morph="none" pos="word" start_char="702">un</TOKEN>
<TOKEN end_char="715" id="token-7-17" morph="none" pos="word" start_char="705">laboratorio</TOKEN>
<TOKEN end_char="718" id="token-7-18" morph="none" pos="word" start_char="717">de</TOKEN>
<TOKEN end_char="723" id="token-7-19" morph="none" pos="word" start_char="720">Fort</TOKEN>
<TOKEN end_char="731" id="token-7-20" morph="none" pos="word" start_char="725">Detrick</TOKEN>
<TOKEN end_char="733" id="token-7-21" morph="none" pos="punct" start_char="733">(</TOKEN>
<TOKEN end_char="740" id="token-7-22" morph="none" pos="word" start_char="734">Estados</TOKEN>
<TOKEN end_char="747" id="token-7-23" morph="none" pos="word" start_char="742">Unidos</TOKEN>
<TOKEN end_char="748" id="token-7-24" morph="none" pos="punct" start_char="748">)</TOKEN>
<TOKEN end_char="752" id="token-7-25" morph="none" pos="word" start_char="750">con</TOKEN>
<TOKEN end_char="755" id="token-7-26" morph="none" pos="word" start_char="754">el</TOKEN>
<TOKEN end_char="764" id="token-7-27" morph="none" pos="word" start_char="757">objetivo</TOKEN>
<TOKEN end_char="767" id="token-7-28" morph="none" pos="word" start_char="766">de</TOKEN>
<TOKEN end_char="774" id="token-7-29" morph="none" pos="word" start_char="769">frenar</TOKEN>
<TOKEN end_char="777" id="token-7-30" morph="none" pos="word" start_char="776">el</TOKEN>
<TOKEN end_char="788" id="token-7-31" morph="none" pos="word" start_char="779">desarrollo</TOKEN>
<TOKEN end_char="791" id="token-7-32" morph="none" pos="word" start_char="790">de</TOKEN>
<TOKEN end_char="794" id="token-7-33" morph="none" pos="word" start_char="793">la</TOKEN>
<TOKEN end_char="805" id="token-7-34" morph="none" pos="word" start_char="796">tecnología</TOKEN>
<TOKEN end_char="808" id="token-7-35" morph="none" pos="word" start_char="807">5G</TOKEN>
<TOKEN end_char="810" id="token-7-36" morph="none" pos="word" start_char="810">y</TOKEN>
<TOKEN end_char="815" id="token-7-37" morph="none" pos="word" start_char="812">para</TOKEN>
<TOKEN end_char="822" id="token-7-38" morph="none" pos="word" start_char="817">acabar</TOKEN>
<TOKEN end_char="826" id="token-7-39" morph="none" pos="word" start_char="824">con</TOKEN>
<TOKEN end_char="830" id="token-7-40" morph="none" pos="word" start_char="828">las</TOKEN>
<TOKEN end_char="839" id="token-7-41" morph="none" pos="word" start_char="832">personas</TOKEN>
<TOKEN end_char="847" id="token-7-42" morph="none" pos="word" start_char="841">mayores</TOKEN>
<TOKEN end_char="848" id="token-7-43" morph="none" pos="punct" start_char="848">.</TOKEN>
<TRANSLATED_TEXT>The Covid-19 was created in a laboratory in Fort Detrick, United States, to slow down the development of 5G technology and to kill the elderly.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="862" id="segment-8" start_char="850">
<ORIGINAL_TEXT>¡Menudo bulo!</ORIGINAL_TEXT>
<TOKEN end_char="850" id="token-8-0" morph="none" pos="punct" start_char="850">¡</TOKEN>
<TOKEN end_char="856" id="token-8-1" morph="none" pos="word" start_char="851">Menudo</TOKEN>
<TOKEN end_char="861" id="token-8-2" morph="none" pos="word" start_char="858">bulo</TOKEN>
<TOKEN end_char="862" id="token-8-3" morph="none" pos="punct" start_char="862">!</TOKEN>
<TRANSLATED_TEXT>I'm lying!</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="953" id="segment-9" start_char="864">
<ORIGINAL_TEXT>No es más que otra teoría de la conspiración que no aporta ninguna prueba que la confirme.</ORIGINAL_TEXT>
<TOKEN end_char="865" id="token-9-0" morph="none" pos="word" start_char="864">No</TOKEN>
<TOKEN end_char="868" id="token-9-1" morph="none" pos="word" start_char="867">es</TOKEN>
<TOKEN end_char="872" id="token-9-2" morph="none" pos="word" start_char="870">más</TOKEN>
<TOKEN end_char="876" id="token-9-3" morph="none" pos="word" start_char="874">que</TOKEN>
<TOKEN end_char="881" id="token-9-4" morph="none" pos="word" start_char="878">otra</TOKEN>
<TOKEN end_char="888" id="token-9-5" morph="none" pos="word" start_char="883">teoría</TOKEN>
<TOKEN end_char="891" id="token-9-6" morph="none" pos="word" start_char="890">de</TOKEN>
<TOKEN end_char="894" id="token-9-7" morph="none" pos="word" start_char="893">la</TOKEN>
<TOKEN end_char="907" id="token-9-8" morph="none" pos="word" start_char="896">conspiración</TOKEN>
<TOKEN end_char="911" id="token-9-9" morph="none" pos="word" start_char="909">que</TOKEN>
<TOKEN end_char="914" id="token-9-10" morph="none" pos="word" start_char="913">no</TOKEN>
<TOKEN end_char="921" id="token-9-11" morph="none" pos="word" start_char="916">aporta</TOKEN>
<TOKEN end_char="929" id="token-9-12" morph="none" pos="word" start_char="923">ninguna</TOKEN>
<TOKEN end_char="936" id="token-9-13" morph="none" pos="word" start_char="931">prueba</TOKEN>
<TOKEN end_char="940" id="token-9-14" morph="none" pos="word" start_char="938">que</TOKEN>
<TOKEN end_char="943" id="token-9-15" morph="none" pos="word" start_char="942">la</TOKEN>
<TOKEN end_char="952" id="token-9-16" morph="none" pos="word" start_char="945">confirme</TOKEN>
<TOKEN end_char="953" id="token-9-17" morph="none" pos="punct" start_char="953">.</TOKEN>
<TRANSLATED_TEXT>It is only another conspiracy theory that provides no evidence to support it.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1009" id="segment-10" start_char="956">
<ORIGINAL_TEXT>Esta en concreto ha salido publicada en el blog online</ORIGINAL_TEXT>
<TOKEN end_char="959" id="token-10-0" morph="none" pos="word" start_char="956">Esta</TOKEN>
<TOKEN end_char="962" id="token-10-1" morph="none" pos="word" start_char="961">en</TOKEN>
<TOKEN end_char="971" id="token-10-2" morph="none" pos="word" start_char="964">concreto</TOKEN>
<TOKEN end_char="974" id="token-10-3" morph="none" pos="word" start_char="973">ha</TOKEN>
<TOKEN end_char="981" id="token-10-4" morph="none" pos="word" start_char="976">salido</TOKEN>
<TOKEN end_char="991" id="token-10-5" morph="none" pos="word" start_char="983">publicada</TOKEN>
<TOKEN end_char="994" id="token-10-6" morph="none" pos="word" start_char="993">en</TOKEN>
<TOKEN end_char="997" id="token-10-7" morph="none" pos="word" start_char="996">el</TOKEN>
<TOKEN end_char="1002" id="token-10-8" morph="none" pos="word" start_char="999">blog</TOKEN>
<TOKEN end_char="1009" id="token-10-9" morph="none" pos="word" start_char="1004">online</TOKEN>
<TRANSLATED_TEXT>This particular one has been published on the online blog</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1034" id="segment-11" start_char="1012">
<ORIGINAL_TEXT>Kit Radio Internacional</ORIGINAL_TEXT>
<TOKEN end_char="1014" id="token-11-0" morph="none" pos="word" start_char="1012">Kit</TOKEN>
<TOKEN end_char="1020" id="token-11-1" morph="none" pos="word" start_char="1016">Radio</TOKEN>
<TOKEN end_char="1034" id="token-11-2" morph="none" pos="word" start_char="1022">Internacional</TOKEN>
</SEG>
<SEG end_char="1037" id="segment-12" start_char="1037">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1037" id="token-12-0" morph="none" pos="punct" start_char="1037">.</TOKEN>
</SEG>
<SEG end_char="1216" id="segment-13" start_char="1039">
<ORIGINAL_TEXT>Y lo sabemos porque científicos de varios países han analizado los genomas del agente que causa el virus y han llegado a la conclusión de que su origen está en la vida silvestre.</ORIGINAL_TEXT>
<TOKEN end_char="1039" id="token-13-0" morph="none" pos="word" start_char="1039">Y</TOKEN>
<TOKEN end_char="1042" id="token-13-1" morph="none" pos="word" start_char="1041">lo</TOKEN>
<TOKEN end_char="1050" id="token-13-2" morph="none" pos="word" start_char="1044">sabemos</TOKEN>
<TOKEN end_char="1057" id="token-13-3" morph="none" pos="word" start_char="1052">porque</TOKEN>
<TOKEN end_char="1069" id="token-13-4" morph="none" pos="word" start_char="1059">científicos</TOKEN>
<TOKEN end_char="1072" id="token-13-5" morph="none" pos="word" start_char="1071">de</TOKEN>
<TOKEN end_char="1079" id="token-13-6" morph="none" pos="word" start_char="1074">varios</TOKEN>
<TOKEN end_char="1086" id="token-13-7" morph="none" pos="word" start_char="1081">países</TOKEN>
<TOKEN end_char="1090" id="token-13-8" morph="none" pos="word" start_char="1088">han</TOKEN>
<TOKEN end_char="1100" id="token-13-9" morph="none" pos="word" start_char="1092">analizado</TOKEN>
<TOKEN end_char="1104" id="token-13-10" morph="none" pos="word" start_char="1102">los</TOKEN>
<TOKEN end_char="1112" id="token-13-11" morph="none" pos="word" start_char="1106">genomas</TOKEN>
<TOKEN end_char="1116" id="token-13-12" morph="none" pos="word" start_char="1114">del</TOKEN>
<TOKEN end_char="1123" id="token-13-13" morph="none" pos="word" start_char="1118">agente</TOKEN>
<TOKEN end_char="1127" id="token-13-14" morph="none" pos="word" start_char="1125">que</TOKEN>
<TOKEN end_char="1133" id="token-13-15" morph="none" pos="word" start_char="1129">causa</TOKEN>
<TOKEN end_char="1136" id="token-13-16" morph="none" pos="word" start_char="1135">el</TOKEN>
<TOKEN end_char="1142" id="token-13-17" morph="none" pos="word" start_char="1138">virus</TOKEN>
<TOKEN end_char="1144" id="token-13-18" morph="none" pos="word" start_char="1144">y</TOKEN>
<TOKEN end_char="1148" id="token-13-19" morph="none" pos="word" start_char="1146">han</TOKEN>
<TOKEN end_char="1156" id="token-13-20" morph="none" pos="word" start_char="1150">llegado</TOKEN>
<TOKEN end_char="1158" id="token-13-21" morph="none" pos="word" start_char="1158">a</TOKEN>
<TOKEN end_char="1161" id="token-13-22" morph="none" pos="word" start_char="1160">la</TOKEN>
<TOKEN end_char="1172" id="token-13-23" morph="none" pos="word" start_char="1163">conclusión</TOKEN>
<TOKEN end_char="1175" id="token-13-24" morph="none" pos="word" start_char="1174">de</TOKEN>
<TOKEN end_char="1179" id="token-13-25" morph="none" pos="word" start_char="1177">que</TOKEN>
<TOKEN end_char="1182" id="token-13-26" morph="none" pos="word" start_char="1181">su</TOKEN>
<TOKEN end_char="1189" id="token-13-27" morph="none" pos="word" start_char="1184">origen</TOKEN>
<TOKEN end_char="1194" id="token-13-28" morph="none" pos="word" start_char="1191">está</TOKEN>
<TOKEN end_char="1197" id="token-13-29" morph="none" pos="word" start_char="1196">en</TOKEN>
<TOKEN end_char="1200" id="token-13-30" morph="none" pos="word" start_char="1199">la</TOKEN>
<TOKEN end_char="1205" id="token-13-31" morph="none" pos="word" start_char="1202">vida</TOKEN>
<TOKEN end_char="1215" id="token-13-32" morph="none" pos="word" start_char="1207">silvestre</TOKEN>
<TOKEN end_char="1216" id="token-13-33" morph="none" pos="punct" start_char="1216">.</TOKEN>
<TRANSLATED_TEXT>And we know that because scientists from several countries have analyzed the genomes of the agent that causes the virus and have concluded that its origin is in the wild.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1289" id="segment-14" start_char="1219">
<ORIGINAL_TEXT>El bulo de que el coronavirus salió de un laboratorio de Estados Unidos</ORIGINAL_TEXT>
<TOKEN end_char="1220" id="token-14-0" morph="none" pos="word" start_char="1219">El</TOKEN>
<TOKEN end_char="1225" id="token-14-1" morph="none" pos="word" start_char="1222">bulo</TOKEN>
<TOKEN end_char="1228" id="token-14-2" morph="none" pos="word" start_char="1227">de</TOKEN>
<TOKEN end_char="1232" id="token-14-3" morph="none" pos="word" start_char="1230">que</TOKEN>
<TOKEN end_char="1235" id="token-14-4" morph="none" pos="word" start_char="1234">el</TOKEN>
<TOKEN end_char="1247" id="token-14-5" morph="none" pos="word" start_char="1237">coronavirus</TOKEN>
<TOKEN end_char="1253" id="token-14-6" morph="none" pos="word" start_char="1249">salió</TOKEN>
<TOKEN end_char="1256" id="token-14-7" morph="none" pos="word" start_char="1255">de</TOKEN>
<TOKEN end_char="1259" id="token-14-8" morph="none" pos="word" start_char="1258">un</TOKEN>
<TOKEN end_char="1271" id="token-14-9" morph="none" pos="word" start_char="1261">laboratorio</TOKEN>
<TOKEN end_char="1274" id="token-14-10" morph="none" pos="word" start_char="1273">de</TOKEN>
<TOKEN end_char="1282" id="token-14-11" morph="none" pos="word" start_char="1276">Estados</TOKEN>
<TOKEN end_char="1289" id="token-14-12" morph="none" pos="word" start_char="1284">Unidos</TOKEN>
<TRANSLATED_TEXT>The Myth That the Coronavirus Came From an American Laboratory</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1487" id="segment-15" start_char="1293">
<ORIGINAL_TEXT>Albert Bosch Navarro, presidente de la Sociedad Española de Virología, se muestra tajante al respecto: "Siempre que aparece una nueva epidemia se oyen rumores sobre su creación en un laboratorio.</ORIGINAL_TEXT>
<TOKEN end_char="1298" id="token-15-0" morph="none" pos="word" start_char="1293">Albert</TOKEN>
<TOKEN end_char="1304" id="token-15-1" morph="none" pos="word" start_char="1300">Bosch</TOKEN>
<TOKEN end_char="1312" id="token-15-2" morph="none" pos="word" start_char="1306">Navarro</TOKEN>
<TOKEN end_char="1313" id="token-15-3" morph="none" pos="punct" start_char="1313">,</TOKEN>
<TOKEN end_char="1324" id="token-15-4" morph="none" pos="word" start_char="1315">presidente</TOKEN>
<TOKEN end_char="1327" id="token-15-5" morph="none" pos="word" start_char="1326">de</TOKEN>
<TOKEN end_char="1330" id="token-15-6" morph="none" pos="word" start_char="1329">la</TOKEN>
<TOKEN end_char="1339" id="token-15-7" morph="none" pos="word" start_char="1332">Sociedad</TOKEN>
<TOKEN end_char="1348" id="token-15-8" morph="none" pos="word" start_char="1341">Española</TOKEN>
<TOKEN end_char="1351" id="token-15-9" morph="none" pos="word" start_char="1350">de</TOKEN>
<TOKEN end_char="1361" id="token-15-10" morph="none" pos="word" start_char="1353">Virología</TOKEN>
<TOKEN end_char="1362" id="token-15-11" morph="none" pos="punct" start_char="1362">,</TOKEN>
<TOKEN end_char="1365" id="token-15-12" morph="none" pos="word" start_char="1364">se</TOKEN>
<TOKEN end_char="1373" id="token-15-13" morph="none" pos="word" start_char="1367">muestra</TOKEN>
<TOKEN end_char="1381" id="token-15-14" morph="none" pos="word" start_char="1375">tajante</TOKEN>
<TOKEN end_char="1384" id="token-15-15" morph="none" pos="word" start_char="1383">al</TOKEN>
<TOKEN end_char="1393" id="token-15-16" morph="none" pos="word" start_char="1386">respecto</TOKEN>
<TOKEN end_char="1394" id="token-15-17" morph="none" pos="punct" start_char="1394">:</TOKEN>
<TOKEN end_char="1396" id="token-15-18" morph="none" pos="punct" start_char="1396">"</TOKEN>
<TOKEN end_char="1403" id="token-15-19" morph="none" pos="word" start_char="1397">Siempre</TOKEN>
<TOKEN end_char="1407" id="token-15-20" morph="none" pos="word" start_char="1405">que</TOKEN>
<TOKEN end_char="1415" id="token-15-21" morph="none" pos="word" start_char="1409">aparece</TOKEN>
<TOKEN end_char="1419" id="token-15-22" morph="none" pos="word" start_char="1417">una</TOKEN>
<TOKEN end_char="1425" id="token-15-23" morph="none" pos="word" start_char="1421">nueva</TOKEN>
<TOKEN end_char="1434" id="token-15-24" morph="none" pos="word" start_char="1427">epidemia</TOKEN>
<TOKEN end_char="1437" id="token-15-25" morph="none" pos="word" start_char="1436">se</TOKEN>
<TOKEN end_char="1442" id="token-15-26" morph="none" pos="word" start_char="1439">oyen</TOKEN>
<TOKEN end_char="1450" id="token-15-27" morph="none" pos="word" start_char="1444">rumores</TOKEN>
<TOKEN end_char="1456" id="token-15-28" morph="none" pos="word" start_char="1452">sobre</TOKEN>
<TOKEN end_char="1459" id="token-15-29" morph="none" pos="word" start_char="1458">su</TOKEN>
<TOKEN end_char="1468" id="token-15-30" morph="none" pos="word" start_char="1461">creación</TOKEN>
<TOKEN end_char="1471" id="token-15-31" morph="none" pos="word" start_char="1470">en</TOKEN>
<TOKEN end_char="1474" id="token-15-32" morph="none" pos="word" start_char="1473">un</TOKEN>
<TOKEN end_char="1486" id="token-15-33" morph="none" pos="word" start_char="1476">laboratorio</TOKEN>
<TOKEN end_char="1487" id="token-15-34" morph="none" pos="punct" start_char="1487">.</TOKEN>
<TRANSLATED_TEXT>Albert Bosch Navarro, president of the Spanish Society of Virology, says: "Whenever a new epidemic appears, rumors of its creation are heard in a laboratory.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1568" id="segment-16" start_char="1489">
<ORIGINAL_TEXT>Sucedió en el 2002 con el SARS, en el 2009 con el H1N1 y ahora con la Covid-19".</ORIGINAL_TEXT>
<TOKEN end_char="1495" id="token-16-0" morph="none" pos="word" start_char="1489">Sucedió</TOKEN>
<TOKEN end_char="1498" id="token-16-1" morph="none" pos="word" start_char="1497">en</TOKEN>
<TOKEN end_char="1501" id="token-16-2" morph="none" pos="word" start_char="1500">el</TOKEN>
<TOKEN end_char="1506" id="token-16-3" morph="none" pos="word" start_char="1503">2002</TOKEN>
<TOKEN end_char="1510" id="token-16-4" morph="none" pos="word" start_char="1508">con</TOKEN>
<TOKEN end_char="1513" id="token-16-5" morph="none" pos="word" start_char="1512">el</TOKEN>
<TOKEN end_char="1518" id="token-16-6" morph="none" pos="word" start_char="1515">SARS</TOKEN>
<TOKEN end_char="1519" id="token-16-7" morph="none" pos="punct" start_char="1519">,</TOKEN>
<TOKEN end_char="1522" id="token-16-8" morph="none" pos="word" start_char="1521">en</TOKEN>
<TOKEN end_char="1525" id="token-16-9" morph="none" pos="word" start_char="1524">el</TOKEN>
<TOKEN end_char="1530" id="token-16-10" morph="none" pos="word" start_char="1527">2009</TOKEN>
<TOKEN end_char="1534" id="token-16-11" morph="none" pos="word" start_char="1532">con</TOKEN>
<TOKEN end_char="1537" id="token-16-12" morph="none" pos="word" start_char="1536">el</TOKEN>
<TOKEN end_char="1542" id="token-16-13" morph="none" pos="word" start_char="1539">H1N1</TOKEN>
<TOKEN end_char="1544" id="token-16-14" morph="none" pos="word" start_char="1544">y</TOKEN>
<TOKEN end_char="1550" id="token-16-15" morph="none" pos="word" start_char="1546">ahora</TOKEN>
<TOKEN end_char="1554" id="token-16-16" morph="none" pos="word" start_char="1552">con</TOKEN>
<TOKEN end_char="1557" id="token-16-17" morph="none" pos="word" start_char="1556">la</TOKEN>
<TOKEN end_char="1566" id="token-16-18" morph="none" pos="unknown" start_char="1559">Covid-19</TOKEN>
<TOKEN end_char="1568" id="token-16-19" morph="none" pos="punct" start_char="1567">".</TOKEN>
<TRANSLATED_TEXT>It happened in 2002 with SARS, in 2009 with H1N1 and now with Covid-19. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1632" id="segment-17" start_char="1571">
<ORIGINAL_TEXT>Artículos publicados en prestigiosas revistas científicas como</ORIGINAL_TEXT>
<TOKEN end_char="1579" id="token-17-0" morph="none" pos="word" start_char="1571">Artículos</TOKEN>
<TOKEN end_char="1590" id="token-17-1" morph="none" pos="word" start_char="1581">publicados</TOKEN>
<TOKEN end_char="1593" id="token-17-2" morph="none" pos="word" start_char="1592">en</TOKEN>
<TOKEN end_char="1606" id="token-17-3" morph="none" pos="word" start_char="1595">prestigiosas</TOKEN>
<TOKEN end_char="1615" id="token-17-4" morph="none" pos="word" start_char="1608">revistas</TOKEN>
<TOKEN end_char="1627" id="token-17-5" morph="none" pos="word" start_char="1617">científicas</TOKEN>
<TOKEN end_char="1632" id="token-17-6" morph="none" pos="word" start_char="1629">como</TOKEN>
<TRANSLATED_TEXT>Articles published in prestigious scientific journals such as</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1649" id="segment-18" start_char="1635">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN end_char="1640" id="token-18-0" morph="none" pos="word" start_char="1635">Nature</TOKEN>
<TOKEN end_char="1649" id="token-18-1" morph="none" pos="word" start_char="1642">Medicine</TOKEN>
<TRANSLATED_TEXT>Naturmedicin</TRANSLATED_TEXT><DETECTED_LANGUAGE>ro</DETECTED_LANGUAGE></SEG>
<SEG end_char="1652" id="segment-19" start_char="1652">
<ORIGINAL_TEXT>y</ORIGINAL_TEXT>
<TOKEN end_char="1652" id="token-19-0" morph="none" pos="word" start_char="1652">y</TOKEN>
</SEG>
<SEG end_char="1664" id="segment-20" start_char="1655">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN end_char="1657" id="token-20-0" morph="none" pos="word" start_char="1655">The</TOKEN>
<TOKEN end_char="1664" id="token-20-1" morph="none" pos="word" start_char="1659">Lancet</TOKEN>
</SEG>
<SEG end_char="1804" id="segment-21" start_char="1667">
<ORIGINAL_TEXT>confirman las palabras de Bosch al sostener que ninguno de estos virus ha sido creado en un laboratorio ni ha sido manipulado a propósito.</ORIGINAL_TEXT>
<TOKEN end_char="1675" id="token-21-0" morph="none" pos="word" start_char="1667">confirman</TOKEN>
<TOKEN end_char="1679" id="token-21-1" morph="none" pos="word" start_char="1677">las</TOKEN>
<TOKEN end_char="1688" id="token-21-2" morph="none" pos="word" start_char="1681">palabras</TOKEN>
<TOKEN end_char="1691" id="token-21-3" morph="none" pos="word" start_char="1690">de</TOKEN>
<TOKEN end_char="1697" id="token-21-4" morph="none" pos="word" start_char="1693">Bosch</TOKEN>
<TOKEN end_char="1700" id="token-21-5" morph="none" pos="word" start_char="1699">al</TOKEN>
<TOKEN end_char="1709" id="token-21-6" morph="none" pos="word" start_char="1702">sostener</TOKEN>
<TOKEN end_char="1713" id="token-21-7" morph="none" pos="word" start_char="1711">que</TOKEN>
<TOKEN end_char="1721" id="token-21-8" morph="none" pos="word" start_char="1715">ninguno</TOKEN>
<TOKEN end_char="1724" id="token-21-9" morph="none" pos="word" start_char="1723">de</TOKEN>
<TOKEN end_char="1730" id="token-21-10" morph="none" pos="word" start_char="1726">estos</TOKEN>
<TOKEN end_char="1736" id="token-21-11" morph="none" pos="word" start_char="1732">virus</TOKEN>
<TOKEN end_char="1739" id="token-21-12" morph="none" pos="word" start_char="1738">ha</TOKEN>
<TOKEN end_char="1744" id="token-21-13" morph="none" pos="word" start_char="1741">sido</TOKEN>
<TOKEN end_char="1751" id="token-21-14" morph="none" pos="word" start_char="1746">creado</TOKEN>
<TOKEN end_char="1754" id="token-21-15" morph="none" pos="word" start_char="1753">en</TOKEN>
<TOKEN end_char="1757" id="token-21-16" morph="none" pos="word" start_char="1756">un</TOKEN>
<TOKEN end_char="1769" id="token-21-17" morph="none" pos="word" start_char="1759">laboratorio</TOKEN>
<TOKEN end_char="1772" id="token-21-18" morph="none" pos="word" start_char="1771">ni</TOKEN>
<TOKEN end_char="1775" id="token-21-19" morph="none" pos="word" start_char="1774">ha</TOKEN>
<TOKEN end_char="1780" id="token-21-20" morph="none" pos="word" start_char="1777">sido</TOKEN>
<TOKEN end_char="1791" id="token-21-21" morph="none" pos="word" start_char="1782">manipulado</TOKEN>
<TOKEN end_char="1793" id="token-21-22" morph="none" pos="word" start_char="1793">a</TOKEN>
<TOKEN end_char="1803" id="token-21-23" morph="none" pos="word" start_char="1795">propósito</TOKEN>
<TOKEN end_char="1804" id="token-21-24" morph="none" pos="punct" start_char="1804">.</TOKEN>
<TRANSLATED_TEXT>confirm Bosch's words by arguing that none of these viruses have been created in a laboratory or intentionally manipulated.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2115" id="segment-22" start_char="1807">
<ORIGINAL_TEXT>En lo que respecta al objetivo de acabar con las personas mayores, este bulo adquiere tintes dramáticos, ya que hace referencia a una supuesta cita de la expresidenta del Fondo Monetario Internacional, Christine Lagarde, según la cual "los ancianos viven demasiado y eso es un riesgo para la economía global".</ORIGINAL_TEXT>
<TOKEN end_char="1808" id="token-22-0" morph="none" pos="word" start_char="1807">En</TOKEN>
<TOKEN end_char="1811" id="token-22-1" morph="none" pos="word" start_char="1810">lo</TOKEN>
<TOKEN end_char="1815" id="token-22-2" morph="none" pos="word" start_char="1813">que</TOKEN>
<TOKEN end_char="1824" id="token-22-3" morph="none" pos="word" start_char="1817">respecta</TOKEN>
<TOKEN end_char="1827" id="token-22-4" morph="none" pos="word" start_char="1826">al</TOKEN>
<TOKEN end_char="1836" id="token-22-5" morph="none" pos="word" start_char="1829">objetivo</TOKEN>
<TOKEN end_char="1839" id="token-22-6" morph="none" pos="word" start_char="1838">de</TOKEN>
<TOKEN end_char="1846" id="token-22-7" morph="none" pos="word" start_char="1841">acabar</TOKEN>
<TOKEN end_char="1850" id="token-22-8" morph="none" pos="word" start_char="1848">con</TOKEN>
<TOKEN end_char="1854" id="token-22-9" morph="none" pos="word" start_char="1852">las</TOKEN>
<TOKEN end_char="1863" id="token-22-10" morph="none" pos="word" start_char="1856">personas</TOKEN>
<TOKEN end_char="1871" id="token-22-11" morph="none" pos="word" start_char="1865">mayores</TOKEN>
<TOKEN end_char="1872" id="token-22-12" morph="none" pos="punct" start_char="1872">,</TOKEN>
<TOKEN end_char="1877" id="token-22-13" morph="none" pos="word" start_char="1874">este</TOKEN>
<TOKEN end_char="1882" id="token-22-14" morph="none" pos="word" start_char="1879">bulo</TOKEN>
<TOKEN end_char="1891" id="token-22-15" morph="none" pos="word" start_char="1884">adquiere</TOKEN>
<TOKEN end_char="1898" id="token-22-16" morph="none" pos="word" start_char="1893">tintes</TOKEN>
<TOKEN end_char="1909" id="token-22-17" morph="none" pos="word" start_char="1900">dramáticos</TOKEN>
<TOKEN end_char="1910" id="token-22-18" morph="none" pos="punct" start_char="1910">,</TOKEN>
<TOKEN end_char="1913" id="token-22-19" morph="none" pos="word" start_char="1912">ya</TOKEN>
<TOKEN end_char="1917" id="token-22-20" morph="none" pos="word" start_char="1915">que</TOKEN>
<TOKEN end_char="1922" id="token-22-21" morph="none" pos="word" start_char="1919">hace</TOKEN>
<TOKEN end_char="1933" id="token-22-22" morph="none" pos="word" start_char="1924">referencia</TOKEN>
<TOKEN end_char="1935" id="token-22-23" morph="none" pos="word" start_char="1935">a</TOKEN>
<TOKEN end_char="1939" id="token-22-24" morph="none" pos="word" start_char="1937">una</TOKEN>
<TOKEN end_char="1948" id="token-22-25" morph="none" pos="word" start_char="1941">supuesta</TOKEN>
<TOKEN end_char="1953" id="token-22-26" morph="none" pos="word" start_char="1950">cita</TOKEN>
<TOKEN end_char="1956" id="token-22-27" morph="none" pos="word" start_char="1955">de</TOKEN>
<TOKEN end_char="1959" id="token-22-28" morph="none" pos="word" start_char="1958">la</TOKEN>
<TOKEN end_char="1972" id="token-22-29" morph="none" pos="word" start_char="1961">expresidenta</TOKEN>
<TOKEN end_char="1976" id="token-22-30" morph="none" pos="word" start_char="1974">del</TOKEN>
<TOKEN end_char="1982" id="token-22-31" morph="none" pos="word" start_char="1978">Fondo</TOKEN>
<TOKEN end_char="1992" id="token-22-32" morph="none" pos="word" start_char="1984">Monetario</TOKEN>
<TOKEN end_char="2006" id="token-22-33" morph="none" pos="word" start_char="1994">Internacional</TOKEN>
<TOKEN end_char="2007" id="token-22-34" morph="none" pos="punct" start_char="2007">,</TOKEN>
<TOKEN end_char="2017" id="token-22-35" morph="none" pos="word" start_char="2009">Christine</TOKEN>
<TOKEN end_char="2025" id="token-22-36" morph="none" pos="word" start_char="2019">Lagarde</TOKEN>
<TOKEN end_char="2026" id="token-22-37" morph="none" pos="punct" start_char="2026">,</TOKEN>
<TOKEN end_char="2032" id="token-22-38" morph="none" pos="word" start_char="2028">según</TOKEN>
<TOKEN end_char="2035" id="token-22-39" morph="none" pos="word" start_char="2034">la</TOKEN>
<TOKEN end_char="2040" id="token-22-40" morph="none" pos="word" start_char="2037">cual</TOKEN>
<TOKEN end_char="2042" id="token-22-41" morph="none" pos="punct" start_char="2042">"</TOKEN>
<TOKEN end_char="2045" id="token-22-42" morph="none" pos="word" start_char="2043">los</TOKEN>
<TOKEN end_char="2054" id="token-22-43" morph="none" pos="word" start_char="2047">ancianos</TOKEN>
<TOKEN end_char="2060" id="token-22-44" morph="none" pos="word" start_char="2056">viven</TOKEN>
<TOKEN end_char="2070" id="token-22-45" morph="none" pos="word" start_char="2062">demasiado</TOKEN>
<TOKEN end_char="2072" id="token-22-46" morph="none" pos="word" start_char="2072">y</TOKEN>
<TOKEN end_char="2076" id="token-22-47" morph="none" pos="word" start_char="2074">eso</TOKEN>
<TOKEN end_char="2079" id="token-22-48" morph="none" pos="word" start_char="2078">es</TOKEN>
<TOKEN end_char="2082" id="token-22-49" morph="none" pos="word" start_char="2081">un</TOKEN>
<TOKEN end_char="2089" id="token-22-50" morph="none" pos="word" start_char="2084">riesgo</TOKEN>
<TOKEN end_char="2094" id="token-22-51" morph="none" pos="word" start_char="2091">para</TOKEN>
<TOKEN end_char="2097" id="token-22-52" morph="none" pos="word" start_char="2096">la</TOKEN>
<TOKEN end_char="2106" id="token-22-53" morph="none" pos="word" start_char="2099">economía</TOKEN>
<TOKEN end_char="2113" id="token-22-54" morph="none" pos="word" start_char="2108">global</TOKEN>
<TOKEN end_char="2115" id="token-22-55" morph="none" pos="punct" start_char="2114">".</TOKEN>
<TRANSLATED_TEXT>With regard to the goal of ending the elderly, this blur is dramatic, as it refers to a supposed quote by former International Monetary Fund President Christine Lagarde that "the elderly live too much and that is a risk to the global economy."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2324" id="segment-23" start_char="2118">
<ORIGINAL_TEXT>Por supuesto, no hay pruebas de que Lagarde haya realizado nunca semejantes declaraciones; de hecho, desde el Banco Central Europeo, organismo que ahora preside Lagarde, ya han desmentido esas informaciones.</ORIGINAL_TEXT>
<TOKEN end_char="2120" id="token-23-0" morph="none" pos="word" start_char="2118">Por</TOKEN>
<TOKEN end_char="2129" id="token-23-1" morph="none" pos="word" start_char="2122">supuesto</TOKEN>
<TOKEN end_char="2130" id="token-23-2" morph="none" pos="punct" start_char="2130">,</TOKEN>
<TOKEN end_char="2133" id="token-23-3" morph="none" pos="word" start_char="2132">no</TOKEN>
<TOKEN end_char="2137" id="token-23-4" morph="none" pos="word" start_char="2135">hay</TOKEN>
<TOKEN end_char="2145" id="token-23-5" morph="none" pos="word" start_char="2139">pruebas</TOKEN>
<TOKEN end_char="2148" id="token-23-6" morph="none" pos="word" start_char="2147">de</TOKEN>
<TOKEN end_char="2152" id="token-23-7" morph="none" pos="word" start_char="2150">que</TOKEN>
<TOKEN end_char="2160" id="token-23-8" morph="none" pos="word" start_char="2154">Lagarde</TOKEN>
<TOKEN end_char="2165" id="token-23-9" morph="none" pos="word" start_char="2162">haya</TOKEN>
<TOKEN end_char="2175" id="token-23-10" morph="none" pos="word" start_char="2167">realizado</TOKEN>
<TOKEN end_char="2181" id="token-23-11" morph="none" pos="word" start_char="2177">nunca</TOKEN>
<TOKEN end_char="2192" id="token-23-12" morph="none" pos="word" start_char="2183">semejantes</TOKEN>
<TOKEN end_char="2206" id="token-23-13" morph="none" pos="word" start_char="2194">declaraciones</TOKEN>
<TOKEN end_char="2207" id="token-23-14" morph="none" pos="punct" start_char="2207">;</TOKEN>
<TOKEN end_char="2210" id="token-23-15" morph="none" pos="word" start_char="2209">de</TOKEN>
<TOKEN end_char="2216" id="token-23-16" morph="none" pos="word" start_char="2212">hecho</TOKEN>
<TOKEN end_char="2217" id="token-23-17" morph="none" pos="punct" start_char="2217">,</TOKEN>
<TOKEN end_char="2223" id="token-23-18" morph="none" pos="word" start_char="2219">desde</TOKEN>
<TOKEN end_char="2226" id="token-23-19" morph="none" pos="word" start_char="2225">el</TOKEN>
<TOKEN end_char="2232" id="token-23-20" morph="none" pos="word" start_char="2228">Banco</TOKEN>
<TOKEN end_char="2240" id="token-23-21" morph="none" pos="word" start_char="2234">Central</TOKEN>
<TOKEN end_char="2248" id="token-23-22" morph="none" pos="word" start_char="2242">Europeo</TOKEN>
<TOKEN end_char="2249" id="token-23-23" morph="none" pos="punct" start_char="2249">,</TOKEN>
<TOKEN end_char="2259" id="token-23-24" morph="none" pos="word" start_char="2251">organismo</TOKEN>
<TOKEN end_char="2263" id="token-23-25" morph="none" pos="word" start_char="2261">que</TOKEN>
<TOKEN end_char="2269" id="token-23-26" morph="none" pos="word" start_char="2265">ahora</TOKEN>
<TOKEN end_char="2277" id="token-23-27" morph="none" pos="word" start_char="2271">preside</TOKEN>
<TOKEN end_char="2285" id="token-23-28" morph="none" pos="word" start_char="2279">Lagarde</TOKEN>
<TOKEN end_char="2286" id="token-23-29" morph="none" pos="punct" start_char="2286">,</TOKEN>
<TOKEN end_char="2289" id="token-23-30" morph="none" pos="word" start_char="2288">ya</TOKEN>
<TOKEN end_char="2293" id="token-23-31" morph="none" pos="word" start_char="2291">han</TOKEN>
<TOKEN end_char="2304" id="token-23-32" morph="none" pos="word" start_char="2295">desmentido</TOKEN>
<TOKEN end_char="2309" id="token-23-33" morph="none" pos="word" start_char="2306">esas</TOKEN>
<TOKEN end_char="2323" id="token-23-34" morph="none" pos="word" start_char="2311">informaciones</TOKEN>
<TOKEN end_char="2324" id="token-23-35" morph="none" pos="punct" start_char="2324">.</TOKEN>
<TRANSLATED_TEXT>Of course, there is no evidence that Lagarde has ever made such statements; indeed, the European Central Bank, the body that now chairs Lagarde, has already denied this information.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2347" id="segment-24" start_char="2326">
<ORIGINAL_TEXT>Pero así funcionan las</ORIGINAL_TEXT>
<TOKEN end_char="2329" id="token-24-0" morph="none" pos="word" start_char="2326">Pero</TOKEN>
<TOKEN end_char="2333" id="token-24-1" morph="none" pos="word" start_char="2331">así</TOKEN>
<TOKEN end_char="2343" id="token-24-2" morph="none" pos="word" start_char="2335">funcionan</TOKEN>
<TOKEN end_char="2347" id="token-24-3" morph="none" pos="word" start_char="2345">las</TOKEN>
<TRANSLATED_TEXT>But that 's how they work.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2358" id="segment-25" start_char="2350">
<ORIGINAL_TEXT>fake news</ORIGINAL_TEXT>
<TOKEN end_char="2353" id="token-25-0" morph="none" pos="word" start_char="2350">fake</TOKEN>
<TOKEN end_char="2358" id="token-25-1" morph="none" pos="word" start_char="2355">news</TOKEN>
<TRANSLATED_TEXT>Fakte Nyheter</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="2487" id="segment-26" start_char="2361">
<ORIGINAL_TEXT>, dando apariencia de veracidad a expresiones que nunca se han pronunciado o que no las ha pronunciado esa persona en cuestión.</ORIGINAL_TEXT>
<TOKEN end_char="2361" id="token-26-0" morph="none" pos="punct" start_char="2361">,</TOKEN>
<TOKEN end_char="2367" id="token-26-1" morph="none" pos="word" start_char="2363">dando</TOKEN>
<TOKEN end_char="2378" id="token-26-2" morph="none" pos="word" start_char="2369">apariencia</TOKEN>
<TOKEN end_char="2381" id="token-26-3" morph="none" pos="word" start_char="2380">de</TOKEN>
<TOKEN end_char="2391" id="token-26-4" morph="none" pos="word" start_char="2383">veracidad</TOKEN>
<TOKEN end_char="2393" id="token-26-5" morph="none" pos="word" start_char="2393">a</TOKEN>
<TOKEN end_char="2405" id="token-26-6" morph="none" pos="word" start_char="2395">expresiones</TOKEN>
<TOKEN end_char="2409" id="token-26-7" morph="none" pos="word" start_char="2407">que</TOKEN>
<TOKEN end_char="2415" id="token-26-8" morph="none" pos="word" start_char="2411">nunca</TOKEN>
<TOKEN end_char="2418" id="token-26-9" morph="none" pos="word" start_char="2417">se</TOKEN>
<TOKEN end_char="2422" id="token-26-10" morph="none" pos="word" start_char="2420">han</TOKEN>
<TOKEN end_char="2434" id="token-26-11" morph="none" pos="word" start_char="2424">pronunciado</TOKEN>
<TOKEN end_char="2436" id="token-26-12" morph="none" pos="word" start_char="2436">o</TOKEN>
<TOKEN end_char="2440" id="token-26-13" morph="none" pos="word" start_char="2438">que</TOKEN>
<TOKEN end_char="2443" id="token-26-14" morph="none" pos="word" start_char="2442">no</TOKEN>
<TOKEN end_char="2447" id="token-26-15" morph="none" pos="word" start_char="2445">las</TOKEN>
<TOKEN end_char="2450" id="token-26-16" morph="none" pos="word" start_char="2449">ha</TOKEN>
<TOKEN end_char="2462" id="token-26-17" morph="none" pos="word" start_char="2452">pronunciado</TOKEN>
<TOKEN end_char="2466" id="token-26-18" morph="none" pos="word" start_char="2464">esa</TOKEN>
<TOKEN end_char="2474" id="token-26-19" morph="none" pos="word" start_char="2468">persona</TOKEN>
<TOKEN end_char="2477" id="token-26-20" morph="none" pos="word" start_char="2476">en</TOKEN>
<TOKEN end_char="2486" id="token-26-21" morph="none" pos="word" start_char="2479">cuestión</TOKEN>
<TOKEN end_char="2487" id="token-26-22" morph="none" pos="punct" start_char="2487">.</TOKEN>
<TRANSLATED_TEXT>, giving the appearance of truthfulness to expressions that have never been pronounced or that have not been pronounced by the person in question.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2514" id="segment-27" start_char="2489">
<ORIGINAL_TEXT>¡Otro bulo desenmascarado!</ORIGINAL_TEXT>
<TOKEN end_char="2489" id="token-27-0" morph="none" pos="punct" start_char="2489">¡</TOKEN>
<TOKEN end_char="2493" id="token-27-1" morph="none" pos="word" start_char="2490">Otro</TOKEN>
<TOKEN end_char="2498" id="token-27-2" morph="none" pos="word" start_char="2495">bulo</TOKEN>
<TOKEN end_char="2513" id="token-27-3" morph="none" pos="word" start_char="2500">desenmascarado</TOKEN>
<TOKEN end_char="2514" id="token-27-4" morph="none" pos="punct" start_char="2514">!</TOKEN>
<TRANSLATED_TEXT>Another unmasked hoax!</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATQ0" lang="spa" raw_text_char_length="2025" raw_text_md5="6d13e487898a53495e0572c5ca9744dc" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="96" id="segment-0" start_char="1">
<ORIGINAL_TEXT>China rechaza versión de que el coronavirus surgió en agosto y acusa intento de "desinformación"</ORIGINAL_TEXT>
<TOKEN end_char="5" id="token-0-0" morph="none" pos="word" start_char="1">China</TOKEN>
<TOKEN end_char="13" id="token-0-1" morph="none" pos="word" start_char="7">rechaza</TOKEN>
<TOKEN end_char="21" id="token-0-2" morph="none" pos="word" start_char="15">versión</TOKEN>
<TOKEN end_char="24" id="token-0-3" morph="none" pos="word" start_char="23">de</TOKEN>
<TOKEN end_char="28" id="token-0-4" morph="none" pos="word" start_char="26">que</TOKEN>
<TOKEN end_char="31" id="token-0-5" morph="none" pos="word" start_char="30">el</TOKEN>
<TOKEN end_char="43" id="token-0-6" morph="none" pos="word" start_char="33">coronavirus</TOKEN>
<TOKEN end_char="50" id="token-0-7" morph="none" pos="word" start_char="45">surgió</TOKEN>
<TOKEN end_char="53" id="token-0-8" morph="none" pos="word" start_char="52">en</TOKEN>
<TOKEN end_char="60" id="token-0-9" morph="none" pos="word" start_char="55">agosto</TOKEN>
<TOKEN end_char="62" id="token-0-10" morph="none" pos="word" start_char="62">y</TOKEN>
<TOKEN end_char="68" id="token-0-11" morph="none" pos="word" start_char="64">acusa</TOKEN>
<TOKEN end_char="76" id="token-0-12" morph="none" pos="word" start_char="70">intento</TOKEN>
<TOKEN end_char="79" id="token-0-13" morph="none" pos="word" start_char="78">de</TOKEN>
<TOKEN end_char="81" id="token-0-14" morph="none" pos="punct" start_char="81">"</TOKEN>
<TOKEN end_char="95" id="token-0-15" morph="none" pos="word" start_char="82">desinformación</TOKEN>
<TOKEN end_char="96" id="token-0-16" morph="none" pos="punct" start_char="96">"</TOKEN>
<TRANSLATED_TEXT>China rejects version that coronavirus emerged in August and accuses attempt at "disinformation"</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="150" id="segment-1" start_char="101">
<ORIGINAL_TEXT>Todo Avisos, para publicar sus avisos clasificados</ORIGINAL_TEXT>
<TOKEN end_char="104" id="token-1-0" morph="none" pos="word" start_char="101">Todo</TOKEN>
<TOKEN end_char="111" id="token-1-1" morph="none" pos="word" start_char="106">Avisos</TOKEN>
<TOKEN end_char="112" id="token-1-2" morph="none" pos="punct" start_char="112">,</TOKEN>
<TOKEN end_char="117" id="token-1-3" morph="none" pos="word" start_char="114">para</TOKEN>
<TOKEN end_char="126" id="token-1-4" morph="none" pos="word" start_char="119">publicar</TOKEN>
<TOKEN end_char="130" id="token-1-5" morph="none" pos="word" start_char="128">sus</TOKEN>
<TOKEN end_char="137" id="token-1-6" morph="none" pos="word" start_char="132">avisos</TOKEN>
<TOKEN end_char="150" id="token-1-7" morph="none" pos="word" start_char="139">clasificados</TOKEN>
<TRANSLATED_TEXT>All Notices, to publish your classified notices</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="385" id="segment-2" start_char="156">
<ORIGINAL_TEXT>El estudio preliminar de investigadores de las prestigiosas universidades de Boston y Harvard deja entrever que la epidemia pudo surgir en el verano de 2019 en Wuhan, metrópoli del centro de China que quedó en cuarentena en enero.</ORIGINAL_TEXT>
<TOKEN end_char="157" id="token-2-0" morph="none" pos="word" start_char="156">El</TOKEN>
<TOKEN end_char="165" id="token-2-1" morph="none" pos="word" start_char="159">estudio</TOKEN>
<TOKEN end_char="176" id="token-2-2" morph="none" pos="word" start_char="167">preliminar</TOKEN>
<TOKEN end_char="179" id="token-2-3" morph="none" pos="word" start_char="178">de</TOKEN>
<TOKEN end_char="194" id="token-2-4" morph="none" pos="word" start_char="181">investigadores</TOKEN>
<TOKEN end_char="197" id="token-2-5" morph="none" pos="word" start_char="196">de</TOKEN>
<TOKEN end_char="201" id="token-2-6" morph="none" pos="word" start_char="199">las</TOKEN>
<TOKEN end_char="214" id="token-2-7" morph="none" pos="word" start_char="203">prestigiosas</TOKEN>
<TOKEN end_char="228" id="token-2-8" morph="none" pos="word" start_char="216">universidades</TOKEN>
<TOKEN end_char="231" id="token-2-9" morph="none" pos="word" start_char="230">de</TOKEN>
<TOKEN end_char="238" id="token-2-10" morph="none" pos="word" start_char="233">Boston</TOKEN>
<TOKEN end_char="240" id="token-2-11" morph="none" pos="word" start_char="240">y</TOKEN>
<TOKEN end_char="248" id="token-2-12" morph="none" pos="word" start_char="242">Harvard</TOKEN>
<TOKEN end_char="253" id="token-2-13" morph="none" pos="word" start_char="250">deja</TOKEN>
<TOKEN end_char="262" id="token-2-14" morph="none" pos="word" start_char="255">entrever</TOKEN>
<TOKEN end_char="266" id="token-2-15" morph="none" pos="word" start_char="264">que</TOKEN>
<TOKEN end_char="269" id="token-2-16" morph="none" pos="word" start_char="268">la</TOKEN>
<TOKEN end_char="278" id="token-2-17" morph="none" pos="word" start_char="271">epidemia</TOKEN>
<TOKEN end_char="283" id="token-2-18" morph="none" pos="word" start_char="280">pudo</TOKEN>
<TOKEN end_char="290" id="token-2-19" morph="none" pos="word" start_char="285">surgir</TOKEN>
<TOKEN end_char="293" id="token-2-20" morph="none" pos="word" start_char="292">en</TOKEN>
<TOKEN end_char="296" id="token-2-21" morph="none" pos="word" start_char="295">el</TOKEN>
<TOKEN end_char="303" id="token-2-22" morph="none" pos="word" start_char="298">verano</TOKEN>
<TOKEN end_char="306" id="token-2-23" morph="none" pos="word" start_char="305">de</TOKEN>
<TOKEN end_char="311" id="token-2-24" morph="none" pos="word" start_char="308">2019</TOKEN>
<TOKEN end_char="314" id="token-2-25" morph="none" pos="word" start_char="313">en</TOKEN>
<TOKEN end_char="320" id="token-2-26" morph="none" pos="word" start_char="316">Wuhan</TOKEN>
<TOKEN end_char="321" id="token-2-27" morph="none" pos="punct" start_char="321">,</TOKEN>
<TOKEN end_char="331" id="token-2-28" morph="none" pos="word" start_char="323">metrópoli</TOKEN>
<TOKEN end_char="335" id="token-2-29" morph="none" pos="word" start_char="333">del</TOKEN>
<TOKEN end_char="342" id="token-2-30" morph="none" pos="word" start_char="337">centro</TOKEN>
<TOKEN end_char="345" id="token-2-31" morph="none" pos="word" start_char="344">de</TOKEN>
<TOKEN end_char="351" id="token-2-32" morph="none" pos="word" start_char="347">China</TOKEN>
<TOKEN end_char="355" id="token-2-33" morph="none" pos="word" start_char="353">que</TOKEN>
<TOKEN end_char="361" id="token-2-34" morph="none" pos="word" start_char="357">quedó</TOKEN>
<TOKEN end_char="364" id="token-2-35" morph="none" pos="word" start_char="363">en</TOKEN>
<TOKEN end_char="375" id="token-2-36" morph="none" pos="word" start_char="366">cuarentena</TOKEN>
<TOKEN end_char="378" id="token-2-37" morph="none" pos="word" start_char="377">en</TOKEN>
<TOKEN end_char="384" id="token-2-38" morph="none" pos="word" start_char="380">enero</TOKEN>
<TOKEN end_char="385" id="token-2-39" morph="none" pos="punct" start_char="385">.</TOKEN>
<TRANSLATED_TEXT>A preliminary study by researchers at the prestigious Boston and Harvard Universities suggests that the epidemic may have arisen in the summer of 2019 in Wuhan, a central Chinese metropolis that was quarantined in January.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="538" id="segment-3" start_char="388">
<ORIGINAL_TEXT>Este estudio se basa en las imágenes de satélite que muestran una afluencia inhabitual en los estacionamientos de los hospitales en Wuhan desde agosto.</ORIGINAL_TEXT>
<TOKEN end_char="391" id="token-3-0" morph="none" pos="word" start_char="388">Este</TOKEN>
<TOKEN end_char="399" id="token-3-1" morph="none" pos="word" start_char="393">estudio</TOKEN>
<TOKEN end_char="402" id="token-3-2" morph="none" pos="word" start_char="401">se</TOKEN>
<TOKEN end_char="407" id="token-3-3" morph="none" pos="word" start_char="404">basa</TOKEN>
<TOKEN end_char="410" id="token-3-4" morph="none" pos="word" start_char="409">en</TOKEN>
<TOKEN end_char="414" id="token-3-5" morph="none" pos="word" start_char="412">las</TOKEN>
<TOKEN end_char="423" id="token-3-6" morph="none" pos="word" start_char="416">imágenes</TOKEN>
<TOKEN end_char="426" id="token-3-7" morph="none" pos="word" start_char="425">de</TOKEN>
<TOKEN end_char="435" id="token-3-8" morph="none" pos="word" start_char="428">satélite</TOKEN>
<TOKEN end_char="439" id="token-3-9" morph="none" pos="word" start_char="437">que</TOKEN>
<TOKEN end_char="448" id="token-3-10" morph="none" pos="word" start_char="441">muestran</TOKEN>
<TOKEN end_char="452" id="token-3-11" morph="none" pos="word" start_char="450">una</TOKEN>
<TOKEN end_char="462" id="token-3-12" morph="none" pos="word" start_char="454">afluencia</TOKEN>
<TOKEN end_char="473" id="token-3-13" morph="none" pos="word" start_char="464">inhabitual</TOKEN>
<TOKEN end_char="476" id="token-3-14" morph="none" pos="word" start_char="475">en</TOKEN>
<TOKEN end_char="480" id="token-3-15" morph="none" pos="word" start_char="478">los</TOKEN>
<TOKEN end_char="497" id="token-3-16" morph="none" pos="word" start_char="482">estacionamientos</TOKEN>
<TOKEN end_char="500" id="token-3-17" morph="none" pos="word" start_char="499">de</TOKEN>
<TOKEN end_char="504" id="token-3-18" morph="none" pos="word" start_char="502">los</TOKEN>
<TOKEN end_char="515" id="token-3-19" morph="none" pos="word" start_char="506">hospitales</TOKEN>
<TOKEN end_char="518" id="token-3-20" morph="none" pos="word" start_char="517">en</TOKEN>
<TOKEN end_char="524" id="token-3-21" morph="none" pos="word" start_char="520">Wuhan</TOKEN>
<TOKEN end_char="530" id="token-3-22" morph="none" pos="word" start_char="526">desde</TOKEN>
<TOKEN end_char="537" id="token-3-23" morph="none" pos="word" start_char="532">agosto</TOKEN>
<TOKEN end_char="538" id="token-3-24" morph="none" pos="punct" start_char="538">.</TOKEN>
<TRANSLATED_TEXT>This study is based on satellite imagery showing an unusual influx of hospital parking in Wuhan since August.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="642" id="segment-4" start_char="541">
<ORIGINAL_TEXT>Asimismo, muestra el aumento de las consultas de la palabra "tos" en el motor de búsqueda chino Baidu.</ORIGINAL_TEXT>
<TOKEN end_char="548" id="token-4-0" morph="none" pos="word" start_char="541">Asimismo</TOKEN>
<TOKEN end_char="549" id="token-4-1" morph="none" pos="punct" start_char="549">,</TOKEN>
<TOKEN end_char="557" id="token-4-2" morph="none" pos="word" start_char="551">muestra</TOKEN>
<TOKEN end_char="560" id="token-4-3" morph="none" pos="word" start_char="559">el</TOKEN>
<TOKEN end_char="568" id="token-4-4" morph="none" pos="word" start_char="562">aumento</TOKEN>
<TOKEN end_char="571" id="token-4-5" morph="none" pos="word" start_char="570">de</TOKEN>
<TOKEN end_char="575" id="token-4-6" morph="none" pos="word" start_char="573">las</TOKEN>
<TOKEN end_char="585" id="token-4-7" morph="none" pos="word" start_char="577">consultas</TOKEN>
<TOKEN end_char="588" id="token-4-8" morph="none" pos="word" start_char="587">de</TOKEN>
<TOKEN end_char="591" id="token-4-9" morph="none" pos="word" start_char="590">la</TOKEN>
<TOKEN end_char="599" id="token-4-10" morph="none" pos="word" start_char="593">palabra</TOKEN>
<TOKEN end_char="601" id="token-4-11" morph="none" pos="punct" start_char="601">"</TOKEN>
<TOKEN end_char="604" id="token-4-12" morph="none" pos="word" start_char="602">tos</TOKEN>
<TOKEN end_char="605" id="token-4-13" morph="none" pos="punct" start_char="605">"</TOKEN>
<TOKEN end_char="608" id="token-4-14" morph="none" pos="word" start_char="607">en</TOKEN>
<TOKEN end_char="611" id="token-4-15" morph="none" pos="word" start_char="610">el</TOKEN>
<TOKEN end_char="617" id="token-4-16" morph="none" pos="word" start_char="613">motor</TOKEN>
<TOKEN end_char="620" id="token-4-17" morph="none" pos="word" start_char="619">de</TOKEN>
<TOKEN end_char="629" id="token-4-18" morph="none" pos="word" start_char="622">búsqueda</TOKEN>
<TOKEN end_char="635" id="token-4-19" morph="none" pos="word" start_char="631">chino</TOKEN>
<TOKEN end_char="641" id="token-4-20" morph="none" pos="word" start_char="637">Baidu</TOKEN>
<TOKEN end_char="642" id="token-4-21" morph="none" pos="punct" start_char="642">.</TOKEN>
<TRANSLATED_TEXT>It also shows the increase in queries of the word "tos" in the Chinese search engine Baidu.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="839" id="segment-5" start_char="645">
<ORIGINAL_TEXT>Este estudio, que todavía no ha sido publicado en ninguna revista científica, podría ser la prueba de que China habría escondido al mundo durante varios meses la existencia del nuevo coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="648" id="token-5-0" morph="none" pos="word" start_char="645">Este</TOKEN>
<TOKEN end_char="656" id="token-5-1" morph="none" pos="word" start_char="650">estudio</TOKEN>
<TOKEN end_char="657" id="token-5-2" morph="none" pos="punct" start_char="657">,</TOKEN>
<TOKEN end_char="661" id="token-5-3" morph="none" pos="word" start_char="659">que</TOKEN>
<TOKEN end_char="669" id="token-5-4" morph="none" pos="word" start_char="663">todavía</TOKEN>
<TOKEN end_char="672" id="token-5-5" morph="none" pos="word" start_char="671">no</TOKEN>
<TOKEN end_char="675" id="token-5-6" morph="none" pos="word" start_char="674">ha</TOKEN>
<TOKEN end_char="680" id="token-5-7" morph="none" pos="word" start_char="677">sido</TOKEN>
<TOKEN end_char="690" id="token-5-8" morph="none" pos="word" start_char="682">publicado</TOKEN>
<TOKEN end_char="693" id="token-5-9" morph="none" pos="word" start_char="692">en</TOKEN>
<TOKEN end_char="701" id="token-5-10" morph="none" pos="word" start_char="695">ninguna</TOKEN>
<TOKEN end_char="709" id="token-5-11" morph="none" pos="word" start_char="703">revista</TOKEN>
<TOKEN end_char="720" id="token-5-12" morph="none" pos="word" start_char="711">científica</TOKEN>
<TOKEN end_char="721" id="token-5-13" morph="none" pos="punct" start_char="721">,</TOKEN>
<TOKEN end_char="728" id="token-5-14" morph="none" pos="word" start_char="723">podría</TOKEN>
<TOKEN end_char="732" id="token-5-15" morph="none" pos="word" start_char="730">ser</TOKEN>
<TOKEN end_char="735" id="token-5-16" morph="none" pos="word" start_char="734">la</TOKEN>
<TOKEN end_char="742" id="token-5-17" morph="none" pos="word" start_char="737">prueba</TOKEN>
<TOKEN end_char="745" id="token-5-18" morph="none" pos="word" start_char="744">de</TOKEN>
<TOKEN end_char="749" id="token-5-19" morph="none" pos="word" start_char="747">que</TOKEN>
<TOKEN end_char="755" id="token-5-20" morph="none" pos="word" start_char="751">China</TOKEN>
<TOKEN end_char="762" id="token-5-21" morph="none" pos="word" start_char="757">habría</TOKEN>
<TOKEN end_char="772" id="token-5-22" morph="none" pos="word" start_char="764">escondido</TOKEN>
<TOKEN end_char="775" id="token-5-23" morph="none" pos="word" start_char="774">al</TOKEN>
<TOKEN end_char="781" id="token-5-24" morph="none" pos="word" start_char="777">mundo</TOKEN>
<TOKEN end_char="789" id="token-5-25" morph="none" pos="word" start_char="783">durante</TOKEN>
<TOKEN end_char="796" id="token-5-26" morph="none" pos="word" start_char="791">varios</TOKEN>
<TOKEN end_char="802" id="token-5-27" morph="none" pos="word" start_char="798">meses</TOKEN>
<TOKEN end_char="805" id="token-5-28" morph="none" pos="word" start_char="804">la</TOKEN>
<TOKEN end_char="816" id="token-5-29" morph="none" pos="word" start_char="807">existencia</TOKEN>
<TOKEN end_char="820" id="token-5-30" morph="none" pos="word" start_char="818">del</TOKEN>
<TOKEN end_char="826" id="token-5-31" morph="none" pos="word" start_char="822">nuevo</TOKEN>
<TOKEN end_char="838" id="token-5-32" morph="none" pos="word" start_char="828">coronavirus</TOKEN>
<TOKEN end_char="839" id="token-5-33" morph="none" pos="punct" start_char="839">.</TOKEN>
<TRANSLATED_TEXT>This study, which has not yet been published in any scientific journal, could prove that China would have hidden the existence of the new coronavirus from the world for several months.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="980" id="segment-6" start_char="842">
<ORIGINAL_TEXT>Pero el ministerio chino de Relaciones Exteriores consideró el jueves que el estudio está "lleno de deficiencias" y "burdamente fabricado".</ORIGINAL_TEXT>
<TOKEN end_char="845" id="token-6-0" morph="none" pos="word" start_char="842">Pero</TOKEN>
<TOKEN end_char="848" id="token-6-1" morph="none" pos="word" start_char="847">el</TOKEN>
<TOKEN end_char="859" id="token-6-2" morph="none" pos="word" start_char="850">ministerio</TOKEN>
<TOKEN end_char="865" id="token-6-3" morph="none" pos="word" start_char="861">chino</TOKEN>
<TOKEN end_char="868" id="token-6-4" morph="none" pos="word" start_char="867">de</TOKEN>
<TOKEN end_char="879" id="token-6-5" morph="none" pos="word" start_char="870">Relaciones</TOKEN>
<TOKEN end_char="890" id="token-6-6" morph="none" pos="word" start_char="881">Exteriores</TOKEN>
<TOKEN end_char="900" id="token-6-7" morph="none" pos="word" start_char="892">consideró</TOKEN>
<TOKEN end_char="903" id="token-6-8" morph="none" pos="word" start_char="902">el</TOKEN>
<TOKEN end_char="910" id="token-6-9" morph="none" pos="word" start_char="905">jueves</TOKEN>
<TOKEN end_char="914" id="token-6-10" morph="none" pos="word" start_char="912">que</TOKEN>
<TOKEN end_char="917" id="token-6-11" morph="none" pos="word" start_char="916">el</TOKEN>
<TOKEN end_char="925" id="token-6-12" morph="none" pos="word" start_char="919">estudio</TOKEN>
<TOKEN end_char="930" id="token-6-13" morph="none" pos="word" start_char="927">está</TOKEN>
<TOKEN end_char="932" id="token-6-14" morph="none" pos="punct" start_char="932">"</TOKEN>
<TOKEN end_char="937" id="token-6-15" morph="none" pos="word" start_char="933">lleno</TOKEN>
<TOKEN end_char="940" id="token-6-16" morph="none" pos="word" start_char="939">de</TOKEN>
<TOKEN end_char="953" id="token-6-17" morph="none" pos="word" start_char="942">deficiencias</TOKEN>
<TOKEN end_char="954" id="token-6-18" morph="none" pos="punct" start_char="954">"</TOKEN>
<TOKEN end_char="956" id="token-6-19" morph="none" pos="word" start_char="956">y</TOKEN>
<TOKEN end_char="958" id="token-6-20" morph="none" pos="punct" start_char="958">"</TOKEN>
<TOKEN end_char="968" id="token-6-21" morph="none" pos="word" start_char="959">burdamente</TOKEN>
<TOKEN end_char="978" id="token-6-22" morph="none" pos="word" start_char="970">fabricado</TOKEN>
<TOKEN end_char="980" id="token-6-23" morph="none" pos="punct" start_char="979">".</TOKEN>
<TRANSLATED_TEXT>But the Chinese foreign ministry considered Thursday that the study is "flawed" and "burly fabricated."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1168" id="segment-7" start_char="983">
<ORIGINAL_TEXT>La portavoz del ministerio, Hua Chunying, ve en el mismo la prueba de la existencia de una campaña en Estados Unidos para "crear y diseminar deliberadamente desinformación contra China".</ORIGINAL_TEXT>
<TOKEN end_char="984" id="token-7-0" morph="none" pos="word" start_char="983">La</TOKEN>
<TOKEN end_char="993" id="token-7-1" morph="none" pos="word" start_char="986">portavoz</TOKEN>
<TOKEN end_char="997" id="token-7-2" morph="none" pos="word" start_char="995">del</TOKEN>
<TOKEN end_char="1008" id="token-7-3" morph="none" pos="word" start_char="999">ministerio</TOKEN>
<TOKEN end_char="1009" id="token-7-4" morph="none" pos="punct" start_char="1009">,</TOKEN>
<TOKEN end_char="1013" id="token-7-5" morph="none" pos="word" start_char="1011">Hua</TOKEN>
<TOKEN end_char="1022" id="token-7-6" morph="none" pos="word" start_char="1015">Chunying</TOKEN>
<TOKEN end_char="1023" id="token-7-7" morph="none" pos="punct" start_char="1023">,</TOKEN>
<TOKEN end_char="1026" id="token-7-8" morph="none" pos="word" start_char="1025">ve</TOKEN>
<TOKEN end_char="1029" id="token-7-9" morph="none" pos="word" start_char="1028">en</TOKEN>
<TOKEN end_char="1032" id="token-7-10" morph="none" pos="word" start_char="1031">el</TOKEN>
<TOKEN end_char="1038" id="token-7-11" morph="none" pos="word" start_char="1034">mismo</TOKEN>
<TOKEN end_char="1041" id="token-7-12" morph="none" pos="word" start_char="1040">la</TOKEN>
<TOKEN end_char="1048" id="token-7-13" morph="none" pos="word" start_char="1043">prueba</TOKEN>
<TOKEN end_char="1051" id="token-7-14" morph="none" pos="word" start_char="1050">de</TOKEN>
<TOKEN end_char="1054" id="token-7-15" morph="none" pos="word" start_char="1053">la</TOKEN>
<TOKEN end_char="1065" id="token-7-16" morph="none" pos="word" start_char="1056">existencia</TOKEN>
<TOKEN end_char="1068" id="token-7-17" morph="none" pos="word" start_char="1067">de</TOKEN>
<TOKEN end_char="1072" id="token-7-18" morph="none" pos="word" start_char="1070">una</TOKEN>
<TOKEN end_char="1080" id="token-7-19" morph="none" pos="word" start_char="1074">campaña</TOKEN>
<TOKEN end_char="1083" id="token-7-20" morph="none" pos="word" start_char="1082">en</TOKEN>
<TOKEN end_char="1091" id="token-7-21" morph="none" pos="word" start_char="1085">Estados</TOKEN>
<TOKEN end_char="1098" id="token-7-22" morph="none" pos="word" start_char="1093">Unidos</TOKEN>
<TOKEN end_char="1103" id="token-7-23" morph="none" pos="word" start_char="1100">para</TOKEN>
<TOKEN end_char="1105" id="token-7-24" morph="none" pos="punct" start_char="1105">"</TOKEN>
<TOKEN end_char="1110" id="token-7-25" morph="none" pos="word" start_char="1106">crear</TOKEN>
<TOKEN end_char="1112" id="token-7-26" morph="none" pos="word" start_char="1112">y</TOKEN>
<TOKEN end_char="1122" id="token-7-27" morph="none" pos="word" start_char="1114">diseminar</TOKEN>
<TOKEN end_char="1138" id="token-7-28" morph="none" pos="word" start_char="1124">deliberadamente</TOKEN>
<TOKEN end_char="1153" id="token-7-29" morph="none" pos="word" start_char="1140">desinformación</TOKEN>
<TOKEN end_char="1160" id="token-7-30" morph="none" pos="word" start_char="1155">contra</TOKEN>
<TOKEN end_char="1166" id="token-7-31" morph="none" pos="word" start_char="1162">China</TOKEN>
<TOKEN end_char="1168" id="token-7-32" morph="none" pos="punct" start_char="1167">".</TOKEN>
<TRANSLATED_TEXT>The ministry's spokesman, Hua Chunying, sees in it evidence of a campaign in the United States to "deliberately create and disseminate disinformation against China."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1336" id="segment-8" start_char="1170">
<ORIGINAL_TEXT>"Responsables políticos y medios estadounidenses actúan como si hubieran descubierto un tesoro, como si tuvieran la prueba de que China escondió la epidemia", lamentó.</ORIGINAL_TEXT>
<TOKEN end_char="1170" id="token-8-0" morph="none" pos="punct" start_char="1170">"</TOKEN>
<TOKEN end_char="1182" id="token-8-1" morph="none" pos="word" start_char="1171">Responsables</TOKEN>
<TOKEN end_char="1192" id="token-8-2" morph="none" pos="word" start_char="1184">políticos</TOKEN>
<TOKEN end_char="1194" id="token-8-3" morph="none" pos="word" start_char="1194">y</TOKEN>
<TOKEN end_char="1201" id="token-8-4" morph="none" pos="word" start_char="1196">medios</TOKEN>
<TOKEN end_char="1217" id="token-8-5" morph="none" pos="word" start_char="1203">estadounidenses</TOKEN>
<TOKEN end_char="1224" id="token-8-6" morph="none" pos="word" start_char="1219">actúan</TOKEN>
<TOKEN end_char="1229" id="token-8-7" morph="none" pos="word" start_char="1226">como</TOKEN>
<TOKEN end_char="1232" id="token-8-8" morph="none" pos="word" start_char="1231">si</TOKEN>
<TOKEN end_char="1241" id="token-8-9" morph="none" pos="word" start_char="1234">hubieran</TOKEN>
<TOKEN end_char="1253" id="token-8-10" morph="none" pos="word" start_char="1243">descubierto</TOKEN>
<TOKEN end_char="1256" id="token-8-11" morph="none" pos="word" start_char="1255">un</TOKEN>
<TOKEN end_char="1263" id="token-8-12" morph="none" pos="word" start_char="1258">tesoro</TOKEN>
<TOKEN end_char="1264" id="token-8-13" morph="none" pos="punct" start_char="1264">,</TOKEN>
<TOKEN end_char="1269" id="token-8-14" morph="none" pos="word" start_char="1266">como</TOKEN>
<TOKEN end_char="1272" id="token-8-15" morph="none" pos="word" start_char="1271">si</TOKEN>
<TOKEN end_char="1281" id="token-8-16" morph="none" pos="word" start_char="1274">tuvieran</TOKEN>
<TOKEN end_char="1284" id="token-8-17" morph="none" pos="word" start_char="1283">la</TOKEN>
<TOKEN end_char="1291" id="token-8-18" morph="none" pos="word" start_char="1286">prueba</TOKEN>
<TOKEN end_char="1294" id="token-8-19" morph="none" pos="word" start_char="1293">de</TOKEN>
<TOKEN end_char="1298" id="token-8-20" morph="none" pos="word" start_char="1296">que</TOKEN>
<TOKEN end_char="1304" id="token-8-21" morph="none" pos="word" start_char="1300">China</TOKEN>
<TOKEN end_char="1313" id="token-8-22" morph="none" pos="word" start_char="1306">escondió</TOKEN>
<TOKEN end_char="1316" id="token-8-23" morph="none" pos="word" start_char="1315">la</TOKEN>
<TOKEN end_char="1325" id="token-8-24" morph="none" pos="word" start_char="1318">epidemia</TOKEN>
<TOKEN end_char="1327" id="token-8-25" morph="none" pos="punct" start_char="1326">",</TOKEN>
<TOKEN end_char="1335" id="token-8-26" morph="none" pos="word" start_char="1329">lamentó</TOKEN>
<TOKEN end_char="1336" id="token-8-27" morph="none" pos="punct" start_char="1336">.</TOKEN>
<TRANSLATED_TEXT>"American political and media leaders act as if they had discovered a treasure, as if they had proof that China had hidden the epidemic," he lamented.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1521" id="segment-9" start_char="1339">
<ORIGINAL_TEXT>Según las autoridades chinas, el nuevo coronavirus fue detectado en diciembre y China compartió a principios de enero su código genético con la Organización Mundial de la Salud (OMS).</ORIGINAL_TEXT>
<TOKEN end_char="1343" id="token-9-0" morph="none" pos="word" start_char="1339">Según</TOKEN>
<TOKEN end_char="1347" id="token-9-1" morph="none" pos="word" start_char="1345">las</TOKEN>
<TOKEN end_char="1359" id="token-9-2" morph="none" pos="word" start_char="1349">autoridades</TOKEN>
<TOKEN end_char="1366" id="token-9-3" morph="none" pos="word" start_char="1361">chinas</TOKEN>
<TOKEN end_char="1367" id="token-9-4" morph="none" pos="punct" start_char="1367">,</TOKEN>
<TOKEN end_char="1370" id="token-9-5" morph="none" pos="word" start_char="1369">el</TOKEN>
<TOKEN end_char="1376" id="token-9-6" morph="none" pos="word" start_char="1372">nuevo</TOKEN>
<TOKEN end_char="1388" id="token-9-7" morph="none" pos="word" start_char="1378">coronavirus</TOKEN>
<TOKEN end_char="1392" id="token-9-8" morph="none" pos="word" start_char="1390">fue</TOKEN>
<TOKEN end_char="1402" id="token-9-9" morph="none" pos="word" start_char="1394">detectado</TOKEN>
<TOKEN end_char="1405" id="token-9-10" morph="none" pos="word" start_char="1404">en</TOKEN>
<TOKEN end_char="1415" id="token-9-11" morph="none" pos="word" start_char="1407">diciembre</TOKEN>
<TOKEN end_char="1417" id="token-9-12" morph="none" pos="word" start_char="1417">y</TOKEN>
<TOKEN end_char="1423" id="token-9-13" morph="none" pos="word" start_char="1419">China</TOKEN>
<TOKEN end_char="1433" id="token-9-14" morph="none" pos="word" start_char="1425">compartió</TOKEN>
<TOKEN end_char="1435" id="token-9-15" morph="none" pos="word" start_char="1435">a</TOKEN>
<TOKEN end_char="1446" id="token-9-16" morph="none" pos="word" start_char="1437">principios</TOKEN>
<TOKEN end_char="1449" id="token-9-17" morph="none" pos="word" start_char="1448">de</TOKEN>
<TOKEN end_char="1455" id="token-9-18" morph="none" pos="word" start_char="1451">enero</TOKEN>
<TOKEN end_char="1458" id="token-9-19" morph="none" pos="word" start_char="1457">su</TOKEN>
<TOKEN end_char="1465" id="token-9-20" morph="none" pos="word" start_char="1460">código</TOKEN>
<TOKEN end_char="1474" id="token-9-21" morph="none" pos="word" start_char="1467">genético</TOKEN>
<TOKEN end_char="1478" id="token-9-22" morph="none" pos="word" start_char="1476">con</TOKEN>
<TOKEN end_char="1481" id="token-9-23" morph="none" pos="word" start_char="1480">la</TOKEN>
<TOKEN end_char="1494" id="token-9-24" morph="none" pos="word" start_char="1483">Organización</TOKEN>
<TOKEN end_char="1502" id="token-9-25" morph="none" pos="word" start_char="1496">Mundial</TOKEN>
<TOKEN end_char="1505" id="token-9-26" morph="none" pos="word" start_char="1504">de</TOKEN>
<TOKEN end_char="1508" id="token-9-27" morph="none" pos="word" start_char="1507">la</TOKEN>
<TOKEN end_char="1514" id="token-9-28" morph="none" pos="word" start_char="1510">Salud</TOKEN>
<TOKEN end_char="1516" id="token-9-29" morph="none" pos="punct" start_char="1516">(</TOKEN>
<TOKEN end_char="1519" id="token-9-30" morph="none" pos="word" start_char="1517">OMS</TOKEN>
<TOKEN end_char="1521" id="token-9-31" morph="none" pos="punct" start_char="1520">).</TOKEN>
<TRANSLATED_TEXT>According to Chinese authorities, the new coronavirus was detected in December and China shared its genetic code with the World Health Organization (WHO) in early January.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1625" id="segment-10" start_char="1523">
<ORIGINAL_TEXT>Estados Unidos y China se han enfrascado en los últimos meses en una batalla sobre el origen del virus.</ORIGINAL_TEXT>
<TOKEN end_char="1529" id="token-10-0" morph="none" pos="word" start_char="1523">Estados</TOKEN>
<TOKEN end_char="1536" id="token-10-1" morph="none" pos="word" start_char="1531">Unidos</TOKEN>
<TOKEN end_char="1538" id="token-10-2" morph="none" pos="word" start_char="1538">y</TOKEN>
<TOKEN end_char="1544" id="token-10-3" morph="none" pos="word" start_char="1540">China</TOKEN>
<TOKEN end_char="1547" id="token-10-4" morph="none" pos="word" start_char="1546">se</TOKEN>
<TOKEN end_char="1551" id="token-10-5" morph="none" pos="word" start_char="1549">han</TOKEN>
<TOKEN end_char="1562" id="token-10-6" morph="none" pos="word" start_char="1553">enfrascado</TOKEN>
<TOKEN end_char="1565" id="token-10-7" morph="none" pos="word" start_char="1564">en</TOKEN>
<TOKEN end_char="1569" id="token-10-8" morph="none" pos="word" start_char="1567">los</TOKEN>
<TOKEN end_char="1577" id="token-10-9" morph="none" pos="word" start_char="1571">últimos</TOKEN>
<TOKEN end_char="1583" id="token-10-10" morph="none" pos="word" start_char="1579">meses</TOKEN>
<TOKEN end_char="1586" id="token-10-11" morph="none" pos="word" start_char="1585">en</TOKEN>
<TOKEN end_char="1590" id="token-10-12" morph="none" pos="word" start_char="1588">una</TOKEN>
<TOKEN end_char="1598" id="token-10-13" morph="none" pos="word" start_char="1592">batalla</TOKEN>
<TOKEN end_char="1604" id="token-10-14" morph="none" pos="word" start_char="1600">sobre</TOKEN>
<TOKEN end_char="1607" id="token-10-15" morph="none" pos="word" start_char="1606">el</TOKEN>
<TOKEN end_char="1614" id="token-10-16" morph="none" pos="word" start_char="1609">origen</TOKEN>
<TOKEN end_char="1618" id="token-10-17" morph="none" pos="word" start_char="1616">del</TOKEN>
<TOKEN end_char="1624" id="token-10-18" morph="none" pos="word" start_char="1620">virus</TOKEN>
<TOKEN end_char="1625" id="token-10-19" morph="none" pos="punct" start_char="1625">.</TOKEN>
<TRANSLATED_TEXT>The US and China have engaged in a battle over the origin of the virus in recent months.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1801" id="segment-11" start_char="1627">
<ORIGINAL_TEXT>Las autoridades estadounidense sugieren que pudo escapar de un laboratorio en Wuhan, mientras que Pekín dio a entender que pudo haber sido traído por soldados estadounidenses.</ORIGINAL_TEXT>
<TOKEN end_char="1629" id="token-11-0" morph="none" pos="word" start_char="1627">Las</TOKEN>
<TOKEN end_char="1641" id="token-11-1" morph="none" pos="word" start_char="1631">autoridades</TOKEN>
<TOKEN end_char="1656" id="token-11-2" morph="none" pos="word" start_char="1643">estadounidense</TOKEN>
<TOKEN end_char="1665" id="token-11-3" morph="none" pos="word" start_char="1658">sugieren</TOKEN>
<TOKEN end_char="1669" id="token-11-4" morph="none" pos="word" start_char="1667">que</TOKEN>
<TOKEN end_char="1674" id="token-11-5" morph="none" pos="word" start_char="1671">pudo</TOKEN>
<TOKEN end_char="1682" id="token-11-6" morph="none" pos="word" start_char="1676">escapar</TOKEN>
<TOKEN end_char="1685" id="token-11-7" morph="none" pos="word" start_char="1684">de</TOKEN>
<TOKEN end_char="1688" id="token-11-8" morph="none" pos="word" start_char="1687">un</TOKEN>
<TOKEN end_char="1700" id="token-11-9" morph="none" pos="word" start_char="1690">laboratorio</TOKEN>
<TOKEN end_char="1703" id="token-11-10" morph="none" pos="word" start_char="1702">en</TOKEN>
<TOKEN end_char="1709" id="token-11-11" morph="none" pos="word" start_char="1705">Wuhan</TOKEN>
<TOKEN end_char="1710" id="token-11-12" morph="none" pos="punct" start_char="1710">,</TOKEN>
<TOKEN end_char="1719" id="token-11-13" morph="none" pos="word" start_char="1712">mientras</TOKEN>
<TOKEN end_char="1723" id="token-11-14" morph="none" pos="word" start_char="1721">que</TOKEN>
<TOKEN end_char="1729" id="token-11-15" morph="none" pos="word" start_char="1725">Pekín</TOKEN>
<TOKEN end_char="1733" id="token-11-16" morph="none" pos="word" start_char="1731">dio</TOKEN>
<TOKEN end_char="1735" id="token-11-17" morph="none" pos="word" start_char="1735">a</TOKEN>
<TOKEN end_char="1744" id="token-11-18" morph="none" pos="word" start_char="1737">entender</TOKEN>
<TOKEN end_char="1748" id="token-11-19" morph="none" pos="word" start_char="1746">que</TOKEN>
<TOKEN end_char="1753" id="token-11-20" morph="none" pos="word" start_char="1750">pudo</TOKEN>
<TOKEN end_char="1759" id="token-11-21" morph="none" pos="word" start_char="1755">haber</TOKEN>
<TOKEN end_char="1764" id="token-11-22" morph="none" pos="word" start_char="1761">sido</TOKEN>
<TOKEN end_char="1771" id="token-11-23" morph="none" pos="word" start_char="1766">traído</TOKEN>
<TOKEN end_char="1775" id="token-11-24" morph="none" pos="word" start_char="1773">por</TOKEN>
<TOKEN end_char="1784" id="token-11-25" morph="none" pos="word" start_char="1777">soldados</TOKEN>
<TOKEN end_char="1800" id="token-11-26" morph="none" pos="word" start_char="1786">estadounidenses</TOKEN>
<TOKEN end_char="1801" id="token-11-27" morph="none" pos="punct" start_char="1801">.</TOKEN>
<TRANSLATED_TEXT>US authorities suggest that he was able to escape from a laboratory in Wuhan, while Beijing implied that he might have been brought in by American soldiers.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2021" id="segment-12" start_char="1804">
<ORIGINAL_TEXT>Pingüino Multimedia entrega este espacio a su público para la expresión personal de opiniones y comentarios, apelando al respeto entre los usuarios y desligándose por completo del contenido de los comentarios emitidos.</ORIGINAL_TEXT>
<TOKEN end_char="1811" id="token-12-0" morph="none" pos="word" start_char="1804">Pingüino</TOKEN>
<TOKEN end_char="1822" id="token-12-1" morph="none" pos="word" start_char="1813">Multimedia</TOKEN>
<TOKEN end_char="1830" id="token-12-2" morph="none" pos="word" start_char="1824">entrega</TOKEN>
<TOKEN end_char="1835" id="token-12-3" morph="none" pos="word" start_char="1832">este</TOKEN>
<TOKEN end_char="1843" id="token-12-4" morph="none" pos="word" start_char="1837">espacio</TOKEN>
<TOKEN end_char="1845" id="token-12-5" morph="none" pos="word" start_char="1845">a</TOKEN>
<TOKEN end_char="1848" id="token-12-6" morph="none" pos="word" start_char="1847">su</TOKEN>
<TOKEN end_char="1856" id="token-12-7" morph="none" pos="word" start_char="1850">público</TOKEN>
<TOKEN end_char="1861" id="token-12-8" morph="none" pos="word" start_char="1858">para</TOKEN>
<TOKEN end_char="1864" id="token-12-9" morph="none" pos="word" start_char="1863">la</TOKEN>
<TOKEN end_char="1874" id="token-12-10" morph="none" pos="word" start_char="1866">expresión</TOKEN>
<TOKEN end_char="1883" id="token-12-11" morph="none" pos="word" start_char="1876">personal</TOKEN>
<TOKEN end_char="1886" id="token-12-12" morph="none" pos="word" start_char="1885">de</TOKEN>
<TOKEN end_char="1896" id="token-12-13" morph="none" pos="word" start_char="1888">opiniones</TOKEN>
<TOKEN end_char="1898" id="token-12-14" morph="none" pos="word" start_char="1898">y</TOKEN>
<TOKEN end_char="1910" id="token-12-15" morph="none" pos="word" start_char="1900">comentarios</TOKEN>
<TOKEN end_char="1911" id="token-12-16" morph="none" pos="punct" start_char="1911">,</TOKEN>
<TOKEN end_char="1920" id="token-12-17" morph="none" pos="word" start_char="1913">apelando</TOKEN>
<TOKEN end_char="1923" id="token-12-18" morph="none" pos="word" start_char="1922">al</TOKEN>
<TOKEN end_char="1931" id="token-12-19" morph="none" pos="word" start_char="1925">respeto</TOKEN>
<TOKEN end_char="1937" id="token-12-20" morph="none" pos="word" start_char="1933">entre</TOKEN>
<TOKEN end_char="1941" id="token-12-21" morph="none" pos="word" start_char="1939">los</TOKEN>
<TOKEN end_char="1950" id="token-12-22" morph="none" pos="word" start_char="1943">usuarios</TOKEN>
<TOKEN end_char="1952" id="token-12-23" morph="none" pos="word" start_char="1952">y</TOKEN>
<TOKEN end_char="1965" id="token-12-24" morph="none" pos="word" start_char="1954">desligándose</TOKEN>
<TOKEN end_char="1969" id="token-12-25" morph="none" pos="word" start_char="1967">por</TOKEN>
<TOKEN end_char="1978" id="token-12-26" morph="none" pos="word" start_char="1971">completo</TOKEN>
<TOKEN end_char="1982" id="token-12-27" morph="none" pos="word" start_char="1980">del</TOKEN>
<TOKEN end_char="1992" id="token-12-28" morph="none" pos="word" start_char="1984">contenido</TOKEN>
<TOKEN end_char="1995" id="token-12-29" morph="none" pos="word" start_char="1994">de</TOKEN>
<TOKEN end_char="1999" id="token-12-30" morph="none" pos="word" start_char="1997">los</TOKEN>
<TOKEN end_char="2011" id="token-12-31" morph="none" pos="word" start_char="2001">comentarios</TOKEN>
<TOKEN end_char="2020" id="token-12-32" morph="none" pos="word" start_char="2013">emitidos</TOKEN>
<TOKEN end_char="2021" id="token-12-33" morph="none" pos="punct" start_char="2021">.</TOKEN>
<TRANSLATED_TEXT>Multimedia Penguin delivers this space to its public for the personal expression of opinions and comments, appealing to respect among users and completely disconnecting the content of the comments issued.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="eng">
<DOC grammar="none" id="L0C049DZU" lang="eng" raw_text_char_length="5719" raw_text_md5="386327f6a9e02df11731c49a24addfdb" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="43" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Conspiracy and false claims surrounding Dr.</ORIGINAL_TEXT>
<TOKEN end_char="10" id="token-0-0" morph="none" pos="word" start_char="1">Conspiracy</TOKEN>
<TOKEN end_char="14" id="token-0-1" morph="none" pos="word" start_char="12">and</TOKEN>
<TOKEN end_char="20" id="token-0-2" morph="none" pos="word" start_char="16">false</TOKEN>
<TOKEN end_char="27" id="token-0-3" morph="none" pos="word" start_char="22">claims</TOKEN>
<TOKEN end_char="39" id="token-0-4" morph="none" pos="word" start_char="29">surrounding</TOKEN>
<TOKEN end_char="42" id="token-0-5" morph="none" pos="word" start_char="41">Dr</TOKEN>
<TOKEN end_char="43" id="token-0-6" morph="none" pos="punct" start_char="43">.</TOKEN>
</SEG>
<SEG end_char="90" id="segment-1" start_char="45">
<ORIGINAL_TEXT>Charles Lieber, China and COVID-19 coronavirus</ORIGINAL_TEXT>
<TOKEN end_char="51" id="token-1-0" morph="none" pos="word" start_char="45">Charles</TOKEN>
<TOKEN end_char="58" id="token-1-1" morph="none" pos="word" start_char="53">Lieber</TOKEN>
<TOKEN end_char="59" id="token-1-2" morph="none" pos="punct" start_char="59">,</TOKEN>
<TOKEN end_char="65" id="token-1-3" morph="none" pos="word" start_char="61">China</TOKEN>
<TOKEN end_char="69" id="token-1-4" morph="none" pos="word" start_char="67">and</TOKEN>
<TOKEN end_char="78" id="token-1-5" morph="none" pos="unknown" start_char="71">COVID-19</TOKEN>
<TOKEN end_char="90" id="token-1-6" morph="none" pos="word" start_char="80">coronavirus</TOKEN>
</SEG>
<SEG end_char="120" id="segment-2" start_char="94">
<ORIGINAL_TEXT>wcvb logo SOURCE: wcvb logo</ORIGINAL_TEXT>
<TOKEN end_char="97" id="token-2-0" morph="none" pos="word" start_char="94">wcvb</TOKEN>
<TOKEN end_char="102" id="token-2-1" morph="none" pos="word" start_char="99">logo</TOKEN>
<TOKEN end_char="109" id="token-2-2" morph="none" pos="word" start_char="104">SOURCE</TOKEN>
<TOKEN end_char="110" id="token-2-3" morph="none" pos="punct" start_char="110">:</TOKEN>
<TOKEN end_char="115" id="token-2-4" morph="none" pos="word" start_char="112">wcvb</TOKEN>
<TOKEN end_char="120" id="token-2-5" morph="none" pos="word" start_char="117">logo</TOKEN>
</SEG>
<SEG end_char="137" id="segment-3" start_char="124">
<ORIGINAL_TEXT>NEEDHAM, Mass.</ORIGINAL_TEXT>
<TOKEN end_char="130" id="token-3-0" morph="none" pos="word" start_char="124">NEEDHAM</TOKEN>
<TOKEN end_char="131" id="token-3-1" morph="none" pos="punct" start_char="131">,</TOKEN>
<TOKEN end_char="136" id="token-3-2" morph="none" pos="word" start_char="133">Mass</TOKEN>
<TOKEN end_char="137" id="token-3-3" morph="none" pos="punct" start_char="137">.</TOKEN>
</SEG>
<SEG end_char="139" id="segment-4" start_char="139">
<ORIGINAL_TEXT>—</ORIGINAL_TEXT>
<TOKEN end_char="139" id="token-4-0" morph="none" pos="punct" start_char="139">—</TOKEN>
</SEG>
<SEG end_char="250" id="segment-5" start_char="142">
<ORIGINAL_TEXT>Stories and information can spread like wildfire on social media -- go viral -- especially false information.</ORIGINAL_TEXT>
<TOKEN end_char="148" id="token-5-0" morph="none" pos="word" start_char="142">Stories</TOKEN>
<TOKEN end_char="152" id="token-5-1" morph="none" pos="word" start_char="150">and</TOKEN>
<TOKEN end_char="164" id="token-5-2" morph="none" pos="word" start_char="154">information</TOKEN>
<TOKEN end_char="168" id="token-5-3" morph="none" pos="word" start_char="166">can</TOKEN>
<TOKEN end_char="175" id="token-5-4" morph="none" pos="word" start_char="170">spread</TOKEN>
<TOKEN end_char="180" id="token-5-5" morph="none" pos="word" start_char="177">like</TOKEN>
<TOKEN end_char="189" id="token-5-6" morph="none" pos="word" start_char="182">wildfire</TOKEN>
<TOKEN end_char="192" id="token-5-7" morph="none" pos="word" start_char="191">on</TOKEN>
<TOKEN end_char="199" id="token-5-8" morph="none" pos="word" start_char="194">social</TOKEN>
<TOKEN end_char="205" id="token-5-9" morph="none" pos="word" start_char="201">media</TOKEN>
<TOKEN end_char="208" id="token-5-10" morph="none" pos="punct" start_char="207">--</TOKEN>
<TOKEN end_char="211" id="token-5-11" morph="none" pos="word" start_char="210">go</TOKEN>
<TOKEN end_char="217" id="token-5-12" morph="none" pos="word" start_char="213">viral</TOKEN>
<TOKEN end_char="220" id="token-5-13" morph="none" pos="punct" start_char="219">--</TOKEN>
<TOKEN end_char="231" id="token-5-14" morph="none" pos="word" start_char="222">especially</TOKEN>
<TOKEN end_char="237" id="token-5-15" morph="none" pos="word" start_char="233">false</TOKEN>
<TOKEN end_char="249" id="token-5-16" morph="none" pos="word" start_char="239">information</TOKEN>
<TOKEN end_char="250" id="token-5-17" morph="none" pos="punct" start_char="250">.</TOKEN>
</SEG>
<SEG end_char="482" id="segment-6" start_char="253">
<ORIGINAL_TEXT>WCVB is experiencing that phenomenon first-hand as we find one of our stories in the middle of a growing COVID-19 conspiracy online – a story that has been taken out of context and stamped with inaccurate and misleading headlines.</ORIGINAL_TEXT>
<TOKEN end_char="256" id="token-6-0" morph="none" pos="word" start_char="253">WCVB</TOKEN>
<TOKEN end_char="259" id="token-6-1" morph="none" pos="word" start_char="258">is</TOKEN>
<TOKEN end_char="272" id="token-6-2" morph="none" pos="word" start_char="261">experiencing</TOKEN>
<TOKEN end_char="277" id="token-6-3" morph="none" pos="word" start_char="274">that</TOKEN>
<TOKEN end_char="288" id="token-6-4" morph="none" pos="word" start_char="279">phenomenon</TOKEN>
<TOKEN end_char="299" id="token-6-5" morph="none" pos="unknown" start_char="290">first-hand</TOKEN>
<TOKEN end_char="302" id="token-6-6" morph="none" pos="word" start_char="301">as</TOKEN>
<TOKEN end_char="305" id="token-6-7" morph="none" pos="word" start_char="304">we</TOKEN>
<TOKEN end_char="310" id="token-6-8" morph="none" pos="word" start_char="307">find</TOKEN>
<TOKEN end_char="314" id="token-6-9" morph="none" pos="word" start_char="312">one</TOKEN>
<TOKEN end_char="317" id="token-6-10" morph="none" pos="word" start_char="316">of</TOKEN>
<TOKEN end_char="321" id="token-6-11" morph="none" pos="word" start_char="319">our</TOKEN>
<TOKEN end_char="329" id="token-6-12" morph="none" pos="word" start_char="323">stories</TOKEN>
<TOKEN end_char="332" id="token-6-13" morph="none" pos="word" start_char="331">in</TOKEN>
<TOKEN end_char="336" id="token-6-14" morph="none" pos="word" start_char="334">the</TOKEN>
<TOKEN end_char="343" id="token-6-15" morph="none" pos="word" start_char="338">middle</TOKEN>
<TOKEN end_char="346" id="token-6-16" morph="none" pos="word" start_char="345">of</TOKEN>
<TOKEN end_char="348" id="token-6-17" morph="none" pos="word" start_char="348">a</TOKEN>
<TOKEN end_char="356" id="token-6-18" morph="none" pos="word" start_char="350">growing</TOKEN>
<TOKEN end_char="365" id="token-6-19" morph="none" pos="unknown" start_char="358">COVID-19</TOKEN>
<TOKEN end_char="376" id="token-6-20" morph="none" pos="word" start_char="367">conspiracy</TOKEN>
<TOKEN end_char="383" id="token-6-21" morph="none" pos="word" start_char="378">online</TOKEN>
<TOKEN end_char="385" id="token-6-22" morph="none" pos="punct" start_char="385">–</TOKEN>
<TOKEN end_char="387" id="token-6-23" morph="none" pos="word" start_char="387">a</TOKEN>
<TOKEN end_char="393" id="token-6-24" morph="none" pos="word" start_char="389">story</TOKEN>
<TOKEN end_char="398" id="token-6-25" morph="none" pos="word" start_char="395">that</TOKEN>
<TOKEN end_char="402" id="token-6-26" morph="none" pos="word" start_char="400">has</TOKEN>
<TOKEN end_char="407" id="token-6-27" morph="none" pos="word" start_char="404">been</TOKEN>
<TOKEN end_char="413" id="token-6-28" morph="none" pos="word" start_char="409">taken</TOKEN>
<TOKEN end_char="417" id="token-6-29" morph="none" pos="word" start_char="415">out</TOKEN>
<TOKEN end_char="420" id="token-6-30" morph="none" pos="word" start_char="419">of</TOKEN>
<TOKEN end_char="428" id="token-6-31" morph="none" pos="word" start_char="422">context</TOKEN>
<TOKEN end_char="432" id="token-6-32" morph="none" pos="word" start_char="430">and</TOKEN>
<TOKEN end_char="440" id="token-6-33" morph="none" pos="word" start_char="434">stamped</TOKEN>
<TOKEN end_char="445" id="token-6-34" morph="none" pos="word" start_char="442">with</TOKEN>
<TOKEN end_char="456" id="token-6-35" morph="none" pos="word" start_char="447">inaccurate</TOKEN>
<TOKEN end_char="460" id="token-6-36" morph="none" pos="word" start_char="458">and</TOKEN>
<TOKEN end_char="471" id="token-6-37" morph="none" pos="word" start_char="462">misleading</TOKEN>
<TOKEN end_char="481" id="token-6-38" morph="none" pos="word" start_char="473">headlines</TOKEN>
<TOKEN end_char="482" id="token-6-39" morph="none" pos="punct" start_char="482">.</TOKEN>
</SEG>
<SEG end_char="680" id="segment-7" start_char="485">
<ORIGINAL_TEXT>Thousands of social media posts and several YouTube videos are spreading false claims that an American researcher who worked at Harvard University was involved in developing the novel coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="493" id="token-7-0" morph="none" pos="word" start_char="485">Thousands</TOKEN>
<TOKEN end_char="496" id="token-7-1" morph="none" pos="word" start_char="495">of</TOKEN>
<TOKEN end_char="503" id="token-7-2" morph="none" pos="word" start_char="498">social</TOKEN>
<TOKEN end_char="509" id="token-7-3" morph="none" pos="word" start_char="505">media</TOKEN>
<TOKEN end_char="515" id="token-7-4" morph="none" pos="word" start_char="511">posts</TOKEN>
<TOKEN end_char="519" id="token-7-5" morph="none" pos="word" start_char="517">and</TOKEN>
<TOKEN end_char="527" id="token-7-6" morph="none" pos="word" start_char="521">several</TOKEN>
<TOKEN end_char="535" id="token-7-7" morph="none" pos="word" start_char="529">YouTube</TOKEN>
<TOKEN end_char="542" id="token-7-8" morph="none" pos="word" start_char="537">videos</TOKEN>
<TOKEN end_char="546" id="token-7-9" morph="none" pos="word" start_char="544">are</TOKEN>
<TOKEN end_char="556" id="token-7-10" morph="none" pos="word" start_char="548">spreading</TOKEN>
<TOKEN end_char="562" id="token-7-11" morph="none" pos="word" start_char="558">false</TOKEN>
<TOKEN end_char="569" id="token-7-12" morph="none" pos="word" start_char="564">claims</TOKEN>
<TOKEN end_char="574" id="token-7-13" morph="none" pos="word" start_char="571">that</TOKEN>
<TOKEN end_char="577" id="token-7-14" morph="none" pos="word" start_char="576">an</TOKEN>
<TOKEN end_char="586" id="token-7-15" morph="none" pos="word" start_char="579">American</TOKEN>
<TOKEN end_char="597" id="token-7-16" morph="none" pos="word" start_char="588">researcher</TOKEN>
<TOKEN end_char="601" id="token-7-17" morph="none" pos="word" start_char="599">who</TOKEN>
<TOKEN end_char="608" id="token-7-18" morph="none" pos="word" start_char="603">worked</TOKEN>
<TOKEN end_char="611" id="token-7-19" morph="none" pos="word" start_char="610">at</TOKEN>
<TOKEN end_char="619" id="token-7-20" morph="none" pos="word" start_char="613">Harvard</TOKEN>
<TOKEN end_char="630" id="token-7-21" morph="none" pos="word" start_char="621">University</TOKEN>
<TOKEN end_char="634" id="token-7-22" morph="none" pos="word" start_char="632">was</TOKEN>
<TOKEN end_char="643" id="token-7-23" morph="none" pos="word" start_char="636">involved</TOKEN>
<TOKEN end_char="646" id="token-7-24" morph="none" pos="word" start_char="645">in</TOKEN>
<TOKEN end_char="657" id="token-7-25" morph="none" pos="word" start_char="648">developing</TOKEN>
<TOKEN end_char="661" id="token-7-26" morph="none" pos="word" start_char="659">the</TOKEN>
<TOKEN end_char="667" id="token-7-27" morph="none" pos="word" start_char="663">novel</TOKEN>
<TOKEN end_char="679" id="token-7-28" morph="none" pos="word" start_char="669">coronavirus</TOKEN>
<TOKEN end_char="680" id="token-7-29" morph="none" pos="punct" start_char="680">.</TOKEN>
</SEG>
<SEG end_char="776" id="segment-8" start_char="682">
<ORIGINAL_TEXT>In the attempt to legitimize those claims, the posts are pointing to a WCVB story from January.</ORIGINAL_TEXT>
<TOKEN end_char="683" id="token-8-0" morph="none" pos="word" start_char="682">In</TOKEN>
<TOKEN end_char="687" id="token-8-1" morph="none" pos="word" start_char="685">the</TOKEN>
<TOKEN end_char="695" id="token-8-2" morph="none" pos="word" start_char="689">attempt</TOKEN>
<TOKEN end_char="698" id="token-8-3" morph="none" pos="word" start_char="697">to</TOKEN>
<TOKEN end_char="709" id="token-8-4" morph="none" pos="word" start_char="700">legitimize</TOKEN>
<TOKEN end_char="715" id="token-8-5" morph="none" pos="word" start_char="711">those</TOKEN>
<TOKEN end_char="722" id="token-8-6" morph="none" pos="word" start_char="717">claims</TOKEN>
<TOKEN end_char="723" id="token-8-7" morph="none" pos="punct" start_char="723">,</TOKEN>
<TOKEN end_char="727" id="token-8-8" morph="none" pos="word" start_char="725">the</TOKEN>
<TOKEN end_char="733" id="token-8-9" morph="none" pos="word" start_char="729">posts</TOKEN>
<TOKEN end_char="737" id="token-8-10" morph="none" pos="word" start_char="735">are</TOKEN>
<TOKEN end_char="746" id="token-8-11" morph="none" pos="word" start_char="739">pointing</TOKEN>
<TOKEN end_char="749" id="token-8-12" morph="none" pos="word" start_char="748">to</TOKEN>
<TOKEN end_char="751" id="token-8-13" morph="none" pos="word" start_char="751">a</TOKEN>
<TOKEN end_char="756" id="token-8-14" morph="none" pos="word" start_char="753">WCVB</TOKEN>
<TOKEN end_char="762" id="token-8-15" morph="none" pos="word" start_char="758">story</TOKEN>
<TOKEN end_char="767" id="token-8-16" morph="none" pos="word" start_char="764">from</TOKEN>
<TOKEN end_char="775" id="token-8-17" morph="none" pos="word" start_char="769">January</TOKEN>
<TOKEN end_char="776" id="token-8-18" morph="none" pos="punct" start_char="776">.</TOKEN>
</SEG>
<SEG end_char="843" id="segment-9" start_char="778">
<ORIGINAL_TEXT>But the claims are not true, and the story never made any of them.</ORIGINAL_TEXT>
<TOKEN end_char="780" id="token-9-0" morph="none" pos="word" start_char="778">But</TOKEN>
<TOKEN end_char="784" id="token-9-1" morph="none" pos="word" start_char="782">the</TOKEN>
<TOKEN end_char="791" id="token-9-2" morph="none" pos="word" start_char="786">claims</TOKEN>
<TOKEN end_char="795" id="token-9-3" morph="none" pos="word" start_char="793">are</TOKEN>
<TOKEN end_char="799" id="token-9-4" morph="none" pos="word" start_char="797">not</TOKEN>
<TOKEN end_char="804" id="token-9-5" morph="none" pos="word" start_char="801">true</TOKEN>
<TOKEN end_char="805" id="token-9-6" morph="none" pos="punct" start_char="805">,</TOKEN>
<TOKEN end_char="809" id="token-9-7" morph="none" pos="word" start_char="807">and</TOKEN>
<TOKEN end_char="813" id="token-9-8" morph="none" pos="word" start_char="811">the</TOKEN>
<TOKEN end_char="819" id="token-9-9" morph="none" pos="word" start_char="815">story</TOKEN>
<TOKEN end_char="825" id="token-9-10" morph="none" pos="word" start_char="821">never</TOKEN>
<TOKEN end_char="830" id="token-9-11" morph="none" pos="word" start_char="827">made</TOKEN>
<TOKEN end_char="834" id="token-9-12" morph="none" pos="word" start_char="832">any</TOKEN>
<TOKEN end_char="837" id="token-9-13" morph="none" pos="word" start_char="836">of</TOKEN>
<TOKEN end_char="842" id="token-9-14" morph="none" pos="word" start_char="839">them</TOKEN>
<TOKEN end_char="843" id="token-9-15" morph="none" pos="punct" start_char="843">.</TOKEN>
</SEG>
<SEG end_char="952" id="segment-10" start_char="846">
<ORIGINAL_TEXT>Some of the false claims have been translated into multiple languages and are circulating around the world.</ORIGINAL_TEXT>
<TOKEN end_char="849" id="token-10-0" morph="none" pos="word" start_char="846">Some</TOKEN>
<TOKEN end_char="852" id="token-10-1" morph="none" pos="word" start_char="851">of</TOKEN>
<TOKEN end_char="856" id="token-10-2" morph="none" pos="word" start_char="854">the</TOKEN>
<TOKEN end_char="862" id="token-10-3" morph="none" pos="word" start_char="858">false</TOKEN>
<TOKEN end_char="869" id="token-10-4" morph="none" pos="word" start_char="864">claims</TOKEN>
<TOKEN end_char="874" id="token-10-5" morph="none" pos="word" start_char="871">have</TOKEN>
<TOKEN end_char="879" id="token-10-6" morph="none" pos="word" start_char="876">been</TOKEN>
<TOKEN end_char="890" id="token-10-7" morph="none" pos="word" start_char="881">translated</TOKEN>
<TOKEN end_char="895" id="token-10-8" morph="none" pos="word" start_char="892">into</TOKEN>
<TOKEN end_char="904" id="token-10-9" morph="none" pos="word" start_char="897">multiple</TOKEN>
<TOKEN end_char="914" id="token-10-10" morph="none" pos="word" start_char="906">languages</TOKEN>
<TOKEN end_char="918" id="token-10-11" morph="none" pos="word" start_char="916">and</TOKEN>
<TOKEN end_char="922" id="token-10-12" morph="none" pos="word" start_char="920">are</TOKEN>
<TOKEN end_char="934" id="token-10-13" morph="none" pos="word" start_char="924">circulating</TOKEN>
<TOKEN end_char="941" id="token-10-14" morph="none" pos="word" start_char="936">around</TOKEN>
<TOKEN end_char="945" id="token-10-15" morph="none" pos="word" start_char="943">the</TOKEN>
<TOKEN end_char="951" id="token-10-16" morph="none" pos="word" start_char="947">world</TOKEN>
<TOKEN end_char="952" id="token-10-17" morph="none" pos="punct" start_char="952">.</TOKEN>
</SEG>
<SEG end_char="1038" id="segment-11" start_char="955">
<ORIGINAL_TEXT>Here are the facts about the story and what we know about the investigation into Dr.</ORIGINAL_TEXT>
<TOKEN end_char="958" id="token-11-0" morph="none" pos="word" start_char="955">Here</TOKEN>
<TOKEN end_char="962" id="token-11-1" morph="none" pos="word" start_char="960">are</TOKEN>
<TOKEN end_char="966" id="token-11-2" morph="none" pos="word" start_char="964">the</TOKEN>
<TOKEN end_char="972" id="token-11-3" morph="none" pos="word" start_char="968">facts</TOKEN>
<TOKEN end_char="978" id="token-11-4" morph="none" pos="word" start_char="974">about</TOKEN>
<TOKEN end_char="982" id="token-11-5" morph="none" pos="word" start_char="980">the</TOKEN>
<TOKEN end_char="988" id="token-11-6" morph="none" pos="word" start_char="984">story</TOKEN>
<TOKEN end_char="992" id="token-11-7" morph="none" pos="word" start_char="990">and</TOKEN>
<TOKEN end_char="997" id="token-11-8" morph="none" pos="word" start_char="994">what</TOKEN>
<TOKEN end_char="1000" id="token-11-9" morph="none" pos="word" start_char="999">we</TOKEN>
<TOKEN end_char="1005" id="token-11-10" morph="none" pos="word" start_char="1002">know</TOKEN>
<TOKEN end_char="1011" id="token-11-11" morph="none" pos="word" start_char="1007">about</TOKEN>
<TOKEN end_char="1015" id="token-11-12" morph="none" pos="word" start_char="1013">the</TOKEN>
<TOKEN end_char="1029" id="token-11-13" morph="none" pos="word" start_char="1017">investigation</TOKEN>
<TOKEN end_char="1034" id="token-11-14" morph="none" pos="word" start_char="1031">into</TOKEN>
<TOKEN end_char="1037" id="token-11-15" morph="none" pos="word" start_char="1036">Dr</TOKEN>
<TOKEN end_char="1038" id="token-11-16" morph="none" pos="punct" start_char="1038">.</TOKEN>
</SEG>
<SEG end_char="1054" id="segment-12" start_char="1040">
<ORIGINAL_TEXT>Charles Lieber:</ORIGINAL_TEXT>
<TOKEN end_char="1046" id="token-12-0" morph="none" pos="word" start_char="1040">Charles</TOKEN>
<TOKEN end_char="1053" id="token-12-1" morph="none" pos="word" start_char="1048">Lieber</TOKEN>
<TOKEN end_char="1054" id="token-12-2" morph="none" pos="punct" start_char="1054">:</TOKEN>
</SEG>
<SEG end_char="1092" id="segment-13" start_char="1057">
<ORIGINAL_TEXT>Harvard Department Chairman Arrested</ORIGINAL_TEXT>
<TOKEN end_char="1063" id="token-13-0" morph="none" pos="word" start_char="1057">Harvard</TOKEN>
<TOKEN end_char="1074" id="token-13-1" morph="none" pos="word" start_char="1065">Department</TOKEN>
<TOKEN end_char="1083" id="token-13-2" morph="none" pos="word" start_char="1076">Chairman</TOKEN>
<TOKEN end_char="1092" id="token-13-3" morph="none" pos="word" start_char="1085">Arrested</TOKEN>
</SEG>
<SEG end_char="1189" id="segment-14" start_char="1095">
<ORIGINAL_TEXT>"The complaint alleges that Dr. Lieber signed a contract with the Chinese University in Wuhan."</ORIGINAL_TEXT>
<TOKEN end_char="1095" id="token-14-0" morph="none" pos="punct" start_char="1095">"</TOKEN>
<TOKEN end_char="1098" id="token-14-1" morph="none" pos="word" start_char="1096">The</TOKEN>
<TOKEN end_char="1108" id="token-14-2" morph="none" pos="word" start_char="1100">complaint</TOKEN>
<TOKEN end_char="1116" id="token-14-3" morph="none" pos="word" start_char="1110">alleges</TOKEN>
<TOKEN end_char="1121" id="token-14-4" morph="none" pos="word" start_char="1118">that</TOKEN>
<TOKEN end_char="1124" id="token-14-5" morph="none" pos="word" start_char="1123">Dr</TOKEN>
<TOKEN end_char="1125" id="token-14-6" morph="none" pos="punct" start_char="1125">.</TOKEN>
<TOKEN end_char="1132" id="token-14-7" morph="none" pos="word" start_char="1127">Lieber</TOKEN>
<TOKEN end_char="1139" id="token-14-8" morph="none" pos="word" start_char="1134">signed</TOKEN>
<TOKEN end_char="1141" id="token-14-9" morph="none" pos="word" start_char="1141">a</TOKEN>
<TOKEN end_char="1150" id="token-14-10" morph="none" pos="word" start_char="1143">contract</TOKEN>
<TOKEN end_char="1155" id="token-14-11" morph="none" pos="word" start_char="1152">with</TOKEN>
<TOKEN end_char="1159" id="token-14-12" morph="none" pos="word" start_char="1157">the</TOKEN>
<TOKEN end_char="1167" id="token-14-13" morph="none" pos="word" start_char="1161">Chinese</TOKEN>
<TOKEN end_char="1178" id="token-14-14" morph="none" pos="word" start_char="1169">University</TOKEN>
<TOKEN end_char="1181" id="token-14-15" morph="none" pos="word" start_char="1180">in</TOKEN>
<TOKEN end_char="1187" id="token-14-16" morph="none" pos="word" start_char="1183">Wuhan</TOKEN>
<TOKEN end_char="1189" id="token-14-17" morph="none" pos="punct" start_char="1188">."</TOKEN>
</SEG>
<SEG end_char="1290" id="segment-15" start_char="1192">
<ORIGINAL_TEXT>Those words were spoken by Andrew Lelling, U.S. Attorney for the District of Massachusetts, on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="1196" id="token-15-0" morph="none" pos="word" start_char="1192">Those</TOKEN>
<TOKEN end_char="1202" id="token-15-1" morph="none" pos="word" start_char="1198">words</TOKEN>
<TOKEN end_char="1207" id="token-15-2" morph="none" pos="word" start_char="1204">were</TOKEN>
<TOKEN end_char="1214" id="token-15-3" morph="none" pos="word" start_char="1209">spoken</TOKEN>
<TOKEN end_char="1217" id="token-15-4" morph="none" pos="word" start_char="1216">by</TOKEN>
<TOKEN end_char="1224" id="token-15-5" morph="none" pos="word" start_char="1219">Andrew</TOKEN>
<TOKEN end_char="1232" id="token-15-6" morph="none" pos="word" start_char="1226">Lelling</TOKEN>
<TOKEN end_char="1233" id="token-15-7" morph="none" pos="punct" start_char="1233">,</TOKEN>
<TOKEN end_char="1237" id="token-15-8" morph="none" pos="unknown" start_char="1235">U.S</TOKEN>
<TOKEN end_char="1238" id="token-15-9" morph="none" pos="punct" start_char="1238">.</TOKEN>
<TOKEN end_char="1247" id="token-15-10" morph="none" pos="word" start_char="1240">Attorney</TOKEN>
<TOKEN end_char="1251" id="token-15-11" morph="none" pos="word" start_char="1249">for</TOKEN>
<TOKEN end_char="1255" id="token-15-12" morph="none" pos="word" start_char="1253">the</TOKEN>
<TOKEN end_char="1264" id="token-15-13" morph="none" pos="word" start_char="1257">District</TOKEN>
<TOKEN end_char="1267" id="token-15-14" morph="none" pos="word" start_char="1266">of</TOKEN>
<TOKEN end_char="1281" id="token-15-15" morph="none" pos="word" start_char="1269">Massachusetts</TOKEN>
<TOKEN end_char="1282" id="token-15-16" morph="none" pos="punct" start_char="1282">,</TOKEN>
<TOKEN end_char="1285" id="token-15-17" morph="none" pos="word" start_char="1284">on</TOKEN>
<TOKEN end_char="1289" id="token-15-18" morph="none" pos="word" start_char="1287">Jan</TOKEN>
<TOKEN end_char="1290" id="token-15-19" morph="none" pos="punct" start_char="1290">.</TOKEN>
</SEG>
<SEG end_char="1294" id="segment-16" start_char="1292">
<ORIGINAL_TEXT>28.</ORIGINAL_TEXT>
<TOKEN end_char="1293" id="token-16-0" morph="none" pos="word" start_char="1292">28</TOKEN>
<TOKEN end_char="1294" id="token-16-1" morph="none" pos="punct" start_char="1294">.</TOKEN>
<TRANSLATED_TEXT>- 28.</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="1361" id="segment-17" start_char="1296">
<ORIGINAL_TEXT>They are now being used to fuel the conspiracy and misconceptions.</ORIGINAL_TEXT>
<TOKEN end_char="1299" id="token-17-0" morph="none" pos="word" start_char="1296">They</TOKEN>
<TOKEN end_char="1303" id="token-17-1" morph="none" pos="word" start_char="1301">are</TOKEN>
<TOKEN end_char="1307" id="token-17-2" morph="none" pos="word" start_char="1305">now</TOKEN>
<TOKEN end_char="1313" id="token-17-3" morph="none" pos="word" start_char="1309">being</TOKEN>
<TOKEN end_char="1318" id="token-17-4" morph="none" pos="word" start_char="1315">used</TOKEN>
<TOKEN end_char="1321" id="token-17-5" morph="none" pos="word" start_char="1320">to</TOKEN>
<TOKEN end_char="1326" id="token-17-6" morph="none" pos="word" start_char="1323">fuel</TOKEN>
<TOKEN end_char="1330" id="token-17-7" morph="none" pos="word" start_char="1328">the</TOKEN>
<TOKEN end_char="1341" id="token-17-8" morph="none" pos="word" start_char="1332">conspiracy</TOKEN>
<TOKEN end_char="1345" id="token-17-9" morph="none" pos="word" start_char="1343">and</TOKEN>
<TOKEN end_char="1360" id="token-17-10" morph="none" pos="word" start_char="1347">misconceptions</TOKEN>
<TOKEN end_char="1361" id="token-17-11" morph="none" pos="punct" start_char="1361">.</TOKEN>
</SEG>
<SEG end_char="1528" id="segment-18" start_char="1364">
<ORIGINAL_TEXT>Lelling was speaking at a news conference regarding the arrest of Dr. Lieber, the chairman of the Department of Chemistry and Chemical Biology at Harvard University.</ORIGINAL_TEXT>
<TOKEN end_char="1370" id="token-18-0" morph="none" pos="word" start_char="1364">Lelling</TOKEN>
<TOKEN end_char="1374" id="token-18-1" morph="none" pos="word" start_char="1372">was</TOKEN>
<TOKEN end_char="1383" id="token-18-2" morph="none" pos="word" start_char="1376">speaking</TOKEN>
<TOKEN end_char="1386" id="token-18-3" morph="none" pos="word" start_char="1385">at</TOKEN>
<TOKEN end_char="1388" id="token-18-4" morph="none" pos="word" start_char="1388">a</TOKEN>
<TOKEN end_char="1393" id="token-18-5" morph="none" pos="word" start_char="1390">news</TOKEN>
<TOKEN end_char="1404" id="token-18-6" morph="none" pos="word" start_char="1395">conference</TOKEN>
<TOKEN end_char="1414" id="token-18-7" morph="none" pos="word" start_char="1406">regarding</TOKEN>
<TOKEN end_char="1418" id="token-18-8" morph="none" pos="word" start_char="1416">the</TOKEN>
<TOKEN end_char="1425" id="token-18-9" morph="none" pos="word" start_char="1420">arrest</TOKEN>
<TOKEN end_char="1428" id="token-18-10" morph="none" pos="word" start_char="1427">of</TOKEN>
<TOKEN end_char="1431" id="token-18-11" morph="none" pos="word" start_char="1430">Dr</TOKEN>
<TOKEN end_char="1432" id="token-18-12" morph="none" pos="punct" start_char="1432">.</TOKEN>
<TOKEN end_char="1439" id="token-18-13" morph="none" pos="word" start_char="1434">Lieber</TOKEN>
<TOKEN end_char="1440" id="token-18-14" morph="none" pos="punct" start_char="1440">,</TOKEN>
<TOKEN end_char="1444" id="token-18-15" morph="none" pos="word" start_char="1442">the</TOKEN>
<TOKEN end_char="1453" id="token-18-16" morph="none" pos="word" start_char="1446">chairman</TOKEN>
<TOKEN end_char="1456" id="token-18-17" morph="none" pos="word" start_char="1455">of</TOKEN>
<TOKEN end_char="1460" id="token-18-18" morph="none" pos="word" start_char="1458">the</TOKEN>
<TOKEN end_char="1471" id="token-18-19" morph="none" pos="word" start_char="1462">Department</TOKEN>
<TOKEN end_char="1474" id="token-18-20" morph="none" pos="word" start_char="1473">of</TOKEN>
<TOKEN end_char="1484" id="token-18-21" morph="none" pos="word" start_char="1476">Chemistry</TOKEN>
<TOKEN end_char="1488" id="token-18-22" morph="none" pos="word" start_char="1486">and</TOKEN>
<TOKEN end_char="1497" id="token-18-23" morph="none" pos="word" start_char="1490">Chemical</TOKEN>
<TOKEN end_char="1505" id="token-18-24" morph="none" pos="word" start_char="1499">Biology</TOKEN>
<TOKEN end_char="1508" id="token-18-25" morph="none" pos="word" start_char="1507">at</TOKEN>
<TOKEN end_char="1516" id="token-18-26" morph="none" pos="word" start_char="1510">Harvard</TOKEN>
<TOKEN end_char="1527" id="token-18-27" morph="none" pos="word" start_char="1518">University</TOKEN>
<TOKEN end_char="1528" id="token-18-28" morph="none" pos="punct" start_char="1528">.</TOKEN>
</SEG>
<SEG end_char="1708" id="segment-19" start_char="1531">
<ORIGINAL_TEXT>Dr. Lieber, of Lexington, Mass., is charged with "Making false statements to the agency of the United States Government," or lying to federal authorities about his ties to China.</ORIGINAL_TEXT>
<TOKEN end_char="1532" id="token-19-0" morph="none" pos="word" start_char="1531">Dr</TOKEN>
<TOKEN end_char="1533" id="token-19-1" morph="none" pos="punct" start_char="1533">.</TOKEN>
<TOKEN end_char="1540" id="token-19-2" morph="none" pos="word" start_char="1535">Lieber</TOKEN>
<TOKEN end_char="1541" id="token-19-3" morph="none" pos="punct" start_char="1541">,</TOKEN>
<TOKEN end_char="1544" id="token-19-4" morph="none" pos="word" start_char="1543">of</TOKEN>
<TOKEN end_char="1554" id="token-19-5" morph="none" pos="word" start_char="1546">Lexington</TOKEN>
<TOKEN end_char="1555" id="token-19-6" morph="none" pos="punct" start_char="1555">,</TOKEN>
<TOKEN end_char="1560" id="token-19-7" morph="none" pos="word" start_char="1557">Mass</TOKEN>
<TOKEN end_char="1562" id="token-19-8" morph="none" pos="punct" start_char="1561">.,</TOKEN>
<TOKEN end_char="1565" id="token-19-9" morph="none" pos="word" start_char="1564">is</TOKEN>
<TOKEN end_char="1573" id="token-19-10" morph="none" pos="word" start_char="1567">charged</TOKEN>
<TOKEN end_char="1578" id="token-19-11" morph="none" pos="word" start_char="1575">with</TOKEN>
<TOKEN end_char="1580" id="token-19-12" morph="none" pos="punct" start_char="1580">"</TOKEN>
<TOKEN end_char="1586" id="token-19-13" morph="none" pos="word" start_char="1581">Making</TOKEN>
<TOKEN end_char="1592" id="token-19-14" morph="none" pos="word" start_char="1588">false</TOKEN>
<TOKEN end_char="1603" id="token-19-15" morph="none" pos="word" start_char="1594">statements</TOKEN>
<TOKEN end_char="1606" id="token-19-16" morph="none" pos="word" start_char="1605">to</TOKEN>
<TOKEN end_char="1610" id="token-19-17" morph="none" pos="word" start_char="1608">the</TOKEN>
<TOKEN end_char="1617" id="token-19-18" morph="none" pos="word" start_char="1612">agency</TOKEN>
<TOKEN end_char="1620" id="token-19-19" morph="none" pos="word" start_char="1619">of</TOKEN>
<TOKEN end_char="1624" id="token-19-20" morph="none" pos="word" start_char="1622">the</TOKEN>
<TOKEN end_char="1631" id="token-19-21" morph="none" pos="word" start_char="1626">United</TOKEN>
<TOKEN end_char="1638" id="token-19-22" morph="none" pos="word" start_char="1633">States</TOKEN>
<TOKEN end_char="1649" id="token-19-23" morph="none" pos="word" start_char="1640">Government</TOKEN>
<TOKEN end_char="1651" id="token-19-24" morph="none" pos="punct" start_char="1650">,"</TOKEN>
<TOKEN end_char="1654" id="token-19-25" morph="none" pos="word" start_char="1653">or</TOKEN>
<TOKEN end_char="1660" id="token-19-26" morph="none" pos="word" start_char="1656">lying</TOKEN>
<TOKEN end_char="1663" id="token-19-27" morph="none" pos="word" start_char="1662">to</TOKEN>
<TOKEN end_char="1671" id="token-19-28" morph="none" pos="word" start_char="1665">federal</TOKEN>
<TOKEN end_char="1683" id="token-19-29" morph="none" pos="word" start_char="1673">authorities</TOKEN>
<TOKEN end_char="1689" id="token-19-30" morph="none" pos="word" start_char="1685">about</TOKEN>
<TOKEN end_char="1693" id="token-19-31" morph="none" pos="word" start_char="1691">his</TOKEN>
<TOKEN end_char="1698" id="token-19-32" morph="none" pos="word" start_char="1695">ties</TOKEN>
<TOKEN end_char="1701" id="token-19-33" morph="none" pos="word" start_char="1700">to</TOKEN>
<TOKEN end_char="1707" id="token-19-34" morph="none" pos="word" start_char="1703">China</TOKEN>
<TOKEN end_char="1708" id="token-19-35" morph="none" pos="punct" start_char="1708">.</TOKEN>
</SEG>
<SEG end_char="1833" id="segment-20" start_char="1711">
<ORIGINAL_TEXT>According to court documents, Dr. Lieber was the Principal Investigator of the Lieber Research Group at Harvard University.</ORIGINAL_TEXT>
<TOKEN end_char="1719" id="token-20-0" morph="none" pos="word" start_char="1711">According</TOKEN>
<TOKEN end_char="1722" id="token-20-1" morph="none" pos="word" start_char="1721">to</TOKEN>
<TOKEN end_char="1728" id="token-20-2" morph="none" pos="word" start_char="1724">court</TOKEN>
<TOKEN end_char="1738" id="token-20-3" morph="none" pos="word" start_char="1730">documents</TOKEN>
<TOKEN end_char="1739" id="token-20-4" morph="none" pos="punct" start_char="1739">,</TOKEN>
<TOKEN end_char="1742" id="token-20-5" morph="none" pos="word" start_char="1741">Dr</TOKEN>
<TOKEN end_char="1743" id="token-20-6" morph="none" pos="punct" start_char="1743">.</TOKEN>
<TOKEN end_char="1750" id="token-20-7" morph="none" pos="word" start_char="1745">Lieber</TOKEN>
<TOKEN end_char="1754" id="token-20-8" morph="none" pos="word" start_char="1752">was</TOKEN>
<TOKEN end_char="1758" id="token-20-9" morph="none" pos="word" start_char="1756">the</TOKEN>
<TOKEN end_char="1768" id="token-20-10" morph="none" pos="word" start_char="1760">Principal</TOKEN>
<TOKEN end_char="1781" id="token-20-11" morph="none" pos="word" start_char="1770">Investigator</TOKEN>
<TOKEN end_char="1784" id="token-20-12" morph="none" pos="word" start_char="1783">of</TOKEN>
<TOKEN end_char="1788" id="token-20-13" morph="none" pos="word" start_char="1786">the</TOKEN>
<TOKEN end_char="1795" id="token-20-14" morph="none" pos="word" start_char="1790">Lieber</TOKEN>
<TOKEN end_char="1804" id="token-20-15" morph="none" pos="word" start_char="1797">Research</TOKEN>
<TOKEN end_char="1810" id="token-20-16" morph="none" pos="word" start_char="1806">Group</TOKEN>
<TOKEN end_char="1813" id="token-20-17" morph="none" pos="word" start_char="1812">at</TOKEN>
<TOKEN end_char="1821" id="token-20-18" morph="none" pos="word" start_char="1815">Harvard</TOKEN>
<TOKEN end_char="1832" id="token-20-19" morph="none" pos="word" start_char="1823">University</TOKEN>
<TOKEN end_char="1833" id="token-20-20" morph="none" pos="punct" start_char="1833">.</TOKEN>
</SEG>
<SEG end_char="1970" id="segment-21" start_char="1835">
<ORIGINAL_TEXT>Since 2008, the group had received more than $15 million in grants from the National Institutes of Health and the Department of Defense.</ORIGINAL_TEXT>
<TOKEN end_char="1839" id="token-21-0" morph="none" pos="word" start_char="1835">Since</TOKEN>
<TOKEN end_char="1844" id="token-21-1" morph="none" pos="word" start_char="1841">2008</TOKEN>
<TOKEN end_char="1845" id="token-21-2" morph="none" pos="punct" start_char="1845">,</TOKEN>
<TOKEN end_char="1849" id="token-21-3" morph="none" pos="word" start_char="1847">the</TOKEN>
<TOKEN end_char="1855" id="token-21-4" morph="none" pos="word" start_char="1851">group</TOKEN>
<TOKEN end_char="1859" id="token-21-5" morph="none" pos="word" start_char="1857">had</TOKEN>
<TOKEN end_char="1868" id="token-21-6" morph="none" pos="word" start_char="1861">received</TOKEN>
<TOKEN end_char="1873" id="token-21-7" morph="none" pos="word" start_char="1870">more</TOKEN>
<TOKEN end_char="1878" id="token-21-8" morph="none" pos="word" start_char="1875">than</TOKEN>
<TOKEN end_char="1882" id="token-21-9" morph="none" pos="unknown" start_char="1880">$15</TOKEN>
<TOKEN end_char="1890" id="token-21-10" morph="none" pos="word" start_char="1884">million</TOKEN>
<TOKEN end_char="1893" id="token-21-11" morph="none" pos="word" start_char="1892">in</TOKEN>
<TOKEN end_char="1900" id="token-21-12" morph="none" pos="word" start_char="1895">grants</TOKEN>
<TOKEN end_char="1905" id="token-21-13" morph="none" pos="word" start_char="1902">from</TOKEN>
<TOKEN end_char="1909" id="token-21-14" morph="none" pos="word" start_char="1907">the</TOKEN>
<TOKEN end_char="1918" id="token-21-15" morph="none" pos="word" start_char="1911">National</TOKEN>
<TOKEN end_char="1929" id="token-21-16" morph="none" pos="word" start_char="1920">Institutes</TOKEN>
<TOKEN end_char="1932" id="token-21-17" morph="none" pos="word" start_char="1931">of</TOKEN>
<TOKEN end_char="1939" id="token-21-18" morph="none" pos="word" start_char="1934">Health</TOKEN>
<TOKEN end_char="1943" id="token-21-19" morph="none" pos="word" start_char="1941">and</TOKEN>
<TOKEN end_char="1947" id="token-21-20" morph="none" pos="word" start_char="1945">the</TOKEN>
<TOKEN end_char="1958" id="token-21-21" morph="none" pos="word" start_char="1949">Department</TOKEN>
<TOKEN end_char="1961" id="token-21-22" morph="none" pos="word" start_char="1960">of</TOKEN>
<TOKEN end_char="1969" id="token-21-23" morph="none" pos="word" start_char="1963">Defense</TOKEN>
<TOKEN end_char="1970" id="token-21-24" morph="none" pos="punct" start_char="1970">.</TOKEN>
</SEG>
<SEG end_char="2249" id="segment-22" start_char="1973">
<ORIGINAL_TEXT>However, prosecutors allege that on applications with the NIH and DoD, Dr. Lieber did not disclose that he was being paid a salary of up to $50,000 per month and up to $158,000 per year in living expenses by China's Thousand Talents Plan and the Wuhan University of Technology.</ORIGINAL_TEXT>
<TOKEN end_char="1979" id="token-22-0" morph="none" pos="word" start_char="1973">However</TOKEN>
<TOKEN end_char="1980" id="token-22-1" morph="none" pos="punct" start_char="1980">,</TOKEN>
<TOKEN end_char="1992" id="token-22-2" morph="none" pos="word" start_char="1982">prosecutors</TOKEN>
<TOKEN end_char="1999" id="token-22-3" morph="none" pos="word" start_char="1994">allege</TOKEN>
<TOKEN end_char="2004" id="token-22-4" morph="none" pos="word" start_char="2001">that</TOKEN>
<TOKEN end_char="2007" id="token-22-5" morph="none" pos="word" start_char="2006">on</TOKEN>
<TOKEN end_char="2020" id="token-22-6" morph="none" pos="word" start_char="2009">applications</TOKEN>
<TOKEN end_char="2025" id="token-22-7" morph="none" pos="word" start_char="2022">with</TOKEN>
<TOKEN end_char="2029" id="token-22-8" morph="none" pos="word" start_char="2027">the</TOKEN>
<TOKEN end_char="2033" id="token-22-9" morph="none" pos="word" start_char="2031">NIH</TOKEN>
<TOKEN end_char="2037" id="token-22-10" morph="none" pos="word" start_char="2035">and</TOKEN>
<TOKEN end_char="2041" id="token-22-11" morph="none" pos="word" start_char="2039">DoD</TOKEN>
<TOKEN end_char="2042" id="token-22-12" morph="none" pos="punct" start_char="2042">,</TOKEN>
<TOKEN end_char="2045" id="token-22-13" morph="none" pos="word" start_char="2044">Dr</TOKEN>
<TOKEN end_char="2046" id="token-22-14" morph="none" pos="punct" start_char="2046">.</TOKEN>
<TOKEN end_char="2053" id="token-22-15" morph="none" pos="word" start_char="2048">Lieber</TOKEN>
<TOKEN end_char="2057" id="token-22-16" morph="none" pos="word" start_char="2055">did</TOKEN>
<TOKEN end_char="2061" id="token-22-17" morph="none" pos="word" start_char="2059">not</TOKEN>
<TOKEN end_char="2070" id="token-22-18" morph="none" pos="word" start_char="2063">disclose</TOKEN>
<TOKEN end_char="2075" id="token-22-19" morph="none" pos="word" start_char="2072">that</TOKEN>
<TOKEN end_char="2078" id="token-22-20" morph="none" pos="word" start_char="2077">he</TOKEN>
<TOKEN end_char="2082" id="token-22-21" morph="none" pos="word" start_char="2080">was</TOKEN>
<TOKEN end_char="2088" id="token-22-22" morph="none" pos="word" start_char="2084">being</TOKEN>
<TOKEN end_char="2093" id="token-22-23" morph="none" pos="word" start_char="2090">paid</TOKEN>
<TOKEN end_char="2095" id="token-22-24" morph="none" pos="word" start_char="2095">a</TOKEN>
<TOKEN end_char="2102" id="token-22-25" morph="none" pos="word" start_char="2097">salary</TOKEN>
<TOKEN end_char="2105" id="token-22-26" morph="none" pos="word" start_char="2104">of</TOKEN>
<TOKEN end_char="2108" id="token-22-27" morph="none" pos="word" start_char="2107">up</TOKEN>
<TOKEN end_char="2111" id="token-22-28" morph="none" pos="word" start_char="2110">to</TOKEN>
<TOKEN end_char="2119" id="token-22-29" morph="none" pos="unknown" start_char="2113">$50,000</TOKEN>
<TOKEN end_char="2123" id="token-22-30" morph="none" pos="word" start_char="2121">per</TOKEN>
<TOKEN end_char="2129" id="token-22-31" morph="none" pos="word" start_char="2125">month</TOKEN>
<TOKEN end_char="2133" id="token-22-32" morph="none" pos="word" start_char="2131">and</TOKEN>
<TOKEN end_char="2136" id="token-22-33" morph="none" pos="word" start_char="2135">up</TOKEN>
<TOKEN end_char="2139" id="token-22-34" morph="none" pos="word" start_char="2138">to</TOKEN>
<TOKEN end_char="2148" id="token-22-35" morph="none" pos="unknown" start_char="2141">$158,000</TOKEN>
<TOKEN end_char="2152" id="token-22-36" morph="none" pos="word" start_char="2150">per</TOKEN>
<TOKEN end_char="2157" id="token-22-37" morph="none" pos="word" start_char="2154">year</TOKEN>
<TOKEN end_char="2160" id="token-22-38" morph="none" pos="word" start_char="2159">in</TOKEN>
<TOKEN end_char="2167" id="token-22-39" morph="none" pos="word" start_char="2162">living</TOKEN>
<TOKEN end_char="2176" id="token-22-40" morph="none" pos="word" start_char="2169">expenses</TOKEN>
<TOKEN end_char="2179" id="token-22-41" morph="none" pos="word" start_char="2178">by</TOKEN>
<TOKEN end_char="2187" id="token-22-42" morph="none" pos="word" start_char="2181">China's</TOKEN>
<TOKEN end_char="2196" id="token-22-43" morph="none" pos="word" start_char="2189">Thousand</TOKEN>
<TOKEN end_char="2204" id="token-22-44" morph="none" pos="word" start_char="2198">Talents</TOKEN>
<TOKEN end_char="2209" id="token-22-45" morph="none" pos="word" start_char="2206">Plan</TOKEN>
<TOKEN end_char="2213" id="token-22-46" morph="none" pos="word" start_char="2211">and</TOKEN>
<TOKEN end_char="2217" id="token-22-47" morph="none" pos="word" start_char="2215">the</TOKEN>
<TOKEN end_char="2223" id="token-22-48" morph="none" pos="word" start_char="2219">Wuhan</TOKEN>
<TOKEN end_char="2234" id="token-22-49" morph="none" pos="word" start_char="2225">University</TOKEN>
<TOKEN end_char="2237" id="token-22-50" morph="none" pos="word" start_char="2236">of</TOKEN>
<TOKEN end_char="2248" id="token-22-51" morph="none" pos="word" start_char="2239">Technology</TOKEN>
<TOKEN end_char="2249" id="token-22-52" morph="none" pos="punct" start_char="2249">.</TOKEN>
</SEG>
<SEG end_char="2370" id="segment-23" start_char="2251">
<ORIGINAL_TEXT>The complaint alleges that Dr. Lieber worked with the University for significant periods between at least 2012 and 2017.</ORIGINAL_TEXT>
<TOKEN end_char="2253" id="token-23-0" morph="none" pos="word" start_char="2251">The</TOKEN>
<TOKEN end_char="2263" id="token-23-1" morph="none" pos="word" start_char="2255">complaint</TOKEN>
<TOKEN end_char="2271" id="token-23-2" morph="none" pos="word" start_char="2265">alleges</TOKEN>
<TOKEN end_char="2276" id="token-23-3" morph="none" pos="word" start_char="2273">that</TOKEN>
<TOKEN end_char="2279" id="token-23-4" morph="none" pos="word" start_char="2278">Dr</TOKEN>
<TOKEN end_char="2280" id="token-23-5" morph="none" pos="punct" start_char="2280">.</TOKEN>
<TOKEN end_char="2287" id="token-23-6" morph="none" pos="word" start_char="2282">Lieber</TOKEN>
<TOKEN end_char="2294" id="token-23-7" morph="none" pos="word" start_char="2289">worked</TOKEN>
<TOKEN end_char="2299" id="token-23-8" morph="none" pos="word" start_char="2296">with</TOKEN>
<TOKEN end_char="2303" id="token-23-9" morph="none" pos="word" start_char="2301">the</TOKEN>
<TOKEN end_char="2314" id="token-23-10" morph="none" pos="word" start_char="2305">University</TOKEN>
<TOKEN end_char="2318" id="token-23-11" morph="none" pos="word" start_char="2316">for</TOKEN>
<TOKEN end_char="2330" id="token-23-12" morph="none" pos="word" start_char="2320">significant</TOKEN>
<TOKEN end_char="2338" id="token-23-13" morph="none" pos="word" start_char="2332">periods</TOKEN>
<TOKEN end_char="2346" id="token-23-14" morph="none" pos="word" start_char="2340">between</TOKEN>
<TOKEN end_char="2349" id="token-23-15" morph="none" pos="word" start_char="2348">at</TOKEN>
<TOKEN end_char="2355" id="token-23-16" morph="none" pos="word" start_char="2351">least</TOKEN>
<TOKEN end_char="2360" id="token-23-17" morph="none" pos="word" start_char="2357">2012</TOKEN>
<TOKEN end_char="2364" id="token-23-18" morph="none" pos="word" start_char="2362">and</TOKEN>
<TOKEN end_char="2369" id="token-23-19" morph="none" pos="word" start_char="2366">2017</TOKEN>
<TOKEN end_char="2370" id="token-23-20" morph="none" pos="punct" start_char="2370">.</TOKEN>
</SEG>
<SEG end_char="2511" id="segment-24" start_char="2373">
<ORIGINAL_TEXT>Federal investigators also determined that Dr. Lieber was awarded more than $1.5 million to establish a nanotechnology research lab at WUT.</ORIGINAL_TEXT>
<TOKEN end_char="2379" id="token-24-0" morph="none" pos="word" start_char="2373">Federal</TOKEN>
<TOKEN end_char="2393" id="token-24-1" morph="none" pos="word" start_char="2381">investigators</TOKEN>
<TOKEN end_char="2398" id="token-24-2" morph="none" pos="word" start_char="2395">also</TOKEN>
<TOKEN end_char="2409" id="token-24-3" morph="none" pos="word" start_char="2400">determined</TOKEN>
<TOKEN end_char="2414" id="token-24-4" morph="none" pos="word" start_char="2411">that</TOKEN>
<TOKEN end_char="2417" id="token-24-5" morph="none" pos="word" start_char="2416">Dr</TOKEN>
<TOKEN end_char="2418" id="token-24-6" morph="none" pos="punct" start_char="2418">.</TOKEN>
<TOKEN end_char="2425" id="token-24-7" morph="none" pos="word" start_char="2420">Lieber</TOKEN>
<TOKEN end_char="2429" id="token-24-8" morph="none" pos="word" start_char="2427">was</TOKEN>
<TOKEN end_char="2437" id="token-24-9" morph="none" pos="word" start_char="2431">awarded</TOKEN>
<TOKEN end_char="2442" id="token-24-10" morph="none" pos="word" start_char="2439">more</TOKEN>
<TOKEN end_char="2447" id="token-24-11" morph="none" pos="word" start_char="2444">than</TOKEN>
<TOKEN end_char="2452" id="token-24-12" morph="none" pos="unknown" start_char="2449">$1.5</TOKEN>
<TOKEN end_char="2460" id="token-24-13" morph="none" pos="word" start_char="2454">million</TOKEN>
<TOKEN end_char="2463" id="token-24-14" morph="none" pos="word" start_char="2462">to</TOKEN>
<TOKEN end_char="2473" id="token-24-15" morph="none" pos="word" start_char="2465">establish</TOKEN>
<TOKEN end_char="2475" id="token-24-16" morph="none" pos="word" start_char="2475">a</TOKEN>
<TOKEN end_char="2490" id="token-24-17" morph="none" pos="word" start_char="2477">nanotechnology</TOKEN>
<TOKEN end_char="2499" id="token-24-18" morph="none" pos="word" start_char="2492">research</TOKEN>
<TOKEN end_char="2503" id="token-24-19" morph="none" pos="word" start_char="2501">lab</TOKEN>
<TOKEN end_char="2506" id="token-24-20" morph="none" pos="word" start_char="2505">at</TOKEN>
<TOKEN end_char="2510" id="token-24-21" morph="none" pos="word" start_char="2508">WUT</TOKEN>
<TOKEN end_char="2511" id="token-24-22" morph="none" pos="punct" start_char="2511">.</TOKEN>
</SEG>
<SEG end_char="2761" id="segment-25" start_char="2514">
<ORIGINAL_TEXT>"China's Thousand Talents Plan, according to the complaint (is) a Chinese government-run program designed to entice scientists and researchers in the United States to share their research expertise with China," Lelling said at that news conference.</ORIGINAL_TEXT>
<TOKEN end_char="2514" id="token-25-0" morph="none" pos="punct" start_char="2514">"</TOKEN>
<TOKEN end_char="2521" id="token-25-1" morph="none" pos="word" start_char="2515">China's</TOKEN>
<TOKEN end_char="2530" id="token-25-2" morph="none" pos="word" start_char="2523">Thousand</TOKEN>
<TOKEN end_char="2538" id="token-25-3" morph="none" pos="word" start_char="2532">Talents</TOKEN>
<TOKEN end_char="2543" id="token-25-4" morph="none" pos="word" start_char="2540">Plan</TOKEN>
<TOKEN end_char="2544" id="token-25-5" morph="none" pos="punct" start_char="2544">,</TOKEN>
<TOKEN end_char="2554" id="token-25-6" morph="none" pos="word" start_char="2546">according</TOKEN>
<TOKEN end_char="2557" id="token-25-7" morph="none" pos="word" start_char="2556">to</TOKEN>
<TOKEN end_char="2561" id="token-25-8" morph="none" pos="word" start_char="2559">the</TOKEN>
<TOKEN end_char="2571" id="token-25-9" morph="none" pos="word" start_char="2563">complaint</TOKEN>
<TOKEN end_char="2573" id="token-25-10" morph="none" pos="punct" start_char="2573">(</TOKEN>
<TOKEN end_char="2575" id="token-25-11" morph="none" pos="word" start_char="2574">is</TOKEN>
<TOKEN end_char="2576" id="token-25-12" morph="none" pos="punct" start_char="2576">)</TOKEN>
<TOKEN end_char="2578" id="token-25-13" morph="none" pos="word" start_char="2578">a</TOKEN>
<TOKEN end_char="2586" id="token-25-14" morph="none" pos="word" start_char="2580">Chinese</TOKEN>
<TOKEN end_char="2601" id="token-25-15" morph="none" pos="unknown" start_char="2588">government-run</TOKEN>
<TOKEN end_char="2609" id="token-25-16" morph="none" pos="word" start_char="2603">program</TOKEN>
<TOKEN end_char="2618" id="token-25-17" morph="none" pos="word" start_char="2611">designed</TOKEN>
<TOKEN end_char="2621" id="token-25-18" morph="none" pos="word" start_char="2620">to</TOKEN>
<TOKEN end_char="2628" id="token-25-19" morph="none" pos="word" start_char="2623">entice</TOKEN>
<TOKEN end_char="2639" id="token-25-20" morph="none" pos="word" start_char="2630">scientists</TOKEN>
<TOKEN end_char="2643" id="token-25-21" morph="none" pos="word" start_char="2641">and</TOKEN>
<TOKEN end_char="2655" id="token-25-22" morph="none" pos="word" start_char="2645">researchers</TOKEN>
<TOKEN end_char="2658" id="token-25-23" morph="none" pos="word" start_char="2657">in</TOKEN>
<TOKEN end_char="2662" id="token-25-24" morph="none" pos="word" start_char="2660">the</TOKEN>
<TOKEN end_char="2669" id="token-25-25" morph="none" pos="word" start_char="2664">United</TOKEN>
<TOKEN end_char="2676" id="token-25-26" morph="none" pos="word" start_char="2671">States</TOKEN>
<TOKEN end_char="2679" id="token-25-27" morph="none" pos="word" start_char="2678">to</TOKEN>
<TOKEN end_char="2685" id="token-25-28" morph="none" pos="word" start_char="2681">share</TOKEN>
<TOKEN end_char="2691" id="token-25-29" morph="none" pos="word" start_char="2687">their</TOKEN>
<TOKEN end_char="2700" id="token-25-30" morph="none" pos="word" start_char="2693">research</TOKEN>
<TOKEN end_char="2710" id="token-25-31" morph="none" pos="word" start_char="2702">expertise</TOKEN>
<TOKEN end_char="2715" id="token-25-32" morph="none" pos="word" start_char="2712">with</TOKEN>
<TOKEN end_char="2721" id="token-25-33" morph="none" pos="word" start_char="2717">China</TOKEN>
<TOKEN end_char="2723" id="token-25-34" morph="none" pos="punct" start_char="2722">,"</TOKEN>
<TOKEN end_char="2731" id="token-25-35" morph="none" pos="word" start_char="2725">Lelling</TOKEN>
<TOKEN end_char="2736" id="token-25-36" morph="none" pos="word" start_char="2733">said</TOKEN>
<TOKEN end_char="2739" id="token-25-37" morph="none" pos="word" start_char="2738">at</TOKEN>
<TOKEN end_char="2744" id="token-25-38" morph="none" pos="word" start_char="2741">that</TOKEN>
<TOKEN end_char="2749" id="token-25-39" morph="none" pos="word" start_char="2746">news</TOKEN>
<TOKEN end_char="2760" id="token-25-40" morph="none" pos="word" start_char="2751">conference</TOKEN>
<TOKEN end_char="2761" id="token-25-41" morph="none" pos="punct" start_char="2761">.</TOKEN>
</SEG>
<SEG end_char="2974" id="segment-26" start_char="2764">
<ORIGINAL_TEXT>According to the criminal complaint, "On April 24, 2018, DoD investigators interviewed Dr. Lieber about his active grants and whether Dr. Lieber had appropriately disclosed foreign research collaboration to DoD.</ORIGINAL_TEXT>
<TOKEN end_char="2772" id="token-26-0" morph="none" pos="word" start_char="2764">According</TOKEN>
<TOKEN end_char="2775" id="token-26-1" morph="none" pos="word" start_char="2774">to</TOKEN>
<TOKEN end_char="2779" id="token-26-2" morph="none" pos="word" start_char="2777">the</TOKEN>
<TOKEN end_char="2788" id="token-26-3" morph="none" pos="word" start_char="2781">criminal</TOKEN>
<TOKEN end_char="2798" id="token-26-4" morph="none" pos="word" start_char="2790">complaint</TOKEN>
<TOKEN end_char="2799" id="token-26-5" morph="none" pos="punct" start_char="2799">,</TOKEN>
<TOKEN end_char="2801" id="token-26-6" morph="none" pos="punct" start_char="2801">"</TOKEN>
<TOKEN end_char="2803" id="token-26-7" morph="none" pos="word" start_char="2802">On</TOKEN>
<TOKEN end_char="2809" id="token-26-8" morph="none" pos="word" start_char="2805">April</TOKEN>
<TOKEN end_char="2812" id="token-26-9" morph="none" pos="word" start_char="2811">24</TOKEN>
<TOKEN end_char="2813" id="token-26-10" morph="none" pos="punct" start_char="2813">,</TOKEN>
<TOKEN end_char="2818" id="token-26-11" morph="none" pos="word" start_char="2815">2018</TOKEN>
<TOKEN end_char="2819" id="token-26-12" morph="none" pos="punct" start_char="2819">,</TOKEN>
<TOKEN end_char="2823" id="token-26-13" morph="none" pos="word" start_char="2821">DoD</TOKEN>
<TOKEN end_char="2837" id="token-26-14" morph="none" pos="word" start_char="2825">investigators</TOKEN>
<TOKEN end_char="2849" id="token-26-15" morph="none" pos="word" start_char="2839">interviewed</TOKEN>
<TOKEN end_char="2852" id="token-26-16" morph="none" pos="word" start_char="2851">Dr</TOKEN>
<TOKEN end_char="2853" id="token-26-17" morph="none" pos="punct" start_char="2853">.</TOKEN>
<TOKEN end_char="2860" id="token-26-18" morph="none" pos="word" start_char="2855">Lieber</TOKEN>
<TOKEN end_char="2866" id="token-26-19" morph="none" pos="word" start_char="2862">about</TOKEN>
<TOKEN end_char="2870" id="token-26-20" morph="none" pos="word" start_char="2868">his</TOKEN>
<TOKEN end_char="2877" id="token-26-21" morph="none" pos="word" start_char="2872">active</TOKEN>
<TOKEN end_char="2884" id="token-26-22" morph="none" pos="word" start_char="2879">grants</TOKEN>
<TOKEN end_char="2888" id="token-26-23" morph="none" pos="word" start_char="2886">and</TOKEN>
<TOKEN end_char="2896" id="token-26-24" morph="none" pos="word" start_char="2890">whether</TOKEN>
<TOKEN end_char="2899" id="token-26-25" morph="none" pos="word" start_char="2898">Dr</TOKEN>
<TOKEN end_char="2900" id="token-26-26" morph="none" pos="punct" start_char="2900">.</TOKEN>
<TOKEN end_char="2907" id="token-26-27" morph="none" pos="word" start_char="2902">Lieber</TOKEN>
<TOKEN end_char="2911" id="token-26-28" morph="none" pos="word" start_char="2909">had</TOKEN>
<TOKEN end_char="2925" id="token-26-29" morph="none" pos="word" start_char="2913">appropriately</TOKEN>
<TOKEN end_char="2935" id="token-26-30" morph="none" pos="word" start_char="2927">disclosed</TOKEN>
<TOKEN end_char="2943" id="token-26-31" morph="none" pos="word" start_char="2937">foreign</TOKEN>
<TOKEN end_char="2952" id="token-26-32" morph="none" pos="word" start_char="2945">research</TOKEN>
<TOKEN end_char="2966" id="token-26-33" morph="none" pos="word" start_char="2954">collaboration</TOKEN>
<TOKEN end_char="2969" id="token-26-34" morph="none" pos="word" start_char="2968">to</TOKEN>
<TOKEN end_char="2973" id="token-26-35" morph="none" pos="word" start_char="2971">DoD</TOKEN>
<TOKEN end_char="2974" id="token-26-36" morph="none" pos="punct" start_char="2974">.</TOKEN>
</SEG>
<SEG end_char="3136" id="segment-27" start_char="2976">
<ORIGINAL_TEXT>During the interview … Dr. Lieber said that he was familiar with China's Thousand Talent's Plan, but that he had never been asked to participate in the program."</ORIGINAL_TEXT>
<TOKEN end_char="2981" id="token-27-0" morph="none" pos="word" start_char="2976">During</TOKEN>
<TOKEN end_char="2985" id="token-27-1" morph="none" pos="word" start_char="2983">the</TOKEN>
<TOKEN end_char="2995" id="token-27-2" morph="none" pos="word" start_char="2987">interview</TOKEN>
<TOKEN end_char="2997" id="token-27-3" morph="none" pos="punct" start_char="2997">…</TOKEN>
<TOKEN end_char="3000" id="token-27-4" morph="none" pos="word" start_char="2999">Dr</TOKEN>
<TOKEN end_char="3001" id="token-27-5" morph="none" pos="punct" start_char="3001">.</TOKEN>
<TOKEN end_char="3008" id="token-27-6" morph="none" pos="word" start_char="3003">Lieber</TOKEN>
<TOKEN end_char="3013" id="token-27-7" morph="none" pos="word" start_char="3010">said</TOKEN>
<TOKEN end_char="3018" id="token-27-8" morph="none" pos="word" start_char="3015">that</TOKEN>
<TOKEN end_char="3021" id="token-27-9" morph="none" pos="word" start_char="3020">he</TOKEN>
<TOKEN end_char="3025" id="token-27-10" morph="none" pos="word" start_char="3023">was</TOKEN>
<TOKEN end_char="3034" id="token-27-11" morph="none" pos="word" start_char="3027">familiar</TOKEN>
<TOKEN end_char="3039" id="token-27-12" morph="none" pos="word" start_char="3036">with</TOKEN>
<TOKEN end_char="3047" id="token-27-13" morph="none" pos="word" start_char="3041">China's</TOKEN>
<TOKEN end_char="3056" id="token-27-14" morph="none" pos="word" start_char="3049">Thousand</TOKEN>
<TOKEN end_char="3065" id="token-27-15" morph="none" pos="word" start_char="3058">Talent's</TOKEN>
<TOKEN end_char="3070" id="token-27-16" morph="none" pos="word" start_char="3067">Plan</TOKEN>
<TOKEN end_char="3071" id="token-27-17" morph="none" pos="punct" start_char="3071">,</TOKEN>
<TOKEN end_char="3075" id="token-27-18" morph="none" pos="word" start_char="3073">but</TOKEN>
<TOKEN end_char="3080" id="token-27-19" morph="none" pos="word" start_char="3077">that</TOKEN>
<TOKEN end_char="3083" id="token-27-20" morph="none" pos="word" start_char="3082">he</TOKEN>
<TOKEN end_char="3087" id="token-27-21" morph="none" pos="word" start_char="3085">had</TOKEN>
<TOKEN end_char="3093" id="token-27-22" morph="none" pos="word" start_char="3089">never</TOKEN>
<TOKEN end_char="3098" id="token-27-23" morph="none" pos="word" start_char="3095">been</TOKEN>
<TOKEN end_char="3104" id="token-27-24" morph="none" pos="word" start_char="3100">asked</TOKEN>
<TOKEN end_char="3107" id="token-27-25" morph="none" pos="word" start_char="3106">to</TOKEN>
<TOKEN end_char="3119" id="token-27-26" morph="none" pos="word" start_char="3109">participate</TOKEN>
<TOKEN end_char="3122" id="token-27-27" morph="none" pos="word" start_char="3121">in</TOKEN>
<TOKEN end_char="3126" id="token-27-28" morph="none" pos="word" start_char="3124">the</TOKEN>
<TOKEN end_char="3134" id="token-27-29" morph="none" pos="word" start_char="3128">program</TOKEN>
<TOKEN end_char="3136" id="token-27-30" morph="none" pos="punct" start_char="3135">."</TOKEN>
</SEG>
<SEG end_char="3344" id="segment-28" start_char="3139">
<ORIGINAL_TEXT>Prosecutors allege that Dr. Lieber also lied to Harvard about his foreign ties, which "caused Harvard to tell NIH that Dr. Lieber ‘is not and has never been a participant in’ China's Thousand Talents Plan."</ORIGINAL_TEXT>
<TOKEN end_char="3149" id="token-28-0" morph="none" pos="word" start_char="3139">Prosecutors</TOKEN>
<TOKEN end_char="3156" id="token-28-1" morph="none" pos="word" start_char="3151">allege</TOKEN>
<TOKEN end_char="3161" id="token-28-2" morph="none" pos="word" start_char="3158">that</TOKEN>
<TOKEN end_char="3164" id="token-28-3" morph="none" pos="word" start_char="3163">Dr</TOKEN>
<TOKEN end_char="3165" id="token-28-4" morph="none" pos="punct" start_char="3165">.</TOKEN>
<TOKEN end_char="3172" id="token-28-5" morph="none" pos="word" start_char="3167">Lieber</TOKEN>
<TOKEN end_char="3177" id="token-28-6" morph="none" pos="word" start_char="3174">also</TOKEN>
<TOKEN end_char="3182" id="token-28-7" morph="none" pos="word" start_char="3179">lied</TOKEN>
<TOKEN end_char="3185" id="token-28-8" morph="none" pos="word" start_char="3184">to</TOKEN>
<TOKEN end_char="3193" id="token-28-9" morph="none" pos="word" start_char="3187">Harvard</TOKEN>
<TOKEN end_char="3199" id="token-28-10" morph="none" pos="word" start_char="3195">about</TOKEN>
<TOKEN end_char="3203" id="token-28-11" morph="none" pos="word" start_char="3201">his</TOKEN>
<TOKEN end_char="3211" id="token-28-12" morph="none" pos="word" start_char="3205">foreign</TOKEN>
<TOKEN end_char="3216" id="token-28-13" morph="none" pos="word" start_char="3213">ties</TOKEN>
<TOKEN end_char="3217" id="token-28-14" morph="none" pos="punct" start_char="3217">,</TOKEN>
<TOKEN end_char="3223" id="token-28-15" morph="none" pos="word" start_char="3219">which</TOKEN>
<TOKEN end_char="3225" id="token-28-16" morph="none" pos="punct" start_char="3225">"</TOKEN>
<TOKEN end_char="3231" id="token-28-17" morph="none" pos="word" start_char="3226">caused</TOKEN>
<TOKEN end_char="3239" id="token-28-18" morph="none" pos="word" start_char="3233">Harvard</TOKEN>
<TOKEN end_char="3242" id="token-28-19" morph="none" pos="word" start_char="3241">to</TOKEN>
<TOKEN end_char="3247" id="token-28-20" morph="none" pos="word" start_char="3244">tell</TOKEN>
<TOKEN end_char="3251" id="token-28-21" morph="none" pos="word" start_char="3249">NIH</TOKEN>
<TOKEN end_char="3256" id="token-28-22" morph="none" pos="word" start_char="3253">that</TOKEN>
<TOKEN end_char="3259" id="token-28-23" morph="none" pos="word" start_char="3258">Dr</TOKEN>
<TOKEN end_char="3260" id="token-28-24" morph="none" pos="punct" start_char="3260">.</TOKEN>
<TOKEN end_char="3267" id="token-28-25" morph="none" pos="word" start_char="3262">Lieber</TOKEN>
<TOKEN end_char="3269" id="token-28-26" morph="none" pos="punct" start_char="3269">‘</TOKEN>
<TOKEN end_char="3271" id="token-28-27" morph="none" pos="word" start_char="3270">is</TOKEN>
<TOKEN end_char="3275" id="token-28-28" morph="none" pos="word" start_char="3273">not</TOKEN>
<TOKEN end_char="3279" id="token-28-29" morph="none" pos="word" start_char="3277">and</TOKEN>
<TOKEN end_char="3283" id="token-28-30" morph="none" pos="word" start_char="3281">has</TOKEN>
<TOKEN end_char="3289" id="token-28-31" morph="none" pos="word" start_char="3285">never</TOKEN>
<TOKEN end_char="3294" id="token-28-32" morph="none" pos="word" start_char="3291">been</TOKEN>
<TOKEN end_char="3296" id="token-28-33" morph="none" pos="word" start_char="3296">a</TOKEN>
<TOKEN end_char="3308" id="token-28-34" morph="none" pos="word" start_char="3298">participant</TOKEN>
<TOKEN end_char="3311" id="token-28-35" morph="none" pos="word" start_char="3310">in</TOKEN>
<TOKEN end_char="3312" id="token-28-36" morph="none" pos="punct" start_char="3312">’</TOKEN>
<TOKEN end_char="3320" id="token-28-37" morph="none" pos="word" start_char="3314">China's</TOKEN>
<TOKEN end_char="3329" id="token-28-38" morph="none" pos="word" start_char="3322">Thousand</TOKEN>
<TOKEN end_char="3337" id="token-28-39" morph="none" pos="word" start_char="3331">Talents</TOKEN>
<TOKEN end_char="3342" id="token-28-40" morph="none" pos="word" start_char="3339">Plan</TOKEN>
<TOKEN end_char="3344" id="token-28-41" morph="none" pos="punct" start_char="3343">."</TOKEN>
</SEG>
<SEG end_char="3489" id="segment-29" start_char="3347">
<ORIGINAL_TEXT>Prosecutors and investigators did not allege at any point that Dr. Lieber engineered any virus, and they never tied him in any way to COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="3357" id="token-29-0" morph="none" pos="word" start_char="3347">Prosecutors</TOKEN>
<TOKEN end_char="3361" id="token-29-1" morph="none" pos="word" start_char="3359">and</TOKEN>
<TOKEN end_char="3375" id="token-29-2" morph="none" pos="word" start_char="3363">investigators</TOKEN>
<TOKEN end_char="3379" id="token-29-3" morph="none" pos="word" start_char="3377">did</TOKEN>
<TOKEN end_char="3383" id="token-29-4" morph="none" pos="word" start_char="3381">not</TOKEN>
<TOKEN end_char="3390" id="token-29-5" morph="none" pos="word" start_char="3385">allege</TOKEN>
<TOKEN end_char="3393" id="token-29-6" morph="none" pos="word" start_char="3392">at</TOKEN>
<TOKEN end_char="3397" id="token-29-7" morph="none" pos="word" start_char="3395">any</TOKEN>
<TOKEN end_char="3403" id="token-29-8" morph="none" pos="word" start_char="3399">point</TOKEN>
<TOKEN end_char="3408" id="token-29-9" morph="none" pos="word" start_char="3405">that</TOKEN>
<TOKEN end_char="3411" id="token-29-10" morph="none" pos="word" start_char="3410">Dr</TOKEN>
<TOKEN end_char="3412" id="token-29-11" morph="none" pos="punct" start_char="3412">.</TOKEN>
<TOKEN end_char="3419" id="token-29-12" morph="none" pos="word" start_char="3414">Lieber</TOKEN>
<TOKEN end_char="3430" id="token-29-13" morph="none" pos="word" start_char="3421">engineered</TOKEN>
<TOKEN end_char="3434" id="token-29-14" morph="none" pos="word" start_char="3432">any</TOKEN>
<TOKEN end_char="3440" id="token-29-15" morph="none" pos="word" start_char="3436">virus</TOKEN>
<TOKEN end_char="3441" id="token-29-16" morph="none" pos="punct" start_char="3441">,</TOKEN>
<TOKEN end_char="3445" id="token-29-17" morph="none" pos="word" start_char="3443">and</TOKEN>
<TOKEN end_char="3450" id="token-29-18" morph="none" pos="word" start_char="3447">they</TOKEN>
<TOKEN end_char="3456" id="token-29-19" morph="none" pos="word" start_char="3452">never</TOKEN>
<TOKEN end_char="3461" id="token-29-20" morph="none" pos="word" start_char="3458">tied</TOKEN>
<TOKEN end_char="3465" id="token-29-21" morph="none" pos="word" start_char="3463">him</TOKEN>
<TOKEN end_char="3468" id="token-29-22" morph="none" pos="word" start_char="3467">in</TOKEN>
<TOKEN end_char="3472" id="token-29-23" morph="none" pos="word" start_char="3470">any</TOKEN>
<TOKEN end_char="3476" id="token-29-24" morph="none" pos="word" start_char="3474">way</TOKEN>
<TOKEN end_char="3479" id="token-29-25" morph="none" pos="word" start_char="3478">to</TOKEN>
<TOKEN end_char="3488" id="token-29-26" morph="none" pos="unknown" start_char="3481">COVID-19</TOKEN>
<TOKEN end_char="3489" id="token-29-27" morph="none" pos="punct" start_char="3489">.</TOKEN>
</SEG>
<SEG end_char="3633" id="segment-30" start_char="3492">
<ORIGINAL_TEXT>Further, many of the false headlines and misleading social media posts are suggesting that Dr. Lieber was "just arrested" or "arrested today."</ORIGINAL_TEXT>
<TOKEN end_char="3498" id="token-30-0" morph="none" pos="word" start_char="3492">Further</TOKEN>
<TOKEN end_char="3499" id="token-30-1" morph="none" pos="punct" start_char="3499">,</TOKEN>
<TOKEN end_char="3504" id="token-30-2" morph="none" pos="word" start_char="3501">many</TOKEN>
<TOKEN end_char="3507" id="token-30-3" morph="none" pos="word" start_char="3506">of</TOKEN>
<TOKEN end_char="3511" id="token-30-4" morph="none" pos="word" start_char="3509">the</TOKEN>
<TOKEN end_char="3517" id="token-30-5" morph="none" pos="word" start_char="3513">false</TOKEN>
<TOKEN end_char="3527" id="token-30-6" morph="none" pos="word" start_char="3519">headlines</TOKEN>
<TOKEN end_char="3531" id="token-30-7" morph="none" pos="word" start_char="3529">and</TOKEN>
<TOKEN end_char="3542" id="token-30-8" morph="none" pos="word" start_char="3533">misleading</TOKEN>
<TOKEN end_char="3549" id="token-30-9" morph="none" pos="word" start_char="3544">social</TOKEN>
<TOKEN end_char="3555" id="token-30-10" morph="none" pos="word" start_char="3551">media</TOKEN>
<TOKEN end_char="3561" id="token-30-11" morph="none" pos="word" start_char="3557">posts</TOKEN>
<TOKEN end_char="3565" id="token-30-12" morph="none" pos="word" start_char="3563">are</TOKEN>
<TOKEN end_char="3576" id="token-30-13" morph="none" pos="word" start_char="3567">suggesting</TOKEN>
<TOKEN end_char="3581" id="token-30-14" morph="none" pos="word" start_char="3578">that</TOKEN>
<TOKEN end_char="3584" id="token-30-15" morph="none" pos="word" start_char="3583">Dr</TOKEN>
<TOKEN end_char="3585" id="token-30-16" morph="none" pos="punct" start_char="3585">.</TOKEN>
<TOKEN end_char="3592" id="token-30-17" morph="none" pos="word" start_char="3587">Lieber</TOKEN>
<TOKEN end_char="3596" id="token-30-18" morph="none" pos="word" start_char="3594">was</TOKEN>
<TOKEN end_char="3598" id="token-30-19" morph="none" pos="punct" start_char="3598">"</TOKEN>
<TOKEN end_char="3602" id="token-30-20" morph="none" pos="word" start_char="3599">just</TOKEN>
<TOKEN end_char="3611" id="token-30-21" morph="none" pos="word" start_char="3604">arrested</TOKEN>
<TOKEN end_char="3612" id="token-30-22" morph="none" pos="punct" start_char="3612">"</TOKEN>
<TOKEN end_char="3615" id="token-30-23" morph="none" pos="word" start_char="3614">or</TOKEN>
<TOKEN end_char="3617" id="token-30-24" morph="none" pos="punct" start_char="3617">"</TOKEN>
<TOKEN end_char="3625" id="token-30-25" morph="none" pos="word" start_char="3618">arrested</TOKEN>
<TOKEN end_char="3631" id="token-30-26" morph="none" pos="word" start_char="3627">today</TOKEN>
<TOKEN end_char="3633" id="token-30-27" morph="none" pos="punct" start_char="3632">."</TOKEN>
</SEG>
<SEG end_char="3696" id="segment-31" start_char="3635">
<ORIGINAL_TEXT>Dr. Lieber was arrested and arraigned in federal court on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="3636" id="token-31-0" morph="none" pos="word" start_char="3635">Dr</TOKEN>
<TOKEN end_char="3637" id="token-31-1" morph="none" pos="punct" start_char="3637">.</TOKEN>
<TOKEN end_char="3644" id="token-31-2" morph="none" pos="word" start_char="3639">Lieber</TOKEN>
<TOKEN end_char="3648" id="token-31-3" morph="none" pos="word" start_char="3646">was</TOKEN>
<TOKEN end_char="3657" id="token-31-4" morph="none" pos="word" start_char="3650">arrested</TOKEN>
<TOKEN end_char="3661" id="token-31-5" morph="none" pos="word" start_char="3659">and</TOKEN>
<TOKEN end_char="3671" id="token-31-6" morph="none" pos="word" start_char="3663">arraigned</TOKEN>
<TOKEN end_char="3674" id="token-31-7" morph="none" pos="word" start_char="3673">in</TOKEN>
<TOKEN end_char="3682" id="token-31-8" morph="none" pos="word" start_char="3676">federal</TOKEN>
<TOKEN end_char="3688" id="token-31-9" morph="none" pos="word" start_char="3684">court</TOKEN>
<TOKEN end_char="3691" id="token-31-10" morph="none" pos="word" start_char="3690">on</TOKEN>
<TOKEN end_char="3695" id="token-31-11" morph="none" pos="word" start_char="3693">Jan</TOKEN>
<TOKEN end_char="3696" id="token-31-12" morph="none" pos="punct" start_char="3696">.</TOKEN>
</SEG>
<SEG end_char="3706" id="segment-32" start_char="3698">
<ORIGINAL_TEXT>28, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="3699" id="token-32-0" morph="none" pos="word" start_char="3698">28</TOKEN>
<TOKEN end_char="3700" id="token-32-1" morph="none" pos="punct" start_char="3700">,</TOKEN>
<TOKEN end_char="3705" id="token-32-2" morph="none" pos="word" start_char="3702">2020</TOKEN>
<TOKEN end_char="3706" id="token-32-3" morph="none" pos="punct" start_char="3706">.</TOKEN>
<TRANSLATED_TEXT>28, 2020</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="3734" id="segment-33" start_char="3709">
<ORIGINAL_TEXT>False Claims and The Facts</ORIGINAL_TEXT>
<TOKEN end_char="3713" id="token-33-0" morph="none" pos="word" start_char="3709">False</TOKEN>
<TOKEN end_char="3720" id="token-33-1" morph="none" pos="word" start_char="3715">Claims</TOKEN>
<TOKEN end_char="3724" id="token-33-2" morph="none" pos="word" start_char="3722">and</TOKEN>
<TOKEN end_char="3728" id="token-33-3" morph="none" pos="word" start_char="3726">The</TOKEN>
<TOKEN end_char="3734" id="token-33-4" morph="none" pos="word" start_char="3730">Facts</TOKEN>
</SEG>
<SEG end_char="3828" id="segment-34" start_char="3737">
<ORIGINAL_TEXT>Claim: "America just discovered the man who manufactured and sold the #Coronavirus to China"</ORIGINAL_TEXT>
<TOKEN end_char="3741" id="token-34-0" morph="none" pos="word" start_char="3737">Claim</TOKEN>
<TOKEN end_char="3742" id="token-34-1" morph="none" pos="punct" start_char="3742">:</TOKEN>
<TOKEN end_char="3744" id="token-34-2" morph="none" pos="punct" start_char="3744">"</TOKEN>
<TOKEN end_char="3751" id="token-34-3" morph="none" pos="word" start_char="3745">America</TOKEN>
<TOKEN end_char="3756" id="token-34-4" morph="none" pos="word" start_char="3753">just</TOKEN>
<TOKEN end_char="3767" id="token-34-5" morph="none" pos="word" start_char="3758">discovered</TOKEN>
<TOKEN end_char="3771" id="token-34-6" morph="none" pos="word" start_char="3769">the</TOKEN>
<TOKEN end_char="3775" id="token-34-7" morph="none" pos="word" start_char="3773">man</TOKEN>
<TOKEN end_char="3779" id="token-34-8" morph="none" pos="word" start_char="3777">who</TOKEN>
<TOKEN end_char="3792" id="token-34-9" morph="none" pos="word" start_char="3781">manufactured</TOKEN>
<TOKEN end_char="3796" id="token-34-10" morph="none" pos="word" start_char="3794">and</TOKEN>
<TOKEN end_char="3801" id="token-34-11" morph="none" pos="word" start_char="3798">sold</TOKEN>
<TOKEN end_char="3805" id="token-34-12" morph="none" pos="word" start_char="3803">the</TOKEN>
<TOKEN end_char="3818" id="token-34-13" morph="none" pos="tag" start_char="3807">#Coronavirus</TOKEN>
<TOKEN end_char="3821" id="token-34-14" morph="none" pos="word" start_char="3820">to</TOKEN>
<TOKEN end_char="3827" id="token-34-15" morph="none" pos="word" start_char="3823">China</TOKEN>
<TOKEN end_char="3828" id="token-34-16" morph="none" pos="punct" start_char="3828">"</TOKEN>
</SEG>
<SEG end_char="3860" id="segment-35" start_char="3831">
<ORIGINAL_TEXT>Response: This claim is false.</ORIGINAL_TEXT>
<TOKEN end_char="3838" id="token-35-0" morph="none" pos="word" start_char="3831">Response</TOKEN>
<TOKEN end_char="3839" id="token-35-1" morph="none" pos="punct" start_char="3839">:</TOKEN>
<TOKEN end_char="3844" id="token-35-2" morph="none" pos="word" start_char="3841">This</TOKEN>
<TOKEN end_char="3850" id="token-35-3" morph="none" pos="word" start_char="3846">claim</TOKEN>
<TOKEN end_char="3853" id="token-35-4" morph="none" pos="word" start_char="3852">is</TOKEN>
<TOKEN end_char="3859" id="token-35-5" morph="none" pos="word" start_char="3855">false</TOKEN>
<TOKEN end_char="3860" id="token-35-6" morph="none" pos="punct" start_char="3860">.</TOKEN>
</SEG>
<SEG end_char="3970" id="segment-36" start_char="3862">
<ORIGINAL_TEXT>Prosecutors have never alleged that Dr. Lieber was involved in manufacturing and/or selling a virus to China.</ORIGINAL_TEXT>
<TOKEN end_char="3872" id="token-36-0" morph="none" pos="word" start_char="3862">Prosecutors</TOKEN>
<TOKEN end_char="3877" id="token-36-1" morph="none" pos="word" start_char="3874">have</TOKEN>
<TOKEN end_char="3883" id="token-36-2" morph="none" pos="word" start_char="3879">never</TOKEN>
<TOKEN end_char="3891" id="token-36-3" morph="none" pos="word" start_char="3885">alleged</TOKEN>
<TOKEN end_char="3896" id="token-36-4" morph="none" pos="word" start_char="3893">that</TOKEN>
<TOKEN end_char="3899" id="token-36-5" morph="none" pos="word" start_char="3898">Dr</TOKEN>
<TOKEN end_char="3900" id="token-36-6" morph="none" pos="punct" start_char="3900">.</TOKEN>
<TOKEN end_char="3907" id="token-36-7" morph="none" pos="word" start_char="3902">Lieber</TOKEN>
<TOKEN end_char="3911" id="token-36-8" morph="none" pos="word" start_char="3909">was</TOKEN>
<TOKEN end_char="3920" id="token-36-9" morph="none" pos="word" start_char="3913">involved</TOKEN>
<TOKEN end_char="3923" id="token-36-10" morph="none" pos="word" start_char="3922">in</TOKEN>
<TOKEN end_char="3937" id="token-36-11" morph="none" pos="word" start_char="3925">manufacturing</TOKEN>
<TOKEN end_char="3944" id="token-36-12" morph="none" pos="unknown" start_char="3939">and/or</TOKEN>
<TOKEN end_char="3952" id="token-36-13" morph="none" pos="word" start_char="3946">selling</TOKEN>
<TOKEN end_char="3954" id="token-36-14" morph="none" pos="word" start_char="3954">a</TOKEN>
<TOKEN end_char="3960" id="token-36-15" morph="none" pos="word" start_char="3956">virus</TOKEN>
<TOKEN end_char="3963" id="token-36-16" morph="none" pos="word" start_char="3962">to</TOKEN>
<TOKEN end_char="3969" id="token-36-17" morph="none" pos="word" start_char="3965">China</TOKEN>
<TOKEN end_char="3970" id="token-36-18" morph="none" pos="punct" start_char="3970">.</TOKEN>
</SEG>
<SEG end_char="4007" id="segment-37" start_char="3972">
<ORIGINAL_TEXT>Dr. Lieber was also arrested on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="3973" id="token-37-0" morph="none" pos="word" start_char="3972">Dr</TOKEN>
<TOKEN end_char="3974" id="token-37-1" morph="none" pos="punct" start_char="3974">.</TOKEN>
<TOKEN end_char="3981" id="token-37-2" morph="none" pos="word" start_char="3976">Lieber</TOKEN>
<TOKEN end_char="3985" id="token-37-3" morph="none" pos="word" start_char="3983">was</TOKEN>
<TOKEN end_char="3990" id="token-37-4" morph="none" pos="word" start_char="3987">also</TOKEN>
<TOKEN end_char="3999" id="token-37-5" morph="none" pos="word" start_char="3992">arrested</TOKEN>
<TOKEN end_char="4002" id="token-37-6" morph="none" pos="word" start_char="4001">on</TOKEN>
<TOKEN end_char="4006" id="token-37-7" morph="none" pos="word" start_char="4004">Jan</TOKEN>
<TOKEN end_char="4007" id="token-37-8" morph="none" pos="punct" start_char="4007">.</TOKEN>
</SEG>
<SEG end_char="4017" id="segment-38" start_char="4009">
<ORIGINAL_TEXT>28, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="4010" id="token-38-0" morph="none" pos="word" start_char="4009">28</TOKEN>
<TOKEN end_char="4011" id="token-38-1" morph="none" pos="punct" start_char="4011">,</TOKEN>
<TOKEN end_char="4016" id="token-38-2" morph="none" pos="word" start_char="4013">2020</TOKEN>
<TOKEN end_char="4017" id="token-38-3" morph="none" pos="punct" start_char="4017">.</TOKEN>
<TRANSLATED_TEXT>28, 2020</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="4056" id="segment-39" start_char="4019">
<ORIGINAL_TEXT>Read the full federal court complaint.</ORIGINAL_TEXT>
<TOKEN end_char="4022" id="token-39-0" morph="none" pos="word" start_char="4019">Read</TOKEN>
<TOKEN end_char="4026" id="token-39-1" morph="none" pos="word" start_char="4024">the</TOKEN>
<TOKEN end_char="4031" id="token-39-2" morph="none" pos="word" start_char="4028">full</TOKEN>
<TOKEN end_char="4039" id="token-39-3" morph="none" pos="word" start_char="4033">federal</TOKEN>
<TOKEN end_char="4045" id="token-39-4" morph="none" pos="word" start_char="4041">court</TOKEN>
<TOKEN end_char="4055" id="token-39-5" morph="none" pos="word" start_char="4047">complaint</TOKEN>
<TOKEN end_char="4056" id="token-39-6" morph="none" pos="punct" start_char="4056">.</TOKEN>
</SEG>
<SEG end_char="4141" id="segment-40" start_char="4059">
<ORIGINAL_TEXT>Claim: "What was he doing in ‘Wuhan’ the city where #coronavirus outbreak started?"</ORIGINAL_TEXT>
<TOKEN end_char="4063" id="token-40-0" morph="none" pos="word" start_char="4059">Claim</TOKEN>
<TOKEN end_char="4064" id="token-40-1" morph="none" pos="punct" start_char="4064">:</TOKEN>
<TOKEN end_char="4066" id="token-40-2" morph="none" pos="punct" start_char="4066">"</TOKEN>
<TOKEN end_char="4070" id="token-40-3" morph="none" pos="word" start_char="4067">What</TOKEN>
<TOKEN end_char="4074" id="token-40-4" morph="none" pos="word" start_char="4072">was</TOKEN>
<TOKEN end_char="4077" id="token-40-5" morph="none" pos="word" start_char="4076">he</TOKEN>
<TOKEN end_char="4083" id="token-40-6" morph="none" pos="word" start_char="4079">doing</TOKEN>
<TOKEN end_char="4086" id="token-40-7" morph="none" pos="word" start_char="4085">in</TOKEN>
<TOKEN end_char="4088" id="token-40-8" morph="none" pos="punct" start_char="4088">‘</TOKEN>
<TOKEN end_char="4093" id="token-40-9" morph="none" pos="word" start_char="4089">Wuhan</TOKEN>
<TOKEN end_char="4094" id="token-40-10" morph="none" pos="punct" start_char="4094">’</TOKEN>
<TOKEN end_char="4098" id="token-40-11" morph="none" pos="word" start_char="4096">the</TOKEN>
<TOKEN end_char="4103" id="token-40-12" morph="none" pos="word" start_char="4100">city</TOKEN>
<TOKEN end_char="4109" id="token-40-13" morph="none" pos="word" start_char="4105">where</TOKEN>
<TOKEN end_char="4122" id="token-40-14" morph="none" pos="tag" start_char="4111">#coronavirus</TOKEN>
<TOKEN end_char="4131" id="token-40-15" morph="none" pos="word" start_char="4124">outbreak</TOKEN>
<TOKEN end_char="4139" id="token-40-16" morph="none" pos="word" start_char="4133">started</TOKEN>
<TOKEN end_char="4141" id="token-40-17" morph="none" pos="punct" start_char="4140">?"</TOKEN>
</SEG>
<SEG end_char="4178" id="segment-41" start_char="4144">
<ORIGINAL_TEXT>Response: This claim is misleading.</ORIGINAL_TEXT>
<TOKEN end_char="4151" id="token-41-0" morph="none" pos="word" start_char="4144">Response</TOKEN>
<TOKEN end_char="4152" id="token-41-1" morph="none" pos="punct" start_char="4152">:</TOKEN>
<TOKEN end_char="4157" id="token-41-2" morph="none" pos="word" start_char="4154">This</TOKEN>
<TOKEN end_char="4163" id="token-41-3" morph="none" pos="word" start_char="4159">claim</TOKEN>
<TOKEN end_char="4166" id="token-41-4" morph="none" pos="word" start_char="4165">is</TOKEN>
<TOKEN end_char="4177" id="token-41-5" morph="none" pos="word" start_char="4168">misleading</TOKEN>
<TOKEN end_char="4178" id="token-41-6" morph="none" pos="punct" start_char="4178">.</TOKEN>
</SEG>
<SEG end_char="4299" id="segment-42" start_char="4180">
<ORIGINAL_TEXT>According to federal prosecutors, Dr. Lieber was in Wuhan years before it became the center of the coronavirus outbreak.</ORIGINAL_TEXT>
<TOKEN end_char="4188" id="token-42-0" morph="none" pos="word" start_char="4180">According</TOKEN>
<TOKEN end_char="4191" id="token-42-1" morph="none" pos="word" start_char="4190">to</TOKEN>
<TOKEN end_char="4199" id="token-42-2" morph="none" pos="word" start_char="4193">federal</TOKEN>
<TOKEN end_char="4211" id="token-42-3" morph="none" pos="word" start_char="4201">prosecutors</TOKEN>
<TOKEN end_char="4212" id="token-42-4" morph="none" pos="punct" start_char="4212">,</TOKEN>
<TOKEN end_char="4215" id="token-42-5" morph="none" pos="word" start_char="4214">Dr</TOKEN>
<TOKEN end_char="4216" id="token-42-6" morph="none" pos="punct" start_char="4216">.</TOKEN>
<TOKEN end_char="4223" id="token-42-7" morph="none" pos="word" start_char="4218">Lieber</TOKEN>
<TOKEN end_char="4227" id="token-42-8" morph="none" pos="word" start_char="4225">was</TOKEN>
<TOKEN end_char="4230" id="token-42-9" morph="none" pos="word" start_char="4229">in</TOKEN>
<TOKEN end_char="4236" id="token-42-10" morph="none" pos="word" start_char="4232">Wuhan</TOKEN>
<TOKEN end_char="4242" id="token-42-11" morph="none" pos="word" start_char="4238">years</TOKEN>
<TOKEN end_char="4249" id="token-42-12" morph="none" pos="word" start_char="4244">before</TOKEN>
<TOKEN end_char="4252" id="token-42-13" morph="none" pos="word" start_char="4251">it</TOKEN>
<TOKEN end_char="4259" id="token-42-14" morph="none" pos="word" start_char="4254">became</TOKEN>
<TOKEN end_char="4263" id="token-42-15" morph="none" pos="word" start_char="4261">the</TOKEN>
<TOKEN end_char="4270" id="token-42-16" morph="none" pos="word" start_char="4265">center</TOKEN>
<TOKEN end_char="4273" id="token-42-17" morph="none" pos="word" start_char="4272">of</TOKEN>
<TOKEN end_char="4277" id="token-42-18" morph="none" pos="word" start_char="4275">the</TOKEN>
<TOKEN end_char="4289" id="token-42-19" morph="none" pos="word" start_char="4279">coronavirus</TOKEN>
<TOKEN end_char="4298" id="token-42-20" morph="none" pos="word" start_char="4291">outbreak</TOKEN>
<TOKEN end_char="4299" id="token-42-21" morph="none" pos="punct" start_char="4299">.</TOKEN>
</SEG>
<SEG end_char="4447" id="segment-43" start_char="4301">
<ORIGINAL_TEXT>"Lieber traveled to WUT (Wuhan University of Technology) in mid-November 2011 ostensibly in order to participate in a Nano-Energy Materials Forum."</ORIGINAL_TEXT>
<TOKEN end_char="4301" id="token-43-0" morph="none" pos="punct" start_char="4301">"</TOKEN>
<TOKEN end_char="4307" id="token-43-1" morph="none" pos="word" start_char="4302">Lieber</TOKEN>
<TOKEN end_char="4316" id="token-43-2" morph="none" pos="word" start_char="4309">traveled</TOKEN>
<TOKEN end_char="4319" id="token-43-3" morph="none" pos="word" start_char="4318">to</TOKEN>
<TOKEN end_char="4323" id="token-43-4" morph="none" pos="word" start_char="4321">WUT</TOKEN>
<TOKEN end_char="4325" id="token-43-5" morph="none" pos="punct" start_char="4325">(</TOKEN>
<TOKEN end_char="4330" id="token-43-6" morph="none" pos="word" start_char="4326">Wuhan</TOKEN>
<TOKEN end_char="4341" id="token-43-7" morph="none" pos="word" start_char="4332">University</TOKEN>
<TOKEN end_char="4344" id="token-43-8" morph="none" pos="word" start_char="4343">of</TOKEN>
<TOKEN end_char="4355" id="token-43-9" morph="none" pos="word" start_char="4346">Technology</TOKEN>
<TOKEN end_char="4356" id="token-43-10" morph="none" pos="punct" start_char="4356">)</TOKEN>
<TOKEN end_char="4359" id="token-43-11" morph="none" pos="word" start_char="4358">in</TOKEN>
<TOKEN end_char="4372" id="token-43-12" morph="none" pos="unknown" start_char="4361">mid-November</TOKEN>
<TOKEN end_char="4377" id="token-43-13" morph="none" pos="word" start_char="4374">2011</TOKEN>
<TOKEN end_char="4388" id="token-43-14" morph="none" pos="word" start_char="4379">ostensibly</TOKEN>
<TOKEN end_char="4391" id="token-43-15" morph="none" pos="word" start_char="4390">in</TOKEN>
<TOKEN end_char="4397" id="token-43-16" morph="none" pos="word" start_char="4393">order</TOKEN>
<TOKEN end_char="4400" id="token-43-17" morph="none" pos="word" start_char="4399">to</TOKEN>
<TOKEN end_char="4412" id="token-43-18" morph="none" pos="word" start_char="4402">participate</TOKEN>
<TOKEN end_char="4415" id="token-43-19" morph="none" pos="word" start_char="4414">in</TOKEN>
<TOKEN end_char="4417" id="token-43-20" morph="none" pos="word" start_char="4417">a</TOKEN>
<TOKEN end_char="4429" id="token-43-21" morph="none" pos="unknown" start_char="4419">Nano-Energy</TOKEN>
<TOKEN end_char="4439" id="token-43-22" morph="none" pos="word" start_char="4431">Materials</TOKEN>
<TOKEN end_char="4445" id="token-43-23" morph="none" pos="word" start_char="4441">Forum</TOKEN>
<TOKEN end_char="4447" id="token-43-24" morph="none" pos="punct" start_char="4446">."</TOKEN>
</SEG>
<SEG end_char="4522" id="segment-44" start_char="4449">
<ORIGINAL_TEXT>"Lieber returned to Massachusetts from WUT on or about November 16, 2011."</ORIGINAL_TEXT>
<TOKEN end_char="4449" id="token-44-0" morph="none" pos="punct" start_char="4449">"</TOKEN>
<TOKEN end_char="4455" id="token-44-1" morph="none" pos="word" start_char="4450">Lieber</TOKEN>
<TOKEN end_char="4464" id="token-44-2" morph="none" pos="word" start_char="4457">returned</TOKEN>
<TOKEN end_char="4467" id="token-44-3" morph="none" pos="word" start_char="4466">to</TOKEN>
<TOKEN end_char="4481" id="token-44-4" morph="none" pos="word" start_char="4469">Massachusetts</TOKEN>
<TOKEN end_char="4486" id="token-44-5" morph="none" pos="word" start_char="4483">from</TOKEN>
<TOKEN end_char="4490" id="token-44-6" morph="none" pos="word" start_char="4488">WUT</TOKEN>
<TOKEN end_char="4493" id="token-44-7" morph="none" pos="word" start_char="4492">on</TOKEN>
<TOKEN end_char="4496" id="token-44-8" morph="none" pos="word" start_char="4495">or</TOKEN>
<TOKEN end_char="4502" id="token-44-9" morph="none" pos="word" start_char="4498">about</TOKEN>
<TOKEN end_char="4511" id="token-44-10" morph="none" pos="word" start_char="4504">November</TOKEN>
<TOKEN end_char="4514" id="token-44-11" morph="none" pos="word" start_char="4513">16</TOKEN>
<TOKEN end_char="4515" id="token-44-12" morph="none" pos="punct" start_char="4515">,</TOKEN>
<TOKEN end_char="4520" id="token-44-13" morph="none" pos="word" start_char="4517">2011</TOKEN>
<TOKEN end_char="4522" id="token-44-14" morph="none" pos="punct" start_char="4521">."</TOKEN>
</SEG>
<SEG end_char="4591" id="segment-45" start_char="4524">
<ORIGINAL_TEXT>Prosecutors do not detail any further travel to Wuhan by Dr. Lieber.</ORIGINAL_TEXT>
<TOKEN end_char="4534" id="token-45-0" morph="none" pos="word" start_char="4524">Prosecutors</TOKEN>
<TOKEN end_char="4537" id="token-45-1" morph="none" pos="word" start_char="4536">do</TOKEN>
<TOKEN end_char="4541" id="token-45-2" morph="none" pos="word" start_char="4539">not</TOKEN>
<TOKEN end_char="4548" id="token-45-3" morph="none" pos="word" start_char="4543">detail</TOKEN>
<TOKEN end_char="4552" id="token-45-4" morph="none" pos="word" start_char="4550">any</TOKEN>
<TOKEN end_char="4560" id="token-45-5" morph="none" pos="word" start_char="4554">further</TOKEN>
<TOKEN end_char="4567" id="token-45-6" morph="none" pos="word" start_char="4562">travel</TOKEN>
<TOKEN end_char="4570" id="token-45-7" morph="none" pos="word" start_char="4569">to</TOKEN>
<TOKEN end_char="4576" id="token-45-8" morph="none" pos="word" start_char="4572">Wuhan</TOKEN>
<TOKEN end_char="4579" id="token-45-9" morph="none" pos="word" start_char="4578">by</TOKEN>
<TOKEN end_char="4582" id="token-45-10" morph="none" pos="word" start_char="4581">Dr</TOKEN>
<TOKEN end_char="4583" id="token-45-11" morph="none" pos="punct" start_char="4583">.</TOKEN>
<TOKEN end_char="4590" id="token-45-12" morph="none" pos="word" start_char="4585">Lieber</TOKEN>
<TOKEN end_char="4591" id="token-45-13" morph="none" pos="punct" start_char="4591">.</TOKEN>
</SEG>
<SEG end_char="4709" id="segment-46" start_char="4594">
<ORIGINAL_TEXT>Claim: "USA says man who manufactured and sold the coronavirus to #China…was just arrested today" (Tweet on April 4)</ORIGINAL_TEXT>
<TOKEN end_char="4598" id="token-46-0" morph="none" pos="word" start_char="4594">Claim</TOKEN>
<TOKEN end_char="4599" id="token-46-1" morph="none" pos="punct" start_char="4599">:</TOKEN>
<TOKEN end_char="4601" id="token-46-2" morph="none" pos="punct" start_char="4601">"</TOKEN>
<TOKEN end_char="4604" id="token-46-3" morph="none" pos="word" start_char="4602">USA</TOKEN>
<TOKEN end_char="4609" id="token-46-4" morph="none" pos="word" start_char="4606">says</TOKEN>
<TOKEN end_char="4613" id="token-46-5" morph="none" pos="word" start_char="4611">man</TOKEN>
<TOKEN end_char="4617" id="token-46-6" morph="none" pos="word" start_char="4615">who</TOKEN>
<TOKEN end_char="4630" id="token-46-7" morph="none" pos="word" start_char="4619">manufactured</TOKEN>
<TOKEN end_char="4634" id="token-46-8" morph="none" pos="word" start_char="4632">and</TOKEN>
<TOKEN end_char="4639" id="token-46-9" morph="none" pos="word" start_char="4636">sold</TOKEN>
<TOKEN end_char="4643" id="token-46-10" morph="none" pos="word" start_char="4641">the</TOKEN>
<TOKEN end_char="4655" id="token-46-11" morph="none" pos="word" start_char="4645">coronavirus</TOKEN>
<TOKEN end_char="4658" id="token-46-12" morph="none" pos="word" start_char="4657">to</TOKEN>
<TOKEN end_char="4669" id="token-46-13" morph="none" pos="tag" start_char="4660">#China…was</TOKEN>
<TOKEN end_char="4674" id="token-46-14" morph="none" pos="word" start_char="4671">just</TOKEN>
<TOKEN end_char="4683" id="token-46-15" morph="none" pos="word" start_char="4676">arrested</TOKEN>
<TOKEN end_char="4689" id="token-46-16" morph="none" pos="word" start_char="4685">today</TOKEN>
<TOKEN end_char="4690" id="token-46-17" morph="none" pos="punct" start_char="4690">"</TOKEN>
<TOKEN end_char="4692" id="token-46-18" morph="none" pos="punct" start_char="4692">(</TOKEN>
<TOKEN end_char="4697" id="token-46-19" morph="none" pos="word" start_char="4693">Tweet</TOKEN>
<TOKEN end_char="4700" id="token-46-20" morph="none" pos="word" start_char="4699">on</TOKEN>
<TOKEN end_char="4706" id="token-46-21" morph="none" pos="word" start_char="4702">April</TOKEN>
<TOKEN end_char="4708" id="token-46-22" morph="none" pos="word" start_char="4708">4</TOKEN>
<TOKEN end_char="4709" id="token-46-23" morph="none" pos="punct" start_char="4709">)</TOKEN>
</SEG>
<SEG end_char="4746" id="segment-47" start_char="4712">
<ORIGINAL_TEXT>Response: This claim is inaccurate.</ORIGINAL_TEXT>
<TOKEN end_char="4719" id="token-47-0" morph="none" pos="word" start_char="4712">Response</TOKEN>
<TOKEN end_char="4720" id="token-47-1" morph="none" pos="punct" start_char="4720">:</TOKEN>
<TOKEN end_char="4725" id="token-47-2" morph="none" pos="word" start_char="4722">This</TOKEN>
<TOKEN end_char="4731" id="token-47-3" morph="none" pos="word" start_char="4727">claim</TOKEN>
<TOKEN end_char="4734" id="token-47-4" morph="none" pos="word" start_char="4733">is</TOKEN>
<TOKEN end_char="4745" id="token-47-5" morph="none" pos="word" start_char="4736">inaccurate</TOKEN>
<TOKEN end_char="4746" id="token-47-6" morph="none" pos="punct" start_char="4746">.</TOKEN>
</SEG>
<SEG end_char="4778" id="segment-48" start_char="4748">
<ORIGINAL_TEXT>Dr. Lieber was arrested on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="4749" id="token-48-0" morph="none" pos="word" start_char="4748">Dr</TOKEN>
<TOKEN end_char="4750" id="token-48-1" morph="none" pos="punct" start_char="4750">.</TOKEN>
<TOKEN end_char="4757" id="token-48-2" morph="none" pos="word" start_char="4752">Lieber</TOKEN>
<TOKEN end_char="4761" id="token-48-3" morph="none" pos="word" start_char="4759">was</TOKEN>
<TOKEN end_char="4770" id="token-48-4" morph="none" pos="word" start_char="4763">arrested</TOKEN>
<TOKEN end_char="4773" id="token-48-5" morph="none" pos="word" start_char="4772">on</TOKEN>
<TOKEN end_char="4777" id="token-48-6" morph="none" pos="word" start_char="4775">Jan</TOKEN>
<TOKEN end_char="4778" id="token-48-7" morph="none" pos="punct" start_char="4778">.</TOKEN>
</SEG>
<SEG end_char="4836" id="segment-49" start_char="4780">
<ORIGINAL_TEXT>28, 2020, more than two months before the tweet was sent.</ORIGINAL_TEXT>
<TOKEN end_char="4781" id="token-49-0" morph="none" pos="word" start_char="4780">28</TOKEN>
<TOKEN end_char="4782" id="token-49-1" morph="none" pos="punct" start_char="4782">,</TOKEN>
<TOKEN end_char="4787" id="token-49-2" morph="none" pos="word" start_char="4784">2020</TOKEN>
<TOKEN end_char="4788" id="token-49-3" morph="none" pos="punct" start_char="4788">,</TOKEN>
<TOKEN end_char="4793" id="token-49-4" morph="none" pos="word" start_char="4790">more</TOKEN>
<TOKEN end_char="4798" id="token-49-5" morph="none" pos="word" start_char="4795">than</TOKEN>
<TOKEN end_char="4802" id="token-49-6" morph="none" pos="word" start_char="4800">two</TOKEN>
<TOKEN end_char="4809" id="token-49-7" morph="none" pos="word" start_char="4804">months</TOKEN>
<TOKEN end_char="4816" id="token-49-8" morph="none" pos="word" start_char="4811">before</TOKEN>
<TOKEN end_char="4820" id="token-49-9" morph="none" pos="word" start_char="4818">the</TOKEN>
<TOKEN end_char="4826" id="token-49-10" morph="none" pos="word" start_char="4822">tweet</TOKEN>
<TOKEN end_char="4830" id="token-49-11" morph="none" pos="word" start_char="4828">was</TOKEN>
<TOKEN end_char="4835" id="token-49-12" morph="none" pos="word" start_char="4832">sent</TOKEN>
<TOKEN end_char="4836" id="token-49-13" morph="none" pos="punct" start_char="4836">.</TOKEN>
</SEG>
<SEG end_char="4875" id="segment-50" start_char="4839">
<ORIGINAL_TEXT>Claim: "Charles Lieber @Harvard Univ.</ORIGINAL_TEXT>
<TOKEN end_char="4843" id="token-50-0" morph="none" pos="word" start_char="4839">Claim</TOKEN>
<TOKEN end_char="4844" id="token-50-1" morph="none" pos="punct" start_char="4844">:</TOKEN>
<TOKEN end_char="4846" id="token-50-2" morph="none" pos="punct" start_char="4846">"</TOKEN>
<TOKEN end_char="4853" id="token-50-3" morph="none" pos="word" start_char="4847">Charles</TOKEN>
<TOKEN end_char="4860" id="token-50-4" morph="none" pos="word" start_char="4855">Lieber</TOKEN>
<TOKEN end_char="4869" id="token-50-5" morph="none" pos="tag" start_char="4862">@Harvard</TOKEN>
<TOKEN end_char="4874" id="token-50-6" morph="none" pos="word" start_char="4871">Univ</TOKEN>
<TOKEN end_char="4875" id="token-50-7" morph="none" pos="punct" start_char="4875">.</TOKEN>
</SEG>
<SEG end_char="4995" id="segment-51" start_char="4877">
<ORIGINAL_TEXT>who was arrested on Friday along with 2 Chinese Communist Int’l for manufacturing viruses since 2000 to sell to China."</ORIGINAL_TEXT>
<TOKEN end_char="4879" id="token-51-0" morph="none" pos="word" start_char="4877">who</TOKEN>
<TOKEN end_char="4883" id="token-51-1" morph="none" pos="word" start_char="4881">was</TOKEN>
<TOKEN end_char="4892" id="token-51-2" morph="none" pos="word" start_char="4885">arrested</TOKEN>
<TOKEN end_char="4895" id="token-51-3" morph="none" pos="word" start_char="4894">on</TOKEN>
<TOKEN end_char="4902" id="token-51-4" morph="none" pos="word" start_char="4897">Friday</TOKEN>
<TOKEN end_char="4908" id="token-51-5" morph="none" pos="word" start_char="4904">along</TOKEN>
<TOKEN end_char="4913" id="token-51-6" morph="none" pos="word" start_char="4910">with</TOKEN>
<TOKEN end_char="4915" id="token-51-7" morph="none" pos="word" start_char="4915">2</TOKEN>
<TOKEN end_char="4923" id="token-51-8" morph="none" pos="word" start_char="4917">Chinese</TOKEN>
<TOKEN end_char="4933" id="token-51-9" morph="none" pos="word" start_char="4925">Communist</TOKEN>
<TOKEN end_char="4939" id="token-51-10" morph="none" pos="word" start_char="4935">Int’l</TOKEN>
<TOKEN end_char="4943" id="token-51-11" morph="none" pos="word" start_char="4941">for</TOKEN>
<TOKEN end_char="4957" id="token-51-12" morph="none" pos="word" start_char="4945">manufacturing</TOKEN>
<TOKEN end_char="4965" id="token-51-13" morph="none" pos="word" start_char="4959">viruses</TOKEN>
<TOKEN end_char="4971" id="token-51-14" morph="none" pos="word" start_char="4967">since</TOKEN>
<TOKEN end_char="4976" id="token-51-15" morph="none" pos="word" start_char="4973">2000</TOKEN>
<TOKEN end_char="4979" id="token-51-16" morph="none" pos="word" start_char="4978">to</TOKEN>
<TOKEN end_char="4984" id="token-51-17" morph="none" pos="word" start_char="4981">sell</TOKEN>
<TOKEN end_char="4987" id="token-51-18" morph="none" pos="word" start_char="4986">to</TOKEN>
<TOKEN end_char="4993" id="token-51-19" morph="none" pos="word" start_char="4989">China</TOKEN>
<TOKEN end_char="4995" id="token-51-20" morph="none" pos="punct" start_char="4994">."</TOKEN>
</SEG>
<SEG end_char="5014" id="segment-52" start_char="4997">
<ORIGINAL_TEXT>(Tweet on April 6)</ORIGINAL_TEXT>
<TOKEN end_char="4997" id="token-52-0" morph="none" pos="punct" start_char="4997">(</TOKEN>
<TOKEN end_char="5002" id="token-52-1" morph="none" pos="word" start_char="4998">Tweet</TOKEN>
<TOKEN end_char="5005" id="token-52-2" morph="none" pos="word" start_char="5004">on</TOKEN>
<TOKEN end_char="5011" id="token-52-3" morph="none" pos="word" start_char="5007">April</TOKEN>
<TOKEN end_char="5013" id="token-52-4" morph="none" pos="word" start_char="5013">6</TOKEN>
<TOKEN end_char="5014" id="token-52-5" morph="none" pos="punct" start_char="5014">)</TOKEN>
</SEG>
<SEG end_char="5066" id="segment-53" start_char="5017">
<ORIGINAL_TEXT>Response: This claim is inaccurate and misleading.</ORIGINAL_TEXT>
<TOKEN end_char="5024" id="token-53-0" morph="none" pos="word" start_char="5017">Response</TOKEN>
<TOKEN end_char="5025" id="token-53-1" morph="none" pos="punct" start_char="5025">:</TOKEN>
<TOKEN end_char="5030" id="token-53-2" morph="none" pos="word" start_char="5027">This</TOKEN>
<TOKEN end_char="5036" id="token-53-3" morph="none" pos="word" start_char="5032">claim</TOKEN>
<TOKEN end_char="5039" id="token-53-4" morph="none" pos="word" start_char="5038">is</TOKEN>
<TOKEN end_char="5050" id="token-53-5" morph="none" pos="word" start_char="5041">inaccurate</TOKEN>
<TOKEN end_char="5054" id="token-53-6" morph="none" pos="word" start_char="5052">and</TOKEN>
<TOKEN end_char="5065" id="token-53-7" morph="none" pos="word" start_char="5056">misleading</TOKEN>
<TOKEN end_char="5066" id="token-53-8" morph="none" pos="punct" start_char="5066">.</TOKEN>
</SEG>
<SEG end_char="5098" id="segment-54" start_char="5068">
<ORIGINAL_TEXT>Dr. Lieber was arrested on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="5069" id="token-54-0" morph="none" pos="word" start_char="5068">Dr</TOKEN>
<TOKEN end_char="5070" id="token-54-1" morph="none" pos="punct" start_char="5070">.</TOKEN>
<TOKEN end_char="5077" id="token-54-2" morph="none" pos="word" start_char="5072">Lieber</TOKEN>
<TOKEN end_char="5081" id="token-54-3" morph="none" pos="word" start_char="5079">was</TOKEN>
<TOKEN end_char="5090" id="token-54-4" morph="none" pos="word" start_char="5083">arrested</TOKEN>
<TOKEN end_char="5093" id="token-54-5" morph="none" pos="word" start_char="5092">on</TOKEN>
<TOKEN end_char="5097" id="token-54-6" morph="none" pos="word" start_char="5095">Jan</TOKEN>
<TOKEN end_char="5098" id="token-54-7" morph="none" pos="punct" start_char="5098">.</TOKEN>
</SEG>
<SEG end_char="5108" id="segment-55" start_char="5100">
<ORIGINAL_TEXT>28, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="5101" id="token-55-0" morph="none" pos="word" start_char="5100">28</TOKEN>
<TOKEN end_char="5102" id="token-55-1" morph="none" pos="punct" start_char="5102">,</TOKEN>
<TOKEN end_char="5107" id="token-55-2" morph="none" pos="word" start_char="5104">2020</TOKEN>
<TOKEN end_char="5108" id="token-55-3" morph="none" pos="punct" start_char="5108">.</TOKEN>
<TRANSLATED_TEXT>28, 2020</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="5211" id="segment-56" start_char="5110">
<ORIGINAL_TEXT>Federal prosecutors have not alleged in any way that Dr. Lieber manufactured or sold viruses to China.</ORIGINAL_TEXT>
<TOKEN end_char="5116" id="token-56-0" morph="none" pos="word" start_char="5110">Federal</TOKEN>
<TOKEN end_char="5128" id="token-56-1" morph="none" pos="word" start_char="5118">prosecutors</TOKEN>
<TOKEN end_char="5133" id="token-56-2" morph="none" pos="word" start_char="5130">have</TOKEN>
<TOKEN end_char="5137" id="token-56-3" morph="none" pos="word" start_char="5135">not</TOKEN>
<TOKEN end_char="5145" id="token-56-4" morph="none" pos="word" start_char="5139">alleged</TOKEN>
<TOKEN end_char="5148" id="token-56-5" morph="none" pos="word" start_char="5147">in</TOKEN>
<TOKEN end_char="5152" id="token-56-6" morph="none" pos="word" start_char="5150">any</TOKEN>
<TOKEN end_char="5156" id="token-56-7" morph="none" pos="word" start_char="5154">way</TOKEN>
<TOKEN end_char="5161" id="token-56-8" morph="none" pos="word" start_char="5158">that</TOKEN>
<TOKEN end_char="5164" id="token-56-9" morph="none" pos="word" start_char="5163">Dr</TOKEN>
<TOKEN end_char="5165" id="token-56-10" morph="none" pos="punct" start_char="5165">.</TOKEN>
<TOKEN end_char="5172" id="token-56-11" morph="none" pos="word" start_char="5167">Lieber</TOKEN>
<TOKEN end_char="5185" id="token-56-12" morph="none" pos="word" start_char="5174">manufactured</TOKEN>
<TOKEN end_char="5188" id="token-56-13" morph="none" pos="word" start_char="5187">or</TOKEN>
<TOKEN end_char="5193" id="token-56-14" morph="none" pos="word" start_char="5190">sold</TOKEN>
<TOKEN end_char="5201" id="token-56-15" morph="none" pos="word" start_char="5195">viruses</TOKEN>
<TOKEN end_char="5204" id="token-56-16" morph="none" pos="word" start_char="5203">to</TOKEN>
<TOKEN end_char="5210" id="token-56-17" morph="none" pos="word" start_char="5206">China</TOKEN>
<TOKEN end_char="5211" id="token-56-18" morph="none" pos="punct" start_char="5211">.</TOKEN>
</SEG>
<SEG end_char="5304" id="segment-57" start_char="5213">
<ORIGINAL_TEXT>According to court documents, Dr. Lieber’s interactions with China did not begin until 2011.</ORIGINAL_TEXT>
<TOKEN end_char="5221" id="token-57-0" morph="none" pos="word" start_char="5213">According</TOKEN>
<TOKEN end_char="5224" id="token-57-1" morph="none" pos="word" start_char="5223">to</TOKEN>
<TOKEN end_char="5230" id="token-57-2" morph="none" pos="word" start_char="5226">court</TOKEN>
<TOKEN end_char="5240" id="token-57-3" morph="none" pos="word" start_char="5232">documents</TOKEN>
<TOKEN end_char="5241" id="token-57-4" morph="none" pos="punct" start_char="5241">,</TOKEN>
<TOKEN end_char="5244" id="token-57-5" morph="none" pos="word" start_char="5243">Dr</TOKEN>
<TOKEN end_char="5245" id="token-57-6" morph="none" pos="punct" start_char="5245">.</TOKEN>
<TOKEN end_char="5254" id="token-57-7" morph="none" pos="word" start_char="5247">Lieber’s</TOKEN>
<TOKEN end_char="5267" id="token-57-8" morph="none" pos="word" start_char="5256">interactions</TOKEN>
<TOKEN end_char="5272" id="token-57-9" morph="none" pos="word" start_char="5269">with</TOKEN>
<TOKEN end_char="5278" id="token-57-10" morph="none" pos="word" start_char="5274">China</TOKEN>
<TOKEN end_char="5282" id="token-57-11" morph="none" pos="word" start_char="5280">did</TOKEN>
<TOKEN end_char="5286" id="token-57-12" morph="none" pos="word" start_char="5284">not</TOKEN>
<TOKEN end_char="5292" id="token-57-13" morph="none" pos="word" start_char="5288">begin</TOKEN>
<TOKEN end_char="5298" id="token-57-14" morph="none" pos="word" start_char="5294">until</TOKEN>
<TOKEN end_char="5303" id="token-57-15" morph="none" pos="word" start_char="5300">2011</TOKEN>
<TOKEN end_char="5304" id="token-57-16" morph="none" pos="punct" start_char="5304">.</TOKEN>
</SEG>
<SEG end_char="5338" id="segment-58" start_char="5306">
<ORIGINAL_TEXT>Read the federal court complaint.</ORIGINAL_TEXT>
<TOKEN end_char="5309" id="token-58-0" morph="none" pos="word" start_char="5306">Read</TOKEN>
<TOKEN end_char="5313" id="token-58-1" morph="none" pos="word" start_char="5311">the</TOKEN>
<TOKEN end_char="5321" id="token-58-2" morph="none" pos="word" start_char="5315">federal</TOKEN>
<TOKEN end_char="5327" id="token-58-3" morph="none" pos="word" start_char="5323">court</TOKEN>
<TOKEN end_char="5337" id="token-58-4" morph="none" pos="word" start_char="5329">complaint</TOKEN>
<TOKEN end_char="5338" id="token-58-5" morph="none" pos="punct" start_char="5338">.</TOKEN>
</SEG>
<SEG end_char="5541" id="segment-59" start_char="5340">
<ORIGINAL_TEXT>The arrests of two other people in Massachusetts were announced at the same time in separate cases related to China, however prosecutors do not allege they had anything to do with the novel coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="5342" id="token-59-0" morph="none" pos="word" start_char="5340">The</TOKEN>
<TOKEN end_char="5350" id="token-59-1" morph="none" pos="word" start_char="5344">arrests</TOKEN>
<TOKEN end_char="5353" id="token-59-2" morph="none" pos="word" start_char="5352">of</TOKEN>
<TOKEN end_char="5357" id="token-59-3" morph="none" pos="word" start_char="5355">two</TOKEN>
<TOKEN end_char="5363" id="token-59-4" morph="none" pos="word" start_char="5359">other</TOKEN>
<TOKEN end_char="5370" id="token-59-5" morph="none" pos="word" start_char="5365">people</TOKEN>
<TOKEN end_char="5373" id="token-59-6" morph="none" pos="word" start_char="5372">in</TOKEN>
<TOKEN end_char="5387" id="token-59-7" morph="none" pos="word" start_char="5375">Massachusetts</TOKEN>
<TOKEN end_char="5392" id="token-59-8" morph="none" pos="word" start_char="5389">were</TOKEN>
<TOKEN end_char="5402" id="token-59-9" morph="none" pos="word" start_char="5394">announced</TOKEN>
<TOKEN end_char="5405" id="token-59-10" morph="none" pos="word" start_char="5404">at</TOKEN>
<TOKEN end_char="5409" id="token-59-11" morph="none" pos="word" start_char="5407">the</TOKEN>
<TOKEN end_char="5414" id="token-59-12" morph="none" pos="word" start_char="5411">same</TOKEN>
<TOKEN end_char="5419" id="token-59-13" morph="none" pos="word" start_char="5416">time</TOKEN>
<TOKEN end_char="5422" id="token-59-14" morph="none" pos="word" start_char="5421">in</TOKEN>
<TOKEN end_char="5431" id="token-59-15" morph="none" pos="word" start_char="5424">separate</TOKEN>
<TOKEN end_char="5437" id="token-59-16" morph="none" pos="word" start_char="5433">cases</TOKEN>
<TOKEN end_char="5445" id="token-59-17" morph="none" pos="word" start_char="5439">related</TOKEN>
<TOKEN end_char="5448" id="token-59-18" morph="none" pos="word" start_char="5447">to</TOKEN>
<TOKEN end_char="5454" id="token-59-19" morph="none" pos="word" start_char="5450">China</TOKEN>
<TOKEN end_char="5455" id="token-59-20" morph="none" pos="punct" start_char="5455">,</TOKEN>
<TOKEN end_char="5463" id="token-59-21" morph="none" pos="word" start_char="5457">however</TOKEN>
<TOKEN end_char="5475" id="token-59-22" morph="none" pos="word" start_char="5465">prosecutors</TOKEN>
<TOKEN end_char="5478" id="token-59-23" morph="none" pos="word" start_char="5477">do</TOKEN>
<TOKEN end_char="5482" id="token-59-24" morph="none" pos="word" start_char="5480">not</TOKEN>
<TOKEN end_char="5489" id="token-59-25" morph="none" pos="word" start_char="5484">allege</TOKEN>
<TOKEN end_char="5494" id="token-59-26" morph="none" pos="word" start_char="5491">they</TOKEN>
<TOKEN end_char="5498" id="token-59-27" morph="none" pos="word" start_char="5496">had</TOKEN>
<TOKEN end_char="5507" id="token-59-28" morph="none" pos="word" start_char="5500">anything</TOKEN>
<TOKEN end_char="5510" id="token-59-29" morph="none" pos="word" start_char="5509">to</TOKEN>
<TOKEN end_char="5513" id="token-59-30" morph="none" pos="word" start_char="5512">do</TOKEN>
<TOKEN end_char="5518" id="token-59-31" morph="none" pos="word" start_char="5515">with</TOKEN>
<TOKEN end_char="5522" id="token-59-32" morph="none" pos="word" start_char="5520">the</TOKEN>
<TOKEN end_char="5528" id="token-59-33" morph="none" pos="word" start_char="5524">novel</TOKEN>
<TOKEN end_char="5540" id="token-59-34" morph="none" pos="word" start_char="5530">coronavirus</TOKEN>
<TOKEN end_char="5541" id="token-59-35" morph="none" pos="punct" start_char="5541">.</TOKEN>
</SEG>
<SEG end_char="5613" id="segment-60" start_char="5544">
<ORIGINAL_TEXT>READ: Yanqing Ye criminal complaint | Zaosong Zheng criminal complaint</ORIGINAL_TEXT>
<TOKEN end_char="5547" id="token-60-0" morph="none" pos="word" start_char="5544">READ</TOKEN>
<TOKEN end_char="5548" id="token-60-1" morph="none" pos="punct" start_char="5548">:</TOKEN>
<TOKEN end_char="5556" id="token-60-2" morph="none" pos="word" start_char="5550">Yanqing</TOKEN>
<TOKEN end_char="5559" id="token-60-3" morph="none" pos="word" start_char="5558">Ye</TOKEN>
<TOKEN end_char="5568" id="token-60-4" morph="none" pos="word" start_char="5561">criminal</TOKEN>
<TOKEN end_char="5578" id="token-60-5" morph="none" pos="word" start_char="5570">complaint</TOKEN>
<TOKEN end_char="5580" id="token-60-6" morph="none" pos="unknown" start_char="5580">|</TOKEN>
<TOKEN end_char="5588" id="token-60-7" morph="none" pos="word" start_char="5582">Zaosong</TOKEN>
<TOKEN end_char="5594" id="token-60-8" morph="none" pos="word" start_char="5590">Zheng</TOKEN>
<TOKEN end_char="5603" id="token-60-9" morph="none" pos="word" start_char="5596">criminal</TOKEN>
<TOKEN end_char="5613" id="token-60-10" morph="none" pos="word" start_char="5605">complaint</TOKEN>
</SEG>
<SEG end_char="5645" id="segment-61" start_char="5616">
<ORIGINAL_TEXT>Helpful Links and Information:</ORIGINAL_TEXT>
<TOKEN end_char="5622" id="token-61-0" morph="none" pos="word" start_char="5616">Helpful</TOKEN>
<TOKEN end_char="5628" id="token-61-1" morph="none" pos="word" start_char="5624">Links</TOKEN>
<TOKEN end_char="5632" id="token-61-2" morph="none" pos="word" start_char="5630">and</TOKEN>
<TOKEN end_char="5644" id="token-61-3" morph="none" pos="word" start_char="5634">Information</TOKEN>
<TOKEN end_char="5645" id="token-61-4" morph="none" pos="punct" start_char="5645">:</TOKEN>
</SEG>
<SEG end_char="5700" id="segment-62" start_char="5648">
<ORIGINAL_TEXT>•Federal Court Complaint: United States of America v.</ORIGINAL_TEXT>
<TOKEN end_char="5648" id="token-62-0" morph="none" pos="punct" start_char="5648">•</TOKEN>
<TOKEN end_char="5655" id="token-62-1" morph="none" pos="word" start_char="5649">Federal</TOKEN>
<TOKEN end_char="5661" id="token-62-2" morph="none" pos="word" start_char="5657">Court</TOKEN>
<TOKEN end_char="5671" id="token-62-3" morph="none" pos="word" start_char="5663">Complaint</TOKEN>
<TOKEN end_char="5672" id="token-62-4" morph="none" pos="punct" start_char="5672">:</TOKEN>
<TOKEN end_char="5679" id="token-62-5" morph="none" pos="word" start_char="5674">United</TOKEN>
<TOKEN end_char="5686" id="token-62-6" morph="none" pos="word" start_char="5681">States</TOKEN>
<TOKEN end_char="5689" id="token-62-7" morph="none" pos="word" start_char="5688">of</TOKEN>
<TOKEN end_char="5697" id="token-62-8" morph="none" pos="word" start_char="5691">America</TOKEN>
<TOKEN end_char="5699" id="token-62-9" morph="none" pos="word" start_char="5699">v</TOKEN>
<TOKEN end_char="5700" id="token-62-10" morph="none" pos="punct" start_char="5700">.</TOKEN>
</SEG>
<SEG end_char="5715" id="segment-63" start_char="5702">
<ORIGINAL_TEXT>Charles Lieber</ORIGINAL_TEXT>
<TOKEN end_char="5708" id="token-63-0" morph="none" pos="word" start_char="5702">Charles</TOKEN>
<TOKEN end_char="5715" id="token-63-1" morph="none" pos="word" start_char="5710">Lieber</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
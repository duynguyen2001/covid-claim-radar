<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATFQ" lang="spa" raw_text_char_length="4729" raw_text_md5="1c65b4560d900411ec02c10c9f4de716" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="111" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Immunity for YEARS or DECADES: Covid resistance may last much longer than previously thought, says new research</ORIGINAL_TEXT>
<TOKEN end_char="8" id="token-0-0" morph="none" pos="word" start_char="1">Immunity</TOKEN>
<TOKEN end_char="12" id="token-0-1" morph="none" pos="word" start_char="10">for</TOKEN>
<TOKEN end_char="18" id="token-0-2" morph="none" pos="word" start_char="14">YEARS</TOKEN>
<TOKEN end_char="21" id="token-0-3" morph="none" pos="word" start_char="20">or</TOKEN>
<TOKEN end_char="29" id="token-0-4" morph="none" pos="word" start_char="23">DECADES</TOKEN>
<TOKEN end_char="30" id="token-0-5" morph="none" pos="punct" start_char="30">:</TOKEN>
<TOKEN end_char="36" id="token-0-6" morph="none" pos="word" start_char="32">Covid</TOKEN>
<TOKEN end_char="47" id="token-0-7" morph="none" pos="word" start_char="38">resistance</TOKEN>
<TOKEN end_char="51" id="token-0-8" morph="none" pos="word" start_char="49">may</TOKEN>
<TOKEN end_char="56" id="token-0-9" morph="none" pos="word" start_char="53">last</TOKEN>
<TOKEN end_char="61" id="token-0-10" morph="none" pos="word" start_char="58">much</TOKEN>
<TOKEN end_char="68" id="token-0-11" morph="none" pos="word" start_char="63">longer</TOKEN>
<TOKEN end_char="73" id="token-0-12" morph="none" pos="word" start_char="70">than</TOKEN>
<TOKEN end_char="84" id="token-0-13" morph="none" pos="word" start_char="75">previously</TOKEN>
<TOKEN end_char="92" id="token-0-14" morph="none" pos="word" start_char="86">thought</TOKEN>
<TOKEN end_char="93" id="token-0-15" morph="none" pos="punct" start_char="93">,</TOKEN>
<TOKEN end_char="98" id="token-0-16" morph="none" pos="word" start_char="95">says</TOKEN>
<TOKEN end_char="102" id="token-0-17" morph="none" pos="word" start_char="100">new</TOKEN>
<TOKEN end_char="111" id="token-0-18" morph="none" pos="word" start_char="104">research</TOKEN>
</SEG>
<SEG end_char="127" id="segment-1" start_char="115">
<ORIGINAL_TEXT>Get short URL</ORIGINAL_TEXT>
<TOKEN end_char="117" id="token-1-0" morph="none" pos="word" start_char="115">Get</TOKEN>
<TOKEN end_char="123" id="token-1-1" morph="none" pos="word" start_char="119">short</TOKEN>
<TOKEN end_char="127" id="token-1-2" morph="none" pos="word" start_char="125">URL</TOKEN>
</SEG>
<SEG end_char="227" id="segment-2" start_char="130">
<ORIGINAL_TEXT>Clinical trial of tests for the coronavirus disease (COVID-19) antibodies, at Keele University, UK</ORIGINAL_TEXT>
<TOKEN end_char="137" id="token-2-0" morph="none" pos="word" start_char="130">Clinical</TOKEN>
<TOKEN end_char="143" id="token-2-1" morph="none" pos="word" start_char="139">trial</TOKEN>
<TOKEN end_char="146" id="token-2-2" morph="none" pos="word" start_char="145">of</TOKEN>
<TOKEN end_char="152" id="token-2-3" morph="none" pos="word" start_char="148">tests</TOKEN>
<TOKEN end_char="156" id="token-2-4" morph="none" pos="word" start_char="154">for</TOKEN>
<TOKEN end_char="160" id="token-2-5" morph="none" pos="word" start_char="158">the</TOKEN>
<TOKEN end_char="172" id="token-2-6" morph="none" pos="word" start_char="162">coronavirus</TOKEN>
<TOKEN end_char="180" id="token-2-7" morph="none" pos="word" start_char="174">disease</TOKEN>
<TOKEN end_char="182" id="token-2-8" morph="none" pos="punct" start_char="182">(</TOKEN>
<TOKEN end_char="190" id="token-2-9" morph="none" pos="unknown" start_char="183">COVID-19</TOKEN>
<TOKEN end_char="191" id="token-2-10" morph="none" pos="punct" start_char="191">)</TOKEN>
<TOKEN end_char="202" id="token-2-11" morph="none" pos="word" start_char="193">antibodies</TOKEN>
<TOKEN end_char="203" id="token-2-12" morph="none" pos="punct" start_char="203">,</TOKEN>
<TOKEN end_char="206" id="token-2-13" morph="none" pos="word" start_char="205">at</TOKEN>
<TOKEN end_char="212" id="token-2-14" morph="none" pos="word" start_char="208">Keele</TOKEN>
<TOKEN end_char="223" id="token-2-15" morph="none" pos="word" start_char="214">University</TOKEN>
<TOKEN end_char="224" id="token-2-16" morph="none" pos="punct" start_char="224">,</TOKEN>
<TOKEN end_char="227" id="token-2-17" morph="none" pos="word" start_char="226">UK</TOKEN>
</SEG>
<SEG end_char="239" id="segment-3" start_char="231">
<ORIGINAL_TEXT>© Reuters</ORIGINAL_TEXT>
<TOKEN end_char="231" id="token-3-0" morph="none" pos="unknown" start_char="231">©</TOKEN>
<TOKEN end_char="239" id="token-3-1" morph="none" pos="word" start_char="233">Reuters</TOKEN>
<TRANSLATED_TEXT>(c) Reuters</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="311" id="segment-4" start_char="242">
<ORIGINAL_TEXT>By Peter Andrews, Irish science journalist and writer based in London.</ORIGINAL_TEXT>
<TOKEN end_char="243" id="token-4-0" morph="none" pos="word" start_char="242">By</TOKEN>
<TOKEN end_char="249" id="token-4-1" morph="none" pos="word" start_char="245">Peter</TOKEN>
<TOKEN end_char="257" id="token-4-2" morph="none" pos="word" start_char="251">Andrews</TOKEN>
<TOKEN end_char="258" id="token-4-3" morph="none" pos="punct" start_char="258">,</TOKEN>
<TOKEN end_char="264" id="token-4-4" morph="none" pos="word" start_char="260">Irish</TOKEN>
<TOKEN end_char="272" id="token-4-5" morph="none" pos="word" start_char="266">science</TOKEN>
<TOKEN end_char="283" id="token-4-6" morph="none" pos="word" start_char="274">journalist</TOKEN>
<TOKEN end_char="287" id="token-4-7" morph="none" pos="word" start_char="285">and</TOKEN>
<TOKEN end_char="294" id="token-4-8" morph="none" pos="word" start_char="289">writer</TOKEN>
<TOKEN end_char="300" id="token-4-9" morph="none" pos="word" start_char="296">based</TOKEN>
<TOKEN end_char="303" id="token-4-10" morph="none" pos="word" start_char="302">in</TOKEN>
<TOKEN end_char="310" id="token-4-11" morph="none" pos="word" start_char="305">London</TOKEN>
<TOKEN end_char="311" id="token-4-12" morph="none" pos="punct" start_char="311">.</TOKEN>
</SEG>
<SEG end_char="425" id="segment-5" start_char="313">
<ORIGINAL_TEXT>He has a background in the life sciences, and graduated from the University of Glasgow with a degree in genetics.</ORIGINAL_TEXT>
<TOKEN end_char="314" id="token-5-0" morph="none" pos="word" start_char="313">He</TOKEN>
<TOKEN end_char="318" id="token-5-1" morph="none" pos="word" start_char="316">has</TOKEN>
<TOKEN end_char="320" id="token-5-2" morph="none" pos="word" start_char="320">a</TOKEN>
<TOKEN end_char="331" id="token-5-3" morph="none" pos="word" start_char="322">background</TOKEN>
<TOKEN end_char="334" id="token-5-4" morph="none" pos="word" start_char="333">in</TOKEN>
<TOKEN end_char="338" id="token-5-5" morph="none" pos="word" start_char="336">the</TOKEN>
<TOKEN end_char="343" id="token-5-6" morph="none" pos="word" start_char="340">life</TOKEN>
<TOKEN end_char="352" id="token-5-7" morph="none" pos="word" start_char="345">sciences</TOKEN>
<TOKEN end_char="353" id="token-5-8" morph="none" pos="punct" start_char="353">,</TOKEN>
<TOKEN end_char="357" id="token-5-9" morph="none" pos="word" start_char="355">and</TOKEN>
<TOKEN end_char="367" id="token-5-10" morph="none" pos="word" start_char="359">graduated</TOKEN>
<TOKEN end_char="372" id="token-5-11" morph="none" pos="word" start_char="369">from</TOKEN>
<TOKEN end_char="376" id="token-5-12" morph="none" pos="word" start_char="374">the</TOKEN>
<TOKEN end_char="387" id="token-5-13" morph="none" pos="word" start_char="378">University</TOKEN>
<TOKEN end_char="390" id="token-5-14" morph="none" pos="word" start_char="389">of</TOKEN>
<TOKEN end_char="398" id="token-5-15" morph="none" pos="word" start_char="392">Glasgow</TOKEN>
<TOKEN end_char="403" id="token-5-16" morph="none" pos="word" start_char="400">with</TOKEN>
<TOKEN end_char="405" id="token-5-17" morph="none" pos="word" start_char="405">a</TOKEN>
<TOKEN end_char="412" id="token-5-18" morph="none" pos="word" start_char="407">degree</TOKEN>
<TOKEN end_char="415" id="token-5-19" morph="none" pos="word" start_char="414">in</TOKEN>
<TOKEN end_char="424" id="token-5-20" morph="none" pos="word" start_char="417">genetics</TOKEN>
<TOKEN end_char="425" id="token-5-21" morph="none" pos="punct" start_char="425">.</TOKEN>
</SEG>
<SEG end_char="588" id="segment-6" start_char="429">
<ORIGINAL_TEXT>According to a small but significant study, immunity to coronavirus after infection appears to last a long time, boosting hopes of a successful vaccine rollout.</ORIGINAL_TEXT>
<TOKEN end_char="437" id="token-6-0" morph="none" pos="word" start_char="429">According</TOKEN>
<TOKEN end_char="440" id="token-6-1" morph="none" pos="word" start_char="439">to</TOKEN>
<TOKEN end_char="442" id="token-6-2" morph="none" pos="word" start_char="442">a</TOKEN>
<TOKEN end_char="448" id="token-6-3" morph="none" pos="word" start_char="444">small</TOKEN>
<TOKEN end_char="452" id="token-6-4" morph="none" pos="word" start_char="450">but</TOKEN>
<TOKEN end_char="464" id="token-6-5" morph="none" pos="word" start_char="454">significant</TOKEN>
<TOKEN end_char="470" id="token-6-6" morph="none" pos="word" start_char="466">study</TOKEN>
<TOKEN end_char="471" id="token-6-7" morph="none" pos="punct" start_char="471">,</TOKEN>
<TOKEN end_char="480" id="token-6-8" morph="none" pos="word" start_char="473">immunity</TOKEN>
<TOKEN end_char="483" id="token-6-9" morph="none" pos="word" start_char="482">to</TOKEN>
<TOKEN end_char="495" id="token-6-10" morph="none" pos="word" start_char="485">coronavirus</TOKEN>
<TOKEN end_char="501" id="token-6-11" morph="none" pos="word" start_char="497">after</TOKEN>
<TOKEN end_char="511" id="token-6-12" morph="none" pos="word" start_char="503">infection</TOKEN>
<TOKEN end_char="519" id="token-6-13" morph="none" pos="word" start_char="513">appears</TOKEN>
<TOKEN end_char="522" id="token-6-14" morph="none" pos="word" start_char="521">to</TOKEN>
<TOKEN end_char="527" id="token-6-15" morph="none" pos="word" start_char="524">last</TOKEN>
<TOKEN end_char="529" id="token-6-16" morph="none" pos="word" start_char="529">a</TOKEN>
<TOKEN end_char="534" id="token-6-17" morph="none" pos="word" start_char="531">long</TOKEN>
<TOKEN end_char="539" id="token-6-18" morph="none" pos="word" start_char="536">time</TOKEN>
<TOKEN end_char="540" id="token-6-19" morph="none" pos="punct" start_char="540">,</TOKEN>
<TOKEN end_char="549" id="token-6-20" morph="none" pos="word" start_char="542">boosting</TOKEN>
<TOKEN end_char="555" id="token-6-21" morph="none" pos="word" start_char="551">hopes</TOKEN>
<TOKEN end_char="558" id="token-6-22" morph="none" pos="word" start_char="557">of</TOKEN>
<TOKEN end_char="560" id="token-6-23" morph="none" pos="word" start_char="560">a</TOKEN>
<TOKEN end_char="571" id="token-6-24" morph="none" pos="word" start_char="562">successful</TOKEN>
<TOKEN end_char="579" id="token-6-25" morph="none" pos="word" start_char="573">vaccine</TOKEN>
<TOKEN end_char="587" id="token-6-26" morph="none" pos="word" start_char="581">rollout</TOKEN>
<TOKEN end_char="588" id="token-6-27" morph="none" pos="punct" start_char="588">.</TOKEN>
</SEG>
<SEG end_char="638" id="segment-7" start_char="590">
<ORIGINAL_TEXT>But why were earlier indications of this ignored?</ORIGINAL_TEXT>
<TOKEN end_char="592" id="token-7-0" morph="none" pos="word" start_char="590">But</TOKEN>
<TOKEN end_char="596" id="token-7-1" morph="none" pos="word" start_char="594">why</TOKEN>
<TOKEN end_char="601" id="token-7-2" morph="none" pos="word" start_char="598">were</TOKEN>
<TOKEN end_char="609" id="token-7-3" morph="none" pos="word" start_char="603">earlier</TOKEN>
<TOKEN end_char="621" id="token-7-4" morph="none" pos="word" start_char="611">indications</TOKEN>
<TOKEN end_char="624" id="token-7-5" morph="none" pos="word" start_char="623">of</TOKEN>
<TOKEN end_char="629" id="token-7-6" morph="none" pos="word" start_char="626">this</TOKEN>
<TOKEN end_char="637" id="token-7-7" morph="none" pos="word" start_char="631">ignored</TOKEN>
<TOKEN end_char="638" id="token-7-8" morph="none" pos="punct" start_char="638">?</TOKEN>
</SEG>
<SEG end_char="788" id="segment-8" start_char="641">
<ORIGINAL_TEXT>The new study, which is small and has not yet been peer reviewed or published by a journal, has been shared online, on the pre-print server bioRxiv.</ORIGINAL_TEXT>
<TOKEN end_char="643" id="token-8-0" morph="none" pos="word" start_char="641">The</TOKEN>
<TOKEN end_char="647" id="token-8-1" morph="none" pos="word" start_char="645">new</TOKEN>
<TOKEN end_char="653" id="token-8-2" morph="none" pos="word" start_char="649">study</TOKEN>
<TOKEN end_char="654" id="token-8-3" morph="none" pos="punct" start_char="654">,</TOKEN>
<TOKEN end_char="660" id="token-8-4" morph="none" pos="word" start_char="656">which</TOKEN>
<TOKEN end_char="663" id="token-8-5" morph="none" pos="word" start_char="662">is</TOKEN>
<TOKEN end_char="669" id="token-8-6" morph="none" pos="word" start_char="665">small</TOKEN>
<TOKEN end_char="673" id="token-8-7" morph="none" pos="word" start_char="671">and</TOKEN>
<TOKEN end_char="677" id="token-8-8" morph="none" pos="word" start_char="675">has</TOKEN>
<TOKEN end_char="681" id="token-8-9" morph="none" pos="word" start_char="679">not</TOKEN>
<TOKEN end_char="685" id="token-8-10" morph="none" pos="word" start_char="683">yet</TOKEN>
<TOKEN end_char="690" id="token-8-11" morph="none" pos="word" start_char="687">been</TOKEN>
<TOKEN end_char="695" id="token-8-12" morph="none" pos="word" start_char="692">peer</TOKEN>
<TOKEN end_char="704" id="token-8-13" morph="none" pos="word" start_char="697">reviewed</TOKEN>
<TOKEN end_char="707" id="token-8-14" morph="none" pos="word" start_char="706">or</TOKEN>
<TOKEN end_char="717" id="token-8-15" morph="none" pos="word" start_char="709">published</TOKEN>
<TOKEN end_char="720" id="token-8-16" morph="none" pos="word" start_char="719">by</TOKEN>
<TOKEN end_char="722" id="token-8-17" morph="none" pos="word" start_char="722">a</TOKEN>
<TOKEN end_char="730" id="token-8-18" morph="none" pos="word" start_char="724">journal</TOKEN>
<TOKEN end_char="731" id="token-8-19" morph="none" pos="punct" start_char="731">,</TOKEN>
<TOKEN end_char="735" id="token-8-20" morph="none" pos="word" start_char="733">has</TOKEN>
<TOKEN end_char="740" id="token-8-21" morph="none" pos="word" start_char="737">been</TOKEN>
<TOKEN end_char="747" id="token-8-22" morph="none" pos="word" start_char="742">shared</TOKEN>
<TOKEN end_char="754" id="token-8-23" morph="none" pos="word" start_char="749">online</TOKEN>
<TOKEN end_char="755" id="token-8-24" morph="none" pos="punct" start_char="755">,</TOKEN>
<TOKEN end_char="758" id="token-8-25" morph="none" pos="word" start_char="757">on</TOKEN>
<TOKEN end_char="762" id="token-8-26" morph="none" pos="word" start_char="760">the</TOKEN>
<TOKEN end_char="772" id="token-8-27" morph="none" pos="unknown" start_char="764">pre-print</TOKEN>
<TOKEN end_char="779" id="token-8-28" morph="none" pos="word" start_char="774">server</TOKEN>
<TOKEN end_char="787" id="token-8-29" morph="none" pos="word" start_char="781">bioRxiv</TOKEN>
<TOKEN end_char="788" id="token-8-30" morph="none" pos="punct" start_char="788">.</TOKEN>
</SEG>
<SEG end_char="899" id="segment-9" start_char="790">
<ORIGINAL_TEXT>Despite its relative dearth of credentials at this early stage, it’s being heralded by the New York Times as "</ORIGINAL_TEXT>
<TOKEN end_char="796" id="token-9-0" morph="none" pos="word" start_char="790">Despite</TOKEN>
<TOKEN end_char="800" id="token-9-1" morph="none" pos="word" start_char="798">its</TOKEN>
<TOKEN end_char="809" id="token-9-2" morph="none" pos="word" start_char="802">relative</TOKEN>
<TOKEN end_char="816" id="token-9-3" morph="none" pos="word" start_char="811">dearth</TOKEN>
<TOKEN end_char="819" id="token-9-4" morph="none" pos="word" start_char="818">of</TOKEN>
<TOKEN end_char="831" id="token-9-5" morph="none" pos="word" start_char="821">credentials</TOKEN>
<TOKEN end_char="834" id="token-9-6" morph="none" pos="word" start_char="833">at</TOKEN>
<TOKEN end_char="839" id="token-9-7" morph="none" pos="word" start_char="836">this</TOKEN>
<TOKEN end_char="845" id="token-9-8" morph="none" pos="word" start_char="841">early</TOKEN>
<TOKEN end_char="851" id="token-9-9" morph="none" pos="word" start_char="847">stage</TOKEN>
<TOKEN end_char="852" id="token-9-10" morph="none" pos="punct" start_char="852">,</TOKEN>
<TOKEN end_char="857" id="token-9-11" morph="none" pos="word" start_char="854">it’s</TOKEN>
<TOKEN end_char="863" id="token-9-12" morph="none" pos="word" start_char="859">being</TOKEN>
<TOKEN end_char="872" id="token-9-13" morph="none" pos="word" start_char="865">heralded</TOKEN>
<TOKEN end_char="875" id="token-9-14" morph="none" pos="word" start_char="874">by</TOKEN>
<TOKEN end_char="879" id="token-9-15" morph="none" pos="word" start_char="877">the</TOKEN>
<TOKEN end_char="883" id="token-9-16" morph="none" pos="word" start_char="881">New</TOKEN>
<TOKEN end_char="888" id="token-9-17" morph="none" pos="word" start_char="885">York</TOKEN>
<TOKEN end_char="894" id="token-9-18" morph="none" pos="word" start_char="890">Times</TOKEN>
<TOKEN end_char="897" id="token-9-19" morph="none" pos="word" start_char="896">as</TOKEN>
<TOKEN end_char="899" id="token-9-20" morph="none" pos="punct" start_char="899">"</TOKEN>
</SEG>
<SEG end_char="990" id="segment-10" start_char="902">
<ORIGINAL_TEXT>the most comprehensive and long-ranging study of immune memory to the coronavirus to date</ORIGINAL_TEXT>
<TOKEN end_char="904" id="token-10-0" morph="none" pos="word" start_char="902">the</TOKEN>
<TOKEN end_char="909" id="token-10-1" morph="none" pos="word" start_char="906">most</TOKEN>
<TOKEN end_char="923" id="token-10-2" morph="none" pos="word" start_char="911">comprehensive</TOKEN>
<TOKEN end_char="927" id="token-10-3" morph="none" pos="word" start_char="925">and</TOKEN>
<TOKEN end_char="940" id="token-10-4" morph="none" pos="unknown" start_char="929">long-ranging</TOKEN>
<TOKEN end_char="946" id="token-10-5" morph="none" pos="word" start_char="942">study</TOKEN>
<TOKEN end_char="949" id="token-10-6" morph="none" pos="word" start_char="948">of</TOKEN>
<TOKEN end_char="956" id="token-10-7" morph="none" pos="word" start_char="951">immune</TOKEN>
<TOKEN end_char="963" id="token-10-8" morph="none" pos="word" start_char="958">memory</TOKEN>
<TOKEN end_char="966" id="token-10-9" morph="none" pos="word" start_char="965">to</TOKEN>
<TOKEN end_char="970" id="token-10-10" morph="none" pos="word" start_char="968">the</TOKEN>
<TOKEN end_char="982" id="token-10-11" morph="none" pos="word" start_char="972">coronavirus</TOKEN>
<TOKEN end_char="985" id="token-10-12" morph="none" pos="word" start_char="984">to</TOKEN>
<TOKEN end_char="990" id="token-10-13" morph="none" pos="word" start_char="987">date</TOKEN>
</SEG>
<SEG end_char="994" id="segment-11" start_char="993">
<ORIGINAL_TEXT>."</ORIGINAL_TEXT>
<TOKEN end_char="994" id="token-11-0" morph="none" pos="punct" start_char="993">."</TOKEN>
</SEG>
<SEG end_char="1215" id="segment-12" start_char="996">
<ORIGINAL_TEXT>High praise, indeed; and it’s warranted, as the study looks beyond just antibodies to analyse all forms of resistance to Covid: namely, T cells and B cells – that is, white blood cells that combat all forms of infection.</ORIGINAL_TEXT>
<TOKEN end_char="999" id="token-12-0" morph="none" pos="word" start_char="996">High</TOKEN>
<TOKEN end_char="1006" id="token-12-1" morph="none" pos="word" start_char="1001">praise</TOKEN>
<TOKEN end_char="1007" id="token-12-2" morph="none" pos="punct" start_char="1007">,</TOKEN>
<TOKEN end_char="1014" id="token-12-3" morph="none" pos="word" start_char="1009">indeed</TOKEN>
<TOKEN end_char="1015" id="token-12-4" morph="none" pos="punct" start_char="1015">;</TOKEN>
<TOKEN end_char="1019" id="token-12-5" morph="none" pos="word" start_char="1017">and</TOKEN>
<TOKEN end_char="1024" id="token-12-6" morph="none" pos="word" start_char="1021">it’s</TOKEN>
<TOKEN end_char="1034" id="token-12-7" morph="none" pos="word" start_char="1026">warranted</TOKEN>
<TOKEN end_char="1035" id="token-12-8" morph="none" pos="punct" start_char="1035">,</TOKEN>
<TOKEN end_char="1038" id="token-12-9" morph="none" pos="word" start_char="1037">as</TOKEN>
<TOKEN end_char="1042" id="token-12-10" morph="none" pos="word" start_char="1040">the</TOKEN>
<TOKEN end_char="1048" id="token-12-11" morph="none" pos="word" start_char="1044">study</TOKEN>
<TOKEN end_char="1054" id="token-12-12" morph="none" pos="word" start_char="1050">looks</TOKEN>
<TOKEN end_char="1061" id="token-12-13" morph="none" pos="word" start_char="1056">beyond</TOKEN>
<TOKEN end_char="1066" id="token-12-14" morph="none" pos="word" start_char="1063">just</TOKEN>
<TOKEN end_char="1077" id="token-12-15" morph="none" pos="word" start_char="1068">antibodies</TOKEN>
<TOKEN end_char="1080" id="token-12-16" morph="none" pos="word" start_char="1079">to</TOKEN>
<TOKEN end_char="1088" id="token-12-17" morph="none" pos="word" start_char="1082">analyse</TOKEN>
<TOKEN end_char="1092" id="token-12-18" morph="none" pos="word" start_char="1090">all</TOKEN>
<TOKEN end_char="1098" id="token-12-19" morph="none" pos="word" start_char="1094">forms</TOKEN>
<TOKEN end_char="1101" id="token-12-20" morph="none" pos="word" start_char="1100">of</TOKEN>
<TOKEN end_char="1112" id="token-12-21" morph="none" pos="word" start_char="1103">resistance</TOKEN>
<TOKEN end_char="1115" id="token-12-22" morph="none" pos="word" start_char="1114">to</TOKEN>
<TOKEN end_char="1121" id="token-12-23" morph="none" pos="word" start_char="1117">Covid</TOKEN>
<TOKEN end_char="1122" id="token-12-24" morph="none" pos="punct" start_char="1122">:</TOKEN>
<TOKEN end_char="1129" id="token-12-25" morph="none" pos="word" start_char="1124">namely</TOKEN>
<TOKEN end_char="1130" id="token-12-26" morph="none" pos="punct" start_char="1130">,</TOKEN>
<TOKEN end_char="1132" id="token-12-27" morph="none" pos="word" start_char="1132">T</TOKEN>
<TOKEN end_char="1138" id="token-12-28" morph="none" pos="word" start_char="1134">cells</TOKEN>
<TOKEN end_char="1142" id="token-12-29" morph="none" pos="word" start_char="1140">and</TOKEN>
<TOKEN end_char="1144" id="token-12-30" morph="none" pos="word" start_char="1144">B</TOKEN>
<TOKEN end_char="1150" id="token-12-31" morph="none" pos="word" start_char="1146">cells</TOKEN>
<TOKEN end_char="1152" id="token-12-32" morph="none" pos="punct" start_char="1152">–</TOKEN>
<TOKEN end_char="1157" id="token-12-33" morph="none" pos="word" start_char="1154">that</TOKEN>
<TOKEN end_char="1160" id="token-12-34" morph="none" pos="word" start_char="1159">is</TOKEN>
<TOKEN end_char="1161" id="token-12-35" morph="none" pos="punct" start_char="1161">,</TOKEN>
<TOKEN end_char="1167" id="token-12-36" morph="none" pos="word" start_char="1163">white</TOKEN>
<TOKEN end_char="1173" id="token-12-37" morph="none" pos="word" start_char="1169">blood</TOKEN>
<TOKEN end_char="1179" id="token-12-38" morph="none" pos="word" start_char="1175">cells</TOKEN>
<TOKEN end_char="1184" id="token-12-39" morph="none" pos="word" start_char="1181">that</TOKEN>
<TOKEN end_char="1191" id="token-12-40" morph="none" pos="word" start_char="1186">combat</TOKEN>
<TOKEN end_char="1195" id="token-12-41" morph="none" pos="word" start_char="1193">all</TOKEN>
<TOKEN end_char="1201" id="token-12-42" morph="none" pos="word" start_char="1197">forms</TOKEN>
<TOKEN end_char="1204" id="token-12-43" morph="none" pos="word" start_char="1203">of</TOKEN>
<TOKEN end_char="1214" id="token-12-44" morph="none" pos="word" start_char="1206">infection</TOKEN>
<TOKEN end_char="1215" id="token-12-45" morph="none" pos="punct" start_char="1215">.</TOKEN>
</SEG>
<SEG end_char="1340" id="segment-13" start_char="1218">
<ORIGINAL_TEXT>The study, co-led by the La Jolla Institute for Immunology, in California, looked at 185 people who had Covid and survived.</ORIGINAL_TEXT>
<TOKEN end_char="1220" id="token-13-0" morph="none" pos="word" start_char="1218">The</TOKEN>
<TOKEN end_char="1226" id="token-13-1" morph="none" pos="word" start_char="1222">study</TOKEN>
<TOKEN end_char="1227" id="token-13-2" morph="none" pos="punct" start_char="1227">,</TOKEN>
<TOKEN end_char="1234" id="token-13-3" morph="none" pos="unknown" start_char="1229">co-led</TOKEN>
<TOKEN end_char="1237" id="token-13-4" morph="none" pos="word" start_char="1236">by</TOKEN>
<TOKEN end_char="1241" id="token-13-5" morph="none" pos="word" start_char="1239">the</TOKEN>
<TOKEN end_char="1244" id="token-13-6" morph="none" pos="word" start_char="1243">La</TOKEN>
<TOKEN end_char="1250" id="token-13-7" morph="none" pos="word" start_char="1246">Jolla</TOKEN>
<TOKEN end_char="1260" id="token-13-8" morph="none" pos="word" start_char="1252">Institute</TOKEN>
<TOKEN end_char="1264" id="token-13-9" morph="none" pos="word" start_char="1262">for</TOKEN>
<TOKEN end_char="1275" id="token-13-10" morph="none" pos="word" start_char="1266">Immunology</TOKEN>
<TOKEN end_char="1276" id="token-13-11" morph="none" pos="punct" start_char="1276">,</TOKEN>
<TOKEN end_char="1279" id="token-13-12" morph="none" pos="word" start_char="1278">in</TOKEN>
<TOKEN end_char="1290" id="token-13-13" morph="none" pos="word" start_char="1281">California</TOKEN>
<TOKEN end_char="1291" id="token-13-14" morph="none" pos="punct" start_char="1291">,</TOKEN>
<TOKEN end_char="1298" id="token-13-15" morph="none" pos="word" start_char="1293">looked</TOKEN>
<TOKEN end_char="1301" id="token-13-16" morph="none" pos="word" start_char="1300">at</TOKEN>
<TOKEN end_char="1305" id="token-13-17" morph="none" pos="word" start_char="1303">185</TOKEN>
<TOKEN end_char="1312" id="token-13-18" morph="none" pos="word" start_char="1307">people</TOKEN>
<TOKEN end_char="1316" id="token-13-19" morph="none" pos="word" start_char="1314">who</TOKEN>
<TOKEN end_char="1320" id="token-13-20" morph="none" pos="word" start_char="1318">had</TOKEN>
<TOKEN end_char="1326" id="token-13-21" morph="none" pos="word" start_char="1322">Covid</TOKEN>
<TOKEN end_char="1330" id="token-13-22" morph="none" pos="word" start_char="1328">and</TOKEN>
<TOKEN end_char="1339" id="token-13-23" morph="none" pos="word" start_char="1332">survived</TOKEN>
<TOKEN end_char="1340" id="token-13-24" morph="none" pos="punct" start_char="1340">.</TOKEN>
</SEG>
<SEG end_char="1539" id="segment-14" start_char="1342">
<ORIGINAL_TEXT>It revealed that, although their antibody levels began to fall off six to eight months after infection, consistent with previous findings, they had abundant and robust levels of T cells and B cells.</ORIGINAL_TEXT>
<TOKEN end_char="1343" id="token-14-0" morph="none" pos="word" start_char="1342">It</TOKEN>
<TOKEN end_char="1352" id="token-14-1" morph="none" pos="word" start_char="1345">revealed</TOKEN>
<TOKEN end_char="1357" id="token-14-2" morph="none" pos="word" start_char="1354">that</TOKEN>
<TOKEN end_char="1358" id="token-14-3" morph="none" pos="punct" start_char="1358">,</TOKEN>
<TOKEN end_char="1367" id="token-14-4" morph="none" pos="word" start_char="1360">although</TOKEN>
<TOKEN end_char="1373" id="token-14-5" morph="none" pos="word" start_char="1369">their</TOKEN>
<TOKEN end_char="1382" id="token-14-6" morph="none" pos="word" start_char="1375">antibody</TOKEN>
<TOKEN end_char="1389" id="token-14-7" morph="none" pos="word" start_char="1384">levels</TOKEN>
<TOKEN end_char="1395" id="token-14-8" morph="none" pos="word" start_char="1391">began</TOKEN>
<TOKEN end_char="1398" id="token-14-9" morph="none" pos="word" start_char="1397">to</TOKEN>
<TOKEN end_char="1403" id="token-14-10" morph="none" pos="word" start_char="1400">fall</TOKEN>
<TOKEN end_char="1407" id="token-14-11" morph="none" pos="word" start_char="1405">off</TOKEN>
<TOKEN end_char="1411" id="token-14-12" morph="none" pos="word" start_char="1409">six</TOKEN>
<TOKEN end_char="1414" id="token-14-13" morph="none" pos="word" start_char="1413">to</TOKEN>
<TOKEN end_char="1420" id="token-14-14" morph="none" pos="word" start_char="1416">eight</TOKEN>
<TOKEN end_char="1427" id="token-14-15" morph="none" pos="word" start_char="1422">months</TOKEN>
<TOKEN end_char="1433" id="token-14-16" morph="none" pos="word" start_char="1429">after</TOKEN>
<TOKEN end_char="1443" id="token-14-17" morph="none" pos="word" start_char="1435">infection</TOKEN>
<TOKEN end_char="1444" id="token-14-18" morph="none" pos="punct" start_char="1444">,</TOKEN>
<TOKEN end_char="1455" id="token-14-19" morph="none" pos="word" start_char="1446">consistent</TOKEN>
<TOKEN end_char="1460" id="token-14-20" morph="none" pos="word" start_char="1457">with</TOKEN>
<TOKEN end_char="1469" id="token-14-21" morph="none" pos="word" start_char="1462">previous</TOKEN>
<TOKEN end_char="1478" id="token-14-22" morph="none" pos="word" start_char="1471">findings</TOKEN>
<TOKEN end_char="1479" id="token-14-23" morph="none" pos="punct" start_char="1479">,</TOKEN>
<TOKEN end_char="1484" id="token-14-24" morph="none" pos="word" start_char="1481">they</TOKEN>
<TOKEN end_char="1488" id="token-14-25" morph="none" pos="word" start_char="1486">had</TOKEN>
<TOKEN end_char="1497" id="token-14-26" morph="none" pos="word" start_char="1490">abundant</TOKEN>
<TOKEN end_char="1501" id="token-14-27" morph="none" pos="word" start_char="1499">and</TOKEN>
<TOKEN end_char="1508" id="token-14-28" morph="none" pos="word" start_char="1503">robust</TOKEN>
<TOKEN end_char="1515" id="token-14-29" morph="none" pos="word" start_char="1510">levels</TOKEN>
<TOKEN end_char="1518" id="token-14-30" morph="none" pos="word" start_char="1517">of</TOKEN>
<TOKEN end_char="1520" id="token-14-31" morph="none" pos="word" start_char="1520">T</TOKEN>
<TOKEN end_char="1526" id="token-14-32" morph="none" pos="word" start_char="1522">cells</TOKEN>
<TOKEN end_char="1530" id="token-14-33" morph="none" pos="word" start_char="1528">and</TOKEN>
<TOKEN end_char="1532" id="token-14-34" morph="none" pos="word" start_char="1532">B</TOKEN>
<TOKEN end_char="1538" id="token-14-35" morph="none" pos="word" start_char="1534">cells</TOKEN>
<TOKEN end_char="1539" id="token-14-36" morph="none" pos="punct" start_char="1539">.</TOKEN>
</SEG>
<SEG end_char="1609" id="segment-15" start_char="1541">
<ORIGINAL_TEXT>In fact, B cells kept increasing after infection for reasons unknown.</ORIGINAL_TEXT>
<TOKEN end_char="1542" id="token-15-0" morph="none" pos="word" start_char="1541">In</TOKEN>
<TOKEN end_char="1547" id="token-15-1" morph="none" pos="word" start_char="1544">fact</TOKEN>
<TOKEN end_char="1548" id="token-15-2" morph="none" pos="punct" start_char="1548">,</TOKEN>
<TOKEN end_char="1550" id="token-15-3" morph="none" pos="word" start_char="1550">B</TOKEN>
<TOKEN end_char="1556" id="token-15-4" morph="none" pos="word" start_char="1552">cells</TOKEN>
<TOKEN end_char="1561" id="token-15-5" morph="none" pos="word" start_char="1558">kept</TOKEN>
<TOKEN end_char="1572" id="token-15-6" morph="none" pos="word" start_char="1563">increasing</TOKEN>
<TOKEN end_char="1578" id="token-15-7" morph="none" pos="word" start_char="1574">after</TOKEN>
<TOKEN end_char="1588" id="token-15-8" morph="none" pos="word" start_char="1580">infection</TOKEN>
<TOKEN end_char="1592" id="token-15-9" morph="none" pos="word" start_char="1590">for</TOKEN>
<TOKEN end_char="1600" id="token-15-10" morph="none" pos="word" start_char="1594">reasons</TOKEN>
<TOKEN end_char="1608" id="token-15-11" morph="none" pos="word" start_char="1602">unknown</TOKEN>
<TOKEN end_char="1609" id="token-15-12" morph="none" pos="punct" start_char="1609">.</TOKEN>
</SEG>
<SEG end_char="1687" id="segment-16" start_char="1611">
<ORIGINAL_TEXT>The levels found in the subjects’ blood would, according to a study leader, "</ORIGINAL_TEXT>
<TOKEN end_char="1613" id="token-16-0" morph="none" pos="word" start_char="1611">The</TOKEN>
<TOKEN end_char="1620" id="token-16-1" morph="none" pos="word" start_char="1615">levels</TOKEN>
<TOKEN end_char="1626" id="token-16-2" morph="none" pos="word" start_char="1622">found</TOKEN>
<TOKEN end_char="1629" id="token-16-3" morph="none" pos="word" start_char="1628">in</TOKEN>
<TOKEN end_char="1633" id="token-16-4" morph="none" pos="word" start_char="1631">the</TOKEN>
<TOKEN end_char="1642" id="token-16-5" morph="none" pos="word" start_char="1635">subjects</TOKEN>
<TOKEN end_char="1643" id="token-16-6" morph="none" pos="punct" start_char="1643">’</TOKEN>
<TOKEN end_char="1649" id="token-16-7" morph="none" pos="word" start_char="1645">blood</TOKEN>
<TOKEN end_char="1655" id="token-16-8" morph="none" pos="word" start_char="1651">would</TOKEN>
<TOKEN end_char="1656" id="token-16-9" morph="none" pos="punct" start_char="1656">,</TOKEN>
<TOKEN end_char="1666" id="token-16-10" morph="none" pos="word" start_char="1658">according</TOKEN>
<TOKEN end_char="1669" id="token-16-11" morph="none" pos="word" start_char="1668">to</TOKEN>
<TOKEN end_char="1671" id="token-16-12" morph="none" pos="word" start_char="1671">a</TOKEN>
<TOKEN end_char="1677" id="token-16-13" morph="none" pos="word" start_char="1673">study</TOKEN>
<TOKEN end_char="1684" id="token-16-14" morph="none" pos="word" start_char="1679">leader</TOKEN>
<TOKEN end_char="1685" id="token-16-15" morph="none" pos="punct" start_char="1685">,</TOKEN>
<TOKEN end_char="1687" id="token-16-16" morph="none" pos="punct" start_char="1687">"</TOKEN>
</SEG>
<SEG end_char="1797" id="segment-17" start_char="1690">
<ORIGINAL_TEXT>likely prevent the vast majority of people from getting hospitalized disease, severe disease, for many years</ORIGINAL_TEXT>
<TOKEN end_char="1695" id="token-17-0" morph="none" pos="word" start_char="1690">likely</TOKEN>
<TOKEN end_char="1703" id="token-17-1" morph="none" pos="word" start_char="1697">prevent</TOKEN>
<TOKEN end_char="1707" id="token-17-2" morph="none" pos="word" start_char="1705">the</TOKEN>
<TOKEN end_char="1712" id="token-17-3" morph="none" pos="word" start_char="1709">vast</TOKEN>
<TOKEN end_char="1721" id="token-17-4" morph="none" pos="word" start_char="1714">majority</TOKEN>
<TOKEN end_char="1724" id="token-17-5" morph="none" pos="word" start_char="1723">of</TOKEN>
<TOKEN end_char="1731" id="token-17-6" morph="none" pos="word" start_char="1726">people</TOKEN>
<TOKEN end_char="1736" id="token-17-7" morph="none" pos="word" start_char="1733">from</TOKEN>
<TOKEN end_char="1744" id="token-17-8" morph="none" pos="word" start_char="1738">getting</TOKEN>
<TOKEN end_char="1757" id="token-17-9" morph="none" pos="word" start_char="1746">hospitalized</TOKEN>
<TOKEN end_char="1765" id="token-17-10" morph="none" pos="word" start_char="1759">disease</TOKEN>
<TOKEN end_char="1766" id="token-17-11" morph="none" pos="punct" start_char="1766">,</TOKEN>
<TOKEN end_char="1773" id="token-17-12" morph="none" pos="word" start_char="1768">severe</TOKEN>
<TOKEN end_char="1781" id="token-17-13" morph="none" pos="word" start_char="1775">disease</TOKEN>
<TOKEN end_char="1782" id="token-17-14" morph="none" pos="punct" start_char="1782">,</TOKEN>
<TOKEN end_char="1786" id="token-17-15" morph="none" pos="word" start_char="1784">for</TOKEN>
<TOKEN end_char="1791" id="token-17-16" morph="none" pos="word" start_char="1788">many</TOKEN>
<TOKEN end_char="1797" id="token-17-17" morph="none" pos="word" start_char="1793">years</TOKEN>
</SEG>
<SEG end_char="1802" id="segment-18" start_char="1800">
<ORIGINAL_TEXT>.’’</ORIGINAL_TEXT>
<TOKEN end_char="1802" id="token-18-0" morph="none" pos="punct" start_char="1800">.’’</TOKEN>
<TRANSLATED_TEXT>. "</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="1830" id="segment-19" start_char="1807">
<ORIGINAL_TEXT>Why the sudden interest?</ORIGINAL_TEXT>
<TOKEN end_char="1809" id="token-19-0" morph="none" pos="word" start_char="1807">Why</TOKEN>
<TOKEN end_char="1813" id="token-19-1" morph="none" pos="word" start_char="1811">the</TOKEN>
<TOKEN end_char="1820" id="token-19-2" morph="none" pos="word" start_char="1815">sudden</TOKEN>
<TOKEN end_char="1829" id="token-19-3" morph="none" pos="word" start_char="1822">interest</TOKEN>
<TOKEN end_char="1830" id="token-19-4" morph="none" pos="punct" start_char="1830">?</TOKEN>
</SEG>
<SEG end_char="1949" id="segment-20" start_char="1834">
<ORIGINAL_TEXT>The NYT and the rest of the mainstream media seem to finally be relinquishing their obsession with antibody studies.</ORIGINAL_TEXT>
<TOKEN end_char="1836" id="token-20-0" morph="none" pos="word" start_char="1834">The</TOKEN>
<TOKEN end_char="1840" id="token-20-1" morph="none" pos="word" start_char="1838">NYT</TOKEN>
<TOKEN end_char="1844" id="token-20-2" morph="none" pos="word" start_char="1842">and</TOKEN>
<TOKEN end_char="1848" id="token-20-3" morph="none" pos="word" start_char="1846">the</TOKEN>
<TOKEN end_char="1853" id="token-20-4" morph="none" pos="word" start_char="1850">rest</TOKEN>
<TOKEN end_char="1856" id="token-20-5" morph="none" pos="word" start_char="1855">of</TOKEN>
<TOKEN end_char="1860" id="token-20-6" morph="none" pos="word" start_char="1858">the</TOKEN>
<TOKEN end_char="1871" id="token-20-7" morph="none" pos="word" start_char="1862">mainstream</TOKEN>
<TOKEN end_char="1877" id="token-20-8" morph="none" pos="word" start_char="1873">media</TOKEN>
<TOKEN end_char="1882" id="token-20-9" morph="none" pos="word" start_char="1879">seem</TOKEN>
<TOKEN end_char="1885" id="token-20-10" morph="none" pos="word" start_char="1884">to</TOKEN>
<TOKEN end_char="1893" id="token-20-11" morph="none" pos="word" start_char="1887">finally</TOKEN>
<TOKEN end_char="1896" id="token-20-12" morph="none" pos="word" start_char="1895">be</TOKEN>
<TOKEN end_char="1910" id="token-20-13" morph="none" pos="word" start_char="1898">relinquishing</TOKEN>
<TOKEN end_char="1916" id="token-20-14" morph="none" pos="word" start_char="1912">their</TOKEN>
<TOKEN end_char="1926" id="token-20-15" morph="none" pos="word" start_char="1918">obsession</TOKEN>
<TOKEN end_char="1931" id="token-20-16" morph="none" pos="word" start_char="1928">with</TOKEN>
<TOKEN end_char="1940" id="token-20-17" morph="none" pos="word" start_char="1933">antibody</TOKEN>
<TOKEN end_char="1948" id="token-20-18" morph="none" pos="word" start_char="1942">studies</TOKEN>
<TOKEN end_char="1949" id="token-20-19" morph="none" pos="punct" start_char="1949">.</TOKEN>
</SEG>
<SEG end_char="2088" id="segment-21" start_char="1951">
<ORIGINAL_TEXT>In the past, they have considered this fluffy test, riddled with unknowns, as the only way to determine whether a person is immune or not.</ORIGINAL_TEXT>
<TOKEN end_char="1952" id="token-21-0" morph="none" pos="word" start_char="1951">In</TOKEN>
<TOKEN end_char="1956" id="token-21-1" morph="none" pos="word" start_char="1954">the</TOKEN>
<TOKEN end_char="1961" id="token-21-2" morph="none" pos="word" start_char="1958">past</TOKEN>
<TOKEN end_char="1962" id="token-21-3" morph="none" pos="punct" start_char="1962">,</TOKEN>
<TOKEN end_char="1967" id="token-21-4" morph="none" pos="word" start_char="1964">they</TOKEN>
<TOKEN end_char="1972" id="token-21-5" morph="none" pos="word" start_char="1969">have</TOKEN>
<TOKEN end_char="1983" id="token-21-6" morph="none" pos="word" start_char="1974">considered</TOKEN>
<TOKEN end_char="1988" id="token-21-7" morph="none" pos="word" start_char="1985">this</TOKEN>
<TOKEN end_char="1995" id="token-21-8" morph="none" pos="word" start_char="1990">fluffy</TOKEN>
<TOKEN end_char="2000" id="token-21-9" morph="none" pos="word" start_char="1997">test</TOKEN>
<TOKEN end_char="2001" id="token-21-10" morph="none" pos="punct" start_char="2001">,</TOKEN>
<TOKEN end_char="2009" id="token-21-11" morph="none" pos="word" start_char="2003">riddled</TOKEN>
<TOKEN end_char="2014" id="token-21-12" morph="none" pos="word" start_char="2011">with</TOKEN>
<TOKEN end_char="2023" id="token-21-13" morph="none" pos="word" start_char="2016">unknowns</TOKEN>
<TOKEN end_char="2024" id="token-21-14" morph="none" pos="punct" start_char="2024">,</TOKEN>
<TOKEN end_char="2027" id="token-21-15" morph="none" pos="word" start_char="2026">as</TOKEN>
<TOKEN end_char="2031" id="token-21-16" morph="none" pos="word" start_char="2029">the</TOKEN>
<TOKEN end_char="2036" id="token-21-17" morph="none" pos="word" start_char="2033">only</TOKEN>
<TOKEN end_char="2040" id="token-21-18" morph="none" pos="word" start_char="2038">way</TOKEN>
<TOKEN end_char="2043" id="token-21-19" morph="none" pos="word" start_char="2042">to</TOKEN>
<TOKEN end_char="2053" id="token-21-20" morph="none" pos="word" start_char="2045">determine</TOKEN>
<TOKEN end_char="2061" id="token-21-21" morph="none" pos="word" start_char="2055">whether</TOKEN>
<TOKEN end_char="2063" id="token-21-22" morph="none" pos="word" start_char="2063">a</TOKEN>
<TOKEN end_char="2070" id="token-21-23" morph="none" pos="word" start_char="2065">person</TOKEN>
<TOKEN end_char="2073" id="token-21-24" morph="none" pos="word" start_char="2072">is</TOKEN>
<TOKEN end_char="2080" id="token-21-25" morph="none" pos="word" start_char="2075">immune</TOKEN>
<TOKEN end_char="2083" id="token-21-26" morph="none" pos="word" start_char="2082">or</TOKEN>
<TOKEN end_char="2087" id="token-21-27" morph="none" pos="word" start_char="2085">not</TOKEN>
<TOKEN end_char="2088" id="token-21-28" morph="none" pos="punct" start_char="2088">.</TOKEN>
</SEG>
<SEG end_char="2200" id="segment-22" start_char="2090">
<ORIGINAL_TEXT>But their lack of interest in T cell immunity doesn’t mean that many top scientists haven’t been discussing it.</ORIGINAL_TEXT>
<TOKEN end_char="2092" id="token-22-0" morph="none" pos="word" start_char="2090">But</TOKEN>
<TOKEN end_char="2098" id="token-22-1" morph="none" pos="word" start_char="2094">their</TOKEN>
<TOKEN end_char="2103" id="token-22-2" morph="none" pos="word" start_char="2100">lack</TOKEN>
<TOKEN end_char="2106" id="token-22-3" morph="none" pos="word" start_char="2105">of</TOKEN>
<TOKEN end_char="2115" id="token-22-4" morph="none" pos="word" start_char="2108">interest</TOKEN>
<TOKEN end_char="2118" id="token-22-5" morph="none" pos="word" start_char="2117">in</TOKEN>
<TOKEN end_char="2120" id="token-22-6" morph="none" pos="word" start_char="2120">T</TOKEN>
<TOKEN end_char="2125" id="token-22-7" morph="none" pos="word" start_char="2122">cell</TOKEN>
<TOKEN end_char="2134" id="token-22-8" morph="none" pos="word" start_char="2127">immunity</TOKEN>
<TOKEN end_char="2142" id="token-22-9" morph="none" pos="word" start_char="2136">doesn’t</TOKEN>
<TOKEN end_char="2147" id="token-22-10" morph="none" pos="word" start_char="2144">mean</TOKEN>
<TOKEN end_char="2152" id="token-22-11" morph="none" pos="word" start_char="2149">that</TOKEN>
<TOKEN end_char="2157" id="token-22-12" morph="none" pos="word" start_char="2154">many</TOKEN>
<TOKEN end_char="2161" id="token-22-13" morph="none" pos="word" start_char="2159">top</TOKEN>
<TOKEN end_char="2172" id="token-22-14" morph="none" pos="word" start_char="2163">scientists</TOKEN>
<TOKEN end_char="2180" id="token-22-15" morph="none" pos="word" start_char="2174">haven’t</TOKEN>
<TOKEN end_char="2185" id="token-22-16" morph="none" pos="word" start_char="2182">been</TOKEN>
<TOKEN end_char="2196" id="token-22-17" morph="none" pos="word" start_char="2187">discussing</TOKEN>
<TOKEN end_char="2199" id="token-22-18" morph="none" pos="word" start_char="2198">it</TOKEN>
<TOKEN end_char="2200" id="token-22-19" morph="none" pos="punct" start_char="2200">.</TOKEN>
</SEG>
<SEG end_char="2436" id="segment-23" start_char="2203">
<ORIGINAL_TEXT>For instance, in an interview last month with James Delingpole, the outspoken Dr Mike Yeadon, a staunch opponent of the prevailing Covid strategy, gave an in-depth account of why the absence of antibodies does not imply vulnerability.</ORIGINAL_TEXT>
<TOKEN end_char="2205" id="token-23-0" morph="none" pos="word" start_char="2203">For</TOKEN>
<TOKEN end_char="2214" id="token-23-1" morph="none" pos="word" start_char="2207">instance</TOKEN>
<TOKEN end_char="2215" id="token-23-2" morph="none" pos="punct" start_char="2215">,</TOKEN>
<TOKEN end_char="2218" id="token-23-3" morph="none" pos="word" start_char="2217">in</TOKEN>
<TOKEN end_char="2221" id="token-23-4" morph="none" pos="word" start_char="2220">an</TOKEN>
<TOKEN end_char="2231" id="token-23-5" morph="none" pos="word" start_char="2223">interview</TOKEN>
<TOKEN end_char="2236" id="token-23-6" morph="none" pos="word" start_char="2233">last</TOKEN>
<TOKEN end_char="2242" id="token-23-7" morph="none" pos="word" start_char="2238">month</TOKEN>
<TOKEN end_char="2247" id="token-23-8" morph="none" pos="word" start_char="2244">with</TOKEN>
<TOKEN end_char="2253" id="token-23-9" morph="none" pos="word" start_char="2249">James</TOKEN>
<TOKEN end_char="2264" id="token-23-10" morph="none" pos="word" start_char="2255">Delingpole</TOKEN>
<TOKEN end_char="2265" id="token-23-11" morph="none" pos="punct" start_char="2265">,</TOKEN>
<TOKEN end_char="2269" id="token-23-12" morph="none" pos="word" start_char="2267">the</TOKEN>
<TOKEN end_char="2279" id="token-23-13" morph="none" pos="word" start_char="2271">outspoken</TOKEN>
<TOKEN end_char="2282" id="token-23-14" morph="none" pos="word" start_char="2281">Dr</TOKEN>
<TOKEN end_char="2287" id="token-23-15" morph="none" pos="word" start_char="2284">Mike</TOKEN>
<TOKEN end_char="2294" id="token-23-16" morph="none" pos="word" start_char="2289">Yeadon</TOKEN>
<TOKEN end_char="2295" id="token-23-17" morph="none" pos="punct" start_char="2295">,</TOKEN>
<TOKEN end_char="2297" id="token-23-18" morph="none" pos="word" start_char="2297">a</TOKEN>
<TOKEN end_char="2305" id="token-23-19" morph="none" pos="word" start_char="2299">staunch</TOKEN>
<TOKEN end_char="2314" id="token-23-20" morph="none" pos="word" start_char="2307">opponent</TOKEN>
<TOKEN end_char="2317" id="token-23-21" morph="none" pos="word" start_char="2316">of</TOKEN>
<TOKEN end_char="2321" id="token-23-22" morph="none" pos="word" start_char="2319">the</TOKEN>
<TOKEN end_char="2332" id="token-23-23" morph="none" pos="word" start_char="2323">prevailing</TOKEN>
<TOKEN end_char="2338" id="token-23-24" morph="none" pos="word" start_char="2334">Covid</TOKEN>
<TOKEN end_char="2347" id="token-23-25" morph="none" pos="word" start_char="2340">strategy</TOKEN>
<TOKEN end_char="2348" id="token-23-26" morph="none" pos="punct" start_char="2348">,</TOKEN>
<TOKEN end_char="2353" id="token-23-27" morph="none" pos="word" start_char="2350">gave</TOKEN>
<TOKEN end_char="2356" id="token-23-28" morph="none" pos="word" start_char="2355">an</TOKEN>
<TOKEN end_char="2365" id="token-23-29" morph="none" pos="unknown" start_char="2358">in-depth</TOKEN>
<TOKEN end_char="2373" id="token-23-30" morph="none" pos="word" start_char="2367">account</TOKEN>
<TOKEN end_char="2376" id="token-23-31" morph="none" pos="word" start_char="2375">of</TOKEN>
<TOKEN end_char="2380" id="token-23-32" morph="none" pos="word" start_char="2378">why</TOKEN>
<TOKEN end_char="2384" id="token-23-33" morph="none" pos="word" start_char="2382">the</TOKEN>
<TOKEN end_char="2392" id="token-23-34" morph="none" pos="word" start_char="2386">absence</TOKEN>
<TOKEN end_char="2395" id="token-23-35" morph="none" pos="word" start_char="2394">of</TOKEN>
<TOKEN end_char="2406" id="token-23-36" morph="none" pos="word" start_char="2397">antibodies</TOKEN>
<TOKEN end_char="2411" id="token-23-37" morph="none" pos="word" start_char="2408">does</TOKEN>
<TOKEN end_char="2415" id="token-23-38" morph="none" pos="word" start_char="2413">not</TOKEN>
<TOKEN end_char="2421" id="token-23-39" morph="none" pos="word" start_char="2417">imply</TOKEN>
<TOKEN end_char="2435" id="token-23-40" morph="none" pos="word" start_char="2423">vulnerability</TOKEN>
<TOKEN end_char="2436" id="token-23-41" morph="none" pos="punct" start_char="2436">.</TOKEN>
</SEG>
<SEG end_char="2539" id="segment-24" start_char="2438">
<ORIGINAL_TEXT>Dr Yeadon is adamant that, as with other coronaviruses, immunity to Covid lasts years, if not decades.</ORIGINAL_TEXT>
<TOKEN end_char="2439" id="token-24-0" morph="none" pos="word" start_char="2438">Dr</TOKEN>
<TOKEN end_char="2446" id="token-24-1" morph="none" pos="word" start_char="2441">Yeadon</TOKEN>
<TOKEN end_char="2449" id="token-24-2" morph="none" pos="word" start_char="2448">is</TOKEN>
<TOKEN end_char="2457" id="token-24-3" morph="none" pos="word" start_char="2451">adamant</TOKEN>
<TOKEN end_char="2462" id="token-24-4" morph="none" pos="word" start_char="2459">that</TOKEN>
<TOKEN end_char="2463" id="token-24-5" morph="none" pos="punct" start_char="2463">,</TOKEN>
<TOKEN end_char="2466" id="token-24-6" morph="none" pos="word" start_char="2465">as</TOKEN>
<TOKEN end_char="2471" id="token-24-7" morph="none" pos="word" start_char="2468">with</TOKEN>
<TOKEN end_char="2477" id="token-24-8" morph="none" pos="word" start_char="2473">other</TOKEN>
<TOKEN end_char="2491" id="token-24-9" morph="none" pos="word" start_char="2479">coronaviruses</TOKEN>
<TOKEN end_char="2492" id="token-24-10" morph="none" pos="punct" start_char="2492">,</TOKEN>
<TOKEN end_char="2501" id="token-24-11" morph="none" pos="word" start_char="2494">immunity</TOKEN>
<TOKEN end_char="2504" id="token-24-12" morph="none" pos="word" start_char="2503">to</TOKEN>
<TOKEN end_char="2510" id="token-24-13" morph="none" pos="word" start_char="2506">Covid</TOKEN>
<TOKEN end_char="2516" id="token-24-14" morph="none" pos="word" start_char="2512">lasts</TOKEN>
<TOKEN end_char="2522" id="token-24-15" morph="none" pos="word" start_char="2518">years</TOKEN>
<TOKEN end_char="2523" id="token-24-16" morph="none" pos="punct" start_char="2523">,</TOKEN>
<TOKEN end_char="2526" id="token-24-17" morph="none" pos="word" start_char="2525">if</TOKEN>
<TOKEN end_char="2530" id="token-24-18" morph="none" pos="word" start_char="2528">not</TOKEN>
<TOKEN end_char="2538" id="token-24-19" morph="none" pos="word" start_char="2532">decades</TOKEN>
<TOKEN end_char="2539" id="token-24-20" morph="none" pos="punct" start_char="2539">.</TOKEN>
</SEG>
<SEG end_char="2661" id="segment-25" start_char="2541">
<ORIGINAL_TEXT>He says there was never any reason to doubt that immunity would last this long; it is simply how our immune systems work.</ORIGINAL_TEXT>
<TOKEN end_char="2542" id="token-25-0" morph="none" pos="word" start_char="2541">He</TOKEN>
<TOKEN end_char="2547" id="token-25-1" morph="none" pos="word" start_char="2544">says</TOKEN>
<TOKEN end_char="2553" id="token-25-2" morph="none" pos="word" start_char="2549">there</TOKEN>
<TOKEN end_char="2557" id="token-25-3" morph="none" pos="word" start_char="2555">was</TOKEN>
<TOKEN end_char="2563" id="token-25-4" morph="none" pos="word" start_char="2559">never</TOKEN>
<TOKEN end_char="2567" id="token-25-5" morph="none" pos="word" start_char="2565">any</TOKEN>
<TOKEN end_char="2574" id="token-25-6" morph="none" pos="word" start_char="2569">reason</TOKEN>
<TOKEN end_char="2577" id="token-25-7" morph="none" pos="word" start_char="2576">to</TOKEN>
<TOKEN end_char="2583" id="token-25-8" morph="none" pos="word" start_char="2579">doubt</TOKEN>
<TOKEN end_char="2588" id="token-25-9" morph="none" pos="word" start_char="2585">that</TOKEN>
<TOKEN end_char="2597" id="token-25-10" morph="none" pos="word" start_char="2590">immunity</TOKEN>
<TOKEN end_char="2603" id="token-25-11" morph="none" pos="word" start_char="2599">would</TOKEN>
<TOKEN end_char="2608" id="token-25-12" morph="none" pos="word" start_char="2605">last</TOKEN>
<TOKEN end_char="2613" id="token-25-13" morph="none" pos="word" start_char="2610">this</TOKEN>
<TOKEN end_char="2618" id="token-25-14" morph="none" pos="word" start_char="2615">long</TOKEN>
<TOKEN end_char="2619" id="token-25-15" morph="none" pos="punct" start_char="2619">;</TOKEN>
<TOKEN end_char="2622" id="token-25-16" morph="none" pos="word" start_char="2621">it</TOKEN>
<TOKEN end_char="2625" id="token-25-17" morph="none" pos="word" start_char="2624">is</TOKEN>
<TOKEN end_char="2632" id="token-25-18" morph="none" pos="word" start_char="2627">simply</TOKEN>
<TOKEN end_char="2636" id="token-25-19" morph="none" pos="word" start_char="2634">how</TOKEN>
<TOKEN end_char="2640" id="token-25-20" morph="none" pos="word" start_char="2638">our</TOKEN>
<TOKEN end_char="2647" id="token-25-21" morph="none" pos="word" start_char="2642">immune</TOKEN>
<TOKEN end_char="2655" id="token-25-22" morph="none" pos="word" start_char="2649">systems</TOKEN>
<TOKEN end_char="2660" id="token-25-23" morph="none" pos="word" start_char="2657">work</TOKEN>
<TOKEN end_char="2661" id="token-25-24" morph="none" pos="punct" start_char="2661">.</TOKEN>
</SEG>
<SEG end_char="2782" id="segment-26" start_char="2664">
<ORIGINAL_TEXT>Dr Yeadon is treated as something of a crank by the scientific establishment, of course – but completely without cause.</ORIGINAL_TEXT>
<TOKEN end_char="2665" id="token-26-0" morph="none" pos="word" start_char="2664">Dr</TOKEN>
<TOKEN end_char="2672" id="token-26-1" morph="none" pos="word" start_char="2667">Yeadon</TOKEN>
<TOKEN end_char="2675" id="token-26-2" morph="none" pos="word" start_char="2674">is</TOKEN>
<TOKEN end_char="2683" id="token-26-3" morph="none" pos="word" start_char="2677">treated</TOKEN>
<TOKEN end_char="2686" id="token-26-4" morph="none" pos="word" start_char="2685">as</TOKEN>
<TOKEN end_char="2696" id="token-26-5" morph="none" pos="word" start_char="2688">something</TOKEN>
<TOKEN end_char="2699" id="token-26-6" morph="none" pos="word" start_char="2698">of</TOKEN>
<TOKEN end_char="2701" id="token-26-7" morph="none" pos="word" start_char="2701">a</TOKEN>
<TOKEN end_char="2707" id="token-26-8" morph="none" pos="word" start_char="2703">crank</TOKEN>
<TOKEN end_char="2710" id="token-26-9" morph="none" pos="word" start_char="2709">by</TOKEN>
<TOKEN end_char="2714" id="token-26-10" morph="none" pos="word" start_char="2712">the</TOKEN>
<TOKEN end_char="2725" id="token-26-11" morph="none" pos="word" start_char="2716">scientific</TOKEN>
<TOKEN end_char="2739" id="token-26-12" morph="none" pos="word" start_char="2727">establishment</TOKEN>
<TOKEN end_char="2740" id="token-26-13" morph="none" pos="punct" start_char="2740">,</TOKEN>
<TOKEN end_char="2743" id="token-26-14" morph="none" pos="word" start_char="2742">of</TOKEN>
<TOKEN end_char="2750" id="token-26-15" morph="none" pos="word" start_char="2745">course</TOKEN>
<TOKEN end_char="2752" id="token-26-16" morph="none" pos="punct" start_char="2752">–</TOKEN>
<TOKEN end_char="2756" id="token-26-17" morph="none" pos="word" start_char="2754">but</TOKEN>
<TOKEN end_char="2767" id="token-26-18" morph="none" pos="word" start_char="2758">completely</TOKEN>
<TOKEN end_char="2775" id="token-26-19" morph="none" pos="word" start_char="2769">without</TOKEN>
<TOKEN end_char="2781" id="token-26-20" morph="none" pos="word" start_char="2777">cause</TOKEN>
<TOKEN end_char="2782" id="token-26-21" morph="none" pos="punct" start_char="2782">.</TOKEN>
</SEG>
<SEG end_char="2998" id="segment-27" start_char="2784">
<ORIGINAL_TEXT>The man’s credentials are impeccable: he has a degree in biochemistry and toxicology, and a research-based PhD in respiratory pharmacology; is a former scientific adviser to Pfizer; and started his own biotech firm.</ORIGINAL_TEXT>
<TOKEN end_char="2786" id="token-27-0" morph="none" pos="word" start_char="2784">The</TOKEN>
<TOKEN end_char="2792" id="token-27-1" morph="none" pos="word" start_char="2788">man’s</TOKEN>
<TOKEN end_char="2804" id="token-27-2" morph="none" pos="word" start_char="2794">credentials</TOKEN>
<TOKEN end_char="2808" id="token-27-3" morph="none" pos="word" start_char="2806">are</TOKEN>
<TOKEN end_char="2819" id="token-27-4" morph="none" pos="word" start_char="2810">impeccable</TOKEN>
<TOKEN end_char="2820" id="token-27-5" morph="none" pos="punct" start_char="2820">:</TOKEN>
<TOKEN end_char="2823" id="token-27-6" morph="none" pos="word" start_char="2822">he</TOKEN>
<TOKEN end_char="2827" id="token-27-7" morph="none" pos="word" start_char="2825">has</TOKEN>
<TOKEN end_char="2829" id="token-27-8" morph="none" pos="word" start_char="2829">a</TOKEN>
<TOKEN end_char="2836" id="token-27-9" morph="none" pos="word" start_char="2831">degree</TOKEN>
<TOKEN end_char="2839" id="token-27-10" morph="none" pos="word" start_char="2838">in</TOKEN>
<TOKEN end_char="2852" id="token-27-11" morph="none" pos="word" start_char="2841">biochemistry</TOKEN>
<TOKEN end_char="2856" id="token-27-12" morph="none" pos="word" start_char="2854">and</TOKEN>
<TOKEN end_char="2867" id="token-27-13" morph="none" pos="word" start_char="2858">toxicology</TOKEN>
<TOKEN end_char="2868" id="token-27-14" morph="none" pos="punct" start_char="2868">,</TOKEN>
<TOKEN end_char="2872" id="token-27-15" morph="none" pos="word" start_char="2870">and</TOKEN>
<TOKEN end_char="2874" id="token-27-16" morph="none" pos="word" start_char="2874">a</TOKEN>
<TOKEN end_char="2889" id="token-27-17" morph="none" pos="unknown" start_char="2876">research-based</TOKEN>
<TOKEN end_char="2893" id="token-27-18" morph="none" pos="word" start_char="2891">PhD</TOKEN>
<TOKEN end_char="2896" id="token-27-19" morph="none" pos="word" start_char="2895">in</TOKEN>
<TOKEN end_char="2908" id="token-27-20" morph="none" pos="word" start_char="2898">respiratory</TOKEN>
<TOKEN end_char="2921" id="token-27-21" morph="none" pos="word" start_char="2910">pharmacology</TOKEN>
<TOKEN end_char="2922" id="token-27-22" morph="none" pos="punct" start_char="2922">;</TOKEN>
<TOKEN end_char="2925" id="token-27-23" morph="none" pos="word" start_char="2924">is</TOKEN>
<TOKEN end_char="2927" id="token-27-24" morph="none" pos="word" start_char="2927">a</TOKEN>
<TOKEN end_char="2934" id="token-27-25" morph="none" pos="word" start_char="2929">former</TOKEN>
<TOKEN end_char="2945" id="token-27-26" morph="none" pos="word" start_char="2936">scientific</TOKEN>
<TOKEN end_char="2953" id="token-27-27" morph="none" pos="word" start_char="2947">adviser</TOKEN>
<TOKEN end_char="2956" id="token-27-28" morph="none" pos="word" start_char="2955">to</TOKEN>
<TOKEN end_char="2963" id="token-27-29" morph="none" pos="word" start_char="2958">Pfizer</TOKEN>
<TOKEN end_char="2964" id="token-27-30" morph="none" pos="punct" start_char="2964">;</TOKEN>
<TOKEN end_char="2968" id="token-27-31" morph="none" pos="word" start_char="2966">and</TOKEN>
<TOKEN end_char="2976" id="token-27-32" morph="none" pos="word" start_char="2970">started</TOKEN>
<TOKEN end_char="2980" id="token-27-33" morph="none" pos="word" start_char="2978">his</TOKEN>
<TOKEN end_char="2984" id="token-27-34" morph="none" pos="word" start_char="2982">own</TOKEN>
<TOKEN end_char="2992" id="token-27-35" morph="none" pos="word" start_char="2986">biotech</TOKEN>
<TOKEN end_char="2997" id="token-27-36" morph="none" pos="word" start_char="2994">firm</TOKEN>
<TOKEN end_char="2998" id="token-27-37" morph="none" pos="punct" start_char="2998">.</TOKEN>
</SEG>
<SEG end_char="3089" id="segment-28" start_char="3000">
<ORIGINAL_TEXT>Thankfully, he is gaining traction among some quarters of the media now, but far too late.</ORIGINAL_TEXT>
<TOKEN end_char="3009" id="token-28-0" morph="none" pos="word" start_char="3000">Thankfully</TOKEN>
<TOKEN end_char="3010" id="token-28-1" morph="none" pos="punct" start_char="3010">,</TOKEN>
<TOKEN end_char="3013" id="token-28-2" morph="none" pos="word" start_char="3012">he</TOKEN>
<TOKEN end_char="3016" id="token-28-3" morph="none" pos="word" start_char="3015">is</TOKEN>
<TOKEN end_char="3024" id="token-28-4" morph="none" pos="word" start_char="3018">gaining</TOKEN>
<TOKEN end_char="3033" id="token-28-5" morph="none" pos="word" start_char="3026">traction</TOKEN>
<TOKEN end_char="3039" id="token-28-6" morph="none" pos="word" start_char="3035">among</TOKEN>
<TOKEN end_char="3044" id="token-28-7" morph="none" pos="word" start_char="3041">some</TOKEN>
<TOKEN end_char="3053" id="token-28-8" morph="none" pos="word" start_char="3046">quarters</TOKEN>
<TOKEN end_char="3056" id="token-28-9" morph="none" pos="word" start_char="3055">of</TOKEN>
<TOKEN end_char="3060" id="token-28-10" morph="none" pos="word" start_char="3058">the</TOKEN>
<TOKEN end_char="3066" id="token-28-11" morph="none" pos="word" start_char="3062">media</TOKEN>
<TOKEN end_char="3070" id="token-28-12" morph="none" pos="word" start_char="3068">now</TOKEN>
<TOKEN end_char="3071" id="token-28-13" morph="none" pos="punct" start_char="3071">,</TOKEN>
<TOKEN end_char="3075" id="token-28-14" morph="none" pos="word" start_char="3073">but</TOKEN>
<TOKEN end_char="3079" id="token-28-15" morph="none" pos="word" start_char="3077">far</TOKEN>
<TOKEN end_char="3083" id="token-28-16" morph="none" pos="word" start_char="3081">too</TOKEN>
<TOKEN end_char="3088" id="token-28-17" morph="none" pos="word" start_char="3085">late</TOKEN>
<TOKEN end_char="3089" id="token-28-18" morph="none" pos="punct" start_char="3089">.</TOKEN>
</SEG>
<SEG end_char="3111" id="segment-29" start_char="3092">
<ORIGINAL_TEXT>Big Pharma’s big day</ORIGINAL_TEXT>
<TOKEN end_char="3094" id="token-29-0" morph="none" pos="word" start_char="3092">Big</TOKEN>
<TOKEN end_char="3103" id="token-29-1" morph="none" pos="word" start_char="3096">Pharma’s</TOKEN>
<TOKEN end_char="3107" id="token-29-2" morph="none" pos="word" start_char="3105">big</TOKEN>
<TOKEN end_char="3111" id="token-29-3" morph="none" pos="word" start_char="3109">day</TOKEN>
<TRANSLATED_TEXT>Big Pharma's big day</TRANSLATED_TEXT><DETECTED_LANGUAGE>tl</DETECTED_LANGUAGE></SEG>
<SEG end_char="3266" id="segment-30" start_char="3115">
<ORIGINAL_TEXT>This news, if it survives the peer review process, will be grist to the mill of pharmaceutical companies and politicians, as well as many ordinary folk.</ORIGINAL_TEXT>
<TOKEN end_char="3118" id="token-30-0" morph="none" pos="word" start_char="3115">This</TOKEN>
<TOKEN end_char="3123" id="token-30-1" morph="none" pos="word" start_char="3120">news</TOKEN>
<TOKEN end_char="3124" id="token-30-2" morph="none" pos="punct" start_char="3124">,</TOKEN>
<TOKEN end_char="3127" id="token-30-3" morph="none" pos="word" start_char="3126">if</TOKEN>
<TOKEN end_char="3130" id="token-30-4" morph="none" pos="word" start_char="3129">it</TOKEN>
<TOKEN end_char="3139" id="token-30-5" morph="none" pos="word" start_char="3132">survives</TOKEN>
<TOKEN end_char="3143" id="token-30-6" morph="none" pos="word" start_char="3141">the</TOKEN>
<TOKEN end_char="3148" id="token-30-7" morph="none" pos="word" start_char="3145">peer</TOKEN>
<TOKEN end_char="3155" id="token-30-8" morph="none" pos="word" start_char="3150">review</TOKEN>
<TOKEN end_char="3163" id="token-30-9" morph="none" pos="word" start_char="3157">process</TOKEN>
<TOKEN end_char="3164" id="token-30-10" morph="none" pos="punct" start_char="3164">,</TOKEN>
<TOKEN end_char="3169" id="token-30-11" morph="none" pos="word" start_char="3166">will</TOKEN>
<TOKEN end_char="3172" id="token-30-12" morph="none" pos="word" start_char="3171">be</TOKEN>
<TOKEN end_char="3178" id="token-30-13" morph="none" pos="word" start_char="3174">grist</TOKEN>
<TOKEN end_char="3181" id="token-30-14" morph="none" pos="word" start_char="3180">to</TOKEN>
<TOKEN end_char="3185" id="token-30-15" morph="none" pos="word" start_char="3183">the</TOKEN>
<TOKEN end_char="3190" id="token-30-16" morph="none" pos="word" start_char="3187">mill</TOKEN>
<TOKEN end_char="3193" id="token-30-17" morph="none" pos="word" start_char="3192">of</TOKEN>
<TOKEN end_char="3208" id="token-30-18" morph="none" pos="word" start_char="3195">pharmaceutical</TOKEN>
<TOKEN end_char="3218" id="token-30-19" morph="none" pos="word" start_char="3210">companies</TOKEN>
<TOKEN end_char="3222" id="token-30-20" morph="none" pos="word" start_char="3220">and</TOKEN>
<TOKEN end_char="3234" id="token-30-21" morph="none" pos="word" start_char="3224">politicians</TOKEN>
<TOKEN end_char="3235" id="token-30-22" morph="none" pos="punct" start_char="3235">,</TOKEN>
<TOKEN end_char="3238" id="token-30-23" morph="none" pos="word" start_char="3237">as</TOKEN>
<TOKEN end_char="3243" id="token-30-24" morph="none" pos="word" start_char="3240">well</TOKEN>
<TOKEN end_char="3246" id="token-30-25" morph="none" pos="word" start_char="3245">as</TOKEN>
<TOKEN end_char="3251" id="token-30-26" morph="none" pos="word" start_char="3248">many</TOKEN>
<TOKEN end_char="3260" id="token-30-27" morph="none" pos="word" start_char="3253">ordinary</TOKEN>
<TOKEN end_char="3265" id="token-30-28" morph="none" pos="word" start_char="3262">folk</TOKEN>
<TOKEN end_char="3266" id="token-30-29" morph="none" pos="punct" start_char="3266">.</TOKEN>
</SEG>
<SEG end_char="3415" id="segment-31" start_char="3268">
<ORIGINAL_TEXT>It is hard to blame people for hoping for an end to this pandemic as soon as possible – even, or perhaps especially, if that means being vaccinated.</ORIGINAL_TEXT>
<TOKEN end_char="3269" id="token-31-0" morph="none" pos="word" start_char="3268">It</TOKEN>
<TOKEN end_char="3272" id="token-31-1" morph="none" pos="word" start_char="3271">is</TOKEN>
<TOKEN end_char="3277" id="token-31-2" morph="none" pos="word" start_char="3274">hard</TOKEN>
<TOKEN end_char="3280" id="token-31-3" morph="none" pos="word" start_char="3279">to</TOKEN>
<TOKEN end_char="3286" id="token-31-4" morph="none" pos="word" start_char="3282">blame</TOKEN>
<TOKEN end_char="3293" id="token-31-5" morph="none" pos="word" start_char="3288">people</TOKEN>
<TOKEN end_char="3297" id="token-31-6" morph="none" pos="word" start_char="3295">for</TOKEN>
<TOKEN end_char="3304" id="token-31-7" morph="none" pos="word" start_char="3299">hoping</TOKEN>
<TOKEN end_char="3308" id="token-31-8" morph="none" pos="word" start_char="3306">for</TOKEN>
<TOKEN end_char="3311" id="token-31-9" morph="none" pos="word" start_char="3310">an</TOKEN>
<TOKEN end_char="3315" id="token-31-10" morph="none" pos="word" start_char="3313">end</TOKEN>
<TOKEN end_char="3318" id="token-31-11" morph="none" pos="word" start_char="3317">to</TOKEN>
<TOKEN end_char="3323" id="token-31-12" morph="none" pos="word" start_char="3320">this</TOKEN>
<TOKEN end_char="3332" id="token-31-13" morph="none" pos="word" start_char="3325">pandemic</TOKEN>
<TOKEN end_char="3335" id="token-31-14" morph="none" pos="word" start_char="3334">as</TOKEN>
<TOKEN end_char="3340" id="token-31-15" morph="none" pos="word" start_char="3337">soon</TOKEN>
<TOKEN end_char="3343" id="token-31-16" morph="none" pos="word" start_char="3342">as</TOKEN>
<TOKEN end_char="3352" id="token-31-17" morph="none" pos="word" start_char="3345">possible</TOKEN>
<TOKEN end_char="3354" id="token-31-18" morph="none" pos="punct" start_char="3354">–</TOKEN>
<TOKEN end_char="3359" id="token-31-19" morph="none" pos="word" start_char="3356">even</TOKEN>
<TOKEN end_char="3360" id="token-31-20" morph="none" pos="punct" start_char="3360">,</TOKEN>
<TOKEN end_char="3363" id="token-31-21" morph="none" pos="word" start_char="3362">or</TOKEN>
<TOKEN end_char="3371" id="token-31-22" morph="none" pos="word" start_char="3365">perhaps</TOKEN>
<TOKEN end_char="3382" id="token-31-23" morph="none" pos="word" start_char="3373">especially</TOKEN>
<TOKEN end_char="3383" id="token-31-24" morph="none" pos="punct" start_char="3383">,</TOKEN>
<TOKEN end_char="3386" id="token-31-25" morph="none" pos="word" start_char="3385">if</TOKEN>
<TOKEN end_char="3391" id="token-31-26" morph="none" pos="word" start_char="3388">that</TOKEN>
<TOKEN end_char="3397" id="token-31-27" morph="none" pos="word" start_char="3393">means</TOKEN>
<TOKEN end_char="3403" id="token-31-28" morph="none" pos="word" start_char="3399">being</TOKEN>
<TOKEN end_char="3414" id="token-31-29" morph="none" pos="word" start_char="3405">vaccinated</TOKEN>
<TOKEN end_char="3415" id="token-31-30" morph="none" pos="punct" start_char="3415">.</TOKEN>
</SEG>
<SEG end_char="3552" id="segment-32" start_char="3417">
<ORIGINAL_TEXT>Immunity lasting years means an initial population-wide rollout would justify a full return to normality (at least, one would think so).</ORIGINAL_TEXT>
<TOKEN end_char="3424" id="token-32-0" morph="none" pos="word" start_char="3417">Immunity</TOKEN>
<TOKEN end_char="3432" id="token-32-1" morph="none" pos="word" start_char="3426">lasting</TOKEN>
<TOKEN end_char="3438" id="token-32-2" morph="none" pos="word" start_char="3434">years</TOKEN>
<TOKEN end_char="3444" id="token-32-3" morph="none" pos="word" start_char="3440">means</TOKEN>
<TOKEN end_char="3447" id="token-32-4" morph="none" pos="word" start_char="3446">an</TOKEN>
<TOKEN end_char="3455" id="token-32-5" morph="none" pos="word" start_char="3449">initial</TOKEN>
<TOKEN end_char="3471" id="token-32-6" morph="none" pos="unknown" start_char="3457">population-wide</TOKEN>
<TOKEN end_char="3479" id="token-32-7" morph="none" pos="word" start_char="3473">rollout</TOKEN>
<TOKEN end_char="3485" id="token-32-8" morph="none" pos="word" start_char="3481">would</TOKEN>
<TOKEN end_char="3493" id="token-32-9" morph="none" pos="word" start_char="3487">justify</TOKEN>
<TOKEN end_char="3495" id="token-32-10" morph="none" pos="word" start_char="3495">a</TOKEN>
<TOKEN end_char="3500" id="token-32-11" morph="none" pos="word" start_char="3497">full</TOKEN>
<TOKEN end_char="3507" id="token-32-12" morph="none" pos="word" start_char="3502">return</TOKEN>
<TOKEN end_char="3510" id="token-32-13" morph="none" pos="word" start_char="3509">to</TOKEN>
<TOKEN end_char="3520" id="token-32-14" morph="none" pos="word" start_char="3512">normality</TOKEN>
<TOKEN end_char="3522" id="token-32-15" morph="none" pos="punct" start_char="3522">(</TOKEN>
<TOKEN end_char="3524" id="token-32-16" morph="none" pos="word" start_char="3523">at</TOKEN>
<TOKEN end_char="3530" id="token-32-17" morph="none" pos="word" start_char="3526">least</TOKEN>
<TOKEN end_char="3531" id="token-32-18" morph="none" pos="punct" start_char="3531">,</TOKEN>
<TOKEN end_char="3535" id="token-32-19" morph="none" pos="word" start_char="3533">one</TOKEN>
<TOKEN end_char="3541" id="token-32-20" morph="none" pos="word" start_char="3537">would</TOKEN>
<TOKEN end_char="3547" id="token-32-21" morph="none" pos="word" start_char="3543">think</TOKEN>
<TOKEN end_char="3550" id="token-32-22" morph="none" pos="word" start_char="3549">so</TOKEN>
<TOKEN end_char="3552" id="token-32-23" morph="none" pos="punct" start_char="3551">).</TOKEN>
</SEG>
<SEG end_char="3704" id="segment-33" start_char="3554">
<ORIGINAL_TEXT>If, as was feared until now, boosters were required after only a few months, it would cast major doubt on mass vaccination being the route out of this.</ORIGINAL_TEXT>
<TOKEN end_char="3555" id="token-33-0" morph="none" pos="word" start_char="3554">If</TOKEN>
<TOKEN end_char="3556" id="token-33-1" morph="none" pos="punct" start_char="3556">,</TOKEN>
<TOKEN end_char="3559" id="token-33-2" morph="none" pos="word" start_char="3558">as</TOKEN>
<TOKEN end_char="3563" id="token-33-3" morph="none" pos="word" start_char="3561">was</TOKEN>
<TOKEN end_char="3570" id="token-33-4" morph="none" pos="word" start_char="3565">feared</TOKEN>
<TOKEN end_char="3576" id="token-33-5" morph="none" pos="word" start_char="3572">until</TOKEN>
<TOKEN end_char="3580" id="token-33-6" morph="none" pos="word" start_char="3578">now</TOKEN>
<TOKEN end_char="3581" id="token-33-7" morph="none" pos="punct" start_char="3581">,</TOKEN>
<TOKEN end_char="3590" id="token-33-8" morph="none" pos="word" start_char="3583">boosters</TOKEN>
<TOKEN end_char="3595" id="token-33-9" morph="none" pos="word" start_char="3592">were</TOKEN>
<TOKEN end_char="3604" id="token-33-10" morph="none" pos="word" start_char="3597">required</TOKEN>
<TOKEN end_char="3610" id="token-33-11" morph="none" pos="word" start_char="3606">after</TOKEN>
<TOKEN end_char="3615" id="token-33-12" morph="none" pos="word" start_char="3612">only</TOKEN>
<TOKEN end_char="3617" id="token-33-13" morph="none" pos="word" start_char="3617">a</TOKEN>
<TOKEN end_char="3621" id="token-33-14" morph="none" pos="word" start_char="3619">few</TOKEN>
<TOKEN end_char="3628" id="token-33-15" morph="none" pos="word" start_char="3623">months</TOKEN>
<TOKEN end_char="3629" id="token-33-16" morph="none" pos="punct" start_char="3629">,</TOKEN>
<TOKEN end_char="3632" id="token-33-17" morph="none" pos="word" start_char="3631">it</TOKEN>
<TOKEN end_char="3638" id="token-33-18" morph="none" pos="word" start_char="3634">would</TOKEN>
<TOKEN end_char="3643" id="token-33-19" morph="none" pos="word" start_char="3640">cast</TOKEN>
<TOKEN end_char="3649" id="token-33-20" morph="none" pos="word" start_char="3645">major</TOKEN>
<TOKEN end_char="3655" id="token-33-21" morph="none" pos="word" start_char="3651">doubt</TOKEN>
<TOKEN end_char="3658" id="token-33-22" morph="none" pos="word" start_char="3657">on</TOKEN>
<TOKEN end_char="3663" id="token-33-23" morph="none" pos="word" start_char="3660">mass</TOKEN>
<TOKEN end_char="3675" id="token-33-24" morph="none" pos="word" start_char="3665">vaccination</TOKEN>
<TOKEN end_char="3681" id="token-33-25" morph="none" pos="word" start_char="3677">being</TOKEN>
<TOKEN end_char="3685" id="token-33-26" morph="none" pos="word" start_char="3683">the</TOKEN>
<TOKEN end_char="3691" id="token-33-27" morph="none" pos="word" start_char="3687">route</TOKEN>
<TOKEN end_char="3695" id="token-33-28" morph="none" pos="word" start_char="3693">out</TOKEN>
<TOKEN end_char="3698" id="token-33-29" morph="none" pos="word" start_char="3697">of</TOKEN>
<TOKEN end_char="3703" id="token-33-30" morph="none" pos="word" start_char="3700">this</TOKEN>
<TOKEN end_char="3704" id="token-33-31" morph="none" pos="punct" start_char="3704">.</TOKEN>
</SEG>
<SEG end_char="3812" id="segment-34" start_char="3707">
<ORIGINAL_TEXT>Plans on ice: Freezers logistics are the reasons Pfizer's vaccine is all hype, and won’t be a magic bullet</ORIGINAL_TEXT>
<TOKEN end_char="3711" id="token-34-0" morph="none" pos="word" start_char="3707">Plans</TOKEN>
<TOKEN end_char="3714" id="token-34-1" morph="none" pos="word" start_char="3713">on</TOKEN>
<TOKEN end_char="3718" id="token-34-2" morph="none" pos="word" start_char="3716">ice</TOKEN>
<TOKEN end_char="3719" id="token-34-3" morph="none" pos="punct" start_char="3719">:</TOKEN>
<TOKEN end_char="3728" id="token-34-4" morph="none" pos="word" start_char="3721">Freezers</TOKEN>
<TOKEN end_char="3738" id="token-34-5" morph="none" pos="word" start_char="3730">logistics</TOKEN>
<TOKEN end_char="3742" id="token-34-6" morph="none" pos="word" start_char="3740">are</TOKEN>
<TOKEN end_char="3746" id="token-34-7" morph="none" pos="word" start_char="3744">the</TOKEN>
<TOKEN end_char="3754" id="token-34-8" morph="none" pos="word" start_char="3748">reasons</TOKEN>
<TOKEN end_char="3763" id="token-34-9" morph="none" pos="word" start_char="3756">Pfizer's</TOKEN>
<TOKEN end_char="3771" id="token-34-10" morph="none" pos="word" start_char="3765">vaccine</TOKEN>
<TOKEN end_char="3774" id="token-34-11" morph="none" pos="word" start_char="3773">is</TOKEN>
<TOKEN end_char="3778" id="token-34-12" morph="none" pos="word" start_char="3776">all</TOKEN>
<TOKEN end_char="3783" id="token-34-13" morph="none" pos="word" start_char="3780">hype</TOKEN>
<TOKEN end_char="3784" id="token-34-14" morph="none" pos="punct" start_char="3784">,</TOKEN>
<TOKEN end_char="3788" id="token-34-15" morph="none" pos="word" start_char="3786">and</TOKEN>
<TOKEN end_char="3794" id="token-34-16" morph="none" pos="word" start_char="3790">won’t</TOKEN>
<TOKEN end_char="3797" id="token-34-17" morph="none" pos="word" start_char="3796">be</TOKEN>
<TOKEN end_char="3799" id="token-34-18" morph="none" pos="word" start_char="3799">a</TOKEN>
<TOKEN end_char="3805" id="token-34-19" morph="none" pos="word" start_char="3801">magic</TOKEN>
<TOKEN end_char="3812" id="token-34-20" morph="none" pos="word" start_char="3807">bullet</TOKEN>
</SEG>
<SEG end_char="4020" id="segment-35" start_char="3815">
<ORIGINAL_TEXT>In fact, if one were being very cynical, one might marvel at the timing of these studies showing T cell immunity, just as we are inundated with proclamations of the first vaccines showing promising results.</ORIGINAL_TEXT>
<TOKEN end_char="3816" id="token-35-0" morph="none" pos="word" start_char="3815">In</TOKEN>
<TOKEN end_char="3821" id="token-35-1" morph="none" pos="word" start_char="3818">fact</TOKEN>
<TOKEN end_char="3822" id="token-35-2" morph="none" pos="punct" start_char="3822">,</TOKEN>
<TOKEN end_char="3825" id="token-35-3" morph="none" pos="word" start_char="3824">if</TOKEN>
<TOKEN end_char="3829" id="token-35-4" morph="none" pos="word" start_char="3827">one</TOKEN>
<TOKEN end_char="3834" id="token-35-5" morph="none" pos="word" start_char="3831">were</TOKEN>
<TOKEN end_char="3840" id="token-35-6" morph="none" pos="word" start_char="3836">being</TOKEN>
<TOKEN end_char="3845" id="token-35-7" morph="none" pos="word" start_char="3842">very</TOKEN>
<TOKEN end_char="3853" id="token-35-8" morph="none" pos="word" start_char="3847">cynical</TOKEN>
<TOKEN end_char="3854" id="token-35-9" morph="none" pos="punct" start_char="3854">,</TOKEN>
<TOKEN end_char="3858" id="token-35-10" morph="none" pos="word" start_char="3856">one</TOKEN>
<TOKEN end_char="3864" id="token-35-11" morph="none" pos="word" start_char="3860">might</TOKEN>
<TOKEN end_char="3871" id="token-35-12" morph="none" pos="word" start_char="3866">marvel</TOKEN>
<TOKEN end_char="3874" id="token-35-13" morph="none" pos="word" start_char="3873">at</TOKEN>
<TOKEN end_char="3878" id="token-35-14" morph="none" pos="word" start_char="3876">the</TOKEN>
<TOKEN end_char="3885" id="token-35-15" morph="none" pos="word" start_char="3880">timing</TOKEN>
<TOKEN end_char="3888" id="token-35-16" morph="none" pos="word" start_char="3887">of</TOKEN>
<TOKEN end_char="3894" id="token-35-17" morph="none" pos="word" start_char="3890">these</TOKEN>
<TOKEN end_char="3902" id="token-35-18" morph="none" pos="word" start_char="3896">studies</TOKEN>
<TOKEN end_char="3910" id="token-35-19" morph="none" pos="word" start_char="3904">showing</TOKEN>
<TOKEN end_char="3912" id="token-35-20" morph="none" pos="word" start_char="3912">T</TOKEN>
<TOKEN end_char="3917" id="token-35-21" morph="none" pos="word" start_char="3914">cell</TOKEN>
<TOKEN end_char="3926" id="token-35-22" morph="none" pos="word" start_char="3919">immunity</TOKEN>
<TOKEN end_char="3927" id="token-35-23" morph="none" pos="punct" start_char="3927">,</TOKEN>
<TOKEN end_char="3932" id="token-35-24" morph="none" pos="word" start_char="3929">just</TOKEN>
<TOKEN end_char="3935" id="token-35-25" morph="none" pos="word" start_char="3934">as</TOKEN>
<TOKEN end_char="3938" id="token-35-26" morph="none" pos="word" start_char="3937">we</TOKEN>
<TOKEN end_char="3942" id="token-35-27" morph="none" pos="word" start_char="3940">are</TOKEN>
<TOKEN end_char="3952" id="token-35-28" morph="none" pos="word" start_char="3944">inundated</TOKEN>
<TOKEN end_char="3957" id="token-35-29" morph="none" pos="word" start_char="3954">with</TOKEN>
<TOKEN end_char="3971" id="token-35-30" morph="none" pos="word" start_char="3959">proclamations</TOKEN>
<TOKEN end_char="3974" id="token-35-31" morph="none" pos="word" start_char="3973">of</TOKEN>
<TOKEN end_char="3978" id="token-35-32" morph="none" pos="word" start_char="3976">the</TOKEN>
<TOKEN end_char="3984" id="token-35-33" morph="none" pos="word" start_char="3980">first</TOKEN>
<TOKEN end_char="3993" id="token-35-34" morph="none" pos="word" start_char="3986">vaccines</TOKEN>
<TOKEN end_char="4001" id="token-35-35" morph="none" pos="word" start_char="3995">showing</TOKEN>
<TOKEN end_char="4011" id="token-35-36" morph="none" pos="word" start_char="4003">promising</TOKEN>
<TOKEN end_char="4019" id="token-35-37" morph="none" pos="word" start_char="4013">results</TOKEN>
<TOKEN end_char="4020" id="token-35-38" morph="none" pos="punct" start_char="4020">.</TOKEN>
</SEG>
<SEG end_char="4230" id="segment-36" start_char="4022">
<ORIGINAL_TEXT>The notion that only antibodies correspond to immunity has never been widely held by any scientists, but you wouldn’t think that, if you’d witnessed the past nine months of public relations and media coverage.</ORIGINAL_TEXT>
<TOKEN end_char="4024" id="token-36-0" morph="none" pos="word" start_char="4022">The</TOKEN>
<TOKEN end_char="4031" id="token-36-1" morph="none" pos="word" start_char="4026">notion</TOKEN>
<TOKEN end_char="4036" id="token-36-2" morph="none" pos="word" start_char="4033">that</TOKEN>
<TOKEN end_char="4041" id="token-36-3" morph="none" pos="word" start_char="4038">only</TOKEN>
<TOKEN end_char="4052" id="token-36-4" morph="none" pos="word" start_char="4043">antibodies</TOKEN>
<TOKEN end_char="4063" id="token-36-5" morph="none" pos="word" start_char="4054">correspond</TOKEN>
<TOKEN end_char="4066" id="token-36-6" morph="none" pos="word" start_char="4065">to</TOKEN>
<TOKEN end_char="4075" id="token-36-7" morph="none" pos="word" start_char="4068">immunity</TOKEN>
<TOKEN end_char="4079" id="token-36-8" morph="none" pos="word" start_char="4077">has</TOKEN>
<TOKEN end_char="4085" id="token-36-9" morph="none" pos="word" start_char="4081">never</TOKEN>
<TOKEN end_char="4090" id="token-36-10" morph="none" pos="word" start_char="4087">been</TOKEN>
<TOKEN end_char="4097" id="token-36-11" morph="none" pos="word" start_char="4092">widely</TOKEN>
<TOKEN end_char="4102" id="token-36-12" morph="none" pos="word" start_char="4099">held</TOKEN>
<TOKEN end_char="4105" id="token-36-13" morph="none" pos="word" start_char="4104">by</TOKEN>
<TOKEN end_char="4109" id="token-36-14" morph="none" pos="word" start_char="4107">any</TOKEN>
<TOKEN end_char="4120" id="token-36-15" morph="none" pos="word" start_char="4111">scientists</TOKEN>
<TOKEN end_char="4121" id="token-36-16" morph="none" pos="punct" start_char="4121">,</TOKEN>
<TOKEN end_char="4125" id="token-36-17" morph="none" pos="word" start_char="4123">but</TOKEN>
<TOKEN end_char="4129" id="token-36-18" morph="none" pos="word" start_char="4127">you</TOKEN>
<TOKEN end_char="4138" id="token-36-19" morph="none" pos="word" start_char="4131">wouldn’t</TOKEN>
<TOKEN end_char="4144" id="token-36-20" morph="none" pos="word" start_char="4140">think</TOKEN>
<TOKEN end_char="4149" id="token-36-21" morph="none" pos="word" start_char="4146">that</TOKEN>
<TOKEN end_char="4150" id="token-36-22" morph="none" pos="punct" start_char="4150">,</TOKEN>
<TOKEN end_char="4153" id="token-36-23" morph="none" pos="word" start_char="4152">if</TOKEN>
<TOKEN end_char="4159" id="token-36-24" morph="none" pos="word" start_char="4155">you’d</TOKEN>
<TOKEN end_char="4169" id="token-36-25" morph="none" pos="word" start_char="4161">witnessed</TOKEN>
<TOKEN end_char="4173" id="token-36-26" morph="none" pos="word" start_char="4171">the</TOKEN>
<TOKEN end_char="4178" id="token-36-27" morph="none" pos="word" start_char="4175">past</TOKEN>
<TOKEN end_char="4183" id="token-36-28" morph="none" pos="word" start_char="4180">nine</TOKEN>
<TOKEN end_char="4190" id="token-36-29" morph="none" pos="word" start_char="4185">months</TOKEN>
<TOKEN end_char="4193" id="token-36-30" morph="none" pos="word" start_char="4192">of</TOKEN>
<TOKEN end_char="4200" id="token-36-31" morph="none" pos="word" start_char="4195">public</TOKEN>
<TOKEN end_char="4210" id="token-36-32" morph="none" pos="word" start_char="4202">relations</TOKEN>
<TOKEN end_char="4214" id="token-36-33" morph="none" pos="word" start_char="4212">and</TOKEN>
<TOKEN end_char="4220" id="token-36-34" morph="none" pos="word" start_char="4216">media</TOKEN>
<TOKEN end_char="4229" id="token-36-35" morph="none" pos="word" start_char="4222">coverage</TOKEN>
<TOKEN end_char="4230" id="token-36-36" morph="none" pos="punct" start_char="4230">.</TOKEN>
</SEG>
<SEG end_char="4353" id="segment-37" start_char="4233">
<ORIGINAL_TEXT>In any case, it looks as though the Pfizers and Modernas of this world got the results they needed when they needed them.</ORIGINAL_TEXT>
<TOKEN end_char="4234" id="token-37-0" morph="none" pos="word" start_char="4233">In</TOKEN>
<TOKEN end_char="4238" id="token-37-1" morph="none" pos="word" start_char="4236">any</TOKEN>
<TOKEN end_char="4243" id="token-37-2" morph="none" pos="word" start_char="4240">case</TOKEN>
<TOKEN end_char="4244" id="token-37-3" morph="none" pos="punct" start_char="4244">,</TOKEN>
<TOKEN end_char="4247" id="token-37-4" morph="none" pos="word" start_char="4246">it</TOKEN>
<TOKEN end_char="4253" id="token-37-5" morph="none" pos="word" start_char="4249">looks</TOKEN>
<TOKEN end_char="4256" id="token-37-6" morph="none" pos="word" start_char="4255">as</TOKEN>
<TOKEN end_char="4263" id="token-37-7" morph="none" pos="word" start_char="4258">though</TOKEN>
<TOKEN end_char="4267" id="token-37-8" morph="none" pos="word" start_char="4265">the</TOKEN>
<TOKEN end_char="4275" id="token-37-9" morph="none" pos="word" start_char="4269">Pfizers</TOKEN>
<TOKEN end_char="4279" id="token-37-10" morph="none" pos="word" start_char="4277">and</TOKEN>
<TOKEN end_char="4288" id="token-37-11" morph="none" pos="word" start_char="4281">Modernas</TOKEN>
<TOKEN end_char="4291" id="token-37-12" morph="none" pos="word" start_char="4290">of</TOKEN>
<TOKEN end_char="4296" id="token-37-13" morph="none" pos="word" start_char="4293">this</TOKEN>
<TOKEN end_char="4302" id="token-37-14" morph="none" pos="word" start_char="4298">world</TOKEN>
<TOKEN end_char="4306" id="token-37-15" morph="none" pos="word" start_char="4304">got</TOKEN>
<TOKEN end_char="4310" id="token-37-16" morph="none" pos="word" start_char="4308">the</TOKEN>
<TOKEN end_char="4318" id="token-37-17" morph="none" pos="word" start_char="4312">results</TOKEN>
<TOKEN end_char="4323" id="token-37-18" morph="none" pos="word" start_char="4320">they</TOKEN>
<TOKEN end_char="4330" id="token-37-19" morph="none" pos="word" start_char="4325">needed</TOKEN>
<TOKEN end_char="4335" id="token-37-20" morph="none" pos="word" start_char="4332">when</TOKEN>
<TOKEN end_char="4340" id="token-37-21" morph="none" pos="word" start_char="4337">they</TOKEN>
<TOKEN end_char="4347" id="token-37-22" morph="none" pos="word" start_char="4342">needed</TOKEN>
<TOKEN end_char="4352" id="token-37-23" morph="none" pos="word" start_char="4349">them</TOKEN>
<TOKEN end_char="4353" id="token-37-24" morph="none" pos="punct" start_char="4353">.</TOKEN>
</SEG>
<SEG end_char="4483" id="segment-38" start_char="4355">
<ORIGINAL_TEXT>Prepare for an avalanche of ‘explainers’ on how T cell immunity works, and why it’s so optimistic for the prospects of a vaccine.</ORIGINAL_TEXT>
<TOKEN end_char="4361" id="token-38-0" morph="none" pos="word" start_char="4355">Prepare</TOKEN>
<TOKEN end_char="4365" id="token-38-1" morph="none" pos="word" start_char="4363">for</TOKEN>
<TOKEN end_char="4368" id="token-38-2" morph="none" pos="word" start_char="4367">an</TOKEN>
<TOKEN end_char="4378" id="token-38-3" morph="none" pos="word" start_char="4370">avalanche</TOKEN>
<TOKEN end_char="4381" id="token-38-4" morph="none" pos="word" start_char="4380">of</TOKEN>
<TOKEN end_char="4383" id="token-38-5" morph="none" pos="punct" start_char="4383">‘</TOKEN>
<TOKEN end_char="4393" id="token-38-6" morph="none" pos="word" start_char="4384">explainers</TOKEN>
<TOKEN end_char="4394" id="token-38-7" morph="none" pos="punct" start_char="4394">’</TOKEN>
<TOKEN end_char="4397" id="token-38-8" morph="none" pos="word" start_char="4396">on</TOKEN>
<TOKEN end_char="4401" id="token-38-9" morph="none" pos="word" start_char="4399">how</TOKEN>
<TOKEN end_char="4403" id="token-38-10" morph="none" pos="word" start_char="4403">T</TOKEN>
<TOKEN end_char="4408" id="token-38-11" morph="none" pos="word" start_char="4405">cell</TOKEN>
<TOKEN end_char="4417" id="token-38-12" morph="none" pos="word" start_char="4410">immunity</TOKEN>
<TOKEN end_char="4423" id="token-38-13" morph="none" pos="word" start_char="4419">works</TOKEN>
<TOKEN end_char="4424" id="token-38-14" morph="none" pos="punct" start_char="4424">,</TOKEN>
<TOKEN end_char="4428" id="token-38-15" morph="none" pos="word" start_char="4426">and</TOKEN>
<TOKEN end_char="4432" id="token-38-16" morph="none" pos="word" start_char="4430">why</TOKEN>
<TOKEN end_char="4437" id="token-38-17" morph="none" pos="word" start_char="4434">it’s</TOKEN>
<TOKEN end_char="4440" id="token-38-18" morph="none" pos="word" start_char="4439">so</TOKEN>
<TOKEN end_char="4451" id="token-38-19" morph="none" pos="word" start_char="4442">optimistic</TOKEN>
<TOKEN end_char="4455" id="token-38-20" morph="none" pos="word" start_char="4453">for</TOKEN>
<TOKEN end_char="4459" id="token-38-21" morph="none" pos="word" start_char="4457">the</TOKEN>
<TOKEN end_char="4469" id="token-38-22" morph="none" pos="word" start_char="4461">prospects</TOKEN>
<TOKEN end_char="4472" id="token-38-23" morph="none" pos="word" start_char="4471">of</TOKEN>
<TOKEN end_char="4474" id="token-38-24" morph="none" pos="word" start_char="4474">a</TOKEN>
<TOKEN end_char="4482" id="token-38-25" morph="none" pos="word" start_char="4476">vaccine</TOKEN>
<TOKEN end_char="4483" id="token-38-26" morph="none" pos="punct" start_char="4483">.</TOKEN>
</SEG>
<SEG end_char="4666" id="segment-39" start_char="4485">
<ORIGINAL_TEXT>But if you’re hoping for a wider discussion of whether previous infection might make vaccination redundant, or whether mass T cell testing might be an option, don’t hold your breath.</ORIGINAL_TEXT>
<TOKEN end_char="4487" id="token-39-0" morph="none" pos="word" start_char="4485">But</TOKEN>
<TOKEN end_char="4490" id="token-39-1" morph="none" pos="word" start_char="4489">if</TOKEN>
<TOKEN end_char="4497" id="token-39-2" morph="none" pos="word" start_char="4492">you’re</TOKEN>
<TOKEN end_char="4504" id="token-39-3" morph="none" pos="word" start_char="4499">hoping</TOKEN>
<TOKEN end_char="4508" id="token-39-4" morph="none" pos="word" start_char="4506">for</TOKEN>
<TOKEN end_char="4510" id="token-39-5" morph="none" pos="word" start_char="4510">a</TOKEN>
<TOKEN end_char="4516" id="token-39-6" morph="none" pos="word" start_char="4512">wider</TOKEN>
<TOKEN end_char="4527" id="token-39-7" morph="none" pos="word" start_char="4518">discussion</TOKEN>
<TOKEN end_char="4530" id="token-39-8" morph="none" pos="word" start_char="4529">of</TOKEN>
<TOKEN end_char="4538" id="token-39-9" morph="none" pos="word" start_char="4532">whether</TOKEN>
<TOKEN end_char="4547" id="token-39-10" morph="none" pos="word" start_char="4540">previous</TOKEN>
<TOKEN end_char="4557" id="token-39-11" morph="none" pos="word" start_char="4549">infection</TOKEN>
<TOKEN end_char="4563" id="token-39-12" morph="none" pos="word" start_char="4559">might</TOKEN>
<TOKEN end_char="4568" id="token-39-13" morph="none" pos="word" start_char="4565">make</TOKEN>
<TOKEN end_char="4580" id="token-39-14" morph="none" pos="word" start_char="4570">vaccination</TOKEN>
<TOKEN end_char="4590" id="token-39-15" morph="none" pos="word" start_char="4582">redundant</TOKEN>
<TOKEN end_char="4591" id="token-39-16" morph="none" pos="punct" start_char="4591">,</TOKEN>
<TOKEN end_char="4594" id="token-39-17" morph="none" pos="word" start_char="4593">or</TOKEN>
<TOKEN end_char="4602" id="token-39-18" morph="none" pos="word" start_char="4596">whether</TOKEN>
<TOKEN end_char="4607" id="token-39-19" morph="none" pos="word" start_char="4604">mass</TOKEN>
<TOKEN end_char="4609" id="token-39-20" morph="none" pos="word" start_char="4609">T</TOKEN>
<TOKEN end_char="4614" id="token-39-21" morph="none" pos="word" start_char="4611">cell</TOKEN>
<TOKEN end_char="4622" id="token-39-22" morph="none" pos="word" start_char="4616">testing</TOKEN>
<TOKEN end_char="4628" id="token-39-23" morph="none" pos="word" start_char="4624">might</TOKEN>
<TOKEN end_char="4631" id="token-39-24" morph="none" pos="word" start_char="4630">be</TOKEN>
<TOKEN end_char="4634" id="token-39-25" morph="none" pos="word" start_char="4633">an</TOKEN>
<TOKEN end_char="4641" id="token-39-26" morph="none" pos="word" start_char="4636">option</TOKEN>
<TOKEN end_char="4642" id="token-39-27" morph="none" pos="punct" start_char="4642">,</TOKEN>
<TOKEN end_char="4648" id="token-39-28" morph="none" pos="word" start_char="4644">don’t</TOKEN>
<TOKEN end_char="4653" id="token-39-29" morph="none" pos="word" start_char="4650">hold</TOKEN>
<TOKEN end_char="4658" id="token-39-30" morph="none" pos="word" start_char="4655">your</TOKEN>
<TOKEN end_char="4665" id="token-39-31" morph="none" pos="word" start_char="4660">breath</TOKEN>
<TOKEN end_char="4666" id="token-39-32" morph="none" pos="punct" start_char="4666">.</TOKEN>
</SEG>
<SEG end_char="4707" id="segment-40" start_char="4669">
<ORIGINAL_TEXT>Think your friends would be interested?</ORIGINAL_TEXT>
<TOKEN end_char="4673" id="token-40-0" morph="none" pos="word" start_char="4669">Think</TOKEN>
<TOKEN end_char="4678" id="token-40-1" morph="none" pos="word" start_char="4675">your</TOKEN>
<TOKEN end_char="4686" id="token-40-2" morph="none" pos="word" start_char="4680">friends</TOKEN>
<TOKEN end_char="4692" id="token-40-3" morph="none" pos="word" start_char="4688">would</TOKEN>
<TOKEN end_char="4695" id="token-40-4" morph="none" pos="word" start_char="4694">be</TOKEN>
<TOKEN end_char="4706" id="token-40-5" morph="none" pos="word" start_char="4697">interested</TOKEN>
<TOKEN end_char="4707" id="token-40-6" morph="none" pos="punct" start_char="4707">?</TOKEN>
</SEG>
<SEG end_char="4725" id="segment-41" start_char="4709">
<ORIGINAL_TEXT>Share this story!</ORIGINAL_TEXT>
<TOKEN end_char="4713" id="token-41-0" morph="none" pos="word" start_char="4709">Share</TOKEN>
<TOKEN end_char="4718" id="token-41-1" morph="none" pos="word" start_char="4715">this</TOKEN>
<TOKEN end_char="4724" id="token-41-2" morph="none" pos="word" start_char="4720">story</TOKEN>
<TOKEN end_char="4725" id="token-41-3" morph="none" pos="punct" start_char="4725">!</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
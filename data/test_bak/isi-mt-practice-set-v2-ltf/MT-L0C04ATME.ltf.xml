<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATME" lang="spa" raw_text_char_length="3642" raw_text_md5="fcb2ca74b678a4683dcdf4b28ff53f5b" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="108" id="segment-0" start_char="1">
<ORIGINAL_TEXT>CDC: Some Americans are misusing cleaning products — including drinking them — in effort to kill coronavirus</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">CDC</TOKEN>
<TOKEN end_char="4" id="token-0-1" morph="none" pos="punct" start_char="4">:</TOKEN>
<TOKEN end_char="9" id="token-0-2" morph="none" pos="word" start_char="6">Some</TOKEN>
<TOKEN end_char="19" id="token-0-3" morph="none" pos="word" start_char="11">Americans</TOKEN>
<TOKEN end_char="23" id="token-0-4" morph="none" pos="word" start_char="21">are</TOKEN>
<TOKEN end_char="32" id="token-0-5" morph="none" pos="word" start_char="25">misusing</TOKEN>
<TOKEN end_char="41" id="token-0-6" morph="none" pos="word" start_char="34">cleaning</TOKEN>
<TOKEN end_char="50" id="token-0-7" morph="none" pos="word" start_char="43">products</TOKEN>
<TOKEN end_char="52" id="token-0-8" morph="none" pos="punct" start_char="52">—</TOKEN>
<TOKEN end_char="62" id="token-0-9" morph="none" pos="word" start_char="54">including</TOKEN>
<TOKEN end_char="71" id="token-0-10" morph="none" pos="word" start_char="64">drinking</TOKEN>
<TOKEN end_char="76" id="token-0-11" morph="none" pos="word" start_char="73">them</TOKEN>
<TOKEN end_char="78" id="token-0-12" morph="none" pos="punct" start_char="78">—</TOKEN>
<TOKEN end_char="81" id="token-0-13" morph="none" pos="word" start_char="80">in</TOKEN>
<TOKEN end_char="88" id="token-0-14" morph="none" pos="word" start_char="83">effort</TOKEN>
<TOKEN end_char="91" id="token-0-15" morph="none" pos="word" start_char="90">to</TOKEN>
<TOKEN end_char="96" id="token-0-16" morph="none" pos="word" start_char="93">kill</TOKEN>
<TOKEN end_char="108" id="token-0-17" morph="none" pos="word" start_char="98">coronavirus</TOKEN>
</SEG>
<SEG end_char="131" id="segment-1" start_char="112">
<ORIGINAL_TEXT>Who is more idiotic?</ORIGINAL_TEXT>
<TOKEN end_char="114" id="token-1-0" morph="none" pos="word" start_char="112">Who</TOKEN>
<TOKEN end_char="117" id="token-1-1" morph="none" pos="word" start_char="116">is</TOKEN>
<TOKEN end_char="122" id="token-1-2" morph="none" pos="word" start_char="119">more</TOKEN>
<TOKEN end_char="130" id="token-1-3" morph="none" pos="word" start_char="124">idiotic</TOKEN>
<TOKEN end_char="131" id="token-1-4" morph="none" pos="punct" start_char="131">?</TOKEN>
</SEG>
<SEG end_char="342" id="segment-2" start_char="133">
<ORIGINAL_TEXT>The people presenting this "scientific" report knowing it’s not done the proper scientific way or an unbelievable 20% people who cannot even read a product label little less to use what’s called a common sense.</ORIGINAL_TEXT>
<TOKEN end_char="135" id="token-2-0" morph="none" pos="word" start_char="133">The</TOKEN>
<TOKEN end_char="142" id="token-2-1" morph="none" pos="word" start_char="137">people</TOKEN>
<TOKEN end_char="153" id="token-2-2" morph="none" pos="word" start_char="144">presenting</TOKEN>
<TOKEN end_char="158" id="token-2-3" morph="none" pos="word" start_char="155">this</TOKEN>
<TOKEN end_char="160" id="token-2-4" morph="none" pos="punct" start_char="160">"</TOKEN>
<TOKEN end_char="170" id="token-2-5" morph="none" pos="word" start_char="161">scientific</TOKEN>
<TOKEN end_char="171" id="token-2-6" morph="none" pos="punct" start_char="171">"</TOKEN>
<TOKEN end_char="178" id="token-2-7" morph="none" pos="word" start_char="173">report</TOKEN>
<TOKEN end_char="186" id="token-2-8" morph="none" pos="word" start_char="180">knowing</TOKEN>
<TOKEN end_char="191" id="token-2-9" morph="none" pos="word" start_char="188">it’s</TOKEN>
<TOKEN end_char="195" id="token-2-10" morph="none" pos="word" start_char="193">not</TOKEN>
<TOKEN end_char="200" id="token-2-11" morph="none" pos="word" start_char="197">done</TOKEN>
<TOKEN end_char="204" id="token-2-12" morph="none" pos="word" start_char="202">the</TOKEN>
<TOKEN end_char="211" id="token-2-13" morph="none" pos="word" start_char="206">proper</TOKEN>
<TOKEN end_char="222" id="token-2-14" morph="none" pos="word" start_char="213">scientific</TOKEN>
<TOKEN end_char="226" id="token-2-15" morph="none" pos="word" start_char="224">way</TOKEN>
<TOKEN end_char="229" id="token-2-16" morph="none" pos="word" start_char="228">or</TOKEN>
<TOKEN end_char="232" id="token-2-17" morph="none" pos="word" start_char="231">an</TOKEN>
<TOKEN end_char="245" id="token-2-18" morph="none" pos="word" start_char="234">unbelievable</TOKEN>
<TOKEN end_char="248" id="token-2-19" morph="none" pos="word" start_char="247">20</TOKEN>
<TOKEN end_char="249" id="token-2-20" morph="none" pos="punct" start_char="249">%</TOKEN>
<TOKEN end_char="256" id="token-2-21" morph="none" pos="word" start_char="251">people</TOKEN>
<TOKEN end_char="260" id="token-2-22" morph="none" pos="word" start_char="258">who</TOKEN>
<TOKEN end_char="267" id="token-2-23" morph="none" pos="word" start_char="262">cannot</TOKEN>
<TOKEN end_char="272" id="token-2-24" morph="none" pos="word" start_char="269">even</TOKEN>
<TOKEN end_char="277" id="token-2-25" morph="none" pos="word" start_char="274">read</TOKEN>
<TOKEN end_char="279" id="token-2-26" morph="none" pos="word" start_char="279">a</TOKEN>
<TOKEN end_char="287" id="token-2-27" morph="none" pos="word" start_char="281">product</TOKEN>
<TOKEN end_char="293" id="token-2-28" morph="none" pos="word" start_char="289">label</TOKEN>
<TOKEN end_char="300" id="token-2-29" morph="none" pos="word" start_char="295">little</TOKEN>
<TOKEN end_char="305" id="token-2-30" morph="none" pos="word" start_char="302">less</TOKEN>
<TOKEN end_char="308" id="token-2-31" morph="none" pos="word" start_char="307">to</TOKEN>
<TOKEN end_char="312" id="token-2-32" morph="none" pos="word" start_char="310">use</TOKEN>
<TOKEN end_char="319" id="token-2-33" morph="none" pos="word" start_char="314">what’s</TOKEN>
<TOKEN end_char="326" id="token-2-34" morph="none" pos="word" start_char="321">called</TOKEN>
<TOKEN end_char="328" id="token-2-35" morph="none" pos="word" start_char="328">a</TOKEN>
<TOKEN end_char="335" id="token-2-36" morph="none" pos="word" start_char="330">common</TOKEN>
<TOKEN end_char="341" id="token-2-37" morph="none" pos="word" start_char="337">sense</TOKEN>
<TOKEN end_char="342" id="token-2-38" morph="none" pos="punct" start_char="342">.</TOKEN>
</SEG>
<SEG end_char="385" id="segment-3" start_char="344">
<ORIGINAL_TEXT>In any case it’s a tragedy upon a tragedy.</ORIGINAL_TEXT>
<TOKEN end_char="345" id="token-3-0" morph="none" pos="word" start_char="344">In</TOKEN>
<TOKEN end_char="349" id="token-3-1" morph="none" pos="word" start_char="347">any</TOKEN>
<TOKEN end_char="354" id="token-3-2" morph="none" pos="word" start_char="351">case</TOKEN>
<TOKEN end_char="359" id="token-3-3" morph="none" pos="word" start_char="356">it’s</TOKEN>
<TOKEN end_char="361" id="token-3-4" morph="none" pos="word" start_char="361">a</TOKEN>
<TOKEN end_char="369" id="token-3-5" morph="none" pos="word" start_char="363">tragedy</TOKEN>
<TOKEN end_char="374" id="token-3-6" morph="none" pos="word" start_char="371">upon</TOKEN>
<TOKEN end_char="376" id="token-3-7" morph="none" pos="word" start_char="376">a</TOKEN>
<TOKEN end_char="384" id="token-3-8" morph="none" pos="word" start_char="378">tragedy</TOKEN>
<TOKEN end_char="385" id="token-3-9" morph="none" pos="punct" start_char="385">.</TOKEN>
</SEG>
<SEG end_char="437" id="segment-4" start_char="389">
<ORIGINAL_TEXT>Given the politics over Trump’s bleach statement?</ORIGINAL_TEXT>
<TOKEN end_char="393" id="token-4-0" morph="none" pos="word" start_char="389">Given</TOKEN>
<TOKEN end_char="397" id="token-4-1" morph="none" pos="word" start_char="395">the</TOKEN>
<TOKEN end_char="406" id="token-4-2" morph="none" pos="word" start_char="399">politics</TOKEN>
<TOKEN end_char="411" id="token-4-3" morph="none" pos="word" start_char="408">over</TOKEN>
<TOKEN end_char="419" id="token-4-4" morph="none" pos="word" start_char="413">Trump’s</TOKEN>
<TOKEN end_char="426" id="token-4-5" morph="none" pos="word" start_char="421">bleach</TOKEN>
<TOKEN end_char="436" id="token-4-6" morph="none" pos="word" start_char="428">statement</TOKEN>
<TOKEN end_char="437" id="token-4-7" morph="none" pos="punct" start_char="437">?</TOKEN>
</SEG>
<SEG end_char="554" id="segment-5" start_char="440">
<ORIGINAL_TEXT>That 1 in 5 actually put bleach on food or that a bunch of people trolled this totally unscientific, opt-in survey?</ORIGINAL_TEXT>
<TOKEN end_char="443" id="token-5-0" morph="none" pos="word" start_char="440">That</TOKEN>
<TOKEN end_char="445" id="token-5-1" morph="none" pos="word" start_char="445">1</TOKEN>
<TOKEN end_char="448" id="token-5-2" morph="none" pos="word" start_char="447">in</TOKEN>
<TOKEN end_char="450" id="token-5-3" morph="none" pos="word" start_char="450">5</TOKEN>
<TOKEN end_char="459" id="token-5-4" morph="none" pos="word" start_char="452">actually</TOKEN>
<TOKEN end_char="463" id="token-5-5" morph="none" pos="word" start_char="461">put</TOKEN>
<TOKEN end_char="470" id="token-5-6" morph="none" pos="word" start_char="465">bleach</TOKEN>
<TOKEN end_char="473" id="token-5-7" morph="none" pos="word" start_char="472">on</TOKEN>
<TOKEN end_char="478" id="token-5-8" morph="none" pos="word" start_char="475">food</TOKEN>
<TOKEN end_char="481" id="token-5-9" morph="none" pos="word" start_char="480">or</TOKEN>
<TOKEN end_char="486" id="token-5-10" morph="none" pos="word" start_char="483">that</TOKEN>
<TOKEN end_char="488" id="token-5-11" morph="none" pos="word" start_char="488">a</TOKEN>
<TOKEN end_char="494" id="token-5-12" morph="none" pos="word" start_char="490">bunch</TOKEN>
<TOKEN end_char="497" id="token-5-13" morph="none" pos="word" start_char="496">of</TOKEN>
<TOKEN end_char="504" id="token-5-14" morph="none" pos="word" start_char="499">people</TOKEN>
<TOKEN end_char="512" id="token-5-15" morph="none" pos="word" start_char="506">trolled</TOKEN>
<TOKEN end_char="517" id="token-5-16" morph="none" pos="word" start_char="514">this</TOKEN>
<TOKEN end_char="525" id="token-5-17" morph="none" pos="word" start_char="519">totally</TOKEN>
<TOKEN end_char="538" id="token-5-18" morph="none" pos="word" start_char="527">unscientific</TOKEN>
<TOKEN end_char="539" id="token-5-19" morph="none" pos="punct" start_char="539">,</TOKEN>
<TOKEN end_char="546" id="token-5-20" morph="none" pos="unknown" start_char="541">opt-in</TOKEN>
<TOKEN end_char="553" id="token-5-21" morph="none" pos="word" start_char="548">survey</TOKEN>
<TOKEN end_char="554" id="token-5-22" morph="none" pos="punct" start_char="554">?</TOKEN>
</SEG>
<SEG end_char="638" id="segment-6" start_char="557">
<ORIGINAL_TEXT>I love StatNews, but this survey is probably as reliable and the Surgispehre data.</ORIGINAL_TEXT>
<TOKEN end_char="557" id="token-6-0" morph="none" pos="word" start_char="557">I</TOKEN>
<TOKEN end_char="562" id="token-6-1" morph="none" pos="word" start_char="559">love</TOKEN>
<TOKEN end_char="571" id="token-6-2" morph="none" pos="word" start_char="564">StatNews</TOKEN>
<TOKEN end_char="572" id="token-6-3" morph="none" pos="punct" start_char="572">,</TOKEN>
<TOKEN end_char="576" id="token-6-4" morph="none" pos="word" start_char="574">but</TOKEN>
<TOKEN end_char="581" id="token-6-5" morph="none" pos="word" start_char="578">this</TOKEN>
<TOKEN end_char="588" id="token-6-6" morph="none" pos="word" start_char="583">survey</TOKEN>
<TOKEN end_char="591" id="token-6-7" morph="none" pos="word" start_char="590">is</TOKEN>
<TOKEN end_char="600" id="token-6-8" morph="none" pos="word" start_char="593">probably</TOKEN>
<TOKEN end_char="603" id="token-6-9" morph="none" pos="word" start_char="602">as</TOKEN>
<TOKEN end_char="612" id="token-6-10" morph="none" pos="word" start_char="605">reliable</TOKEN>
<TOKEN end_char="616" id="token-6-11" morph="none" pos="word" start_char="614">and</TOKEN>
<TOKEN end_char="620" id="token-6-12" morph="none" pos="word" start_char="618">the</TOKEN>
<TOKEN end_char="632" id="token-6-13" morph="none" pos="word" start_char="622">Surgispehre</TOKEN>
<TOKEN end_char="637" id="token-6-14" morph="none" pos="word" start_char="634">data</TOKEN>
<TOKEN end_char="638" id="token-6-15" morph="none" pos="punct" start_char="638">.</TOKEN>
</SEG>
<SEG end_char="681" id="segment-7" start_char="642">
<ORIGINAL_TEXT>Another anti-Trump rubbish by "experts".</ORIGINAL_TEXT>
<TOKEN end_char="648" id="token-7-0" morph="none" pos="word" start_char="642">Another</TOKEN>
<TOKEN end_char="659" id="token-7-1" morph="none" pos="unknown" start_char="650">anti-Trump</TOKEN>
<TOKEN end_char="667" id="token-7-2" morph="none" pos="word" start_char="661">rubbish</TOKEN>
<TOKEN end_char="670" id="token-7-3" morph="none" pos="word" start_char="669">by</TOKEN>
<TOKEN end_char="672" id="token-7-4" morph="none" pos="punct" start_char="672">"</TOKEN>
<TOKEN end_char="679" id="token-7-5" morph="none" pos="word" start_char="673">experts</TOKEN>
<TOKEN end_char="681" id="token-7-6" morph="none" pos="punct" start_char="680">".</TOKEN>
</SEG>
<SEG end_char="788" id="segment-8" start_char="683">
<ORIGINAL_TEXT>Trump should tell people PhDs prevent COVID-19 and then we see if more people will enroll for PhD courses.</ORIGINAL_TEXT>
<TOKEN end_char="687" id="token-8-0" morph="none" pos="word" start_char="683">Trump</TOKEN>
<TOKEN end_char="694" id="token-8-1" morph="none" pos="word" start_char="689">should</TOKEN>
<TOKEN end_char="699" id="token-8-2" morph="none" pos="word" start_char="696">tell</TOKEN>
<TOKEN end_char="706" id="token-8-3" morph="none" pos="word" start_char="701">people</TOKEN>
<TOKEN end_char="711" id="token-8-4" morph="none" pos="word" start_char="708">PhDs</TOKEN>
<TOKEN end_char="719" id="token-8-5" morph="none" pos="word" start_char="713">prevent</TOKEN>
<TOKEN end_char="728" id="token-8-6" morph="none" pos="unknown" start_char="721">COVID-19</TOKEN>
<TOKEN end_char="732" id="token-8-7" morph="none" pos="word" start_char="730">and</TOKEN>
<TOKEN end_char="737" id="token-8-8" morph="none" pos="word" start_char="734">then</TOKEN>
<TOKEN end_char="740" id="token-8-9" morph="none" pos="word" start_char="739">we</TOKEN>
<TOKEN end_char="744" id="token-8-10" morph="none" pos="word" start_char="742">see</TOKEN>
<TOKEN end_char="747" id="token-8-11" morph="none" pos="word" start_char="746">if</TOKEN>
<TOKEN end_char="752" id="token-8-12" morph="none" pos="word" start_char="749">more</TOKEN>
<TOKEN end_char="759" id="token-8-13" morph="none" pos="word" start_char="754">people</TOKEN>
<TOKEN end_char="764" id="token-8-14" morph="none" pos="word" start_char="761">will</TOKEN>
<TOKEN end_char="771" id="token-8-15" morph="none" pos="word" start_char="766">enroll</TOKEN>
<TOKEN end_char="775" id="token-8-16" morph="none" pos="word" start_char="773">for</TOKEN>
<TOKEN end_char="779" id="token-8-17" morph="none" pos="word" start_char="777">PhD</TOKEN>
<TOKEN end_char="787" id="token-8-18" morph="none" pos="word" start_char="781">courses</TOKEN>
<TOKEN end_char="788" id="token-8-19" morph="none" pos="punct" start_char="788">.</TOKEN>
</SEG>
<SEG end_char="851" id="segment-9" start_char="791">
<ORIGINAL_TEXT>The "experts" and the media take millions of people as fools.</ORIGINAL_TEXT>
<TOKEN end_char="793" id="token-9-0" morph="none" pos="word" start_char="791">The</TOKEN>
<TOKEN end_char="795" id="token-9-1" morph="none" pos="punct" start_char="795">"</TOKEN>
<TOKEN end_char="802" id="token-9-2" morph="none" pos="word" start_char="796">experts</TOKEN>
<TOKEN end_char="803" id="token-9-3" morph="none" pos="punct" start_char="803">"</TOKEN>
<TOKEN end_char="807" id="token-9-4" morph="none" pos="word" start_char="805">and</TOKEN>
<TOKEN end_char="811" id="token-9-5" morph="none" pos="word" start_char="809">the</TOKEN>
<TOKEN end_char="817" id="token-9-6" morph="none" pos="word" start_char="813">media</TOKEN>
<TOKEN end_char="822" id="token-9-7" morph="none" pos="word" start_char="819">take</TOKEN>
<TOKEN end_char="831" id="token-9-8" morph="none" pos="word" start_char="824">millions</TOKEN>
<TOKEN end_char="834" id="token-9-9" morph="none" pos="word" start_char="833">of</TOKEN>
<TOKEN end_char="841" id="token-9-10" morph="none" pos="word" start_char="836">people</TOKEN>
<TOKEN end_char="844" id="token-9-11" morph="none" pos="word" start_char="843">as</TOKEN>
<TOKEN end_char="850" id="token-9-12" morph="none" pos="word" start_char="846">fools</TOKEN>
<TOKEN end_char="851" id="token-9-13" morph="none" pos="punct" start_char="851">.</TOKEN>
</SEG>
<SEG end_char="916" id="segment-10" start_char="855">
<ORIGINAL_TEXT>That means still there are many who listen to their president!</ORIGINAL_TEXT>
<TOKEN end_char="858" id="token-10-0" morph="none" pos="word" start_char="855">That</TOKEN>
<TOKEN end_char="864" id="token-10-1" morph="none" pos="word" start_char="860">means</TOKEN>
<TOKEN end_char="870" id="token-10-2" morph="none" pos="word" start_char="866">still</TOKEN>
<TOKEN end_char="876" id="token-10-3" morph="none" pos="word" start_char="872">there</TOKEN>
<TOKEN end_char="880" id="token-10-4" morph="none" pos="word" start_char="878">are</TOKEN>
<TOKEN end_char="885" id="token-10-5" morph="none" pos="word" start_char="882">many</TOKEN>
<TOKEN end_char="889" id="token-10-6" morph="none" pos="word" start_char="887">who</TOKEN>
<TOKEN end_char="896" id="token-10-7" morph="none" pos="word" start_char="891">listen</TOKEN>
<TOKEN end_char="899" id="token-10-8" morph="none" pos="word" start_char="898">to</TOKEN>
<TOKEN end_char="905" id="token-10-9" morph="none" pos="word" start_char="901">their</TOKEN>
<TOKEN end_char="915" id="token-10-10" morph="none" pos="word" start_char="907">president</TOKEN>
<TOKEN end_char="916" id="token-10-11" morph="none" pos="punct" start_char="916">!</TOKEN>
</SEG>
<SEG end_char="926" id="segment-11" start_char="920">
<ORIGINAL_TEXT>Shhhhh.</ORIGINAL_TEXT>
<TOKEN end_char="925" id="token-11-0" morph="none" pos="word" start_char="920">Shhhhh</TOKEN>
<TOKEN end_char="926" id="token-11-1" morph="none" pos="punct" start_char="926">.</TOKEN>
<TRANSLATED_TEXT>Shhhh..............</TRANSLATED_TEXT><DETECTED_LANGUAGE>sq</DETECTED_LANGUAGE></SEG>
<SEG end_char="942" id="segment-12" start_char="928">
<ORIGINAL_TEXT>Darwin at work!</ORIGINAL_TEXT>
<TOKEN end_char="933" id="token-12-0" morph="none" pos="word" start_char="928">Darwin</TOKEN>
<TOKEN end_char="936" id="token-12-1" morph="none" pos="word" start_char="935">at</TOKEN>
<TOKEN end_char="941" id="token-12-2" morph="none" pos="word" start_char="938">work</TOKEN>
<TOKEN end_char="942" id="token-12-3" morph="none" pos="punct" start_char="942">!</TOKEN>
<TRANSLATED_TEXT>Darwin at Work!</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="1061" id="segment-13" start_char="946">
<ORIGINAL_TEXT>"Thirty-nine percent had misused the cleaning products" – so about the same percentage that voted for Trump in 2016.</ORIGINAL_TEXT>
<TOKEN end_char="946" id="token-13-0" morph="none" pos="punct" start_char="946">"</TOKEN>
<TOKEN end_char="957" id="token-13-1" morph="none" pos="unknown" start_char="947">Thirty-nine</TOKEN>
<TOKEN end_char="965" id="token-13-2" morph="none" pos="word" start_char="959">percent</TOKEN>
<TOKEN end_char="969" id="token-13-3" morph="none" pos="word" start_char="967">had</TOKEN>
<TOKEN end_char="977" id="token-13-4" morph="none" pos="word" start_char="971">misused</TOKEN>
<TOKEN end_char="981" id="token-13-5" morph="none" pos="word" start_char="979">the</TOKEN>
<TOKEN end_char="990" id="token-13-6" morph="none" pos="word" start_char="983">cleaning</TOKEN>
<TOKEN end_char="999" id="token-13-7" morph="none" pos="word" start_char="992">products</TOKEN>
<TOKEN end_char="1000" id="token-13-8" morph="none" pos="punct" start_char="1000">"</TOKEN>
<TOKEN end_char="1002" id="token-13-9" morph="none" pos="punct" start_char="1002">–</TOKEN>
<TOKEN end_char="1005" id="token-13-10" morph="none" pos="word" start_char="1004">so</TOKEN>
<TOKEN end_char="1011" id="token-13-11" morph="none" pos="word" start_char="1007">about</TOKEN>
<TOKEN end_char="1015" id="token-13-12" morph="none" pos="word" start_char="1013">the</TOKEN>
<TOKEN end_char="1020" id="token-13-13" morph="none" pos="word" start_char="1017">same</TOKEN>
<TOKEN end_char="1031" id="token-13-14" morph="none" pos="word" start_char="1022">percentage</TOKEN>
<TOKEN end_char="1036" id="token-13-15" morph="none" pos="word" start_char="1033">that</TOKEN>
<TOKEN end_char="1042" id="token-13-16" morph="none" pos="word" start_char="1038">voted</TOKEN>
<TOKEN end_char="1046" id="token-13-17" morph="none" pos="word" start_char="1044">for</TOKEN>
<TOKEN end_char="1052" id="token-13-18" morph="none" pos="word" start_char="1048">Trump</TOKEN>
<TOKEN end_char="1055" id="token-13-19" morph="none" pos="word" start_char="1054">in</TOKEN>
<TOKEN end_char="1060" id="token-13-20" morph="none" pos="word" start_char="1057">2016</TOKEN>
<TOKEN end_char="1061" id="token-13-21" morph="none" pos="punct" start_char="1061">.</TOKEN>
</SEG>
<SEG end_char="1303" id="segment-14" start_char="1063">
<ORIGINAL_TEXT>Basically the most uneducated inbred Americans ever, that blame immigrants/liberals/global trade/opiates/China/gun control/Obama Care for their lot in life, rather than taking ownership for educating themselves and improving their situation.</ORIGINAL_TEXT>
<TOKEN end_char="1071" id="token-14-0" morph="none" pos="word" start_char="1063">Basically</TOKEN>
<TOKEN end_char="1075" id="token-14-1" morph="none" pos="word" start_char="1073">the</TOKEN>
<TOKEN end_char="1080" id="token-14-2" morph="none" pos="word" start_char="1077">most</TOKEN>
<TOKEN end_char="1091" id="token-14-3" morph="none" pos="word" start_char="1082">uneducated</TOKEN>
<TOKEN end_char="1098" id="token-14-4" morph="none" pos="word" start_char="1093">inbred</TOKEN>
<TOKEN end_char="1108" id="token-14-5" morph="none" pos="word" start_char="1100">Americans</TOKEN>
<TOKEN end_char="1113" id="token-14-6" morph="none" pos="word" start_char="1110">ever</TOKEN>
<TOKEN end_char="1114" id="token-14-7" morph="none" pos="punct" start_char="1114">,</TOKEN>
<TOKEN end_char="1119" id="token-14-8" morph="none" pos="word" start_char="1116">that</TOKEN>
<TOKEN end_char="1125" id="token-14-9" morph="none" pos="word" start_char="1121">blame</TOKEN>
<TOKEN end_char="1152" id="token-14-10" morph="none" pos="unknown" start_char="1127">immigrants/liberals/global</TOKEN>
<TOKEN end_char="1176" id="token-14-11" morph="none" pos="unknown" start_char="1154">trade/opiates/China/gun</TOKEN>
<TOKEN end_char="1190" id="token-14-12" morph="none" pos="unknown" start_char="1178">control/Obama</TOKEN>
<TOKEN end_char="1195" id="token-14-13" morph="none" pos="word" start_char="1192">Care</TOKEN>
<TOKEN end_char="1199" id="token-14-14" morph="none" pos="word" start_char="1197">for</TOKEN>
<TOKEN end_char="1205" id="token-14-15" morph="none" pos="word" start_char="1201">their</TOKEN>
<TOKEN end_char="1209" id="token-14-16" morph="none" pos="word" start_char="1207">lot</TOKEN>
<TOKEN end_char="1212" id="token-14-17" morph="none" pos="word" start_char="1211">in</TOKEN>
<TOKEN end_char="1217" id="token-14-18" morph="none" pos="word" start_char="1214">life</TOKEN>
<TOKEN end_char="1218" id="token-14-19" morph="none" pos="punct" start_char="1218">,</TOKEN>
<TOKEN end_char="1225" id="token-14-20" morph="none" pos="word" start_char="1220">rather</TOKEN>
<TOKEN end_char="1230" id="token-14-21" morph="none" pos="word" start_char="1227">than</TOKEN>
<TOKEN end_char="1237" id="token-14-22" morph="none" pos="word" start_char="1232">taking</TOKEN>
<TOKEN end_char="1247" id="token-14-23" morph="none" pos="word" start_char="1239">ownership</TOKEN>
<TOKEN end_char="1251" id="token-14-24" morph="none" pos="word" start_char="1249">for</TOKEN>
<TOKEN end_char="1261" id="token-14-25" morph="none" pos="word" start_char="1253">educating</TOKEN>
<TOKEN end_char="1272" id="token-14-26" morph="none" pos="word" start_char="1263">themselves</TOKEN>
<TOKEN end_char="1276" id="token-14-27" morph="none" pos="word" start_char="1274">and</TOKEN>
<TOKEN end_char="1286" id="token-14-28" morph="none" pos="word" start_char="1278">improving</TOKEN>
<TOKEN end_char="1292" id="token-14-29" morph="none" pos="word" start_char="1288">their</TOKEN>
<TOKEN end_char="1302" id="token-14-30" morph="none" pos="word" start_char="1294">situation</TOKEN>
<TOKEN end_char="1303" id="token-14-31" morph="none" pos="punct" start_char="1303">.</TOKEN>
</SEG>
<SEG end_char="1380" id="segment-15" start_char="1307">
<ORIGINAL_TEXT>But I thought it was rich people and the one percent that voted for Trump?</ORIGINAL_TEXT>
<TOKEN end_char="1309" id="token-15-0" morph="none" pos="word" start_char="1307">But</TOKEN>
<TOKEN end_char="1311" id="token-15-1" morph="none" pos="word" start_char="1311">I</TOKEN>
<TOKEN end_char="1319" id="token-15-2" morph="none" pos="word" start_char="1313">thought</TOKEN>
<TOKEN end_char="1322" id="token-15-3" morph="none" pos="word" start_char="1321">it</TOKEN>
<TOKEN end_char="1326" id="token-15-4" morph="none" pos="word" start_char="1324">was</TOKEN>
<TOKEN end_char="1331" id="token-15-5" morph="none" pos="word" start_char="1328">rich</TOKEN>
<TOKEN end_char="1338" id="token-15-6" morph="none" pos="word" start_char="1333">people</TOKEN>
<TOKEN end_char="1342" id="token-15-7" morph="none" pos="word" start_char="1340">and</TOKEN>
<TOKEN end_char="1346" id="token-15-8" morph="none" pos="word" start_char="1344">the</TOKEN>
<TOKEN end_char="1350" id="token-15-9" morph="none" pos="word" start_char="1348">one</TOKEN>
<TOKEN end_char="1358" id="token-15-10" morph="none" pos="word" start_char="1352">percent</TOKEN>
<TOKEN end_char="1363" id="token-15-11" morph="none" pos="word" start_char="1360">that</TOKEN>
<TOKEN end_char="1369" id="token-15-12" morph="none" pos="word" start_char="1365">voted</TOKEN>
<TOKEN end_char="1373" id="token-15-13" morph="none" pos="word" start_char="1371">for</TOKEN>
<TOKEN end_char="1379" id="token-15-14" morph="none" pos="word" start_char="1375">Trump</TOKEN>
<TOKEN end_char="1380" id="token-15-15" morph="none" pos="punct" start_char="1380">?</TOKEN>
</SEG>
<SEG end_char="1442" id="segment-16" start_char="1382">
<ORIGINAL_TEXT>That is a narrative often heard–that Trump is "for the rich."</ORIGINAL_TEXT>
<TOKEN end_char="1385" id="token-16-0" morph="none" pos="word" start_char="1382">That</TOKEN>
<TOKEN end_char="1388" id="token-16-1" morph="none" pos="word" start_char="1387">is</TOKEN>
<TOKEN end_char="1390" id="token-16-2" morph="none" pos="word" start_char="1390">a</TOKEN>
<TOKEN end_char="1400" id="token-16-3" morph="none" pos="word" start_char="1392">narrative</TOKEN>
<TOKEN end_char="1406" id="token-16-4" morph="none" pos="word" start_char="1402">often</TOKEN>
<TOKEN end_char="1417" id="token-16-5" morph="none" pos="unknown" start_char="1408">heard–that</TOKEN>
<TOKEN end_char="1423" id="token-16-6" morph="none" pos="word" start_char="1419">Trump</TOKEN>
<TOKEN end_char="1426" id="token-16-7" morph="none" pos="word" start_char="1425">is</TOKEN>
<TOKEN end_char="1428" id="token-16-8" morph="none" pos="punct" start_char="1428">"</TOKEN>
<TOKEN end_char="1431" id="token-16-9" morph="none" pos="word" start_char="1429">for</TOKEN>
<TOKEN end_char="1435" id="token-16-10" morph="none" pos="word" start_char="1433">the</TOKEN>
<TOKEN end_char="1440" id="token-16-11" morph="none" pos="word" start_char="1437">rich</TOKEN>
<TOKEN end_char="1442" id="token-16-12" morph="none" pos="punct" start_char="1441">."</TOKEN>
</SEG>
<SEG end_char="1558" id="segment-17" start_char="1444">
<ORIGINAL_TEXT>This would conflict with your characterization of the entire percentage you state being a bunch of mouth breathers.</ORIGINAL_TEXT>
<TOKEN end_char="1447" id="token-17-0" morph="none" pos="word" start_char="1444">This</TOKEN>
<TOKEN end_char="1453" id="token-17-1" morph="none" pos="word" start_char="1449">would</TOKEN>
<TOKEN end_char="1462" id="token-17-2" morph="none" pos="word" start_char="1455">conflict</TOKEN>
<TOKEN end_char="1467" id="token-17-3" morph="none" pos="word" start_char="1464">with</TOKEN>
<TOKEN end_char="1472" id="token-17-4" morph="none" pos="word" start_char="1469">your</TOKEN>
<TOKEN end_char="1489" id="token-17-5" morph="none" pos="word" start_char="1474">characterization</TOKEN>
<TOKEN end_char="1492" id="token-17-6" morph="none" pos="word" start_char="1491">of</TOKEN>
<TOKEN end_char="1496" id="token-17-7" morph="none" pos="word" start_char="1494">the</TOKEN>
<TOKEN end_char="1503" id="token-17-8" morph="none" pos="word" start_char="1498">entire</TOKEN>
<TOKEN end_char="1514" id="token-17-9" morph="none" pos="word" start_char="1505">percentage</TOKEN>
<TOKEN end_char="1518" id="token-17-10" morph="none" pos="word" start_char="1516">you</TOKEN>
<TOKEN end_char="1524" id="token-17-11" morph="none" pos="word" start_char="1520">state</TOKEN>
<TOKEN end_char="1530" id="token-17-12" morph="none" pos="word" start_char="1526">being</TOKEN>
<TOKEN end_char="1532" id="token-17-13" morph="none" pos="word" start_char="1532">a</TOKEN>
<TOKEN end_char="1538" id="token-17-14" morph="none" pos="word" start_char="1534">bunch</TOKEN>
<TOKEN end_char="1541" id="token-17-15" morph="none" pos="word" start_char="1540">of</TOKEN>
<TOKEN end_char="1547" id="token-17-16" morph="none" pos="word" start_char="1543">mouth</TOKEN>
<TOKEN end_char="1557" id="token-17-17" morph="none" pos="word" start_char="1549">breathers</TOKEN>
<TOKEN end_char="1558" id="token-17-18" morph="none" pos="punct" start_char="1558">.</TOKEN>
</SEG>
<SEG end_char="1699" id="segment-18" start_char="1562">
<ORIGINAL_TEXT>This bit of "throw away " information was gleaned from an online survey of 502 people, compiled, analyzed and written by 11, yes 11 PhD’s.</ORIGINAL_TEXT>
<TOKEN end_char="1565" id="token-18-0" morph="none" pos="word" start_char="1562">This</TOKEN>
<TOKEN end_char="1569" id="token-18-1" morph="none" pos="word" start_char="1567">bit</TOKEN>
<TOKEN end_char="1572" id="token-18-2" morph="none" pos="word" start_char="1571">of</TOKEN>
<TOKEN end_char="1574" id="token-18-3" morph="none" pos="punct" start_char="1574">"</TOKEN>
<TOKEN end_char="1579" id="token-18-4" morph="none" pos="word" start_char="1575">throw</TOKEN>
<TOKEN end_char="1584" id="token-18-5" morph="none" pos="word" start_char="1581">away</TOKEN>
<TOKEN end_char="1586" id="token-18-6" morph="none" pos="punct" start_char="1586">"</TOKEN>
<TOKEN end_char="1598" id="token-18-7" morph="none" pos="word" start_char="1588">information</TOKEN>
<TOKEN end_char="1602" id="token-18-8" morph="none" pos="word" start_char="1600">was</TOKEN>
<TOKEN end_char="1610" id="token-18-9" morph="none" pos="word" start_char="1604">gleaned</TOKEN>
<TOKEN end_char="1615" id="token-18-10" morph="none" pos="word" start_char="1612">from</TOKEN>
<TOKEN end_char="1618" id="token-18-11" morph="none" pos="word" start_char="1617">an</TOKEN>
<TOKEN end_char="1625" id="token-18-12" morph="none" pos="word" start_char="1620">online</TOKEN>
<TOKEN end_char="1632" id="token-18-13" morph="none" pos="word" start_char="1627">survey</TOKEN>
<TOKEN end_char="1635" id="token-18-14" morph="none" pos="word" start_char="1634">of</TOKEN>
<TOKEN end_char="1639" id="token-18-15" morph="none" pos="word" start_char="1637">502</TOKEN>
<TOKEN end_char="1646" id="token-18-16" morph="none" pos="word" start_char="1641">people</TOKEN>
<TOKEN end_char="1647" id="token-18-17" morph="none" pos="punct" start_char="1647">,</TOKEN>
<TOKEN end_char="1656" id="token-18-18" morph="none" pos="word" start_char="1649">compiled</TOKEN>
<TOKEN end_char="1657" id="token-18-19" morph="none" pos="punct" start_char="1657">,</TOKEN>
<TOKEN end_char="1666" id="token-18-20" morph="none" pos="word" start_char="1659">analyzed</TOKEN>
<TOKEN end_char="1670" id="token-18-21" morph="none" pos="word" start_char="1668">and</TOKEN>
<TOKEN end_char="1678" id="token-18-22" morph="none" pos="word" start_char="1672">written</TOKEN>
<TOKEN end_char="1681" id="token-18-23" morph="none" pos="word" start_char="1680">by</TOKEN>
<TOKEN end_char="1684" id="token-18-24" morph="none" pos="word" start_char="1683">11</TOKEN>
<TOKEN end_char="1685" id="token-18-25" morph="none" pos="punct" start_char="1685">,</TOKEN>
<TOKEN end_char="1689" id="token-18-26" morph="none" pos="word" start_char="1687">yes</TOKEN>
<TOKEN end_char="1692" id="token-18-27" morph="none" pos="word" start_char="1691">11</TOKEN>
<TOKEN end_char="1698" id="token-18-28" morph="none" pos="word" start_char="1694">PhD’s</TOKEN>
<TOKEN end_char="1699" id="token-18-29" morph="none" pos="punct" start_char="1699">.</TOKEN>
</SEG>
<SEG end_char="1935" id="segment-19" start_char="1701">
<ORIGINAL_TEXT>We learned that a small, non-representative group of people using smartphones or computers are dumb enough to poison themselves because they have been scared out of their gourds by misrepresentations by "experts" and the slavish media.</ORIGINAL_TEXT>
<TOKEN end_char="1702" id="token-19-0" morph="none" pos="word" start_char="1701">We</TOKEN>
<TOKEN end_char="1710" id="token-19-1" morph="none" pos="word" start_char="1704">learned</TOKEN>
<TOKEN end_char="1715" id="token-19-2" morph="none" pos="word" start_char="1712">that</TOKEN>
<TOKEN end_char="1717" id="token-19-3" morph="none" pos="word" start_char="1717">a</TOKEN>
<TOKEN end_char="1723" id="token-19-4" morph="none" pos="word" start_char="1719">small</TOKEN>
<TOKEN end_char="1724" id="token-19-5" morph="none" pos="punct" start_char="1724">,</TOKEN>
<TOKEN end_char="1743" id="token-19-6" morph="none" pos="unknown" start_char="1726">non-representative</TOKEN>
<TOKEN end_char="1749" id="token-19-7" morph="none" pos="word" start_char="1745">group</TOKEN>
<TOKEN end_char="1752" id="token-19-8" morph="none" pos="word" start_char="1751">of</TOKEN>
<TOKEN end_char="1759" id="token-19-9" morph="none" pos="word" start_char="1754">people</TOKEN>
<TOKEN end_char="1765" id="token-19-10" morph="none" pos="word" start_char="1761">using</TOKEN>
<TOKEN end_char="1777" id="token-19-11" morph="none" pos="word" start_char="1767">smartphones</TOKEN>
<TOKEN end_char="1780" id="token-19-12" morph="none" pos="word" start_char="1779">or</TOKEN>
<TOKEN end_char="1790" id="token-19-13" morph="none" pos="word" start_char="1782">computers</TOKEN>
<TOKEN end_char="1794" id="token-19-14" morph="none" pos="word" start_char="1792">are</TOKEN>
<TOKEN end_char="1799" id="token-19-15" morph="none" pos="word" start_char="1796">dumb</TOKEN>
<TOKEN end_char="1806" id="token-19-16" morph="none" pos="word" start_char="1801">enough</TOKEN>
<TOKEN end_char="1809" id="token-19-17" morph="none" pos="word" start_char="1808">to</TOKEN>
<TOKEN end_char="1816" id="token-19-18" morph="none" pos="word" start_char="1811">poison</TOKEN>
<TOKEN end_char="1827" id="token-19-19" morph="none" pos="word" start_char="1818">themselves</TOKEN>
<TOKEN end_char="1835" id="token-19-20" morph="none" pos="word" start_char="1829">because</TOKEN>
<TOKEN end_char="1840" id="token-19-21" morph="none" pos="word" start_char="1837">they</TOKEN>
<TOKEN end_char="1845" id="token-19-22" morph="none" pos="word" start_char="1842">have</TOKEN>
<TOKEN end_char="1850" id="token-19-23" morph="none" pos="word" start_char="1847">been</TOKEN>
<TOKEN end_char="1857" id="token-19-24" morph="none" pos="word" start_char="1852">scared</TOKEN>
<TOKEN end_char="1861" id="token-19-25" morph="none" pos="word" start_char="1859">out</TOKEN>
<TOKEN end_char="1864" id="token-19-26" morph="none" pos="word" start_char="1863">of</TOKEN>
<TOKEN end_char="1870" id="token-19-27" morph="none" pos="word" start_char="1866">their</TOKEN>
<TOKEN end_char="1877" id="token-19-28" morph="none" pos="word" start_char="1872">gourds</TOKEN>
<TOKEN end_char="1880" id="token-19-29" morph="none" pos="word" start_char="1879">by</TOKEN>
<TOKEN end_char="1899" id="token-19-30" morph="none" pos="word" start_char="1882">misrepresentations</TOKEN>
<TOKEN end_char="1902" id="token-19-31" morph="none" pos="word" start_char="1901">by</TOKEN>
<TOKEN end_char="1904" id="token-19-32" morph="none" pos="punct" start_char="1904">"</TOKEN>
<TOKEN end_char="1911" id="token-19-33" morph="none" pos="word" start_char="1905">experts</TOKEN>
<TOKEN end_char="1912" id="token-19-34" morph="none" pos="punct" start_char="1912">"</TOKEN>
<TOKEN end_char="1916" id="token-19-35" morph="none" pos="word" start_char="1914">and</TOKEN>
<TOKEN end_char="1920" id="token-19-36" morph="none" pos="word" start_char="1918">the</TOKEN>
<TOKEN end_char="1928" id="token-19-37" morph="none" pos="word" start_char="1922">slavish</TOKEN>
<TOKEN end_char="1934" id="token-19-38" morph="none" pos="word" start_char="1930">media</TOKEN>
<TOKEN end_char="1935" id="token-19-39" morph="none" pos="punct" start_char="1935">.</TOKEN>
</SEG>
<SEG end_char="1989" id="segment-20" start_char="1937">
<ORIGINAL_TEXT>The only scientific principles proved here is that 1.</ORIGINAL_TEXT>
<TOKEN end_char="1939" id="token-20-0" morph="none" pos="word" start_char="1937">The</TOKEN>
<TOKEN end_char="1944" id="token-20-1" morph="none" pos="word" start_char="1941">only</TOKEN>
<TOKEN end_char="1955" id="token-20-2" morph="none" pos="word" start_char="1946">scientific</TOKEN>
<TOKEN end_char="1966" id="token-20-3" morph="none" pos="word" start_char="1957">principles</TOKEN>
<TOKEN end_char="1973" id="token-20-4" morph="none" pos="word" start_char="1968">proved</TOKEN>
<TOKEN end_char="1978" id="token-20-5" morph="none" pos="word" start_char="1975">here</TOKEN>
<TOKEN end_char="1981" id="token-20-6" morph="none" pos="word" start_char="1980">is</TOKEN>
<TOKEN end_char="1986" id="token-20-7" morph="none" pos="word" start_char="1983">that</TOKEN>
<TOKEN end_char="1988" id="token-20-8" morph="none" pos="word" start_char="1988">1</TOKEN>
<TOKEN end_char="1989" id="token-20-9" morph="none" pos="punct" start_char="1989">.</TOKEN>
</SEG>
<SEG end_char="2007" id="segment-21" start_char="1991">
<ORIGINAL_TEXT>Agitprop works 2.</ORIGINAL_TEXT>
<TOKEN end_char="1998" id="token-21-0" morph="none" pos="word" start_char="1991">Agitprop</TOKEN>
<TOKEN end_char="2004" id="token-21-1" morph="none" pos="word" start_char="2000">works</TOKEN>
<TOKEN end_char="2006" id="token-21-2" morph="none" pos="word" start_char="2006">2</TOKEN>
<TOKEN end_char="2007" id="token-21-3" morph="none" pos="punct" start_char="2007">.</TOKEN>
<TRANSLATED_TEXT>Agitprop-werken 2.</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="2024" id="segment-22" start_char="2009">
<ORIGINAL_TEXT>Darwin is right.</ORIGINAL_TEXT>
<TOKEN end_char="2014" id="token-22-0" morph="none" pos="word" start_char="2009">Darwin</TOKEN>
<TOKEN end_char="2017" id="token-22-1" morph="none" pos="word" start_char="2016">is</TOKEN>
<TOKEN end_char="2023" id="token-22-2" morph="none" pos="word" start_char="2019">right</TOKEN>
<TOKEN end_char="2024" id="token-22-3" morph="none" pos="punct" start_char="2024">.</TOKEN>
<TRANSLATED_TEXT>Darwini je pravo.</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="2071" id="segment-23" start_char="2026">
<ORIGINAL_TEXT>Oh, and one other thing the Orange Guy is bad!</ORIGINAL_TEXT>
<TOKEN end_char="2027" id="token-23-0" morph="none" pos="word" start_char="2026">Oh</TOKEN>
<TOKEN end_char="2028" id="token-23-1" morph="none" pos="punct" start_char="2028">,</TOKEN>
<TOKEN end_char="2032" id="token-23-2" morph="none" pos="word" start_char="2030">and</TOKEN>
<TOKEN end_char="2036" id="token-23-3" morph="none" pos="word" start_char="2034">one</TOKEN>
<TOKEN end_char="2042" id="token-23-4" morph="none" pos="word" start_char="2038">other</TOKEN>
<TOKEN end_char="2048" id="token-23-5" morph="none" pos="word" start_char="2044">thing</TOKEN>
<TOKEN end_char="2052" id="token-23-6" morph="none" pos="word" start_char="2050">the</TOKEN>
<TOKEN end_char="2059" id="token-23-7" morph="none" pos="word" start_char="2054">Orange</TOKEN>
<TOKEN end_char="2063" id="token-23-8" morph="none" pos="word" start_char="2061">Guy</TOKEN>
<TOKEN end_char="2066" id="token-23-9" morph="none" pos="word" start_char="2065">is</TOKEN>
<TOKEN end_char="2070" id="token-23-10" morph="none" pos="word" start_char="2068">bad</TOKEN>
<TOKEN end_char="2071" id="token-23-11" morph="none" pos="punct" start_char="2071">!</TOKEN>
</SEG>
<SEG end_char="2184" id="segment-24" start_char="2075">
<ORIGINAL_TEXT>Everyone is to blame: The media, the idiots, the experts…even the researchers leading this "throw away" study.</ORIGINAL_TEXT>
<TOKEN end_char="2082" id="token-24-0" morph="none" pos="word" start_char="2075">Everyone</TOKEN>
<TOKEN end_char="2085" id="token-24-1" morph="none" pos="word" start_char="2084">is</TOKEN>
<TOKEN end_char="2088" id="token-24-2" morph="none" pos="word" start_char="2087">to</TOKEN>
<TOKEN end_char="2094" id="token-24-3" morph="none" pos="word" start_char="2090">blame</TOKEN>
<TOKEN end_char="2095" id="token-24-4" morph="none" pos="punct" start_char="2095">:</TOKEN>
<TOKEN end_char="2099" id="token-24-5" morph="none" pos="word" start_char="2097">The</TOKEN>
<TOKEN end_char="2105" id="token-24-6" morph="none" pos="word" start_char="2101">media</TOKEN>
<TOKEN end_char="2106" id="token-24-7" morph="none" pos="punct" start_char="2106">,</TOKEN>
<TOKEN end_char="2110" id="token-24-8" morph="none" pos="word" start_char="2108">the</TOKEN>
<TOKEN end_char="2117" id="token-24-9" morph="none" pos="word" start_char="2112">idiots</TOKEN>
<TOKEN end_char="2118" id="token-24-10" morph="none" pos="punct" start_char="2118">,</TOKEN>
<TOKEN end_char="2122" id="token-24-11" morph="none" pos="word" start_char="2120">the</TOKEN>
<TOKEN end_char="2135" id="token-24-12" morph="none" pos="unknown" start_char="2124">experts…even</TOKEN>
<TOKEN end_char="2139" id="token-24-13" morph="none" pos="word" start_char="2137">the</TOKEN>
<TOKEN end_char="2151" id="token-24-14" morph="none" pos="word" start_char="2141">researchers</TOKEN>
<TOKEN end_char="2159" id="token-24-15" morph="none" pos="word" start_char="2153">leading</TOKEN>
<TOKEN end_char="2164" id="token-24-16" morph="none" pos="word" start_char="2161">this</TOKEN>
<TOKEN end_char="2166" id="token-24-17" morph="none" pos="punct" start_char="2166">"</TOKEN>
<TOKEN end_char="2171" id="token-24-18" morph="none" pos="word" start_char="2167">throw</TOKEN>
<TOKEN end_char="2176" id="token-24-19" morph="none" pos="word" start_char="2173">away</TOKEN>
<TOKEN end_char="2177" id="token-24-20" morph="none" pos="punct" start_char="2177">"</TOKEN>
<TOKEN end_char="2183" id="token-24-21" morph="none" pos="word" start_char="2179">study</TOKEN>
<TOKEN end_char="2184" id="token-24-22" morph="none" pos="punct" start_char="2184">.</TOKEN>
</SEG>
<SEG end_char="2211" id="segment-25" start_char="2186">
<ORIGINAL_TEXT>Yes, everyone is to blame.</ORIGINAL_TEXT>
<TOKEN end_char="2188" id="token-25-0" morph="none" pos="word" start_char="2186">Yes</TOKEN>
<TOKEN end_char="2189" id="token-25-1" morph="none" pos="punct" start_char="2189">,</TOKEN>
<TOKEN end_char="2198" id="token-25-2" morph="none" pos="word" start_char="2191">everyone</TOKEN>
<TOKEN end_char="2201" id="token-25-3" morph="none" pos="word" start_char="2200">is</TOKEN>
<TOKEN end_char="2204" id="token-25-4" morph="none" pos="word" start_char="2203">to</TOKEN>
<TOKEN end_char="2210" id="token-25-5" morph="none" pos="word" start_char="2206">blame</TOKEN>
<TOKEN end_char="2211" id="token-25-6" morph="none" pos="punct" start_char="2211">.</TOKEN>
</SEG>
<SEG end_char="2252" id="segment-26" start_char="2213">
<ORIGINAL_TEXT>Everyone, that is, except the President.</ORIGINAL_TEXT>
<TOKEN end_char="2220" id="token-26-0" morph="none" pos="word" start_char="2213">Everyone</TOKEN>
<TOKEN end_char="2221" id="token-26-1" morph="none" pos="punct" start_char="2221">,</TOKEN>
<TOKEN end_char="2226" id="token-26-2" morph="none" pos="word" start_char="2223">that</TOKEN>
<TOKEN end_char="2229" id="token-26-3" morph="none" pos="word" start_char="2228">is</TOKEN>
<TOKEN end_char="2230" id="token-26-4" morph="none" pos="punct" start_char="2230">,</TOKEN>
<TOKEN end_char="2237" id="token-26-5" morph="none" pos="word" start_char="2232">except</TOKEN>
<TOKEN end_char="2241" id="token-26-6" morph="none" pos="word" start_char="2239">the</TOKEN>
<TOKEN end_char="2251" id="token-26-7" morph="none" pos="word" start_char="2243">President</TOKEN>
<TOKEN end_char="2252" id="token-26-8" morph="none" pos="punct" start_char="2252">.</TOKEN>
</SEG>
<SEG end_char="2296" id="segment-27" start_char="2254">
<ORIGINAL_TEXT>That bastion of truth and tremendous ideas.</ORIGINAL_TEXT>
<TOKEN end_char="2257" id="token-27-0" morph="none" pos="word" start_char="2254">That</TOKEN>
<TOKEN end_char="2265" id="token-27-1" morph="none" pos="word" start_char="2259">bastion</TOKEN>
<TOKEN end_char="2268" id="token-27-2" morph="none" pos="word" start_char="2267">of</TOKEN>
<TOKEN end_char="2274" id="token-27-3" morph="none" pos="word" start_char="2270">truth</TOKEN>
<TOKEN end_char="2278" id="token-27-4" morph="none" pos="word" start_char="2276">and</TOKEN>
<TOKEN end_char="2289" id="token-27-5" morph="none" pos="word" start_char="2280">tremendous</TOKEN>
<TOKEN end_char="2295" id="token-27-6" morph="none" pos="word" start_char="2291">ideas</TOKEN>
<TOKEN end_char="2296" id="token-27-7" morph="none" pos="punct" start_char="2296">.</TOKEN>
</SEG>
<SEG end_char="2357" id="segment-28" start_char="2298">
<ORIGINAL_TEXT>That paragon of dignity, knowledge, and measured leadership.</ORIGINAL_TEXT>
<TOKEN end_char="2301" id="token-28-0" morph="none" pos="word" start_char="2298">That</TOKEN>
<TOKEN end_char="2309" id="token-28-1" morph="none" pos="word" start_char="2303">paragon</TOKEN>
<TOKEN end_char="2312" id="token-28-2" morph="none" pos="word" start_char="2311">of</TOKEN>
<TOKEN end_char="2320" id="token-28-3" morph="none" pos="word" start_char="2314">dignity</TOKEN>
<TOKEN end_char="2321" id="token-28-4" morph="none" pos="punct" start_char="2321">,</TOKEN>
<TOKEN end_char="2331" id="token-28-5" morph="none" pos="word" start_char="2323">knowledge</TOKEN>
<TOKEN end_char="2332" id="token-28-6" morph="none" pos="punct" start_char="2332">,</TOKEN>
<TOKEN end_char="2336" id="token-28-7" morph="none" pos="word" start_char="2334">and</TOKEN>
<TOKEN end_char="2345" id="token-28-8" morph="none" pos="word" start_char="2338">measured</TOKEN>
<TOKEN end_char="2356" id="token-28-9" morph="none" pos="word" start_char="2347">leadership</TOKEN>
<TOKEN end_char="2357" id="token-28-10" morph="none" pos="punct" start_char="2357">.</TOKEN>
</SEG>
<SEG end_char="2389" id="segment-29" start_char="2359">
<ORIGINAL_TEXT>Thank you for opening our eyes.</ORIGINAL_TEXT>
<TOKEN end_char="2363" id="token-29-0" morph="none" pos="word" start_char="2359">Thank</TOKEN>
<TOKEN end_char="2367" id="token-29-1" morph="none" pos="word" start_char="2365">you</TOKEN>
<TOKEN end_char="2371" id="token-29-2" morph="none" pos="word" start_char="2369">for</TOKEN>
<TOKEN end_char="2379" id="token-29-3" morph="none" pos="word" start_char="2373">opening</TOKEN>
<TOKEN end_char="2383" id="token-29-4" morph="none" pos="word" start_char="2381">our</TOKEN>
<TOKEN end_char="2388" id="token-29-5" morph="none" pos="word" start_char="2385">eyes</TOKEN>
<TOKEN end_char="2389" id="token-29-6" morph="none" pos="punct" start_char="2389">.</TOKEN>
</SEG>
<SEG end_char="2420" id="segment-30" start_char="2391">
<ORIGINAL_TEXT>You are a tremendous American.</ORIGINAL_TEXT>
<TOKEN end_char="2393" id="token-30-0" morph="none" pos="word" start_char="2391">You</TOKEN>
<TOKEN end_char="2397" id="token-30-1" morph="none" pos="word" start_char="2395">are</TOKEN>
<TOKEN end_char="2399" id="token-30-2" morph="none" pos="word" start_char="2399">a</TOKEN>
<TOKEN end_char="2410" id="token-30-3" morph="none" pos="word" start_char="2401">tremendous</TOKEN>
<TOKEN end_char="2419" id="token-30-4" morph="none" pos="word" start_char="2412">American</TOKEN>
<TOKEN end_char="2420" id="token-30-5" morph="none" pos="punct" start_char="2420">.</TOKEN>
</SEG>
<SEG end_char="2457" id="segment-31" start_char="2424">
<ORIGINAL_TEXT>It’s everyone else’s fault, right?</ORIGINAL_TEXT>
<TOKEN end_char="2427" id="token-31-0" morph="none" pos="word" start_char="2424">It’s</TOKEN>
<TOKEN end_char="2436" id="token-31-1" morph="none" pos="word" start_char="2429">everyone</TOKEN>
<TOKEN end_char="2443" id="token-31-2" morph="none" pos="word" start_char="2438">else’s</TOKEN>
<TOKEN end_char="2449" id="token-31-3" morph="none" pos="word" start_char="2445">fault</TOKEN>
<TOKEN end_char="2450" id="token-31-4" morph="none" pos="punct" start_char="2450">,</TOKEN>
<TOKEN end_char="2456" id="token-31-5" morph="none" pos="word" start_char="2452">right</TOKEN>
<TOKEN end_char="2457" id="token-31-6" morph="none" pos="punct" start_char="2457">?</TOKEN>
</SEG>
<SEG end_char="2501" id="segment-32" start_char="2459">
<ORIGINAL_TEXT>Please, pretty please, take some ownership.</ORIGINAL_TEXT>
<TOKEN end_char="2464" id="token-32-0" morph="none" pos="word" start_char="2459">Please</TOKEN>
<TOKEN end_char="2465" id="token-32-1" morph="none" pos="punct" start_char="2465">,</TOKEN>
<TOKEN end_char="2472" id="token-32-2" morph="none" pos="word" start_char="2467">pretty</TOKEN>
<TOKEN end_char="2479" id="token-32-3" morph="none" pos="word" start_char="2474">please</TOKEN>
<TOKEN end_char="2480" id="token-32-4" morph="none" pos="punct" start_char="2480">,</TOKEN>
<TOKEN end_char="2485" id="token-32-5" morph="none" pos="word" start_char="2482">take</TOKEN>
<TOKEN end_char="2490" id="token-32-6" morph="none" pos="word" start_char="2487">some</TOKEN>
<TOKEN end_char="2500" id="token-32-7" morph="none" pos="word" start_char="2492">ownership</TOKEN>
<TOKEN end_char="2501" id="token-32-8" morph="none" pos="punct" start_char="2501">.</TOKEN>
</SEG>
<SEG end_char="2642" id="segment-33" start_char="2503">
<ORIGINAL_TEXT>There is no perfect administration, no one can get everything right all of the time, so it’s ok to be objective and call things as they are.</ORIGINAL_TEXT>
<TOKEN end_char="2507" id="token-33-0" morph="none" pos="word" start_char="2503">There</TOKEN>
<TOKEN end_char="2510" id="token-33-1" morph="none" pos="word" start_char="2509">is</TOKEN>
<TOKEN end_char="2513" id="token-33-2" morph="none" pos="word" start_char="2512">no</TOKEN>
<TOKEN end_char="2521" id="token-33-3" morph="none" pos="word" start_char="2515">perfect</TOKEN>
<TOKEN end_char="2536" id="token-33-4" morph="none" pos="word" start_char="2523">administration</TOKEN>
<TOKEN end_char="2537" id="token-33-5" morph="none" pos="punct" start_char="2537">,</TOKEN>
<TOKEN end_char="2540" id="token-33-6" morph="none" pos="word" start_char="2539">no</TOKEN>
<TOKEN end_char="2544" id="token-33-7" morph="none" pos="word" start_char="2542">one</TOKEN>
<TOKEN end_char="2548" id="token-33-8" morph="none" pos="word" start_char="2546">can</TOKEN>
<TOKEN end_char="2552" id="token-33-9" morph="none" pos="word" start_char="2550">get</TOKEN>
<TOKEN end_char="2563" id="token-33-10" morph="none" pos="word" start_char="2554">everything</TOKEN>
<TOKEN end_char="2569" id="token-33-11" morph="none" pos="word" start_char="2565">right</TOKEN>
<TOKEN end_char="2573" id="token-33-12" morph="none" pos="word" start_char="2571">all</TOKEN>
<TOKEN end_char="2576" id="token-33-13" morph="none" pos="word" start_char="2575">of</TOKEN>
<TOKEN end_char="2580" id="token-33-14" morph="none" pos="word" start_char="2578">the</TOKEN>
<TOKEN end_char="2585" id="token-33-15" morph="none" pos="word" start_char="2582">time</TOKEN>
<TOKEN end_char="2586" id="token-33-16" morph="none" pos="punct" start_char="2586">,</TOKEN>
<TOKEN end_char="2589" id="token-33-17" morph="none" pos="word" start_char="2588">so</TOKEN>
<TOKEN end_char="2594" id="token-33-18" morph="none" pos="word" start_char="2591">it’s</TOKEN>
<TOKEN end_char="2597" id="token-33-19" morph="none" pos="word" start_char="2596">ok</TOKEN>
<TOKEN end_char="2600" id="token-33-20" morph="none" pos="word" start_char="2599">to</TOKEN>
<TOKEN end_char="2603" id="token-33-21" morph="none" pos="word" start_char="2602">be</TOKEN>
<TOKEN end_char="2613" id="token-33-22" morph="none" pos="word" start_char="2605">objective</TOKEN>
<TOKEN end_char="2617" id="token-33-23" morph="none" pos="word" start_char="2615">and</TOKEN>
<TOKEN end_char="2622" id="token-33-24" morph="none" pos="word" start_char="2619">call</TOKEN>
<TOKEN end_char="2629" id="token-33-25" morph="none" pos="word" start_char="2624">things</TOKEN>
<TOKEN end_char="2632" id="token-33-26" morph="none" pos="word" start_char="2631">as</TOKEN>
<TOKEN end_char="2637" id="token-33-27" morph="none" pos="word" start_char="2634">they</TOKEN>
<TOKEN end_char="2641" id="token-33-28" morph="none" pos="word" start_char="2639">are</TOKEN>
<TOKEN end_char="2642" id="token-33-29" morph="none" pos="punct" start_char="2642">.</TOKEN>
</SEG>
<SEG end_char="2702" id="segment-34" start_char="2644">
<ORIGINAL_TEXT>This administration has made many errors, many were costly.</ORIGINAL_TEXT>
<TOKEN end_char="2647" id="token-34-0" morph="none" pos="word" start_char="2644">This</TOKEN>
<TOKEN end_char="2662" id="token-34-1" morph="none" pos="word" start_char="2649">administration</TOKEN>
<TOKEN end_char="2666" id="token-34-2" morph="none" pos="word" start_char="2664">has</TOKEN>
<TOKEN end_char="2671" id="token-34-3" morph="none" pos="word" start_char="2668">made</TOKEN>
<TOKEN end_char="2676" id="token-34-4" morph="none" pos="word" start_char="2673">many</TOKEN>
<TOKEN end_char="2683" id="token-34-5" morph="none" pos="word" start_char="2678">errors</TOKEN>
<TOKEN end_char="2684" id="token-34-6" morph="none" pos="punct" start_char="2684">,</TOKEN>
<TOKEN end_char="2689" id="token-34-7" morph="none" pos="word" start_char="2686">many</TOKEN>
<TOKEN end_char="2694" id="token-34-8" morph="none" pos="word" start_char="2691">were</TOKEN>
<TOKEN end_char="2701" id="token-34-9" morph="none" pos="word" start_char="2696">costly</TOKEN>
<TOKEN end_char="2702" id="token-34-10" morph="none" pos="punct" start_char="2702">.</TOKEN>
</SEG>
<SEG end_char="2739" id="segment-35" start_char="2704">
<ORIGINAL_TEXT>I am not sure how one can deny that.</ORIGINAL_TEXT>
<TOKEN end_char="2704" id="token-35-0" morph="none" pos="word" start_char="2704">I</TOKEN>
<TOKEN end_char="2707" id="token-35-1" morph="none" pos="word" start_char="2706">am</TOKEN>
<TOKEN end_char="2711" id="token-35-2" morph="none" pos="word" start_char="2709">not</TOKEN>
<TOKEN end_char="2716" id="token-35-3" morph="none" pos="word" start_char="2713">sure</TOKEN>
<TOKEN end_char="2720" id="token-35-4" morph="none" pos="word" start_char="2718">how</TOKEN>
<TOKEN end_char="2724" id="token-35-5" morph="none" pos="word" start_char="2722">one</TOKEN>
<TOKEN end_char="2728" id="token-35-6" morph="none" pos="word" start_char="2726">can</TOKEN>
<TOKEN end_char="2733" id="token-35-7" morph="none" pos="word" start_char="2730">deny</TOKEN>
<TOKEN end_char="2738" id="token-35-8" morph="none" pos="word" start_char="2735">that</TOKEN>
<TOKEN end_char="2739" id="token-35-9" morph="none" pos="punct" start_char="2739">.</TOKEN>
</SEG>
<SEG end_char="2783" id="segment-36" start_char="2743">
<ORIGINAL_TEXT>Bleach on the skin is not very dangerous.</ORIGINAL_TEXT>
<TOKEN end_char="2748" id="token-36-0" morph="none" pos="word" start_char="2743">Bleach</TOKEN>
<TOKEN end_char="2751" id="token-36-1" morph="none" pos="word" start_char="2750">on</TOKEN>
<TOKEN end_char="2755" id="token-36-2" morph="none" pos="word" start_char="2753">the</TOKEN>
<TOKEN end_char="2760" id="token-36-3" morph="none" pos="word" start_char="2757">skin</TOKEN>
<TOKEN end_char="2763" id="token-36-4" morph="none" pos="word" start_char="2762">is</TOKEN>
<TOKEN end_char="2767" id="token-36-5" morph="none" pos="word" start_char="2765">not</TOKEN>
<TOKEN end_char="2772" id="token-36-6" morph="none" pos="word" start_char="2769">very</TOKEN>
<TOKEN end_char="2782" id="token-36-7" morph="none" pos="word" start_char="2774">dangerous</TOKEN>
<TOKEN end_char="2783" id="token-36-8" morph="none" pos="punct" start_char="2783">.</TOKEN>
</SEG>
<SEG end_char="2872" id="segment-37" start_char="2785">
<ORIGINAL_TEXT>I have soaked my feet in bleach and water plenty of times to remove bacteria and fungus.</ORIGINAL_TEXT>
<TOKEN end_char="2785" id="token-37-0" morph="none" pos="word" start_char="2785">I</TOKEN>
<TOKEN end_char="2790" id="token-37-1" morph="none" pos="word" start_char="2787">have</TOKEN>
<TOKEN end_char="2797" id="token-37-2" morph="none" pos="word" start_char="2792">soaked</TOKEN>
<TOKEN end_char="2800" id="token-37-3" morph="none" pos="word" start_char="2799">my</TOKEN>
<TOKEN end_char="2805" id="token-37-4" morph="none" pos="word" start_char="2802">feet</TOKEN>
<TOKEN end_char="2808" id="token-37-5" morph="none" pos="word" start_char="2807">in</TOKEN>
<TOKEN end_char="2815" id="token-37-6" morph="none" pos="word" start_char="2810">bleach</TOKEN>
<TOKEN end_char="2819" id="token-37-7" morph="none" pos="word" start_char="2817">and</TOKEN>
<TOKEN end_char="2825" id="token-37-8" morph="none" pos="word" start_char="2821">water</TOKEN>
<TOKEN end_char="2832" id="token-37-9" morph="none" pos="word" start_char="2827">plenty</TOKEN>
<TOKEN end_char="2835" id="token-37-10" morph="none" pos="word" start_char="2834">of</TOKEN>
<TOKEN end_char="2841" id="token-37-11" morph="none" pos="word" start_char="2837">times</TOKEN>
<TOKEN end_char="2844" id="token-37-12" morph="none" pos="word" start_char="2843">to</TOKEN>
<TOKEN end_char="2851" id="token-37-13" morph="none" pos="word" start_char="2846">remove</TOKEN>
<TOKEN end_char="2860" id="token-37-14" morph="none" pos="word" start_char="2853">bacteria</TOKEN>
<TOKEN end_char="2864" id="token-37-15" morph="none" pos="word" start_char="2862">and</TOKEN>
<TOKEN end_char="2871" id="token-37-16" morph="none" pos="word" start_char="2866">fungus</TOKEN>
<TOKEN end_char="2872" id="token-37-17" morph="none" pos="punct" start_char="2872">.</TOKEN>
</SEG>
<SEG end_char="2895" id="segment-38" start_char="2874">
<ORIGINAL_TEXT>There are no problems.</ORIGINAL_TEXT>
<TOKEN end_char="2878" id="token-38-0" morph="none" pos="word" start_char="2874">There</TOKEN>
<TOKEN end_char="2882" id="token-38-1" morph="none" pos="word" start_char="2880">are</TOKEN>
<TOKEN end_char="2885" id="token-38-2" morph="none" pos="word" start_char="2884">no</TOKEN>
<TOKEN end_char="2894" id="token-38-3" morph="none" pos="word" start_char="2887">problems</TOKEN>
<TOKEN end_char="2895" id="token-38-4" morph="none" pos="punct" start_char="2895">.</TOKEN>
</SEG>
<SEG end_char="3053" id="segment-39" start_char="2897">
<ORIGINAL_TEXT>I even use a mixture of bleach and 91% isopropyl alcohol as a sanitizer because using public transportation and washing one’s hands frequently is not viable.</ORIGINAL_TEXT>
<TOKEN end_char="2897" id="token-39-0" morph="none" pos="word" start_char="2897">I</TOKEN>
<TOKEN end_char="2902" id="token-39-1" morph="none" pos="word" start_char="2899">even</TOKEN>
<TOKEN end_char="2906" id="token-39-2" morph="none" pos="word" start_char="2904">use</TOKEN>
<TOKEN end_char="2908" id="token-39-3" morph="none" pos="word" start_char="2908">a</TOKEN>
<TOKEN end_char="2916" id="token-39-4" morph="none" pos="word" start_char="2910">mixture</TOKEN>
<TOKEN end_char="2919" id="token-39-5" morph="none" pos="word" start_char="2918">of</TOKEN>
<TOKEN end_char="2926" id="token-39-6" morph="none" pos="word" start_char="2921">bleach</TOKEN>
<TOKEN end_char="2930" id="token-39-7" morph="none" pos="word" start_char="2928">and</TOKEN>
<TOKEN end_char="2933" id="token-39-8" morph="none" pos="word" start_char="2932">91</TOKEN>
<TOKEN end_char="2934" id="token-39-9" morph="none" pos="punct" start_char="2934">%</TOKEN>
<TOKEN end_char="2944" id="token-39-10" morph="none" pos="word" start_char="2936">isopropyl</TOKEN>
<TOKEN end_char="2952" id="token-39-11" morph="none" pos="word" start_char="2946">alcohol</TOKEN>
<TOKEN end_char="2955" id="token-39-12" morph="none" pos="word" start_char="2954">as</TOKEN>
<TOKEN end_char="2957" id="token-39-13" morph="none" pos="word" start_char="2957">a</TOKEN>
<TOKEN end_char="2967" id="token-39-14" morph="none" pos="word" start_char="2959">sanitizer</TOKEN>
<TOKEN end_char="2975" id="token-39-15" morph="none" pos="word" start_char="2969">because</TOKEN>
<TOKEN end_char="2981" id="token-39-16" morph="none" pos="word" start_char="2977">using</TOKEN>
<TOKEN end_char="2988" id="token-39-17" morph="none" pos="word" start_char="2983">public</TOKEN>
<TOKEN end_char="3003" id="token-39-18" morph="none" pos="word" start_char="2990">transportation</TOKEN>
<TOKEN end_char="3007" id="token-39-19" morph="none" pos="word" start_char="3005">and</TOKEN>
<TOKEN end_char="3015" id="token-39-20" morph="none" pos="word" start_char="3009">washing</TOKEN>
<TOKEN end_char="3021" id="token-39-21" morph="none" pos="word" start_char="3017">one’s</TOKEN>
<TOKEN end_char="3027" id="token-39-22" morph="none" pos="word" start_char="3023">hands</TOKEN>
<TOKEN end_char="3038" id="token-39-23" morph="none" pos="word" start_char="3029">frequently</TOKEN>
<TOKEN end_char="3041" id="token-39-24" morph="none" pos="word" start_char="3040">is</TOKEN>
<TOKEN end_char="3045" id="token-39-25" morph="none" pos="word" start_char="3043">not</TOKEN>
<TOKEN end_char="3052" id="token-39-26" morph="none" pos="word" start_char="3047">viable</TOKEN>
<TOKEN end_char="3053" id="token-39-27" morph="none" pos="punct" start_char="3053">.</TOKEN>
</SEG>
<SEG end_char="3161" id="segment-40" start_char="3055">
<ORIGINAL_TEXT>I would not put bleach on open wounds and sores but for infrequent or occassional use I would recommend it.</ORIGINAL_TEXT>
<TOKEN end_char="3055" id="token-40-0" morph="none" pos="word" start_char="3055">I</TOKEN>
<TOKEN end_char="3061" id="token-40-1" morph="none" pos="word" start_char="3057">would</TOKEN>
<TOKEN end_char="3065" id="token-40-2" morph="none" pos="word" start_char="3063">not</TOKEN>
<TOKEN end_char="3069" id="token-40-3" morph="none" pos="word" start_char="3067">put</TOKEN>
<TOKEN end_char="3076" id="token-40-4" morph="none" pos="word" start_char="3071">bleach</TOKEN>
<TOKEN end_char="3079" id="token-40-5" morph="none" pos="word" start_char="3078">on</TOKEN>
<TOKEN end_char="3084" id="token-40-6" morph="none" pos="word" start_char="3081">open</TOKEN>
<TOKEN end_char="3091" id="token-40-7" morph="none" pos="word" start_char="3086">wounds</TOKEN>
<TOKEN end_char="3095" id="token-40-8" morph="none" pos="word" start_char="3093">and</TOKEN>
<TOKEN end_char="3101" id="token-40-9" morph="none" pos="word" start_char="3097">sores</TOKEN>
<TOKEN end_char="3105" id="token-40-10" morph="none" pos="word" start_char="3103">but</TOKEN>
<TOKEN end_char="3109" id="token-40-11" morph="none" pos="word" start_char="3107">for</TOKEN>
<TOKEN end_char="3120" id="token-40-12" morph="none" pos="word" start_char="3111">infrequent</TOKEN>
<TOKEN end_char="3123" id="token-40-13" morph="none" pos="word" start_char="3122">or</TOKEN>
<TOKEN end_char="3135" id="token-40-14" morph="none" pos="word" start_char="3125">occassional</TOKEN>
<TOKEN end_char="3139" id="token-40-15" morph="none" pos="word" start_char="3137">use</TOKEN>
<TOKEN end_char="3141" id="token-40-16" morph="none" pos="word" start_char="3141">I</TOKEN>
<TOKEN end_char="3147" id="token-40-17" morph="none" pos="word" start_char="3143">would</TOKEN>
<TOKEN end_char="3157" id="token-40-18" morph="none" pos="word" start_char="3149">recommend</TOKEN>
<TOKEN end_char="3160" id="token-40-19" morph="none" pos="word" start_char="3159">it</TOKEN>
<TOKEN end_char="3161" id="token-40-20" morph="none" pos="punct" start_char="3161">.</TOKEN>
</SEG>
<SEG end_char="3182" id="segment-41" start_char="3163">
<ORIGINAL_TEXT>No, do not drink it.</ORIGINAL_TEXT>
<TOKEN end_char="3164" id="token-41-0" morph="none" pos="word" start_char="3163">No</TOKEN>
<TOKEN end_char="3165" id="token-41-1" morph="none" pos="punct" start_char="3165">,</TOKEN>
<TOKEN end_char="3168" id="token-41-2" morph="none" pos="word" start_char="3167">do</TOKEN>
<TOKEN end_char="3172" id="token-41-3" morph="none" pos="word" start_char="3170">not</TOKEN>
<TOKEN end_char="3178" id="token-41-4" morph="none" pos="word" start_char="3174">drink</TOKEN>
<TOKEN end_char="3181" id="token-41-5" morph="none" pos="word" start_char="3180">it</TOKEN>
<TOKEN end_char="3182" id="token-41-6" morph="none" pos="punct" start_char="3182">.</TOKEN>
<TRANSLATED_TEXT>No, don't drink it.</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="3207" id="segment-42" start_char="3184">
<ORIGINAL_TEXT>That will kill a person.</ORIGINAL_TEXT>
<TOKEN end_char="3187" id="token-42-0" morph="none" pos="word" start_char="3184">That</TOKEN>
<TOKEN end_char="3192" id="token-42-1" morph="none" pos="word" start_char="3189">will</TOKEN>
<TOKEN end_char="3197" id="token-42-2" morph="none" pos="word" start_char="3194">kill</TOKEN>
<TOKEN end_char="3199" id="token-42-3" morph="none" pos="word" start_char="3199">a</TOKEN>
<TOKEN end_char="3206" id="token-42-4" morph="none" pos="word" start_char="3201">person</TOKEN>
<TOKEN end_char="3207" id="token-42-5" morph="none" pos="punct" start_char="3207">.</TOKEN>
</SEG>
<SEG end_char="3337" id="segment-43" start_char="3211">
<ORIGINAL_TEXT>I would not do what you are doing with bleach–but clearly you are getting by with it and presumably still well enough to write.</ORIGINAL_TEXT>
<TOKEN end_char="3211" id="token-43-0" morph="none" pos="word" start_char="3211">I</TOKEN>
<TOKEN end_char="3217" id="token-43-1" morph="none" pos="word" start_char="3213">would</TOKEN>
<TOKEN end_char="3221" id="token-43-2" morph="none" pos="word" start_char="3219">not</TOKEN>
<TOKEN end_char="3224" id="token-43-3" morph="none" pos="word" start_char="3223">do</TOKEN>
<TOKEN end_char="3229" id="token-43-4" morph="none" pos="word" start_char="3226">what</TOKEN>
<TOKEN end_char="3233" id="token-43-5" morph="none" pos="word" start_char="3231">you</TOKEN>
<TOKEN end_char="3237" id="token-43-6" morph="none" pos="word" start_char="3235">are</TOKEN>
<TOKEN end_char="3243" id="token-43-7" morph="none" pos="word" start_char="3239">doing</TOKEN>
<TOKEN end_char="3248" id="token-43-8" morph="none" pos="word" start_char="3245">with</TOKEN>
<TOKEN end_char="3259" id="token-43-9" morph="none" pos="unknown" start_char="3250">bleach–but</TOKEN>
<TOKEN end_char="3267" id="token-43-10" morph="none" pos="word" start_char="3261">clearly</TOKEN>
<TOKEN end_char="3271" id="token-43-11" morph="none" pos="word" start_char="3269">you</TOKEN>
<TOKEN end_char="3275" id="token-43-12" morph="none" pos="word" start_char="3273">are</TOKEN>
<TOKEN end_char="3283" id="token-43-13" morph="none" pos="word" start_char="3277">getting</TOKEN>
<TOKEN end_char="3286" id="token-43-14" morph="none" pos="word" start_char="3285">by</TOKEN>
<TOKEN end_char="3291" id="token-43-15" morph="none" pos="word" start_char="3288">with</TOKEN>
<TOKEN end_char="3294" id="token-43-16" morph="none" pos="word" start_char="3293">it</TOKEN>
<TOKEN end_char="3298" id="token-43-17" morph="none" pos="word" start_char="3296">and</TOKEN>
<TOKEN end_char="3309" id="token-43-18" morph="none" pos="word" start_char="3300">presumably</TOKEN>
<TOKEN end_char="3315" id="token-43-19" morph="none" pos="word" start_char="3311">still</TOKEN>
<TOKEN end_char="3320" id="token-43-20" morph="none" pos="word" start_char="3317">well</TOKEN>
<TOKEN end_char="3327" id="token-43-21" morph="none" pos="word" start_char="3322">enough</TOKEN>
<TOKEN end_char="3330" id="token-43-22" morph="none" pos="word" start_char="3329">to</TOKEN>
<TOKEN end_char="3336" id="token-43-23" morph="none" pos="word" start_char="3332">write</TOKEN>
<TOKEN end_char="3337" id="token-43-24" morph="none" pos="punct" start_char="3337">.</TOKEN>
</SEG>
<SEG end_char="3392" id="segment-44" start_char="3339">
<ORIGINAL_TEXT>My dentist says to rinse my mouth with diluted bleach.</ORIGINAL_TEXT>
<TOKEN end_char="3340" id="token-44-0" morph="none" pos="word" start_char="3339">My</TOKEN>
<TOKEN end_char="3348" id="token-44-1" morph="none" pos="word" start_char="3342">dentist</TOKEN>
<TOKEN end_char="3353" id="token-44-2" morph="none" pos="word" start_char="3350">says</TOKEN>
<TOKEN end_char="3356" id="token-44-3" morph="none" pos="word" start_char="3355">to</TOKEN>
<TOKEN end_char="3362" id="token-44-4" morph="none" pos="word" start_char="3358">rinse</TOKEN>
<TOKEN end_char="3365" id="token-44-5" morph="none" pos="word" start_char="3364">my</TOKEN>
<TOKEN end_char="3371" id="token-44-6" morph="none" pos="word" start_char="3367">mouth</TOKEN>
<TOKEN end_char="3376" id="token-44-7" morph="none" pos="word" start_char="3373">with</TOKEN>
<TOKEN end_char="3384" id="token-44-8" morph="none" pos="word" start_char="3378">diluted</TOKEN>
<TOKEN end_char="3391" id="token-44-9" morph="none" pos="word" start_char="3386">bleach</TOKEN>
<TOKEN end_char="3392" id="token-44-10" morph="none" pos="punct" start_char="3392">.</TOKEN>
</SEG>
<SEG end_char="3477" id="segment-45" start_char="3394">
<ORIGINAL_TEXT>In fact that has been in vogue among west coast dentists for about the last 8 years.</ORIGINAL_TEXT>
<TOKEN end_char="3395" id="token-45-0" morph="none" pos="word" start_char="3394">In</TOKEN>
<TOKEN end_char="3400" id="token-45-1" morph="none" pos="word" start_char="3397">fact</TOKEN>
<TOKEN end_char="3405" id="token-45-2" morph="none" pos="word" start_char="3402">that</TOKEN>
<TOKEN end_char="3409" id="token-45-3" morph="none" pos="word" start_char="3407">has</TOKEN>
<TOKEN end_char="3414" id="token-45-4" morph="none" pos="word" start_char="3411">been</TOKEN>
<TOKEN end_char="3417" id="token-45-5" morph="none" pos="word" start_char="3416">in</TOKEN>
<TOKEN end_char="3423" id="token-45-6" morph="none" pos="word" start_char="3419">vogue</TOKEN>
<TOKEN end_char="3429" id="token-45-7" morph="none" pos="word" start_char="3425">among</TOKEN>
<TOKEN end_char="3434" id="token-45-8" morph="none" pos="word" start_char="3431">west</TOKEN>
<TOKEN end_char="3440" id="token-45-9" morph="none" pos="word" start_char="3436">coast</TOKEN>
<TOKEN end_char="3449" id="token-45-10" morph="none" pos="word" start_char="3442">dentists</TOKEN>
<TOKEN end_char="3453" id="token-45-11" morph="none" pos="word" start_char="3451">for</TOKEN>
<TOKEN end_char="3459" id="token-45-12" morph="none" pos="word" start_char="3455">about</TOKEN>
<TOKEN end_char="3463" id="token-45-13" morph="none" pos="word" start_char="3461">the</TOKEN>
<TOKEN end_char="3468" id="token-45-14" morph="none" pos="word" start_char="3465">last</TOKEN>
<TOKEN end_char="3470" id="token-45-15" morph="none" pos="word" start_char="3470">8</TOKEN>
<TOKEN end_char="3476" id="token-45-16" morph="none" pos="word" start_char="3472">years</TOKEN>
<TOKEN end_char="3477" id="token-45-17" morph="none" pos="punct" start_char="3477">.</TOKEN>
</SEG>
<SEG end_char="3555" id="segment-46" start_char="3479">
<ORIGINAL_TEXT>I refused to do it, but many are and doing great keeping the cavities at bay.</ORIGINAL_TEXT>
<TOKEN end_char="3479" id="token-46-0" morph="none" pos="word" start_char="3479">I</TOKEN>
<TOKEN end_char="3487" id="token-46-1" morph="none" pos="word" start_char="3481">refused</TOKEN>
<TOKEN end_char="3490" id="token-46-2" morph="none" pos="word" start_char="3489">to</TOKEN>
<TOKEN end_char="3493" id="token-46-3" morph="none" pos="word" start_char="3492">do</TOKEN>
<TOKEN end_char="3496" id="token-46-4" morph="none" pos="word" start_char="3495">it</TOKEN>
<TOKEN end_char="3497" id="token-46-5" morph="none" pos="punct" start_char="3497">,</TOKEN>
<TOKEN end_char="3501" id="token-46-6" morph="none" pos="word" start_char="3499">but</TOKEN>
<TOKEN end_char="3506" id="token-46-7" morph="none" pos="word" start_char="3503">many</TOKEN>
<TOKEN end_char="3510" id="token-46-8" morph="none" pos="word" start_char="3508">are</TOKEN>
<TOKEN end_char="3514" id="token-46-9" morph="none" pos="word" start_char="3512">and</TOKEN>
<TOKEN end_char="3520" id="token-46-10" morph="none" pos="word" start_char="3516">doing</TOKEN>
<TOKEN end_char="3526" id="token-46-11" morph="none" pos="word" start_char="3522">great</TOKEN>
<TOKEN end_char="3534" id="token-46-12" morph="none" pos="word" start_char="3528">keeping</TOKEN>
<TOKEN end_char="3538" id="token-46-13" morph="none" pos="word" start_char="3536">the</TOKEN>
<TOKEN end_char="3547" id="token-46-14" morph="none" pos="word" start_char="3540">cavities</TOKEN>
<TOKEN end_char="3550" id="token-46-15" morph="none" pos="word" start_char="3549">at</TOKEN>
<TOKEN end_char="3554" id="token-46-16" morph="none" pos="word" start_char="3552">bay</TOKEN>
<TOKEN end_char="3555" id="token-46-17" morph="none" pos="punct" start_char="3555">.</TOKEN>
</SEG>
<SEG end_char="3638" id="segment-47" start_char="3557">
<ORIGINAL_TEXT>So you may be right that some dilute usage is not as dangerous as one would think.</ORIGINAL_TEXT>
<TOKEN end_char="3558" id="token-47-0" morph="none" pos="word" start_char="3557">So</TOKEN>
<TOKEN end_char="3562" id="token-47-1" morph="none" pos="word" start_char="3560">you</TOKEN>
<TOKEN end_char="3566" id="token-47-2" morph="none" pos="word" start_char="3564">may</TOKEN>
<TOKEN end_char="3569" id="token-47-3" morph="none" pos="word" start_char="3568">be</TOKEN>
<TOKEN end_char="3575" id="token-47-4" morph="none" pos="word" start_char="3571">right</TOKEN>
<TOKEN end_char="3580" id="token-47-5" morph="none" pos="word" start_char="3577">that</TOKEN>
<TOKEN end_char="3585" id="token-47-6" morph="none" pos="word" start_char="3582">some</TOKEN>
<TOKEN end_char="3592" id="token-47-7" morph="none" pos="word" start_char="3587">dilute</TOKEN>
<TOKEN end_char="3598" id="token-47-8" morph="none" pos="word" start_char="3594">usage</TOKEN>
<TOKEN end_char="3601" id="token-47-9" morph="none" pos="word" start_char="3600">is</TOKEN>
<TOKEN end_char="3605" id="token-47-10" morph="none" pos="word" start_char="3603">not</TOKEN>
<TOKEN end_char="3608" id="token-47-11" morph="none" pos="word" start_char="3607">as</TOKEN>
<TOKEN end_char="3618" id="token-47-12" morph="none" pos="word" start_char="3610">dangerous</TOKEN>
<TOKEN end_char="3621" id="token-47-13" morph="none" pos="word" start_char="3620">as</TOKEN>
<TOKEN end_char="3625" id="token-47-14" morph="none" pos="word" start_char="3623">one</TOKEN>
<TOKEN end_char="3631" id="token-47-15" morph="none" pos="word" start_char="3627">would</TOKEN>
<TOKEN end_char="3637" id="token-47-16" morph="none" pos="word" start_char="3633">think</TOKEN>
<TOKEN end_char="3638" id="token-47-17" morph="none" pos="punct" start_char="3638">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
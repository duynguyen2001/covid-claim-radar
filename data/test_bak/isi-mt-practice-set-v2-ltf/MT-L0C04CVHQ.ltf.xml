<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CVHQ" lang="spa" raw_text_char_length="1649" raw_text_md5="4dba1bfe3d5e94399e59038bfa6dcf27" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="72" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Why doesn’t Florida use contact tracing apps to help combat coronavirus?</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">Why</TOKEN>
<TOKEN end_char="11" id="token-0-1" morph="none" pos="word" start_char="5">doesn’t</TOKEN>
<TOKEN end_char="19" id="token-0-2" morph="none" pos="word" start_char="13">Florida</TOKEN>
<TOKEN end_char="23" id="token-0-3" morph="none" pos="word" start_char="21">use</TOKEN>
<TOKEN end_char="31" id="token-0-4" morph="none" pos="word" start_char="25">contact</TOKEN>
<TOKEN end_char="39" id="token-0-5" morph="none" pos="word" start_char="33">tracing</TOKEN>
<TOKEN end_char="44" id="token-0-6" morph="none" pos="word" start_char="41">apps</TOKEN>
<TOKEN end_char="47" id="token-0-7" morph="none" pos="word" start_char="46">to</TOKEN>
<TOKEN end_char="52" id="token-0-8" morph="none" pos="word" start_char="49">help</TOKEN>
<TOKEN end_char="59" id="token-0-9" morph="none" pos="word" start_char="54">combat</TOKEN>
<TOKEN end_char="71" id="token-0-10" morph="none" pos="word" start_char="61">coronavirus</TOKEN>
<TOKEN end_char="72" id="token-0-11" morph="none" pos="punct" start_char="72">?</TOKEN>
</SEG>
<SEG end_char="86" id="segment-1" start_char="76">
<ORIGINAL_TEXT>TAMPA, Fla.</ORIGINAL_TEXT>
<TOKEN end_char="80" id="token-1-0" morph="none" pos="word" start_char="76">TAMPA</TOKEN>
<TOKEN end_char="81" id="token-1-1" morph="none" pos="punct" start_char="81">,</TOKEN>
<TOKEN end_char="85" id="token-1-2" morph="none" pos="word" start_char="83">Fla</TOKEN>
<TOKEN end_char="86" id="token-1-3" morph="none" pos="punct" start_char="86">.</TOKEN>
<TRANSLATED_TEXT>Tampa, Fla.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="200" id="segment-2" start_char="88">
<ORIGINAL_TEXT>(WFLA) — As COVID-19 cases surge across the country, states are looking for ways to slow the spread of the virus.</ORIGINAL_TEXT>
<TOKEN end_char="88" id="token-2-0" morph="none" pos="punct" start_char="88">(</TOKEN>
<TOKEN end_char="92" id="token-2-1" morph="none" pos="word" start_char="89">WFLA</TOKEN>
<TOKEN end_char="93" id="token-2-2" morph="none" pos="punct" start_char="93">)</TOKEN>
<TOKEN end_char="95" id="token-2-3" morph="none" pos="punct" start_char="95">—</TOKEN>
<TOKEN end_char="98" id="token-2-4" morph="none" pos="word" start_char="97">As</TOKEN>
<TOKEN end_char="107" id="token-2-5" morph="none" pos="unknown" start_char="100">COVID-19</TOKEN>
<TOKEN end_char="113" id="token-2-6" morph="none" pos="word" start_char="109">cases</TOKEN>
<TOKEN end_char="119" id="token-2-7" morph="none" pos="word" start_char="115">surge</TOKEN>
<TOKEN end_char="126" id="token-2-8" morph="none" pos="word" start_char="121">across</TOKEN>
<TOKEN end_char="130" id="token-2-9" morph="none" pos="word" start_char="128">the</TOKEN>
<TOKEN end_char="138" id="token-2-10" morph="none" pos="word" start_char="132">country</TOKEN>
<TOKEN end_char="139" id="token-2-11" morph="none" pos="punct" start_char="139">,</TOKEN>
<TOKEN end_char="146" id="token-2-12" morph="none" pos="word" start_char="141">states</TOKEN>
<TOKEN end_char="150" id="token-2-13" morph="none" pos="word" start_char="148">are</TOKEN>
<TOKEN end_char="158" id="token-2-14" morph="none" pos="word" start_char="152">looking</TOKEN>
<TOKEN end_char="162" id="token-2-15" morph="none" pos="word" start_char="160">for</TOKEN>
<TOKEN end_char="167" id="token-2-16" morph="none" pos="word" start_char="164">ways</TOKEN>
<TOKEN end_char="170" id="token-2-17" morph="none" pos="word" start_char="169">to</TOKEN>
<TOKEN end_char="175" id="token-2-18" morph="none" pos="word" start_char="172">slow</TOKEN>
<TOKEN end_char="179" id="token-2-19" morph="none" pos="word" start_char="177">the</TOKEN>
<TOKEN end_char="186" id="token-2-20" morph="none" pos="word" start_char="181">spread</TOKEN>
<TOKEN end_char="189" id="token-2-21" morph="none" pos="word" start_char="188">of</TOKEN>
<TOKEN end_char="193" id="token-2-22" morph="none" pos="word" start_char="191">the</TOKEN>
<TOKEN end_char="199" id="token-2-23" morph="none" pos="word" start_char="195">virus</TOKEN>
<TOKEN end_char="200" id="token-2-24" morph="none" pos="punct" start_char="200">.</TOKEN>
</SEG>
<SEG end_char="301" id="segment-3" start_char="203">
<ORIGINAL_TEXT>There’s a tool health experts say could help, but has yet to really take off: Contact tracing apps.</ORIGINAL_TEXT>
<TOKEN end_char="209" id="token-3-0" morph="none" pos="word" start_char="203">There’s</TOKEN>
<TOKEN end_char="211" id="token-3-1" morph="none" pos="word" start_char="211">a</TOKEN>
<TOKEN end_char="216" id="token-3-2" morph="none" pos="word" start_char="213">tool</TOKEN>
<TOKEN end_char="223" id="token-3-3" morph="none" pos="word" start_char="218">health</TOKEN>
<TOKEN end_char="231" id="token-3-4" morph="none" pos="word" start_char="225">experts</TOKEN>
<TOKEN end_char="235" id="token-3-5" morph="none" pos="word" start_char="233">say</TOKEN>
<TOKEN end_char="241" id="token-3-6" morph="none" pos="word" start_char="237">could</TOKEN>
<TOKEN end_char="246" id="token-3-7" morph="none" pos="word" start_char="243">help</TOKEN>
<TOKEN end_char="247" id="token-3-8" morph="none" pos="punct" start_char="247">,</TOKEN>
<TOKEN end_char="251" id="token-3-9" morph="none" pos="word" start_char="249">but</TOKEN>
<TOKEN end_char="255" id="token-3-10" morph="none" pos="word" start_char="253">has</TOKEN>
<TOKEN end_char="259" id="token-3-11" morph="none" pos="word" start_char="257">yet</TOKEN>
<TOKEN end_char="262" id="token-3-12" morph="none" pos="word" start_char="261">to</TOKEN>
<TOKEN end_char="269" id="token-3-13" morph="none" pos="word" start_char="264">really</TOKEN>
<TOKEN end_char="274" id="token-3-14" morph="none" pos="word" start_char="271">take</TOKEN>
<TOKEN end_char="278" id="token-3-15" morph="none" pos="word" start_char="276">off</TOKEN>
<TOKEN end_char="279" id="token-3-16" morph="none" pos="punct" start_char="279">:</TOKEN>
<TOKEN end_char="287" id="token-3-17" morph="none" pos="word" start_char="281">Contact</TOKEN>
<TOKEN end_char="295" id="token-3-18" morph="none" pos="word" start_char="289">tracing</TOKEN>
<TOKEN end_char="300" id="token-3-19" morph="none" pos="word" start_char="297">apps</TOKEN>
<TOKEN end_char="301" id="token-3-20" morph="none" pos="punct" start_char="301">.</TOKEN>
</SEG>
<SEG end_char="428" id="segment-4" start_char="303">
<ORIGINAL_TEXT>States that have rolled out apps are seeing low enrollment numbers as residents are hesitant to sign up over privacy concerns.</ORIGINAL_TEXT>
<TOKEN end_char="308" id="token-4-0" morph="none" pos="word" start_char="303">States</TOKEN>
<TOKEN end_char="313" id="token-4-1" morph="none" pos="word" start_char="310">that</TOKEN>
<TOKEN end_char="318" id="token-4-2" morph="none" pos="word" start_char="315">have</TOKEN>
<TOKEN end_char="325" id="token-4-3" morph="none" pos="word" start_char="320">rolled</TOKEN>
<TOKEN end_char="329" id="token-4-4" morph="none" pos="word" start_char="327">out</TOKEN>
<TOKEN end_char="334" id="token-4-5" morph="none" pos="word" start_char="331">apps</TOKEN>
<TOKEN end_char="338" id="token-4-6" morph="none" pos="word" start_char="336">are</TOKEN>
<TOKEN end_char="345" id="token-4-7" morph="none" pos="word" start_char="340">seeing</TOKEN>
<TOKEN end_char="349" id="token-4-8" morph="none" pos="word" start_char="347">low</TOKEN>
<TOKEN end_char="360" id="token-4-9" morph="none" pos="word" start_char="351">enrollment</TOKEN>
<TOKEN end_char="368" id="token-4-10" morph="none" pos="word" start_char="362">numbers</TOKEN>
<TOKEN end_char="371" id="token-4-11" morph="none" pos="word" start_char="370">as</TOKEN>
<TOKEN end_char="381" id="token-4-12" morph="none" pos="word" start_char="373">residents</TOKEN>
<TOKEN end_char="385" id="token-4-13" morph="none" pos="word" start_char="383">are</TOKEN>
<TOKEN end_char="394" id="token-4-14" morph="none" pos="word" start_char="387">hesitant</TOKEN>
<TOKEN end_char="397" id="token-4-15" morph="none" pos="word" start_char="396">to</TOKEN>
<TOKEN end_char="402" id="token-4-16" morph="none" pos="word" start_char="399">sign</TOKEN>
<TOKEN end_char="405" id="token-4-17" morph="none" pos="word" start_char="404">up</TOKEN>
<TOKEN end_char="410" id="token-4-18" morph="none" pos="word" start_char="407">over</TOKEN>
<TOKEN end_char="418" id="token-4-19" morph="none" pos="word" start_char="412">privacy</TOKEN>
<TOKEN end_char="427" id="token-4-20" morph="none" pos="word" start_char="420">concerns</TOKEN>
<TOKEN end_char="428" id="token-4-21" morph="none" pos="punct" start_char="428">.</TOKEN>
</SEG>
<SEG end_char="497" id="segment-5" start_char="431">
<ORIGINAL_TEXT>"People are very reluctant to share any information right now," Dr.</ORIGINAL_TEXT>
<TOKEN end_char="431" id="token-5-0" morph="none" pos="punct" start_char="431">"</TOKEN>
<TOKEN end_char="437" id="token-5-1" morph="none" pos="word" start_char="432">People</TOKEN>
<TOKEN end_char="441" id="token-5-2" morph="none" pos="word" start_char="439">are</TOKEN>
<TOKEN end_char="446" id="token-5-3" morph="none" pos="word" start_char="443">very</TOKEN>
<TOKEN end_char="456" id="token-5-4" morph="none" pos="word" start_char="448">reluctant</TOKEN>
<TOKEN end_char="459" id="token-5-5" morph="none" pos="word" start_char="458">to</TOKEN>
<TOKEN end_char="465" id="token-5-6" morph="none" pos="word" start_char="461">share</TOKEN>
<TOKEN end_char="469" id="token-5-7" morph="none" pos="word" start_char="467">any</TOKEN>
<TOKEN end_char="481" id="token-5-8" morph="none" pos="word" start_char="471">information</TOKEN>
<TOKEN end_char="487" id="token-5-9" morph="none" pos="word" start_char="483">right</TOKEN>
<TOKEN end_char="491" id="token-5-10" morph="none" pos="word" start_char="489">now</TOKEN>
<TOKEN end_char="493" id="token-5-11" morph="none" pos="punct" start_char="492">,"</TOKEN>
<TOKEN end_char="496" id="token-5-12" morph="none" pos="word" start_char="495">Dr</TOKEN>
<TOKEN end_char="497" id="token-5-13" morph="none" pos="punct" start_char="497">.</TOKEN>
</SEG>
<SEG end_char="568" id="segment-6" start_char="499">
<ORIGINAL_TEXT>Jay Wolfson, the senior associate dean at Morsani College of Medicine.</ORIGINAL_TEXT>
<TOKEN end_char="501" id="token-6-0" morph="none" pos="word" start_char="499">Jay</TOKEN>
<TOKEN end_char="509" id="token-6-1" morph="none" pos="word" start_char="503">Wolfson</TOKEN>
<TOKEN end_char="510" id="token-6-2" morph="none" pos="punct" start_char="510">,</TOKEN>
<TOKEN end_char="514" id="token-6-3" morph="none" pos="word" start_char="512">the</TOKEN>
<TOKEN end_char="521" id="token-6-4" morph="none" pos="word" start_char="516">senior</TOKEN>
<TOKEN end_char="531" id="token-6-5" morph="none" pos="word" start_char="523">associate</TOKEN>
<TOKEN end_char="536" id="token-6-6" morph="none" pos="word" start_char="533">dean</TOKEN>
<TOKEN end_char="539" id="token-6-7" morph="none" pos="word" start_char="538">at</TOKEN>
<TOKEN end_char="547" id="token-6-8" morph="none" pos="word" start_char="541">Morsani</TOKEN>
<TOKEN end_char="555" id="token-6-9" morph="none" pos="word" start_char="549">College</TOKEN>
<TOKEN end_char="558" id="token-6-10" morph="none" pos="word" start_char="557">of</TOKEN>
<TOKEN end_char="567" id="token-6-11" morph="none" pos="word" start_char="560">Medicine</TOKEN>
<TOKEN end_char="568" id="token-6-12" morph="none" pos="punct" start_char="568">.</TOKEN>
</SEG>
<SEG end_char="686" id="segment-7" start_char="571">
<ORIGINAL_TEXT>Unlike states like New York, New Jersey, Virginia and Nevada, Florida does not have an official contact tracing app.</ORIGINAL_TEXT>
<TOKEN end_char="576" id="token-7-0" morph="none" pos="word" start_char="571">Unlike</TOKEN>
<TOKEN end_char="583" id="token-7-1" morph="none" pos="word" start_char="578">states</TOKEN>
<TOKEN end_char="588" id="token-7-2" morph="none" pos="word" start_char="585">like</TOKEN>
<TOKEN end_char="592" id="token-7-3" morph="none" pos="word" start_char="590">New</TOKEN>
<TOKEN end_char="597" id="token-7-4" morph="none" pos="word" start_char="594">York</TOKEN>
<TOKEN end_char="598" id="token-7-5" morph="none" pos="punct" start_char="598">,</TOKEN>
<TOKEN end_char="602" id="token-7-6" morph="none" pos="word" start_char="600">New</TOKEN>
<TOKEN end_char="609" id="token-7-7" morph="none" pos="word" start_char="604">Jersey</TOKEN>
<TOKEN end_char="610" id="token-7-8" morph="none" pos="punct" start_char="610">,</TOKEN>
<TOKEN end_char="619" id="token-7-9" morph="none" pos="word" start_char="612">Virginia</TOKEN>
<TOKEN end_char="623" id="token-7-10" morph="none" pos="word" start_char="621">and</TOKEN>
<TOKEN end_char="630" id="token-7-11" morph="none" pos="word" start_char="625">Nevada</TOKEN>
<TOKEN end_char="631" id="token-7-12" morph="none" pos="punct" start_char="631">,</TOKEN>
<TOKEN end_char="639" id="token-7-13" morph="none" pos="word" start_char="633">Florida</TOKEN>
<TOKEN end_char="644" id="token-7-14" morph="none" pos="word" start_char="641">does</TOKEN>
<TOKEN end_char="648" id="token-7-15" morph="none" pos="word" start_char="646">not</TOKEN>
<TOKEN end_char="653" id="token-7-16" morph="none" pos="word" start_char="650">have</TOKEN>
<TOKEN end_char="656" id="token-7-17" morph="none" pos="word" start_char="655">an</TOKEN>
<TOKEN end_char="665" id="token-7-18" morph="none" pos="word" start_char="658">official</TOKEN>
<TOKEN end_char="673" id="token-7-19" morph="none" pos="word" start_char="667">contact</TOKEN>
<TOKEN end_char="681" id="token-7-20" morph="none" pos="word" start_char="675">tracing</TOKEN>
<TOKEN end_char="685" id="token-7-21" morph="none" pos="word" start_char="683">app</TOKEN>
<TOKEN end_char="686" id="token-7-22" morph="none" pos="punct" start_char="686">.</TOKEN>
</SEG>
<SEG end_char="853" id="segment-8" start_char="689">
<ORIGINAL_TEXT>"The state’s resources are limited and the state is putting all the resources and the data management into vaccination preparation and [traditional] contact tracing.</ORIGINAL_TEXT>
<TOKEN end_char="689" id="token-8-0" morph="none" pos="punct" start_char="689">"</TOKEN>
<TOKEN end_char="692" id="token-8-1" morph="none" pos="word" start_char="690">The</TOKEN>
<TOKEN end_char="700" id="token-8-2" morph="none" pos="word" start_char="694">state’s</TOKEN>
<TOKEN end_char="710" id="token-8-3" morph="none" pos="word" start_char="702">resources</TOKEN>
<TOKEN end_char="714" id="token-8-4" morph="none" pos="word" start_char="712">are</TOKEN>
<TOKEN end_char="722" id="token-8-5" morph="none" pos="word" start_char="716">limited</TOKEN>
<TOKEN end_char="726" id="token-8-6" morph="none" pos="word" start_char="724">and</TOKEN>
<TOKEN end_char="730" id="token-8-7" morph="none" pos="word" start_char="728">the</TOKEN>
<TOKEN end_char="736" id="token-8-8" morph="none" pos="word" start_char="732">state</TOKEN>
<TOKEN end_char="739" id="token-8-9" morph="none" pos="word" start_char="738">is</TOKEN>
<TOKEN end_char="747" id="token-8-10" morph="none" pos="word" start_char="741">putting</TOKEN>
<TOKEN end_char="751" id="token-8-11" morph="none" pos="word" start_char="749">all</TOKEN>
<TOKEN end_char="755" id="token-8-12" morph="none" pos="word" start_char="753">the</TOKEN>
<TOKEN end_char="765" id="token-8-13" morph="none" pos="word" start_char="757">resources</TOKEN>
<TOKEN end_char="769" id="token-8-14" morph="none" pos="word" start_char="767">and</TOKEN>
<TOKEN end_char="773" id="token-8-15" morph="none" pos="word" start_char="771">the</TOKEN>
<TOKEN end_char="778" id="token-8-16" morph="none" pos="word" start_char="775">data</TOKEN>
<TOKEN end_char="789" id="token-8-17" morph="none" pos="word" start_char="780">management</TOKEN>
<TOKEN end_char="794" id="token-8-18" morph="none" pos="word" start_char="791">into</TOKEN>
<TOKEN end_char="806" id="token-8-19" morph="none" pos="word" start_char="796">vaccination</TOKEN>
<TOKEN end_char="818" id="token-8-20" morph="none" pos="word" start_char="808">preparation</TOKEN>
<TOKEN end_char="822" id="token-8-21" morph="none" pos="word" start_char="820">and</TOKEN>
<TOKEN end_char="824" id="token-8-22" morph="none" pos="punct" start_char="824">[</TOKEN>
<TOKEN end_char="835" id="token-8-23" morph="none" pos="word" start_char="825">traditional</TOKEN>
<TOKEN end_char="836" id="token-8-24" morph="none" pos="punct" start_char="836">]</TOKEN>
<TOKEN end_char="844" id="token-8-25" morph="none" pos="word" start_char="838">contact</TOKEN>
<TOKEN end_char="852" id="token-8-26" morph="none" pos="word" start_char="846">tracing</TOKEN>
<TOKEN end_char="853" id="token-8-27" morph="none" pos="punct" start_char="853">.</TOKEN>
</SEG>
<SEG end_char="984" id="segment-9" start_char="855">
<ORIGINAL_TEXT>We are one of four states participating in a pilot study to figure out how to logistically distribute the stuff once it gets here.</ORIGINAL_TEXT>
<TOKEN end_char="856" id="token-9-0" morph="none" pos="word" start_char="855">We</TOKEN>
<TOKEN end_char="860" id="token-9-1" morph="none" pos="word" start_char="858">are</TOKEN>
<TOKEN end_char="864" id="token-9-2" morph="none" pos="word" start_char="862">one</TOKEN>
<TOKEN end_char="867" id="token-9-3" morph="none" pos="word" start_char="866">of</TOKEN>
<TOKEN end_char="872" id="token-9-4" morph="none" pos="word" start_char="869">four</TOKEN>
<TOKEN end_char="879" id="token-9-5" morph="none" pos="word" start_char="874">states</TOKEN>
<TOKEN end_char="893" id="token-9-6" morph="none" pos="word" start_char="881">participating</TOKEN>
<TOKEN end_char="896" id="token-9-7" morph="none" pos="word" start_char="895">in</TOKEN>
<TOKEN end_char="898" id="token-9-8" morph="none" pos="word" start_char="898">a</TOKEN>
<TOKEN end_char="904" id="token-9-9" morph="none" pos="word" start_char="900">pilot</TOKEN>
<TOKEN end_char="910" id="token-9-10" morph="none" pos="word" start_char="906">study</TOKEN>
<TOKEN end_char="913" id="token-9-11" morph="none" pos="word" start_char="912">to</TOKEN>
<TOKEN end_char="920" id="token-9-12" morph="none" pos="word" start_char="915">figure</TOKEN>
<TOKEN end_char="924" id="token-9-13" morph="none" pos="word" start_char="922">out</TOKEN>
<TOKEN end_char="928" id="token-9-14" morph="none" pos="word" start_char="926">how</TOKEN>
<TOKEN end_char="931" id="token-9-15" morph="none" pos="word" start_char="930">to</TOKEN>
<TOKEN end_char="944" id="token-9-16" morph="none" pos="word" start_char="933">logistically</TOKEN>
<TOKEN end_char="955" id="token-9-17" morph="none" pos="word" start_char="946">distribute</TOKEN>
<TOKEN end_char="959" id="token-9-18" morph="none" pos="word" start_char="957">the</TOKEN>
<TOKEN end_char="965" id="token-9-19" morph="none" pos="word" start_char="961">stuff</TOKEN>
<TOKEN end_char="970" id="token-9-20" morph="none" pos="word" start_char="967">once</TOKEN>
<TOKEN end_char="973" id="token-9-21" morph="none" pos="word" start_char="972">it</TOKEN>
<TOKEN end_char="978" id="token-9-22" morph="none" pos="word" start_char="975">gets</TOKEN>
<TOKEN end_char="983" id="token-9-23" morph="none" pos="word" start_char="980">here</TOKEN>
<TOKEN end_char="984" id="token-9-24" morph="none" pos="punct" start_char="984">.</TOKEN>
</SEG>
<SEG end_char="1055" id="segment-10" start_char="986">
<ORIGINAL_TEXT>Once the vaccine gets here, it is a huge endeavor," Wolfson explained.</ORIGINAL_TEXT>
<TOKEN end_char="989" id="token-10-0" morph="none" pos="word" start_char="986">Once</TOKEN>
<TOKEN end_char="993" id="token-10-1" morph="none" pos="word" start_char="991">the</TOKEN>
<TOKEN end_char="1001" id="token-10-2" morph="none" pos="word" start_char="995">vaccine</TOKEN>
<TOKEN end_char="1006" id="token-10-3" morph="none" pos="word" start_char="1003">gets</TOKEN>
<TOKEN end_char="1011" id="token-10-4" morph="none" pos="word" start_char="1008">here</TOKEN>
<TOKEN end_char="1012" id="token-10-5" morph="none" pos="punct" start_char="1012">,</TOKEN>
<TOKEN end_char="1015" id="token-10-6" morph="none" pos="word" start_char="1014">it</TOKEN>
<TOKEN end_char="1018" id="token-10-7" morph="none" pos="word" start_char="1017">is</TOKEN>
<TOKEN end_char="1020" id="token-10-8" morph="none" pos="word" start_char="1020">a</TOKEN>
<TOKEN end_char="1025" id="token-10-9" morph="none" pos="word" start_char="1022">huge</TOKEN>
<TOKEN end_char="1034" id="token-10-10" morph="none" pos="word" start_char="1027">endeavor</TOKEN>
<TOKEN end_char="1036" id="token-10-11" morph="none" pos="punct" start_char="1035">,"</TOKEN>
<TOKEN end_char="1044" id="token-10-12" morph="none" pos="word" start_char="1038">Wolfson</TOKEN>
<TOKEN end_char="1054" id="token-10-13" morph="none" pos="word" start_char="1046">explained</TOKEN>
<TOKEN end_char="1055" id="token-10-14" morph="none" pos="punct" start_char="1055">.</TOKEN>
</SEG>
<SEG end_char="1124" id="segment-11" start_char="1057">
<ORIGINAL_TEXT>"We don’t really have a health department that is that well-staffed.</ORIGINAL_TEXT>
<TOKEN end_char="1057" id="token-11-0" morph="none" pos="punct" start_char="1057">"</TOKEN>
<TOKEN end_char="1059" id="token-11-1" morph="none" pos="word" start_char="1058">We</TOKEN>
<TOKEN end_char="1065" id="token-11-2" morph="none" pos="word" start_char="1061">don’t</TOKEN>
<TOKEN end_char="1072" id="token-11-3" morph="none" pos="word" start_char="1067">really</TOKEN>
<TOKEN end_char="1077" id="token-11-4" morph="none" pos="word" start_char="1074">have</TOKEN>
<TOKEN end_char="1079" id="token-11-5" morph="none" pos="word" start_char="1079">a</TOKEN>
<TOKEN end_char="1086" id="token-11-6" morph="none" pos="word" start_char="1081">health</TOKEN>
<TOKEN end_char="1097" id="token-11-7" morph="none" pos="word" start_char="1088">department</TOKEN>
<TOKEN end_char="1102" id="token-11-8" morph="none" pos="word" start_char="1099">that</TOKEN>
<TOKEN end_char="1105" id="token-11-9" morph="none" pos="word" start_char="1104">is</TOKEN>
<TOKEN end_char="1110" id="token-11-10" morph="none" pos="word" start_char="1107">that</TOKEN>
<TOKEN end_char="1123" id="token-11-11" morph="none" pos="unknown" start_char="1112">well-staffed</TOKEN>
<TOKEN end_char="1124" id="token-11-12" morph="none" pos="punct" start_char="1124">.</TOKEN>
</SEG>
<SEG end_char="1238" id="segment-12" start_char="1126">
<ORIGINAL_TEXT>For the last 20 years or so, the legislature underfunded – in some cases defunded – our state health department."</ORIGINAL_TEXT>
<TOKEN end_char="1128" id="token-12-0" morph="none" pos="word" start_char="1126">For</TOKEN>
<TOKEN end_char="1132" id="token-12-1" morph="none" pos="word" start_char="1130">the</TOKEN>
<TOKEN end_char="1137" id="token-12-2" morph="none" pos="word" start_char="1134">last</TOKEN>
<TOKEN end_char="1140" id="token-12-3" morph="none" pos="word" start_char="1139">20</TOKEN>
<TOKEN end_char="1146" id="token-12-4" morph="none" pos="word" start_char="1142">years</TOKEN>
<TOKEN end_char="1149" id="token-12-5" morph="none" pos="word" start_char="1148">or</TOKEN>
<TOKEN end_char="1152" id="token-12-6" morph="none" pos="word" start_char="1151">so</TOKEN>
<TOKEN end_char="1153" id="token-12-7" morph="none" pos="punct" start_char="1153">,</TOKEN>
<TOKEN end_char="1157" id="token-12-8" morph="none" pos="word" start_char="1155">the</TOKEN>
<TOKEN end_char="1169" id="token-12-9" morph="none" pos="word" start_char="1159">legislature</TOKEN>
<TOKEN end_char="1181" id="token-12-10" morph="none" pos="word" start_char="1171">underfunded</TOKEN>
<TOKEN end_char="1183" id="token-12-11" morph="none" pos="punct" start_char="1183">–</TOKEN>
<TOKEN end_char="1186" id="token-12-12" morph="none" pos="word" start_char="1185">in</TOKEN>
<TOKEN end_char="1191" id="token-12-13" morph="none" pos="word" start_char="1188">some</TOKEN>
<TOKEN end_char="1197" id="token-12-14" morph="none" pos="word" start_char="1193">cases</TOKEN>
<TOKEN end_char="1206" id="token-12-15" morph="none" pos="word" start_char="1199">defunded</TOKEN>
<TOKEN end_char="1208" id="token-12-16" morph="none" pos="punct" start_char="1208">–</TOKEN>
<TOKEN end_char="1212" id="token-12-17" morph="none" pos="word" start_char="1210">our</TOKEN>
<TOKEN end_char="1218" id="token-12-18" morph="none" pos="word" start_char="1214">state</TOKEN>
<TOKEN end_char="1225" id="token-12-19" morph="none" pos="word" start_char="1220">health</TOKEN>
<TOKEN end_char="1236" id="token-12-20" morph="none" pos="word" start_char="1227">department</TOKEN>
<TOKEN end_char="1238" id="token-12-21" morph="none" pos="punct" start_char="1237">."</TOKEN>
</SEG>
<SEG end_char="1374" id="segment-13" start_char="1241">
<ORIGINAL_TEXT>Wolfson believes contact tracing apps could help but they are not being marketed enough by states and people are reluctant to sign up.</ORIGINAL_TEXT>
<TOKEN end_char="1247" id="token-13-0" morph="none" pos="word" start_char="1241">Wolfson</TOKEN>
<TOKEN end_char="1256" id="token-13-1" morph="none" pos="word" start_char="1249">believes</TOKEN>
<TOKEN end_char="1264" id="token-13-2" morph="none" pos="word" start_char="1258">contact</TOKEN>
<TOKEN end_char="1272" id="token-13-3" morph="none" pos="word" start_char="1266">tracing</TOKEN>
<TOKEN end_char="1277" id="token-13-4" morph="none" pos="word" start_char="1274">apps</TOKEN>
<TOKEN end_char="1283" id="token-13-5" morph="none" pos="word" start_char="1279">could</TOKEN>
<TOKEN end_char="1288" id="token-13-6" morph="none" pos="word" start_char="1285">help</TOKEN>
<TOKEN end_char="1292" id="token-13-7" morph="none" pos="word" start_char="1290">but</TOKEN>
<TOKEN end_char="1297" id="token-13-8" morph="none" pos="word" start_char="1294">they</TOKEN>
<TOKEN end_char="1301" id="token-13-9" morph="none" pos="word" start_char="1299">are</TOKEN>
<TOKEN end_char="1305" id="token-13-10" morph="none" pos="word" start_char="1303">not</TOKEN>
<TOKEN end_char="1311" id="token-13-11" morph="none" pos="word" start_char="1307">being</TOKEN>
<TOKEN end_char="1320" id="token-13-12" morph="none" pos="word" start_char="1313">marketed</TOKEN>
<TOKEN end_char="1327" id="token-13-13" morph="none" pos="word" start_char="1322">enough</TOKEN>
<TOKEN end_char="1330" id="token-13-14" morph="none" pos="word" start_char="1329">by</TOKEN>
<TOKEN end_char="1337" id="token-13-15" morph="none" pos="word" start_char="1332">states</TOKEN>
<TOKEN end_char="1341" id="token-13-16" morph="none" pos="word" start_char="1339">and</TOKEN>
<TOKEN end_char="1348" id="token-13-17" morph="none" pos="word" start_char="1343">people</TOKEN>
<TOKEN end_char="1352" id="token-13-18" morph="none" pos="word" start_char="1350">are</TOKEN>
<TOKEN end_char="1362" id="token-13-19" morph="none" pos="word" start_char="1354">reluctant</TOKEN>
<TOKEN end_char="1365" id="token-13-20" morph="none" pos="word" start_char="1364">to</TOKEN>
<TOKEN end_char="1370" id="token-13-21" morph="none" pos="word" start_char="1367">sign</TOKEN>
<TOKEN end_char="1373" id="token-13-22" morph="none" pos="word" start_char="1372">up</TOKEN>
<TOKEN end_char="1374" id="token-13-23" morph="none" pos="punct" start_char="1374">.</TOKEN>
</SEG>
<SEG end_char="1428" id="segment-14" start_char="1377">
<ORIGINAL_TEXT>"Even 10-15% [people signing up] makes a difference.</ORIGINAL_TEXT>
<TOKEN end_char="1377" id="token-14-0" morph="none" pos="punct" start_char="1377">"</TOKEN>
<TOKEN end_char="1381" id="token-14-1" morph="none" pos="word" start_char="1378">Even</TOKEN>
<TOKEN end_char="1387" id="token-14-2" morph="none" pos="unknown" start_char="1383">10-15</TOKEN>
<TOKEN end_char="1388" id="token-14-3" morph="none" pos="punct" start_char="1388">%</TOKEN>
<TOKEN end_char="1390" id="token-14-4" morph="none" pos="punct" start_char="1390">[</TOKEN>
<TOKEN end_char="1396" id="token-14-5" morph="none" pos="word" start_char="1391">people</TOKEN>
<TOKEN end_char="1404" id="token-14-6" morph="none" pos="word" start_char="1398">signing</TOKEN>
<TOKEN end_char="1407" id="token-14-7" morph="none" pos="word" start_char="1406">up</TOKEN>
<TOKEN end_char="1408" id="token-14-8" morph="none" pos="punct" start_char="1408">]</TOKEN>
<TOKEN end_char="1414" id="token-14-9" morph="none" pos="word" start_char="1410">makes</TOKEN>
<TOKEN end_char="1416" id="token-14-10" morph="none" pos="word" start_char="1416">a</TOKEN>
<TOKEN end_char="1427" id="token-14-11" morph="none" pos="word" start_char="1418">difference</TOKEN>
<TOKEN end_char="1428" id="token-14-12" morph="none" pos="punct" start_char="1428">.</TOKEN>
</SEG>
<SEG end_char="1636" id="segment-15" start_char="1430">
<ORIGINAL_TEXT>I mean you may not find everybody but anything you can do to push that curve down, to early identify people who have been exposed or potentially exposed, that can make a tremendous difference," said Wolfson.</ORIGINAL_TEXT>
<TOKEN end_char="1430" id="token-15-0" morph="none" pos="word" start_char="1430">I</TOKEN>
<TOKEN end_char="1435" id="token-15-1" morph="none" pos="word" start_char="1432">mean</TOKEN>
<TOKEN end_char="1439" id="token-15-2" morph="none" pos="word" start_char="1437">you</TOKEN>
<TOKEN end_char="1443" id="token-15-3" morph="none" pos="word" start_char="1441">may</TOKEN>
<TOKEN end_char="1447" id="token-15-4" morph="none" pos="word" start_char="1445">not</TOKEN>
<TOKEN end_char="1452" id="token-15-5" morph="none" pos="word" start_char="1449">find</TOKEN>
<TOKEN end_char="1462" id="token-15-6" morph="none" pos="word" start_char="1454">everybody</TOKEN>
<TOKEN end_char="1466" id="token-15-7" morph="none" pos="word" start_char="1464">but</TOKEN>
<TOKEN end_char="1475" id="token-15-8" morph="none" pos="word" start_char="1468">anything</TOKEN>
<TOKEN end_char="1479" id="token-15-9" morph="none" pos="word" start_char="1477">you</TOKEN>
<TOKEN end_char="1483" id="token-15-10" morph="none" pos="word" start_char="1481">can</TOKEN>
<TOKEN end_char="1486" id="token-15-11" morph="none" pos="word" start_char="1485">do</TOKEN>
<TOKEN end_char="1489" id="token-15-12" morph="none" pos="word" start_char="1488">to</TOKEN>
<TOKEN end_char="1494" id="token-15-13" morph="none" pos="word" start_char="1491">push</TOKEN>
<TOKEN end_char="1499" id="token-15-14" morph="none" pos="word" start_char="1496">that</TOKEN>
<TOKEN end_char="1505" id="token-15-15" morph="none" pos="word" start_char="1501">curve</TOKEN>
<TOKEN end_char="1510" id="token-15-16" morph="none" pos="word" start_char="1507">down</TOKEN>
<TOKEN end_char="1511" id="token-15-17" morph="none" pos="punct" start_char="1511">,</TOKEN>
<TOKEN end_char="1514" id="token-15-18" morph="none" pos="word" start_char="1513">to</TOKEN>
<TOKEN end_char="1520" id="token-15-19" morph="none" pos="word" start_char="1516">early</TOKEN>
<TOKEN end_char="1529" id="token-15-20" morph="none" pos="word" start_char="1522">identify</TOKEN>
<TOKEN end_char="1536" id="token-15-21" morph="none" pos="word" start_char="1531">people</TOKEN>
<TOKEN end_char="1540" id="token-15-22" morph="none" pos="word" start_char="1538">who</TOKEN>
<TOKEN end_char="1545" id="token-15-23" morph="none" pos="word" start_char="1542">have</TOKEN>
<TOKEN end_char="1550" id="token-15-24" morph="none" pos="word" start_char="1547">been</TOKEN>
<TOKEN end_char="1558" id="token-15-25" morph="none" pos="word" start_char="1552">exposed</TOKEN>
<TOKEN end_char="1561" id="token-15-26" morph="none" pos="word" start_char="1560">or</TOKEN>
<TOKEN end_char="1573" id="token-15-27" morph="none" pos="word" start_char="1563">potentially</TOKEN>
<TOKEN end_char="1581" id="token-15-28" morph="none" pos="word" start_char="1575">exposed</TOKEN>
<TOKEN end_char="1582" id="token-15-29" morph="none" pos="punct" start_char="1582">,</TOKEN>
<TOKEN end_char="1587" id="token-15-30" morph="none" pos="word" start_char="1584">that</TOKEN>
<TOKEN end_char="1591" id="token-15-31" morph="none" pos="word" start_char="1589">can</TOKEN>
<TOKEN end_char="1596" id="token-15-32" morph="none" pos="word" start_char="1593">make</TOKEN>
<TOKEN end_char="1598" id="token-15-33" morph="none" pos="word" start_char="1598">a</TOKEN>
<TOKEN end_char="1609" id="token-15-34" morph="none" pos="word" start_char="1600">tremendous</TOKEN>
<TOKEN end_char="1620" id="token-15-35" morph="none" pos="word" start_char="1611">difference</TOKEN>
<TOKEN end_char="1622" id="token-15-36" morph="none" pos="punct" start_char="1621">,"</TOKEN>
<TOKEN end_char="1627" id="token-15-37" morph="none" pos="word" start_char="1624">said</TOKEN>
<TOKEN end_char="1635" id="token-15-38" morph="none" pos="word" start_char="1629">Wolfson</TOKEN>
<TOKEN end_char="1636" id="token-15-39" morph="none" pos="punct" start_char="1636">.</TOKEN>
</SEG>
<SEG end_char="1645" id="segment-16" start_char="1641">
<ORIGINAL_TEXT>Video</ORIGINAL_TEXT>
<TOKEN end_char="1645" id="token-16-0" morph="none" pos="word" start_char="1641">Video</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
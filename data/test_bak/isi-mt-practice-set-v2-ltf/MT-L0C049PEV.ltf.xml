<LCTL_TEXT lang="ukr">
<DOC grammar="none" id="L0C049PEV" lang="ukr" raw_text_char_length="1370" raw_text_md5="4944d50f052cc533bc63afe392b8ec10" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="77" id="segment-0" start_char="1">
<ORIGINAL_TEXT>No, los pacientes asintomáticos no son inmunes y pueden contagiar coronavirus</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">No</TOKEN>
<TOKEN end_char="3" id="token-0-1" morph="none" pos="punct" start_char="3">,</TOKEN>
<TOKEN end_char="7" id="token-0-2" morph="none" pos="word" start_char="5">los</TOKEN>
<TOKEN end_char="17" id="token-0-3" morph="none" pos="word" start_char="9">pacientes</TOKEN>
<TOKEN end_char="31" id="token-0-4" morph="none" pos="word" start_char="19">asintomáticos</TOKEN>
<TOKEN end_char="34" id="token-0-5" morph="none" pos="word" start_char="33">no</TOKEN>
<TOKEN end_char="38" id="token-0-6" morph="none" pos="word" start_char="36">son</TOKEN>
<TOKEN end_char="46" id="token-0-7" morph="none" pos="word" start_char="40">inmunes</TOKEN>
<TOKEN end_char="48" id="token-0-8" morph="none" pos="word" start_char="48">y</TOKEN>
<TOKEN end_char="55" id="token-0-9" morph="none" pos="word" start_char="50">pueden</TOKEN>
<TOKEN end_char="65" id="token-0-10" morph="none" pos="word" start_char="57">contagiar</TOKEN>
<TOKEN end_char="77" id="token-0-11" morph="none" pos="word" start_char="67">coronavirus</TOKEN>
<TRANSLATED_TEXT>No, asymptomatic patients are not immune and can infect coronavirus</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="211" id="segment-1" start_char="81">
<ORIGINAL_TEXT>you wont be happy until everyone is in a tiny box DEAD OR ALIVE – a miserable existence you are creating with less and less freedom</ORIGINAL_TEXT>
<TOKEN end_char="83" id="token-1-0" morph="none" pos="word" start_char="81">you</TOKEN>
<TOKEN end_char="88" id="token-1-1" morph="none" pos="word" start_char="85">wont</TOKEN>
<TOKEN end_char="91" id="token-1-2" morph="none" pos="word" start_char="90">be</TOKEN>
<TOKEN end_char="97" id="token-1-3" morph="none" pos="word" start_char="93">happy</TOKEN>
<TOKEN end_char="103" id="token-1-4" morph="none" pos="word" start_char="99">until</TOKEN>
<TOKEN end_char="112" id="token-1-5" morph="none" pos="word" start_char="105">everyone</TOKEN>
<TOKEN end_char="115" id="token-1-6" morph="none" pos="word" start_char="114">is</TOKEN>
<TOKEN end_char="118" id="token-1-7" morph="none" pos="word" start_char="117">in</TOKEN>
<TOKEN end_char="120" id="token-1-8" morph="none" pos="word" start_char="120">a</TOKEN>
<TOKEN end_char="125" id="token-1-9" morph="none" pos="word" start_char="122">tiny</TOKEN>
<TOKEN end_char="129" id="token-1-10" morph="none" pos="word" start_char="127">box</TOKEN>
<TOKEN end_char="134" id="token-1-11" morph="none" pos="word" start_char="131">DEAD</TOKEN>
<TOKEN end_char="137" id="token-1-12" morph="none" pos="word" start_char="136">OR</TOKEN>
<TOKEN end_char="143" id="token-1-13" morph="none" pos="word" start_char="139">ALIVE</TOKEN>
<TOKEN end_char="145" id="token-1-14" morph="none" pos="punct" start_char="145">–</TOKEN>
<TOKEN end_char="147" id="token-1-15" morph="none" pos="word" start_char="147">a</TOKEN>
<TOKEN end_char="157" id="token-1-16" morph="none" pos="word" start_char="149">miserable</TOKEN>
<TOKEN end_char="167" id="token-1-17" morph="none" pos="word" start_char="159">existence</TOKEN>
<TOKEN end_char="171" id="token-1-18" morph="none" pos="word" start_char="169">you</TOKEN>
<TOKEN end_char="175" id="token-1-19" morph="none" pos="word" start_char="173">are</TOKEN>
<TOKEN end_char="184" id="token-1-20" morph="none" pos="word" start_char="177">creating</TOKEN>
<TOKEN end_char="189" id="token-1-21" morph="none" pos="word" start_char="186">with</TOKEN>
<TOKEN end_char="194" id="token-1-22" morph="none" pos="word" start_char="191">less</TOKEN>
<TOKEN end_char="198" id="token-1-23" morph="none" pos="word" start_char="196">and</TOKEN>
<TOKEN end_char="203" id="token-1-24" morph="none" pos="word" start_char="200">less</TOKEN>
<TOKEN end_char="211" id="token-1-25" morph="none" pos="word" start_char="205">freedom</TOKEN>
</SEG>
<SEG end_char="274" id="segment-2" start_char="215">
<ORIGINAL_TEXT>Muchas gracias por la ayuda, enseñando la información falsa.</ORIGINAL_TEXT>
<TOKEN end_char="220" id="token-2-0" morph="none" pos="word" start_char="215">Muchas</TOKEN>
<TOKEN end_char="228" id="token-2-1" morph="none" pos="word" start_char="222">gracias</TOKEN>
<TOKEN end_char="232" id="token-2-2" morph="none" pos="word" start_char="230">por</TOKEN>
<TOKEN end_char="235" id="token-2-3" morph="none" pos="word" start_char="234">la</TOKEN>
<TOKEN end_char="241" id="token-2-4" morph="none" pos="word" start_char="237">ayuda</TOKEN>
<TOKEN end_char="242" id="token-2-5" morph="none" pos="punct" start_char="242">,</TOKEN>
<TOKEN end_char="252" id="token-2-6" morph="none" pos="word" start_char="244">enseñando</TOKEN>
<TOKEN end_char="255" id="token-2-7" morph="none" pos="word" start_char="254">la</TOKEN>
<TOKEN end_char="267" id="token-2-8" morph="none" pos="word" start_char="257">información</TOKEN>
<TOKEN end_char="273" id="token-2-9" morph="none" pos="word" start_char="269">falsa</TOKEN>
<TOKEN end_char="274" id="token-2-10" morph="none" pos="punct" start_char="274">.</TOKEN>
<TRANSLATED_TEXT>Thank you very much for the help, teaching the false information.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="308" id="segment-3" start_char="276">
<ORIGINAL_TEXT>Disculpa y chequeare las próximas</ORIGINAL_TEXT>
<TOKEN end_char="283" id="token-3-0" morph="none" pos="word" start_char="276">Disculpa</TOKEN>
<TOKEN end_char="285" id="token-3-1" morph="none" pos="word" start_char="285">y</TOKEN>
<TOKEN end_char="295" id="token-3-2" morph="none" pos="word" start_char="287">chequeare</TOKEN>
<TOKEN end_char="299" id="token-3-3" morph="none" pos="word" start_char="297">las</TOKEN>
<TOKEN end_char="308" id="token-3-4" morph="none" pos="word" start_char="301">próximas</TOKEN>
<TRANSLATED_TEXT>Excuse me and check the next one.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="320" id="segment-4" start_char="312">
<ORIGINAL_TEXT>Excelente</ORIGINAL_TEXT>
<TOKEN end_char="320" id="token-4-0" morph="none" pos="word" start_char="312">Excelente</TOKEN>
<TRANSLATED_TEXT>Excellent.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ro</DETECTED_LANGUAGE></SEG>
<SEG end_char="401" id="segment-5" start_char="324">
<ORIGINAL_TEXT>Me parece muy bien que tengan controladas las noticias falsas.gcias y adelante</ORIGINAL_TEXT>
<TOKEN end_char="325" id="token-5-0" morph="none" pos="word" start_char="324">Me</TOKEN>
<TOKEN end_char="332" id="token-5-1" morph="none" pos="word" start_char="327">parece</TOKEN>
<TOKEN end_char="336" id="token-5-2" morph="none" pos="word" start_char="334">muy</TOKEN>
<TOKEN end_char="341" id="token-5-3" morph="none" pos="word" start_char="338">bien</TOKEN>
<TOKEN end_char="345" id="token-5-4" morph="none" pos="word" start_char="343">que</TOKEN>
<TOKEN end_char="352" id="token-5-5" morph="none" pos="word" start_char="347">tengan</TOKEN>
<TOKEN end_char="364" id="token-5-6" morph="none" pos="word" start_char="354">controladas</TOKEN>
<TOKEN end_char="368" id="token-5-7" morph="none" pos="word" start_char="366">las</TOKEN>
<TOKEN end_char="377" id="token-5-8" morph="none" pos="word" start_char="370">noticias</TOKEN>
<TOKEN end_char="390" id="token-5-9" morph="none" pos="unknown" start_char="379">falsas.gcias</TOKEN>
<TOKEN end_char="392" id="token-5-10" morph="none" pos="word" start_char="392">y</TOKEN>
<TOKEN end_char="401" id="token-5-11" morph="none" pos="word" start_char="394">adelante</TOKEN>
<TRANSLATED_TEXT>I think it's very good that you have control of the fake news.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="618" id="segment-6" start_char="405">
<ORIGINAL_TEXT>Yo siempre he estado condiente de que el paciente asintomatico es el que no presenta ninguno de los síntomas característicos del covid 19, pero que si pueden contagiar, no se porque dicen que yo apoyo lo contrario.</ORIGINAL_TEXT>
<TOKEN end_char="406" id="token-6-0" morph="none" pos="word" start_char="405">Yo</TOKEN>
<TOKEN end_char="414" id="token-6-1" morph="none" pos="word" start_char="408">siempre</TOKEN>
<TOKEN end_char="417" id="token-6-2" morph="none" pos="word" start_char="416">he</TOKEN>
<TOKEN end_char="424" id="token-6-3" morph="none" pos="word" start_char="419">estado</TOKEN>
<TOKEN end_char="434" id="token-6-4" morph="none" pos="word" start_char="426">condiente</TOKEN>
<TOKEN end_char="437" id="token-6-5" morph="none" pos="word" start_char="436">de</TOKEN>
<TOKEN end_char="441" id="token-6-6" morph="none" pos="word" start_char="439">que</TOKEN>
<TOKEN end_char="444" id="token-6-7" morph="none" pos="word" start_char="443">el</TOKEN>
<TOKEN end_char="453" id="token-6-8" morph="none" pos="word" start_char="446">paciente</TOKEN>
<TOKEN end_char="466" id="token-6-9" morph="none" pos="word" start_char="455">asintomatico</TOKEN>
<TOKEN end_char="469" id="token-6-10" morph="none" pos="word" start_char="468">es</TOKEN>
<TOKEN end_char="472" id="token-6-11" morph="none" pos="word" start_char="471">el</TOKEN>
<TOKEN end_char="476" id="token-6-12" morph="none" pos="word" start_char="474">que</TOKEN>
<TOKEN end_char="479" id="token-6-13" morph="none" pos="word" start_char="478">no</TOKEN>
<TOKEN end_char="488" id="token-6-14" morph="none" pos="word" start_char="481">presenta</TOKEN>
<TOKEN end_char="496" id="token-6-15" morph="none" pos="word" start_char="490">ninguno</TOKEN>
<TOKEN end_char="499" id="token-6-16" morph="none" pos="word" start_char="498">de</TOKEN>
<TOKEN end_char="503" id="token-6-17" morph="none" pos="word" start_char="501">los</TOKEN>
<TOKEN end_char="512" id="token-6-18" morph="none" pos="word" start_char="505">síntomas</TOKEN>
<TOKEN end_char="528" id="token-6-19" morph="none" pos="word" start_char="514">característicos</TOKEN>
<TOKEN end_char="532" id="token-6-20" morph="none" pos="word" start_char="530">del</TOKEN>
<TOKEN end_char="538" id="token-6-21" morph="none" pos="word" start_char="534">covid</TOKEN>
<TOKEN end_char="541" id="token-6-22" morph="none" pos="word" start_char="540">19</TOKEN>
<TOKEN end_char="542" id="token-6-23" morph="none" pos="punct" start_char="542">,</TOKEN>
<TOKEN end_char="547" id="token-6-24" morph="none" pos="word" start_char="544">pero</TOKEN>
<TOKEN end_char="551" id="token-6-25" morph="none" pos="word" start_char="549">que</TOKEN>
<TOKEN end_char="554" id="token-6-26" morph="none" pos="word" start_char="553">si</TOKEN>
<TOKEN end_char="561" id="token-6-27" morph="none" pos="word" start_char="556">pueden</TOKEN>
<TOKEN end_char="571" id="token-6-28" morph="none" pos="word" start_char="563">contagiar</TOKEN>
<TOKEN end_char="572" id="token-6-29" morph="none" pos="punct" start_char="572">,</TOKEN>
<TOKEN end_char="575" id="token-6-30" morph="none" pos="word" start_char="574">no</TOKEN>
<TOKEN end_char="578" id="token-6-31" morph="none" pos="word" start_char="577">se</TOKEN>
<TOKEN end_char="585" id="token-6-32" morph="none" pos="word" start_char="580">porque</TOKEN>
<TOKEN end_char="591" id="token-6-33" morph="none" pos="word" start_char="587">dicen</TOKEN>
<TOKEN end_char="595" id="token-6-34" morph="none" pos="word" start_char="593">que</TOKEN>
<TOKEN end_char="598" id="token-6-35" morph="none" pos="word" start_char="597">yo</TOKEN>
<TOKEN end_char="604" id="token-6-36" morph="none" pos="word" start_char="600">apoyo</TOKEN>
<TOKEN end_char="607" id="token-6-37" morph="none" pos="word" start_char="606">lo</TOKEN>
<TOKEN end_char="617" id="token-6-38" morph="none" pos="word" start_char="609">contrario</TOKEN>
<TOKEN end_char="618" id="token-6-39" morph="none" pos="punct" start_char="618">.</TOKEN>
<TRANSLATED_TEXT>I've always been conditioned that the asymptomatic patient is the one who doesn't have any of the characteristic symptoms of covid 19, but that if they can infect, it's not because they say I support the opposite.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="726" id="segment-7" start_char="620">
<ORIGINAL_TEXT>No me acuerdo de haber publicado ese reportaje, si lo hice disculpen, a lo mejor lo hice inconscientemente.</ORIGINAL_TEXT>
<TOKEN end_char="621" id="token-7-0" morph="none" pos="word" start_char="620">No</TOKEN>
<TOKEN end_char="624" id="token-7-1" morph="none" pos="word" start_char="623">me</TOKEN>
<TOKEN end_char="632" id="token-7-2" morph="none" pos="word" start_char="626">acuerdo</TOKEN>
<TOKEN end_char="635" id="token-7-3" morph="none" pos="word" start_char="634">de</TOKEN>
<TOKEN end_char="641" id="token-7-4" morph="none" pos="word" start_char="637">haber</TOKEN>
<TOKEN end_char="651" id="token-7-5" morph="none" pos="word" start_char="643">publicado</TOKEN>
<TOKEN end_char="655" id="token-7-6" morph="none" pos="word" start_char="653">ese</TOKEN>
<TOKEN end_char="665" id="token-7-7" morph="none" pos="word" start_char="657">reportaje</TOKEN>
<TOKEN end_char="666" id="token-7-8" morph="none" pos="punct" start_char="666">,</TOKEN>
<TOKEN end_char="669" id="token-7-9" morph="none" pos="word" start_char="668">si</TOKEN>
<TOKEN end_char="672" id="token-7-10" morph="none" pos="word" start_char="671">lo</TOKEN>
<TOKEN end_char="677" id="token-7-11" morph="none" pos="word" start_char="674">hice</TOKEN>
<TOKEN end_char="687" id="token-7-12" morph="none" pos="word" start_char="679">disculpen</TOKEN>
<TOKEN end_char="688" id="token-7-13" morph="none" pos="punct" start_char="688">,</TOKEN>
<TOKEN end_char="690" id="token-7-14" morph="none" pos="word" start_char="690">a</TOKEN>
<TOKEN end_char="693" id="token-7-15" morph="none" pos="word" start_char="692">lo</TOKEN>
<TOKEN end_char="699" id="token-7-16" morph="none" pos="word" start_char="695">mejor</TOKEN>
<TOKEN end_char="702" id="token-7-17" morph="none" pos="word" start_char="701">lo</TOKEN>
<TOKEN end_char="707" id="token-7-18" morph="none" pos="word" start_char="704">hice</TOKEN>
<TOKEN end_char="725" id="token-7-19" morph="none" pos="word" start_char="709">inconscientemente</TOKEN>
<TOKEN end_char="726" id="token-7-20" morph="none" pos="punct" start_char="726">.</TOKEN>
<TRANSLATED_TEXT>I don't remember publishing that report, if I apologized, maybe I did it unconsciously.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="836" id="segment-8" start_char="730">
<ORIGINAL_TEXT>SERIA BUENO QUE ESTE MEDIO EXPLIQUE EL CONFLICTO DE INTERESES CON SUS FINANCIADORES COMO GOOGLE Y FACEBOOK.</ORIGINAL_TEXT>
<TOKEN end_char="734" id="token-8-0" morph="none" pos="word" start_char="730">SERIA</TOKEN>
<TOKEN end_char="740" id="token-8-1" morph="none" pos="word" start_char="736">BUENO</TOKEN>
<TOKEN end_char="744" id="token-8-2" morph="none" pos="word" start_char="742">QUE</TOKEN>
<TOKEN end_char="749" id="token-8-3" morph="none" pos="word" start_char="746">ESTE</TOKEN>
<TOKEN end_char="755" id="token-8-4" morph="none" pos="word" start_char="751">MEDIO</TOKEN>
<TOKEN end_char="764" id="token-8-5" morph="none" pos="word" start_char="757">EXPLIQUE</TOKEN>
<TOKEN end_char="767" id="token-8-6" morph="none" pos="word" start_char="766">EL</TOKEN>
<TOKEN end_char="777" id="token-8-7" morph="none" pos="word" start_char="769">CONFLICTO</TOKEN>
<TOKEN end_char="780" id="token-8-8" morph="none" pos="word" start_char="779">DE</TOKEN>
<TOKEN end_char="790" id="token-8-9" morph="none" pos="word" start_char="782">INTERESES</TOKEN>
<TOKEN end_char="794" id="token-8-10" morph="none" pos="word" start_char="792">CON</TOKEN>
<TOKEN end_char="798" id="token-8-11" morph="none" pos="word" start_char="796">SUS</TOKEN>
<TOKEN end_char="812" id="token-8-12" morph="none" pos="word" start_char="800">FINANCIADORES</TOKEN>
<TOKEN end_char="817" id="token-8-13" morph="none" pos="word" start_char="814">COMO</TOKEN>
<TOKEN end_char="824" id="token-8-14" morph="none" pos="word" start_char="819">GOOGLE</TOKEN>
<TOKEN end_char="826" id="token-8-15" morph="none" pos="word" start_char="826">Y</TOKEN>
<TOKEN end_char="835" id="token-8-16" morph="none" pos="word" start_char="828">FACEBOOK</TOKEN>
<TOKEN end_char="836" id="token-8-17" morph="none" pos="punct" start_char="836">.</TOKEN>
</SEG>
<SEG end_char="1004" id="segment-9" start_char="838">
<ORIGINAL_TEXT>ADEMAS DEBERIA PRESENTAR EVIDENCIA CIENTIFICA PARA DESMENTIR ALGO ….EN LA REVISTA NATURE DEL DIA 20 DE NOVIEMBRE UN ESTUDIO DEMOSTRO QUE LOS ASINTOMATICOS NO CONTAGIAN</ORIGINAL_TEXT>
<TOKEN end_char="843" id="token-9-0" morph="none" pos="word" start_char="838">ADEMAS</TOKEN>
<TOKEN end_char="851" id="token-9-1" morph="none" pos="word" start_char="845">DEBERIA</TOKEN>
<TOKEN end_char="861" id="token-9-2" morph="none" pos="word" start_char="853">PRESENTAR</TOKEN>
<TOKEN end_char="871" id="token-9-3" morph="none" pos="word" start_char="863">EVIDENCIA</TOKEN>
<TOKEN end_char="882" id="token-9-4" morph="none" pos="word" start_char="873">CIENTIFICA</TOKEN>
<TOKEN end_char="887" id="token-9-5" morph="none" pos="word" start_char="884">PARA</TOKEN>
<TOKEN end_char="897" id="token-9-6" morph="none" pos="word" start_char="889">DESMENTIR</TOKEN>
<TOKEN end_char="902" id="token-9-7" morph="none" pos="word" start_char="899">ALGO</TOKEN>
<TOKEN end_char="905" id="token-9-8" morph="none" pos="punct" start_char="904">….</TOKEN>
<TOKEN end_char="907" id="token-9-9" morph="none" pos="word" start_char="906">EN</TOKEN>
<TOKEN end_char="910" id="token-9-10" morph="none" pos="word" start_char="909">LA</TOKEN>
<TOKEN end_char="918" id="token-9-11" morph="none" pos="word" start_char="912">REVISTA</TOKEN>
<TOKEN end_char="925" id="token-9-12" morph="none" pos="word" start_char="920">NATURE</TOKEN>
<TOKEN end_char="929" id="token-9-13" morph="none" pos="word" start_char="927">DEL</TOKEN>
<TOKEN end_char="933" id="token-9-14" morph="none" pos="word" start_char="931">DIA</TOKEN>
<TOKEN end_char="936" id="token-9-15" morph="none" pos="word" start_char="935">20</TOKEN>
<TOKEN end_char="939" id="token-9-16" morph="none" pos="word" start_char="938">DE</TOKEN>
<TOKEN end_char="949" id="token-9-17" morph="none" pos="word" start_char="941">NOVIEMBRE</TOKEN>
<TOKEN end_char="952" id="token-9-18" morph="none" pos="word" start_char="951">UN</TOKEN>
<TOKEN end_char="960" id="token-9-19" morph="none" pos="word" start_char="954">ESTUDIO</TOKEN>
<TOKEN end_char="969" id="token-9-20" morph="none" pos="word" start_char="962">DEMOSTRO</TOKEN>
<TOKEN end_char="973" id="token-9-21" morph="none" pos="word" start_char="971">QUE</TOKEN>
<TOKEN end_char="977" id="token-9-22" morph="none" pos="word" start_char="975">LOS</TOKEN>
<TOKEN end_char="991" id="token-9-23" morph="none" pos="word" start_char="979">ASINTOMATICOS</TOKEN>
<TOKEN end_char="994" id="token-9-24" morph="none" pos="word" start_char="993">NO</TOKEN>
<TOKEN end_char="1004" id="token-9-25" morph="none" pos="word" start_char="996">CONTAGIAN</TOKEN>
<TRANSLATED_TEXT>ADEMAS DEBERIA TO PRESENT CIENTIFIC EVIDENCE TO DESERVE ALGO... IN THE REVIST NATURE OF NOVEMBER 20th A STUDY THAT THE ASINTOMATICS DO NOT CONTAGIAN</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="1147" id="segment-10" start_char="1008">
<ORIGINAL_TEXT>No hay argumentos de rigor científico q confirmen q los asintomáticos transmiten el virus, salvó los mosquitos c vectores de una enfermedad.</ORIGINAL_TEXT>
<TOKEN end_char="1009" id="token-10-0" morph="none" pos="word" start_char="1008">No</TOKEN>
<TOKEN end_char="1013" id="token-10-1" morph="none" pos="word" start_char="1011">hay</TOKEN>
<TOKEN end_char="1024" id="token-10-2" morph="none" pos="word" start_char="1015">argumentos</TOKEN>
<TOKEN end_char="1027" id="token-10-3" morph="none" pos="word" start_char="1026">de</TOKEN>
<TOKEN end_char="1033" id="token-10-4" morph="none" pos="word" start_char="1029">rigor</TOKEN>
<TOKEN end_char="1044" id="token-10-5" morph="none" pos="word" start_char="1035">científico</TOKEN>
<TOKEN end_char="1046" id="token-10-6" morph="none" pos="word" start_char="1046">q</TOKEN>
<TOKEN end_char="1056" id="token-10-7" morph="none" pos="word" start_char="1048">confirmen</TOKEN>
<TOKEN end_char="1058" id="token-10-8" morph="none" pos="word" start_char="1058">q</TOKEN>
<TOKEN end_char="1062" id="token-10-9" morph="none" pos="word" start_char="1060">los</TOKEN>
<TOKEN end_char="1076" id="token-10-10" morph="none" pos="word" start_char="1064">asintomáticos</TOKEN>
<TOKEN end_char="1087" id="token-10-11" morph="none" pos="word" start_char="1078">transmiten</TOKEN>
<TOKEN end_char="1090" id="token-10-12" morph="none" pos="word" start_char="1089">el</TOKEN>
<TOKEN end_char="1096" id="token-10-13" morph="none" pos="word" start_char="1092">virus</TOKEN>
<TOKEN end_char="1097" id="token-10-14" morph="none" pos="punct" start_char="1097">,</TOKEN>
<TOKEN end_char="1103" id="token-10-15" morph="none" pos="word" start_char="1099">salvó</TOKEN>
<TOKEN end_char="1107" id="token-10-16" morph="none" pos="word" start_char="1105">los</TOKEN>
<TOKEN end_char="1117" id="token-10-17" morph="none" pos="word" start_char="1109">mosquitos</TOKEN>
<TOKEN end_char="1119" id="token-10-18" morph="none" pos="word" start_char="1119">c</TOKEN>
<TOKEN end_char="1128" id="token-10-19" morph="none" pos="word" start_char="1121">vectores</TOKEN>
<TOKEN end_char="1131" id="token-10-20" morph="none" pos="word" start_char="1130">de</TOKEN>
<TOKEN end_char="1135" id="token-10-21" morph="none" pos="word" start_char="1133">una</TOKEN>
<TOKEN end_char="1146" id="token-10-22" morph="none" pos="word" start_char="1137">enfermedad</TOKEN>
<TOKEN end_char="1147" id="token-10-23" morph="none" pos="punct" start_char="1147">.</TOKEN>
<TRANSLATED_TEXT>There are no arguments of scientific rigour q confirm q asymptomatic transmission of the virus, saved mosquitoes c vectors of a disease.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1244" id="segment-11" start_char="1151">
<ORIGINAL_TEXT>Y hay un par preguntando cómo se prueba que el asintomático sí transmite el virus.. increíble.</ORIGINAL_TEXT>
<TOKEN end_char="1151" id="token-11-0" morph="none" pos="word" start_char="1151">Y</TOKEN>
<TOKEN end_char="1155" id="token-11-1" morph="none" pos="word" start_char="1153">hay</TOKEN>
<TOKEN end_char="1158" id="token-11-2" morph="none" pos="word" start_char="1157">un</TOKEN>
<TOKEN end_char="1162" id="token-11-3" morph="none" pos="word" start_char="1160">par</TOKEN>
<TOKEN end_char="1174" id="token-11-4" morph="none" pos="word" start_char="1164">preguntando</TOKEN>
<TOKEN end_char="1179" id="token-11-5" morph="none" pos="word" start_char="1176">cómo</TOKEN>
<TOKEN end_char="1182" id="token-11-6" morph="none" pos="word" start_char="1181">se</TOKEN>
<TOKEN end_char="1189" id="token-11-7" morph="none" pos="word" start_char="1184">prueba</TOKEN>
<TOKEN end_char="1193" id="token-11-8" morph="none" pos="word" start_char="1191">que</TOKEN>
<TOKEN end_char="1196" id="token-11-9" morph="none" pos="word" start_char="1195">el</TOKEN>
<TOKEN end_char="1209" id="token-11-10" morph="none" pos="word" start_char="1198">asintomático</TOKEN>
<TOKEN end_char="1212" id="token-11-11" morph="none" pos="word" start_char="1211">sí</TOKEN>
<TOKEN end_char="1222" id="token-11-12" morph="none" pos="word" start_char="1214">transmite</TOKEN>
<TOKEN end_char="1225" id="token-11-13" morph="none" pos="word" start_char="1224">el</TOKEN>
<TOKEN end_char="1231" id="token-11-14" morph="none" pos="word" start_char="1227">virus</TOKEN>
<TOKEN end_char="1233" id="token-11-15" morph="none" pos="punct" start_char="1232">..</TOKEN>
<TOKEN end_char="1243" id="token-11-16" morph="none" pos="word" start_char="1235">increíble</TOKEN>
<TOKEN end_char="1244" id="token-11-17" morph="none" pos="punct" start_char="1244">.</TOKEN>
<TRANSLATED_TEXT>And there 's a couple wondering how it' s proven that the asymptomatic does transmit the incredible virus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1366" id="segment-12" start_char="1246">
<ORIGINAL_TEXT>Quizás porque hace un año vivimos los miles de contagios por día de gente que tuvo contacto con asintomáticos, no sé digo</ORIGINAL_TEXT>
<TOKEN end_char="1251" id="token-12-0" morph="none" pos="word" start_char="1246">Quizás</TOKEN>
<TOKEN end_char="1258" id="token-12-1" morph="none" pos="word" start_char="1253">porque</TOKEN>
<TOKEN end_char="1263" id="token-12-2" morph="none" pos="word" start_char="1260">hace</TOKEN>
<TOKEN end_char="1266" id="token-12-3" morph="none" pos="word" start_char="1265">un</TOKEN>
<TOKEN end_char="1270" id="token-12-4" morph="none" pos="word" start_char="1268">año</TOKEN>
<TOKEN end_char="1278" id="token-12-5" morph="none" pos="word" start_char="1272">vivimos</TOKEN>
<TOKEN end_char="1282" id="token-12-6" morph="none" pos="word" start_char="1280">los</TOKEN>
<TOKEN end_char="1288" id="token-12-7" morph="none" pos="word" start_char="1284">miles</TOKEN>
<TOKEN end_char="1291" id="token-12-8" morph="none" pos="word" start_char="1290">de</TOKEN>
<TOKEN end_char="1301" id="token-12-9" morph="none" pos="word" start_char="1293">contagios</TOKEN>
<TOKEN end_char="1305" id="token-12-10" morph="none" pos="word" start_char="1303">por</TOKEN>
<TOKEN end_char="1309" id="token-12-11" morph="none" pos="word" start_char="1307">día</TOKEN>
<TOKEN end_char="1312" id="token-12-12" morph="none" pos="word" start_char="1311">de</TOKEN>
<TOKEN end_char="1318" id="token-12-13" morph="none" pos="word" start_char="1314">gente</TOKEN>
<TOKEN end_char="1322" id="token-12-14" morph="none" pos="word" start_char="1320">que</TOKEN>
<TOKEN end_char="1327" id="token-12-15" morph="none" pos="word" start_char="1324">tuvo</TOKEN>
<TOKEN end_char="1336" id="token-12-16" morph="none" pos="word" start_char="1329">contacto</TOKEN>
<TOKEN end_char="1340" id="token-12-17" morph="none" pos="word" start_char="1338">con</TOKEN>
<TOKEN end_char="1354" id="token-12-18" morph="none" pos="word" start_char="1342">asintomáticos</TOKEN>
<TOKEN end_char="1355" id="token-12-19" morph="none" pos="punct" start_char="1355">,</TOKEN>
<TOKEN end_char="1358" id="token-12-20" morph="none" pos="word" start_char="1357">no</TOKEN>
<TOKEN end_char="1361" id="token-12-21" morph="none" pos="word" start_char="1360">sé</TOKEN>
<TOKEN end_char="1366" id="token-12-22" morph="none" pos="word" start_char="1363">digo</TOKEN>
<TRANSLATED_TEXT>Maybe because a year ago we lived through the thousands of infections a day of people who had contact with asymptomatic, I don't know.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
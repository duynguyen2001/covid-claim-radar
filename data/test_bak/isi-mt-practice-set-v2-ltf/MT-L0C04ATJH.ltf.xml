<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATJH" lang="spa" raw_text_char_length="6901" raw_text_md5="c90f28d2b914c1d46d344017d5337bef" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="38" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Should pets be tested for coronavirus?</ORIGINAL_TEXT>
<TOKEN end_char="6" id="token-0-0" morph="none" pos="word" start_char="1">Should</TOKEN>
<TOKEN end_char="11" id="token-0-1" morph="none" pos="word" start_char="8">pets</TOKEN>
<TOKEN end_char="14" id="token-0-2" morph="none" pos="word" start_char="13">be</TOKEN>
<TOKEN end_char="21" id="token-0-3" morph="none" pos="word" start_char="16">tested</TOKEN>
<TOKEN end_char="25" id="token-0-4" morph="none" pos="word" start_char="23">for</TOKEN>
<TOKEN end_char="37" id="token-0-5" morph="none" pos="word" start_char="27">coronavirus</TOKEN>
<TOKEN end_char="38" id="token-0-6" morph="none" pos="punct" start_char="38">?</TOKEN>
</SEG>
<SEG end_char="74" id="segment-1" start_char="43">
<ORIGINAL_TEXT>A dog wearing a mask in Shanghai</ORIGINAL_TEXT>
<TOKEN end_char="43" id="token-1-0" morph="none" pos="word" start_char="43">A</TOKEN>
<TOKEN end_char="47" id="token-1-1" morph="none" pos="word" start_char="45">dog</TOKEN>
<TOKEN end_char="55" id="token-1-2" morph="none" pos="word" start_char="49">wearing</TOKEN>
<TOKEN end_char="57" id="token-1-3" morph="none" pos="word" start_char="57">a</TOKEN>
<TOKEN end_char="62" id="token-1-4" morph="none" pos="word" start_char="59">mask</TOKEN>
<TOKEN end_char="65" id="token-1-5" morph="none" pos="word" start_char="64">in</TOKEN>
<TOKEN end_char="74" id="token-1-6" morph="none" pos="word" start_char="67">Shanghai</TOKEN>
</SEG>
<SEG end_char="142" id="segment-2" start_char="78">
<ORIGINAL_TEXT>Science’s COVID-19 reporting is supported by the Pulitzer Center.</ORIGINAL_TEXT>
<TOKEN end_char="86" id="token-2-0" morph="none" pos="word" start_char="78">Science’s</TOKEN>
<TOKEN end_char="95" id="token-2-1" morph="none" pos="unknown" start_char="88">COVID-19</TOKEN>
<TOKEN end_char="105" id="token-2-2" morph="none" pos="word" start_char="97">reporting</TOKEN>
<TOKEN end_char="108" id="token-2-3" morph="none" pos="word" start_char="107">is</TOKEN>
<TOKEN end_char="118" id="token-2-4" morph="none" pos="word" start_char="110">supported</TOKEN>
<TOKEN end_char="121" id="token-2-5" morph="none" pos="word" start_char="120">by</TOKEN>
<TOKEN end_char="125" id="token-2-6" morph="none" pos="word" start_char="123">the</TOKEN>
<TOKEN end_char="134" id="token-2-7" morph="none" pos="word" start_char="127">Pulitzer</TOKEN>
<TOKEN end_char="141" id="token-2-8" morph="none" pos="word" start_char="136">Center</TOKEN>
<TOKEN end_char="142" id="token-2-9" morph="none" pos="punct" start_char="142">.</TOKEN>
</SEG>
<SEG end_char="213" id="segment-3" start_char="145">
<ORIGINAL_TEXT>Last Thursday, the first cat tested positive for the new coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="148" id="token-3-0" morph="none" pos="word" start_char="145">Last</TOKEN>
<TOKEN end_char="157" id="token-3-1" morph="none" pos="word" start_char="150">Thursday</TOKEN>
<TOKEN end_char="158" id="token-3-2" morph="none" pos="punct" start_char="158">,</TOKEN>
<TOKEN end_char="162" id="token-3-3" morph="none" pos="word" start_char="160">the</TOKEN>
<TOKEN end_char="168" id="token-3-4" morph="none" pos="word" start_char="164">first</TOKEN>
<TOKEN end_char="172" id="token-3-5" morph="none" pos="word" start_char="170">cat</TOKEN>
<TOKEN end_char="179" id="token-3-6" morph="none" pos="word" start_char="174">tested</TOKEN>
<TOKEN end_char="188" id="token-3-7" morph="none" pos="word" start_char="181">positive</TOKEN>
<TOKEN end_char="192" id="token-3-8" morph="none" pos="word" start_char="190">for</TOKEN>
<TOKEN end_char="196" id="token-3-9" morph="none" pos="word" start_char="194">the</TOKEN>
<TOKEN end_char="200" id="token-3-10" morph="none" pos="word" start_char="198">new</TOKEN>
<TOKEN end_char="212" id="token-3-11" morph="none" pos="word" start_char="202">coronavirus</TOKEN>
<TOKEN end_char="213" id="token-3-12" morph="none" pos="punct" start_char="213">.</TOKEN>
</SEG>
<SEG end_char="379" id="segment-4" start_char="215">
<ORIGINAL_TEXT>The feline had diarrhea, vomiting, and difficulty breathing, and it had come down with COVID-19 about 1 week after its owner did, Belgian health officials announced.</ORIGINAL_TEXT>
<TOKEN end_char="217" id="token-4-0" morph="none" pos="word" start_char="215">The</TOKEN>
<TOKEN end_char="224" id="token-4-1" morph="none" pos="word" start_char="219">feline</TOKEN>
<TOKEN end_char="228" id="token-4-2" morph="none" pos="word" start_char="226">had</TOKEN>
<TOKEN end_char="237" id="token-4-3" morph="none" pos="word" start_char="230">diarrhea</TOKEN>
<TOKEN end_char="238" id="token-4-4" morph="none" pos="punct" start_char="238">,</TOKEN>
<TOKEN end_char="247" id="token-4-5" morph="none" pos="word" start_char="240">vomiting</TOKEN>
<TOKEN end_char="248" id="token-4-6" morph="none" pos="punct" start_char="248">,</TOKEN>
<TOKEN end_char="252" id="token-4-7" morph="none" pos="word" start_char="250">and</TOKEN>
<TOKEN end_char="263" id="token-4-8" morph="none" pos="word" start_char="254">difficulty</TOKEN>
<TOKEN end_char="273" id="token-4-9" morph="none" pos="word" start_char="265">breathing</TOKEN>
<TOKEN end_char="274" id="token-4-10" morph="none" pos="punct" start_char="274">,</TOKEN>
<TOKEN end_char="278" id="token-4-11" morph="none" pos="word" start_char="276">and</TOKEN>
<TOKEN end_char="281" id="token-4-12" morph="none" pos="word" start_char="280">it</TOKEN>
<TOKEN end_char="285" id="token-4-13" morph="none" pos="word" start_char="283">had</TOKEN>
<TOKEN end_char="290" id="token-4-14" morph="none" pos="word" start_char="287">come</TOKEN>
<TOKEN end_char="295" id="token-4-15" morph="none" pos="word" start_char="292">down</TOKEN>
<TOKEN end_char="300" id="token-4-16" morph="none" pos="word" start_char="297">with</TOKEN>
<TOKEN end_char="309" id="token-4-17" morph="none" pos="unknown" start_char="302">COVID-19</TOKEN>
<TOKEN end_char="315" id="token-4-18" morph="none" pos="word" start_char="311">about</TOKEN>
<TOKEN end_char="317" id="token-4-19" morph="none" pos="word" start_char="317">1</TOKEN>
<TOKEN end_char="322" id="token-4-20" morph="none" pos="word" start_char="319">week</TOKEN>
<TOKEN end_char="328" id="token-4-21" morph="none" pos="word" start_char="324">after</TOKEN>
<TOKEN end_char="332" id="token-4-22" morph="none" pos="word" start_char="330">its</TOKEN>
<TOKEN end_char="338" id="token-4-23" morph="none" pos="word" start_char="334">owner</TOKEN>
<TOKEN end_char="342" id="token-4-24" morph="none" pos="word" start_char="340">did</TOKEN>
<TOKEN end_char="343" id="token-4-25" morph="none" pos="punct" start_char="343">,</TOKEN>
<TOKEN end_char="351" id="token-4-26" morph="none" pos="word" start_char="345">Belgian</TOKEN>
<TOKEN end_char="358" id="token-4-27" morph="none" pos="word" start_char="353">health</TOKEN>
<TOKEN end_char="368" id="token-4-28" morph="none" pos="word" start_char="360">officials</TOKEN>
<TOKEN end_char="378" id="token-4-29" morph="none" pos="word" start_char="370">announced</TOKEN>
<TOKEN end_char="379" id="token-4-30" morph="none" pos="punct" start_char="379">.</TOKEN>
</SEG>
<SEG end_char="631" id="segment-5" start_char="382">
<ORIGINAL_TEXT>The same day, Hong Kong’s Agriculture, Fisheries and Conservation Department reported that a 17-year-old Pomeranian—which had initially tested "weak positive" for SARS-CoV-2—had indeed been infected by the virus, likely by its owner or another human.</ORIGINAL_TEXT>
<TOKEN end_char="384" id="token-5-0" morph="none" pos="word" start_char="382">The</TOKEN>
<TOKEN end_char="389" id="token-5-1" morph="none" pos="word" start_char="386">same</TOKEN>
<TOKEN end_char="393" id="token-5-2" morph="none" pos="word" start_char="391">day</TOKEN>
<TOKEN end_char="394" id="token-5-3" morph="none" pos="punct" start_char="394">,</TOKEN>
<TOKEN end_char="399" id="token-5-4" morph="none" pos="word" start_char="396">Hong</TOKEN>
<TOKEN end_char="406" id="token-5-5" morph="none" pos="word" start_char="401">Kong’s</TOKEN>
<TOKEN end_char="418" id="token-5-6" morph="none" pos="word" start_char="408">Agriculture</TOKEN>
<TOKEN end_char="419" id="token-5-7" morph="none" pos="punct" start_char="419">,</TOKEN>
<TOKEN end_char="429" id="token-5-8" morph="none" pos="word" start_char="421">Fisheries</TOKEN>
<TOKEN end_char="433" id="token-5-9" morph="none" pos="word" start_char="431">and</TOKEN>
<TOKEN end_char="446" id="token-5-10" morph="none" pos="word" start_char="435">Conservation</TOKEN>
<TOKEN end_char="457" id="token-5-11" morph="none" pos="word" start_char="448">Department</TOKEN>
<TOKEN end_char="466" id="token-5-12" morph="none" pos="word" start_char="459">reported</TOKEN>
<TOKEN end_char="471" id="token-5-13" morph="none" pos="word" start_char="468">that</TOKEN>
<TOKEN end_char="473" id="token-5-14" morph="none" pos="word" start_char="473">a</TOKEN>
<TOKEN end_char="485" id="token-5-15" morph="none" pos="unknown" start_char="475">17-year-old</TOKEN>
<TOKEN end_char="502" id="token-5-16" morph="none" pos="unknown" start_char="487">Pomeranian—which</TOKEN>
<TOKEN end_char="506" id="token-5-17" morph="none" pos="word" start_char="504">had</TOKEN>
<TOKEN end_char="516" id="token-5-18" morph="none" pos="word" start_char="508">initially</TOKEN>
<TOKEN end_char="523" id="token-5-19" morph="none" pos="word" start_char="518">tested</TOKEN>
<TOKEN end_char="525" id="token-5-20" morph="none" pos="punct" start_char="525">"</TOKEN>
<TOKEN end_char="529" id="token-5-21" morph="none" pos="word" start_char="526">weak</TOKEN>
<TOKEN end_char="538" id="token-5-22" morph="none" pos="word" start_char="531">positive</TOKEN>
<TOKEN end_char="539" id="token-5-23" morph="none" pos="punct" start_char="539">"</TOKEN>
<TOKEN end_char="543" id="token-5-24" morph="none" pos="word" start_char="541">for</TOKEN>
<TOKEN end_char="558" id="token-5-25" morph="none" pos="unknown" start_char="545">SARS-CoV-2—had</TOKEN>
<TOKEN end_char="565" id="token-5-26" morph="none" pos="word" start_char="560">indeed</TOKEN>
<TOKEN end_char="570" id="token-5-27" morph="none" pos="word" start_char="567">been</TOKEN>
<TOKEN end_char="579" id="token-5-28" morph="none" pos="word" start_char="572">infected</TOKEN>
<TOKEN end_char="582" id="token-5-29" morph="none" pos="word" start_char="581">by</TOKEN>
<TOKEN end_char="586" id="token-5-30" morph="none" pos="word" start_char="584">the</TOKEN>
<TOKEN end_char="592" id="token-5-31" morph="none" pos="word" start_char="588">virus</TOKEN>
<TOKEN end_char="593" id="token-5-32" morph="none" pos="punct" start_char="593">,</TOKEN>
<TOKEN end_char="600" id="token-5-33" morph="none" pos="word" start_char="595">likely</TOKEN>
<TOKEN end_char="603" id="token-5-34" morph="none" pos="word" start_char="602">by</TOKEN>
<TOKEN end_char="607" id="token-5-35" morph="none" pos="word" start_char="605">its</TOKEN>
<TOKEN end_char="613" id="token-5-36" morph="none" pos="word" start_char="609">owner</TOKEN>
<TOKEN end_char="616" id="token-5-37" morph="none" pos="word" start_char="615">or</TOKEN>
<TOKEN end_char="624" id="token-5-38" morph="none" pos="word" start_char="618">another</TOKEN>
<TOKEN end_char="630" id="token-5-39" morph="none" pos="word" start_char="626">human</TOKEN>
<TOKEN end_char="631" id="token-5-40" morph="none" pos="punct" start_char="631">.</TOKEN>
</SEG>
<SEG end_char="865" id="segment-6" start_char="634">
<ORIGINAL_TEXT>Yet despite these cases—and a third dog that tested positive for coronavirus in Hong Kong earlier this month—the number of pets diagnosed with COVID-19 pales in comparison with the human total, now estimated to be more than 800,000.</ORIGINAL_TEXT>
<TOKEN end_char="636" id="token-6-0" morph="none" pos="word" start_char="634">Yet</TOKEN>
<TOKEN end_char="644" id="token-6-1" morph="none" pos="word" start_char="638">despite</TOKEN>
<TOKEN end_char="650" id="token-6-2" morph="none" pos="word" start_char="646">these</TOKEN>
<TOKEN end_char="660" id="token-6-3" morph="none" pos="unknown" start_char="652">cases—and</TOKEN>
<TOKEN end_char="662" id="token-6-4" morph="none" pos="word" start_char="662">a</TOKEN>
<TOKEN end_char="668" id="token-6-5" morph="none" pos="word" start_char="664">third</TOKEN>
<TOKEN end_char="672" id="token-6-6" morph="none" pos="word" start_char="670">dog</TOKEN>
<TOKEN end_char="677" id="token-6-7" morph="none" pos="word" start_char="674">that</TOKEN>
<TOKEN end_char="684" id="token-6-8" morph="none" pos="word" start_char="679">tested</TOKEN>
<TOKEN end_char="693" id="token-6-9" morph="none" pos="word" start_char="686">positive</TOKEN>
<TOKEN end_char="697" id="token-6-10" morph="none" pos="word" start_char="695">for</TOKEN>
<TOKEN end_char="709" id="token-6-11" morph="none" pos="word" start_char="699">coronavirus</TOKEN>
<TOKEN end_char="712" id="token-6-12" morph="none" pos="word" start_char="711">in</TOKEN>
<TOKEN end_char="717" id="token-6-13" morph="none" pos="word" start_char="714">Hong</TOKEN>
<TOKEN end_char="722" id="token-6-14" morph="none" pos="word" start_char="719">Kong</TOKEN>
<TOKEN end_char="730" id="token-6-15" morph="none" pos="word" start_char="724">earlier</TOKEN>
<TOKEN end_char="735" id="token-6-16" morph="none" pos="word" start_char="732">this</TOKEN>
<TOKEN end_char="745" id="token-6-17" morph="none" pos="unknown" start_char="737">month—the</TOKEN>
<TOKEN end_char="752" id="token-6-18" morph="none" pos="word" start_char="747">number</TOKEN>
<TOKEN end_char="755" id="token-6-19" morph="none" pos="word" start_char="754">of</TOKEN>
<TOKEN end_char="760" id="token-6-20" morph="none" pos="word" start_char="757">pets</TOKEN>
<TOKEN end_char="770" id="token-6-21" morph="none" pos="word" start_char="762">diagnosed</TOKEN>
<TOKEN end_char="775" id="token-6-22" morph="none" pos="word" start_char="772">with</TOKEN>
<TOKEN end_char="784" id="token-6-23" morph="none" pos="unknown" start_char="777">COVID-19</TOKEN>
<TOKEN end_char="790" id="token-6-24" morph="none" pos="word" start_char="786">pales</TOKEN>
<TOKEN end_char="793" id="token-6-25" morph="none" pos="word" start_char="792">in</TOKEN>
<TOKEN end_char="804" id="token-6-26" morph="none" pos="word" start_char="795">comparison</TOKEN>
<TOKEN end_char="809" id="token-6-27" morph="none" pos="word" start_char="806">with</TOKEN>
<TOKEN end_char="813" id="token-6-28" morph="none" pos="word" start_char="811">the</TOKEN>
<TOKEN end_char="819" id="token-6-29" morph="none" pos="word" start_char="815">human</TOKEN>
<TOKEN end_char="825" id="token-6-30" morph="none" pos="word" start_char="821">total</TOKEN>
<TOKEN end_char="826" id="token-6-31" morph="none" pos="punct" start_char="826">,</TOKEN>
<TOKEN end_char="830" id="token-6-32" morph="none" pos="word" start_char="828">now</TOKEN>
<TOKEN end_char="840" id="token-6-33" morph="none" pos="word" start_char="832">estimated</TOKEN>
<TOKEN end_char="843" id="token-6-34" morph="none" pos="word" start_char="842">to</TOKEN>
<TOKEN end_char="846" id="token-6-35" morph="none" pos="word" start_char="845">be</TOKEN>
<TOKEN end_char="851" id="token-6-36" morph="none" pos="word" start_char="848">more</TOKEN>
<TOKEN end_char="856" id="token-6-37" morph="none" pos="word" start_char="853">than</TOKEN>
<TOKEN end_char="864" id="token-6-38" morph="none" pos="unknown" start_char="858">800,000</TOKEN>
<TOKEN end_char="865" id="token-6-39" morph="none" pos="punct" start_char="865">.</TOKEN>
</SEG>
<SEG end_char="1025" id="segment-7" start_char="867">
<ORIGINAL_TEXT>And experts, including those at the U.S. Centers for Disease Control and Prevention (CDC), continue to emphasize that dogs and cats pose little risk to people.</ORIGINAL_TEXT>
<TOKEN end_char="869" id="token-7-0" morph="none" pos="word" start_char="867">And</TOKEN>
<TOKEN end_char="877" id="token-7-1" morph="none" pos="word" start_char="871">experts</TOKEN>
<TOKEN end_char="878" id="token-7-2" morph="none" pos="punct" start_char="878">,</TOKEN>
<TOKEN end_char="888" id="token-7-3" morph="none" pos="word" start_char="880">including</TOKEN>
<TOKEN end_char="894" id="token-7-4" morph="none" pos="word" start_char="890">those</TOKEN>
<TOKEN end_char="897" id="token-7-5" morph="none" pos="word" start_char="896">at</TOKEN>
<TOKEN end_char="901" id="token-7-6" morph="none" pos="word" start_char="899">the</TOKEN>
<TOKEN end_char="905" id="token-7-7" morph="none" pos="unknown" start_char="903">U.S</TOKEN>
<TOKEN end_char="906" id="token-7-8" morph="none" pos="punct" start_char="906">.</TOKEN>
<TOKEN end_char="914" id="token-7-9" morph="none" pos="word" start_char="908">Centers</TOKEN>
<TOKEN end_char="918" id="token-7-10" morph="none" pos="word" start_char="916">for</TOKEN>
<TOKEN end_char="926" id="token-7-11" morph="none" pos="word" start_char="920">Disease</TOKEN>
<TOKEN end_char="934" id="token-7-12" morph="none" pos="word" start_char="928">Control</TOKEN>
<TOKEN end_char="938" id="token-7-13" morph="none" pos="word" start_char="936">and</TOKEN>
<TOKEN end_char="949" id="token-7-14" morph="none" pos="word" start_char="940">Prevention</TOKEN>
<TOKEN end_char="951" id="token-7-15" morph="none" pos="punct" start_char="951">(</TOKEN>
<TOKEN end_char="954" id="token-7-16" morph="none" pos="word" start_char="952">CDC</TOKEN>
<TOKEN end_char="956" id="token-7-17" morph="none" pos="punct" start_char="955">),</TOKEN>
<TOKEN end_char="965" id="token-7-18" morph="none" pos="word" start_char="958">continue</TOKEN>
<TOKEN end_char="968" id="token-7-19" morph="none" pos="word" start_char="967">to</TOKEN>
<TOKEN end_char="978" id="token-7-20" morph="none" pos="word" start_char="970">emphasize</TOKEN>
<TOKEN end_char="983" id="token-7-21" morph="none" pos="word" start_char="980">that</TOKEN>
<TOKEN end_char="988" id="token-7-22" morph="none" pos="word" start_char="985">dogs</TOKEN>
<TOKEN end_char="992" id="token-7-23" morph="none" pos="word" start_char="990">and</TOKEN>
<TOKEN end_char="997" id="token-7-24" morph="none" pos="word" start_char="994">cats</TOKEN>
<TOKEN end_char="1002" id="token-7-25" morph="none" pos="word" start_char="999">pose</TOKEN>
<TOKEN end_char="1009" id="token-7-26" morph="none" pos="word" start_char="1004">little</TOKEN>
<TOKEN end_char="1014" id="token-7-27" morph="none" pos="word" start_char="1011">risk</TOKEN>
<TOKEN end_char="1017" id="token-7-28" morph="none" pos="word" start_char="1016">to</TOKEN>
<TOKEN end_char="1024" id="token-7-29" morph="none" pos="word" start_char="1019">people</TOKEN>
<TOKEN end_char="1025" id="token-7-30" morph="none" pos="punct" start_char="1025">.</TOKEN>
</SEG>
<SEG end_char="1351" id="segment-8" start_char="1027">
<ORIGINAL_TEXT>"CDC does not have evidence that pets can spread COVID-19, and there’s no reason to think pets might be a source of infection based on the information we have at this time," Casey Barton Behravesh, director of the agency’s One Health Office in the National Center for Emerging and Zoonotic Infectious Diseases, tells Science.</ORIGINAL_TEXT>
<TOKEN end_char="1027" id="token-8-0" morph="none" pos="punct" start_char="1027">"</TOKEN>
<TOKEN end_char="1030" id="token-8-1" morph="none" pos="word" start_char="1028">CDC</TOKEN>
<TOKEN end_char="1035" id="token-8-2" morph="none" pos="word" start_char="1032">does</TOKEN>
<TOKEN end_char="1039" id="token-8-3" morph="none" pos="word" start_char="1037">not</TOKEN>
<TOKEN end_char="1044" id="token-8-4" morph="none" pos="word" start_char="1041">have</TOKEN>
<TOKEN end_char="1053" id="token-8-5" morph="none" pos="word" start_char="1046">evidence</TOKEN>
<TOKEN end_char="1058" id="token-8-6" morph="none" pos="word" start_char="1055">that</TOKEN>
<TOKEN end_char="1063" id="token-8-7" morph="none" pos="word" start_char="1060">pets</TOKEN>
<TOKEN end_char="1067" id="token-8-8" morph="none" pos="word" start_char="1065">can</TOKEN>
<TOKEN end_char="1074" id="token-8-9" morph="none" pos="word" start_char="1069">spread</TOKEN>
<TOKEN end_char="1083" id="token-8-10" morph="none" pos="unknown" start_char="1076">COVID-19</TOKEN>
<TOKEN end_char="1084" id="token-8-11" morph="none" pos="punct" start_char="1084">,</TOKEN>
<TOKEN end_char="1088" id="token-8-12" morph="none" pos="word" start_char="1086">and</TOKEN>
<TOKEN end_char="1096" id="token-8-13" morph="none" pos="word" start_char="1090">there’s</TOKEN>
<TOKEN end_char="1099" id="token-8-14" morph="none" pos="word" start_char="1098">no</TOKEN>
<TOKEN end_char="1106" id="token-8-15" morph="none" pos="word" start_char="1101">reason</TOKEN>
<TOKEN end_char="1109" id="token-8-16" morph="none" pos="word" start_char="1108">to</TOKEN>
<TOKEN end_char="1115" id="token-8-17" morph="none" pos="word" start_char="1111">think</TOKEN>
<TOKEN end_char="1120" id="token-8-18" morph="none" pos="word" start_char="1117">pets</TOKEN>
<TOKEN end_char="1126" id="token-8-19" morph="none" pos="word" start_char="1122">might</TOKEN>
<TOKEN end_char="1129" id="token-8-20" morph="none" pos="word" start_char="1128">be</TOKEN>
<TOKEN end_char="1131" id="token-8-21" morph="none" pos="word" start_char="1131">a</TOKEN>
<TOKEN end_char="1138" id="token-8-22" morph="none" pos="word" start_char="1133">source</TOKEN>
<TOKEN end_char="1141" id="token-8-23" morph="none" pos="word" start_char="1140">of</TOKEN>
<TOKEN end_char="1151" id="token-8-24" morph="none" pos="word" start_char="1143">infection</TOKEN>
<TOKEN end_char="1157" id="token-8-25" morph="none" pos="word" start_char="1153">based</TOKEN>
<TOKEN end_char="1160" id="token-8-26" morph="none" pos="word" start_char="1159">on</TOKEN>
<TOKEN end_char="1164" id="token-8-27" morph="none" pos="word" start_char="1162">the</TOKEN>
<TOKEN end_char="1176" id="token-8-28" morph="none" pos="word" start_char="1166">information</TOKEN>
<TOKEN end_char="1179" id="token-8-29" morph="none" pos="word" start_char="1178">we</TOKEN>
<TOKEN end_char="1184" id="token-8-30" morph="none" pos="word" start_char="1181">have</TOKEN>
<TOKEN end_char="1187" id="token-8-31" morph="none" pos="word" start_char="1186">at</TOKEN>
<TOKEN end_char="1192" id="token-8-32" morph="none" pos="word" start_char="1189">this</TOKEN>
<TOKEN end_char="1197" id="token-8-33" morph="none" pos="word" start_char="1194">time</TOKEN>
<TOKEN end_char="1199" id="token-8-34" morph="none" pos="punct" start_char="1198">,"</TOKEN>
<TOKEN end_char="1205" id="token-8-35" morph="none" pos="word" start_char="1201">Casey</TOKEN>
<TOKEN end_char="1212" id="token-8-36" morph="none" pos="word" start_char="1207">Barton</TOKEN>
<TOKEN end_char="1222" id="token-8-37" morph="none" pos="word" start_char="1214">Behravesh</TOKEN>
<TOKEN end_char="1223" id="token-8-38" morph="none" pos="punct" start_char="1223">,</TOKEN>
<TOKEN end_char="1232" id="token-8-39" morph="none" pos="word" start_char="1225">director</TOKEN>
<TOKEN end_char="1235" id="token-8-40" morph="none" pos="word" start_char="1234">of</TOKEN>
<TOKEN end_char="1239" id="token-8-41" morph="none" pos="word" start_char="1237">the</TOKEN>
<TOKEN end_char="1248" id="token-8-42" morph="none" pos="word" start_char="1241">agency’s</TOKEN>
<TOKEN end_char="1252" id="token-8-43" morph="none" pos="word" start_char="1250">One</TOKEN>
<TOKEN end_char="1259" id="token-8-44" morph="none" pos="word" start_char="1254">Health</TOKEN>
<TOKEN end_char="1266" id="token-8-45" morph="none" pos="word" start_char="1261">Office</TOKEN>
<TOKEN end_char="1269" id="token-8-46" morph="none" pos="word" start_char="1268">in</TOKEN>
<TOKEN end_char="1273" id="token-8-47" morph="none" pos="word" start_char="1271">the</TOKEN>
<TOKEN end_char="1282" id="token-8-48" morph="none" pos="word" start_char="1275">National</TOKEN>
<TOKEN end_char="1289" id="token-8-49" morph="none" pos="word" start_char="1284">Center</TOKEN>
<TOKEN end_char="1293" id="token-8-50" morph="none" pos="word" start_char="1291">for</TOKEN>
<TOKEN end_char="1302" id="token-8-51" morph="none" pos="word" start_char="1295">Emerging</TOKEN>
<TOKEN end_char="1306" id="token-8-52" morph="none" pos="word" start_char="1304">and</TOKEN>
<TOKEN end_char="1315" id="token-8-53" morph="none" pos="word" start_char="1308">Zoonotic</TOKEN>
<TOKEN end_char="1326" id="token-8-54" morph="none" pos="word" start_char="1317">Infectious</TOKEN>
<TOKEN end_char="1335" id="token-8-55" morph="none" pos="word" start_char="1328">Diseases</TOKEN>
<TOKEN end_char="1336" id="token-8-56" morph="none" pos="punct" start_char="1336">,</TOKEN>
<TOKEN end_char="1342" id="token-8-57" morph="none" pos="word" start_char="1338">tells</TOKEN>
<TOKEN end_char="1350" id="token-8-58" morph="none" pos="word" start_char="1344">Science</TOKEN>
<TOKEN end_char="1351" id="token-8-59" morph="none" pos="punct" start_char="1351">.</TOKEN>
</SEG>
<SEG end_char="1396" id="segment-9" start_char="1354">
<ORIGINAL_TEXT>Still, veterinarians want more information.</ORIGINAL_TEXT>
<TOKEN end_char="1358" id="token-9-0" morph="none" pos="word" start_char="1354">Still</TOKEN>
<TOKEN end_char="1359" id="token-9-1" morph="none" pos="punct" start_char="1359">,</TOKEN>
<TOKEN end_char="1373" id="token-9-2" morph="none" pos="word" start_char="1361">veterinarians</TOKEN>
<TOKEN end_char="1378" id="token-9-3" morph="none" pos="word" start_char="1375">want</TOKEN>
<TOKEN end_char="1383" id="token-9-4" morph="none" pos="word" start_char="1380">more</TOKEN>
<TOKEN end_char="1395" id="token-9-5" morph="none" pos="word" start_char="1385">information</TOKEN>
<TOKEN end_char="1396" id="token-9-6" morph="none" pos="punct" start_char="1396">.</TOKEN>
</SEG>
<SEG end_char="1520" id="segment-10" start_char="1398">
<ORIGINAL_TEXT>Though human tests might work on animals, they are in short supply—and veterinarians prefer species-specific tests, anyway.</ORIGINAL_TEXT>
<TOKEN end_char="1403" id="token-10-0" morph="none" pos="word" start_char="1398">Though</TOKEN>
<TOKEN end_char="1409" id="token-10-1" morph="none" pos="word" start_char="1405">human</TOKEN>
<TOKEN end_char="1415" id="token-10-2" morph="none" pos="word" start_char="1411">tests</TOKEN>
<TOKEN end_char="1421" id="token-10-3" morph="none" pos="word" start_char="1417">might</TOKEN>
<TOKEN end_char="1426" id="token-10-4" morph="none" pos="word" start_char="1423">work</TOKEN>
<TOKEN end_char="1429" id="token-10-5" morph="none" pos="word" start_char="1428">on</TOKEN>
<TOKEN end_char="1437" id="token-10-6" morph="none" pos="word" start_char="1431">animals</TOKEN>
<TOKEN end_char="1438" id="token-10-7" morph="none" pos="punct" start_char="1438">,</TOKEN>
<TOKEN end_char="1443" id="token-10-8" morph="none" pos="word" start_char="1440">they</TOKEN>
<TOKEN end_char="1447" id="token-10-9" morph="none" pos="word" start_char="1445">are</TOKEN>
<TOKEN end_char="1450" id="token-10-10" morph="none" pos="word" start_char="1449">in</TOKEN>
<TOKEN end_char="1456" id="token-10-11" morph="none" pos="word" start_char="1452">short</TOKEN>
<TOKEN end_char="1467" id="token-10-12" morph="none" pos="unknown" start_char="1458">supply—and</TOKEN>
<TOKEN end_char="1481" id="token-10-13" morph="none" pos="word" start_char="1469">veterinarians</TOKEN>
<TOKEN end_char="1488" id="token-10-14" morph="none" pos="word" start_char="1483">prefer</TOKEN>
<TOKEN end_char="1505" id="token-10-15" morph="none" pos="unknown" start_char="1490">species-specific</TOKEN>
<TOKEN end_char="1511" id="token-10-16" morph="none" pos="word" start_char="1507">tests</TOKEN>
<TOKEN end_char="1512" id="token-10-17" morph="none" pos="punct" start_char="1512">,</TOKEN>
<TOKEN end_char="1519" id="token-10-18" morph="none" pos="word" start_char="1514">anyway</TOKEN>
<TOKEN end_char="1520" id="token-10-19" morph="none" pos="punct" start_char="1520">.</TOKEN>
</SEG>
<SEG end_char="1621" id="segment-11" start_char="1522">
<ORIGINAL_TEXT>Several labs have developed a SARS-CoV-2 test for pets, but none has begun to broadly administer it.</ORIGINAL_TEXT>
<TOKEN end_char="1528" id="token-11-0" morph="none" pos="word" start_char="1522">Several</TOKEN>
<TOKEN end_char="1533" id="token-11-1" morph="none" pos="word" start_char="1530">labs</TOKEN>
<TOKEN end_char="1538" id="token-11-2" morph="none" pos="word" start_char="1535">have</TOKEN>
<TOKEN end_char="1548" id="token-11-3" morph="none" pos="word" start_char="1540">developed</TOKEN>
<TOKEN end_char="1550" id="token-11-4" morph="none" pos="word" start_char="1550">a</TOKEN>
<TOKEN end_char="1561" id="token-11-5" morph="none" pos="unknown" start_char="1552">SARS-CoV-2</TOKEN>
<TOKEN end_char="1566" id="token-11-6" morph="none" pos="word" start_char="1563">test</TOKEN>
<TOKEN end_char="1570" id="token-11-7" morph="none" pos="word" start_char="1568">for</TOKEN>
<TOKEN end_char="1575" id="token-11-8" morph="none" pos="word" start_char="1572">pets</TOKEN>
<TOKEN end_char="1576" id="token-11-9" morph="none" pos="punct" start_char="1576">,</TOKEN>
<TOKEN end_char="1580" id="token-11-10" morph="none" pos="word" start_char="1578">but</TOKEN>
<TOKEN end_char="1585" id="token-11-11" morph="none" pos="word" start_char="1582">none</TOKEN>
<TOKEN end_char="1589" id="token-11-12" morph="none" pos="word" start_char="1587">has</TOKEN>
<TOKEN end_char="1595" id="token-11-13" morph="none" pos="word" start_char="1591">begun</TOKEN>
<TOKEN end_char="1598" id="token-11-14" morph="none" pos="word" start_char="1597">to</TOKEN>
<TOKEN end_char="1606" id="token-11-15" morph="none" pos="word" start_char="1600">broadly</TOKEN>
<TOKEN end_char="1617" id="token-11-16" morph="none" pos="word" start_char="1608">administer</TOKEN>
<TOKEN end_char="1620" id="token-11-17" morph="none" pos="word" start_char="1619">it</TOKEN>
<TOKEN end_char="1621" id="token-11-18" morph="none" pos="punct" start_char="1621">.</TOKEN>
</SEG>
<SEG end_char="1826" id="segment-12" start_char="1623">
<ORIGINAL_TEXT>The U.S. Department of Agriculture (USDA) has advised against it, and many experts are concerned about spreading unwarranted fear—especially amid reports that some owners have begun to abandon their pets.</ORIGINAL_TEXT>
<TOKEN end_char="1625" id="token-12-0" morph="none" pos="word" start_char="1623">The</TOKEN>
<TOKEN end_char="1629" id="token-12-1" morph="none" pos="unknown" start_char="1627">U.S</TOKEN>
<TOKEN end_char="1630" id="token-12-2" morph="none" pos="punct" start_char="1630">.</TOKEN>
<TOKEN end_char="1641" id="token-12-3" morph="none" pos="word" start_char="1632">Department</TOKEN>
<TOKEN end_char="1644" id="token-12-4" morph="none" pos="word" start_char="1643">of</TOKEN>
<TOKEN end_char="1656" id="token-12-5" morph="none" pos="word" start_char="1646">Agriculture</TOKEN>
<TOKEN end_char="1658" id="token-12-6" morph="none" pos="punct" start_char="1658">(</TOKEN>
<TOKEN end_char="1662" id="token-12-7" morph="none" pos="word" start_char="1659">USDA</TOKEN>
<TOKEN end_char="1663" id="token-12-8" morph="none" pos="punct" start_char="1663">)</TOKEN>
<TOKEN end_char="1667" id="token-12-9" morph="none" pos="word" start_char="1665">has</TOKEN>
<TOKEN end_char="1675" id="token-12-10" morph="none" pos="word" start_char="1669">advised</TOKEN>
<TOKEN end_char="1683" id="token-12-11" morph="none" pos="word" start_char="1677">against</TOKEN>
<TOKEN end_char="1686" id="token-12-12" morph="none" pos="word" start_char="1685">it</TOKEN>
<TOKEN end_char="1687" id="token-12-13" morph="none" pos="punct" start_char="1687">,</TOKEN>
<TOKEN end_char="1691" id="token-12-14" morph="none" pos="word" start_char="1689">and</TOKEN>
<TOKEN end_char="1696" id="token-12-15" morph="none" pos="word" start_char="1693">many</TOKEN>
<TOKEN end_char="1704" id="token-12-16" morph="none" pos="word" start_char="1698">experts</TOKEN>
<TOKEN end_char="1708" id="token-12-17" morph="none" pos="word" start_char="1706">are</TOKEN>
<TOKEN end_char="1718" id="token-12-18" morph="none" pos="word" start_char="1710">concerned</TOKEN>
<TOKEN end_char="1724" id="token-12-19" morph="none" pos="word" start_char="1720">about</TOKEN>
<TOKEN end_char="1734" id="token-12-20" morph="none" pos="word" start_char="1726">spreading</TOKEN>
<TOKEN end_char="1746" id="token-12-21" morph="none" pos="word" start_char="1736">unwarranted</TOKEN>
<TOKEN end_char="1762" id="token-12-22" morph="none" pos="unknown" start_char="1748">fear—especially</TOKEN>
<TOKEN end_char="1767" id="token-12-23" morph="none" pos="word" start_char="1764">amid</TOKEN>
<TOKEN end_char="1775" id="token-12-24" morph="none" pos="word" start_char="1769">reports</TOKEN>
<TOKEN end_char="1780" id="token-12-25" morph="none" pos="word" start_char="1777">that</TOKEN>
<TOKEN end_char="1785" id="token-12-26" morph="none" pos="word" start_char="1782">some</TOKEN>
<TOKEN end_char="1792" id="token-12-27" morph="none" pos="word" start_char="1787">owners</TOKEN>
<TOKEN end_char="1797" id="token-12-28" morph="none" pos="word" start_char="1794">have</TOKEN>
<TOKEN end_char="1803" id="token-12-29" morph="none" pos="word" start_char="1799">begun</TOKEN>
<TOKEN end_char="1806" id="token-12-30" morph="none" pos="word" start_char="1805">to</TOKEN>
<TOKEN end_char="1814" id="token-12-31" morph="none" pos="word" start_char="1808">abandon</TOKEN>
<TOKEN end_char="1820" id="token-12-32" morph="none" pos="word" start_char="1816">their</TOKEN>
<TOKEN end_char="1825" id="token-12-33" morph="none" pos="word" start_char="1822">pets</TOKEN>
<TOKEN end_char="1826" id="token-12-34" morph="none" pos="punct" start_char="1826">.</TOKEN>
</SEG>
<SEG end_char="2133" id="segment-13" start_char="1828">
<ORIGINAL_TEXT>"Even though we have no evidence that pets can transmit the virus, we desperately need [more] evidence one way or the other," says Timothy Baszler, executive director of the Washington Animal Disease Diagnostic Laboratory (WADDL), which announced 2 weeks ago that it had developed a COVID-19 test for pets.</ORIGINAL_TEXT>
<TOKEN end_char="1828" id="token-13-0" morph="none" pos="punct" start_char="1828">"</TOKEN>
<TOKEN end_char="1832" id="token-13-1" morph="none" pos="word" start_char="1829">Even</TOKEN>
<TOKEN end_char="1839" id="token-13-2" morph="none" pos="word" start_char="1834">though</TOKEN>
<TOKEN end_char="1842" id="token-13-3" morph="none" pos="word" start_char="1841">we</TOKEN>
<TOKEN end_char="1847" id="token-13-4" morph="none" pos="word" start_char="1844">have</TOKEN>
<TOKEN end_char="1850" id="token-13-5" morph="none" pos="word" start_char="1849">no</TOKEN>
<TOKEN end_char="1859" id="token-13-6" morph="none" pos="word" start_char="1852">evidence</TOKEN>
<TOKEN end_char="1864" id="token-13-7" morph="none" pos="word" start_char="1861">that</TOKEN>
<TOKEN end_char="1869" id="token-13-8" morph="none" pos="word" start_char="1866">pets</TOKEN>
<TOKEN end_char="1873" id="token-13-9" morph="none" pos="word" start_char="1871">can</TOKEN>
<TOKEN end_char="1882" id="token-13-10" morph="none" pos="word" start_char="1875">transmit</TOKEN>
<TOKEN end_char="1886" id="token-13-11" morph="none" pos="word" start_char="1884">the</TOKEN>
<TOKEN end_char="1892" id="token-13-12" morph="none" pos="word" start_char="1888">virus</TOKEN>
<TOKEN end_char="1893" id="token-13-13" morph="none" pos="punct" start_char="1893">,</TOKEN>
<TOKEN end_char="1896" id="token-13-14" morph="none" pos="word" start_char="1895">we</TOKEN>
<TOKEN end_char="1908" id="token-13-15" morph="none" pos="word" start_char="1898">desperately</TOKEN>
<TOKEN end_char="1913" id="token-13-16" morph="none" pos="word" start_char="1910">need</TOKEN>
<TOKEN end_char="1915" id="token-13-17" morph="none" pos="punct" start_char="1915">[</TOKEN>
<TOKEN end_char="1919" id="token-13-18" morph="none" pos="word" start_char="1916">more</TOKEN>
<TOKEN end_char="1920" id="token-13-19" morph="none" pos="punct" start_char="1920">]</TOKEN>
<TOKEN end_char="1929" id="token-13-20" morph="none" pos="word" start_char="1922">evidence</TOKEN>
<TOKEN end_char="1933" id="token-13-21" morph="none" pos="word" start_char="1931">one</TOKEN>
<TOKEN end_char="1937" id="token-13-22" morph="none" pos="word" start_char="1935">way</TOKEN>
<TOKEN end_char="1940" id="token-13-23" morph="none" pos="word" start_char="1939">or</TOKEN>
<TOKEN end_char="1944" id="token-13-24" morph="none" pos="word" start_char="1942">the</TOKEN>
<TOKEN end_char="1950" id="token-13-25" morph="none" pos="word" start_char="1946">other</TOKEN>
<TOKEN end_char="1952" id="token-13-26" morph="none" pos="punct" start_char="1951">,"</TOKEN>
<TOKEN end_char="1957" id="token-13-27" morph="none" pos="word" start_char="1954">says</TOKEN>
<TOKEN end_char="1965" id="token-13-28" morph="none" pos="word" start_char="1959">Timothy</TOKEN>
<TOKEN end_char="1973" id="token-13-29" morph="none" pos="word" start_char="1967">Baszler</TOKEN>
<TOKEN end_char="1974" id="token-13-30" morph="none" pos="punct" start_char="1974">,</TOKEN>
<TOKEN end_char="1984" id="token-13-31" morph="none" pos="word" start_char="1976">executive</TOKEN>
<TOKEN end_char="1993" id="token-13-32" morph="none" pos="word" start_char="1986">director</TOKEN>
<TOKEN end_char="1996" id="token-13-33" morph="none" pos="word" start_char="1995">of</TOKEN>
<TOKEN end_char="2000" id="token-13-34" morph="none" pos="word" start_char="1998">the</TOKEN>
<TOKEN end_char="2011" id="token-13-35" morph="none" pos="word" start_char="2002">Washington</TOKEN>
<TOKEN end_char="2018" id="token-13-36" morph="none" pos="word" start_char="2013">Animal</TOKEN>
<TOKEN end_char="2026" id="token-13-37" morph="none" pos="word" start_char="2020">Disease</TOKEN>
<TOKEN end_char="2037" id="token-13-38" morph="none" pos="word" start_char="2028">Diagnostic</TOKEN>
<TOKEN end_char="2048" id="token-13-39" morph="none" pos="word" start_char="2039">Laboratory</TOKEN>
<TOKEN end_char="2050" id="token-13-40" morph="none" pos="punct" start_char="2050">(</TOKEN>
<TOKEN end_char="2055" id="token-13-41" morph="none" pos="word" start_char="2051">WADDL</TOKEN>
<TOKEN end_char="2057" id="token-13-42" morph="none" pos="punct" start_char="2056">),</TOKEN>
<TOKEN end_char="2063" id="token-13-43" morph="none" pos="word" start_char="2059">which</TOKEN>
<TOKEN end_char="2073" id="token-13-44" morph="none" pos="word" start_char="2065">announced</TOKEN>
<TOKEN end_char="2075" id="token-13-45" morph="none" pos="word" start_char="2075">2</TOKEN>
<TOKEN end_char="2081" id="token-13-46" morph="none" pos="word" start_char="2077">weeks</TOKEN>
<TOKEN end_char="2085" id="token-13-47" morph="none" pos="word" start_char="2083">ago</TOKEN>
<TOKEN end_char="2090" id="token-13-48" morph="none" pos="word" start_char="2087">that</TOKEN>
<TOKEN end_char="2093" id="token-13-49" morph="none" pos="word" start_char="2092">it</TOKEN>
<TOKEN end_char="2097" id="token-13-50" morph="none" pos="word" start_char="2095">had</TOKEN>
<TOKEN end_char="2107" id="token-13-51" morph="none" pos="word" start_char="2099">developed</TOKEN>
<TOKEN end_char="2109" id="token-13-52" morph="none" pos="word" start_char="2109">a</TOKEN>
<TOKEN end_char="2118" id="token-13-53" morph="none" pos="unknown" start_char="2111">COVID-19</TOKEN>
<TOKEN end_char="2123" id="token-13-54" morph="none" pos="word" start_char="2120">test</TOKEN>
<TOKEN end_char="2127" id="token-13-55" morph="none" pos="word" start_char="2125">for</TOKEN>
<TOKEN end_char="2132" id="token-13-56" morph="none" pos="word" start_char="2129">pets</TOKEN>
<TOKEN end_char="2133" id="token-13-57" morph="none" pos="punct" start_char="2133">.</TOKEN>
</SEG>
<SEG end_char="2217" id="segment-14" start_char="2136">
<ORIGINAL_TEXT>WADDL created its test at the request of local and federal animal health agencies.</ORIGINAL_TEXT>
<TOKEN end_char="2140" id="token-14-0" morph="none" pos="word" start_char="2136">WADDL</TOKEN>
<TOKEN end_char="2148" id="token-14-1" morph="none" pos="word" start_char="2142">created</TOKEN>
<TOKEN end_char="2152" id="token-14-2" morph="none" pos="word" start_char="2150">its</TOKEN>
<TOKEN end_char="2157" id="token-14-3" morph="none" pos="word" start_char="2154">test</TOKEN>
<TOKEN end_char="2160" id="token-14-4" morph="none" pos="word" start_char="2159">at</TOKEN>
<TOKEN end_char="2164" id="token-14-5" morph="none" pos="word" start_char="2162">the</TOKEN>
<TOKEN end_char="2172" id="token-14-6" morph="none" pos="word" start_char="2166">request</TOKEN>
<TOKEN end_char="2175" id="token-14-7" morph="none" pos="word" start_char="2174">of</TOKEN>
<TOKEN end_char="2181" id="token-14-8" morph="none" pos="word" start_char="2177">local</TOKEN>
<TOKEN end_char="2185" id="token-14-9" morph="none" pos="word" start_char="2183">and</TOKEN>
<TOKEN end_char="2193" id="token-14-10" morph="none" pos="word" start_char="2187">federal</TOKEN>
<TOKEN end_char="2200" id="token-14-11" morph="none" pos="word" start_char="2195">animal</TOKEN>
<TOKEN end_char="2207" id="token-14-12" morph="none" pos="word" start_char="2202">health</TOKEN>
<TOKEN end_char="2216" id="token-14-13" morph="none" pos="word" start_char="2209">agencies</TOKEN>
<TOKEN end_char="2217" id="token-14-14" morph="none" pos="punct" start_char="2217">.</TOKEN>
</SEG>
<SEG end_char="2410" id="segment-15" start_char="2219">
<ORIGINAL_TEXT>Officials were concerned because a nursing home in Kirkland, Washington—site of one of the first U.S. cluster outbreaks of COVID-19 in early March—was also home to a number of residents’ cats.</ORIGINAL_TEXT>
<TOKEN end_char="2227" id="token-15-0" morph="none" pos="word" start_char="2219">Officials</TOKEN>
<TOKEN end_char="2232" id="token-15-1" morph="none" pos="word" start_char="2229">were</TOKEN>
<TOKEN end_char="2242" id="token-15-2" morph="none" pos="word" start_char="2234">concerned</TOKEN>
<TOKEN end_char="2250" id="token-15-3" morph="none" pos="word" start_char="2244">because</TOKEN>
<TOKEN end_char="2252" id="token-15-4" morph="none" pos="word" start_char="2252">a</TOKEN>
<TOKEN end_char="2260" id="token-15-5" morph="none" pos="word" start_char="2254">nursing</TOKEN>
<TOKEN end_char="2265" id="token-15-6" morph="none" pos="word" start_char="2262">home</TOKEN>
<TOKEN end_char="2268" id="token-15-7" morph="none" pos="word" start_char="2267">in</TOKEN>
<TOKEN end_char="2277" id="token-15-8" morph="none" pos="word" start_char="2270">Kirkland</TOKEN>
<TOKEN end_char="2278" id="token-15-9" morph="none" pos="punct" start_char="2278">,</TOKEN>
<TOKEN end_char="2294" id="token-15-10" morph="none" pos="unknown" start_char="2280">Washington—site</TOKEN>
<TOKEN end_char="2297" id="token-15-11" morph="none" pos="word" start_char="2296">of</TOKEN>
<TOKEN end_char="2301" id="token-15-12" morph="none" pos="word" start_char="2299">one</TOKEN>
<TOKEN end_char="2304" id="token-15-13" morph="none" pos="word" start_char="2303">of</TOKEN>
<TOKEN end_char="2308" id="token-15-14" morph="none" pos="word" start_char="2306">the</TOKEN>
<TOKEN end_char="2314" id="token-15-15" morph="none" pos="word" start_char="2310">first</TOKEN>
<TOKEN end_char="2318" id="token-15-16" morph="none" pos="unknown" start_char="2316">U.S</TOKEN>
<TOKEN end_char="2319" id="token-15-17" morph="none" pos="punct" start_char="2319">.</TOKEN>
<TOKEN end_char="2327" id="token-15-18" morph="none" pos="word" start_char="2321">cluster</TOKEN>
<TOKEN end_char="2337" id="token-15-19" morph="none" pos="word" start_char="2329">outbreaks</TOKEN>
<TOKEN end_char="2340" id="token-15-20" morph="none" pos="word" start_char="2339">of</TOKEN>
<TOKEN end_char="2349" id="token-15-21" morph="none" pos="unknown" start_char="2342">COVID-19</TOKEN>
<TOKEN end_char="2352" id="token-15-22" morph="none" pos="word" start_char="2351">in</TOKEN>
<TOKEN end_char="2358" id="token-15-23" morph="none" pos="word" start_char="2354">early</TOKEN>
<TOKEN end_char="2368" id="token-15-24" morph="none" pos="unknown" start_char="2360">March—was</TOKEN>
<TOKEN end_char="2373" id="token-15-25" morph="none" pos="word" start_char="2370">also</TOKEN>
<TOKEN end_char="2378" id="token-15-26" morph="none" pos="word" start_char="2375">home</TOKEN>
<TOKEN end_char="2381" id="token-15-27" morph="none" pos="word" start_char="2380">to</TOKEN>
<TOKEN end_char="2383" id="token-15-28" morph="none" pos="word" start_char="2383">a</TOKEN>
<TOKEN end_char="2390" id="token-15-29" morph="none" pos="word" start_char="2385">number</TOKEN>
<TOKEN end_char="2393" id="token-15-30" morph="none" pos="word" start_char="2392">of</TOKEN>
<TOKEN end_char="2403" id="token-15-31" morph="none" pos="word" start_char="2395">residents</TOKEN>
<TOKEN end_char="2404" id="token-15-32" morph="none" pos="punct" start_char="2404">’</TOKEN>
<TOKEN end_char="2409" id="token-15-33" morph="none" pos="word" start_char="2406">cats</TOKEN>
<TOKEN end_char="2410" id="token-15-34" morph="none" pos="punct" start_char="2410">.</TOKEN>
</SEG>
<SEG end_char="2700" id="segment-16" start_char="2412">
<ORIGINAL_TEXT>Dogs and cats share many of the same cell receptors we do—which viruses can bind to—and during the 2003 outbreak of severe acute respiratory syndrome (a coronavirus relative of SARS-CoV-2), scientists reported that cats could become infected with the virus and pass it on to other felines.</ORIGINAL_TEXT>
<TOKEN end_char="2415" id="token-16-0" morph="none" pos="word" start_char="2412">Dogs</TOKEN>
<TOKEN end_char="2419" id="token-16-1" morph="none" pos="word" start_char="2417">and</TOKEN>
<TOKEN end_char="2424" id="token-16-2" morph="none" pos="word" start_char="2421">cats</TOKEN>
<TOKEN end_char="2430" id="token-16-3" morph="none" pos="word" start_char="2426">share</TOKEN>
<TOKEN end_char="2435" id="token-16-4" morph="none" pos="word" start_char="2432">many</TOKEN>
<TOKEN end_char="2438" id="token-16-5" morph="none" pos="word" start_char="2437">of</TOKEN>
<TOKEN end_char="2442" id="token-16-6" morph="none" pos="word" start_char="2440">the</TOKEN>
<TOKEN end_char="2447" id="token-16-7" morph="none" pos="word" start_char="2444">same</TOKEN>
<TOKEN end_char="2452" id="token-16-8" morph="none" pos="word" start_char="2449">cell</TOKEN>
<TOKEN end_char="2462" id="token-16-9" morph="none" pos="word" start_char="2454">receptors</TOKEN>
<TOKEN end_char="2465" id="token-16-10" morph="none" pos="word" start_char="2464">we</TOKEN>
<TOKEN end_char="2474" id="token-16-11" morph="none" pos="unknown" start_char="2467">do—which</TOKEN>
<TOKEN end_char="2482" id="token-16-12" morph="none" pos="word" start_char="2476">viruses</TOKEN>
<TOKEN end_char="2486" id="token-16-13" morph="none" pos="word" start_char="2484">can</TOKEN>
<TOKEN end_char="2491" id="token-16-14" morph="none" pos="word" start_char="2488">bind</TOKEN>
<TOKEN end_char="2498" id="token-16-15" morph="none" pos="unknown" start_char="2493">to—and</TOKEN>
<TOKEN end_char="2505" id="token-16-16" morph="none" pos="word" start_char="2500">during</TOKEN>
<TOKEN end_char="2509" id="token-16-17" morph="none" pos="word" start_char="2507">the</TOKEN>
<TOKEN end_char="2514" id="token-16-18" morph="none" pos="word" start_char="2511">2003</TOKEN>
<TOKEN end_char="2523" id="token-16-19" morph="none" pos="word" start_char="2516">outbreak</TOKEN>
<TOKEN end_char="2526" id="token-16-20" morph="none" pos="word" start_char="2525">of</TOKEN>
<TOKEN end_char="2533" id="token-16-21" morph="none" pos="word" start_char="2528">severe</TOKEN>
<TOKEN end_char="2539" id="token-16-22" morph="none" pos="word" start_char="2535">acute</TOKEN>
<TOKEN end_char="2551" id="token-16-23" morph="none" pos="word" start_char="2541">respiratory</TOKEN>
<TOKEN end_char="2560" id="token-16-24" morph="none" pos="word" start_char="2553">syndrome</TOKEN>
<TOKEN end_char="2562" id="token-16-25" morph="none" pos="punct" start_char="2562">(</TOKEN>
<TOKEN end_char="2563" id="token-16-26" morph="none" pos="word" start_char="2563">a</TOKEN>
<TOKEN end_char="2575" id="token-16-27" morph="none" pos="word" start_char="2565">coronavirus</TOKEN>
<TOKEN end_char="2584" id="token-16-28" morph="none" pos="word" start_char="2577">relative</TOKEN>
<TOKEN end_char="2587" id="token-16-29" morph="none" pos="word" start_char="2586">of</TOKEN>
<TOKEN end_char="2598" id="token-16-30" morph="none" pos="unknown" start_char="2589">SARS-CoV-2</TOKEN>
<TOKEN end_char="2600" id="token-16-31" morph="none" pos="punct" start_char="2599">),</TOKEN>
<TOKEN end_char="2611" id="token-16-32" morph="none" pos="word" start_char="2602">scientists</TOKEN>
<TOKEN end_char="2620" id="token-16-33" morph="none" pos="word" start_char="2613">reported</TOKEN>
<TOKEN end_char="2625" id="token-16-34" morph="none" pos="word" start_char="2622">that</TOKEN>
<TOKEN end_char="2630" id="token-16-35" morph="none" pos="word" start_char="2627">cats</TOKEN>
<TOKEN end_char="2636" id="token-16-36" morph="none" pos="word" start_char="2632">could</TOKEN>
<TOKEN end_char="2643" id="token-16-37" morph="none" pos="word" start_char="2638">become</TOKEN>
<TOKEN end_char="2652" id="token-16-38" morph="none" pos="word" start_char="2645">infected</TOKEN>
<TOKEN end_char="2657" id="token-16-39" morph="none" pos="word" start_char="2654">with</TOKEN>
<TOKEN end_char="2661" id="token-16-40" morph="none" pos="word" start_char="2659">the</TOKEN>
<TOKEN end_char="2667" id="token-16-41" morph="none" pos="word" start_char="2663">virus</TOKEN>
<TOKEN end_char="2671" id="token-16-42" morph="none" pos="word" start_char="2669">and</TOKEN>
<TOKEN end_char="2676" id="token-16-43" morph="none" pos="word" start_char="2673">pass</TOKEN>
<TOKEN end_char="2679" id="token-16-44" morph="none" pos="word" start_char="2678">it</TOKEN>
<TOKEN end_char="2682" id="token-16-45" morph="none" pos="word" start_char="2681">on</TOKEN>
<TOKEN end_char="2685" id="token-16-46" morph="none" pos="word" start_char="2684">to</TOKEN>
<TOKEN end_char="2691" id="token-16-47" morph="none" pos="word" start_char="2687">other</TOKEN>
<TOKEN end_char="2699" id="token-16-48" morph="none" pos="word" start_char="2693">felines</TOKEN>
<TOKEN end_char="2700" id="token-16-49" morph="none" pos="punct" start_char="2700">.</TOKEN>
</SEG>
<SEG end_char="2834" id="segment-17" start_char="2703">
<ORIGINAL_TEXT>WADDL’s SARS-CoV-2 pet test is similar to the human test: It uses the polymerase chain reaction (PCR) to amplify RNA from the virus.</ORIGINAL_TEXT>
<TOKEN end_char="2709" id="token-17-0" morph="none" pos="word" start_char="2703">WADDL’s</TOKEN>
<TOKEN end_char="2720" id="token-17-1" morph="none" pos="unknown" start_char="2711">SARS-CoV-2</TOKEN>
<TOKEN end_char="2724" id="token-17-2" morph="none" pos="word" start_char="2722">pet</TOKEN>
<TOKEN end_char="2729" id="token-17-3" morph="none" pos="word" start_char="2726">test</TOKEN>
<TOKEN end_char="2732" id="token-17-4" morph="none" pos="word" start_char="2731">is</TOKEN>
<TOKEN end_char="2740" id="token-17-5" morph="none" pos="word" start_char="2734">similar</TOKEN>
<TOKEN end_char="2743" id="token-17-6" morph="none" pos="word" start_char="2742">to</TOKEN>
<TOKEN end_char="2747" id="token-17-7" morph="none" pos="word" start_char="2745">the</TOKEN>
<TOKEN end_char="2753" id="token-17-8" morph="none" pos="word" start_char="2749">human</TOKEN>
<TOKEN end_char="2758" id="token-17-9" morph="none" pos="word" start_char="2755">test</TOKEN>
<TOKEN end_char="2759" id="token-17-10" morph="none" pos="punct" start_char="2759">:</TOKEN>
<TOKEN end_char="2762" id="token-17-11" morph="none" pos="word" start_char="2761">It</TOKEN>
<TOKEN end_char="2767" id="token-17-12" morph="none" pos="word" start_char="2764">uses</TOKEN>
<TOKEN end_char="2771" id="token-17-13" morph="none" pos="word" start_char="2769">the</TOKEN>
<TOKEN end_char="2782" id="token-17-14" morph="none" pos="word" start_char="2773">polymerase</TOKEN>
<TOKEN end_char="2788" id="token-17-15" morph="none" pos="word" start_char="2784">chain</TOKEN>
<TOKEN end_char="2797" id="token-17-16" morph="none" pos="word" start_char="2790">reaction</TOKEN>
<TOKEN end_char="2799" id="token-17-17" morph="none" pos="punct" start_char="2799">(</TOKEN>
<TOKEN end_char="2802" id="token-17-18" morph="none" pos="word" start_char="2800">PCR</TOKEN>
<TOKEN end_char="2803" id="token-17-19" morph="none" pos="punct" start_char="2803">)</TOKEN>
<TOKEN end_char="2806" id="token-17-20" morph="none" pos="word" start_char="2805">to</TOKEN>
<TOKEN end_char="2814" id="token-17-21" morph="none" pos="word" start_char="2808">amplify</TOKEN>
<TOKEN end_char="2818" id="token-17-22" morph="none" pos="word" start_char="2816">RNA</TOKEN>
<TOKEN end_char="2823" id="token-17-23" morph="none" pos="word" start_char="2820">from</TOKEN>
<TOKEN end_char="2827" id="token-17-24" morph="none" pos="word" start_char="2825">the</TOKEN>
<TOKEN end_char="2833" id="token-17-25" morph="none" pos="word" start_char="2829">virus</TOKEN>
<TOKEN end_char="2834" id="token-17-26" morph="none" pos="punct" start_char="2834">.</TOKEN>
</SEG>
<SEG end_char="3031" id="segment-18" start_char="2836">
<ORIGINAL_TEXT>Baszler says his team developed it with dozens of archived samples of nasal and throat swabs from cats and dogs collected from the western United States, some of which were seeded with SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN end_char="2842" id="token-18-0" morph="none" pos="word" start_char="2836">Baszler</TOKEN>
<TOKEN end_char="2847" id="token-18-1" morph="none" pos="word" start_char="2844">says</TOKEN>
<TOKEN end_char="2851" id="token-18-2" morph="none" pos="word" start_char="2849">his</TOKEN>
<TOKEN end_char="2856" id="token-18-3" morph="none" pos="word" start_char="2853">team</TOKEN>
<TOKEN end_char="2866" id="token-18-4" morph="none" pos="word" start_char="2858">developed</TOKEN>
<TOKEN end_char="2869" id="token-18-5" morph="none" pos="word" start_char="2868">it</TOKEN>
<TOKEN end_char="2874" id="token-18-6" morph="none" pos="word" start_char="2871">with</TOKEN>
<TOKEN end_char="2881" id="token-18-7" morph="none" pos="word" start_char="2876">dozens</TOKEN>
<TOKEN end_char="2884" id="token-18-8" morph="none" pos="word" start_char="2883">of</TOKEN>
<TOKEN end_char="2893" id="token-18-9" morph="none" pos="word" start_char="2886">archived</TOKEN>
<TOKEN end_char="2901" id="token-18-10" morph="none" pos="word" start_char="2895">samples</TOKEN>
<TOKEN end_char="2904" id="token-18-11" morph="none" pos="word" start_char="2903">of</TOKEN>
<TOKEN end_char="2910" id="token-18-12" morph="none" pos="word" start_char="2906">nasal</TOKEN>
<TOKEN end_char="2914" id="token-18-13" morph="none" pos="word" start_char="2912">and</TOKEN>
<TOKEN end_char="2921" id="token-18-14" morph="none" pos="word" start_char="2916">throat</TOKEN>
<TOKEN end_char="2927" id="token-18-15" morph="none" pos="word" start_char="2923">swabs</TOKEN>
<TOKEN end_char="2932" id="token-18-16" morph="none" pos="word" start_char="2929">from</TOKEN>
<TOKEN end_char="2937" id="token-18-17" morph="none" pos="word" start_char="2934">cats</TOKEN>
<TOKEN end_char="2941" id="token-18-18" morph="none" pos="word" start_char="2939">and</TOKEN>
<TOKEN end_char="2946" id="token-18-19" morph="none" pos="word" start_char="2943">dogs</TOKEN>
<TOKEN end_char="2956" id="token-18-20" morph="none" pos="word" start_char="2948">collected</TOKEN>
<TOKEN end_char="2961" id="token-18-21" morph="none" pos="word" start_char="2958">from</TOKEN>
<TOKEN end_char="2965" id="token-18-22" morph="none" pos="word" start_char="2963">the</TOKEN>
<TOKEN end_char="2973" id="token-18-23" morph="none" pos="word" start_char="2967">western</TOKEN>
<TOKEN end_char="2980" id="token-18-24" morph="none" pos="word" start_char="2975">United</TOKEN>
<TOKEN end_char="2987" id="token-18-25" morph="none" pos="word" start_char="2982">States</TOKEN>
<TOKEN end_char="2988" id="token-18-26" morph="none" pos="punct" start_char="2988">,</TOKEN>
<TOKEN end_char="2993" id="token-18-27" morph="none" pos="word" start_char="2990">some</TOKEN>
<TOKEN end_char="2996" id="token-18-28" morph="none" pos="word" start_char="2995">of</TOKEN>
<TOKEN end_char="3002" id="token-18-29" morph="none" pos="word" start_char="2998">which</TOKEN>
<TOKEN end_char="3007" id="token-18-30" morph="none" pos="word" start_char="3004">were</TOKEN>
<TOKEN end_char="3014" id="token-18-31" morph="none" pos="word" start_char="3009">seeded</TOKEN>
<TOKEN end_char="3019" id="token-18-32" morph="none" pos="word" start_char="3016">with</TOKEN>
<TOKEN end_char="3030" id="token-18-33" morph="none" pos="unknown" start_char="3021">SARS-CoV-2</TOKEN>
<TOKEN end_char="3031" id="token-18-34" morph="none" pos="punct" start_char="3031">.</TOKEN>
</SEG>
<SEG end_char="3197" id="segment-19" start_char="3033">
<ORIGINAL_TEXT>Though none of these animals had COVID-19, the test was able to pick up the virus in the seeded samples, while not reporting false positives for other coronaviruses.</ORIGINAL_TEXT>
<TOKEN end_char="3038" id="token-19-0" morph="none" pos="word" start_char="3033">Though</TOKEN>
<TOKEN end_char="3043" id="token-19-1" morph="none" pos="word" start_char="3040">none</TOKEN>
<TOKEN end_char="3046" id="token-19-2" morph="none" pos="word" start_char="3045">of</TOKEN>
<TOKEN end_char="3052" id="token-19-3" morph="none" pos="word" start_char="3048">these</TOKEN>
<TOKEN end_char="3060" id="token-19-4" morph="none" pos="word" start_char="3054">animals</TOKEN>
<TOKEN end_char="3064" id="token-19-5" morph="none" pos="word" start_char="3062">had</TOKEN>
<TOKEN end_char="3073" id="token-19-6" morph="none" pos="unknown" start_char="3066">COVID-19</TOKEN>
<TOKEN end_char="3074" id="token-19-7" morph="none" pos="punct" start_char="3074">,</TOKEN>
<TOKEN end_char="3078" id="token-19-8" morph="none" pos="word" start_char="3076">the</TOKEN>
<TOKEN end_char="3083" id="token-19-9" morph="none" pos="word" start_char="3080">test</TOKEN>
<TOKEN end_char="3087" id="token-19-10" morph="none" pos="word" start_char="3085">was</TOKEN>
<TOKEN end_char="3092" id="token-19-11" morph="none" pos="word" start_char="3089">able</TOKEN>
<TOKEN end_char="3095" id="token-19-12" morph="none" pos="word" start_char="3094">to</TOKEN>
<TOKEN end_char="3100" id="token-19-13" morph="none" pos="word" start_char="3097">pick</TOKEN>
<TOKEN end_char="3103" id="token-19-14" morph="none" pos="word" start_char="3102">up</TOKEN>
<TOKEN end_char="3107" id="token-19-15" morph="none" pos="word" start_char="3105">the</TOKEN>
<TOKEN end_char="3113" id="token-19-16" morph="none" pos="word" start_char="3109">virus</TOKEN>
<TOKEN end_char="3116" id="token-19-17" morph="none" pos="word" start_char="3115">in</TOKEN>
<TOKEN end_char="3120" id="token-19-18" morph="none" pos="word" start_char="3118">the</TOKEN>
<TOKEN end_char="3127" id="token-19-19" morph="none" pos="word" start_char="3122">seeded</TOKEN>
<TOKEN end_char="3135" id="token-19-20" morph="none" pos="word" start_char="3129">samples</TOKEN>
<TOKEN end_char="3136" id="token-19-21" morph="none" pos="punct" start_char="3136">,</TOKEN>
<TOKEN end_char="3142" id="token-19-22" morph="none" pos="word" start_char="3138">while</TOKEN>
<TOKEN end_char="3146" id="token-19-23" morph="none" pos="word" start_char="3144">not</TOKEN>
<TOKEN end_char="3156" id="token-19-24" morph="none" pos="word" start_char="3148">reporting</TOKEN>
<TOKEN end_char="3162" id="token-19-25" morph="none" pos="word" start_char="3158">false</TOKEN>
<TOKEN end_char="3172" id="token-19-26" morph="none" pos="word" start_char="3164">positives</TOKEN>
<TOKEN end_char="3176" id="token-19-27" morph="none" pos="word" start_char="3174">for</TOKEN>
<TOKEN end_char="3182" id="token-19-28" morph="none" pos="word" start_char="3178">other</TOKEN>
<TOKEN end_char="3196" id="token-19-29" morph="none" pos="word" start_char="3184">coronaviruses</TOKEN>
<TOKEN end_char="3197" id="token-19-30" morph="none" pos="punct" start_char="3197">.</TOKEN>
</SEG>
<SEG end_char="3338" id="segment-20" start_char="3199">
<ORIGINAL_TEXT>Baszler says the World Health Organization has approved the diagnostic and that WADDL could start to test up to 100 pets per day, if needed.</ORIGINAL_TEXT>
<TOKEN end_char="3205" id="token-20-0" morph="none" pos="word" start_char="3199">Baszler</TOKEN>
<TOKEN end_char="3210" id="token-20-1" morph="none" pos="word" start_char="3207">says</TOKEN>
<TOKEN end_char="3214" id="token-20-2" morph="none" pos="word" start_char="3212">the</TOKEN>
<TOKEN end_char="3220" id="token-20-3" morph="none" pos="word" start_char="3216">World</TOKEN>
<TOKEN end_char="3227" id="token-20-4" morph="none" pos="word" start_char="3222">Health</TOKEN>
<TOKEN end_char="3240" id="token-20-5" morph="none" pos="word" start_char="3229">Organization</TOKEN>
<TOKEN end_char="3244" id="token-20-6" morph="none" pos="word" start_char="3242">has</TOKEN>
<TOKEN end_char="3253" id="token-20-7" morph="none" pos="word" start_char="3246">approved</TOKEN>
<TOKEN end_char="3257" id="token-20-8" morph="none" pos="word" start_char="3255">the</TOKEN>
<TOKEN end_char="3268" id="token-20-9" morph="none" pos="word" start_char="3259">diagnostic</TOKEN>
<TOKEN end_char="3272" id="token-20-10" morph="none" pos="word" start_char="3270">and</TOKEN>
<TOKEN end_char="3277" id="token-20-11" morph="none" pos="word" start_char="3274">that</TOKEN>
<TOKEN end_char="3283" id="token-20-12" morph="none" pos="word" start_char="3279">WADDL</TOKEN>
<TOKEN end_char="3289" id="token-20-13" morph="none" pos="word" start_char="3285">could</TOKEN>
<TOKEN end_char="3295" id="token-20-14" morph="none" pos="word" start_char="3291">start</TOKEN>
<TOKEN end_char="3298" id="token-20-15" morph="none" pos="word" start_char="3297">to</TOKEN>
<TOKEN end_char="3303" id="token-20-16" morph="none" pos="word" start_char="3300">test</TOKEN>
<TOKEN end_char="3306" id="token-20-17" morph="none" pos="word" start_char="3305">up</TOKEN>
<TOKEN end_char="3309" id="token-20-18" morph="none" pos="word" start_char="3308">to</TOKEN>
<TOKEN end_char="3313" id="token-20-19" morph="none" pos="word" start_char="3311">100</TOKEN>
<TOKEN end_char="3318" id="token-20-20" morph="none" pos="word" start_char="3315">pets</TOKEN>
<TOKEN end_char="3322" id="token-20-21" morph="none" pos="word" start_char="3320">per</TOKEN>
<TOKEN end_char="3326" id="token-20-22" morph="none" pos="word" start_char="3324">day</TOKEN>
<TOKEN end_char="3327" id="token-20-23" morph="none" pos="punct" start_char="3327">,</TOKEN>
<TOKEN end_char="3330" id="token-20-24" morph="none" pos="word" start_char="3329">if</TOKEN>
<TOKEN end_char="3337" id="token-20-25" morph="none" pos="word" start_char="3332">needed</TOKEN>
<TOKEN end_char="3338" id="token-20-26" morph="none" pos="punct" start_char="3338">.</TOKEN>
</SEG>
<SEG end_char="3468" id="segment-21" start_char="3341">
<ORIGINAL_TEXT>IDEXX Laboratories, a global network of more than 80 diagnostic labs, also announced a SARS-CoV-2 test for animals in mid-March.</ORIGINAL_TEXT>
<TOKEN end_char="3345" id="token-21-0" morph="none" pos="word" start_char="3341">IDEXX</TOKEN>
<TOKEN end_char="3358" id="token-21-1" morph="none" pos="word" start_char="3347">Laboratories</TOKEN>
<TOKEN end_char="3359" id="token-21-2" morph="none" pos="punct" start_char="3359">,</TOKEN>
<TOKEN end_char="3361" id="token-21-3" morph="none" pos="word" start_char="3361">a</TOKEN>
<TOKEN end_char="3368" id="token-21-4" morph="none" pos="word" start_char="3363">global</TOKEN>
<TOKEN end_char="3376" id="token-21-5" morph="none" pos="word" start_char="3370">network</TOKEN>
<TOKEN end_char="3379" id="token-21-6" morph="none" pos="word" start_char="3378">of</TOKEN>
<TOKEN end_char="3384" id="token-21-7" morph="none" pos="word" start_char="3381">more</TOKEN>
<TOKEN end_char="3389" id="token-21-8" morph="none" pos="word" start_char="3386">than</TOKEN>
<TOKEN end_char="3392" id="token-21-9" morph="none" pos="word" start_char="3391">80</TOKEN>
<TOKEN end_char="3403" id="token-21-10" morph="none" pos="word" start_char="3394">diagnostic</TOKEN>
<TOKEN end_char="3408" id="token-21-11" morph="none" pos="word" start_char="3405">labs</TOKEN>
<TOKEN end_char="3409" id="token-21-12" morph="none" pos="punct" start_char="3409">,</TOKEN>
<TOKEN end_char="3414" id="token-21-13" morph="none" pos="word" start_char="3411">also</TOKEN>
<TOKEN end_char="3424" id="token-21-14" morph="none" pos="word" start_char="3416">announced</TOKEN>
<TOKEN end_char="3426" id="token-21-15" morph="none" pos="word" start_char="3426">a</TOKEN>
<TOKEN end_char="3437" id="token-21-16" morph="none" pos="unknown" start_char="3428">SARS-CoV-2</TOKEN>
<TOKEN end_char="3442" id="token-21-17" morph="none" pos="word" start_char="3439">test</TOKEN>
<TOKEN end_char="3446" id="token-21-18" morph="none" pos="word" start_char="3444">for</TOKEN>
<TOKEN end_char="3454" id="token-21-19" morph="none" pos="word" start_char="3448">animals</TOKEN>
<TOKEN end_char="3457" id="token-21-20" morph="none" pos="word" start_char="3456">in</TOKEN>
<TOKEN end_char="3467" id="token-21-21" morph="none" pos="unknown" start_char="3459">mid-March</TOKEN>
<TOKEN end_char="3468" id="token-21-22" morph="none" pos="punct" start_char="3468">.</TOKEN>
</SEG>
<SEG end_char="3559" id="segment-22" start_char="3470">
<ORIGINAL_TEXT>Like the WADDL test, it’s based on PCR and was developed using samples from cats and dogs.</ORIGINAL_TEXT>
<TOKEN end_char="3473" id="token-22-0" morph="none" pos="word" start_char="3470">Like</TOKEN>
<TOKEN end_char="3477" id="token-22-1" morph="none" pos="word" start_char="3475">the</TOKEN>
<TOKEN end_char="3483" id="token-22-2" morph="none" pos="word" start_char="3479">WADDL</TOKEN>
<TOKEN end_char="3488" id="token-22-3" morph="none" pos="word" start_char="3485">test</TOKEN>
<TOKEN end_char="3489" id="token-22-4" morph="none" pos="punct" start_char="3489">,</TOKEN>
<TOKEN end_char="3494" id="token-22-5" morph="none" pos="word" start_char="3491">it’s</TOKEN>
<TOKEN end_char="3500" id="token-22-6" morph="none" pos="word" start_char="3496">based</TOKEN>
<TOKEN end_char="3503" id="token-22-7" morph="none" pos="word" start_char="3502">on</TOKEN>
<TOKEN end_char="3507" id="token-22-8" morph="none" pos="word" start_char="3505">PCR</TOKEN>
<TOKEN end_char="3511" id="token-22-9" morph="none" pos="word" start_char="3509">and</TOKEN>
<TOKEN end_char="3515" id="token-22-10" morph="none" pos="word" start_char="3513">was</TOKEN>
<TOKEN end_char="3525" id="token-22-11" morph="none" pos="word" start_char="3517">developed</TOKEN>
<TOKEN end_char="3531" id="token-22-12" morph="none" pos="word" start_char="3527">using</TOKEN>
<TOKEN end_char="3539" id="token-22-13" morph="none" pos="word" start_char="3533">samples</TOKEN>
<TOKEN end_char="3544" id="token-22-14" morph="none" pos="word" start_char="3541">from</TOKEN>
<TOKEN end_char="3549" id="token-22-15" morph="none" pos="word" start_char="3546">cats</TOKEN>
<TOKEN end_char="3553" id="token-22-16" morph="none" pos="word" start_char="3551">and</TOKEN>
<TOKEN end_char="3558" id="token-22-17" morph="none" pos="word" start_char="3555">dogs</TOKEN>
<TOKEN end_char="3559" id="token-22-18" morph="none" pos="punct" start_char="3559">.</TOKEN>
</SEG>
<SEG end_char="3620" id="segment-23" start_char="3561">
<ORIGINAL_TEXT>(In IDEXX’s case, test development used horse samples, too.)</ORIGINAL_TEXT>
<TOKEN end_char="3561" id="token-23-0" morph="none" pos="punct" start_char="3561">(</TOKEN>
<TOKEN end_char="3563" id="token-23-1" morph="none" pos="word" start_char="3562">In</TOKEN>
<TOKEN end_char="3571" id="token-23-2" morph="none" pos="word" start_char="3565">IDEXX’s</TOKEN>
<TOKEN end_char="3576" id="token-23-3" morph="none" pos="word" start_char="3573">case</TOKEN>
<TOKEN end_char="3577" id="token-23-4" morph="none" pos="punct" start_char="3577">,</TOKEN>
<TOKEN end_char="3582" id="token-23-5" morph="none" pos="word" start_char="3579">test</TOKEN>
<TOKEN end_char="3594" id="token-23-6" morph="none" pos="word" start_char="3584">development</TOKEN>
<TOKEN end_char="3599" id="token-23-7" morph="none" pos="word" start_char="3596">used</TOKEN>
<TOKEN end_char="3605" id="token-23-8" morph="none" pos="word" start_char="3601">horse</TOKEN>
<TOKEN end_char="3613" id="token-23-9" morph="none" pos="word" start_char="3607">samples</TOKEN>
<TOKEN end_char="3614" id="token-23-10" morph="none" pos="punct" start_char="3614">,</TOKEN>
<TOKEN end_char="3618" id="token-23-11" morph="none" pos="word" start_char="3616">too</TOKEN>
<TOKEN end_char="3620" id="token-23-12" morph="none" pos="punct" start_char="3619">.)</TOKEN>
</SEG>
<SEG end_char="3730" id="segment-24" start_char="3622">
<ORIGINAL_TEXT>The company has analyzed more than 4000 samples, including specimens from animals with respiratory disorders.</ORIGINAL_TEXT>
<TOKEN end_char="3624" id="token-24-0" morph="none" pos="word" start_char="3622">The</TOKEN>
<TOKEN end_char="3632" id="token-24-1" morph="none" pos="word" start_char="3626">company</TOKEN>
<TOKEN end_char="3636" id="token-24-2" morph="none" pos="word" start_char="3634">has</TOKEN>
<TOKEN end_char="3645" id="token-24-3" morph="none" pos="word" start_char="3638">analyzed</TOKEN>
<TOKEN end_char="3650" id="token-24-4" morph="none" pos="word" start_char="3647">more</TOKEN>
<TOKEN end_char="3655" id="token-24-5" morph="none" pos="word" start_char="3652">than</TOKEN>
<TOKEN end_char="3660" id="token-24-6" morph="none" pos="word" start_char="3657">4000</TOKEN>
<TOKEN end_char="3668" id="token-24-7" morph="none" pos="word" start_char="3662">samples</TOKEN>
<TOKEN end_char="3669" id="token-24-8" morph="none" pos="punct" start_char="3669">,</TOKEN>
<TOKEN end_char="3679" id="token-24-9" morph="none" pos="word" start_char="3671">including</TOKEN>
<TOKEN end_char="3689" id="token-24-10" morph="none" pos="word" start_char="3681">specimens</TOKEN>
<TOKEN end_char="3694" id="token-24-11" morph="none" pos="word" start_char="3691">from</TOKEN>
<TOKEN end_char="3702" id="token-24-12" morph="none" pos="word" start_char="3696">animals</TOKEN>
<TOKEN end_char="3707" id="token-24-13" morph="none" pos="word" start_char="3704">with</TOKEN>
<TOKEN end_char="3719" id="token-24-14" morph="none" pos="word" start_char="3709">respiratory</TOKEN>
<TOKEN end_char="3729" id="token-24-15" morph="none" pos="word" start_char="3721">disorders</TOKEN>
<TOKEN end_char="3730" id="token-24-16" morph="none" pos="punct" start_char="3730">.</TOKEN>
</SEG>
<SEG end_char="3809" id="segment-25" start_char="3732">
<ORIGINAL_TEXT>"All have come back negative," says Jim Blacka, the company’s senior director.</ORIGINAL_TEXT>
<TOKEN end_char="3732" id="token-25-0" morph="none" pos="punct" start_char="3732">"</TOKEN>
<TOKEN end_char="3735" id="token-25-1" morph="none" pos="word" start_char="3733">All</TOKEN>
<TOKEN end_char="3740" id="token-25-2" morph="none" pos="word" start_char="3737">have</TOKEN>
<TOKEN end_char="3745" id="token-25-3" morph="none" pos="word" start_char="3742">come</TOKEN>
<TOKEN end_char="3750" id="token-25-4" morph="none" pos="word" start_char="3747">back</TOKEN>
<TOKEN end_char="3759" id="token-25-5" morph="none" pos="word" start_char="3752">negative</TOKEN>
<TOKEN end_char="3761" id="token-25-6" morph="none" pos="punct" start_char="3760">,"</TOKEN>
<TOKEN end_char="3766" id="token-25-7" morph="none" pos="word" start_char="3763">says</TOKEN>
<TOKEN end_char="3770" id="token-25-8" morph="none" pos="word" start_char="3768">Jim</TOKEN>
<TOKEN end_char="3777" id="token-25-9" morph="none" pos="word" start_char="3772">Blacka</TOKEN>
<TOKEN end_char="3778" id="token-25-10" morph="none" pos="punct" start_char="3778">,</TOKEN>
<TOKEN end_char="3782" id="token-25-11" morph="none" pos="word" start_char="3780">the</TOKEN>
<TOKEN end_char="3792" id="token-25-12" morph="none" pos="word" start_char="3784">company’s</TOKEN>
<TOKEN end_char="3799" id="token-25-13" morph="none" pos="word" start_char="3794">senior</TOKEN>
<TOKEN end_char="3808" id="token-25-14" morph="none" pos="word" start_char="3801">director</TOKEN>
<TOKEN end_char="3809" id="token-25-15" morph="none" pos="punct" start_char="3809">.</TOKEN>
</SEG>
<SEG end_char="3915" id="segment-26" start_char="3811">
<ORIGINAL_TEXT>"If there is a need to start testing pets, we’re ready to commercialize it and make it widely available."</ORIGINAL_TEXT>
<TOKEN end_char="3811" id="token-26-0" morph="none" pos="punct" start_char="3811">"</TOKEN>
<TOKEN end_char="3813" id="token-26-1" morph="none" pos="word" start_char="3812">If</TOKEN>
<TOKEN end_char="3819" id="token-26-2" morph="none" pos="word" start_char="3815">there</TOKEN>
<TOKEN end_char="3822" id="token-26-3" morph="none" pos="word" start_char="3821">is</TOKEN>
<TOKEN end_char="3824" id="token-26-4" morph="none" pos="word" start_char="3824">a</TOKEN>
<TOKEN end_char="3829" id="token-26-5" morph="none" pos="word" start_char="3826">need</TOKEN>
<TOKEN end_char="3832" id="token-26-6" morph="none" pos="word" start_char="3831">to</TOKEN>
<TOKEN end_char="3838" id="token-26-7" morph="none" pos="word" start_char="3834">start</TOKEN>
<TOKEN end_char="3846" id="token-26-8" morph="none" pos="word" start_char="3840">testing</TOKEN>
<TOKEN end_char="3851" id="token-26-9" morph="none" pos="word" start_char="3848">pets</TOKEN>
<TOKEN end_char="3852" id="token-26-10" morph="none" pos="punct" start_char="3852">,</TOKEN>
<TOKEN end_char="3858" id="token-26-11" morph="none" pos="word" start_char="3854">we’re</TOKEN>
<TOKEN end_char="3864" id="token-26-12" morph="none" pos="word" start_char="3860">ready</TOKEN>
<TOKEN end_char="3867" id="token-26-13" morph="none" pos="word" start_char="3866">to</TOKEN>
<TOKEN end_char="3881" id="token-26-14" morph="none" pos="word" start_char="3869">commercialize</TOKEN>
<TOKEN end_char="3884" id="token-26-15" morph="none" pos="word" start_char="3883">it</TOKEN>
<TOKEN end_char="3888" id="token-26-16" morph="none" pos="word" start_char="3886">and</TOKEN>
<TOKEN end_char="3893" id="token-26-17" morph="none" pos="word" start_char="3890">make</TOKEN>
<TOKEN end_char="3896" id="token-26-18" morph="none" pos="word" start_char="3895">it</TOKEN>
<TOKEN end_char="3903" id="token-26-19" morph="none" pos="word" start_char="3898">widely</TOKEN>
<TOKEN end_char="3913" id="token-26-20" morph="none" pos="word" start_char="3905">available</TOKEN>
<TOKEN end_char="3915" id="token-26-21" morph="none" pos="punct" start_char="3914">."</TOKEN>
</SEG>
<SEG end_char="3970" id="segment-27" start_char="3918">
<ORIGINAL_TEXT>But there are roadblocks to implementing either test.</ORIGINAL_TEXT>
<TOKEN end_char="3920" id="token-27-0" morph="none" pos="word" start_char="3918">But</TOKEN>
<TOKEN end_char="3926" id="token-27-1" morph="none" pos="word" start_char="3922">there</TOKEN>
<TOKEN end_char="3930" id="token-27-2" morph="none" pos="word" start_char="3928">are</TOKEN>
<TOKEN end_char="3941" id="token-27-3" morph="none" pos="word" start_char="3932">roadblocks</TOKEN>
<TOKEN end_char="3944" id="token-27-4" morph="none" pos="word" start_char="3943">to</TOKEN>
<TOKEN end_char="3957" id="token-27-5" morph="none" pos="word" start_char="3946">implementing</TOKEN>
<TOKEN end_char="3964" id="token-27-6" morph="none" pos="word" start_char="3959">either</TOKEN>
<TOKEN end_char="3969" id="token-27-7" morph="none" pos="word" start_char="3966">test</TOKEN>
<TOKEN end_char="3970" id="token-27-8" morph="none" pos="punct" start_char="3970">.</TOKEN>
</SEG>
<SEG end_char="4008" id="segment-28" start_char="3972">
<ORIGINAL_TEXT>The first issue is a lack of urgency.</ORIGINAL_TEXT>
<TOKEN end_char="3974" id="token-28-0" morph="none" pos="word" start_char="3972">The</TOKEN>
<TOKEN end_char="3980" id="token-28-1" morph="none" pos="word" start_char="3976">first</TOKEN>
<TOKEN end_char="3986" id="token-28-2" morph="none" pos="word" start_char="3982">issue</TOKEN>
<TOKEN end_char="3989" id="token-28-3" morph="none" pos="word" start_char="3988">is</TOKEN>
<TOKEN end_char="3991" id="token-28-4" morph="none" pos="word" start_char="3991">a</TOKEN>
<TOKEN end_char="3996" id="token-28-5" morph="none" pos="word" start_char="3993">lack</TOKEN>
<TOKEN end_char="3999" id="token-28-6" morph="none" pos="word" start_char="3998">of</TOKEN>
<TOKEN end_char="4007" id="token-28-7" morph="none" pos="word" start_char="4001">urgency</TOKEN>
<TOKEN end_char="4008" id="token-28-8" morph="none" pos="punct" start_char="4008">.</TOKEN>
</SEG>
<SEG end_char="4274" id="segment-29" start_char="4010">
<ORIGINAL_TEXT>Given that there are about 150 million dogs and cats in the United States alone, if pets could readily catch COVID-19, we would be seeing tons of cases of by now, says Shelley Rankin, a microbiologist at the University of Pennsylvania School of Veterinary Medicine.</ORIGINAL_TEXT>
<TOKEN end_char="4014" id="token-29-0" morph="none" pos="word" start_char="4010">Given</TOKEN>
<TOKEN end_char="4019" id="token-29-1" morph="none" pos="word" start_char="4016">that</TOKEN>
<TOKEN end_char="4025" id="token-29-2" morph="none" pos="word" start_char="4021">there</TOKEN>
<TOKEN end_char="4029" id="token-29-3" morph="none" pos="word" start_char="4027">are</TOKEN>
<TOKEN end_char="4035" id="token-29-4" morph="none" pos="word" start_char="4031">about</TOKEN>
<TOKEN end_char="4039" id="token-29-5" morph="none" pos="word" start_char="4037">150</TOKEN>
<TOKEN end_char="4047" id="token-29-6" morph="none" pos="word" start_char="4041">million</TOKEN>
<TOKEN end_char="4052" id="token-29-7" morph="none" pos="word" start_char="4049">dogs</TOKEN>
<TOKEN end_char="4056" id="token-29-8" morph="none" pos="word" start_char="4054">and</TOKEN>
<TOKEN end_char="4061" id="token-29-9" morph="none" pos="word" start_char="4058">cats</TOKEN>
<TOKEN end_char="4064" id="token-29-10" morph="none" pos="word" start_char="4063">in</TOKEN>
<TOKEN end_char="4068" id="token-29-11" morph="none" pos="word" start_char="4066">the</TOKEN>
<TOKEN end_char="4075" id="token-29-12" morph="none" pos="word" start_char="4070">United</TOKEN>
<TOKEN end_char="4082" id="token-29-13" morph="none" pos="word" start_char="4077">States</TOKEN>
<TOKEN end_char="4088" id="token-29-14" morph="none" pos="word" start_char="4084">alone</TOKEN>
<TOKEN end_char="4089" id="token-29-15" morph="none" pos="punct" start_char="4089">,</TOKEN>
<TOKEN end_char="4092" id="token-29-16" morph="none" pos="word" start_char="4091">if</TOKEN>
<TOKEN end_char="4097" id="token-29-17" morph="none" pos="word" start_char="4094">pets</TOKEN>
<TOKEN end_char="4103" id="token-29-18" morph="none" pos="word" start_char="4099">could</TOKEN>
<TOKEN end_char="4111" id="token-29-19" morph="none" pos="word" start_char="4105">readily</TOKEN>
<TOKEN end_char="4117" id="token-29-20" morph="none" pos="word" start_char="4113">catch</TOKEN>
<TOKEN end_char="4126" id="token-29-21" morph="none" pos="unknown" start_char="4119">COVID-19</TOKEN>
<TOKEN end_char="4127" id="token-29-22" morph="none" pos="punct" start_char="4127">,</TOKEN>
<TOKEN end_char="4130" id="token-29-23" morph="none" pos="word" start_char="4129">we</TOKEN>
<TOKEN end_char="4136" id="token-29-24" morph="none" pos="word" start_char="4132">would</TOKEN>
<TOKEN end_char="4139" id="token-29-25" morph="none" pos="word" start_char="4138">be</TOKEN>
<TOKEN end_char="4146" id="token-29-26" morph="none" pos="word" start_char="4141">seeing</TOKEN>
<TOKEN end_char="4151" id="token-29-27" morph="none" pos="word" start_char="4148">tons</TOKEN>
<TOKEN end_char="4154" id="token-29-28" morph="none" pos="word" start_char="4153">of</TOKEN>
<TOKEN end_char="4160" id="token-29-29" morph="none" pos="word" start_char="4156">cases</TOKEN>
<TOKEN end_char="4163" id="token-29-30" morph="none" pos="word" start_char="4162">of</TOKEN>
<TOKEN end_char="4166" id="token-29-31" morph="none" pos="word" start_char="4165">by</TOKEN>
<TOKEN end_char="4170" id="token-29-32" morph="none" pos="word" start_char="4168">now</TOKEN>
<TOKEN end_char="4171" id="token-29-33" morph="none" pos="punct" start_char="4171">,</TOKEN>
<TOKEN end_char="4176" id="token-29-34" morph="none" pos="word" start_char="4173">says</TOKEN>
<TOKEN end_char="4184" id="token-29-35" morph="none" pos="word" start_char="4178">Shelley</TOKEN>
<TOKEN end_char="4191" id="token-29-36" morph="none" pos="word" start_char="4186">Rankin</TOKEN>
<TOKEN end_char="4192" id="token-29-37" morph="none" pos="punct" start_char="4192">,</TOKEN>
<TOKEN end_char="4194" id="token-29-38" morph="none" pos="word" start_char="4194">a</TOKEN>
<TOKEN end_char="4209" id="token-29-39" morph="none" pos="word" start_char="4196">microbiologist</TOKEN>
<TOKEN end_char="4212" id="token-29-40" morph="none" pos="word" start_char="4211">at</TOKEN>
<TOKEN end_char="4216" id="token-29-41" morph="none" pos="word" start_char="4214">the</TOKEN>
<TOKEN end_char="4227" id="token-29-42" morph="none" pos="word" start_char="4218">University</TOKEN>
<TOKEN end_char="4230" id="token-29-43" morph="none" pos="word" start_char="4229">of</TOKEN>
<TOKEN end_char="4243" id="token-29-44" morph="none" pos="word" start_char="4232">Pennsylvania</TOKEN>
<TOKEN end_char="4250" id="token-29-45" morph="none" pos="word" start_char="4245">School</TOKEN>
<TOKEN end_char="4253" id="token-29-46" morph="none" pos="word" start_char="4252">of</TOKEN>
<TOKEN end_char="4264" id="token-29-47" morph="none" pos="word" start_char="4255">Veterinary</TOKEN>
<TOKEN end_char="4273" id="token-29-48" morph="none" pos="word" start_char="4266">Medicine</TOKEN>
<TOKEN end_char="4274" id="token-29-49" morph="none" pos="punct" start_char="4274">.</TOKEN>
</SEG>
<SEG end_char="4352" id="segment-30" start_char="4276">
<ORIGINAL_TEXT>"Yet nobody is reporting a spike" in respiratory infections in cats and dogs.</ORIGINAL_TEXT>
<TOKEN end_char="4276" id="token-30-0" morph="none" pos="punct" start_char="4276">"</TOKEN>
<TOKEN end_char="4279" id="token-30-1" morph="none" pos="word" start_char="4277">Yet</TOKEN>
<TOKEN end_char="4286" id="token-30-2" morph="none" pos="word" start_char="4281">nobody</TOKEN>
<TOKEN end_char="4289" id="token-30-3" morph="none" pos="word" start_char="4288">is</TOKEN>
<TOKEN end_char="4299" id="token-30-4" morph="none" pos="word" start_char="4291">reporting</TOKEN>
<TOKEN end_char="4301" id="token-30-5" morph="none" pos="word" start_char="4301">a</TOKEN>
<TOKEN end_char="4307" id="token-30-6" morph="none" pos="word" start_char="4303">spike</TOKEN>
<TOKEN end_char="4308" id="token-30-7" morph="none" pos="punct" start_char="4308">"</TOKEN>
<TOKEN end_char="4311" id="token-30-8" morph="none" pos="word" start_char="4310">in</TOKEN>
<TOKEN end_char="4323" id="token-30-9" morph="none" pos="word" start_char="4313">respiratory</TOKEN>
<TOKEN end_char="4334" id="token-30-10" morph="none" pos="word" start_char="4325">infections</TOKEN>
<TOKEN end_char="4337" id="token-30-11" morph="none" pos="word" start_char="4336">in</TOKEN>
<TOKEN end_char="4342" id="token-30-12" morph="none" pos="word" start_char="4339">cats</TOKEN>
<TOKEN end_char="4346" id="token-30-13" morph="none" pos="word" start_char="4344">and</TOKEN>
<TOKEN end_char="4351" id="token-30-14" morph="none" pos="word" start_char="4348">dogs</TOKEN>
<TOKEN end_char="4352" id="token-30-15" morph="none" pos="punct" start_char="4352">.</TOKEN>
</SEG>
<SEG end_char="4583" id="segment-31" start_char="4355">
<ORIGINAL_TEXT>Even the three pets that have tested positive for the virus shouldn’t sound an alarm, says Jonathan Epstein, vice president for science and outreach at the EcoHealth Alliance, a nonprofit that tracks emerging diseases in animals.</ORIGINAL_TEXT>
<TOKEN end_char="4358" id="token-31-0" morph="none" pos="word" start_char="4355">Even</TOKEN>
<TOKEN end_char="4362" id="token-31-1" morph="none" pos="word" start_char="4360">the</TOKEN>
<TOKEN end_char="4368" id="token-31-2" morph="none" pos="word" start_char="4364">three</TOKEN>
<TOKEN end_char="4373" id="token-31-3" morph="none" pos="word" start_char="4370">pets</TOKEN>
<TOKEN end_char="4378" id="token-31-4" morph="none" pos="word" start_char="4375">that</TOKEN>
<TOKEN end_char="4383" id="token-31-5" morph="none" pos="word" start_char="4380">have</TOKEN>
<TOKEN end_char="4390" id="token-31-6" morph="none" pos="word" start_char="4385">tested</TOKEN>
<TOKEN end_char="4399" id="token-31-7" morph="none" pos="word" start_char="4392">positive</TOKEN>
<TOKEN end_char="4403" id="token-31-8" morph="none" pos="word" start_char="4401">for</TOKEN>
<TOKEN end_char="4407" id="token-31-9" morph="none" pos="word" start_char="4405">the</TOKEN>
<TOKEN end_char="4413" id="token-31-10" morph="none" pos="word" start_char="4409">virus</TOKEN>
<TOKEN end_char="4423" id="token-31-11" morph="none" pos="word" start_char="4415">shouldn’t</TOKEN>
<TOKEN end_char="4429" id="token-31-12" morph="none" pos="word" start_char="4425">sound</TOKEN>
<TOKEN end_char="4432" id="token-31-13" morph="none" pos="word" start_char="4431">an</TOKEN>
<TOKEN end_char="4438" id="token-31-14" morph="none" pos="word" start_char="4434">alarm</TOKEN>
<TOKEN end_char="4439" id="token-31-15" morph="none" pos="punct" start_char="4439">,</TOKEN>
<TOKEN end_char="4444" id="token-31-16" morph="none" pos="word" start_char="4441">says</TOKEN>
<TOKEN end_char="4453" id="token-31-17" morph="none" pos="word" start_char="4446">Jonathan</TOKEN>
<TOKEN end_char="4461" id="token-31-18" morph="none" pos="word" start_char="4455">Epstein</TOKEN>
<TOKEN end_char="4462" id="token-31-19" morph="none" pos="punct" start_char="4462">,</TOKEN>
<TOKEN end_char="4467" id="token-31-20" morph="none" pos="word" start_char="4464">vice</TOKEN>
<TOKEN end_char="4477" id="token-31-21" morph="none" pos="word" start_char="4469">president</TOKEN>
<TOKEN end_char="4481" id="token-31-22" morph="none" pos="word" start_char="4479">for</TOKEN>
<TOKEN end_char="4489" id="token-31-23" morph="none" pos="word" start_char="4483">science</TOKEN>
<TOKEN end_char="4493" id="token-31-24" morph="none" pos="word" start_char="4491">and</TOKEN>
<TOKEN end_char="4502" id="token-31-25" morph="none" pos="word" start_char="4495">outreach</TOKEN>
<TOKEN end_char="4505" id="token-31-26" morph="none" pos="word" start_char="4504">at</TOKEN>
<TOKEN end_char="4509" id="token-31-27" morph="none" pos="word" start_char="4507">the</TOKEN>
<TOKEN end_char="4519" id="token-31-28" morph="none" pos="word" start_char="4511">EcoHealth</TOKEN>
<TOKEN end_char="4528" id="token-31-29" morph="none" pos="word" start_char="4521">Alliance</TOKEN>
<TOKEN end_char="4529" id="token-31-30" morph="none" pos="punct" start_char="4529">,</TOKEN>
<TOKEN end_char="4531" id="token-31-31" morph="none" pos="word" start_char="4531">a</TOKEN>
<TOKEN end_char="4541" id="token-31-32" morph="none" pos="word" start_char="4533">nonprofit</TOKEN>
<TOKEN end_char="4546" id="token-31-33" morph="none" pos="word" start_char="4543">that</TOKEN>
<TOKEN end_char="4553" id="token-31-34" morph="none" pos="word" start_char="4548">tracks</TOKEN>
<TOKEN end_char="4562" id="token-31-35" morph="none" pos="word" start_char="4555">emerging</TOKEN>
<TOKEN end_char="4571" id="token-31-36" morph="none" pos="word" start_char="4564">diseases</TOKEN>
<TOKEN end_char="4574" id="token-31-37" morph="none" pos="word" start_char="4573">in</TOKEN>
<TOKEN end_char="4582" id="token-31-38" morph="none" pos="word" start_char="4576">animals</TOKEN>
<TOKEN end_char="4583" id="token-31-39" morph="none" pos="punct" start_char="4583">.</TOKEN>
</SEG>
<SEG end_char="4663" id="segment-32" start_char="4585">
<ORIGINAL_TEXT>"Detecting RNA is different from [animals] shedding infectious virus," he says.</ORIGINAL_TEXT>
<TOKEN end_char="4585" id="token-32-0" morph="none" pos="punct" start_char="4585">"</TOKEN>
<TOKEN end_char="4594" id="token-32-1" morph="none" pos="word" start_char="4586">Detecting</TOKEN>
<TOKEN end_char="4598" id="token-32-2" morph="none" pos="word" start_char="4596">RNA</TOKEN>
<TOKEN end_char="4601" id="token-32-3" morph="none" pos="word" start_char="4600">is</TOKEN>
<TOKEN end_char="4611" id="token-32-4" morph="none" pos="word" start_char="4603">different</TOKEN>
<TOKEN end_char="4616" id="token-32-5" morph="none" pos="word" start_char="4613">from</TOKEN>
<TOKEN end_char="4618" id="token-32-6" morph="none" pos="punct" start_char="4618">[</TOKEN>
<TOKEN end_char="4625" id="token-32-7" morph="none" pos="word" start_char="4619">animals</TOKEN>
<TOKEN end_char="4626" id="token-32-8" morph="none" pos="punct" start_char="4626">]</TOKEN>
<TOKEN end_char="4635" id="token-32-9" morph="none" pos="word" start_char="4628">shedding</TOKEN>
<TOKEN end_char="4646" id="token-32-10" morph="none" pos="word" start_char="4637">infectious</TOKEN>
<TOKEN end_char="4652" id="token-32-11" morph="none" pos="word" start_char="4648">virus</TOKEN>
<TOKEN end_char="4654" id="token-32-12" morph="none" pos="punct" start_char="4653">,"</TOKEN>
<TOKEN end_char="4657" id="token-32-13" morph="none" pos="word" start_char="4656">he</TOKEN>
<TOKEN end_char="4662" id="token-32-14" morph="none" pos="word" start_char="4659">says</TOKEN>
<TOKEN end_char="4663" id="token-32-15" morph="none" pos="punct" start_char="4663">.</TOKEN>
</SEG>
<SEG end_char="4765" id="segment-33" start_char="4665">
<ORIGINAL_TEXT>"Our focus now should be on human-to-human transmission, because that’s what’s driving the epidemic."</ORIGINAL_TEXT>
<TOKEN end_char="4665" id="token-33-0" morph="none" pos="punct" start_char="4665">"</TOKEN>
<TOKEN end_char="4668" id="token-33-1" morph="none" pos="word" start_char="4666">Our</TOKEN>
<TOKEN end_char="4674" id="token-33-2" morph="none" pos="word" start_char="4670">focus</TOKEN>
<TOKEN end_char="4678" id="token-33-3" morph="none" pos="word" start_char="4676">now</TOKEN>
<TOKEN end_char="4685" id="token-33-4" morph="none" pos="word" start_char="4680">should</TOKEN>
<TOKEN end_char="4688" id="token-33-5" morph="none" pos="word" start_char="4687">be</TOKEN>
<TOKEN end_char="4691" id="token-33-6" morph="none" pos="word" start_char="4690">on</TOKEN>
<TOKEN end_char="4706" id="token-33-7" morph="none" pos="unknown" start_char="4693">human-to-human</TOKEN>
<TOKEN end_char="4719" id="token-33-8" morph="none" pos="word" start_char="4708">transmission</TOKEN>
<TOKEN end_char="4720" id="token-33-9" morph="none" pos="punct" start_char="4720">,</TOKEN>
<TOKEN end_char="4728" id="token-33-10" morph="none" pos="word" start_char="4722">because</TOKEN>
<TOKEN end_char="4735" id="token-33-11" morph="none" pos="word" start_char="4730">that’s</TOKEN>
<TOKEN end_char="4742" id="token-33-12" morph="none" pos="word" start_char="4737">what’s</TOKEN>
<TOKEN end_char="4750" id="token-33-13" morph="none" pos="word" start_char="4744">driving</TOKEN>
<TOKEN end_char="4754" id="token-33-14" morph="none" pos="word" start_char="4752">the</TOKEN>
<TOKEN end_char="4763" id="token-33-15" morph="none" pos="word" start_char="4756">epidemic</TOKEN>
<TOKEN end_char="4765" id="token-33-16" morph="none" pos="punct" start_char="4764">."</TOKEN>
</SEG>
<SEG end_char="4833" id="segment-34" start_char="4768">
<ORIGINAL_TEXT>USDA released an FAQ last week that cautioned against pet testing.</ORIGINAL_TEXT>
<TOKEN end_char="4771" id="token-34-0" morph="none" pos="word" start_char="4768">USDA</TOKEN>
<TOKEN end_char="4780" id="token-34-1" morph="none" pos="word" start_char="4773">released</TOKEN>
<TOKEN end_char="4783" id="token-34-2" morph="none" pos="word" start_char="4782">an</TOKEN>
<TOKEN end_char="4787" id="token-34-3" morph="none" pos="word" start_char="4785">FAQ</TOKEN>
<TOKEN end_char="4792" id="token-34-4" morph="none" pos="word" start_char="4789">last</TOKEN>
<TOKEN end_char="4797" id="token-34-5" morph="none" pos="word" start_char="4794">week</TOKEN>
<TOKEN end_char="4802" id="token-34-6" morph="none" pos="word" start_char="4799">that</TOKEN>
<TOKEN end_char="4812" id="token-34-7" morph="none" pos="word" start_char="4804">cautioned</TOKEN>
<TOKEN end_char="4820" id="token-34-8" morph="none" pos="word" start_char="4814">against</TOKEN>
<TOKEN end_char="4824" id="token-34-9" morph="none" pos="word" start_char="4822">pet</TOKEN>
<TOKEN end_char="4832" id="token-34-10" morph="none" pos="word" start_char="4826">testing</TOKEN>
<TOKEN end_char="4833" id="token-34-11" morph="none" pos="punct" start_char="4833">.</TOKEN>
</SEG>
<SEG end_char="5021" id="segment-35" start_char="4835">
<ORIGINAL_TEXT>"At this time, testing for companion animals will only be done if animal and public health officials agree testing should occur due to a link to a known human case of COVID-19," it reads.</ORIGINAL_TEXT>
<TOKEN end_char="4835" id="token-35-0" morph="none" pos="punct" start_char="4835">"</TOKEN>
<TOKEN end_char="4837" id="token-35-1" morph="none" pos="word" start_char="4836">At</TOKEN>
<TOKEN end_char="4842" id="token-35-2" morph="none" pos="word" start_char="4839">this</TOKEN>
<TOKEN end_char="4847" id="token-35-3" morph="none" pos="word" start_char="4844">time</TOKEN>
<TOKEN end_char="4848" id="token-35-4" morph="none" pos="punct" start_char="4848">,</TOKEN>
<TOKEN end_char="4856" id="token-35-5" morph="none" pos="word" start_char="4850">testing</TOKEN>
<TOKEN end_char="4860" id="token-35-6" morph="none" pos="word" start_char="4858">for</TOKEN>
<TOKEN end_char="4870" id="token-35-7" morph="none" pos="word" start_char="4862">companion</TOKEN>
<TOKEN end_char="4878" id="token-35-8" morph="none" pos="word" start_char="4872">animals</TOKEN>
<TOKEN end_char="4883" id="token-35-9" morph="none" pos="word" start_char="4880">will</TOKEN>
<TOKEN end_char="4888" id="token-35-10" morph="none" pos="word" start_char="4885">only</TOKEN>
<TOKEN end_char="4891" id="token-35-11" morph="none" pos="word" start_char="4890">be</TOKEN>
<TOKEN end_char="4896" id="token-35-12" morph="none" pos="word" start_char="4893">done</TOKEN>
<TOKEN end_char="4899" id="token-35-13" morph="none" pos="word" start_char="4898">if</TOKEN>
<TOKEN end_char="4906" id="token-35-14" morph="none" pos="word" start_char="4901">animal</TOKEN>
<TOKEN end_char="4910" id="token-35-15" morph="none" pos="word" start_char="4908">and</TOKEN>
<TOKEN end_char="4917" id="token-35-16" morph="none" pos="word" start_char="4912">public</TOKEN>
<TOKEN end_char="4924" id="token-35-17" morph="none" pos="word" start_char="4919">health</TOKEN>
<TOKEN end_char="4934" id="token-35-18" morph="none" pos="word" start_char="4926">officials</TOKEN>
<TOKEN end_char="4940" id="token-35-19" morph="none" pos="word" start_char="4936">agree</TOKEN>
<TOKEN end_char="4948" id="token-35-20" morph="none" pos="word" start_char="4942">testing</TOKEN>
<TOKEN end_char="4955" id="token-35-21" morph="none" pos="word" start_char="4950">should</TOKEN>
<TOKEN end_char="4961" id="token-35-22" morph="none" pos="word" start_char="4957">occur</TOKEN>
<TOKEN end_char="4965" id="token-35-23" morph="none" pos="word" start_char="4963">due</TOKEN>
<TOKEN end_char="4968" id="token-35-24" morph="none" pos="word" start_char="4967">to</TOKEN>
<TOKEN end_char="4970" id="token-35-25" morph="none" pos="word" start_char="4970">a</TOKEN>
<TOKEN end_char="4975" id="token-35-26" morph="none" pos="word" start_char="4972">link</TOKEN>
<TOKEN end_char="4978" id="token-35-27" morph="none" pos="word" start_char="4977">to</TOKEN>
<TOKEN end_char="4980" id="token-35-28" morph="none" pos="word" start_char="4980">a</TOKEN>
<TOKEN end_char="4986" id="token-35-29" morph="none" pos="word" start_char="4982">known</TOKEN>
<TOKEN end_char="4992" id="token-35-30" morph="none" pos="word" start_char="4988">human</TOKEN>
<TOKEN end_char="4997" id="token-35-31" morph="none" pos="word" start_char="4994">case</TOKEN>
<TOKEN end_char="5000" id="token-35-32" morph="none" pos="word" start_char="4999">of</TOKEN>
<TOKEN end_char="5009" id="token-35-33" morph="none" pos="unknown" start_char="5002">COVID-19</TOKEN>
<TOKEN end_char="5011" id="token-35-34" morph="none" pos="punct" start_char="5010">,"</TOKEN>
<TOKEN end_char="5014" id="token-35-35" morph="none" pos="word" start_char="5013">it</TOKEN>
<TOKEN end_char="5020" id="token-35-36" morph="none" pos="word" start_char="5016">reads</TOKEN>
<TOKEN end_char="5021" id="token-35-37" morph="none" pos="punct" start_char="5021">.</TOKEN>
</SEG>
<SEG end_char="5087" id="segment-36" start_char="5023">
<ORIGINAL_TEXT>"We will not be testing the general companion animal population."</ORIGINAL_TEXT>
<TOKEN end_char="5023" id="token-36-0" morph="none" pos="punct" start_char="5023">"</TOKEN>
<TOKEN end_char="5025" id="token-36-1" morph="none" pos="word" start_char="5024">We</TOKEN>
<TOKEN end_char="5030" id="token-36-2" morph="none" pos="word" start_char="5027">will</TOKEN>
<TOKEN end_char="5034" id="token-36-3" morph="none" pos="word" start_char="5032">not</TOKEN>
<TOKEN end_char="5037" id="token-36-4" morph="none" pos="word" start_char="5036">be</TOKEN>
<TOKEN end_char="5045" id="token-36-5" morph="none" pos="word" start_char="5039">testing</TOKEN>
<TOKEN end_char="5049" id="token-36-6" morph="none" pos="word" start_char="5047">the</TOKEN>
<TOKEN end_char="5057" id="token-36-7" morph="none" pos="word" start_char="5051">general</TOKEN>
<TOKEN end_char="5067" id="token-36-8" morph="none" pos="word" start_char="5059">companion</TOKEN>
<TOKEN end_char="5074" id="token-36-9" morph="none" pos="word" start_char="5069">animal</TOKEN>
<TOKEN end_char="5085" id="token-36-10" morph="none" pos="word" start_char="5076">population</TOKEN>
<TOKEN end_char="5087" id="token-36-11" morph="none" pos="punct" start_char="5086">."</TOKEN>
</SEG>
<SEG end_char="5220" id="segment-37" start_char="5090">
<ORIGINAL_TEXT>The document, Rankin argues, effectively prevents labs from broadly testing companion animals for SARS-CoV-2 without USDA approval.</ORIGINAL_TEXT>
<TOKEN end_char="5092" id="token-37-0" morph="none" pos="word" start_char="5090">The</TOKEN>
<TOKEN end_char="5101" id="token-37-1" morph="none" pos="word" start_char="5094">document</TOKEN>
<TOKEN end_char="5102" id="token-37-2" morph="none" pos="punct" start_char="5102">,</TOKEN>
<TOKEN end_char="5109" id="token-37-3" morph="none" pos="word" start_char="5104">Rankin</TOKEN>
<TOKEN end_char="5116" id="token-37-4" morph="none" pos="word" start_char="5111">argues</TOKEN>
<TOKEN end_char="5117" id="token-37-5" morph="none" pos="punct" start_char="5117">,</TOKEN>
<TOKEN end_char="5129" id="token-37-6" morph="none" pos="word" start_char="5119">effectively</TOKEN>
<TOKEN end_char="5138" id="token-37-7" morph="none" pos="word" start_char="5131">prevents</TOKEN>
<TOKEN end_char="5143" id="token-37-8" morph="none" pos="word" start_char="5140">labs</TOKEN>
<TOKEN end_char="5148" id="token-37-9" morph="none" pos="word" start_char="5145">from</TOKEN>
<TOKEN end_char="5156" id="token-37-10" morph="none" pos="word" start_char="5150">broadly</TOKEN>
<TOKEN end_char="5164" id="token-37-11" morph="none" pos="word" start_char="5158">testing</TOKEN>
<TOKEN end_char="5174" id="token-37-12" morph="none" pos="word" start_char="5166">companion</TOKEN>
<TOKEN end_char="5182" id="token-37-13" morph="none" pos="word" start_char="5176">animals</TOKEN>
<TOKEN end_char="5186" id="token-37-14" morph="none" pos="word" start_char="5184">for</TOKEN>
<TOKEN end_char="5197" id="token-37-15" morph="none" pos="unknown" start_char="5188">SARS-CoV-2</TOKEN>
<TOKEN end_char="5205" id="token-37-16" morph="none" pos="word" start_char="5199">without</TOKEN>
<TOKEN end_char="5210" id="token-37-17" morph="none" pos="word" start_char="5207">USDA</TOKEN>
<TOKEN end_char="5219" id="token-37-18" morph="none" pos="word" start_char="5212">approval</TOKEN>
<TOKEN end_char="5220" id="token-37-19" morph="none" pos="punct" start_char="5220">.</TOKEN>
</SEG>
<SEG end_char="5337" id="segment-38" start_char="5222">
<ORIGINAL_TEXT>Baszler says the recommendations are helpful, because it’s unclear what to do if a pet tests positive for the virus.</ORIGINAL_TEXT>
<TOKEN end_char="5228" id="token-38-0" morph="none" pos="word" start_char="5222">Baszler</TOKEN>
<TOKEN end_char="5233" id="token-38-1" morph="none" pos="word" start_char="5230">says</TOKEN>
<TOKEN end_char="5237" id="token-38-2" morph="none" pos="word" start_char="5235">the</TOKEN>
<TOKEN end_char="5253" id="token-38-3" morph="none" pos="word" start_char="5239">recommendations</TOKEN>
<TOKEN end_char="5257" id="token-38-4" morph="none" pos="word" start_char="5255">are</TOKEN>
<TOKEN end_char="5265" id="token-38-5" morph="none" pos="word" start_char="5259">helpful</TOKEN>
<TOKEN end_char="5266" id="token-38-6" morph="none" pos="punct" start_char="5266">,</TOKEN>
<TOKEN end_char="5274" id="token-38-7" morph="none" pos="word" start_char="5268">because</TOKEN>
<TOKEN end_char="5279" id="token-38-8" morph="none" pos="word" start_char="5276">it’s</TOKEN>
<TOKEN end_char="5287" id="token-38-9" morph="none" pos="word" start_char="5281">unclear</TOKEN>
<TOKEN end_char="5292" id="token-38-10" morph="none" pos="word" start_char="5289">what</TOKEN>
<TOKEN end_char="5295" id="token-38-11" morph="none" pos="word" start_char="5294">to</TOKEN>
<TOKEN end_char="5298" id="token-38-12" morph="none" pos="word" start_char="5297">do</TOKEN>
<TOKEN end_char="5301" id="token-38-13" morph="none" pos="word" start_char="5300">if</TOKEN>
<TOKEN end_char="5303" id="token-38-14" morph="none" pos="word" start_char="5303">a</TOKEN>
<TOKEN end_char="5307" id="token-38-15" morph="none" pos="word" start_char="5305">pet</TOKEN>
<TOKEN end_char="5313" id="token-38-16" morph="none" pos="word" start_char="5309">tests</TOKEN>
<TOKEN end_char="5322" id="token-38-17" morph="none" pos="word" start_char="5315">positive</TOKEN>
<TOKEN end_char="5326" id="token-38-18" morph="none" pos="word" start_char="5324">for</TOKEN>
<TOKEN end_char="5330" id="token-38-19" morph="none" pos="word" start_char="5328">the</TOKEN>
<TOKEN end_char="5336" id="token-38-20" morph="none" pos="word" start_char="5332">virus</TOKEN>
<TOKEN end_char="5337" id="token-38-21" morph="none" pos="punct" start_char="5337">.</TOKEN>
</SEG>
<SEG end_char="5435" id="segment-39" start_char="5339">
<ORIGINAL_TEXT>"If you get a positive dog in a home where no one else is sick, what do you do with that animal?"</ORIGINAL_TEXT>
<TOKEN end_char="5339" id="token-39-0" morph="none" pos="punct" start_char="5339">"</TOKEN>
<TOKEN end_char="5341" id="token-39-1" morph="none" pos="word" start_char="5340">If</TOKEN>
<TOKEN end_char="5345" id="token-39-2" morph="none" pos="word" start_char="5343">you</TOKEN>
<TOKEN end_char="5349" id="token-39-3" morph="none" pos="word" start_char="5347">get</TOKEN>
<TOKEN end_char="5351" id="token-39-4" morph="none" pos="word" start_char="5351">a</TOKEN>
<TOKEN end_char="5360" id="token-39-5" morph="none" pos="word" start_char="5353">positive</TOKEN>
<TOKEN end_char="5364" id="token-39-6" morph="none" pos="word" start_char="5362">dog</TOKEN>
<TOKEN end_char="5367" id="token-39-7" morph="none" pos="word" start_char="5366">in</TOKEN>
<TOKEN end_char="5369" id="token-39-8" morph="none" pos="word" start_char="5369">a</TOKEN>
<TOKEN end_char="5374" id="token-39-9" morph="none" pos="word" start_char="5371">home</TOKEN>
<TOKEN end_char="5380" id="token-39-10" morph="none" pos="word" start_char="5376">where</TOKEN>
<TOKEN end_char="5383" id="token-39-11" morph="none" pos="word" start_char="5382">no</TOKEN>
<TOKEN end_char="5387" id="token-39-12" morph="none" pos="word" start_char="5385">one</TOKEN>
<TOKEN end_char="5392" id="token-39-13" morph="none" pos="word" start_char="5389">else</TOKEN>
<TOKEN end_char="5395" id="token-39-14" morph="none" pos="word" start_char="5394">is</TOKEN>
<TOKEN end_char="5400" id="token-39-15" morph="none" pos="word" start_char="5397">sick</TOKEN>
<TOKEN end_char="5401" id="token-39-16" morph="none" pos="punct" start_char="5401">,</TOKEN>
<TOKEN end_char="5406" id="token-39-17" morph="none" pos="word" start_char="5403">what</TOKEN>
<TOKEN end_char="5409" id="token-39-18" morph="none" pos="word" start_char="5408">do</TOKEN>
<TOKEN end_char="5413" id="token-39-19" morph="none" pos="word" start_char="5411">you</TOKEN>
<TOKEN end_char="5416" id="token-39-20" morph="none" pos="word" start_char="5415">do</TOKEN>
<TOKEN end_char="5421" id="token-39-21" morph="none" pos="word" start_char="5418">with</TOKEN>
<TOKEN end_char="5426" id="token-39-22" morph="none" pos="word" start_char="5423">that</TOKEN>
<TOKEN end_char="5433" id="token-39-23" morph="none" pos="word" start_char="5428">animal</TOKEN>
<TOKEN end_char="5435" id="token-39-24" morph="none" pos="punct" start_char="5434">?"</TOKEN>
</SEG>
<SEG end_char="5444" id="segment-40" start_char="5437">
<ORIGINAL_TEXT>he asks.</ORIGINAL_TEXT>
<TOKEN end_char="5438" id="token-40-0" morph="none" pos="word" start_char="5437">he</TOKEN>
<TOKEN end_char="5443" id="token-40-1" morph="none" pos="word" start_char="5440">asks</TOKEN>
<TOKEN end_char="5444" id="token-40-2" morph="none" pos="punct" start_char="5444">.</TOKEN>
<TRANSLATED_TEXT>ha chiesto.</TRANSLATED_TEXT><DETECTED_LANGUAGE>et</DETECTED_LANGUAGE></SEG>
<SEG end_char="5467" id="segment-41" start_char="5446">
<ORIGINAL_TEXT>"Do you quarantine it?</ORIGINAL_TEXT>
<TOKEN end_char="5446" id="token-41-0" morph="none" pos="punct" start_char="5446">"</TOKEN>
<TOKEN end_char="5448" id="token-41-1" morph="none" pos="word" start_char="5447">Do</TOKEN>
<TOKEN end_char="5452" id="token-41-2" morph="none" pos="word" start_char="5450">you</TOKEN>
<TOKEN end_char="5463" id="token-41-3" morph="none" pos="word" start_char="5454">quarantine</TOKEN>
<TOKEN end_char="5466" id="token-41-4" morph="none" pos="word" start_char="5465">it</TOKEN>
<TOKEN end_char="5467" id="token-41-5" morph="none" pos="punct" start_char="5467">?</TOKEN>
<TRANSLATED_TEXT>Do you quarantine it?</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="5474" id="segment-42" start_char="5469">
<ORIGINAL_TEXT>Where?</ORIGINAL_TEXT>
<TOKEN end_char="5473" id="token-42-0" morph="none" pos="word" start_char="5469">Where</TOKEN>
<TOKEN end_char="5474" id="token-42-1" morph="none" pos="punct" start_char="5474">?</TOKEN>
</SEG>
<SEG end_char="5525" id="segment-43" start_char="5476">
<ORIGINAL_TEXT>And who decides when that quarantine gets lifted?"</ORIGINAL_TEXT>
<TOKEN end_char="5478" id="token-43-0" morph="none" pos="word" start_char="5476">And</TOKEN>
<TOKEN end_char="5482" id="token-43-1" morph="none" pos="word" start_char="5480">who</TOKEN>
<TOKEN end_char="5490" id="token-43-2" morph="none" pos="word" start_char="5484">decides</TOKEN>
<TOKEN end_char="5495" id="token-43-3" morph="none" pos="word" start_char="5492">when</TOKEN>
<TOKEN end_char="5500" id="token-43-4" morph="none" pos="word" start_char="5497">that</TOKEN>
<TOKEN end_char="5511" id="token-43-5" morph="none" pos="word" start_char="5502">quarantine</TOKEN>
<TOKEN end_char="5516" id="token-43-6" morph="none" pos="word" start_char="5513">gets</TOKEN>
<TOKEN end_char="5523" id="token-43-7" morph="none" pos="word" start_char="5518">lifted</TOKEN>
<TOKEN end_char="5525" id="token-43-8" morph="none" pos="punct" start_char="5524">?"</TOKEN>
</SEG>
<SEG end_char="5606" id="segment-44" start_char="5527">
<ORIGINAL_TEXT>Rushing into testing without a road map, he says, "just creates angst and fear."</ORIGINAL_TEXT>
<TOKEN end_char="5533" id="token-44-0" morph="none" pos="word" start_char="5527">Rushing</TOKEN>
<TOKEN end_char="5538" id="token-44-1" morph="none" pos="word" start_char="5535">into</TOKEN>
<TOKEN end_char="5546" id="token-44-2" morph="none" pos="word" start_char="5540">testing</TOKEN>
<TOKEN end_char="5554" id="token-44-3" morph="none" pos="word" start_char="5548">without</TOKEN>
<TOKEN end_char="5556" id="token-44-4" morph="none" pos="word" start_char="5556">a</TOKEN>
<TOKEN end_char="5561" id="token-44-5" morph="none" pos="word" start_char="5558">road</TOKEN>
<TOKEN end_char="5565" id="token-44-6" morph="none" pos="word" start_char="5563">map</TOKEN>
<TOKEN end_char="5566" id="token-44-7" morph="none" pos="punct" start_char="5566">,</TOKEN>
<TOKEN end_char="5569" id="token-44-8" morph="none" pos="word" start_char="5568">he</TOKEN>
<TOKEN end_char="5574" id="token-44-9" morph="none" pos="word" start_char="5571">says</TOKEN>
<TOKEN end_char="5575" id="token-44-10" morph="none" pos="punct" start_char="5575">,</TOKEN>
<TOKEN end_char="5577" id="token-44-11" morph="none" pos="punct" start_char="5577">"</TOKEN>
<TOKEN end_char="5581" id="token-44-12" morph="none" pos="word" start_char="5578">just</TOKEN>
<TOKEN end_char="5589" id="token-44-13" morph="none" pos="word" start_char="5583">creates</TOKEN>
<TOKEN end_char="5595" id="token-44-14" morph="none" pos="word" start_char="5591">angst</TOKEN>
<TOKEN end_char="5599" id="token-44-15" morph="none" pos="word" start_char="5597">and</TOKEN>
<TOKEN end_char="5604" id="token-44-16" morph="none" pos="word" start_char="5601">fear</TOKEN>
<TOKEN end_char="5606" id="token-44-17" morph="none" pos="punct" start_char="5605">."</TOKEN>
</SEG>
<SEG end_char="5706" id="segment-45" start_char="5609">
<ORIGINAL_TEXT>Baszler says he is working with state veterinary officials to develop such a plan for pet testing.</ORIGINAL_TEXT>
<TOKEN end_char="5615" id="token-45-0" morph="none" pos="word" start_char="5609">Baszler</TOKEN>
<TOKEN end_char="5620" id="token-45-1" morph="none" pos="word" start_char="5617">says</TOKEN>
<TOKEN end_char="5623" id="token-45-2" morph="none" pos="word" start_char="5622">he</TOKEN>
<TOKEN end_char="5626" id="token-45-3" morph="none" pos="word" start_char="5625">is</TOKEN>
<TOKEN end_char="5634" id="token-45-4" morph="none" pos="word" start_char="5628">working</TOKEN>
<TOKEN end_char="5639" id="token-45-5" morph="none" pos="word" start_char="5636">with</TOKEN>
<TOKEN end_char="5645" id="token-45-6" morph="none" pos="word" start_char="5641">state</TOKEN>
<TOKEN end_char="5656" id="token-45-7" morph="none" pos="word" start_char="5647">veterinary</TOKEN>
<TOKEN end_char="5666" id="token-45-8" morph="none" pos="word" start_char="5658">officials</TOKEN>
<TOKEN end_char="5669" id="token-45-9" morph="none" pos="word" start_char="5668">to</TOKEN>
<TOKEN end_char="5677" id="token-45-10" morph="none" pos="word" start_char="5671">develop</TOKEN>
<TOKEN end_char="5682" id="token-45-11" morph="none" pos="word" start_char="5679">such</TOKEN>
<TOKEN end_char="5684" id="token-45-12" morph="none" pos="word" start_char="5684">a</TOKEN>
<TOKEN end_char="5689" id="token-45-13" morph="none" pos="word" start_char="5686">plan</TOKEN>
<TOKEN end_char="5693" id="token-45-14" morph="none" pos="word" start_char="5691">for</TOKEN>
<TOKEN end_char="5697" id="token-45-15" morph="none" pos="word" start_char="5695">pet</TOKEN>
<TOKEN end_char="5705" id="token-45-16" morph="none" pos="word" start_char="5699">testing</TOKEN>
<TOKEN end_char="5706" id="token-45-17" morph="none" pos="punct" start_char="5706">.</TOKEN>
</SEG>
<SEG end_char="5831" id="segment-46" start_char="5708">
<ORIGINAL_TEXT>He says if the efforts do begin, the first focus should be on animals in homes in which humans have already tested positive.</ORIGINAL_TEXT>
<TOKEN end_char="5709" id="token-46-0" morph="none" pos="word" start_char="5708">He</TOKEN>
<TOKEN end_char="5714" id="token-46-1" morph="none" pos="word" start_char="5711">says</TOKEN>
<TOKEN end_char="5717" id="token-46-2" morph="none" pos="word" start_char="5716">if</TOKEN>
<TOKEN end_char="5721" id="token-46-3" morph="none" pos="word" start_char="5719">the</TOKEN>
<TOKEN end_char="5729" id="token-46-4" morph="none" pos="word" start_char="5723">efforts</TOKEN>
<TOKEN end_char="5732" id="token-46-5" morph="none" pos="word" start_char="5731">do</TOKEN>
<TOKEN end_char="5738" id="token-46-6" morph="none" pos="word" start_char="5734">begin</TOKEN>
<TOKEN end_char="5739" id="token-46-7" morph="none" pos="punct" start_char="5739">,</TOKEN>
<TOKEN end_char="5743" id="token-46-8" morph="none" pos="word" start_char="5741">the</TOKEN>
<TOKEN end_char="5749" id="token-46-9" morph="none" pos="word" start_char="5745">first</TOKEN>
<TOKEN end_char="5755" id="token-46-10" morph="none" pos="word" start_char="5751">focus</TOKEN>
<TOKEN end_char="5762" id="token-46-11" morph="none" pos="word" start_char="5757">should</TOKEN>
<TOKEN end_char="5765" id="token-46-12" morph="none" pos="word" start_char="5764">be</TOKEN>
<TOKEN end_char="5768" id="token-46-13" morph="none" pos="word" start_char="5767">on</TOKEN>
<TOKEN end_char="5776" id="token-46-14" morph="none" pos="word" start_char="5770">animals</TOKEN>
<TOKEN end_char="5779" id="token-46-15" morph="none" pos="word" start_char="5778">in</TOKEN>
<TOKEN end_char="5785" id="token-46-16" morph="none" pos="word" start_char="5781">homes</TOKEN>
<TOKEN end_char="5788" id="token-46-17" morph="none" pos="word" start_char="5787">in</TOKEN>
<TOKEN end_char="5794" id="token-46-18" morph="none" pos="word" start_char="5790">which</TOKEN>
<TOKEN end_char="5801" id="token-46-19" morph="none" pos="word" start_char="5796">humans</TOKEN>
<TOKEN end_char="5806" id="token-46-20" morph="none" pos="word" start_char="5803">have</TOKEN>
<TOKEN end_char="5814" id="token-46-21" morph="none" pos="word" start_char="5808">already</TOKEN>
<TOKEN end_char="5821" id="token-46-22" morph="none" pos="word" start_char="5816">tested</TOKEN>
<TOKEN end_char="5830" id="token-46-23" morph="none" pos="word" start_char="5823">positive</TOKEN>
<TOKEN end_char="5831" id="token-46-24" morph="none" pos="punct" start_char="5831">.</TOKEN>
</SEG>
<SEG end_char="5956" id="segment-47" start_char="5833">
<ORIGINAL_TEXT>If those animals were positive, too, veterinarians could study them to learn more about how the virus affects cats and dogs.</ORIGINAL_TEXT>
<TOKEN end_char="5834" id="token-47-0" morph="none" pos="word" start_char="5833">If</TOKEN>
<TOKEN end_char="5840" id="token-47-1" morph="none" pos="word" start_char="5836">those</TOKEN>
<TOKEN end_char="5848" id="token-47-2" morph="none" pos="word" start_char="5842">animals</TOKEN>
<TOKEN end_char="5853" id="token-47-3" morph="none" pos="word" start_char="5850">were</TOKEN>
<TOKEN end_char="5862" id="token-47-4" morph="none" pos="word" start_char="5855">positive</TOKEN>
<TOKEN end_char="5863" id="token-47-5" morph="none" pos="punct" start_char="5863">,</TOKEN>
<TOKEN end_char="5867" id="token-47-6" morph="none" pos="word" start_char="5865">too</TOKEN>
<TOKEN end_char="5868" id="token-47-7" morph="none" pos="punct" start_char="5868">,</TOKEN>
<TOKEN end_char="5882" id="token-47-8" morph="none" pos="word" start_char="5870">veterinarians</TOKEN>
<TOKEN end_char="5888" id="token-47-9" morph="none" pos="word" start_char="5884">could</TOKEN>
<TOKEN end_char="5894" id="token-47-10" morph="none" pos="word" start_char="5890">study</TOKEN>
<TOKEN end_char="5899" id="token-47-11" morph="none" pos="word" start_char="5896">them</TOKEN>
<TOKEN end_char="5902" id="token-47-12" morph="none" pos="word" start_char="5901">to</TOKEN>
<TOKEN end_char="5908" id="token-47-13" morph="none" pos="word" start_char="5904">learn</TOKEN>
<TOKEN end_char="5913" id="token-47-14" morph="none" pos="word" start_char="5910">more</TOKEN>
<TOKEN end_char="5919" id="token-47-15" morph="none" pos="word" start_char="5915">about</TOKEN>
<TOKEN end_char="5923" id="token-47-16" morph="none" pos="word" start_char="5921">how</TOKEN>
<TOKEN end_char="5927" id="token-47-17" morph="none" pos="word" start_char="5925">the</TOKEN>
<TOKEN end_char="5933" id="token-47-18" morph="none" pos="word" start_char="5929">virus</TOKEN>
<TOKEN end_char="5941" id="token-47-19" morph="none" pos="word" start_char="5935">affects</TOKEN>
<TOKEN end_char="5946" id="token-47-20" morph="none" pos="word" start_char="5943">cats</TOKEN>
<TOKEN end_char="5950" id="token-47-21" morph="none" pos="word" start_char="5948">and</TOKEN>
<TOKEN end_char="5955" id="token-47-22" morph="none" pos="word" start_char="5952">dogs</TOKEN>
<TOKEN end_char="5956" id="token-47-23" morph="none" pos="punct" start_char="5956">.</TOKEN>
</SEG>
<SEG end_char="6076" id="segment-48" start_char="5959">
<ORIGINAL_TEXT>Epstein says that even if COVID-19 becomes a mere seasonal disease, knowing pets’ role in viral spread will be useful.</ORIGINAL_TEXT>
<TOKEN end_char="5965" id="token-48-0" morph="none" pos="word" start_char="5959">Epstein</TOKEN>
<TOKEN end_char="5970" id="token-48-1" morph="none" pos="word" start_char="5967">says</TOKEN>
<TOKEN end_char="5975" id="token-48-2" morph="none" pos="word" start_char="5972">that</TOKEN>
<TOKEN end_char="5980" id="token-48-3" morph="none" pos="word" start_char="5977">even</TOKEN>
<TOKEN end_char="5983" id="token-48-4" morph="none" pos="word" start_char="5982">if</TOKEN>
<TOKEN end_char="5992" id="token-48-5" morph="none" pos="unknown" start_char="5985">COVID-19</TOKEN>
<TOKEN end_char="6000" id="token-48-6" morph="none" pos="word" start_char="5994">becomes</TOKEN>
<TOKEN end_char="6002" id="token-48-7" morph="none" pos="word" start_char="6002">a</TOKEN>
<TOKEN end_char="6007" id="token-48-8" morph="none" pos="word" start_char="6004">mere</TOKEN>
<TOKEN end_char="6016" id="token-48-9" morph="none" pos="word" start_char="6009">seasonal</TOKEN>
<TOKEN end_char="6024" id="token-48-10" morph="none" pos="word" start_char="6018">disease</TOKEN>
<TOKEN end_char="6025" id="token-48-11" morph="none" pos="punct" start_char="6025">,</TOKEN>
<TOKEN end_char="6033" id="token-48-12" morph="none" pos="word" start_char="6027">knowing</TOKEN>
<TOKEN end_char="6038" id="token-48-13" morph="none" pos="word" start_char="6035">pets</TOKEN>
<TOKEN end_char="6039" id="token-48-14" morph="none" pos="punct" start_char="6039">’</TOKEN>
<TOKEN end_char="6044" id="token-48-15" morph="none" pos="word" start_char="6041">role</TOKEN>
<TOKEN end_char="6047" id="token-48-16" morph="none" pos="word" start_char="6046">in</TOKEN>
<TOKEN end_char="6053" id="token-48-17" morph="none" pos="word" start_char="6049">viral</TOKEN>
<TOKEN end_char="6060" id="token-48-18" morph="none" pos="word" start_char="6055">spread</TOKEN>
<TOKEN end_char="6065" id="token-48-19" morph="none" pos="word" start_char="6062">will</TOKEN>
<TOKEN end_char="6068" id="token-48-20" morph="none" pos="word" start_char="6067">be</TOKEN>
<TOKEN end_char="6075" id="token-48-21" morph="none" pos="word" start_char="6070">useful</TOKEN>
<TOKEN end_char="6076" id="token-48-22" morph="none" pos="punct" start_char="6076">.</TOKEN>
</SEG>
<SEG end_char="6270" id="segment-49" start_char="6078">
<ORIGINAL_TEXT>If animals do spread the virus, he says, "You’d want to take extra precautions if you have elderly relatives visiting, or if you’re bringing dogs to nursing homes as emotional support animals."</ORIGINAL_TEXT>
<TOKEN end_char="6079" id="token-49-0" morph="none" pos="word" start_char="6078">If</TOKEN>
<TOKEN end_char="6087" id="token-49-1" morph="none" pos="word" start_char="6081">animals</TOKEN>
<TOKEN end_char="6090" id="token-49-2" morph="none" pos="word" start_char="6089">do</TOKEN>
<TOKEN end_char="6097" id="token-49-3" morph="none" pos="word" start_char="6092">spread</TOKEN>
<TOKEN end_char="6101" id="token-49-4" morph="none" pos="word" start_char="6099">the</TOKEN>
<TOKEN end_char="6107" id="token-49-5" morph="none" pos="word" start_char="6103">virus</TOKEN>
<TOKEN end_char="6108" id="token-49-6" morph="none" pos="punct" start_char="6108">,</TOKEN>
<TOKEN end_char="6111" id="token-49-7" morph="none" pos="word" start_char="6110">he</TOKEN>
<TOKEN end_char="6116" id="token-49-8" morph="none" pos="word" start_char="6113">says</TOKEN>
<TOKEN end_char="6117" id="token-49-9" morph="none" pos="punct" start_char="6117">,</TOKEN>
<TOKEN end_char="6119" id="token-49-10" morph="none" pos="punct" start_char="6119">"</TOKEN>
<TOKEN end_char="6124" id="token-49-11" morph="none" pos="word" start_char="6120">You’d</TOKEN>
<TOKEN end_char="6129" id="token-49-12" morph="none" pos="word" start_char="6126">want</TOKEN>
<TOKEN end_char="6132" id="token-49-13" morph="none" pos="word" start_char="6131">to</TOKEN>
<TOKEN end_char="6137" id="token-49-14" morph="none" pos="word" start_char="6134">take</TOKEN>
<TOKEN end_char="6143" id="token-49-15" morph="none" pos="word" start_char="6139">extra</TOKEN>
<TOKEN end_char="6155" id="token-49-16" morph="none" pos="word" start_char="6145">precautions</TOKEN>
<TOKEN end_char="6158" id="token-49-17" morph="none" pos="word" start_char="6157">if</TOKEN>
<TOKEN end_char="6162" id="token-49-18" morph="none" pos="word" start_char="6160">you</TOKEN>
<TOKEN end_char="6167" id="token-49-19" morph="none" pos="word" start_char="6164">have</TOKEN>
<TOKEN end_char="6175" id="token-49-20" morph="none" pos="word" start_char="6169">elderly</TOKEN>
<TOKEN end_char="6185" id="token-49-21" morph="none" pos="word" start_char="6177">relatives</TOKEN>
<TOKEN end_char="6194" id="token-49-22" morph="none" pos="word" start_char="6187">visiting</TOKEN>
<TOKEN end_char="6195" id="token-49-23" morph="none" pos="punct" start_char="6195">,</TOKEN>
<TOKEN end_char="6198" id="token-49-24" morph="none" pos="word" start_char="6197">or</TOKEN>
<TOKEN end_char="6201" id="token-49-25" morph="none" pos="word" start_char="6200">if</TOKEN>
<TOKEN end_char="6208" id="token-49-26" morph="none" pos="word" start_char="6203">you’re</TOKEN>
<TOKEN end_char="6217" id="token-49-27" morph="none" pos="word" start_char="6210">bringing</TOKEN>
<TOKEN end_char="6222" id="token-49-28" morph="none" pos="word" start_char="6219">dogs</TOKEN>
<TOKEN end_char="6225" id="token-49-29" morph="none" pos="word" start_char="6224">to</TOKEN>
<TOKEN end_char="6233" id="token-49-30" morph="none" pos="word" start_char="6227">nursing</TOKEN>
<TOKEN end_char="6239" id="token-49-31" morph="none" pos="word" start_char="6235">homes</TOKEN>
<TOKEN end_char="6242" id="token-49-32" morph="none" pos="word" start_char="6241">as</TOKEN>
<TOKEN end_char="6252" id="token-49-33" morph="none" pos="word" start_char="6244">emotional</TOKEN>
<TOKEN end_char="6260" id="token-49-34" morph="none" pos="word" start_char="6254">support</TOKEN>
<TOKEN end_char="6268" id="token-49-35" morph="none" pos="word" start_char="6262">animals</TOKEN>
<TOKEN end_char="6270" id="token-49-36" morph="none" pos="punct" start_char="6269">."</TOKEN>
</SEG>
<SEG end_char="6348" id="segment-50" start_char="6273">
<ORIGINAL_TEXT>For now, Behravesh recommends treating our pets like we now treat ourselves.</ORIGINAL_TEXT>
<TOKEN end_char="6275" id="token-50-0" morph="none" pos="word" start_char="6273">For</TOKEN>
<TOKEN end_char="6279" id="token-50-1" morph="none" pos="word" start_char="6277">now</TOKEN>
<TOKEN end_char="6280" id="token-50-2" morph="none" pos="punct" start_char="6280">,</TOKEN>
<TOKEN end_char="6290" id="token-50-3" morph="none" pos="word" start_char="6282">Behravesh</TOKEN>
<TOKEN end_char="6301" id="token-50-4" morph="none" pos="word" start_char="6292">recommends</TOKEN>
<TOKEN end_char="6310" id="token-50-5" morph="none" pos="word" start_char="6303">treating</TOKEN>
<TOKEN end_char="6314" id="token-50-6" morph="none" pos="word" start_char="6312">our</TOKEN>
<TOKEN end_char="6319" id="token-50-7" morph="none" pos="word" start_char="6316">pets</TOKEN>
<TOKEN end_char="6324" id="token-50-8" morph="none" pos="word" start_char="6321">like</TOKEN>
<TOKEN end_char="6327" id="token-50-9" morph="none" pos="word" start_char="6326">we</TOKEN>
<TOKEN end_char="6331" id="token-50-10" morph="none" pos="word" start_char="6329">now</TOKEN>
<TOKEN end_char="6337" id="token-50-11" morph="none" pos="word" start_char="6333">treat</TOKEN>
<TOKEN end_char="6347" id="token-50-12" morph="none" pos="word" start_char="6339">ourselves</TOKEN>
<TOKEN end_char="6348" id="token-50-13" morph="none" pos="punct" start_char="6348">.</TOKEN>
</SEG>
<SEG end_char="6429" id="segment-51" start_char="6350">
<ORIGINAL_TEXT>"If you’re sick, restrict your access to your pet as much as you can," she says.</ORIGINAL_TEXT>
<TOKEN end_char="6350" id="token-51-0" morph="none" pos="punct" start_char="6350">"</TOKEN>
<TOKEN end_char="6352" id="token-51-1" morph="none" pos="word" start_char="6351">If</TOKEN>
<TOKEN end_char="6359" id="token-51-2" morph="none" pos="word" start_char="6354">you’re</TOKEN>
<TOKEN end_char="6364" id="token-51-3" morph="none" pos="word" start_char="6361">sick</TOKEN>
<TOKEN end_char="6365" id="token-51-4" morph="none" pos="punct" start_char="6365">,</TOKEN>
<TOKEN end_char="6374" id="token-51-5" morph="none" pos="word" start_char="6367">restrict</TOKEN>
<TOKEN end_char="6379" id="token-51-6" morph="none" pos="word" start_char="6376">your</TOKEN>
<TOKEN end_char="6386" id="token-51-7" morph="none" pos="word" start_char="6381">access</TOKEN>
<TOKEN end_char="6389" id="token-51-8" morph="none" pos="word" start_char="6388">to</TOKEN>
<TOKEN end_char="6394" id="token-51-9" morph="none" pos="word" start_char="6391">your</TOKEN>
<TOKEN end_char="6398" id="token-51-10" morph="none" pos="word" start_char="6396">pet</TOKEN>
<TOKEN end_char="6401" id="token-51-11" morph="none" pos="word" start_char="6400">as</TOKEN>
<TOKEN end_char="6406" id="token-51-12" morph="none" pos="word" start_char="6403">much</TOKEN>
<TOKEN end_char="6409" id="token-51-13" morph="none" pos="word" start_char="6408">as</TOKEN>
<TOKEN end_char="6413" id="token-51-14" morph="none" pos="word" start_char="6411">you</TOKEN>
<TOKEN end_char="6417" id="token-51-15" morph="none" pos="word" start_char="6415">can</TOKEN>
<TOKEN end_char="6419" id="token-51-16" morph="none" pos="punct" start_char="6418">,"</TOKEN>
<TOKEN end_char="6423" id="token-51-17" morph="none" pos="word" start_char="6421">she</TOKEN>
<TOKEN end_char="6428" id="token-51-18" morph="none" pos="word" start_char="6425">says</TOKEN>
<TOKEN end_char="6429" id="token-51-19" morph="none" pos="punct" start_char="6429">.</TOKEN>
</SEG>
<SEG end_char="6491" id="segment-52" start_char="6431">
<ORIGINAL_TEXT>"When you walk your dog, stay 6 feet away from other animals.</ORIGINAL_TEXT>
<TOKEN end_char="6431" id="token-52-0" morph="none" pos="punct" start_char="6431">"</TOKEN>
<TOKEN end_char="6435" id="token-52-1" morph="none" pos="word" start_char="6432">When</TOKEN>
<TOKEN end_char="6439" id="token-52-2" morph="none" pos="word" start_char="6437">you</TOKEN>
<TOKEN end_char="6444" id="token-52-3" morph="none" pos="word" start_char="6441">walk</TOKEN>
<TOKEN end_char="6449" id="token-52-4" morph="none" pos="word" start_char="6446">your</TOKEN>
<TOKEN end_char="6453" id="token-52-5" morph="none" pos="word" start_char="6451">dog</TOKEN>
<TOKEN end_char="6454" id="token-52-6" morph="none" pos="punct" start_char="6454">,</TOKEN>
<TOKEN end_char="6459" id="token-52-7" morph="none" pos="word" start_char="6456">stay</TOKEN>
<TOKEN end_char="6461" id="token-52-8" morph="none" pos="word" start_char="6461">6</TOKEN>
<TOKEN end_char="6466" id="token-52-9" morph="none" pos="word" start_char="6463">feet</TOKEN>
<TOKEN end_char="6471" id="token-52-10" morph="none" pos="word" start_char="6468">away</TOKEN>
<TOKEN end_char="6476" id="token-52-11" morph="none" pos="word" start_char="6473">from</TOKEN>
<TOKEN end_char="6482" id="token-52-12" morph="none" pos="word" start_char="6478">other</TOKEN>
<TOKEN end_char="6490" id="token-52-13" morph="none" pos="word" start_char="6484">animals</TOKEN>
<TOKEN end_char="6491" id="token-52-14" morph="none" pos="punct" start_char="6491">.</TOKEN>
</SEG>
<SEG end_char="6522" id="segment-53" start_char="6493">
<ORIGINAL_TEXT>Don’t pet other people’s dogs.</ORIGINAL_TEXT>
<TOKEN end_char="6497" id="token-53-0" morph="none" pos="word" start_char="6493">Don’t</TOKEN>
<TOKEN end_char="6501" id="token-53-1" morph="none" pos="word" start_char="6499">pet</TOKEN>
<TOKEN end_char="6507" id="token-53-2" morph="none" pos="word" start_char="6503">other</TOKEN>
<TOKEN end_char="6516" id="token-53-3" morph="none" pos="word" start_char="6509">people’s</TOKEN>
<TOKEN end_char="6521" id="token-53-4" morph="none" pos="word" start_char="6518">dogs</TOKEN>
<TOKEN end_char="6522" id="token-53-5" morph="none" pos="punct" start_char="6522">.</TOKEN>
</SEG>
<SEG end_char="6557" id="segment-54" start_char="6524">
<ORIGINAL_TEXT>Always wash your hands," she says.</ORIGINAL_TEXT>
<TOKEN end_char="6529" id="token-54-0" morph="none" pos="word" start_char="6524">Always</TOKEN>
<TOKEN end_char="6534" id="token-54-1" morph="none" pos="word" start_char="6531">wash</TOKEN>
<TOKEN end_char="6539" id="token-54-2" morph="none" pos="word" start_char="6536">your</TOKEN>
<TOKEN end_char="6545" id="token-54-3" morph="none" pos="word" start_char="6541">hands</TOKEN>
<TOKEN end_char="6547" id="token-54-4" morph="none" pos="punct" start_char="6546">,"</TOKEN>
<TOKEN end_char="6551" id="token-54-5" morph="none" pos="word" start_char="6549">she</TOKEN>
<TOKEN end_char="6556" id="token-54-6" morph="none" pos="word" start_char="6553">says</TOKEN>
<TOKEN end_char="6557" id="token-54-7" morph="none" pos="punct" start_char="6557">.</TOKEN>
</SEG>
<SEG end_char="6606" id="segment-55" start_char="6559">
<ORIGINAL_TEXT>"It’s really important that people don’t panic."</ORIGINAL_TEXT>
<TOKEN end_char="6559" id="token-55-0" morph="none" pos="punct" start_char="6559">"</TOKEN>
<TOKEN end_char="6563" id="token-55-1" morph="none" pos="word" start_char="6560">It’s</TOKEN>
<TOKEN end_char="6570" id="token-55-2" morph="none" pos="word" start_char="6565">really</TOKEN>
<TOKEN end_char="6580" id="token-55-3" morph="none" pos="word" start_char="6572">important</TOKEN>
<TOKEN end_char="6585" id="token-55-4" morph="none" pos="word" start_char="6582">that</TOKEN>
<TOKEN end_char="6592" id="token-55-5" morph="none" pos="word" start_char="6587">people</TOKEN>
<TOKEN end_char="6598" id="token-55-6" morph="none" pos="word" start_char="6594">don’t</TOKEN>
<TOKEN end_char="6604" id="token-55-7" morph="none" pos="word" start_char="6600">panic</TOKEN>
<TOKEN end_char="6606" id="token-55-8" morph="none" pos="punct" start_char="6605">."</TOKEN>
</SEG>
<SEG end_char="6623" id="segment-56" start_char="6609">
<ORIGINAL_TEXT>Epstein agrees.</ORIGINAL_TEXT>
<TOKEN end_char="6615" id="token-56-0" morph="none" pos="word" start_char="6609">Epstein</TOKEN>
<TOKEN end_char="6622" id="token-56-1" morph="none" pos="word" start_char="6617">agrees</TOKEN>
<TOKEN end_char="6623" id="token-56-2" morph="none" pos="punct" start_char="6623">.</TOKEN>
</SEG>
<SEG end_char="6782" id="segment-57" start_char="6625">
<ORIGINAL_TEXT>"I don’t want to create unnecessary concern about pets," he says, arguing that our emotional connection with cats and dogs may be more critical now than ever.</ORIGINAL_TEXT>
<TOKEN end_char="6625" id="token-57-0" morph="none" pos="punct" start_char="6625">"</TOKEN>
<TOKEN end_char="6626" id="token-57-1" morph="none" pos="word" start_char="6626">I</TOKEN>
<TOKEN end_char="6632" id="token-57-2" morph="none" pos="word" start_char="6628">don’t</TOKEN>
<TOKEN end_char="6637" id="token-57-3" morph="none" pos="word" start_char="6634">want</TOKEN>
<TOKEN end_char="6640" id="token-57-4" morph="none" pos="word" start_char="6639">to</TOKEN>
<TOKEN end_char="6647" id="token-57-5" morph="none" pos="word" start_char="6642">create</TOKEN>
<TOKEN end_char="6659" id="token-57-6" morph="none" pos="word" start_char="6649">unnecessary</TOKEN>
<TOKEN end_char="6667" id="token-57-7" morph="none" pos="word" start_char="6661">concern</TOKEN>
<TOKEN end_char="6673" id="token-57-8" morph="none" pos="word" start_char="6669">about</TOKEN>
<TOKEN end_char="6678" id="token-57-9" morph="none" pos="word" start_char="6675">pets</TOKEN>
<TOKEN end_char="6680" id="token-57-10" morph="none" pos="punct" start_char="6679">,"</TOKEN>
<TOKEN end_char="6683" id="token-57-11" morph="none" pos="word" start_char="6682">he</TOKEN>
<TOKEN end_char="6688" id="token-57-12" morph="none" pos="word" start_char="6685">says</TOKEN>
<TOKEN end_char="6689" id="token-57-13" morph="none" pos="punct" start_char="6689">,</TOKEN>
<TOKEN end_char="6697" id="token-57-14" morph="none" pos="word" start_char="6691">arguing</TOKEN>
<TOKEN end_char="6702" id="token-57-15" morph="none" pos="word" start_char="6699">that</TOKEN>
<TOKEN end_char="6706" id="token-57-16" morph="none" pos="word" start_char="6704">our</TOKEN>
<TOKEN end_char="6716" id="token-57-17" morph="none" pos="word" start_char="6708">emotional</TOKEN>
<TOKEN end_char="6727" id="token-57-18" morph="none" pos="word" start_char="6718">connection</TOKEN>
<TOKEN end_char="6732" id="token-57-19" morph="none" pos="word" start_char="6729">with</TOKEN>
<TOKEN end_char="6737" id="token-57-20" morph="none" pos="word" start_char="6734">cats</TOKEN>
<TOKEN end_char="6741" id="token-57-21" morph="none" pos="word" start_char="6739">and</TOKEN>
<TOKEN end_char="6746" id="token-57-22" morph="none" pos="word" start_char="6743">dogs</TOKEN>
<TOKEN end_char="6750" id="token-57-23" morph="none" pos="word" start_char="6748">may</TOKEN>
<TOKEN end_char="6753" id="token-57-24" morph="none" pos="word" start_char="6752">be</TOKEN>
<TOKEN end_char="6758" id="token-57-25" morph="none" pos="word" start_char="6755">more</TOKEN>
<TOKEN end_char="6767" id="token-57-26" morph="none" pos="word" start_char="6760">critical</TOKEN>
<TOKEN end_char="6771" id="token-57-27" morph="none" pos="word" start_char="6769">now</TOKEN>
<TOKEN end_char="6776" id="token-57-28" morph="none" pos="word" start_char="6773">than</TOKEN>
<TOKEN end_char="6781" id="token-57-29" morph="none" pos="word" start_char="6778">ever</TOKEN>
<TOKEN end_char="6782" id="token-57-30" morph="none" pos="punct" start_char="6782">.</TOKEN>
</SEG>
<SEG end_char="6897" id="segment-58" start_char="6784">
<ORIGINAL_TEXT>"In these difficult, isolating times," he says, "there is an importance to having companion animals in your life."</ORIGINAL_TEXT>
<TOKEN end_char="6784" id="token-58-0" morph="none" pos="punct" start_char="6784">"</TOKEN>
<TOKEN end_char="6786" id="token-58-1" morph="none" pos="word" start_char="6785">In</TOKEN>
<TOKEN end_char="6792" id="token-58-2" morph="none" pos="word" start_char="6788">these</TOKEN>
<TOKEN end_char="6802" id="token-58-3" morph="none" pos="word" start_char="6794">difficult</TOKEN>
<TOKEN end_char="6803" id="token-58-4" morph="none" pos="punct" start_char="6803">,</TOKEN>
<TOKEN end_char="6813" id="token-58-5" morph="none" pos="word" start_char="6805">isolating</TOKEN>
<TOKEN end_char="6819" id="token-58-6" morph="none" pos="word" start_char="6815">times</TOKEN>
<TOKEN end_char="6821" id="token-58-7" morph="none" pos="punct" start_char="6820">,"</TOKEN>
<TOKEN end_char="6824" id="token-58-8" morph="none" pos="word" start_char="6823">he</TOKEN>
<TOKEN end_char="6829" id="token-58-9" morph="none" pos="word" start_char="6826">says</TOKEN>
<TOKEN end_char="6830" id="token-58-10" morph="none" pos="punct" start_char="6830">,</TOKEN>
<TOKEN end_char="6832" id="token-58-11" morph="none" pos="punct" start_char="6832">"</TOKEN>
<TOKEN end_char="6837" id="token-58-12" morph="none" pos="word" start_char="6833">there</TOKEN>
<TOKEN end_char="6840" id="token-58-13" morph="none" pos="word" start_char="6839">is</TOKEN>
<TOKEN end_char="6843" id="token-58-14" morph="none" pos="word" start_char="6842">an</TOKEN>
<TOKEN end_char="6854" id="token-58-15" morph="none" pos="word" start_char="6845">importance</TOKEN>
<TOKEN end_char="6857" id="token-58-16" morph="none" pos="word" start_char="6856">to</TOKEN>
<TOKEN end_char="6864" id="token-58-17" morph="none" pos="word" start_char="6859">having</TOKEN>
<TOKEN end_char="6874" id="token-58-18" morph="none" pos="word" start_char="6866">companion</TOKEN>
<TOKEN end_char="6882" id="token-58-19" morph="none" pos="word" start_char="6876">animals</TOKEN>
<TOKEN end_char="6885" id="token-58-20" morph="none" pos="word" start_char="6884">in</TOKEN>
<TOKEN end_char="6890" id="token-58-21" morph="none" pos="word" start_char="6887">your</TOKEN>
<TOKEN end_char="6895" id="token-58-22" morph="none" pos="word" start_char="6892">life</TOKEN>
<TOKEN end_char="6897" id="token-58-23" morph="none" pos="punct" start_char="6896">."</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
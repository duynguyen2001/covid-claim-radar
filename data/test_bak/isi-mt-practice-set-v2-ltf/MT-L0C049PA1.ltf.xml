<LCTL_TEXT lang="ukr">
<DOC grammar="none" id="L0C049PA1" lang="ukr" raw_text_char_length="10311" raw_text_md5="ff8d7aaebfa42e780531c0371970c481" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="44" id="segment-0" start_char="1">
<ORIGINAL_TEXT>New coronavirus threat galvanizes scientists</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">New</TOKEN>
<TOKEN end_char="15" id="token-0-1" morph="none" pos="word" start_char="5">coronavirus</TOKEN>
<TOKEN end_char="22" id="token-0-2" morph="none" pos="word" start_char="17">threat</TOKEN>
<TOKEN end_char="33" id="token-0-3" morph="none" pos="word" start_char="24">galvanizes</TOKEN>
<TOKEN end_char="44" id="token-0-4" morph="none" pos="word" start_char="35">scientists</TOKEN>
</SEG>
<SEG end_char="219" id="segment-1" start_char="48">
<ORIGINAL_TEXT>Barely 1 month after Chinese health authorities reported the first cases of a mysterious new pneumonia in the city of Wuhan, the world may be on the cusp of a new pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="53" id="token-1-0" morph="none" pos="word" start_char="48">Barely</TOKEN>
<TOKEN end_char="55" id="token-1-1" morph="none" pos="word" start_char="55">1</TOKEN>
<TOKEN end_char="61" id="token-1-2" morph="none" pos="word" start_char="57">month</TOKEN>
<TOKEN end_char="67" id="token-1-3" morph="none" pos="word" start_char="63">after</TOKEN>
<TOKEN end_char="75" id="token-1-4" morph="none" pos="word" start_char="69">Chinese</TOKEN>
<TOKEN end_char="82" id="token-1-5" morph="none" pos="word" start_char="77">health</TOKEN>
<TOKEN end_char="94" id="token-1-6" morph="none" pos="word" start_char="84">authorities</TOKEN>
<TOKEN end_char="103" id="token-1-7" morph="none" pos="word" start_char="96">reported</TOKEN>
<TOKEN end_char="107" id="token-1-8" morph="none" pos="word" start_char="105">the</TOKEN>
<TOKEN end_char="113" id="token-1-9" morph="none" pos="word" start_char="109">first</TOKEN>
<TOKEN end_char="119" id="token-1-10" morph="none" pos="word" start_char="115">cases</TOKEN>
<TOKEN end_char="122" id="token-1-11" morph="none" pos="word" start_char="121">of</TOKEN>
<TOKEN end_char="124" id="token-1-12" morph="none" pos="word" start_char="124">a</TOKEN>
<TOKEN end_char="135" id="token-1-13" morph="none" pos="word" start_char="126">mysterious</TOKEN>
<TOKEN end_char="139" id="token-1-14" morph="none" pos="word" start_char="137">new</TOKEN>
<TOKEN end_char="149" id="token-1-15" morph="none" pos="word" start_char="141">pneumonia</TOKEN>
<TOKEN end_char="152" id="token-1-16" morph="none" pos="word" start_char="151">in</TOKEN>
<TOKEN end_char="156" id="token-1-17" morph="none" pos="word" start_char="154">the</TOKEN>
<TOKEN end_char="161" id="token-1-18" morph="none" pos="word" start_char="158">city</TOKEN>
<TOKEN end_char="164" id="token-1-19" morph="none" pos="word" start_char="163">of</TOKEN>
<TOKEN end_char="170" id="token-1-20" morph="none" pos="word" start_char="166">Wuhan</TOKEN>
<TOKEN end_char="171" id="token-1-21" morph="none" pos="punct" start_char="171">,</TOKEN>
<TOKEN end_char="175" id="token-1-22" morph="none" pos="word" start_char="173">the</TOKEN>
<TOKEN end_char="181" id="token-1-23" morph="none" pos="word" start_char="177">world</TOKEN>
<TOKEN end_char="185" id="token-1-24" morph="none" pos="word" start_char="183">may</TOKEN>
<TOKEN end_char="188" id="token-1-25" morph="none" pos="word" start_char="187">be</TOKEN>
<TOKEN end_char="191" id="token-1-26" morph="none" pos="word" start_char="190">on</TOKEN>
<TOKEN end_char="195" id="token-1-27" morph="none" pos="word" start_char="193">the</TOKEN>
<TOKEN end_char="200" id="token-1-28" morph="none" pos="word" start_char="197">cusp</TOKEN>
<TOKEN end_char="203" id="token-1-29" morph="none" pos="word" start_char="202">of</TOKEN>
<TOKEN end_char="205" id="token-1-30" morph="none" pos="word" start_char="205">a</TOKEN>
<TOKEN end_char="209" id="token-1-31" morph="none" pos="word" start_char="207">new</TOKEN>
<TOKEN end_char="218" id="token-1-32" morph="none" pos="word" start_char="211">pandemic</TOKEN>
<TOKEN end_char="219" id="token-1-33" morph="none" pos="punct" start_char="219">.</TOKEN>
</SEG>
<SEG end_char="222" id="segment-2" start_char="221">
<ORIGINAL_TEXT>As</ORIGINAL_TEXT>
<TOKEN end_char="222" id="token-2-0" morph="none" pos="word" start_char="221">As</TOKEN>
</SEG>
<SEG end_char="231" id="segment-3" start_char="225">
<ORIGINAL_TEXT>Science</ORIGINAL_TEXT>
<TOKEN end_char="231" id="token-3-0" morph="none" pos="word" start_char="225">Science</TOKEN>
<TRANSLATED_TEXT>Wetenschap</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="439" id="segment-4" start_char="234">
<ORIGINAL_TEXT>went to press, the number of confirmed cases of the novel coronavirus, dubbed 2019-nCoV, had shot up to more than 4500, most of them in mainland China but more than 80 in 17 other countries and territories.</ORIGINAL_TEXT>
<TOKEN end_char="237" id="token-4-0" morph="none" pos="word" start_char="234">went</TOKEN>
<TOKEN end_char="240" id="token-4-1" morph="none" pos="word" start_char="239">to</TOKEN>
<TOKEN end_char="246" id="token-4-2" morph="none" pos="word" start_char="242">press</TOKEN>
<TOKEN end_char="247" id="token-4-3" morph="none" pos="punct" start_char="247">,</TOKEN>
<TOKEN end_char="251" id="token-4-4" morph="none" pos="word" start_char="249">the</TOKEN>
<TOKEN end_char="258" id="token-4-5" morph="none" pos="word" start_char="253">number</TOKEN>
<TOKEN end_char="261" id="token-4-6" morph="none" pos="word" start_char="260">of</TOKEN>
<TOKEN end_char="271" id="token-4-7" morph="none" pos="word" start_char="263">confirmed</TOKEN>
<TOKEN end_char="277" id="token-4-8" morph="none" pos="word" start_char="273">cases</TOKEN>
<TOKEN end_char="280" id="token-4-9" morph="none" pos="word" start_char="279">of</TOKEN>
<TOKEN end_char="284" id="token-4-10" morph="none" pos="word" start_char="282">the</TOKEN>
<TOKEN end_char="290" id="token-4-11" morph="none" pos="word" start_char="286">novel</TOKEN>
<TOKEN end_char="302" id="token-4-12" morph="none" pos="word" start_char="292">coronavirus</TOKEN>
<TOKEN end_char="303" id="token-4-13" morph="none" pos="punct" start_char="303">,</TOKEN>
<TOKEN end_char="310" id="token-4-14" morph="none" pos="word" start_char="305">dubbed</TOKEN>
<TOKEN end_char="320" id="token-4-15" morph="none" pos="unknown" start_char="312">2019-nCoV</TOKEN>
<TOKEN end_char="321" id="token-4-16" morph="none" pos="punct" start_char="321">,</TOKEN>
<TOKEN end_char="325" id="token-4-17" morph="none" pos="word" start_char="323">had</TOKEN>
<TOKEN end_char="330" id="token-4-18" morph="none" pos="word" start_char="327">shot</TOKEN>
<TOKEN end_char="333" id="token-4-19" morph="none" pos="word" start_char="332">up</TOKEN>
<TOKEN end_char="336" id="token-4-20" morph="none" pos="word" start_char="335">to</TOKEN>
<TOKEN end_char="341" id="token-4-21" morph="none" pos="word" start_char="338">more</TOKEN>
<TOKEN end_char="346" id="token-4-22" morph="none" pos="word" start_char="343">than</TOKEN>
<TOKEN end_char="351" id="token-4-23" morph="none" pos="word" start_char="348">4500</TOKEN>
<TOKEN end_char="352" id="token-4-24" morph="none" pos="punct" start_char="352">,</TOKEN>
<TOKEN end_char="357" id="token-4-25" morph="none" pos="word" start_char="354">most</TOKEN>
<TOKEN end_char="360" id="token-4-26" morph="none" pos="word" start_char="359">of</TOKEN>
<TOKEN end_char="365" id="token-4-27" morph="none" pos="word" start_char="362">them</TOKEN>
<TOKEN end_char="368" id="token-4-28" morph="none" pos="word" start_char="367">in</TOKEN>
<TOKEN end_char="377" id="token-4-29" morph="none" pos="word" start_char="370">mainland</TOKEN>
<TOKEN end_char="383" id="token-4-30" morph="none" pos="word" start_char="379">China</TOKEN>
<TOKEN end_char="387" id="token-4-31" morph="none" pos="word" start_char="385">but</TOKEN>
<TOKEN end_char="392" id="token-4-32" morph="none" pos="word" start_char="389">more</TOKEN>
<TOKEN end_char="397" id="token-4-33" morph="none" pos="word" start_char="394">than</TOKEN>
<TOKEN end_char="400" id="token-4-34" morph="none" pos="word" start_char="399">80</TOKEN>
<TOKEN end_char="403" id="token-4-35" morph="none" pos="word" start_char="402">in</TOKEN>
<TOKEN end_char="406" id="token-4-36" morph="none" pos="word" start_char="405">17</TOKEN>
<TOKEN end_char="412" id="token-4-37" morph="none" pos="word" start_char="408">other</TOKEN>
<TOKEN end_char="422" id="token-4-38" morph="none" pos="word" start_char="414">countries</TOKEN>
<TOKEN end_char="426" id="token-4-39" morph="none" pos="word" start_char="424">and</TOKEN>
<TOKEN end_char="438" id="token-4-40" morph="none" pos="word" start_char="428">territories</TOKEN>
<TOKEN end_char="439" id="token-4-41" morph="none" pos="punct" start_char="439">.</TOKEN>
</SEG>
<SEG end_char="569" id="segment-5" start_char="441">
<ORIGINAL_TEXT>China has quarantined 35 million people in Wuhan and several other cities in a desperate attempt to slow the spread of the virus.</ORIGINAL_TEXT>
<TOKEN end_char="445" id="token-5-0" morph="none" pos="word" start_char="441">China</TOKEN>
<TOKEN end_char="449" id="token-5-1" morph="none" pos="word" start_char="447">has</TOKEN>
<TOKEN end_char="461" id="token-5-2" morph="none" pos="word" start_char="451">quarantined</TOKEN>
<TOKEN end_char="464" id="token-5-3" morph="none" pos="word" start_char="463">35</TOKEN>
<TOKEN end_char="472" id="token-5-4" morph="none" pos="word" start_char="466">million</TOKEN>
<TOKEN end_char="479" id="token-5-5" morph="none" pos="word" start_char="474">people</TOKEN>
<TOKEN end_char="482" id="token-5-6" morph="none" pos="word" start_char="481">in</TOKEN>
<TOKEN end_char="488" id="token-5-7" morph="none" pos="word" start_char="484">Wuhan</TOKEN>
<TOKEN end_char="492" id="token-5-8" morph="none" pos="word" start_char="490">and</TOKEN>
<TOKEN end_char="500" id="token-5-9" morph="none" pos="word" start_char="494">several</TOKEN>
<TOKEN end_char="506" id="token-5-10" morph="none" pos="word" start_char="502">other</TOKEN>
<TOKEN end_char="513" id="token-5-11" morph="none" pos="word" start_char="508">cities</TOKEN>
<TOKEN end_char="516" id="token-5-12" morph="none" pos="word" start_char="515">in</TOKEN>
<TOKEN end_char="518" id="token-5-13" morph="none" pos="word" start_char="518">a</TOKEN>
<TOKEN end_char="528" id="token-5-14" morph="none" pos="word" start_char="520">desperate</TOKEN>
<TOKEN end_char="536" id="token-5-15" morph="none" pos="word" start_char="530">attempt</TOKEN>
<TOKEN end_char="539" id="token-5-16" morph="none" pos="word" start_char="538">to</TOKEN>
<TOKEN end_char="544" id="token-5-17" morph="none" pos="word" start_char="541">slow</TOKEN>
<TOKEN end_char="548" id="token-5-18" morph="none" pos="word" start_char="546">the</TOKEN>
<TOKEN end_char="555" id="token-5-19" morph="none" pos="word" start_char="550">spread</TOKEN>
<TOKEN end_char="558" id="token-5-20" morph="none" pos="word" start_char="557">of</TOKEN>
<TOKEN end_char="562" id="token-5-21" morph="none" pos="word" start_char="560">the</TOKEN>
<TOKEN end_char="568" id="token-5-22" morph="none" pos="word" start_char="564">virus</TOKEN>
<TOKEN end_char="569" id="token-5-23" morph="none" pos="punct" start_char="569">.</TOKEN>
</SEG>
<SEG end_char="679" id="segment-6" start_char="571">
<ORIGINAL_TEXT>But as the case numbers keep soaring, the realization has set in that it may be too late to have much impact.</ORIGINAL_TEXT>
<TOKEN end_char="573" id="token-6-0" morph="none" pos="word" start_char="571">But</TOKEN>
<TOKEN end_char="576" id="token-6-1" morph="none" pos="word" start_char="575">as</TOKEN>
<TOKEN end_char="580" id="token-6-2" morph="none" pos="word" start_char="578">the</TOKEN>
<TOKEN end_char="585" id="token-6-3" morph="none" pos="word" start_char="582">case</TOKEN>
<TOKEN end_char="593" id="token-6-4" morph="none" pos="word" start_char="587">numbers</TOKEN>
<TOKEN end_char="598" id="token-6-5" morph="none" pos="word" start_char="595">keep</TOKEN>
<TOKEN end_char="606" id="token-6-6" morph="none" pos="word" start_char="600">soaring</TOKEN>
<TOKEN end_char="607" id="token-6-7" morph="none" pos="punct" start_char="607">,</TOKEN>
<TOKEN end_char="611" id="token-6-8" morph="none" pos="word" start_char="609">the</TOKEN>
<TOKEN end_char="623" id="token-6-9" morph="none" pos="word" start_char="613">realization</TOKEN>
<TOKEN end_char="627" id="token-6-10" morph="none" pos="word" start_char="625">has</TOKEN>
<TOKEN end_char="631" id="token-6-11" morph="none" pos="word" start_char="629">set</TOKEN>
<TOKEN end_char="634" id="token-6-12" morph="none" pos="word" start_char="633">in</TOKEN>
<TOKEN end_char="639" id="token-6-13" morph="none" pos="word" start_char="636">that</TOKEN>
<TOKEN end_char="642" id="token-6-14" morph="none" pos="word" start_char="641">it</TOKEN>
<TOKEN end_char="646" id="token-6-15" morph="none" pos="word" start_char="644">may</TOKEN>
<TOKEN end_char="649" id="token-6-16" morph="none" pos="word" start_char="648">be</TOKEN>
<TOKEN end_char="653" id="token-6-17" morph="none" pos="word" start_char="651">too</TOKEN>
<TOKEN end_char="658" id="token-6-18" morph="none" pos="word" start_char="655">late</TOKEN>
<TOKEN end_char="661" id="token-6-19" morph="none" pos="word" start_char="660">to</TOKEN>
<TOKEN end_char="666" id="token-6-20" morph="none" pos="word" start_char="663">have</TOKEN>
<TOKEN end_char="671" id="token-6-21" morph="none" pos="word" start_char="668">much</TOKEN>
<TOKEN end_char="678" id="token-6-22" morph="none" pos="word" start_char="673">impact</TOKEN>
<TOKEN end_char="679" id="token-6-23" morph="none" pos="punct" start_char="679">.</TOKEN>
</SEG>
<SEG end_char="757" id="segment-7" start_char="682">
<ORIGINAL_TEXT>Even seasoned epidemiologists are astonished at the virus's dizzying spread.</ORIGINAL_TEXT>
<TOKEN end_char="685" id="token-7-0" morph="none" pos="word" start_char="682">Even</TOKEN>
<TOKEN end_char="694" id="token-7-1" morph="none" pos="word" start_char="687">seasoned</TOKEN>
<TOKEN end_char="710" id="token-7-2" morph="none" pos="word" start_char="696">epidemiologists</TOKEN>
<TOKEN end_char="714" id="token-7-3" morph="none" pos="word" start_char="712">are</TOKEN>
<TOKEN end_char="725" id="token-7-4" morph="none" pos="word" start_char="716">astonished</TOKEN>
<TOKEN end_char="728" id="token-7-5" morph="none" pos="word" start_char="727">at</TOKEN>
<TOKEN end_char="732" id="token-7-6" morph="none" pos="word" start_char="730">the</TOKEN>
<TOKEN end_char="740" id="token-7-7" morph="none" pos="word" start_char="734">virus's</TOKEN>
<TOKEN end_char="749" id="token-7-8" morph="none" pos="word" start_char="742">dizzying</TOKEN>
<TOKEN end_char="756" id="token-7-9" morph="none" pos="word" start_char="751">spread</TOKEN>
<TOKEN end_char="757" id="token-7-10" morph="none" pos="punct" start_char="757">.</TOKEN>
</SEG>
<SEG end_char="885" id="segment-8" start_char="759">
<ORIGINAL_TEXT>Early estimates of the number of infected people—thought to far exceed the number of confirmed cases—became obsolete overnight.</ORIGINAL_TEXT>
<TOKEN end_char="763" id="token-8-0" morph="none" pos="word" start_char="759">Early</TOKEN>
<TOKEN end_char="773" id="token-8-1" morph="none" pos="word" start_char="765">estimates</TOKEN>
<TOKEN end_char="776" id="token-8-2" morph="none" pos="word" start_char="775">of</TOKEN>
<TOKEN end_char="780" id="token-8-3" morph="none" pos="word" start_char="778">the</TOKEN>
<TOKEN end_char="787" id="token-8-4" morph="none" pos="word" start_char="782">number</TOKEN>
<TOKEN end_char="790" id="token-8-5" morph="none" pos="word" start_char="789">of</TOKEN>
<TOKEN end_char="799" id="token-8-6" morph="none" pos="word" start_char="792">infected</TOKEN>
<TOKEN end_char="814" id="token-8-7" morph="none" pos="unknown" start_char="801">people—thought</TOKEN>
<TOKEN end_char="817" id="token-8-8" morph="none" pos="word" start_char="816">to</TOKEN>
<TOKEN end_char="821" id="token-8-9" morph="none" pos="word" start_char="819">far</TOKEN>
<TOKEN end_char="828" id="token-8-10" morph="none" pos="word" start_char="823">exceed</TOKEN>
<TOKEN end_char="832" id="token-8-11" morph="none" pos="word" start_char="830">the</TOKEN>
<TOKEN end_char="839" id="token-8-12" morph="none" pos="word" start_char="834">number</TOKEN>
<TOKEN end_char="842" id="token-8-13" morph="none" pos="word" start_char="841">of</TOKEN>
<TOKEN end_char="852" id="token-8-14" morph="none" pos="word" start_char="844">confirmed</TOKEN>
<TOKEN end_char="865" id="token-8-15" morph="none" pos="unknown" start_char="854">cases—became</TOKEN>
<TOKEN end_char="874" id="token-8-16" morph="none" pos="word" start_char="867">obsolete</TOKEN>
<TOKEN end_char="884" id="token-8-17" morph="none" pos="word" start_char="876">overnight</TOKEN>
<TOKEN end_char="885" id="token-8-18" morph="none" pos="punct" start_char="885">.</TOKEN>
</SEG>
<SEG end_char="1084" id="segment-9" start_char="887">
<ORIGINAL_TEXT>"Our original results are NO LONGER VALID," University of Hong Kong epidemiologist Gabriel Leung tweeted on 22 January, 1 day after his group had posted its first mathematical model of the epidemic.</ORIGINAL_TEXT>
<TOKEN end_char="887" id="token-9-0" morph="none" pos="punct" start_char="887">"</TOKEN>
<TOKEN end_char="890" id="token-9-1" morph="none" pos="word" start_char="888">Our</TOKEN>
<TOKEN end_char="899" id="token-9-2" morph="none" pos="word" start_char="892">original</TOKEN>
<TOKEN end_char="907" id="token-9-3" morph="none" pos="word" start_char="901">results</TOKEN>
<TOKEN end_char="911" id="token-9-4" morph="none" pos="word" start_char="909">are</TOKEN>
<TOKEN end_char="914" id="token-9-5" morph="none" pos="word" start_char="913">NO</TOKEN>
<TOKEN end_char="921" id="token-9-6" morph="none" pos="word" start_char="916">LONGER</TOKEN>
<TOKEN end_char="927" id="token-9-7" morph="none" pos="word" start_char="923">VALID</TOKEN>
<TOKEN end_char="929" id="token-9-8" morph="none" pos="punct" start_char="928">,"</TOKEN>
<TOKEN end_char="940" id="token-9-9" morph="none" pos="word" start_char="931">University</TOKEN>
<TOKEN end_char="943" id="token-9-10" morph="none" pos="word" start_char="942">of</TOKEN>
<TOKEN end_char="948" id="token-9-11" morph="none" pos="word" start_char="945">Hong</TOKEN>
<TOKEN end_char="953" id="token-9-12" morph="none" pos="word" start_char="950">Kong</TOKEN>
<TOKEN end_char="968" id="token-9-13" morph="none" pos="word" start_char="955">epidemiologist</TOKEN>
<TOKEN end_char="976" id="token-9-14" morph="none" pos="word" start_char="970">Gabriel</TOKEN>
<TOKEN end_char="982" id="token-9-15" morph="none" pos="word" start_char="978">Leung</TOKEN>
<TOKEN end_char="990" id="token-9-16" morph="none" pos="word" start_char="984">tweeted</TOKEN>
<TOKEN end_char="993" id="token-9-17" morph="none" pos="word" start_char="992">on</TOKEN>
<TOKEN end_char="996" id="token-9-18" morph="none" pos="word" start_char="995">22</TOKEN>
<TOKEN end_char="1004" id="token-9-19" morph="none" pos="word" start_char="998">January</TOKEN>
<TOKEN end_char="1005" id="token-9-20" morph="none" pos="punct" start_char="1005">,</TOKEN>
<TOKEN end_char="1007" id="token-9-21" morph="none" pos="word" start_char="1007">1</TOKEN>
<TOKEN end_char="1011" id="token-9-22" morph="none" pos="word" start_char="1009">day</TOKEN>
<TOKEN end_char="1017" id="token-9-23" morph="none" pos="word" start_char="1013">after</TOKEN>
<TOKEN end_char="1021" id="token-9-24" morph="none" pos="word" start_char="1019">his</TOKEN>
<TOKEN end_char="1027" id="token-9-25" morph="none" pos="word" start_char="1023">group</TOKEN>
<TOKEN end_char="1031" id="token-9-26" morph="none" pos="word" start_char="1029">had</TOKEN>
<TOKEN end_char="1038" id="token-9-27" morph="none" pos="word" start_char="1033">posted</TOKEN>
<TOKEN end_char="1042" id="token-9-28" morph="none" pos="word" start_char="1040">its</TOKEN>
<TOKEN end_char="1048" id="token-9-29" morph="none" pos="word" start_char="1044">first</TOKEN>
<TOKEN end_char="1061" id="token-9-30" morph="none" pos="word" start_char="1050">mathematical</TOKEN>
<TOKEN end_char="1067" id="token-9-31" morph="none" pos="word" start_char="1063">model</TOKEN>
<TOKEN end_char="1070" id="token-9-32" morph="none" pos="word" start_char="1069">of</TOKEN>
<TOKEN end_char="1074" id="token-9-33" morph="none" pos="word" start_char="1072">the</TOKEN>
<TOKEN end_char="1083" id="token-9-34" morph="none" pos="word" start_char="1076">epidemic</TOKEN>
<TOKEN end_char="1084" id="token-9-35" morph="none" pos="punct" start_char="1084">.</TOKEN>
</SEG>
<SEG end_char="1207" id="segment-10" start_char="1086">
<ORIGINAL_TEXT>Leung is now estimating that Wuhan alone had 43,590 infections by 25 January—and that the number is doubling every 6 days.</ORIGINAL_TEXT>
<TOKEN end_char="1090" id="token-10-0" morph="none" pos="word" start_char="1086">Leung</TOKEN>
<TOKEN end_char="1093" id="token-10-1" morph="none" pos="word" start_char="1092">is</TOKEN>
<TOKEN end_char="1097" id="token-10-2" morph="none" pos="word" start_char="1095">now</TOKEN>
<TOKEN end_char="1108" id="token-10-3" morph="none" pos="word" start_char="1099">estimating</TOKEN>
<TOKEN end_char="1113" id="token-10-4" morph="none" pos="word" start_char="1110">that</TOKEN>
<TOKEN end_char="1119" id="token-10-5" morph="none" pos="word" start_char="1115">Wuhan</TOKEN>
<TOKEN end_char="1125" id="token-10-6" morph="none" pos="word" start_char="1121">alone</TOKEN>
<TOKEN end_char="1129" id="token-10-7" morph="none" pos="word" start_char="1127">had</TOKEN>
<TOKEN end_char="1136" id="token-10-8" morph="none" pos="unknown" start_char="1131">43,590</TOKEN>
<TOKEN end_char="1147" id="token-10-9" morph="none" pos="word" start_char="1138">infections</TOKEN>
<TOKEN end_char="1150" id="token-10-10" morph="none" pos="word" start_char="1149">by</TOKEN>
<TOKEN end_char="1153" id="token-10-11" morph="none" pos="word" start_char="1152">25</TOKEN>
<TOKEN end_char="1165" id="token-10-12" morph="none" pos="unknown" start_char="1155">January—and</TOKEN>
<TOKEN end_char="1170" id="token-10-13" morph="none" pos="word" start_char="1167">that</TOKEN>
<TOKEN end_char="1174" id="token-10-14" morph="none" pos="word" start_char="1172">the</TOKEN>
<TOKEN end_char="1181" id="token-10-15" morph="none" pos="word" start_char="1176">number</TOKEN>
<TOKEN end_char="1184" id="token-10-16" morph="none" pos="word" start_char="1183">is</TOKEN>
<TOKEN end_char="1193" id="token-10-17" morph="none" pos="word" start_char="1186">doubling</TOKEN>
<TOKEN end_char="1199" id="token-10-18" morph="none" pos="word" start_char="1195">every</TOKEN>
<TOKEN end_char="1201" id="token-10-19" morph="none" pos="word" start_char="1201">6</TOKEN>
<TOKEN end_char="1206" id="token-10-20" morph="none" pos="word" start_char="1203">days</TOKEN>
<TOKEN end_char="1207" id="token-10-21" morph="none" pos="punct" start_char="1207">.</TOKEN>
</SEG>
<SEG end_char="1238" id="segment-11" start_char="1209">
<ORIGINAL_TEXT>"How widespread does this go?"</ORIGINAL_TEXT>
<TOKEN end_char="1209" id="token-11-0" morph="none" pos="punct" start_char="1209">"</TOKEN>
<TOKEN end_char="1212" id="token-11-1" morph="none" pos="word" start_char="1210">How</TOKEN>
<TOKEN end_char="1223" id="token-11-2" morph="none" pos="word" start_char="1214">widespread</TOKEN>
<TOKEN end_char="1228" id="token-11-3" morph="none" pos="word" start_char="1225">does</TOKEN>
<TOKEN end_char="1233" id="token-11-4" morph="none" pos="word" start_char="1230">this</TOKEN>
<TOKEN end_char="1236" id="token-11-5" morph="none" pos="word" start_char="1235">go</TOKEN>
<TOKEN end_char="1238" id="token-11-6" morph="none" pos="punct" start_char="1237">?"</TOKEN>
</SEG>
<SEG end_char="1300" id="segment-12" start_char="1240">
<ORIGINAL_TEXT>asks Marion Koopmans, a virologist at Erasmus Medical Center.</ORIGINAL_TEXT>
<TOKEN end_char="1243" id="token-12-0" morph="none" pos="word" start_char="1240">asks</TOKEN>
<TOKEN end_char="1250" id="token-12-1" morph="none" pos="word" start_char="1245">Marion</TOKEN>
<TOKEN end_char="1259" id="token-12-2" morph="none" pos="word" start_char="1252">Koopmans</TOKEN>
<TOKEN end_char="1260" id="token-12-3" morph="none" pos="punct" start_char="1260">,</TOKEN>
<TOKEN end_char="1262" id="token-12-4" morph="none" pos="word" start_char="1262">a</TOKEN>
<TOKEN end_char="1273" id="token-12-5" morph="none" pos="word" start_char="1264">virologist</TOKEN>
<TOKEN end_char="1276" id="token-12-6" morph="none" pos="word" start_char="1275">at</TOKEN>
<TOKEN end_char="1284" id="token-12-7" morph="none" pos="word" start_char="1278">Erasmus</TOKEN>
<TOKEN end_char="1292" id="token-12-8" morph="none" pos="word" start_char="1286">Medical</TOKEN>
<TOKEN end_char="1299" id="token-12-9" morph="none" pos="word" start_char="1294">Center</TOKEN>
<TOKEN end_char="1300" id="token-12-10" morph="none" pos="punct" start_char="1300">.</TOKEN>
</SEG>
<SEG end_char="1336" id="segment-13" start_char="1302">
<ORIGINAL_TEXT>"This deserves our full attention."</ORIGINAL_TEXT>
<TOKEN end_char="1302" id="token-13-0" morph="none" pos="punct" start_char="1302">"</TOKEN>
<TOKEN end_char="1306" id="token-13-1" morph="none" pos="word" start_char="1303">This</TOKEN>
<TOKEN end_char="1315" id="token-13-2" morph="none" pos="word" start_char="1308">deserves</TOKEN>
<TOKEN end_char="1319" id="token-13-3" morph="none" pos="word" start_char="1317">our</TOKEN>
<TOKEN end_char="1324" id="token-13-4" morph="none" pos="word" start_char="1321">full</TOKEN>
<TOKEN end_char="1334" id="token-13-5" morph="none" pos="word" start_char="1326">attention</TOKEN>
<TOKEN end_char="1336" id="token-13-6" morph="none" pos="punct" start_char="1335">."</TOKEN>
</SEG>
<SEG end_char="1524" id="segment-14" start_char="1339">
<ORIGINAL_TEXT>Early this week, the World Health Organization (WHO) had not yet declared the outbreak a Public Health Emergency of International Concern (PHEIC), the loudest alarm the agency can sound.</ORIGINAL_TEXT>
<TOKEN end_char="1343" id="token-14-0" morph="none" pos="word" start_char="1339">Early</TOKEN>
<TOKEN end_char="1348" id="token-14-1" morph="none" pos="word" start_char="1345">this</TOKEN>
<TOKEN end_char="1353" id="token-14-2" morph="none" pos="word" start_char="1350">week</TOKEN>
<TOKEN end_char="1354" id="token-14-3" morph="none" pos="punct" start_char="1354">,</TOKEN>
<TOKEN end_char="1358" id="token-14-4" morph="none" pos="word" start_char="1356">the</TOKEN>
<TOKEN end_char="1364" id="token-14-5" morph="none" pos="word" start_char="1360">World</TOKEN>
<TOKEN end_char="1371" id="token-14-6" morph="none" pos="word" start_char="1366">Health</TOKEN>
<TOKEN end_char="1384" id="token-14-7" morph="none" pos="word" start_char="1373">Organization</TOKEN>
<TOKEN end_char="1386" id="token-14-8" morph="none" pos="punct" start_char="1386">(</TOKEN>
<TOKEN end_char="1389" id="token-14-9" morph="none" pos="word" start_char="1387">WHO</TOKEN>
<TOKEN end_char="1390" id="token-14-10" morph="none" pos="punct" start_char="1390">)</TOKEN>
<TOKEN end_char="1394" id="token-14-11" morph="none" pos="word" start_char="1392">had</TOKEN>
<TOKEN end_char="1398" id="token-14-12" morph="none" pos="word" start_char="1396">not</TOKEN>
<TOKEN end_char="1402" id="token-14-13" morph="none" pos="word" start_char="1400">yet</TOKEN>
<TOKEN end_char="1411" id="token-14-14" morph="none" pos="word" start_char="1404">declared</TOKEN>
<TOKEN end_char="1415" id="token-14-15" morph="none" pos="word" start_char="1413">the</TOKEN>
<TOKEN end_char="1424" id="token-14-16" morph="none" pos="word" start_char="1417">outbreak</TOKEN>
<TOKEN end_char="1426" id="token-14-17" morph="none" pos="word" start_char="1426">a</TOKEN>
<TOKEN end_char="1433" id="token-14-18" morph="none" pos="word" start_char="1428">Public</TOKEN>
<TOKEN end_char="1440" id="token-14-19" morph="none" pos="word" start_char="1435">Health</TOKEN>
<TOKEN end_char="1450" id="token-14-20" morph="none" pos="word" start_char="1442">Emergency</TOKEN>
<TOKEN end_char="1453" id="token-14-21" morph="none" pos="word" start_char="1452">of</TOKEN>
<TOKEN end_char="1467" id="token-14-22" morph="none" pos="word" start_char="1455">International</TOKEN>
<TOKEN end_char="1475" id="token-14-23" morph="none" pos="word" start_char="1469">Concern</TOKEN>
<TOKEN end_char="1477" id="token-14-24" morph="none" pos="punct" start_char="1477">(</TOKEN>
<TOKEN end_char="1482" id="token-14-25" morph="none" pos="word" start_char="1478">PHEIC</TOKEN>
<TOKEN end_char="1484" id="token-14-26" morph="none" pos="punct" start_char="1483">),</TOKEN>
<TOKEN end_char="1488" id="token-14-27" morph="none" pos="word" start_char="1486">the</TOKEN>
<TOKEN end_char="1496" id="token-14-28" morph="none" pos="word" start_char="1490">loudest</TOKEN>
<TOKEN end_char="1502" id="token-14-29" morph="none" pos="word" start_char="1498">alarm</TOKEN>
<TOKEN end_char="1506" id="token-14-30" morph="none" pos="word" start_char="1504">the</TOKEN>
<TOKEN end_char="1513" id="token-14-31" morph="none" pos="word" start_char="1508">agency</TOKEN>
<TOKEN end_char="1517" id="token-14-32" morph="none" pos="word" start_char="1515">can</TOKEN>
<TOKEN end_char="1523" id="token-14-33" morph="none" pos="word" start_char="1519">sound</TOKEN>
<TOKEN end_char="1524" id="token-14-34" morph="none" pos="punct" start_char="1524">.</TOKEN>
</SEG>
<SEG end_char="1748" id="segment-15" start_char="1526">
<ORIGINAL_TEXT>In meetings on 22 and 23 January, a special WHO committee that includes Koopmans was divided on whether a PHEIC was warranted, in part because there was no evidence the disease was spreading between people outside of China.</ORIGINAL_TEXT>
<TOKEN end_char="1527" id="token-15-0" morph="none" pos="word" start_char="1526">In</TOKEN>
<TOKEN end_char="1536" id="token-15-1" morph="none" pos="word" start_char="1529">meetings</TOKEN>
<TOKEN end_char="1539" id="token-15-2" morph="none" pos="word" start_char="1538">on</TOKEN>
<TOKEN end_char="1542" id="token-15-3" morph="none" pos="word" start_char="1541">22</TOKEN>
<TOKEN end_char="1546" id="token-15-4" morph="none" pos="word" start_char="1544">and</TOKEN>
<TOKEN end_char="1549" id="token-15-5" morph="none" pos="word" start_char="1548">23</TOKEN>
<TOKEN end_char="1557" id="token-15-6" morph="none" pos="word" start_char="1551">January</TOKEN>
<TOKEN end_char="1558" id="token-15-7" morph="none" pos="punct" start_char="1558">,</TOKEN>
<TOKEN end_char="1560" id="token-15-8" morph="none" pos="word" start_char="1560">a</TOKEN>
<TOKEN end_char="1568" id="token-15-9" morph="none" pos="word" start_char="1562">special</TOKEN>
<TOKEN end_char="1572" id="token-15-10" morph="none" pos="word" start_char="1570">WHO</TOKEN>
<TOKEN end_char="1582" id="token-15-11" morph="none" pos="word" start_char="1574">committee</TOKEN>
<TOKEN end_char="1587" id="token-15-12" morph="none" pos="word" start_char="1584">that</TOKEN>
<TOKEN end_char="1596" id="token-15-13" morph="none" pos="word" start_char="1589">includes</TOKEN>
<TOKEN end_char="1605" id="token-15-14" morph="none" pos="word" start_char="1598">Koopmans</TOKEN>
<TOKEN end_char="1609" id="token-15-15" morph="none" pos="word" start_char="1607">was</TOKEN>
<TOKEN end_char="1617" id="token-15-16" morph="none" pos="word" start_char="1611">divided</TOKEN>
<TOKEN end_char="1620" id="token-15-17" morph="none" pos="word" start_char="1619">on</TOKEN>
<TOKEN end_char="1628" id="token-15-18" morph="none" pos="word" start_char="1622">whether</TOKEN>
<TOKEN end_char="1630" id="token-15-19" morph="none" pos="word" start_char="1630">a</TOKEN>
<TOKEN end_char="1636" id="token-15-20" morph="none" pos="word" start_char="1632">PHEIC</TOKEN>
<TOKEN end_char="1640" id="token-15-21" morph="none" pos="word" start_char="1638">was</TOKEN>
<TOKEN end_char="1650" id="token-15-22" morph="none" pos="word" start_char="1642">warranted</TOKEN>
<TOKEN end_char="1651" id="token-15-23" morph="none" pos="punct" start_char="1651">,</TOKEN>
<TOKEN end_char="1654" id="token-15-24" morph="none" pos="word" start_char="1653">in</TOKEN>
<TOKEN end_char="1659" id="token-15-25" morph="none" pos="word" start_char="1656">part</TOKEN>
<TOKEN end_char="1667" id="token-15-26" morph="none" pos="word" start_char="1661">because</TOKEN>
<TOKEN end_char="1673" id="token-15-27" morph="none" pos="word" start_char="1669">there</TOKEN>
<TOKEN end_char="1677" id="token-15-28" morph="none" pos="word" start_char="1675">was</TOKEN>
<TOKEN end_char="1680" id="token-15-29" morph="none" pos="word" start_char="1679">no</TOKEN>
<TOKEN end_char="1689" id="token-15-30" morph="none" pos="word" start_char="1682">evidence</TOKEN>
<TOKEN end_char="1693" id="token-15-31" morph="none" pos="word" start_char="1691">the</TOKEN>
<TOKEN end_char="1701" id="token-15-32" morph="none" pos="word" start_char="1695">disease</TOKEN>
<TOKEN end_char="1705" id="token-15-33" morph="none" pos="word" start_char="1703">was</TOKEN>
<TOKEN end_char="1715" id="token-15-34" morph="none" pos="word" start_char="1707">spreading</TOKEN>
<TOKEN end_char="1723" id="token-15-35" morph="none" pos="word" start_char="1717">between</TOKEN>
<TOKEN end_char="1730" id="token-15-36" morph="none" pos="word" start_char="1725">people</TOKEN>
<TOKEN end_char="1738" id="token-15-37" morph="none" pos="word" start_char="1732">outside</TOKEN>
<TOKEN end_char="1741" id="token-15-38" morph="none" pos="word" start_char="1740">of</TOKEN>
<TOKEN end_char="1747" id="token-15-39" morph="none" pos="word" start_char="1743">China</TOKEN>
<TOKEN end_char="1748" id="token-15-40" morph="none" pos="punct" start_char="1748">.</TOKEN>
</SEG>
<SEG end_char="1864" id="segment-16" start_char="1750">
<ORIGINAL_TEXT>But by 28 January, several countries had reported local human-to-human transmission, which may change the equation.</ORIGINAL_TEXT>
<TOKEN end_char="1752" id="token-16-0" morph="none" pos="word" start_char="1750">But</TOKEN>
<TOKEN end_char="1755" id="token-16-1" morph="none" pos="word" start_char="1754">by</TOKEN>
<TOKEN end_char="1758" id="token-16-2" morph="none" pos="word" start_char="1757">28</TOKEN>
<TOKEN end_char="1766" id="token-16-3" morph="none" pos="word" start_char="1760">January</TOKEN>
<TOKEN end_char="1767" id="token-16-4" morph="none" pos="punct" start_char="1767">,</TOKEN>
<TOKEN end_char="1775" id="token-16-5" morph="none" pos="word" start_char="1769">several</TOKEN>
<TOKEN end_char="1785" id="token-16-6" morph="none" pos="word" start_char="1777">countries</TOKEN>
<TOKEN end_char="1789" id="token-16-7" morph="none" pos="word" start_char="1787">had</TOKEN>
<TOKEN end_char="1798" id="token-16-8" morph="none" pos="word" start_char="1791">reported</TOKEN>
<TOKEN end_char="1804" id="token-16-9" morph="none" pos="word" start_char="1800">local</TOKEN>
<TOKEN end_char="1819" id="token-16-10" morph="none" pos="unknown" start_char="1806">human-to-human</TOKEN>
<TOKEN end_char="1832" id="token-16-11" morph="none" pos="word" start_char="1821">transmission</TOKEN>
<TOKEN end_char="1833" id="token-16-12" morph="none" pos="punct" start_char="1833">,</TOKEN>
<TOKEN end_char="1839" id="token-16-13" morph="none" pos="word" start_char="1835">which</TOKEN>
<TOKEN end_char="1843" id="token-16-14" morph="none" pos="word" start_char="1841">may</TOKEN>
<TOKEN end_char="1850" id="token-16-15" morph="none" pos="word" start_char="1845">change</TOKEN>
<TOKEN end_char="1854" id="token-16-16" morph="none" pos="word" start_char="1852">the</TOKEN>
<TOKEN end_char="1863" id="token-16-17" morph="none" pos="word" start_char="1856">equation</TOKEN>
<TOKEN end_char="1864" id="token-16-18" morph="none" pos="punct" start_char="1864">.</TOKEN>
</SEG>
<SEG end_char="1889" id="segment-17" start_char="1867">
<ORIGINAL_TEXT>Get the latest issue of</ORIGINAL_TEXT>
<TOKEN end_char="1869" id="token-17-0" morph="none" pos="word" start_char="1867">Get</TOKEN>
<TOKEN end_char="1873" id="token-17-1" morph="none" pos="word" start_char="1871">the</TOKEN>
<TOKEN end_char="1880" id="token-17-2" morph="none" pos="word" start_char="1875">latest</TOKEN>
<TOKEN end_char="1886" id="token-17-3" morph="none" pos="word" start_char="1882">issue</TOKEN>
<TOKEN end_char="1889" id="token-17-4" morph="none" pos="word" start_char="1888">of</TOKEN>
</SEG>
<SEG end_char="1898" id="segment-18" start_char="1892">
<ORIGINAL_TEXT>Science</ORIGINAL_TEXT>
<TOKEN end_char="1898" id="token-18-0" morph="none" pos="word" start_char="1892">Science</TOKEN>
<TRANSLATED_TEXT>Wetenschap</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1923" id="segment-19" start_char="1901">
<ORIGINAL_TEXT>delivered right to you!</ORIGINAL_TEXT>
<TOKEN end_char="1909" id="token-19-0" morph="none" pos="word" start_char="1901">delivered</TOKEN>
<TOKEN end_char="1915" id="token-19-1" morph="none" pos="word" start_char="1911">right</TOKEN>
<TOKEN end_char="1918" id="token-19-2" morph="none" pos="word" start_char="1917">to</TOKEN>
<TOKEN end_char="1922" id="token-19-3" morph="none" pos="word" start_char="1920">you</TOKEN>
<TOKEN end_char="1923" id="token-19-4" morph="none" pos="punct" start_char="1923">!</TOKEN>
</SEG>
<SEG end_char="2056" id="segment-20" start_char="1926">
<ORIGINAL_TEXT>So far 2019-nCoV appears to be milder than its cousin, severe acute respiratory syndrome (SARS), which had a mortality rate of 10%.</ORIGINAL_TEXT>
<TOKEN end_char="1927" id="token-20-0" morph="none" pos="word" start_char="1926">So</TOKEN>
<TOKEN end_char="1931" id="token-20-1" morph="none" pos="word" start_char="1929">far</TOKEN>
<TOKEN end_char="1941" id="token-20-2" morph="none" pos="unknown" start_char="1933">2019-nCoV</TOKEN>
<TOKEN end_char="1949" id="token-20-3" morph="none" pos="word" start_char="1943">appears</TOKEN>
<TOKEN end_char="1952" id="token-20-4" morph="none" pos="word" start_char="1951">to</TOKEN>
<TOKEN end_char="1955" id="token-20-5" morph="none" pos="word" start_char="1954">be</TOKEN>
<TOKEN end_char="1962" id="token-20-6" morph="none" pos="word" start_char="1957">milder</TOKEN>
<TOKEN end_char="1967" id="token-20-7" morph="none" pos="word" start_char="1964">than</TOKEN>
<TOKEN end_char="1971" id="token-20-8" morph="none" pos="word" start_char="1969">its</TOKEN>
<TOKEN end_char="1978" id="token-20-9" morph="none" pos="word" start_char="1973">cousin</TOKEN>
<TOKEN end_char="1979" id="token-20-10" morph="none" pos="punct" start_char="1979">,</TOKEN>
<TOKEN end_char="1986" id="token-20-11" morph="none" pos="word" start_char="1981">severe</TOKEN>
<TOKEN end_char="1992" id="token-20-12" morph="none" pos="word" start_char="1988">acute</TOKEN>
<TOKEN end_char="2004" id="token-20-13" morph="none" pos="word" start_char="1994">respiratory</TOKEN>
<TOKEN end_char="2013" id="token-20-14" morph="none" pos="word" start_char="2006">syndrome</TOKEN>
<TOKEN end_char="2015" id="token-20-15" morph="none" pos="punct" start_char="2015">(</TOKEN>
<TOKEN end_char="2019" id="token-20-16" morph="none" pos="word" start_char="2016">SARS</TOKEN>
<TOKEN end_char="2021" id="token-20-17" morph="none" pos="punct" start_char="2020">),</TOKEN>
<TOKEN end_char="2027" id="token-20-18" morph="none" pos="word" start_char="2023">which</TOKEN>
<TOKEN end_char="2031" id="token-20-19" morph="none" pos="word" start_char="2029">had</TOKEN>
<TOKEN end_char="2033" id="token-20-20" morph="none" pos="word" start_char="2033">a</TOKEN>
<TOKEN end_char="2043" id="token-20-21" morph="none" pos="word" start_char="2035">mortality</TOKEN>
<TOKEN end_char="2048" id="token-20-22" morph="none" pos="word" start_char="2045">rate</TOKEN>
<TOKEN end_char="2051" id="token-20-23" morph="none" pos="word" start_char="2050">of</TOKEN>
<TOKEN end_char="2054" id="token-20-24" morph="none" pos="word" start_char="2053">10</TOKEN>
<TOKEN end_char="2056" id="token-20-25" morph="none" pos="punct" start_char="2055">%.</TOKEN>
</SEG>
<SEG end_char="2100" id="segment-21" start_char="2058">
<ORIGINAL_TEXT>Only 106 deaths have been recorded to date.</ORIGINAL_TEXT>
<TOKEN end_char="2061" id="token-21-0" morph="none" pos="word" start_char="2058">Only</TOKEN>
<TOKEN end_char="2065" id="token-21-1" morph="none" pos="word" start_char="2063">106</TOKEN>
<TOKEN end_char="2072" id="token-21-2" morph="none" pos="word" start_char="2067">deaths</TOKEN>
<TOKEN end_char="2077" id="token-21-3" morph="none" pos="word" start_char="2074">have</TOKEN>
<TOKEN end_char="2082" id="token-21-4" morph="none" pos="word" start_char="2079">been</TOKEN>
<TOKEN end_char="2091" id="token-21-5" morph="none" pos="word" start_char="2084">recorded</TOKEN>
<TOKEN end_char="2094" id="token-21-6" morph="none" pos="word" start_char="2093">to</TOKEN>
<TOKEN end_char="2099" id="token-21-7" morph="none" pos="word" start_char="2096">date</TOKEN>
<TOKEN end_char="2100" id="token-21-8" morph="none" pos="punct" start_char="2100">.</TOKEN>
</SEG>
<SEG end_char="2171" id="segment-22" start_char="2102">
<ORIGINAL_TEXT>But hundreds more people are seriously ill, and their fate is unclear.</ORIGINAL_TEXT>
<TOKEN end_char="2104" id="token-22-0" morph="none" pos="word" start_char="2102">But</TOKEN>
<TOKEN end_char="2113" id="token-22-1" morph="none" pos="word" start_char="2106">hundreds</TOKEN>
<TOKEN end_char="2118" id="token-22-2" morph="none" pos="word" start_char="2115">more</TOKEN>
<TOKEN end_char="2125" id="token-22-3" morph="none" pos="word" start_char="2120">people</TOKEN>
<TOKEN end_char="2129" id="token-22-4" morph="none" pos="word" start_char="2127">are</TOKEN>
<TOKEN end_char="2139" id="token-22-5" morph="none" pos="word" start_char="2131">seriously</TOKEN>
<TOKEN end_char="2143" id="token-22-6" morph="none" pos="word" start_char="2141">ill</TOKEN>
<TOKEN end_char="2144" id="token-22-7" morph="none" pos="punct" start_char="2144">,</TOKEN>
<TOKEN end_char="2148" id="token-22-8" morph="none" pos="word" start_char="2146">and</TOKEN>
<TOKEN end_char="2154" id="token-22-9" morph="none" pos="word" start_char="2150">their</TOKEN>
<TOKEN end_char="2159" id="token-22-10" morph="none" pos="word" start_char="2156">fate</TOKEN>
<TOKEN end_char="2162" id="token-22-11" morph="none" pos="word" start_char="2161">is</TOKEN>
<TOKEN end_char="2170" id="token-22-12" morph="none" pos="word" start_char="2164">unclear</TOKEN>
<TOKEN end_char="2171" id="token-22-13" morph="none" pos="punct" start_char="2171">.</TOKEN>
</SEG>
<SEG end_char="2209" id="segment-23" start_char="2173">
<ORIGINAL_TEXT>And countless other questions remain.</ORIGINAL_TEXT>
<TOKEN end_char="2175" id="token-23-0" morph="none" pos="word" start_char="2173">And</TOKEN>
<TOKEN end_char="2185" id="token-23-1" morph="none" pos="word" start_char="2177">countless</TOKEN>
<TOKEN end_char="2191" id="token-23-2" morph="none" pos="word" start_char="2187">other</TOKEN>
<TOKEN end_char="2201" id="token-23-3" morph="none" pos="word" start_char="2193">questions</TOKEN>
<TOKEN end_char="2208" id="token-23-4" morph="none" pos="word" start_char="2203">remain</TOKEN>
<TOKEN end_char="2209" id="token-23-5" morph="none" pos="punct" start_char="2209">.</TOKEN>
</SEG>
<SEG end_char="2340" id="segment-24" start_char="2211">
<ORIGINAL_TEXT>Scientists don't know how long the incubation period lasts or whether infected people who show no symptoms can transmit the virus.</ORIGINAL_TEXT>
<TOKEN end_char="2220" id="token-24-0" morph="none" pos="word" start_char="2211">Scientists</TOKEN>
<TOKEN end_char="2226" id="token-24-1" morph="none" pos="word" start_char="2222">don't</TOKEN>
<TOKEN end_char="2231" id="token-24-2" morph="none" pos="word" start_char="2228">know</TOKEN>
<TOKEN end_char="2235" id="token-24-3" morph="none" pos="word" start_char="2233">how</TOKEN>
<TOKEN end_char="2240" id="token-24-4" morph="none" pos="word" start_char="2237">long</TOKEN>
<TOKEN end_char="2244" id="token-24-5" morph="none" pos="word" start_char="2242">the</TOKEN>
<TOKEN end_char="2255" id="token-24-6" morph="none" pos="word" start_char="2246">incubation</TOKEN>
<TOKEN end_char="2262" id="token-24-7" morph="none" pos="word" start_char="2257">period</TOKEN>
<TOKEN end_char="2268" id="token-24-8" morph="none" pos="word" start_char="2264">lasts</TOKEN>
<TOKEN end_char="2271" id="token-24-9" morph="none" pos="word" start_char="2270">or</TOKEN>
<TOKEN end_char="2279" id="token-24-10" morph="none" pos="word" start_char="2273">whether</TOKEN>
<TOKEN end_char="2288" id="token-24-11" morph="none" pos="word" start_char="2281">infected</TOKEN>
<TOKEN end_char="2295" id="token-24-12" morph="none" pos="word" start_char="2290">people</TOKEN>
<TOKEN end_char="2299" id="token-24-13" morph="none" pos="word" start_char="2297">who</TOKEN>
<TOKEN end_char="2304" id="token-24-14" morph="none" pos="word" start_char="2301">show</TOKEN>
<TOKEN end_char="2307" id="token-24-15" morph="none" pos="word" start_char="2306">no</TOKEN>
<TOKEN end_char="2316" id="token-24-16" morph="none" pos="word" start_char="2309">symptoms</TOKEN>
<TOKEN end_char="2320" id="token-24-17" morph="none" pos="word" start_char="2318">can</TOKEN>
<TOKEN end_char="2329" id="token-24-18" morph="none" pos="word" start_char="2322">transmit</TOKEN>
<TOKEN end_char="2333" id="token-24-19" morph="none" pos="word" start_char="2331">the</TOKEN>
<TOKEN end_char="2339" id="token-24-20" morph="none" pos="word" start_char="2335">virus</TOKEN>
<TOKEN end_char="2340" id="token-24-21" morph="none" pos="punct" start_char="2340">.</TOKEN>
</SEG>
<SEG end_char="2475" id="segment-25" start_char="2342">
<ORIGINAL_TEXT>China's state-run news agency Xinhua reported on 26 January that a seemingly healthy man appeared to have infected "a few colleagues."</ORIGINAL_TEXT>
<TOKEN end_char="2348" id="token-25-0" morph="none" pos="word" start_char="2342">China's</TOKEN>
<TOKEN end_char="2358" id="token-25-1" morph="none" pos="unknown" start_char="2350">state-run</TOKEN>
<TOKEN end_char="2363" id="token-25-2" morph="none" pos="word" start_char="2360">news</TOKEN>
<TOKEN end_char="2370" id="token-25-3" morph="none" pos="word" start_char="2365">agency</TOKEN>
<TOKEN end_char="2377" id="token-25-4" morph="none" pos="word" start_char="2372">Xinhua</TOKEN>
<TOKEN end_char="2386" id="token-25-5" morph="none" pos="word" start_char="2379">reported</TOKEN>
<TOKEN end_char="2389" id="token-25-6" morph="none" pos="word" start_char="2388">on</TOKEN>
<TOKEN end_char="2392" id="token-25-7" morph="none" pos="word" start_char="2391">26</TOKEN>
<TOKEN end_char="2400" id="token-25-8" morph="none" pos="word" start_char="2394">January</TOKEN>
<TOKEN end_char="2405" id="token-25-9" morph="none" pos="word" start_char="2402">that</TOKEN>
<TOKEN end_char="2407" id="token-25-10" morph="none" pos="word" start_char="2407">a</TOKEN>
<TOKEN end_char="2417" id="token-25-11" morph="none" pos="word" start_char="2409">seemingly</TOKEN>
<TOKEN end_char="2425" id="token-25-12" morph="none" pos="word" start_char="2419">healthy</TOKEN>
<TOKEN end_char="2429" id="token-25-13" morph="none" pos="word" start_char="2427">man</TOKEN>
<TOKEN end_char="2438" id="token-25-14" morph="none" pos="word" start_char="2431">appeared</TOKEN>
<TOKEN end_char="2441" id="token-25-15" morph="none" pos="word" start_char="2440">to</TOKEN>
<TOKEN end_char="2446" id="token-25-16" morph="none" pos="word" start_char="2443">have</TOKEN>
<TOKEN end_char="2455" id="token-25-17" morph="none" pos="word" start_char="2448">infected</TOKEN>
<TOKEN end_char="2457" id="token-25-18" morph="none" pos="punct" start_char="2457">"</TOKEN>
<TOKEN end_char="2458" id="token-25-19" morph="none" pos="word" start_char="2458">a</TOKEN>
<TOKEN end_char="2462" id="token-25-20" morph="none" pos="word" start_char="2460">few</TOKEN>
<TOKEN end_char="2473" id="token-25-21" morph="none" pos="word" start_char="2464">colleagues</TOKEN>
<TOKEN end_char="2475" id="token-25-22" morph="none" pos="punct" start_char="2474">."</TOKEN>
</SEG>
<SEG end_char="2581" id="segment-26" start_char="2477">
<ORIGINAL_TEXT>If asymptomatic people frequently infect others, it could vastly complicate efforts to contain 2019-nCoV.</ORIGINAL_TEXT>
<TOKEN end_char="2478" id="token-26-0" morph="none" pos="word" start_char="2477">If</TOKEN>
<TOKEN end_char="2491" id="token-26-1" morph="none" pos="word" start_char="2480">asymptomatic</TOKEN>
<TOKEN end_char="2498" id="token-26-2" morph="none" pos="word" start_char="2493">people</TOKEN>
<TOKEN end_char="2509" id="token-26-3" morph="none" pos="word" start_char="2500">frequently</TOKEN>
<TOKEN end_char="2516" id="token-26-4" morph="none" pos="word" start_char="2511">infect</TOKEN>
<TOKEN end_char="2523" id="token-26-5" morph="none" pos="word" start_char="2518">others</TOKEN>
<TOKEN end_char="2524" id="token-26-6" morph="none" pos="punct" start_char="2524">,</TOKEN>
<TOKEN end_char="2527" id="token-26-7" morph="none" pos="word" start_char="2526">it</TOKEN>
<TOKEN end_char="2533" id="token-26-8" morph="none" pos="word" start_char="2529">could</TOKEN>
<TOKEN end_char="2540" id="token-26-9" morph="none" pos="word" start_char="2535">vastly</TOKEN>
<TOKEN end_char="2551" id="token-26-10" morph="none" pos="word" start_char="2542">complicate</TOKEN>
<TOKEN end_char="2559" id="token-26-11" morph="none" pos="word" start_char="2553">efforts</TOKEN>
<TOKEN end_char="2562" id="token-26-12" morph="none" pos="word" start_char="2561">to</TOKEN>
<TOKEN end_char="2570" id="token-26-13" morph="none" pos="word" start_char="2564">contain</TOKEN>
<TOKEN end_char="2580" id="token-26-14" morph="none" pos="unknown" start_char="2572">2019-nCoV</TOKEN>
<TOKEN end_char="2581" id="token-26-15" morph="none" pos="punct" start_char="2581">.</TOKEN>
</SEG>
<SEG end_char="2801" id="segment-27" start_char="2584">
<ORIGINAL_TEXT>The virus's explosive spread has been met by an unprecedented rush by scientists to uncover its origins, find treatments, and develop vaccines that could save millions of lives if the world really does face a pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="2586" id="token-27-0" morph="none" pos="word" start_char="2584">The</TOKEN>
<TOKEN end_char="2594" id="token-27-1" morph="none" pos="word" start_char="2588">virus's</TOKEN>
<TOKEN end_char="2604" id="token-27-2" morph="none" pos="word" start_char="2596">explosive</TOKEN>
<TOKEN end_char="2611" id="token-27-3" morph="none" pos="word" start_char="2606">spread</TOKEN>
<TOKEN end_char="2615" id="token-27-4" morph="none" pos="word" start_char="2613">has</TOKEN>
<TOKEN end_char="2620" id="token-27-5" morph="none" pos="word" start_char="2617">been</TOKEN>
<TOKEN end_char="2624" id="token-27-6" morph="none" pos="word" start_char="2622">met</TOKEN>
<TOKEN end_char="2627" id="token-27-7" morph="none" pos="word" start_char="2626">by</TOKEN>
<TOKEN end_char="2630" id="token-27-8" morph="none" pos="word" start_char="2629">an</TOKEN>
<TOKEN end_char="2644" id="token-27-9" morph="none" pos="word" start_char="2632">unprecedented</TOKEN>
<TOKEN end_char="2649" id="token-27-10" morph="none" pos="word" start_char="2646">rush</TOKEN>
<TOKEN end_char="2652" id="token-27-11" morph="none" pos="word" start_char="2651">by</TOKEN>
<TOKEN end_char="2663" id="token-27-12" morph="none" pos="word" start_char="2654">scientists</TOKEN>
<TOKEN end_char="2666" id="token-27-13" morph="none" pos="word" start_char="2665">to</TOKEN>
<TOKEN end_char="2674" id="token-27-14" morph="none" pos="word" start_char="2668">uncover</TOKEN>
<TOKEN end_char="2678" id="token-27-15" morph="none" pos="word" start_char="2676">its</TOKEN>
<TOKEN end_char="2686" id="token-27-16" morph="none" pos="word" start_char="2680">origins</TOKEN>
<TOKEN end_char="2687" id="token-27-17" morph="none" pos="punct" start_char="2687">,</TOKEN>
<TOKEN end_char="2692" id="token-27-18" morph="none" pos="word" start_char="2689">find</TOKEN>
<TOKEN end_char="2703" id="token-27-19" morph="none" pos="word" start_char="2694">treatments</TOKEN>
<TOKEN end_char="2704" id="token-27-20" morph="none" pos="punct" start_char="2704">,</TOKEN>
<TOKEN end_char="2708" id="token-27-21" morph="none" pos="word" start_char="2706">and</TOKEN>
<TOKEN end_char="2716" id="token-27-22" morph="none" pos="word" start_char="2710">develop</TOKEN>
<TOKEN end_char="2725" id="token-27-23" morph="none" pos="word" start_char="2718">vaccines</TOKEN>
<TOKEN end_char="2730" id="token-27-24" morph="none" pos="word" start_char="2727">that</TOKEN>
<TOKEN end_char="2736" id="token-27-25" morph="none" pos="word" start_char="2732">could</TOKEN>
<TOKEN end_char="2741" id="token-27-26" morph="none" pos="word" start_char="2738">save</TOKEN>
<TOKEN end_char="2750" id="token-27-27" morph="none" pos="word" start_char="2743">millions</TOKEN>
<TOKEN end_char="2753" id="token-27-28" morph="none" pos="word" start_char="2752">of</TOKEN>
<TOKEN end_char="2759" id="token-27-29" morph="none" pos="word" start_char="2755">lives</TOKEN>
<TOKEN end_char="2762" id="token-27-30" morph="none" pos="word" start_char="2761">if</TOKEN>
<TOKEN end_char="2766" id="token-27-31" morph="none" pos="word" start_char="2764">the</TOKEN>
<TOKEN end_char="2772" id="token-27-32" morph="none" pos="word" start_char="2768">world</TOKEN>
<TOKEN end_char="2779" id="token-27-33" morph="none" pos="word" start_char="2774">really</TOKEN>
<TOKEN end_char="2784" id="token-27-34" morph="none" pos="word" start_char="2781">does</TOKEN>
<TOKEN end_char="2789" id="token-27-35" morph="none" pos="word" start_char="2786">face</TOKEN>
<TOKEN end_char="2791" id="token-27-36" morph="none" pos="word" start_char="2791">a</TOKEN>
<TOKEN end_char="2800" id="token-27-37" morph="none" pos="word" start_char="2793">pandemic</TOKEN>
<TOKEN end_char="2801" id="token-27-38" morph="none" pos="punct" start_char="2801">.</TOKEN>
</SEG>
<SEG end_char="2906" id="segment-28" start_char="2803">
<ORIGINAL_TEXT>Here are some of the ways researchers are attempting to better understand 2019-nCoV and reduce its harm.</ORIGINAL_TEXT>
<TOKEN end_char="2806" id="token-28-0" morph="none" pos="word" start_char="2803">Here</TOKEN>
<TOKEN end_char="2810" id="token-28-1" morph="none" pos="word" start_char="2808">are</TOKEN>
<TOKEN end_char="2815" id="token-28-2" morph="none" pos="word" start_char="2812">some</TOKEN>
<TOKEN end_char="2818" id="token-28-3" morph="none" pos="word" start_char="2817">of</TOKEN>
<TOKEN end_char="2822" id="token-28-4" morph="none" pos="word" start_char="2820">the</TOKEN>
<TOKEN end_char="2827" id="token-28-5" morph="none" pos="word" start_char="2824">ways</TOKEN>
<TOKEN end_char="2839" id="token-28-6" morph="none" pos="word" start_char="2829">researchers</TOKEN>
<TOKEN end_char="2843" id="token-28-7" morph="none" pos="word" start_char="2841">are</TOKEN>
<TOKEN end_char="2854" id="token-28-8" morph="none" pos="word" start_char="2845">attempting</TOKEN>
<TOKEN end_char="2857" id="token-28-9" morph="none" pos="word" start_char="2856">to</TOKEN>
<TOKEN end_char="2864" id="token-28-10" morph="none" pos="word" start_char="2859">better</TOKEN>
<TOKEN end_char="2875" id="token-28-11" morph="none" pos="word" start_char="2866">understand</TOKEN>
<TOKEN end_char="2885" id="token-28-12" morph="none" pos="unknown" start_char="2877">2019-nCoV</TOKEN>
<TOKEN end_char="2889" id="token-28-13" morph="none" pos="word" start_char="2887">and</TOKEN>
<TOKEN end_char="2896" id="token-28-14" morph="none" pos="word" start_char="2891">reduce</TOKEN>
<TOKEN end_char="2900" id="token-28-15" morph="none" pos="word" start_char="2898">its</TOKEN>
<TOKEN end_char="2905" id="token-28-16" morph="none" pos="word" start_char="2902">harm</TOKEN>
<TOKEN end_char="2906" id="token-28-17" morph="none" pos="punct" start_char="2906">.</TOKEN>
</SEG>
<SEG end_char="2938" id="segment-29" start_char="2909">
<ORIGINAL_TEXT>Where Did the Virus Come From?</ORIGINAL_TEXT>
<TOKEN end_char="2913" id="token-29-0" morph="none" pos="word" start_char="2909">Where</TOKEN>
<TOKEN end_char="2917" id="token-29-1" morph="none" pos="word" start_char="2915">Did</TOKEN>
<TOKEN end_char="2921" id="token-29-2" morph="none" pos="word" start_char="2919">the</TOKEN>
<TOKEN end_char="2927" id="token-29-3" morph="none" pos="word" start_char="2923">Virus</TOKEN>
<TOKEN end_char="2932" id="token-29-4" morph="none" pos="word" start_char="2929">Come</TOKEN>
<TOKEN end_char="2937" id="token-29-5" morph="none" pos="word" start_char="2934">From</TOKEN>
<TOKEN end_char="2938" id="token-29-6" morph="none" pos="punct" start_char="2938">?</TOKEN>
</SEG>
<SEG end_char="3003" id="segment-30" start_char="2942">
<ORIGINAL_TEXT>Almost certainly from animals, but when and how are mysteries.</ORIGINAL_TEXT>
<TOKEN end_char="2947" id="token-30-0" morph="none" pos="word" start_char="2942">Almost</TOKEN>
<TOKEN end_char="2957" id="token-30-1" morph="none" pos="word" start_char="2949">certainly</TOKEN>
<TOKEN end_char="2962" id="token-30-2" morph="none" pos="word" start_char="2959">from</TOKEN>
<TOKEN end_char="2970" id="token-30-3" morph="none" pos="word" start_char="2964">animals</TOKEN>
<TOKEN end_char="2971" id="token-30-4" morph="none" pos="punct" start_char="2971">,</TOKEN>
<TOKEN end_char="2975" id="token-30-5" morph="none" pos="word" start_char="2973">but</TOKEN>
<TOKEN end_char="2980" id="token-30-6" morph="none" pos="word" start_char="2977">when</TOKEN>
<TOKEN end_char="2984" id="token-30-7" morph="none" pos="word" start_char="2982">and</TOKEN>
<TOKEN end_char="2988" id="token-30-8" morph="none" pos="word" start_char="2986">how</TOKEN>
<TOKEN end_char="2992" id="token-30-9" morph="none" pos="word" start_char="2990">are</TOKEN>
<TOKEN end_char="3002" id="token-30-10" morph="none" pos="word" start_char="2994">mysteries</TOKEN>
<TOKEN end_char="3003" id="token-30-11" morph="none" pos="punct" start_char="3003">.</TOKEN>
</SEG>
<SEG end_char="3054" id="segment-31" start_char="3005">
<ORIGINAL_TEXT>Genetic analyses are starting to yield some clues.</ORIGINAL_TEXT>
<TOKEN end_char="3011" id="token-31-0" morph="none" pos="word" start_char="3005">Genetic</TOKEN>
<TOKEN end_char="3020" id="token-31-1" morph="none" pos="word" start_char="3013">analyses</TOKEN>
<TOKEN end_char="3024" id="token-31-2" morph="none" pos="word" start_char="3022">are</TOKEN>
<TOKEN end_char="3033" id="token-31-3" morph="none" pos="word" start_char="3026">starting</TOKEN>
<TOKEN end_char="3036" id="token-31-4" morph="none" pos="word" start_char="3035">to</TOKEN>
<TOKEN end_char="3042" id="token-31-5" morph="none" pos="word" start_char="3038">yield</TOKEN>
<TOKEN end_char="3047" id="token-31-6" morph="none" pos="word" start_char="3044">some</TOKEN>
<TOKEN end_char="3053" id="token-31-7" morph="none" pos="word" start_char="3049">clues</TOKEN>
<TOKEN end_char="3054" id="token-31-8" morph="none" pos="punct" start_char="3054">.</TOKEN>
</SEG>
<SEG end_char="3134" id="segment-32" start_char="3056">
<ORIGINAL_TEXT>Chinese researchers first shared a genomic sequence of 2019-nCoV on 11 January.</ORIGINAL_TEXT>
<TOKEN end_char="3062" id="token-32-0" morph="none" pos="word" start_char="3056">Chinese</TOKEN>
<TOKEN end_char="3074" id="token-32-1" morph="none" pos="word" start_char="3064">researchers</TOKEN>
<TOKEN end_char="3080" id="token-32-2" morph="none" pos="word" start_char="3076">first</TOKEN>
<TOKEN end_char="3087" id="token-32-3" morph="none" pos="word" start_char="3082">shared</TOKEN>
<TOKEN end_char="3089" id="token-32-4" morph="none" pos="word" start_char="3089">a</TOKEN>
<TOKEN end_char="3097" id="token-32-5" morph="none" pos="word" start_char="3091">genomic</TOKEN>
<TOKEN end_char="3106" id="token-32-6" morph="none" pos="word" start_char="3099">sequence</TOKEN>
<TOKEN end_char="3109" id="token-32-7" morph="none" pos="word" start_char="3108">of</TOKEN>
<TOKEN end_char="3119" id="token-32-8" morph="none" pos="unknown" start_char="3111">2019-nCoV</TOKEN>
<TOKEN end_char="3122" id="token-32-9" morph="none" pos="word" start_char="3121">on</TOKEN>
<TOKEN end_char="3125" id="token-32-10" morph="none" pos="word" start_char="3124">11</TOKEN>
<TOKEN end_char="3133" id="token-32-11" morph="none" pos="word" start_char="3127">January</TOKEN>
<TOKEN end_char="3134" id="token-32-12" morph="none" pos="punct" start_char="3134">.</TOKEN>
</SEG>
<SEG end_char="3265" id="segment-33" start_char="3136">
<ORIGINAL_TEXT>Labs in China and abroad have since announced nearly three dozen additional sequences of the virus—"a stellar job," Koopmans says.</ORIGINAL_TEXT>
<TOKEN end_char="3139" id="token-33-0" morph="none" pos="word" start_char="3136">Labs</TOKEN>
<TOKEN end_char="3142" id="token-33-1" morph="none" pos="word" start_char="3141">in</TOKEN>
<TOKEN end_char="3148" id="token-33-2" morph="none" pos="word" start_char="3144">China</TOKEN>
<TOKEN end_char="3152" id="token-33-3" morph="none" pos="word" start_char="3150">and</TOKEN>
<TOKEN end_char="3159" id="token-33-4" morph="none" pos="word" start_char="3154">abroad</TOKEN>
<TOKEN end_char="3164" id="token-33-5" morph="none" pos="word" start_char="3161">have</TOKEN>
<TOKEN end_char="3170" id="token-33-6" morph="none" pos="word" start_char="3166">since</TOKEN>
<TOKEN end_char="3180" id="token-33-7" morph="none" pos="word" start_char="3172">announced</TOKEN>
<TOKEN end_char="3187" id="token-33-8" morph="none" pos="word" start_char="3182">nearly</TOKEN>
<TOKEN end_char="3193" id="token-33-9" morph="none" pos="word" start_char="3189">three</TOKEN>
<TOKEN end_char="3199" id="token-33-10" morph="none" pos="word" start_char="3195">dozen</TOKEN>
<TOKEN end_char="3210" id="token-33-11" morph="none" pos="word" start_char="3201">additional</TOKEN>
<TOKEN end_char="3220" id="token-33-12" morph="none" pos="word" start_char="3212">sequences</TOKEN>
<TOKEN end_char="3223" id="token-33-13" morph="none" pos="word" start_char="3222">of</TOKEN>
<TOKEN end_char="3227" id="token-33-14" morph="none" pos="word" start_char="3225">the</TOKEN>
<TOKEN end_char="3236" id="token-33-15" morph="none" pos="unknown" start_char="3229">virus—"a</TOKEN>
<TOKEN end_char="3244" id="token-33-16" morph="none" pos="word" start_char="3238">stellar</TOKEN>
<TOKEN end_char="3248" id="token-33-17" morph="none" pos="word" start_char="3246">job</TOKEN>
<TOKEN end_char="3250" id="token-33-18" morph="none" pos="punct" start_char="3249">,"</TOKEN>
<TOKEN end_char="3259" id="token-33-19" morph="none" pos="word" start_char="3252">Koopmans</TOKEN>
<TOKEN end_char="3264" id="token-33-20" morph="none" pos="word" start_char="3261">says</TOKEN>
<TOKEN end_char="3265" id="token-33-21" morph="none" pos="punct" start_char="3265">.</TOKEN>
</SEG>
<SEG end_char="3471" id="segment-34" start_char="3268">
<ORIGINAL_TEXT>A team led by Shi Zheng-Li of the Wuhan Institute of Virology reported on 23 January that 2019-nCoV's sequence was 96.2% identical to that of a bat coronavirus and 79.5% identical to the SARS coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="3268" id="token-34-0" morph="none" pos="word" start_char="3268">A</TOKEN>
<TOKEN end_char="3273" id="token-34-1" morph="none" pos="word" start_char="3270">team</TOKEN>
<TOKEN end_char="3277" id="token-34-2" morph="none" pos="word" start_char="3275">led</TOKEN>
<TOKEN end_char="3280" id="token-34-3" morph="none" pos="word" start_char="3279">by</TOKEN>
<TOKEN end_char="3284" id="token-34-4" morph="none" pos="word" start_char="3282">Shi</TOKEN>
<TOKEN end_char="3293" id="token-34-5" morph="none" pos="unknown" start_char="3286">Zheng-Li</TOKEN>
<TOKEN end_char="3296" id="token-34-6" morph="none" pos="word" start_char="3295">of</TOKEN>
<TOKEN end_char="3300" id="token-34-7" morph="none" pos="word" start_char="3298">the</TOKEN>
<TOKEN end_char="3306" id="token-34-8" morph="none" pos="word" start_char="3302">Wuhan</TOKEN>
<TOKEN end_char="3316" id="token-34-9" morph="none" pos="word" start_char="3308">Institute</TOKEN>
<TOKEN end_char="3319" id="token-34-10" morph="none" pos="word" start_char="3318">of</TOKEN>
<TOKEN end_char="3328" id="token-34-11" morph="none" pos="word" start_char="3321">Virology</TOKEN>
<TOKEN end_char="3337" id="token-34-12" morph="none" pos="word" start_char="3330">reported</TOKEN>
<TOKEN end_char="3340" id="token-34-13" morph="none" pos="word" start_char="3339">on</TOKEN>
<TOKEN end_char="3343" id="token-34-14" morph="none" pos="word" start_char="3342">23</TOKEN>
<TOKEN end_char="3351" id="token-34-15" morph="none" pos="word" start_char="3345">January</TOKEN>
<TOKEN end_char="3356" id="token-34-16" morph="none" pos="word" start_char="3353">that</TOKEN>
<TOKEN end_char="3368" id="token-34-17" morph="none" pos="unknown" start_char="3358">2019-nCoV's</TOKEN>
<TOKEN end_char="3377" id="token-34-18" morph="none" pos="word" start_char="3370">sequence</TOKEN>
<TOKEN end_char="3381" id="token-34-19" morph="none" pos="word" start_char="3379">was</TOKEN>
<TOKEN end_char="3386" id="token-34-20" morph="none" pos="unknown" start_char="3383">96.2</TOKEN>
<TOKEN end_char="3387" id="token-34-21" morph="none" pos="punct" start_char="3387">%</TOKEN>
<TOKEN end_char="3397" id="token-34-22" morph="none" pos="word" start_char="3389">identical</TOKEN>
<TOKEN end_char="3400" id="token-34-23" morph="none" pos="word" start_char="3399">to</TOKEN>
<TOKEN end_char="3405" id="token-34-24" morph="none" pos="word" start_char="3402">that</TOKEN>
<TOKEN end_char="3408" id="token-34-25" morph="none" pos="word" start_char="3407">of</TOKEN>
<TOKEN end_char="3410" id="token-34-26" morph="none" pos="word" start_char="3410">a</TOKEN>
<TOKEN end_char="3414" id="token-34-27" morph="none" pos="word" start_char="3412">bat</TOKEN>
<TOKEN end_char="3426" id="token-34-28" morph="none" pos="word" start_char="3416">coronavirus</TOKEN>
<TOKEN end_char="3430" id="token-34-29" morph="none" pos="word" start_char="3428">and</TOKEN>
<TOKEN end_char="3435" id="token-34-30" morph="none" pos="unknown" start_char="3432">79.5</TOKEN>
<TOKEN end_char="3436" id="token-34-31" morph="none" pos="punct" start_char="3436">%</TOKEN>
<TOKEN end_char="3446" id="token-34-32" morph="none" pos="word" start_char="3438">identical</TOKEN>
<TOKEN end_char="3449" id="token-34-33" morph="none" pos="word" start_char="3448">to</TOKEN>
<TOKEN end_char="3453" id="token-34-34" morph="none" pos="word" start_char="3451">the</TOKEN>
<TOKEN end_char="3458" id="token-34-35" morph="none" pos="word" start_char="3455">SARS</TOKEN>
<TOKEN end_char="3470" id="token-34-36" morph="none" pos="word" start_char="3460">coronavirus</TOKEN>
<TOKEN end_char="3471" id="token-34-37" morph="none" pos="punct" start_char="3471">.</TOKEN>
</SEG>
<SEG end_char="3603" id="segment-35" start_char="3473">
<ORIGINAL_TEXT>That doesn't mean 2019-nCoV jumped directly from bats to humans, says evolutionary biologist Kristian Andersen of Scripps Research.</ORIGINAL_TEXT>
<TOKEN end_char="3476" id="token-35-0" morph="none" pos="word" start_char="3473">That</TOKEN>
<TOKEN end_char="3484" id="token-35-1" morph="none" pos="word" start_char="3478">doesn't</TOKEN>
<TOKEN end_char="3489" id="token-35-2" morph="none" pos="word" start_char="3486">mean</TOKEN>
<TOKEN end_char="3499" id="token-35-3" morph="none" pos="unknown" start_char="3491">2019-nCoV</TOKEN>
<TOKEN end_char="3506" id="token-35-4" morph="none" pos="word" start_char="3501">jumped</TOKEN>
<TOKEN end_char="3515" id="token-35-5" morph="none" pos="word" start_char="3508">directly</TOKEN>
<TOKEN end_char="3520" id="token-35-6" morph="none" pos="word" start_char="3517">from</TOKEN>
<TOKEN end_char="3525" id="token-35-7" morph="none" pos="word" start_char="3522">bats</TOKEN>
<TOKEN end_char="3528" id="token-35-8" morph="none" pos="word" start_char="3527">to</TOKEN>
<TOKEN end_char="3535" id="token-35-9" morph="none" pos="word" start_char="3530">humans</TOKEN>
<TOKEN end_char="3536" id="token-35-10" morph="none" pos="punct" start_char="3536">,</TOKEN>
<TOKEN end_char="3541" id="token-35-11" morph="none" pos="word" start_char="3538">says</TOKEN>
<TOKEN end_char="3554" id="token-35-12" morph="none" pos="word" start_char="3543">evolutionary</TOKEN>
<TOKEN end_char="3564" id="token-35-13" morph="none" pos="word" start_char="3556">biologist</TOKEN>
<TOKEN end_char="3573" id="token-35-14" morph="none" pos="word" start_char="3566">Kristian</TOKEN>
<TOKEN end_char="3582" id="token-35-15" morph="none" pos="word" start_char="3575">Andersen</TOKEN>
<TOKEN end_char="3585" id="token-35-16" morph="none" pos="word" start_char="3584">of</TOKEN>
<TOKEN end_char="3593" id="token-35-17" morph="none" pos="word" start_char="3587">Scripps</TOKEN>
<TOKEN end_char="3602" id="token-35-18" morph="none" pos="word" start_char="3595">Research</TOKEN>
<TOKEN end_char="3603" id="token-35-19" morph="none" pos="punct" start_char="3603">.</TOKEN>
</SEG>
<SEG end_char="3703" id="segment-36" start_char="3605">
<ORIGINAL_TEXT>SARS, for example, probably moved from bats to civets—sold as a delicacy in many markets—to humans.</ORIGINAL_TEXT>
<TOKEN end_char="3608" id="token-36-0" morph="none" pos="word" start_char="3605">SARS</TOKEN>
<TOKEN end_char="3609" id="token-36-1" morph="none" pos="punct" start_char="3609">,</TOKEN>
<TOKEN end_char="3613" id="token-36-2" morph="none" pos="word" start_char="3611">for</TOKEN>
<TOKEN end_char="3621" id="token-36-3" morph="none" pos="word" start_char="3615">example</TOKEN>
<TOKEN end_char="3622" id="token-36-4" morph="none" pos="punct" start_char="3622">,</TOKEN>
<TOKEN end_char="3631" id="token-36-5" morph="none" pos="word" start_char="3624">probably</TOKEN>
<TOKEN end_char="3637" id="token-36-6" morph="none" pos="word" start_char="3633">moved</TOKEN>
<TOKEN end_char="3642" id="token-36-7" morph="none" pos="word" start_char="3639">from</TOKEN>
<TOKEN end_char="3647" id="token-36-8" morph="none" pos="word" start_char="3644">bats</TOKEN>
<TOKEN end_char="3650" id="token-36-9" morph="none" pos="word" start_char="3649">to</TOKEN>
<TOKEN end_char="3662" id="token-36-10" morph="none" pos="unknown" start_char="3652">civets—sold</TOKEN>
<TOKEN end_char="3665" id="token-36-11" morph="none" pos="word" start_char="3664">as</TOKEN>
<TOKEN end_char="3667" id="token-36-12" morph="none" pos="word" start_char="3667">a</TOKEN>
<TOKEN end_char="3676" id="token-36-13" morph="none" pos="word" start_char="3669">delicacy</TOKEN>
<TOKEN end_char="3679" id="token-36-14" morph="none" pos="word" start_char="3678">in</TOKEN>
<TOKEN end_char="3684" id="token-36-15" morph="none" pos="word" start_char="3681">many</TOKEN>
<TOKEN end_char="3695" id="token-36-16" morph="none" pos="unknown" start_char="3686">markets—to</TOKEN>
<TOKEN end_char="3702" id="token-36-17" morph="none" pos="word" start_char="3697">humans</TOKEN>
<TOKEN end_char="3703" id="token-36-18" morph="none" pos="punct" start_char="3703">.</TOKEN>
</SEG>
<SEG end_char="3898" id="segment-37" start_char="3706">
<ORIGINAL_TEXT>From the start, the Huanan Seafood Wholesale Market in Wuhan—which sold mammals as well as fish—was considered a likely source of the outbreak because most of the early patients had visited it.</ORIGINAL_TEXT>
<TOKEN end_char="3709" id="token-37-0" morph="none" pos="word" start_char="3706">From</TOKEN>
<TOKEN end_char="3713" id="token-37-1" morph="none" pos="word" start_char="3711">the</TOKEN>
<TOKEN end_char="3719" id="token-37-2" morph="none" pos="word" start_char="3715">start</TOKEN>
<TOKEN end_char="3720" id="token-37-3" morph="none" pos="punct" start_char="3720">,</TOKEN>
<TOKEN end_char="3724" id="token-37-4" morph="none" pos="word" start_char="3722">the</TOKEN>
<TOKEN end_char="3731" id="token-37-5" morph="none" pos="word" start_char="3726">Huanan</TOKEN>
<TOKEN end_char="3739" id="token-37-6" morph="none" pos="word" start_char="3733">Seafood</TOKEN>
<TOKEN end_char="3749" id="token-37-7" morph="none" pos="word" start_char="3741">Wholesale</TOKEN>
<TOKEN end_char="3756" id="token-37-8" morph="none" pos="word" start_char="3751">Market</TOKEN>
<TOKEN end_char="3759" id="token-37-9" morph="none" pos="word" start_char="3758">in</TOKEN>
<TOKEN end_char="3771" id="token-37-10" morph="none" pos="unknown" start_char="3761">Wuhan—which</TOKEN>
<TOKEN end_char="3776" id="token-37-11" morph="none" pos="word" start_char="3773">sold</TOKEN>
<TOKEN end_char="3784" id="token-37-12" morph="none" pos="word" start_char="3778">mammals</TOKEN>
<TOKEN end_char="3787" id="token-37-13" morph="none" pos="word" start_char="3786">as</TOKEN>
<TOKEN end_char="3792" id="token-37-14" morph="none" pos="word" start_char="3789">well</TOKEN>
<TOKEN end_char="3795" id="token-37-15" morph="none" pos="word" start_char="3794">as</TOKEN>
<TOKEN end_char="3804" id="token-37-16" morph="none" pos="unknown" start_char="3797">fish—was</TOKEN>
<TOKEN end_char="3815" id="token-37-17" morph="none" pos="word" start_char="3806">considered</TOKEN>
<TOKEN end_char="3817" id="token-37-18" morph="none" pos="word" start_char="3817">a</TOKEN>
<TOKEN end_char="3824" id="token-37-19" morph="none" pos="word" start_char="3819">likely</TOKEN>
<TOKEN end_char="3831" id="token-37-20" morph="none" pos="word" start_char="3826">source</TOKEN>
<TOKEN end_char="3834" id="token-37-21" morph="none" pos="word" start_char="3833">of</TOKEN>
<TOKEN end_char="3838" id="token-37-22" morph="none" pos="word" start_char="3836">the</TOKEN>
<TOKEN end_char="3847" id="token-37-23" morph="none" pos="word" start_char="3840">outbreak</TOKEN>
<TOKEN end_char="3855" id="token-37-24" morph="none" pos="word" start_char="3849">because</TOKEN>
<TOKEN end_char="3860" id="token-37-25" morph="none" pos="word" start_char="3857">most</TOKEN>
<TOKEN end_char="3863" id="token-37-26" morph="none" pos="word" start_char="3862">of</TOKEN>
<TOKEN end_char="3867" id="token-37-27" morph="none" pos="word" start_char="3865">the</TOKEN>
<TOKEN end_char="3873" id="token-37-28" morph="none" pos="word" start_char="3869">early</TOKEN>
<TOKEN end_char="3882" id="token-37-29" morph="none" pos="word" start_char="3875">patients</TOKEN>
<TOKEN end_char="3886" id="token-37-30" morph="none" pos="word" start_char="3884">had</TOKEN>
<TOKEN end_char="3894" id="token-37-31" morph="none" pos="word" start_char="3888">visited</TOKEN>
<TOKEN end_char="3897" id="token-37-32" morph="none" pos="word" start_char="3896">it</TOKEN>
<TOKEN end_char="3898" id="token-37-33" morph="none" pos="punct" start_char="3898">.</TOKEN>
</SEG>
<SEG end_char="4098" id="segment-38" start_char="3900">
<ORIGINAL_TEXT>On 27 January, Xinhua reported that researchers have found evidence of the new coronavirus in 33 of 585 environmental samples taken at the market on 1 January—the day it was closed—and on 12 January.</ORIGINAL_TEXT>
<TOKEN end_char="3901" id="token-38-0" morph="none" pos="word" start_char="3900">On</TOKEN>
<TOKEN end_char="3904" id="token-38-1" morph="none" pos="word" start_char="3903">27</TOKEN>
<TOKEN end_char="3912" id="token-38-2" morph="none" pos="word" start_char="3906">January</TOKEN>
<TOKEN end_char="3913" id="token-38-3" morph="none" pos="punct" start_char="3913">,</TOKEN>
<TOKEN end_char="3920" id="token-38-4" morph="none" pos="word" start_char="3915">Xinhua</TOKEN>
<TOKEN end_char="3929" id="token-38-5" morph="none" pos="word" start_char="3922">reported</TOKEN>
<TOKEN end_char="3934" id="token-38-6" morph="none" pos="word" start_char="3931">that</TOKEN>
<TOKEN end_char="3946" id="token-38-7" morph="none" pos="word" start_char="3936">researchers</TOKEN>
<TOKEN end_char="3951" id="token-38-8" morph="none" pos="word" start_char="3948">have</TOKEN>
<TOKEN end_char="3957" id="token-38-9" morph="none" pos="word" start_char="3953">found</TOKEN>
<TOKEN end_char="3966" id="token-38-10" morph="none" pos="word" start_char="3959">evidence</TOKEN>
<TOKEN end_char="3969" id="token-38-11" morph="none" pos="word" start_char="3968">of</TOKEN>
<TOKEN end_char="3973" id="token-38-12" morph="none" pos="word" start_char="3971">the</TOKEN>
<TOKEN end_char="3977" id="token-38-13" morph="none" pos="word" start_char="3975">new</TOKEN>
<TOKEN end_char="3989" id="token-38-14" morph="none" pos="word" start_char="3979">coronavirus</TOKEN>
<TOKEN end_char="3992" id="token-38-15" morph="none" pos="word" start_char="3991">in</TOKEN>
<TOKEN end_char="3995" id="token-38-16" morph="none" pos="word" start_char="3994">33</TOKEN>
<TOKEN end_char="3998" id="token-38-17" morph="none" pos="word" start_char="3997">of</TOKEN>
<TOKEN end_char="4002" id="token-38-18" morph="none" pos="word" start_char="4000">585</TOKEN>
<TOKEN end_char="4016" id="token-38-19" morph="none" pos="word" start_char="4004">environmental</TOKEN>
<TOKEN end_char="4024" id="token-38-20" morph="none" pos="word" start_char="4018">samples</TOKEN>
<TOKEN end_char="4030" id="token-38-21" morph="none" pos="word" start_char="4026">taken</TOKEN>
<TOKEN end_char="4033" id="token-38-22" morph="none" pos="word" start_char="4032">at</TOKEN>
<TOKEN end_char="4037" id="token-38-23" morph="none" pos="word" start_char="4035">the</TOKEN>
<TOKEN end_char="4044" id="token-38-24" morph="none" pos="word" start_char="4039">market</TOKEN>
<TOKEN end_char="4047" id="token-38-25" morph="none" pos="word" start_char="4046">on</TOKEN>
<TOKEN end_char="4049" id="token-38-26" morph="none" pos="word" start_char="4049">1</TOKEN>
<TOKEN end_char="4061" id="token-38-27" morph="none" pos="unknown" start_char="4051">January—the</TOKEN>
<TOKEN end_char="4065" id="token-38-28" morph="none" pos="word" start_char="4063">day</TOKEN>
<TOKEN end_char="4068" id="token-38-29" morph="none" pos="word" start_char="4067">it</TOKEN>
<TOKEN end_char="4072" id="token-38-30" morph="none" pos="word" start_char="4070">was</TOKEN>
<TOKEN end_char="4083" id="token-38-31" morph="none" pos="unknown" start_char="4074">closed—and</TOKEN>
<TOKEN end_char="4086" id="token-38-32" morph="none" pos="word" start_char="4085">on</TOKEN>
<TOKEN end_char="4089" id="token-38-33" morph="none" pos="word" start_char="4088">12</TOKEN>
<TOKEN end_char="4097" id="token-38-34" morph="none" pos="word" start_char="4091">January</TOKEN>
<TOKEN end_char="4098" id="token-38-35" morph="none" pos="punct" start_char="4098">.</TOKEN>
</SEG>
<SEG end_char="4188" id="segment-39" start_char="4100">
<ORIGINAL_TEXT>They all came from the western end, which had a concentration of booths selling wildlife.</ORIGINAL_TEXT>
<TOKEN end_char="4103" id="token-39-0" morph="none" pos="word" start_char="4100">They</TOKEN>
<TOKEN end_char="4107" id="token-39-1" morph="none" pos="word" start_char="4105">all</TOKEN>
<TOKEN end_char="4112" id="token-39-2" morph="none" pos="word" start_char="4109">came</TOKEN>
<TOKEN end_char="4117" id="token-39-3" morph="none" pos="word" start_char="4114">from</TOKEN>
<TOKEN end_char="4121" id="token-39-4" morph="none" pos="word" start_char="4119">the</TOKEN>
<TOKEN end_char="4129" id="token-39-5" morph="none" pos="word" start_char="4123">western</TOKEN>
<TOKEN end_char="4133" id="token-39-6" morph="none" pos="word" start_char="4131">end</TOKEN>
<TOKEN end_char="4134" id="token-39-7" morph="none" pos="punct" start_char="4134">,</TOKEN>
<TOKEN end_char="4140" id="token-39-8" morph="none" pos="word" start_char="4136">which</TOKEN>
<TOKEN end_char="4144" id="token-39-9" morph="none" pos="word" start_char="4142">had</TOKEN>
<TOKEN end_char="4146" id="token-39-10" morph="none" pos="word" start_char="4146">a</TOKEN>
<TOKEN end_char="4160" id="token-39-11" morph="none" pos="word" start_char="4148">concentration</TOKEN>
<TOKEN end_char="4163" id="token-39-12" morph="none" pos="word" start_char="4162">of</TOKEN>
<TOKEN end_char="4170" id="token-39-13" morph="none" pos="word" start_char="4165">booths</TOKEN>
<TOKEN end_char="4178" id="token-39-14" morph="none" pos="word" start_char="4172">selling</TOKEN>
<TOKEN end_char="4187" id="token-39-15" morph="none" pos="word" start_char="4180">wildlife</TOKEN>
<TOKEN end_char="4188" id="token-39-16" morph="none" pos="punct" start_char="4188">.</TOKEN>
</SEG>
<SEG end_char="4383" id="segment-40" start_char="4191">
<ORIGINAL_TEXT>That indicates the market played a role in spreading the virus, says Daniel Lucey, an infectious disease specialist at Georgetown University—but he says other data suggest it wasn't the origin.</ORIGINAL_TEXT>
<TOKEN end_char="4194" id="token-40-0" morph="none" pos="word" start_char="4191">That</TOKEN>
<TOKEN end_char="4204" id="token-40-1" morph="none" pos="word" start_char="4196">indicates</TOKEN>
<TOKEN end_char="4208" id="token-40-2" morph="none" pos="word" start_char="4206">the</TOKEN>
<TOKEN end_char="4215" id="token-40-3" morph="none" pos="word" start_char="4210">market</TOKEN>
<TOKEN end_char="4222" id="token-40-4" morph="none" pos="word" start_char="4217">played</TOKEN>
<TOKEN end_char="4224" id="token-40-5" morph="none" pos="word" start_char="4224">a</TOKEN>
<TOKEN end_char="4229" id="token-40-6" morph="none" pos="word" start_char="4226">role</TOKEN>
<TOKEN end_char="4232" id="token-40-7" morph="none" pos="word" start_char="4231">in</TOKEN>
<TOKEN end_char="4242" id="token-40-8" morph="none" pos="word" start_char="4234">spreading</TOKEN>
<TOKEN end_char="4246" id="token-40-9" morph="none" pos="word" start_char="4244">the</TOKEN>
<TOKEN end_char="4252" id="token-40-10" morph="none" pos="word" start_char="4248">virus</TOKEN>
<TOKEN end_char="4253" id="token-40-11" morph="none" pos="punct" start_char="4253">,</TOKEN>
<TOKEN end_char="4258" id="token-40-12" morph="none" pos="word" start_char="4255">says</TOKEN>
<TOKEN end_char="4265" id="token-40-13" morph="none" pos="word" start_char="4260">Daniel</TOKEN>
<TOKEN end_char="4271" id="token-40-14" morph="none" pos="word" start_char="4267">Lucey</TOKEN>
<TOKEN end_char="4272" id="token-40-15" morph="none" pos="punct" start_char="4272">,</TOKEN>
<TOKEN end_char="4275" id="token-40-16" morph="none" pos="word" start_char="4274">an</TOKEN>
<TOKEN end_char="4286" id="token-40-17" morph="none" pos="word" start_char="4277">infectious</TOKEN>
<TOKEN end_char="4294" id="token-40-18" morph="none" pos="word" start_char="4288">disease</TOKEN>
<TOKEN end_char="4305" id="token-40-19" morph="none" pos="word" start_char="4296">specialist</TOKEN>
<TOKEN end_char="4308" id="token-40-20" morph="none" pos="word" start_char="4307">at</TOKEN>
<TOKEN end_char="4319" id="token-40-21" morph="none" pos="word" start_char="4310">Georgetown</TOKEN>
<TOKEN end_char="4334" id="token-40-22" morph="none" pos="unknown" start_char="4321">University—but</TOKEN>
<TOKEN end_char="4337" id="token-40-23" morph="none" pos="word" start_char="4336">he</TOKEN>
<TOKEN end_char="4342" id="token-40-24" morph="none" pos="word" start_char="4339">says</TOKEN>
<TOKEN end_char="4348" id="token-40-25" morph="none" pos="word" start_char="4344">other</TOKEN>
<TOKEN end_char="4353" id="token-40-26" morph="none" pos="word" start_char="4350">data</TOKEN>
<TOKEN end_char="4361" id="token-40-27" morph="none" pos="word" start_char="4355">suggest</TOKEN>
<TOKEN end_char="4364" id="token-40-28" morph="none" pos="word" start_char="4363">it</TOKEN>
<TOKEN end_char="4371" id="token-40-29" morph="none" pos="word" start_char="4366">wasn't</TOKEN>
<TOKEN end_char="4375" id="token-40-30" morph="none" pos="word" start_char="4373">the</TOKEN>
<TOKEN end_char="4382" id="token-40-31" morph="none" pos="word" start_char="4377">origin</TOKEN>
<TOKEN end_char="4383" id="token-40-32" morph="none" pos="punct" start_char="4383">.</TOKEN>
</SEG>
<SEG end_char="4526" id="segment-41" start_char="4385">
<ORIGINAL_TEXT>The first known patient became ill on 1 December 2019 and had no links to the market, according to a paper published by Chinese researchers in</ORIGINAL_TEXT>
<TOKEN end_char="4387" id="token-41-0" morph="none" pos="word" start_char="4385">The</TOKEN>
<TOKEN end_char="4393" id="token-41-1" morph="none" pos="word" start_char="4389">first</TOKEN>
<TOKEN end_char="4399" id="token-41-2" morph="none" pos="word" start_char="4395">known</TOKEN>
<TOKEN end_char="4407" id="token-41-3" morph="none" pos="word" start_char="4401">patient</TOKEN>
<TOKEN end_char="4414" id="token-41-4" morph="none" pos="word" start_char="4409">became</TOKEN>
<TOKEN end_char="4418" id="token-41-5" morph="none" pos="word" start_char="4416">ill</TOKEN>
<TOKEN end_char="4421" id="token-41-6" morph="none" pos="word" start_char="4420">on</TOKEN>
<TOKEN end_char="4423" id="token-41-7" morph="none" pos="word" start_char="4423">1</TOKEN>
<TOKEN end_char="4432" id="token-41-8" morph="none" pos="word" start_char="4425">December</TOKEN>
<TOKEN end_char="4437" id="token-41-9" morph="none" pos="word" start_char="4434">2019</TOKEN>
<TOKEN end_char="4441" id="token-41-10" morph="none" pos="word" start_char="4439">and</TOKEN>
<TOKEN end_char="4445" id="token-41-11" morph="none" pos="word" start_char="4443">had</TOKEN>
<TOKEN end_char="4448" id="token-41-12" morph="none" pos="word" start_char="4447">no</TOKEN>
<TOKEN end_char="4454" id="token-41-13" morph="none" pos="word" start_char="4450">links</TOKEN>
<TOKEN end_char="4457" id="token-41-14" morph="none" pos="word" start_char="4456">to</TOKEN>
<TOKEN end_char="4461" id="token-41-15" morph="none" pos="word" start_char="4459">the</TOKEN>
<TOKEN end_char="4468" id="token-41-16" morph="none" pos="word" start_char="4463">market</TOKEN>
<TOKEN end_char="4469" id="token-41-17" morph="none" pos="punct" start_char="4469">,</TOKEN>
<TOKEN end_char="4479" id="token-41-18" morph="none" pos="word" start_char="4471">according</TOKEN>
<TOKEN end_char="4482" id="token-41-19" morph="none" pos="word" start_char="4481">to</TOKEN>
<TOKEN end_char="4484" id="token-41-20" morph="none" pos="word" start_char="4484">a</TOKEN>
<TOKEN end_char="4490" id="token-41-21" morph="none" pos="word" start_char="4486">paper</TOKEN>
<TOKEN end_char="4500" id="token-41-22" morph="none" pos="word" start_char="4492">published</TOKEN>
<TOKEN end_char="4503" id="token-41-23" morph="none" pos="word" start_char="4502">by</TOKEN>
<TOKEN end_char="4511" id="token-41-24" morph="none" pos="word" start_char="4505">Chinese</TOKEN>
<TOKEN end_char="4523" id="token-41-25" morph="none" pos="word" start_char="4513">researchers</TOKEN>
<TOKEN end_char="4526" id="token-41-26" morph="none" pos="word" start_char="4525">in</TOKEN>
</SEG>
<SEG end_char="4538" id="segment-42" start_char="4529">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN end_char="4531" id="token-42-0" morph="none" pos="word" start_char="4529">The</TOKEN>
<TOKEN end_char="4538" id="token-42-1" morph="none" pos="word" start_char="4533">Lancet</TOKEN>
</SEG>
<SEG end_char="4612" id="segment-43" start_char="4541">
<ORIGINAL_TEXT>on 24 January that offered details about the first 41 patients in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="4542" id="token-43-0" morph="none" pos="word" start_char="4541">on</TOKEN>
<TOKEN end_char="4545" id="token-43-1" morph="none" pos="word" start_char="4544">24</TOKEN>
<TOKEN end_char="4553" id="token-43-2" morph="none" pos="word" start_char="4547">January</TOKEN>
<TOKEN end_char="4558" id="token-43-3" morph="none" pos="word" start_char="4555">that</TOKEN>
<TOKEN end_char="4566" id="token-43-4" morph="none" pos="word" start_char="4560">offered</TOKEN>
<TOKEN end_char="4574" id="token-43-5" morph="none" pos="word" start_char="4568">details</TOKEN>
<TOKEN end_char="4580" id="token-43-6" morph="none" pos="word" start_char="4576">about</TOKEN>
<TOKEN end_char="4584" id="token-43-7" morph="none" pos="word" start_char="4582">the</TOKEN>
<TOKEN end_char="4590" id="token-43-8" morph="none" pos="word" start_char="4586">first</TOKEN>
<TOKEN end_char="4593" id="token-43-9" morph="none" pos="word" start_char="4592">41</TOKEN>
<TOKEN end_char="4602" id="token-43-10" morph="none" pos="word" start_char="4595">patients</TOKEN>
<TOKEN end_char="4605" id="token-43-11" morph="none" pos="word" start_char="4604">in</TOKEN>
<TOKEN end_char="4611" id="token-43-12" morph="none" pos="word" start_char="4607">Wuhan</TOKEN>
<TOKEN end_char="4612" id="token-43-13" morph="none" pos="punct" start_char="4612">.</TOKEN>
</SEG>
<SEG end_char="4670" id="segment-44" start_char="4614">
<ORIGINAL_TEXT>In that group, 12 others also had no links to the market.</ORIGINAL_TEXT>
<TOKEN end_char="4615" id="token-44-0" morph="none" pos="word" start_char="4614">In</TOKEN>
<TOKEN end_char="4620" id="token-44-1" morph="none" pos="word" start_char="4617">that</TOKEN>
<TOKEN end_char="4626" id="token-44-2" morph="none" pos="word" start_char="4622">group</TOKEN>
<TOKEN end_char="4627" id="token-44-3" morph="none" pos="punct" start_char="4627">,</TOKEN>
<TOKEN end_char="4630" id="token-44-4" morph="none" pos="word" start_char="4629">12</TOKEN>
<TOKEN end_char="4637" id="token-44-5" morph="none" pos="word" start_char="4632">others</TOKEN>
<TOKEN end_char="4642" id="token-44-6" morph="none" pos="word" start_char="4639">also</TOKEN>
<TOKEN end_char="4646" id="token-44-7" morph="none" pos="word" start_char="4644">had</TOKEN>
<TOKEN end_char="4649" id="token-44-8" morph="none" pos="word" start_char="4648">no</TOKEN>
<TOKEN end_char="4655" id="token-44-9" morph="none" pos="word" start_char="4651">links</TOKEN>
<TOKEN end_char="4658" id="token-44-10" morph="none" pos="word" start_char="4657">to</TOKEN>
<TOKEN end_char="4662" id="token-44-11" morph="none" pos="word" start_char="4660">the</TOKEN>
<TOKEN end_char="4669" id="token-44-12" morph="none" pos="word" start_char="4664">market</TOKEN>
<TOKEN end_char="4670" id="token-44-13" morph="none" pos="punct" start_char="4670">.</TOKEN>
</SEG>
<SEG end_char="4831" id="segment-45" start_char="4672">
<ORIGINAL_TEXT>Lucey contends the virus was already circulating silently among humans before it contaminated the seafood market, possibly by infected animals, humans, or both.</ORIGINAL_TEXT>
<TOKEN end_char="4676" id="token-45-0" morph="none" pos="word" start_char="4672">Lucey</TOKEN>
<TOKEN end_char="4685" id="token-45-1" morph="none" pos="word" start_char="4678">contends</TOKEN>
<TOKEN end_char="4689" id="token-45-2" morph="none" pos="word" start_char="4687">the</TOKEN>
<TOKEN end_char="4695" id="token-45-3" morph="none" pos="word" start_char="4691">virus</TOKEN>
<TOKEN end_char="4699" id="token-45-4" morph="none" pos="word" start_char="4697">was</TOKEN>
<TOKEN end_char="4707" id="token-45-5" morph="none" pos="word" start_char="4701">already</TOKEN>
<TOKEN end_char="4719" id="token-45-6" morph="none" pos="word" start_char="4709">circulating</TOKEN>
<TOKEN end_char="4728" id="token-45-7" morph="none" pos="word" start_char="4721">silently</TOKEN>
<TOKEN end_char="4734" id="token-45-8" morph="none" pos="word" start_char="4730">among</TOKEN>
<TOKEN end_char="4741" id="token-45-9" morph="none" pos="word" start_char="4736">humans</TOKEN>
<TOKEN end_char="4748" id="token-45-10" morph="none" pos="word" start_char="4743">before</TOKEN>
<TOKEN end_char="4751" id="token-45-11" morph="none" pos="word" start_char="4750">it</TOKEN>
<TOKEN end_char="4764" id="token-45-12" morph="none" pos="word" start_char="4753">contaminated</TOKEN>
<TOKEN end_char="4768" id="token-45-13" morph="none" pos="word" start_char="4766">the</TOKEN>
<TOKEN end_char="4776" id="token-45-14" morph="none" pos="word" start_char="4770">seafood</TOKEN>
<TOKEN end_char="4783" id="token-45-15" morph="none" pos="word" start_char="4778">market</TOKEN>
<TOKEN end_char="4784" id="token-45-16" morph="none" pos="punct" start_char="4784">,</TOKEN>
<TOKEN end_char="4793" id="token-45-17" morph="none" pos="word" start_char="4786">possibly</TOKEN>
<TOKEN end_char="4796" id="token-45-18" morph="none" pos="word" start_char="4795">by</TOKEN>
<TOKEN end_char="4805" id="token-45-19" morph="none" pos="word" start_char="4798">infected</TOKEN>
<TOKEN end_char="4813" id="token-45-20" morph="none" pos="word" start_char="4807">animals</TOKEN>
<TOKEN end_char="4814" id="token-45-21" morph="none" pos="punct" start_char="4814">,</TOKEN>
<TOKEN end_char="4821" id="token-45-22" morph="none" pos="word" start_char="4816">humans</TOKEN>
<TOKEN end_char="4822" id="token-45-23" morph="none" pos="punct" start_char="4822">,</TOKEN>
<TOKEN end_char="4825" id="token-45-24" morph="none" pos="word" start_char="4824">or</TOKEN>
<TOKEN end_char="4830" id="token-45-25" morph="none" pos="word" start_char="4827">both</TOKEN>
<TOKEN end_char="4831" id="token-45-26" morph="none" pos="punct" start_char="4831">.</TOKEN>
</SEG>
<SEG end_char="4965" id="segment-46" start_char="4834">
<ORIGINAL_TEXT>The genomic data cannot pinpoint the origin, but they do show that the jump from animals to humans happened recently, Koopmans says.</ORIGINAL_TEXT>
<TOKEN end_char="4836" id="token-46-0" morph="none" pos="word" start_char="4834">The</TOKEN>
<TOKEN end_char="4844" id="token-46-1" morph="none" pos="word" start_char="4838">genomic</TOKEN>
<TOKEN end_char="4849" id="token-46-2" morph="none" pos="word" start_char="4846">data</TOKEN>
<TOKEN end_char="4856" id="token-46-3" morph="none" pos="word" start_char="4851">cannot</TOKEN>
<TOKEN end_char="4865" id="token-46-4" morph="none" pos="word" start_char="4858">pinpoint</TOKEN>
<TOKEN end_char="4869" id="token-46-5" morph="none" pos="word" start_char="4867">the</TOKEN>
<TOKEN end_char="4876" id="token-46-6" morph="none" pos="word" start_char="4871">origin</TOKEN>
<TOKEN end_char="4877" id="token-46-7" morph="none" pos="punct" start_char="4877">,</TOKEN>
<TOKEN end_char="4881" id="token-46-8" morph="none" pos="word" start_char="4879">but</TOKEN>
<TOKEN end_char="4886" id="token-46-9" morph="none" pos="word" start_char="4883">they</TOKEN>
<TOKEN end_char="4889" id="token-46-10" morph="none" pos="word" start_char="4888">do</TOKEN>
<TOKEN end_char="4894" id="token-46-11" morph="none" pos="word" start_char="4891">show</TOKEN>
<TOKEN end_char="4899" id="token-46-12" morph="none" pos="word" start_char="4896">that</TOKEN>
<TOKEN end_char="4903" id="token-46-13" morph="none" pos="word" start_char="4901">the</TOKEN>
<TOKEN end_char="4908" id="token-46-14" morph="none" pos="word" start_char="4905">jump</TOKEN>
<TOKEN end_char="4913" id="token-46-15" morph="none" pos="word" start_char="4910">from</TOKEN>
<TOKEN end_char="4921" id="token-46-16" morph="none" pos="word" start_char="4915">animals</TOKEN>
<TOKEN end_char="4924" id="token-46-17" morph="none" pos="word" start_char="4923">to</TOKEN>
<TOKEN end_char="4931" id="token-46-18" morph="none" pos="word" start_char="4926">humans</TOKEN>
<TOKEN end_char="4940" id="token-46-19" morph="none" pos="word" start_char="4933">happened</TOKEN>
<TOKEN end_char="4949" id="token-46-20" morph="none" pos="word" start_char="4942">recently</TOKEN>
<TOKEN end_char="4950" id="token-46-21" morph="none" pos="punct" start_char="4950">,</TOKEN>
<TOKEN end_char="4959" id="token-46-22" morph="none" pos="word" start_char="4952">Koopmans</TOKEN>
<TOKEN end_char="4964" id="token-46-23" morph="none" pos="word" start_char="4961">says</TOKEN>
<TOKEN end_char="4965" id="token-46-24" morph="none" pos="punct" start_char="4965">.</TOKEN>
</SEG>
<SEG end_char="5109" id="segment-47" start_char="4967">
<ORIGINAL_TEXT>An analysis of the first 30 publicly posted sequences shows they differ from each other by no more than seven nucleotides (see graphic, right).</ORIGINAL_TEXT>
<TOKEN end_char="4968" id="token-47-0" morph="none" pos="word" start_char="4967">An</TOKEN>
<TOKEN end_char="4977" id="token-47-1" morph="none" pos="word" start_char="4970">analysis</TOKEN>
<TOKEN end_char="4980" id="token-47-2" morph="none" pos="word" start_char="4979">of</TOKEN>
<TOKEN end_char="4984" id="token-47-3" morph="none" pos="word" start_char="4982">the</TOKEN>
<TOKEN end_char="4990" id="token-47-4" morph="none" pos="word" start_char="4986">first</TOKEN>
<TOKEN end_char="4993" id="token-47-5" morph="none" pos="word" start_char="4992">30</TOKEN>
<TOKEN end_char="5002" id="token-47-6" morph="none" pos="word" start_char="4995">publicly</TOKEN>
<TOKEN end_char="5009" id="token-47-7" morph="none" pos="word" start_char="5004">posted</TOKEN>
<TOKEN end_char="5019" id="token-47-8" morph="none" pos="word" start_char="5011">sequences</TOKEN>
<TOKEN end_char="5025" id="token-47-9" morph="none" pos="word" start_char="5021">shows</TOKEN>
<TOKEN end_char="5030" id="token-47-10" morph="none" pos="word" start_char="5027">they</TOKEN>
<TOKEN end_char="5037" id="token-47-11" morph="none" pos="word" start_char="5032">differ</TOKEN>
<TOKEN end_char="5042" id="token-47-12" morph="none" pos="word" start_char="5039">from</TOKEN>
<TOKEN end_char="5047" id="token-47-13" morph="none" pos="word" start_char="5044">each</TOKEN>
<TOKEN end_char="5053" id="token-47-14" morph="none" pos="word" start_char="5049">other</TOKEN>
<TOKEN end_char="5056" id="token-47-15" morph="none" pos="word" start_char="5055">by</TOKEN>
<TOKEN end_char="5059" id="token-47-16" morph="none" pos="word" start_char="5058">no</TOKEN>
<TOKEN end_char="5064" id="token-47-17" morph="none" pos="word" start_char="5061">more</TOKEN>
<TOKEN end_char="5069" id="token-47-18" morph="none" pos="word" start_char="5066">than</TOKEN>
<TOKEN end_char="5075" id="token-47-19" morph="none" pos="word" start_char="5071">seven</TOKEN>
<TOKEN end_char="5087" id="token-47-20" morph="none" pos="word" start_char="5077">nucleotides</TOKEN>
<TOKEN end_char="5089" id="token-47-21" morph="none" pos="punct" start_char="5089">(</TOKEN>
<TOKEN end_char="5092" id="token-47-22" morph="none" pos="word" start_char="5090">see</TOKEN>
<TOKEN end_char="5100" id="token-47-23" morph="none" pos="word" start_char="5094">graphic</TOKEN>
<TOKEN end_char="5101" id="token-47-24" morph="none" pos="punct" start_char="5101">,</TOKEN>
<TOKEN end_char="5107" id="token-47-25" morph="none" pos="word" start_char="5103">right</TOKEN>
<TOKEN end_char="5109" id="token-47-26" morph="none" pos="punct" start_char="5108">).</TOKEN>
</SEG>
<SEG end_char="5351" id="segment-48" start_char="5111">
<ORIGINAL_TEXT>Using these differences and presumed mutation rates, several groups have calculated that the virus began to spread around mid-November 2019—which supports the thesis that spread may have occurred before any of the cases linked to the market.</ORIGINAL_TEXT>
<TOKEN end_char="5115" id="token-48-0" morph="none" pos="word" start_char="5111">Using</TOKEN>
<TOKEN end_char="5121" id="token-48-1" morph="none" pos="word" start_char="5117">these</TOKEN>
<TOKEN end_char="5133" id="token-48-2" morph="none" pos="word" start_char="5123">differences</TOKEN>
<TOKEN end_char="5137" id="token-48-3" morph="none" pos="word" start_char="5135">and</TOKEN>
<TOKEN end_char="5146" id="token-48-4" morph="none" pos="word" start_char="5139">presumed</TOKEN>
<TOKEN end_char="5155" id="token-48-5" morph="none" pos="word" start_char="5148">mutation</TOKEN>
<TOKEN end_char="5161" id="token-48-6" morph="none" pos="word" start_char="5157">rates</TOKEN>
<TOKEN end_char="5162" id="token-48-7" morph="none" pos="punct" start_char="5162">,</TOKEN>
<TOKEN end_char="5170" id="token-48-8" morph="none" pos="word" start_char="5164">several</TOKEN>
<TOKEN end_char="5177" id="token-48-9" morph="none" pos="word" start_char="5172">groups</TOKEN>
<TOKEN end_char="5182" id="token-48-10" morph="none" pos="word" start_char="5179">have</TOKEN>
<TOKEN end_char="5193" id="token-48-11" morph="none" pos="word" start_char="5184">calculated</TOKEN>
<TOKEN end_char="5198" id="token-48-12" morph="none" pos="word" start_char="5195">that</TOKEN>
<TOKEN end_char="5202" id="token-48-13" morph="none" pos="word" start_char="5200">the</TOKEN>
<TOKEN end_char="5208" id="token-48-14" morph="none" pos="word" start_char="5204">virus</TOKEN>
<TOKEN end_char="5214" id="token-48-15" morph="none" pos="word" start_char="5210">began</TOKEN>
<TOKEN end_char="5217" id="token-48-16" morph="none" pos="word" start_char="5216">to</TOKEN>
<TOKEN end_char="5224" id="token-48-17" morph="none" pos="word" start_char="5219">spread</TOKEN>
<TOKEN end_char="5231" id="token-48-18" morph="none" pos="word" start_char="5226">around</TOKEN>
<TOKEN end_char="5244" id="token-48-19" morph="none" pos="unknown" start_char="5233">mid-November</TOKEN>
<TOKEN end_char="5255" id="token-48-20" morph="none" pos="unknown" start_char="5246">2019—which</TOKEN>
<TOKEN end_char="5264" id="token-48-21" morph="none" pos="word" start_char="5257">supports</TOKEN>
<TOKEN end_char="5268" id="token-48-22" morph="none" pos="word" start_char="5266">the</TOKEN>
<TOKEN end_char="5275" id="token-48-23" morph="none" pos="word" start_char="5270">thesis</TOKEN>
<TOKEN end_char="5280" id="token-48-24" morph="none" pos="word" start_char="5277">that</TOKEN>
<TOKEN end_char="5287" id="token-48-25" morph="none" pos="word" start_char="5282">spread</TOKEN>
<TOKEN end_char="5291" id="token-48-26" morph="none" pos="word" start_char="5289">may</TOKEN>
<TOKEN end_char="5296" id="token-48-27" morph="none" pos="word" start_char="5293">have</TOKEN>
<TOKEN end_char="5305" id="token-48-28" morph="none" pos="word" start_char="5298">occurred</TOKEN>
<TOKEN end_char="5312" id="token-48-29" morph="none" pos="word" start_char="5307">before</TOKEN>
<TOKEN end_char="5316" id="token-48-30" morph="none" pos="word" start_char="5314">any</TOKEN>
<TOKEN end_char="5319" id="token-48-31" morph="none" pos="word" start_char="5318">of</TOKEN>
<TOKEN end_char="5323" id="token-48-32" morph="none" pos="word" start_char="5321">the</TOKEN>
<TOKEN end_char="5329" id="token-48-33" morph="none" pos="word" start_char="5325">cases</TOKEN>
<TOKEN end_char="5336" id="token-48-34" morph="none" pos="word" start_char="5331">linked</TOKEN>
<TOKEN end_char="5339" id="token-48-35" morph="none" pos="word" start_char="5338">to</TOKEN>
<TOKEN end_char="5343" id="token-48-36" morph="none" pos="word" start_char="5341">the</TOKEN>
<TOKEN end_char="5350" id="token-48-37" morph="none" pos="word" start_char="5345">market</TOKEN>
<TOKEN end_char="5351" id="token-48-38" morph="none" pos="punct" start_char="5351">.</TOKEN>
</SEG>
<SEG end_char="5423" id="segment-49" start_char="5353">
<ORIGINAL_TEXT>One group put the origin of the outbreak as early as 18 September 2019.</ORIGINAL_TEXT>
<TOKEN end_char="5355" id="token-49-0" morph="none" pos="word" start_char="5353">One</TOKEN>
<TOKEN end_char="5361" id="token-49-1" morph="none" pos="word" start_char="5357">group</TOKEN>
<TOKEN end_char="5365" id="token-49-2" morph="none" pos="word" start_char="5363">put</TOKEN>
<TOKEN end_char="5369" id="token-49-3" morph="none" pos="word" start_char="5367">the</TOKEN>
<TOKEN end_char="5376" id="token-49-4" morph="none" pos="word" start_char="5371">origin</TOKEN>
<TOKEN end_char="5379" id="token-49-5" morph="none" pos="word" start_char="5378">of</TOKEN>
<TOKEN end_char="5383" id="token-49-6" morph="none" pos="word" start_char="5381">the</TOKEN>
<TOKEN end_char="5392" id="token-49-7" morph="none" pos="word" start_char="5385">outbreak</TOKEN>
<TOKEN end_char="5395" id="token-49-8" morph="none" pos="word" start_char="5394">as</TOKEN>
<TOKEN end_char="5401" id="token-49-9" morph="none" pos="word" start_char="5397">early</TOKEN>
<TOKEN end_char="5404" id="token-49-10" morph="none" pos="word" start_char="5403">as</TOKEN>
<TOKEN end_char="5407" id="token-49-11" morph="none" pos="word" start_char="5406">18</TOKEN>
<TOKEN end_char="5417" id="token-49-12" morph="none" pos="word" start_char="5409">September</TOKEN>
<TOKEN end_char="5422" id="token-49-13" morph="none" pos="word" start_char="5419">2019</TOKEN>
<TOKEN end_char="5423" id="token-49-14" morph="none" pos="punct" start_char="5423">.</TOKEN>
</SEG>
<SEG end_char="5529" id="segment-50" start_char="5426">
<ORIGINAL_TEXT>Bin Cao, a pulmonary specialist at Capital Medical University in Beijing and the corresponding author of</ORIGINAL_TEXT>
<TOKEN end_char="5428" id="token-50-0" morph="none" pos="word" start_char="5426">Bin</TOKEN>
<TOKEN end_char="5432" id="token-50-1" morph="none" pos="word" start_char="5430">Cao</TOKEN>
<TOKEN end_char="5433" id="token-50-2" morph="none" pos="punct" start_char="5433">,</TOKEN>
<TOKEN end_char="5435" id="token-50-3" morph="none" pos="word" start_char="5435">a</TOKEN>
<TOKEN end_char="5445" id="token-50-4" morph="none" pos="word" start_char="5437">pulmonary</TOKEN>
<TOKEN end_char="5456" id="token-50-5" morph="none" pos="word" start_char="5447">specialist</TOKEN>
<TOKEN end_char="5459" id="token-50-6" morph="none" pos="word" start_char="5458">at</TOKEN>
<TOKEN end_char="5467" id="token-50-7" morph="none" pos="word" start_char="5461">Capital</TOKEN>
<TOKEN end_char="5475" id="token-50-8" morph="none" pos="word" start_char="5469">Medical</TOKEN>
<TOKEN end_char="5486" id="token-50-9" morph="none" pos="word" start_char="5477">University</TOKEN>
<TOKEN end_char="5489" id="token-50-10" morph="none" pos="word" start_char="5488">in</TOKEN>
<TOKEN end_char="5497" id="token-50-11" morph="none" pos="word" start_char="5491">Beijing</TOKEN>
<TOKEN end_char="5501" id="token-50-12" morph="none" pos="word" start_char="5499">and</TOKEN>
<TOKEN end_char="5505" id="token-50-13" morph="none" pos="word" start_char="5503">the</TOKEN>
<TOKEN end_char="5519" id="token-50-14" morph="none" pos="word" start_char="5507">corresponding</TOKEN>
<TOKEN end_char="5526" id="token-50-15" morph="none" pos="word" start_char="5521">author</TOKEN>
<TOKEN end_char="5529" id="token-50-16" morph="none" pos="word" start_char="5528">of</TOKEN>
</SEG>
<SEG end_char="5541" id="segment-51" start_char="5532">
<ORIGINAL_TEXT>The Lancet</ORIGINAL_TEXT>
<TOKEN end_char="5534" id="token-51-0" morph="none" pos="word" start_char="5532">The</TOKEN>
<TOKEN end_char="5541" id="token-51-1" morph="none" pos="word" start_char="5536">Lancet</TOKEN>
</SEG>
<SEG end_char="5607" id="segment-52" start_char="5544">
<ORIGINAL_TEXT>article, agrees the story is more complicated than many thought.</ORIGINAL_TEXT>
<TOKEN end_char="5550" id="token-52-0" morph="none" pos="word" start_char="5544">article</TOKEN>
<TOKEN end_char="5551" id="token-52-1" morph="none" pos="punct" start_char="5551">,</TOKEN>
<TOKEN end_char="5558" id="token-52-2" morph="none" pos="word" start_char="5553">agrees</TOKEN>
<TOKEN end_char="5562" id="token-52-3" morph="none" pos="word" start_char="5560">the</TOKEN>
<TOKEN end_char="5568" id="token-52-4" morph="none" pos="word" start_char="5564">story</TOKEN>
<TOKEN end_char="5571" id="token-52-5" morph="none" pos="word" start_char="5570">is</TOKEN>
<TOKEN end_char="5576" id="token-52-6" morph="none" pos="word" start_char="5573">more</TOKEN>
<TOKEN end_char="5588" id="token-52-7" morph="none" pos="word" start_char="5578">complicated</TOKEN>
<TOKEN end_char="5593" id="token-52-8" morph="none" pos="word" start_char="5590">than</TOKEN>
<TOKEN end_char="5598" id="token-52-9" morph="none" pos="word" start_char="5595">many</TOKEN>
<TOKEN end_char="5606" id="token-52-10" morph="none" pos="word" start_char="5600">thought</TOKEN>
<TOKEN end_char="5607" id="token-52-11" morph="none" pos="punct" start_char="5607">.</TOKEN>
</SEG>
<SEG end_char="5715" id="segment-53" start_char="5609">
<ORIGINAL_TEXT>"Now it seems clear that [the] seafood market is not the only origin of the virus," he wrote in an email to</ORIGINAL_TEXT>
<TOKEN end_char="5609" id="token-53-0" morph="none" pos="punct" start_char="5609">"</TOKEN>
<TOKEN end_char="5612" id="token-53-1" morph="none" pos="word" start_char="5610">Now</TOKEN>
<TOKEN end_char="5615" id="token-53-2" morph="none" pos="word" start_char="5614">it</TOKEN>
<TOKEN end_char="5621" id="token-53-3" morph="none" pos="word" start_char="5617">seems</TOKEN>
<TOKEN end_char="5627" id="token-53-4" morph="none" pos="word" start_char="5623">clear</TOKEN>
<TOKEN end_char="5632" id="token-53-5" morph="none" pos="word" start_char="5629">that</TOKEN>
<TOKEN end_char="5634" id="token-53-6" morph="none" pos="punct" start_char="5634">[</TOKEN>
<TOKEN end_char="5637" id="token-53-7" morph="none" pos="word" start_char="5635">the</TOKEN>
<TOKEN end_char="5638" id="token-53-8" morph="none" pos="punct" start_char="5638">]</TOKEN>
<TOKEN end_char="5646" id="token-53-9" morph="none" pos="word" start_char="5640">seafood</TOKEN>
<TOKEN end_char="5653" id="token-53-10" morph="none" pos="word" start_char="5648">market</TOKEN>
<TOKEN end_char="5656" id="token-53-11" morph="none" pos="word" start_char="5655">is</TOKEN>
<TOKEN end_char="5660" id="token-53-12" morph="none" pos="word" start_char="5658">not</TOKEN>
<TOKEN end_char="5664" id="token-53-13" morph="none" pos="word" start_char="5662">the</TOKEN>
<TOKEN end_char="5669" id="token-53-14" morph="none" pos="word" start_char="5666">only</TOKEN>
<TOKEN end_char="5676" id="token-53-15" morph="none" pos="word" start_char="5671">origin</TOKEN>
<TOKEN end_char="5679" id="token-53-16" morph="none" pos="word" start_char="5678">of</TOKEN>
<TOKEN end_char="5683" id="token-53-17" morph="none" pos="word" start_char="5681">the</TOKEN>
<TOKEN end_char="5689" id="token-53-18" morph="none" pos="word" start_char="5685">virus</TOKEN>
<TOKEN end_char="5691" id="token-53-19" morph="none" pos="punct" start_char="5690">,"</TOKEN>
<TOKEN end_char="5694" id="token-53-20" morph="none" pos="word" start_char="5693">he</TOKEN>
<TOKEN end_char="5700" id="token-53-21" morph="none" pos="word" start_char="5696">wrote</TOKEN>
<TOKEN end_char="5703" id="token-53-22" morph="none" pos="word" start_char="5702">in</TOKEN>
<TOKEN end_char="5706" id="token-53-23" morph="none" pos="word" start_char="5705">an</TOKEN>
<TOKEN end_char="5712" id="token-53-24" morph="none" pos="word" start_char="5708">email</TOKEN>
<TOKEN end_char="5715" id="token-53-25" morph="none" pos="word" start_char="5714">to</TOKEN>
</SEG>
<SEG end_char="5725" id="segment-54" start_char="5718">
<ORIGINAL_TEXT>Science.</ORIGINAL_TEXT>
<TOKEN end_char="5724" id="token-54-0" morph="none" pos="word" start_char="5718">Science</TOKEN>
<TOKEN end_char="5725" id="token-54-1" morph="none" pos="punct" start_char="5725">.</TOKEN>
<TRANSLATED_TEXT>Wissenschaft.</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="5798" id="segment-55" start_char="5728">
<ORIGINAL_TEXT>"But to be honest, we still do not know where the virus came from now."</ORIGINAL_TEXT>
<TOKEN end_char="5728" id="token-55-0" morph="none" pos="punct" start_char="5728">"</TOKEN>
<TOKEN end_char="5731" id="token-55-1" morph="none" pos="word" start_char="5729">But</TOKEN>
<TOKEN end_char="5734" id="token-55-2" morph="none" pos="word" start_char="5733">to</TOKEN>
<TOKEN end_char="5737" id="token-55-3" morph="none" pos="word" start_char="5736">be</TOKEN>
<TOKEN end_char="5744" id="token-55-4" morph="none" pos="word" start_char="5739">honest</TOKEN>
<TOKEN end_char="5745" id="token-55-5" morph="none" pos="punct" start_char="5745">,</TOKEN>
<TOKEN end_char="5748" id="token-55-6" morph="none" pos="word" start_char="5747">we</TOKEN>
<TOKEN end_char="5754" id="token-55-7" morph="none" pos="word" start_char="5750">still</TOKEN>
<TOKEN end_char="5757" id="token-55-8" morph="none" pos="word" start_char="5756">do</TOKEN>
<TOKEN end_char="5761" id="token-55-9" morph="none" pos="word" start_char="5759">not</TOKEN>
<TOKEN end_char="5766" id="token-55-10" morph="none" pos="word" start_char="5763">know</TOKEN>
<TOKEN end_char="5772" id="token-55-11" morph="none" pos="word" start_char="5768">where</TOKEN>
<TOKEN end_char="5776" id="token-55-12" morph="none" pos="word" start_char="5774">the</TOKEN>
<TOKEN end_char="5782" id="token-55-13" morph="none" pos="word" start_char="5778">virus</TOKEN>
<TOKEN end_char="5787" id="token-55-14" morph="none" pos="word" start_char="5784">came</TOKEN>
<TOKEN end_char="5792" id="token-55-15" morph="none" pos="word" start_char="5789">from</TOKEN>
<TOKEN end_char="5796" id="token-55-16" morph="none" pos="word" start_char="5794">now</TOKEN>
<TOKEN end_char="5798" id="token-55-17" morph="none" pos="punct" start_char="5797">."</TOKEN>
</SEG>
<SEG end_char="5826" id="segment-56" start_char="5801">
<ORIGINAL_TEXT>Could Existing Drugs Work?</ORIGINAL_TEXT>
<TOKEN end_char="5805" id="token-56-0" morph="none" pos="word" start_char="5801">Could</TOKEN>
<TOKEN end_char="5814" id="token-56-1" morph="none" pos="word" start_char="5807">Existing</TOKEN>
<TOKEN end_char="5820" id="token-56-2" morph="none" pos="word" start_char="5816">Drugs</TOKEN>
<TOKEN end_char="5825" id="token-56-3" morph="none" pos="word" start_char="5822">Work</TOKEN>
<TOKEN end_char="5826" id="token-56-4" morph="none" pos="punct" start_char="5826">?</TOKEN>
</SEG>
<SEG end_char="5951" id="segment-57" start_char="5830">
<ORIGINAL_TEXT>It may take years to develop treatments specifically designed for 2019-nCoV, but researchers hope existing drugs can help.</ORIGINAL_TEXT>
<TOKEN end_char="5831" id="token-57-0" morph="none" pos="word" start_char="5830">It</TOKEN>
<TOKEN end_char="5835" id="token-57-1" morph="none" pos="word" start_char="5833">may</TOKEN>
<TOKEN end_char="5840" id="token-57-2" morph="none" pos="word" start_char="5837">take</TOKEN>
<TOKEN end_char="5846" id="token-57-3" morph="none" pos="word" start_char="5842">years</TOKEN>
<TOKEN end_char="5849" id="token-57-4" morph="none" pos="word" start_char="5848">to</TOKEN>
<TOKEN end_char="5857" id="token-57-5" morph="none" pos="word" start_char="5851">develop</TOKEN>
<TOKEN end_char="5868" id="token-57-6" morph="none" pos="word" start_char="5859">treatments</TOKEN>
<TOKEN end_char="5881" id="token-57-7" morph="none" pos="word" start_char="5870">specifically</TOKEN>
<TOKEN end_char="5890" id="token-57-8" morph="none" pos="word" start_char="5883">designed</TOKEN>
<TOKEN end_char="5894" id="token-57-9" morph="none" pos="word" start_char="5892">for</TOKEN>
<TOKEN end_char="5904" id="token-57-10" morph="none" pos="unknown" start_char="5896">2019-nCoV</TOKEN>
<TOKEN end_char="5905" id="token-57-11" morph="none" pos="punct" start_char="5905">,</TOKEN>
<TOKEN end_char="5909" id="token-57-12" morph="none" pos="word" start_char="5907">but</TOKEN>
<TOKEN end_char="5921" id="token-57-13" morph="none" pos="word" start_char="5911">researchers</TOKEN>
<TOKEN end_char="5926" id="token-57-14" morph="none" pos="word" start_char="5923">hope</TOKEN>
<TOKEN end_char="5935" id="token-57-15" morph="none" pos="word" start_char="5928">existing</TOKEN>
<TOKEN end_char="5941" id="token-57-16" morph="none" pos="word" start_char="5937">drugs</TOKEN>
<TOKEN end_char="5945" id="token-57-17" morph="none" pos="word" start_char="5943">can</TOKEN>
<TOKEN end_char="5950" id="token-57-18" morph="none" pos="word" start_char="5947">help</TOKEN>
<TOKEN end_char="5951" id="token-57-19" morph="none" pos="punct" start_char="5951">.</TOKEN>
</SEG>
<SEG end_char="6119" id="segment-58" start_char="5953">
<ORIGINAL_TEXT>Wuhan's Jin Yintan Hospital has already launched a randomized, controlled trial of the anti-HIV drug combination of lopinavir and ritonavir, according to the report in</ORIGINAL_TEXT>
<TOKEN end_char="5959" id="token-58-0" morph="none" pos="word" start_char="5953">Wuhan's</TOKEN>
<TOKEN end_char="5963" id="token-58-1" morph="none" pos="word" start_char="5961">Jin</TOKEN>
<TOKEN end_char="5970" id="token-58-2" morph="none" pos="word" start_char="5965">Yintan</TOKEN>
<TOKEN end_char="5979" id="token-58-3" morph="none" pos="word" start_char="5972">Hospital</TOKEN>
<TOKEN end_char="5983" id="token-58-4" morph="none" pos="word" start_char="5981">has</TOKEN>
<TOKEN end_char="5991" id="token-58-5" morph="none" pos="word" start_char="5985">already</TOKEN>
<TOKEN end_char="6000" id="token-58-6" morph="none" pos="word" start_char="5993">launched</TOKEN>
<TOKEN end_char="6002" id="token-58-7" morph="none" pos="word" start_char="6002">a</TOKEN>
<TOKEN end_char="6013" id="token-58-8" morph="none" pos="word" start_char="6004">randomized</TOKEN>
<TOKEN end_char="6014" id="token-58-9" morph="none" pos="punct" start_char="6014">,</TOKEN>
<TOKEN end_char="6025" id="token-58-10" morph="none" pos="word" start_char="6016">controlled</TOKEN>
<TOKEN end_char="6031" id="token-58-11" morph="none" pos="word" start_char="6027">trial</TOKEN>
<TOKEN end_char="6034" id="token-58-12" morph="none" pos="word" start_char="6033">of</TOKEN>
<TOKEN end_char="6038" id="token-58-13" morph="none" pos="word" start_char="6036">the</TOKEN>
<TOKEN end_char="6047" id="token-58-14" morph="none" pos="unknown" start_char="6040">anti-HIV</TOKEN>
<TOKEN end_char="6052" id="token-58-15" morph="none" pos="word" start_char="6049">drug</TOKEN>
<TOKEN end_char="6064" id="token-58-16" morph="none" pos="word" start_char="6054">combination</TOKEN>
<TOKEN end_char="6067" id="token-58-17" morph="none" pos="word" start_char="6066">of</TOKEN>
<TOKEN end_char="6077" id="token-58-18" morph="none" pos="word" start_char="6069">lopinavir</TOKEN>
<TOKEN end_char="6081" id="token-58-19" morph="none" pos="word" start_char="6079">and</TOKEN>
<TOKEN end_char="6091" id="token-58-20" morph="none" pos="word" start_char="6083">ritonavir</TOKEN>
<TOKEN end_char="6092" id="token-58-21" morph="none" pos="punct" start_char="6092">,</TOKEN>
<TOKEN end_char="6102" id="token-58-22" morph="none" pos="word" start_char="6094">according</TOKEN>
<TOKEN end_char="6105" id="token-58-23" morph="none" pos="word" start_char="6104">to</TOKEN>
<TOKEN end_char="6109" id="token-58-24" morph="none" pos="word" start_char="6107">the</TOKEN>
<TOKEN end_char="6116" id="token-58-25" morph="none" pos="word" start_char="6111">report</TOKEN>
<TOKEN end_char="6119" id="token-58-26" morph="none" pos="word" start_char="6118">in</TOKEN>
</SEG>
<SEG end_char="6132" id="segment-59" start_char="6122">
<ORIGINAL_TEXT>The Lancet.</ORIGINAL_TEXT>
<TOKEN end_char="6124" id="token-59-0" morph="none" pos="word" start_char="6122">The</TOKEN>
<TOKEN end_char="6131" id="token-59-1" morph="none" pos="word" start_char="6126">Lancet</TOKEN>
<TOKEN end_char="6132" id="token-59-2" morph="none" pos="punct" start_char="6132">.</TOKEN>
</SEG>
<SEG end_char="6253" id="segment-60" start_char="6135">
<ORIGINAL_TEXT>The duo targets the protease enzyme used by HIV to copy itself, and it might thwart the coronavirus's protease as well.</ORIGINAL_TEXT>
<TOKEN end_char="6137" id="token-60-0" morph="none" pos="word" start_char="6135">The</TOKEN>
<TOKEN end_char="6141" id="token-60-1" morph="none" pos="word" start_char="6139">duo</TOKEN>
<TOKEN end_char="6149" id="token-60-2" morph="none" pos="word" start_char="6143">targets</TOKEN>
<TOKEN end_char="6153" id="token-60-3" morph="none" pos="word" start_char="6151">the</TOKEN>
<TOKEN end_char="6162" id="token-60-4" morph="none" pos="word" start_char="6155">protease</TOKEN>
<TOKEN end_char="6169" id="token-60-5" morph="none" pos="word" start_char="6164">enzyme</TOKEN>
<TOKEN end_char="6174" id="token-60-6" morph="none" pos="word" start_char="6171">used</TOKEN>
<TOKEN end_char="6177" id="token-60-7" morph="none" pos="word" start_char="6176">by</TOKEN>
<TOKEN end_char="6181" id="token-60-8" morph="none" pos="word" start_char="6179">HIV</TOKEN>
<TOKEN end_char="6184" id="token-60-9" morph="none" pos="word" start_char="6183">to</TOKEN>
<TOKEN end_char="6189" id="token-60-10" morph="none" pos="word" start_char="6186">copy</TOKEN>
<TOKEN end_char="6196" id="token-60-11" morph="none" pos="word" start_char="6191">itself</TOKEN>
<TOKEN end_char="6197" id="token-60-12" morph="none" pos="punct" start_char="6197">,</TOKEN>
<TOKEN end_char="6201" id="token-60-13" morph="none" pos="word" start_char="6199">and</TOKEN>
<TOKEN end_char="6204" id="token-60-14" morph="none" pos="word" start_char="6203">it</TOKEN>
<TOKEN end_char="6210" id="token-60-15" morph="none" pos="word" start_char="6206">might</TOKEN>
<TOKEN end_char="6217" id="token-60-16" morph="none" pos="word" start_char="6212">thwart</TOKEN>
<TOKEN end_char="6221" id="token-60-17" morph="none" pos="word" start_char="6219">the</TOKEN>
<TOKEN end_char="6235" id="token-60-18" morph="none" pos="word" start_char="6223">coronavirus's</TOKEN>
<TOKEN end_char="6244" id="token-60-19" morph="none" pos="word" start_char="6237">protease</TOKEN>
<TOKEN end_char="6247" id="token-60-20" morph="none" pos="word" start_char="6246">as</TOKEN>
<TOKEN end_char="6252" id="token-60-21" morph="none" pos="word" start_char="6249">well</TOKEN>
<TOKEN end_char="6253" id="token-60-22" morph="none" pos="punct" start_char="6253">.</TOKEN>
</SEG>
<SEG end_char="6484" id="segment-61" start_char="6255">
<ORIGINAL_TEXT>There's a precedent from the SARS outbreak: In a nonrandomized trial published in 2004, researchers saw an "apparent improved outcome" from the same two protease inhibitors, combined with a third drug, ribavirin, in SARS patients.</ORIGINAL_TEXT>
<TOKEN end_char="6261" id="token-61-0" morph="none" pos="word" start_char="6255">There's</TOKEN>
<TOKEN end_char="6263" id="token-61-1" morph="none" pos="word" start_char="6263">a</TOKEN>
<TOKEN end_char="6273" id="token-61-2" morph="none" pos="word" start_char="6265">precedent</TOKEN>
<TOKEN end_char="6278" id="token-61-3" morph="none" pos="word" start_char="6275">from</TOKEN>
<TOKEN end_char="6282" id="token-61-4" morph="none" pos="word" start_char="6280">the</TOKEN>
<TOKEN end_char="6287" id="token-61-5" morph="none" pos="word" start_char="6284">SARS</TOKEN>
<TOKEN end_char="6296" id="token-61-6" morph="none" pos="word" start_char="6289">outbreak</TOKEN>
<TOKEN end_char="6297" id="token-61-7" morph="none" pos="punct" start_char="6297">:</TOKEN>
<TOKEN end_char="6300" id="token-61-8" morph="none" pos="word" start_char="6299">In</TOKEN>
<TOKEN end_char="6302" id="token-61-9" morph="none" pos="word" start_char="6302">a</TOKEN>
<TOKEN end_char="6316" id="token-61-10" morph="none" pos="word" start_char="6304">nonrandomized</TOKEN>
<TOKEN end_char="6322" id="token-61-11" morph="none" pos="word" start_char="6318">trial</TOKEN>
<TOKEN end_char="6332" id="token-61-12" morph="none" pos="word" start_char="6324">published</TOKEN>
<TOKEN end_char="6335" id="token-61-13" morph="none" pos="word" start_char="6334">in</TOKEN>
<TOKEN end_char="6340" id="token-61-14" morph="none" pos="word" start_char="6337">2004</TOKEN>
<TOKEN end_char="6341" id="token-61-15" morph="none" pos="punct" start_char="6341">,</TOKEN>
<TOKEN end_char="6353" id="token-61-16" morph="none" pos="word" start_char="6343">researchers</TOKEN>
<TOKEN end_char="6357" id="token-61-17" morph="none" pos="word" start_char="6355">saw</TOKEN>
<TOKEN end_char="6360" id="token-61-18" morph="none" pos="word" start_char="6359">an</TOKEN>
<TOKEN end_char="6362" id="token-61-19" morph="none" pos="punct" start_char="6362">"</TOKEN>
<TOKEN end_char="6370" id="token-61-20" morph="none" pos="word" start_char="6363">apparent</TOKEN>
<TOKEN end_char="6379" id="token-61-21" morph="none" pos="word" start_char="6372">improved</TOKEN>
<TOKEN end_char="6387" id="token-61-22" morph="none" pos="word" start_char="6381">outcome</TOKEN>
<TOKEN end_char="6388" id="token-61-23" morph="none" pos="punct" start_char="6388">"</TOKEN>
<TOKEN end_char="6393" id="token-61-24" morph="none" pos="word" start_char="6390">from</TOKEN>
<TOKEN end_char="6397" id="token-61-25" morph="none" pos="word" start_char="6395">the</TOKEN>
<TOKEN end_char="6402" id="token-61-26" morph="none" pos="word" start_char="6399">same</TOKEN>
<TOKEN end_char="6406" id="token-61-27" morph="none" pos="word" start_char="6404">two</TOKEN>
<TOKEN end_char="6415" id="token-61-28" morph="none" pos="word" start_char="6408">protease</TOKEN>
<TOKEN end_char="6426" id="token-61-29" morph="none" pos="word" start_char="6417">inhibitors</TOKEN>
<TOKEN end_char="6427" id="token-61-30" morph="none" pos="punct" start_char="6427">,</TOKEN>
<TOKEN end_char="6436" id="token-61-31" morph="none" pos="word" start_char="6429">combined</TOKEN>
<TOKEN end_char="6441" id="token-61-32" morph="none" pos="word" start_char="6438">with</TOKEN>
<TOKEN end_char="6443" id="token-61-33" morph="none" pos="word" start_char="6443">a</TOKEN>
<TOKEN end_char="6449" id="token-61-34" morph="none" pos="word" start_char="6445">third</TOKEN>
<TOKEN end_char="6454" id="token-61-35" morph="none" pos="word" start_char="6451">drug</TOKEN>
<TOKEN end_char="6455" id="token-61-36" morph="none" pos="punct" start_char="6455">,</TOKEN>
<TOKEN end_char="6465" id="token-61-37" morph="none" pos="word" start_char="6457">ribavirin</TOKEN>
<TOKEN end_char="6466" id="token-61-38" morph="none" pos="punct" start_char="6466">,</TOKEN>
<TOKEN end_char="6469" id="token-61-39" morph="none" pos="word" start_char="6468">in</TOKEN>
<TOKEN end_char="6474" id="token-61-40" morph="none" pos="word" start_char="6471">SARS</TOKEN>
<TOKEN end_char="6483" id="token-61-41" morph="none" pos="word" start_char="6476">patients</TOKEN>
<TOKEN end_char="6484" id="token-61-42" morph="none" pos="punct" start_char="6484">.</TOKEN>
</SEG>
<SEG end_char="6735" id="segment-62" start_char="6487">
<ORIGINAL_TEXT>Saudi Arabia is now conducting a trial with the same protease inhibitors, combined with interferon beta-1b, against Middle East respiratory syndrome (MERS), a coronavirus distantly related to SARS and 2019-nCoV that is occasionally spread by camels.</ORIGINAL_TEXT>
<TOKEN end_char="6491" id="token-62-0" morph="none" pos="word" start_char="6487">Saudi</TOKEN>
<TOKEN end_char="6498" id="token-62-1" morph="none" pos="word" start_char="6493">Arabia</TOKEN>
<TOKEN end_char="6501" id="token-62-2" morph="none" pos="word" start_char="6500">is</TOKEN>
<TOKEN end_char="6505" id="token-62-3" morph="none" pos="word" start_char="6503">now</TOKEN>
<TOKEN end_char="6516" id="token-62-4" morph="none" pos="word" start_char="6507">conducting</TOKEN>
<TOKEN end_char="6518" id="token-62-5" morph="none" pos="word" start_char="6518">a</TOKEN>
<TOKEN end_char="6524" id="token-62-6" morph="none" pos="word" start_char="6520">trial</TOKEN>
<TOKEN end_char="6529" id="token-62-7" morph="none" pos="word" start_char="6526">with</TOKEN>
<TOKEN end_char="6533" id="token-62-8" morph="none" pos="word" start_char="6531">the</TOKEN>
<TOKEN end_char="6538" id="token-62-9" morph="none" pos="word" start_char="6535">same</TOKEN>
<TOKEN end_char="6547" id="token-62-10" morph="none" pos="word" start_char="6540">protease</TOKEN>
<TOKEN end_char="6558" id="token-62-11" morph="none" pos="word" start_char="6549">inhibitors</TOKEN>
<TOKEN end_char="6559" id="token-62-12" morph="none" pos="punct" start_char="6559">,</TOKEN>
<TOKEN end_char="6568" id="token-62-13" morph="none" pos="word" start_char="6561">combined</TOKEN>
<TOKEN end_char="6573" id="token-62-14" morph="none" pos="word" start_char="6570">with</TOKEN>
<TOKEN end_char="6584" id="token-62-15" morph="none" pos="word" start_char="6575">interferon</TOKEN>
<TOKEN end_char="6592" id="token-62-16" morph="none" pos="unknown" start_char="6586">beta-1b</TOKEN>
<TOKEN end_char="6593" id="token-62-17" morph="none" pos="punct" start_char="6593">,</TOKEN>
<TOKEN end_char="6601" id="token-62-18" morph="none" pos="word" start_char="6595">against</TOKEN>
<TOKEN end_char="6608" id="token-62-19" morph="none" pos="word" start_char="6603">Middle</TOKEN>
<TOKEN end_char="6613" id="token-62-20" morph="none" pos="word" start_char="6610">East</TOKEN>
<TOKEN end_char="6625" id="token-62-21" morph="none" pos="word" start_char="6615">respiratory</TOKEN>
<TOKEN end_char="6634" id="token-62-22" morph="none" pos="word" start_char="6627">syndrome</TOKEN>
<TOKEN end_char="6636" id="token-62-23" morph="none" pos="punct" start_char="6636">(</TOKEN>
<TOKEN end_char="6640" id="token-62-24" morph="none" pos="word" start_char="6637">MERS</TOKEN>
<TOKEN end_char="6642" id="token-62-25" morph="none" pos="punct" start_char="6641">),</TOKEN>
<TOKEN end_char="6644" id="token-62-26" morph="none" pos="word" start_char="6644">a</TOKEN>
<TOKEN end_char="6656" id="token-62-27" morph="none" pos="word" start_char="6646">coronavirus</TOKEN>
<TOKEN end_char="6666" id="token-62-28" morph="none" pos="word" start_char="6658">distantly</TOKEN>
<TOKEN end_char="6674" id="token-62-29" morph="none" pos="word" start_char="6668">related</TOKEN>
<TOKEN end_char="6677" id="token-62-30" morph="none" pos="word" start_char="6676">to</TOKEN>
<TOKEN end_char="6682" id="token-62-31" morph="none" pos="word" start_char="6679">SARS</TOKEN>
<TOKEN end_char="6686" id="token-62-32" morph="none" pos="word" start_char="6684">and</TOKEN>
<TOKEN end_char="6696" id="token-62-33" morph="none" pos="unknown" start_char="6688">2019-nCoV</TOKEN>
<TOKEN end_char="6701" id="token-62-34" morph="none" pos="word" start_char="6698">that</TOKEN>
<TOKEN end_char="6704" id="token-62-35" morph="none" pos="word" start_char="6703">is</TOKEN>
<TOKEN end_char="6717" id="token-62-36" morph="none" pos="word" start_char="6706">occasionally</TOKEN>
<TOKEN end_char="6724" id="token-62-37" morph="none" pos="word" start_char="6719">spread</TOKEN>
<TOKEN end_char="6727" id="token-62-38" morph="none" pos="word" start_char="6726">by</TOKEN>
<TOKEN end_char="6734" id="token-62-39" morph="none" pos="word" start_char="6729">camels</TOKEN>
<TOKEN end_char="6735" id="token-62-40" morph="none" pos="punct" start_char="6735">.</TOKEN>
</SEG>
<SEG end_char="6879" id="segment-63" start_char="6737">
<ORIGINAL_TEXT>But in a recent mouse study by Ralph Baric of the University of North Carolina, Chapel Hill, this cocktail had lackluster results against MERS.</ORIGINAL_TEXT>
<TOKEN end_char="6739" id="token-63-0" morph="none" pos="word" start_char="6737">But</TOKEN>
<TOKEN end_char="6742" id="token-63-1" morph="none" pos="word" start_char="6741">in</TOKEN>
<TOKEN end_char="6744" id="token-63-2" morph="none" pos="word" start_char="6744">a</TOKEN>
<TOKEN end_char="6751" id="token-63-3" morph="none" pos="word" start_char="6746">recent</TOKEN>
<TOKEN end_char="6757" id="token-63-4" morph="none" pos="word" start_char="6753">mouse</TOKEN>
<TOKEN end_char="6763" id="token-63-5" morph="none" pos="word" start_char="6759">study</TOKEN>
<TOKEN end_char="6766" id="token-63-6" morph="none" pos="word" start_char="6765">by</TOKEN>
<TOKEN end_char="6772" id="token-63-7" morph="none" pos="word" start_char="6768">Ralph</TOKEN>
<TOKEN end_char="6778" id="token-63-8" morph="none" pos="word" start_char="6774">Baric</TOKEN>
<TOKEN end_char="6781" id="token-63-9" morph="none" pos="word" start_char="6780">of</TOKEN>
<TOKEN end_char="6785" id="token-63-10" morph="none" pos="word" start_char="6783">the</TOKEN>
<TOKEN end_char="6796" id="token-63-11" morph="none" pos="word" start_char="6787">University</TOKEN>
<TOKEN end_char="6799" id="token-63-12" morph="none" pos="word" start_char="6798">of</TOKEN>
<TOKEN end_char="6805" id="token-63-13" morph="none" pos="word" start_char="6801">North</TOKEN>
<TOKEN end_char="6814" id="token-63-14" morph="none" pos="word" start_char="6807">Carolina</TOKEN>
<TOKEN end_char="6815" id="token-63-15" morph="none" pos="punct" start_char="6815">,</TOKEN>
<TOKEN end_char="6822" id="token-63-16" morph="none" pos="word" start_char="6817">Chapel</TOKEN>
<TOKEN end_char="6827" id="token-63-17" morph="none" pos="word" start_char="6824">Hill</TOKEN>
<TOKEN end_char="6828" id="token-63-18" morph="none" pos="punct" start_char="6828">,</TOKEN>
<TOKEN end_char="6833" id="token-63-19" morph="none" pos="word" start_char="6830">this</TOKEN>
<TOKEN end_char="6842" id="token-63-20" morph="none" pos="word" start_char="6835">cocktail</TOKEN>
<TOKEN end_char="6846" id="token-63-21" morph="none" pos="word" start_char="6844">had</TOKEN>
<TOKEN end_char="6857" id="token-63-22" morph="none" pos="word" start_char="6848">lackluster</TOKEN>
<TOKEN end_char="6865" id="token-63-23" morph="none" pos="word" start_char="6859">results</TOKEN>
<TOKEN end_char="6873" id="token-63-24" morph="none" pos="word" start_char="6867">against</TOKEN>
<TOKEN end_char="6878" id="token-63-25" morph="none" pos="word" start_char="6875">MERS</TOKEN>
<TOKEN end_char="6879" id="token-63-26" morph="none" pos="punct" start_char="6879">.</TOKEN>
</SEG>
<SEG end_char="7056" id="segment-64" start_char="6882">
<ORIGINAL_TEXT>The same study showed better outcomes for remdesivir, an experimental drug made by Gilead and previously tested against Ebola that interferes with the viral polymerase enzyme.</ORIGINAL_TEXT>
<TOKEN end_char="6884" id="token-64-0" morph="none" pos="word" start_char="6882">The</TOKEN>
<TOKEN end_char="6889" id="token-64-1" morph="none" pos="word" start_char="6886">same</TOKEN>
<TOKEN end_char="6895" id="token-64-2" morph="none" pos="word" start_char="6891">study</TOKEN>
<TOKEN end_char="6902" id="token-64-3" morph="none" pos="word" start_char="6897">showed</TOKEN>
<TOKEN end_char="6909" id="token-64-4" morph="none" pos="word" start_char="6904">better</TOKEN>
<TOKEN end_char="6918" id="token-64-5" morph="none" pos="word" start_char="6911">outcomes</TOKEN>
<TOKEN end_char="6922" id="token-64-6" morph="none" pos="word" start_char="6920">for</TOKEN>
<TOKEN end_char="6933" id="token-64-7" morph="none" pos="word" start_char="6924">remdesivir</TOKEN>
<TOKEN end_char="6934" id="token-64-8" morph="none" pos="punct" start_char="6934">,</TOKEN>
<TOKEN end_char="6937" id="token-64-9" morph="none" pos="word" start_char="6936">an</TOKEN>
<TOKEN end_char="6950" id="token-64-10" morph="none" pos="word" start_char="6939">experimental</TOKEN>
<TOKEN end_char="6955" id="token-64-11" morph="none" pos="word" start_char="6952">drug</TOKEN>
<TOKEN end_char="6960" id="token-64-12" morph="none" pos="word" start_char="6957">made</TOKEN>
<TOKEN end_char="6963" id="token-64-13" morph="none" pos="word" start_char="6962">by</TOKEN>
<TOKEN end_char="6970" id="token-64-14" morph="none" pos="word" start_char="6965">Gilead</TOKEN>
<TOKEN end_char="6974" id="token-64-15" morph="none" pos="word" start_char="6972">and</TOKEN>
<TOKEN end_char="6985" id="token-64-16" morph="none" pos="word" start_char="6976">previously</TOKEN>
<TOKEN end_char="6992" id="token-64-17" morph="none" pos="word" start_char="6987">tested</TOKEN>
<TOKEN end_char="7000" id="token-64-18" morph="none" pos="word" start_char="6994">against</TOKEN>
<TOKEN end_char="7006" id="token-64-19" morph="none" pos="word" start_char="7002">Ebola</TOKEN>
<TOKEN end_char="7011" id="token-64-20" morph="none" pos="word" start_char="7008">that</TOKEN>
<TOKEN end_char="7022" id="token-64-21" morph="none" pos="word" start_char="7013">interferes</TOKEN>
<TOKEN end_char="7027" id="token-64-22" morph="none" pos="word" start_char="7024">with</TOKEN>
<TOKEN end_char="7031" id="token-64-23" morph="none" pos="word" start_char="7029">the</TOKEN>
<TOKEN end_char="7037" id="token-64-24" morph="none" pos="word" start_char="7033">viral</TOKEN>
<TOKEN end_char="7048" id="token-64-25" morph="none" pos="word" start_char="7039">polymerase</TOKEN>
<TOKEN end_char="7055" id="token-64-26" morph="none" pos="word" start_char="7050">enzyme</TOKEN>
<TOKEN end_char="7056" id="token-64-27" morph="none" pos="punct" start_char="7056">.</TOKEN>
</SEG>
<SEG end_char="7174" id="segment-65" start_char="7058">
<ORIGINAL_TEXT>Remdesivir combined with interferon slowed viral replication in MERS-infected mice, and their lung function improved.</ORIGINAL_TEXT>
<TOKEN end_char="7067" id="token-65-0" morph="none" pos="word" start_char="7058">Remdesivir</TOKEN>
<TOKEN end_char="7076" id="token-65-1" morph="none" pos="word" start_char="7069">combined</TOKEN>
<TOKEN end_char="7081" id="token-65-2" morph="none" pos="word" start_char="7078">with</TOKEN>
<TOKEN end_char="7092" id="token-65-3" morph="none" pos="word" start_char="7083">interferon</TOKEN>
<TOKEN end_char="7099" id="token-65-4" morph="none" pos="word" start_char="7094">slowed</TOKEN>
<TOKEN end_char="7105" id="token-65-5" morph="none" pos="word" start_char="7101">viral</TOKEN>
<TOKEN end_char="7117" id="token-65-6" morph="none" pos="word" start_char="7107">replication</TOKEN>
<TOKEN end_char="7120" id="token-65-7" morph="none" pos="word" start_char="7119">in</TOKEN>
<TOKEN end_char="7134" id="token-65-8" morph="none" pos="unknown" start_char="7122">MERS-infected</TOKEN>
<TOKEN end_char="7139" id="token-65-9" morph="none" pos="word" start_char="7136">mice</TOKEN>
<TOKEN end_char="7140" id="token-65-10" morph="none" pos="punct" start_char="7140">,</TOKEN>
<TOKEN end_char="7144" id="token-65-11" morph="none" pos="word" start_char="7142">and</TOKEN>
<TOKEN end_char="7150" id="token-65-12" morph="none" pos="word" start_char="7146">their</TOKEN>
<TOKEN end_char="7155" id="token-65-13" morph="none" pos="word" start_char="7152">lung</TOKEN>
<TOKEN end_char="7164" id="token-65-14" morph="none" pos="word" start_char="7157">function</TOKEN>
<TOKEN end_char="7173" id="token-65-15" morph="none" pos="word" start_char="7166">improved</TOKEN>
<TOKEN end_char="7174" id="token-65-16" morph="none" pos="punct" start_char="7174">.</TOKEN>
</SEG>
<SEG end_char="7379" id="segment-66" start_char="7176">
<ORIGINAL_TEXT>"Remdesivir has had activity against every coronavirus we've tested, and I'd be surprised if it didn't have activity against" 2019-nCoV, says co-author Mark Denison, a virologist at Vanderbilt University.</ORIGINAL_TEXT>
<TOKEN end_char="7176" id="token-66-0" morph="none" pos="punct" start_char="7176">"</TOKEN>
<TOKEN end_char="7186" id="token-66-1" morph="none" pos="word" start_char="7177">Remdesivir</TOKEN>
<TOKEN end_char="7190" id="token-66-2" morph="none" pos="word" start_char="7188">has</TOKEN>
<TOKEN end_char="7194" id="token-66-3" morph="none" pos="word" start_char="7192">had</TOKEN>
<TOKEN end_char="7203" id="token-66-4" morph="none" pos="word" start_char="7196">activity</TOKEN>
<TOKEN end_char="7211" id="token-66-5" morph="none" pos="word" start_char="7205">against</TOKEN>
<TOKEN end_char="7217" id="token-66-6" morph="none" pos="word" start_char="7213">every</TOKEN>
<TOKEN end_char="7229" id="token-66-7" morph="none" pos="word" start_char="7219">coronavirus</TOKEN>
<TOKEN end_char="7235" id="token-66-8" morph="none" pos="word" start_char="7231">we've</TOKEN>
<TOKEN end_char="7242" id="token-66-9" morph="none" pos="word" start_char="7237">tested</TOKEN>
<TOKEN end_char="7243" id="token-66-10" morph="none" pos="punct" start_char="7243">,</TOKEN>
<TOKEN end_char="7247" id="token-66-11" morph="none" pos="word" start_char="7245">and</TOKEN>
<TOKEN end_char="7251" id="token-66-12" morph="none" pos="word" start_char="7249">I'd</TOKEN>
<TOKEN end_char="7254" id="token-66-13" morph="none" pos="word" start_char="7253">be</TOKEN>
<TOKEN end_char="7264" id="token-66-14" morph="none" pos="word" start_char="7256">surprised</TOKEN>
<TOKEN end_char="7267" id="token-66-15" morph="none" pos="word" start_char="7266">if</TOKEN>
<TOKEN end_char="7270" id="token-66-16" morph="none" pos="word" start_char="7269">it</TOKEN>
<TOKEN end_char="7277" id="token-66-17" morph="none" pos="word" start_char="7272">didn't</TOKEN>
<TOKEN end_char="7282" id="token-66-18" morph="none" pos="word" start_char="7279">have</TOKEN>
<TOKEN end_char="7291" id="token-66-19" morph="none" pos="word" start_char="7284">activity</TOKEN>
<TOKEN end_char="7299" id="token-66-20" morph="none" pos="word" start_char="7293">against</TOKEN>
<TOKEN end_char="7300" id="token-66-21" morph="none" pos="punct" start_char="7300">"</TOKEN>
<TOKEN end_char="7310" id="token-66-22" morph="none" pos="unknown" start_char="7302">2019-nCoV</TOKEN>
<TOKEN end_char="7311" id="token-66-23" morph="none" pos="punct" start_char="7311">,</TOKEN>
<TOKEN end_char="7316" id="token-66-24" morph="none" pos="word" start_char="7313">says</TOKEN>
<TOKEN end_char="7326" id="token-66-25" morph="none" pos="unknown" start_char="7318">co-author</TOKEN>
<TOKEN end_char="7331" id="token-66-26" morph="none" pos="word" start_char="7328">Mark</TOKEN>
<TOKEN end_char="7339" id="token-66-27" morph="none" pos="word" start_char="7333">Denison</TOKEN>
<TOKEN end_char="7340" id="token-66-28" morph="none" pos="punct" start_char="7340">,</TOKEN>
<TOKEN end_char="7342" id="token-66-29" morph="none" pos="word" start_char="7342">a</TOKEN>
<TOKEN end_char="7353" id="token-66-30" morph="none" pos="word" start_char="7344">virologist</TOKEN>
<TOKEN end_char="7356" id="token-66-31" morph="none" pos="word" start_char="7355">at</TOKEN>
<TOKEN end_char="7367" id="token-66-32" morph="none" pos="word" start_char="7358">Vanderbilt</TOKEN>
<TOKEN end_char="7378" id="token-66-33" morph="none" pos="word" start_char="7369">University</TOKEN>
<TOKEN end_char="7379" id="token-66-34" morph="none" pos="punct" start_char="7379">.</TOKEN>
</SEG>
<SEG end_char="7440" id="segment-67" start_char="7382">
<ORIGINAL_TEXT>Development of entirely new treatments has started as well.</ORIGINAL_TEXT>
<TOKEN end_char="7392" id="token-67-0" morph="none" pos="word" start_char="7382">Development</TOKEN>
<TOKEN end_char="7395" id="token-67-1" morph="none" pos="word" start_char="7394">of</TOKEN>
<TOKEN end_char="7404" id="token-67-2" morph="none" pos="word" start_char="7397">entirely</TOKEN>
<TOKEN end_char="7408" id="token-67-3" morph="none" pos="word" start_char="7406">new</TOKEN>
<TOKEN end_char="7419" id="token-67-4" morph="none" pos="word" start_char="7410">treatments</TOKEN>
<TOKEN end_char="7423" id="token-67-5" morph="none" pos="word" start_char="7421">has</TOKEN>
<TOKEN end_char="7431" id="token-67-6" morph="none" pos="word" start_char="7425">started</TOKEN>
<TOKEN end_char="7434" id="token-67-7" morph="none" pos="word" start_char="7433">as</TOKEN>
<TOKEN end_char="7439" id="token-67-8" morph="none" pos="word" start_char="7436">well</TOKEN>
<TOKEN end_char="7440" id="token-67-9" morph="none" pos="punct" start_char="7440">.</TOKEN>
</SEG>
<SEG end_char="7577" id="segment-68" start_char="7442">
<ORIGINAL_TEXT>U.S. biotech Regeneron is trying to identify monoclonal antibodies effective against 2019-nCoV, as it did previously for MERS and Ebola.</ORIGINAL_TEXT>
<TOKEN end_char="7444" id="token-68-0" morph="none" pos="unknown" start_char="7442">U.S</TOKEN>
<TOKEN end_char="7445" id="token-68-1" morph="none" pos="punct" start_char="7445">.</TOKEN>
<TOKEN end_char="7453" id="token-68-2" morph="none" pos="word" start_char="7447">biotech</TOKEN>
<TOKEN end_char="7463" id="token-68-3" morph="none" pos="word" start_char="7455">Regeneron</TOKEN>
<TOKEN end_char="7466" id="token-68-4" morph="none" pos="word" start_char="7465">is</TOKEN>
<TOKEN end_char="7473" id="token-68-5" morph="none" pos="word" start_char="7468">trying</TOKEN>
<TOKEN end_char="7476" id="token-68-6" morph="none" pos="word" start_char="7475">to</TOKEN>
<TOKEN end_char="7485" id="token-68-7" morph="none" pos="word" start_char="7478">identify</TOKEN>
<TOKEN end_char="7496" id="token-68-8" morph="none" pos="word" start_char="7487">monoclonal</TOKEN>
<TOKEN end_char="7507" id="token-68-9" morph="none" pos="word" start_char="7498">antibodies</TOKEN>
<TOKEN end_char="7517" id="token-68-10" morph="none" pos="word" start_char="7509">effective</TOKEN>
<TOKEN end_char="7525" id="token-68-11" morph="none" pos="word" start_char="7519">against</TOKEN>
<TOKEN end_char="7535" id="token-68-12" morph="none" pos="unknown" start_char="7527">2019-nCoV</TOKEN>
<TOKEN end_char="7536" id="token-68-13" morph="none" pos="punct" start_char="7536">,</TOKEN>
<TOKEN end_char="7539" id="token-68-14" morph="none" pos="word" start_char="7538">as</TOKEN>
<TOKEN end_char="7542" id="token-68-15" morph="none" pos="word" start_char="7541">it</TOKEN>
<TOKEN end_char="7546" id="token-68-16" morph="none" pos="word" start_char="7544">did</TOKEN>
<TOKEN end_char="7557" id="token-68-17" morph="none" pos="word" start_char="7548">previously</TOKEN>
<TOKEN end_char="7561" id="token-68-18" morph="none" pos="word" start_char="7559">for</TOKEN>
<TOKEN end_char="7566" id="token-68-19" morph="none" pos="word" start_char="7563">MERS</TOKEN>
<TOKEN end_char="7570" id="token-68-20" morph="none" pos="word" start_char="7568">and</TOKEN>
<TOKEN end_char="7576" id="token-68-21" morph="none" pos="word" start_char="7572">Ebola</TOKEN>
<TOKEN end_char="7577" id="token-68-22" morph="none" pos="punct" start_char="7577">.</TOKEN>
</SEG>
<SEG end_char="7688" id="segment-69" start_char="7579">
<ORIGINAL_TEXT>The ideal treatment for 2019-nCoV may well be a drug like remdesivir plus monoclonal antibodies, Denison says.</ORIGINAL_TEXT>
<TOKEN end_char="7581" id="token-69-0" morph="none" pos="word" start_char="7579">The</TOKEN>
<TOKEN end_char="7587" id="token-69-1" morph="none" pos="word" start_char="7583">ideal</TOKEN>
<TOKEN end_char="7597" id="token-69-2" morph="none" pos="word" start_char="7589">treatment</TOKEN>
<TOKEN end_char="7601" id="token-69-3" morph="none" pos="word" start_char="7599">for</TOKEN>
<TOKEN end_char="7611" id="token-69-4" morph="none" pos="unknown" start_char="7603">2019-nCoV</TOKEN>
<TOKEN end_char="7615" id="token-69-5" morph="none" pos="word" start_char="7613">may</TOKEN>
<TOKEN end_char="7620" id="token-69-6" morph="none" pos="word" start_char="7617">well</TOKEN>
<TOKEN end_char="7623" id="token-69-7" morph="none" pos="word" start_char="7622">be</TOKEN>
<TOKEN end_char="7625" id="token-69-8" morph="none" pos="word" start_char="7625">a</TOKEN>
<TOKEN end_char="7630" id="token-69-9" morph="none" pos="word" start_char="7627">drug</TOKEN>
<TOKEN end_char="7635" id="token-69-10" morph="none" pos="word" start_char="7632">like</TOKEN>
<TOKEN end_char="7646" id="token-69-11" morph="none" pos="word" start_char="7637">remdesivir</TOKEN>
<TOKEN end_char="7651" id="token-69-12" morph="none" pos="word" start_char="7648">plus</TOKEN>
<TOKEN end_char="7662" id="token-69-13" morph="none" pos="word" start_char="7653">monoclonal</TOKEN>
<TOKEN end_char="7673" id="token-69-14" morph="none" pos="word" start_char="7664">antibodies</TOKEN>
<TOKEN end_char="7674" id="token-69-15" morph="none" pos="punct" start_char="7674">,</TOKEN>
<TOKEN end_char="7682" id="token-69-16" morph="none" pos="word" start_char="7676">Denison</TOKEN>
<TOKEN end_char="7687" id="token-69-17" morph="none" pos="word" start_char="7684">says</TOKEN>
<TOKEN end_char="7688" id="token-69-18" morph="none" pos="punct" start_char="7688">.</TOKEN>
</SEG>
<SEG end_char="7767" id="segment-70" start_char="7690">
<ORIGINAL_TEXT>"The idea of using those in combination would have profoundly good prospects."</ORIGINAL_TEXT>
<TOKEN end_char="7690" id="token-70-0" morph="none" pos="punct" start_char="7690">"</TOKEN>
<TOKEN end_char="7693" id="token-70-1" morph="none" pos="word" start_char="7691">The</TOKEN>
<TOKEN end_char="7698" id="token-70-2" morph="none" pos="word" start_char="7695">idea</TOKEN>
<TOKEN end_char="7701" id="token-70-3" morph="none" pos="word" start_char="7700">of</TOKEN>
<TOKEN end_char="7707" id="token-70-4" morph="none" pos="word" start_char="7703">using</TOKEN>
<TOKEN end_char="7713" id="token-70-5" morph="none" pos="word" start_char="7709">those</TOKEN>
<TOKEN end_char="7716" id="token-70-6" morph="none" pos="word" start_char="7715">in</TOKEN>
<TOKEN end_char="7728" id="token-70-7" morph="none" pos="word" start_char="7718">combination</TOKEN>
<TOKEN end_char="7734" id="token-70-8" morph="none" pos="word" start_char="7730">would</TOKEN>
<TOKEN end_char="7739" id="token-70-9" morph="none" pos="word" start_char="7736">have</TOKEN>
<TOKEN end_char="7750" id="token-70-10" morph="none" pos="word" start_char="7741">profoundly</TOKEN>
<TOKEN end_char="7755" id="token-70-11" morph="none" pos="word" start_char="7752">good</TOKEN>
<TOKEN end_char="7765" id="token-70-12" morph="none" pos="word" start_char="7757">prospects</TOKEN>
<TOKEN end_char="7767" id="token-70-13" morph="none" pos="punct" start_char="7766">."</TOKEN>
</SEG>
<SEG end_char="7803" id="segment-71" start_char="7770">
<ORIGINAL_TEXT>Can Vaccines be Developed in Time?</ORIGINAL_TEXT>
<TOKEN end_char="7772" id="token-71-0" morph="none" pos="word" start_char="7770">Can</TOKEN>
<TOKEN end_char="7781" id="token-71-1" morph="none" pos="word" start_char="7774">Vaccines</TOKEN>
<TOKEN end_char="7784" id="token-71-2" morph="none" pos="word" start_char="7783">be</TOKEN>
<TOKEN end_char="7794" id="token-71-3" morph="none" pos="word" start_char="7786">Developed</TOKEN>
<TOKEN end_char="7797" id="token-71-4" morph="none" pos="word" start_char="7796">in</TOKEN>
<TOKEN end_char="7802" id="token-71-5" morph="none" pos="word" start_char="7799">Time</TOKEN>
<TOKEN end_char="7803" id="token-71-6" morph="none" pos="punct" start_char="7803">?</TOKEN>
</SEG>
<SEG end_char="7895" id="segment-72" start_char="7807">
<ORIGINAL_TEXT>In the stock pandemic movie, scientists develop a vaccine just in time to save the world.</ORIGINAL_TEXT>
<TOKEN end_char="7808" id="token-72-0" morph="none" pos="word" start_char="7807">In</TOKEN>
<TOKEN end_char="7812" id="token-72-1" morph="none" pos="word" start_char="7810">the</TOKEN>
<TOKEN end_char="7818" id="token-72-2" morph="none" pos="word" start_char="7814">stock</TOKEN>
<TOKEN end_char="7827" id="token-72-3" morph="none" pos="word" start_char="7820">pandemic</TOKEN>
<TOKEN end_char="7833" id="token-72-4" morph="none" pos="word" start_char="7829">movie</TOKEN>
<TOKEN end_char="7834" id="token-72-5" morph="none" pos="punct" start_char="7834">,</TOKEN>
<TOKEN end_char="7845" id="token-72-6" morph="none" pos="word" start_char="7836">scientists</TOKEN>
<TOKEN end_char="7853" id="token-72-7" morph="none" pos="word" start_char="7847">develop</TOKEN>
<TOKEN end_char="7855" id="token-72-8" morph="none" pos="word" start_char="7855">a</TOKEN>
<TOKEN end_char="7863" id="token-72-9" morph="none" pos="word" start_char="7857">vaccine</TOKEN>
<TOKEN end_char="7868" id="token-72-10" morph="none" pos="word" start_char="7865">just</TOKEN>
<TOKEN end_char="7871" id="token-72-11" morph="none" pos="word" start_char="7870">in</TOKEN>
<TOKEN end_char="7876" id="token-72-12" morph="none" pos="word" start_char="7873">time</TOKEN>
<TOKEN end_char="7879" id="token-72-13" morph="none" pos="word" start_char="7878">to</TOKEN>
<TOKEN end_char="7884" id="token-72-14" morph="none" pos="word" start_char="7881">save</TOKEN>
<TOKEN end_char="7888" id="token-72-15" morph="none" pos="word" start_char="7886">the</TOKEN>
<TOKEN end_char="7894" id="token-72-16" morph="none" pos="word" start_char="7890">world</TOKEN>
<TOKEN end_char="7895" id="token-72-17" morph="none" pos="punct" start_char="7895">.</TOKEN>
</SEG>
<SEG end_char="8011" id="segment-73" start_char="7897">
<ORIGINAL_TEXT>In real life, new vaccines have never been developed fast enough to have a significant impact on an emerging virus.</ORIGINAL_TEXT>
<TOKEN end_char="7898" id="token-73-0" morph="none" pos="word" start_char="7897">In</TOKEN>
<TOKEN end_char="7903" id="token-73-1" morph="none" pos="word" start_char="7900">real</TOKEN>
<TOKEN end_char="7908" id="token-73-2" morph="none" pos="word" start_char="7905">life</TOKEN>
<TOKEN end_char="7909" id="token-73-3" morph="none" pos="punct" start_char="7909">,</TOKEN>
<TOKEN end_char="7913" id="token-73-4" morph="none" pos="word" start_char="7911">new</TOKEN>
<TOKEN end_char="7922" id="token-73-5" morph="none" pos="word" start_char="7915">vaccines</TOKEN>
<TOKEN end_char="7927" id="token-73-6" morph="none" pos="word" start_char="7924">have</TOKEN>
<TOKEN end_char="7933" id="token-73-7" morph="none" pos="word" start_char="7929">never</TOKEN>
<TOKEN end_char="7938" id="token-73-8" morph="none" pos="word" start_char="7935">been</TOKEN>
<TOKEN end_char="7948" id="token-73-9" morph="none" pos="word" start_char="7940">developed</TOKEN>
<TOKEN end_char="7953" id="token-73-10" morph="none" pos="word" start_char="7950">fast</TOKEN>
<TOKEN end_char="7960" id="token-73-11" morph="none" pos="word" start_char="7955">enough</TOKEN>
<TOKEN end_char="7963" id="token-73-12" morph="none" pos="word" start_char="7962">to</TOKEN>
<TOKEN end_char="7968" id="token-73-13" morph="none" pos="word" start_char="7965">have</TOKEN>
<TOKEN end_char="7970" id="token-73-14" morph="none" pos="word" start_char="7970">a</TOKEN>
<TOKEN end_char="7982" id="token-73-15" morph="none" pos="word" start_char="7972">significant</TOKEN>
<TOKEN end_char="7989" id="token-73-16" morph="none" pos="word" start_char="7984">impact</TOKEN>
<TOKEN end_char="7992" id="token-73-17" morph="none" pos="word" start_char="7991">on</TOKEN>
<TOKEN end_char="7995" id="token-73-18" morph="none" pos="word" start_char="7994">an</TOKEN>
<TOKEN end_char="8004" id="token-73-19" morph="none" pos="word" start_char="7997">emerging</TOKEN>
<TOKEN end_char="8010" id="token-73-20" morph="none" pos="word" start_char="8006">virus</TOKEN>
<TOKEN end_char="8011" id="token-73-21" morph="none" pos="punct" start_char="8011">.</TOKEN>
</SEG>
<SEG end_char="8091" id="segment-74" start_char="8013">
<ORIGINAL_TEXT>But in the case of 2019-nCoV, scientists are trying to work at Hollywood speed.</ORIGINAL_TEXT>
<TOKEN end_char="8015" id="token-74-0" morph="none" pos="word" start_char="8013">But</TOKEN>
<TOKEN end_char="8018" id="token-74-1" morph="none" pos="word" start_char="8017">in</TOKEN>
<TOKEN end_char="8022" id="token-74-2" morph="none" pos="word" start_char="8020">the</TOKEN>
<TOKEN end_char="8027" id="token-74-3" morph="none" pos="word" start_char="8024">case</TOKEN>
<TOKEN end_char="8030" id="token-74-4" morph="none" pos="word" start_char="8029">of</TOKEN>
<TOKEN end_char="8040" id="token-74-5" morph="none" pos="unknown" start_char="8032">2019-nCoV</TOKEN>
<TOKEN end_char="8041" id="token-74-6" morph="none" pos="punct" start_char="8041">,</TOKEN>
<TOKEN end_char="8052" id="token-74-7" morph="none" pos="word" start_char="8043">scientists</TOKEN>
<TOKEN end_char="8056" id="token-74-8" morph="none" pos="word" start_char="8054">are</TOKEN>
<TOKEN end_char="8063" id="token-74-9" morph="none" pos="word" start_char="8058">trying</TOKEN>
<TOKEN end_char="8066" id="token-74-10" morph="none" pos="word" start_char="8065">to</TOKEN>
<TOKEN end_char="8071" id="token-74-11" morph="none" pos="word" start_char="8068">work</TOKEN>
<TOKEN end_char="8074" id="token-74-12" morph="none" pos="word" start_char="8073">at</TOKEN>
<TOKEN end_char="8084" id="token-74-13" morph="none" pos="word" start_char="8076">Hollywood</TOKEN>
<TOKEN end_char="8090" id="token-74-14" morph="none" pos="word" start_char="8086">speed</TOKEN>
<TOKEN end_char="8091" id="token-74-15" morph="none" pos="punct" start_char="8091">.</TOKEN>
</SEG>
<SEG end_char="8380" id="segment-75" start_char="8094">
<ORIGINAL_TEXT>The Coalition for Epidemic Preparedness Innovations (CEPI), a nonprofit formed in 2016 to fund and shepherd the development of new vaccines against emerging infectious diseases, has already given two companies and an academic group a total of $12.5 million to develop 2019-nCoV vaccines.</ORIGINAL_TEXT>
<TOKEN end_char="8096" id="token-75-0" morph="none" pos="word" start_char="8094">The</TOKEN>
<TOKEN end_char="8106" id="token-75-1" morph="none" pos="word" start_char="8098">Coalition</TOKEN>
<TOKEN end_char="8110" id="token-75-2" morph="none" pos="word" start_char="8108">for</TOKEN>
<TOKEN end_char="8119" id="token-75-3" morph="none" pos="word" start_char="8112">Epidemic</TOKEN>
<TOKEN end_char="8132" id="token-75-4" morph="none" pos="word" start_char="8121">Preparedness</TOKEN>
<TOKEN end_char="8144" id="token-75-5" morph="none" pos="word" start_char="8134">Innovations</TOKEN>
<TOKEN end_char="8146" id="token-75-6" morph="none" pos="punct" start_char="8146">(</TOKEN>
<TOKEN end_char="8150" id="token-75-7" morph="none" pos="word" start_char="8147">CEPI</TOKEN>
<TOKEN end_char="8152" id="token-75-8" morph="none" pos="punct" start_char="8151">),</TOKEN>
<TOKEN end_char="8154" id="token-75-9" morph="none" pos="word" start_char="8154">a</TOKEN>
<TOKEN end_char="8164" id="token-75-10" morph="none" pos="word" start_char="8156">nonprofit</TOKEN>
<TOKEN end_char="8171" id="token-75-11" morph="none" pos="word" start_char="8166">formed</TOKEN>
<TOKEN end_char="8174" id="token-75-12" morph="none" pos="word" start_char="8173">in</TOKEN>
<TOKEN end_char="8179" id="token-75-13" morph="none" pos="word" start_char="8176">2016</TOKEN>
<TOKEN end_char="8182" id="token-75-14" morph="none" pos="word" start_char="8181">to</TOKEN>
<TOKEN end_char="8187" id="token-75-15" morph="none" pos="word" start_char="8184">fund</TOKEN>
<TOKEN end_char="8191" id="token-75-16" morph="none" pos="word" start_char="8189">and</TOKEN>
<TOKEN end_char="8200" id="token-75-17" morph="none" pos="word" start_char="8193">shepherd</TOKEN>
<TOKEN end_char="8204" id="token-75-18" morph="none" pos="word" start_char="8202">the</TOKEN>
<TOKEN end_char="8216" id="token-75-19" morph="none" pos="word" start_char="8206">development</TOKEN>
<TOKEN end_char="8219" id="token-75-20" morph="none" pos="word" start_char="8218">of</TOKEN>
<TOKEN end_char="8223" id="token-75-21" morph="none" pos="word" start_char="8221">new</TOKEN>
<TOKEN end_char="8232" id="token-75-22" morph="none" pos="word" start_char="8225">vaccines</TOKEN>
<TOKEN end_char="8240" id="token-75-23" morph="none" pos="word" start_char="8234">against</TOKEN>
<TOKEN end_char="8249" id="token-75-24" morph="none" pos="word" start_char="8242">emerging</TOKEN>
<TOKEN end_char="8260" id="token-75-25" morph="none" pos="word" start_char="8251">infectious</TOKEN>
<TOKEN end_char="8269" id="token-75-26" morph="none" pos="word" start_char="8262">diseases</TOKEN>
<TOKEN end_char="8270" id="token-75-27" morph="none" pos="punct" start_char="8270">,</TOKEN>
<TOKEN end_char="8274" id="token-75-28" morph="none" pos="word" start_char="8272">has</TOKEN>
<TOKEN end_char="8282" id="token-75-29" morph="none" pos="word" start_char="8276">already</TOKEN>
<TOKEN end_char="8288" id="token-75-30" morph="none" pos="word" start_char="8284">given</TOKEN>
<TOKEN end_char="8292" id="token-75-31" morph="none" pos="word" start_char="8290">two</TOKEN>
<TOKEN end_char="8302" id="token-75-32" morph="none" pos="word" start_char="8294">companies</TOKEN>
<TOKEN end_char="8306" id="token-75-33" morph="none" pos="word" start_char="8304">and</TOKEN>
<TOKEN end_char="8309" id="token-75-34" morph="none" pos="word" start_char="8308">an</TOKEN>
<TOKEN end_char="8318" id="token-75-35" morph="none" pos="word" start_char="8311">academic</TOKEN>
<TOKEN end_char="8324" id="token-75-36" morph="none" pos="word" start_char="8320">group</TOKEN>
<TOKEN end_char="8326" id="token-75-37" morph="none" pos="word" start_char="8326">a</TOKEN>
<TOKEN end_char="8332" id="token-75-38" morph="none" pos="word" start_char="8328">total</TOKEN>
<TOKEN end_char="8335" id="token-75-39" morph="none" pos="word" start_char="8334">of</TOKEN>
<TOKEN end_char="8341" id="token-75-40" morph="none" pos="unknown" start_char="8337">$12.5</TOKEN>
<TOKEN end_char="8349" id="token-75-41" morph="none" pos="word" start_char="8343">million</TOKEN>
<TOKEN end_char="8352" id="token-75-42" morph="none" pos="word" start_char="8351">to</TOKEN>
<TOKEN end_char="8360" id="token-75-43" morph="none" pos="word" start_char="8354">develop</TOKEN>
<TOKEN end_char="8370" id="token-75-44" morph="none" pos="unknown" start_char="8362">2019-nCoV</TOKEN>
<TOKEN end_char="8379" id="token-75-45" morph="none" pos="word" start_char="8372">vaccines</TOKEN>
<TOKEN end_char="8380" id="token-75-46" morph="none" pos="punct" start_char="8380">.</TOKEN>
</SEG>
<SEG end_char="8476" id="segment-76" start_char="8382">
<ORIGINAL_TEXT>The efforts began hours after Chinese researchers first published a viral sequence 3 weeks ago.</ORIGINAL_TEXT>
<TOKEN end_char="8384" id="token-76-0" morph="none" pos="word" start_char="8382">The</TOKEN>
<TOKEN end_char="8392" id="token-76-1" morph="none" pos="word" start_char="8386">efforts</TOKEN>
<TOKEN end_char="8398" id="token-76-2" morph="none" pos="word" start_char="8394">began</TOKEN>
<TOKEN end_char="8404" id="token-76-3" morph="none" pos="word" start_char="8400">hours</TOKEN>
<TOKEN end_char="8410" id="token-76-4" morph="none" pos="word" start_char="8406">after</TOKEN>
<TOKEN end_char="8418" id="token-76-5" morph="none" pos="word" start_char="8412">Chinese</TOKEN>
<TOKEN end_char="8430" id="token-76-6" morph="none" pos="word" start_char="8420">researchers</TOKEN>
<TOKEN end_char="8436" id="token-76-7" morph="none" pos="word" start_char="8432">first</TOKEN>
<TOKEN end_char="8446" id="token-76-8" morph="none" pos="word" start_char="8438">published</TOKEN>
<TOKEN end_char="8448" id="token-76-9" morph="none" pos="word" start_char="8448">a</TOKEN>
<TOKEN end_char="8454" id="token-76-10" morph="none" pos="word" start_char="8450">viral</TOKEN>
<TOKEN end_char="8463" id="token-76-11" morph="none" pos="word" start_char="8456">sequence</TOKEN>
<TOKEN end_char="8465" id="token-76-12" morph="none" pos="word" start_char="8465">3</TOKEN>
<TOKEN end_char="8471" id="token-76-13" morph="none" pos="word" start_char="8467">weeks</TOKEN>
<TOKEN end_char="8475" id="token-76-14" morph="none" pos="word" start_char="8473">ago</TOKEN>
<TOKEN end_char="8476" id="token-76-15" morph="none" pos="punct" start_char="8476">.</TOKEN>
</SEG>
<SEG end_char="8683" id="segment-77" start_char="8479">
<ORIGINAL_TEXT>One is a collaboration between the U.S. National Institute of Allergy and Infectious Diseases (NIAID) and U.S. biotech Moderna, which makes vaccines by converting viral sequences into messenger RNA (mRNA).</ORIGINAL_TEXT>
<TOKEN end_char="8481" id="token-77-0" morph="none" pos="word" start_char="8479">One</TOKEN>
<TOKEN end_char="8484" id="token-77-1" morph="none" pos="word" start_char="8483">is</TOKEN>
<TOKEN end_char="8486" id="token-77-2" morph="none" pos="word" start_char="8486">a</TOKEN>
<TOKEN end_char="8500" id="token-77-3" morph="none" pos="word" start_char="8488">collaboration</TOKEN>
<TOKEN end_char="8508" id="token-77-4" morph="none" pos="word" start_char="8502">between</TOKEN>
<TOKEN end_char="8512" id="token-77-5" morph="none" pos="word" start_char="8510">the</TOKEN>
<TOKEN end_char="8516" id="token-77-6" morph="none" pos="unknown" start_char="8514">U.S</TOKEN>
<TOKEN end_char="8517" id="token-77-7" morph="none" pos="punct" start_char="8517">.</TOKEN>
<TOKEN end_char="8526" id="token-77-8" morph="none" pos="word" start_char="8519">National</TOKEN>
<TOKEN end_char="8536" id="token-77-9" morph="none" pos="word" start_char="8528">Institute</TOKEN>
<TOKEN end_char="8539" id="token-77-10" morph="none" pos="word" start_char="8538">of</TOKEN>
<TOKEN end_char="8547" id="token-77-11" morph="none" pos="word" start_char="8541">Allergy</TOKEN>
<TOKEN end_char="8551" id="token-77-12" morph="none" pos="word" start_char="8549">and</TOKEN>
<TOKEN end_char="8562" id="token-77-13" morph="none" pos="word" start_char="8553">Infectious</TOKEN>
<TOKEN end_char="8571" id="token-77-14" morph="none" pos="word" start_char="8564">Diseases</TOKEN>
<TOKEN end_char="8573" id="token-77-15" morph="none" pos="punct" start_char="8573">(</TOKEN>
<TOKEN end_char="8578" id="token-77-16" morph="none" pos="word" start_char="8574">NIAID</TOKEN>
<TOKEN end_char="8579" id="token-77-17" morph="none" pos="punct" start_char="8579">)</TOKEN>
<TOKEN end_char="8583" id="token-77-18" morph="none" pos="word" start_char="8581">and</TOKEN>
<TOKEN end_char="8587" id="token-77-19" morph="none" pos="unknown" start_char="8585">U.S</TOKEN>
<TOKEN end_char="8588" id="token-77-20" morph="none" pos="punct" start_char="8588">.</TOKEN>
<TOKEN end_char="8596" id="token-77-21" morph="none" pos="word" start_char="8590">biotech</TOKEN>
<TOKEN end_char="8604" id="token-77-22" morph="none" pos="word" start_char="8598">Moderna</TOKEN>
<TOKEN end_char="8605" id="token-77-23" morph="none" pos="punct" start_char="8605">,</TOKEN>
<TOKEN end_char="8611" id="token-77-24" morph="none" pos="word" start_char="8607">which</TOKEN>
<TOKEN end_char="8617" id="token-77-25" morph="none" pos="word" start_char="8613">makes</TOKEN>
<TOKEN end_char="8626" id="token-77-26" morph="none" pos="word" start_char="8619">vaccines</TOKEN>
<TOKEN end_char="8629" id="token-77-27" morph="none" pos="word" start_char="8628">by</TOKEN>
<TOKEN end_char="8640" id="token-77-28" morph="none" pos="word" start_char="8631">converting</TOKEN>
<TOKEN end_char="8646" id="token-77-29" morph="none" pos="word" start_char="8642">viral</TOKEN>
<TOKEN end_char="8656" id="token-77-30" morph="none" pos="word" start_char="8648">sequences</TOKEN>
<TOKEN end_char="8661" id="token-77-31" morph="none" pos="word" start_char="8658">into</TOKEN>
<TOKEN end_char="8671" id="token-77-32" morph="none" pos="word" start_char="8663">messenger</TOKEN>
<TOKEN end_char="8675" id="token-77-33" morph="none" pos="word" start_char="8673">RNA</TOKEN>
<TOKEN end_char="8677" id="token-77-34" morph="none" pos="punct" start_char="8677">(</TOKEN>
<TOKEN end_char="8681" id="token-77-35" morph="none" pos="word" start_char="8678">mRNA</TOKEN>
<TOKEN end_char="8683" id="token-77-36" morph="none" pos="punct" start_char="8682">).</TOKEN>
</SEG>
<SEG end_char="8796" id="segment-78" start_char="8685">
<ORIGINAL_TEXT>(When injected into the body, mRNA causes the body to produce a viral protein, which triggers immune responses.)</ORIGINAL_TEXT>
<TOKEN end_char="8685" id="token-78-0" morph="none" pos="punct" start_char="8685">(</TOKEN>
<TOKEN end_char="8689" id="token-78-1" morph="none" pos="word" start_char="8686">When</TOKEN>
<TOKEN end_char="8698" id="token-78-2" morph="none" pos="word" start_char="8691">injected</TOKEN>
<TOKEN end_char="8703" id="token-78-3" morph="none" pos="word" start_char="8700">into</TOKEN>
<TOKEN end_char="8707" id="token-78-4" morph="none" pos="word" start_char="8705">the</TOKEN>
<TOKEN end_char="8712" id="token-78-5" morph="none" pos="word" start_char="8709">body</TOKEN>
<TOKEN end_char="8713" id="token-78-6" morph="none" pos="punct" start_char="8713">,</TOKEN>
<TOKEN end_char="8718" id="token-78-7" morph="none" pos="word" start_char="8715">mRNA</TOKEN>
<TOKEN end_char="8725" id="token-78-8" morph="none" pos="word" start_char="8720">causes</TOKEN>
<TOKEN end_char="8729" id="token-78-9" morph="none" pos="word" start_char="8727">the</TOKEN>
<TOKEN end_char="8734" id="token-78-10" morph="none" pos="word" start_char="8731">body</TOKEN>
<TOKEN end_char="8737" id="token-78-11" morph="none" pos="word" start_char="8736">to</TOKEN>
<TOKEN end_char="8745" id="token-78-12" morph="none" pos="word" start_char="8739">produce</TOKEN>
<TOKEN end_char="8747" id="token-78-13" morph="none" pos="word" start_char="8747">a</TOKEN>
<TOKEN end_char="8753" id="token-78-14" morph="none" pos="word" start_char="8749">viral</TOKEN>
<TOKEN end_char="8761" id="token-78-15" morph="none" pos="word" start_char="8755">protein</TOKEN>
<TOKEN end_char="8762" id="token-78-16" morph="none" pos="punct" start_char="8762">,</TOKEN>
<TOKEN end_char="8768" id="token-78-17" morph="none" pos="word" start_char="8764">which</TOKEN>
<TOKEN end_char="8777" id="token-78-18" morph="none" pos="word" start_char="8770">triggers</TOKEN>
<TOKEN end_char="8784" id="token-78-19" morph="none" pos="word" start_char="8779">immune</TOKEN>
<TOKEN end_char="8794" id="token-78-20" morph="none" pos="word" start_char="8786">responses</TOKEN>
<TOKEN end_char="8796" id="token-78-21" morph="none" pos="punct" start_char="8795">.)</TOKEN>
</SEG>
<SEG end_char="9029" id="segment-79" start_char="8798">
<ORIGINAL_TEXT>Moderna and NIAID have worked on a vaccine against MERS that consists of mRNA coding for a protein on the viral surface called the spike; in theory, all the team needs to do now is swap in the genetic sequence for 2019-nCoV's spike.</ORIGINAL_TEXT>
<TOKEN end_char="8804" id="token-79-0" morph="none" pos="word" start_char="8798">Moderna</TOKEN>
<TOKEN end_char="8808" id="token-79-1" morph="none" pos="word" start_char="8806">and</TOKEN>
<TOKEN end_char="8814" id="token-79-2" morph="none" pos="word" start_char="8810">NIAID</TOKEN>
<TOKEN end_char="8819" id="token-79-3" morph="none" pos="word" start_char="8816">have</TOKEN>
<TOKEN end_char="8826" id="token-79-4" morph="none" pos="word" start_char="8821">worked</TOKEN>
<TOKEN end_char="8829" id="token-79-5" morph="none" pos="word" start_char="8828">on</TOKEN>
<TOKEN end_char="8831" id="token-79-6" morph="none" pos="word" start_char="8831">a</TOKEN>
<TOKEN end_char="8839" id="token-79-7" morph="none" pos="word" start_char="8833">vaccine</TOKEN>
<TOKEN end_char="8847" id="token-79-8" morph="none" pos="word" start_char="8841">against</TOKEN>
<TOKEN end_char="8852" id="token-79-9" morph="none" pos="word" start_char="8849">MERS</TOKEN>
<TOKEN end_char="8857" id="token-79-10" morph="none" pos="word" start_char="8854">that</TOKEN>
<TOKEN end_char="8866" id="token-79-11" morph="none" pos="word" start_char="8859">consists</TOKEN>
<TOKEN end_char="8869" id="token-79-12" morph="none" pos="word" start_char="8868">of</TOKEN>
<TOKEN end_char="8874" id="token-79-13" morph="none" pos="word" start_char="8871">mRNA</TOKEN>
<TOKEN end_char="8881" id="token-79-14" morph="none" pos="word" start_char="8876">coding</TOKEN>
<TOKEN end_char="8885" id="token-79-15" morph="none" pos="word" start_char="8883">for</TOKEN>
<TOKEN end_char="8887" id="token-79-16" morph="none" pos="word" start_char="8887">a</TOKEN>
<TOKEN end_char="8895" id="token-79-17" morph="none" pos="word" start_char="8889">protein</TOKEN>
<TOKEN end_char="8898" id="token-79-18" morph="none" pos="word" start_char="8897">on</TOKEN>
<TOKEN end_char="8902" id="token-79-19" morph="none" pos="word" start_char="8900">the</TOKEN>
<TOKEN end_char="8908" id="token-79-20" morph="none" pos="word" start_char="8904">viral</TOKEN>
<TOKEN end_char="8916" id="token-79-21" morph="none" pos="word" start_char="8910">surface</TOKEN>
<TOKEN end_char="8923" id="token-79-22" morph="none" pos="word" start_char="8918">called</TOKEN>
<TOKEN end_char="8927" id="token-79-23" morph="none" pos="word" start_char="8925">the</TOKEN>
<TOKEN end_char="8933" id="token-79-24" morph="none" pos="word" start_char="8929">spike</TOKEN>
<TOKEN end_char="8934" id="token-79-25" morph="none" pos="punct" start_char="8934">;</TOKEN>
<TOKEN end_char="8937" id="token-79-26" morph="none" pos="word" start_char="8936">in</TOKEN>
<TOKEN end_char="8944" id="token-79-27" morph="none" pos="word" start_char="8939">theory</TOKEN>
<TOKEN end_char="8945" id="token-79-28" morph="none" pos="punct" start_char="8945">,</TOKEN>
<TOKEN end_char="8949" id="token-79-29" morph="none" pos="word" start_char="8947">all</TOKEN>
<TOKEN end_char="8953" id="token-79-30" morph="none" pos="word" start_char="8951">the</TOKEN>
<TOKEN end_char="8958" id="token-79-31" morph="none" pos="word" start_char="8955">team</TOKEN>
<TOKEN end_char="8964" id="token-79-32" morph="none" pos="word" start_char="8960">needs</TOKEN>
<TOKEN end_char="8967" id="token-79-33" morph="none" pos="word" start_char="8966">to</TOKEN>
<TOKEN end_char="8970" id="token-79-34" morph="none" pos="word" start_char="8969">do</TOKEN>
<TOKEN end_char="8974" id="token-79-35" morph="none" pos="word" start_char="8972">now</TOKEN>
<TOKEN end_char="8977" id="token-79-36" morph="none" pos="word" start_char="8976">is</TOKEN>
<TOKEN end_char="8982" id="token-79-37" morph="none" pos="word" start_char="8979">swap</TOKEN>
<TOKEN end_char="8985" id="token-79-38" morph="none" pos="word" start_char="8984">in</TOKEN>
<TOKEN end_char="8989" id="token-79-39" morph="none" pos="word" start_char="8987">the</TOKEN>
<TOKEN end_char="8997" id="token-79-40" morph="none" pos="word" start_char="8991">genetic</TOKEN>
<TOKEN end_char="9006" id="token-79-41" morph="none" pos="word" start_char="8999">sequence</TOKEN>
<TOKEN end_char="9010" id="token-79-42" morph="none" pos="word" start_char="9008">for</TOKEN>
<TOKEN end_char="9022" id="token-79-43" morph="none" pos="unknown" start_char="9012">2019-nCoV's</TOKEN>
<TOKEN end_char="9028" id="token-79-44" morph="none" pos="word" start_char="9024">spike</TOKEN>
<TOKEN end_char="9029" id="token-79-45" morph="none" pos="punct" start_char="9029">.</TOKEN>
</SEG>
<SEG end_char="9136" id="segment-80" start_char="9032">
<ORIGINAL_TEXT>CEPI funded a second company, Inovio, to produce vaccines that work in a similar way but are made of DNA.</ORIGINAL_TEXT>
<TOKEN end_char="9035" id="token-80-0" morph="none" pos="word" start_char="9032">CEPI</TOKEN>
<TOKEN end_char="9042" id="token-80-1" morph="none" pos="word" start_char="9037">funded</TOKEN>
<TOKEN end_char="9044" id="token-80-2" morph="none" pos="word" start_char="9044">a</TOKEN>
<TOKEN end_char="9051" id="token-80-3" morph="none" pos="word" start_char="9046">second</TOKEN>
<TOKEN end_char="9059" id="token-80-4" morph="none" pos="word" start_char="9053">company</TOKEN>
<TOKEN end_char="9060" id="token-80-5" morph="none" pos="punct" start_char="9060">,</TOKEN>
<TOKEN end_char="9067" id="token-80-6" morph="none" pos="word" start_char="9062">Inovio</TOKEN>
<TOKEN end_char="9068" id="token-80-7" morph="none" pos="punct" start_char="9068">,</TOKEN>
<TOKEN end_char="9071" id="token-80-8" morph="none" pos="word" start_char="9070">to</TOKEN>
<TOKEN end_char="9079" id="token-80-9" morph="none" pos="word" start_char="9073">produce</TOKEN>
<TOKEN end_char="9088" id="token-80-10" morph="none" pos="word" start_char="9081">vaccines</TOKEN>
<TOKEN end_char="9093" id="token-80-11" morph="none" pos="word" start_char="9090">that</TOKEN>
<TOKEN end_char="9098" id="token-80-12" morph="none" pos="word" start_char="9095">work</TOKEN>
<TOKEN end_char="9101" id="token-80-13" morph="none" pos="word" start_char="9100">in</TOKEN>
<TOKEN end_char="9103" id="token-80-14" morph="none" pos="word" start_char="9103">a</TOKEN>
<TOKEN end_char="9111" id="token-80-15" morph="none" pos="word" start_char="9105">similar</TOKEN>
<TOKEN end_char="9115" id="token-80-16" morph="none" pos="word" start_char="9113">way</TOKEN>
<TOKEN end_char="9119" id="token-80-17" morph="none" pos="word" start_char="9117">but</TOKEN>
<TOKEN end_char="9123" id="token-80-18" morph="none" pos="word" start_char="9121">are</TOKEN>
<TOKEN end_char="9128" id="token-80-19" morph="none" pos="word" start_char="9125">made</TOKEN>
<TOKEN end_char="9131" id="token-80-20" morph="none" pos="word" start_char="9130">of</TOKEN>
<TOKEN end_char="9135" id="token-80-21" morph="none" pos="word" start_char="9133">DNA</TOKEN>
<TOKEN end_char="9136" id="token-80-22" morph="none" pos="punct" start_char="9136">.</TOKEN>
</SEG>
<SEG end_char="9250" id="segment-81" start_char="9138">
<ORIGINAL_TEXT>It, too, has a template for a 2019-nCoV vaccine: another candidate MERS vaccine that relies on the spike protein.</ORIGINAL_TEXT>
<TOKEN end_char="9139" id="token-81-0" morph="none" pos="word" start_char="9138">It</TOKEN>
<TOKEN end_char="9140" id="token-81-1" morph="none" pos="punct" start_char="9140">,</TOKEN>
<TOKEN end_char="9144" id="token-81-2" morph="none" pos="word" start_char="9142">too</TOKEN>
<TOKEN end_char="9145" id="token-81-3" morph="none" pos="punct" start_char="9145">,</TOKEN>
<TOKEN end_char="9149" id="token-81-4" morph="none" pos="word" start_char="9147">has</TOKEN>
<TOKEN end_char="9151" id="token-81-5" morph="none" pos="word" start_char="9151">a</TOKEN>
<TOKEN end_char="9160" id="token-81-6" morph="none" pos="word" start_char="9153">template</TOKEN>
<TOKEN end_char="9164" id="token-81-7" morph="none" pos="word" start_char="9162">for</TOKEN>
<TOKEN end_char="9166" id="token-81-8" morph="none" pos="word" start_char="9166">a</TOKEN>
<TOKEN end_char="9176" id="token-81-9" morph="none" pos="unknown" start_char="9168">2019-nCoV</TOKEN>
<TOKEN end_char="9184" id="token-81-10" morph="none" pos="word" start_char="9178">vaccine</TOKEN>
<TOKEN end_char="9185" id="token-81-11" morph="none" pos="punct" start_char="9185">:</TOKEN>
<TOKEN end_char="9193" id="token-81-12" morph="none" pos="word" start_char="9187">another</TOKEN>
<TOKEN end_char="9203" id="token-81-13" morph="none" pos="word" start_char="9195">candidate</TOKEN>
<TOKEN end_char="9208" id="token-81-14" morph="none" pos="word" start_char="9205">MERS</TOKEN>
<TOKEN end_char="9216" id="token-81-15" morph="none" pos="word" start_char="9210">vaccine</TOKEN>
<TOKEN end_char="9221" id="token-81-16" morph="none" pos="word" start_char="9218">that</TOKEN>
<TOKEN end_char="9228" id="token-81-17" morph="none" pos="word" start_char="9223">relies</TOKEN>
<TOKEN end_char="9231" id="token-81-18" morph="none" pos="word" start_char="9230">on</TOKEN>
<TOKEN end_char="9235" id="token-81-19" morph="none" pos="word" start_char="9233">the</TOKEN>
<TOKEN end_char="9241" id="token-81-20" morph="none" pos="word" start_char="9237">spike</TOKEN>
<TOKEN end_char="9249" id="token-81-21" morph="none" pos="word" start_char="9243">protein</TOKEN>
<TOKEN end_char="9250" id="token-81-22" morph="none" pos="punct" start_char="9250">.</TOKEN>
</SEG>
<SEG end_char="9400" id="segment-82" start_char="9252">
<ORIGINAL_TEXT>CEPI's third grant went to researchers at the University of Queensland who are developing a vaccine made of viral proteins produced in cell cultures.</ORIGINAL_TEXT>
<TOKEN end_char="9257" id="token-82-0" morph="none" pos="word" start_char="9252">CEPI's</TOKEN>
<TOKEN end_char="9263" id="token-82-1" morph="none" pos="word" start_char="9259">third</TOKEN>
<TOKEN end_char="9269" id="token-82-2" morph="none" pos="word" start_char="9265">grant</TOKEN>
<TOKEN end_char="9274" id="token-82-3" morph="none" pos="word" start_char="9271">went</TOKEN>
<TOKEN end_char="9277" id="token-82-4" morph="none" pos="word" start_char="9276">to</TOKEN>
<TOKEN end_char="9289" id="token-82-5" morph="none" pos="word" start_char="9279">researchers</TOKEN>
<TOKEN end_char="9292" id="token-82-6" morph="none" pos="word" start_char="9291">at</TOKEN>
<TOKEN end_char="9296" id="token-82-7" morph="none" pos="word" start_char="9294">the</TOKEN>
<TOKEN end_char="9307" id="token-82-8" morph="none" pos="word" start_char="9298">University</TOKEN>
<TOKEN end_char="9310" id="token-82-9" morph="none" pos="word" start_char="9309">of</TOKEN>
<TOKEN end_char="9321" id="token-82-10" morph="none" pos="word" start_char="9312">Queensland</TOKEN>
<TOKEN end_char="9325" id="token-82-11" morph="none" pos="word" start_char="9323">who</TOKEN>
<TOKEN end_char="9329" id="token-82-12" morph="none" pos="word" start_char="9327">are</TOKEN>
<TOKEN end_char="9340" id="token-82-13" morph="none" pos="word" start_char="9331">developing</TOKEN>
<TOKEN end_char="9342" id="token-82-14" morph="none" pos="word" start_char="9342">a</TOKEN>
<TOKEN end_char="9350" id="token-82-15" morph="none" pos="word" start_char="9344">vaccine</TOKEN>
<TOKEN end_char="9355" id="token-82-16" morph="none" pos="word" start_char="9352">made</TOKEN>
<TOKEN end_char="9358" id="token-82-17" morph="none" pos="word" start_char="9357">of</TOKEN>
<TOKEN end_char="9364" id="token-82-18" morph="none" pos="word" start_char="9360">viral</TOKEN>
<TOKEN end_char="9373" id="token-82-19" morph="none" pos="word" start_char="9366">proteins</TOKEN>
<TOKEN end_char="9382" id="token-82-20" morph="none" pos="word" start_char="9375">produced</TOKEN>
<TOKEN end_char="9385" id="token-82-21" morph="none" pos="word" start_char="9384">in</TOKEN>
<TOKEN end_char="9390" id="token-82-22" morph="none" pos="word" start_char="9387">cell</TOKEN>
<TOKEN end_char="9399" id="token-82-23" morph="none" pos="word" start_char="9392">cultures</TOKEN>
<TOKEN end_char="9400" id="token-82-24" morph="none" pos="punct" start_char="9400">.</TOKEN>
</SEG>
<SEG end_char="9487" id="segment-83" start_char="9402">
<ORIGINAL_TEXT>Vaccine projects are also underway in mainland China, Hong Kong, Belgium, and Germany.</ORIGINAL_TEXT>
<TOKEN end_char="9408" id="token-83-0" morph="none" pos="word" start_char="9402">Vaccine</TOKEN>
<TOKEN end_char="9417" id="token-83-1" morph="none" pos="word" start_char="9410">projects</TOKEN>
<TOKEN end_char="9421" id="token-83-2" morph="none" pos="word" start_char="9419">are</TOKEN>
<TOKEN end_char="9426" id="token-83-3" morph="none" pos="word" start_char="9423">also</TOKEN>
<TOKEN end_char="9435" id="token-83-4" morph="none" pos="word" start_char="9428">underway</TOKEN>
<TOKEN end_char="9438" id="token-83-5" morph="none" pos="word" start_char="9437">in</TOKEN>
<TOKEN end_char="9447" id="token-83-6" morph="none" pos="word" start_char="9440">mainland</TOKEN>
<TOKEN end_char="9453" id="token-83-7" morph="none" pos="word" start_char="9449">China</TOKEN>
<TOKEN end_char="9454" id="token-83-8" morph="none" pos="punct" start_char="9454">,</TOKEN>
<TOKEN end_char="9459" id="token-83-9" morph="none" pos="word" start_char="9456">Hong</TOKEN>
<TOKEN end_char="9464" id="token-83-10" morph="none" pos="word" start_char="9461">Kong</TOKEN>
<TOKEN end_char="9465" id="token-83-11" morph="none" pos="punct" start_char="9465">,</TOKEN>
<TOKEN end_char="9473" id="token-83-12" morph="none" pos="word" start_char="9467">Belgium</TOKEN>
<TOKEN end_char="9474" id="token-83-13" morph="none" pos="punct" start_char="9474">,</TOKEN>
<TOKEN end_char="9478" id="token-83-14" morph="none" pos="word" start_char="9476">and</TOKEN>
<TOKEN end_char="9486" id="token-83-15" morph="none" pos="word" start_char="9480">Germany</TOKEN>
<TOKEN end_char="9487" id="token-83-16" morph="none" pos="punct" start_char="9487">.</TOKEN>
</SEG>
<SEG end_char="9610" id="segment-84" start_char="9489">
<ORIGINAL_TEXT>Once candidate vaccines are available, researchers will test them in animals, then seek approval for phase I human trials.</ORIGINAL_TEXT>
<TOKEN end_char="9492" id="token-84-0" morph="none" pos="word" start_char="9489">Once</TOKEN>
<TOKEN end_char="9502" id="token-84-1" morph="none" pos="word" start_char="9494">candidate</TOKEN>
<TOKEN end_char="9511" id="token-84-2" morph="none" pos="word" start_char="9504">vaccines</TOKEN>
<TOKEN end_char="9515" id="token-84-3" morph="none" pos="word" start_char="9513">are</TOKEN>
<TOKEN end_char="9525" id="token-84-4" morph="none" pos="word" start_char="9517">available</TOKEN>
<TOKEN end_char="9526" id="token-84-5" morph="none" pos="punct" start_char="9526">,</TOKEN>
<TOKEN end_char="9538" id="token-84-6" morph="none" pos="word" start_char="9528">researchers</TOKEN>
<TOKEN end_char="9543" id="token-84-7" morph="none" pos="word" start_char="9540">will</TOKEN>
<TOKEN end_char="9548" id="token-84-8" morph="none" pos="word" start_char="9545">test</TOKEN>
<TOKEN end_char="9553" id="token-84-9" morph="none" pos="word" start_char="9550">them</TOKEN>
<TOKEN end_char="9556" id="token-84-10" morph="none" pos="word" start_char="9555">in</TOKEN>
<TOKEN end_char="9564" id="token-84-11" morph="none" pos="word" start_char="9558">animals</TOKEN>
<TOKEN end_char="9565" id="token-84-12" morph="none" pos="punct" start_char="9565">,</TOKEN>
<TOKEN end_char="9570" id="token-84-13" morph="none" pos="word" start_char="9567">then</TOKEN>
<TOKEN end_char="9575" id="token-84-14" morph="none" pos="word" start_char="9572">seek</TOKEN>
<TOKEN end_char="9584" id="token-84-15" morph="none" pos="word" start_char="9577">approval</TOKEN>
<TOKEN end_char="9588" id="token-84-16" morph="none" pos="word" start_char="9586">for</TOKEN>
<TOKEN end_char="9594" id="token-84-17" morph="none" pos="word" start_char="9590">phase</TOKEN>
<TOKEN end_char="9596" id="token-84-18" morph="none" pos="word" start_char="9596">I</TOKEN>
<TOKEN end_char="9602" id="token-84-19" morph="none" pos="word" start_char="9598">human</TOKEN>
<TOKEN end_char="9609" id="token-84-20" morph="none" pos="word" start_char="9604">trials</TOKEN>
<TOKEN end_char="9610" id="token-84-21" morph="none" pos="punct" start_char="9610">.</TOKEN>
</SEG>
<SEG end_char="9685" id="segment-85" start_char="9612">
<ORIGINAL_TEXT>"We're building the airplane as we're flying," says Inovio CEO Joseph Kim.</ORIGINAL_TEXT>
<TOKEN end_char="9612" id="token-85-0" morph="none" pos="punct" start_char="9612">"</TOKEN>
<TOKEN end_char="9617" id="token-85-1" morph="none" pos="word" start_char="9613">We're</TOKEN>
<TOKEN end_char="9626" id="token-85-2" morph="none" pos="word" start_char="9619">building</TOKEN>
<TOKEN end_char="9630" id="token-85-3" morph="none" pos="word" start_char="9628">the</TOKEN>
<TOKEN end_char="9639" id="token-85-4" morph="none" pos="word" start_char="9632">airplane</TOKEN>
<TOKEN end_char="9642" id="token-85-5" morph="none" pos="word" start_char="9641">as</TOKEN>
<TOKEN end_char="9648" id="token-85-6" morph="none" pos="word" start_char="9644">we're</TOKEN>
<TOKEN end_char="9655" id="token-85-7" morph="none" pos="word" start_char="9650">flying</TOKEN>
<TOKEN end_char="9657" id="token-85-8" morph="none" pos="punct" start_char="9656">,"</TOKEN>
<TOKEN end_char="9662" id="token-85-9" morph="none" pos="word" start_char="9659">says</TOKEN>
<TOKEN end_char="9669" id="token-85-10" morph="none" pos="word" start_char="9664">Inovio</TOKEN>
<TOKEN end_char="9673" id="token-85-11" morph="none" pos="word" start_char="9671">CEO</TOKEN>
<TOKEN end_char="9680" id="token-85-12" morph="none" pos="word" start_char="9675">Joseph</TOKEN>
<TOKEN end_char="9684" id="token-85-13" morph="none" pos="word" start_char="9682">Kim</TOKEN>
<TOKEN end_char="9685" id="token-85-14" morph="none" pos="punct" start_char="9685">.</TOKEN>
</SEG>
<SEG end_char="9797" id="segment-86" start_char="9688">
<ORIGINAL_TEXT>NIAID Director Anthony Fauci says the first clinical trial of the Moderna vaccine could start within 3 months.</ORIGINAL_TEXT>
<TOKEN end_char="9692" id="token-86-0" morph="none" pos="word" start_char="9688">NIAID</TOKEN>
<TOKEN end_char="9701" id="token-86-1" morph="none" pos="word" start_char="9694">Director</TOKEN>
<TOKEN end_char="9709" id="token-86-2" morph="none" pos="word" start_char="9703">Anthony</TOKEN>
<TOKEN end_char="9715" id="token-86-3" morph="none" pos="word" start_char="9711">Fauci</TOKEN>
<TOKEN end_char="9720" id="token-86-4" morph="none" pos="word" start_char="9717">says</TOKEN>
<TOKEN end_char="9724" id="token-86-5" morph="none" pos="word" start_char="9722">the</TOKEN>
<TOKEN end_char="9730" id="token-86-6" morph="none" pos="word" start_char="9726">first</TOKEN>
<TOKEN end_char="9739" id="token-86-7" morph="none" pos="word" start_char="9732">clinical</TOKEN>
<TOKEN end_char="9745" id="token-86-8" morph="none" pos="word" start_char="9741">trial</TOKEN>
<TOKEN end_char="9748" id="token-86-9" morph="none" pos="word" start_char="9747">of</TOKEN>
<TOKEN end_char="9752" id="token-86-10" morph="none" pos="word" start_char="9750">the</TOKEN>
<TOKEN end_char="9760" id="token-86-11" morph="none" pos="word" start_char="9754">Moderna</TOKEN>
<TOKEN end_char="9768" id="token-86-12" morph="none" pos="word" start_char="9762">vaccine</TOKEN>
<TOKEN end_char="9774" id="token-86-13" morph="none" pos="word" start_char="9770">could</TOKEN>
<TOKEN end_char="9780" id="token-86-14" morph="none" pos="word" start_char="9776">start</TOKEN>
<TOKEN end_char="9787" id="token-86-15" morph="none" pos="word" start_char="9782">within</TOKEN>
<TOKEN end_char="9789" id="token-86-16" morph="none" pos="word" start_char="9789">3</TOKEN>
<TOKEN end_char="9796" id="token-86-17" morph="none" pos="word" start_char="9791">months</TOKEN>
<TOKEN end_char="9797" id="token-86-18" morph="none" pos="punct" start_char="9797">.</TOKEN>
</SEG>
<SEG end_char="9971" id="segment-87" start_char="9799">
<ORIGINAL_TEXT>In the best-case scenario, Barney Graham, who leads the project for NIAID, says the Moderna vaccine could be ready for larger, real-world efficacy tests in humans by summer.</ORIGINAL_TEXT>
<TOKEN end_char="9800" id="token-87-0" morph="none" pos="word" start_char="9799">In</TOKEN>
<TOKEN end_char="9804" id="token-87-1" morph="none" pos="word" start_char="9802">the</TOKEN>
<TOKEN end_char="9814" id="token-87-2" morph="none" pos="unknown" start_char="9806">best-case</TOKEN>
<TOKEN end_char="9823" id="token-87-3" morph="none" pos="word" start_char="9816">scenario</TOKEN>
<TOKEN end_char="9824" id="token-87-4" morph="none" pos="punct" start_char="9824">,</TOKEN>
<TOKEN end_char="9831" id="token-87-5" morph="none" pos="word" start_char="9826">Barney</TOKEN>
<TOKEN end_char="9838" id="token-87-6" morph="none" pos="word" start_char="9833">Graham</TOKEN>
<TOKEN end_char="9839" id="token-87-7" morph="none" pos="punct" start_char="9839">,</TOKEN>
<TOKEN end_char="9843" id="token-87-8" morph="none" pos="word" start_char="9841">who</TOKEN>
<TOKEN end_char="9849" id="token-87-9" morph="none" pos="word" start_char="9845">leads</TOKEN>
<TOKEN end_char="9853" id="token-87-10" morph="none" pos="word" start_char="9851">the</TOKEN>
<TOKEN end_char="9861" id="token-87-11" morph="none" pos="word" start_char="9855">project</TOKEN>
<TOKEN end_char="9865" id="token-87-12" morph="none" pos="word" start_char="9863">for</TOKEN>
<TOKEN end_char="9871" id="token-87-13" morph="none" pos="word" start_char="9867">NIAID</TOKEN>
<TOKEN end_char="9872" id="token-87-14" morph="none" pos="punct" start_char="9872">,</TOKEN>
<TOKEN end_char="9877" id="token-87-15" morph="none" pos="word" start_char="9874">says</TOKEN>
<TOKEN end_char="9881" id="token-87-16" morph="none" pos="word" start_char="9879">the</TOKEN>
<TOKEN end_char="9889" id="token-87-17" morph="none" pos="word" start_char="9883">Moderna</TOKEN>
<TOKEN end_char="9897" id="token-87-18" morph="none" pos="word" start_char="9891">vaccine</TOKEN>
<TOKEN end_char="9903" id="token-87-19" morph="none" pos="word" start_char="9899">could</TOKEN>
<TOKEN end_char="9906" id="token-87-20" morph="none" pos="word" start_char="9905">be</TOKEN>
<TOKEN end_char="9912" id="token-87-21" morph="none" pos="word" start_char="9908">ready</TOKEN>
<TOKEN end_char="9916" id="token-87-22" morph="none" pos="word" start_char="9914">for</TOKEN>
<TOKEN end_char="9923" id="token-87-23" morph="none" pos="word" start_char="9918">larger</TOKEN>
<TOKEN end_char="9924" id="token-87-24" morph="none" pos="punct" start_char="9924">,</TOKEN>
<TOKEN end_char="9935" id="token-87-25" morph="none" pos="unknown" start_char="9926">real-world</TOKEN>
<TOKEN end_char="9944" id="token-87-26" morph="none" pos="word" start_char="9937">efficacy</TOKEN>
<TOKEN end_char="9950" id="token-87-27" morph="none" pos="word" start_char="9946">tests</TOKEN>
<TOKEN end_char="9953" id="token-87-28" morph="none" pos="word" start_char="9952">in</TOKEN>
<TOKEN end_char="9960" id="token-87-29" morph="none" pos="word" start_char="9955">humans</TOKEN>
<TOKEN end_char="9963" id="token-87-30" morph="none" pos="word" start_char="9962">by</TOKEN>
<TOKEN end_char="9970" id="token-87-31" morph="none" pos="word" start_char="9965">summer</TOKEN>
<TOKEN end_char="9971" id="token-87-32" morph="none" pos="punct" start_char="9971">.</TOKEN>
</SEG>
<SEG end_char="10068" id="segment-88" start_char="9973">
<ORIGINAL_TEXT>Even if it works, mass-producing it or any other vaccine quickly would present a huge challenge.</ORIGINAL_TEXT>
<TOKEN end_char="9976" id="token-88-0" morph="none" pos="word" start_char="9973">Even</TOKEN>
<TOKEN end_char="9979" id="token-88-1" morph="none" pos="word" start_char="9978">if</TOKEN>
<TOKEN end_char="9982" id="token-88-2" morph="none" pos="word" start_char="9981">it</TOKEN>
<TOKEN end_char="9988" id="token-88-3" morph="none" pos="word" start_char="9984">works</TOKEN>
<TOKEN end_char="9989" id="token-88-4" morph="none" pos="punct" start_char="9989">,</TOKEN>
<TOKEN end_char="10004" id="token-88-5" morph="none" pos="unknown" start_char="9991">mass-producing</TOKEN>
<TOKEN end_char="10007" id="token-88-6" morph="none" pos="word" start_char="10006">it</TOKEN>
<TOKEN end_char="10010" id="token-88-7" morph="none" pos="word" start_char="10009">or</TOKEN>
<TOKEN end_char="10014" id="token-88-8" morph="none" pos="word" start_char="10012">any</TOKEN>
<TOKEN end_char="10020" id="token-88-9" morph="none" pos="word" start_char="10016">other</TOKEN>
<TOKEN end_char="10028" id="token-88-10" morph="none" pos="word" start_char="10022">vaccine</TOKEN>
<TOKEN end_char="10036" id="token-88-11" morph="none" pos="word" start_char="10030">quickly</TOKEN>
<TOKEN end_char="10042" id="token-88-12" morph="none" pos="word" start_char="10038">would</TOKEN>
<TOKEN end_char="10050" id="token-88-13" morph="none" pos="word" start_char="10044">present</TOKEN>
<TOKEN end_char="10052" id="token-88-14" morph="none" pos="word" start_char="10052">a</TOKEN>
<TOKEN end_char="10057" id="token-88-15" morph="none" pos="word" start_char="10054">huge</TOKEN>
<TOKEN end_char="10067" id="token-88-16" morph="none" pos="word" start_char="10059">challenge</TOKEN>
<TOKEN end_char="10068" id="token-88-17" morph="none" pos="punct" start_char="10068">.</TOKEN>
</SEG>
<SEG end_char="10181" id="segment-89" start_char="10071">
<ORIGINAL_TEXT>With luck, however, the outbreak will fade by summer, and with it the urgency of having a vaccine at the ready.</ORIGINAL_TEXT>
<TOKEN end_char="10074" id="token-89-0" morph="none" pos="word" start_char="10071">With</TOKEN>
<TOKEN end_char="10079" id="token-89-1" morph="none" pos="word" start_char="10076">luck</TOKEN>
<TOKEN end_char="10080" id="token-89-2" morph="none" pos="punct" start_char="10080">,</TOKEN>
<TOKEN end_char="10088" id="token-89-3" morph="none" pos="word" start_char="10082">however</TOKEN>
<TOKEN end_char="10089" id="token-89-4" morph="none" pos="punct" start_char="10089">,</TOKEN>
<TOKEN end_char="10093" id="token-89-5" morph="none" pos="word" start_char="10091">the</TOKEN>
<TOKEN end_char="10102" id="token-89-6" morph="none" pos="word" start_char="10095">outbreak</TOKEN>
<TOKEN end_char="10107" id="token-89-7" morph="none" pos="word" start_char="10104">will</TOKEN>
<TOKEN end_char="10112" id="token-89-8" morph="none" pos="word" start_char="10109">fade</TOKEN>
<TOKEN end_char="10115" id="token-89-9" morph="none" pos="word" start_char="10114">by</TOKEN>
<TOKEN end_char="10122" id="token-89-10" morph="none" pos="word" start_char="10117">summer</TOKEN>
<TOKEN end_char="10123" id="token-89-11" morph="none" pos="punct" start_char="10123">,</TOKEN>
<TOKEN end_char="10127" id="token-89-12" morph="none" pos="word" start_char="10125">and</TOKEN>
<TOKEN end_char="10132" id="token-89-13" morph="none" pos="word" start_char="10129">with</TOKEN>
<TOKEN end_char="10135" id="token-89-14" morph="none" pos="word" start_char="10134">it</TOKEN>
<TOKEN end_char="10139" id="token-89-15" morph="none" pos="word" start_char="10137">the</TOKEN>
<TOKEN end_char="10147" id="token-89-16" morph="none" pos="word" start_char="10141">urgency</TOKEN>
<TOKEN end_char="10150" id="token-89-17" morph="none" pos="word" start_char="10149">of</TOKEN>
<TOKEN end_char="10157" id="token-89-18" morph="none" pos="word" start_char="10152">having</TOKEN>
<TOKEN end_char="10159" id="token-89-19" morph="none" pos="word" start_char="10159">a</TOKEN>
<TOKEN end_char="10167" id="token-89-20" morph="none" pos="word" start_char="10161">vaccine</TOKEN>
<TOKEN end_char="10170" id="token-89-21" morph="none" pos="word" start_char="10169">at</TOKEN>
<TOKEN end_char="10174" id="token-89-22" morph="none" pos="word" start_char="10172">the</TOKEN>
<TOKEN end_char="10180" id="token-89-23" morph="none" pos="word" start_char="10176">ready</TOKEN>
<TOKEN end_char="10181" id="token-89-24" morph="none" pos="punct" start_char="10181">.</TOKEN>
</SEG>
<SEG end_char="10257" id="segment-90" start_char="10183">
<ORIGINAL_TEXT>"Nobody knows what's going to happen," says Stéphane Bancel, Moderna's CEO.</ORIGINAL_TEXT>
<TOKEN end_char="10183" id="token-90-0" morph="none" pos="punct" start_char="10183">"</TOKEN>
<TOKEN end_char="10189" id="token-90-1" morph="none" pos="word" start_char="10184">Nobody</TOKEN>
<TOKEN end_char="10195" id="token-90-2" morph="none" pos="word" start_char="10191">knows</TOKEN>
<TOKEN end_char="10202" id="token-90-3" morph="none" pos="word" start_char="10197">what's</TOKEN>
<TOKEN end_char="10208" id="token-90-4" morph="none" pos="word" start_char="10204">going</TOKEN>
<TOKEN end_char="10211" id="token-90-5" morph="none" pos="word" start_char="10210">to</TOKEN>
<TOKEN end_char="10218" id="token-90-6" morph="none" pos="word" start_char="10213">happen</TOKEN>
<TOKEN end_char="10220" id="token-90-7" morph="none" pos="punct" start_char="10219">,"</TOKEN>
<TOKEN end_char="10225" id="token-90-8" morph="none" pos="word" start_char="10222">says</TOKEN>
<TOKEN end_char="10234" id="token-90-9" morph="none" pos="word" start_char="10227">Stéphane</TOKEN>
<TOKEN end_char="10241" id="token-90-10" morph="none" pos="word" start_char="10236">Bancel</TOKEN>
<TOKEN end_char="10242" id="token-90-11" morph="none" pos="punct" start_char="10242">,</TOKEN>
<TOKEN end_char="10252" id="token-90-12" morph="none" pos="word" start_char="10244">Moderna's</TOKEN>
<TOKEN end_char="10256" id="token-90-13" morph="none" pos="word" start_char="10254">CEO</TOKEN>
<TOKEN end_char="10257" id="token-90-14" morph="none" pos="punct" start_char="10257">.</TOKEN>
</SEG>
<SEG end_char="10307" id="segment-91" start_char="10259">
<ORIGINAL_TEXT>"We're all hoping we'll never need this vaccine."</ORIGINAL_TEXT>
<TOKEN end_char="10259" id="token-91-0" morph="none" pos="punct" start_char="10259">"</TOKEN>
<TOKEN end_char="10264" id="token-91-1" morph="none" pos="word" start_char="10260">We're</TOKEN>
<TOKEN end_char="10268" id="token-91-2" morph="none" pos="word" start_char="10266">all</TOKEN>
<TOKEN end_char="10275" id="token-91-3" morph="none" pos="word" start_char="10270">hoping</TOKEN>
<TOKEN end_char="10281" id="token-91-4" morph="none" pos="word" start_char="10277">we'll</TOKEN>
<TOKEN end_char="10287" id="token-91-5" morph="none" pos="word" start_char="10283">never</TOKEN>
<TOKEN end_char="10292" id="token-91-6" morph="none" pos="word" start_char="10289">need</TOKEN>
<TOKEN end_char="10297" id="token-91-7" morph="none" pos="word" start_char="10294">this</TOKEN>
<TOKEN end_char="10305" id="token-91-8" morph="none" pos="word" start_char="10299">vaccine</TOKEN>
<TOKEN end_char="10307" id="token-91-9" morph="none" pos="punct" start_char="10306">."</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="ukr">
<DOC grammar="none" id="L0C049P6S" lang="ukr" raw_text_char_length="7366" raw_text_md5="399705cbecb81005c08b4ddd7c49b891" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="83" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Fact Check: There is NOT An 'Irrefutable Paper Trail' To Prove COVID-19 Is Lab-made</ORIGINAL_TEXT>
<TOKEN end_char="4" id="token-0-0" morph="none" pos="word" start_char="1">Fact</TOKEN>
<TOKEN end_char="10" id="token-0-1" morph="none" pos="word" start_char="6">Check</TOKEN>
<TOKEN end_char="11" id="token-0-2" morph="none" pos="punct" start_char="11">:</TOKEN>
<TOKEN end_char="17" id="token-0-3" morph="none" pos="word" start_char="13">There</TOKEN>
<TOKEN end_char="20" id="token-0-4" morph="none" pos="word" start_char="19">is</TOKEN>
<TOKEN end_char="24" id="token-0-5" morph="none" pos="word" start_char="22">NOT</TOKEN>
<TOKEN end_char="27" id="token-0-6" morph="none" pos="word" start_char="26">An</TOKEN>
<TOKEN end_char="29" id="token-0-7" morph="none" pos="punct" start_char="29">'</TOKEN>
<TOKEN end_char="40" id="token-0-8" morph="none" pos="word" start_char="30">Irrefutable</TOKEN>
<TOKEN end_char="46" id="token-0-9" morph="none" pos="word" start_char="42">Paper</TOKEN>
<TOKEN end_char="52" id="token-0-10" morph="none" pos="word" start_char="48">Trail</TOKEN>
<TOKEN end_char="53" id="token-0-11" morph="none" pos="punct" start_char="53">'</TOKEN>
<TOKEN end_char="56" id="token-0-12" morph="none" pos="word" start_char="55">To</TOKEN>
<TOKEN end_char="62" id="token-0-13" morph="none" pos="word" start_char="58">Prove</TOKEN>
<TOKEN end_char="71" id="token-0-14" morph="none" pos="unknown" start_char="64">COVID-19</TOKEN>
<TOKEN end_char="74" id="token-0-15" morph="none" pos="word" start_char="73">Is</TOKEN>
<TOKEN end_char="83" id="token-0-16" morph="none" pos="unknown" start_char="76">Lab-made</TOKEN>
</SEG>
<SEG end_char="99" id="segment-1" start_char="88">
<ORIGINAL_TEXT>Loaded Query</ORIGINAL_TEXT>
<TOKEN end_char="93" id="token-1-0" morph="none" pos="word" start_char="88">Loaded</TOKEN>
<TOKEN end_char="99" id="token-1-1" morph="none" pos="word" start_char="95">Query</TOKEN>
</SEG>
<SEG end_char="193" id="segment-2" start_char="103">
<ORIGINAL_TEXT>Is there an "irrefutable paper trail" that shows COVID-19 was manufactured in a laboratory?</ORIGINAL_TEXT>
<TOKEN end_char="104" id="token-2-0" morph="none" pos="word" start_char="103">Is</TOKEN>
<TOKEN end_char="110" id="token-2-1" morph="none" pos="word" start_char="106">there</TOKEN>
<TOKEN end_char="113" id="token-2-2" morph="none" pos="word" start_char="112">an</TOKEN>
<TOKEN end_char="115" id="token-2-3" morph="none" pos="punct" start_char="115">"</TOKEN>
<TOKEN end_char="126" id="token-2-4" morph="none" pos="word" start_char="116">irrefutable</TOKEN>
<TOKEN end_char="132" id="token-2-5" morph="none" pos="word" start_char="128">paper</TOKEN>
<TOKEN end_char="138" id="token-2-6" morph="none" pos="word" start_char="134">trail</TOKEN>
<TOKEN end_char="139" id="token-2-7" morph="none" pos="punct" start_char="139">"</TOKEN>
<TOKEN end_char="144" id="token-2-8" morph="none" pos="word" start_char="141">that</TOKEN>
<TOKEN end_char="150" id="token-2-9" morph="none" pos="word" start_char="146">shows</TOKEN>
<TOKEN end_char="159" id="token-2-10" morph="none" pos="unknown" start_char="152">COVID-19</TOKEN>
<TOKEN end_char="163" id="token-2-11" morph="none" pos="word" start_char="161">was</TOKEN>
<TOKEN end_char="176" id="token-2-12" morph="none" pos="word" start_char="165">manufactured</TOKEN>
<TOKEN end_char="179" id="token-2-13" morph="none" pos="word" start_char="178">in</TOKEN>
<TOKEN end_char="181" id="token-2-14" morph="none" pos="word" start_char="181">a</TOKEN>
<TOKEN end_char="192" id="token-2-15" morph="none" pos="word" start_char="183">laboratory</TOKEN>
<TOKEN end_char="193" id="token-2-16" morph="none" pos="punct" start_char="193">?</TOKEN>
</SEG>
<SEG end_char="632" id="segment-3" start_char="195">
<ORIGINAL_TEXT>No, that's not true: Screenshots taken from the rapid-fire display of documents in the video making that claim show only that a number of scientists have in the past worried that lab tests on a coronavirus could lead to an outbreak, that the U.S. Centers for Disease Control and Prevention once patented methods to detect a non-COVID-19 coronavirus, and that other conspiracy-mongers claim to have proven the pandemic of 2020 is man-made.</ORIGINAL_TEXT>
<TOKEN end_char="196" id="token-3-0" morph="none" pos="word" start_char="195">No</TOKEN>
<TOKEN end_char="197" id="token-3-1" morph="none" pos="punct" start_char="197">,</TOKEN>
<TOKEN end_char="204" id="token-3-2" morph="none" pos="word" start_char="199">that's</TOKEN>
<TOKEN end_char="208" id="token-3-3" morph="none" pos="word" start_char="206">not</TOKEN>
<TOKEN end_char="213" id="token-3-4" morph="none" pos="word" start_char="210">true</TOKEN>
<TOKEN end_char="214" id="token-3-5" morph="none" pos="punct" start_char="214">:</TOKEN>
<TOKEN end_char="226" id="token-3-6" morph="none" pos="word" start_char="216">Screenshots</TOKEN>
<TOKEN end_char="232" id="token-3-7" morph="none" pos="word" start_char="228">taken</TOKEN>
<TOKEN end_char="237" id="token-3-8" morph="none" pos="word" start_char="234">from</TOKEN>
<TOKEN end_char="241" id="token-3-9" morph="none" pos="word" start_char="239">the</TOKEN>
<TOKEN end_char="252" id="token-3-10" morph="none" pos="unknown" start_char="243">rapid-fire</TOKEN>
<TOKEN end_char="260" id="token-3-11" morph="none" pos="word" start_char="254">display</TOKEN>
<TOKEN end_char="263" id="token-3-12" morph="none" pos="word" start_char="262">of</TOKEN>
<TOKEN end_char="273" id="token-3-13" morph="none" pos="word" start_char="265">documents</TOKEN>
<TOKEN end_char="276" id="token-3-14" morph="none" pos="word" start_char="275">in</TOKEN>
<TOKEN end_char="280" id="token-3-15" morph="none" pos="word" start_char="278">the</TOKEN>
<TOKEN end_char="286" id="token-3-16" morph="none" pos="word" start_char="282">video</TOKEN>
<TOKEN end_char="293" id="token-3-17" morph="none" pos="word" start_char="288">making</TOKEN>
<TOKEN end_char="298" id="token-3-18" morph="none" pos="word" start_char="295">that</TOKEN>
<TOKEN end_char="304" id="token-3-19" morph="none" pos="word" start_char="300">claim</TOKEN>
<TOKEN end_char="309" id="token-3-20" morph="none" pos="word" start_char="306">show</TOKEN>
<TOKEN end_char="314" id="token-3-21" morph="none" pos="word" start_char="311">only</TOKEN>
<TOKEN end_char="319" id="token-3-22" morph="none" pos="word" start_char="316">that</TOKEN>
<TOKEN end_char="321" id="token-3-23" morph="none" pos="word" start_char="321">a</TOKEN>
<TOKEN end_char="328" id="token-3-24" morph="none" pos="word" start_char="323">number</TOKEN>
<TOKEN end_char="331" id="token-3-25" morph="none" pos="word" start_char="330">of</TOKEN>
<TOKEN end_char="342" id="token-3-26" morph="none" pos="word" start_char="333">scientists</TOKEN>
<TOKEN end_char="347" id="token-3-27" morph="none" pos="word" start_char="344">have</TOKEN>
<TOKEN end_char="350" id="token-3-28" morph="none" pos="word" start_char="349">in</TOKEN>
<TOKEN end_char="354" id="token-3-29" morph="none" pos="word" start_char="352">the</TOKEN>
<TOKEN end_char="359" id="token-3-30" morph="none" pos="word" start_char="356">past</TOKEN>
<TOKEN end_char="367" id="token-3-31" morph="none" pos="word" start_char="361">worried</TOKEN>
<TOKEN end_char="372" id="token-3-32" morph="none" pos="word" start_char="369">that</TOKEN>
<TOKEN end_char="376" id="token-3-33" morph="none" pos="word" start_char="374">lab</TOKEN>
<TOKEN end_char="382" id="token-3-34" morph="none" pos="word" start_char="378">tests</TOKEN>
<TOKEN end_char="385" id="token-3-35" morph="none" pos="word" start_char="384">on</TOKEN>
<TOKEN end_char="387" id="token-3-36" morph="none" pos="word" start_char="387">a</TOKEN>
<TOKEN end_char="399" id="token-3-37" morph="none" pos="word" start_char="389">coronavirus</TOKEN>
<TOKEN end_char="405" id="token-3-38" morph="none" pos="word" start_char="401">could</TOKEN>
<TOKEN end_char="410" id="token-3-39" morph="none" pos="word" start_char="407">lead</TOKEN>
<TOKEN end_char="413" id="token-3-40" morph="none" pos="word" start_char="412">to</TOKEN>
<TOKEN end_char="416" id="token-3-41" morph="none" pos="word" start_char="415">an</TOKEN>
<TOKEN end_char="425" id="token-3-42" morph="none" pos="word" start_char="418">outbreak</TOKEN>
<TOKEN end_char="426" id="token-3-43" morph="none" pos="punct" start_char="426">,</TOKEN>
<TOKEN end_char="431" id="token-3-44" morph="none" pos="word" start_char="428">that</TOKEN>
<TOKEN end_char="435" id="token-3-45" morph="none" pos="word" start_char="433">the</TOKEN>
<TOKEN end_char="439" id="token-3-46" morph="none" pos="unknown" start_char="437">U.S</TOKEN>
<TOKEN end_char="440" id="token-3-47" morph="none" pos="punct" start_char="440">.</TOKEN>
<TOKEN end_char="448" id="token-3-48" morph="none" pos="word" start_char="442">Centers</TOKEN>
<TOKEN end_char="452" id="token-3-49" morph="none" pos="word" start_char="450">for</TOKEN>
<TOKEN end_char="460" id="token-3-50" morph="none" pos="word" start_char="454">Disease</TOKEN>
<TOKEN end_char="468" id="token-3-51" morph="none" pos="word" start_char="462">Control</TOKEN>
<TOKEN end_char="472" id="token-3-52" morph="none" pos="word" start_char="470">and</TOKEN>
<TOKEN end_char="483" id="token-3-53" morph="none" pos="word" start_char="474">Prevention</TOKEN>
<TOKEN end_char="488" id="token-3-54" morph="none" pos="word" start_char="485">once</TOKEN>
<TOKEN end_char="497" id="token-3-55" morph="none" pos="word" start_char="490">patented</TOKEN>
<TOKEN end_char="505" id="token-3-56" morph="none" pos="word" start_char="499">methods</TOKEN>
<TOKEN end_char="508" id="token-3-57" morph="none" pos="word" start_char="507">to</TOKEN>
<TOKEN end_char="515" id="token-3-58" morph="none" pos="word" start_char="510">detect</TOKEN>
<TOKEN end_char="517" id="token-3-59" morph="none" pos="word" start_char="517">a</TOKEN>
<TOKEN end_char="530" id="token-3-60" morph="none" pos="unknown" start_char="519">non-COVID-19</TOKEN>
<TOKEN end_char="542" id="token-3-61" morph="none" pos="word" start_char="532">coronavirus</TOKEN>
<TOKEN end_char="543" id="token-3-62" morph="none" pos="punct" start_char="543">,</TOKEN>
<TOKEN end_char="547" id="token-3-63" morph="none" pos="word" start_char="545">and</TOKEN>
<TOKEN end_char="552" id="token-3-64" morph="none" pos="word" start_char="549">that</TOKEN>
<TOKEN end_char="558" id="token-3-65" morph="none" pos="word" start_char="554">other</TOKEN>
<TOKEN end_char="577" id="token-3-66" morph="none" pos="unknown" start_char="560">conspiracy-mongers</TOKEN>
<TOKEN end_char="583" id="token-3-67" morph="none" pos="word" start_char="579">claim</TOKEN>
<TOKEN end_char="586" id="token-3-68" morph="none" pos="word" start_char="585">to</TOKEN>
<TOKEN end_char="591" id="token-3-69" morph="none" pos="word" start_char="588">have</TOKEN>
<TOKEN end_char="598" id="token-3-70" morph="none" pos="word" start_char="593">proven</TOKEN>
<TOKEN end_char="602" id="token-3-71" morph="none" pos="word" start_char="600">the</TOKEN>
<TOKEN end_char="611" id="token-3-72" morph="none" pos="word" start_char="604">pandemic</TOKEN>
<TOKEN end_char="614" id="token-3-73" morph="none" pos="word" start_char="613">of</TOKEN>
<TOKEN end_char="619" id="token-3-74" morph="none" pos="word" start_char="616">2020</TOKEN>
<TOKEN end_char="622" id="token-3-75" morph="none" pos="word" start_char="621">is</TOKEN>
<TOKEN end_char="631" id="token-3-76" morph="none" pos="unknown" start_char="624">man-made</TOKEN>
<TOKEN end_char="632" id="token-3-77" morph="none" pos="punct" start_char="632">.</TOKEN>
</SEG>
<SEG end_char="757" id="segment-4" start_char="635">
<ORIGINAL_TEXT>The claim appears in a Facebook video (archived here) posted by Ben Swann, a host of a Kremlin-controlled TV show, on Sept.</ORIGINAL_TEXT>
<TOKEN end_char="637" id="token-4-0" morph="none" pos="word" start_char="635">The</TOKEN>
<TOKEN end_char="643" id="token-4-1" morph="none" pos="word" start_char="639">claim</TOKEN>
<TOKEN end_char="651" id="token-4-2" morph="none" pos="word" start_char="645">appears</TOKEN>
<TOKEN end_char="654" id="token-4-3" morph="none" pos="word" start_char="653">in</TOKEN>
<TOKEN end_char="656" id="token-4-4" morph="none" pos="word" start_char="656">a</TOKEN>
<TOKEN end_char="665" id="token-4-5" morph="none" pos="word" start_char="658">Facebook</TOKEN>
<TOKEN end_char="671" id="token-4-6" morph="none" pos="word" start_char="667">video</TOKEN>
<TOKEN end_char="673" id="token-4-7" morph="none" pos="punct" start_char="673">(</TOKEN>
<TOKEN end_char="681" id="token-4-8" morph="none" pos="word" start_char="674">archived</TOKEN>
<TOKEN end_char="686" id="token-4-9" morph="none" pos="word" start_char="683">here</TOKEN>
<TOKEN end_char="687" id="token-4-10" morph="none" pos="punct" start_char="687">)</TOKEN>
<TOKEN end_char="694" id="token-4-11" morph="none" pos="word" start_char="689">posted</TOKEN>
<TOKEN end_char="697" id="token-4-12" morph="none" pos="word" start_char="696">by</TOKEN>
<TOKEN end_char="701" id="token-4-13" morph="none" pos="word" start_char="699">Ben</TOKEN>
<TOKEN end_char="707" id="token-4-14" morph="none" pos="word" start_char="703">Swann</TOKEN>
<TOKEN end_char="708" id="token-4-15" morph="none" pos="punct" start_char="708">,</TOKEN>
<TOKEN end_char="710" id="token-4-16" morph="none" pos="word" start_char="710">a</TOKEN>
<TOKEN end_char="715" id="token-4-17" morph="none" pos="word" start_char="712">host</TOKEN>
<TOKEN end_char="718" id="token-4-18" morph="none" pos="word" start_char="717">of</TOKEN>
<TOKEN end_char="720" id="token-4-19" morph="none" pos="word" start_char="720">a</TOKEN>
<TOKEN end_char="739" id="token-4-20" morph="none" pos="unknown" start_char="722">Kremlin-controlled</TOKEN>
<TOKEN end_char="742" id="token-4-21" morph="none" pos="word" start_char="741">TV</TOKEN>
<TOKEN end_char="747" id="token-4-22" morph="none" pos="word" start_char="744">show</TOKEN>
<TOKEN end_char="748" id="token-4-23" morph="none" pos="punct" start_char="748">,</TOKEN>
<TOKEN end_char="751" id="token-4-24" morph="none" pos="word" start_char="750">on</TOKEN>
<TOKEN end_char="756" id="token-4-25" morph="none" pos="word" start_char="753">Sept</TOKEN>
<TOKEN end_char="757" id="token-4-26" morph="none" pos="punct" start_char="757">.</TOKEN>
</SEG>
<SEG end_char="791" id="segment-5" start_char="759">
<ORIGINAL_TEXT>5, 2020, with the following text:</ORIGINAL_TEXT>
<TOKEN end_char="759" id="token-5-0" morph="none" pos="word" start_char="759">5</TOKEN>
<TOKEN end_char="760" id="token-5-1" morph="none" pos="punct" start_char="760">,</TOKEN>
<TOKEN end_char="765" id="token-5-2" morph="none" pos="word" start_char="762">2020</TOKEN>
<TOKEN end_char="766" id="token-5-3" morph="none" pos="punct" start_char="766">,</TOKEN>
<TOKEN end_char="771" id="token-5-4" morph="none" pos="word" start_char="768">with</TOKEN>
<TOKEN end_char="775" id="token-5-5" morph="none" pos="word" start_char="773">the</TOKEN>
<TOKEN end_char="785" id="token-5-6" morph="none" pos="word" start_char="777">following</TOKEN>
<TOKEN end_char="790" id="token-5-7" morph="none" pos="word" start_char="787">text</TOKEN>
<TOKEN end_char="791" id="token-5-8" morph="none" pos="punct" start_char="791">:</TOKEN>
</SEG>
<SEG end_char="796" id="segment-6" start_char="794">
<ORIGINAL_TEXT>Dr.</ORIGINAL_TEXT>
<TOKEN end_char="795" id="token-6-0" morph="none" pos="word" start_char="794">Dr</TOKEN>
<TOKEN end_char="796" id="token-6-1" morph="none" pos="punct" start_char="796">.</TOKEN>
<TRANSLATED_TEXT>dr.</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="922" id="segment-7" start_char="798">
<ORIGINAL_TEXT>David Martin discusses the irrefutable paper trail that shows C0R0NAVlRUS was manipulated by DARPA, the NIH and Chinese Labs.</ORIGINAL_TEXT>
<TOKEN end_char="802" id="token-7-0" morph="none" pos="word" start_char="798">David</TOKEN>
<TOKEN end_char="809" id="token-7-1" morph="none" pos="word" start_char="804">Martin</TOKEN>
<TOKEN end_char="819" id="token-7-2" morph="none" pos="word" start_char="811">discusses</TOKEN>
<TOKEN end_char="823" id="token-7-3" morph="none" pos="word" start_char="821">the</TOKEN>
<TOKEN end_char="835" id="token-7-4" morph="none" pos="word" start_char="825">irrefutable</TOKEN>
<TOKEN end_char="841" id="token-7-5" morph="none" pos="word" start_char="837">paper</TOKEN>
<TOKEN end_char="847" id="token-7-6" morph="none" pos="word" start_char="843">trail</TOKEN>
<TOKEN end_char="852" id="token-7-7" morph="none" pos="word" start_char="849">that</TOKEN>
<TOKEN end_char="858" id="token-7-8" morph="none" pos="word" start_char="854">shows</TOKEN>
<TOKEN end_char="870" id="token-7-9" morph="none" pos="word" start_char="860">C0R0NAVlRUS</TOKEN>
<TOKEN end_char="874" id="token-7-10" morph="none" pos="word" start_char="872">was</TOKEN>
<TOKEN end_char="886" id="token-7-11" morph="none" pos="word" start_char="876">manipulated</TOKEN>
<TOKEN end_char="889" id="token-7-12" morph="none" pos="word" start_char="888">by</TOKEN>
<TOKEN end_char="895" id="token-7-13" morph="none" pos="word" start_char="891">DARPA</TOKEN>
<TOKEN end_char="896" id="token-7-14" morph="none" pos="punct" start_char="896">,</TOKEN>
<TOKEN end_char="900" id="token-7-15" morph="none" pos="word" start_char="898">the</TOKEN>
<TOKEN end_char="904" id="token-7-16" morph="none" pos="word" start_char="902">NIH</TOKEN>
<TOKEN end_char="908" id="token-7-17" morph="none" pos="word" start_char="906">and</TOKEN>
<TOKEN end_char="916" id="token-7-18" morph="none" pos="word" start_char="910">Chinese</TOKEN>
<TOKEN end_char="921" id="token-7-19" morph="none" pos="word" start_char="918">Labs</TOKEN>
<TOKEN end_char="922" id="token-7-20" morph="none" pos="punct" start_char="922">.</TOKEN>
</SEG>
<SEG end_char="985" id="segment-8" start_char="924">
<ORIGINAL_TEXT>Nothing in this report is "theory", it is all documented fact.</ORIGINAL_TEXT>
<TOKEN end_char="930" id="token-8-0" morph="none" pos="word" start_char="924">Nothing</TOKEN>
<TOKEN end_char="933" id="token-8-1" morph="none" pos="word" start_char="932">in</TOKEN>
<TOKEN end_char="938" id="token-8-2" morph="none" pos="word" start_char="935">this</TOKEN>
<TOKEN end_char="945" id="token-8-3" morph="none" pos="word" start_char="940">report</TOKEN>
<TOKEN end_char="948" id="token-8-4" morph="none" pos="word" start_char="947">is</TOKEN>
<TOKEN end_char="950" id="token-8-5" morph="none" pos="punct" start_char="950">"</TOKEN>
<TOKEN end_char="956" id="token-8-6" morph="none" pos="word" start_char="951">theory</TOKEN>
<TOKEN end_char="958" id="token-8-7" morph="none" pos="punct" start_char="957">",</TOKEN>
<TOKEN end_char="961" id="token-8-8" morph="none" pos="word" start_char="960">it</TOKEN>
<TOKEN end_char="964" id="token-8-9" morph="none" pos="word" start_char="963">is</TOKEN>
<TOKEN end_char="968" id="token-8-10" morph="none" pos="word" start_char="966">all</TOKEN>
<TOKEN end_char="979" id="token-8-11" morph="none" pos="word" start_char="970">documented</TOKEN>
<TOKEN end_char="984" id="token-8-12" morph="none" pos="word" start_char="981">fact</TOKEN>
<TOKEN end_char="985" id="token-8-13" morph="none" pos="punct" start_char="985">.</TOKEN>
</SEG>
<SEG end_char="1057" id="segment-9" start_char="989">
<ORIGINAL_TEXT>This is what the post looked like on Facebook at the time of writing:</ORIGINAL_TEXT>
<TOKEN end_char="992" id="token-9-0" morph="none" pos="word" start_char="989">This</TOKEN>
<TOKEN end_char="995" id="token-9-1" morph="none" pos="word" start_char="994">is</TOKEN>
<TOKEN end_char="1000" id="token-9-2" morph="none" pos="word" start_char="997">what</TOKEN>
<TOKEN end_char="1004" id="token-9-3" morph="none" pos="word" start_char="1002">the</TOKEN>
<TOKEN end_char="1009" id="token-9-4" morph="none" pos="word" start_char="1006">post</TOKEN>
<TOKEN end_char="1016" id="token-9-5" morph="none" pos="word" start_char="1011">looked</TOKEN>
<TOKEN end_char="1021" id="token-9-6" morph="none" pos="word" start_char="1018">like</TOKEN>
<TOKEN end_char="1024" id="token-9-7" morph="none" pos="word" start_char="1023">on</TOKEN>
<TOKEN end_char="1033" id="token-9-8" morph="none" pos="word" start_char="1026">Facebook</TOKEN>
<TOKEN end_char="1036" id="token-9-9" morph="none" pos="word" start_char="1035">at</TOKEN>
<TOKEN end_char="1040" id="token-9-10" morph="none" pos="word" start_char="1038">the</TOKEN>
<TOKEN end_char="1045" id="token-9-11" morph="none" pos="word" start_char="1042">time</TOKEN>
<TOKEN end_char="1048" id="token-9-12" morph="none" pos="word" start_char="1047">of</TOKEN>
<TOKEN end_char="1056" id="token-9-13" morph="none" pos="word" start_char="1050">writing</TOKEN>
<TOKEN end_char="1057" id="token-9-14" morph="none" pos="punct" start_char="1057">:</TOKEN>
</SEG>
<SEG end_char="1127" id="segment-10" start_char="1062">
<ORIGINAL_TEXT>(Source: Facebook screenshot taken on Tue Sep 8 20:46:47 2020 UTC)</ORIGINAL_TEXT>
<TOKEN end_char="1062" id="token-10-0" morph="none" pos="punct" start_char="1062">(</TOKEN>
<TOKEN end_char="1068" id="token-10-1" morph="none" pos="word" start_char="1063">Source</TOKEN>
<TOKEN end_char="1069" id="token-10-2" morph="none" pos="punct" start_char="1069">:</TOKEN>
<TOKEN end_char="1078" id="token-10-3" morph="none" pos="word" start_char="1071">Facebook</TOKEN>
<TOKEN end_char="1089" id="token-10-4" morph="none" pos="word" start_char="1080">screenshot</TOKEN>
<TOKEN end_char="1095" id="token-10-5" morph="none" pos="word" start_char="1091">taken</TOKEN>
<TOKEN end_char="1098" id="token-10-6" morph="none" pos="word" start_char="1097">on</TOKEN>
<TOKEN end_char="1102" id="token-10-7" morph="none" pos="word" start_char="1100">Tue</TOKEN>
<TOKEN end_char="1106" id="token-10-8" morph="none" pos="word" start_char="1104">Sep</TOKEN>
<TOKEN end_char="1108" id="token-10-9" morph="none" pos="word" start_char="1108">8</TOKEN>
<TOKEN end_char="1117" id="token-10-10" morph="none" pos="unknown" start_char="1110">20:46:47</TOKEN>
<TOKEN end_char="1122" id="token-10-11" morph="none" pos="word" start_char="1119">2020</TOKEN>
<TOKEN end_char="1126" id="token-10-12" morph="none" pos="word" start_char="1124">UTC</TOKEN>
<TOKEN end_char="1127" id="token-10-13" morph="none" pos="punct" start_char="1127">)</TOKEN>
</SEG>
<SEG end_char="1247" id="segment-11" start_char="1131">
<ORIGINAL_TEXT>The video features Ben Swann, a host for Russia's global propaganda network -- RT -- and a businessman named David E.</ORIGINAL_TEXT>
<TOKEN end_char="1133" id="token-11-0" morph="none" pos="word" start_char="1131">The</TOKEN>
<TOKEN end_char="1139" id="token-11-1" morph="none" pos="word" start_char="1135">video</TOKEN>
<TOKEN end_char="1148" id="token-11-2" morph="none" pos="word" start_char="1141">features</TOKEN>
<TOKEN end_char="1152" id="token-11-3" morph="none" pos="word" start_char="1150">Ben</TOKEN>
<TOKEN end_char="1158" id="token-11-4" morph="none" pos="word" start_char="1154">Swann</TOKEN>
<TOKEN end_char="1159" id="token-11-5" morph="none" pos="punct" start_char="1159">,</TOKEN>
<TOKEN end_char="1161" id="token-11-6" morph="none" pos="word" start_char="1161">a</TOKEN>
<TOKEN end_char="1166" id="token-11-7" morph="none" pos="word" start_char="1163">host</TOKEN>
<TOKEN end_char="1170" id="token-11-8" morph="none" pos="word" start_char="1168">for</TOKEN>
<TOKEN end_char="1179" id="token-11-9" morph="none" pos="word" start_char="1172">Russia's</TOKEN>
<TOKEN end_char="1186" id="token-11-10" morph="none" pos="word" start_char="1181">global</TOKEN>
<TOKEN end_char="1197" id="token-11-11" morph="none" pos="word" start_char="1188">propaganda</TOKEN>
<TOKEN end_char="1205" id="token-11-12" morph="none" pos="word" start_char="1199">network</TOKEN>
<TOKEN end_char="1208" id="token-11-13" morph="none" pos="punct" start_char="1207">--</TOKEN>
<TOKEN end_char="1211" id="token-11-14" morph="none" pos="word" start_char="1210">RT</TOKEN>
<TOKEN end_char="1214" id="token-11-15" morph="none" pos="punct" start_char="1213">--</TOKEN>
<TOKEN end_char="1218" id="token-11-16" morph="none" pos="word" start_char="1216">and</TOKEN>
<TOKEN end_char="1220" id="token-11-17" morph="none" pos="word" start_char="1220">a</TOKEN>
<TOKEN end_char="1232" id="token-11-18" morph="none" pos="word" start_char="1222">businessman</TOKEN>
<TOKEN end_char="1238" id="token-11-19" morph="none" pos="word" start_char="1234">named</TOKEN>
<TOKEN end_char="1244" id="token-11-20" morph="none" pos="word" start_char="1240">David</TOKEN>
<TOKEN end_char="1246" id="token-11-21" morph="none" pos="word" start_char="1246">E</TOKEN>
<TOKEN end_char="1247" id="token-11-22" morph="none" pos="punct" start_char="1247">.</TOKEN>
</SEG>
<SEG end_char="1427" id="segment-12" start_char="1249">
<ORIGINAL_TEXT>Martin who sells self-actualization books and has operated two small (sub $1.5 million) hedge funds and a trio of exchange-traded mutual funds, among other investing-related jobs.</ORIGINAL_TEXT>
<TOKEN end_char="1254" id="token-12-0" morph="none" pos="word" start_char="1249">Martin</TOKEN>
<TOKEN end_char="1258" id="token-12-1" morph="none" pos="word" start_char="1256">who</TOKEN>
<TOKEN end_char="1264" id="token-12-2" morph="none" pos="word" start_char="1260">sells</TOKEN>
<TOKEN end_char="1283" id="token-12-3" morph="none" pos="unknown" start_char="1266">self-actualization</TOKEN>
<TOKEN end_char="1289" id="token-12-4" morph="none" pos="word" start_char="1285">books</TOKEN>
<TOKEN end_char="1293" id="token-12-5" morph="none" pos="word" start_char="1291">and</TOKEN>
<TOKEN end_char="1297" id="token-12-6" morph="none" pos="word" start_char="1295">has</TOKEN>
<TOKEN end_char="1306" id="token-12-7" morph="none" pos="word" start_char="1299">operated</TOKEN>
<TOKEN end_char="1310" id="token-12-8" morph="none" pos="word" start_char="1308">two</TOKEN>
<TOKEN end_char="1316" id="token-12-9" morph="none" pos="word" start_char="1312">small</TOKEN>
<TOKEN end_char="1318" id="token-12-10" morph="none" pos="punct" start_char="1318">(</TOKEN>
<TOKEN end_char="1321" id="token-12-11" morph="none" pos="word" start_char="1319">sub</TOKEN>
<TOKEN end_char="1326" id="token-12-12" morph="none" pos="unknown" start_char="1323">$1.5</TOKEN>
<TOKEN end_char="1334" id="token-12-13" morph="none" pos="word" start_char="1328">million</TOKEN>
<TOKEN end_char="1335" id="token-12-14" morph="none" pos="punct" start_char="1335">)</TOKEN>
<TOKEN end_char="1341" id="token-12-15" morph="none" pos="word" start_char="1337">hedge</TOKEN>
<TOKEN end_char="1347" id="token-12-16" morph="none" pos="word" start_char="1343">funds</TOKEN>
<TOKEN end_char="1351" id="token-12-17" morph="none" pos="word" start_char="1349">and</TOKEN>
<TOKEN end_char="1353" id="token-12-18" morph="none" pos="word" start_char="1353">a</TOKEN>
<TOKEN end_char="1358" id="token-12-19" morph="none" pos="word" start_char="1355">trio</TOKEN>
<TOKEN end_char="1361" id="token-12-20" morph="none" pos="word" start_char="1360">of</TOKEN>
<TOKEN end_char="1377" id="token-12-21" morph="none" pos="unknown" start_char="1363">exchange-traded</TOKEN>
<TOKEN end_char="1384" id="token-12-22" morph="none" pos="word" start_char="1379">mutual</TOKEN>
<TOKEN end_char="1390" id="token-12-23" morph="none" pos="word" start_char="1386">funds</TOKEN>
<TOKEN end_char="1391" id="token-12-24" morph="none" pos="punct" start_char="1391">,</TOKEN>
<TOKEN end_char="1397" id="token-12-25" morph="none" pos="word" start_char="1393">among</TOKEN>
<TOKEN end_char="1403" id="token-12-26" morph="none" pos="word" start_char="1399">other</TOKEN>
<TOKEN end_char="1421" id="token-12-27" morph="none" pos="unknown" start_char="1405">investing-related</TOKEN>
<TOKEN end_char="1426" id="token-12-28" morph="none" pos="word" start_char="1423">jobs</TOKEN>
<TOKEN end_char="1427" id="token-12-29" morph="none" pos="punct" start_char="1427">.</TOKEN>
</SEG>
<SEG end_char="1515" id="segment-13" start_char="1429">
<ORIGINAL_TEXT>Although Martin is referred to as "doctor" throughout the video, he is not a physician.</ORIGINAL_TEXT>
<TOKEN end_char="1436" id="token-13-0" morph="none" pos="word" start_char="1429">Although</TOKEN>
<TOKEN end_char="1443" id="token-13-1" morph="none" pos="word" start_char="1438">Martin</TOKEN>
<TOKEN end_char="1446" id="token-13-2" morph="none" pos="word" start_char="1445">is</TOKEN>
<TOKEN end_char="1455" id="token-13-3" morph="none" pos="word" start_char="1448">referred</TOKEN>
<TOKEN end_char="1458" id="token-13-4" morph="none" pos="word" start_char="1457">to</TOKEN>
<TOKEN end_char="1461" id="token-13-5" morph="none" pos="word" start_char="1460">as</TOKEN>
<TOKEN end_char="1463" id="token-13-6" morph="none" pos="punct" start_char="1463">"</TOKEN>
<TOKEN end_char="1469" id="token-13-7" morph="none" pos="word" start_char="1464">doctor</TOKEN>
<TOKEN end_char="1470" id="token-13-8" morph="none" pos="punct" start_char="1470">"</TOKEN>
<TOKEN end_char="1481" id="token-13-9" morph="none" pos="word" start_char="1472">throughout</TOKEN>
<TOKEN end_char="1485" id="token-13-10" morph="none" pos="word" start_char="1483">the</TOKEN>
<TOKEN end_char="1491" id="token-13-11" morph="none" pos="word" start_char="1487">video</TOKEN>
<TOKEN end_char="1492" id="token-13-12" morph="none" pos="punct" start_char="1492">,</TOKEN>
<TOKEN end_char="1495" id="token-13-13" morph="none" pos="word" start_char="1494">he</TOKEN>
<TOKEN end_char="1498" id="token-13-14" morph="none" pos="word" start_char="1497">is</TOKEN>
<TOKEN end_char="1502" id="token-13-15" morph="none" pos="word" start_char="1500">not</TOKEN>
<TOKEN end_char="1504" id="token-13-16" morph="none" pos="word" start_char="1504">a</TOKEN>
<TOKEN end_char="1514" id="token-13-17" morph="none" pos="word" start_char="1506">physician</TOKEN>
<TOKEN end_char="1515" id="token-13-18" morph="none" pos="punct" start_char="1515">.</TOKEN>
</SEG>
<SEG end_char="1660" id="segment-14" start_char="1517">
<ORIGINAL_TEXT>He has a Ph.D., but neither Martin's office nor the University of Virginia will confirm the discipline in which he received his doctoral degree.</ORIGINAL_TEXT>
<TOKEN end_char="1518" id="token-14-0" morph="none" pos="word" start_char="1517">He</TOKEN>
<TOKEN end_char="1522" id="token-14-1" morph="none" pos="word" start_char="1520">has</TOKEN>
<TOKEN end_char="1524" id="token-14-2" morph="none" pos="word" start_char="1524">a</TOKEN>
<TOKEN end_char="1529" id="token-14-3" morph="none" pos="unknown" start_char="1526">Ph.D</TOKEN>
<TOKEN end_char="1531" id="token-14-4" morph="none" pos="punct" start_char="1530">.,</TOKEN>
<TOKEN end_char="1535" id="token-14-5" morph="none" pos="word" start_char="1533">but</TOKEN>
<TOKEN end_char="1543" id="token-14-6" morph="none" pos="word" start_char="1537">neither</TOKEN>
<TOKEN end_char="1552" id="token-14-7" morph="none" pos="word" start_char="1545">Martin's</TOKEN>
<TOKEN end_char="1559" id="token-14-8" morph="none" pos="word" start_char="1554">office</TOKEN>
<TOKEN end_char="1563" id="token-14-9" morph="none" pos="word" start_char="1561">nor</TOKEN>
<TOKEN end_char="1567" id="token-14-10" morph="none" pos="word" start_char="1565">the</TOKEN>
<TOKEN end_char="1578" id="token-14-11" morph="none" pos="word" start_char="1569">University</TOKEN>
<TOKEN end_char="1581" id="token-14-12" morph="none" pos="word" start_char="1580">of</TOKEN>
<TOKEN end_char="1590" id="token-14-13" morph="none" pos="word" start_char="1583">Virginia</TOKEN>
<TOKEN end_char="1595" id="token-14-14" morph="none" pos="word" start_char="1592">will</TOKEN>
<TOKEN end_char="1603" id="token-14-15" morph="none" pos="word" start_char="1597">confirm</TOKEN>
<TOKEN end_char="1607" id="token-14-16" morph="none" pos="word" start_char="1605">the</TOKEN>
<TOKEN end_char="1618" id="token-14-17" morph="none" pos="word" start_char="1609">discipline</TOKEN>
<TOKEN end_char="1621" id="token-14-18" morph="none" pos="word" start_char="1620">in</TOKEN>
<TOKEN end_char="1627" id="token-14-19" morph="none" pos="word" start_char="1623">which</TOKEN>
<TOKEN end_char="1630" id="token-14-20" morph="none" pos="word" start_char="1629">he</TOKEN>
<TOKEN end_char="1639" id="token-14-21" morph="none" pos="word" start_char="1632">received</TOKEN>
<TOKEN end_char="1643" id="token-14-22" morph="none" pos="word" start_char="1641">his</TOKEN>
<TOKEN end_char="1652" id="token-14-23" morph="none" pos="word" start_char="1645">doctoral</TOKEN>
<TOKEN end_char="1659" id="token-14-24" morph="none" pos="word" start_char="1654">degree</TOKEN>
<TOKEN end_char="1660" id="token-14-25" morph="none" pos="punct" start_char="1660">.</TOKEN>
</SEG>
<SEG end_char="2009" id="segment-15" start_char="1663">
<ORIGINAL_TEXT>The video -- which opens with a fund-raising pitch for Swann's streaming video business -- uses quick-cut editing techniques and ominous added shadows to create the impression of documentary evidence piling up in support of a conspiracy theory: That the Defense Advanced Research Projects Agency paid for the creation of pandemic-creating viruses.</ORIGINAL_TEXT>
<TOKEN end_char="1665" id="token-15-0" morph="none" pos="word" start_char="1663">The</TOKEN>
<TOKEN end_char="1671" id="token-15-1" morph="none" pos="word" start_char="1667">video</TOKEN>
<TOKEN end_char="1674" id="token-15-2" morph="none" pos="punct" start_char="1673">--</TOKEN>
<TOKEN end_char="1680" id="token-15-3" morph="none" pos="word" start_char="1676">which</TOKEN>
<TOKEN end_char="1686" id="token-15-4" morph="none" pos="word" start_char="1682">opens</TOKEN>
<TOKEN end_char="1691" id="token-15-5" morph="none" pos="word" start_char="1688">with</TOKEN>
<TOKEN end_char="1693" id="token-15-6" morph="none" pos="word" start_char="1693">a</TOKEN>
<TOKEN end_char="1706" id="token-15-7" morph="none" pos="unknown" start_char="1695">fund-raising</TOKEN>
<TOKEN end_char="1712" id="token-15-8" morph="none" pos="word" start_char="1708">pitch</TOKEN>
<TOKEN end_char="1716" id="token-15-9" morph="none" pos="word" start_char="1714">for</TOKEN>
<TOKEN end_char="1724" id="token-15-10" morph="none" pos="word" start_char="1718">Swann's</TOKEN>
<TOKEN end_char="1734" id="token-15-11" morph="none" pos="word" start_char="1726">streaming</TOKEN>
<TOKEN end_char="1740" id="token-15-12" morph="none" pos="word" start_char="1736">video</TOKEN>
<TOKEN end_char="1749" id="token-15-13" morph="none" pos="word" start_char="1742">business</TOKEN>
<TOKEN end_char="1752" id="token-15-14" morph="none" pos="punct" start_char="1751">--</TOKEN>
<TOKEN end_char="1757" id="token-15-15" morph="none" pos="word" start_char="1754">uses</TOKEN>
<TOKEN end_char="1767" id="token-15-16" morph="none" pos="unknown" start_char="1759">quick-cut</TOKEN>
<TOKEN end_char="1775" id="token-15-17" morph="none" pos="word" start_char="1769">editing</TOKEN>
<TOKEN end_char="1786" id="token-15-18" morph="none" pos="word" start_char="1777">techniques</TOKEN>
<TOKEN end_char="1790" id="token-15-19" morph="none" pos="word" start_char="1788">and</TOKEN>
<TOKEN end_char="1798" id="token-15-20" morph="none" pos="word" start_char="1792">ominous</TOKEN>
<TOKEN end_char="1804" id="token-15-21" morph="none" pos="word" start_char="1800">added</TOKEN>
<TOKEN end_char="1812" id="token-15-22" morph="none" pos="word" start_char="1806">shadows</TOKEN>
<TOKEN end_char="1815" id="token-15-23" morph="none" pos="word" start_char="1814">to</TOKEN>
<TOKEN end_char="1822" id="token-15-24" morph="none" pos="word" start_char="1817">create</TOKEN>
<TOKEN end_char="1826" id="token-15-25" morph="none" pos="word" start_char="1824">the</TOKEN>
<TOKEN end_char="1837" id="token-15-26" morph="none" pos="word" start_char="1828">impression</TOKEN>
<TOKEN end_char="1840" id="token-15-27" morph="none" pos="word" start_char="1839">of</TOKEN>
<TOKEN end_char="1852" id="token-15-28" morph="none" pos="word" start_char="1842">documentary</TOKEN>
<TOKEN end_char="1861" id="token-15-29" morph="none" pos="word" start_char="1854">evidence</TOKEN>
<TOKEN end_char="1868" id="token-15-30" morph="none" pos="word" start_char="1863">piling</TOKEN>
<TOKEN end_char="1871" id="token-15-31" morph="none" pos="word" start_char="1870">up</TOKEN>
<TOKEN end_char="1874" id="token-15-32" morph="none" pos="word" start_char="1873">in</TOKEN>
<TOKEN end_char="1882" id="token-15-33" morph="none" pos="word" start_char="1876">support</TOKEN>
<TOKEN end_char="1885" id="token-15-34" morph="none" pos="word" start_char="1884">of</TOKEN>
<TOKEN end_char="1887" id="token-15-35" morph="none" pos="word" start_char="1887">a</TOKEN>
<TOKEN end_char="1898" id="token-15-36" morph="none" pos="word" start_char="1889">conspiracy</TOKEN>
<TOKEN end_char="1905" id="token-15-37" morph="none" pos="word" start_char="1900">theory</TOKEN>
<TOKEN end_char="1906" id="token-15-38" morph="none" pos="punct" start_char="1906">:</TOKEN>
<TOKEN end_char="1911" id="token-15-39" morph="none" pos="word" start_char="1908">That</TOKEN>
<TOKEN end_char="1915" id="token-15-40" morph="none" pos="word" start_char="1913">the</TOKEN>
<TOKEN end_char="1923" id="token-15-41" morph="none" pos="word" start_char="1917">Defense</TOKEN>
<TOKEN end_char="1932" id="token-15-42" morph="none" pos="word" start_char="1925">Advanced</TOKEN>
<TOKEN end_char="1941" id="token-15-43" morph="none" pos="word" start_char="1934">Research</TOKEN>
<TOKEN end_char="1950" id="token-15-44" morph="none" pos="word" start_char="1943">Projects</TOKEN>
<TOKEN end_char="1957" id="token-15-45" morph="none" pos="word" start_char="1952">Agency</TOKEN>
<TOKEN end_char="1962" id="token-15-46" morph="none" pos="word" start_char="1959">paid</TOKEN>
<TOKEN end_char="1966" id="token-15-47" morph="none" pos="word" start_char="1964">for</TOKEN>
<TOKEN end_char="1970" id="token-15-48" morph="none" pos="word" start_char="1968">the</TOKEN>
<TOKEN end_char="1979" id="token-15-49" morph="none" pos="word" start_char="1972">creation</TOKEN>
<TOKEN end_char="1982" id="token-15-50" morph="none" pos="word" start_char="1981">of</TOKEN>
<TOKEN end_char="2000" id="token-15-51" morph="none" pos="unknown" start_char="1984">pandemic-creating</TOKEN>
<TOKEN end_char="2008" id="token-15-52" morph="none" pos="word" start_char="2002">viruses</TOKEN>
<TOKEN end_char="2009" id="token-15-53" morph="none" pos="punct" start_char="2009">.</TOKEN>
</SEG>
<SEG end_char="2266" id="segment-16" start_char="2011">
<ORIGINAL_TEXT>By examining each document, Lead Stories is able to show the gap in the evidentiary chain: No document shown in the video establishes that a lab-created virus caused the pandemic of 2020 and one of the documents offered as "proof" makes the opposite point.</ORIGINAL_TEXT>
<TOKEN end_char="2012" id="token-16-0" morph="none" pos="word" start_char="2011">By</TOKEN>
<TOKEN end_char="2022" id="token-16-1" morph="none" pos="word" start_char="2014">examining</TOKEN>
<TOKEN end_char="2027" id="token-16-2" morph="none" pos="word" start_char="2024">each</TOKEN>
<TOKEN end_char="2036" id="token-16-3" morph="none" pos="word" start_char="2029">document</TOKEN>
<TOKEN end_char="2037" id="token-16-4" morph="none" pos="punct" start_char="2037">,</TOKEN>
<TOKEN end_char="2042" id="token-16-5" morph="none" pos="word" start_char="2039">Lead</TOKEN>
<TOKEN end_char="2050" id="token-16-6" morph="none" pos="word" start_char="2044">Stories</TOKEN>
<TOKEN end_char="2053" id="token-16-7" morph="none" pos="word" start_char="2052">is</TOKEN>
<TOKEN end_char="2058" id="token-16-8" morph="none" pos="word" start_char="2055">able</TOKEN>
<TOKEN end_char="2061" id="token-16-9" morph="none" pos="word" start_char="2060">to</TOKEN>
<TOKEN end_char="2066" id="token-16-10" morph="none" pos="word" start_char="2063">show</TOKEN>
<TOKEN end_char="2070" id="token-16-11" morph="none" pos="word" start_char="2068">the</TOKEN>
<TOKEN end_char="2074" id="token-16-12" morph="none" pos="word" start_char="2072">gap</TOKEN>
<TOKEN end_char="2077" id="token-16-13" morph="none" pos="word" start_char="2076">in</TOKEN>
<TOKEN end_char="2081" id="token-16-14" morph="none" pos="word" start_char="2079">the</TOKEN>
<TOKEN end_char="2093" id="token-16-15" morph="none" pos="word" start_char="2083">evidentiary</TOKEN>
<TOKEN end_char="2099" id="token-16-16" morph="none" pos="word" start_char="2095">chain</TOKEN>
<TOKEN end_char="2100" id="token-16-17" morph="none" pos="punct" start_char="2100">:</TOKEN>
<TOKEN end_char="2103" id="token-16-18" morph="none" pos="word" start_char="2102">No</TOKEN>
<TOKEN end_char="2112" id="token-16-19" morph="none" pos="word" start_char="2105">document</TOKEN>
<TOKEN end_char="2118" id="token-16-20" morph="none" pos="word" start_char="2114">shown</TOKEN>
<TOKEN end_char="2121" id="token-16-21" morph="none" pos="word" start_char="2120">in</TOKEN>
<TOKEN end_char="2125" id="token-16-22" morph="none" pos="word" start_char="2123">the</TOKEN>
<TOKEN end_char="2131" id="token-16-23" morph="none" pos="word" start_char="2127">video</TOKEN>
<TOKEN end_char="2143" id="token-16-24" morph="none" pos="word" start_char="2133">establishes</TOKEN>
<TOKEN end_char="2148" id="token-16-25" morph="none" pos="word" start_char="2145">that</TOKEN>
<TOKEN end_char="2150" id="token-16-26" morph="none" pos="word" start_char="2150">a</TOKEN>
<TOKEN end_char="2162" id="token-16-27" morph="none" pos="unknown" start_char="2152">lab-created</TOKEN>
<TOKEN end_char="2168" id="token-16-28" morph="none" pos="word" start_char="2164">virus</TOKEN>
<TOKEN end_char="2175" id="token-16-29" morph="none" pos="word" start_char="2170">caused</TOKEN>
<TOKEN end_char="2179" id="token-16-30" morph="none" pos="word" start_char="2177">the</TOKEN>
<TOKEN end_char="2188" id="token-16-31" morph="none" pos="word" start_char="2181">pandemic</TOKEN>
<TOKEN end_char="2191" id="token-16-32" morph="none" pos="word" start_char="2190">of</TOKEN>
<TOKEN end_char="2196" id="token-16-33" morph="none" pos="word" start_char="2193">2020</TOKEN>
<TOKEN end_char="2200" id="token-16-34" morph="none" pos="word" start_char="2198">and</TOKEN>
<TOKEN end_char="2204" id="token-16-35" morph="none" pos="word" start_char="2202">one</TOKEN>
<TOKEN end_char="2207" id="token-16-36" morph="none" pos="word" start_char="2206">of</TOKEN>
<TOKEN end_char="2211" id="token-16-37" morph="none" pos="word" start_char="2209">the</TOKEN>
<TOKEN end_char="2221" id="token-16-38" morph="none" pos="word" start_char="2213">documents</TOKEN>
<TOKEN end_char="2229" id="token-16-39" morph="none" pos="word" start_char="2223">offered</TOKEN>
<TOKEN end_char="2232" id="token-16-40" morph="none" pos="word" start_char="2231">as</TOKEN>
<TOKEN end_char="2234" id="token-16-41" morph="none" pos="punct" start_char="2234">"</TOKEN>
<TOKEN end_char="2239" id="token-16-42" morph="none" pos="word" start_char="2235">proof</TOKEN>
<TOKEN end_char="2240" id="token-16-43" morph="none" pos="punct" start_char="2240">"</TOKEN>
<TOKEN end_char="2246" id="token-16-44" morph="none" pos="word" start_char="2242">makes</TOKEN>
<TOKEN end_char="2250" id="token-16-45" morph="none" pos="word" start_char="2248">the</TOKEN>
<TOKEN end_char="2259" id="token-16-46" morph="none" pos="word" start_char="2252">opposite</TOKEN>
<TOKEN end_char="2265" id="token-16-47" morph="none" pos="word" start_char="2261">point</TOKEN>
<TOKEN end_char="2266" id="token-16-48" morph="none" pos="punct" start_char="2266">.</TOKEN>
</SEG>
<SEG end_char="2367" id="segment-17" start_char="2269">
<ORIGINAL_TEXT>The video makes claims easily disproved in public documents, DARPA Chief of Communications Jared B.</ORIGINAL_TEXT>
<TOKEN end_char="2271" id="token-17-0" morph="none" pos="word" start_char="2269">The</TOKEN>
<TOKEN end_char="2277" id="token-17-1" morph="none" pos="word" start_char="2273">video</TOKEN>
<TOKEN end_char="2283" id="token-17-2" morph="none" pos="word" start_char="2279">makes</TOKEN>
<TOKEN end_char="2290" id="token-17-3" morph="none" pos="word" start_char="2285">claims</TOKEN>
<TOKEN end_char="2297" id="token-17-4" morph="none" pos="word" start_char="2292">easily</TOKEN>
<TOKEN end_char="2307" id="token-17-5" morph="none" pos="word" start_char="2299">disproved</TOKEN>
<TOKEN end_char="2310" id="token-17-6" morph="none" pos="word" start_char="2309">in</TOKEN>
<TOKEN end_char="2317" id="token-17-7" morph="none" pos="word" start_char="2312">public</TOKEN>
<TOKEN end_char="2327" id="token-17-8" morph="none" pos="word" start_char="2319">documents</TOKEN>
<TOKEN end_char="2328" id="token-17-9" morph="none" pos="punct" start_char="2328">,</TOKEN>
<TOKEN end_char="2334" id="token-17-10" morph="none" pos="word" start_char="2330">DARPA</TOKEN>
<TOKEN end_char="2340" id="token-17-11" morph="none" pos="word" start_char="2336">Chief</TOKEN>
<TOKEN end_char="2343" id="token-17-12" morph="none" pos="word" start_char="2342">of</TOKEN>
<TOKEN end_char="2358" id="token-17-13" morph="none" pos="word" start_char="2345">Communications</TOKEN>
<TOKEN end_char="2364" id="token-17-14" morph="none" pos="word" start_char="2360">Jared</TOKEN>
<TOKEN end_char="2366" id="token-17-15" morph="none" pos="word" start_char="2366">B</TOKEN>
<TOKEN end_char="2367" id="token-17-16" morph="none" pos="punct" start_char="2367">.</TOKEN>
</SEG>
<SEG end_char="2389" id="segment-18" start_char="2369">
<ORIGINAL_TEXT>Adams said in a Sept.</ORIGINAL_TEXT>
<TOKEN end_char="2373" id="token-18-0" morph="none" pos="word" start_char="2369">Adams</TOKEN>
<TOKEN end_char="2378" id="token-18-1" morph="none" pos="word" start_char="2375">said</TOKEN>
<TOKEN end_char="2381" id="token-18-2" morph="none" pos="word" start_char="2380">in</TOKEN>
<TOKEN end_char="2383" id="token-18-3" morph="none" pos="word" start_char="2383">a</TOKEN>
<TOKEN end_char="2388" id="token-18-4" morph="none" pos="word" start_char="2385">Sept</TOKEN>
<TOKEN end_char="2389" id="token-18-5" morph="none" pos="punct" start_char="2389">.</TOKEN>
</SEG>
<SEG end_char="2421" id="segment-19" start_char="2391">
<ORIGINAL_TEXT>9, 2020, email to Lead Stories.</ORIGINAL_TEXT>
<TOKEN end_char="2391" id="token-19-0" morph="none" pos="word" start_char="2391">9</TOKEN>
<TOKEN end_char="2392" id="token-19-1" morph="none" pos="punct" start_char="2392">,</TOKEN>
<TOKEN end_char="2397" id="token-19-2" morph="none" pos="word" start_char="2394">2020</TOKEN>
<TOKEN end_char="2398" id="token-19-3" morph="none" pos="punct" start_char="2398">,</TOKEN>
<TOKEN end_char="2404" id="token-19-4" morph="none" pos="word" start_char="2400">email</TOKEN>
<TOKEN end_char="2407" id="token-19-5" morph="none" pos="word" start_char="2406">to</TOKEN>
<TOKEN end_char="2412" id="token-19-6" morph="none" pos="word" start_char="2409">Lead</TOKEN>
<TOKEN end_char="2420" id="token-19-7" morph="none" pos="word" start_char="2414">Stories</TOKEN>
<TOKEN end_char="2421" id="token-19-8" morph="none" pos="punct" start_char="2421">.</TOKEN>
</SEG>
<SEG end_char="2476" id="segment-20" start_char="2423">
<ORIGINAL_TEXT>For starters, he said, DARPA has never worked with Dr.</ORIGINAL_TEXT>
<TOKEN end_char="2425" id="token-20-0" morph="none" pos="word" start_char="2423">For</TOKEN>
<TOKEN end_char="2434" id="token-20-1" morph="none" pos="word" start_char="2427">starters</TOKEN>
<TOKEN end_char="2435" id="token-20-2" morph="none" pos="punct" start_char="2435">,</TOKEN>
<TOKEN end_char="2438" id="token-20-3" morph="none" pos="word" start_char="2437">he</TOKEN>
<TOKEN end_char="2443" id="token-20-4" morph="none" pos="word" start_char="2440">said</TOKEN>
<TOKEN end_char="2444" id="token-20-5" morph="none" pos="punct" start_char="2444">,</TOKEN>
<TOKEN end_char="2450" id="token-20-6" morph="none" pos="word" start_char="2446">DARPA</TOKEN>
<TOKEN end_char="2454" id="token-20-7" morph="none" pos="word" start_char="2452">has</TOKEN>
<TOKEN end_char="2460" id="token-20-8" morph="none" pos="word" start_char="2456">never</TOKEN>
<TOKEN end_char="2467" id="token-20-9" morph="none" pos="word" start_char="2462">worked</TOKEN>
<TOKEN end_char="2472" id="token-20-10" morph="none" pos="word" start_char="2469">with</TOKEN>
<TOKEN end_char="2475" id="token-20-11" morph="none" pos="word" start_char="2474">Dr</TOKEN>
<TOKEN end_char="2476" id="token-20-12" morph="none" pos="punct" start_char="2476">.</TOKEN>
</SEG>
<SEG end_char="2598" id="segment-21" start_char="2478">
<ORIGINAL_TEXT>Ralph Baric, the University of North Carolina virologist Swann and Martin claim is in the thick of a COVID-19 conspiracy.</ORIGINAL_TEXT>
<TOKEN end_char="2482" id="token-21-0" morph="none" pos="word" start_char="2478">Ralph</TOKEN>
<TOKEN end_char="2488" id="token-21-1" morph="none" pos="word" start_char="2484">Baric</TOKEN>
<TOKEN end_char="2489" id="token-21-2" morph="none" pos="punct" start_char="2489">,</TOKEN>
<TOKEN end_char="2493" id="token-21-3" morph="none" pos="word" start_char="2491">the</TOKEN>
<TOKEN end_char="2504" id="token-21-4" morph="none" pos="word" start_char="2495">University</TOKEN>
<TOKEN end_char="2507" id="token-21-5" morph="none" pos="word" start_char="2506">of</TOKEN>
<TOKEN end_char="2513" id="token-21-6" morph="none" pos="word" start_char="2509">North</TOKEN>
<TOKEN end_char="2522" id="token-21-7" morph="none" pos="word" start_char="2515">Carolina</TOKEN>
<TOKEN end_char="2533" id="token-21-8" morph="none" pos="word" start_char="2524">virologist</TOKEN>
<TOKEN end_char="2539" id="token-21-9" morph="none" pos="word" start_char="2535">Swann</TOKEN>
<TOKEN end_char="2543" id="token-21-10" morph="none" pos="word" start_char="2541">and</TOKEN>
<TOKEN end_char="2550" id="token-21-11" morph="none" pos="word" start_char="2545">Martin</TOKEN>
<TOKEN end_char="2556" id="token-21-12" morph="none" pos="word" start_char="2552">claim</TOKEN>
<TOKEN end_char="2559" id="token-21-13" morph="none" pos="word" start_char="2558">is</TOKEN>
<TOKEN end_char="2562" id="token-21-14" morph="none" pos="word" start_char="2561">in</TOKEN>
<TOKEN end_char="2566" id="token-21-15" morph="none" pos="word" start_char="2564">the</TOKEN>
<TOKEN end_char="2572" id="token-21-16" morph="none" pos="word" start_char="2568">thick</TOKEN>
<TOKEN end_char="2575" id="token-21-17" morph="none" pos="word" start_char="2574">of</TOKEN>
<TOKEN end_char="2577" id="token-21-18" morph="none" pos="word" start_char="2577">a</TOKEN>
<TOKEN end_char="2586" id="token-21-19" morph="none" pos="unknown" start_char="2579">COVID-19</TOKEN>
<TOKEN end_char="2597" id="token-21-20" morph="none" pos="word" start_char="2588">conspiracy</TOKEN>
<TOKEN end_char="2598" id="token-21-21" morph="none" pos="punct" start_char="2598">.</TOKEN>
</SEG>
<SEG end_char="2610" id="segment-22" start_char="2600">
<ORIGINAL_TEXT>From Adams:</ORIGINAL_TEXT>
<TOKEN end_char="2603" id="token-22-0" morph="none" pos="word" start_char="2600">From</TOKEN>
<TOKEN end_char="2609" id="token-22-1" morph="none" pos="word" start_char="2605">Adams</TOKEN>
<TOKEN end_char="2610" id="token-22-2" morph="none" pos="punct" start_char="2610">:</TOKEN>
</SEG>
<SEG end_char="2895" id="segment-23" start_char="2613">
<ORIGINAL_TEXT>Like all conspiracy theorists, Swann and Martin build on elements of truth and then add false and/or misleading claims...DARPA's research concerning zoonosis or the animal origins of viral pathogens began in 2018, not earlier in 2005 nor in 1999-2001 as the video incorrectly claims.</ORIGINAL_TEXT>
<TOKEN end_char="2616" id="token-23-0" morph="none" pos="word" start_char="2613">Like</TOKEN>
<TOKEN end_char="2620" id="token-23-1" morph="none" pos="word" start_char="2618">all</TOKEN>
<TOKEN end_char="2631" id="token-23-2" morph="none" pos="word" start_char="2622">conspiracy</TOKEN>
<TOKEN end_char="2641" id="token-23-3" morph="none" pos="word" start_char="2633">theorists</TOKEN>
<TOKEN end_char="2642" id="token-23-4" morph="none" pos="punct" start_char="2642">,</TOKEN>
<TOKEN end_char="2648" id="token-23-5" morph="none" pos="word" start_char="2644">Swann</TOKEN>
<TOKEN end_char="2652" id="token-23-6" morph="none" pos="word" start_char="2650">and</TOKEN>
<TOKEN end_char="2659" id="token-23-7" morph="none" pos="word" start_char="2654">Martin</TOKEN>
<TOKEN end_char="2665" id="token-23-8" morph="none" pos="word" start_char="2661">build</TOKEN>
<TOKEN end_char="2668" id="token-23-9" morph="none" pos="word" start_char="2667">on</TOKEN>
<TOKEN end_char="2677" id="token-23-10" morph="none" pos="word" start_char="2670">elements</TOKEN>
<TOKEN end_char="2680" id="token-23-11" morph="none" pos="word" start_char="2679">of</TOKEN>
<TOKEN end_char="2686" id="token-23-12" morph="none" pos="word" start_char="2682">truth</TOKEN>
<TOKEN end_char="2690" id="token-23-13" morph="none" pos="word" start_char="2688">and</TOKEN>
<TOKEN end_char="2695" id="token-23-14" morph="none" pos="word" start_char="2692">then</TOKEN>
<TOKEN end_char="2699" id="token-23-15" morph="none" pos="word" start_char="2697">add</TOKEN>
<TOKEN end_char="2705" id="token-23-16" morph="none" pos="word" start_char="2701">false</TOKEN>
<TOKEN end_char="2712" id="token-23-17" morph="none" pos="unknown" start_char="2707">and/or</TOKEN>
<TOKEN end_char="2723" id="token-23-18" morph="none" pos="word" start_char="2714">misleading</TOKEN>
<TOKEN end_char="2740" id="token-23-19" morph="none" pos="unknown" start_char="2725">claims...DARPA's</TOKEN>
<TOKEN end_char="2749" id="token-23-20" morph="none" pos="word" start_char="2742">research</TOKEN>
<TOKEN end_char="2760" id="token-23-21" morph="none" pos="word" start_char="2751">concerning</TOKEN>
<TOKEN end_char="2769" id="token-23-22" morph="none" pos="word" start_char="2762">zoonosis</TOKEN>
<TOKEN end_char="2772" id="token-23-23" morph="none" pos="word" start_char="2771">or</TOKEN>
<TOKEN end_char="2776" id="token-23-24" morph="none" pos="word" start_char="2774">the</TOKEN>
<TOKEN end_char="2783" id="token-23-25" morph="none" pos="word" start_char="2778">animal</TOKEN>
<TOKEN end_char="2791" id="token-23-26" morph="none" pos="word" start_char="2785">origins</TOKEN>
<TOKEN end_char="2794" id="token-23-27" morph="none" pos="word" start_char="2793">of</TOKEN>
<TOKEN end_char="2800" id="token-23-28" morph="none" pos="word" start_char="2796">viral</TOKEN>
<TOKEN end_char="2810" id="token-23-29" morph="none" pos="word" start_char="2802">pathogens</TOKEN>
<TOKEN end_char="2816" id="token-23-30" morph="none" pos="word" start_char="2812">began</TOKEN>
<TOKEN end_char="2819" id="token-23-31" morph="none" pos="word" start_char="2818">in</TOKEN>
<TOKEN end_char="2824" id="token-23-32" morph="none" pos="word" start_char="2821">2018</TOKEN>
<TOKEN end_char="2825" id="token-23-33" morph="none" pos="punct" start_char="2825">,</TOKEN>
<TOKEN end_char="2829" id="token-23-34" morph="none" pos="word" start_char="2827">not</TOKEN>
<TOKEN end_char="2837" id="token-23-35" morph="none" pos="word" start_char="2831">earlier</TOKEN>
<TOKEN end_char="2840" id="token-23-36" morph="none" pos="word" start_char="2839">in</TOKEN>
<TOKEN end_char="2845" id="token-23-37" morph="none" pos="word" start_char="2842">2005</TOKEN>
<TOKEN end_char="2849" id="token-23-38" morph="none" pos="word" start_char="2847">nor</TOKEN>
<TOKEN end_char="2852" id="token-23-39" morph="none" pos="word" start_char="2851">in</TOKEN>
<TOKEN end_char="2862" id="token-23-40" morph="none" pos="unknown" start_char="2854">1999-2001</TOKEN>
<TOKEN end_char="2865" id="token-23-41" morph="none" pos="word" start_char="2864">as</TOKEN>
<TOKEN end_char="2869" id="token-23-42" morph="none" pos="word" start_char="2867">the</TOKEN>
<TOKEN end_char="2875" id="token-23-43" morph="none" pos="word" start_char="2871">video</TOKEN>
<TOKEN end_char="2887" id="token-23-44" morph="none" pos="word" start_char="2877">incorrectly</TOKEN>
<TOKEN end_char="2894" id="token-23-45" morph="none" pos="word" start_char="2889">claims</TOKEN>
<TOKEN end_char="2895" id="token-23-46" morph="none" pos="punct" start_char="2895">.</TOKEN>
</SEG>
<SEG end_char="3144" id="segment-24" start_char="2897">
<ORIGINAL_TEXT>DARPA would certainly welcome seeing the "trail of evidence" Swann has that ties the good professor to the agency considering the micro flashes of paper in the YouTube video prove nothing other than that Baric is active in publishing and patenting.</ORIGINAL_TEXT>
<TOKEN end_char="2901" id="token-24-0" morph="none" pos="word" start_char="2897">DARPA</TOKEN>
<TOKEN end_char="2907" id="token-24-1" morph="none" pos="word" start_char="2903">would</TOKEN>
<TOKEN end_char="2917" id="token-24-2" morph="none" pos="word" start_char="2909">certainly</TOKEN>
<TOKEN end_char="2925" id="token-24-3" morph="none" pos="word" start_char="2919">welcome</TOKEN>
<TOKEN end_char="2932" id="token-24-4" morph="none" pos="word" start_char="2927">seeing</TOKEN>
<TOKEN end_char="2936" id="token-24-5" morph="none" pos="word" start_char="2934">the</TOKEN>
<TOKEN end_char="2938" id="token-24-6" morph="none" pos="punct" start_char="2938">"</TOKEN>
<TOKEN end_char="2943" id="token-24-7" morph="none" pos="word" start_char="2939">trail</TOKEN>
<TOKEN end_char="2946" id="token-24-8" morph="none" pos="word" start_char="2945">of</TOKEN>
<TOKEN end_char="2955" id="token-24-9" morph="none" pos="word" start_char="2948">evidence</TOKEN>
<TOKEN end_char="2956" id="token-24-10" morph="none" pos="punct" start_char="2956">"</TOKEN>
<TOKEN end_char="2962" id="token-24-11" morph="none" pos="word" start_char="2958">Swann</TOKEN>
<TOKEN end_char="2966" id="token-24-12" morph="none" pos="word" start_char="2964">has</TOKEN>
<TOKEN end_char="2971" id="token-24-13" morph="none" pos="word" start_char="2968">that</TOKEN>
<TOKEN end_char="2976" id="token-24-14" morph="none" pos="word" start_char="2973">ties</TOKEN>
<TOKEN end_char="2980" id="token-24-15" morph="none" pos="word" start_char="2978">the</TOKEN>
<TOKEN end_char="2985" id="token-24-16" morph="none" pos="word" start_char="2982">good</TOKEN>
<TOKEN end_char="2995" id="token-24-17" morph="none" pos="word" start_char="2987">professor</TOKEN>
<TOKEN end_char="2998" id="token-24-18" morph="none" pos="word" start_char="2997">to</TOKEN>
<TOKEN end_char="3002" id="token-24-19" morph="none" pos="word" start_char="3000">the</TOKEN>
<TOKEN end_char="3009" id="token-24-20" morph="none" pos="word" start_char="3004">agency</TOKEN>
<TOKEN end_char="3021" id="token-24-21" morph="none" pos="word" start_char="3011">considering</TOKEN>
<TOKEN end_char="3025" id="token-24-22" morph="none" pos="word" start_char="3023">the</TOKEN>
<TOKEN end_char="3031" id="token-24-23" morph="none" pos="word" start_char="3027">micro</TOKEN>
<TOKEN end_char="3039" id="token-24-24" morph="none" pos="word" start_char="3033">flashes</TOKEN>
<TOKEN end_char="3042" id="token-24-25" morph="none" pos="word" start_char="3041">of</TOKEN>
<TOKEN end_char="3048" id="token-24-26" morph="none" pos="word" start_char="3044">paper</TOKEN>
<TOKEN end_char="3051" id="token-24-27" morph="none" pos="word" start_char="3050">in</TOKEN>
<TOKEN end_char="3055" id="token-24-28" morph="none" pos="word" start_char="3053">the</TOKEN>
<TOKEN end_char="3063" id="token-24-29" morph="none" pos="word" start_char="3057">YouTube</TOKEN>
<TOKEN end_char="3069" id="token-24-30" morph="none" pos="word" start_char="3065">video</TOKEN>
<TOKEN end_char="3075" id="token-24-31" morph="none" pos="word" start_char="3071">prove</TOKEN>
<TOKEN end_char="3083" id="token-24-32" morph="none" pos="word" start_char="3077">nothing</TOKEN>
<TOKEN end_char="3089" id="token-24-33" morph="none" pos="word" start_char="3085">other</TOKEN>
<TOKEN end_char="3094" id="token-24-34" morph="none" pos="word" start_char="3091">than</TOKEN>
<TOKEN end_char="3099" id="token-24-35" morph="none" pos="word" start_char="3096">that</TOKEN>
<TOKEN end_char="3105" id="token-24-36" morph="none" pos="word" start_char="3101">Baric</TOKEN>
<TOKEN end_char="3108" id="token-24-37" morph="none" pos="word" start_char="3107">is</TOKEN>
<TOKEN end_char="3115" id="token-24-38" morph="none" pos="word" start_char="3110">active</TOKEN>
<TOKEN end_char="3118" id="token-24-39" morph="none" pos="word" start_char="3117">in</TOKEN>
<TOKEN end_char="3129" id="token-24-40" morph="none" pos="word" start_char="3120">publishing</TOKEN>
<TOKEN end_char="3133" id="token-24-41" morph="none" pos="word" start_char="3131">and</TOKEN>
<TOKEN end_char="3143" id="token-24-42" morph="none" pos="word" start_char="3135">patenting</TOKEN>
<TOKEN end_char="3144" id="token-24-43" morph="none" pos="punct" start_char="3144">.</TOKEN>
</SEG>
<SEG end_char="3279" id="segment-25" start_char="3146">
<ORIGINAL_TEXT>More important than these supposed ties, however, is that DARPA is not now nor has it ever been involved in gain of function research.</ORIGINAL_TEXT>
<TOKEN end_char="3149" id="token-25-0" morph="none" pos="word" start_char="3146">More</TOKEN>
<TOKEN end_char="3159" id="token-25-1" morph="none" pos="word" start_char="3151">important</TOKEN>
<TOKEN end_char="3164" id="token-25-2" morph="none" pos="word" start_char="3161">than</TOKEN>
<TOKEN end_char="3170" id="token-25-3" morph="none" pos="word" start_char="3166">these</TOKEN>
<TOKEN end_char="3179" id="token-25-4" morph="none" pos="word" start_char="3172">supposed</TOKEN>
<TOKEN end_char="3184" id="token-25-5" morph="none" pos="word" start_char="3181">ties</TOKEN>
<TOKEN end_char="3185" id="token-25-6" morph="none" pos="punct" start_char="3185">,</TOKEN>
<TOKEN end_char="3193" id="token-25-7" morph="none" pos="word" start_char="3187">however</TOKEN>
<TOKEN end_char="3194" id="token-25-8" morph="none" pos="punct" start_char="3194">,</TOKEN>
<TOKEN end_char="3197" id="token-25-9" morph="none" pos="word" start_char="3196">is</TOKEN>
<TOKEN end_char="3202" id="token-25-10" morph="none" pos="word" start_char="3199">that</TOKEN>
<TOKEN end_char="3208" id="token-25-11" morph="none" pos="word" start_char="3204">DARPA</TOKEN>
<TOKEN end_char="3211" id="token-25-12" morph="none" pos="word" start_char="3210">is</TOKEN>
<TOKEN end_char="3215" id="token-25-13" morph="none" pos="word" start_char="3213">not</TOKEN>
<TOKEN end_char="3219" id="token-25-14" morph="none" pos="word" start_char="3217">now</TOKEN>
<TOKEN end_char="3223" id="token-25-15" morph="none" pos="word" start_char="3221">nor</TOKEN>
<TOKEN end_char="3227" id="token-25-16" morph="none" pos="word" start_char="3225">has</TOKEN>
<TOKEN end_char="3230" id="token-25-17" morph="none" pos="word" start_char="3229">it</TOKEN>
<TOKEN end_char="3235" id="token-25-18" morph="none" pos="word" start_char="3232">ever</TOKEN>
<TOKEN end_char="3240" id="token-25-19" morph="none" pos="word" start_char="3237">been</TOKEN>
<TOKEN end_char="3249" id="token-25-20" morph="none" pos="word" start_char="3242">involved</TOKEN>
<TOKEN end_char="3252" id="token-25-21" morph="none" pos="word" start_char="3251">in</TOKEN>
<TOKEN end_char="3257" id="token-25-22" morph="none" pos="word" start_char="3254">gain</TOKEN>
<TOKEN end_char="3260" id="token-25-23" morph="none" pos="word" start_char="3259">of</TOKEN>
<TOKEN end_char="3269" id="token-25-24" morph="none" pos="word" start_char="3262">function</TOKEN>
<TOKEN end_char="3278" id="token-25-25" morph="none" pos="word" start_char="3271">research</TOKEN>
<TOKEN end_char="3279" id="token-25-26" morph="none" pos="punct" start_char="3279">.</TOKEN>
</SEG>
<SEG end_char="3547" id="segment-26" start_char="3281">
<ORIGINAL_TEXT>If Swann had an ounce of journalistic integrity, which he obviously does not, he could easily talk to any of our PREEMPT researchers and/or review extant literature and realize pretty quickly that DARPA is not making bioweapons: (Full listing of PREEPMT researchers).</ORIGINAL_TEXT>
<TOKEN end_char="3282" id="token-26-0" morph="none" pos="word" start_char="3281">If</TOKEN>
<TOKEN end_char="3288" id="token-26-1" morph="none" pos="word" start_char="3284">Swann</TOKEN>
<TOKEN end_char="3292" id="token-26-2" morph="none" pos="word" start_char="3290">had</TOKEN>
<TOKEN end_char="3295" id="token-26-3" morph="none" pos="word" start_char="3294">an</TOKEN>
<TOKEN end_char="3301" id="token-26-4" morph="none" pos="word" start_char="3297">ounce</TOKEN>
<TOKEN end_char="3304" id="token-26-5" morph="none" pos="word" start_char="3303">of</TOKEN>
<TOKEN end_char="3317" id="token-26-6" morph="none" pos="word" start_char="3306">journalistic</TOKEN>
<TOKEN end_char="3327" id="token-26-7" morph="none" pos="word" start_char="3319">integrity</TOKEN>
<TOKEN end_char="3328" id="token-26-8" morph="none" pos="punct" start_char="3328">,</TOKEN>
<TOKEN end_char="3334" id="token-26-9" morph="none" pos="word" start_char="3330">which</TOKEN>
<TOKEN end_char="3337" id="token-26-10" morph="none" pos="word" start_char="3336">he</TOKEN>
<TOKEN end_char="3347" id="token-26-11" morph="none" pos="word" start_char="3339">obviously</TOKEN>
<TOKEN end_char="3352" id="token-26-12" morph="none" pos="word" start_char="3349">does</TOKEN>
<TOKEN end_char="3356" id="token-26-13" morph="none" pos="word" start_char="3354">not</TOKEN>
<TOKEN end_char="3357" id="token-26-14" morph="none" pos="punct" start_char="3357">,</TOKEN>
<TOKEN end_char="3360" id="token-26-15" morph="none" pos="word" start_char="3359">he</TOKEN>
<TOKEN end_char="3366" id="token-26-16" morph="none" pos="word" start_char="3362">could</TOKEN>
<TOKEN end_char="3373" id="token-26-17" morph="none" pos="word" start_char="3368">easily</TOKEN>
<TOKEN end_char="3378" id="token-26-18" morph="none" pos="word" start_char="3375">talk</TOKEN>
<TOKEN end_char="3381" id="token-26-19" morph="none" pos="word" start_char="3380">to</TOKEN>
<TOKEN end_char="3385" id="token-26-20" morph="none" pos="word" start_char="3383">any</TOKEN>
<TOKEN end_char="3388" id="token-26-21" morph="none" pos="word" start_char="3387">of</TOKEN>
<TOKEN end_char="3392" id="token-26-22" morph="none" pos="word" start_char="3390">our</TOKEN>
<TOKEN end_char="3400" id="token-26-23" morph="none" pos="word" start_char="3394">PREEMPT</TOKEN>
<TOKEN end_char="3412" id="token-26-24" morph="none" pos="word" start_char="3402">researchers</TOKEN>
<TOKEN end_char="3419" id="token-26-25" morph="none" pos="unknown" start_char="3414">and/or</TOKEN>
<TOKEN end_char="3426" id="token-26-26" morph="none" pos="word" start_char="3421">review</TOKEN>
<TOKEN end_char="3433" id="token-26-27" morph="none" pos="word" start_char="3428">extant</TOKEN>
<TOKEN end_char="3444" id="token-26-28" morph="none" pos="word" start_char="3435">literature</TOKEN>
<TOKEN end_char="3448" id="token-26-29" morph="none" pos="word" start_char="3446">and</TOKEN>
<TOKEN end_char="3456" id="token-26-30" morph="none" pos="word" start_char="3450">realize</TOKEN>
<TOKEN end_char="3463" id="token-26-31" morph="none" pos="word" start_char="3458">pretty</TOKEN>
<TOKEN end_char="3471" id="token-26-32" morph="none" pos="word" start_char="3465">quickly</TOKEN>
<TOKEN end_char="3476" id="token-26-33" morph="none" pos="word" start_char="3473">that</TOKEN>
<TOKEN end_char="3482" id="token-26-34" morph="none" pos="word" start_char="3478">DARPA</TOKEN>
<TOKEN end_char="3485" id="token-26-35" morph="none" pos="word" start_char="3484">is</TOKEN>
<TOKEN end_char="3489" id="token-26-36" morph="none" pos="word" start_char="3487">not</TOKEN>
<TOKEN end_char="3496" id="token-26-37" morph="none" pos="word" start_char="3491">making</TOKEN>
<TOKEN end_char="3507" id="token-26-38" morph="none" pos="word" start_char="3498">bioweapons</TOKEN>
<TOKEN end_char="3508" id="token-26-39" morph="none" pos="punct" start_char="3508">:</TOKEN>
<TOKEN end_char="3510" id="token-26-40" morph="none" pos="punct" start_char="3510">(</TOKEN>
<TOKEN end_char="3514" id="token-26-41" morph="none" pos="word" start_char="3511">Full</TOKEN>
<TOKEN end_char="3522" id="token-26-42" morph="none" pos="word" start_char="3516">listing</TOKEN>
<TOKEN end_char="3525" id="token-26-43" morph="none" pos="word" start_char="3524">of</TOKEN>
<TOKEN end_char="3533" id="token-26-44" morph="none" pos="word" start_char="3527">PREEPMT</TOKEN>
<TOKEN end_char="3545" id="token-26-45" morph="none" pos="word" start_char="3535">researchers</TOKEN>
<TOKEN end_char="3547" id="token-26-46" morph="none" pos="punct" start_char="3546">).</TOKEN>
</SEG>
<SEG end_char="3710" id="segment-27" start_char="3549">
<ORIGINAL_TEXT>Further, DARPA and the PREEMPT teams receive guidance from independent expert advisors in the ethical, legal, social, and regulatory aspects of the life sciences.</ORIGINAL_TEXT>
<TOKEN end_char="3555" id="token-27-0" morph="none" pos="word" start_char="3549">Further</TOKEN>
<TOKEN end_char="3556" id="token-27-1" morph="none" pos="punct" start_char="3556">,</TOKEN>
<TOKEN end_char="3562" id="token-27-2" morph="none" pos="word" start_char="3558">DARPA</TOKEN>
<TOKEN end_char="3566" id="token-27-3" morph="none" pos="word" start_char="3564">and</TOKEN>
<TOKEN end_char="3570" id="token-27-4" morph="none" pos="word" start_char="3568">the</TOKEN>
<TOKEN end_char="3578" id="token-27-5" morph="none" pos="word" start_char="3572">PREEMPT</TOKEN>
<TOKEN end_char="3584" id="token-27-6" morph="none" pos="word" start_char="3580">teams</TOKEN>
<TOKEN end_char="3592" id="token-27-7" morph="none" pos="word" start_char="3586">receive</TOKEN>
<TOKEN end_char="3601" id="token-27-8" morph="none" pos="word" start_char="3594">guidance</TOKEN>
<TOKEN end_char="3606" id="token-27-9" morph="none" pos="word" start_char="3603">from</TOKEN>
<TOKEN end_char="3618" id="token-27-10" morph="none" pos="word" start_char="3608">independent</TOKEN>
<TOKEN end_char="3625" id="token-27-11" morph="none" pos="word" start_char="3620">expert</TOKEN>
<TOKEN end_char="3634" id="token-27-12" morph="none" pos="word" start_char="3627">advisors</TOKEN>
<TOKEN end_char="3637" id="token-27-13" morph="none" pos="word" start_char="3636">in</TOKEN>
<TOKEN end_char="3641" id="token-27-14" morph="none" pos="word" start_char="3639">the</TOKEN>
<TOKEN end_char="3649" id="token-27-15" morph="none" pos="word" start_char="3643">ethical</TOKEN>
<TOKEN end_char="3650" id="token-27-16" morph="none" pos="punct" start_char="3650">,</TOKEN>
<TOKEN end_char="3656" id="token-27-17" morph="none" pos="word" start_char="3652">legal</TOKEN>
<TOKEN end_char="3657" id="token-27-18" morph="none" pos="punct" start_char="3657">,</TOKEN>
<TOKEN end_char="3664" id="token-27-19" morph="none" pos="word" start_char="3659">social</TOKEN>
<TOKEN end_char="3665" id="token-27-20" morph="none" pos="punct" start_char="3665">,</TOKEN>
<TOKEN end_char="3669" id="token-27-21" morph="none" pos="word" start_char="3667">and</TOKEN>
<TOKEN end_char="3680" id="token-27-22" morph="none" pos="word" start_char="3671">regulatory</TOKEN>
<TOKEN end_char="3688" id="token-27-23" morph="none" pos="word" start_char="3682">aspects</TOKEN>
<TOKEN end_char="3691" id="token-27-24" morph="none" pos="word" start_char="3690">of</TOKEN>
<TOKEN end_char="3695" id="token-27-25" morph="none" pos="word" start_char="3693">the</TOKEN>
<TOKEN end_char="3700" id="token-27-26" morph="none" pos="word" start_char="3697">life</TOKEN>
<TOKEN end_char="3709" id="token-27-27" morph="none" pos="word" start_char="3702">sciences</TOKEN>
<TOKEN end_char="3710" id="token-27-28" morph="none" pos="punct" start_char="3710">.</TOKEN>
</SEG>
<SEG end_char="3843" id="segment-28" start_char="3712">
<ORIGINAL_TEXT>These individuals include Dr. Claudia Emerson, director of the Institute on Ethics Policy for Innovation at McMaster University; Dr.</ORIGINAL_TEXT>
<TOKEN end_char="3716" id="token-28-0" morph="none" pos="word" start_char="3712">These</TOKEN>
<TOKEN end_char="3728" id="token-28-1" morph="none" pos="word" start_char="3718">individuals</TOKEN>
<TOKEN end_char="3736" id="token-28-2" morph="none" pos="word" start_char="3730">include</TOKEN>
<TOKEN end_char="3739" id="token-28-3" morph="none" pos="word" start_char="3738">Dr</TOKEN>
<TOKEN end_char="3740" id="token-28-4" morph="none" pos="punct" start_char="3740">.</TOKEN>
<TOKEN end_char="3748" id="token-28-5" morph="none" pos="word" start_char="3742">Claudia</TOKEN>
<TOKEN end_char="3756" id="token-28-6" morph="none" pos="word" start_char="3750">Emerson</TOKEN>
<TOKEN end_char="3757" id="token-28-7" morph="none" pos="punct" start_char="3757">,</TOKEN>
<TOKEN end_char="3766" id="token-28-8" morph="none" pos="word" start_char="3759">director</TOKEN>
<TOKEN end_char="3769" id="token-28-9" morph="none" pos="word" start_char="3768">of</TOKEN>
<TOKEN end_char="3773" id="token-28-10" morph="none" pos="word" start_char="3771">the</TOKEN>
<TOKEN end_char="3783" id="token-28-11" morph="none" pos="word" start_char="3775">Institute</TOKEN>
<TOKEN end_char="3786" id="token-28-12" morph="none" pos="word" start_char="3785">on</TOKEN>
<TOKEN end_char="3793" id="token-28-13" morph="none" pos="word" start_char="3788">Ethics</TOKEN>
<TOKEN end_char="3800" id="token-28-14" morph="none" pos="word" start_char="3795">Policy</TOKEN>
<TOKEN end_char="3804" id="token-28-15" morph="none" pos="word" start_char="3802">for</TOKEN>
<TOKEN end_char="3815" id="token-28-16" morph="none" pos="word" start_char="3806">Innovation</TOKEN>
<TOKEN end_char="3818" id="token-28-17" morph="none" pos="word" start_char="3817">at</TOKEN>
<TOKEN end_char="3827" id="token-28-18" morph="none" pos="word" start_char="3820">McMaster</TOKEN>
<TOKEN end_char="3838" id="token-28-19" morph="none" pos="word" start_char="3829">University</TOKEN>
<TOKEN end_char="3839" id="token-28-20" morph="none" pos="punct" start_char="3839">;</TOKEN>
<TOKEN end_char="3842" id="token-28-21" morph="none" pos="word" start_char="3841">Dr</TOKEN>
<TOKEN end_char="3843" id="token-28-22" morph="none" pos="punct" start_char="3843">.</TOKEN>
</SEG>
<SEG end_char="4034" id="segment-29" start_char="3845">
<ORIGINAL_TEXT>Matt Kasper, legislative liaison for the U.S. Navy's Bureau of Medicine and Surgery, and a former deputy director of field laboratory operations at the Naval Medical Research Center; and Dr.</ORIGINAL_TEXT>
<TOKEN end_char="3848" id="token-29-0" morph="none" pos="word" start_char="3845">Matt</TOKEN>
<TOKEN end_char="3855" id="token-29-1" morph="none" pos="word" start_char="3850">Kasper</TOKEN>
<TOKEN end_char="3856" id="token-29-2" morph="none" pos="punct" start_char="3856">,</TOKEN>
<TOKEN end_char="3868" id="token-29-3" morph="none" pos="word" start_char="3858">legislative</TOKEN>
<TOKEN end_char="3876" id="token-29-4" morph="none" pos="word" start_char="3870">liaison</TOKEN>
<TOKEN end_char="3880" id="token-29-5" morph="none" pos="word" start_char="3878">for</TOKEN>
<TOKEN end_char="3884" id="token-29-6" morph="none" pos="word" start_char="3882">the</TOKEN>
<TOKEN end_char="3888" id="token-29-7" morph="none" pos="unknown" start_char="3886">U.S</TOKEN>
<TOKEN end_char="3889" id="token-29-8" morph="none" pos="punct" start_char="3889">.</TOKEN>
<TOKEN end_char="3896" id="token-29-9" morph="none" pos="word" start_char="3891">Navy's</TOKEN>
<TOKEN end_char="3903" id="token-29-10" morph="none" pos="word" start_char="3898">Bureau</TOKEN>
<TOKEN end_char="3906" id="token-29-11" morph="none" pos="word" start_char="3905">of</TOKEN>
<TOKEN end_char="3915" id="token-29-12" morph="none" pos="word" start_char="3908">Medicine</TOKEN>
<TOKEN end_char="3919" id="token-29-13" morph="none" pos="word" start_char="3917">and</TOKEN>
<TOKEN end_char="3927" id="token-29-14" morph="none" pos="word" start_char="3921">Surgery</TOKEN>
<TOKEN end_char="3928" id="token-29-15" morph="none" pos="punct" start_char="3928">,</TOKEN>
<TOKEN end_char="3932" id="token-29-16" morph="none" pos="word" start_char="3930">and</TOKEN>
<TOKEN end_char="3934" id="token-29-17" morph="none" pos="word" start_char="3934">a</TOKEN>
<TOKEN end_char="3941" id="token-29-18" morph="none" pos="word" start_char="3936">former</TOKEN>
<TOKEN end_char="3948" id="token-29-19" morph="none" pos="word" start_char="3943">deputy</TOKEN>
<TOKEN end_char="3957" id="token-29-20" morph="none" pos="word" start_char="3950">director</TOKEN>
<TOKEN end_char="3960" id="token-29-21" morph="none" pos="word" start_char="3959">of</TOKEN>
<TOKEN end_char="3966" id="token-29-22" morph="none" pos="word" start_char="3962">field</TOKEN>
<TOKEN end_char="3977" id="token-29-23" morph="none" pos="word" start_char="3968">laboratory</TOKEN>
<TOKEN end_char="3988" id="token-29-24" morph="none" pos="word" start_char="3979">operations</TOKEN>
<TOKEN end_char="3991" id="token-29-25" morph="none" pos="word" start_char="3990">at</TOKEN>
<TOKEN end_char="3995" id="token-29-26" morph="none" pos="word" start_char="3993">the</TOKEN>
<TOKEN end_char="4001" id="token-29-27" morph="none" pos="word" start_char="3997">Naval</TOKEN>
<TOKEN end_char="4009" id="token-29-28" morph="none" pos="word" start_char="4003">Medical</TOKEN>
<TOKEN end_char="4018" id="token-29-29" morph="none" pos="word" start_char="4011">Research</TOKEN>
<TOKEN end_char="4025" id="token-29-30" morph="none" pos="word" start_char="4020">Center</TOKEN>
<TOKEN end_char="4026" id="token-29-31" morph="none" pos="punct" start_char="4026">;</TOKEN>
<TOKEN end_char="4030" id="token-29-32" morph="none" pos="word" start_char="4028">and</TOKEN>
<TOKEN end_char="4033" id="token-29-33" morph="none" pos="word" start_char="4032">Dr</TOKEN>
<TOKEN end_char="4034" id="token-29-34" morph="none" pos="punct" start_char="4034">.</TOKEN>
</SEG>
<SEG end_char="4218" id="segment-30" start_char="4036">
<ORIGINAL_TEXT>Steve Monroe, associate director for Laboratory Science and Safety at the CDC, and a former deputy director of the CDC's National Center for Emerging and Zoonotic Infectious Diseases.</ORIGINAL_TEXT>
<TOKEN end_char="4040" id="token-30-0" morph="none" pos="word" start_char="4036">Steve</TOKEN>
<TOKEN end_char="4047" id="token-30-1" morph="none" pos="word" start_char="4042">Monroe</TOKEN>
<TOKEN end_char="4048" id="token-30-2" morph="none" pos="punct" start_char="4048">,</TOKEN>
<TOKEN end_char="4058" id="token-30-3" morph="none" pos="word" start_char="4050">associate</TOKEN>
<TOKEN end_char="4067" id="token-30-4" morph="none" pos="word" start_char="4060">director</TOKEN>
<TOKEN end_char="4071" id="token-30-5" morph="none" pos="word" start_char="4069">for</TOKEN>
<TOKEN end_char="4082" id="token-30-6" morph="none" pos="word" start_char="4073">Laboratory</TOKEN>
<TOKEN end_char="4090" id="token-30-7" morph="none" pos="word" start_char="4084">Science</TOKEN>
<TOKEN end_char="4094" id="token-30-8" morph="none" pos="word" start_char="4092">and</TOKEN>
<TOKEN end_char="4101" id="token-30-9" morph="none" pos="word" start_char="4096">Safety</TOKEN>
<TOKEN end_char="4104" id="token-30-10" morph="none" pos="word" start_char="4103">at</TOKEN>
<TOKEN end_char="4108" id="token-30-11" morph="none" pos="word" start_char="4106">the</TOKEN>
<TOKEN end_char="4112" id="token-30-12" morph="none" pos="word" start_char="4110">CDC</TOKEN>
<TOKEN end_char="4113" id="token-30-13" morph="none" pos="punct" start_char="4113">,</TOKEN>
<TOKEN end_char="4117" id="token-30-14" morph="none" pos="word" start_char="4115">and</TOKEN>
<TOKEN end_char="4119" id="token-30-15" morph="none" pos="word" start_char="4119">a</TOKEN>
<TOKEN end_char="4126" id="token-30-16" morph="none" pos="word" start_char="4121">former</TOKEN>
<TOKEN end_char="4133" id="token-30-17" morph="none" pos="word" start_char="4128">deputy</TOKEN>
<TOKEN end_char="4142" id="token-30-18" morph="none" pos="word" start_char="4135">director</TOKEN>
<TOKEN end_char="4145" id="token-30-19" morph="none" pos="word" start_char="4144">of</TOKEN>
<TOKEN end_char="4149" id="token-30-20" morph="none" pos="word" start_char="4147">the</TOKEN>
<TOKEN end_char="4155" id="token-30-21" morph="none" pos="word" start_char="4151">CDC's</TOKEN>
<TOKEN end_char="4164" id="token-30-22" morph="none" pos="word" start_char="4157">National</TOKEN>
<TOKEN end_char="4171" id="token-30-23" morph="none" pos="word" start_char="4166">Center</TOKEN>
<TOKEN end_char="4175" id="token-30-24" morph="none" pos="word" start_char="4173">for</TOKEN>
<TOKEN end_char="4184" id="token-30-25" morph="none" pos="word" start_char="4177">Emerging</TOKEN>
<TOKEN end_char="4188" id="token-30-26" morph="none" pos="word" start_char="4186">and</TOKEN>
<TOKEN end_char="4197" id="token-30-27" morph="none" pos="word" start_char="4190">Zoonotic</TOKEN>
<TOKEN end_char="4208" id="token-30-28" morph="none" pos="word" start_char="4199">Infectious</TOKEN>
<TOKEN end_char="4217" id="token-30-29" morph="none" pos="word" start_char="4210">Diseases</TOKEN>
<TOKEN end_char="4218" id="token-30-30" morph="none" pos="punct" start_char="4218">.</TOKEN>
</SEG>
<SEG end_char="4285" id="segment-31" start_char="4220">
<ORIGINAL_TEXT>You are welcome to call anyone above to inquire about the program.</ORIGINAL_TEXT>
<TOKEN end_char="4222" id="token-31-0" morph="none" pos="word" start_char="4220">You</TOKEN>
<TOKEN end_char="4226" id="token-31-1" morph="none" pos="word" start_char="4224">are</TOKEN>
<TOKEN end_char="4234" id="token-31-2" morph="none" pos="word" start_char="4228">welcome</TOKEN>
<TOKEN end_char="4237" id="token-31-3" morph="none" pos="word" start_char="4236">to</TOKEN>
<TOKEN end_char="4242" id="token-31-4" morph="none" pos="word" start_char="4239">call</TOKEN>
<TOKEN end_char="4249" id="token-31-5" morph="none" pos="word" start_char="4244">anyone</TOKEN>
<TOKEN end_char="4255" id="token-31-6" morph="none" pos="word" start_char="4251">above</TOKEN>
<TOKEN end_char="4258" id="token-31-7" morph="none" pos="word" start_char="4257">to</TOKEN>
<TOKEN end_char="4266" id="token-31-8" morph="none" pos="word" start_char="4260">inquire</TOKEN>
<TOKEN end_char="4272" id="token-31-9" morph="none" pos="word" start_char="4268">about</TOKEN>
<TOKEN end_char="4276" id="token-31-10" morph="none" pos="word" start_char="4274">the</TOKEN>
<TOKEN end_char="4284" id="token-31-11" morph="none" pos="word" start_char="4278">program</TOKEN>
<TOKEN end_char="4285" id="token-31-12" morph="none" pos="punct" start_char="4285">.</TOKEN>
</SEG>
<SEG end_char="4366" id="segment-32" start_char="4289">
<ORIGINAL_TEXT>Here's a review of the documents the film-makers pasted into their production:</ORIGINAL_TEXT>
<TOKEN end_char="4294" id="token-32-0" morph="none" pos="word" start_char="4289">Here's</TOKEN>
<TOKEN end_char="4296" id="token-32-1" morph="none" pos="word" start_char="4296">a</TOKEN>
<TOKEN end_char="4303" id="token-32-2" morph="none" pos="word" start_char="4298">review</TOKEN>
<TOKEN end_char="4306" id="token-32-3" morph="none" pos="word" start_char="4305">of</TOKEN>
<TOKEN end_char="4310" id="token-32-4" morph="none" pos="word" start_char="4308">the</TOKEN>
<TOKEN end_char="4320" id="token-32-5" morph="none" pos="word" start_char="4312">documents</TOKEN>
<TOKEN end_char="4324" id="token-32-6" morph="none" pos="word" start_char="4322">the</TOKEN>
<TOKEN end_char="4336" id="token-32-7" morph="none" pos="unknown" start_char="4326">film-makers</TOKEN>
<TOKEN end_char="4343" id="token-32-8" morph="none" pos="word" start_char="4338">pasted</TOKEN>
<TOKEN end_char="4348" id="token-32-9" morph="none" pos="word" start_char="4345">into</TOKEN>
<TOKEN end_char="4354" id="token-32-10" morph="none" pos="word" start_char="4350">their</TOKEN>
<TOKEN end_char="4365" id="token-32-11" morph="none" pos="word" start_char="4356">production</TOKEN>
<TOKEN end_char="4366" id="token-32-12" morph="none" pos="punct" start_char="4366">:</TOKEN>
</SEG>
<SEG end_char="4436" id="segment-33" start_char="4369">
<ORIGINAL_TEXT>One 'proof' document explicitly contradicts Swann and Martin's claim</ORIGINAL_TEXT>
<TOKEN end_char="4371" id="token-33-0" morph="none" pos="word" start_char="4369">One</TOKEN>
<TOKEN end_char="4373" id="token-33-1" morph="none" pos="punct" start_char="4373">'</TOKEN>
<TOKEN end_char="4378" id="token-33-2" morph="none" pos="word" start_char="4374">proof</TOKEN>
<TOKEN end_char="4379" id="token-33-3" morph="none" pos="punct" start_char="4379">'</TOKEN>
<TOKEN end_char="4388" id="token-33-4" morph="none" pos="word" start_char="4381">document</TOKEN>
<TOKEN end_char="4399" id="token-33-5" morph="none" pos="word" start_char="4390">explicitly</TOKEN>
<TOKEN end_char="4411" id="token-33-6" morph="none" pos="word" start_char="4401">contradicts</TOKEN>
<TOKEN end_char="4417" id="token-33-7" morph="none" pos="word" start_char="4413">Swann</TOKEN>
<TOKEN end_char="4421" id="token-33-8" morph="none" pos="word" start_char="4419">and</TOKEN>
<TOKEN end_char="4430" id="token-33-9" morph="none" pos="word" start_char="4423">Martin's</TOKEN>
<TOKEN end_char="4436" id="token-33-10" morph="none" pos="word" start_char="4432">claim</TOKEN>
</SEG>
<SEG end_char="4521" id="segment-34" start_char="4440">
<ORIGINAL_TEXT>Following is a screenshot of one of the documents Swann and Martin offer as proof.</ORIGINAL_TEXT>
<TOKEN end_char="4448" id="token-34-0" morph="none" pos="word" start_char="4440">Following</TOKEN>
<TOKEN end_char="4451" id="token-34-1" morph="none" pos="word" start_char="4450">is</TOKEN>
<TOKEN end_char="4453" id="token-34-2" morph="none" pos="word" start_char="4453">a</TOKEN>
<TOKEN end_char="4464" id="token-34-3" morph="none" pos="word" start_char="4455">screenshot</TOKEN>
<TOKEN end_char="4467" id="token-34-4" morph="none" pos="word" start_char="4466">of</TOKEN>
<TOKEN end_char="4471" id="token-34-5" morph="none" pos="word" start_char="4469">one</TOKEN>
<TOKEN end_char="4474" id="token-34-6" morph="none" pos="word" start_char="4473">of</TOKEN>
<TOKEN end_char="4478" id="token-34-7" morph="none" pos="word" start_char="4476">the</TOKEN>
<TOKEN end_char="4488" id="token-34-8" morph="none" pos="word" start_char="4480">documents</TOKEN>
<TOKEN end_char="4494" id="token-34-9" morph="none" pos="word" start_char="4490">Swann</TOKEN>
<TOKEN end_char="4498" id="token-34-10" morph="none" pos="word" start_char="4496">and</TOKEN>
<TOKEN end_char="4505" id="token-34-11" morph="none" pos="word" start_char="4500">Martin</TOKEN>
<TOKEN end_char="4511" id="token-34-12" morph="none" pos="word" start_char="4507">offer</TOKEN>
<TOKEN end_char="4514" id="token-34-13" morph="none" pos="word" start_char="4513">as</TOKEN>
<TOKEN end_char="4520" id="token-34-14" morph="none" pos="word" start_char="4516">proof</TOKEN>
<TOKEN end_char="4521" id="token-34-15" morph="none" pos="punct" start_char="4521">.</TOKEN>
</SEG>
<SEG end_char="4619" id="segment-35" start_char="4523">
<ORIGINAL_TEXT>Lead Stories has highlighted in yellow an update added by the publisher that refutes their claim.</ORIGINAL_TEXT>
<TOKEN end_char="4526" id="token-35-0" morph="none" pos="word" start_char="4523">Lead</TOKEN>
<TOKEN end_char="4534" id="token-35-1" morph="none" pos="word" start_char="4528">Stories</TOKEN>
<TOKEN end_char="4538" id="token-35-2" morph="none" pos="word" start_char="4536">has</TOKEN>
<TOKEN end_char="4550" id="token-35-3" morph="none" pos="word" start_char="4540">highlighted</TOKEN>
<TOKEN end_char="4553" id="token-35-4" morph="none" pos="word" start_char="4552">in</TOKEN>
<TOKEN end_char="4560" id="token-35-5" morph="none" pos="word" start_char="4555">yellow</TOKEN>
<TOKEN end_char="4563" id="token-35-6" morph="none" pos="word" start_char="4562">an</TOKEN>
<TOKEN end_char="4570" id="token-35-7" morph="none" pos="word" start_char="4565">update</TOKEN>
<TOKEN end_char="4576" id="token-35-8" morph="none" pos="word" start_char="4572">added</TOKEN>
<TOKEN end_char="4579" id="token-35-9" morph="none" pos="word" start_char="4578">by</TOKEN>
<TOKEN end_char="4583" id="token-35-10" morph="none" pos="word" start_char="4581">the</TOKEN>
<TOKEN end_char="4593" id="token-35-11" morph="none" pos="word" start_char="4585">publisher</TOKEN>
<TOKEN end_char="4598" id="token-35-12" morph="none" pos="word" start_char="4595">that</TOKEN>
<TOKEN end_char="4606" id="token-35-13" morph="none" pos="word" start_char="4600">refutes</TOKEN>
<TOKEN end_char="4612" id="token-35-14" morph="none" pos="word" start_char="4608">their</TOKEN>
<TOKEN end_char="4618" id="token-35-15" morph="none" pos="word" start_char="4614">claim</TOKEN>
<TOKEN end_char="4619" id="token-35-16" morph="none" pos="punct" start_char="4619">.</TOKEN>
</SEG>
<SEG end_char="4706" id="segment-36" start_char="4622">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:07 2020 UTC)</ORIGINAL_TEXT>
<TOKEN end_char="4622" id="token-36-0" morph="none" pos="punct" start_char="4622">(</TOKEN>
<TOKEN end_char="4628" id="token-36-1" morph="none" pos="word" start_char="4623">Source</TOKEN>
<TOKEN end_char="4629" id="token-36-2" morph="none" pos="punct" start_char="4629">:</TOKEN>
<TOKEN end_char="4634" id="token-36-3" morph="none" pos="word" start_char="4631">Lead</TOKEN>
<TOKEN end_char="4642" id="token-36-4" morph="none" pos="word" start_char="4636">Stories</TOKEN>
<TOKEN end_char="4653" id="token-36-5" morph="none" pos="word" start_char="4644">Screenshot</TOKEN>
<TOKEN end_char="4658" id="token-36-6" morph="none" pos="word" start_char="4655">from</TOKEN>
<TOKEN end_char="4665" id="token-36-7" morph="none" pos="word" start_char="4660">paused</TOKEN>
<TOKEN end_char="4674" id="token-36-8" morph="none" pos="word" start_char="4667">Facebook</TOKEN>
<TOKEN end_char="4680" id="token-36-9" morph="none" pos="word" start_char="4676">video</TOKEN>
<TOKEN end_char="4684" id="token-36-10" morph="none" pos="word" start_char="4682">Wed</TOKEN>
<TOKEN end_char="4688" id="token-36-11" morph="none" pos="word" start_char="4686">Sep</TOKEN>
<TOKEN end_char="4690" id="token-36-12" morph="none" pos="word" start_char="4690">9</TOKEN>
<TOKEN end_char="4696" id="token-36-13" morph="none" pos="unknown" start_char="4692">17:07</TOKEN>
<TOKEN end_char="4701" id="token-36-14" morph="none" pos="word" start_char="4698">2020</TOKEN>
<TOKEN end_char="4705" id="token-36-15" morph="none" pos="word" start_char="4703">UTC</TOKEN>
<TOKEN end_char="4706" id="token-36-16" morph="none" pos="punct" start_char="4706">)</TOKEN>
</SEG>
<SEG end_char="4803" id="segment-37" start_char="4710">
<ORIGINAL_TEXT>The November, 2015 article in The Scientist is a favorite among COVID-19 conspiracy theorists.</ORIGINAL_TEXT>
<TOKEN end_char="4712" id="token-37-0" morph="none" pos="word" start_char="4710">The</TOKEN>
<TOKEN end_char="4721" id="token-37-1" morph="none" pos="word" start_char="4714">November</TOKEN>
<TOKEN end_char="4722" id="token-37-2" morph="none" pos="punct" start_char="4722">,</TOKEN>
<TOKEN end_char="4727" id="token-37-3" morph="none" pos="word" start_char="4724">2015</TOKEN>
<TOKEN end_char="4735" id="token-37-4" morph="none" pos="word" start_char="4729">article</TOKEN>
<TOKEN end_char="4738" id="token-37-5" morph="none" pos="word" start_char="4737">in</TOKEN>
<TOKEN end_char="4742" id="token-37-6" morph="none" pos="word" start_char="4740">The</TOKEN>
<TOKEN end_char="4752" id="token-37-7" morph="none" pos="word" start_char="4744">Scientist</TOKEN>
<TOKEN end_char="4755" id="token-37-8" morph="none" pos="word" start_char="4754">is</TOKEN>
<TOKEN end_char="4757" id="token-37-9" morph="none" pos="word" start_char="4757">a</TOKEN>
<TOKEN end_char="4766" id="token-37-10" morph="none" pos="word" start_char="4759">favorite</TOKEN>
<TOKEN end_char="4772" id="token-37-11" morph="none" pos="word" start_char="4768">among</TOKEN>
<TOKEN end_char="4781" id="token-37-12" morph="none" pos="unknown" start_char="4774">COVID-19</TOKEN>
<TOKEN end_char="4792" id="token-37-13" morph="none" pos="word" start_char="4783">conspiracy</TOKEN>
<TOKEN end_char="4802" id="token-37-14" morph="none" pos="word" start_char="4794">theorists</TOKEN>
<TOKEN end_char="4803" id="token-37-15" morph="none" pos="punct" start_char="4803">.</TOKEN>
</SEG>
<SEG end_char="4974" id="segment-38" start_char="4805">
<ORIGINAL_TEXT>The repeated mischaracterization of it was the subject of a January, 2020, Lead Stories fact check: "Fact Check: 2015 Article About Lab-Made Coronavirus Triggers Debate".</ORIGINAL_TEXT>
<TOKEN end_char="4807" id="token-38-0" morph="none" pos="word" start_char="4805">The</TOKEN>
<TOKEN end_char="4816" id="token-38-1" morph="none" pos="word" start_char="4809">repeated</TOKEN>
<TOKEN end_char="4836" id="token-38-2" morph="none" pos="word" start_char="4818">mischaracterization</TOKEN>
<TOKEN end_char="4839" id="token-38-3" morph="none" pos="word" start_char="4838">of</TOKEN>
<TOKEN end_char="4842" id="token-38-4" morph="none" pos="word" start_char="4841">it</TOKEN>
<TOKEN end_char="4846" id="token-38-5" morph="none" pos="word" start_char="4844">was</TOKEN>
<TOKEN end_char="4850" id="token-38-6" morph="none" pos="word" start_char="4848">the</TOKEN>
<TOKEN end_char="4858" id="token-38-7" morph="none" pos="word" start_char="4852">subject</TOKEN>
<TOKEN end_char="4861" id="token-38-8" morph="none" pos="word" start_char="4860">of</TOKEN>
<TOKEN end_char="4863" id="token-38-9" morph="none" pos="word" start_char="4863">a</TOKEN>
<TOKEN end_char="4871" id="token-38-10" morph="none" pos="word" start_char="4865">January</TOKEN>
<TOKEN end_char="4872" id="token-38-11" morph="none" pos="punct" start_char="4872">,</TOKEN>
<TOKEN end_char="4877" id="token-38-12" morph="none" pos="word" start_char="4874">2020</TOKEN>
<TOKEN end_char="4878" id="token-38-13" morph="none" pos="punct" start_char="4878">,</TOKEN>
<TOKEN end_char="4883" id="token-38-14" morph="none" pos="word" start_char="4880">Lead</TOKEN>
<TOKEN end_char="4891" id="token-38-15" morph="none" pos="word" start_char="4885">Stories</TOKEN>
<TOKEN end_char="4896" id="token-38-16" morph="none" pos="word" start_char="4893">fact</TOKEN>
<TOKEN end_char="4902" id="token-38-17" morph="none" pos="word" start_char="4898">check</TOKEN>
<TOKEN end_char="4903" id="token-38-18" morph="none" pos="punct" start_char="4903">:</TOKEN>
<TOKEN end_char="4905" id="token-38-19" morph="none" pos="punct" start_char="4905">"</TOKEN>
<TOKEN end_char="4909" id="token-38-20" morph="none" pos="word" start_char="4906">Fact</TOKEN>
<TOKEN end_char="4915" id="token-38-21" morph="none" pos="word" start_char="4911">Check</TOKEN>
<TOKEN end_char="4916" id="token-38-22" morph="none" pos="punct" start_char="4916">:</TOKEN>
<TOKEN end_char="4921" id="token-38-23" morph="none" pos="word" start_char="4918">2015</TOKEN>
<TOKEN end_char="4929" id="token-38-24" morph="none" pos="word" start_char="4923">Article</TOKEN>
<TOKEN end_char="4935" id="token-38-25" morph="none" pos="word" start_char="4931">About</TOKEN>
<TOKEN end_char="4944" id="token-38-26" morph="none" pos="unknown" start_char="4937">Lab-Made</TOKEN>
<TOKEN end_char="4956" id="token-38-27" morph="none" pos="word" start_char="4946">Coronavirus</TOKEN>
<TOKEN end_char="4965" id="token-38-28" morph="none" pos="word" start_char="4958">Triggers</TOKEN>
<TOKEN end_char="4972" id="token-38-29" morph="none" pos="word" start_char="4967">Debate</TOKEN>
<TOKEN end_char="4974" id="token-38-30" morph="none" pos="punct" start_char="4973">".</TOKEN>
</SEG>
<SEG end_char="5051" id="segment-39" start_char="4977">
<ORIGINAL_TEXT>This 'proof' document refers to six-year-old concerns about virus research.</ORIGINAL_TEXT>
<TOKEN end_char="4980" id="token-39-0" morph="none" pos="word" start_char="4977">This</TOKEN>
<TOKEN end_char="4982" id="token-39-1" morph="none" pos="punct" start_char="4982">'</TOKEN>
<TOKEN end_char="4987" id="token-39-2" morph="none" pos="word" start_char="4983">proof</TOKEN>
<TOKEN end_char="4988" id="token-39-3" morph="none" pos="punct" start_char="4988">'</TOKEN>
<TOKEN end_char="4997" id="token-39-4" morph="none" pos="word" start_char="4990">document</TOKEN>
<TOKEN end_char="5004" id="token-39-5" morph="none" pos="word" start_char="4999">refers</TOKEN>
<TOKEN end_char="5007" id="token-39-6" morph="none" pos="word" start_char="5006">to</TOKEN>
<TOKEN end_char="5020" id="token-39-7" morph="none" pos="unknown" start_char="5009">six-year-old</TOKEN>
<TOKEN end_char="5029" id="token-39-8" morph="none" pos="word" start_char="5022">concerns</TOKEN>
<TOKEN end_char="5035" id="token-39-9" morph="none" pos="word" start_char="5031">about</TOKEN>
<TOKEN end_char="5041" id="token-39-10" morph="none" pos="word" start_char="5037">virus</TOKEN>
<TOKEN end_char="5050" id="token-39-11" morph="none" pos="word" start_char="5043">research</TOKEN>
<TOKEN end_char="5051" id="token-39-12" morph="none" pos="punct" start_char="5051">.</TOKEN>
</SEG>
<SEG end_char="5203" id="segment-40" start_char="5055">
<ORIGINAL_TEXT>Science Magazine reported, in October of 2014, on the U.S. government's moratorium on "gain-of-function" research until new rules could be developed.</ORIGINAL_TEXT>
<TOKEN end_char="5061" id="token-40-0" morph="none" pos="word" start_char="5055">Science</TOKEN>
<TOKEN end_char="5070" id="token-40-1" morph="none" pos="word" start_char="5063">Magazine</TOKEN>
<TOKEN end_char="5079" id="token-40-2" morph="none" pos="word" start_char="5072">reported</TOKEN>
<TOKEN end_char="5080" id="token-40-3" morph="none" pos="punct" start_char="5080">,</TOKEN>
<TOKEN end_char="5083" id="token-40-4" morph="none" pos="word" start_char="5082">in</TOKEN>
<TOKEN end_char="5091" id="token-40-5" morph="none" pos="word" start_char="5085">October</TOKEN>
<TOKEN end_char="5094" id="token-40-6" morph="none" pos="word" start_char="5093">of</TOKEN>
<TOKEN end_char="5099" id="token-40-7" morph="none" pos="word" start_char="5096">2014</TOKEN>
<TOKEN end_char="5100" id="token-40-8" morph="none" pos="punct" start_char="5100">,</TOKEN>
<TOKEN end_char="5103" id="token-40-9" morph="none" pos="word" start_char="5102">on</TOKEN>
<TOKEN end_char="5107" id="token-40-10" morph="none" pos="word" start_char="5105">the</TOKEN>
<TOKEN end_char="5111" id="token-40-11" morph="none" pos="unknown" start_char="5109">U.S</TOKEN>
<TOKEN end_char="5112" id="token-40-12" morph="none" pos="punct" start_char="5112">.</TOKEN>
<TOKEN end_char="5125" id="token-40-13" morph="none" pos="word" start_char="5114">government's</TOKEN>
<TOKEN end_char="5136" id="token-40-14" morph="none" pos="word" start_char="5127">moratorium</TOKEN>
<TOKEN end_char="5139" id="token-40-15" morph="none" pos="word" start_char="5138">on</TOKEN>
<TOKEN end_char="5141" id="token-40-16" morph="none" pos="punct" start_char="5141">"</TOKEN>
<TOKEN end_char="5157" id="token-40-17" morph="none" pos="unknown" start_char="5142">gain-of-function</TOKEN>
<TOKEN end_char="5158" id="token-40-18" morph="none" pos="punct" start_char="5158">"</TOKEN>
<TOKEN end_char="5167" id="token-40-19" morph="none" pos="word" start_char="5160">research</TOKEN>
<TOKEN end_char="5173" id="token-40-20" morph="none" pos="word" start_char="5169">until</TOKEN>
<TOKEN end_char="5177" id="token-40-21" morph="none" pos="word" start_char="5175">new</TOKEN>
<TOKEN end_char="5183" id="token-40-22" morph="none" pos="word" start_char="5179">rules</TOKEN>
<TOKEN end_char="5189" id="token-40-23" morph="none" pos="word" start_char="5185">could</TOKEN>
<TOKEN end_char="5192" id="token-40-24" morph="none" pos="word" start_char="5191">be</TOKEN>
<TOKEN end_char="5202" id="token-40-25" morph="none" pos="word" start_char="5194">developed</TOKEN>
<TOKEN end_char="5203" id="token-40-26" morph="none" pos="punct" start_char="5203">.</TOKEN>
</SEG>
<SEG end_char="5352" id="segment-41" start_char="5205">
<ORIGINAL_TEXT>Virologists deconstruct and reconstruct viruses to understand how viruses change in the wild and what characteristics make them dangerous to humans.</ORIGINAL_TEXT>
<TOKEN end_char="5215" id="token-41-0" morph="none" pos="word" start_char="5205">Virologists</TOKEN>
<TOKEN end_char="5227" id="token-41-1" morph="none" pos="word" start_char="5217">deconstruct</TOKEN>
<TOKEN end_char="5231" id="token-41-2" morph="none" pos="word" start_char="5229">and</TOKEN>
<TOKEN end_char="5243" id="token-41-3" morph="none" pos="word" start_char="5233">reconstruct</TOKEN>
<TOKEN end_char="5251" id="token-41-4" morph="none" pos="word" start_char="5245">viruses</TOKEN>
<TOKEN end_char="5254" id="token-41-5" morph="none" pos="word" start_char="5253">to</TOKEN>
<TOKEN end_char="5265" id="token-41-6" morph="none" pos="word" start_char="5256">understand</TOKEN>
<TOKEN end_char="5269" id="token-41-7" morph="none" pos="word" start_char="5267">how</TOKEN>
<TOKEN end_char="5277" id="token-41-8" morph="none" pos="word" start_char="5271">viruses</TOKEN>
<TOKEN end_char="5284" id="token-41-9" morph="none" pos="word" start_char="5279">change</TOKEN>
<TOKEN end_char="5287" id="token-41-10" morph="none" pos="word" start_char="5286">in</TOKEN>
<TOKEN end_char="5291" id="token-41-11" morph="none" pos="word" start_char="5289">the</TOKEN>
<TOKEN end_char="5296" id="token-41-12" morph="none" pos="word" start_char="5293">wild</TOKEN>
<TOKEN end_char="5300" id="token-41-13" morph="none" pos="word" start_char="5298">and</TOKEN>
<TOKEN end_char="5305" id="token-41-14" morph="none" pos="word" start_char="5302">what</TOKEN>
<TOKEN end_char="5321" id="token-41-15" morph="none" pos="word" start_char="5307">characteristics</TOKEN>
<TOKEN end_char="5326" id="token-41-16" morph="none" pos="word" start_char="5323">make</TOKEN>
<TOKEN end_char="5331" id="token-41-17" morph="none" pos="word" start_char="5328">them</TOKEN>
<TOKEN end_char="5341" id="token-41-18" morph="none" pos="word" start_char="5333">dangerous</TOKEN>
<TOKEN end_char="5344" id="token-41-19" morph="none" pos="word" start_char="5343">to</TOKEN>
<TOKEN end_char="5351" id="token-41-20" morph="none" pos="word" start_char="5346">humans</TOKEN>
<TOKEN end_char="5352" id="token-41-21" morph="none" pos="punct" start_char="5352">.</TOKEN>
</SEG>
<SEG end_char="5390" id="segment-42" start_char="5354">
<ORIGINAL_TEXT>The moratorium has since been lifted.</ORIGINAL_TEXT>
<TOKEN end_char="5356" id="token-42-0" morph="none" pos="word" start_char="5354">The</TOKEN>
<TOKEN end_char="5367" id="token-42-1" morph="none" pos="word" start_char="5358">moratorium</TOKEN>
<TOKEN end_char="5371" id="token-42-2" morph="none" pos="word" start_char="5369">has</TOKEN>
<TOKEN end_char="5377" id="token-42-3" morph="none" pos="word" start_char="5373">since</TOKEN>
<TOKEN end_char="5382" id="token-42-4" morph="none" pos="word" start_char="5379">been</TOKEN>
<TOKEN end_char="5389" id="token-42-5" morph="none" pos="word" start_char="5384">lifted</TOKEN>
<TOKEN end_char="5390" id="token-42-6" morph="none" pos="punct" start_char="5390">.</TOKEN>
</SEG>
<SEG end_char="5484" id="segment-43" start_char="5392">
<ORIGINAL_TEXT>At that time, they were studying SARS, one of the seven coronavirus forms that infect humans.</ORIGINAL_TEXT>
<TOKEN end_char="5393" id="token-43-0" morph="none" pos="word" start_char="5392">At</TOKEN>
<TOKEN end_char="5398" id="token-43-1" morph="none" pos="word" start_char="5395">that</TOKEN>
<TOKEN end_char="5403" id="token-43-2" morph="none" pos="word" start_char="5400">time</TOKEN>
<TOKEN end_char="5404" id="token-43-3" morph="none" pos="punct" start_char="5404">,</TOKEN>
<TOKEN end_char="5409" id="token-43-4" morph="none" pos="word" start_char="5406">they</TOKEN>
<TOKEN end_char="5414" id="token-43-5" morph="none" pos="word" start_char="5411">were</TOKEN>
<TOKEN end_char="5423" id="token-43-6" morph="none" pos="word" start_char="5416">studying</TOKEN>
<TOKEN end_char="5428" id="token-43-7" morph="none" pos="word" start_char="5425">SARS</TOKEN>
<TOKEN end_char="5429" id="token-43-8" morph="none" pos="punct" start_char="5429">,</TOKEN>
<TOKEN end_char="5433" id="token-43-9" morph="none" pos="word" start_char="5431">one</TOKEN>
<TOKEN end_char="5436" id="token-43-10" morph="none" pos="word" start_char="5435">of</TOKEN>
<TOKEN end_char="5440" id="token-43-11" morph="none" pos="word" start_char="5438">the</TOKEN>
<TOKEN end_char="5446" id="token-43-12" morph="none" pos="word" start_char="5442">seven</TOKEN>
<TOKEN end_char="5458" id="token-43-13" morph="none" pos="word" start_char="5448">coronavirus</TOKEN>
<TOKEN end_char="5464" id="token-43-14" morph="none" pos="word" start_char="5460">forms</TOKEN>
<TOKEN end_char="5469" id="token-43-15" morph="none" pos="word" start_char="5466">that</TOKEN>
<TOKEN end_char="5476" id="token-43-16" morph="none" pos="word" start_char="5471">infect</TOKEN>
<TOKEN end_char="5483" id="token-43-17" morph="none" pos="word" start_char="5478">humans</TOKEN>
<TOKEN end_char="5484" id="token-43-18" morph="none" pos="punct" start_char="5484">.</TOKEN>
</SEG>
<SEG end_char="5571" id="segment-44" start_char="5487">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:21 2020 UTC)</ORIGINAL_TEXT>
<TOKEN end_char="5487" id="token-44-0" morph="none" pos="punct" start_char="5487">(</TOKEN>
<TOKEN end_char="5493" id="token-44-1" morph="none" pos="word" start_char="5488">Source</TOKEN>
<TOKEN end_char="5494" id="token-44-2" morph="none" pos="punct" start_char="5494">:</TOKEN>
<TOKEN end_char="5499" id="token-44-3" morph="none" pos="word" start_char="5496">Lead</TOKEN>
<TOKEN end_char="5507" id="token-44-4" morph="none" pos="word" start_char="5501">Stories</TOKEN>
<TOKEN end_char="5518" id="token-44-5" morph="none" pos="word" start_char="5509">Screenshot</TOKEN>
<TOKEN end_char="5523" id="token-44-6" morph="none" pos="word" start_char="5520">from</TOKEN>
<TOKEN end_char="5530" id="token-44-7" morph="none" pos="word" start_char="5525">paused</TOKEN>
<TOKEN end_char="5539" id="token-44-8" morph="none" pos="word" start_char="5532">Facebook</TOKEN>
<TOKEN end_char="5545" id="token-44-9" morph="none" pos="word" start_char="5541">video</TOKEN>
<TOKEN end_char="5549" id="token-44-10" morph="none" pos="word" start_char="5547">Wed</TOKEN>
<TOKEN end_char="5553" id="token-44-11" morph="none" pos="word" start_char="5551">Sep</TOKEN>
<TOKEN end_char="5555" id="token-44-12" morph="none" pos="word" start_char="5555">9</TOKEN>
<TOKEN end_char="5561" id="token-44-13" morph="none" pos="unknown" start_char="5557">17:21</TOKEN>
<TOKEN end_char="5566" id="token-44-14" morph="none" pos="word" start_char="5563">2020</TOKEN>
<TOKEN end_char="5570" id="token-44-15" morph="none" pos="word" start_char="5568">UTC</TOKEN>
<TOKEN end_char="5571" id="token-44-16" morph="none" pos="punct" start_char="5571">)</TOKEN>
</SEG>
<SEG end_char="5662" id="segment-45" start_char="5575">
<ORIGINAL_TEXT>This 'proof' document is a position paper about influenza bio-weapons, not coronaviruses</ORIGINAL_TEXT>
<TOKEN end_char="5578" id="token-45-0" morph="none" pos="word" start_char="5575">This</TOKEN>
<TOKEN end_char="5580" id="token-45-1" morph="none" pos="punct" start_char="5580">'</TOKEN>
<TOKEN end_char="5585" id="token-45-2" morph="none" pos="word" start_char="5581">proof</TOKEN>
<TOKEN end_char="5586" id="token-45-3" morph="none" pos="punct" start_char="5586">'</TOKEN>
<TOKEN end_char="5595" id="token-45-4" morph="none" pos="word" start_char="5588">document</TOKEN>
<TOKEN end_char="5598" id="token-45-5" morph="none" pos="word" start_char="5597">is</TOKEN>
<TOKEN end_char="5600" id="token-45-6" morph="none" pos="word" start_char="5600">a</TOKEN>
<TOKEN end_char="5609" id="token-45-7" morph="none" pos="word" start_char="5602">position</TOKEN>
<TOKEN end_char="5615" id="token-45-8" morph="none" pos="word" start_char="5611">paper</TOKEN>
<TOKEN end_char="5621" id="token-45-9" morph="none" pos="word" start_char="5617">about</TOKEN>
<TOKEN end_char="5631" id="token-45-10" morph="none" pos="word" start_char="5623">influenza</TOKEN>
<TOKEN end_char="5643" id="token-45-11" morph="none" pos="unknown" start_char="5633">bio-weapons</TOKEN>
<TOKEN end_char="5644" id="token-45-12" morph="none" pos="punct" start_char="5644">,</TOKEN>
<TOKEN end_char="5648" id="token-45-13" morph="none" pos="word" start_char="5646">not</TOKEN>
<TOKEN end_char="5662" id="token-45-14" morph="none" pos="word" start_char="5650">coronaviruses</TOKEN>
</SEG>
<SEG end_char="5750" id="segment-46" start_char="5666">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:29 2020 UTC)</ORIGINAL_TEXT>
<TOKEN end_char="5666" id="token-46-0" morph="none" pos="punct" start_char="5666">(</TOKEN>
<TOKEN end_char="5672" id="token-46-1" morph="none" pos="word" start_char="5667">Source</TOKEN>
<TOKEN end_char="5673" id="token-46-2" morph="none" pos="punct" start_char="5673">:</TOKEN>
<TOKEN end_char="5678" id="token-46-3" morph="none" pos="word" start_char="5675">Lead</TOKEN>
<TOKEN end_char="5686" id="token-46-4" morph="none" pos="word" start_char="5680">Stories</TOKEN>
<TOKEN end_char="5697" id="token-46-5" morph="none" pos="word" start_char="5688">Screenshot</TOKEN>
<TOKEN end_char="5702" id="token-46-6" morph="none" pos="word" start_char="5699">from</TOKEN>
<TOKEN end_char="5709" id="token-46-7" morph="none" pos="word" start_char="5704">paused</TOKEN>
<TOKEN end_char="5718" id="token-46-8" morph="none" pos="word" start_char="5711">Facebook</TOKEN>
<TOKEN end_char="5724" id="token-46-9" morph="none" pos="word" start_char="5720">video</TOKEN>
<TOKEN end_char="5728" id="token-46-10" morph="none" pos="word" start_char="5726">Wed</TOKEN>
<TOKEN end_char="5732" id="token-46-11" morph="none" pos="word" start_char="5730">Sep</TOKEN>
<TOKEN end_char="5734" id="token-46-12" morph="none" pos="word" start_char="5734">9</TOKEN>
<TOKEN end_char="5740" id="token-46-13" morph="none" pos="unknown" start_char="5736">17:29</TOKEN>
<TOKEN end_char="5745" id="token-46-14" morph="none" pos="word" start_char="5742">2020</TOKEN>
<TOKEN end_char="5749" id="token-46-15" morph="none" pos="word" start_char="5747">UTC</TOKEN>
<TOKEN end_char="5750" id="token-46-16" morph="none" pos="punct" start_char="5750">)</TOKEN>
</SEG>
<SEG end_char="6043" id="segment-47" start_char="5754">
<ORIGINAL_TEXT>In 2014, scientists at the Center for Arms Control and Non-proliferation wrote to the National Science Advisory Board for Biosecurity to express their support for proposed safety measures to prevent pathogens from being released from labs and to limit the development of biological weapons.</ORIGINAL_TEXT>
<TOKEN end_char="5755" id="token-47-0" morph="none" pos="word" start_char="5754">In</TOKEN>
<TOKEN end_char="5760" id="token-47-1" morph="none" pos="word" start_char="5757">2014</TOKEN>
<TOKEN end_char="5761" id="token-47-2" morph="none" pos="punct" start_char="5761">,</TOKEN>
<TOKEN end_char="5772" id="token-47-3" morph="none" pos="word" start_char="5763">scientists</TOKEN>
<TOKEN end_char="5775" id="token-47-4" morph="none" pos="word" start_char="5774">at</TOKEN>
<TOKEN end_char="5779" id="token-47-5" morph="none" pos="word" start_char="5777">the</TOKEN>
<TOKEN end_char="5786" id="token-47-6" morph="none" pos="word" start_char="5781">Center</TOKEN>
<TOKEN end_char="5790" id="token-47-7" morph="none" pos="word" start_char="5788">for</TOKEN>
<TOKEN end_char="5795" id="token-47-8" morph="none" pos="word" start_char="5792">Arms</TOKEN>
<TOKEN end_char="5803" id="token-47-9" morph="none" pos="word" start_char="5797">Control</TOKEN>
<TOKEN end_char="5807" id="token-47-10" morph="none" pos="word" start_char="5805">and</TOKEN>
<TOKEN end_char="5825" id="token-47-11" morph="none" pos="unknown" start_char="5809">Non-proliferation</TOKEN>
<TOKEN end_char="5831" id="token-47-12" morph="none" pos="word" start_char="5827">wrote</TOKEN>
<TOKEN end_char="5834" id="token-47-13" morph="none" pos="word" start_char="5833">to</TOKEN>
<TOKEN end_char="5838" id="token-47-14" morph="none" pos="word" start_char="5836">the</TOKEN>
<TOKEN end_char="5847" id="token-47-15" morph="none" pos="word" start_char="5840">National</TOKEN>
<TOKEN end_char="5855" id="token-47-16" morph="none" pos="word" start_char="5849">Science</TOKEN>
<TOKEN end_char="5864" id="token-47-17" morph="none" pos="word" start_char="5857">Advisory</TOKEN>
<TOKEN end_char="5870" id="token-47-18" morph="none" pos="word" start_char="5866">Board</TOKEN>
<TOKEN end_char="5874" id="token-47-19" morph="none" pos="word" start_char="5872">for</TOKEN>
<TOKEN end_char="5886" id="token-47-20" morph="none" pos="word" start_char="5876">Biosecurity</TOKEN>
<TOKEN end_char="5889" id="token-47-21" morph="none" pos="word" start_char="5888">to</TOKEN>
<TOKEN end_char="5897" id="token-47-22" morph="none" pos="word" start_char="5891">express</TOKEN>
<TOKEN end_char="5903" id="token-47-23" morph="none" pos="word" start_char="5899">their</TOKEN>
<TOKEN end_char="5911" id="token-47-24" morph="none" pos="word" start_char="5905">support</TOKEN>
<TOKEN end_char="5915" id="token-47-25" morph="none" pos="word" start_char="5913">for</TOKEN>
<TOKEN end_char="5924" id="token-47-26" morph="none" pos="word" start_char="5917">proposed</TOKEN>
<TOKEN end_char="5931" id="token-47-27" morph="none" pos="word" start_char="5926">safety</TOKEN>
<TOKEN end_char="5940" id="token-47-28" morph="none" pos="word" start_char="5933">measures</TOKEN>
<TOKEN end_char="5943" id="token-47-29" morph="none" pos="word" start_char="5942">to</TOKEN>
<TOKEN end_char="5951" id="token-47-30" morph="none" pos="word" start_char="5945">prevent</TOKEN>
<TOKEN end_char="5961" id="token-47-31" morph="none" pos="word" start_char="5953">pathogens</TOKEN>
<TOKEN end_char="5966" id="token-47-32" morph="none" pos="word" start_char="5963">from</TOKEN>
<TOKEN end_char="5972" id="token-47-33" morph="none" pos="word" start_char="5968">being</TOKEN>
<TOKEN end_char="5981" id="token-47-34" morph="none" pos="word" start_char="5974">released</TOKEN>
<TOKEN end_char="5986" id="token-47-35" morph="none" pos="word" start_char="5983">from</TOKEN>
<TOKEN end_char="5991" id="token-47-36" morph="none" pos="word" start_char="5988">labs</TOKEN>
<TOKEN end_char="5995" id="token-47-37" morph="none" pos="word" start_char="5993">and</TOKEN>
<TOKEN end_char="5998" id="token-47-38" morph="none" pos="word" start_char="5997">to</TOKEN>
<TOKEN end_char="6004" id="token-47-39" morph="none" pos="word" start_char="6000">limit</TOKEN>
<TOKEN end_char="6008" id="token-47-40" morph="none" pos="word" start_char="6006">the</TOKEN>
<TOKEN end_char="6020" id="token-47-41" morph="none" pos="word" start_char="6010">development</TOKEN>
<TOKEN end_char="6023" id="token-47-42" morph="none" pos="word" start_char="6022">of</TOKEN>
<TOKEN end_char="6034" id="token-47-43" morph="none" pos="word" start_char="6025">biological</TOKEN>
<TOKEN end_char="6042" id="token-47-44" morph="none" pos="word" start_char="6036">weapons</TOKEN>
<TOKEN end_char="6043" id="token-47-45" morph="none" pos="punct" start_char="6043">.</TOKEN>
</SEG>
<SEG end_char="6173" id="segment-48" start_char="6045">
<ORIGINAL_TEXT>While the letter raises the possibility of a pandemic caused by human actions, it does not in itself prove COVID-19 was lab-made.</ORIGINAL_TEXT>
<TOKEN end_char="6049" id="token-48-0" morph="none" pos="word" start_char="6045">While</TOKEN>
<TOKEN end_char="6053" id="token-48-1" morph="none" pos="word" start_char="6051">the</TOKEN>
<TOKEN end_char="6060" id="token-48-2" morph="none" pos="word" start_char="6055">letter</TOKEN>
<TOKEN end_char="6067" id="token-48-3" morph="none" pos="word" start_char="6062">raises</TOKEN>
<TOKEN end_char="6071" id="token-48-4" morph="none" pos="word" start_char="6069">the</TOKEN>
<TOKEN end_char="6083" id="token-48-5" morph="none" pos="word" start_char="6073">possibility</TOKEN>
<TOKEN end_char="6086" id="token-48-6" morph="none" pos="word" start_char="6085">of</TOKEN>
<TOKEN end_char="6088" id="token-48-7" morph="none" pos="word" start_char="6088">a</TOKEN>
<TOKEN end_char="6097" id="token-48-8" morph="none" pos="word" start_char="6090">pandemic</TOKEN>
<TOKEN end_char="6104" id="token-48-9" morph="none" pos="word" start_char="6099">caused</TOKEN>
<TOKEN end_char="6107" id="token-48-10" morph="none" pos="word" start_char="6106">by</TOKEN>
<TOKEN end_char="6113" id="token-48-11" morph="none" pos="word" start_char="6109">human</TOKEN>
<TOKEN end_char="6121" id="token-48-12" morph="none" pos="word" start_char="6115">actions</TOKEN>
<TOKEN end_char="6122" id="token-48-13" morph="none" pos="punct" start_char="6122">,</TOKEN>
<TOKEN end_char="6125" id="token-48-14" morph="none" pos="word" start_char="6124">it</TOKEN>
<TOKEN end_char="6130" id="token-48-15" morph="none" pos="word" start_char="6127">does</TOKEN>
<TOKEN end_char="6134" id="token-48-16" morph="none" pos="word" start_char="6132">not</TOKEN>
<TOKEN end_char="6137" id="token-48-17" morph="none" pos="word" start_char="6136">in</TOKEN>
<TOKEN end_char="6144" id="token-48-18" morph="none" pos="word" start_char="6139">itself</TOKEN>
<TOKEN end_char="6150" id="token-48-19" morph="none" pos="word" start_char="6146">prove</TOKEN>
<TOKEN end_char="6159" id="token-48-20" morph="none" pos="unknown" start_char="6152">COVID-19</TOKEN>
<TOKEN end_char="6163" id="token-48-21" morph="none" pos="word" start_char="6161">was</TOKEN>
<TOKEN end_char="6172" id="token-48-22" morph="none" pos="unknown" start_char="6165">lab-made</TOKEN>
<TOKEN end_char="6173" id="token-48-23" morph="none" pos="punct" start_char="6173">.</TOKEN>
</SEG>
<SEG end_char="6230" id="segment-49" start_char="6176">
<ORIGINAL_TEXT>This 'proof' document is just a copy of a U.S. law book</ORIGINAL_TEXT>
<TOKEN end_char="6179" id="token-49-0" morph="none" pos="word" start_char="6176">This</TOKEN>
<TOKEN end_char="6181" id="token-49-1" morph="none" pos="punct" start_char="6181">'</TOKEN>
<TOKEN end_char="6186" id="token-49-2" morph="none" pos="word" start_char="6182">proof</TOKEN>
<TOKEN end_char="6187" id="token-49-3" morph="none" pos="punct" start_char="6187">'</TOKEN>
<TOKEN end_char="6196" id="token-49-4" morph="none" pos="word" start_char="6189">document</TOKEN>
<TOKEN end_char="6199" id="token-49-5" morph="none" pos="word" start_char="6198">is</TOKEN>
<TOKEN end_char="6204" id="token-49-6" morph="none" pos="word" start_char="6201">just</TOKEN>
<TOKEN end_char="6206" id="token-49-7" morph="none" pos="word" start_char="6206">a</TOKEN>
<TOKEN end_char="6211" id="token-49-8" morph="none" pos="word" start_char="6208">copy</TOKEN>
<TOKEN end_char="6214" id="token-49-9" morph="none" pos="word" start_char="6213">of</TOKEN>
<TOKEN end_char="6216" id="token-49-10" morph="none" pos="word" start_char="6216">a</TOKEN>
<TOKEN end_char="6220" id="token-49-11" morph="none" pos="unknown" start_char="6218">U.S</TOKEN>
<TOKEN end_char="6221" id="token-49-12" morph="none" pos="punct" start_char="6221">.</TOKEN>
<TOKEN end_char="6225" id="token-49-13" morph="none" pos="word" start_char="6223">law</TOKEN>
<TOKEN end_char="6230" id="token-49-14" morph="none" pos="word" start_char="6227">book</TOKEN>
</SEG>
<SEG end_char="6337" id="segment-50" start_char="6234">
<ORIGINAL_TEXT>The photo shows the section of U.S. law that defines the powers of the U.S. Patent and Trademark Office.</ORIGINAL_TEXT>
<TOKEN end_char="6236" id="token-50-0" morph="none" pos="word" start_char="6234">The</TOKEN>
<TOKEN end_char="6242" id="token-50-1" morph="none" pos="word" start_char="6238">photo</TOKEN>
<TOKEN end_char="6248" id="token-50-2" morph="none" pos="word" start_char="6244">shows</TOKEN>
<TOKEN end_char="6252" id="token-50-3" morph="none" pos="word" start_char="6250">the</TOKEN>
<TOKEN end_char="6260" id="token-50-4" morph="none" pos="word" start_char="6254">section</TOKEN>
<TOKEN end_char="6263" id="token-50-5" morph="none" pos="word" start_char="6262">of</TOKEN>
<TOKEN end_char="6267" id="token-50-6" morph="none" pos="unknown" start_char="6265">U.S</TOKEN>
<TOKEN end_char="6268" id="token-50-7" morph="none" pos="punct" start_char="6268">.</TOKEN>
<TOKEN end_char="6272" id="token-50-8" morph="none" pos="word" start_char="6270">law</TOKEN>
<TOKEN end_char="6277" id="token-50-9" morph="none" pos="word" start_char="6274">that</TOKEN>
<TOKEN end_char="6285" id="token-50-10" morph="none" pos="word" start_char="6279">defines</TOKEN>
<TOKEN end_char="6289" id="token-50-11" morph="none" pos="word" start_char="6287">the</TOKEN>
<TOKEN end_char="6296" id="token-50-12" morph="none" pos="word" start_char="6291">powers</TOKEN>
<TOKEN end_char="6299" id="token-50-13" morph="none" pos="word" start_char="6298">of</TOKEN>
<TOKEN end_char="6303" id="token-50-14" morph="none" pos="word" start_char="6301">the</TOKEN>
<TOKEN end_char="6307" id="token-50-15" morph="none" pos="unknown" start_char="6305">U.S</TOKEN>
<TOKEN end_char="6308" id="token-50-16" morph="none" pos="punct" start_char="6308">.</TOKEN>
<TOKEN end_char="6315" id="token-50-17" morph="none" pos="word" start_char="6310">Patent</TOKEN>
<TOKEN end_char="6319" id="token-50-18" morph="none" pos="word" start_char="6317">and</TOKEN>
<TOKEN end_char="6329" id="token-50-19" morph="none" pos="word" start_char="6321">Trademark</TOKEN>
<TOKEN end_char="6336" id="token-50-20" morph="none" pos="word" start_char="6331">Office</TOKEN>
<TOKEN end_char="6337" id="token-50-21" morph="none" pos="punct" start_char="6337">.</TOKEN>
</SEG>
<SEG end_char="6488" id="segment-51" start_char="6339">
<ORIGINAL_TEXT>Swann and Martin claim federal judges and attorneys all got it wrong when the CDC applied for a patent to keep virus information in the public domain.</ORIGINAL_TEXT>
<TOKEN end_char="6343" id="token-51-0" morph="none" pos="word" start_char="6339">Swann</TOKEN>
<TOKEN end_char="6347" id="token-51-1" morph="none" pos="word" start_char="6345">and</TOKEN>
<TOKEN end_char="6354" id="token-51-2" morph="none" pos="word" start_char="6349">Martin</TOKEN>
<TOKEN end_char="6360" id="token-51-3" morph="none" pos="word" start_char="6356">claim</TOKEN>
<TOKEN end_char="6368" id="token-51-4" morph="none" pos="word" start_char="6362">federal</TOKEN>
<TOKEN end_char="6375" id="token-51-5" morph="none" pos="word" start_char="6370">judges</TOKEN>
<TOKEN end_char="6379" id="token-51-6" morph="none" pos="word" start_char="6377">and</TOKEN>
<TOKEN end_char="6389" id="token-51-7" morph="none" pos="word" start_char="6381">attorneys</TOKEN>
<TOKEN end_char="6393" id="token-51-8" morph="none" pos="word" start_char="6391">all</TOKEN>
<TOKEN end_char="6397" id="token-51-9" morph="none" pos="word" start_char="6395">got</TOKEN>
<TOKEN end_char="6400" id="token-51-10" morph="none" pos="word" start_char="6399">it</TOKEN>
<TOKEN end_char="6406" id="token-51-11" morph="none" pos="word" start_char="6402">wrong</TOKEN>
<TOKEN end_char="6411" id="token-51-12" morph="none" pos="word" start_char="6408">when</TOKEN>
<TOKEN end_char="6415" id="token-51-13" morph="none" pos="word" start_char="6413">the</TOKEN>
<TOKEN end_char="6419" id="token-51-14" morph="none" pos="word" start_char="6417">CDC</TOKEN>
<TOKEN end_char="6427" id="token-51-15" morph="none" pos="word" start_char="6421">applied</TOKEN>
<TOKEN end_char="6431" id="token-51-16" morph="none" pos="word" start_char="6429">for</TOKEN>
<TOKEN end_char="6433" id="token-51-17" morph="none" pos="word" start_char="6433">a</TOKEN>
<TOKEN end_char="6440" id="token-51-18" morph="none" pos="word" start_char="6435">patent</TOKEN>
<TOKEN end_char="6443" id="token-51-19" morph="none" pos="word" start_char="6442">to</TOKEN>
<TOKEN end_char="6448" id="token-51-20" morph="none" pos="word" start_char="6445">keep</TOKEN>
<TOKEN end_char="6454" id="token-51-21" morph="none" pos="word" start_char="6450">virus</TOKEN>
<TOKEN end_char="6466" id="token-51-22" morph="none" pos="word" start_char="6456">information</TOKEN>
<TOKEN end_char="6469" id="token-51-23" morph="none" pos="word" start_char="6468">in</TOKEN>
<TOKEN end_char="6473" id="token-51-24" morph="none" pos="word" start_char="6471">the</TOKEN>
<TOKEN end_char="6480" id="token-51-25" morph="none" pos="word" start_char="6475">public</TOKEN>
<TOKEN end_char="6487" id="token-51-26" morph="none" pos="word" start_char="6482">domain</TOKEN>
<TOKEN end_char="6488" id="token-51-27" morph="none" pos="punct" start_char="6488">.</TOKEN>
</SEG>
<SEG end_char="6575" id="segment-52" start_char="6491">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:16 2020 UTC)</ORIGINAL_TEXT>
<TOKEN end_char="6491" id="token-52-0" morph="none" pos="punct" start_char="6491">(</TOKEN>
<TOKEN end_char="6497" id="token-52-1" morph="none" pos="word" start_char="6492">Source</TOKEN>
<TOKEN end_char="6498" id="token-52-2" morph="none" pos="punct" start_char="6498">:</TOKEN>
<TOKEN end_char="6503" id="token-52-3" morph="none" pos="word" start_char="6500">Lead</TOKEN>
<TOKEN end_char="6511" id="token-52-4" morph="none" pos="word" start_char="6505">Stories</TOKEN>
<TOKEN end_char="6522" id="token-52-5" morph="none" pos="word" start_char="6513">Screenshot</TOKEN>
<TOKEN end_char="6527" id="token-52-6" morph="none" pos="word" start_char="6524">from</TOKEN>
<TOKEN end_char="6534" id="token-52-7" morph="none" pos="word" start_char="6529">paused</TOKEN>
<TOKEN end_char="6543" id="token-52-8" morph="none" pos="word" start_char="6536">Facebook</TOKEN>
<TOKEN end_char="6549" id="token-52-9" morph="none" pos="word" start_char="6545">video</TOKEN>
<TOKEN end_char="6553" id="token-52-10" morph="none" pos="word" start_char="6551">Wed</TOKEN>
<TOKEN end_char="6557" id="token-52-11" morph="none" pos="word" start_char="6555">Sep</TOKEN>
<TOKEN end_char="6559" id="token-52-12" morph="none" pos="word" start_char="6559">9</TOKEN>
<TOKEN end_char="6565" id="token-52-13" morph="none" pos="unknown" start_char="6561">17:16</TOKEN>
<TOKEN end_char="6570" id="token-52-14" morph="none" pos="word" start_char="6567">2020</TOKEN>
<TOKEN end_char="6574" id="token-52-15" morph="none" pos="word" start_char="6572">UTC</TOKEN>
<TOKEN end_char="6575" id="token-52-16" morph="none" pos="punct" start_char="6575">)</TOKEN>
</SEG>
<SEG end_char="6633" id="segment-53" start_char="6579">
<ORIGINAL_TEXT>This Supreme Court decision does not prove a conspiracy</ORIGINAL_TEXT>
<TOKEN end_char="6582" id="token-53-0" morph="none" pos="word" start_char="6579">This</TOKEN>
<TOKEN end_char="6590" id="token-53-1" morph="none" pos="word" start_char="6584">Supreme</TOKEN>
<TOKEN end_char="6596" id="token-53-2" morph="none" pos="word" start_char="6592">Court</TOKEN>
<TOKEN end_char="6605" id="token-53-3" morph="none" pos="word" start_char="6598">decision</TOKEN>
<TOKEN end_char="6610" id="token-53-4" morph="none" pos="word" start_char="6607">does</TOKEN>
<TOKEN end_char="6614" id="token-53-5" morph="none" pos="word" start_char="6612">not</TOKEN>
<TOKEN end_char="6620" id="token-53-6" morph="none" pos="word" start_char="6616">prove</TOKEN>
<TOKEN end_char="6622" id="token-53-7" morph="none" pos="word" start_char="6622">a</TOKEN>
<TOKEN end_char="6633" id="token-53-8" morph="none" pos="word" start_char="6624">conspiracy</TOKEN>
</SEG>
<SEG end_char="6729" id="segment-54" start_char="6637">
<ORIGINAL_TEXT>Martin claims the CDC had nefarious intent when it patented methods to detect the SARS virus.</ORIGINAL_TEXT>
<TOKEN end_char="6642" id="token-54-0" morph="none" pos="word" start_char="6637">Martin</TOKEN>
<TOKEN end_char="6649" id="token-54-1" morph="none" pos="word" start_char="6644">claims</TOKEN>
<TOKEN end_char="6653" id="token-54-2" morph="none" pos="word" start_char="6651">the</TOKEN>
<TOKEN end_char="6657" id="token-54-3" morph="none" pos="word" start_char="6655">CDC</TOKEN>
<TOKEN end_char="6661" id="token-54-4" morph="none" pos="word" start_char="6659">had</TOKEN>
<TOKEN end_char="6671" id="token-54-5" morph="none" pos="word" start_char="6663">nefarious</TOKEN>
<TOKEN end_char="6678" id="token-54-6" morph="none" pos="word" start_char="6673">intent</TOKEN>
<TOKEN end_char="6683" id="token-54-7" morph="none" pos="word" start_char="6680">when</TOKEN>
<TOKEN end_char="6686" id="token-54-8" morph="none" pos="word" start_char="6685">it</TOKEN>
<TOKEN end_char="6695" id="token-54-9" morph="none" pos="word" start_char="6688">patented</TOKEN>
<TOKEN end_char="6703" id="token-54-10" morph="none" pos="word" start_char="6697">methods</TOKEN>
<TOKEN end_char="6706" id="token-54-11" morph="none" pos="word" start_char="6705">to</TOKEN>
<TOKEN end_char="6713" id="token-54-12" morph="none" pos="word" start_char="6708">detect</TOKEN>
<TOKEN end_char="6717" id="token-54-13" morph="none" pos="word" start_char="6715">the</TOKEN>
<TOKEN end_char="6722" id="token-54-14" morph="none" pos="word" start_char="6719">SARS</TOKEN>
<TOKEN end_char="6728" id="token-54-15" morph="none" pos="word" start_char="6724">virus</TOKEN>
<TOKEN end_char="6729" id="token-54-16" morph="none" pos="punct" start_char="6729">.</TOKEN>
</SEG>
<SEG end_char="6915" id="segment-55" start_char="6731">
<ORIGINAL_TEXT>The Wall Street Journal reported at the time that CDC officials were clear that they were trying the patent route to prevent commercial firms from monopolizing public health technology.</ORIGINAL_TEXT>
<TOKEN end_char="6733" id="token-55-0" morph="none" pos="word" start_char="6731">The</TOKEN>
<TOKEN end_char="6738" id="token-55-1" morph="none" pos="word" start_char="6735">Wall</TOKEN>
<TOKEN end_char="6745" id="token-55-2" morph="none" pos="word" start_char="6740">Street</TOKEN>
<TOKEN end_char="6753" id="token-55-3" morph="none" pos="word" start_char="6747">Journal</TOKEN>
<TOKEN end_char="6762" id="token-55-4" morph="none" pos="word" start_char="6755">reported</TOKEN>
<TOKEN end_char="6765" id="token-55-5" morph="none" pos="word" start_char="6764">at</TOKEN>
<TOKEN end_char="6769" id="token-55-6" morph="none" pos="word" start_char="6767">the</TOKEN>
<TOKEN end_char="6774" id="token-55-7" morph="none" pos="word" start_char="6771">time</TOKEN>
<TOKEN end_char="6779" id="token-55-8" morph="none" pos="word" start_char="6776">that</TOKEN>
<TOKEN end_char="6783" id="token-55-9" morph="none" pos="word" start_char="6781">CDC</TOKEN>
<TOKEN end_char="6793" id="token-55-10" morph="none" pos="word" start_char="6785">officials</TOKEN>
<TOKEN end_char="6798" id="token-55-11" morph="none" pos="word" start_char="6795">were</TOKEN>
<TOKEN end_char="6804" id="token-55-12" morph="none" pos="word" start_char="6800">clear</TOKEN>
<TOKEN end_char="6809" id="token-55-13" morph="none" pos="word" start_char="6806">that</TOKEN>
<TOKEN end_char="6814" id="token-55-14" morph="none" pos="word" start_char="6811">they</TOKEN>
<TOKEN end_char="6819" id="token-55-15" morph="none" pos="word" start_char="6816">were</TOKEN>
<TOKEN end_char="6826" id="token-55-16" morph="none" pos="word" start_char="6821">trying</TOKEN>
<TOKEN end_char="6830" id="token-55-17" morph="none" pos="word" start_char="6828">the</TOKEN>
<TOKEN end_char="6837" id="token-55-18" morph="none" pos="word" start_char="6832">patent</TOKEN>
<TOKEN end_char="6843" id="token-55-19" morph="none" pos="word" start_char="6839">route</TOKEN>
<TOKEN end_char="6846" id="token-55-20" morph="none" pos="word" start_char="6845">to</TOKEN>
<TOKEN end_char="6854" id="token-55-21" morph="none" pos="word" start_char="6848">prevent</TOKEN>
<TOKEN end_char="6865" id="token-55-22" morph="none" pos="word" start_char="6856">commercial</TOKEN>
<TOKEN end_char="6871" id="token-55-23" morph="none" pos="word" start_char="6867">firms</TOKEN>
<TOKEN end_char="6876" id="token-55-24" morph="none" pos="word" start_char="6873">from</TOKEN>
<TOKEN end_char="6889" id="token-55-25" morph="none" pos="word" start_char="6878">monopolizing</TOKEN>
<TOKEN end_char="6896" id="token-55-26" morph="none" pos="word" start_char="6891">public</TOKEN>
<TOKEN end_char="6903" id="token-55-27" morph="none" pos="word" start_char="6898">health</TOKEN>
<TOKEN end_char="6914" id="token-55-28" morph="none" pos="word" start_char="6905">technology</TOKEN>
<TOKEN end_char="6915" id="token-55-29" morph="none" pos="punct" start_char="6915">.</TOKEN>
</SEG>
<SEG end_char="7044" id="segment-56" start_char="6917">
<ORIGINAL_TEXT>Martin also claims the patent was itself illegal, a claim that has also been disputed by patent attorneys and professors of law.</ORIGINAL_TEXT>
<TOKEN end_char="6922" id="token-56-0" morph="none" pos="word" start_char="6917">Martin</TOKEN>
<TOKEN end_char="6927" id="token-56-1" morph="none" pos="word" start_char="6924">also</TOKEN>
<TOKEN end_char="6934" id="token-56-2" morph="none" pos="word" start_char="6929">claims</TOKEN>
<TOKEN end_char="6938" id="token-56-3" morph="none" pos="word" start_char="6936">the</TOKEN>
<TOKEN end_char="6945" id="token-56-4" morph="none" pos="word" start_char="6940">patent</TOKEN>
<TOKEN end_char="6949" id="token-56-5" morph="none" pos="word" start_char="6947">was</TOKEN>
<TOKEN end_char="6956" id="token-56-6" morph="none" pos="word" start_char="6951">itself</TOKEN>
<TOKEN end_char="6964" id="token-56-7" morph="none" pos="word" start_char="6958">illegal</TOKEN>
<TOKEN end_char="6965" id="token-56-8" morph="none" pos="punct" start_char="6965">,</TOKEN>
<TOKEN end_char="6967" id="token-56-9" morph="none" pos="word" start_char="6967">a</TOKEN>
<TOKEN end_char="6973" id="token-56-10" morph="none" pos="word" start_char="6969">claim</TOKEN>
<TOKEN end_char="6978" id="token-56-11" morph="none" pos="word" start_char="6975">that</TOKEN>
<TOKEN end_char="6982" id="token-56-12" morph="none" pos="word" start_char="6980">has</TOKEN>
<TOKEN end_char="6987" id="token-56-13" morph="none" pos="word" start_char="6984">also</TOKEN>
<TOKEN end_char="6992" id="token-56-14" morph="none" pos="word" start_char="6989">been</TOKEN>
<TOKEN end_char="7001" id="token-56-15" morph="none" pos="word" start_char="6994">disputed</TOKEN>
<TOKEN end_char="7004" id="token-56-16" morph="none" pos="word" start_char="7003">by</TOKEN>
<TOKEN end_char="7011" id="token-56-17" morph="none" pos="word" start_char="7006">patent</TOKEN>
<TOKEN end_char="7021" id="token-56-18" morph="none" pos="word" start_char="7013">attorneys</TOKEN>
<TOKEN end_char="7025" id="token-56-19" morph="none" pos="word" start_char="7023">and</TOKEN>
<TOKEN end_char="7036" id="token-56-20" morph="none" pos="word" start_char="7027">professors</TOKEN>
<TOKEN end_char="7039" id="token-56-21" morph="none" pos="word" start_char="7038">of</TOKEN>
<TOKEN end_char="7043" id="token-56-22" morph="none" pos="word" start_char="7041">law</TOKEN>
<TOKEN end_char="7044" id="token-56-23" morph="none" pos="punct" start_char="7044">.</TOKEN>
</SEG>
<SEG end_char="7086" id="segment-57" start_char="7046">
<ORIGINAL_TEXT>In Association for Molecular Pathology v.</ORIGINAL_TEXT>
<TOKEN end_char="7047" id="token-57-0" morph="none" pos="word" start_char="7046">In</TOKEN>
<TOKEN end_char="7059" id="token-57-1" morph="none" pos="word" start_char="7049">Association</TOKEN>
<TOKEN end_char="7063" id="token-57-2" morph="none" pos="word" start_char="7061">for</TOKEN>
<TOKEN end_char="7073" id="token-57-3" morph="none" pos="word" start_char="7065">Molecular</TOKEN>
<TOKEN end_char="7083" id="token-57-4" morph="none" pos="word" start_char="7075">Pathology</TOKEN>
<TOKEN end_char="7085" id="token-57-5" morph="none" pos="word" start_char="7085">v</TOKEN>
<TOKEN end_char="7086" id="token-57-6" morph="none" pos="punct" start_char="7086">.</TOKEN>
</SEG>
<SEG end_char="7275" id="segment-58" start_char="7088">
<ORIGINAL_TEXT>Myriad Genetics, the court ruled that isolated strands of DNA code could not be patented, which Martin claims is proof of CDC illegality in patenting its SARS testing methods and findings.</ORIGINAL_TEXT>
<TOKEN end_char="7093" id="token-58-0" morph="none" pos="word" start_char="7088">Myriad</TOKEN>
<TOKEN end_char="7102" id="token-58-1" morph="none" pos="word" start_char="7095">Genetics</TOKEN>
<TOKEN end_char="7103" id="token-58-2" morph="none" pos="punct" start_char="7103">,</TOKEN>
<TOKEN end_char="7107" id="token-58-3" morph="none" pos="word" start_char="7105">the</TOKEN>
<TOKEN end_char="7113" id="token-58-4" morph="none" pos="word" start_char="7109">court</TOKEN>
<TOKEN end_char="7119" id="token-58-5" morph="none" pos="word" start_char="7115">ruled</TOKEN>
<TOKEN end_char="7124" id="token-58-6" morph="none" pos="word" start_char="7121">that</TOKEN>
<TOKEN end_char="7133" id="token-58-7" morph="none" pos="word" start_char="7126">isolated</TOKEN>
<TOKEN end_char="7141" id="token-58-8" morph="none" pos="word" start_char="7135">strands</TOKEN>
<TOKEN end_char="7144" id="token-58-9" morph="none" pos="word" start_char="7143">of</TOKEN>
<TOKEN end_char="7148" id="token-58-10" morph="none" pos="word" start_char="7146">DNA</TOKEN>
<TOKEN end_char="7153" id="token-58-11" morph="none" pos="word" start_char="7150">code</TOKEN>
<TOKEN end_char="7159" id="token-58-12" morph="none" pos="word" start_char="7155">could</TOKEN>
<TOKEN end_char="7163" id="token-58-13" morph="none" pos="word" start_char="7161">not</TOKEN>
<TOKEN end_char="7166" id="token-58-14" morph="none" pos="word" start_char="7165">be</TOKEN>
<TOKEN end_char="7175" id="token-58-15" morph="none" pos="word" start_char="7168">patented</TOKEN>
<TOKEN end_char="7176" id="token-58-16" morph="none" pos="punct" start_char="7176">,</TOKEN>
<TOKEN end_char="7182" id="token-58-17" morph="none" pos="word" start_char="7178">which</TOKEN>
<TOKEN end_char="7189" id="token-58-18" morph="none" pos="word" start_char="7184">Martin</TOKEN>
<TOKEN end_char="7196" id="token-58-19" morph="none" pos="word" start_char="7191">claims</TOKEN>
<TOKEN end_char="7199" id="token-58-20" morph="none" pos="word" start_char="7198">is</TOKEN>
<TOKEN end_char="7205" id="token-58-21" morph="none" pos="word" start_char="7201">proof</TOKEN>
<TOKEN end_char="7208" id="token-58-22" morph="none" pos="word" start_char="7207">of</TOKEN>
<TOKEN end_char="7212" id="token-58-23" morph="none" pos="word" start_char="7210">CDC</TOKEN>
<TOKEN end_char="7223" id="token-58-24" morph="none" pos="word" start_char="7214">illegality</TOKEN>
<TOKEN end_char="7226" id="token-58-25" morph="none" pos="word" start_char="7225">in</TOKEN>
<TOKEN end_char="7236" id="token-58-26" morph="none" pos="word" start_char="7228">patenting</TOKEN>
<TOKEN end_char="7240" id="token-58-27" morph="none" pos="word" start_char="7238">its</TOKEN>
<TOKEN end_char="7245" id="token-58-28" morph="none" pos="word" start_char="7242">SARS</TOKEN>
<TOKEN end_char="7253" id="token-58-29" morph="none" pos="word" start_char="7247">testing</TOKEN>
<TOKEN end_char="7261" id="token-58-30" morph="none" pos="word" start_char="7255">methods</TOKEN>
<TOKEN end_char="7265" id="token-58-31" morph="none" pos="word" start_char="7263">and</TOKEN>
<TOKEN end_char="7274" id="token-58-32" morph="none" pos="word" start_char="7267">findings</TOKEN>
<TOKEN end_char="7275" id="token-58-33" morph="none" pos="punct" start_char="7275">.</TOKEN>
</SEG>
<SEG end_char="7362" id="segment-59" start_char="7278">
<ORIGINAL_TEXT>(Source: Lead Stories Screenshot from paused Facebook video Wed Sep 9 17:17 2020 UTC)</ORIGINAL_TEXT>
<TOKEN end_char="7278" id="token-59-0" morph="none" pos="punct" start_char="7278">(</TOKEN>
<TOKEN end_char="7284" id="token-59-1" morph="none" pos="word" start_char="7279">Source</TOKEN>
<TOKEN end_char="7285" id="token-59-2" morph="none" pos="punct" start_char="7285">:</TOKEN>
<TOKEN end_char="7290" id="token-59-3" morph="none" pos="word" start_char="7287">Lead</TOKEN>
<TOKEN end_char="7298" id="token-59-4" morph="none" pos="word" start_char="7292">Stories</TOKEN>
<TOKEN end_char="7309" id="token-59-5" morph="none" pos="word" start_char="7300">Screenshot</TOKEN>
<TOKEN end_char="7314" id="token-59-6" morph="none" pos="word" start_char="7311">from</TOKEN>
<TOKEN end_char="7321" id="token-59-7" morph="none" pos="word" start_char="7316">paused</TOKEN>
<TOKEN end_char="7330" id="token-59-8" morph="none" pos="word" start_char="7323">Facebook</TOKEN>
<TOKEN end_char="7336" id="token-59-9" morph="none" pos="word" start_char="7332">video</TOKEN>
<TOKEN end_char="7340" id="token-59-10" morph="none" pos="word" start_char="7338">Wed</TOKEN>
<TOKEN end_char="7344" id="token-59-11" morph="none" pos="word" start_char="7342">Sep</TOKEN>
<TOKEN end_char="7346" id="token-59-12" morph="none" pos="word" start_char="7346">9</TOKEN>
<TOKEN end_char="7352" id="token-59-13" morph="none" pos="unknown" start_char="7348">17:17</TOKEN>
<TOKEN end_char="7357" id="token-59-14" morph="none" pos="word" start_char="7354">2020</TOKEN>
<TOKEN end_char="7361" id="token-59-15" morph="none" pos="word" start_char="7359">UTC</TOKEN>
<TOKEN end_char="7362" id="token-59-16" morph="none" pos="punct" start_char="7362">)</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
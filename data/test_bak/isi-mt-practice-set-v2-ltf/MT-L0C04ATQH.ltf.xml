<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATQH" lang="spa" raw_text_char_length="2996" raw_text_md5="947591fe3f85f90f217a0ed54923a480" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="81" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Frank Cuesta, sobre el origen del coronavirus: "En agosto ya estaba pasando algo"</ORIGINAL_TEXT>
<TOKEN end_char="5" id="token-0-0" morph="none" pos="word" start_char="1">Frank</TOKEN>
<TOKEN end_char="12" id="token-0-1" morph="none" pos="word" start_char="7">Cuesta</TOKEN>
<TOKEN end_char="13" id="token-0-2" morph="none" pos="punct" start_char="13">,</TOKEN>
<TOKEN end_char="19" id="token-0-3" morph="none" pos="word" start_char="15">sobre</TOKEN>
<TOKEN end_char="22" id="token-0-4" morph="none" pos="word" start_char="21">el</TOKEN>
<TOKEN end_char="29" id="token-0-5" morph="none" pos="word" start_char="24">origen</TOKEN>
<TOKEN end_char="33" id="token-0-6" morph="none" pos="word" start_char="31">del</TOKEN>
<TOKEN end_char="45" id="token-0-7" morph="none" pos="word" start_char="35">coronavirus</TOKEN>
<TOKEN end_char="46" id="token-0-8" morph="none" pos="punct" start_char="46">:</TOKEN>
<TOKEN end_char="48" id="token-0-9" morph="none" pos="punct" start_char="48">"</TOKEN>
<TOKEN end_char="50" id="token-0-10" morph="none" pos="word" start_char="49">En</TOKEN>
<TOKEN end_char="57" id="token-0-11" morph="none" pos="word" start_char="52">agosto</TOKEN>
<TOKEN end_char="60" id="token-0-12" morph="none" pos="word" start_char="59">ya</TOKEN>
<TOKEN end_char="67" id="token-0-13" morph="none" pos="word" start_char="62">estaba</TOKEN>
<TOKEN end_char="75" id="token-0-14" morph="none" pos="word" start_char="69">pasando</TOKEN>
<TOKEN end_char="80" id="token-0-15" morph="none" pos="word" start_char="77">algo</TOKEN>
<TOKEN end_char="81" id="token-0-16" morph="none" pos="punct" start_char="81">"</TOKEN>
<TRANSLATED_TEXT>Frank Cuesta, on the origin of coronavirus: "In August something was already going on."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="115" id="segment-1" start_char="86">
<ORIGINAL_TEXT>Frank Cuesta acudió de nuevo a</ORIGINAL_TEXT>
<TOKEN end_char="90" id="token-1-0" morph="none" pos="word" start_char="86">Frank</TOKEN>
<TOKEN end_char="97" id="token-1-1" morph="none" pos="word" start_char="92">Cuesta</TOKEN>
<TOKEN end_char="104" id="token-1-2" morph="none" pos="word" start_char="99">acudió</TOKEN>
<TOKEN end_char="107" id="token-1-3" morph="none" pos="word" start_char="106">de</TOKEN>
<TOKEN end_char="113" id="token-1-4" morph="none" pos="word" start_char="109">nuevo</TOKEN>
<TOKEN end_char="115" id="token-1-5" morph="none" pos="word" start_char="115">a</TOKEN>
<TRANSLATED_TEXT>Frank Cuesta came back to</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="141" id="segment-2" start_char="118">
<ORIGINAL_TEXT>Es la mañana de Federico</ORIGINAL_TEXT>
<TOKEN end_char="119" id="token-2-0" morph="none" pos="word" start_char="118">Es</TOKEN>
<TOKEN end_char="122" id="token-2-1" morph="none" pos="word" start_char="121">la</TOKEN>
<TOKEN end_char="129" id="token-2-2" morph="none" pos="word" start_char="124">mañana</TOKEN>
<TOKEN end_char="132" id="token-2-3" morph="none" pos="word" start_char="131">de</TOKEN>
<TOKEN end_char="141" id="token-2-4" morph="none" pos="word" start_char="134">Federico</TOKEN>
<TRANSLATED_TEXT>It's Federico's morning</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="217" id="segment-3" start_char="144">
<ORIGINAL_TEXT>, en esRadio, para anunciar el estreno inminente de las nuevas entregas de</ORIGINAL_TEXT>
<TOKEN end_char="144" id="token-3-0" morph="none" pos="punct" start_char="144">,</TOKEN>
<TOKEN end_char="147" id="token-3-1" morph="none" pos="word" start_char="146">en</TOKEN>
<TOKEN end_char="155" id="token-3-2" morph="none" pos="word" start_char="149">esRadio</TOKEN>
<TOKEN end_char="156" id="token-3-3" morph="none" pos="punct" start_char="156">,</TOKEN>
<TOKEN end_char="161" id="token-3-4" morph="none" pos="word" start_char="158">para</TOKEN>
<TOKEN end_char="170" id="token-3-5" morph="none" pos="word" start_char="163">anunciar</TOKEN>
<TOKEN end_char="173" id="token-3-6" morph="none" pos="word" start_char="172">el</TOKEN>
<TOKEN end_char="181" id="token-3-7" morph="none" pos="word" start_char="175">estreno</TOKEN>
<TOKEN end_char="191" id="token-3-8" morph="none" pos="word" start_char="183">inminente</TOKEN>
<TOKEN end_char="194" id="token-3-9" morph="none" pos="word" start_char="193">de</TOKEN>
<TOKEN end_char="198" id="token-3-10" morph="none" pos="word" start_char="196">las</TOKEN>
<TOKEN end_char="205" id="token-3-11" morph="none" pos="word" start_char="200">nuevas</TOKEN>
<TOKEN end_char="214" id="token-3-12" morph="none" pos="word" start_char="207">entregas</TOKEN>
<TOKEN end_char="217" id="token-3-13" morph="none" pos="word" start_char="216">de</TOKEN>
<TRANSLATED_TEXT>, on esRadio, to announce the imminent premiere of new</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="229" id="segment-4" start_char="220">
<ORIGINAL_TEXT>Wild Frank</ORIGINAL_TEXT>
<TOKEN end_char="223" id="token-4-0" morph="none" pos="word" start_char="220">Wild</TOKEN>
<TOKEN end_char="229" id="token-4-1" morph="none" pos="word" start_char="225">Frank</TOKEN>
</SEG>
<SEG end_char="310" id="segment-5" start_char="232">
<ORIGINAL_TEXT>, su programa documental en Dmax, este domingo a las nueve y media de la noche.</ORIGINAL_TEXT>
<TOKEN end_char="232" id="token-5-0" morph="none" pos="punct" start_char="232">,</TOKEN>
<TOKEN end_char="235" id="token-5-1" morph="none" pos="word" start_char="234">su</TOKEN>
<TOKEN end_char="244" id="token-5-2" morph="none" pos="word" start_char="237">programa</TOKEN>
<TOKEN end_char="255" id="token-5-3" morph="none" pos="word" start_char="246">documental</TOKEN>
<TOKEN end_char="258" id="token-5-4" morph="none" pos="word" start_char="257">en</TOKEN>
<TOKEN end_char="263" id="token-5-5" morph="none" pos="word" start_char="260">Dmax</TOKEN>
<TOKEN end_char="264" id="token-5-6" morph="none" pos="punct" start_char="264">,</TOKEN>
<TOKEN end_char="269" id="token-5-7" morph="none" pos="word" start_char="266">este</TOKEN>
<TOKEN end_char="277" id="token-5-8" morph="none" pos="word" start_char="271">domingo</TOKEN>
<TOKEN end_char="279" id="token-5-9" morph="none" pos="word" start_char="279">a</TOKEN>
<TOKEN end_char="283" id="token-5-10" morph="none" pos="word" start_char="281">las</TOKEN>
<TOKEN end_char="289" id="token-5-11" morph="none" pos="word" start_char="285">nueve</TOKEN>
<TOKEN end_char="291" id="token-5-12" morph="none" pos="word" start_char="291">y</TOKEN>
<TOKEN end_char="297" id="token-5-13" morph="none" pos="word" start_char="293">media</TOKEN>
<TOKEN end_char="300" id="token-5-14" morph="none" pos="word" start_char="299">de</TOKEN>
<TOKEN end_char="303" id="token-5-15" morph="none" pos="word" start_char="302">la</TOKEN>
<TOKEN end_char="309" id="token-5-16" morph="none" pos="word" start_char="305">noche</TOKEN>
<TOKEN end_char="310" id="token-5-17" morph="none" pos="punct" start_char="310">.</TOKEN>
<TRANSLATED_TEXT>, his documentary program on Dmax, this Sunday at 9: 30 p.m.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="462" id="segment-6" start_char="312">
<ORIGINAL_TEXT>Frank conversó con Federico Jiménez Losantos e Isabel González de los más diversos temas, entre ellos la gran influencia de los míticos documentales de</ORIGINAL_TEXT>
<TOKEN end_char="316" id="token-6-0" morph="none" pos="word" start_char="312">Frank</TOKEN>
<TOKEN end_char="325" id="token-6-1" morph="none" pos="word" start_char="318">conversó</TOKEN>
<TOKEN end_char="329" id="token-6-2" morph="none" pos="word" start_char="327">con</TOKEN>
<TOKEN end_char="338" id="token-6-3" morph="none" pos="word" start_char="331">Federico</TOKEN>
<TOKEN end_char="346" id="token-6-4" morph="none" pos="word" start_char="340">Jiménez</TOKEN>
<TOKEN end_char="355" id="token-6-5" morph="none" pos="word" start_char="348">Losantos</TOKEN>
<TOKEN end_char="357" id="token-6-6" morph="none" pos="word" start_char="357">e</TOKEN>
<TOKEN end_char="364" id="token-6-7" morph="none" pos="word" start_char="359">Isabel</TOKEN>
<TOKEN end_char="373" id="token-6-8" morph="none" pos="word" start_char="366">González</TOKEN>
<TOKEN end_char="376" id="token-6-9" morph="none" pos="word" start_char="375">de</TOKEN>
<TOKEN end_char="380" id="token-6-10" morph="none" pos="word" start_char="378">los</TOKEN>
<TOKEN end_char="384" id="token-6-11" morph="none" pos="word" start_char="382">más</TOKEN>
<TOKEN end_char="393" id="token-6-12" morph="none" pos="word" start_char="386">diversos</TOKEN>
<TOKEN end_char="399" id="token-6-13" morph="none" pos="word" start_char="395">temas</TOKEN>
<TOKEN end_char="400" id="token-6-14" morph="none" pos="punct" start_char="400">,</TOKEN>
<TOKEN end_char="406" id="token-6-15" morph="none" pos="word" start_char="402">entre</TOKEN>
<TOKEN end_char="412" id="token-6-16" morph="none" pos="word" start_char="408">ellos</TOKEN>
<TOKEN end_char="415" id="token-6-17" morph="none" pos="word" start_char="414">la</TOKEN>
<TOKEN end_char="420" id="token-6-18" morph="none" pos="word" start_char="417">gran</TOKEN>
<TOKEN end_char="431" id="token-6-19" morph="none" pos="word" start_char="422">influencia</TOKEN>
<TOKEN end_char="434" id="token-6-20" morph="none" pos="word" start_char="433">de</TOKEN>
<TOKEN end_char="438" id="token-6-21" morph="none" pos="word" start_char="436">los</TOKEN>
<TOKEN end_char="446" id="token-6-22" morph="none" pos="word" start_char="440">míticos</TOKEN>
<TOKEN end_char="459" id="token-6-23" morph="none" pos="word" start_char="448">documentales</TOKEN>
<TOKEN end_char="462" id="token-6-24" morph="none" pos="word" start_char="461">de</TOKEN>
<TRANSLATED_TEXT>Frank spoke with Federico Jiménez Losantos and Isabel González on the most diverse topics, including the great influence of the mythical documentaries of</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="485" id="segment-7" start_char="465">
<ORIGINAL_TEXT>El Hombre y la Tierra</ORIGINAL_TEXT>
<TOKEN end_char="466" id="token-7-0" morph="none" pos="word" start_char="465">El</TOKEN>
<TOKEN end_char="473" id="token-7-1" morph="none" pos="word" start_char="468">Hombre</TOKEN>
<TOKEN end_char="475" id="token-7-2" morph="none" pos="word" start_char="475">y</TOKEN>
<TOKEN end_char="478" id="token-7-3" morph="none" pos="word" start_char="477">la</TOKEN>
<TOKEN end_char="485" id="token-7-4" morph="none" pos="word" start_char="480">Tierra</TOKEN>
<TRANSLATED_TEXT>Man and the Earth</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="519" id="segment-8" start_char="488">
<ORIGINAL_TEXT>de Félix Rodríguez de la Fuente.</ORIGINAL_TEXT>
<TOKEN end_char="489" id="token-8-0" morph="none" pos="word" start_char="488">de</TOKEN>
<TOKEN end_char="495" id="token-8-1" morph="none" pos="word" start_char="491">Félix</TOKEN>
<TOKEN end_char="505" id="token-8-2" morph="none" pos="word" start_char="497">Rodríguez</TOKEN>
<TOKEN end_char="508" id="token-8-3" morph="none" pos="word" start_char="507">de</TOKEN>
<TOKEN end_char="511" id="token-8-4" morph="none" pos="word" start_char="510">la</TOKEN>
<TOKEN end_char="518" id="token-8-5" morph="none" pos="word" start_char="513">Fuente</TOKEN>
<TOKEN end_char="519" id="token-8-6" morph="none" pos="punct" start_char="519">.</TOKEN>
<TRANSLATED_TEXT>by Felix Rodriguez de la Fuente.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="563" id="segment-9" start_char="521">
<ORIGINAL_TEXT>De hecho, las nuevas entregas se subtitulan</ORIGINAL_TEXT>
<TOKEN end_char="522" id="token-9-0" morph="none" pos="word" start_char="521">De</TOKEN>
<TOKEN end_char="528" id="token-9-1" morph="none" pos="word" start_char="524">hecho</TOKEN>
<TOKEN end_char="529" id="token-9-2" morph="none" pos="punct" start_char="529">,</TOKEN>
<TOKEN end_char="533" id="token-9-3" morph="none" pos="word" start_char="531">las</TOKEN>
<TOKEN end_char="540" id="token-9-4" morph="none" pos="word" start_char="535">nuevas</TOKEN>
<TOKEN end_char="549" id="token-9-5" morph="none" pos="word" start_char="542">entregas</TOKEN>
<TOKEN end_char="552" id="token-9-6" morph="none" pos="word" start_char="551">se</TOKEN>
<TOKEN end_char="563" id="token-9-7" morph="none" pos="word" start_char="554">subtitulan</TOKEN>
<TRANSLATED_TEXT>In fact, new deliveries are being subtitled</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="584" id="segment-10" start_char="566">
<ORIGINAL_TEXT>El Legado de Félix.</ORIGINAL_TEXT>
<TOKEN end_char="567" id="token-10-0" morph="none" pos="word" start_char="566">El</TOKEN>
<TOKEN end_char="574" id="token-10-1" morph="none" pos="word" start_char="569">Legado</TOKEN>
<TOKEN end_char="577" id="token-10-2" morph="none" pos="word" start_char="576">de</TOKEN>
<TOKEN end_char="583" id="token-10-3" morph="none" pos="word" start_char="579">Félix</TOKEN>
<TOKEN end_char="584" id="token-10-4" morph="none" pos="punct" start_char="584">.</TOKEN>
<TRANSLATED_TEXT>Felix's Legacy.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="685" id="segment-11" start_char="588">
<ORIGINAL_TEXT>Pero además de eso, Frank Cuesta abordó el pánico por la actual epidemia de coronavirus en España.</ORIGINAL_TEXT>
<TOKEN end_char="591" id="token-11-0" morph="none" pos="word" start_char="588">Pero</TOKEN>
<TOKEN end_char="598" id="token-11-1" morph="none" pos="word" start_char="593">además</TOKEN>
<TOKEN end_char="601" id="token-11-2" morph="none" pos="word" start_char="600">de</TOKEN>
<TOKEN end_char="605" id="token-11-3" morph="none" pos="word" start_char="603">eso</TOKEN>
<TOKEN end_char="606" id="token-11-4" morph="none" pos="punct" start_char="606">,</TOKEN>
<TOKEN end_char="612" id="token-11-5" morph="none" pos="word" start_char="608">Frank</TOKEN>
<TOKEN end_char="619" id="token-11-6" morph="none" pos="word" start_char="614">Cuesta</TOKEN>
<TOKEN end_char="626" id="token-11-7" morph="none" pos="word" start_char="621">abordó</TOKEN>
<TOKEN end_char="629" id="token-11-8" morph="none" pos="word" start_char="628">el</TOKEN>
<TOKEN end_char="636" id="token-11-9" morph="none" pos="word" start_char="631">pánico</TOKEN>
<TOKEN end_char="640" id="token-11-10" morph="none" pos="word" start_char="638">por</TOKEN>
<TOKEN end_char="643" id="token-11-11" morph="none" pos="word" start_char="642">la</TOKEN>
<TOKEN end_char="650" id="token-11-12" morph="none" pos="word" start_char="645">actual</TOKEN>
<TOKEN end_char="659" id="token-11-13" morph="none" pos="word" start_char="652">epidemia</TOKEN>
<TOKEN end_char="662" id="token-11-14" morph="none" pos="word" start_char="661">de</TOKEN>
<TOKEN end_char="674" id="token-11-15" morph="none" pos="word" start_char="664">coronavirus</TOKEN>
<TOKEN end_char="677" id="token-11-16" morph="none" pos="word" start_char="676">en</TOKEN>
<TOKEN end_char="684" id="token-11-17" morph="none" pos="word" start_char="679">España</TOKEN>
<TOKEN end_char="685" id="token-11-18" morph="none" pos="punct" start_char="685">.</TOKEN>
<TRANSLATED_TEXT>But in addition to that, Frank Cuesta addressed the panic over the current coronavirus epidemic in Spain.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="833" id="segment-12" start_char="687">
<ORIGINAL_TEXT>Y asegura, de hecho, haber presenciado sus inicios en Tailandia hace ya unos meses, en pleno 2019, y que lleva campando sin control desde entonces.</ORIGINAL_TEXT>
<TOKEN end_char="687" id="token-12-0" morph="none" pos="word" start_char="687">Y</TOKEN>
<TOKEN end_char="695" id="token-12-1" morph="none" pos="word" start_char="689">asegura</TOKEN>
<TOKEN end_char="696" id="token-12-2" morph="none" pos="punct" start_char="696">,</TOKEN>
<TOKEN end_char="699" id="token-12-3" morph="none" pos="word" start_char="698">de</TOKEN>
<TOKEN end_char="705" id="token-12-4" morph="none" pos="word" start_char="701">hecho</TOKEN>
<TOKEN end_char="706" id="token-12-5" morph="none" pos="punct" start_char="706">,</TOKEN>
<TOKEN end_char="712" id="token-12-6" morph="none" pos="word" start_char="708">haber</TOKEN>
<TOKEN end_char="724" id="token-12-7" morph="none" pos="word" start_char="714">presenciado</TOKEN>
<TOKEN end_char="728" id="token-12-8" morph="none" pos="word" start_char="726">sus</TOKEN>
<TOKEN end_char="736" id="token-12-9" morph="none" pos="word" start_char="730">inicios</TOKEN>
<TOKEN end_char="739" id="token-12-10" morph="none" pos="word" start_char="738">en</TOKEN>
<TOKEN end_char="749" id="token-12-11" morph="none" pos="word" start_char="741">Tailandia</TOKEN>
<TOKEN end_char="754" id="token-12-12" morph="none" pos="word" start_char="751">hace</TOKEN>
<TOKEN end_char="757" id="token-12-13" morph="none" pos="word" start_char="756">ya</TOKEN>
<TOKEN end_char="762" id="token-12-14" morph="none" pos="word" start_char="759">unos</TOKEN>
<TOKEN end_char="768" id="token-12-15" morph="none" pos="word" start_char="764">meses</TOKEN>
<TOKEN end_char="769" id="token-12-16" morph="none" pos="punct" start_char="769">,</TOKEN>
<TOKEN end_char="772" id="token-12-17" morph="none" pos="word" start_char="771">en</TOKEN>
<TOKEN end_char="778" id="token-12-18" morph="none" pos="word" start_char="774">pleno</TOKEN>
<TOKEN end_char="783" id="token-12-19" morph="none" pos="word" start_char="780">2019</TOKEN>
<TOKEN end_char="784" id="token-12-20" morph="none" pos="punct" start_char="784">,</TOKEN>
<TOKEN end_char="786" id="token-12-21" morph="none" pos="word" start_char="786">y</TOKEN>
<TOKEN end_char="790" id="token-12-22" morph="none" pos="word" start_char="788">que</TOKEN>
<TOKEN end_char="796" id="token-12-23" morph="none" pos="word" start_char="792">lleva</TOKEN>
<TOKEN end_char="805" id="token-12-24" morph="none" pos="word" start_char="798">campando</TOKEN>
<TOKEN end_char="809" id="token-12-25" morph="none" pos="word" start_char="807">sin</TOKEN>
<TOKEN end_char="817" id="token-12-26" morph="none" pos="word" start_char="811">control</TOKEN>
<TOKEN end_char="823" id="token-12-27" morph="none" pos="word" start_char="819">desde</TOKEN>
<TOKEN end_char="832" id="token-12-28" morph="none" pos="word" start_char="825">entonces</TOKEN>
<TOKEN end_char="833" id="token-12-29" morph="none" pos="punct" start_char="833">.</TOKEN>
<TRANSLATED_TEXT>And it claims, in fact, to have witnessed its beginnings in Thailand a few months ago, in the middle of 2019, and that it has been ringing unchecked ever since.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="881" id="segment-13" start_char="836">
<ORIGINAL_TEXT>"Esto puede ser por el pangolín por una razón.</ORIGINAL_TEXT>
<TOKEN end_char="836" id="token-13-0" morph="none" pos="punct" start_char="836">"</TOKEN>
<TOKEN end_char="840" id="token-13-1" morph="none" pos="word" start_char="837">Esto</TOKEN>
<TOKEN end_char="846" id="token-13-2" morph="none" pos="word" start_char="842">puede</TOKEN>
<TOKEN end_char="850" id="token-13-3" morph="none" pos="word" start_char="848">ser</TOKEN>
<TOKEN end_char="854" id="token-13-4" morph="none" pos="word" start_char="852">por</TOKEN>
<TOKEN end_char="857" id="token-13-5" morph="none" pos="word" start_char="856">el</TOKEN>
<TOKEN end_char="866" id="token-13-6" morph="none" pos="word" start_char="859">pangolín</TOKEN>
<TOKEN end_char="870" id="token-13-7" morph="none" pos="word" start_char="868">por</TOKEN>
<TOKEN end_char="874" id="token-13-8" morph="none" pos="word" start_char="872">una</TOKEN>
<TOKEN end_char="880" id="token-13-9" morph="none" pos="word" start_char="876">razón</TOKEN>
<TOKEN end_char="881" id="token-13-10" morph="none" pos="punct" start_char="881">.</TOKEN>
<TRANSLATED_TEXT>This can be for pangolin for a reason.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1085" id="segment-14" start_char="883">
<ORIGINAL_TEXT>Nosotros sabemos que se pillan una media de cincuenta a cien pangolines todas las semanas que salen a Vietnam o China", dijo a raíz de su habitual actividad luchando contra el tráfico ilegal de animales.</ORIGINAL_TEXT>
<TOKEN end_char="890" id="token-14-0" morph="none" pos="word" start_char="883">Nosotros</TOKEN>
<TOKEN end_char="898" id="token-14-1" morph="none" pos="word" start_char="892">sabemos</TOKEN>
<TOKEN end_char="902" id="token-14-2" morph="none" pos="word" start_char="900">que</TOKEN>
<TOKEN end_char="905" id="token-14-3" morph="none" pos="word" start_char="904">se</TOKEN>
<TOKEN end_char="912" id="token-14-4" morph="none" pos="word" start_char="907">pillan</TOKEN>
<TOKEN end_char="916" id="token-14-5" morph="none" pos="word" start_char="914">una</TOKEN>
<TOKEN end_char="922" id="token-14-6" morph="none" pos="word" start_char="918">media</TOKEN>
<TOKEN end_char="925" id="token-14-7" morph="none" pos="word" start_char="924">de</TOKEN>
<TOKEN end_char="935" id="token-14-8" morph="none" pos="word" start_char="927">cincuenta</TOKEN>
<TOKEN end_char="937" id="token-14-9" morph="none" pos="word" start_char="937">a</TOKEN>
<TOKEN end_char="942" id="token-14-10" morph="none" pos="word" start_char="939">cien</TOKEN>
<TOKEN end_char="953" id="token-14-11" morph="none" pos="word" start_char="944">pangolines</TOKEN>
<TOKEN end_char="959" id="token-14-12" morph="none" pos="word" start_char="955">todas</TOKEN>
<TOKEN end_char="963" id="token-14-13" morph="none" pos="word" start_char="961">las</TOKEN>
<TOKEN end_char="971" id="token-14-14" morph="none" pos="word" start_char="965">semanas</TOKEN>
<TOKEN end_char="975" id="token-14-15" morph="none" pos="word" start_char="973">que</TOKEN>
<TOKEN end_char="981" id="token-14-16" morph="none" pos="word" start_char="977">salen</TOKEN>
<TOKEN end_char="983" id="token-14-17" morph="none" pos="word" start_char="983">a</TOKEN>
<TOKEN end_char="991" id="token-14-18" morph="none" pos="word" start_char="985">Vietnam</TOKEN>
<TOKEN end_char="993" id="token-14-19" morph="none" pos="word" start_char="993">o</TOKEN>
<TOKEN end_char="999" id="token-14-20" morph="none" pos="word" start_char="995">China</TOKEN>
<TOKEN end_char="1001" id="token-14-21" morph="none" pos="punct" start_char="1000">",</TOKEN>
<TOKEN end_char="1006" id="token-14-22" morph="none" pos="word" start_char="1003">dijo</TOKEN>
<TOKEN end_char="1008" id="token-14-23" morph="none" pos="word" start_char="1008">a</TOKEN>
<TOKEN end_char="1013" id="token-14-24" morph="none" pos="word" start_char="1010">raíz</TOKEN>
<TOKEN end_char="1016" id="token-14-25" morph="none" pos="word" start_char="1015">de</TOKEN>
<TOKEN end_char="1019" id="token-14-26" morph="none" pos="word" start_char="1018">su</TOKEN>
<TOKEN end_char="1028" id="token-14-27" morph="none" pos="word" start_char="1021">habitual</TOKEN>
<TOKEN end_char="1038" id="token-14-28" morph="none" pos="word" start_char="1030">actividad</TOKEN>
<TOKEN end_char="1047" id="token-14-29" morph="none" pos="word" start_char="1040">luchando</TOKEN>
<TOKEN end_char="1054" id="token-14-30" morph="none" pos="word" start_char="1049">contra</TOKEN>
<TOKEN end_char="1057" id="token-14-31" morph="none" pos="word" start_char="1056">el</TOKEN>
<TOKEN end_char="1065" id="token-14-32" morph="none" pos="word" start_char="1059">tráfico</TOKEN>
<TOKEN end_char="1072" id="token-14-33" morph="none" pos="word" start_char="1067">ilegal</TOKEN>
<TOKEN end_char="1075" id="token-14-34" morph="none" pos="word" start_char="1074">de</TOKEN>
<TOKEN end_char="1084" id="token-14-35" morph="none" pos="word" start_char="1077">animales</TOKEN>
<TOKEN end_char="1085" id="token-14-36" morph="none" pos="punct" start_char="1085">.</TOKEN>
<TRANSLATED_TEXT>We know that an average of fifty to one hundred pangolins are caught every week that they leave for Vietnam or China, "he said as a result of his usual activity fighting illegal animal trafficking.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1172" id="segment-15" start_char="1087">
<ORIGINAL_TEXT>"La segunda semana de agosto se dejó de pillar, y también de murciélago y de musaraña.</ORIGINAL_TEXT>
<TOKEN end_char="1087" id="token-15-0" morph="none" pos="punct" start_char="1087">"</TOKEN>
<TOKEN end_char="1089" id="token-15-1" morph="none" pos="word" start_char="1088">La</TOKEN>
<TOKEN end_char="1097" id="token-15-2" morph="none" pos="word" start_char="1091">segunda</TOKEN>
<TOKEN end_char="1104" id="token-15-3" morph="none" pos="word" start_char="1099">semana</TOKEN>
<TOKEN end_char="1107" id="token-15-4" morph="none" pos="word" start_char="1106">de</TOKEN>
<TOKEN end_char="1114" id="token-15-5" morph="none" pos="word" start_char="1109">agosto</TOKEN>
<TOKEN end_char="1117" id="token-15-6" morph="none" pos="word" start_char="1116">se</TOKEN>
<TOKEN end_char="1122" id="token-15-7" morph="none" pos="word" start_char="1119">dejó</TOKEN>
<TOKEN end_char="1125" id="token-15-8" morph="none" pos="word" start_char="1124">de</TOKEN>
<TOKEN end_char="1132" id="token-15-9" morph="none" pos="word" start_char="1127">pillar</TOKEN>
<TOKEN end_char="1133" id="token-15-10" morph="none" pos="punct" start_char="1133">,</TOKEN>
<TOKEN end_char="1135" id="token-15-11" morph="none" pos="word" start_char="1135">y</TOKEN>
<TOKEN end_char="1143" id="token-15-12" morph="none" pos="word" start_char="1137">también</TOKEN>
<TOKEN end_char="1146" id="token-15-13" morph="none" pos="word" start_char="1145">de</TOKEN>
<TOKEN end_char="1157" id="token-15-14" morph="none" pos="word" start_char="1148">murciélago</TOKEN>
<TOKEN end_char="1159" id="token-15-15" morph="none" pos="word" start_char="1159">y</TOKEN>
<TOKEN end_char="1162" id="token-15-16" morph="none" pos="word" start_char="1161">de</TOKEN>
<TOKEN end_char="1171" id="token-15-17" morph="none" pos="word" start_char="1164">musaraña</TOKEN>
<TOKEN end_char="1172" id="token-15-18" morph="none" pos="punct" start_char="1172">.</TOKEN>
<TRANSLATED_TEXT>The second week of August was over from pillar, and also from bat and shrew.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1221" id="segment-16" start_char="1174">
<ORIGINAL_TEXT>No hemos encontrado ni un cargamento, cosa rara.</ORIGINAL_TEXT>
<TOKEN end_char="1175" id="token-16-0" morph="none" pos="word" start_char="1174">No</TOKEN>
<TOKEN end_char="1181" id="token-16-1" morph="none" pos="word" start_char="1177">hemos</TOKEN>
<TOKEN end_char="1192" id="token-16-2" morph="none" pos="word" start_char="1183">encontrado</TOKEN>
<TOKEN end_char="1195" id="token-16-3" morph="none" pos="word" start_char="1194">ni</TOKEN>
<TOKEN end_char="1198" id="token-16-4" morph="none" pos="word" start_char="1197">un</TOKEN>
<TOKEN end_char="1209" id="token-16-5" morph="none" pos="word" start_char="1200">cargamento</TOKEN>
<TOKEN end_char="1210" id="token-16-6" morph="none" pos="punct" start_char="1210">,</TOKEN>
<TOKEN end_char="1215" id="token-16-7" morph="none" pos="word" start_char="1212">cosa</TOKEN>
<TOKEN end_char="1220" id="token-16-8" morph="none" pos="word" start_char="1217">rara</TOKEN>
<TOKEN end_char="1221" id="token-16-9" morph="none" pos="punct" start_char="1221">.</TOKEN>
<TRANSLATED_TEXT>We haven't found a shipment, which is rare.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1321" id="segment-17" start_char="1223">
<ORIGINAL_TEXT>Te estoy hablando del mes de agosto", dijo sobre los primeras pistas de que algo estaba ocurriendo.</ORIGINAL_TEXT>
<TOKEN end_char="1224" id="token-17-0" morph="none" pos="word" start_char="1223">Te</TOKEN>
<TOKEN end_char="1230" id="token-17-1" morph="none" pos="word" start_char="1226">estoy</TOKEN>
<TOKEN end_char="1239" id="token-17-2" morph="none" pos="word" start_char="1232">hablando</TOKEN>
<TOKEN end_char="1243" id="token-17-3" morph="none" pos="word" start_char="1241">del</TOKEN>
<TOKEN end_char="1247" id="token-17-4" morph="none" pos="word" start_char="1245">mes</TOKEN>
<TOKEN end_char="1250" id="token-17-5" morph="none" pos="word" start_char="1249">de</TOKEN>
<TOKEN end_char="1257" id="token-17-6" morph="none" pos="word" start_char="1252">agosto</TOKEN>
<TOKEN end_char="1259" id="token-17-7" morph="none" pos="punct" start_char="1258">",</TOKEN>
<TOKEN end_char="1264" id="token-17-8" morph="none" pos="word" start_char="1261">dijo</TOKEN>
<TOKEN end_char="1270" id="token-17-9" morph="none" pos="word" start_char="1266">sobre</TOKEN>
<TOKEN end_char="1274" id="token-17-10" morph="none" pos="word" start_char="1272">los</TOKEN>
<TOKEN end_char="1283" id="token-17-11" morph="none" pos="word" start_char="1276">primeras</TOKEN>
<TOKEN end_char="1290" id="token-17-12" morph="none" pos="word" start_char="1285">pistas</TOKEN>
<TOKEN end_char="1293" id="token-17-13" morph="none" pos="word" start_char="1292">de</TOKEN>
<TOKEN end_char="1297" id="token-17-14" morph="none" pos="word" start_char="1295">que</TOKEN>
<TOKEN end_char="1302" id="token-17-15" morph="none" pos="word" start_char="1299">algo</TOKEN>
<TOKEN end_char="1309" id="token-17-16" morph="none" pos="word" start_char="1304">estaba</TOKEN>
<TOKEN end_char="1320" id="token-17-17" morph="none" pos="word" start_char="1311">ocurriendo</TOKEN>
<TOKEN end_char="1321" id="token-17-18" morph="none" pos="punct" start_char="1321">.</TOKEN>
<TRANSLATED_TEXT>I'm talking to you about August, "he said about the first clues that something was happening.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1452" id="segment-18" start_char="1323">
<ORIGINAL_TEXT>Frank se preguntó en esRadio "¿cómo puedes coger cien pangolines a la semana y salir de las mismas zonas y luego dejar de hacerlo?</ORIGINAL_TEXT>
<TOKEN end_char="1327" id="token-18-0" morph="none" pos="word" start_char="1323">Frank</TOKEN>
<TOKEN end_char="1330" id="token-18-1" morph="none" pos="word" start_char="1329">se</TOKEN>
<TOKEN end_char="1339" id="token-18-2" morph="none" pos="word" start_char="1332">preguntó</TOKEN>
<TOKEN end_char="1342" id="token-18-3" morph="none" pos="word" start_char="1341">en</TOKEN>
<TOKEN end_char="1350" id="token-18-4" morph="none" pos="word" start_char="1344">esRadio</TOKEN>
<TOKEN end_char="1353" id="token-18-5" morph="none" pos="punct" start_char="1352">"¿</TOKEN>
<TOKEN end_char="1357" id="token-18-6" morph="none" pos="word" start_char="1354">cómo</TOKEN>
<TOKEN end_char="1364" id="token-18-7" morph="none" pos="word" start_char="1359">puedes</TOKEN>
<TOKEN end_char="1370" id="token-18-8" morph="none" pos="word" start_char="1366">coger</TOKEN>
<TOKEN end_char="1375" id="token-18-9" morph="none" pos="word" start_char="1372">cien</TOKEN>
<TOKEN end_char="1386" id="token-18-10" morph="none" pos="word" start_char="1377">pangolines</TOKEN>
<TOKEN end_char="1388" id="token-18-11" morph="none" pos="word" start_char="1388">a</TOKEN>
<TOKEN end_char="1391" id="token-18-12" morph="none" pos="word" start_char="1390">la</TOKEN>
<TOKEN end_char="1398" id="token-18-13" morph="none" pos="word" start_char="1393">semana</TOKEN>
<TOKEN end_char="1400" id="token-18-14" morph="none" pos="word" start_char="1400">y</TOKEN>
<TOKEN end_char="1406" id="token-18-15" morph="none" pos="word" start_char="1402">salir</TOKEN>
<TOKEN end_char="1409" id="token-18-16" morph="none" pos="word" start_char="1408">de</TOKEN>
<TOKEN end_char="1413" id="token-18-17" morph="none" pos="word" start_char="1411">las</TOKEN>
<TOKEN end_char="1420" id="token-18-18" morph="none" pos="word" start_char="1415">mismas</TOKEN>
<TOKEN end_char="1426" id="token-18-19" morph="none" pos="word" start_char="1422">zonas</TOKEN>
<TOKEN end_char="1428" id="token-18-20" morph="none" pos="word" start_char="1428">y</TOKEN>
<TOKEN end_char="1434" id="token-18-21" morph="none" pos="word" start_char="1430">luego</TOKEN>
<TOKEN end_char="1440" id="token-18-22" morph="none" pos="word" start_char="1436">dejar</TOKEN>
<TOKEN end_char="1443" id="token-18-23" morph="none" pos="word" start_char="1442">de</TOKEN>
<TOKEN end_char="1451" id="token-18-24" morph="none" pos="word" start_char="1445">hacerlo</TOKEN>
<TOKEN end_char="1452" id="token-18-25" morph="none" pos="punct" start_char="1452">?</TOKEN>
<TRANSLATED_TEXT>Frank asked on esRadio "How can you pick up a hundred pangolins a week and get out of the same areas and then stop doing it??.?....</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1455" id="segment-19" start_char="1454">
<ORIGINAL_TEXT>".</ORIGINAL_TEXT>
<TOKEN end_char="1455" id="token-19-0" morph="none" pos="punct" start_char="1454">".</TOKEN>
</SEG>
<SEG end_char="1649" id="segment-20" start_char="1458">
<ORIGINAL_TEXT>De modo que, según Frank Cuesta, "en agosto ya pasaba algo ahí"… pero China no anunció el coronavirus hasta mucho, mucho después, sugiriendo que allí sí se detectó pero no se advirtió a nadie.</ORIGINAL_TEXT>
<TOKEN end_char="1459" id="token-20-0" morph="none" pos="word" start_char="1458">De</TOKEN>
<TOKEN end_char="1464" id="token-20-1" morph="none" pos="word" start_char="1461">modo</TOKEN>
<TOKEN end_char="1468" id="token-20-2" morph="none" pos="word" start_char="1466">que</TOKEN>
<TOKEN end_char="1469" id="token-20-3" morph="none" pos="punct" start_char="1469">,</TOKEN>
<TOKEN end_char="1475" id="token-20-4" morph="none" pos="word" start_char="1471">según</TOKEN>
<TOKEN end_char="1481" id="token-20-5" morph="none" pos="word" start_char="1477">Frank</TOKEN>
<TOKEN end_char="1488" id="token-20-6" morph="none" pos="word" start_char="1483">Cuesta</TOKEN>
<TOKEN end_char="1489" id="token-20-7" morph="none" pos="punct" start_char="1489">,</TOKEN>
<TOKEN end_char="1491" id="token-20-8" morph="none" pos="punct" start_char="1491">"</TOKEN>
<TOKEN end_char="1493" id="token-20-9" morph="none" pos="word" start_char="1492">en</TOKEN>
<TOKEN end_char="1500" id="token-20-10" morph="none" pos="word" start_char="1495">agosto</TOKEN>
<TOKEN end_char="1503" id="token-20-11" morph="none" pos="word" start_char="1502">ya</TOKEN>
<TOKEN end_char="1510" id="token-20-12" morph="none" pos="word" start_char="1505">pasaba</TOKEN>
<TOKEN end_char="1515" id="token-20-13" morph="none" pos="word" start_char="1512">algo</TOKEN>
<TOKEN end_char="1519" id="token-20-14" morph="none" pos="word" start_char="1517">ahí</TOKEN>
<TOKEN end_char="1521" id="token-20-15" morph="none" pos="punct" start_char="1520">"…</TOKEN>
<TOKEN end_char="1526" id="token-20-16" morph="none" pos="word" start_char="1523">pero</TOKEN>
<TOKEN end_char="1532" id="token-20-17" morph="none" pos="word" start_char="1528">China</TOKEN>
<TOKEN end_char="1535" id="token-20-18" morph="none" pos="word" start_char="1534">no</TOKEN>
<TOKEN end_char="1543" id="token-20-19" morph="none" pos="word" start_char="1537">anunció</TOKEN>
<TOKEN end_char="1546" id="token-20-20" morph="none" pos="word" start_char="1545">el</TOKEN>
<TOKEN end_char="1558" id="token-20-21" morph="none" pos="word" start_char="1548">coronavirus</TOKEN>
<TOKEN end_char="1564" id="token-20-22" morph="none" pos="word" start_char="1560">hasta</TOKEN>
<TOKEN end_char="1570" id="token-20-23" morph="none" pos="word" start_char="1566">mucho</TOKEN>
<TOKEN end_char="1571" id="token-20-24" morph="none" pos="punct" start_char="1571">,</TOKEN>
<TOKEN end_char="1577" id="token-20-25" morph="none" pos="word" start_char="1573">mucho</TOKEN>
<TOKEN end_char="1585" id="token-20-26" morph="none" pos="word" start_char="1579">después</TOKEN>
<TOKEN end_char="1586" id="token-20-27" morph="none" pos="punct" start_char="1586">,</TOKEN>
<TOKEN end_char="1597" id="token-20-28" morph="none" pos="word" start_char="1588">sugiriendo</TOKEN>
<TOKEN end_char="1601" id="token-20-29" morph="none" pos="word" start_char="1599">que</TOKEN>
<TOKEN end_char="1606" id="token-20-30" morph="none" pos="word" start_char="1603">allí</TOKEN>
<TOKEN end_char="1609" id="token-20-31" morph="none" pos="word" start_char="1608">sí</TOKEN>
<TOKEN end_char="1612" id="token-20-32" morph="none" pos="word" start_char="1611">se</TOKEN>
<TOKEN end_char="1620" id="token-20-33" morph="none" pos="word" start_char="1614">detectó</TOKEN>
<TOKEN end_char="1625" id="token-20-34" morph="none" pos="word" start_char="1622">pero</TOKEN>
<TOKEN end_char="1628" id="token-20-35" morph="none" pos="word" start_char="1627">no</TOKEN>
<TOKEN end_char="1631" id="token-20-36" morph="none" pos="word" start_char="1630">se</TOKEN>
<TOKEN end_char="1640" id="token-20-37" morph="none" pos="word" start_char="1633">advirtió</TOKEN>
<TOKEN end_char="1642" id="token-20-38" morph="none" pos="word" start_char="1642">a</TOKEN>
<TOKEN end_char="1648" id="token-20-39" morph="none" pos="word" start_char="1644">nadie</TOKEN>
<TOKEN end_char="1649" id="token-20-40" morph="none" pos="punct" start_char="1649">.</TOKEN>
<TRANSLATED_TEXT>So, according to Frank Cuesta, "by August something was going on there..." but China did not announce the coronavirus until much, much later, suggesting that it was detected there but no one was warned.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1791" id="segment-21" start_char="1651">
<ORIGINAL_TEXT>Tal y como apuntó Federico Jiménez Losantos, "hubo un médico que sí lo denunció y lo metieron en la cárcel, y después lo sacaron para morir".</ORIGINAL_TEXT>
<TOKEN end_char="1653" id="token-21-0" morph="none" pos="word" start_char="1651">Tal</TOKEN>
<TOKEN end_char="1655" id="token-21-1" morph="none" pos="word" start_char="1655">y</TOKEN>
<TOKEN end_char="1660" id="token-21-2" morph="none" pos="word" start_char="1657">como</TOKEN>
<TOKEN end_char="1667" id="token-21-3" morph="none" pos="word" start_char="1662">apuntó</TOKEN>
<TOKEN end_char="1676" id="token-21-4" morph="none" pos="word" start_char="1669">Federico</TOKEN>
<TOKEN end_char="1684" id="token-21-5" morph="none" pos="word" start_char="1678">Jiménez</TOKEN>
<TOKEN end_char="1693" id="token-21-6" morph="none" pos="word" start_char="1686">Losantos</TOKEN>
<TOKEN end_char="1694" id="token-21-7" morph="none" pos="punct" start_char="1694">,</TOKEN>
<TOKEN end_char="1696" id="token-21-8" morph="none" pos="punct" start_char="1696">"</TOKEN>
<TOKEN end_char="1700" id="token-21-9" morph="none" pos="word" start_char="1697">hubo</TOKEN>
<TOKEN end_char="1703" id="token-21-10" morph="none" pos="word" start_char="1702">un</TOKEN>
<TOKEN end_char="1710" id="token-21-11" morph="none" pos="word" start_char="1705">médico</TOKEN>
<TOKEN end_char="1714" id="token-21-12" morph="none" pos="word" start_char="1712">que</TOKEN>
<TOKEN end_char="1717" id="token-21-13" morph="none" pos="word" start_char="1716">sí</TOKEN>
<TOKEN end_char="1720" id="token-21-14" morph="none" pos="word" start_char="1719">lo</TOKEN>
<TOKEN end_char="1729" id="token-21-15" morph="none" pos="word" start_char="1722">denunció</TOKEN>
<TOKEN end_char="1731" id="token-21-16" morph="none" pos="word" start_char="1731">y</TOKEN>
<TOKEN end_char="1734" id="token-21-17" morph="none" pos="word" start_char="1733">lo</TOKEN>
<TOKEN end_char="1743" id="token-21-18" morph="none" pos="word" start_char="1736">metieron</TOKEN>
<TOKEN end_char="1746" id="token-21-19" morph="none" pos="word" start_char="1745">en</TOKEN>
<TOKEN end_char="1749" id="token-21-20" morph="none" pos="word" start_char="1748">la</TOKEN>
<TOKEN end_char="1756" id="token-21-21" morph="none" pos="word" start_char="1751">cárcel</TOKEN>
<TOKEN end_char="1757" id="token-21-22" morph="none" pos="punct" start_char="1757">,</TOKEN>
<TOKEN end_char="1759" id="token-21-23" morph="none" pos="word" start_char="1759">y</TOKEN>
<TOKEN end_char="1767" id="token-21-24" morph="none" pos="word" start_char="1761">después</TOKEN>
<TOKEN end_char="1770" id="token-21-25" morph="none" pos="word" start_char="1769">lo</TOKEN>
<TOKEN end_char="1778" id="token-21-26" morph="none" pos="word" start_char="1772">sacaron</TOKEN>
<TOKEN end_char="1783" id="token-21-27" morph="none" pos="word" start_char="1780">para</TOKEN>
<TOKEN end_char="1789" id="token-21-28" morph="none" pos="word" start_char="1785">morir</TOKEN>
<TOKEN end_char="1791" id="token-21-29" morph="none" pos="punct" start_char="1790">".</TOKEN>
<TRANSLATED_TEXT>As Federico Jiménez Losantos pointed out, "there was a doctor who did denounce him and put him in jail, and then took him out to die."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1922" id="segment-22" start_char="1794">
<ORIGINAL_TEXT>El problema es que tanto el murciélago como la musaraña o el propio pangolín se usan también "como antes los monos, como cobayas.</ORIGINAL_TEXT>
<TOKEN end_char="1795" id="token-22-0" morph="none" pos="word" start_char="1794">El</TOKEN>
<TOKEN end_char="1804" id="token-22-1" morph="none" pos="word" start_char="1797">problema</TOKEN>
<TOKEN end_char="1807" id="token-22-2" morph="none" pos="word" start_char="1806">es</TOKEN>
<TOKEN end_char="1811" id="token-22-3" morph="none" pos="word" start_char="1809">que</TOKEN>
<TOKEN end_char="1817" id="token-22-4" morph="none" pos="word" start_char="1813">tanto</TOKEN>
<TOKEN end_char="1820" id="token-22-5" morph="none" pos="word" start_char="1819">el</TOKEN>
<TOKEN end_char="1831" id="token-22-6" morph="none" pos="word" start_char="1822">murciélago</TOKEN>
<TOKEN end_char="1836" id="token-22-7" morph="none" pos="word" start_char="1833">como</TOKEN>
<TOKEN end_char="1839" id="token-22-8" morph="none" pos="word" start_char="1838">la</TOKEN>
<TOKEN end_char="1848" id="token-22-9" morph="none" pos="word" start_char="1841">musaraña</TOKEN>
<TOKEN end_char="1850" id="token-22-10" morph="none" pos="word" start_char="1850">o</TOKEN>
<TOKEN end_char="1853" id="token-22-11" morph="none" pos="word" start_char="1852">el</TOKEN>
<TOKEN end_char="1860" id="token-22-12" morph="none" pos="word" start_char="1855">propio</TOKEN>
<TOKEN end_char="1869" id="token-22-13" morph="none" pos="word" start_char="1862">pangolín</TOKEN>
<TOKEN end_char="1872" id="token-22-14" morph="none" pos="word" start_char="1871">se</TOKEN>
<TOKEN end_char="1877" id="token-22-15" morph="none" pos="word" start_char="1874">usan</TOKEN>
<TOKEN end_char="1885" id="token-22-16" morph="none" pos="word" start_char="1879">también</TOKEN>
<TOKEN end_char="1887" id="token-22-17" morph="none" pos="punct" start_char="1887">"</TOKEN>
<TOKEN end_char="1891" id="token-22-18" morph="none" pos="word" start_char="1888">como</TOKEN>
<TOKEN end_char="1897" id="token-22-19" morph="none" pos="word" start_char="1893">antes</TOKEN>
<TOKEN end_char="1901" id="token-22-20" morph="none" pos="word" start_char="1899">los</TOKEN>
<TOKEN end_char="1907" id="token-22-21" morph="none" pos="word" start_char="1903">monos</TOKEN>
<TOKEN end_char="1908" id="token-22-22" morph="none" pos="punct" start_char="1908">,</TOKEN>
<TOKEN end_char="1913" id="token-22-23" morph="none" pos="word" start_char="1910">como</TOKEN>
<TOKEN end_char="1921" id="token-22-24" morph="none" pos="word" start_char="1915">cobayas</TOKEN>
<TOKEN end_char="1922" id="token-22-25" morph="none" pos="punct" start_char="1922">.</TOKEN>
<TRANSLATED_TEXT>The problem is that both the bat and the shrew or the pangolin itself are also used "as before monkeys, as guinea pigs.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1942" id="segment-23" start_char="1924">
<ORIGINAL_TEXT>Para experimentar".</ORIGINAL_TEXT>
<TOKEN end_char="1927" id="token-23-0" morph="none" pos="word" start_char="1924">Para</TOKEN>
<TOKEN end_char="1940" id="token-23-1" morph="none" pos="word" start_char="1929">experimentar</TOKEN>
<TOKEN end_char="1942" id="token-23-2" morph="none" pos="punct" start_char="1941">".</TOKEN>
<TRANSLATED_TEXT>To experiment. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="2141" id="segment-24" start_char="1944">
<ORIGINAL_TEXT>Y el hecho de que ese animal se usa para todo literalmente: "Del pangolín se usan hasta las escamas para ponerselas en las heridas… Y que se lo comen casi crudo, lo meten unos segundos en agua y ya.</ORIGINAL_TEXT>
<TOKEN end_char="1944" id="token-24-0" morph="none" pos="word" start_char="1944">Y</TOKEN>
<TOKEN end_char="1947" id="token-24-1" morph="none" pos="word" start_char="1946">el</TOKEN>
<TOKEN end_char="1953" id="token-24-2" morph="none" pos="word" start_char="1949">hecho</TOKEN>
<TOKEN end_char="1956" id="token-24-3" morph="none" pos="word" start_char="1955">de</TOKEN>
<TOKEN end_char="1960" id="token-24-4" morph="none" pos="word" start_char="1958">que</TOKEN>
<TOKEN end_char="1964" id="token-24-5" morph="none" pos="word" start_char="1962">ese</TOKEN>
<TOKEN end_char="1971" id="token-24-6" morph="none" pos="word" start_char="1966">animal</TOKEN>
<TOKEN end_char="1974" id="token-24-7" morph="none" pos="word" start_char="1973">se</TOKEN>
<TOKEN end_char="1978" id="token-24-8" morph="none" pos="word" start_char="1976">usa</TOKEN>
<TOKEN end_char="1983" id="token-24-9" morph="none" pos="word" start_char="1980">para</TOKEN>
<TOKEN end_char="1988" id="token-24-10" morph="none" pos="word" start_char="1985">todo</TOKEN>
<TOKEN end_char="2001" id="token-24-11" morph="none" pos="word" start_char="1990">literalmente</TOKEN>
<TOKEN end_char="2002" id="token-24-12" morph="none" pos="punct" start_char="2002">:</TOKEN>
<TOKEN end_char="2004" id="token-24-13" morph="none" pos="punct" start_char="2004">"</TOKEN>
<TOKEN end_char="2007" id="token-24-14" morph="none" pos="word" start_char="2005">Del</TOKEN>
<TOKEN end_char="2016" id="token-24-15" morph="none" pos="word" start_char="2009">pangolín</TOKEN>
<TOKEN end_char="2019" id="token-24-16" morph="none" pos="word" start_char="2018">se</TOKEN>
<TOKEN end_char="2024" id="token-24-17" morph="none" pos="word" start_char="2021">usan</TOKEN>
<TOKEN end_char="2030" id="token-24-18" morph="none" pos="word" start_char="2026">hasta</TOKEN>
<TOKEN end_char="2034" id="token-24-19" morph="none" pos="word" start_char="2032">las</TOKEN>
<TOKEN end_char="2042" id="token-24-20" morph="none" pos="word" start_char="2036">escamas</TOKEN>
<TOKEN end_char="2047" id="token-24-21" morph="none" pos="word" start_char="2044">para</TOKEN>
<TOKEN end_char="2058" id="token-24-22" morph="none" pos="word" start_char="2049">ponerselas</TOKEN>
<TOKEN end_char="2061" id="token-24-23" morph="none" pos="word" start_char="2060">en</TOKEN>
<TOKEN end_char="2065" id="token-24-24" morph="none" pos="word" start_char="2063">las</TOKEN>
<TOKEN end_char="2073" id="token-24-25" morph="none" pos="word" start_char="2067">heridas</TOKEN>
<TOKEN end_char="2074" id="token-24-26" morph="none" pos="punct" start_char="2074">…</TOKEN>
<TOKEN end_char="2076" id="token-24-27" morph="none" pos="word" start_char="2076">Y</TOKEN>
<TOKEN end_char="2080" id="token-24-28" morph="none" pos="word" start_char="2078">que</TOKEN>
<TOKEN end_char="2083" id="token-24-29" morph="none" pos="word" start_char="2082">se</TOKEN>
<TOKEN end_char="2086" id="token-24-30" morph="none" pos="word" start_char="2085">lo</TOKEN>
<TOKEN end_char="2092" id="token-24-31" morph="none" pos="word" start_char="2088">comen</TOKEN>
<TOKEN end_char="2097" id="token-24-32" morph="none" pos="word" start_char="2094">casi</TOKEN>
<TOKEN end_char="2103" id="token-24-33" morph="none" pos="word" start_char="2099">crudo</TOKEN>
<TOKEN end_char="2104" id="token-24-34" morph="none" pos="punct" start_char="2104">,</TOKEN>
<TOKEN end_char="2107" id="token-24-35" morph="none" pos="word" start_char="2106">lo</TOKEN>
<TOKEN end_char="2113" id="token-24-36" morph="none" pos="word" start_char="2109">meten</TOKEN>
<TOKEN end_char="2118" id="token-24-37" morph="none" pos="word" start_char="2115">unos</TOKEN>
<TOKEN end_char="2127" id="token-24-38" morph="none" pos="word" start_char="2120">segundos</TOKEN>
<TOKEN end_char="2130" id="token-24-39" morph="none" pos="word" start_char="2129">en</TOKEN>
<TOKEN end_char="2135" id="token-24-40" morph="none" pos="word" start_char="2132">agua</TOKEN>
<TOKEN end_char="2137" id="token-24-41" morph="none" pos="word" start_char="2137">y</TOKEN>
<TOKEN end_char="2140" id="token-24-42" morph="none" pos="word" start_char="2139">ya</TOKEN>
<TOKEN end_char="2141" id="token-24-43" morph="none" pos="punct" start_char="2141">.</TOKEN>
<TRANSLATED_TEXT>And the fact that that animal is used for everything literally: "Pangolin is used up to the scales to put them on wounds... and that they eat it almost raw, put it a few seconds in water and already.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2166" id="segment-25" start_char="2143">
<ORIGINAL_TEXT>Es una especie de sushi.</ORIGINAL_TEXT>
<TOKEN end_char="2144" id="token-25-0" morph="none" pos="word" start_char="2143">Es</TOKEN>
<TOKEN end_char="2148" id="token-25-1" morph="none" pos="word" start_char="2146">una</TOKEN>
<TOKEN end_char="2156" id="token-25-2" morph="none" pos="word" start_char="2150">especie</TOKEN>
<TOKEN end_char="2159" id="token-25-3" morph="none" pos="word" start_char="2158">de</TOKEN>
<TOKEN end_char="2165" id="token-25-4" morph="none" pos="word" start_char="2161">sushi</TOKEN>
<TOKEN end_char="2166" id="token-25-5" morph="none" pos="punct" start_char="2166">.</TOKEN>
<TRANSLATED_TEXT>It's kind of sushi.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2227" id="segment-26" start_char="2168">
<ORIGINAL_TEXT>Es el mamífero mas castigado del mundo, han acabado con él".</ORIGINAL_TEXT>
<TOKEN end_char="2169" id="token-26-0" morph="none" pos="word" start_char="2168">Es</TOKEN>
<TOKEN end_char="2172" id="token-26-1" morph="none" pos="word" start_char="2171">el</TOKEN>
<TOKEN end_char="2181" id="token-26-2" morph="none" pos="word" start_char="2174">mamífero</TOKEN>
<TOKEN end_char="2185" id="token-26-3" morph="none" pos="word" start_char="2183">mas</TOKEN>
<TOKEN end_char="2195" id="token-26-4" morph="none" pos="word" start_char="2187">castigado</TOKEN>
<TOKEN end_char="2199" id="token-26-5" morph="none" pos="word" start_char="2197">del</TOKEN>
<TOKEN end_char="2205" id="token-26-6" morph="none" pos="word" start_char="2201">mundo</TOKEN>
<TOKEN end_char="2206" id="token-26-7" morph="none" pos="punct" start_char="2206">,</TOKEN>
<TOKEN end_char="2210" id="token-26-8" morph="none" pos="word" start_char="2208">han</TOKEN>
<TOKEN end_char="2218" id="token-26-9" morph="none" pos="word" start_char="2212">acabado</TOKEN>
<TOKEN end_char="2222" id="token-26-10" morph="none" pos="word" start_char="2220">con</TOKEN>
<TOKEN end_char="2225" id="token-26-11" morph="none" pos="word" start_char="2224">él</TOKEN>
<TOKEN end_char="2227" id="token-26-12" morph="none" pos="punct" start_char="2226">".</TOKEN>
<TRANSLATED_TEXT>He's the most punished mammal in the world, they've finished him. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2258" id="segment-27" start_char="2229">
<ORIGINAL_TEXT>Frank de la Jungla denunció en</ORIGINAL_TEXT>
<TOKEN end_char="2233" id="token-27-0" morph="none" pos="word" start_char="2229">Frank</TOKEN>
<TOKEN end_char="2236" id="token-27-1" morph="none" pos="word" start_char="2235">de</TOKEN>
<TOKEN end_char="2239" id="token-27-2" morph="none" pos="word" start_char="2238">la</TOKEN>
<TOKEN end_char="2246" id="token-27-3" morph="none" pos="word" start_char="2241">Jungla</TOKEN>
<TOKEN end_char="2255" id="token-27-4" morph="none" pos="word" start_char="2248">denunció</TOKEN>
<TOKEN end_char="2258" id="token-27-5" morph="none" pos="word" start_char="2257">en</TOKEN>
<TRANSLATED_TEXT>Frank de la Jungla denounced it in</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2284" id="segment-28" start_char="2261">
<ORIGINAL_TEXT>Es la mañana de Federico</ORIGINAL_TEXT>
<TOKEN end_char="2262" id="token-28-0" morph="none" pos="word" start_char="2261">Es</TOKEN>
<TOKEN end_char="2265" id="token-28-1" morph="none" pos="word" start_char="2264">la</TOKEN>
<TOKEN end_char="2272" id="token-28-2" morph="none" pos="word" start_char="2267">mañana</TOKEN>
<TOKEN end_char="2275" id="token-28-3" morph="none" pos="word" start_char="2274">de</TOKEN>
<TOKEN end_char="2284" id="token-28-4" morph="none" pos="word" start_char="2277">Federico</TOKEN>
<TRANSLATED_TEXT>It's Federico's morning</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2384" id="segment-29" start_char="2287">
<ORIGINAL_TEXT>que "el problema no es el pangolín, es que se lo han comido y no han dicho lo que estaba pasando".</ORIGINAL_TEXT>
<TOKEN end_char="2289" id="token-29-0" morph="none" pos="word" start_char="2287">que</TOKEN>
<TOKEN end_char="2291" id="token-29-1" morph="none" pos="punct" start_char="2291">"</TOKEN>
<TOKEN end_char="2293" id="token-29-2" morph="none" pos="word" start_char="2292">el</TOKEN>
<TOKEN end_char="2302" id="token-29-3" morph="none" pos="word" start_char="2295">problema</TOKEN>
<TOKEN end_char="2305" id="token-29-4" morph="none" pos="word" start_char="2304">no</TOKEN>
<TOKEN end_char="2308" id="token-29-5" morph="none" pos="word" start_char="2307">es</TOKEN>
<TOKEN end_char="2311" id="token-29-6" morph="none" pos="word" start_char="2310">el</TOKEN>
<TOKEN end_char="2320" id="token-29-7" morph="none" pos="word" start_char="2313">pangolín</TOKEN>
<TOKEN end_char="2321" id="token-29-8" morph="none" pos="punct" start_char="2321">,</TOKEN>
<TOKEN end_char="2324" id="token-29-9" morph="none" pos="word" start_char="2323">es</TOKEN>
<TOKEN end_char="2328" id="token-29-10" morph="none" pos="word" start_char="2326">que</TOKEN>
<TOKEN end_char="2331" id="token-29-11" morph="none" pos="word" start_char="2330">se</TOKEN>
<TOKEN end_char="2334" id="token-29-12" morph="none" pos="word" start_char="2333">lo</TOKEN>
<TOKEN end_char="2338" id="token-29-13" morph="none" pos="word" start_char="2336">han</TOKEN>
<TOKEN end_char="2345" id="token-29-14" morph="none" pos="word" start_char="2340">comido</TOKEN>
<TOKEN end_char="2347" id="token-29-15" morph="none" pos="word" start_char="2347">y</TOKEN>
<TOKEN end_char="2350" id="token-29-16" morph="none" pos="word" start_char="2349">no</TOKEN>
<TOKEN end_char="2354" id="token-29-17" morph="none" pos="word" start_char="2352">han</TOKEN>
<TOKEN end_char="2360" id="token-29-18" morph="none" pos="word" start_char="2356">dicho</TOKEN>
<TOKEN end_char="2363" id="token-29-19" morph="none" pos="word" start_char="2362">lo</TOKEN>
<TOKEN end_char="2367" id="token-29-20" morph="none" pos="word" start_char="2365">que</TOKEN>
<TOKEN end_char="2374" id="token-29-21" morph="none" pos="word" start_char="2369">estaba</TOKEN>
<TOKEN end_char="2382" id="token-29-22" morph="none" pos="word" start_char="2376">pasando</TOKEN>
<TOKEN end_char="2384" id="token-29-23" morph="none" pos="punct" start_char="2383">".</TOKEN>
<TRANSLATED_TEXT>that "the problem is not the pangolin, it is that they ate it and did not say what was going on."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2637" id="segment-30" start_char="2387">
<ORIGINAL_TEXT>El asunto lleva tantos meses cociéndose que Frank cree que allí, en Tailandia, en realidad casi todo el mundo ya lo ha pasado en los meses de agosto, septiembre u octubre de 2019, apuntando a que la epidemia lleva en realidad varios meses sin control.</ORIGINAL_TEXT>
<TOKEN end_char="2388" id="token-30-0" morph="none" pos="word" start_char="2387">El</TOKEN>
<TOKEN end_char="2395" id="token-30-1" morph="none" pos="word" start_char="2390">asunto</TOKEN>
<TOKEN end_char="2401" id="token-30-2" morph="none" pos="word" start_char="2397">lleva</TOKEN>
<TOKEN end_char="2408" id="token-30-3" morph="none" pos="word" start_char="2403">tantos</TOKEN>
<TOKEN end_char="2414" id="token-30-4" morph="none" pos="word" start_char="2410">meses</TOKEN>
<TOKEN end_char="2425" id="token-30-5" morph="none" pos="word" start_char="2416">cociéndose</TOKEN>
<TOKEN end_char="2429" id="token-30-6" morph="none" pos="word" start_char="2427">que</TOKEN>
<TOKEN end_char="2435" id="token-30-7" morph="none" pos="word" start_char="2431">Frank</TOKEN>
<TOKEN end_char="2440" id="token-30-8" morph="none" pos="word" start_char="2437">cree</TOKEN>
<TOKEN end_char="2444" id="token-30-9" morph="none" pos="word" start_char="2442">que</TOKEN>
<TOKEN end_char="2449" id="token-30-10" morph="none" pos="word" start_char="2446">allí</TOKEN>
<TOKEN end_char="2450" id="token-30-11" morph="none" pos="punct" start_char="2450">,</TOKEN>
<TOKEN end_char="2453" id="token-30-12" morph="none" pos="word" start_char="2452">en</TOKEN>
<TOKEN end_char="2463" id="token-30-13" morph="none" pos="word" start_char="2455">Tailandia</TOKEN>
<TOKEN end_char="2464" id="token-30-14" morph="none" pos="punct" start_char="2464">,</TOKEN>
<TOKEN end_char="2467" id="token-30-15" morph="none" pos="word" start_char="2466">en</TOKEN>
<TOKEN end_char="2476" id="token-30-16" morph="none" pos="word" start_char="2469">realidad</TOKEN>
<TOKEN end_char="2481" id="token-30-17" morph="none" pos="word" start_char="2478">casi</TOKEN>
<TOKEN end_char="2486" id="token-30-18" morph="none" pos="word" start_char="2483">todo</TOKEN>
<TOKEN end_char="2489" id="token-30-19" morph="none" pos="word" start_char="2488">el</TOKEN>
<TOKEN end_char="2495" id="token-30-20" morph="none" pos="word" start_char="2491">mundo</TOKEN>
<TOKEN end_char="2498" id="token-30-21" morph="none" pos="word" start_char="2497">ya</TOKEN>
<TOKEN end_char="2501" id="token-30-22" morph="none" pos="word" start_char="2500">lo</TOKEN>
<TOKEN end_char="2504" id="token-30-23" morph="none" pos="word" start_char="2503">ha</TOKEN>
<TOKEN end_char="2511" id="token-30-24" morph="none" pos="word" start_char="2506">pasado</TOKEN>
<TOKEN end_char="2514" id="token-30-25" morph="none" pos="word" start_char="2513">en</TOKEN>
<TOKEN end_char="2518" id="token-30-26" morph="none" pos="word" start_char="2516">los</TOKEN>
<TOKEN end_char="2524" id="token-30-27" morph="none" pos="word" start_char="2520">meses</TOKEN>
<TOKEN end_char="2527" id="token-30-28" morph="none" pos="word" start_char="2526">de</TOKEN>
<TOKEN end_char="2534" id="token-30-29" morph="none" pos="word" start_char="2529">agosto</TOKEN>
<TOKEN end_char="2535" id="token-30-30" morph="none" pos="punct" start_char="2535">,</TOKEN>
<TOKEN end_char="2546" id="token-30-31" morph="none" pos="word" start_char="2537">septiembre</TOKEN>
<TOKEN end_char="2548" id="token-30-32" morph="none" pos="word" start_char="2548">u</TOKEN>
<TOKEN end_char="2556" id="token-30-33" morph="none" pos="word" start_char="2550">octubre</TOKEN>
<TOKEN end_char="2559" id="token-30-34" morph="none" pos="word" start_char="2558">de</TOKEN>
<TOKEN end_char="2564" id="token-30-35" morph="none" pos="word" start_char="2561">2019</TOKEN>
<TOKEN end_char="2565" id="token-30-36" morph="none" pos="punct" start_char="2565">,</TOKEN>
<TOKEN end_char="2575" id="token-30-37" morph="none" pos="word" start_char="2567">apuntando</TOKEN>
<TOKEN end_char="2577" id="token-30-38" morph="none" pos="word" start_char="2577">a</TOKEN>
<TOKEN end_char="2581" id="token-30-39" morph="none" pos="word" start_char="2579">que</TOKEN>
<TOKEN end_char="2584" id="token-30-40" morph="none" pos="word" start_char="2583">la</TOKEN>
<TOKEN end_char="2593" id="token-30-41" morph="none" pos="word" start_char="2586">epidemia</TOKEN>
<TOKEN end_char="2599" id="token-30-42" morph="none" pos="word" start_char="2595">lleva</TOKEN>
<TOKEN end_char="2602" id="token-30-43" morph="none" pos="word" start_char="2601">en</TOKEN>
<TOKEN end_char="2611" id="token-30-44" morph="none" pos="word" start_char="2604">realidad</TOKEN>
<TOKEN end_char="2618" id="token-30-45" morph="none" pos="word" start_char="2613">varios</TOKEN>
<TOKEN end_char="2624" id="token-30-46" morph="none" pos="word" start_char="2620">meses</TOKEN>
<TOKEN end_char="2628" id="token-30-47" morph="none" pos="word" start_char="2626">sin</TOKEN>
<TOKEN end_char="2636" id="token-30-48" morph="none" pos="word" start_char="2630">control</TOKEN>
<TOKEN end_char="2637" id="token-30-49" morph="none" pos="punct" start_char="2637">.</TOKEN>
<TRANSLATED_TEXT>The issue has been burning for so many months that Frank believes that there, in Thailand, almost everyone has actually been there in August, September or October 2019, pointing out that the epidemic has actually been out of control for several months.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2725" id="segment-31" start_char="2639">
<ORIGINAL_TEXT>Lo podría haber pasado él mismo pero también su familia, que han estado enfermos todos.</ORIGINAL_TEXT>
<TOKEN end_char="2640" id="token-31-0" morph="none" pos="word" start_char="2639">Lo</TOKEN>
<TOKEN end_char="2647" id="token-31-1" morph="none" pos="word" start_char="2642">podría</TOKEN>
<TOKEN end_char="2653" id="token-31-2" morph="none" pos="word" start_char="2649">haber</TOKEN>
<TOKEN end_char="2660" id="token-31-3" morph="none" pos="word" start_char="2655">pasado</TOKEN>
<TOKEN end_char="2663" id="token-31-4" morph="none" pos="word" start_char="2662">él</TOKEN>
<TOKEN end_char="2669" id="token-31-5" morph="none" pos="word" start_char="2665">mismo</TOKEN>
<TOKEN end_char="2674" id="token-31-6" morph="none" pos="word" start_char="2671">pero</TOKEN>
<TOKEN end_char="2682" id="token-31-7" morph="none" pos="word" start_char="2676">también</TOKEN>
<TOKEN end_char="2685" id="token-31-8" morph="none" pos="word" start_char="2684">su</TOKEN>
<TOKEN end_char="2693" id="token-31-9" morph="none" pos="word" start_char="2687">familia</TOKEN>
<TOKEN end_char="2694" id="token-31-10" morph="none" pos="punct" start_char="2694">,</TOKEN>
<TOKEN end_char="2698" id="token-31-11" morph="none" pos="word" start_char="2696">que</TOKEN>
<TOKEN end_char="2702" id="token-31-12" morph="none" pos="word" start_char="2700">han</TOKEN>
<TOKEN end_char="2709" id="token-31-13" morph="none" pos="word" start_char="2704">estado</TOKEN>
<TOKEN end_char="2718" id="token-31-14" morph="none" pos="word" start_char="2711">enfermos</TOKEN>
<TOKEN end_char="2724" id="token-31-15" morph="none" pos="word" start_char="2720">todos</TOKEN>
<TOKEN end_char="2725" id="token-31-16" morph="none" pos="punct" start_char="2725">.</TOKEN>
<TRANSLATED_TEXT>It could have happened to him but also to his family, who have all been sick.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2779" id="segment-32" start_char="2727">
<ORIGINAL_TEXT>"En agosto, por allí, ya hemos pasado todos el virus.</ORIGINAL_TEXT>
<TOKEN end_char="2727" id="token-32-0" morph="none" pos="punct" start_char="2727">"</TOKEN>
<TOKEN end_char="2729" id="token-32-1" morph="none" pos="word" start_char="2728">En</TOKEN>
<TOKEN end_char="2736" id="token-32-2" morph="none" pos="word" start_char="2731">agosto</TOKEN>
<TOKEN end_char="2737" id="token-32-3" morph="none" pos="punct" start_char="2737">,</TOKEN>
<TOKEN end_char="2741" id="token-32-4" morph="none" pos="word" start_char="2739">por</TOKEN>
<TOKEN end_char="2746" id="token-32-5" morph="none" pos="word" start_char="2743">allí</TOKEN>
<TOKEN end_char="2747" id="token-32-6" morph="none" pos="punct" start_char="2747">,</TOKEN>
<TOKEN end_char="2750" id="token-32-7" morph="none" pos="word" start_char="2749">ya</TOKEN>
<TOKEN end_char="2756" id="token-32-8" morph="none" pos="word" start_char="2752">hemos</TOKEN>
<TOKEN end_char="2763" id="token-32-9" morph="none" pos="word" start_char="2758">pasado</TOKEN>
<TOKEN end_char="2769" id="token-32-10" morph="none" pos="word" start_char="2765">todos</TOKEN>
<TOKEN end_char="2772" id="token-32-11" morph="none" pos="word" start_char="2771">el</TOKEN>
<TOKEN end_char="2778" id="token-32-12" morph="none" pos="word" start_char="2774">virus</TOKEN>
<TOKEN end_char="2779" id="token-32-13" morph="none" pos="punct" start_char="2779">.</TOKEN>
<TRANSLATED_TEXT>In August, through there, we have all passed the virus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2801" id="segment-33" start_char="2781">
<ORIGINAL_TEXT>Hemos pasado catarro.</ORIGINAL_TEXT>
<TOKEN end_char="2785" id="token-33-0" morph="none" pos="word" start_char="2781">Hemos</TOKEN>
<TOKEN end_char="2792" id="token-33-1" morph="none" pos="word" start_char="2787">pasado</TOKEN>
<TOKEN end_char="2800" id="token-33-2" morph="none" pos="word" start_char="2794">catarro</TOKEN>
<TOKEN end_char="2801" id="token-33-3" morph="none" pos="punct" start_char="2801">.</TOKEN>
<TRANSLATED_TEXT>We've passed the cataract.</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="2827" id="segment-34" start_char="2803">
<ORIGINAL_TEXT>Lo cogimos en casa todos.</ORIGINAL_TEXT>
<TOKEN end_char="2804" id="token-34-0" morph="none" pos="word" start_char="2803">Lo</TOKEN>
<TOKEN end_char="2812" id="token-34-1" morph="none" pos="word" start_char="2806">cogimos</TOKEN>
<TOKEN end_char="2815" id="token-34-2" morph="none" pos="word" start_char="2814">en</TOKEN>
<TOKEN end_char="2820" id="token-34-3" morph="none" pos="word" start_char="2817">casa</TOKEN>
<TOKEN end_char="2826" id="token-34-4" morph="none" pos="word" start_char="2822">todos</TOKEN>
<TOKEN end_char="2827" id="token-34-5" morph="none" pos="punct" start_char="2827">.</TOKEN>
<TRANSLATED_TEXT>We all took it at home.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2956" id="segment-35" start_char="2829">
<ORIGINAL_TEXT>Y ahora, empiezas a dar marchas atrás y piensas qué ha estado pasando desde septiembre, octubre y nadie entonces se dio cuenta".</ORIGINAL_TEXT>
<TOKEN end_char="2829" id="token-35-0" morph="none" pos="word" start_char="2829">Y</TOKEN>
<TOKEN end_char="2835" id="token-35-1" morph="none" pos="word" start_char="2831">ahora</TOKEN>
<TOKEN end_char="2836" id="token-35-2" morph="none" pos="punct" start_char="2836">,</TOKEN>
<TOKEN end_char="2845" id="token-35-3" morph="none" pos="word" start_char="2838">empiezas</TOKEN>
<TOKEN end_char="2847" id="token-35-4" morph="none" pos="word" start_char="2847">a</TOKEN>
<TOKEN end_char="2851" id="token-35-5" morph="none" pos="word" start_char="2849">dar</TOKEN>
<TOKEN end_char="2859" id="token-35-6" morph="none" pos="word" start_char="2853">marchas</TOKEN>
<TOKEN end_char="2865" id="token-35-7" morph="none" pos="word" start_char="2861">atrás</TOKEN>
<TOKEN end_char="2867" id="token-35-8" morph="none" pos="word" start_char="2867">y</TOKEN>
<TOKEN end_char="2875" id="token-35-9" morph="none" pos="word" start_char="2869">piensas</TOKEN>
<TOKEN end_char="2879" id="token-35-10" morph="none" pos="word" start_char="2877">qué</TOKEN>
<TOKEN end_char="2882" id="token-35-11" morph="none" pos="word" start_char="2881">ha</TOKEN>
<TOKEN end_char="2889" id="token-35-12" morph="none" pos="word" start_char="2884">estado</TOKEN>
<TOKEN end_char="2897" id="token-35-13" morph="none" pos="word" start_char="2891">pasando</TOKEN>
<TOKEN end_char="2903" id="token-35-14" morph="none" pos="word" start_char="2899">desde</TOKEN>
<TOKEN end_char="2914" id="token-35-15" morph="none" pos="word" start_char="2905">septiembre</TOKEN>
<TOKEN end_char="2915" id="token-35-16" morph="none" pos="punct" start_char="2915">,</TOKEN>
<TOKEN end_char="2923" id="token-35-17" morph="none" pos="word" start_char="2917">octubre</TOKEN>
<TOKEN end_char="2925" id="token-35-18" morph="none" pos="word" start_char="2925">y</TOKEN>
<TOKEN end_char="2931" id="token-35-19" morph="none" pos="word" start_char="2927">nadie</TOKEN>
<TOKEN end_char="2940" id="token-35-20" morph="none" pos="word" start_char="2933">entonces</TOKEN>
<TOKEN end_char="2943" id="token-35-21" morph="none" pos="word" start_char="2942">se</TOKEN>
<TOKEN end_char="2947" id="token-35-22" morph="none" pos="word" start_char="2945">dio</TOKEN>
<TOKEN end_char="2954" id="token-35-23" morph="none" pos="word" start_char="2949">cuenta</TOKEN>
<TOKEN end_char="2956" id="token-35-24" morph="none" pos="punct" start_char="2955">".</TOKEN>
<TRANSLATED_TEXT>And now, you start walking back and thinking about what has been going on since September, October and nobody then realized. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2991" id="segment-36" start_char="2962">
<ORIGINAL_TEXT>Crónica Rosa: Con Frank Cuesta</ORIGINAL_TEXT>
<TOKEN end_char="2968" id="token-36-0" morph="none" pos="word" start_char="2962">Crónica</TOKEN>
<TOKEN end_char="2973" id="token-36-1" morph="none" pos="word" start_char="2970">Rosa</TOKEN>
<TOKEN end_char="2974" id="token-36-2" morph="none" pos="punct" start_char="2974">:</TOKEN>
<TOKEN end_char="2978" id="token-36-3" morph="none" pos="word" start_char="2976">Con</TOKEN>
<TOKEN end_char="2984" id="token-36-4" morph="none" pos="word" start_char="2980">Frank</TOKEN>
<TOKEN end_char="2991" id="token-36-5" morph="none" pos="word" start_char="2986">Cuesta</TOKEN>
<TRANSLATED_TEXT>The Rose Chronicle: With Frank Cuesta.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
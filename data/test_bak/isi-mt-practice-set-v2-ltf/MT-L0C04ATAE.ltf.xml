<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATAE" lang="spa" raw_text_char_length="5549" raw_text_md5="1d10cee84ed4c77b39b561612b9fec37" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="61" id="segment-0" start_char="1">
<ORIGINAL_TEXT>¿Es cierto que el virus SARS-CoV-2 está perdiendo virulencia?</ORIGINAL_TEXT>
<TOKEN end_char="1" id="token-0-0" morph="none" pos="punct" start_char="1">¿</TOKEN>
<TOKEN end_char="3" id="token-0-1" morph="none" pos="word" start_char="2">Es</TOKEN>
<TOKEN end_char="10" id="token-0-2" morph="none" pos="word" start_char="5">cierto</TOKEN>
<TOKEN end_char="14" id="token-0-3" morph="none" pos="word" start_char="12">que</TOKEN>
<TOKEN end_char="17" id="token-0-4" morph="none" pos="word" start_char="16">el</TOKEN>
<TOKEN end_char="23" id="token-0-5" morph="none" pos="word" start_char="19">virus</TOKEN>
<TOKEN end_char="34" id="token-0-6" morph="none" pos="unknown" start_char="25">SARS-CoV-2</TOKEN>
<TOKEN end_char="39" id="token-0-7" morph="none" pos="word" start_char="36">está</TOKEN>
<TOKEN end_char="49" id="token-0-8" morph="none" pos="word" start_char="41">perdiendo</TOKEN>
<TOKEN end_char="60" id="token-0-9" morph="none" pos="word" start_char="51">virulencia</TOKEN>
<TOKEN end_char="61" id="token-0-10" morph="none" pos="punct" start_char="61">?</TOKEN>
<TRANSLATED_TEXT>Is it true that SARS-CoV-2 is losing virulence?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="198" id="segment-1" start_char="66">
<ORIGINAL_TEXT>El virus se propaga poco en España por las medidas de confinamiento, pero no hay ninguna prueba científica de que haya perdido fuerza</ORIGINAL_TEXT>
<TOKEN end_char="67" id="token-1-0" morph="none" pos="word" start_char="66">El</TOKEN>
<TOKEN end_char="73" id="token-1-1" morph="none" pos="word" start_char="69">virus</TOKEN>
<TOKEN end_char="76" id="token-1-2" morph="none" pos="word" start_char="75">se</TOKEN>
<TOKEN end_char="84" id="token-1-3" morph="none" pos="word" start_char="78">propaga</TOKEN>
<TOKEN end_char="89" id="token-1-4" morph="none" pos="word" start_char="86">poco</TOKEN>
<TOKEN end_char="92" id="token-1-5" morph="none" pos="word" start_char="91">en</TOKEN>
<TOKEN end_char="99" id="token-1-6" morph="none" pos="word" start_char="94">España</TOKEN>
<TOKEN end_char="103" id="token-1-7" morph="none" pos="word" start_char="101">por</TOKEN>
<TOKEN end_char="107" id="token-1-8" morph="none" pos="word" start_char="105">las</TOKEN>
<TOKEN end_char="115" id="token-1-9" morph="none" pos="word" start_char="109">medidas</TOKEN>
<TOKEN end_char="118" id="token-1-10" morph="none" pos="word" start_char="117">de</TOKEN>
<TOKEN end_char="132" id="token-1-11" morph="none" pos="word" start_char="120">confinamiento</TOKEN>
<TOKEN end_char="133" id="token-1-12" morph="none" pos="punct" start_char="133">,</TOKEN>
<TOKEN end_char="138" id="token-1-13" morph="none" pos="word" start_char="135">pero</TOKEN>
<TOKEN end_char="141" id="token-1-14" morph="none" pos="word" start_char="140">no</TOKEN>
<TOKEN end_char="145" id="token-1-15" morph="none" pos="word" start_char="143">hay</TOKEN>
<TOKEN end_char="153" id="token-1-16" morph="none" pos="word" start_char="147">ninguna</TOKEN>
<TOKEN end_char="160" id="token-1-17" morph="none" pos="word" start_char="155">prueba</TOKEN>
<TOKEN end_char="171" id="token-1-18" morph="none" pos="word" start_char="162">científica</TOKEN>
<TOKEN end_char="174" id="token-1-19" morph="none" pos="word" start_char="173">de</TOKEN>
<TOKEN end_char="178" id="token-1-20" morph="none" pos="word" start_char="176">que</TOKEN>
<TOKEN end_char="183" id="token-1-21" morph="none" pos="word" start_char="180">haya</TOKEN>
<TOKEN end_char="191" id="token-1-22" morph="none" pos="word" start_char="185">perdido</TOKEN>
<TOKEN end_char="198" id="token-1-23" morph="none" pos="word" start_char="193">fuerza</TOKEN>
<TRANSLATED_TEXT>The virus spreads little in Spain through containment measures, but there is no scientific evidence that it has lost its strength.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="303" id="segment-2" start_char="202">
<ORIGINAL_TEXT>https://elpais.com/ciencia/2020-06-02/es-cierto-que-el-virus-sars-cov-2-esta-perdiendo-virulencia.html</ORIGINAL_TEXT>
<TOKEN end_char="303" id="token-2-0" morph="none" pos="url" start_char="202">https://elpais.com/ciencia/2020-06-02/es-cierto-que-el-virus-sars-cov-2-esta-perdiendo-virulencia.html</TOKEN>
<TRANSLATED_TEXT>https: / / elpais.com / ciencia / 2020-06-02 / es-certa-que-el-virus-sars-cov-2-esta-losing-virulencia.html</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="612" id="segment-3" start_char="306">
<ORIGINAL_TEXT>La pregunta proviene de las declaraciones que ha hecho un médico italiano, anestesista de un hospital de Milán y médico de Silvio Berlusconi, que ha dicho que cuando recogen muestras de un enfermo de covid-19 con un hisopo, la carga viral que se detecta es mucho menor ahora de lo que era hace unas semanas.</ORIGINAL_TEXT>
<TOKEN end_char="307" id="token-3-0" morph="none" pos="word" start_char="306">La</TOKEN>
<TOKEN end_char="316" id="token-3-1" morph="none" pos="word" start_char="309">pregunta</TOKEN>
<TOKEN end_char="325" id="token-3-2" morph="none" pos="word" start_char="318">proviene</TOKEN>
<TOKEN end_char="328" id="token-3-3" morph="none" pos="word" start_char="327">de</TOKEN>
<TOKEN end_char="332" id="token-3-4" morph="none" pos="word" start_char="330">las</TOKEN>
<TOKEN end_char="346" id="token-3-5" morph="none" pos="word" start_char="334">declaraciones</TOKEN>
<TOKEN end_char="350" id="token-3-6" morph="none" pos="word" start_char="348">que</TOKEN>
<TOKEN end_char="353" id="token-3-7" morph="none" pos="word" start_char="352">ha</TOKEN>
<TOKEN end_char="359" id="token-3-8" morph="none" pos="word" start_char="355">hecho</TOKEN>
<TOKEN end_char="362" id="token-3-9" morph="none" pos="word" start_char="361">un</TOKEN>
<TOKEN end_char="369" id="token-3-10" morph="none" pos="word" start_char="364">médico</TOKEN>
<TOKEN end_char="378" id="token-3-11" morph="none" pos="word" start_char="371">italiano</TOKEN>
<TOKEN end_char="379" id="token-3-12" morph="none" pos="punct" start_char="379">,</TOKEN>
<TOKEN end_char="391" id="token-3-13" morph="none" pos="word" start_char="381">anestesista</TOKEN>
<TOKEN end_char="394" id="token-3-14" morph="none" pos="word" start_char="393">de</TOKEN>
<TOKEN end_char="397" id="token-3-15" morph="none" pos="word" start_char="396">un</TOKEN>
<TOKEN end_char="406" id="token-3-16" morph="none" pos="word" start_char="399">hospital</TOKEN>
<TOKEN end_char="409" id="token-3-17" morph="none" pos="word" start_char="408">de</TOKEN>
<TOKEN end_char="415" id="token-3-18" morph="none" pos="word" start_char="411">Milán</TOKEN>
<TOKEN end_char="417" id="token-3-19" morph="none" pos="word" start_char="417">y</TOKEN>
<TOKEN end_char="424" id="token-3-20" morph="none" pos="word" start_char="419">médico</TOKEN>
<TOKEN end_char="427" id="token-3-21" morph="none" pos="word" start_char="426">de</TOKEN>
<TOKEN end_char="434" id="token-3-22" morph="none" pos="word" start_char="429">Silvio</TOKEN>
<TOKEN end_char="445" id="token-3-23" morph="none" pos="word" start_char="436">Berlusconi</TOKEN>
<TOKEN end_char="446" id="token-3-24" morph="none" pos="punct" start_char="446">,</TOKEN>
<TOKEN end_char="450" id="token-3-25" morph="none" pos="word" start_char="448">que</TOKEN>
<TOKEN end_char="453" id="token-3-26" morph="none" pos="word" start_char="452">ha</TOKEN>
<TOKEN end_char="459" id="token-3-27" morph="none" pos="word" start_char="455">dicho</TOKEN>
<TOKEN end_char="463" id="token-3-28" morph="none" pos="word" start_char="461">que</TOKEN>
<TOKEN end_char="470" id="token-3-29" morph="none" pos="word" start_char="465">cuando</TOKEN>
<TOKEN end_char="478" id="token-3-30" morph="none" pos="word" start_char="472">recogen</TOKEN>
<TOKEN end_char="487" id="token-3-31" morph="none" pos="word" start_char="480">muestras</TOKEN>
<TOKEN end_char="490" id="token-3-32" morph="none" pos="word" start_char="489">de</TOKEN>
<TOKEN end_char="493" id="token-3-33" morph="none" pos="word" start_char="492">un</TOKEN>
<TOKEN end_char="501" id="token-3-34" morph="none" pos="word" start_char="495">enfermo</TOKEN>
<TOKEN end_char="504" id="token-3-35" morph="none" pos="word" start_char="503">de</TOKEN>
<TOKEN end_char="513" id="token-3-36" morph="none" pos="unknown" start_char="506">covid-19</TOKEN>
<TOKEN end_char="517" id="token-3-37" morph="none" pos="word" start_char="515">con</TOKEN>
<TOKEN end_char="520" id="token-3-38" morph="none" pos="word" start_char="519">un</TOKEN>
<TOKEN end_char="527" id="token-3-39" morph="none" pos="word" start_char="522">hisopo</TOKEN>
<TOKEN end_char="528" id="token-3-40" morph="none" pos="punct" start_char="528">,</TOKEN>
<TOKEN end_char="531" id="token-3-41" morph="none" pos="word" start_char="530">la</TOKEN>
<TOKEN end_char="537" id="token-3-42" morph="none" pos="word" start_char="533">carga</TOKEN>
<TOKEN end_char="543" id="token-3-43" morph="none" pos="word" start_char="539">viral</TOKEN>
<TOKEN end_char="547" id="token-3-44" morph="none" pos="word" start_char="545">que</TOKEN>
<TOKEN end_char="550" id="token-3-45" morph="none" pos="word" start_char="549">se</TOKEN>
<TOKEN end_char="558" id="token-3-46" morph="none" pos="word" start_char="552">detecta</TOKEN>
<TOKEN end_char="561" id="token-3-47" morph="none" pos="word" start_char="560">es</TOKEN>
<TOKEN end_char="567" id="token-3-48" morph="none" pos="word" start_char="563">mucho</TOKEN>
<TOKEN end_char="573" id="token-3-49" morph="none" pos="word" start_char="569">menor</TOKEN>
<TOKEN end_char="579" id="token-3-50" morph="none" pos="word" start_char="575">ahora</TOKEN>
<TOKEN end_char="582" id="token-3-51" morph="none" pos="word" start_char="581">de</TOKEN>
<TOKEN end_char="585" id="token-3-52" morph="none" pos="word" start_char="584">lo</TOKEN>
<TOKEN end_char="589" id="token-3-53" morph="none" pos="word" start_char="587">que</TOKEN>
<TOKEN end_char="593" id="token-3-54" morph="none" pos="word" start_char="591">era</TOKEN>
<TOKEN end_char="598" id="token-3-55" morph="none" pos="word" start_char="595">hace</TOKEN>
<TOKEN end_char="603" id="token-3-56" morph="none" pos="word" start_char="600">unas</TOKEN>
<TOKEN end_char="611" id="token-3-57" morph="none" pos="word" start_char="605">semanas</TOKEN>
<TOKEN end_char="612" id="token-3-58" morph="none" pos="punct" start_char="612">.</TOKEN>
<TRANSLATED_TEXT>The question comes from statements made by an Italian doctor, an anesthesiologist at a Milan hospital, and Silvio Berlusconi's doctor, who said that when they collect samples from a patient with a cough, the viral load being detected is much lower now than it was a few weeks ago.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="785" id="segment-4" start_char="614">
<ORIGINAL_TEXT>Para empezar, hay que decir que estas declaraciones hacen un flaco favor, sobre todo en los países mediterráneos, en los que hay gente que piensa que esto ya se ha acabado.</ORIGINAL_TEXT>
<TOKEN end_char="617" id="token-4-0" morph="none" pos="word" start_char="614">Para</TOKEN>
<TOKEN end_char="625" id="token-4-1" morph="none" pos="word" start_char="619">empezar</TOKEN>
<TOKEN end_char="626" id="token-4-2" morph="none" pos="punct" start_char="626">,</TOKEN>
<TOKEN end_char="630" id="token-4-3" morph="none" pos="word" start_char="628">hay</TOKEN>
<TOKEN end_char="634" id="token-4-4" morph="none" pos="word" start_char="632">que</TOKEN>
<TOKEN end_char="640" id="token-4-5" morph="none" pos="word" start_char="636">decir</TOKEN>
<TOKEN end_char="644" id="token-4-6" morph="none" pos="word" start_char="642">que</TOKEN>
<TOKEN end_char="650" id="token-4-7" morph="none" pos="word" start_char="646">estas</TOKEN>
<TOKEN end_char="664" id="token-4-8" morph="none" pos="word" start_char="652">declaraciones</TOKEN>
<TOKEN end_char="670" id="token-4-9" morph="none" pos="word" start_char="666">hacen</TOKEN>
<TOKEN end_char="673" id="token-4-10" morph="none" pos="word" start_char="672">un</TOKEN>
<TOKEN end_char="679" id="token-4-11" morph="none" pos="word" start_char="675">flaco</TOKEN>
<TOKEN end_char="685" id="token-4-12" morph="none" pos="word" start_char="681">favor</TOKEN>
<TOKEN end_char="686" id="token-4-13" morph="none" pos="punct" start_char="686">,</TOKEN>
<TOKEN end_char="692" id="token-4-14" morph="none" pos="word" start_char="688">sobre</TOKEN>
<TOKEN end_char="697" id="token-4-15" morph="none" pos="word" start_char="694">todo</TOKEN>
<TOKEN end_char="700" id="token-4-16" morph="none" pos="word" start_char="699">en</TOKEN>
<TOKEN end_char="704" id="token-4-17" morph="none" pos="word" start_char="702">los</TOKEN>
<TOKEN end_char="711" id="token-4-18" morph="none" pos="word" start_char="706">países</TOKEN>
<TOKEN end_char="725" id="token-4-19" morph="none" pos="word" start_char="713">mediterráneos</TOKEN>
<TOKEN end_char="726" id="token-4-20" morph="none" pos="punct" start_char="726">,</TOKEN>
<TOKEN end_char="729" id="token-4-21" morph="none" pos="word" start_char="728">en</TOKEN>
<TOKEN end_char="733" id="token-4-22" morph="none" pos="word" start_char="731">los</TOKEN>
<TOKEN end_char="737" id="token-4-23" morph="none" pos="word" start_char="735">que</TOKEN>
<TOKEN end_char="741" id="token-4-24" morph="none" pos="word" start_char="739">hay</TOKEN>
<TOKEN end_char="747" id="token-4-25" morph="none" pos="word" start_char="743">gente</TOKEN>
<TOKEN end_char="751" id="token-4-26" morph="none" pos="word" start_char="749">que</TOKEN>
<TOKEN end_char="758" id="token-4-27" morph="none" pos="word" start_char="753">piensa</TOKEN>
<TOKEN end_char="762" id="token-4-28" morph="none" pos="word" start_char="760">que</TOKEN>
<TOKEN end_char="767" id="token-4-29" morph="none" pos="word" start_char="764">esto</TOKEN>
<TOKEN end_char="770" id="token-4-30" morph="none" pos="word" start_char="769">ya</TOKEN>
<TOKEN end_char="773" id="token-4-31" morph="none" pos="word" start_char="772">se</TOKEN>
<TOKEN end_char="776" id="token-4-32" morph="none" pos="word" start_char="775">ha</TOKEN>
<TOKEN end_char="784" id="token-4-33" morph="none" pos="word" start_char="778">acabado</TOKEN>
<TOKEN end_char="785" id="token-4-34" morph="none" pos="punct" start_char="785">.</TOKEN>
<TRANSLATED_TEXT>For starters, these statements do little good, especially in the Mediterranean countries, where there are people who think this is over.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="815" id="segment-5" start_char="787">
<ORIGINAL_TEXT>La realidad es muy diferente.</ORIGINAL_TEXT>
<TOKEN end_char="788" id="token-5-0" morph="none" pos="word" start_char="787">La</TOKEN>
<TOKEN end_char="797" id="token-5-1" morph="none" pos="word" start_char="790">realidad</TOKEN>
<TOKEN end_char="800" id="token-5-2" morph="none" pos="word" start_char="799">es</TOKEN>
<TOKEN end_char="804" id="token-5-3" morph="none" pos="word" start_char="802">muy</TOKEN>
<TOKEN end_char="814" id="token-5-4" morph="none" pos="word" start_char="806">diferente</TOKEN>
<TOKEN end_char="815" id="token-5-5" morph="none" pos="punct" start_char="815">.</TOKEN>
<TRANSLATED_TEXT>The reality is very different.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="858" id="segment-6" start_char="817">
<ORIGINAL_TEXT>Para empezar, el virus no ha desaparecido.</ORIGINAL_TEXT>
<TOKEN end_char="820" id="token-6-0" morph="none" pos="word" start_char="817">Para</TOKEN>
<TOKEN end_char="828" id="token-6-1" morph="none" pos="word" start_char="822">empezar</TOKEN>
<TOKEN end_char="829" id="token-6-2" morph="none" pos="punct" start_char="829">,</TOKEN>
<TOKEN end_char="832" id="token-6-3" morph="none" pos="word" start_char="831">el</TOKEN>
<TOKEN end_char="838" id="token-6-4" morph="none" pos="word" start_char="834">virus</TOKEN>
<TOKEN end_char="841" id="token-6-5" morph="none" pos="word" start_char="840">no</TOKEN>
<TOKEN end_char="844" id="token-6-6" morph="none" pos="word" start_char="843">ha</TOKEN>
<TOKEN end_char="857" id="token-6-7" morph="none" pos="word" start_char="846">desaparecido</TOKEN>
<TOKEN end_char="858" id="token-6-8" morph="none" pos="punct" start_char="858">.</TOKEN>
<TRANSLATED_TEXT>For starters, the virus has not disappeared.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1025" id="segment-7" start_char="860">
<ORIGINAL_TEXT>No podemos olvidar que el lunes de esta semana ha sido el primer día en España en el que no se ha comunicado ningún fallecimiento por covid desde principios de marzo.</ORIGINAL_TEXT>
<TOKEN end_char="861" id="token-7-0" morph="none" pos="word" start_char="860">No</TOKEN>
<TOKEN end_char="869" id="token-7-1" morph="none" pos="word" start_char="863">podemos</TOKEN>
<TOKEN end_char="877" id="token-7-2" morph="none" pos="word" start_char="871">olvidar</TOKEN>
<TOKEN end_char="881" id="token-7-3" morph="none" pos="word" start_char="879">que</TOKEN>
<TOKEN end_char="884" id="token-7-4" morph="none" pos="word" start_char="883">el</TOKEN>
<TOKEN end_char="890" id="token-7-5" morph="none" pos="word" start_char="886">lunes</TOKEN>
<TOKEN end_char="893" id="token-7-6" morph="none" pos="word" start_char="892">de</TOKEN>
<TOKEN end_char="898" id="token-7-7" morph="none" pos="word" start_char="895">esta</TOKEN>
<TOKEN end_char="905" id="token-7-8" morph="none" pos="word" start_char="900">semana</TOKEN>
<TOKEN end_char="908" id="token-7-9" morph="none" pos="word" start_char="907">ha</TOKEN>
<TOKEN end_char="913" id="token-7-10" morph="none" pos="word" start_char="910">sido</TOKEN>
<TOKEN end_char="916" id="token-7-11" morph="none" pos="word" start_char="915">el</TOKEN>
<TOKEN end_char="923" id="token-7-12" morph="none" pos="word" start_char="918">primer</TOKEN>
<TOKEN end_char="927" id="token-7-13" morph="none" pos="word" start_char="925">día</TOKEN>
<TOKEN end_char="930" id="token-7-14" morph="none" pos="word" start_char="929">en</TOKEN>
<TOKEN end_char="937" id="token-7-15" morph="none" pos="word" start_char="932">España</TOKEN>
<TOKEN end_char="940" id="token-7-16" morph="none" pos="word" start_char="939">en</TOKEN>
<TOKEN end_char="943" id="token-7-17" morph="none" pos="word" start_char="942">el</TOKEN>
<TOKEN end_char="947" id="token-7-18" morph="none" pos="word" start_char="945">que</TOKEN>
<TOKEN end_char="950" id="token-7-19" morph="none" pos="word" start_char="949">no</TOKEN>
<TOKEN end_char="953" id="token-7-20" morph="none" pos="word" start_char="952">se</TOKEN>
<TOKEN end_char="956" id="token-7-21" morph="none" pos="word" start_char="955">ha</TOKEN>
<TOKEN end_char="967" id="token-7-22" morph="none" pos="word" start_char="958">comunicado</TOKEN>
<TOKEN end_char="974" id="token-7-23" morph="none" pos="word" start_char="969">ningún</TOKEN>
<TOKEN end_char="988" id="token-7-24" morph="none" pos="word" start_char="976">fallecimiento</TOKEN>
<TOKEN end_char="992" id="token-7-25" morph="none" pos="word" start_char="990">por</TOKEN>
<TOKEN end_char="998" id="token-7-26" morph="none" pos="word" start_char="994">covid</TOKEN>
<TOKEN end_char="1004" id="token-7-27" morph="none" pos="word" start_char="1000">desde</TOKEN>
<TOKEN end_char="1015" id="token-7-28" morph="none" pos="word" start_char="1006">principios</TOKEN>
<TOKEN end_char="1018" id="token-7-29" morph="none" pos="word" start_char="1017">de</TOKEN>
<TOKEN end_char="1024" id="token-7-30" morph="none" pos="word" start_char="1020">marzo</TOKEN>
<TOKEN end_char="1025" id="token-7-31" morph="none" pos="punct" start_char="1025">.</TOKEN>
<TRANSLATED_TEXT>We must not forget that Monday this week has been the first day in Spain in which no death by covid has been reported since the beginning of March.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1051" id="segment-8" start_char="1027">
<ORIGINAL_TEXT>Eso no podemos olvidarlo.</ORIGINAL_TEXT>
<TOKEN end_char="1029" id="token-8-0" morph="none" pos="word" start_char="1027">Eso</TOKEN>
<TOKEN end_char="1032" id="token-8-1" morph="none" pos="word" start_char="1031">no</TOKEN>
<TOKEN end_char="1040" id="token-8-2" morph="none" pos="word" start_char="1034">podemos</TOKEN>
<TOKEN end_char="1050" id="token-8-3" morph="none" pos="word" start_char="1042">olvidarlo</TOKEN>
<TOKEN end_char="1051" id="token-8-4" morph="none" pos="punct" start_char="1051">.</TOKEN>
<TRANSLATED_TEXT>We can't forget that.</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="1146" id="segment-9" start_char="1053">
<ORIGINAL_TEXT>Como tampoco podemos olvidar que sigue habiendo infectados, sigue habiendo focos de infección.</ORIGINAL_TEXT>
<TOKEN end_char="1056" id="token-9-0" morph="none" pos="word" start_char="1053">Como</TOKEN>
<TOKEN end_char="1064" id="token-9-1" morph="none" pos="word" start_char="1058">tampoco</TOKEN>
<TOKEN end_char="1072" id="token-9-2" morph="none" pos="word" start_char="1066">podemos</TOKEN>
<TOKEN end_char="1080" id="token-9-3" morph="none" pos="word" start_char="1074">olvidar</TOKEN>
<TOKEN end_char="1084" id="token-9-4" morph="none" pos="word" start_char="1082">que</TOKEN>
<TOKEN end_char="1090" id="token-9-5" morph="none" pos="word" start_char="1086">sigue</TOKEN>
<TOKEN end_char="1099" id="token-9-6" morph="none" pos="word" start_char="1092">habiendo</TOKEN>
<TOKEN end_char="1110" id="token-9-7" morph="none" pos="word" start_char="1101">infectados</TOKEN>
<TOKEN end_char="1111" id="token-9-8" morph="none" pos="punct" start_char="1111">,</TOKEN>
<TOKEN end_char="1117" id="token-9-9" morph="none" pos="word" start_char="1113">sigue</TOKEN>
<TOKEN end_char="1126" id="token-9-10" morph="none" pos="word" start_char="1119">habiendo</TOKEN>
<TOKEN end_char="1132" id="token-9-11" morph="none" pos="word" start_char="1128">focos</TOKEN>
<TOKEN end_char="1135" id="token-9-12" morph="none" pos="word" start_char="1134">de</TOKEN>
<TOKEN end_char="1145" id="token-9-13" morph="none" pos="word" start_char="1137">infección</TOKEN>
<TOKEN end_char="1146" id="token-9-14" morph="none" pos="punct" start_char="1146">.</TOKEN>
<TRANSLATED_TEXT>As we cannot forget either that they are still infected, there are still outbreaks of infection.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1174" id="segment-10" start_char="1149">
<ORIGINAL_TEXT>El virus sigue circulando.</ORIGINAL_TEXT>
<TOKEN end_char="1150" id="token-10-0" morph="none" pos="word" start_char="1149">El</TOKEN>
<TOKEN end_char="1156" id="token-10-1" morph="none" pos="word" start_char="1152">virus</TOKEN>
<TOKEN end_char="1162" id="token-10-2" morph="none" pos="word" start_char="1158">sigue</TOKEN>
<TOKEN end_char="1173" id="token-10-3" morph="none" pos="word" start_char="1164">circulando</TOKEN>
<TOKEN end_char="1174" id="token-10-4" morph="none" pos="punct" start_char="1174">.</TOKEN>
<TRANSLATED_TEXT>The virus is still circulating.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1326" id="segment-11" start_char="1176">
<ORIGINAL_TEXT>Circula poco porque se lo ponemos cada vez más difícil, pero si nos relajamos, el virus seguirá infectando porque sigue habiendo población susceptible.</ORIGINAL_TEXT>
<TOKEN end_char="1182" id="token-11-0" morph="none" pos="word" start_char="1176">Circula</TOKEN>
<TOKEN end_char="1187" id="token-11-1" morph="none" pos="word" start_char="1184">poco</TOKEN>
<TOKEN end_char="1194" id="token-11-2" morph="none" pos="word" start_char="1189">porque</TOKEN>
<TOKEN end_char="1197" id="token-11-3" morph="none" pos="word" start_char="1196">se</TOKEN>
<TOKEN end_char="1200" id="token-11-4" morph="none" pos="word" start_char="1199">lo</TOKEN>
<TOKEN end_char="1208" id="token-11-5" morph="none" pos="word" start_char="1202">ponemos</TOKEN>
<TOKEN end_char="1213" id="token-11-6" morph="none" pos="word" start_char="1210">cada</TOKEN>
<TOKEN end_char="1217" id="token-11-7" morph="none" pos="word" start_char="1215">vez</TOKEN>
<TOKEN end_char="1221" id="token-11-8" morph="none" pos="word" start_char="1219">más</TOKEN>
<TOKEN end_char="1229" id="token-11-9" morph="none" pos="word" start_char="1223">difícil</TOKEN>
<TOKEN end_char="1230" id="token-11-10" morph="none" pos="punct" start_char="1230">,</TOKEN>
<TOKEN end_char="1235" id="token-11-11" morph="none" pos="word" start_char="1232">pero</TOKEN>
<TOKEN end_char="1238" id="token-11-12" morph="none" pos="word" start_char="1237">si</TOKEN>
<TOKEN end_char="1242" id="token-11-13" morph="none" pos="word" start_char="1240">nos</TOKEN>
<TOKEN end_char="1252" id="token-11-14" morph="none" pos="word" start_char="1244">relajamos</TOKEN>
<TOKEN end_char="1253" id="token-11-15" morph="none" pos="punct" start_char="1253">,</TOKEN>
<TOKEN end_char="1256" id="token-11-16" morph="none" pos="word" start_char="1255">el</TOKEN>
<TOKEN end_char="1262" id="token-11-17" morph="none" pos="word" start_char="1258">virus</TOKEN>
<TOKEN end_char="1270" id="token-11-18" morph="none" pos="word" start_char="1264">seguirá</TOKEN>
<TOKEN end_char="1281" id="token-11-19" morph="none" pos="word" start_char="1272">infectando</TOKEN>
<TOKEN end_char="1288" id="token-11-20" morph="none" pos="word" start_char="1283">porque</TOKEN>
<TOKEN end_char="1294" id="token-11-21" morph="none" pos="word" start_char="1290">sigue</TOKEN>
<TOKEN end_char="1303" id="token-11-22" morph="none" pos="word" start_char="1296">habiendo</TOKEN>
<TOKEN end_char="1313" id="token-11-23" morph="none" pos="word" start_char="1305">población</TOKEN>
<TOKEN end_char="1325" id="token-11-24" morph="none" pos="word" start_char="1315">susceptible</TOKEN>
<TOKEN end_char="1326" id="token-11-25" morph="none" pos="punct" start_char="1326">.</TOKEN>
<TRANSLATED_TEXT>Little is circulating because we make it increasingly difficult, but if we relax, the virus will continue to infect because there is still a susceptible population.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1610" id="segment-12" start_char="1328">
<ORIGINAL_TEXT>No podemos pensar que ya se ha acabado porque no es así: en la población española tenemos una inmunidad que puede rondar entre el 5% y el 20%, es decir, muy lejos del 60% que se considera necesario para que exista una inmunidad colectiva capaz de acabar con la transmisión del virus.</ORIGINAL_TEXT>
<TOKEN end_char="1329" id="token-12-0" morph="none" pos="word" start_char="1328">No</TOKEN>
<TOKEN end_char="1337" id="token-12-1" morph="none" pos="word" start_char="1331">podemos</TOKEN>
<TOKEN end_char="1344" id="token-12-2" morph="none" pos="word" start_char="1339">pensar</TOKEN>
<TOKEN end_char="1348" id="token-12-3" morph="none" pos="word" start_char="1346">que</TOKEN>
<TOKEN end_char="1351" id="token-12-4" morph="none" pos="word" start_char="1350">ya</TOKEN>
<TOKEN end_char="1354" id="token-12-5" morph="none" pos="word" start_char="1353">se</TOKEN>
<TOKEN end_char="1357" id="token-12-6" morph="none" pos="word" start_char="1356">ha</TOKEN>
<TOKEN end_char="1365" id="token-12-7" morph="none" pos="word" start_char="1359">acabado</TOKEN>
<TOKEN end_char="1372" id="token-12-8" morph="none" pos="word" start_char="1367">porque</TOKEN>
<TOKEN end_char="1375" id="token-12-9" morph="none" pos="word" start_char="1374">no</TOKEN>
<TOKEN end_char="1378" id="token-12-10" morph="none" pos="word" start_char="1377">es</TOKEN>
<TOKEN end_char="1382" id="token-12-11" morph="none" pos="word" start_char="1380">así</TOKEN>
<TOKEN end_char="1383" id="token-12-12" morph="none" pos="punct" start_char="1383">:</TOKEN>
<TOKEN end_char="1386" id="token-12-13" morph="none" pos="word" start_char="1385">en</TOKEN>
<TOKEN end_char="1389" id="token-12-14" morph="none" pos="word" start_char="1388">la</TOKEN>
<TOKEN end_char="1399" id="token-12-15" morph="none" pos="word" start_char="1391">población</TOKEN>
<TOKEN end_char="1408" id="token-12-16" morph="none" pos="word" start_char="1401">española</TOKEN>
<TOKEN end_char="1416" id="token-12-17" morph="none" pos="word" start_char="1410">tenemos</TOKEN>
<TOKEN end_char="1420" id="token-12-18" morph="none" pos="word" start_char="1418">una</TOKEN>
<TOKEN end_char="1430" id="token-12-19" morph="none" pos="word" start_char="1422">inmunidad</TOKEN>
<TOKEN end_char="1434" id="token-12-20" morph="none" pos="word" start_char="1432">que</TOKEN>
<TOKEN end_char="1440" id="token-12-21" morph="none" pos="word" start_char="1436">puede</TOKEN>
<TOKEN end_char="1447" id="token-12-22" morph="none" pos="word" start_char="1442">rondar</TOKEN>
<TOKEN end_char="1453" id="token-12-23" morph="none" pos="word" start_char="1449">entre</TOKEN>
<TOKEN end_char="1456" id="token-12-24" morph="none" pos="word" start_char="1455">el</TOKEN>
<TOKEN end_char="1458" id="token-12-25" morph="none" pos="word" start_char="1458">5</TOKEN>
<TOKEN end_char="1459" id="token-12-26" morph="none" pos="punct" start_char="1459">%</TOKEN>
<TOKEN end_char="1461" id="token-12-27" morph="none" pos="word" start_char="1461">y</TOKEN>
<TOKEN end_char="1464" id="token-12-28" morph="none" pos="word" start_char="1463">el</TOKEN>
<TOKEN end_char="1467" id="token-12-29" morph="none" pos="word" start_char="1466">20</TOKEN>
<TOKEN end_char="1469" id="token-12-30" morph="none" pos="punct" start_char="1468">%,</TOKEN>
<TOKEN end_char="1472" id="token-12-31" morph="none" pos="word" start_char="1471">es</TOKEN>
<TOKEN end_char="1478" id="token-12-32" morph="none" pos="word" start_char="1474">decir</TOKEN>
<TOKEN end_char="1479" id="token-12-33" morph="none" pos="punct" start_char="1479">,</TOKEN>
<TOKEN end_char="1483" id="token-12-34" morph="none" pos="word" start_char="1481">muy</TOKEN>
<TOKEN end_char="1489" id="token-12-35" morph="none" pos="word" start_char="1485">lejos</TOKEN>
<TOKEN end_char="1493" id="token-12-36" morph="none" pos="word" start_char="1491">del</TOKEN>
<TOKEN end_char="1496" id="token-12-37" morph="none" pos="word" start_char="1495">60</TOKEN>
<TOKEN end_char="1497" id="token-12-38" morph="none" pos="punct" start_char="1497">%</TOKEN>
<TOKEN end_char="1501" id="token-12-39" morph="none" pos="word" start_char="1499">que</TOKEN>
<TOKEN end_char="1504" id="token-12-40" morph="none" pos="word" start_char="1503">se</TOKEN>
<TOKEN end_char="1514" id="token-12-41" morph="none" pos="word" start_char="1506">considera</TOKEN>
<TOKEN end_char="1524" id="token-12-42" morph="none" pos="word" start_char="1516">necesario</TOKEN>
<TOKEN end_char="1529" id="token-12-43" morph="none" pos="word" start_char="1526">para</TOKEN>
<TOKEN end_char="1533" id="token-12-44" morph="none" pos="word" start_char="1531">que</TOKEN>
<TOKEN end_char="1540" id="token-12-45" morph="none" pos="word" start_char="1535">exista</TOKEN>
<TOKEN end_char="1544" id="token-12-46" morph="none" pos="word" start_char="1542">una</TOKEN>
<TOKEN end_char="1554" id="token-12-47" morph="none" pos="word" start_char="1546">inmunidad</TOKEN>
<TOKEN end_char="1564" id="token-12-48" morph="none" pos="word" start_char="1556">colectiva</TOKEN>
<TOKEN end_char="1570" id="token-12-49" morph="none" pos="word" start_char="1566">capaz</TOKEN>
<TOKEN end_char="1573" id="token-12-50" morph="none" pos="word" start_char="1572">de</TOKEN>
<TOKEN end_char="1580" id="token-12-51" morph="none" pos="word" start_char="1575">acabar</TOKEN>
<TOKEN end_char="1584" id="token-12-52" morph="none" pos="word" start_char="1582">con</TOKEN>
<TOKEN end_char="1587" id="token-12-53" morph="none" pos="word" start_char="1586">la</TOKEN>
<TOKEN end_char="1599" id="token-12-54" morph="none" pos="word" start_char="1589">transmisión</TOKEN>
<TOKEN end_char="1603" id="token-12-55" morph="none" pos="word" start_char="1601">del</TOKEN>
<TOKEN end_char="1609" id="token-12-56" morph="none" pos="word" start_char="1605">virus</TOKEN>
<TOKEN end_char="1610" id="token-12-57" morph="none" pos="punct" start_char="1610">.</TOKEN>
<TRANSLATED_TEXT>We cannot think that it has already ended because that is not the case: in the Spanish population we have immunity that can range between 5% and 20%, that is, far from the 60% that is considered necessary for there to be a collective immunity capable of ending the transmission of the virus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1703" id="segment-13" start_char="1613">
<ORIGINAL_TEXT>"Si nos relajamos, el virus seguirá infectando porque sigue habiendo población susceptible.</ORIGINAL_TEXT>
<TOKEN end_char="1613" id="token-13-0" morph="none" pos="punct" start_char="1613">"</TOKEN>
<TOKEN end_char="1615" id="token-13-1" morph="none" pos="word" start_char="1614">Si</TOKEN>
<TOKEN end_char="1619" id="token-13-2" morph="none" pos="word" start_char="1617">nos</TOKEN>
<TOKEN end_char="1629" id="token-13-3" morph="none" pos="word" start_char="1621">relajamos</TOKEN>
<TOKEN end_char="1630" id="token-13-4" morph="none" pos="punct" start_char="1630">,</TOKEN>
<TOKEN end_char="1633" id="token-13-5" morph="none" pos="word" start_char="1632">el</TOKEN>
<TOKEN end_char="1639" id="token-13-6" morph="none" pos="word" start_char="1635">virus</TOKEN>
<TOKEN end_char="1647" id="token-13-7" morph="none" pos="word" start_char="1641">seguirá</TOKEN>
<TOKEN end_char="1658" id="token-13-8" morph="none" pos="word" start_char="1649">infectando</TOKEN>
<TOKEN end_char="1665" id="token-13-9" morph="none" pos="word" start_char="1660">porque</TOKEN>
<TOKEN end_char="1671" id="token-13-10" morph="none" pos="word" start_char="1667">sigue</TOKEN>
<TOKEN end_char="1680" id="token-13-11" morph="none" pos="word" start_char="1673">habiendo</TOKEN>
<TOKEN end_char="1690" id="token-13-12" morph="none" pos="word" start_char="1682">población</TOKEN>
<TOKEN end_char="1702" id="token-13-13" morph="none" pos="word" start_char="1692">susceptible</TOKEN>
<TOKEN end_char="1703" id="token-13-14" morph="none" pos="punct" start_char="1703">.</TOKEN>
<TRANSLATED_TEXT>If we relax, the virus will continue to infect because there is still a susceptible population.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1760" id="segment-14" start_char="1705">
<ORIGINAL_TEXT>No podemos pensar que ya se ha acabado porque no es así"</ORIGINAL_TEXT>
<TOKEN end_char="1706" id="token-14-0" morph="none" pos="word" start_char="1705">No</TOKEN>
<TOKEN end_char="1714" id="token-14-1" morph="none" pos="word" start_char="1708">podemos</TOKEN>
<TOKEN end_char="1721" id="token-14-2" morph="none" pos="word" start_char="1716">pensar</TOKEN>
<TOKEN end_char="1725" id="token-14-3" morph="none" pos="word" start_char="1723">que</TOKEN>
<TOKEN end_char="1728" id="token-14-4" morph="none" pos="word" start_char="1727">ya</TOKEN>
<TOKEN end_char="1731" id="token-14-5" morph="none" pos="word" start_char="1730">se</TOKEN>
<TOKEN end_char="1734" id="token-14-6" morph="none" pos="word" start_char="1733">ha</TOKEN>
<TOKEN end_char="1742" id="token-14-7" morph="none" pos="word" start_char="1736">acabado</TOKEN>
<TOKEN end_char="1749" id="token-14-8" morph="none" pos="word" start_char="1744">porque</TOKEN>
<TOKEN end_char="1752" id="token-14-9" morph="none" pos="word" start_char="1751">no</TOKEN>
<TOKEN end_char="1755" id="token-14-10" morph="none" pos="word" start_char="1754">es</TOKEN>
<TOKEN end_char="1759" id="token-14-11" morph="none" pos="word" start_char="1757">así</TOKEN>
<TOKEN end_char="1760" id="token-14-12" morph="none" pos="punct" start_char="1760">"</TOKEN>
<TRANSLATED_TEXT>We can't think it's over because it's not. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1824" id="segment-15" start_char="1764">
<ORIGINAL_TEXT>Así que el virus está y el virus tiene capacidad de infectar.</ORIGINAL_TEXT>
<TOKEN end_char="1766" id="token-15-0" morph="none" pos="word" start_char="1764">Así</TOKEN>
<TOKEN end_char="1770" id="token-15-1" morph="none" pos="word" start_char="1768">que</TOKEN>
<TOKEN end_char="1773" id="token-15-2" morph="none" pos="word" start_char="1772">el</TOKEN>
<TOKEN end_char="1779" id="token-15-3" morph="none" pos="word" start_char="1775">virus</TOKEN>
<TOKEN end_char="1784" id="token-15-4" morph="none" pos="word" start_char="1781">está</TOKEN>
<TOKEN end_char="1786" id="token-15-5" morph="none" pos="word" start_char="1786">y</TOKEN>
<TOKEN end_char="1789" id="token-15-6" morph="none" pos="word" start_char="1788">el</TOKEN>
<TOKEN end_char="1795" id="token-15-7" morph="none" pos="word" start_char="1791">virus</TOKEN>
<TOKEN end_char="1801" id="token-15-8" morph="none" pos="word" start_char="1797">tiene</TOKEN>
<TOKEN end_char="1811" id="token-15-9" morph="none" pos="word" start_char="1803">capacidad</TOKEN>
<TOKEN end_char="1814" id="token-15-10" morph="none" pos="word" start_char="1813">de</TOKEN>
<TOKEN end_char="1823" id="token-15-11" morph="none" pos="word" start_char="1816">infectar</TOKEN>
<TOKEN end_char="1824" id="token-15-12" morph="none" pos="punct" start_char="1824">.</TOKEN>
<TRANSLATED_TEXT>So the virus is there and the virus has the ability to infect.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1902" id="segment-16" start_char="1826">
<ORIGINAL_TEXT>Eso lo sabemos porque seguimos teniendo nuevos casos de gente que se infecta.</ORIGINAL_TEXT>
<TOKEN end_char="1828" id="token-16-0" morph="none" pos="word" start_char="1826">Eso</TOKEN>
<TOKEN end_char="1831" id="token-16-1" morph="none" pos="word" start_char="1830">lo</TOKEN>
<TOKEN end_char="1839" id="token-16-2" morph="none" pos="word" start_char="1833">sabemos</TOKEN>
<TOKEN end_char="1846" id="token-16-3" morph="none" pos="word" start_char="1841">porque</TOKEN>
<TOKEN end_char="1855" id="token-16-4" morph="none" pos="word" start_char="1848">seguimos</TOKEN>
<TOKEN end_char="1864" id="token-16-5" morph="none" pos="word" start_char="1857">teniendo</TOKEN>
<TOKEN end_char="1871" id="token-16-6" morph="none" pos="word" start_char="1866">nuevos</TOKEN>
<TOKEN end_char="1877" id="token-16-7" morph="none" pos="word" start_char="1873">casos</TOKEN>
<TOKEN end_char="1880" id="token-16-8" morph="none" pos="word" start_char="1879">de</TOKEN>
<TOKEN end_char="1886" id="token-16-9" morph="none" pos="word" start_char="1882">gente</TOKEN>
<TOKEN end_char="1890" id="token-16-10" morph="none" pos="word" start_char="1888">que</TOKEN>
<TOKEN end_char="1893" id="token-16-11" morph="none" pos="word" start_char="1892">se</TOKEN>
<TOKEN end_char="1901" id="token-16-12" morph="none" pos="word" start_char="1895">infecta</TOKEN>
<TOKEN end_char="1902" id="token-16-13" morph="none" pos="punct" start_char="1902">.</TOKEN>
<TRANSLATED_TEXT>We know that because we still have new cases of people getting infected.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2022" id="segment-17" start_char="1904">
<ORIGINAL_TEXT>No sé qué evidencias tiene ese médico italiano para hacer esta afirmación, pero las que yo tengo me dicen lo contrario.</ORIGINAL_TEXT>
<TOKEN end_char="1905" id="token-17-0" morph="none" pos="word" start_char="1904">No</TOKEN>
<TOKEN end_char="1908" id="token-17-1" morph="none" pos="word" start_char="1907">sé</TOKEN>
<TOKEN end_char="1912" id="token-17-2" morph="none" pos="word" start_char="1910">qué</TOKEN>
<TOKEN end_char="1923" id="token-17-3" morph="none" pos="word" start_char="1914">evidencias</TOKEN>
<TOKEN end_char="1929" id="token-17-4" morph="none" pos="word" start_char="1925">tiene</TOKEN>
<TOKEN end_char="1933" id="token-17-5" morph="none" pos="word" start_char="1931">ese</TOKEN>
<TOKEN end_char="1940" id="token-17-6" morph="none" pos="word" start_char="1935">médico</TOKEN>
<TOKEN end_char="1949" id="token-17-7" morph="none" pos="word" start_char="1942">italiano</TOKEN>
<TOKEN end_char="1954" id="token-17-8" morph="none" pos="word" start_char="1951">para</TOKEN>
<TOKEN end_char="1960" id="token-17-9" morph="none" pos="word" start_char="1956">hacer</TOKEN>
<TOKEN end_char="1965" id="token-17-10" morph="none" pos="word" start_char="1962">esta</TOKEN>
<TOKEN end_char="1976" id="token-17-11" morph="none" pos="word" start_char="1967">afirmación</TOKEN>
<TOKEN end_char="1977" id="token-17-12" morph="none" pos="punct" start_char="1977">,</TOKEN>
<TOKEN end_char="1982" id="token-17-13" morph="none" pos="word" start_char="1979">pero</TOKEN>
<TOKEN end_char="1986" id="token-17-14" morph="none" pos="word" start_char="1984">las</TOKEN>
<TOKEN end_char="1990" id="token-17-15" morph="none" pos="word" start_char="1988">que</TOKEN>
<TOKEN end_char="1993" id="token-17-16" morph="none" pos="word" start_char="1992">yo</TOKEN>
<TOKEN end_char="1999" id="token-17-17" morph="none" pos="word" start_char="1995">tengo</TOKEN>
<TOKEN end_char="2002" id="token-17-18" morph="none" pos="word" start_char="2001">me</TOKEN>
<TOKEN end_char="2008" id="token-17-19" morph="none" pos="word" start_char="2004">dicen</TOKEN>
<TOKEN end_char="2011" id="token-17-20" morph="none" pos="word" start_char="2010">lo</TOKEN>
<TOKEN end_char="2021" id="token-17-21" morph="none" pos="word" start_char="2013">contrario</TOKEN>
<TOKEN end_char="2022" id="token-17-22" morph="none" pos="punct" start_char="2022">.</TOKEN>
<TRANSLATED_TEXT>I don't know what evidence that Italian doctor has to make this claim, but what I have tells me the opposite.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2073" id="segment-18" start_char="2024">
<ORIGINAL_TEXT>Y en ciencia trabajamos con evidencias, con datos.</ORIGINAL_TEXT>
<TOKEN end_char="2024" id="token-18-0" morph="none" pos="word" start_char="2024">Y</TOKEN>
<TOKEN end_char="2027" id="token-18-1" morph="none" pos="word" start_char="2026">en</TOKEN>
<TOKEN end_char="2035" id="token-18-2" morph="none" pos="word" start_char="2029">ciencia</TOKEN>
<TOKEN end_char="2046" id="token-18-3" morph="none" pos="word" start_char="2037">trabajamos</TOKEN>
<TOKEN end_char="2050" id="token-18-4" morph="none" pos="word" start_char="2048">con</TOKEN>
<TOKEN end_char="2061" id="token-18-5" morph="none" pos="word" start_char="2052">evidencias</TOKEN>
<TOKEN end_char="2062" id="token-18-6" morph="none" pos="punct" start_char="2062">,</TOKEN>
<TOKEN end_char="2066" id="token-18-7" morph="none" pos="word" start_char="2064">con</TOKEN>
<TOKEN end_char="2072" id="token-18-8" morph="none" pos="word" start_char="2068">datos</TOKEN>
<TOKEN end_char="2073" id="token-18-9" morph="none" pos="punct" start_char="2073">.</TOKEN>
<TRANSLATED_TEXT>And in science, we work with evidence, with data.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2330" id="segment-19" start_char="2075">
<ORIGINAL_TEXT>Los datos que se manejan en España dicen que el virus se propaga poco porque hemos internalizado la necesidad de la distancia social, porque la mayoría de la gente lleva mascarilla (aunque deberían ser más) y porque todas esas barreras se lo ponen difícil.</ORIGINAL_TEXT>
<TOKEN end_char="2077" id="token-19-0" morph="none" pos="word" start_char="2075">Los</TOKEN>
<TOKEN end_char="2083" id="token-19-1" morph="none" pos="word" start_char="2079">datos</TOKEN>
<TOKEN end_char="2087" id="token-19-2" morph="none" pos="word" start_char="2085">que</TOKEN>
<TOKEN end_char="2090" id="token-19-3" morph="none" pos="word" start_char="2089">se</TOKEN>
<TOKEN end_char="2098" id="token-19-4" morph="none" pos="word" start_char="2092">manejan</TOKEN>
<TOKEN end_char="2101" id="token-19-5" morph="none" pos="word" start_char="2100">en</TOKEN>
<TOKEN end_char="2108" id="token-19-6" morph="none" pos="word" start_char="2103">España</TOKEN>
<TOKEN end_char="2114" id="token-19-7" morph="none" pos="word" start_char="2110">dicen</TOKEN>
<TOKEN end_char="2118" id="token-19-8" morph="none" pos="word" start_char="2116">que</TOKEN>
<TOKEN end_char="2121" id="token-19-9" morph="none" pos="word" start_char="2120">el</TOKEN>
<TOKEN end_char="2127" id="token-19-10" morph="none" pos="word" start_char="2123">virus</TOKEN>
<TOKEN end_char="2130" id="token-19-11" morph="none" pos="word" start_char="2129">se</TOKEN>
<TOKEN end_char="2138" id="token-19-12" morph="none" pos="word" start_char="2132">propaga</TOKEN>
<TOKEN end_char="2143" id="token-19-13" morph="none" pos="word" start_char="2140">poco</TOKEN>
<TOKEN end_char="2150" id="token-19-14" morph="none" pos="word" start_char="2145">porque</TOKEN>
<TOKEN end_char="2156" id="token-19-15" morph="none" pos="word" start_char="2152">hemos</TOKEN>
<TOKEN end_char="2170" id="token-19-16" morph="none" pos="word" start_char="2158">internalizado</TOKEN>
<TOKEN end_char="2173" id="token-19-17" morph="none" pos="word" start_char="2172">la</TOKEN>
<TOKEN end_char="2183" id="token-19-18" morph="none" pos="word" start_char="2175">necesidad</TOKEN>
<TOKEN end_char="2186" id="token-19-19" morph="none" pos="word" start_char="2185">de</TOKEN>
<TOKEN end_char="2189" id="token-19-20" morph="none" pos="word" start_char="2188">la</TOKEN>
<TOKEN end_char="2199" id="token-19-21" morph="none" pos="word" start_char="2191">distancia</TOKEN>
<TOKEN end_char="2206" id="token-19-22" morph="none" pos="word" start_char="2201">social</TOKEN>
<TOKEN end_char="2207" id="token-19-23" morph="none" pos="punct" start_char="2207">,</TOKEN>
<TOKEN end_char="2214" id="token-19-24" morph="none" pos="word" start_char="2209">porque</TOKEN>
<TOKEN end_char="2217" id="token-19-25" morph="none" pos="word" start_char="2216">la</TOKEN>
<TOKEN end_char="2225" id="token-19-26" morph="none" pos="word" start_char="2219">mayoría</TOKEN>
<TOKEN end_char="2228" id="token-19-27" morph="none" pos="word" start_char="2227">de</TOKEN>
<TOKEN end_char="2231" id="token-19-28" morph="none" pos="word" start_char="2230">la</TOKEN>
<TOKEN end_char="2237" id="token-19-29" morph="none" pos="word" start_char="2233">gente</TOKEN>
<TOKEN end_char="2243" id="token-19-30" morph="none" pos="word" start_char="2239">lleva</TOKEN>
<TOKEN end_char="2254" id="token-19-31" morph="none" pos="word" start_char="2245">mascarilla</TOKEN>
<TOKEN end_char="2256" id="token-19-32" morph="none" pos="punct" start_char="2256">(</TOKEN>
<TOKEN end_char="2262" id="token-19-33" morph="none" pos="word" start_char="2257">aunque</TOKEN>
<TOKEN end_char="2271" id="token-19-34" morph="none" pos="word" start_char="2264">deberían</TOKEN>
<TOKEN end_char="2275" id="token-19-35" morph="none" pos="word" start_char="2273">ser</TOKEN>
<TOKEN end_char="2279" id="token-19-36" morph="none" pos="word" start_char="2277">más</TOKEN>
<TOKEN end_char="2280" id="token-19-37" morph="none" pos="punct" start_char="2280">)</TOKEN>
<TOKEN end_char="2282" id="token-19-38" morph="none" pos="word" start_char="2282">y</TOKEN>
<TOKEN end_char="2289" id="token-19-39" morph="none" pos="word" start_char="2284">porque</TOKEN>
<TOKEN end_char="2295" id="token-19-40" morph="none" pos="word" start_char="2291">todas</TOKEN>
<TOKEN end_char="2300" id="token-19-41" morph="none" pos="word" start_char="2297">esas</TOKEN>
<TOKEN end_char="2309" id="token-19-42" morph="none" pos="word" start_char="2302">barreras</TOKEN>
<TOKEN end_char="2312" id="token-19-43" morph="none" pos="word" start_char="2311">se</TOKEN>
<TOKEN end_char="2315" id="token-19-44" morph="none" pos="word" start_char="2314">lo</TOKEN>
<TOKEN end_char="2321" id="token-19-45" morph="none" pos="word" start_char="2317">ponen</TOKEN>
<TOKEN end_char="2329" id="token-19-46" morph="none" pos="word" start_char="2323">difícil</TOKEN>
<TOKEN end_char="2330" id="token-19-47" morph="none" pos="punct" start_char="2330">.</TOKEN>
<TRANSLATED_TEXT>Data handled in Spain say that the virus spreads little because we have internalized the need for social distance, because most people wear masks (though they should be more), and because all those barriers make it difficult.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2456" id="segment-20" start_char="2332">
<ORIGINAL_TEXT>Pero en cuanto nos despistamos y se dejan de seguir esas medidas, aparecen focos como los de Córdoba, Ceuta, Murcia o Lérida.</ORIGINAL_TEXT>
<TOKEN end_char="2335" id="token-20-0" morph="none" pos="word" start_char="2332">Pero</TOKEN>
<TOKEN end_char="2338" id="token-20-1" morph="none" pos="word" start_char="2337">en</TOKEN>
<TOKEN end_char="2345" id="token-20-2" morph="none" pos="word" start_char="2340">cuanto</TOKEN>
<TOKEN end_char="2349" id="token-20-3" morph="none" pos="word" start_char="2347">nos</TOKEN>
<TOKEN end_char="2361" id="token-20-4" morph="none" pos="word" start_char="2351">despistamos</TOKEN>
<TOKEN end_char="2363" id="token-20-5" morph="none" pos="word" start_char="2363">y</TOKEN>
<TOKEN end_char="2366" id="token-20-6" morph="none" pos="word" start_char="2365">se</TOKEN>
<TOKEN end_char="2372" id="token-20-7" morph="none" pos="word" start_char="2368">dejan</TOKEN>
<TOKEN end_char="2375" id="token-20-8" morph="none" pos="word" start_char="2374">de</TOKEN>
<TOKEN end_char="2382" id="token-20-9" morph="none" pos="word" start_char="2377">seguir</TOKEN>
<TOKEN end_char="2387" id="token-20-10" morph="none" pos="word" start_char="2384">esas</TOKEN>
<TOKEN end_char="2395" id="token-20-11" morph="none" pos="word" start_char="2389">medidas</TOKEN>
<TOKEN end_char="2396" id="token-20-12" morph="none" pos="punct" start_char="2396">,</TOKEN>
<TOKEN end_char="2405" id="token-20-13" morph="none" pos="word" start_char="2398">aparecen</TOKEN>
<TOKEN end_char="2411" id="token-20-14" morph="none" pos="word" start_char="2407">focos</TOKEN>
<TOKEN end_char="2416" id="token-20-15" morph="none" pos="word" start_char="2413">como</TOKEN>
<TOKEN end_char="2420" id="token-20-16" morph="none" pos="word" start_char="2418">los</TOKEN>
<TOKEN end_char="2423" id="token-20-17" morph="none" pos="word" start_char="2422">de</TOKEN>
<TOKEN end_char="2431" id="token-20-18" morph="none" pos="word" start_char="2425">Córdoba</TOKEN>
<TOKEN end_char="2432" id="token-20-19" morph="none" pos="punct" start_char="2432">,</TOKEN>
<TOKEN end_char="2438" id="token-20-20" morph="none" pos="word" start_char="2434">Ceuta</TOKEN>
<TOKEN end_char="2439" id="token-20-21" morph="none" pos="punct" start_char="2439">,</TOKEN>
<TOKEN end_char="2446" id="token-20-22" morph="none" pos="word" start_char="2441">Murcia</TOKEN>
<TOKEN end_char="2448" id="token-20-23" morph="none" pos="word" start_char="2448">o</TOKEN>
<TOKEN end_char="2455" id="token-20-24" morph="none" pos="word" start_char="2450">Lérida</TOKEN>
<TOKEN end_char="2456" id="token-20-25" morph="none" pos="punct" start_char="2456">.</TOKEN>
<TRANSLATED_TEXT>But as soon as we get out of the way and stop following these measures, foci like Córdoba, Ceuta, Murcia or Lleida appear.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2602" id="segment-21" start_char="2458">
<ORIGINAL_TEXT>Eso nos dice que podemos ir retomando nuestra vida poco a poco pero manteniendo todas estas cuestiones de higiene, distancia social y mascarilla.</ORIGINAL_TEXT>
<TOKEN end_char="2460" id="token-21-0" morph="none" pos="word" start_char="2458">Eso</TOKEN>
<TOKEN end_char="2464" id="token-21-1" morph="none" pos="word" start_char="2462">nos</TOKEN>
<TOKEN end_char="2469" id="token-21-2" morph="none" pos="word" start_char="2466">dice</TOKEN>
<TOKEN end_char="2473" id="token-21-3" morph="none" pos="word" start_char="2471">que</TOKEN>
<TOKEN end_char="2481" id="token-21-4" morph="none" pos="word" start_char="2475">podemos</TOKEN>
<TOKEN end_char="2484" id="token-21-5" morph="none" pos="word" start_char="2483">ir</TOKEN>
<TOKEN end_char="2494" id="token-21-6" morph="none" pos="word" start_char="2486">retomando</TOKEN>
<TOKEN end_char="2502" id="token-21-7" morph="none" pos="word" start_char="2496">nuestra</TOKEN>
<TOKEN end_char="2507" id="token-21-8" morph="none" pos="word" start_char="2504">vida</TOKEN>
<TOKEN end_char="2512" id="token-21-9" morph="none" pos="word" start_char="2509">poco</TOKEN>
<TOKEN end_char="2514" id="token-21-10" morph="none" pos="word" start_char="2514">a</TOKEN>
<TOKEN end_char="2519" id="token-21-11" morph="none" pos="word" start_char="2516">poco</TOKEN>
<TOKEN end_char="2524" id="token-21-12" morph="none" pos="word" start_char="2521">pero</TOKEN>
<TOKEN end_char="2536" id="token-21-13" morph="none" pos="word" start_char="2526">manteniendo</TOKEN>
<TOKEN end_char="2542" id="token-21-14" morph="none" pos="word" start_char="2538">todas</TOKEN>
<TOKEN end_char="2548" id="token-21-15" morph="none" pos="word" start_char="2544">estas</TOKEN>
<TOKEN end_char="2559" id="token-21-16" morph="none" pos="word" start_char="2550">cuestiones</TOKEN>
<TOKEN end_char="2562" id="token-21-17" morph="none" pos="word" start_char="2561">de</TOKEN>
<TOKEN end_char="2570" id="token-21-18" morph="none" pos="word" start_char="2564">higiene</TOKEN>
<TOKEN end_char="2571" id="token-21-19" morph="none" pos="punct" start_char="2571">,</TOKEN>
<TOKEN end_char="2581" id="token-21-20" morph="none" pos="word" start_char="2573">distancia</TOKEN>
<TOKEN end_char="2588" id="token-21-21" morph="none" pos="word" start_char="2583">social</TOKEN>
<TOKEN end_char="2590" id="token-21-22" morph="none" pos="word" start_char="2590">y</TOKEN>
<TOKEN end_char="2601" id="token-21-23" morph="none" pos="word" start_char="2592">mascarilla</TOKEN>
<TOKEN end_char="2602" id="token-21-24" morph="none" pos="punct" start_char="2602">.</TOKEN>
<TRANSLATED_TEXT>That tells us that we can go back to our lives little by little but keep all these issues of hygiene, social distance and masks.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2753" id="segment-22" start_char="2605">
<ORIGINAL_TEXT>En cuanto a la cuestión de que actualmente, al recoger las muestras, se encuentra menos carga viral es porque se está detectando antes la enfermedad.</ORIGINAL_TEXT>
<TOKEN end_char="2606" id="token-22-0" morph="none" pos="word" start_char="2605">En</TOKEN>
<TOKEN end_char="2613" id="token-22-1" morph="none" pos="word" start_char="2608">cuanto</TOKEN>
<TOKEN end_char="2615" id="token-22-2" morph="none" pos="word" start_char="2615">a</TOKEN>
<TOKEN end_char="2618" id="token-22-3" morph="none" pos="word" start_char="2617">la</TOKEN>
<TOKEN end_char="2627" id="token-22-4" morph="none" pos="word" start_char="2620">cuestión</TOKEN>
<TOKEN end_char="2630" id="token-22-5" morph="none" pos="word" start_char="2629">de</TOKEN>
<TOKEN end_char="2634" id="token-22-6" morph="none" pos="word" start_char="2632">que</TOKEN>
<TOKEN end_char="2646" id="token-22-7" morph="none" pos="word" start_char="2636">actualmente</TOKEN>
<TOKEN end_char="2647" id="token-22-8" morph="none" pos="punct" start_char="2647">,</TOKEN>
<TOKEN end_char="2650" id="token-22-9" morph="none" pos="word" start_char="2649">al</TOKEN>
<TOKEN end_char="2658" id="token-22-10" morph="none" pos="word" start_char="2652">recoger</TOKEN>
<TOKEN end_char="2662" id="token-22-11" morph="none" pos="word" start_char="2660">las</TOKEN>
<TOKEN end_char="2671" id="token-22-12" morph="none" pos="word" start_char="2664">muestras</TOKEN>
<TOKEN end_char="2672" id="token-22-13" morph="none" pos="punct" start_char="2672">,</TOKEN>
<TOKEN end_char="2675" id="token-22-14" morph="none" pos="word" start_char="2674">se</TOKEN>
<TOKEN end_char="2685" id="token-22-15" morph="none" pos="word" start_char="2677">encuentra</TOKEN>
<TOKEN end_char="2691" id="token-22-16" morph="none" pos="word" start_char="2687">menos</TOKEN>
<TOKEN end_char="2697" id="token-22-17" morph="none" pos="word" start_char="2693">carga</TOKEN>
<TOKEN end_char="2703" id="token-22-18" morph="none" pos="word" start_char="2699">viral</TOKEN>
<TOKEN end_char="2706" id="token-22-19" morph="none" pos="word" start_char="2705">es</TOKEN>
<TOKEN end_char="2713" id="token-22-20" morph="none" pos="word" start_char="2708">porque</TOKEN>
<TOKEN end_char="2716" id="token-22-21" morph="none" pos="word" start_char="2715">se</TOKEN>
<TOKEN end_char="2721" id="token-22-22" morph="none" pos="word" start_char="2718">está</TOKEN>
<TOKEN end_char="2732" id="token-22-23" morph="none" pos="word" start_char="2723">detectando</TOKEN>
<TOKEN end_char="2738" id="token-22-24" morph="none" pos="word" start_char="2734">antes</TOKEN>
<TOKEN end_char="2741" id="token-22-25" morph="none" pos="word" start_char="2740">la</TOKEN>
<TOKEN end_char="2752" id="token-22-26" morph="none" pos="word" start_char="2743">enfermedad</TOKEN>
<TOKEN end_char="2753" id="token-22-27" morph="none" pos="punct" start_char="2753">.</TOKEN>
<TRANSLATED_TEXT>As for the question that, at present, when samples are collected, there is less viral load because the disease is being detected earlier.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2913" id="segment-23" start_char="2755">
<ORIGINAL_TEXT>Ahora se están haciendo pruebas a los asintomáticos a los que antes ni se veía porque la prioridad era salvar a los cientos de personas que estaban en las UCI.</ORIGINAL_TEXT>
<TOKEN end_char="2759" id="token-23-0" morph="none" pos="word" start_char="2755">Ahora</TOKEN>
<TOKEN end_char="2762" id="token-23-1" morph="none" pos="word" start_char="2761">se</TOKEN>
<TOKEN end_char="2768" id="token-23-2" morph="none" pos="word" start_char="2764">están</TOKEN>
<TOKEN end_char="2777" id="token-23-3" morph="none" pos="word" start_char="2770">haciendo</TOKEN>
<TOKEN end_char="2785" id="token-23-4" morph="none" pos="word" start_char="2779">pruebas</TOKEN>
<TOKEN end_char="2787" id="token-23-5" morph="none" pos="word" start_char="2787">a</TOKEN>
<TOKEN end_char="2791" id="token-23-6" morph="none" pos="word" start_char="2789">los</TOKEN>
<TOKEN end_char="2805" id="token-23-7" morph="none" pos="word" start_char="2793">asintomáticos</TOKEN>
<TOKEN end_char="2807" id="token-23-8" morph="none" pos="word" start_char="2807">a</TOKEN>
<TOKEN end_char="2811" id="token-23-9" morph="none" pos="word" start_char="2809">los</TOKEN>
<TOKEN end_char="2815" id="token-23-10" morph="none" pos="word" start_char="2813">que</TOKEN>
<TOKEN end_char="2821" id="token-23-11" morph="none" pos="word" start_char="2817">antes</TOKEN>
<TOKEN end_char="2824" id="token-23-12" morph="none" pos="word" start_char="2823">ni</TOKEN>
<TOKEN end_char="2827" id="token-23-13" morph="none" pos="word" start_char="2826">se</TOKEN>
<TOKEN end_char="2832" id="token-23-14" morph="none" pos="word" start_char="2829">veía</TOKEN>
<TOKEN end_char="2839" id="token-23-15" morph="none" pos="word" start_char="2834">porque</TOKEN>
<TOKEN end_char="2842" id="token-23-16" morph="none" pos="word" start_char="2841">la</TOKEN>
<TOKEN end_char="2852" id="token-23-17" morph="none" pos="word" start_char="2844">prioridad</TOKEN>
<TOKEN end_char="2856" id="token-23-18" morph="none" pos="word" start_char="2854">era</TOKEN>
<TOKEN end_char="2863" id="token-23-19" morph="none" pos="word" start_char="2858">salvar</TOKEN>
<TOKEN end_char="2865" id="token-23-20" morph="none" pos="word" start_char="2865">a</TOKEN>
<TOKEN end_char="2869" id="token-23-21" morph="none" pos="word" start_char="2867">los</TOKEN>
<TOKEN end_char="2877" id="token-23-22" morph="none" pos="word" start_char="2871">cientos</TOKEN>
<TOKEN end_char="2880" id="token-23-23" morph="none" pos="word" start_char="2879">de</TOKEN>
<TOKEN end_char="2889" id="token-23-24" morph="none" pos="word" start_char="2882">personas</TOKEN>
<TOKEN end_char="2893" id="token-23-25" morph="none" pos="word" start_char="2891">que</TOKEN>
<TOKEN end_char="2901" id="token-23-26" morph="none" pos="word" start_char="2895">estaban</TOKEN>
<TOKEN end_char="2904" id="token-23-27" morph="none" pos="word" start_char="2903">en</TOKEN>
<TOKEN end_char="2908" id="token-23-28" morph="none" pos="word" start_char="2906">las</TOKEN>
<TOKEN end_char="2912" id="token-23-29" morph="none" pos="word" start_char="2910">UCI</TOKEN>
<TOKEN end_char="2913" id="token-23-30" morph="none" pos="punct" start_char="2913">.</TOKEN>
<TRANSLATED_TEXT>Now they 're testing asymptomatic patients who were never seen before because the priority was to save the hundreds of people who were in the ICU.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3243" id="segment-24" start_char="2915">
<ORIGINAL_TEXT>Ahora que ya, por suerte, no tenemos esa prioridad, se han implementado detecciones epidemiológicas y trazabilidad de los contagios que está detectando a los asintomáticos y a los sintomáticos en etapas tempranas y, en ambos casos, la carga vírica es menor que la de una persona que está ya con la enfermedad en un estadio grave.</ORIGINAL_TEXT>
<TOKEN end_char="2919" id="token-24-0" morph="none" pos="word" start_char="2915">Ahora</TOKEN>
<TOKEN end_char="2923" id="token-24-1" morph="none" pos="word" start_char="2921">que</TOKEN>
<TOKEN end_char="2926" id="token-24-2" morph="none" pos="word" start_char="2925">ya</TOKEN>
<TOKEN end_char="2927" id="token-24-3" morph="none" pos="punct" start_char="2927">,</TOKEN>
<TOKEN end_char="2931" id="token-24-4" morph="none" pos="word" start_char="2929">por</TOKEN>
<TOKEN end_char="2938" id="token-24-5" morph="none" pos="word" start_char="2933">suerte</TOKEN>
<TOKEN end_char="2939" id="token-24-6" morph="none" pos="punct" start_char="2939">,</TOKEN>
<TOKEN end_char="2942" id="token-24-7" morph="none" pos="word" start_char="2941">no</TOKEN>
<TOKEN end_char="2950" id="token-24-8" morph="none" pos="word" start_char="2944">tenemos</TOKEN>
<TOKEN end_char="2954" id="token-24-9" morph="none" pos="word" start_char="2952">esa</TOKEN>
<TOKEN end_char="2964" id="token-24-10" morph="none" pos="word" start_char="2956">prioridad</TOKEN>
<TOKEN end_char="2965" id="token-24-11" morph="none" pos="punct" start_char="2965">,</TOKEN>
<TOKEN end_char="2968" id="token-24-12" morph="none" pos="word" start_char="2967">se</TOKEN>
<TOKEN end_char="2972" id="token-24-13" morph="none" pos="word" start_char="2970">han</TOKEN>
<TOKEN end_char="2985" id="token-24-14" morph="none" pos="word" start_char="2974">implementado</TOKEN>
<TOKEN end_char="2997" id="token-24-15" morph="none" pos="word" start_char="2987">detecciones</TOKEN>
<TOKEN end_char="3013" id="token-24-16" morph="none" pos="word" start_char="2999">epidemiológicas</TOKEN>
<TOKEN end_char="3015" id="token-24-17" morph="none" pos="word" start_char="3015">y</TOKEN>
<TOKEN end_char="3028" id="token-24-18" morph="none" pos="word" start_char="3017">trazabilidad</TOKEN>
<TOKEN end_char="3031" id="token-24-19" morph="none" pos="word" start_char="3030">de</TOKEN>
<TOKEN end_char="3035" id="token-24-20" morph="none" pos="word" start_char="3033">los</TOKEN>
<TOKEN end_char="3045" id="token-24-21" morph="none" pos="word" start_char="3037">contagios</TOKEN>
<TOKEN end_char="3049" id="token-24-22" morph="none" pos="word" start_char="3047">que</TOKEN>
<TOKEN end_char="3054" id="token-24-23" morph="none" pos="word" start_char="3051">está</TOKEN>
<TOKEN end_char="3065" id="token-24-24" morph="none" pos="word" start_char="3056">detectando</TOKEN>
<TOKEN end_char="3067" id="token-24-25" morph="none" pos="word" start_char="3067">a</TOKEN>
<TOKEN end_char="3071" id="token-24-26" morph="none" pos="word" start_char="3069">los</TOKEN>
<TOKEN end_char="3085" id="token-24-27" morph="none" pos="word" start_char="3073">asintomáticos</TOKEN>
<TOKEN end_char="3087" id="token-24-28" morph="none" pos="word" start_char="3087">y</TOKEN>
<TOKEN end_char="3089" id="token-24-29" morph="none" pos="word" start_char="3089">a</TOKEN>
<TOKEN end_char="3093" id="token-24-30" morph="none" pos="word" start_char="3091">los</TOKEN>
<TOKEN end_char="3106" id="token-24-31" morph="none" pos="word" start_char="3095">sintomáticos</TOKEN>
<TOKEN end_char="3109" id="token-24-32" morph="none" pos="word" start_char="3108">en</TOKEN>
<TOKEN end_char="3116" id="token-24-33" morph="none" pos="word" start_char="3111">etapas</TOKEN>
<TOKEN end_char="3126" id="token-24-34" morph="none" pos="word" start_char="3118">tempranas</TOKEN>
<TOKEN end_char="3128" id="token-24-35" morph="none" pos="word" start_char="3128">y</TOKEN>
<TOKEN end_char="3129" id="token-24-36" morph="none" pos="punct" start_char="3129">,</TOKEN>
<TOKEN end_char="3132" id="token-24-37" morph="none" pos="word" start_char="3131">en</TOKEN>
<TOKEN end_char="3138" id="token-24-38" morph="none" pos="word" start_char="3134">ambos</TOKEN>
<TOKEN end_char="3144" id="token-24-39" morph="none" pos="word" start_char="3140">casos</TOKEN>
<TOKEN end_char="3145" id="token-24-40" morph="none" pos="punct" start_char="3145">,</TOKEN>
<TOKEN end_char="3148" id="token-24-41" morph="none" pos="word" start_char="3147">la</TOKEN>
<TOKEN end_char="3154" id="token-24-42" morph="none" pos="word" start_char="3150">carga</TOKEN>
<TOKEN end_char="3161" id="token-24-43" morph="none" pos="word" start_char="3156">vírica</TOKEN>
<TOKEN end_char="3164" id="token-24-44" morph="none" pos="word" start_char="3163">es</TOKEN>
<TOKEN end_char="3170" id="token-24-45" morph="none" pos="word" start_char="3166">menor</TOKEN>
<TOKEN end_char="3174" id="token-24-46" morph="none" pos="word" start_char="3172">que</TOKEN>
<TOKEN end_char="3177" id="token-24-47" morph="none" pos="word" start_char="3176">la</TOKEN>
<TOKEN end_char="3180" id="token-24-48" morph="none" pos="word" start_char="3179">de</TOKEN>
<TOKEN end_char="3184" id="token-24-49" morph="none" pos="word" start_char="3182">una</TOKEN>
<TOKEN end_char="3192" id="token-24-50" morph="none" pos="word" start_char="3186">persona</TOKEN>
<TOKEN end_char="3196" id="token-24-51" morph="none" pos="word" start_char="3194">que</TOKEN>
<TOKEN end_char="3201" id="token-24-52" morph="none" pos="word" start_char="3198">está</TOKEN>
<TOKEN end_char="3204" id="token-24-53" morph="none" pos="word" start_char="3203">ya</TOKEN>
<TOKEN end_char="3208" id="token-24-54" morph="none" pos="word" start_char="3206">con</TOKEN>
<TOKEN end_char="3211" id="token-24-55" morph="none" pos="word" start_char="3210">la</TOKEN>
<TOKEN end_char="3222" id="token-24-56" morph="none" pos="word" start_char="3213">enfermedad</TOKEN>
<TOKEN end_char="3225" id="token-24-57" morph="none" pos="word" start_char="3224">en</TOKEN>
<TOKEN end_char="3228" id="token-24-58" morph="none" pos="word" start_char="3227">un</TOKEN>
<TOKEN end_char="3236" id="token-24-59" morph="none" pos="word" start_char="3230">estadio</TOKEN>
<TOKEN end_char="3242" id="token-24-60" morph="none" pos="word" start_char="3238">grave</TOKEN>
<TOKEN end_char="3243" id="token-24-61" morph="none" pos="punct" start_char="3243">.</TOKEN>
<TRANSLATED_TEXT>Now that, fortunately, we no longer have that priority, epidemiological detections and traceability of the infections that are detecting asymptomatic and symptomatic early stages have been implemented and, in both cases, the viral load is less than that of a person who is already with the disease in a serious stage.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3331" id="segment-25" start_char="3246">
<ORIGINAL_TEXT>También hay quien está diciendo que el virus ha mutado y que ahora es menos virulento.</ORIGINAL_TEXT>
<TOKEN end_char="3252" id="token-25-0" morph="none" pos="word" start_char="3246">También</TOKEN>
<TOKEN end_char="3256" id="token-25-1" morph="none" pos="word" start_char="3254">hay</TOKEN>
<TOKEN end_char="3262" id="token-25-2" morph="none" pos="word" start_char="3258">quien</TOKEN>
<TOKEN end_char="3267" id="token-25-3" morph="none" pos="word" start_char="3264">está</TOKEN>
<TOKEN end_char="3276" id="token-25-4" morph="none" pos="word" start_char="3269">diciendo</TOKEN>
<TOKEN end_char="3280" id="token-25-5" morph="none" pos="word" start_char="3278">que</TOKEN>
<TOKEN end_char="3283" id="token-25-6" morph="none" pos="word" start_char="3282">el</TOKEN>
<TOKEN end_char="3289" id="token-25-7" morph="none" pos="word" start_char="3285">virus</TOKEN>
<TOKEN end_char="3292" id="token-25-8" morph="none" pos="word" start_char="3291">ha</TOKEN>
<TOKEN end_char="3299" id="token-25-9" morph="none" pos="word" start_char="3294">mutado</TOKEN>
<TOKEN end_char="3301" id="token-25-10" morph="none" pos="word" start_char="3301">y</TOKEN>
<TOKEN end_char="3305" id="token-25-11" morph="none" pos="word" start_char="3303">que</TOKEN>
<TOKEN end_char="3311" id="token-25-12" morph="none" pos="word" start_char="3307">ahora</TOKEN>
<TOKEN end_char="3314" id="token-25-13" morph="none" pos="word" start_char="3313">es</TOKEN>
<TOKEN end_char="3320" id="token-25-14" morph="none" pos="word" start_char="3316">menos</TOKEN>
<TOKEN end_char="3330" id="token-25-15" morph="none" pos="word" start_char="3322">virulento</TOKEN>
<TOKEN end_char="3331" id="token-25-16" morph="none" pos="punct" start_char="3331">.</TOKEN>
<TRANSLATED_TEXT>There are also those who are saying that the virus has mutated and is now less virulent.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3491" id="segment-26" start_char="3333">
<ORIGINAL_TEXT>Ahora mismo se están secuenciado una gran cantidad de coronavirus en todo el mundo y se está viendo que el virus está cambiando, y muta porque es un virus ARN.</ORIGINAL_TEXT>
<TOKEN end_char="3337" id="token-26-0" morph="none" pos="word" start_char="3333">Ahora</TOKEN>
<TOKEN end_char="3343" id="token-26-1" morph="none" pos="word" start_char="3339">mismo</TOKEN>
<TOKEN end_char="3346" id="token-26-2" morph="none" pos="word" start_char="3345">se</TOKEN>
<TOKEN end_char="3352" id="token-26-3" morph="none" pos="word" start_char="3348">están</TOKEN>
<TOKEN end_char="3364" id="token-26-4" morph="none" pos="word" start_char="3354">secuenciado</TOKEN>
<TOKEN end_char="3368" id="token-26-5" morph="none" pos="word" start_char="3366">una</TOKEN>
<TOKEN end_char="3373" id="token-26-6" morph="none" pos="word" start_char="3370">gran</TOKEN>
<TOKEN end_char="3382" id="token-26-7" morph="none" pos="word" start_char="3375">cantidad</TOKEN>
<TOKEN end_char="3385" id="token-26-8" morph="none" pos="word" start_char="3384">de</TOKEN>
<TOKEN end_char="3397" id="token-26-9" morph="none" pos="word" start_char="3387">coronavirus</TOKEN>
<TOKEN end_char="3400" id="token-26-10" morph="none" pos="word" start_char="3399">en</TOKEN>
<TOKEN end_char="3405" id="token-26-11" morph="none" pos="word" start_char="3402">todo</TOKEN>
<TOKEN end_char="3408" id="token-26-12" morph="none" pos="word" start_char="3407">el</TOKEN>
<TOKEN end_char="3414" id="token-26-13" morph="none" pos="word" start_char="3410">mundo</TOKEN>
<TOKEN end_char="3416" id="token-26-14" morph="none" pos="word" start_char="3416">y</TOKEN>
<TOKEN end_char="3419" id="token-26-15" morph="none" pos="word" start_char="3418">se</TOKEN>
<TOKEN end_char="3424" id="token-26-16" morph="none" pos="word" start_char="3421">está</TOKEN>
<TOKEN end_char="3431" id="token-26-17" morph="none" pos="word" start_char="3426">viendo</TOKEN>
<TOKEN end_char="3435" id="token-26-18" morph="none" pos="word" start_char="3433">que</TOKEN>
<TOKEN end_char="3438" id="token-26-19" morph="none" pos="word" start_char="3437">el</TOKEN>
<TOKEN end_char="3444" id="token-26-20" morph="none" pos="word" start_char="3440">virus</TOKEN>
<TOKEN end_char="3449" id="token-26-21" morph="none" pos="word" start_char="3446">está</TOKEN>
<TOKEN end_char="3459" id="token-26-22" morph="none" pos="word" start_char="3451">cambiando</TOKEN>
<TOKEN end_char="3460" id="token-26-23" morph="none" pos="punct" start_char="3460">,</TOKEN>
<TOKEN end_char="3462" id="token-26-24" morph="none" pos="word" start_char="3462">y</TOKEN>
<TOKEN end_char="3467" id="token-26-25" morph="none" pos="word" start_char="3464">muta</TOKEN>
<TOKEN end_char="3474" id="token-26-26" morph="none" pos="word" start_char="3469">porque</TOKEN>
<TOKEN end_char="3477" id="token-26-27" morph="none" pos="word" start_char="3476">es</TOKEN>
<TOKEN end_char="3480" id="token-26-28" morph="none" pos="word" start_char="3479">un</TOKEN>
<TOKEN end_char="3486" id="token-26-29" morph="none" pos="word" start_char="3482">virus</TOKEN>
<TOKEN end_char="3490" id="token-26-30" morph="none" pos="word" start_char="3488">ARN</TOKEN>
<TOKEN end_char="3491" id="token-26-31" morph="none" pos="punct" start_char="3491">.</TOKEN>
<TRANSLATED_TEXT>Right now, a lot of coronaviruses are being sequenced around the world and you 're seeing the virus changing, and mutating because it' s an RNA virus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3661" id="segment-27" start_char="3493">
<ORIGINAL_TEXT>Pero, hasta el momento, yo no he visto ningún dato ni ninguna secuencia que esté asociada a baja virulencia con datos comprobados; hay hipótesis, pero todavía es pronto.</ORIGINAL_TEXT>
<TOKEN end_char="3496" id="token-27-0" morph="none" pos="word" start_char="3493">Pero</TOKEN>
<TOKEN end_char="3497" id="token-27-1" morph="none" pos="punct" start_char="3497">,</TOKEN>
<TOKEN end_char="3503" id="token-27-2" morph="none" pos="word" start_char="3499">hasta</TOKEN>
<TOKEN end_char="3506" id="token-27-3" morph="none" pos="word" start_char="3505">el</TOKEN>
<TOKEN end_char="3514" id="token-27-4" morph="none" pos="word" start_char="3508">momento</TOKEN>
<TOKEN end_char="3515" id="token-27-5" morph="none" pos="punct" start_char="3515">,</TOKEN>
<TOKEN end_char="3518" id="token-27-6" morph="none" pos="word" start_char="3517">yo</TOKEN>
<TOKEN end_char="3521" id="token-27-7" morph="none" pos="word" start_char="3520">no</TOKEN>
<TOKEN end_char="3524" id="token-27-8" morph="none" pos="word" start_char="3523">he</TOKEN>
<TOKEN end_char="3530" id="token-27-9" morph="none" pos="word" start_char="3526">visto</TOKEN>
<TOKEN end_char="3537" id="token-27-10" morph="none" pos="word" start_char="3532">ningún</TOKEN>
<TOKEN end_char="3542" id="token-27-11" morph="none" pos="word" start_char="3539">dato</TOKEN>
<TOKEN end_char="3545" id="token-27-12" morph="none" pos="word" start_char="3544">ni</TOKEN>
<TOKEN end_char="3553" id="token-27-13" morph="none" pos="word" start_char="3547">ninguna</TOKEN>
<TOKEN end_char="3563" id="token-27-14" morph="none" pos="word" start_char="3555">secuencia</TOKEN>
<TOKEN end_char="3567" id="token-27-15" morph="none" pos="word" start_char="3565">que</TOKEN>
<TOKEN end_char="3572" id="token-27-16" morph="none" pos="word" start_char="3569">esté</TOKEN>
<TOKEN end_char="3581" id="token-27-17" morph="none" pos="word" start_char="3574">asociada</TOKEN>
<TOKEN end_char="3583" id="token-27-18" morph="none" pos="word" start_char="3583">a</TOKEN>
<TOKEN end_char="3588" id="token-27-19" morph="none" pos="word" start_char="3585">baja</TOKEN>
<TOKEN end_char="3599" id="token-27-20" morph="none" pos="word" start_char="3590">virulencia</TOKEN>
<TOKEN end_char="3603" id="token-27-21" morph="none" pos="word" start_char="3601">con</TOKEN>
<TOKEN end_char="3609" id="token-27-22" morph="none" pos="word" start_char="3605">datos</TOKEN>
<TOKEN end_char="3621" id="token-27-23" morph="none" pos="word" start_char="3611">comprobados</TOKEN>
<TOKEN end_char="3622" id="token-27-24" morph="none" pos="punct" start_char="3622">;</TOKEN>
<TOKEN end_char="3626" id="token-27-25" morph="none" pos="word" start_char="3624">hay</TOKEN>
<TOKEN end_char="3636" id="token-27-26" morph="none" pos="word" start_char="3628">hipótesis</TOKEN>
<TOKEN end_char="3637" id="token-27-27" morph="none" pos="punct" start_char="3637">,</TOKEN>
<TOKEN end_char="3642" id="token-27-28" morph="none" pos="word" start_char="3639">pero</TOKEN>
<TOKEN end_char="3650" id="token-27-29" morph="none" pos="word" start_char="3644">todavía</TOKEN>
<TOKEN end_char="3653" id="token-27-30" morph="none" pos="word" start_char="3652">es</TOKEN>
<TOKEN end_char="3660" id="token-27-31" morph="none" pos="word" start_char="3655">pronto</TOKEN>
<TOKEN end_char="3661" id="token-27-32" morph="none" pos="punct" start_char="3661">.</TOKEN>
<TRANSLATED_TEXT>But, so far, I have not seen any data or sequence that is associated with low virulence with proven data; there are hypotheses, but it is still early.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3700" id="segment-28" start_char="3663">
<ORIGINAL_TEXT>Los científicos no tenemos esos datos.</ORIGINAL_TEXT>
<TOKEN end_char="3665" id="token-28-0" morph="none" pos="word" start_char="3663">Los</TOKEN>
<TOKEN end_char="3677" id="token-28-1" morph="none" pos="word" start_char="3667">científicos</TOKEN>
<TOKEN end_char="3680" id="token-28-2" morph="none" pos="word" start_char="3679">no</TOKEN>
<TOKEN end_char="3688" id="token-28-3" morph="none" pos="word" start_char="3682">tenemos</TOKEN>
<TOKEN end_char="3693" id="token-28-4" morph="none" pos="word" start_char="3690">esos</TOKEN>
<TOKEN end_char="3699" id="token-28-5" morph="none" pos="word" start_char="3695">datos</TOKEN>
<TOKEN end_char="3700" id="token-28-6" morph="none" pos="punct" start_char="3700">.</TOKEN>
<TRANSLATED_TEXT>Scientists don 't have that data.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3799" id="segment-29" start_char="3702">
<ORIGINAL_TEXT>Puede ser una percepción de los clínicos pero hasta que no tengamos los datos no se puede afirmar.</ORIGINAL_TEXT>
<TOKEN end_char="3706" id="token-29-0" morph="none" pos="word" start_char="3702">Puede</TOKEN>
<TOKEN end_char="3710" id="token-29-1" morph="none" pos="word" start_char="3708">ser</TOKEN>
<TOKEN end_char="3714" id="token-29-2" morph="none" pos="word" start_char="3712">una</TOKEN>
<TOKEN end_char="3725" id="token-29-3" morph="none" pos="word" start_char="3716">percepción</TOKEN>
<TOKEN end_char="3728" id="token-29-4" morph="none" pos="word" start_char="3727">de</TOKEN>
<TOKEN end_char="3732" id="token-29-5" morph="none" pos="word" start_char="3730">los</TOKEN>
<TOKEN end_char="3741" id="token-29-6" morph="none" pos="word" start_char="3734">clínicos</TOKEN>
<TOKEN end_char="3746" id="token-29-7" morph="none" pos="word" start_char="3743">pero</TOKEN>
<TOKEN end_char="3752" id="token-29-8" morph="none" pos="word" start_char="3748">hasta</TOKEN>
<TOKEN end_char="3756" id="token-29-9" morph="none" pos="word" start_char="3754">que</TOKEN>
<TOKEN end_char="3759" id="token-29-10" morph="none" pos="word" start_char="3758">no</TOKEN>
<TOKEN end_char="3768" id="token-29-11" morph="none" pos="word" start_char="3761">tengamos</TOKEN>
<TOKEN end_char="3772" id="token-29-12" morph="none" pos="word" start_char="3770">los</TOKEN>
<TOKEN end_char="3778" id="token-29-13" morph="none" pos="word" start_char="3774">datos</TOKEN>
<TOKEN end_char="3781" id="token-29-14" morph="none" pos="word" start_char="3780">no</TOKEN>
<TOKEN end_char="3784" id="token-29-15" morph="none" pos="word" start_char="3783">se</TOKEN>
<TOKEN end_char="3790" id="token-29-16" morph="none" pos="word" start_char="3786">puede</TOKEN>
<TOKEN end_char="3798" id="token-29-17" morph="none" pos="word" start_char="3792">afirmar</TOKEN>
<TOKEN end_char="3799" id="token-29-18" morph="none" pos="punct" start_char="3799">.</TOKEN>
<TRANSLATED_TEXT>It may be a perception of clinicians, but until we have the data, it cannot be asserted.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4007" id="segment-30" start_char="3801">
<ORIGINAL_TEXT>Habiendo aclarado este punto, los virus en general, cuando saltan a un nuevo hospedador, como en este caso que el SARS-CoV-2 (que ha saltado de un animal a las personas) hacen todo lo posible por extenderse.</ORIGINAL_TEXT>
<TOKEN end_char="3808" id="token-30-0" morph="none" pos="word" start_char="3801">Habiendo</TOKEN>
<TOKEN end_char="3817" id="token-30-1" morph="none" pos="word" start_char="3810">aclarado</TOKEN>
<TOKEN end_char="3822" id="token-30-2" morph="none" pos="word" start_char="3819">este</TOKEN>
<TOKEN end_char="3828" id="token-30-3" morph="none" pos="word" start_char="3824">punto</TOKEN>
<TOKEN end_char="3829" id="token-30-4" morph="none" pos="punct" start_char="3829">,</TOKEN>
<TOKEN end_char="3833" id="token-30-5" morph="none" pos="word" start_char="3831">los</TOKEN>
<TOKEN end_char="3839" id="token-30-6" morph="none" pos="word" start_char="3835">virus</TOKEN>
<TOKEN end_char="3842" id="token-30-7" morph="none" pos="word" start_char="3841">en</TOKEN>
<TOKEN end_char="3850" id="token-30-8" morph="none" pos="word" start_char="3844">general</TOKEN>
<TOKEN end_char="3851" id="token-30-9" morph="none" pos="punct" start_char="3851">,</TOKEN>
<TOKEN end_char="3858" id="token-30-10" morph="none" pos="word" start_char="3853">cuando</TOKEN>
<TOKEN end_char="3865" id="token-30-11" morph="none" pos="word" start_char="3860">saltan</TOKEN>
<TOKEN end_char="3867" id="token-30-12" morph="none" pos="word" start_char="3867">a</TOKEN>
<TOKEN end_char="3870" id="token-30-13" morph="none" pos="word" start_char="3869">un</TOKEN>
<TOKEN end_char="3876" id="token-30-14" morph="none" pos="word" start_char="3872">nuevo</TOKEN>
<TOKEN end_char="3887" id="token-30-15" morph="none" pos="word" start_char="3878">hospedador</TOKEN>
<TOKEN end_char="3888" id="token-30-16" morph="none" pos="punct" start_char="3888">,</TOKEN>
<TOKEN end_char="3893" id="token-30-17" morph="none" pos="word" start_char="3890">como</TOKEN>
<TOKEN end_char="3896" id="token-30-18" morph="none" pos="word" start_char="3895">en</TOKEN>
<TOKEN end_char="3901" id="token-30-19" morph="none" pos="word" start_char="3898">este</TOKEN>
<TOKEN end_char="3906" id="token-30-20" morph="none" pos="word" start_char="3903">caso</TOKEN>
<TOKEN end_char="3910" id="token-30-21" morph="none" pos="word" start_char="3908">que</TOKEN>
<TOKEN end_char="3913" id="token-30-22" morph="none" pos="word" start_char="3912">el</TOKEN>
<TOKEN end_char="3924" id="token-30-23" morph="none" pos="unknown" start_char="3915">SARS-CoV-2</TOKEN>
<TOKEN end_char="3926" id="token-30-24" morph="none" pos="punct" start_char="3926">(</TOKEN>
<TOKEN end_char="3929" id="token-30-25" morph="none" pos="word" start_char="3927">que</TOKEN>
<TOKEN end_char="3932" id="token-30-26" morph="none" pos="word" start_char="3931">ha</TOKEN>
<TOKEN end_char="3940" id="token-30-27" morph="none" pos="word" start_char="3934">saltado</TOKEN>
<TOKEN end_char="3943" id="token-30-28" morph="none" pos="word" start_char="3942">de</TOKEN>
<TOKEN end_char="3946" id="token-30-29" morph="none" pos="word" start_char="3945">un</TOKEN>
<TOKEN end_char="3953" id="token-30-30" morph="none" pos="word" start_char="3948">animal</TOKEN>
<TOKEN end_char="3955" id="token-30-31" morph="none" pos="word" start_char="3955">a</TOKEN>
<TOKEN end_char="3959" id="token-30-32" morph="none" pos="word" start_char="3957">las</TOKEN>
<TOKEN end_char="3968" id="token-30-33" morph="none" pos="word" start_char="3961">personas</TOKEN>
<TOKEN end_char="3969" id="token-30-34" morph="none" pos="punct" start_char="3969">)</TOKEN>
<TOKEN end_char="3975" id="token-30-35" morph="none" pos="word" start_char="3971">hacen</TOKEN>
<TOKEN end_char="3980" id="token-30-36" morph="none" pos="word" start_char="3977">todo</TOKEN>
<TOKEN end_char="3983" id="token-30-37" morph="none" pos="word" start_char="3982">lo</TOKEN>
<TOKEN end_char="3991" id="token-30-38" morph="none" pos="word" start_char="3985">posible</TOKEN>
<TOKEN end_char="3995" id="token-30-39" morph="none" pos="word" start_char="3993">por</TOKEN>
<TOKEN end_char="4006" id="token-30-40" morph="none" pos="word" start_char="3997">extenderse</TOKEN>
<TOKEN end_char="4007" id="token-30-41" morph="none" pos="punct" start_char="4007">.</TOKEN>
<TRANSLATED_TEXT>Having clarified this point, viruses in general, when they jump to a new host, as in this case SARS-CoV-2 (which has jumped from an animal to people) do everything possible to spread.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4181" id="segment-31" start_char="4009">
<ORIGINAL_TEXT>La mejor estrategia para un virus no es matar al hospedador sino que los hospedadores sigan vivos para poder multiplicarse y transmitirse de la manera más eficiente posible.</ORIGINAL_TEXT>
<TOKEN end_char="4010" id="token-31-0" morph="none" pos="word" start_char="4009">La</TOKEN>
<TOKEN end_char="4016" id="token-31-1" morph="none" pos="word" start_char="4012">mejor</TOKEN>
<TOKEN end_char="4027" id="token-31-2" morph="none" pos="word" start_char="4018">estrategia</TOKEN>
<TOKEN end_char="4032" id="token-31-3" morph="none" pos="word" start_char="4029">para</TOKEN>
<TOKEN end_char="4035" id="token-31-4" morph="none" pos="word" start_char="4034">un</TOKEN>
<TOKEN end_char="4041" id="token-31-5" morph="none" pos="word" start_char="4037">virus</TOKEN>
<TOKEN end_char="4044" id="token-31-6" morph="none" pos="word" start_char="4043">no</TOKEN>
<TOKEN end_char="4047" id="token-31-7" morph="none" pos="word" start_char="4046">es</TOKEN>
<TOKEN end_char="4053" id="token-31-8" morph="none" pos="word" start_char="4049">matar</TOKEN>
<TOKEN end_char="4056" id="token-31-9" morph="none" pos="word" start_char="4055">al</TOKEN>
<TOKEN end_char="4067" id="token-31-10" morph="none" pos="word" start_char="4058">hospedador</TOKEN>
<TOKEN end_char="4072" id="token-31-11" morph="none" pos="word" start_char="4069">sino</TOKEN>
<TOKEN end_char="4076" id="token-31-12" morph="none" pos="word" start_char="4074">que</TOKEN>
<TOKEN end_char="4080" id="token-31-13" morph="none" pos="word" start_char="4078">los</TOKEN>
<TOKEN end_char="4093" id="token-31-14" morph="none" pos="word" start_char="4082">hospedadores</TOKEN>
<TOKEN end_char="4099" id="token-31-15" morph="none" pos="word" start_char="4095">sigan</TOKEN>
<TOKEN end_char="4105" id="token-31-16" morph="none" pos="word" start_char="4101">vivos</TOKEN>
<TOKEN end_char="4110" id="token-31-17" morph="none" pos="word" start_char="4107">para</TOKEN>
<TOKEN end_char="4116" id="token-31-18" morph="none" pos="word" start_char="4112">poder</TOKEN>
<TOKEN end_char="4130" id="token-31-19" morph="none" pos="word" start_char="4118">multiplicarse</TOKEN>
<TOKEN end_char="4132" id="token-31-20" morph="none" pos="word" start_char="4132">y</TOKEN>
<TOKEN end_char="4145" id="token-31-21" morph="none" pos="word" start_char="4134">transmitirse</TOKEN>
<TOKEN end_char="4148" id="token-31-22" morph="none" pos="word" start_char="4147">de</TOKEN>
<TOKEN end_char="4151" id="token-31-23" morph="none" pos="word" start_char="4150">la</TOKEN>
<TOKEN end_char="4158" id="token-31-24" morph="none" pos="word" start_char="4153">manera</TOKEN>
<TOKEN end_char="4162" id="token-31-25" morph="none" pos="word" start_char="4160">más</TOKEN>
<TOKEN end_char="4172" id="token-31-26" morph="none" pos="word" start_char="4164">eficiente</TOKEN>
<TOKEN end_char="4180" id="token-31-27" morph="none" pos="word" start_char="4174">posible</TOKEN>
<TOKEN end_char="4181" id="token-31-28" morph="none" pos="punct" start_char="4181">.</TOKEN>
<TRANSLATED_TEXT>The best strategy for a virus is not to kill the host but to keep the hosts alive so that they can multiply and transmit as efficiently as possible.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4365" id="segment-32" start_char="4183">
<ORIGINAL_TEXT>Así que por lo general, en este tipo de saltos entre especies, ocurre que después de un tiempo las variantes menos agresivas se van seleccionando y son las que quedan en la población.</ORIGINAL_TEXT>
<TOKEN end_char="4185" id="token-32-0" morph="none" pos="word" start_char="4183">Así</TOKEN>
<TOKEN end_char="4189" id="token-32-1" morph="none" pos="word" start_char="4187">que</TOKEN>
<TOKEN end_char="4193" id="token-32-2" morph="none" pos="word" start_char="4191">por</TOKEN>
<TOKEN end_char="4196" id="token-32-3" morph="none" pos="word" start_char="4195">lo</TOKEN>
<TOKEN end_char="4204" id="token-32-4" morph="none" pos="word" start_char="4198">general</TOKEN>
<TOKEN end_char="4205" id="token-32-5" morph="none" pos="punct" start_char="4205">,</TOKEN>
<TOKEN end_char="4208" id="token-32-6" morph="none" pos="word" start_char="4207">en</TOKEN>
<TOKEN end_char="4213" id="token-32-7" morph="none" pos="word" start_char="4210">este</TOKEN>
<TOKEN end_char="4218" id="token-32-8" morph="none" pos="word" start_char="4215">tipo</TOKEN>
<TOKEN end_char="4221" id="token-32-9" morph="none" pos="word" start_char="4220">de</TOKEN>
<TOKEN end_char="4228" id="token-32-10" morph="none" pos="word" start_char="4223">saltos</TOKEN>
<TOKEN end_char="4234" id="token-32-11" morph="none" pos="word" start_char="4230">entre</TOKEN>
<TOKEN end_char="4243" id="token-32-12" morph="none" pos="word" start_char="4236">especies</TOKEN>
<TOKEN end_char="4244" id="token-32-13" morph="none" pos="punct" start_char="4244">,</TOKEN>
<TOKEN end_char="4251" id="token-32-14" morph="none" pos="word" start_char="4246">ocurre</TOKEN>
<TOKEN end_char="4255" id="token-32-15" morph="none" pos="word" start_char="4253">que</TOKEN>
<TOKEN end_char="4263" id="token-32-16" morph="none" pos="word" start_char="4257">después</TOKEN>
<TOKEN end_char="4266" id="token-32-17" morph="none" pos="word" start_char="4265">de</TOKEN>
<TOKEN end_char="4269" id="token-32-18" morph="none" pos="word" start_char="4268">un</TOKEN>
<TOKEN end_char="4276" id="token-32-19" morph="none" pos="word" start_char="4271">tiempo</TOKEN>
<TOKEN end_char="4280" id="token-32-20" morph="none" pos="word" start_char="4278">las</TOKEN>
<TOKEN end_char="4290" id="token-32-21" morph="none" pos="word" start_char="4282">variantes</TOKEN>
<TOKEN end_char="4296" id="token-32-22" morph="none" pos="word" start_char="4292">menos</TOKEN>
<TOKEN end_char="4306" id="token-32-23" morph="none" pos="word" start_char="4298">agresivas</TOKEN>
<TOKEN end_char="4309" id="token-32-24" morph="none" pos="word" start_char="4308">se</TOKEN>
<TOKEN end_char="4313" id="token-32-25" morph="none" pos="word" start_char="4311">van</TOKEN>
<TOKEN end_char="4327" id="token-32-26" morph="none" pos="word" start_char="4315">seleccionando</TOKEN>
<TOKEN end_char="4329" id="token-32-27" morph="none" pos="word" start_char="4329">y</TOKEN>
<TOKEN end_char="4333" id="token-32-28" morph="none" pos="word" start_char="4331">son</TOKEN>
<TOKEN end_char="4337" id="token-32-29" morph="none" pos="word" start_char="4335">las</TOKEN>
<TOKEN end_char="4341" id="token-32-30" morph="none" pos="word" start_char="4339">que</TOKEN>
<TOKEN end_char="4348" id="token-32-31" morph="none" pos="word" start_char="4343">quedan</TOKEN>
<TOKEN end_char="4351" id="token-32-32" morph="none" pos="word" start_char="4350">en</TOKEN>
<TOKEN end_char="4354" id="token-32-33" morph="none" pos="word" start_char="4353">la</TOKEN>
<TOKEN end_char="4364" id="token-32-34" morph="none" pos="word" start_char="4356">población</TOKEN>
<TOKEN end_char="4365" id="token-32-35" morph="none" pos="punct" start_char="4365">.</TOKEN>
<TRANSLATED_TEXT>So usually, in this type of jumping between species, it happens that after a while the less aggressive variants are selected and are the ones left in the population.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4435" id="segment-33" start_char="4367">
<ORIGINAL_TEXT>Sin embargo, aquí hemos hecho un corte, hemos dicho: "Confinamiento".</ORIGINAL_TEXT>
<TOKEN end_char="4369" id="token-33-0" morph="none" pos="word" start_char="4367">Sin</TOKEN>
<TOKEN end_char="4377" id="token-33-1" morph="none" pos="word" start_char="4371">embargo</TOKEN>
<TOKEN end_char="4378" id="token-33-2" morph="none" pos="punct" start_char="4378">,</TOKEN>
<TOKEN end_char="4383" id="token-33-3" morph="none" pos="word" start_char="4380">aquí</TOKEN>
<TOKEN end_char="4389" id="token-33-4" morph="none" pos="word" start_char="4385">hemos</TOKEN>
<TOKEN end_char="4395" id="token-33-5" morph="none" pos="word" start_char="4391">hecho</TOKEN>
<TOKEN end_char="4398" id="token-33-6" morph="none" pos="word" start_char="4397">un</TOKEN>
<TOKEN end_char="4404" id="token-33-7" morph="none" pos="word" start_char="4400">corte</TOKEN>
<TOKEN end_char="4405" id="token-33-8" morph="none" pos="punct" start_char="4405">,</TOKEN>
<TOKEN end_char="4411" id="token-33-9" morph="none" pos="word" start_char="4407">hemos</TOKEN>
<TOKEN end_char="4417" id="token-33-10" morph="none" pos="word" start_char="4413">dicho</TOKEN>
<TOKEN end_char="4418" id="token-33-11" morph="none" pos="punct" start_char="4418">:</TOKEN>
<TOKEN end_char="4420" id="token-33-12" morph="none" pos="punct" start_char="4420">"</TOKEN>
<TOKEN end_char="4433" id="token-33-13" morph="none" pos="word" start_char="4421">Confinamiento</TOKEN>
<TOKEN end_char="4435" id="token-33-14" morph="none" pos="punct" start_char="4434">".</TOKEN>
<TRANSLATED_TEXT>However, here we have made a cut, we have said: "Confession."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4525" id="segment-34" start_char="4437">
<ORIGINAL_TEXT>Eso ha salvado a mucha gente y ha impedido al virus circular como normalmente circularía.</ORIGINAL_TEXT>
<TOKEN end_char="4439" id="token-34-0" morph="none" pos="word" start_char="4437">Eso</TOKEN>
<TOKEN end_char="4442" id="token-34-1" morph="none" pos="word" start_char="4441">ha</TOKEN>
<TOKEN end_char="4450" id="token-34-2" morph="none" pos="word" start_char="4444">salvado</TOKEN>
<TOKEN end_char="4452" id="token-34-3" morph="none" pos="word" start_char="4452">a</TOKEN>
<TOKEN end_char="4458" id="token-34-4" morph="none" pos="word" start_char="4454">mucha</TOKEN>
<TOKEN end_char="4464" id="token-34-5" morph="none" pos="word" start_char="4460">gente</TOKEN>
<TOKEN end_char="4466" id="token-34-6" morph="none" pos="word" start_char="4466">y</TOKEN>
<TOKEN end_char="4469" id="token-34-7" morph="none" pos="word" start_char="4468">ha</TOKEN>
<TOKEN end_char="4478" id="token-34-8" morph="none" pos="word" start_char="4471">impedido</TOKEN>
<TOKEN end_char="4481" id="token-34-9" morph="none" pos="word" start_char="4480">al</TOKEN>
<TOKEN end_char="4487" id="token-34-10" morph="none" pos="word" start_char="4483">virus</TOKEN>
<TOKEN end_char="4496" id="token-34-11" morph="none" pos="word" start_char="4489">circular</TOKEN>
<TOKEN end_char="4501" id="token-34-12" morph="none" pos="word" start_char="4498">como</TOKEN>
<TOKEN end_char="4513" id="token-34-13" morph="none" pos="word" start_char="4503">normalmente</TOKEN>
<TOKEN end_char="4524" id="token-34-14" morph="none" pos="word" start_char="4515">circularía</TOKEN>
<TOKEN end_char="4525" id="token-34-15" morph="none" pos="punct" start_char="4525">.</TOKEN>
<TRANSLATED_TEXT>That has saved a lot of people and prevented the virus from circulating as it normally would.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4655" id="segment-35" start_char="4527">
<ORIGINAL_TEXT>Así que debido a ese estado de la situación, ahora no sabemos si el virus va a evolucionar seleccionando las variantes más leves.</ORIGINAL_TEXT>
<TOKEN end_char="4529" id="token-35-0" morph="none" pos="word" start_char="4527">Así</TOKEN>
<TOKEN end_char="4533" id="token-35-1" morph="none" pos="word" start_char="4531">que</TOKEN>
<TOKEN end_char="4540" id="token-35-2" morph="none" pos="word" start_char="4535">debido</TOKEN>
<TOKEN end_char="4542" id="token-35-3" morph="none" pos="word" start_char="4542">a</TOKEN>
<TOKEN end_char="4546" id="token-35-4" morph="none" pos="word" start_char="4544">ese</TOKEN>
<TOKEN end_char="4553" id="token-35-5" morph="none" pos="word" start_char="4548">estado</TOKEN>
<TOKEN end_char="4556" id="token-35-6" morph="none" pos="word" start_char="4555">de</TOKEN>
<TOKEN end_char="4559" id="token-35-7" morph="none" pos="word" start_char="4558">la</TOKEN>
<TOKEN end_char="4569" id="token-35-8" morph="none" pos="word" start_char="4561">situación</TOKEN>
<TOKEN end_char="4570" id="token-35-9" morph="none" pos="punct" start_char="4570">,</TOKEN>
<TOKEN end_char="4576" id="token-35-10" morph="none" pos="word" start_char="4572">ahora</TOKEN>
<TOKEN end_char="4579" id="token-35-11" morph="none" pos="word" start_char="4578">no</TOKEN>
<TOKEN end_char="4587" id="token-35-12" morph="none" pos="word" start_char="4581">sabemos</TOKEN>
<TOKEN end_char="4590" id="token-35-13" morph="none" pos="word" start_char="4589">si</TOKEN>
<TOKEN end_char="4593" id="token-35-14" morph="none" pos="word" start_char="4592">el</TOKEN>
<TOKEN end_char="4599" id="token-35-15" morph="none" pos="word" start_char="4595">virus</TOKEN>
<TOKEN end_char="4602" id="token-35-16" morph="none" pos="word" start_char="4601">va</TOKEN>
<TOKEN end_char="4604" id="token-35-17" morph="none" pos="word" start_char="4604">a</TOKEN>
<TOKEN end_char="4616" id="token-35-18" morph="none" pos="word" start_char="4606">evolucionar</TOKEN>
<TOKEN end_char="4630" id="token-35-19" morph="none" pos="word" start_char="4618">seleccionando</TOKEN>
<TOKEN end_char="4634" id="token-35-20" morph="none" pos="word" start_char="4632">las</TOKEN>
<TOKEN end_char="4644" id="token-35-21" morph="none" pos="word" start_char="4636">variantes</TOKEN>
<TOKEN end_char="4648" id="token-35-22" morph="none" pos="word" start_char="4646">más</TOKEN>
<TOKEN end_char="4654" id="token-35-23" morph="none" pos="word" start_char="4650">leves</TOKEN>
<TOKEN end_char="4655" id="token-35-24" morph="none" pos="punct" start_char="4655">.</TOKEN>
<TRANSLATED_TEXT>So because of that state of affairs, we now don 't know if the virus is going to evolve by selecting the lighter variants.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4737" id="segment-36" start_char="4657">
<ORIGINAL_TEXT>Hemos actuado para bien pero hemos detenido el ciclo evolutivo natural del virus.</ORIGINAL_TEXT>
<TOKEN end_char="4661" id="token-36-0" morph="none" pos="word" start_char="4657">Hemos</TOKEN>
<TOKEN end_char="4669" id="token-36-1" morph="none" pos="word" start_char="4663">actuado</TOKEN>
<TOKEN end_char="4674" id="token-36-2" morph="none" pos="word" start_char="4671">para</TOKEN>
<TOKEN end_char="4679" id="token-36-3" morph="none" pos="word" start_char="4676">bien</TOKEN>
<TOKEN end_char="4684" id="token-36-4" morph="none" pos="word" start_char="4681">pero</TOKEN>
<TOKEN end_char="4690" id="token-36-5" morph="none" pos="word" start_char="4686">hemos</TOKEN>
<TOKEN end_char="4699" id="token-36-6" morph="none" pos="word" start_char="4692">detenido</TOKEN>
<TOKEN end_char="4702" id="token-36-7" morph="none" pos="word" start_char="4701">el</TOKEN>
<TOKEN end_char="4708" id="token-36-8" morph="none" pos="word" start_char="4704">ciclo</TOKEN>
<TOKEN end_char="4718" id="token-36-9" morph="none" pos="word" start_char="4710">evolutivo</TOKEN>
<TOKEN end_char="4726" id="token-36-10" morph="none" pos="word" start_char="4720">natural</TOKEN>
<TOKEN end_char="4730" id="token-36-11" morph="none" pos="word" start_char="4728">del</TOKEN>
<TOKEN end_char="4736" id="token-36-12" morph="none" pos="word" start_char="4732">virus</TOKEN>
<TOKEN end_char="4737" id="token-36-13" morph="none" pos="punct" start_char="4737">.</TOKEN>
<TRANSLATED_TEXT>We have acted well, but we have stopped the natural evolutionary cycle of the virus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4822" id="segment-37" start_char="4739">
<ORIGINAL_TEXT>Por eso, hasta no tener los datos de la evolución del virus, solo podemos especular.</ORIGINAL_TEXT>
<TOKEN end_char="4741" id="token-37-0" morph="none" pos="word" start_char="4739">Por</TOKEN>
<TOKEN end_char="4745" id="token-37-1" morph="none" pos="word" start_char="4743">eso</TOKEN>
<TOKEN end_char="4746" id="token-37-2" morph="none" pos="punct" start_char="4746">,</TOKEN>
<TOKEN end_char="4752" id="token-37-3" morph="none" pos="word" start_char="4748">hasta</TOKEN>
<TOKEN end_char="4755" id="token-37-4" morph="none" pos="word" start_char="4754">no</TOKEN>
<TOKEN end_char="4761" id="token-37-5" morph="none" pos="word" start_char="4757">tener</TOKEN>
<TOKEN end_char="4765" id="token-37-6" morph="none" pos="word" start_char="4763">los</TOKEN>
<TOKEN end_char="4771" id="token-37-7" morph="none" pos="word" start_char="4767">datos</TOKEN>
<TOKEN end_char="4774" id="token-37-8" morph="none" pos="word" start_char="4773">de</TOKEN>
<TOKEN end_char="4777" id="token-37-9" morph="none" pos="word" start_char="4776">la</TOKEN>
<TOKEN end_char="4787" id="token-37-10" morph="none" pos="word" start_char="4779">evolución</TOKEN>
<TOKEN end_char="4791" id="token-37-11" morph="none" pos="word" start_char="4789">del</TOKEN>
<TOKEN end_char="4797" id="token-37-12" morph="none" pos="word" start_char="4793">virus</TOKEN>
<TOKEN end_char="4798" id="token-37-13" morph="none" pos="punct" start_char="4798">,</TOKEN>
<TOKEN end_char="4803" id="token-37-14" morph="none" pos="word" start_char="4800">solo</TOKEN>
<TOKEN end_char="4811" id="token-37-15" morph="none" pos="word" start_char="4805">podemos</TOKEN>
<TOKEN end_char="4821" id="token-37-16" morph="none" pos="word" start_char="4813">especular</TOKEN>
<TOKEN end_char="4822" id="token-37-17" morph="none" pos="punct" start_char="4822">.</TOKEN>
<TRANSLATED_TEXT>So until we have data on the evolution of the virus, we can only speculate.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4837" id="segment-38" start_char="4825">
<ORIGINAL_TEXT>María Montoya</ORIGINAL_TEXT>
<TOKEN end_char="4829" id="token-38-0" morph="none" pos="word" start_char="4825">María</TOKEN>
<TOKEN end_char="4837" id="token-38-1" morph="none" pos="word" start_char="4831">Montoya</TOKEN>
<TRANSLATED_TEXT>Maria Montoya</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5044" id="segment-39" start_char="4840">
<ORIGINAL_TEXT>es jefa del grupo de Inmunología Viral en el Centro de Investigaciones Biológicas Margarita Salas (CSIC) y forma parte de la junta directiva de la Sociedad Española de Inmunología, investiga el SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN end_char="4841" id="token-39-0" morph="none" pos="word" start_char="4840">es</TOKEN>
<TOKEN end_char="4846" id="token-39-1" morph="none" pos="word" start_char="4843">jefa</TOKEN>
<TOKEN end_char="4850" id="token-39-2" morph="none" pos="word" start_char="4848">del</TOKEN>
<TOKEN end_char="4856" id="token-39-3" morph="none" pos="word" start_char="4852">grupo</TOKEN>
<TOKEN end_char="4859" id="token-39-4" morph="none" pos="word" start_char="4858">de</TOKEN>
<TOKEN end_char="4871" id="token-39-5" morph="none" pos="word" start_char="4861">Inmunología</TOKEN>
<TOKEN end_char="4877" id="token-39-6" morph="none" pos="word" start_char="4873">Viral</TOKEN>
<TOKEN end_char="4880" id="token-39-7" morph="none" pos="word" start_char="4879">en</TOKEN>
<TOKEN end_char="4883" id="token-39-8" morph="none" pos="word" start_char="4882">el</TOKEN>
<TOKEN end_char="4890" id="token-39-9" morph="none" pos="word" start_char="4885">Centro</TOKEN>
<TOKEN end_char="4893" id="token-39-10" morph="none" pos="word" start_char="4892">de</TOKEN>
<TOKEN end_char="4909" id="token-39-11" morph="none" pos="word" start_char="4895">Investigaciones</TOKEN>
<TOKEN end_char="4920" id="token-39-12" morph="none" pos="word" start_char="4911">Biológicas</TOKEN>
<TOKEN end_char="4930" id="token-39-13" morph="none" pos="word" start_char="4922">Margarita</TOKEN>
<TOKEN end_char="4936" id="token-39-14" morph="none" pos="word" start_char="4932">Salas</TOKEN>
<TOKEN end_char="4938" id="token-39-15" morph="none" pos="punct" start_char="4938">(</TOKEN>
<TOKEN end_char="4942" id="token-39-16" morph="none" pos="word" start_char="4939">CSIC</TOKEN>
<TOKEN end_char="4943" id="token-39-17" morph="none" pos="punct" start_char="4943">)</TOKEN>
<TOKEN end_char="4945" id="token-39-18" morph="none" pos="word" start_char="4945">y</TOKEN>
<TOKEN end_char="4951" id="token-39-19" morph="none" pos="word" start_char="4947">forma</TOKEN>
<TOKEN end_char="4957" id="token-39-20" morph="none" pos="word" start_char="4953">parte</TOKEN>
<TOKEN end_char="4960" id="token-39-21" morph="none" pos="word" start_char="4959">de</TOKEN>
<TOKEN end_char="4963" id="token-39-22" morph="none" pos="word" start_char="4962">la</TOKEN>
<TOKEN end_char="4969" id="token-39-23" morph="none" pos="word" start_char="4965">junta</TOKEN>
<TOKEN end_char="4979" id="token-39-24" morph="none" pos="word" start_char="4971">directiva</TOKEN>
<TOKEN end_char="4982" id="token-39-25" morph="none" pos="word" start_char="4981">de</TOKEN>
<TOKEN end_char="4985" id="token-39-26" morph="none" pos="word" start_char="4984">la</TOKEN>
<TOKEN end_char="4994" id="token-39-27" morph="none" pos="word" start_char="4987">Sociedad</TOKEN>
<TOKEN end_char="5003" id="token-39-28" morph="none" pos="word" start_char="4996">Española</TOKEN>
<TOKEN end_char="5006" id="token-39-29" morph="none" pos="word" start_char="5005">de</TOKEN>
<TOKEN end_char="5018" id="token-39-30" morph="none" pos="word" start_char="5008">Inmunología</TOKEN>
<TOKEN end_char="5019" id="token-39-31" morph="none" pos="punct" start_char="5019">,</TOKEN>
<TOKEN end_char="5029" id="token-39-32" morph="none" pos="word" start_char="5021">investiga</TOKEN>
<TOKEN end_char="5032" id="token-39-33" morph="none" pos="word" start_char="5031">el</TOKEN>
<TOKEN end_char="5043" id="token-39-34" morph="none" pos="unknown" start_char="5034">SARS-CoV-2</TOKEN>
<TOKEN end_char="5044" id="token-39-35" morph="none" pos="punct" start_char="5044">.</TOKEN>
<TRANSLATED_TEXT>She is head of the Viral Immunology Group at the Center for Biological Research Margarita Salas (CSIC) and is a member of the board of the Spanish Society of Immunology, investigating SARS-CoV-2.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5076" id="segment-40" start_char="5047">
<ORIGINAL_TEXT>Pregunta enviada vía email por</ORIGINAL_TEXT>
<TOKEN end_char="5054" id="token-40-0" morph="none" pos="word" start_char="5047">Pregunta</TOKEN>
<TOKEN end_char="5062" id="token-40-1" morph="none" pos="word" start_char="5056">enviada</TOKEN>
<TOKEN end_char="5066" id="token-40-2" morph="none" pos="word" start_char="5064">vía</TOKEN>
<TOKEN end_char="5072" id="token-40-3" morph="none" pos="word" start_char="5068">email</TOKEN>
<TOKEN end_char="5076" id="token-40-4" morph="none" pos="word" start_char="5074">por</TOKEN>
<TRANSLATED_TEXT>Question sent by email</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="5095" id="segment-41" start_char="5079">
<ORIGINAL_TEXT>Ada Luanda García</ORIGINAL_TEXT>
<TOKEN end_char="5081" id="token-41-0" morph="none" pos="word" start_char="5079">Ada</TOKEN>
<TOKEN end_char="5088" id="token-41-1" morph="none" pos="word" start_char="5083">Luanda</TOKEN>
<TOKEN end_char="5095" id="token-41-2" morph="none" pos="word" start_char="5090">García</TOKEN>
<TRANSLATED_TEXT>Ada Luanda Garcia</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5117" id="segment-42" start_char="5098">
<ORIGINAL_TEXT>Nosotras respondemos</ORIGINAL_TEXT>
<TOKEN end_char="5105" id="token-42-0" morph="none" pos="word" start_char="5098">Nosotras</TOKEN>
<TOKEN end_char="5117" id="token-42-1" morph="none" pos="word" start_char="5107">respondemos</TOKEN>
<TRANSLATED_TEXT>We answer</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="5325" id="segment-43" start_char="5120">
<ORIGINAL_TEXT>es un consultorio científico semanal, patrocinado por la Fundación Dr. Antoni Esteve y el programa L’Oréal-Unesco ‘For Women in Science’, que contesta a las dudas de los lectores sobre ciencia y tecnología.</ORIGINAL_TEXT>
<TOKEN end_char="5121" id="token-43-0" morph="none" pos="word" start_char="5120">es</TOKEN>
<TOKEN end_char="5124" id="token-43-1" morph="none" pos="word" start_char="5123">un</TOKEN>
<TOKEN end_char="5136" id="token-43-2" morph="none" pos="word" start_char="5126">consultorio</TOKEN>
<TOKEN end_char="5147" id="token-43-3" morph="none" pos="word" start_char="5138">científico</TOKEN>
<TOKEN end_char="5155" id="token-43-4" morph="none" pos="word" start_char="5149">semanal</TOKEN>
<TOKEN end_char="5156" id="token-43-5" morph="none" pos="punct" start_char="5156">,</TOKEN>
<TOKEN end_char="5168" id="token-43-6" morph="none" pos="word" start_char="5158">patrocinado</TOKEN>
<TOKEN end_char="5172" id="token-43-7" morph="none" pos="word" start_char="5170">por</TOKEN>
<TOKEN end_char="5175" id="token-43-8" morph="none" pos="word" start_char="5174">la</TOKEN>
<TOKEN end_char="5185" id="token-43-9" morph="none" pos="word" start_char="5177">Fundación</TOKEN>
<TOKEN end_char="5188" id="token-43-10" morph="none" pos="word" start_char="5187">Dr</TOKEN>
<TOKEN end_char="5189" id="token-43-11" morph="none" pos="punct" start_char="5189">.</TOKEN>
<TOKEN end_char="5196" id="token-43-12" morph="none" pos="word" start_char="5191">Antoni</TOKEN>
<TOKEN end_char="5203" id="token-43-13" morph="none" pos="word" start_char="5198">Esteve</TOKEN>
<TOKEN end_char="5205" id="token-43-14" morph="none" pos="word" start_char="5205">y</TOKEN>
<TOKEN end_char="5208" id="token-43-15" morph="none" pos="word" start_char="5207">el</TOKEN>
<TOKEN end_char="5217" id="token-43-16" morph="none" pos="word" start_char="5210">programa</TOKEN>
<TOKEN end_char="5232" id="token-43-17" morph="none" pos="unknown" start_char="5219">L’Oréal-Unesco</TOKEN>
<TOKEN end_char="5234" id="token-43-18" morph="none" pos="punct" start_char="5234">‘</TOKEN>
<TOKEN end_char="5237" id="token-43-19" morph="none" pos="word" start_char="5235">For</TOKEN>
<TOKEN end_char="5243" id="token-43-20" morph="none" pos="word" start_char="5239">Women</TOKEN>
<TOKEN end_char="5246" id="token-43-21" morph="none" pos="word" start_char="5245">in</TOKEN>
<TOKEN end_char="5254" id="token-43-22" morph="none" pos="word" start_char="5248">Science</TOKEN>
<TOKEN end_char="5256" id="token-43-23" morph="none" pos="punct" start_char="5255">’,</TOKEN>
<TOKEN end_char="5260" id="token-43-24" morph="none" pos="word" start_char="5258">que</TOKEN>
<TOKEN end_char="5269" id="token-43-25" morph="none" pos="word" start_char="5262">contesta</TOKEN>
<TOKEN end_char="5271" id="token-43-26" morph="none" pos="word" start_char="5271">a</TOKEN>
<TOKEN end_char="5275" id="token-43-27" morph="none" pos="word" start_char="5273">las</TOKEN>
<TOKEN end_char="5281" id="token-43-28" morph="none" pos="word" start_char="5277">dudas</TOKEN>
<TOKEN end_char="5284" id="token-43-29" morph="none" pos="word" start_char="5283">de</TOKEN>
<TOKEN end_char="5288" id="token-43-30" morph="none" pos="word" start_char="5286">los</TOKEN>
<TOKEN end_char="5297" id="token-43-31" morph="none" pos="word" start_char="5290">lectores</TOKEN>
<TOKEN end_char="5303" id="token-43-32" morph="none" pos="word" start_char="5299">sobre</TOKEN>
<TOKEN end_char="5311" id="token-43-33" morph="none" pos="word" start_char="5305">ciencia</TOKEN>
<TOKEN end_char="5313" id="token-43-34" morph="none" pos="word" start_char="5313">y</TOKEN>
<TOKEN end_char="5324" id="token-43-35" morph="none" pos="word" start_char="5315">tecnología</TOKEN>
<TOKEN end_char="5325" id="token-43-36" morph="none" pos="punct" start_char="5325">.</TOKEN>
<TRANSLATED_TEXT>is a weekly scientific consultancy, sponsored by the Dr. Antoni Esteve Foundation and the L'Oréal-Unesco programme 'For Women in Science', which answers readers' doubts about science and technology.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5455" id="segment-44" start_char="5327">
<ORIGINAL_TEXT>Son científicas y tecnólogas, socias de AMIT (Asociación de Mujeres Investigadoras y Tecnólogas), las que responden a esas dudas.</ORIGINAL_TEXT>
<TOKEN end_char="5329" id="token-44-0" morph="none" pos="word" start_char="5327">Son</TOKEN>
<TOKEN end_char="5341" id="token-44-1" morph="none" pos="word" start_char="5331">científicas</TOKEN>
<TOKEN end_char="5343" id="token-44-2" morph="none" pos="word" start_char="5343">y</TOKEN>
<TOKEN end_char="5354" id="token-44-3" morph="none" pos="word" start_char="5345">tecnólogas</TOKEN>
<TOKEN end_char="5355" id="token-44-4" morph="none" pos="punct" start_char="5355">,</TOKEN>
<TOKEN end_char="5362" id="token-44-5" morph="none" pos="word" start_char="5357">socias</TOKEN>
<TOKEN end_char="5365" id="token-44-6" morph="none" pos="word" start_char="5364">de</TOKEN>
<TOKEN end_char="5370" id="token-44-7" morph="none" pos="word" start_char="5367">AMIT</TOKEN>
<TOKEN end_char="5372" id="token-44-8" morph="none" pos="punct" start_char="5372">(</TOKEN>
<TOKEN end_char="5382" id="token-44-9" morph="none" pos="word" start_char="5373">Asociación</TOKEN>
<TOKEN end_char="5385" id="token-44-10" morph="none" pos="word" start_char="5384">de</TOKEN>
<TOKEN end_char="5393" id="token-44-11" morph="none" pos="word" start_char="5387">Mujeres</TOKEN>
<TOKEN end_char="5408" id="token-44-12" morph="none" pos="word" start_char="5395">Investigadoras</TOKEN>
<TOKEN end_char="5410" id="token-44-13" morph="none" pos="word" start_char="5410">y</TOKEN>
<TOKEN end_char="5421" id="token-44-14" morph="none" pos="word" start_char="5412">Tecnólogas</TOKEN>
<TOKEN end_char="5423" id="token-44-15" morph="none" pos="punct" start_char="5422">),</TOKEN>
<TOKEN end_char="5427" id="token-44-16" morph="none" pos="word" start_char="5425">las</TOKEN>
<TOKEN end_char="5431" id="token-44-17" morph="none" pos="word" start_char="5429">que</TOKEN>
<TOKEN end_char="5441" id="token-44-18" morph="none" pos="word" start_char="5433">responden</TOKEN>
<TOKEN end_char="5443" id="token-44-19" morph="none" pos="word" start_char="5443">a</TOKEN>
<TOKEN end_char="5448" id="token-44-20" morph="none" pos="word" start_char="5445">esas</TOKEN>
<TOKEN end_char="5454" id="token-44-21" morph="none" pos="word" start_char="5450">dudas</TOKEN>
<TOKEN end_char="5455" id="token-44-22" morph="none" pos="punct" start_char="5455">.</TOKEN>
<TRANSLATED_TEXT>They are scientists and technologists, partners of AMIT (Association of Women Researchers and Technologists), who answer these questions.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5477" id="segment-45" start_char="5457">
<ORIGINAL_TEXT>Envía tus preguntas a</ORIGINAL_TEXT>
<TOKEN end_char="5461" id="token-45-0" morph="none" pos="word" start_char="5457">Envía</TOKEN>
<TOKEN end_char="5465" id="token-45-1" morph="none" pos="word" start_char="5463">tus</TOKEN>
<TOKEN end_char="5475" id="token-45-2" morph="none" pos="word" start_char="5467">preguntas</TOKEN>
<TOKEN end_char="5477" id="token-45-3" morph="none" pos="word" start_char="5477">a</TOKEN>
<TRANSLATED_TEXT>Send your questions to</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5508" id="segment-46" start_char="5480">
<ORIGINAL_TEXT>nosotrasrespondemos@gmail.com</ORIGINAL_TEXT>
<TOKEN end_char="5508" id="token-46-0" morph="none" pos="unknown" start_char="5480">nosotrasrespondemos@gmail.com</TOKEN>
<TRANSLATED_TEXT>nosotrasrespondemo@gmail.com</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="5545" id="segment-47" start_char="5511">
<ORIGINAL_TEXT>o por Twitter #nosotrasrespondemos.</ORIGINAL_TEXT>
<TOKEN end_char="5511" id="token-47-0" morph="none" pos="word" start_char="5511">o</TOKEN>
<TOKEN end_char="5515" id="token-47-1" morph="none" pos="word" start_char="5513">por</TOKEN>
<TOKEN end_char="5523" id="token-47-2" morph="none" pos="word" start_char="5517">Twitter</TOKEN>
<TOKEN end_char="5545" id="token-47-3" morph="none" pos="tag" start_char="5525">#nosotrasrespondemos.</TOKEN>
<TRANSLATED_TEXT>or by Twitter # we're still responding.</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATG5" lang="spa" raw_text_char_length="427" raw_text_md5="48f98efc1a70aedc3d05a52a46e28c1e" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="38" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Are you happy covid is getting weaker?</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">Are</TOKEN>
<TOKEN end_char="7" id="token-0-1" morph="none" pos="word" start_char="5">you</TOKEN>
<TOKEN end_char="13" id="token-0-2" morph="none" pos="word" start_char="9">happy</TOKEN>
<TOKEN end_char="19" id="token-0-3" morph="none" pos="word" start_char="15">covid</TOKEN>
<TOKEN end_char="22" id="token-0-4" morph="none" pos="word" start_char="21">is</TOKEN>
<TOKEN end_char="30" id="token-0-5" morph="none" pos="word" start_char="24">getting</TOKEN>
<TOKEN end_char="37" id="token-0-6" morph="none" pos="word" start_char="32">weaker</TOKEN>
<TOKEN end_char="38" id="token-0-7" morph="none" pos="punct" start_char="38">?</TOKEN>
</SEG>
<SEG end_char="80" id="segment-1" start_char="43">
<ORIGINAL_TEXT>Are you happy covid is getting weaker?</ORIGINAL_TEXT>
<TOKEN end_char="45" id="token-1-0" morph="none" pos="word" start_char="43">Are</TOKEN>
<TOKEN end_char="49" id="token-1-1" morph="none" pos="word" start_char="47">you</TOKEN>
<TOKEN end_char="55" id="token-1-2" morph="none" pos="word" start_char="51">happy</TOKEN>
<TOKEN end_char="61" id="token-1-3" morph="none" pos="word" start_char="57">covid</TOKEN>
<TOKEN end_char="64" id="token-1-4" morph="none" pos="word" start_char="63">is</TOKEN>
<TOKEN end_char="72" id="token-1-5" morph="none" pos="word" start_char="66">getting</TOKEN>
<TOKEN end_char="79" id="token-1-6" morph="none" pos="word" start_char="74">weaker</TOKEN>
<TOKEN end_char="80" id="token-1-7" morph="none" pos="punct" start_char="80">?</TOKEN>
</SEG>
<SEG end_char="158" id="segment-2" start_char="85">
<ORIGINAL_TEXT>covid is mutating at a rate faster than the medical profession can detect.</ORIGINAL_TEXT>
<TOKEN end_char="89" id="token-2-0" morph="none" pos="word" start_char="85">covid</TOKEN>
<TOKEN end_char="92" id="token-2-1" morph="none" pos="word" start_char="91">is</TOKEN>
<TOKEN end_char="101" id="token-2-2" morph="none" pos="word" start_char="94">mutating</TOKEN>
<TOKEN end_char="104" id="token-2-3" morph="none" pos="word" start_char="103">at</TOKEN>
<TOKEN end_char="106" id="token-2-4" morph="none" pos="word" start_char="106">a</TOKEN>
<TOKEN end_char="111" id="token-2-5" morph="none" pos="word" start_char="108">rate</TOKEN>
<TOKEN end_char="118" id="token-2-6" morph="none" pos="word" start_char="113">faster</TOKEN>
<TOKEN end_char="123" id="token-2-7" morph="none" pos="word" start_char="120">than</TOKEN>
<TOKEN end_char="127" id="token-2-8" morph="none" pos="word" start_char="125">the</TOKEN>
<TOKEN end_char="135" id="token-2-9" morph="none" pos="word" start_char="129">medical</TOKEN>
<TOKEN end_char="146" id="token-2-10" morph="none" pos="word" start_char="137">profession</TOKEN>
<TOKEN end_char="150" id="token-2-11" morph="none" pos="word" start_char="148">can</TOKEN>
<TOKEN end_char="157" id="token-2-12" morph="none" pos="word" start_char="152">detect</TOKEN>
<TOKEN end_char="158" id="token-2-13" morph="none" pos="punct" start_char="158">.</TOKEN>
</SEG>
<SEG end_char="170" id="segment-3" start_char="162">
<ORIGINAL_TEXT>It isn't.</ORIGINAL_TEXT>
<TOKEN end_char="163" id="token-3-0" morph="none" pos="word" start_char="162">It</TOKEN>
<TOKEN end_char="169" id="token-3-1" morph="none" pos="word" start_char="165">isn't</TOKEN>
<TOKEN end_char="170" id="token-3-2" morph="none" pos="punct" start_char="170">.</TOKEN>
</SEG>
<SEG end_char="226" id="segment-4" start_char="172">
<ORIGINAL_TEXT>That's just your INCORRECT evaluation of the situation.</ORIGINAL_TEXT>
<TOKEN end_char="177" id="token-4-0" morph="none" pos="word" start_char="172">That's</TOKEN>
<TOKEN end_char="182" id="token-4-1" morph="none" pos="word" start_char="179">just</TOKEN>
<TOKEN end_char="187" id="token-4-2" morph="none" pos="word" start_char="184">your</TOKEN>
<TOKEN end_char="197" id="token-4-3" morph="none" pos="word" start_char="189">INCORRECT</TOKEN>
<TOKEN end_char="208" id="token-4-4" morph="none" pos="word" start_char="199">evaluation</TOKEN>
<TOKEN end_char="211" id="token-4-5" morph="none" pos="word" start_char="210">of</TOKEN>
<TOKEN end_char="215" id="token-4-6" morph="none" pos="word" start_char="213">the</TOKEN>
<TOKEN end_char="225" id="token-4-7" morph="none" pos="word" start_char="217">situation</TOKEN>
<TOKEN end_char="226" id="token-4-8" morph="none" pos="punct" start_char="226">.</TOKEN>
</SEG>
<SEG end_char="289" id="segment-5" start_char="230">
<ORIGINAL_TEXT>It's not getting weaker, especially with the new variants...</ORIGINAL_TEXT>
<TOKEN end_char="233" id="token-5-0" morph="none" pos="word" start_char="230">It's</TOKEN>
<TOKEN end_char="237" id="token-5-1" morph="none" pos="word" start_char="235">not</TOKEN>
<TOKEN end_char="245" id="token-5-2" morph="none" pos="word" start_char="239">getting</TOKEN>
<TOKEN end_char="252" id="token-5-3" morph="none" pos="word" start_char="247">weaker</TOKEN>
<TOKEN end_char="253" id="token-5-4" morph="none" pos="punct" start_char="253">,</TOKEN>
<TOKEN end_char="264" id="token-5-5" morph="none" pos="word" start_char="255">especially</TOKEN>
<TOKEN end_char="269" id="token-5-6" morph="none" pos="word" start_char="266">with</TOKEN>
<TOKEN end_char="273" id="token-5-7" morph="none" pos="word" start_char="271">the</TOKEN>
<TOKEN end_char="277" id="token-5-8" morph="none" pos="word" start_char="275">new</TOKEN>
<TOKEN end_char="286" id="token-5-9" morph="none" pos="word" start_char="279">variants</TOKEN>
<TOKEN end_char="289" id="token-5-10" morph="none" pos="punct" start_char="287">...</TOKEN>
</SEG>
<SEG end_char="317" id="segment-6" start_char="293">
<ORIGINAL_TEXT>It is not getting weaker.</ORIGINAL_TEXT>
<TOKEN end_char="294" id="token-6-0" morph="none" pos="word" start_char="293">It</TOKEN>
<TOKEN end_char="297" id="token-6-1" morph="none" pos="word" start_char="296">is</TOKEN>
<TOKEN end_char="301" id="token-6-2" morph="none" pos="word" start_char="299">not</TOKEN>
<TOKEN end_char="309" id="token-6-3" morph="none" pos="word" start_char="303">getting</TOKEN>
<TOKEN end_char="316" id="token-6-4" morph="none" pos="word" start_char="311">weaker</TOKEN>
<TOKEN end_char="317" id="token-6-5" morph="none" pos="punct" start_char="317">.</TOKEN>
<TRANSLATED_TEXT>Het wordt niet zwakker.</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="423" id="segment-7" start_char="319">
<ORIGINAL_TEXT>There is vaccine, but the virus is still virulent and potentially deadly if you have not been vaccinated.</ORIGINAL_TEXT>
<TOKEN end_char="323" id="token-7-0" morph="none" pos="word" start_char="319">There</TOKEN>
<TOKEN end_char="326" id="token-7-1" morph="none" pos="word" start_char="325">is</TOKEN>
<TOKEN end_char="334" id="token-7-2" morph="none" pos="word" start_char="328">vaccine</TOKEN>
<TOKEN end_char="335" id="token-7-3" morph="none" pos="punct" start_char="335">,</TOKEN>
<TOKEN end_char="339" id="token-7-4" morph="none" pos="word" start_char="337">but</TOKEN>
<TOKEN end_char="343" id="token-7-5" morph="none" pos="word" start_char="341">the</TOKEN>
<TOKEN end_char="349" id="token-7-6" morph="none" pos="word" start_char="345">virus</TOKEN>
<TOKEN end_char="352" id="token-7-7" morph="none" pos="word" start_char="351">is</TOKEN>
<TOKEN end_char="358" id="token-7-8" morph="none" pos="word" start_char="354">still</TOKEN>
<TOKEN end_char="367" id="token-7-9" morph="none" pos="word" start_char="360">virulent</TOKEN>
<TOKEN end_char="371" id="token-7-10" morph="none" pos="word" start_char="369">and</TOKEN>
<TOKEN end_char="383" id="token-7-11" morph="none" pos="word" start_char="373">potentially</TOKEN>
<TOKEN end_char="390" id="token-7-12" morph="none" pos="word" start_char="385">deadly</TOKEN>
<TOKEN end_char="393" id="token-7-13" morph="none" pos="word" start_char="392">if</TOKEN>
<TOKEN end_char="397" id="token-7-14" morph="none" pos="word" start_char="395">you</TOKEN>
<TOKEN end_char="402" id="token-7-15" morph="none" pos="word" start_char="399">have</TOKEN>
<TOKEN end_char="406" id="token-7-16" morph="none" pos="word" start_char="404">not</TOKEN>
<TOKEN end_char="411" id="token-7-17" morph="none" pos="word" start_char="408">been</TOKEN>
<TOKEN end_char="422" id="token-7-18" morph="none" pos="word" start_char="413">vaccinated</TOKEN>
<TOKEN end_char="423" id="token-7-19" morph="none" pos="punct" start_char="423">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
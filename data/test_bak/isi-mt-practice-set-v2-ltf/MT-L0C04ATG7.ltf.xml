<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATG7" lang="spa" raw_text_char_length="2534" raw_text_md5="8b56755370d87c789faeb13479411011" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="115" id="segment-0" start_char="1">
<ORIGINAL_TEXT>What will be the after effects of social distancing and complete lockdown imposed due to the spread of coronavirus?</ORIGINAL_TEXT>
<TOKEN end_char="4" id="token-0-0" morph="none" pos="word" start_char="1">What</TOKEN>
<TOKEN end_char="9" id="token-0-1" morph="none" pos="word" start_char="6">will</TOKEN>
<TOKEN end_char="12" id="token-0-2" morph="none" pos="word" start_char="11">be</TOKEN>
<TOKEN end_char="16" id="token-0-3" morph="none" pos="word" start_char="14">the</TOKEN>
<TOKEN end_char="22" id="token-0-4" morph="none" pos="word" start_char="18">after</TOKEN>
<TOKEN end_char="30" id="token-0-5" morph="none" pos="word" start_char="24">effects</TOKEN>
<TOKEN end_char="33" id="token-0-6" morph="none" pos="word" start_char="32">of</TOKEN>
<TOKEN end_char="40" id="token-0-7" morph="none" pos="word" start_char="35">social</TOKEN>
<TOKEN end_char="51" id="token-0-8" morph="none" pos="word" start_char="42">distancing</TOKEN>
<TOKEN end_char="55" id="token-0-9" morph="none" pos="word" start_char="53">and</TOKEN>
<TOKEN end_char="64" id="token-0-10" morph="none" pos="word" start_char="57">complete</TOKEN>
<TOKEN end_char="73" id="token-0-11" morph="none" pos="word" start_char="66">lockdown</TOKEN>
<TOKEN end_char="81" id="token-0-12" morph="none" pos="word" start_char="75">imposed</TOKEN>
<TOKEN end_char="85" id="token-0-13" morph="none" pos="word" start_char="83">due</TOKEN>
<TOKEN end_char="88" id="token-0-14" morph="none" pos="word" start_char="87">to</TOKEN>
<TOKEN end_char="92" id="token-0-15" morph="none" pos="word" start_char="90">the</TOKEN>
<TOKEN end_char="99" id="token-0-16" morph="none" pos="word" start_char="94">spread</TOKEN>
<TOKEN end_char="102" id="token-0-17" morph="none" pos="word" start_char="101">of</TOKEN>
<TOKEN end_char="114" id="token-0-18" morph="none" pos="word" start_char="104">coronavirus</TOKEN>
<TOKEN end_char="115" id="token-0-19" morph="none" pos="punct" start_char="115">?</TOKEN>
</SEG>
<SEG end_char="189" id="segment-1" start_char="119">
<ORIGINAL_TEXT>The pathogens will keep coming just as they have for billions of years.</ORIGINAL_TEXT>
<TOKEN end_char="121" id="token-1-0" morph="none" pos="word" start_char="119">The</TOKEN>
<TOKEN end_char="131" id="token-1-1" morph="none" pos="word" start_char="123">pathogens</TOKEN>
<TOKEN end_char="136" id="token-1-2" morph="none" pos="word" start_char="133">will</TOKEN>
<TOKEN end_char="141" id="token-1-3" morph="none" pos="word" start_char="138">keep</TOKEN>
<TOKEN end_char="148" id="token-1-4" morph="none" pos="word" start_char="143">coming</TOKEN>
<TOKEN end_char="153" id="token-1-5" morph="none" pos="word" start_char="150">just</TOKEN>
<TOKEN end_char="156" id="token-1-6" morph="none" pos="word" start_char="155">as</TOKEN>
<TOKEN end_char="161" id="token-1-7" morph="none" pos="word" start_char="158">they</TOKEN>
<TOKEN end_char="166" id="token-1-8" morph="none" pos="word" start_char="163">have</TOKEN>
<TOKEN end_char="170" id="token-1-9" morph="none" pos="word" start_char="168">for</TOKEN>
<TOKEN end_char="179" id="token-1-10" morph="none" pos="word" start_char="172">billions</TOKEN>
<TOKEN end_char="182" id="token-1-11" morph="none" pos="word" start_char="181">of</TOKEN>
<TOKEN end_char="188" id="token-1-12" morph="none" pos="word" start_char="184">years</TOKEN>
<TOKEN end_char="189" id="token-1-13" morph="none" pos="punct" start_char="189">.</TOKEN>
</SEG>
<SEG end_char="268" id="segment-2" start_char="191">
<ORIGINAL_TEXT>It's valuable to remember that microbes once had the planet all to themselves.</ORIGINAL_TEXT>
<TOKEN end_char="194" id="token-2-0" morph="none" pos="word" start_char="191">It's</TOKEN>
<TOKEN end_char="203" id="token-2-1" morph="none" pos="word" start_char="196">valuable</TOKEN>
<TOKEN end_char="206" id="token-2-2" morph="none" pos="word" start_char="205">to</TOKEN>
<TOKEN end_char="215" id="token-2-3" morph="none" pos="word" start_char="208">remember</TOKEN>
<TOKEN end_char="220" id="token-2-4" morph="none" pos="word" start_char="217">that</TOKEN>
<TOKEN end_char="229" id="token-2-5" morph="none" pos="word" start_char="222">microbes</TOKEN>
<TOKEN end_char="234" id="token-2-6" morph="none" pos="word" start_char="231">once</TOKEN>
<TOKEN end_char="238" id="token-2-7" morph="none" pos="word" start_char="236">had</TOKEN>
<TOKEN end_char="242" id="token-2-8" morph="none" pos="word" start_char="240">the</TOKEN>
<TOKEN end_char="249" id="token-2-9" morph="none" pos="word" start_char="244">planet</TOKEN>
<TOKEN end_char="253" id="token-2-10" morph="none" pos="word" start_char="251">all</TOKEN>
<TOKEN end_char="256" id="token-2-11" morph="none" pos="word" start_char="255">to</TOKEN>
<TOKEN end_char="267" id="token-2-12" morph="none" pos="word" start_char="258">themselves</TOKEN>
<TOKEN end_char="268" id="token-2-13" morph="none" pos="punct" start_char="268">.</TOKEN>
</SEG>
<SEG end_char="290" id="segment-3" start_char="270">
<ORIGINAL_TEXT>Bacteria and viruses.</ORIGINAL_TEXT>
<TOKEN end_char="277" id="token-3-0" morph="none" pos="word" start_char="270">Bacteria</TOKEN>
<TOKEN end_char="281" id="token-3-1" morph="none" pos="word" start_char="279">and</TOKEN>
<TOKEN end_char="289" id="token-3-2" morph="none" pos="word" start_char="283">viruses</TOKEN>
<TOKEN end_char="290" id="token-3-3" morph="none" pos="punct" start_char="290">.</TOKEN>
</SEG>
<SEG end_char="297" id="segment-4" start_char="293">
<ORIGINAL_TEXT>Also?</ORIGINAL_TEXT>
<TOKEN end_char="296" id="token-4-0" morph="none" pos="word" start_char="293">Also</TOKEN>
<TOKEN end_char="297" id="token-4-1" morph="none" pos="punct" start_char="297">?</TOKEN>
</SEG>
<SEG end_char="350" id="segment-5" start_char="299">
<ORIGINAL_TEXT>90+% of what each of us calls 'my self' is microbes.</ORIGINAL_TEXT>
<TOKEN end_char="302" id="token-5-0" morph="none" pos="unknown" start_char="299">90+%</TOKEN>
<TOKEN end_char="305" id="token-5-1" morph="none" pos="word" start_char="304">of</TOKEN>
<TOKEN end_char="310" id="token-5-2" morph="none" pos="word" start_char="307">what</TOKEN>
<TOKEN end_char="315" id="token-5-3" morph="none" pos="word" start_char="312">each</TOKEN>
<TOKEN end_char="318" id="token-5-4" morph="none" pos="word" start_char="317">of</TOKEN>
<TOKEN end_char="321" id="token-5-5" morph="none" pos="word" start_char="320">us</TOKEN>
<TOKEN end_char="327" id="token-5-6" morph="none" pos="word" start_char="323">calls</TOKEN>
<TOKEN end_char="329" id="token-5-7" morph="none" pos="punct" start_char="329">'</TOKEN>
<TOKEN end_char="331" id="token-5-8" morph="none" pos="word" start_char="330">my</TOKEN>
<TOKEN end_char="336" id="token-5-9" morph="none" pos="word" start_char="333">self</TOKEN>
<TOKEN end_char="337" id="token-5-10" morph="none" pos="punct" start_char="337">'</TOKEN>
<TOKEN end_char="340" id="token-5-11" morph="none" pos="word" start_char="339">is</TOKEN>
<TOKEN end_char="349" id="token-5-12" morph="none" pos="word" start_char="342">microbes</TOKEN>
<TOKEN end_char="350" id="token-5-13" morph="none" pos="punct" start_char="350">.</TOKEN>
</SEG>
<SEG end_char="402" id="segment-6" start_char="352">
<ORIGINAL_TEXT>90+% of all cells in our bodies are bacteria et al.</ORIGINAL_TEXT>
<TOKEN end_char="355" id="token-6-0" morph="none" pos="unknown" start_char="352">90+%</TOKEN>
<TOKEN end_char="358" id="token-6-1" morph="none" pos="word" start_char="357">of</TOKEN>
<TOKEN end_char="362" id="token-6-2" morph="none" pos="word" start_char="360">all</TOKEN>
<TOKEN end_char="368" id="token-6-3" morph="none" pos="word" start_char="364">cells</TOKEN>
<TOKEN end_char="371" id="token-6-4" morph="none" pos="word" start_char="370">in</TOKEN>
<TOKEN end_char="375" id="token-6-5" morph="none" pos="word" start_char="373">our</TOKEN>
<TOKEN end_char="382" id="token-6-6" morph="none" pos="word" start_char="377">bodies</TOKEN>
<TOKEN end_char="386" id="token-6-7" morph="none" pos="word" start_char="384">are</TOKEN>
<TOKEN end_char="395" id="token-6-8" morph="none" pos="word" start_char="388">bacteria</TOKEN>
<TOKEN end_char="398" id="token-6-9" morph="none" pos="word" start_char="397">et</TOKEN>
<TOKEN end_char="401" id="token-6-10" morph="none" pos="word" start_char="400">al</TOKEN>
<TOKEN end_char="402" id="token-6-11" morph="none" pos="punct" start_char="402">.</TOKEN>
</SEG>
<SEG end_char="408" id="segment-7" start_char="405">
<ORIGINAL_TEXT>And?</ORIGINAL_TEXT>
<TOKEN end_char="407" id="token-7-0" morph="none" pos="word" start_char="405">And</TOKEN>
<TOKEN end_char="408" id="token-7-1" morph="none" pos="punct" start_char="408">?</TOKEN>
<TRANSLATED_TEXT>- And?</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="524" id="segment-8" start_char="411">
<ORIGINAL_TEXT>We owe most of our current nature to both our benign microbial tennants - and the ones that have tried to kill us.</ORIGINAL_TEXT>
<TOKEN end_char="412" id="token-8-0" morph="none" pos="word" start_char="411">We</TOKEN>
<TOKEN end_char="416" id="token-8-1" morph="none" pos="word" start_char="414">owe</TOKEN>
<TOKEN end_char="421" id="token-8-2" morph="none" pos="word" start_char="418">most</TOKEN>
<TOKEN end_char="424" id="token-8-3" morph="none" pos="word" start_char="423">of</TOKEN>
<TOKEN end_char="428" id="token-8-4" morph="none" pos="word" start_char="426">our</TOKEN>
<TOKEN end_char="436" id="token-8-5" morph="none" pos="word" start_char="430">current</TOKEN>
<TOKEN end_char="443" id="token-8-6" morph="none" pos="word" start_char="438">nature</TOKEN>
<TOKEN end_char="446" id="token-8-7" morph="none" pos="word" start_char="445">to</TOKEN>
<TOKEN end_char="451" id="token-8-8" morph="none" pos="word" start_char="448">both</TOKEN>
<TOKEN end_char="455" id="token-8-9" morph="none" pos="word" start_char="453">our</TOKEN>
<TOKEN end_char="462" id="token-8-10" morph="none" pos="word" start_char="457">benign</TOKEN>
<TOKEN end_char="472" id="token-8-11" morph="none" pos="word" start_char="464">microbial</TOKEN>
<TOKEN end_char="481" id="token-8-12" morph="none" pos="word" start_char="474">tennants</TOKEN>
<TOKEN end_char="483" id="token-8-13" morph="none" pos="punct" start_char="483">-</TOKEN>
<TOKEN end_char="487" id="token-8-14" morph="none" pos="word" start_char="485">and</TOKEN>
<TOKEN end_char="491" id="token-8-15" morph="none" pos="word" start_char="489">the</TOKEN>
<TOKEN end_char="496" id="token-8-16" morph="none" pos="word" start_char="493">ones</TOKEN>
<TOKEN end_char="501" id="token-8-17" morph="none" pos="word" start_char="498">that</TOKEN>
<TOKEN end_char="506" id="token-8-18" morph="none" pos="word" start_char="503">have</TOKEN>
<TOKEN end_char="512" id="token-8-19" morph="none" pos="word" start_char="508">tried</TOKEN>
<TOKEN end_char="515" id="token-8-20" morph="none" pos="word" start_char="514">to</TOKEN>
<TOKEN end_char="520" id="token-8-21" morph="none" pos="word" start_char="517">kill</TOKEN>
<TOKEN end_char="523" id="token-8-22" morph="none" pos="word" start_char="522">us</TOKEN>
<TOKEN end_char="524" id="token-8-23" morph="none" pos="punct" start_char="524">.</TOKEN>
</SEG>
<SEG end_char="529" id="segment-9" start_char="527">
<ORIGINAL_TEXT>So.</ORIGINAL_TEXT>
<TOKEN end_char="528" id="token-9-0" morph="none" pos="word" start_char="527">So</TOKEN>
<TOKEN end_char="529" id="token-9-1" morph="none" pos="punct" start_char="529">.</TOKEN>
<TRANSLATED_TEXT>Salt.</TRANSLATED_TEXT><DETECTED_LANGUAGE>so</DETECTED_LANGUAGE></SEG>
<SEG end_char="557" id="segment-10" start_char="531">
<ORIGINAL_TEXT>Viruses are always with us.</ORIGINAL_TEXT>
<TOKEN end_char="537" id="token-10-0" morph="none" pos="word" start_char="531">Viruses</TOKEN>
<TOKEN end_char="541" id="token-10-1" morph="none" pos="word" start_char="539">are</TOKEN>
<TOKEN end_char="548" id="token-10-2" morph="none" pos="word" start_char="543">always</TOKEN>
<TOKEN end_char="553" id="token-10-3" morph="none" pos="word" start_char="550">with</TOKEN>
<TOKEN end_char="556" id="token-10-4" morph="none" pos="word" start_char="555">us</TOKEN>
<TOKEN end_char="557" id="token-10-5" morph="none" pos="punct" start_char="557">.</TOKEN>
</SEG>
<SEG end_char="598" id="segment-11" start_char="559">
<ORIGINAL_TEXT>They were here long long long before us.</ORIGINAL_TEXT>
<TOKEN end_char="562" id="token-11-0" morph="none" pos="word" start_char="559">They</TOKEN>
<TOKEN end_char="567" id="token-11-1" morph="none" pos="word" start_char="564">were</TOKEN>
<TOKEN end_char="572" id="token-11-2" morph="none" pos="word" start_char="569">here</TOKEN>
<TOKEN end_char="577" id="token-11-3" morph="none" pos="word" start_char="574">long</TOKEN>
<TOKEN end_char="582" id="token-11-4" morph="none" pos="word" start_char="579">long</TOKEN>
<TOKEN end_char="587" id="token-11-5" morph="none" pos="word" start_char="584">long</TOKEN>
<TOKEN end_char="594" id="token-11-6" morph="none" pos="word" start_char="589">before</TOKEN>
<TOKEN end_char="597" id="token-11-7" morph="none" pos="word" start_char="596">us</TOKEN>
<TOKEN end_char="598" id="token-11-8" morph="none" pos="punct" start_char="598">.</TOKEN>
</SEG>
<SEG end_char="674" id="segment-12" start_char="600">
<ORIGINAL_TEXT>There's no preventing them inventing new expressions of their ‘inner self'.</ORIGINAL_TEXT>
<TOKEN end_char="606" id="token-12-0" morph="none" pos="word" start_char="600">There's</TOKEN>
<TOKEN end_char="609" id="token-12-1" morph="none" pos="word" start_char="608">no</TOKEN>
<TOKEN end_char="620" id="token-12-2" morph="none" pos="word" start_char="611">preventing</TOKEN>
<TOKEN end_char="625" id="token-12-3" morph="none" pos="word" start_char="622">them</TOKEN>
<TOKEN end_char="635" id="token-12-4" morph="none" pos="word" start_char="627">inventing</TOKEN>
<TOKEN end_char="639" id="token-12-5" morph="none" pos="word" start_char="637">new</TOKEN>
<TOKEN end_char="651" id="token-12-6" morph="none" pos="word" start_char="641">expressions</TOKEN>
<TOKEN end_char="654" id="token-12-7" morph="none" pos="word" start_char="653">of</TOKEN>
<TOKEN end_char="660" id="token-12-8" morph="none" pos="word" start_char="656">their</TOKEN>
<TOKEN end_char="662" id="token-12-9" morph="none" pos="punct" start_char="662">‘</TOKEN>
<TOKEN end_char="667" id="token-12-10" morph="none" pos="word" start_char="663">inner</TOKEN>
<TOKEN end_char="672" id="token-12-11" morph="none" pos="word" start_char="669">self</TOKEN>
<TOKEN end_char="674" id="token-12-12" morph="none" pos="punct" start_char="673">'.</TOKEN>
</SEG>
<SEG end_char="725" id="segment-13" start_char="677">
<ORIGINAL_TEXT>The best we can do is be as vigilant as possible.</ORIGINAL_TEXT>
<TOKEN end_char="679" id="token-13-0" morph="none" pos="word" start_char="677">The</TOKEN>
<TOKEN end_char="684" id="token-13-1" morph="none" pos="word" start_char="681">best</TOKEN>
<TOKEN end_char="687" id="token-13-2" morph="none" pos="word" start_char="686">we</TOKEN>
<TOKEN end_char="691" id="token-13-3" morph="none" pos="word" start_char="689">can</TOKEN>
<TOKEN end_char="694" id="token-13-4" morph="none" pos="word" start_char="693">do</TOKEN>
<TOKEN end_char="697" id="token-13-5" morph="none" pos="word" start_char="696">is</TOKEN>
<TOKEN end_char="700" id="token-13-6" morph="none" pos="word" start_char="699">be</TOKEN>
<TOKEN end_char="703" id="token-13-7" morph="none" pos="word" start_char="702">as</TOKEN>
<TOKEN end_char="712" id="token-13-8" morph="none" pos="word" start_char="705">vigilant</TOKEN>
<TOKEN end_char="715" id="token-13-9" morph="none" pos="word" start_char="714">as</TOKEN>
<TOKEN end_char="724" id="token-13-10" morph="none" pos="word" start_char="717">possible</TOKEN>
<TOKEN end_char="725" id="token-13-11" morph="none" pos="punct" start_char="725">.</TOKEN>
</SEG>
<SEG end_char="728" id="segment-14" start_char="727">
<ORIGINAL_TEXT>Th</ORIGINAL_TEXT>
<TOKEN end_char="728" id="token-14-0" morph="none" pos="word" start_char="727">Th</TOKEN>
</SEG>
<SEG end_char="785" id="segment-15" start_char="731">
<ORIGINAL_TEXT>The previous SARS was far more dangerous if you got it.</ORIGINAL_TEXT>
<TOKEN end_char="733" id="token-15-0" morph="none" pos="word" start_char="731">The</TOKEN>
<TOKEN end_char="742" id="token-15-1" morph="none" pos="word" start_char="735">previous</TOKEN>
<TOKEN end_char="747" id="token-15-2" morph="none" pos="word" start_char="744">SARS</TOKEN>
<TOKEN end_char="751" id="token-15-3" morph="none" pos="word" start_char="749">was</TOKEN>
<TOKEN end_char="755" id="token-15-4" morph="none" pos="word" start_char="753">far</TOKEN>
<TOKEN end_char="760" id="token-15-5" morph="none" pos="word" start_char="757">more</TOKEN>
<TOKEN end_char="770" id="token-15-6" morph="none" pos="word" start_char="762">dangerous</TOKEN>
<TOKEN end_char="773" id="token-15-7" morph="none" pos="word" start_char="772">if</TOKEN>
<TOKEN end_char="777" id="token-15-8" morph="none" pos="word" start_char="775">you</TOKEN>
<TOKEN end_char="781" id="token-15-9" morph="none" pos="word" start_char="779">got</TOKEN>
<TOKEN end_char="784" id="token-15-10" morph="none" pos="word" start_char="783">it</TOKEN>
<TOKEN end_char="785" id="token-15-11" morph="none" pos="punct" start_char="785">.</TOKEN>
</SEG>
<SEG end_char="881" id="segment-16" start_char="787">
<ORIGINAL_TEXT>This new that that causes the COVID-19 disease, the virus that causes it, is also a SARS virus.</ORIGINAL_TEXT>
<TOKEN end_char="790" id="token-16-0" morph="none" pos="word" start_char="787">This</TOKEN>
<TOKEN end_char="794" id="token-16-1" morph="none" pos="word" start_char="792">new</TOKEN>
<TOKEN end_char="799" id="token-16-2" morph="none" pos="word" start_char="796">that</TOKEN>
<TOKEN end_char="804" id="token-16-3" morph="none" pos="word" start_char="801">that</TOKEN>
<TOKEN end_char="811" id="token-16-4" morph="none" pos="word" start_char="806">causes</TOKEN>
<TOKEN end_char="815" id="token-16-5" morph="none" pos="word" start_char="813">the</TOKEN>
<TOKEN end_char="824" id="token-16-6" morph="none" pos="unknown" start_char="817">COVID-19</TOKEN>
<TOKEN end_char="832" id="token-16-7" morph="none" pos="word" start_char="826">disease</TOKEN>
<TOKEN end_char="833" id="token-16-8" morph="none" pos="punct" start_char="833">,</TOKEN>
<TOKEN end_char="837" id="token-16-9" morph="none" pos="word" start_char="835">the</TOKEN>
<TOKEN end_char="843" id="token-16-10" morph="none" pos="word" start_char="839">virus</TOKEN>
<TOKEN end_char="848" id="token-16-11" morph="none" pos="word" start_char="845">that</TOKEN>
<TOKEN end_char="855" id="token-16-12" morph="none" pos="word" start_char="850">causes</TOKEN>
<TOKEN end_char="858" id="token-16-13" morph="none" pos="word" start_char="857">it</TOKEN>
<TOKEN end_char="859" id="token-16-14" morph="none" pos="punct" start_char="859">,</TOKEN>
<TOKEN end_char="862" id="token-16-15" morph="none" pos="word" start_char="861">is</TOKEN>
<TOKEN end_char="867" id="token-16-16" morph="none" pos="word" start_char="864">also</TOKEN>
<TOKEN end_char="869" id="token-16-17" morph="none" pos="word" start_char="869">a</TOKEN>
<TOKEN end_char="874" id="token-16-18" morph="none" pos="word" start_char="871">SARS</TOKEN>
<TOKEN end_char="880" id="token-16-19" morph="none" pos="word" start_char="876">virus</TOKEN>
<TOKEN end_char="881" id="token-16-20" morph="none" pos="punct" start_char="881">.</TOKEN>
</SEG>
<SEG end_char="905" id="segment-17" start_char="883">
<ORIGINAL_TEXT>It’s called SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN end_char="886" id="token-17-0" morph="none" pos="word" start_char="883">It’s</TOKEN>
<TOKEN end_char="893" id="token-17-1" morph="none" pos="word" start_char="888">called</TOKEN>
<TOKEN end_char="904" id="token-17-2" morph="none" pos="unknown" start_char="895">SARS-CoV-2</TOKEN>
<TOKEN end_char="905" id="token-17-3" morph="none" pos="punct" start_char="905">.</TOKEN>
</SEG>
<SEG end_char="936" id="segment-18" start_char="907">
<ORIGINAL_TEXT>Also called novel coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="910" id="token-18-0" morph="none" pos="word" start_char="907">Also</TOKEN>
<TOKEN end_char="917" id="token-18-1" morph="none" pos="word" start_char="912">called</TOKEN>
<TOKEN end_char="923" id="token-18-2" morph="none" pos="word" start_char="919">novel</TOKEN>
<TOKEN end_char="935" id="token-18-3" morph="none" pos="word" start_char="925">coronavirus</TOKEN>
<TOKEN end_char="936" id="token-18-4" morph="none" pos="punct" start_char="936">.</TOKEN>
</SEG>
<SEG end_char="976" id="segment-19" start_char="938">
<ORIGINAL_TEXT>The virus itself isn’t called COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="940" id="token-19-0" morph="none" pos="word" start_char="938">The</TOKEN>
<TOKEN end_char="946" id="token-19-1" morph="none" pos="word" start_char="942">virus</TOKEN>
<TOKEN end_char="953" id="token-19-2" morph="none" pos="word" start_char="948">itself</TOKEN>
<TOKEN end_char="959" id="token-19-3" morph="none" pos="word" start_char="955">isn’t</TOKEN>
<TOKEN end_char="966" id="token-19-4" morph="none" pos="word" start_char="961">called</TOKEN>
<TOKEN end_char="975" id="token-19-5" morph="none" pos="unknown" start_char="968">COVID-19</TOKEN>
<TOKEN end_char="976" id="token-19-6" morph="none" pos="punct" start_char="976">.</TOKEN>
</SEG>
<SEG end_char="1018" id="segment-20" start_char="978">
<ORIGINAL_TEXT>The disease it causes is called COVID-19.</ORIGINAL_TEXT>
<TOKEN end_char="980" id="token-20-0" morph="none" pos="word" start_char="978">The</TOKEN>
<TOKEN end_char="988" id="token-20-1" morph="none" pos="word" start_char="982">disease</TOKEN>
<TOKEN end_char="991" id="token-20-2" morph="none" pos="word" start_char="990">it</TOKEN>
<TOKEN end_char="998" id="token-20-3" morph="none" pos="word" start_char="993">causes</TOKEN>
<TOKEN end_char="1001" id="token-20-4" morph="none" pos="word" start_char="1000">is</TOKEN>
<TOKEN end_char="1008" id="token-20-5" morph="none" pos="word" start_char="1003">called</TOKEN>
<TOKEN end_char="1017" id="token-20-6" morph="none" pos="unknown" start_char="1010">COVID-19</TOKEN>
<TOKEN end_char="1018" id="token-20-7" morph="none" pos="punct" start_char="1018">.</TOKEN>
</SEG>
<SEG end_char="1122" id="segment-21" start_char="1021">
<ORIGINAL_TEXT>So anyway, this new novel coronavirus, can spread when no symptoms are there or before symptoms arise.</ORIGINAL_TEXT>
<TOKEN end_char="1022" id="token-21-0" morph="none" pos="word" start_char="1021">So</TOKEN>
<TOKEN end_char="1029" id="token-21-1" morph="none" pos="word" start_char="1024">anyway</TOKEN>
<TOKEN end_char="1030" id="token-21-2" morph="none" pos="punct" start_char="1030">,</TOKEN>
<TOKEN end_char="1035" id="token-21-3" morph="none" pos="word" start_char="1032">this</TOKEN>
<TOKEN end_char="1039" id="token-21-4" morph="none" pos="word" start_char="1037">new</TOKEN>
<TOKEN end_char="1045" id="token-21-5" morph="none" pos="word" start_char="1041">novel</TOKEN>
<TOKEN end_char="1057" id="token-21-6" morph="none" pos="word" start_char="1047">coronavirus</TOKEN>
<TOKEN end_char="1058" id="token-21-7" morph="none" pos="punct" start_char="1058">,</TOKEN>
<TOKEN end_char="1062" id="token-21-8" morph="none" pos="word" start_char="1060">can</TOKEN>
<TOKEN end_char="1069" id="token-21-9" morph="none" pos="word" start_char="1064">spread</TOKEN>
<TOKEN end_char="1074" id="token-21-10" morph="none" pos="word" start_char="1071">when</TOKEN>
<TOKEN end_char="1077" id="token-21-11" morph="none" pos="word" start_char="1076">no</TOKEN>
<TOKEN end_char="1086" id="token-21-12" morph="none" pos="word" start_char="1079">symptoms</TOKEN>
<TOKEN end_char="1090" id="token-21-13" morph="none" pos="word" start_char="1088">are</TOKEN>
<TOKEN end_char="1096" id="token-21-14" morph="none" pos="word" start_char="1092">there</TOKEN>
<TOKEN end_char="1099" id="token-21-15" morph="none" pos="word" start_char="1098">or</TOKEN>
<TOKEN end_char="1106" id="token-21-16" morph="none" pos="word" start_char="1101">before</TOKEN>
<TOKEN end_char="1115" id="token-21-17" morph="none" pos="word" start_char="1108">symptoms</TOKEN>
<TOKEN end_char="1121" id="token-21-18" morph="none" pos="word" start_char="1117">arise</TOKEN>
<TOKEN end_char="1122" id="token-21-19" morph="none" pos="punct" start_char="1122">.</TOKEN>
</SEG>
<SEG end_char="1150" id="segment-22" start_char="1124">
<ORIGINAL_TEXT>It makes it rather stealth.</ORIGINAL_TEXT>
<TOKEN end_char="1125" id="token-22-0" morph="none" pos="word" start_char="1124">It</TOKEN>
<TOKEN end_char="1131" id="token-22-1" morph="none" pos="word" start_char="1127">makes</TOKEN>
<TOKEN end_char="1134" id="token-22-2" morph="none" pos="word" start_char="1133">it</TOKEN>
<TOKEN end_char="1141" id="token-22-3" morph="none" pos="word" start_char="1136">rather</TOKEN>
<TOKEN end_char="1149" id="token-22-4" morph="none" pos="word" start_char="1143">stealth</TOKEN>
<TOKEN end_char="1150" id="token-22-5" morph="none" pos="punct" start_char="1150">.</TOKEN>
</SEG>
<SEG end_char="1257" id="segment-23" start_char="1152">
<ORIGINAL_TEXT>Also… and this is not discussed much, many people actually *DO* get symptoms, but those symptoms are mild.</ORIGINAL_TEXT>
<TOKEN end_char="1155" id="token-23-0" morph="none" pos="word" start_char="1152">Also</TOKEN>
<TOKEN end_char="1156" id="token-23-1" morph="none" pos="punct" start_char="1156">…</TOKEN>
<TOKEN end_char="1160" id="token-23-2" morph="none" pos="word" start_char="1158">and</TOKEN>
<TOKEN end_char="1165" id="token-23-3" morph="none" pos="word" start_char="1162">this</TOKEN>
<TOKEN end_char="1168" id="token-23-4" morph="none" pos="word" start_char="1167">is</TOKEN>
<TOKEN end_char="1172" id="token-23-5" morph="none" pos="word" start_char="1170">not</TOKEN>
<TOKEN end_char="1182" id="token-23-6" morph="none" pos="word" start_char="1174">discussed</TOKEN>
<TOKEN end_char="1187" id="token-23-7" morph="none" pos="word" start_char="1184">much</TOKEN>
<TOKEN end_char="1188" id="token-23-8" morph="none" pos="punct" start_char="1188">,</TOKEN>
<TOKEN end_char="1193" id="token-23-9" morph="none" pos="word" start_char="1190">many</TOKEN>
<TOKEN end_char="1200" id="token-23-10" morph="none" pos="word" start_char="1195">people</TOKEN>
<TOKEN end_char="1209" id="token-23-11" morph="none" pos="word" start_char="1202">actually</TOKEN>
<TOKEN end_char="1211" id="token-23-12" morph="none" pos="punct" start_char="1211">*</TOKEN>
<TOKEN end_char="1213" id="token-23-13" morph="none" pos="word" start_char="1212">DO</TOKEN>
<TOKEN end_char="1214" id="token-23-14" morph="none" pos="punct" start_char="1214">*</TOKEN>
<TOKEN end_char="1218" id="token-23-15" morph="none" pos="word" start_char="1216">get</TOKEN>
<TOKEN end_char="1227" id="token-23-16" morph="none" pos="word" start_char="1220">symptoms</TOKEN>
<TOKEN end_char="1228" id="token-23-17" morph="none" pos="punct" start_char="1228">,</TOKEN>
<TOKEN end_char="1232" id="token-23-18" morph="none" pos="word" start_char="1230">but</TOKEN>
<TOKEN end_char="1238" id="token-23-19" morph="none" pos="word" start_char="1234">those</TOKEN>
<TOKEN end_char="1247" id="token-23-20" morph="none" pos="word" start_char="1240">symptoms</TOKEN>
<TOKEN end_char="1251" id="token-23-21" morph="none" pos="word" start_char="1249">are</TOKEN>
<TOKEN end_char="1256" id="token-23-22" morph="none" pos="word" start_char="1253">mild</TOKEN>
<TOKEN end_char="1257" id="token-23-23" morph="none" pos="punct" start_char="1257">.</TOKEN>
</SEG>
<SEG end_char="1283" id="segment-24" start_char="1259">
<ORIGINAL_TEXT>A mild fever for example.</ORIGINAL_TEXT>
<TOKEN end_char="1259" id="token-24-0" morph="none" pos="word" start_char="1259">A</TOKEN>
<TOKEN end_char="1264" id="token-24-1" morph="none" pos="word" start_char="1261">mild</TOKEN>
<TOKEN end_char="1270" id="token-24-2" morph="none" pos="word" start_char="1266">fever</TOKEN>
<TOKEN end_char="1274" id="token-24-3" morph="none" pos="word" start_char="1272">for</TOKEN>
<TOKEN end_char="1282" id="token-24-4" morph="none" pos="word" start_char="1276">example</TOKEN>
<TOKEN end_char="1283" id="token-24-5" morph="none" pos="punct" start_char="1283">.</TOKEN>
</SEG>
<SEG end_char="1331" id="segment-25" start_char="1285">
<ORIGINAL_TEXT>The problem is that people can’t be bothered or</ORIGINAL_TEXT>
<TOKEN end_char="1287" id="token-25-0" morph="none" pos="word" start_char="1285">The</TOKEN>
<TOKEN end_char="1295" id="token-25-1" morph="none" pos="word" start_char="1289">problem</TOKEN>
<TOKEN end_char="1298" id="token-25-2" morph="none" pos="word" start_char="1297">is</TOKEN>
<TOKEN end_char="1303" id="token-25-3" morph="none" pos="word" start_char="1300">that</TOKEN>
<TOKEN end_char="1310" id="token-25-4" morph="none" pos="word" start_char="1305">people</TOKEN>
<TOKEN end_char="1316" id="token-25-5" morph="none" pos="word" start_char="1312">can’t</TOKEN>
<TOKEN end_char="1319" id="token-25-6" morph="none" pos="word" start_char="1318">be</TOKEN>
<TOKEN end_char="1328" id="token-25-7" morph="none" pos="word" start_char="1321">bothered</TOKEN>
<TOKEN end_char="1331" id="token-25-8" morph="none" pos="word" start_char="1330">or</TOKEN>
</SEG>
<SEG end_char="1381" id="segment-26" start_char="1334">
<ORIGINAL_TEXT>You know the answer already as you said…"like it</ORIGINAL_TEXT>
<TOKEN end_char="1336" id="token-26-0" morph="none" pos="word" start_char="1334">You</TOKEN>
<TOKEN end_char="1341" id="token-26-1" morph="none" pos="word" start_char="1338">know</TOKEN>
<TOKEN end_char="1345" id="token-26-2" morph="none" pos="word" start_char="1343">the</TOKEN>
<TOKEN end_char="1352" id="token-26-3" morph="none" pos="word" start_char="1347">answer</TOKEN>
<TOKEN end_char="1360" id="token-26-4" morph="none" pos="word" start_char="1354">already</TOKEN>
<TOKEN end_char="1363" id="token-26-5" morph="none" pos="word" start_char="1362">as</TOKEN>
<TOKEN end_char="1367" id="token-26-6" morph="none" pos="word" start_char="1365">you</TOKEN>
<TOKEN end_char="1378" id="token-26-7" morph="none" pos="unknown" start_char="1369">said…"like</TOKEN>
<TOKEN end_char="1381" id="token-26-8" morph="none" pos="word" start_char="1380">it</TOKEN>
</SEG>
<SEG end_char="1408" id="segment-27" start_char="1384">
<ORIGINAL_TEXT>Here is my 2 cents worth…</ORIGINAL_TEXT>
<TOKEN end_char="1387" id="token-27-0" morph="none" pos="word" start_char="1384">Here</TOKEN>
<TOKEN end_char="1390" id="token-27-1" morph="none" pos="word" start_char="1389">is</TOKEN>
<TOKEN end_char="1393" id="token-27-2" morph="none" pos="word" start_char="1392">my</TOKEN>
<TOKEN end_char="1395" id="token-27-3" morph="none" pos="word" start_char="1395">2</TOKEN>
<TOKEN end_char="1401" id="token-27-4" morph="none" pos="word" start_char="1397">cents</TOKEN>
<TOKEN end_char="1407" id="token-27-5" morph="none" pos="word" start_char="1403">worth</TOKEN>
<TOKEN end_char="1408" id="token-27-6" morph="none" pos="punct" start_char="1408">…</TOKEN>
</SEG>
<SEG end_char="1530" id="segment-28" start_char="1411">
<ORIGINAL_TEXT>China has the political will, discipline, and resources to do what they have to do to solve whatever problems they face.</ORIGINAL_TEXT>
<TOKEN end_char="1415" id="token-28-0" morph="none" pos="word" start_char="1411">China</TOKEN>
<TOKEN end_char="1419" id="token-28-1" morph="none" pos="word" start_char="1417">has</TOKEN>
<TOKEN end_char="1423" id="token-28-2" morph="none" pos="word" start_char="1421">the</TOKEN>
<TOKEN end_char="1433" id="token-28-3" morph="none" pos="word" start_char="1425">political</TOKEN>
<TOKEN end_char="1438" id="token-28-4" morph="none" pos="word" start_char="1435">will</TOKEN>
<TOKEN end_char="1439" id="token-28-5" morph="none" pos="punct" start_char="1439">,</TOKEN>
<TOKEN end_char="1450" id="token-28-6" morph="none" pos="word" start_char="1441">discipline</TOKEN>
<TOKEN end_char="1451" id="token-28-7" morph="none" pos="punct" start_char="1451">,</TOKEN>
<TOKEN end_char="1455" id="token-28-8" morph="none" pos="word" start_char="1453">and</TOKEN>
<TOKEN end_char="1465" id="token-28-9" morph="none" pos="word" start_char="1457">resources</TOKEN>
<TOKEN end_char="1468" id="token-28-10" morph="none" pos="word" start_char="1467">to</TOKEN>
<TOKEN end_char="1471" id="token-28-11" morph="none" pos="word" start_char="1470">do</TOKEN>
<TOKEN end_char="1476" id="token-28-12" morph="none" pos="word" start_char="1473">what</TOKEN>
<TOKEN end_char="1481" id="token-28-13" morph="none" pos="word" start_char="1478">they</TOKEN>
<TOKEN end_char="1486" id="token-28-14" morph="none" pos="word" start_char="1483">have</TOKEN>
<TOKEN end_char="1489" id="token-28-15" morph="none" pos="word" start_char="1488">to</TOKEN>
<TOKEN end_char="1492" id="token-28-16" morph="none" pos="word" start_char="1491">do</TOKEN>
<TOKEN end_char="1495" id="token-28-17" morph="none" pos="word" start_char="1494">to</TOKEN>
<TOKEN end_char="1501" id="token-28-18" morph="none" pos="word" start_char="1497">solve</TOKEN>
<TOKEN end_char="1510" id="token-28-19" morph="none" pos="word" start_char="1503">whatever</TOKEN>
<TOKEN end_char="1519" id="token-28-20" morph="none" pos="word" start_char="1512">problems</TOKEN>
<TOKEN end_char="1524" id="token-28-21" morph="none" pos="word" start_char="1521">they</TOKEN>
<TOKEN end_char="1529" id="token-28-22" morph="none" pos="word" start_char="1526">face</TOKEN>
<TOKEN end_char="1530" id="token-28-23" morph="none" pos="punct" start_char="1530">.</TOKEN>
</SEG>
<SEG end_char="1625" id="segment-29" start_char="1532">
<ORIGINAL_TEXT>Once they realise the coronavirus flu is not just your common flu, they mobilized into action.</ORIGINAL_TEXT>
<TOKEN end_char="1535" id="token-29-0" morph="none" pos="word" start_char="1532">Once</TOKEN>
<TOKEN end_char="1540" id="token-29-1" morph="none" pos="word" start_char="1537">they</TOKEN>
<TOKEN end_char="1548" id="token-29-2" morph="none" pos="word" start_char="1542">realise</TOKEN>
<TOKEN end_char="1552" id="token-29-3" morph="none" pos="word" start_char="1550">the</TOKEN>
<TOKEN end_char="1564" id="token-29-4" morph="none" pos="word" start_char="1554">coronavirus</TOKEN>
<TOKEN end_char="1568" id="token-29-5" morph="none" pos="word" start_char="1566">flu</TOKEN>
<TOKEN end_char="1571" id="token-29-6" morph="none" pos="word" start_char="1570">is</TOKEN>
<TOKEN end_char="1575" id="token-29-7" morph="none" pos="word" start_char="1573">not</TOKEN>
<TOKEN end_char="1580" id="token-29-8" morph="none" pos="word" start_char="1577">just</TOKEN>
<TOKEN end_char="1585" id="token-29-9" morph="none" pos="word" start_char="1582">your</TOKEN>
<TOKEN end_char="1592" id="token-29-10" morph="none" pos="word" start_char="1587">common</TOKEN>
<TOKEN end_char="1596" id="token-29-11" morph="none" pos="word" start_char="1594">flu</TOKEN>
<TOKEN end_char="1597" id="token-29-12" morph="none" pos="punct" start_char="1597">,</TOKEN>
<TOKEN end_char="1602" id="token-29-13" morph="none" pos="word" start_char="1599">they</TOKEN>
<TOKEN end_char="1612" id="token-29-14" morph="none" pos="word" start_char="1604">mobilized</TOKEN>
<TOKEN end_char="1617" id="token-29-15" morph="none" pos="word" start_char="1614">into</TOKEN>
<TOKEN end_char="1624" id="token-29-16" morph="none" pos="word" start_char="1619">action</TOKEN>
<TOKEN end_char="1625" id="token-29-17" morph="none" pos="punct" start_char="1625">.</TOKEN>
</SEG>
<SEG end_char="1701" id="segment-30" start_char="1627">
<ORIGINAL_TEXT>They shutdown and literally quarantined Wuhan, a city of 11 million people.</ORIGINAL_TEXT>
<TOKEN end_char="1630" id="token-30-0" morph="none" pos="word" start_char="1627">They</TOKEN>
<TOKEN end_char="1639" id="token-30-1" morph="none" pos="word" start_char="1632">shutdown</TOKEN>
<TOKEN end_char="1643" id="token-30-2" morph="none" pos="word" start_char="1641">and</TOKEN>
<TOKEN end_char="1653" id="token-30-3" morph="none" pos="word" start_char="1645">literally</TOKEN>
<TOKEN end_char="1665" id="token-30-4" morph="none" pos="word" start_char="1655">quarantined</TOKEN>
<TOKEN end_char="1671" id="token-30-5" morph="none" pos="word" start_char="1667">Wuhan</TOKEN>
<TOKEN end_char="1672" id="token-30-6" morph="none" pos="punct" start_char="1672">,</TOKEN>
<TOKEN end_char="1674" id="token-30-7" morph="none" pos="word" start_char="1674">a</TOKEN>
<TOKEN end_char="1679" id="token-30-8" morph="none" pos="word" start_char="1676">city</TOKEN>
<TOKEN end_char="1682" id="token-30-9" morph="none" pos="word" start_char="1681">of</TOKEN>
<TOKEN end_char="1685" id="token-30-10" morph="none" pos="word" start_char="1684">11</TOKEN>
<TOKEN end_char="1693" id="token-30-11" morph="none" pos="word" start_char="1687">million</TOKEN>
<TOKEN end_char="1700" id="token-30-12" morph="none" pos="word" start_char="1695">people</TOKEN>
<TOKEN end_char="1701" id="token-30-13" morph="none" pos="punct" start_char="1701">.</TOKEN>
</SEG>
<SEG end_char="1729" id="segment-31" start_char="1703">
<ORIGINAL_TEXT>Which country can do this ?</ORIGINAL_TEXT>
<TOKEN end_char="1707" id="token-31-0" morph="none" pos="word" start_char="1703">Which</TOKEN>
<TOKEN end_char="1715" id="token-31-1" morph="none" pos="word" start_char="1709">country</TOKEN>
<TOKEN end_char="1719" id="token-31-2" morph="none" pos="word" start_char="1717">can</TOKEN>
<TOKEN end_char="1722" id="token-31-3" morph="none" pos="word" start_char="1721">do</TOKEN>
<TOKEN end_char="1727" id="token-31-4" morph="none" pos="word" start_char="1724">this</TOKEN>
<TOKEN end_char="1729" id="token-31-5" morph="none" pos="punct" start_char="1729">?</TOKEN>
</SEG>
<SEG end_char="1844" id="segment-32" start_char="1731">
<ORIGINAL_TEXT>They mobilized their medical resources into Hubei province immediately, and built a 1000 bed hospital in 6 days !!</ORIGINAL_TEXT>
<TOKEN end_char="1734" id="token-32-0" morph="none" pos="word" start_char="1731">They</TOKEN>
<TOKEN end_char="1744" id="token-32-1" morph="none" pos="word" start_char="1736">mobilized</TOKEN>
<TOKEN end_char="1750" id="token-32-2" morph="none" pos="word" start_char="1746">their</TOKEN>
<TOKEN end_char="1758" id="token-32-3" morph="none" pos="word" start_char="1752">medical</TOKEN>
<TOKEN end_char="1768" id="token-32-4" morph="none" pos="word" start_char="1760">resources</TOKEN>
<TOKEN end_char="1773" id="token-32-5" morph="none" pos="word" start_char="1770">into</TOKEN>
<TOKEN end_char="1779" id="token-32-6" morph="none" pos="word" start_char="1775">Hubei</TOKEN>
<TOKEN end_char="1788" id="token-32-7" morph="none" pos="word" start_char="1781">province</TOKEN>
<TOKEN end_char="1800" id="token-32-8" morph="none" pos="word" start_char="1790">immediately</TOKEN>
<TOKEN end_char="1801" id="token-32-9" morph="none" pos="punct" start_char="1801">,</TOKEN>
<TOKEN end_char="1805" id="token-32-10" morph="none" pos="word" start_char="1803">and</TOKEN>
<TOKEN end_char="1811" id="token-32-11" morph="none" pos="word" start_char="1807">built</TOKEN>
<TOKEN end_char="1813" id="token-32-12" morph="none" pos="word" start_char="1813">a</TOKEN>
<TOKEN end_char="1818" id="token-32-13" morph="none" pos="word" start_char="1815">1000</TOKEN>
<TOKEN end_char="1822" id="token-32-14" morph="none" pos="word" start_char="1820">bed</TOKEN>
<TOKEN end_char="1831" id="token-32-15" morph="none" pos="word" start_char="1824">hospital</TOKEN>
<TOKEN end_char="1834" id="token-32-16" morph="none" pos="word" start_char="1833">in</TOKEN>
<TOKEN end_char="1836" id="token-32-17" morph="none" pos="word" start_char="1836">6</TOKEN>
<TOKEN end_char="1841" id="token-32-18" morph="none" pos="word" start_char="1838">days</TOKEN>
<TOKEN end_char="1844" id="token-32-19" morph="none" pos="punct" start_char="1843">!!</TOKEN>
</SEG>
<SEG end_char="1923" id="segment-33" start_char="1847">
<ORIGINAL_TEXT>Of course they will have to discipline and change the poor personal hygiene h</ORIGINAL_TEXT>
<TOKEN end_char="1848" id="token-33-0" morph="none" pos="word" start_char="1847">Of</TOKEN>
<TOKEN end_char="1855" id="token-33-1" morph="none" pos="word" start_char="1850">course</TOKEN>
<TOKEN end_char="1860" id="token-33-2" morph="none" pos="word" start_char="1857">they</TOKEN>
<TOKEN end_char="1865" id="token-33-3" morph="none" pos="word" start_char="1862">will</TOKEN>
<TOKEN end_char="1870" id="token-33-4" morph="none" pos="word" start_char="1867">have</TOKEN>
<TOKEN end_char="1873" id="token-33-5" morph="none" pos="word" start_char="1872">to</TOKEN>
<TOKEN end_char="1884" id="token-33-6" morph="none" pos="word" start_char="1875">discipline</TOKEN>
<TOKEN end_char="1888" id="token-33-7" morph="none" pos="word" start_char="1886">and</TOKEN>
<TOKEN end_char="1895" id="token-33-8" morph="none" pos="word" start_char="1890">change</TOKEN>
<TOKEN end_char="1899" id="token-33-9" morph="none" pos="word" start_char="1897">the</TOKEN>
<TOKEN end_char="1904" id="token-33-10" morph="none" pos="word" start_char="1901">poor</TOKEN>
<TOKEN end_char="1913" id="token-33-11" morph="none" pos="word" start_char="1906">personal</TOKEN>
<TOKEN end_char="1921" id="token-33-12" morph="none" pos="word" start_char="1915">hygiene</TOKEN>
<TOKEN end_char="1923" id="token-33-13" morph="none" pos="word" start_char="1923">h</TOKEN>
</SEG>
<SEG end_char="1947" id="segment-34" start_char="1926">
<ORIGINAL_TEXT>Thank you for the A2A:</ORIGINAL_TEXT>
<TOKEN end_char="1930" id="token-34-0" morph="none" pos="word" start_char="1926">Thank</TOKEN>
<TOKEN end_char="1934" id="token-34-1" morph="none" pos="word" start_char="1932">you</TOKEN>
<TOKEN end_char="1938" id="token-34-2" morph="none" pos="word" start_char="1936">for</TOKEN>
<TOKEN end_char="1942" id="token-34-3" morph="none" pos="word" start_char="1940">the</TOKEN>
<TOKEN end_char="1946" id="token-34-4" morph="none" pos="word" start_char="1944">A2A</TOKEN>
<TOKEN end_char="1947" id="token-34-5" morph="none" pos="punct" start_char="1947">:</TOKEN>
</SEG>
<SEG end_char="2103" id="segment-35" start_char="1950">
<ORIGINAL_TEXT>Is it true that unlike SARS and MERS, the coronavirus can yield mild or asymptomatic cases that are more difficult to detect, making it harder to contain?</ORIGINAL_TEXT>
<TOKEN end_char="1951" id="token-35-0" morph="none" pos="word" start_char="1950">Is</TOKEN>
<TOKEN end_char="1954" id="token-35-1" morph="none" pos="word" start_char="1953">it</TOKEN>
<TOKEN end_char="1959" id="token-35-2" morph="none" pos="word" start_char="1956">true</TOKEN>
<TOKEN end_char="1964" id="token-35-3" morph="none" pos="word" start_char="1961">that</TOKEN>
<TOKEN end_char="1971" id="token-35-4" morph="none" pos="word" start_char="1966">unlike</TOKEN>
<TOKEN end_char="1976" id="token-35-5" morph="none" pos="word" start_char="1973">SARS</TOKEN>
<TOKEN end_char="1980" id="token-35-6" morph="none" pos="word" start_char="1978">and</TOKEN>
<TOKEN end_char="1985" id="token-35-7" morph="none" pos="word" start_char="1982">MERS</TOKEN>
<TOKEN end_char="1986" id="token-35-8" morph="none" pos="punct" start_char="1986">,</TOKEN>
<TOKEN end_char="1990" id="token-35-9" morph="none" pos="word" start_char="1988">the</TOKEN>
<TOKEN end_char="2002" id="token-35-10" morph="none" pos="word" start_char="1992">coronavirus</TOKEN>
<TOKEN end_char="2006" id="token-35-11" morph="none" pos="word" start_char="2004">can</TOKEN>
<TOKEN end_char="2012" id="token-35-12" morph="none" pos="word" start_char="2008">yield</TOKEN>
<TOKEN end_char="2017" id="token-35-13" morph="none" pos="word" start_char="2014">mild</TOKEN>
<TOKEN end_char="2020" id="token-35-14" morph="none" pos="word" start_char="2019">or</TOKEN>
<TOKEN end_char="2033" id="token-35-15" morph="none" pos="word" start_char="2022">asymptomatic</TOKEN>
<TOKEN end_char="2039" id="token-35-16" morph="none" pos="word" start_char="2035">cases</TOKEN>
<TOKEN end_char="2044" id="token-35-17" morph="none" pos="word" start_char="2041">that</TOKEN>
<TOKEN end_char="2048" id="token-35-18" morph="none" pos="word" start_char="2046">are</TOKEN>
<TOKEN end_char="2053" id="token-35-19" morph="none" pos="word" start_char="2050">more</TOKEN>
<TOKEN end_char="2063" id="token-35-20" morph="none" pos="word" start_char="2055">difficult</TOKEN>
<TOKEN end_char="2066" id="token-35-21" morph="none" pos="word" start_char="2065">to</TOKEN>
<TOKEN end_char="2073" id="token-35-22" morph="none" pos="word" start_char="2068">detect</TOKEN>
<TOKEN end_char="2074" id="token-35-23" morph="none" pos="punct" start_char="2074">,</TOKEN>
<TOKEN end_char="2081" id="token-35-24" morph="none" pos="word" start_char="2076">making</TOKEN>
<TOKEN end_char="2084" id="token-35-25" morph="none" pos="word" start_char="2083">it</TOKEN>
<TOKEN end_char="2091" id="token-35-26" morph="none" pos="word" start_char="2086">harder</TOKEN>
<TOKEN end_char="2094" id="token-35-27" morph="none" pos="word" start_char="2093">to</TOKEN>
<TOKEN end_char="2102" id="token-35-28" morph="none" pos="word" start_char="2096">contain</TOKEN>
<TOKEN end_char="2103" id="token-35-29" morph="none" pos="punct" start_char="2103">?</TOKEN>
</SEG>
<SEG end_char="2270" id="segment-36" start_char="2106">
<ORIGINAL_TEXT>Yes, this is highly likely as a number of cases in Europe have no apparent contact with known cases, have not traveled to areas where known cases have been detected.</ORIGINAL_TEXT>
<TOKEN end_char="2108" id="token-36-0" morph="none" pos="word" start_char="2106">Yes</TOKEN>
<TOKEN end_char="2109" id="token-36-1" morph="none" pos="punct" start_char="2109">,</TOKEN>
<TOKEN end_char="2114" id="token-36-2" morph="none" pos="word" start_char="2111">this</TOKEN>
<TOKEN end_char="2117" id="token-36-3" morph="none" pos="word" start_char="2116">is</TOKEN>
<TOKEN end_char="2124" id="token-36-4" morph="none" pos="word" start_char="2119">highly</TOKEN>
<TOKEN end_char="2131" id="token-36-5" morph="none" pos="word" start_char="2126">likely</TOKEN>
<TOKEN end_char="2134" id="token-36-6" morph="none" pos="word" start_char="2133">as</TOKEN>
<TOKEN end_char="2136" id="token-36-7" morph="none" pos="word" start_char="2136">a</TOKEN>
<TOKEN end_char="2143" id="token-36-8" morph="none" pos="word" start_char="2138">number</TOKEN>
<TOKEN end_char="2146" id="token-36-9" morph="none" pos="word" start_char="2145">of</TOKEN>
<TOKEN end_char="2152" id="token-36-10" morph="none" pos="word" start_char="2148">cases</TOKEN>
<TOKEN end_char="2155" id="token-36-11" morph="none" pos="word" start_char="2154">in</TOKEN>
<TOKEN end_char="2162" id="token-36-12" morph="none" pos="word" start_char="2157">Europe</TOKEN>
<TOKEN end_char="2167" id="token-36-13" morph="none" pos="word" start_char="2164">have</TOKEN>
<TOKEN end_char="2170" id="token-36-14" morph="none" pos="word" start_char="2169">no</TOKEN>
<TOKEN end_char="2179" id="token-36-15" morph="none" pos="word" start_char="2172">apparent</TOKEN>
<TOKEN end_char="2187" id="token-36-16" morph="none" pos="word" start_char="2181">contact</TOKEN>
<TOKEN end_char="2192" id="token-36-17" morph="none" pos="word" start_char="2189">with</TOKEN>
<TOKEN end_char="2198" id="token-36-18" morph="none" pos="word" start_char="2194">known</TOKEN>
<TOKEN end_char="2204" id="token-36-19" morph="none" pos="word" start_char="2200">cases</TOKEN>
<TOKEN end_char="2205" id="token-36-20" morph="none" pos="punct" start_char="2205">,</TOKEN>
<TOKEN end_char="2210" id="token-36-21" morph="none" pos="word" start_char="2207">have</TOKEN>
<TOKEN end_char="2214" id="token-36-22" morph="none" pos="word" start_char="2212">not</TOKEN>
<TOKEN end_char="2223" id="token-36-23" morph="none" pos="word" start_char="2216">traveled</TOKEN>
<TOKEN end_char="2226" id="token-36-24" morph="none" pos="word" start_char="2225">to</TOKEN>
<TOKEN end_char="2232" id="token-36-25" morph="none" pos="word" start_char="2228">areas</TOKEN>
<TOKEN end_char="2238" id="token-36-26" morph="none" pos="word" start_char="2234">where</TOKEN>
<TOKEN end_char="2244" id="token-36-27" morph="none" pos="word" start_char="2240">known</TOKEN>
<TOKEN end_char="2250" id="token-36-28" morph="none" pos="word" start_char="2246">cases</TOKEN>
<TOKEN end_char="2255" id="token-36-29" morph="none" pos="word" start_char="2252">have</TOKEN>
<TOKEN end_char="2260" id="token-36-30" morph="none" pos="word" start_char="2257">been</TOKEN>
<TOKEN end_char="2269" id="token-36-31" morph="none" pos="word" start_char="2262">detected</TOKEN>
<TOKEN end_char="2270" id="token-36-32" morph="none" pos="punct" start_char="2270">.</TOKEN>
</SEG>
<SEG end_char="2373" id="segment-37" start_char="2272">
<ORIGINAL_TEXT>We also know that quite a few cases are mild diseases that mimic a normal upper respiratory infection.</ORIGINAL_TEXT>
<TOKEN end_char="2273" id="token-37-0" morph="none" pos="word" start_char="2272">We</TOKEN>
<TOKEN end_char="2278" id="token-37-1" morph="none" pos="word" start_char="2275">also</TOKEN>
<TOKEN end_char="2283" id="token-37-2" morph="none" pos="word" start_char="2280">know</TOKEN>
<TOKEN end_char="2288" id="token-37-3" morph="none" pos="word" start_char="2285">that</TOKEN>
<TOKEN end_char="2294" id="token-37-4" morph="none" pos="word" start_char="2290">quite</TOKEN>
<TOKEN end_char="2296" id="token-37-5" morph="none" pos="word" start_char="2296">a</TOKEN>
<TOKEN end_char="2300" id="token-37-6" morph="none" pos="word" start_char="2298">few</TOKEN>
<TOKEN end_char="2306" id="token-37-7" morph="none" pos="word" start_char="2302">cases</TOKEN>
<TOKEN end_char="2310" id="token-37-8" morph="none" pos="word" start_char="2308">are</TOKEN>
<TOKEN end_char="2315" id="token-37-9" morph="none" pos="word" start_char="2312">mild</TOKEN>
<TOKEN end_char="2324" id="token-37-10" morph="none" pos="word" start_char="2317">diseases</TOKEN>
<TOKEN end_char="2329" id="token-37-11" morph="none" pos="word" start_char="2326">that</TOKEN>
<TOKEN end_char="2335" id="token-37-12" morph="none" pos="word" start_char="2331">mimic</TOKEN>
<TOKEN end_char="2337" id="token-37-13" morph="none" pos="word" start_char="2337">a</TOKEN>
<TOKEN end_char="2344" id="token-37-14" morph="none" pos="word" start_char="2339">normal</TOKEN>
<TOKEN end_char="2350" id="token-37-15" morph="none" pos="word" start_char="2346">upper</TOKEN>
<TOKEN end_char="2362" id="token-37-16" morph="none" pos="word" start_char="2352">respiratory</TOKEN>
<TOKEN end_char="2372" id="token-37-17" morph="none" pos="word" start_char="2364">infection</TOKEN>
<TOKEN end_char="2373" id="token-37-18" morph="none" pos="punct" start_char="2373">.</TOKEN>
</SEG>
<SEG end_char="2530" id="segment-38" start_char="2376">
<ORIGINAL_TEXT>Statistical models that have been applied to the current data from the outbreak indicate that there is probably a considerable number of asymptomatic cases</ORIGINAL_TEXT>
<TOKEN end_char="2386" id="token-38-0" morph="none" pos="word" start_char="2376">Statistical</TOKEN>
<TOKEN end_char="2393" id="token-38-1" morph="none" pos="word" start_char="2388">models</TOKEN>
<TOKEN end_char="2398" id="token-38-2" morph="none" pos="word" start_char="2395">that</TOKEN>
<TOKEN end_char="2403" id="token-38-3" morph="none" pos="word" start_char="2400">have</TOKEN>
<TOKEN end_char="2408" id="token-38-4" morph="none" pos="word" start_char="2405">been</TOKEN>
<TOKEN end_char="2416" id="token-38-5" morph="none" pos="word" start_char="2410">applied</TOKEN>
<TOKEN end_char="2419" id="token-38-6" morph="none" pos="word" start_char="2418">to</TOKEN>
<TOKEN end_char="2423" id="token-38-7" morph="none" pos="word" start_char="2421">the</TOKEN>
<TOKEN end_char="2431" id="token-38-8" morph="none" pos="word" start_char="2425">current</TOKEN>
<TOKEN end_char="2436" id="token-38-9" morph="none" pos="word" start_char="2433">data</TOKEN>
<TOKEN end_char="2441" id="token-38-10" morph="none" pos="word" start_char="2438">from</TOKEN>
<TOKEN end_char="2445" id="token-38-11" morph="none" pos="word" start_char="2443">the</TOKEN>
<TOKEN end_char="2454" id="token-38-12" morph="none" pos="word" start_char="2447">outbreak</TOKEN>
<TOKEN end_char="2463" id="token-38-13" morph="none" pos="word" start_char="2456">indicate</TOKEN>
<TOKEN end_char="2468" id="token-38-14" morph="none" pos="word" start_char="2465">that</TOKEN>
<TOKEN end_char="2474" id="token-38-15" morph="none" pos="word" start_char="2470">there</TOKEN>
<TOKEN end_char="2477" id="token-38-16" morph="none" pos="word" start_char="2476">is</TOKEN>
<TOKEN end_char="2486" id="token-38-17" morph="none" pos="word" start_char="2479">probably</TOKEN>
<TOKEN end_char="2488" id="token-38-18" morph="none" pos="word" start_char="2488">a</TOKEN>
<TOKEN end_char="2501" id="token-38-19" morph="none" pos="word" start_char="2490">considerable</TOKEN>
<TOKEN end_char="2508" id="token-38-20" morph="none" pos="word" start_char="2503">number</TOKEN>
<TOKEN end_char="2511" id="token-38-21" morph="none" pos="word" start_char="2510">of</TOKEN>
<TOKEN end_char="2524" id="token-38-22" morph="none" pos="word" start_char="2513">asymptomatic</TOKEN>
<TOKEN end_char="2530" id="token-38-23" morph="none" pos="word" start_char="2526">cases</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CAB8" lang="spa" raw_text_char_length="1306" raw_text_md5="6a0a153a27093bd3de6c460903331d04" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="119" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Analysis of hospital traffic and search engine data in Wuhan China indicates early disease activity in the Fall of 2019</ORIGINAL_TEXT>
<TOKEN end_char="8" id="token-0-0" morph="none" pos="word" start_char="1">Analysis</TOKEN>
<TOKEN end_char="11" id="token-0-1" morph="none" pos="word" start_char="10">of</TOKEN>
<TOKEN end_char="20" id="token-0-2" morph="none" pos="word" start_char="13">hospital</TOKEN>
<TOKEN end_char="28" id="token-0-3" morph="none" pos="word" start_char="22">traffic</TOKEN>
<TOKEN end_char="32" id="token-0-4" morph="none" pos="word" start_char="30">and</TOKEN>
<TOKEN end_char="39" id="token-0-5" morph="none" pos="word" start_char="34">search</TOKEN>
<TOKEN end_char="46" id="token-0-6" morph="none" pos="word" start_char="41">engine</TOKEN>
<TOKEN end_char="51" id="token-0-7" morph="none" pos="word" start_char="48">data</TOKEN>
<TOKEN end_char="54" id="token-0-8" morph="none" pos="word" start_char="53">in</TOKEN>
<TOKEN end_char="60" id="token-0-9" morph="none" pos="word" start_char="56">Wuhan</TOKEN>
<TOKEN end_char="66" id="token-0-10" morph="none" pos="word" start_char="62">China</TOKEN>
<TOKEN end_char="76" id="token-0-11" morph="none" pos="word" start_char="68">indicates</TOKEN>
<TOKEN end_char="82" id="token-0-12" morph="none" pos="word" start_char="78">early</TOKEN>
<TOKEN end_char="90" id="token-0-13" morph="none" pos="word" start_char="84">disease</TOKEN>
<TOKEN end_char="99" id="token-0-14" morph="none" pos="word" start_char="92">activity</TOKEN>
<TOKEN end_char="102" id="token-0-15" morph="none" pos="word" start_char="101">in</TOKEN>
<TOKEN end_char="106" id="token-0-16" morph="none" pos="word" start_char="104">the</TOKEN>
<TOKEN end_char="111" id="token-0-17" morph="none" pos="word" start_char="108">Fall</TOKEN>
<TOKEN end_char="114" id="token-0-18" morph="none" pos="word" start_char="113">of</TOKEN>
<TOKEN end_char="119" id="token-0-19" morph="none" pos="word" start_char="116">2019</TOKEN>
</SEG>
<SEG end_char="222" id="segment-1" start_char="124">
<ORIGINAL_TEXT>Nsoesie, Elaine Okanyene, Benjamin Rader, Yiyao L. Barnoon, Lauren Goodwin, and John S. Brownstein.</ORIGINAL_TEXT>
<TOKEN end_char="130" id="token-1-0" morph="none" pos="word" start_char="124">Nsoesie</TOKEN>
<TOKEN end_char="131" id="token-1-1" morph="none" pos="punct" start_char="131">,</TOKEN>
<TOKEN end_char="138" id="token-1-2" morph="none" pos="word" start_char="133">Elaine</TOKEN>
<TOKEN end_char="147" id="token-1-3" morph="none" pos="word" start_char="140">Okanyene</TOKEN>
<TOKEN end_char="148" id="token-1-4" morph="none" pos="punct" start_char="148">,</TOKEN>
<TOKEN end_char="157" id="token-1-5" morph="none" pos="word" start_char="150">Benjamin</TOKEN>
<TOKEN end_char="163" id="token-1-6" morph="none" pos="word" start_char="159">Rader</TOKEN>
<TOKEN end_char="164" id="token-1-7" morph="none" pos="punct" start_char="164">,</TOKEN>
<TOKEN end_char="170" id="token-1-8" morph="none" pos="word" start_char="166">Yiyao</TOKEN>
<TOKEN end_char="172" id="token-1-9" morph="none" pos="word" start_char="172">L</TOKEN>
<TOKEN end_char="173" id="token-1-10" morph="none" pos="punct" start_char="173">.</TOKEN>
<TOKEN end_char="181" id="token-1-11" morph="none" pos="word" start_char="175">Barnoon</TOKEN>
<TOKEN end_char="182" id="token-1-12" morph="none" pos="punct" start_char="182">,</TOKEN>
<TOKEN end_char="189" id="token-1-13" morph="none" pos="word" start_char="184">Lauren</TOKEN>
<TOKEN end_char="197" id="token-1-14" morph="none" pos="word" start_char="191">Goodwin</TOKEN>
<TOKEN end_char="198" id="token-1-15" morph="none" pos="punct" start_char="198">,</TOKEN>
<TOKEN end_char="202" id="token-1-16" morph="none" pos="word" start_char="200">and</TOKEN>
<TOKEN end_char="207" id="token-1-17" morph="none" pos="word" start_char="204">John</TOKEN>
<TOKEN end_char="209" id="token-1-18" morph="none" pos="word" start_char="209">S</TOKEN>
<TOKEN end_char="210" id="token-1-19" morph="none" pos="punct" start_char="210">.</TOKEN>
<TOKEN end_char="221" id="token-1-20" morph="none" pos="word" start_char="212">Brownstein</TOKEN>
<TOKEN end_char="222" id="token-1-21" morph="none" pos="punct" start_char="222">.</TOKEN>
</SEG>
<SEG end_char="350" id="segment-2" start_char="224">
<ORIGINAL_TEXT>Analysis of hospital traffic and search engine data in Wuhan China indicates early disease activity in the Fall of 2019 (2020).</ORIGINAL_TEXT>
<TOKEN end_char="231" id="token-2-0" morph="none" pos="word" start_char="224">Analysis</TOKEN>
<TOKEN end_char="234" id="token-2-1" morph="none" pos="word" start_char="233">of</TOKEN>
<TOKEN end_char="243" id="token-2-2" morph="none" pos="word" start_char="236">hospital</TOKEN>
<TOKEN end_char="251" id="token-2-3" morph="none" pos="word" start_char="245">traffic</TOKEN>
<TOKEN end_char="255" id="token-2-4" morph="none" pos="word" start_char="253">and</TOKEN>
<TOKEN end_char="262" id="token-2-5" morph="none" pos="word" start_char="257">search</TOKEN>
<TOKEN end_char="269" id="token-2-6" morph="none" pos="word" start_char="264">engine</TOKEN>
<TOKEN end_char="274" id="token-2-7" morph="none" pos="word" start_char="271">data</TOKEN>
<TOKEN end_char="277" id="token-2-8" morph="none" pos="word" start_char="276">in</TOKEN>
<TOKEN end_char="283" id="token-2-9" morph="none" pos="word" start_char="279">Wuhan</TOKEN>
<TOKEN end_char="289" id="token-2-10" morph="none" pos="word" start_char="285">China</TOKEN>
<TOKEN end_char="299" id="token-2-11" morph="none" pos="word" start_char="291">indicates</TOKEN>
<TOKEN end_char="305" id="token-2-12" morph="none" pos="word" start_char="301">early</TOKEN>
<TOKEN end_char="313" id="token-2-13" morph="none" pos="word" start_char="307">disease</TOKEN>
<TOKEN end_char="322" id="token-2-14" morph="none" pos="word" start_char="315">activity</TOKEN>
<TOKEN end_char="325" id="token-2-15" morph="none" pos="word" start_char="324">in</TOKEN>
<TOKEN end_char="329" id="token-2-16" morph="none" pos="word" start_char="327">the</TOKEN>
<TOKEN end_char="334" id="token-2-17" morph="none" pos="word" start_char="331">Fall</TOKEN>
<TOKEN end_char="337" id="token-2-18" morph="none" pos="word" start_char="336">of</TOKEN>
<TOKEN end_char="342" id="token-2-19" morph="none" pos="word" start_char="339">2019</TOKEN>
<TOKEN end_char="344" id="token-2-20" morph="none" pos="punct" start_char="344">(</TOKEN>
<TOKEN end_char="348" id="token-2-21" morph="none" pos="word" start_char="345">2020</TOKEN>
<TOKEN end_char="350" id="token-2-22" morph="none" pos="punct" start_char="349">).</TOKEN>
</SEG>
<SEG end_char="498" id="segment-3" start_char="353">
<ORIGINAL_TEXT>The global COVID-19 pandemic was originally linked to a zoonotic spillover event in Wuhan’s Huanan Seafood Market in November or December of 2019.</ORIGINAL_TEXT>
<TOKEN end_char="355" id="token-3-0" morph="none" pos="word" start_char="353">The</TOKEN>
<TOKEN end_char="362" id="token-3-1" morph="none" pos="word" start_char="357">global</TOKEN>
<TOKEN end_char="371" id="token-3-2" morph="none" pos="unknown" start_char="364">COVID-19</TOKEN>
<TOKEN end_char="380" id="token-3-3" morph="none" pos="word" start_char="373">pandemic</TOKEN>
<TOKEN end_char="384" id="token-3-4" morph="none" pos="word" start_char="382">was</TOKEN>
<TOKEN end_char="395" id="token-3-5" morph="none" pos="word" start_char="386">originally</TOKEN>
<TOKEN end_char="402" id="token-3-6" morph="none" pos="word" start_char="397">linked</TOKEN>
<TOKEN end_char="405" id="token-3-7" morph="none" pos="word" start_char="404">to</TOKEN>
<TOKEN end_char="407" id="token-3-8" morph="none" pos="word" start_char="407">a</TOKEN>
<TOKEN end_char="416" id="token-3-9" morph="none" pos="word" start_char="409">zoonotic</TOKEN>
<TOKEN end_char="426" id="token-3-10" morph="none" pos="word" start_char="418">spillover</TOKEN>
<TOKEN end_char="432" id="token-3-11" morph="none" pos="word" start_char="428">event</TOKEN>
<TOKEN end_char="435" id="token-3-12" morph="none" pos="word" start_char="434">in</TOKEN>
<TOKEN end_char="443" id="token-3-13" morph="none" pos="word" start_char="437">Wuhan’s</TOKEN>
<TOKEN end_char="450" id="token-3-14" morph="none" pos="word" start_char="445">Huanan</TOKEN>
<TOKEN end_char="458" id="token-3-15" morph="none" pos="word" start_char="452">Seafood</TOKEN>
<TOKEN end_char="465" id="token-3-16" morph="none" pos="word" start_char="460">Market</TOKEN>
<TOKEN end_char="468" id="token-3-17" morph="none" pos="word" start_char="467">in</TOKEN>
<TOKEN end_char="477" id="token-3-18" morph="none" pos="word" start_char="470">November</TOKEN>
<TOKEN end_char="480" id="token-3-19" morph="none" pos="word" start_char="479">or</TOKEN>
<TOKEN end_char="489" id="token-3-20" morph="none" pos="word" start_char="482">December</TOKEN>
<TOKEN end_char="492" id="token-3-21" morph="none" pos="word" start_char="491">of</TOKEN>
<TOKEN end_char="497" id="token-3-22" morph="none" pos="word" start_char="494">2019</TOKEN>
<TOKEN end_char="498" id="token-3-23" morph="none" pos="punct" start_char="498">.</TOKEN>
</SEG>
<SEG end_char="610" id="segment-4" start_char="500">
<ORIGINAL_TEXT>However, recent evidence suggests that the virus may have already been circulating at the time of the outbreak.</ORIGINAL_TEXT>
<TOKEN end_char="506" id="token-4-0" morph="none" pos="word" start_char="500">However</TOKEN>
<TOKEN end_char="507" id="token-4-1" morph="none" pos="punct" start_char="507">,</TOKEN>
<TOKEN end_char="514" id="token-4-2" morph="none" pos="word" start_char="509">recent</TOKEN>
<TOKEN end_char="523" id="token-4-3" morph="none" pos="word" start_char="516">evidence</TOKEN>
<TOKEN end_char="532" id="token-4-4" morph="none" pos="word" start_char="525">suggests</TOKEN>
<TOKEN end_char="537" id="token-4-5" morph="none" pos="word" start_char="534">that</TOKEN>
<TOKEN end_char="541" id="token-4-6" morph="none" pos="word" start_char="539">the</TOKEN>
<TOKEN end_char="547" id="token-4-7" morph="none" pos="word" start_char="543">virus</TOKEN>
<TOKEN end_char="551" id="token-4-8" morph="none" pos="word" start_char="549">may</TOKEN>
<TOKEN end_char="556" id="token-4-9" morph="none" pos="word" start_char="553">have</TOKEN>
<TOKEN end_char="564" id="token-4-10" morph="none" pos="word" start_char="558">already</TOKEN>
<TOKEN end_char="569" id="token-4-11" morph="none" pos="word" start_char="566">been</TOKEN>
<TOKEN end_char="581" id="token-4-12" morph="none" pos="word" start_char="571">circulating</TOKEN>
<TOKEN end_char="584" id="token-4-13" morph="none" pos="word" start_char="583">at</TOKEN>
<TOKEN end_char="588" id="token-4-14" morph="none" pos="word" start_char="586">the</TOKEN>
<TOKEN end_char="593" id="token-4-15" morph="none" pos="word" start_char="590">time</TOKEN>
<TOKEN end_char="596" id="token-4-16" morph="none" pos="word" start_char="595">of</TOKEN>
<TOKEN end_char="600" id="token-4-17" morph="none" pos="word" start_char="598">the</TOKEN>
<TOKEN end_char="609" id="token-4-18" morph="none" pos="word" start_char="602">outbreak</TOKEN>
<TOKEN end_char="610" id="token-4-19" morph="none" pos="punct" start_char="610">.</TOKEN>
</SEG>
<SEG end_char="786" id="segment-5" start_char="612">
<ORIGINAL_TEXT>Here we use previously validated data streams - satellite imagery of hospital parking lots and Baidu search queries of disease related terms - to investigate this possibility.</ORIGINAL_TEXT>
<TOKEN end_char="615" id="token-5-0" morph="none" pos="word" start_char="612">Here</TOKEN>
<TOKEN end_char="618" id="token-5-1" morph="none" pos="word" start_char="617">we</TOKEN>
<TOKEN end_char="622" id="token-5-2" morph="none" pos="word" start_char="620">use</TOKEN>
<TOKEN end_char="633" id="token-5-3" morph="none" pos="word" start_char="624">previously</TOKEN>
<TOKEN end_char="643" id="token-5-4" morph="none" pos="word" start_char="635">validated</TOKEN>
<TOKEN end_char="648" id="token-5-5" morph="none" pos="word" start_char="645">data</TOKEN>
<TOKEN end_char="656" id="token-5-6" morph="none" pos="word" start_char="650">streams</TOKEN>
<TOKEN end_char="658" id="token-5-7" morph="none" pos="punct" start_char="658">-</TOKEN>
<TOKEN end_char="668" id="token-5-8" morph="none" pos="word" start_char="660">satellite</TOKEN>
<TOKEN end_char="676" id="token-5-9" morph="none" pos="word" start_char="670">imagery</TOKEN>
<TOKEN end_char="679" id="token-5-10" morph="none" pos="word" start_char="678">of</TOKEN>
<TOKEN end_char="688" id="token-5-11" morph="none" pos="word" start_char="681">hospital</TOKEN>
<TOKEN end_char="696" id="token-5-12" morph="none" pos="word" start_char="690">parking</TOKEN>
<TOKEN end_char="701" id="token-5-13" morph="none" pos="word" start_char="698">lots</TOKEN>
<TOKEN end_char="705" id="token-5-14" morph="none" pos="word" start_char="703">and</TOKEN>
<TOKEN end_char="711" id="token-5-15" morph="none" pos="word" start_char="707">Baidu</TOKEN>
<TOKEN end_char="718" id="token-5-16" morph="none" pos="word" start_char="713">search</TOKEN>
<TOKEN end_char="726" id="token-5-17" morph="none" pos="word" start_char="720">queries</TOKEN>
<TOKEN end_char="729" id="token-5-18" morph="none" pos="word" start_char="728">of</TOKEN>
<TOKEN end_char="737" id="token-5-19" morph="none" pos="word" start_char="731">disease</TOKEN>
<TOKEN end_char="745" id="token-5-20" morph="none" pos="word" start_char="739">related</TOKEN>
<TOKEN end_char="751" id="token-5-21" morph="none" pos="word" start_char="747">terms</TOKEN>
<TOKEN end_char="753" id="token-5-22" morph="none" pos="punct" start_char="753">-</TOKEN>
<TOKEN end_char="756" id="token-5-23" morph="none" pos="word" start_char="755">to</TOKEN>
<TOKEN end_char="768" id="token-5-24" morph="none" pos="word" start_char="758">investigate</TOKEN>
<TOKEN end_char="773" id="token-5-25" morph="none" pos="word" start_char="770">this</TOKEN>
<TOKEN end_char="785" id="token-5-26" morph="none" pos="word" start_char="775">possibility</TOKEN>
<TOKEN end_char="786" id="token-5-27" morph="none" pos="punct" start_char="786">.</TOKEN>
</SEG>
<SEG end_char="897" id="segment-6" start_char="788">
<ORIGINAL_TEXT>We observe an upward trend in hospital traffic and search volume beginning in late Summer and early Fall 2019.</ORIGINAL_TEXT>
<TOKEN end_char="789" id="token-6-0" morph="none" pos="word" start_char="788">We</TOKEN>
<TOKEN end_char="797" id="token-6-1" morph="none" pos="word" start_char="791">observe</TOKEN>
<TOKEN end_char="800" id="token-6-2" morph="none" pos="word" start_char="799">an</TOKEN>
<TOKEN end_char="807" id="token-6-3" morph="none" pos="word" start_char="802">upward</TOKEN>
<TOKEN end_char="813" id="token-6-4" morph="none" pos="word" start_char="809">trend</TOKEN>
<TOKEN end_char="816" id="token-6-5" morph="none" pos="word" start_char="815">in</TOKEN>
<TOKEN end_char="825" id="token-6-6" morph="none" pos="word" start_char="818">hospital</TOKEN>
<TOKEN end_char="833" id="token-6-7" morph="none" pos="word" start_char="827">traffic</TOKEN>
<TOKEN end_char="837" id="token-6-8" morph="none" pos="word" start_char="835">and</TOKEN>
<TOKEN end_char="844" id="token-6-9" morph="none" pos="word" start_char="839">search</TOKEN>
<TOKEN end_char="851" id="token-6-10" morph="none" pos="word" start_char="846">volume</TOKEN>
<TOKEN end_char="861" id="token-6-11" morph="none" pos="word" start_char="853">beginning</TOKEN>
<TOKEN end_char="864" id="token-6-12" morph="none" pos="word" start_char="863">in</TOKEN>
<TOKEN end_char="869" id="token-6-13" morph="none" pos="word" start_char="866">late</TOKEN>
<TOKEN end_char="876" id="token-6-14" morph="none" pos="word" start_char="871">Summer</TOKEN>
<TOKEN end_char="880" id="token-6-15" morph="none" pos="word" start_char="878">and</TOKEN>
<TOKEN end_char="886" id="token-6-16" morph="none" pos="word" start_char="882">early</TOKEN>
<TOKEN end_char="891" id="token-6-17" morph="none" pos="word" start_char="888">Fall</TOKEN>
<TOKEN end_char="896" id="token-6-18" morph="none" pos="word" start_char="893">2019</TOKEN>
<TOKEN end_char="897" id="token-6-19" morph="none" pos="punct" start_char="897">.</TOKEN>
</SEG>
<SEG end_char="1119" id="segment-7" start_char="899">
<ORIGINAL_TEXT>While queries of the respiratory symptom "cough" show seasonal fluctuations coinciding with yearly influenza seasons, "diarrhea" is a more COVID-19 specific symptom and only shows an association with the current epidemic.</ORIGINAL_TEXT>
<TOKEN end_char="903" id="token-7-0" morph="none" pos="word" start_char="899">While</TOKEN>
<TOKEN end_char="911" id="token-7-1" morph="none" pos="word" start_char="905">queries</TOKEN>
<TOKEN end_char="914" id="token-7-2" morph="none" pos="word" start_char="913">of</TOKEN>
<TOKEN end_char="918" id="token-7-3" morph="none" pos="word" start_char="916">the</TOKEN>
<TOKEN end_char="930" id="token-7-4" morph="none" pos="word" start_char="920">respiratory</TOKEN>
<TOKEN end_char="938" id="token-7-5" morph="none" pos="word" start_char="932">symptom</TOKEN>
<TOKEN end_char="940" id="token-7-6" morph="none" pos="punct" start_char="940">"</TOKEN>
<TOKEN end_char="945" id="token-7-7" morph="none" pos="word" start_char="941">cough</TOKEN>
<TOKEN end_char="946" id="token-7-8" morph="none" pos="punct" start_char="946">"</TOKEN>
<TOKEN end_char="951" id="token-7-9" morph="none" pos="word" start_char="948">show</TOKEN>
<TOKEN end_char="960" id="token-7-10" morph="none" pos="word" start_char="953">seasonal</TOKEN>
<TOKEN end_char="973" id="token-7-11" morph="none" pos="word" start_char="962">fluctuations</TOKEN>
<TOKEN end_char="984" id="token-7-12" morph="none" pos="word" start_char="975">coinciding</TOKEN>
<TOKEN end_char="989" id="token-7-13" morph="none" pos="word" start_char="986">with</TOKEN>
<TOKEN end_char="996" id="token-7-14" morph="none" pos="word" start_char="991">yearly</TOKEN>
<TOKEN end_char="1006" id="token-7-15" morph="none" pos="word" start_char="998">influenza</TOKEN>
<TOKEN end_char="1014" id="token-7-16" morph="none" pos="word" start_char="1008">seasons</TOKEN>
<TOKEN end_char="1015" id="token-7-17" morph="none" pos="punct" start_char="1015">,</TOKEN>
<TOKEN end_char="1017" id="token-7-18" morph="none" pos="punct" start_char="1017">"</TOKEN>
<TOKEN end_char="1025" id="token-7-19" morph="none" pos="word" start_char="1018">diarrhea</TOKEN>
<TOKEN end_char="1026" id="token-7-20" morph="none" pos="punct" start_char="1026">"</TOKEN>
<TOKEN end_char="1029" id="token-7-21" morph="none" pos="word" start_char="1028">is</TOKEN>
<TOKEN end_char="1031" id="token-7-22" morph="none" pos="word" start_char="1031">a</TOKEN>
<TOKEN end_char="1036" id="token-7-23" morph="none" pos="word" start_char="1033">more</TOKEN>
<TOKEN end_char="1045" id="token-7-24" morph="none" pos="unknown" start_char="1038">COVID-19</TOKEN>
<TOKEN end_char="1054" id="token-7-25" morph="none" pos="word" start_char="1047">specific</TOKEN>
<TOKEN end_char="1062" id="token-7-26" morph="none" pos="word" start_char="1056">symptom</TOKEN>
<TOKEN end_char="1066" id="token-7-27" morph="none" pos="word" start_char="1064">and</TOKEN>
<TOKEN end_char="1071" id="token-7-28" morph="none" pos="word" start_char="1068">only</TOKEN>
<TOKEN end_char="1077" id="token-7-29" morph="none" pos="word" start_char="1073">shows</TOKEN>
<TOKEN end_char="1080" id="token-7-30" morph="none" pos="word" start_char="1079">an</TOKEN>
<TOKEN end_char="1092" id="token-7-31" morph="none" pos="word" start_char="1082">association</TOKEN>
<TOKEN end_char="1097" id="token-7-32" morph="none" pos="word" start_char="1094">with</TOKEN>
<TOKEN end_char="1101" id="token-7-33" morph="none" pos="word" start_char="1099">the</TOKEN>
<TOKEN end_char="1109" id="token-7-34" morph="none" pos="word" start_char="1103">current</TOKEN>
<TOKEN end_char="1118" id="token-7-35" morph="none" pos="word" start_char="1111">epidemic</TOKEN>
<TOKEN end_char="1119" id="token-7-36" morph="none" pos="punct" start_char="1119">.</TOKEN>
</SEG>
<SEG end_char="1302" id="segment-8" start_char="1121">
<ORIGINAL_TEXT>The increase of both signals precede the documented start of the COVID-19 pandemic in December, highlighting the value of novel digital sources for surveillance of emerging pathogens</ORIGINAL_TEXT>
<TOKEN end_char="1123" id="token-8-0" morph="none" pos="word" start_char="1121">The</TOKEN>
<TOKEN end_char="1132" id="token-8-1" morph="none" pos="word" start_char="1125">increase</TOKEN>
<TOKEN end_char="1135" id="token-8-2" morph="none" pos="word" start_char="1134">of</TOKEN>
<TOKEN end_char="1140" id="token-8-3" morph="none" pos="word" start_char="1137">both</TOKEN>
<TOKEN end_char="1148" id="token-8-4" morph="none" pos="word" start_char="1142">signals</TOKEN>
<TOKEN end_char="1156" id="token-8-5" morph="none" pos="word" start_char="1150">precede</TOKEN>
<TOKEN end_char="1160" id="token-8-6" morph="none" pos="word" start_char="1158">the</TOKEN>
<TOKEN end_char="1171" id="token-8-7" morph="none" pos="word" start_char="1162">documented</TOKEN>
<TOKEN end_char="1177" id="token-8-8" morph="none" pos="word" start_char="1173">start</TOKEN>
<TOKEN end_char="1180" id="token-8-9" morph="none" pos="word" start_char="1179">of</TOKEN>
<TOKEN end_char="1184" id="token-8-10" morph="none" pos="word" start_char="1182">the</TOKEN>
<TOKEN end_char="1193" id="token-8-11" morph="none" pos="unknown" start_char="1186">COVID-19</TOKEN>
<TOKEN end_char="1202" id="token-8-12" morph="none" pos="word" start_char="1195">pandemic</TOKEN>
<TOKEN end_char="1205" id="token-8-13" morph="none" pos="word" start_char="1204">in</TOKEN>
<TOKEN end_char="1214" id="token-8-14" morph="none" pos="word" start_char="1207">December</TOKEN>
<TOKEN end_char="1215" id="token-8-15" morph="none" pos="punct" start_char="1215">,</TOKEN>
<TOKEN end_char="1228" id="token-8-16" morph="none" pos="word" start_char="1217">highlighting</TOKEN>
<TOKEN end_char="1232" id="token-8-17" morph="none" pos="word" start_char="1230">the</TOKEN>
<TOKEN end_char="1238" id="token-8-18" morph="none" pos="word" start_char="1234">value</TOKEN>
<TOKEN end_char="1241" id="token-8-19" morph="none" pos="word" start_char="1240">of</TOKEN>
<TOKEN end_char="1247" id="token-8-20" morph="none" pos="word" start_char="1243">novel</TOKEN>
<TOKEN end_char="1255" id="token-8-21" morph="none" pos="word" start_char="1249">digital</TOKEN>
<TOKEN end_char="1263" id="token-8-22" morph="none" pos="word" start_char="1257">sources</TOKEN>
<TOKEN end_char="1267" id="token-8-23" morph="none" pos="word" start_char="1265">for</TOKEN>
<TOKEN end_char="1280" id="token-8-24" morph="none" pos="word" start_char="1269">surveillance</TOKEN>
<TOKEN end_char="1283" id="token-8-25" morph="none" pos="word" start_char="1282">of</TOKEN>
<TOKEN end_char="1292" id="token-8-26" morph="none" pos="word" start_char="1285">emerging</TOKEN>
<TOKEN end_char="1302" id="token-8-27" morph="none" pos="word" start_char="1294">pathogens</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
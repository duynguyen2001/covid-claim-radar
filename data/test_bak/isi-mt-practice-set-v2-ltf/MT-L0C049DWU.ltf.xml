<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C049DWU" lang="spa" raw_text_char_length="7778" raw_text_md5="95d0ec841b4333e2a482645bebc489c7" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="70" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Luc Montaigner, Nobel de Medicina, el virus se creo en un laboratorio.</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">Luc</TOKEN>
<TOKEN end_char="14" id="token-0-1" morph="none" pos="word" start_char="5">Montaigner</TOKEN>
<TOKEN end_char="15" id="token-0-2" morph="none" pos="punct" start_char="15">,</TOKEN>
<TOKEN end_char="21" id="token-0-3" morph="none" pos="word" start_char="17">Nobel</TOKEN>
<TOKEN end_char="24" id="token-0-4" morph="none" pos="word" start_char="23">de</TOKEN>
<TOKEN end_char="33" id="token-0-5" morph="none" pos="word" start_char="26">Medicina</TOKEN>
<TOKEN end_char="34" id="token-0-6" morph="none" pos="punct" start_char="34">,</TOKEN>
<TOKEN end_char="37" id="token-0-7" morph="none" pos="word" start_char="36">el</TOKEN>
<TOKEN end_char="43" id="token-0-8" morph="none" pos="word" start_char="39">virus</TOKEN>
<TOKEN end_char="46" id="token-0-9" morph="none" pos="word" start_char="45">se</TOKEN>
<TOKEN end_char="51" id="token-0-10" morph="none" pos="word" start_char="48">creo</TOKEN>
<TOKEN end_char="54" id="token-0-11" morph="none" pos="word" start_char="53">en</TOKEN>
<TOKEN end_char="57" id="token-0-12" morph="none" pos="word" start_char="56">un</TOKEN>
<TOKEN end_char="69" id="token-0-13" morph="none" pos="word" start_char="59">laboratorio</TOKEN>
<TOKEN end_char="70" id="token-0-14" morph="none" pos="punct" start_char="70">.</TOKEN>
<TRANSLATED_TEXT>Luc Montaigner, Nobel Prize in Medicine, the virus was created in a laboratory.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="126" id="segment-1" start_char="74">
<ORIGINAL_TEXT>http://spanews24h.com/luc-montagnier...n-adn-del-vih/</ORIGINAL_TEXT>
<TOKEN end_char="126" id="token-1-0" morph="none" pos="url" start_char="74">http://spanews24h.com/luc-montagnier...n-adn-del-vih/</TOKEN>
<TRANSLATED_TEXT>http: / / spanews24h.com / luc-montagnier... n-adn-del-hiv /</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="456" id="segment-2" start_char="129">
<ORIGINAL_TEXT>A medida que el mundo se enfrenta a la pandemia de Covid-19 y los científicos intentan encontrar una vacuna para erradicar el virus, Luc Montagnier, virólogo francés y ganador del Premio Nobel de medicina en 2008 después del descubrimiento del SIDA, acaba de presentar una hipótesis controvertida sobre el origen del SARS-CoV-2.</ORIGINAL_TEXT>
<TOKEN end_char="129" id="token-2-0" morph="none" pos="word" start_char="129">A</TOKEN>
<TOKEN end_char="136" id="token-2-1" morph="none" pos="word" start_char="131">medida</TOKEN>
<TOKEN end_char="140" id="token-2-2" morph="none" pos="word" start_char="138">que</TOKEN>
<TOKEN end_char="143" id="token-2-3" morph="none" pos="word" start_char="142">el</TOKEN>
<TOKEN end_char="149" id="token-2-4" morph="none" pos="word" start_char="145">mundo</TOKEN>
<TOKEN end_char="152" id="token-2-5" morph="none" pos="word" start_char="151">se</TOKEN>
<TOKEN end_char="161" id="token-2-6" morph="none" pos="word" start_char="154">enfrenta</TOKEN>
<TOKEN end_char="163" id="token-2-7" morph="none" pos="word" start_char="163">a</TOKEN>
<TOKEN end_char="166" id="token-2-8" morph="none" pos="word" start_char="165">la</TOKEN>
<TOKEN end_char="175" id="token-2-9" morph="none" pos="word" start_char="168">pandemia</TOKEN>
<TOKEN end_char="178" id="token-2-10" morph="none" pos="word" start_char="177">de</TOKEN>
<TOKEN end_char="187" id="token-2-11" morph="none" pos="unknown" start_char="180">Covid-19</TOKEN>
<TOKEN end_char="189" id="token-2-12" morph="none" pos="word" start_char="189">y</TOKEN>
<TOKEN end_char="193" id="token-2-13" morph="none" pos="word" start_char="191">los</TOKEN>
<TOKEN end_char="205" id="token-2-14" morph="none" pos="word" start_char="195">científicos</TOKEN>
<TOKEN end_char="214" id="token-2-15" morph="none" pos="word" start_char="207">intentan</TOKEN>
<TOKEN end_char="224" id="token-2-16" morph="none" pos="word" start_char="216">encontrar</TOKEN>
<TOKEN end_char="228" id="token-2-17" morph="none" pos="word" start_char="226">una</TOKEN>
<TOKEN end_char="235" id="token-2-18" morph="none" pos="word" start_char="230">vacuna</TOKEN>
<TOKEN end_char="240" id="token-2-19" morph="none" pos="word" start_char="237">para</TOKEN>
<TOKEN end_char="250" id="token-2-20" morph="none" pos="word" start_char="242">erradicar</TOKEN>
<TOKEN end_char="253" id="token-2-21" morph="none" pos="word" start_char="252">el</TOKEN>
<TOKEN end_char="259" id="token-2-22" morph="none" pos="word" start_char="255">virus</TOKEN>
<TOKEN end_char="260" id="token-2-23" morph="none" pos="punct" start_char="260">,</TOKEN>
<TOKEN end_char="264" id="token-2-24" morph="none" pos="word" start_char="262">Luc</TOKEN>
<TOKEN end_char="275" id="token-2-25" morph="none" pos="word" start_char="266">Montagnier</TOKEN>
<TOKEN end_char="276" id="token-2-26" morph="none" pos="punct" start_char="276">,</TOKEN>
<TOKEN end_char="285" id="token-2-27" morph="none" pos="word" start_char="278">virólogo</TOKEN>
<TOKEN end_char="293" id="token-2-28" morph="none" pos="word" start_char="287">francés</TOKEN>
<TOKEN end_char="295" id="token-2-29" morph="none" pos="word" start_char="295">y</TOKEN>
<TOKEN end_char="303" id="token-2-30" morph="none" pos="word" start_char="297">ganador</TOKEN>
<TOKEN end_char="307" id="token-2-31" morph="none" pos="word" start_char="305">del</TOKEN>
<TOKEN end_char="314" id="token-2-32" morph="none" pos="word" start_char="309">Premio</TOKEN>
<TOKEN end_char="320" id="token-2-33" morph="none" pos="word" start_char="316">Nobel</TOKEN>
<TOKEN end_char="323" id="token-2-34" morph="none" pos="word" start_char="322">de</TOKEN>
<TOKEN end_char="332" id="token-2-35" morph="none" pos="word" start_char="325">medicina</TOKEN>
<TOKEN end_char="335" id="token-2-36" morph="none" pos="word" start_char="334">en</TOKEN>
<TOKEN end_char="340" id="token-2-37" morph="none" pos="word" start_char="337">2008</TOKEN>
<TOKEN end_char="348" id="token-2-38" morph="none" pos="word" start_char="342">después</TOKEN>
<TOKEN end_char="352" id="token-2-39" morph="none" pos="word" start_char="350">del</TOKEN>
<TOKEN end_char="367" id="token-2-40" morph="none" pos="word" start_char="354">descubrimiento</TOKEN>
<TOKEN end_char="371" id="token-2-41" morph="none" pos="word" start_char="369">del</TOKEN>
<TOKEN end_char="376" id="token-2-42" morph="none" pos="word" start_char="373">SIDA</TOKEN>
<TOKEN end_char="377" id="token-2-43" morph="none" pos="punct" start_char="377">,</TOKEN>
<TOKEN end_char="383" id="token-2-44" morph="none" pos="word" start_char="379">acaba</TOKEN>
<TOKEN end_char="386" id="token-2-45" morph="none" pos="word" start_char="385">de</TOKEN>
<TOKEN end_char="396" id="token-2-46" morph="none" pos="word" start_char="388">presentar</TOKEN>
<TOKEN end_char="400" id="token-2-47" morph="none" pos="word" start_char="398">una</TOKEN>
<TOKEN end_char="410" id="token-2-48" morph="none" pos="word" start_char="402">hipótesis</TOKEN>
<TOKEN end_char="424" id="token-2-49" morph="none" pos="word" start_char="412">controvertida</TOKEN>
<TOKEN end_char="430" id="token-2-50" morph="none" pos="word" start_char="426">sobre</TOKEN>
<TOKEN end_char="433" id="token-2-51" morph="none" pos="word" start_char="432">el</TOKEN>
<TOKEN end_char="440" id="token-2-52" morph="none" pos="word" start_char="435">origen</TOKEN>
<TOKEN end_char="444" id="token-2-53" morph="none" pos="word" start_char="442">del</TOKEN>
<TOKEN end_char="455" id="token-2-54" morph="none" pos="unknown" start_char="446">SARS-CoV-2</TOKEN>
<TOKEN end_char="456" id="token-2-55" morph="none" pos="punct" start_char="456">.</TOKEN>
<TRANSLATED_TEXT>As the world faces the Covid-19 pandemic and scientists try to find a vaccine to eradicate the virus, Luc Montagnier, a French virologist and 2008 Nobel Prize winner in medicine after the discovery of AIDS, has just presented a controversial hypothesis about the origin of SARS-CoV-2.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="484" id="segment-3" start_char="459">
<ORIGINAL_TEXT>Entrevistado por el sitio.</ORIGINAL_TEXT>
<TOKEN end_char="470" id="token-3-0" morph="none" pos="word" start_char="459">Entrevistado</TOKEN>
<TOKEN end_char="474" id="token-3-1" morph="none" pos="word" start_char="472">por</TOKEN>
<TOKEN end_char="477" id="token-3-2" morph="none" pos="word" start_char="476">el</TOKEN>
<TOKEN end_char="483" id="token-3-3" morph="none" pos="word" start_char="479">sitio</TOKEN>
<TOKEN end_char="484" id="token-3-4" morph="none" pos="punct" start_char="484">.</TOKEN>
<TRANSLATED_TEXT>Interviewed by the site.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="502" id="segment-4" start_char="487">
<ORIGINAL_TEXT>¿Por qué doctor?</ORIGINAL_TEXT>
<TOKEN end_char="487" id="token-4-0" morph="none" pos="punct" start_char="487">¿</TOKEN>
<TOKEN end_char="490" id="token-4-1" morph="none" pos="word" start_char="488">Por</TOKEN>
<TOKEN end_char="494" id="token-4-2" morph="none" pos="word" start_char="492">qué</TOKEN>
<TOKEN end_char="501" id="token-4-3" morph="none" pos="word" start_char="496">doctor</TOKEN>
<TOKEN end_char="502" id="token-4-4" morph="none" pos="punct" start_char="502">?</TOKEN>
<TRANSLATED_TEXT>Why doctor?</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="596" id="segment-5" start_char="505">
<ORIGINAL_TEXT>Este jueves 16 de abril, el profesor francés expresó sus dudas sobre el origen del Covid-19.</ORIGINAL_TEXT>
<TOKEN end_char="508" id="token-5-0" morph="none" pos="word" start_char="505">Este</TOKEN>
<TOKEN end_char="515" id="token-5-1" morph="none" pos="word" start_char="510">jueves</TOKEN>
<TOKEN end_char="518" id="token-5-2" morph="none" pos="word" start_char="517">16</TOKEN>
<TOKEN end_char="521" id="token-5-3" morph="none" pos="word" start_char="520">de</TOKEN>
<TOKEN end_char="527" id="token-5-4" morph="none" pos="word" start_char="523">abril</TOKEN>
<TOKEN end_char="528" id="token-5-5" morph="none" pos="punct" start_char="528">,</TOKEN>
<TOKEN end_char="531" id="token-5-6" morph="none" pos="word" start_char="530">el</TOKEN>
<TOKEN end_char="540" id="token-5-7" morph="none" pos="word" start_char="533">profesor</TOKEN>
<TOKEN end_char="548" id="token-5-8" morph="none" pos="word" start_char="542">francés</TOKEN>
<TOKEN end_char="556" id="token-5-9" morph="none" pos="word" start_char="550">expresó</TOKEN>
<TOKEN end_char="560" id="token-5-10" morph="none" pos="word" start_char="558">sus</TOKEN>
<TOKEN end_char="566" id="token-5-11" morph="none" pos="word" start_char="562">dudas</TOKEN>
<TOKEN end_char="572" id="token-5-12" morph="none" pos="word" start_char="568">sobre</TOKEN>
<TOKEN end_char="575" id="token-5-13" morph="none" pos="word" start_char="574">el</TOKEN>
<TOKEN end_char="582" id="token-5-14" morph="none" pos="word" start_char="577">origen</TOKEN>
<TOKEN end_char="586" id="token-5-15" morph="none" pos="word" start_char="584">del</TOKEN>
<TOKEN end_char="595" id="token-5-16" morph="none" pos="unknown" start_char="588">Covid-19</TOKEN>
<TOKEN end_char="596" id="token-5-17" morph="none" pos="punct" start_char="596">.</TOKEN>
<TRANSLATED_TEXT>This Thursday, April 16, the French professor expressed doubts about the origin of the Covid-19.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="675" id="segment-6" start_char="598">
<ORIGINAL_TEXT>Según él, la aparición del virus en un mercado de vida silvestre en Wuhan es "</ORIGINAL_TEXT>
<TOKEN end_char="602" id="token-6-0" morph="none" pos="word" start_char="598">Según</TOKEN>
<TOKEN end_char="605" id="token-6-1" morph="none" pos="word" start_char="604">él</TOKEN>
<TOKEN end_char="606" id="token-6-2" morph="none" pos="punct" start_char="606">,</TOKEN>
<TOKEN end_char="609" id="token-6-3" morph="none" pos="word" start_char="608">la</TOKEN>
<TOKEN end_char="619" id="token-6-4" morph="none" pos="word" start_char="611">aparición</TOKEN>
<TOKEN end_char="623" id="token-6-5" morph="none" pos="word" start_char="621">del</TOKEN>
<TOKEN end_char="629" id="token-6-6" morph="none" pos="word" start_char="625">virus</TOKEN>
<TOKEN end_char="632" id="token-6-7" morph="none" pos="word" start_char="631">en</TOKEN>
<TOKEN end_char="635" id="token-6-8" morph="none" pos="word" start_char="634">un</TOKEN>
<TOKEN end_char="643" id="token-6-9" morph="none" pos="word" start_char="637">mercado</TOKEN>
<TOKEN end_char="646" id="token-6-10" morph="none" pos="word" start_char="645">de</TOKEN>
<TOKEN end_char="651" id="token-6-11" morph="none" pos="word" start_char="648">vida</TOKEN>
<TOKEN end_char="661" id="token-6-12" morph="none" pos="word" start_char="653">silvestre</TOKEN>
<TOKEN end_char="664" id="token-6-13" morph="none" pos="word" start_char="663">en</TOKEN>
<TOKEN end_char="670" id="token-6-14" morph="none" pos="word" start_char="666">Wuhan</TOKEN>
<TOKEN end_char="673" id="token-6-15" morph="none" pos="word" start_char="672">es</TOKEN>
<TOKEN end_char="675" id="token-6-16" morph="none" pos="punct" start_char="675">"</TOKEN>
<TRANSLATED_TEXT>According to him, the emergence of the virus in a wildlife market in Wuhan is "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="694" id="segment-7" start_char="678">
<ORIGINAL_TEXT>una bella leyenda</ORIGINAL_TEXT>
<TOKEN end_char="680" id="token-7-0" morph="none" pos="word" start_char="678">una</TOKEN>
<TOKEN end_char="686" id="token-7-1" morph="none" pos="word" start_char="682">bella</TOKEN>
<TOKEN end_char="694" id="token-7-2" morph="none" pos="word" start_char="688">leyenda</TOKEN>
<TRANSLATED_TEXT>a beautiful legend</TRANSLATED_TEXT><DETECTED_LANGUAGE>tr</DETECTED_LANGUAGE></SEG>
<SEG end_char="699" id="segment-8" start_char="697">
<ORIGINAL_TEXT>"y"</ORIGINAL_TEXT>
<TOKEN end_char="697" id="token-8-0" morph="none" pos="punct" start_char="697">"</TOKEN>
<TOKEN end_char="698" id="token-8-1" morph="none" pos="word" start_char="698">y</TOKEN>
<TOKEN end_char="699" id="token-8-2" morph="none" pos="punct" start_char="699">"</TOKEN>
<TRANSLATED_TEXT>'y'</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="714" id="segment-9" start_char="702">
<ORIGINAL_TEXT>no es posible</ORIGINAL_TEXT>
<TOKEN end_char="703" id="token-9-0" morph="none" pos="word" start_char="702">no</TOKEN>
<TOKEN end_char="706" id="token-9-1" morph="none" pos="word" start_char="705">es</TOKEN>
<TOKEN end_char="714" id="token-9-2" morph="none" pos="word" start_char="708">posible</TOKEN>
<TRANSLATED_TEXT>not possible</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="718" id="segment-10" start_char="717">
<ORIGINAL_TEXT>".</ORIGINAL_TEXT>
<TOKEN end_char="718" id="token-10-0" morph="none" pos="punct" start_char="717">".</TOKEN>
</SEG>
<SEG end_char="744" id="segment-11" start_char="720">
<ORIGINAL_TEXT>El dice que el Covid-19 "</ORIGINAL_TEXT>
<TOKEN end_char="721" id="token-11-0" morph="none" pos="word" start_char="720">El</TOKEN>
<TOKEN end_char="726" id="token-11-1" morph="none" pos="word" start_char="723">dice</TOKEN>
<TOKEN end_char="730" id="token-11-2" morph="none" pos="word" start_char="728">que</TOKEN>
<TOKEN end_char="733" id="token-11-3" morph="none" pos="word" start_char="732">el</TOKEN>
<TOKEN end_char="742" id="token-11-4" morph="none" pos="unknown" start_char="735">Covid-19</TOKEN>
<TOKEN end_char="744" id="token-11-5" morph="none" pos="punct" start_char="744">"</TOKEN>
<TRANSLATED_TEXT>He says that the Covid-19 "..........</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="777" id="segment-12" start_char="747">
<ORIGINAL_TEXT>sale de un laboratorio de Wuhan</ORIGINAL_TEXT>
<TOKEN end_char="750" id="token-12-0" morph="none" pos="word" start_char="747">sale</TOKEN>
<TOKEN end_char="753" id="token-12-1" morph="none" pos="word" start_char="752">de</TOKEN>
<TOKEN end_char="756" id="token-12-2" morph="none" pos="word" start_char="755">un</TOKEN>
<TOKEN end_char="768" id="token-12-3" morph="none" pos="word" start_char="758">laboratorio</TOKEN>
<TOKEN end_char="771" id="token-12-4" morph="none" pos="word" start_char="770">de</TOKEN>
<TOKEN end_char="777" id="token-12-5" morph="none" pos="word" start_char="773">Wuhan</TOKEN>
<TRANSLATED_TEXT>comes out of a Wuhan laboratory</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="781" id="segment-13" start_char="780">
<ORIGINAL_TEXT>".</ORIGINAL_TEXT>
<TOKEN end_char="781" id="token-13-0" morph="none" pos="punct" start_char="780">".</TOKEN>
</SEG>
<SEG end_char="820" id="segment-14" start_char="783">
<ORIGINAL_TEXT>Luc Montagnier continúa diciendo que "</ORIGINAL_TEXT>
<TOKEN end_char="785" id="token-14-0" morph="none" pos="word" start_char="783">Luc</TOKEN>
<TOKEN end_char="796" id="token-14-1" morph="none" pos="word" start_char="787">Montagnier</TOKEN>
<TOKEN end_char="805" id="token-14-2" morph="none" pos="word" start_char="798">continúa</TOKEN>
<TOKEN end_char="814" id="token-14-3" morph="none" pos="word" start_char="807">diciendo</TOKEN>
<TOKEN end_char="818" id="token-14-4" morph="none" pos="word" start_char="816">que</TOKEN>
<TOKEN end_char="820" id="token-14-5" morph="none" pos="punct" start_char="820">"</TOKEN>
<TRANSLATED_TEXT>Luc Montagnier goes on to say that "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="937" id="segment-15" start_char="823">
<ORIGINAL_TEXT>el laboratorio de la ciudad de Wuhan se ha especializado en estos coronavirus desde principios de la década de 2000</ORIGINAL_TEXT>
<TOKEN end_char="824" id="token-15-0" morph="none" pos="word" start_char="823">el</TOKEN>
<TOKEN end_char="836" id="token-15-1" morph="none" pos="word" start_char="826">laboratorio</TOKEN>
<TOKEN end_char="839" id="token-15-2" morph="none" pos="word" start_char="838">de</TOKEN>
<TOKEN end_char="842" id="token-15-3" morph="none" pos="word" start_char="841">la</TOKEN>
<TOKEN end_char="849" id="token-15-4" morph="none" pos="word" start_char="844">ciudad</TOKEN>
<TOKEN end_char="852" id="token-15-5" morph="none" pos="word" start_char="851">de</TOKEN>
<TOKEN end_char="858" id="token-15-6" morph="none" pos="word" start_char="854">Wuhan</TOKEN>
<TOKEN end_char="861" id="token-15-7" morph="none" pos="word" start_char="860">se</TOKEN>
<TOKEN end_char="864" id="token-15-8" morph="none" pos="word" start_char="863">ha</TOKEN>
<TOKEN end_char="878" id="token-15-9" morph="none" pos="word" start_char="866">especializado</TOKEN>
<TOKEN end_char="881" id="token-15-10" morph="none" pos="word" start_char="880">en</TOKEN>
<TOKEN end_char="887" id="token-15-11" morph="none" pos="word" start_char="883">estos</TOKEN>
<TOKEN end_char="899" id="token-15-12" morph="none" pos="word" start_char="889">coronavirus</TOKEN>
<TOKEN end_char="905" id="token-15-13" morph="none" pos="word" start_char="901">desde</TOKEN>
<TOKEN end_char="916" id="token-15-14" morph="none" pos="word" start_char="907">principios</TOKEN>
<TOKEN end_char="919" id="token-15-15" morph="none" pos="word" start_char="918">de</TOKEN>
<TOKEN end_char="922" id="token-15-16" morph="none" pos="word" start_char="921">la</TOKEN>
<TOKEN end_char="929" id="token-15-17" morph="none" pos="word" start_char="924">década</TOKEN>
<TOKEN end_char="932" id="token-15-18" morph="none" pos="word" start_char="931">de</TOKEN>
<TOKEN end_char="937" id="token-15-19" morph="none" pos="word" start_char="934">2000</TOKEN>
<TRANSLATED_TEXT>The Wuhan city lab has specialized in these coronaviruses since the early 2000s.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="948" id="segment-16" start_char="940">
<ORIGINAL_TEXT>"y posee"</ORIGINAL_TEXT>
<TOKEN end_char="940" id="token-16-0" morph="none" pos="punct" start_char="940">"</TOKEN>
<TOKEN end_char="941" id="token-16-1" morph="none" pos="word" start_char="941">y</TOKEN>
<TOKEN end_char="947" id="token-16-2" morph="none" pos="word" start_char="943">posee</TOKEN>
<TOKEN end_char="948" id="token-16-3" morph="none" pos="punct" start_char="948">"</TOKEN>
<TRANSLATED_TEXT>and possesses</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="974" id="segment-17" start_char="951">
<ORIGINAL_TEXT>experiencia en esta área</ORIGINAL_TEXT>
<TOKEN end_char="961" id="token-17-0" morph="none" pos="word" start_char="951">experiencia</TOKEN>
<TOKEN end_char="964" id="token-17-1" morph="none" pos="word" start_char="963">en</TOKEN>
<TOKEN end_char="969" id="token-17-2" morph="none" pos="word" start_char="966">esta</TOKEN>
<TOKEN end_char="974" id="token-17-3" morph="none" pos="word" start_char="971">área</TOKEN>
<TRANSLATED_TEXT>experience in this area</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="978" id="segment-18" start_char="977">
<ORIGINAL_TEXT>".</ORIGINAL_TEXT>
<TOKEN end_char="978" id="token-18-0" morph="none" pos="punct" start_char="977">".</TOKEN>
</SEG>
<SEG end_char="1223" id="segment-19" start_char="981">
<ORIGINAL_TEXT>Frente a sus comentarios, su interlocutor le pregunta si los rastros de VIH encontrados en el coronavirus no son simplemente Una mutación natural del virus en el cuerpo de un paciente con SIDA.. Luc Montagnier responde negativamente y explica:</ORIGINAL_TEXT>
<TOKEN end_char="986" id="token-19-0" morph="none" pos="word" start_char="981">Frente</TOKEN>
<TOKEN end_char="988" id="token-19-1" morph="none" pos="word" start_char="988">a</TOKEN>
<TOKEN end_char="992" id="token-19-2" morph="none" pos="word" start_char="990">sus</TOKEN>
<TOKEN end_char="1004" id="token-19-3" morph="none" pos="word" start_char="994">comentarios</TOKEN>
<TOKEN end_char="1005" id="token-19-4" morph="none" pos="punct" start_char="1005">,</TOKEN>
<TOKEN end_char="1008" id="token-19-5" morph="none" pos="word" start_char="1007">su</TOKEN>
<TOKEN end_char="1021" id="token-19-6" morph="none" pos="word" start_char="1010">interlocutor</TOKEN>
<TOKEN end_char="1024" id="token-19-7" morph="none" pos="word" start_char="1023">le</TOKEN>
<TOKEN end_char="1033" id="token-19-8" morph="none" pos="word" start_char="1026">pregunta</TOKEN>
<TOKEN end_char="1036" id="token-19-9" morph="none" pos="word" start_char="1035">si</TOKEN>
<TOKEN end_char="1040" id="token-19-10" morph="none" pos="word" start_char="1038">los</TOKEN>
<TOKEN end_char="1048" id="token-19-11" morph="none" pos="word" start_char="1042">rastros</TOKEN>
<TOKEN end_char="1051" id="token-19-12" morph="none" pos="word" start_char="1050">de</TOKEN>
<TOKEN end_char="1055" id="token-19-13" morph="none" pos="word" start_char="1053">VIH</TOKEN>
<TOKEN end_char="1067" id="token-19-14" morph="none" pos="word" start_char="1057">encontrados</TOKEN>
<TOKEN end_char="1070" id="token-19-15" morph="none" pos="word" start_char="1069">en</TOKEN>
<TOKEN end_char="1073" id="token-19-16" morph="none" pos="word" start_char="1072">el</TOKEN>
<TOKEN end_char="1085" id="token-19-17" morph="none" pos="word" start_char="1075">coronavirus</TOKEN>
<TOKEN end_char="1088" id="token-19-18" morph="none" pos="word" start_char="1087">no</TOKEN>
<TOKEN end_char="1092" id="token-19-19" morph="none" pos="word" start_char="1090">son</TOKEN>
<TOKEN end_char="1104" id="token-19-20" morph="none" pos="word" start_char="1094">simplemente</TOKEN>
<TOKEN end_char="1108" id="token-19-21" morph="none" pos="word" start_char="1106">Una</TOKEN>
<TOKEN end_char="1117" id="token-19-22" morph="none" pos="word" start_char="1110">mutación</TOKEN>
<TOKEN end_char="1125" id="token-19-23" morph="none" pos="word" start_char="1119">natural</TOKEN>
<TOKEN end_char="1129" id="token-19-24" morph="none" pos="word" start_char="1127">del</TOKEN>
<TOKEN end_char="1135" id="token-19-25" morph="none" pos="word" start_char="1131">virus</TOKEN>
<TOKEN end_char="1138" id="token-19-26" morph="none" pos="word" start_char="1137">en</TOKEN>
<TOKEN end_char="1141" id="token-19-27" morph="none" pos="word" start_char="1140">el</TOKEN>
<TOKEN end_char="1148" id="token-19-28" morph="none" pos="word" start_char="1143">cuerpo</TOKEN>
<TOKEN end_char="1151" id="token-19-29" morph="none" pos="word" start_char="1150">de</TOKEN>
<TOKEN end_char="1154" id="token-19-30" morph="none" pos="word" start_char="1153">un</TOKEN>
<TOKEN end_char="1163" id="token-19-31" morph="none" pos="word" start_char="1156">paciente</TOKEN>
<TOKEN end_char="1167" id="token-19-32" morph="none" pos="word" start_char="1165">con</TOKEN>
<TOKEN end_char="1172" id="token-19-33" morph="none" pos="word" start_char="1169">SIDA</TOKEN>
<TOKEN end_char="1174" id="token-19-34" morph="none" pos="punct" start_char="1173">..</TOKEN>
<TOKEN end_char="1178" id="token-19-35" morph="none" pos="word" start_char="1176">Luc</TOKEN>
<TOKEN end_char="1189" id="token-19-36" morph="none" pos="word" start_char="1180">Montagnier</TOKEN>
<TOKEN end_char="1198" id="token-19-37" morph="none" pos="word" start_char="1191">responde</TOKEN>
<TOKEN end_char="1212" id="token-19-38" morph="none" pos="word" start_char="1200">negativamente</TOKEN>
<TOKEN end_char="1214" id="token-19-39" morph="none" pos="word" start_char="1214">y</TOKEN>
<TOKEN end_char="1222" id="token-19-40" morph="none" pos="word" start_char="1216">explica</TOKEN>
<TOKEN end_char="1223" id="token-19-41" morph="none" pos="punct" start_char="1223">:</TOKEN>
<TRANSLATED_TEXT>In the face of his comments, his interlocutor asks if the traces of HIV found in the coronavirus are not simply a natural mutation of the virus in the body of an AIDS patient. Luc Montagnier responds negatively and explains:</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1369" id="segment-20" start_char="1226">
<ORIGINAL_TEXT>Para insertar una secuencia de VIH en el genoma necesita herramientas moleculares, no es el paciente quien lo hará, es el hombre de laboratorio.</ORIGINAL_TEXT>
<TOKEN end_char="1229" id="token-20-0" morph="none" pos="word" start_char="1226">Para</TOKEN>
<TOKEN end_char="1238" id="token-20-1" morph="none" pos="word" start_char="1231">insertar</TOKEN>
<TOKEN end_char="1242" id="token-20-2" morph="none" pos="word" start_char="1240">una</TOKEN>
<TOKEN end_char="1252" id="token-20-3" morph="none" pos="word" start_char="1244">secuencia</TOKEN>
<TOKEN end_char="1255" id="token-20-4" morph="none" pos="word" start_char="1254">de</TOKEN>
<TOKEN end_char="1259" id="token-20-5" morph="none" pos="word" start_char="1257">VIH</TOKEN>
<TOKEN end_char="1262" id="token-20-6" morph="none" pos="word" start_char="1261">en</TOKEN>
<TOKEN end_char="1265" id="token-20-7" morph="none" pos="word" start_char="1264">el</TOKEN>
<TOKEN end_char="1272" id="token-20-8" morph="none" pos="word" start_char="1267">genoma</TOKEN>
<TOKEN end_char="1281" id="token-20-9" morph="none" pos="word" start_char="1274">necesita</TOKEN>
<TOKEN end_char="1294" id="token-20-10" morph="none" pos="word" start_char="1283">herramientas</TOKEN>
<TOKEN end_char="1306" id="token-20-11" morph="none" pos="word" start_char="1296">moleculares</TOKEN>
<TOKEN end_char="1307" id="token-20-12" morph="none" pos="punct" start_char="1307">,</TOKEN>
<TOKEN end_char="1310" id="token-20-13" morph="none" pos="word" start_char="1309">no</TOKEN>
<TOKEN end_char="1313" id="token-20-14" morph="none" pos="word" start_char="1312">es</TOKEN>
<TOKEN end_char="1316" id="token-20-15" morph="none" pos="word" start_char="1315">el</TOKEN>
<TOKEN end_char="1325" id="token-20-16" morph="none" pos="word" start_char="1318">paciente</TOKEN>
<TOKEN end_char="1331" id="token-20-17" morph="none" pos="word" start_char="1327">quien</TOKEN>
<TOKEN end_char="1334" id="token-20-18" morph="none" pos="word" start_char="1333">lo</TOKEN>
<TOKEN end_char="1339" id="token-20-19" morph="none" pos="word" start_char="1336">hará</TOKEN>
<TOKEN end_char="1340" id="token-20-20" morph="none" pos="punct" start_char="1340">,</TOKEN>
<TOKEN end_char="1343" id="token-20-21" morph="none" pos="word" start_char="1342">es</TOKEN>
<TOKEN end_char="1346" id="token-20-22" morph="none" pos="word" start_char="1345">el</TOKEN>
<TOKEN end_char="1353" id="token-20-23" morph="none" pos="word" start_char="1348">hombre</TOKEN>
<TOKEN end_char="1356" id="token-20-24" morph="none" pos="word" start_char="1355">de</TOKEN>
<TOKEN end_char="1368" id="token-20-25" morph="none" pos="word" start_char="1358">laboratorio</TOKEN>
<TOKEN end_char="1369" id="token-20-26" morph="none" pos="punct" start_char="1369">.</TOKEN>
<TRANSLATED_TEXT>To insert a sequence of HIV into the genome you need molecular tools, it 's not the patient who' s going to do it, it 's the lab.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1456" id="segment-21" start_char="1374">
<ORIGINAL_TEXT>Unos dicen una cosa y otros otra, al final me creo más JL que a los demás, total...</ORIGINAL_TEXT>
<TOKEN end_char="1377" id="token-21-0" morph="none" pos="word" start_char="1374">Unos</TOKEN>
<TOKEN end_char="1383" id="token-21-1" morph="none" pos="word" start_char="1379">dicen</TOKEN>
<TOKEN end_char="1387" id="token-21-2" morph="none" pos="word" start_char="1385">una</TOKEN>
<TOKEN end_char="1392" id="token-21-3" morph="none" pos="word" start_char="1389">cosa</TOKEN>
<TOKEN end_char="1394" id="token-21-4" morph="none" pos="word" start_char="1394">y</TOKEN>
<TOKEN end_char="1400" id="token-21-5" morph="none" pos="word" start_char="1396">otros</TOKEN>
<TOKEN end_char="1405" id="token-21-6" morph="none" pos="word" start_char="1402">otra</TOKEN>
<TOKEN end_char="1406" id="token-21-7" morph="none" pos="punct" start_char="1406">,</TOKEN>
<TOKEN end_char="1409" id="token-21-8" morph="none" pos="word" start_char="1408">al</TOKEN>
<TOKEN end_char="1415" id="token-21-9" morph="none" pos="word" start_char="1411">final</TOKEN>
<TOKEN end_char="1418" id="token-21-10" morph="none" pos="word" start_char="1417">me</TOKEN>
<TOKEN end_char="1423" id="token-21-11" morph="none" pos="word" start_char="1420">creo</TOKEN>
<TOKEN end_char="1427" id="token-21-12" morph="none" pos="word" start_char="1425">más</TOKEN>
<TOKEN end_char="1430" id="token-21-13" morph="none" pos="word" start_char="1429">JL</TOKEN>
<TOKEN end_char="1434" id="token-21-14" morph="none" pos="word" start_char="1432">que</TOKEN>
<TOKEN end_char="1436" id="token-21-15" morph="none" pos="word" start_char="1436">a</TOKEN>
<TOKEN end_char="1440" id="token-21-16" morph="none" pos="word" start_char="1438">los</TOKEN>
<TOKEN end_char="1446" id="token-21-17" morph="none" pos="word" start_char="1442">demás</TOKEN>
<TOKEN end_char="1447" id="token-21-18" morph="none" pos="punct" start_char="1447">,</TOKEN>
<TOKEN end_char="1453" id="token-21-19" morph="none" pos="word" start_char="1449">total</TOKEN>
<TOKEN end_char="1456" id="token-21-20" morph="none" pos="punct" start_char="1454">...</TOKEN>
<TRANSLATED_TEXT>Some say one thing and others, in the end I believe more JL than others, total...</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1481" id="segment-22" start_char="1462">
<ORIGINAL_TEXT>Nos comen los chinos</ORIGINAL_TEXT>
<TOKEN end_char="1464" id="token-22-0" morph="none" pos="word" start_char="1462">Nos</TOKEN>
<TOKEN end_char="1470" id="token-22-1" morph="none" pos="word" start_char="1466">comen</TOKEN>
<TOKEN end_char="1474" id="token-22-2" morph="none" pos="word" start_char="1472">los</TOKEN>
<TOKEN end_char="1481" id="token-22-3" morph="none" pos="word" start_char="1476">chinos</TOKEN>
<TRANSLATED_TEXT>We're eaten by the Chinese...........</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1781" id="segment-23" start_char="1487">
<ORIGINAL_TEXT>Eso lo sabe todo el mundo, menos los periódicos y las teles que aún no están autorizados a informar al pueblo, como el avión iraní derribado y como cualquier noticia así importante que os dan que la tienes en internet 2 semanas antes, y la gente aún viendo los medios de desinformación oficiales</ORIGINAL_TEXT>
<TOKEN end_char="1489" id="token-23-0" morph="none" pos="word" start_char="1487">Eso</TOKEN>
<TOKEN end_char="1492" id="token-23-1" morph="none" pos="word" start_char="1491">lo</TOKEN>
<TOKEN end_char="1497" id="token-23-2" morph="none" pos="word" start_char="1494">sabe</TOKEN>
<TOKEN end_char="1502" id="token-23-3" morph="none" pos="word" start_char="1499">todo</TOKEN>
<TOKEN end_char="1505" id="token-23-4" morph="none" pos="word" start_char="1504">el</TOKEN>
<TOKEN end_char="1511" id="token-23-5" morph="none" pos="word" start_char="1507">mundo</TOKEN>
<TOKEN end_char="1512" id="token-23-6" morph="none" pos="punct" start_char="1512">,</TOKEN>
<TOKEN end_char="1518" id="token-23-7" morph="none" pos="word" start_char="1514">menos</TOKEN>
<TOKEN end_char="1522" id="token-23-8" morph="none" pos="word" start_char="1520">los</TOKEN>
<TOKEN end_char="1533" id="token-23-9" morph="none" pos="word" start_char="1524">periódicos</TOKEN>
<TOKEN end_char="1535" id="token-23-10" morph="none" pos="word" start_char="1535">y</TOKEN>
<TOKEN end_char="1539" id="token-23-11" morph="none" pos="word" start_char="1537">las</TOKEN>
<TOKEN end_char="1545" id="token-23-12" morph="none" pos="word" start_char="1541">teles</TOKEN>
<TOKEN end_char="1549" id="token-23-13" morph="none" pos="word" start_char="1547">que</TOKEN>
<TOKEN end_char="1553" id="token-23-14" morph="none" pos="word" start_char="1551">aún</TOKEN>
<TOKEN end_char="1556" id="token-23-15" morph="none" pos="word" start_char="1555">no</TOKEN>
<TOKEN end_char="1562" id="token-23-16" morph="none" pos="word" start_char="1558">están</TOKEN>
<TOKEN end_char="1574" id="token-23-17" morph="none" pos="word" start_char="1564">autorizados</TOKEN>
<TOKEN end_char="1576" id="token-23-18" morph="none" pos="word" start_char="1576">a</TOKEN>
<TOKEN end_char="1585" id="token-23-19" morph="none" pos="word" start_char="1578">informar</TOKEN>
<TOKEN end_char="1588" id="token-23-20" morph="none" pos="word" start_char="1587">al</TOKEN>
<TOKEN end_char="1595" id="token-23-21" morph="none" pos="word" start_char="1590">pueblo</TOKEN>
<TOKEN end_char="1596" id="token-23-22" morph="none" pos="punct" start_char="1596">,</TOKEN>
<TOKEN end_char="1601" id="token-23-23" morph="none" pos="word" start_char="1598">como</TOKEN>
<TOKEN end_char="1604" id="token-23-24" morph="none" pos="word" start_char="1603">el</TOKEN>
<TOKEN end_char="1610" id="token-23-25" morph="none" pos="word" start_char="1606">avión</TOKEN>
<TOKEN end_char="1616" id="token-23-26" morph="none" pos="word" start_char="1612">iraní</TOKEN>
<TOKEN end_char="1626" id="token-23-27" morph="none" pos="word" start_char="1618">derribado</TOKEN>
<TOKEN end_char="1628" id="token-23-28" morph="none" pos="word" start_char="1628">y</TOKEN>
<TOKEN end_char="1633" id="token-23-29" morph="none" pos="word" start_char="1630">como</TOKEN>
<TOKEN end_char="1643" id="token-23-30" morph="none" pos="word" start_char="1635">cualquier</TOKEN>
<TOKEN end_char="1651" id="token-23-31" morph="none" pos="word" start_char="1645">noticia</TOKEN>
<TOKEN end_char="1655" id="token-23-32" morph="none" pos="word" start_char="1653">así</TOKEN>
<TOKEN end_char="1666" id="token-23-33" morph="none" pos="word" start_char="1657">importante</TOKEN>
<TOKEN end_char="1670" id="token-23-34" morph="none" pos="word" start_char="1668">que</TOKEN>
<TOKEN end_char="1673" id="token-23-35" morph="none" pos="word" start_char="1672">os</TOKEN>
<TOKEN end_char="1677" id="token-23-36" morph="none" pos="word" start_char="1675">dan</TOKEN>
<TOKEN end_char="1681" id="token-23-37" morph="none" pos="word" start_char="1679">que</TOKEN>
<TOKEN end_char="1684" id="token-23-38" morph="none" pos="word" start_char="1683">la</TOKEN>
<TOKEN end_char="1691" id="token-23-39" morph="none" pos="word" start_char="1686">tienes</TOKEN>
<TOKEN end_char="1694" id="token-23-40" morph="none" pos="word" start_char="1693">en</TOKEN>
<TOKEN end_char="1703" id="token-23-41" morph="none" pos="word" start_char="1696">internet</TOKEN>
<TOKEN end_char="1705" id="token-23-42" morph="none" pos="word" start_char="1705">2</TOKEN>
<TOKEN end_char="1713" id="token-23-43" morph="none" pos="word" start_char="1707">semanas</TOKEN>
<TOKEN end_char="1719" id="token-23-44" morph="none" pos="word" start_char="1715">antes</TOKEN>
<TOKEN end_char="1720" id="token-23-45" morph="none" pos="punct" start_char="1720">,</TOKEN>
<TOKEN end_char="1722" id="token-23-46" morph="none" pos="word" start_char="1722">y</TOKEN>
<TOKEN end_char="1725" id="token-23-47" morph="none" pos="word" start_char="1724">la</TOKEN>
<TOKEN end_char="1731" id="token-23-48" morph="none" pos="word" start_char="1727">gente</TOKEN>
<TOKEN end_char="1735" id="token-23-49" morph="none" pos="word" start_char="1733">aún</TOKEN>
<TOKEN end_char="1742" id="token-23-50" morph="none" pos="word" start_char="1737">viendo</TOKEN>
<TOKEN end_char="1746" id="token-23-51" morph="none" pos="word" start_char="1744">los</TOKEN>
<TOKEN end_char="1753" id="token-23-52" morph="none" pos="word" start_char="1748">medios</TOKEN>
<TOKEN end_char="1756" id="token-23-53" morph="none" pos="word" start_char="1755">de</TOKEN>
<TOKEN end_char="1771" id="token-23-54" morph="none" pos="word" start_char="1758">desinformación</TOKEN>
<TOKEN end_char="1781" id="token-23-55" morph="none" pos="word" start_char="1773">oficiales</TOKEN>
<TRANSLATED_TEXT>Everyone knows that, except the newspapers and the fabrics that are not yet authorized to report to the people, like the downed Iranian plane and like any news so important that they tell you that you have it on the Internet two weeks earlier, and people are still watching the official disinformation media.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1816" id="segment-24" start_char="1787">
<ORIGINAL_TEXT>No sé si lo he entendido bien.</ORIGINAL_TEXT>
<TOKEN end_char="1788" id="token-24-0" morph="none" pos="word" start_char="1787">No</TOKEN>
<TOKEN end_char="1791" id="token-24-1" morph="none" pos="word" start_char="1790">sé</TOKEN>
<TOKEN end_char="1794" id="token-24-2" morph="none" pos="word" start_char="1793">si</TOKEN>
<TOKEN end_char="1797" id="token-24-3" morph="none" pos="word" start_char="1796">lo</TOKEN>
<TOKEN end_char="1800" id="token-24-4" morph="none" pos="word" start_char="1799">he</TOKEN>
<TOKEN end_char="1810" id="token-24-5" morph="none" pos="word" start_char="1802">entendido</TOKEN>
<TOKEN end_char="1815" id="token-24-6" morph="none" pos="word" start_char="1812">bien</TOKEN>
<TOKEN end_char="1816" id="token-24-7" morph="none" pos="punct" start_char="1816">.</TOKEN>
<TRANSLATED_TEXT>I don't know if I got it right.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1889" id="segment-25" start_char="1818">
<ORIGINAL_TEXT>¿Se supone que hay genes del virus del Sida que están en el coronarirus?</ORIGINAL_TEXT>
<TOKEN end_char="1818" id="token-25-0" morph="none" pos="punct" start_char="1818">¿</TOKEN>
<TOKEN end_char="1820" id="token-25-1" morph="none" pos="word" start_char="1819">Se</TOKEN>
<TOKEN end_char="1827" id="token-25-2" morph="none" pos="word" start_char="1822">supone</TOKEN>
<TOKEN end_char="1831" id="token-25-3" morph="none" pos="word" start_char="1829">que</TOKEN>
<TOKEN end_char="1835" id="token-25-4" morph="none" pos="word" start_char="1833">hay</TOKEN>
<TOKEN end_char="1841" id="token-25-5" morph="none" pos="word" start_char="1837">genes</TOKEN>
<TOKEN end_char="1845" id="token-25-6" morph="none" pos="word" start_char="1843">del</TOKEN>
<TOKEN end_char="1851" id="token-25-7" morph="none" pos="word" start_char="1847">virus</TOKEN>
<TOKEN end_char="1855" id="token-25-8" morph="none" pos="word" start_char="1853">del</TOKEN>
<TOKEN end_char="1860" id="token-25-9" morph="none" pos="word" start_char="1857">Sida</TOKEN>
<TOKEN end_char="1864" id="token-25-10" morph="none" pos="word" start_char="1862">que</TOKEN>
<TOKEN end_char="1870" id="token-25-11" morph="none" pos="word" start_char="1866">están</TOKEN>
<TOKEN end_char="1873" id="token-25-12" morph="none" pos="word" start_char="1872">en</TOKEN>
<TOKEN end_char="1876" id="token-25-13" morph="none" pos="word" start_char="1875">el</TOKEN>
<TOKEN end_char="1888" id="token-25-14" morph="none" pos="word" start_char="1878">coronarirus</TOKEN>
<TOKEN end_char="1889" id="token-25-15" morph="none" pos="punct" start_char="1889">?</TOKEN>
<TRANSLATED_TEXT>Are there supposed to be AIDS virus genes in the coronarius?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2047" id="segment-26" start_char="1895">
<ORIGINAL_TEXT>y el gordo del Ferreras diciendo que trump se había inventado la noticia gogleando...y ahora resulta que lo ha dicho todo un premio nobel...vaia valía...</ORIGINAL_TEXT>
<TOKEN end_char="1895" id="token-26-0" morph="none" pos="word" start_char="1895">y</TOKEN>
<TOKEN end_char="1898" id="token-26-1" morph="none" pos="word" start_char="1897">el</TOKEN>
<TOKEN end_char="1904" id="token-26-2" morph="none" pos="word" start_char="1900">gordo</TOKEN>
<TOKEN end_char="1908" id="token-26-3" morph="none" pos="word" start_char="1906">del</TOKEN>
<TOKEN end_char="1917" id="token-26-4" morph="none" pos="word" start_char="1910">Ferreras</TOKEN>
<TOKEN end_char="1926" id="token-26-5" morph="none" pos="word" start_char="1919">diciendo</TOKEN>
<TOKEN end_char="1930" id="token-26-6" morph="none" pos="word" start_char="1928">que</TOKEN>
<TOKEN end_char="1936" id="token-26-7" morph="none" pos="word" start_char="1932">trump</TOKEN>
<TOKEN end_char="1939" id="token-26-8" morph="none" pos="word" start_char="1938">se</TOKEN>
<TOKEN end_char="1945" id="token-26-9" morph="none" pos="word" start_char="1941">había</TOKEN>
<TOKEN end_char="1955" id="token-26-10" morph="none" pos="word" start_char="1947">inventado</TOKEN>
<TOKEN end_char="1958" id="token-26-11" morph="none" pos="word" start_char="1957">la</TOKEN>
<TOKEN end_char="1966" id="token-26-12" morph="none" pos="word" start_char="1960">noticia</TOKEN>
<TOKEN end_char="1980" id="token-26-13" morph="none" pos="unknown" start_char="1968">gogleando...y</TOKEN>
<TOKEN end_char="1986" id="token-26-14" morph="none" pos="word" start_char="1982">ahora</TOKEN>
<TOKEN end_char="1994" id="token-26-15" morph="none" pos="word" start_char="1988">resulta</TOKEN>
<TOKEN end_char="1998" id="token-26-16" morph="none" pos="word" start_char="1996">que</TOKEN>
<TOKEN end_char="2001" id="token-26-17" morph="none" pos="word" start_char="2000">lo</TOKEN>
<TOKEN end_char="2004" id="token-26-18" morph="none" pos="word" start_char="2003">ha</TOKEN>
<TOKEN end_char="2010" id="token-26-19" morph="none" pos="word" start_char="2006">dicho</TOKEN>
<TOKEN end_char="2015" id="token-26-20" morph="none" pos="word" start_char="2012">todo</TOKEN>
<TOKEN end_char="2018" id="token-26-21" morph="none" pos="word" start_char="2017">un</TOKEN>
<TOKEN end_char="2025" id="token-26-22" morph="none" pos="word" start_char="2020">premio</TOKEN>
<TOKEN end_char="2038" id="token-26-23" morph="none" pos="unknown" start_char="2027">nobel...vaia</TOKEN>
<TOKEN end_char="2044" id="token-26-24" morph="none" pos="word" start_char="2040">valía</TOKEN>
<TOKEN end_char="2047" id="token-26-25" morph="none" pos="punct" start_char="2045">...</TOKEN>
<TRANSLATED_TEXT>And the fat Ferreras saying that trump had invented the googling news... and now it turns out that the whole Nobel Prize has said so...</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2057" id="segment-27" start_char="2053">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN end_char="2056" id="token-27-0" morph="none" pos="word" start_char="2053">Cita</TOKEN>
<TOKEN end_char="2057" id="token-27-1" morph="none" pos="punct" start_char="2057">:</TOKEN>
<TRANSLATED_TEXT>Other:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="2128" id="segment-28" start_char="2062">
<ORIGINAL_TEXT>Originalmente Escrito por Pauguiller No sé si lo he entendido bien.</ORIGINAL_TEXT>
<TOKEN end_char="2074" id="token-28-0" morph="none" pos="word" start_char="2062">Originalmente</TOKEN>
<TOKEN end_char="2082" id="token-28-1" morph="none" pos="word" start_char="2076">Escrito</TOKEN>
<TOKEN end_char="2086" id="token-28-2" morph="none" pos="word" start_char="2084">por</TOKEN>
<TOKEN end_char="2097" id="token-28-3" morph="none" pos="word" start_char="2088">Pauguiller</TOKEN>
<TOKEN end_char="2100" id="token-28-4" morph="none" pos="word" start_char="2099">No</TOKEN>
<TOKEN end_char="2103" id="token-28-5" morph="none" pos="word" start_char="2102">sé</TOKEN>
<TOKEN end_char="2106" id="token-28-6" morph="none" pos="word" start_char="2105">si</TOKEN>
<TOKEN end_char="2109" id="token-28-7" morph="none" pos="word" start_char="2108">lo</TOKEN>
<TOKEN end_char="2112" id="token-28-8" morph="none" pos="word" start_char="2111">he</TOKEN>
<TOKEN end_char="2122" id="token-28-9" morph="none" pos="word" start_char="2114">entendido</TOKEN>
<TOKEN end_char="2127" id="token-28-10" morph="none" pos="word" start_char="2124">bien</TOKEN>
<TOKEN end_char="2128" id="token-28-11" morph="none" pos="punct" start_char="2128">.</TOKEN>
<TRANSLATED_TEXT>Originally written by Pauguiller I don't know if I understood it well.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2201" id="segment-29" start_char="2130">
<ORIGINAL_TEXT>¿Se supone que hay genes del virus del Sida que están en el coronarirus?</ORIGINAL_TEXT>
<TOKEN end_char="2130" id="token-29-0" morph="none" pos="punct" start_char="2130">¿</TOKEN>
<TOKEN end_char="2132" id="token-29-1" morph="none" pos="word" start_char="2131">Se</TOKEN>
<TOKEN end_char="2139" id="token-29-2" morph="none" pos="word" start_char="2134">supone</TOKEN>
<TOKEN end_char="2143" id="token-29-3" morph="none" pos="word" start_char="2141">que</TOKEN>
<TOKEN end_char="2147" id="token-29-4" morph="none" pos="word" start_char="2145">hay</TOKEN>
<TOKEN end_char="2153" id="token-29-5" morph="none" pos="word" start_char="2149">genes</TOKEN>
<TOKEN end_char="2157" id="token-29-6" morph="none" pos="word" start_char="2155">del</TOKEN>
<TOKEN end_char="2163" id="token-29-7" morph="none" pos="word" start_char="2159">virus</TOKEN>
<TOKEN end_char="2167" id="token-29-8" morph="none" pos="word" start_char="2165">del</TOKEN>
<TOKEN end_char="2172" id="token-29-9" morph="none" pos="word" start_char="2169">Sida</TOKEN>
<TOKEN end_char="2176" id="token-29-10" morph="none" pos="word" start_char="2174">que</TOKEN>
<TOKEN end_char="2182" id="token-29-11" morph="none" pos="word" start_char="2178">están</TOKEN>
<TOKEN end_char="2185" id="token-29-12" morph="none" pos="word" start_char="2184">en</TOKEN>
<TOKEN end_char="2188" id="token-29-13" morph="none" pos="word" start_char="2187">el</TOKEN>
<TOKEN end_char="2200" id="token-29-14" morph="none" pos="word" start_char="2190">coronarirus</TOKEN>
<TOKEN end_char="2201" id="token-29-15" morph="none" pos="punct" start_char="2201">?</TOKEN>
<TRANSLATED_TEXT>Are there supposed to be AIDS virus genes in the coronarius?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2272" id="segment-30" start_char="2203">
<ORIGINAL_TEXT>This, entonces si pillas el coronavirus, coges el vih automáticamente?</ORIGINAL_TEXT>
<TOKEN end_char="2206" id="token-30-0" morph="none" pos="word" start_char="2203">This</TOKEN>
<TOKEN end_char="2207" id="token-30-1" morph="none" pos="punct" start_char="2207">,</TOKEN>
<TOKEN end_char="2216" id="token-30-2" morph="none" pos="word" start_char="2209">entonces</TOKEN>
<TOKEN end_char="2219" id="token-30-3" morph="none" pos="word" start_char="2218">si</TOKEN>
<TOKEN end_char="2226" id="token-30-4" morph="none" pos="word" start_char="2221">pillas</TOKEN>
<TOKEN end_char="2229" id="token-30-5" morph="none" pos="word" start_char="2228">el</TOKEN>
<TOKEN end_char="2241" id="token-30-6" morph="none" pos="word" start_char="2231">coronavirus</TOKEN>
<TOKEN end_char="2242" id="token-30-7" morph="none" pos="punct" start_char="2242">,</TOKEN>
<TOKEN end_char="2248" id="token-30-8" morph="none" pos="word" start_char="2244">coges</TOKEN>
<TOKEN end_char="2251" id="token-30-9" morph="none" pos="word" start_char="2250">el</TOKEN>
<TOKEN end_char="2255" id="token-30-10" morph="none" pos="word" start_char="2253">vih</TOKEN>
<TOKEN end_char="2271" id="token-30-11" morph="none" pos="word" start_char="2257">automáticamente</TOKEN>
<TOKEN end_char="2272" id="token-30-12" morph="none" pos="punct" start_char="2272">?</TOKEN>
<TRANSLATED_TEXT>This, then if you pick up the coronavirus, you automatically pick up the hiv?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2427" id="segment-31" start_char="2274">
<ORIGINAL_TEXT>Joder a ver si va a ser un invento de un científico de wuhan gafotas granudo virgen que se mata a pajas con el hentai, y quiere putear a todo el que folla</ORIGINAL_TEXT>
<TOKEN end_char="2278" id="token-31-0" morph="none" pos="word" start_char="2274">Joder</TOKEN>
<TOKEN end_char="2280" id="token-31-1" morph="none" pos="word" start_char="2280">a</TOKEN>
<TOKEN end_char="2284" id="token-31-2" morph="none" pos="word" start_char="2282">ver</TOKEN>
<TOKEN end_char="2287" id="token-31-3" morph="none" pos="word" start_char="2286">si</TOKEN>
<TOKEN end_char="2290" id="token-31-4" morph="none" pos="word" start_char="2289">va</TOKEN>
<TOKEN end_char="2292" id="token-31-5" morph="none" pos="word" start_char="2292">a</TOKEN>
<TOKEN end_char="2296" id="token-31-6" morph="none" pos="word" start_char="2294">ser</TOKEN>
<TOKEN end_char="2299" id="token-31-7" morph="none" pos="word" start_char="2298">un</TOKEN>
<TOKEN end_char="2307" id="token-31-8" morph="none" pos="word" start_char="2301">invento</TOKEN>
<TOKEN end_char="2310" id="token-31-9" morph="none" pos="word" start_char="2309">de</TOKEN>
<TOKEN end_char="2313" id="token-31-10" morph="none" pos="word" start_char="2312">un</TOKEN>
<TOKEN end_char="2324" id="token-31-11" morph="none" pos="word" start_char="2315">científico</TOKEN>
<TOKEN end_char="2327" id="token-31-12" morph="none" pos="word" start_char="2326">de</TOKEN>
<TOKEN end_char="2333" id="token-31-13" morph="none" pos="word" start_char="2329">wuhan</TOKEN>
<TOKEN end_char="2341" id="token-31-14" morph="none" pos="word" start_char="2335">gafotas</TOKEN>
<TOKEN end_char="2349" id="token-31-15" morph="none" pos="word" start_char="2343">granudo</TOKEN>
<TOKEN end_char="2356" id="token-31-16" morph="none" pos="word" start_char="2351">virgen</TOKEN>
<TOKEN end_char="2360" id="token-31-17" morph="none" pos="word" start_char="2358">que</TOKEN>
<TOKEN end_char="2363" id="token-31-18" morph="none" pos="word" start_char="2362">se</TOKEN>
<TOKEN end_char="2368" id="token-31-19" morph="none" pos="word" start_char="2365">mata</TOKEN>
<TOKEN end_char="2370" id="token-31-20" morph="none" pos="word" start_char="2370">a</TOKEN>
<TOKEN end_char="2376" id="token-31-21" morph="none" pos="word" start_char="2372">pajas</TOKEN>
<TOKEN end_char="2380" id="token-31-22" morph="none" pos="word" start_char="2378">con</TOKEN>
<TOKEN end_char="2383" id="token-31-23" morph="none" pos="word" start_char="2382">el</TOKEN>
<TOKEN end_char="2390" id="token-31-24" morph="none" pos="word" start_char="2385">hentai</TOKEN>
<TOKEN end_char="2391" id="token-31-25" morph="none" pos="punct" start_char="2391">,</TOKEN>
<TOKEN end_char="2393" id="token-31-26" morph="none" pos="word" start_char="2393">y</TOKEN>
<TOKEN end_char="2400" id="token-31-27" morph="none" pos="word" start_char="2395">quiere</TOKEN>
<TOKEN end_char="2407" id="token-31-28" morph="none" pos="word" start_char="2402">putear</TOKEN>
<TOKEN end_char="2409" id="token-31-29" morph="none" pos="word" start_char="2409">a</TOKEN>
<TOKEN end_char="2414" id="token-31-30" morph="none" pos="word" start_char="2411">todo</TOKEN>
<TOKEN end_char="2417" id="token-31-31" morph="none" pos="word" start_char="2416">el</TOKEN>
<TOKEN end_char="2421" id="token-31-32" morph="none" pos="word" start_char="2419">que</TOKEN>
<TOKEN end_char="2427" id="token-31-33" morph="none" pos="word" start_char="2423">folla</TOKEN>
<TRANSLATED_TEXT>Fuck to see if it's going to be an invention by a wuhan scientist who kills himself with hentai straw, and wants to fuck everyone who fucks.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2475" id="segment-32" start_char="2433">
<ORIGINAL_TEXT>Lo fácil era cargar la culpa a un pangolin.</ORIGINAL_TEXT>
<TOKEN end_char="2434" id="token-32-0" morph="none" pos="word" start_char="2433">Lo</TOKEN>
<TOKEN end_char="2440" id="token-32-1" morph="none" pos="word" start_char="2436">fácil</TOKEN>
<TOKEN end_char="2444" id="token-32-2" morph="none" pos="word" start_char="2442">era</TOKEN>
<TOKEN end_char="2451" id="token-32-3" morph="none" pos="word" start_char="2446">cargar</TOKEN>
<TOKEN end_char="2454" id="token-32-4" morph="none" pos="word" start_char="2453">la</TOKEN>
<TOKEN end_char="2460" id="token-32-5" morph="none" pos="word" start_char="2456">culpa</TOKEN>
<TOKEN end_char="2462" id="token-32-6" morph="none" pos="word" start_char="2462">a</TOKEN>
<TOKEN end_char="2465" id="token-32-7" morph="none" pos="word" start_char="2464">un</TOKEN>
<TOKEN end_char="2474" id="token-32-8" morph="none" pos="word" start_char="2467">pangolin</TOKEN>
<TOKEN end_char="2475" id="token-32-9" morph="none" pos="punct" start_char="2475">.</TOKEN>
<TRANSLATED_TEXT>It was easy to blame a pangolin.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2488" id="segment-33" start_char="2477">
<ORIGINAL_TEXT>Pero no coló</ORIGINAL_TEXT>
<TOKEN end_char="2480" id="token-33-0" morph="none" pos="word" start_char="2477">Pero</TOKEN>
<TOKEN end_char="2483" id="token-33-1" morph="none" pos="word" start_char="2482">no</TOKEN>
<TOKEN end_char="2488" id="token-33-2" morph="none" pos="word" start_char="2485">coló</TOKEN>
<TRANSLATED_TEXT>But you didn't.</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="2698" id="segment-34" start_char="2494">
<ORIGINAL_TEXT>"Ya ha presentado teorías muy controvertidas sobre el origen y la transmisión del SIDA y, en 2017, 100 académicos le pidieron al Colegio de Médicos que lo sancionara después de sus posiciones antivacunas."</ORIGINAL_TEXT>
<TOKEN end_char="2494" id="token-34-0" morph="none" pos="punct" start_char="2494">"</TOKEN>
<TOKEN end_char="2496" id="token-34-1" morph="none" pos="word" start_char="2495">Ya</TOKEN>
<TOKEN end_char="2499" id="token-34-2" morph="none" pos="word" start_char="2498">ha</TOKEN>
<TOKEN end_char="2510" id="token-34-3" morph="none" pos="word" start_char="2501">presentado</TOKEN>
<TOKEN end_char="2518" id="token-34-4" morph="none" pos="word" start_char="2512">teorías</TOKEN>
<TOKEN end_char="2522" id="token-34-5" morph="none" pos="word" start_char="2520">muy</TOKEN>
<TOKEN end_char="2537" id="token-34-6" morph="none" pos="word" start_char="2524">controvertidas</TOKEN>
<TOKEN end_char="2543" id="token-34-7" morph="none" pos="word" start_char="2539">sobre</TOKEN>
<TOKEN end_char="2546" id="token-34-8" morph="none" pos="word" start_char="2545">el</TOKEN>
<TOKEN end_char="2553" id="token-34-9" morph="none" pos="word" start_char="2548">origen</TOKEN>
<TOKEN end_char="2555" id="token-34-10" morph="none" pos="word" start_char="2555">y</TOKEN>
<TOKEN end_char="2558" id="token-34-11" morph="none" pos="word" start_char="2557">la</TOKEN>
<TOKEN end_char="2570" id="token-34-12" morph="none" pos="word" start_char="2560">transmisión</TOKEN>
<TOKEN end_char="2574" id="token-34-13" morph="none" pos="word" start_char="2572">del</TOKEN>
<TOKEN end_char="2579" id="token-34-14" morph="none" pos="word" start_char="2576">SIDA</TOKEN>
<TOKEN end_char="2581" id="token-34-15" morph="none" pos="word" start_char="2581">y</TOKEN>
<TOKEN end_char="2582" id="token-34-16" morph="none" pos="punct" start_char="2582">,</TOKEN>
<TOKEN end_char="2585" id="token-34-17" morph="none" pos="word" start_char="2584">en</TOKEN>
<TOKEN end_char="2590" id="token-34-18" morph="none" pos="word" start_char="2587">2017</TOKEN>
<TOKEN end_char="2591" id="token-34-19" morph="none" pos="punct" start_char="2591">,</TOKEN>
<TOKEN end_char="2595" id="token-34-20" morph="none" pos="word" start_char="2593">100</TOKEN>
<TOKEN end_char="2606" id="token-34-21" morph="none" pos="word" start_char="2597">académicos</TOKEN>
<TOKEN end_char="2609" id="token-34-22" morph="none" pos="word" start_char="2608">le</TOKEN>
<TOKEN end_char="2618" id="token-34-23" morph="none" pos="word" start_char="2611">pidieron</TOKEN>
<TOKEN end_char="2621" id="token-34-24" morph="none" pos="word" start_char="2620">al</TOKEN>
<TOKEN end_char="2629" id="token-34-25" morph="none" pos="word" start_char="2623">Colegio</TOKEN>
<TOKEN end_char="2632" id="token-34-26" morph="none" pos="word" start_char="2631">de</TOKEN>
<TOKEN end_char="2640" id="token-34-27" morph="none" pos="word" start_char="2634">Médicos</TOKEN>
<TOKEN end_char="2644" id="token-34-28" morph="none" pos="word" start_char="2642">que</TOKEN>
<TOKEN end_char="2647" id="token-34-29" morph="none" pos="word" start_char="2646">lo</TOKEN>
<TOKEN end_char="2658" id="token-34-30" morph="none" pos="word" start_char="2649">sancionara</TOKEN>
<TOKEN end_char="2666" id="token-34-31" morph="none" pos="word" start_char="2660">después</TOKEN>
<TOKEN end_char="2669" id="token-34-32" morph="none" pos="word" start_char="2668">de</TOKEN>
<TOKEN end_char="2673" id="token-34-33" morph="none" pos="word" start_char="2671">sus</TOKEN>
<TOKEN end_char="2684" id="token-34-34" morph="none" pos="word" start_char="2675">posiciones</TOKEN>
<TOKEN end_char="2696" id="token-34-35" morph="none" pos="word" start_char="2686">antivacunas</TOKEN>
<TOKEN end_char="2698" id="token-34-36" morph="none" pos="punct" start_char="2697">."</TOKEN>
<TRANSLATED_TEXT>He has already presented very controversial theories about the origin and transmission of AIDS and, in 2017, 100 academics asked the College of Physicians to sanction him after his anti-AIDS positions.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2815" id="segment-35" start_char="2704">
<ORIGINAL_TEXT>Todos lo sospechan porque el laboratorio de Wuhan está a 200 metros del mercado donde dicen que se originó todo.</ORIGINAL_TEXT>
<TOKEN end_char="2708" id="token-35-0" morph="none" pos="word" start_char="2704">Todos</TOKEN>
<TOKEN end_char="2711" id="token-35-1" morph="none" pos="word" start_char="2710">lo</TOKEN>
<TOKEN end_char="2721" id="token-35-2" morph="none" pos="word" start_char="2713">sospechan</TOKEN>
<TOKEN end_char="2728" id="token-35-3" morph="none" pos="word" start_char="2723">porque</TOKEN>
<TOKEN end_char="2731" id="token-35-4" morph="none" pos="word" start_char="2730">el</TOKEN>
<TOKEN end_char="2743" id="token-35-5" morph="none" pos="word" start_char="2733">laboratorio</TOKEN>
<TOKEN end_char="2746" id="token-35-6" morph="none" pos="word" start_char="2745">de</TOKEN>
<TOKEN end_char="2752" id="token-35-7" morph="none" pos="word" start_char="2748">Wuhan</TOKEN>
<TOKEN end_char="2757" id="token-35-8" morph="none" pos="word" start_char="2754">está</TOKEN>
<TOKEN end_char="2759" id="token-35-9" morph="none" pos="word" start_char="2759">a</TOKEN>
<TOKEN end_char="2763" id="token-35-10" morph="none" pos="word" start_char="2761">200</TOKEN>
<TOKEN end_char="2770" id="token-35-11" morph="none" pos="word" start_char="2765">metros</TOKEN>
<TOKEN end_char="2774" id="token-35-12" morph="none" pos="word" start_char="2772">del</TOKEN>
<TOKEN end_char="2782" id="token-35-13" morph="none" pos="word" start_char="2776">mercado</TOKEN>
<TOKEN end_char="2788" id="token-35-14" morph="none" pos="word" start_char="2784">donde</TOKEN>
<TOKEN end_char="2794" id="token-35-15" morph="none" pos="word" start_char="2790">dicen</TOKEN>
<TOKEN end_char="2798" id="token-35-16" morph="none" pos="word" start_char="2796">que</TOKEN>
<TOKEN end_char="2801" id="token-35-17" morph="none" pos="word" start_char="2800">se</TOKEN>
<TOKEN end_char="2809" id="token-35-18" morph="none" pos="word" start_char="2803">originó</TOKEN>
<TOKEN end_char="2814" id="token-35-19" morph="none" pos="word" start_char="2811">todo</TOKEN>
<TOKEN end_char="2815" id="token-35-20" morph="none" pos="punct" start_char="2815">.</TOKEN>
<TRANSLATED_TEXT>Everyone suspects it because Wuhan's lab is 200 meters from the market where they say it all originated.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2959" id="segment-36" start_char="2817">
<ORIGINAL_TEXT>Lo que yo creo es que no fue intencionadamente propagado, si no que un investigador se contagió por error y salió del laboratorio con el bicho.</ORIGINAL_TEXT>
<TOKEN end_char="2818" id="token-36-0" morph="none" pos="word" start_char="2817">Lo</TOKEN>
<TOKEN end_char="2822" id="token-36-1" morph="none" pos="word" start_char="2820">que</TOKEN>
<TOKEN end_char="2825" id="token-36-2" morph="none" pos="word" start_char="2824">yo</TOKEN>
<TOKEN end_char="2830" id="token-36-3" morph="none" pos="word" start_char="2827">creo</TOKEN>
<TOKEN end_char="2833" id="token-36-4" morph="none" pos="word" start_char="2832">es</TOKEN>
<TOKEN end_char="2837" id="token-36-5" morph="none" pos="word" start_char="2835">que</TOKEN>
<TOKEN end_char="2840" id="token-36-6" morph="none" pos="word" start_char="2839">no</TOKEN>
<TOKEN end_char="2844" id="token-36-7" morph="none" pos="word" start_char="2842">fue</TOKEN>
<TOKEN end_char="2862" id="token-36-8" morph="none" pos="word" start_char="2846">intencionadamente</TOKEN>
<TOKEN end_char="2872" id="token-36-9" morph="none" pos="word" start_char="2864">propagado</TOKEN>
<TOKEN end_char="2873" id="token-36-10" morph="none" pos="punct" start_char="2873">,</TOKEN>
<TOKEN end_char="2876" id="token-36-11" morph="none" pos="word" start_char="2875">si</TOKEN>
<TOKEN end_char="2879" id="token-36-12" morph="none" pos="word" start_char="2878">no</TOKEN>
<TOKEN end_char="2883" id="token-36-13" morph="none" pos="word" start_char="2881">que</TOKEN>
<TOKEN end_char="2886" id="token-36-14" morph="none" pos="word" start_char="2885">un</TOKEN>
<TOKEN end_char="2899" id="token-36-15" morph="none" pos="word" start_char="2888">investigador</TOKEN>
<TOKEN end_char="2902" id="token-36-16" morph="none" pos="word" start_char="2901">se</TOKEN>
<TOKEN end_char="2911" id="token-36-17" morph="none" pos="word" start_char="2904">contagió</TOKEN>
<TOKEN end_char="2915" id="token-36-18" morph="none" pos="word" start_char="2913">por</TOKEN>
<TOKEN end_char="2921" id="token-36-19" morph="none" pos="word" start_char="2917">error</TOKEN>
<TOKEN end_char="2923" id="token-36-20" morph="none" pos="word" start_char="2923">y</TOKEN>
<TOKEN end_char="2929" id="token-36-21" morph="none" pos="word" start_char="2925">salió</TOKEN>
<TOKEN end_char="2933" id="token-36-22" morph="none" pos="word" start_char="2931">del</TOKEN>
<TOKEN end_char="2945" id="token-36-23" morph="none" pos="word" start_char="2935">laboratorio</TOKEN>
<TOKEN end_char="2949" id="token-36-24" morph="none" pos="word" start_char="2947">con</TOKEN>
<TOKEN end_char="2952" id="token-36-25" morph="none" pos="word" start_char="2951">el</TOKEN>
<TOKEN end_char="2958" id="token-36-26" morph="none" pos="word" start_char="2954">bicho</TOKEN>
<TOKEN end_char="2959" id="token-36-27" morph="none" pos="punct" start_char="2959">.</TOKEN>
<TRANSLATED_TEXT>What I think is that it wasn 't intentionally propagated, if not that a researcher got infected by mistake and walked out of the lab with the bug.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3046" id="segment-37" start_char="2961">
<ORIGINAL_TEXT>Incluso puede que fuera a comer o comprar al mercado donde se supone que es la zona 0.</ORIGINAL_TEXT>
<TOKEN end_char="2967" id="token-37-0" morph="none" pos="word" start_char="2961">Incluso</TOKEN>
<TOKEN end_char="2973" id="token-37-1" morph="none" pos="word" start_char="2969">puede</TOKEN>
<TOKEN end_char="2977" id="token-37-2" morph="none" pos="word" start_char="2975">que</TOKEN>
<TOKEN end_char="2983" id="token-37-3" morph="none" pos="word" start_char="2979">fuera</TOKEN>
<TOKEN end_char="2985" id="token-37-4" morph="none" pos="word" start_char="2985">a</TOKEN>
<TOKEN end_char="2991" id="token-37-5" morph="none" pos="word" start_char="2987">comer</TOKEN>
<TOKEN end_char="2993" id="token-37-6" morph="none" pos="word" start_char="2993">o</TOKEN>
<TOKEN end_char="3001" id="token-37-7" morph="none" pos="word" start_char="2995">comprar</TOKEN>
<TOKEN end_char="3004" id="token-37-8" morph="none" pos="word" start_char="3003">al</TOKEN>
<TOKEN end_char="3012" id="token-37-9" morph="none" pos="word" start_char="3006">mercado</TOKEN>
<TOKEN end_char="3018" id="token-37-10" morph="none" pos="word" start_char="3014">donde</TOKEN>
<TOKEN end_char="3021" id="token-37-11" morph="none" pos="word" start_char="3020">se</TOKEN>
<TOKEN end_char="3028" id="token-37-12" morph="none" pos="word" start_char="3023">supone</TOKEN>
<TOKEN end_char="3032" id="token-37-13" morph="none" pos="word" start_char="3030">que</TOKEN>
<TOKEN end_char="3035" id="token-37-14" morph="none" pos="word" start_char="3034">es</TOKEN>
<TOKEN end_char="3038" id="token-37-15" morph="none" pos="word" start_char="3037">la</TOKEN>
<TOKEN end_char="3043" id="token-37-16" morph="none" pos="word" start_char="3040">zona</TOKEN>
<TOKEN end_char="3045" id="token-37-17" morph="none" pos="word" start_char="3045">0</TOKEN>
<TOKEN end_char="3046" id="token-37-18" morph="none" pos="punct" start_char="3046">.</TOKEN>
<TRANSLATED_TEXT>It may even be eating or buying at the market where it is supposed to be zone 0.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3160" id="segment-38" start_char="3048">
<ORIGINAL_TEXT>Pero supongo que es imposible probar que está hecho por el hombre y que se haya hecho en el laboratorio de Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="3051" id="token-38-0" morph="none" pos="word" start_char="3048">Pero</TOKEN>
<TOKEN end_char="3059" id="token-38-1" morph="none" pos="word" start_char="3053">supongo</TOKEN>
<TOKEN end_char="3063" id="token-38-2" morph="none" pos="word" start_char="3061">que</TOKEN>
<TOKEN end_char="3066" id="token-38-3" morph="none" pos="word" start_char="3065">es</TOKEN>
<TOKEN end_char="3076" id="token-38-4" morph="none" pos="word" start_char="3068">imposible</TOKEN>
<TOKEN end_char="3083" id="token-38-5" morph="none" pos="word" start_char="3078">probar</TOKEN>
<TOKEN end_char="3087" id="token-38-6" morph="none" pos="word" start_char="3085">que</TOKEN>
<TOKEN end_char="3092" id="token-38-7" morph="none" pos="word" start_char="3089">está</TOKEN>
<TOKEN end_char="3098" id="token-38-8" morph="none" pos="word" start_char="3094">hecho</TOKEN>
<TOKEN end_char="3102" id="token-38-9" morph="none" pos="word" start_char="3100">por</TOKEN>
<TOKEN end_char="3105" id="token-38-10" morph="none" pos="word" start_char="3104">el</TOKEN>
<TOKEN end_char="3112" id="token-38-11" morph="none" pos="word" start_char="3107">hombre</TOKEN>
<TOKEN end_char="3114" id="token-38-12" morph="none" pos="word" start_char="3114">y</TOKEN>
<TOKEN end_char="3118" id="token-38-13" morph="none" pos="word" start_char="3116">que</TOKEN>
<TOKEN end_char="3121" id="token-38-14" morph="none" pos="word" start_char="3120">se</TOKEN>
<TOKEN end_char="3126" id="token-38-15" morph="none" pos="word" start_char="3123">haya</TOKEN>
<TOKEN end_char="3132" id="token-38-16" morph="none" pos="word" start_char="3128">hecho</TOKEN>
<TOKEN end_char="3135" id="token-38-17" morph="none" pos="word" start_char="3134">en</TOKEN>
<TOKEN end_char="3138" id="token-38-18" morph="none" pos="word" start_char="3137">el</TOKEN>
<TOKEN end_char="3150" id="token-38-19" morph="none" pos="word" start_char="3140">laboratorio</TOKEN>
<TOKEN end_char="3153" id="token-38-20" morph="none" pos="word" start_char="3152">de</TOKEN>
<TOKEN end_char="3159" id="token-38-21" morph="none" pos="word" start_char="3155">Wuhan</TOKEN>
<TOKEN end_char="3160" id="token-38-22" morph="none" pos="punct" start_char="3160">.</TOKEN>
<TRANSLATED_TEXT>But I guess it's impossible to prove that it was made by man and that it was made in Wuhan's lab.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3170" id="segment-39" start_char="3166">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN end_char="3169" id="token-39-0" morph="none" pos="word" start_char="3166">Cita</TOKEN>
<TOKEN end_char="3170" id="token-39-1" morph="none" pos="punct" start_char="3170">:</TOKEN>
<TRANSLATED_TEXT>Other:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="3250" id="segment-40" start_char="3175">
<ORIGINAL_TEXT>Originalmente Escrito por zirick Lo fácil era cargar la culpa a un pangolin.</ORIGINAL_TEXT>
<TOKEN end_char="3187" id="token-40-0" morph="none" pos="word" start_char="3175">Originalmente</TOKEN>
<TOKEN end_char="3195" id="token-40-1" morph="none" pos="word" start_char="3189">Escrito</TOKEN>
<TOKEN end_char="3199" id="token-40-2" morph="none" pos="word" start_char="3197">por</TOKEN>
<TOKEN end_char="3206" id="token-40-3" morph="none" pos="word" start_char="3201">zirick</TOKEN>
<TOKEN end_char="3209" id="token-40-4" morph="none" pos="word" start_char="3208">Lo</TOKEN>
<TOKEN end_char="3215" id="token-40-5" morph="none" pos="word" start_char="3211">fácil</TOKEN>
<TOKEN end_char="3219" id="token-40-6" morph="none" pos="word" start_char="3217">era</TOKEN>
<TOKEN end_char="3226" id="token-40-7" morph="none" pos="word" start_char="3221">cargar</TOKEN>
<TOKEN end_char="3229" id="token-40-8" morph="none" pos="word" start_char="3228">la</TOKEN>
<TOKEN end_char="3235" id="token-40-9" morph="none" pos="word" start_char="3231">culpa</TOKEN>
<TOKEN end_char="3237" id="token-40-10" morph="none" pos="word" start_char="3237">a</TOKEN>
<TOKEN end_char="3240" id="token-40-11" morph="none" pos="word" start_char="3239">un</TOKEN>
<TOKEN end_char="3249" id="token-40-12" morph="none" pos="word" start_char="3242">pangolin</TOKEN>
<TOKEN end_char="3250" id="token-40-13" morph="none" pos="punct" start_char="3250">.</TOKEN>
<TRANSLATED_TEXT>Originally written by zirick The easy thing was to charge a pangolin.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3312" id="segment-41" start_char="3252">
<ORIGINAL_TEXT>Pero no coló Pero como va a tener virus ese bicho tan majete.</ORIGINAL_TEXT>
<TOKEN end_char="3255" id="token-41-0" morph="none" pos="word" start_char="3252">Pero</TOKEN>
<TOKEN end_char="3258" id="token-41-1" morph="none" pos="word" start_char="3257">no</TOKEN>
<TOKEN end_char="3263" id="token-41-2" morph="none" pos="word" start_char="3260">coló</TOKEN>
<TOKEN end_char="3268" id="token-41-3" morph="none" pos="word" start_char="3265">Pero</TOKEN>
<TOKEN end_char="3273" id="token-41-4" morph="none" pos="word" start_char="3270">como</TOKEN>
<TOKEN end_char="3276" id="token-41-5" morph="none" pos="word" start_char="3275">va</TOKEN>
<TOKEN end_char="3278" id="token-41-6" morph="none" pos="word" start_char="3278">a</TOKEN>
<TOKEN end_char="3284" id="token-41-7" morph="none" pos="word" start_char="3280">tener</TOKEN>
<TOKEN end_char="3290" id="token-41-8" morph="none" pos="word" start_char="3286">virus</TOKEN>
<TOKEN end_char="3294" id="token-41-9" morph="none" pos="word" start_char="3292">ese</TOKEN>
<TOKEN end_char="3300" id="token-41-10" morph="none" pos="word" start_char="3296">bicho</TOKEN>
<TOKEN end_char="3304" id="token-41-11" morph="none" pos="word" start_char="3302">tan</TOKEN>
<TOKEN end_char="3311" id="token-41-12" morph="none" pos="word" start_char="3306">majete</TOKEN>
<TOKEN end_char="3312" id="token-41-13" morph="none" pos="punct" start_char="3312">.</TOKEN>
<TRANSLATED_TEXT>But he didn't. But how is he going to get viruses?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3323" id="segment-42" start_char="3314">
<ORIGINAL_TEXT>Yo adoptó.</ORIGINAL_TEXT>
<TOKEN end_char="3315" id="token-42-0" morph="none" pos="word" start_char="3314">Yo</TOKEN>
<TOKEN end_char="3322" id="token-42-1" morph="none" pos="word" start_char="3317">adoptó</TOKEN>
<TOKEN end_char="3323" id="token-42-2" morph="none" pos="punct" start_char="3323">.</TOKEN>
<TRANSLATED_TEXT>I adopted.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3333" id="segment-43" start_char="3329">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN end_char="3332" id="token-43-0" morph="none" pos="word" start_char="3329">Cita</TOKEN>
<TOKEN end_char="3333" id="token-43-1" morph="none" pos="punct" start_char="3333">:</TOKEN>
<TRANSLATED_TEXT>Other:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="3447" id="segment-44" start_char="3338">
<ORIGINAL_TEXT>Originalmente Escrito por Magikarp sano This, entonces si pillas el coronavirus, coges el vih automáticamente?</ORIGINAL_TEXT>
<TOKEN end_char="3350" id="token-44-0" morph="none" pos="word" start_char="3338">Originalmente</TOKEN>
<TOKEN end_char="3358" id="token-44-1" morph="none" pos="word" start_char="3352">Escrito</TOKEN>
<TOKEN end_char="3362" id="token-44-2" morph="none" pos="word" start_char="3360">por</TOKEN>
<TOKEN end_char="3371" id="token-44-3" morph="none" pos="word" start_char="3364">Magikarp</TOKEN>
<TOKEN end_char="3376" id="token-44-4" morph="none" pos="word" start_char="3373">sano</TOKEN>
<TOKEN end_char="3381" id="token-44-5" morph="none" pos="word" start_char="3378">This</TOKEN>
<TOKEN end_char="3382" id="token-44-6" morph="none" pos="punct" start_char="3382">,</TOKEN>
<TOKEN end_char="3391" id="token-44-7" morph="none" pos="word" start_char="3384">entonces</TOKEN>
<TOKEN end_char="3394" id="token-44-8" morph="none" pos="word" start_char="3393">si</TOKEN>
<TOKEN end_char="3401" id="token-44-9" morph="none" pos="word" start_char="3396">pillas</TOKEN>
<TOKEN end_char="3404" id="token-44-10" morph="none" pos="word" start_char="3403">el</TOKEN>
<TOKEN end_char="3416" id="token-44-11" morph="none" pos="word" start_char="3406">coronavirus</TOKEN>
<TOKEN end_char="3417" id="token-44-12" morph="none" pos="punct" start_char="3417">,</TOKEN>
<TOKEN end_char="3423" id="token-44-13" morph="none" pos="word" start_char="3419">coges</TOKEN>
<TOKEN end_char="3426" id="token-44-14" morph="none" pos="word" start_char="3425">el</TOKEN>
<TOKEN end_char="3430" id="token-44-15" morph="none" pos="word" start_char="3428">vih</TOKEN>
<TOKEN end_char="3446" id="token-44-16" morph="none" pos="word" start_char="3432">automáticamente</TOKEN>
<TOKEN end_char="3447" id="token-44-17" morph="none" pos="punct" start_char="3447">?</TOKEN>
<TRANSLATED_TEXT>Originally Written by Magikarp sano This, then if you catch coronavirus, do you automatically catch Hiv?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3602" id="segment-45" start_char="3449">
<ORIGINAL_TEXT>Joder a ver si va a ser un invento de un científico de wuhan gafotas granudo virgen que se mata a pajas con el hentai, y quiere putear a todo el que folla</ORIGINAL_TEXT>
<TOKEN end_char="3453" id="token-45-0" morph="none" pos="word" start_char="3449">Joder</TOKEN>
<TOKEN end_char="3455" id="token-45-1" morph="none" pos="word" start_char="3455">a</TOKEN>
<TOKEN end_char="3459" id="token-45-2" morph="none" pos="word" start_char="3457">ver</TOKEN>
<TOKEN end_char="3462" id="token-45-3" morph="none" pos="word" start_char="3461">si</TOKEN>
<TOKEN end_char="3465" id="token-45-4" morph="none" pos="word" start_char="3464">va</TOKEN>
<TOKEN end_char="3467" id="token-45-5" morph="none" pos="word" start_char="3467">a</TOKEN>
<TOKEN end_char="3471" id="token-45-6" morph="none" pos="word" start_char="3469">ser</TOKEN>
<TOKEN end_char="3474" id="token-45-7" morph="none" pos="word" start_char="3473">un</TOKEN>
<TOKEN end_char="3482" id="token-45-8" morph="none" pos="word" start_char="3476">invento</TOKEN>
<TOKEN end_char="3485" id="token-45-9" morph="none" pos="word" start_char="3484">de</TOKEN>
<TOKEN end_char="3488" id="token-45-10" morph="none" pos="word" start_char="3487">un</TOKEN>
<TOKEN end_char="3499" id="token-45-11" morph="none" pos="word" start_char="3490">científico</TOKEN>
<TOKEN end_char="3502" id="token-45-12" morph="none" pos="word" start_char="3501">de</TOKEN>
<TOKEN end_char="3508" id="token-45-13" morph="none" pos="word" start_char="3504">wuhan</TOKEN>
<TOKEN end_char="3516" id="token-45-14" morph="none" pos="word" start_char="3510">gafotas</TOKEN>
<TOKEN end_char="3524" id="token-45-15" morph="none" pos="word" start_char="3518">granudo</TOKEN>
<TOKEN end_char="3531" id="token-45-16" morph="none" pos="word" start_char="3526">virgen</TOKEN>
<TOKEN end_char="3535" id="token-45-17" morph="none" pos="word" start_char="3533">que</TOKEN>
<TOKEN end_char="3538" id="token-45-18" morph="none" pos="word" start_char="3537">se</TOKEN>
<TOKEN end_char="3543" id="token-45-19" morph="none" pos="word" start_char="3540">mata</TOKEN>
<TOKEN end_char="3545" id="token-45-20" morph="none" pos="word" start_char="3545">a</TOKEN>
<TOKEN end_char="3551" id="token-45-21" morph="none" pos="word" start_char="3547">pajas</TOKEN>
<TOKEN end_char="3555" id="token-45-22" morph="none" pos="word" start_char="3553">con</TOKEN>
<TOKEN end_char="3558" id="token-45-23" morph="none" pos="word" start_char="3557">el</TOKEN>
<TOKEN end_char="3565" id="token-45-24" morph="none" pos="word" start_char="3560">hentai</TOKEN>
<TOKEN end_char="3566" id="token-45-25" morph="none" pos="punct" start_char="3566">,</TOKEN>
<TOKEN end_char="3568" id="token-45-26" morph="none" pos="word" start_char="3568">y</TOKEN>
<TOKEN end_char="3575" id="token-45-27" morph="none" pos="word" start_char="3570">quiere</TOKEN>
<TOKEN end_char="3582" id="token-45-28" morph="none" pos="word" start_char="3577">putear</TOKEN>
<TOKEN end_char="3584" id="token-45-29" morph="none" pos="word" start_char="3584">a</TOKEN>
<TOKEN end_char="3589" id="token-45-30" morph="none" pos="word" start_char="3586">todo</TOKEN>
<TOKEN end_char="3592" id="token-45-31" morph="none" pos="word" start_char="3591">el</TOKEN>
<TOKEN end_char="3596" id="token-45-32" morph="none" pos="word" start_char="3594">que</TOKEN>
<TOKEN end_char="3602" id="token-45-33" morph="none" pos="word" start_char="3598">folla</TOKEN>
<TRANSLATED_TEXT>Fuck to see if it's going to be an invention by a wuhan scientist who kills himself with hentai straw, and wants to fuck everyone who fucks.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3654" id="segment-46" start_char="3606">
<ORIGINAL_TEXT>No, sería solo una secuencia, no el virus entero.</ORIGINAL_TEXT>
<TOKEN end_char="3607" id="token-46-0" morph="none" pos="word" start_char="3606">No</TOKEN>
<TOKEN end_char="3608" id="token-46-1" morph="none" pos="punct" start_char="3608">,</TOKEN>
<TOKEN end_char="3614" id="token-46-2" morph="none" pos="word" start_char="3610">sería</TOKEN>
<TOKEN end_char="3619" id="token-46-3" morph="none" pos="word" start_char="3616">solo</TOKEN>
<TOKEN end_char="3623" id="token-46-4" morph="none" pos="word" start_char="3621">una</TOKEN>
<TOKEN end_char="3633" id="token-46-5" morph="none" pos="word" start_char="3625">secuencia</TOKEN>
<TOKEN end_char="3634" id="token-46-6" morph="none" pos="punct" start_char="3634">,</TOKEN>
<TOKEN end_char="3637" id="token-46-7" morph="none" pos="word" start_char="3636">no</TOKEN>
<TOKEN end_char="3640" id="token-46-8" morph="none" pos="word" start_char="3639">el</TOKEN>
<TOKEN end_char="3646" id="token-46-9" morph="none" pos="word" start_char="3642">virus</TOKEN>
<TOKEN end_char="3653" id="token-46-10" morph="none" pos="word" start_char="3648">entero</TOKEN>
<TOKEN end_char="3654" id="token-46-11" morph="none" pos="punct" start_char="3654">.</TOKEN>
<TRANSLATED_TEXT>No, it would be just a sequence, not the whole virus.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3716" id="segment-47" start_char="3656">
<ORIGINAL_TEXT>Pero ni siquiera eso estoy seguro de si lo he entendido bien.</ORIGINAL_TEXT>
<TOKEN end_char="3659" id="token-47-0" morph="none" pos="word" start_char="3656">Pero</TOKEN>
<TOKEN end_char="3662" id="token-47-1" morph="none" pos="word" start_char="3661">ni</TOKEN>
<TOKEN end_char="3671" id="token-47-2" morph="none" pos="word" start_char="3664">siquiera</TOKEN>
<TOKEN end_char="3675" id="token-47-3" morph="none" pos="word" start_char="3673">eso</TOKEN>
<TOKEN end_char="3681" id="token-47-4" morph="none" pos="word" start_char="3677">estoy</TOKEN>
<TOKEN end_char="3688" id="token-47-5" morph="none" pos="word" start_char="3683">seguro</TOKEN>
<TOKEN end_char="3691" id="token-47-6" morph="none" pos="word" start_char="3690">de</TOKEN>
<TOKEN end_char="3694" id="token-47-7" morph="none" pos="word" start_char="3693">si</TOKEN>
<TOKEN end_char="3697" id="token-47-8" morph="none" pos="word" start_char="3696">lo</TOKEN>
<TOKEN end_char="3700" id="token-47-9" morph="none" pos="word" start_char="3699">he</TOKEN>
<TOKEN end_char="3710" id="token-47-10" morph="none" pos="word" start_char="3702">entendido</TOKEN>
<TOKEN end_char="3715" id="token-47-11" morph="none" pos="word" start_char="3712">bien</TOKEN>
<TOKEN end_char="3716" id="token-47-12" morph="none" pos="punct" start_char="3716">.</TOKEN>
<TRANSLATED_TEXT>But even that, I'm not sure if I understood it well.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3799" id="segment-48" start_char="3722">
<ORIGINAL_TEXT>Lo primero..... para descartar que sea un bulo...... a quien vota este hombre?</ORIGINAL_TEXT>
<TOKEN end_char="3723" id="token-48-0" morph="none" pos="word" start_char="3722">Lo</TOKEN>
<TOKEN end_char="3731" id="token-48-1" morph="none" pos="word" start_char="3725">primero</TOKEN>
<TOKEN end_char="3736" id="token-48-2" morph="none" pos="punct" start_char="3732">.....</TOKEN>
<TOKEN end_char="3741" id="token-48-3" morph="none" pos="word" start_char="3738">para</TOKEN>
<TOKEN end_char="3751" id="token-48-4" morph="none" pos="word" start_char="3743">descartar</TOKEN>
<TOKEN end_char="3755" id="token-48-5" morph="none" pos="word" start_char="3753">que</TOKEN>
<TOKEN end_char="3759" id="token-48-6" morph="none" pos="word" start_char="3757">sea</TOKEN>
<TOKEN end_char="3762" id="token-48-7" morph="none" pos="word" start_char="3761">un</TOKEN>
<TOKEN end_char="3767" id="token-48-8" morph="none" pos="word" start_char="3764">bulo</TOKEN>
<TOKEN end_char="3773" id="token-48-9" morph="none" pos="punct" start_char="3768">......</TOKEN>
<TOKEN end_char="3775" id="token-48-10" morph="none" pos="word" start_char="3775">a</TOKEN>
<TOKEN end_char="3781" id="token-48-11" morph="none" pos="word" start_char="3777">quien</TOKEN>
<TOKEN end_char="3786" id="token-48-12" morph="none" pos="word" start_char="3783">vota</TOKEN>
<TOKEN end_char="3791" id="token-48-13" morph="none" pos="word" start_char="3788">este</TOKEN>
<TOKEN end_char="3798" id="token-48-14" morph="none" pos="word" start_char="3793">hombre</TOKEN>
<TOKEN end_char="3799" id="token-48-15" morph="none" pos="punct" start_char="3799">?</TOKEN>
<TRANSLATED_TEXT>The first... to rule out that it is a hoax... to whom this man votes?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3854" id="segment-49" start_char="3805">
<ORIGINAL_TEXT>Ese tío es una eminencia en virologia..poco broma.</ORIGINAL_TEXT>
<TOKEN end_char="3807" id="token-49-0" morph="none" pos="word" start_char="3805">Ese</TOKEN>
<TOKEN end_char="3811" id="token-49-1" morph="none" pos="word" start_char="3809">tío</TOKEN>
<TOKEN end_char="3814" id="token-49-2" morph="none" pos="word" start_char="3813">es</TOKEN>
<TOKEN end_char="3818" id="token-49-3" morph="none" pos="word" start_char="3816">una</TOKEN>
<TOKEN end_char="3828" id="token-49-4" morph="none" pos="word" start_char="3820">eminencia</TOKEN>
<TOKEN end_char="3831" id="token-49-5" morph="none" pos="word" start_char="3830">en</TOKEN>
<TOKEN end_char="3847" id="token-49-6" morph="none" pos="unknown" start_char="3833">virologia..poco</TOKEN>
<TOKEN end_char="3853" id="token-49-7" morph="none" pos="word" start_char="3849">broma</TOKEN>
<TOKEN end_char="3854" id="token-49-8" morph="none" pos="punct" start_char="3854">.</TOKEN>
<TRANSLATED_TEXT>That guy's an eminent virologist... no kidding.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3928" id="segment-50" start_char="3860">
<ORIGINAL_TEXT>rastros de VIH encontrados en el coronavirus Mira tio , yo ya dimito.</ORIGINAL_TEXT>
<TOKEN end_char="3866" id="token-50-0" morph="none" pos="word" start_char="3860">rastros</TOKEN>
<TOKEN end_char="3869" id="token-50-1" morph="none" pos="word" start_char="3868">de</TOKEN>
<TOKEN end_char="3873" id="token-50-2" morph="none" pos="word" start_char="3871">VIH</TOKEN>
<TOKEN end_char="3885" id="token-50-3" morph="none" pos="word" start_char="3875">encontrados</TOKEN>
<TOKEN end_char="3888" id="token-50-4" morph="none" pos="word" start_char="3887">en</TOKEN>
<TOKEN end_char="3891" id="token-50-5" morph="none" pos="word" start_char="3890">el</TOKEN>
<TOKEN end_char="3903" id="token-50-6" morph="none" pos="word" start_char="3893">coronavirus</TOKEN>
<TOKEN end_char="3908" id="token-50-7" morph="none" pos="word" start_char="3905">Mira</TOKEN>
<TOKEN end_char="3912" id="token-50-8" morph="none" pos="word" start_char="3910">tio</TOKEN>
<TOKEN end_char="3914" id="token-50-9" morph="none" pos="punct" start_char="3914">,</TOKEN>
<TOKEN end_char="3917" id="token-50-10" morph="none" pos="word" start_char="3916">yo</TOKEN>
<TOKEN end_char="3920" id="token-50-11" morph="none" pos="word" start_char="3919">ya</TOKEN>
<TOKEN end_char="3927" id="token-50-12" morph="none" pos="word" start_char="3922">dimito</TOKEN>
<TOKEN end_char="3928" id="token-50-13" morph="none" pos="punct" start_char="3928">.</TOKEN>
<TRANSLATED_TEXT>traces of HIV found in the coronavirus Look uncle, I already quit.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3985" id="segment-51" start_char="3930">
<ORIGINAL_TEXT>Como sea verdad , habra que esconderse debajo del suelo.</ORIGINAL_TEXT>
<TOKEN end_char="3933" id="token-51-0" morph="none" pos="word" start_char="3930">Como</TOKEN>
<TOKEN end_char="3937" id="token-51-1" morph="none" pos="word" start_char="3935">sea</TOKEN>
<TOKEN end_char="3944" id="token-51-2" morph="none" pos="word" start_char="3939">verdad</TOKEN>
<TOKEN end_char="3946" id="token-51-3" morph="none" pos="punct" start_char="3946">,</TOKEN>
<TOKEN end_char="3952" id="token-51-4" morph="none" pos="word" start_char="3948">habra</TOKEN>
<TOKEN end_char="3956" id="token-51-5" morph="none" pos="word" start_char="3954">que</TOKEN>
<TOKEN end_char="3967" id="token-51-6" morph="none" pos="word" start_char="3958">esconderse</TOKEN>
<TOKEN end_char="3974" id="token-51-7" morph="none" pos="word" start_char="3969">debajo</TOKEN>
<TOKEN end_char="3978" id="token-51-8" morph="none" pos="word" start_char="3976">del</TOKEN>
<TOKEN end_char="3984" id="token-51-9" morph="none" pos="word" start_char="3980">suelo</TOKEN>
<TOKEN end_char="3985" id="token-51-10" morph="none" pos="punct" start_char="3985">.</TOKEN>
<TRANSLATED_TEXT>As a matter of fact, he has to hide under the ground.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3995" id="segment-52" start_char="3991">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN end_char="3994" id="token-52-0" morph="none" pos="word" start_char="3991">Cita</TOKEN>
<TOKEN end_char="3995" id="token-52-1" morph="none" pos="punct" start_char="3995">:</TOKEN>
<TRANSLATED_TEXT>Other:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="4152" id="segment-53" start_char="4000">
<ORIGINAL_TEXT>Originalmente Escrito por Mongodemonguer Todos lo sospechan porque el laboratorio de Wuhan está a 200 metros del mercado donde dicen que se originó todo.</ORIGINAL_TEXT>
<TOKEN end_char="4012" id="token-53-0" morph="none" pos="word" start_char="4000">Originalmente</TOKEN>
<TOKEN end_char="4020" id="token-53-1" morph="none" pos="word" start_char="4014">Escrito</TOKEN>
<TOKEN end_char="4024" id="token-53-2" morph="none" pos="word" start_char="4022">por</TOKEN>
<TOKEN end_char="4039" id="token-53-3" morph="none" pos="word" start_char="4026">Mongodemonguer</TOKEN>
<TOKEN end_char="4045" id="token-53-4" morph="none" pos="word" start_char="4041">Todos</TOKEN>
<TOKEN end_char="4048" id="token-53-5" morph="none" pos="word" start_char="4047">lo</TOKEN>
<TOKEN end_char="4058" id="token-53-6" morph="none" pos="word" start_char="4050">sospechan</TOKEN>
<TOKEN end_char="4065" id="token-53-7" morph="none" pos="word" start_char="4060">porque</TOKEN>
<TOKEN end_char="4068" id="token-53-8" morph="none" pos="word" start_char="4067">el</TOKEN>
<TOKEN end_char="4080" id="token-53-9" morph="none" pos="word" start_char="4070">laboratorio</TOKEN>
<TOKEN end_char="4083" id="token-53-10" morph="none" pos="word" start_char="4082">de</TOKEN>
<TOKEN end_char="4089" id="token-53-11" morph="none" pos="word" start_char="4085">Wuhan</TOKEN>
<TOKEN end_char="4094" id="token-53-12" morph="none" pos="word" start_char="4091">está</TOKEN>
<TOKEN end_char="4096" id="token-53-13" morph="none" pos="word" start_char="4096">a</TOKEN>
<TOKEN end_char="4100" id="token-53-14" morph="none" pos="word" start_char="4098">200</TOKEN>
<TOKEN end_char="4107" id="token-53-15" morph="none" pos="word" start_char="4102">metros</TOKEN>
<TOKEN end_char="4111" id="token-53-16" morph="none" pos="word" start_char="4109">del</TOKEN>
<TOKEN end_char="4119" id="token-53-17" morph="none" pos="word" start_char="4113">mercado</TOKEN>
<TOKEN end_char="4125" id="token-53-18" morph="none" pos="word" start_char="4121">donde</TOKEN>
<TOKEN end_char="4131" id="token-53-19" morph="none" pos="word" start_char="4127">dicen</TOKEN>
<TOKEN end_char="4135" id="token-53-20" morph="none" pos="word" start_char="4133">que</TOKEN>
<TOKEN end_char="4138" id="token-53-21" morph="none" pos="word" start_char="4137">se</TOKEN>
<TOKEN end_char="4146" id="token-53-22" morph="none" pos="word" start_char="4140">originó</TOKEN>
<TOKEN end_char="4151" id="token-53-23" morph="none" pos="word" start_char="4148">todo</TOKEN>
<TOKEN end_char="4152" id="token-53-24" morph="none" pos="punct" start_char="4152">.</TOKEN>
<TRANSLATED_TEXT>Originally Written by Mongodemonguer Everyone suspects it because Wuhan's lab is 200 meters from the market where they say it all originated.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4296" id="segment-54" start_char="4154">
<ORIGINAL_TEXT>Lo que yo creo es que no fue intencionadamente propagado, si no que un investigador se contagió por error y salió del laboratorio con el bicho.</ORIGINAL_TEXT>
<TOKEN end_char="4155" id="token-54-0" morph="none" pos="word" start_char="4154">Lo</TOKEN>
<TOKEN end_char="4159" id="token-54-1" morph="none" pos="word" start_char="4157">que</TOKEN>
<TOKEN end_char="4162" id="token-54-2" morph="none" pos="word" start_char="4161">yo</TOKEN>
<TOKEN end_char="4167" id="token-54-3" morph="none" pos="word" start_char="4164">creo</TOKEN>
<TOKEN end_char="4170" id="token-54-4" morph="none" pos="word" start_char="4169">es</TOKEN>
<TOKEN end_char="4174" id="token-54-5" morph="none" pos="word" start_char="4172">que</TOKEN>
<TOKEN end_char="4177" id="token-54-6" morph="none" pos="word" start_char="4176">no</TOKEN>
<TOKEN end_char="4181" id="token-54-7" morph="none" pos="word" start_char="4179">fue</TOKEN>
<TOKEN end_char="4199" id="token-54-8" morph="none" pos="word" start_char="4183">intencionadamente</TOKEN>
<TOKEN end_char="4209" id="token-54-9" morph="none" pos="word" start_char="4201">propagado</TOKEN>
<TOKEN end_char="4210" id="token-54-10" morph="none" pos="punct" start_char="4210">,</TOKEN>
<TOKEN end_char="4213" id="token-54-11" morph="none" pos="word" start_char="4212">si</TOKEN>
<TOKEN end_char="4216" id="token-54-12" morph="none" pos="word" start_char="4215">no</TOKEN>
<TOKEN end_char="4220" id="token-54-13" morph="none" pos="word" start_char="4218">que</TOKEN>
<TOKEN end_char="4223" id="token-54-14" morph="none" pos="word" start_char="4222">un</TOKEN>
<TOKEN end_char="4236" id="token-54-15" morph="none" pos="word" start_char="4225">investigador</TOKEN>
<TOKEN end_char="4239" id="token-54-16" morph="none" pos="word" start_char="4238">se</TOKEN>
<TOKEN end_char="4248" id="token-54-17" morph="none" pos="word" start_char="4241">contagió</TOKEN>
<TOKEN end_char="4252" id="token-54-18" morph="none" pos="word" start_char="4250">por</TOKEN>
<TOKEN end_char="4258" id="token-54-19" morph="none" pos="word" start_char="4254">error</TOKEN>
<TOKEN end_char="4260" id="token-54-20" morph="none" pos="word" start_char="4260">y</TOKEN>
<TOKEN end_char="4266" id="token-54-21" morph="none" pos="word" start_char="4262">salió</TOKEN>
<TOKEN end_char="4270" id="token-54-22" morph="none" pos="word" start_char="4268">del</TOKEN>
<TOKEN end_char="4282" id="token-54-23" morph="none" pos="word" start_char="4272">laboratorio</TOKEN>
<TOKEN end_char="4286" id="token-54-24" morph="none" pos="word" start_char="4284">con</TOKEN>
<TOKEN end_char="4289" id="token-54-25" morph="none" pos="word" start_char="4288">el</TOKEN>
<TOKEN end_char="4295" id="token-54-26" morph="none" pos="word" start_char="4291">bicho</TOKEN>
<TOKEN end_char="4296" id="token-54-27" morph="none" pos="punct" start_char="4296">.</TOKEN>
<TRANSLATED_TEXT>What I think is that it wasn 't intentionally propagated, if not that a researcher got infected by mistake and walked out of the lab with the bug.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4383" id="segment-55" start_char="4298">
<ORIGINAL_TEXT>Incluso puede que fuera a comer o comprar al mercado donde se supone que es la zona 0.</ORIGINAL_TEXT>
<TOKEN end_char="4304" id="token-55-0" morph="none" pos="word" start_char="4298">Incluso</TOKEN>
<TOKEN end_char="4310" id="token-55-1" morph="none" pos="word" start_char="4306">puede</TOKEN>
<TOKEN end_char="4314" id="token-55-2" morph="none" pos="word" start_char="4312">que</TOKEN>
<TOKEN end_char="4320" id="token-55-3" morph="none" pos="word" start_char="4316">fuera</TOKEN>
<TOKEN end_char="4322" id="token-55-4" morph="none" pos="word" start_char="4322">a</TOKEN>
<TOKEN end_char="4328" id="token-55-5" morph="none" pos="word" start_char="4324">comer</TOKEN>
<TOKEN end_char="4330" id="token-55-6" morph="none" pos="word" start_char="4330">o</TOKEN>
<TOKEN end_char="4338" id="token-55-7" morph="none" pos="word" start_char="4332">comprar</TOKEN>
<TOKEN end_char="4341" id="token-55-8" morph="none" pos="word" start_char="4340">al</TOKEN>
<TOKEN end_char="4349" id="token-55-9" morph="none" pos="word" start_char="4343">mercado</TOKEN>
<TOKEN end_char="4355" id="token-55-10" morph="none" pos="word" start_char="4351">donde</TOKEN>
<TOKEN end_char="4358" id="token-55-11" morph="none" pos="word" start_char="4357">se</TOKEN>
<TOKEN end_char="4365" id="token-55-12" morph="none" pos="word" start_char="4360">supone</TOKEN>
<TOKEN end_char="4369" id="token-55-13" morph="none" pos="word" start_char="4367">que</TOKEN>
<TOKEN end_char="4372" id="token-55-14" morph="none" pos="word" start_char="4371">es</TOKEN>
<TOKEN end_char="4375" id="token-55-15" morph="none" pos="word" start_char="4374">la</TOKEN>
<TOKEN end_char="4380" id="token-55-16" morph="none" pos="word" start_char="4377">zona</TOKEN>
<TOKEN end_char="4382" id="token-55-17" morph="none" pos="word" start_char="4382">0</TOKEN>
<TOKEN end_char="4383" id="token-55-18" morph="none" pos="punct" start_char="4383">.</TOKEN>
<TRANSLATED_TEXT>It may even be eating or buying at the market where it is supposed to be zone 0.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4519" id="segment-56" start_char="4386">
<ORIGINAL_TEXT>Yo también creo en la posibilidad de que los animales de los experimentos en lugar de ser incinerados acabaran vendidos en el mercado.</ORIGINAL_TEXT>
<TOKEN end_char="4387" id="token-56-0" morph="none" pos="word" start_char="4386">Yo</TOKEN>
<TOKEN end_char="4395" id="token-56-1" morph="none" pos="word" start_char="4389">también</TOKEN>
<TOKEN end_char="4400" id="token-56-2" morph="none" pos="word" start_char="4397">creo</TOKEN>
<TOKEN end_char="4403" id="token-56-3" morph="none" pos="word" start_char="4402">en</TOKEN>
<TOKEN end_char="4406" id="token-56-4" morph="none" pos="word" start_char="4405">la</TOKEN>
<TOKEN end_char="4418" id="token-56-5" morph="none" pos="word" start_char="4408">posibilidad</TOKEN>
<TOKEN end_char="4421" id="token-56-6" morph="none" pos="word" start_char="4420">de</TOKEN>
<TOKEN end_char="4425" id="token-56-7" morph="none" pos="word" start_char="4423">que</TOKEN>
<TOKEN end_char="4429" id="token-56-8" morph="none" pos="word" start_char="4427">los</TOKEN>
<TOKEN end_char="4438" id="token-56-9" morph="none" pos="word" start_char="4431">animales</TOKEN>
<TOKEN end_char="4441" id="token-56-10" morph="none" pos="word" start_char="4440">de</TOKEN>
<TOKEN end_char="4445" id="token-56-11" morph="none" pos="word" start_char="4443">los</TOKEN>
<TOKEN end_char="4458" id="token-56-12" morph="none" pos="word" start_char="4447">experimentos</TOKEN>
<TOKEN end_char="4461" id="token-56-13" morph="none" pos="word" start_char="4460">en</TOKEN>
<TOKEN end_char="4467" id="token-56-14" morph="none" pos="word" start_char="4463">lugar</TOKEN>
<TOKEN end_char="4470" id="token-56-15" morph="none" pos="word" start_char="4469">de</TOKEN>
<TOKEN end_char="4474" id="token-56-16" morph="none" pos="word" start_char="4472">ser</TOKEN>
<TOKEN end_char="4486" id="token-56-17" morph="none" pos="word" start_char="4476">incinerados</TOKEN>
<TOKEN end_char="4495" id="token-56-18" morph="none" pos="word" start_char="4488">acabaran</TOKEN>
<TOKEN end_char="4504" id="token-56-19" morph="none" pos="word" start_char="4497">vendidos</TOKEN>
<TOKEN end_char="4507" id="token-56-20" morph="none" pos="word" start_char="4506">en</TOKEN>
<TOKEN end_char="4510" id="token-56-21" morph="none" pos="word" start_char="4509">el</TOKEN>
<TOKEN end_char="4518" id="token-56-22" morph="none" pos="word" start_char="4512">mercado</TOKEN>
<TOKEN end_char="4519" id="token-56-23" morph="none" pos="punct" start_char="4519">.</TOKEN>
<TRANSLATED_TEXT>I also believe in the possibility that the animals from the experiments instead of being incinerated will end up being sold on the market.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4559" id="segment-57" start_char="4521">
<ORIGINAL_TEXT>Se supone que hay un detenido por ello.</ORIGINAL_TEXT>
<TOKEN end_char="4522" id="token-57-0" morph="none" pos="word" start_char="4521">Se</TOKEN>
<TOKEN end_char="4529" id="token-57-1" morph="none" pos="word" start_char="4524">supone</TOKEN>
<TOKEN end_char="4533" id="token-57-2" morph="none" pos="word" start_char="4531">que</TOKEN>
<TOKEN end_char="4537" id="token-57-3" morph="none" pos="word" start_char="4535">hay</TOKEN>
<TOKEN end_char="4540" id="token-57-4" morph="none" pos="word" start_char="4539">un</TOKEN>
<TOKEN end_char="4549" id="token-57-5" morph="none" pos="word" start_char="4542">detenido</TOKEN>
<TOKEN end_char="4553" id="token-57-6" morph="none" pos="word" start_char="4551">por</TOKEN>
<TOKEN end_char="4558" id="token-57-7" morph="none" pos="word" start_char="4555">ello</TOKEN>
<TOKEN end_char="4559" id="token-57-8" morph="none" pos="punct" start_char="4559">.</TOKEN>
<TRANSLATED_TEXT>There's supposed to be a detainee for that.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4606" id="segment-58" start_char="4565">
<ORIGINAL_TEXT>en esa web no encuentro un ¿quienes Somos?</ORIGINAL_TEXT>
<TOKEN end_char="4566" id="token-58-0" morph="none" pos="word" start_char="4565">en</TOKEN>
<TOKEN end_char="4570" id="token-58-1" morph="none" pos="word" start_char="4568">esa</TOKEN>
<TOKEN end_char="4574" id="token-58-2" morph="none" pos="word" start_char="4572">web</TOKEN>
<TOKEN end_char="4577" id="token-58-3" morph="none" pos="word" start_char="4576">no</TOKEN>
<TOKEN end_char="4587" id="token-58-4" morph="none" pos="word" start_char="4579">encuentro</TOKEN>
<TOKEN end_char="4590" id="token-58-5" morph="none" pos="word" start_char="4589">un</TOKEN>
<TOKEN end_char="4592" id="token-58-6" morph="none" pos="punct" start_char="4592">¿</TOKEN>
<TOKEN end_char="4599" id="token-58-7" morph="none" pos="word" start_char="4593">quienes</TOKEN>
<TOKEN end_char="4605" id="token-58-8" morph="none" pos="word" start_char="4601">Somos</TOKEN>
<TOKEN end_char="4606" id="token-58-9" morph="none" pos="punct" start_char="4606">?</TOKEN>
<TRANSLATED_TEXT>on that website I don't find a Who Are We?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4676" id="segment-59" start_char="4608">
<ORIGINAL_TEXT>o similar, nadie parece dirigir/firmar nada...fiabilidad 0 por tanto.</ORIGINAL_TEXT>
<TOKEN end_char="4608" id="token-59-0" morph="none" pos="word" start_char="4608">o</TOKEN>
<TOKEN end_char="4616" id="token-59-1" morph="none" pos="word" start_char="4610">similar</TOKEN>
<TOKEN end_char="4617" id="token-59-2" morph="none" pos="punct" start_char="4617">,</TOKEN>
<TOKEN end_char="4623" id="token-59-3" morph="none" pos="word" start_char="4619">nadie</TOKEN>
<TOKEN end_char="4630" id="token-59-4" morph="none" pos="word" start_char="4625">parece</TOKEN>
<TOKEN end_char="4645" id="token-59-5" morph="none" pos="unknown" start_char="4632">dirigir/firmar</TOKEN>
<TOKEN end_char="4663" id="token-59-6" morph="none" pos="unknown" start_char="4647">nada...fiabilidad</TOKEN>
<TOKEN end_char="4665" id="token-59-7" morph="none" pos="word" start_char="4665">0</TOKEN>
<TOKEN end_char="4669" id="token-59-8" morph="none" pos="word" start_char="4667">por</TOKEN>
<TOKEN end_char="4675" id="token-59-9" morph="none" pos="word" start_char="4671">tanto</TOKEN>
<TOKEN end_char="4676" id="token-59-10" morph="none" pos="punct" start_char="4676">.</TOKEN>
<TRANSLATED_TEXT>or similar, no one seems to direct / sign anything... reliability 0 therefore.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4686" id="segment-60" start_char="4682">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN end_char="4685" id="token-60-0" morph="none" pos="word" start_char="4682">Cita</TOKEN>
<TOKEN end_char="4686" id="token-60-1" morph="none" pos="punct" start_char="4686">:</TOKEN>
<TRANSLATED_TEXT>Other:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="4766" id="segment-61" start_char="4691">
<ORIGINAL_TEXT>Originalmente Escrito por zirick Lo fácil era cargar la culpa a un pangolin.</ORIGINAL_TEXT>
<TOKEN end_char="4703" id="token-61-0" morph="none" pos="word" start_char="4691">Originalmente</TOKEN>
<TOKEN end_char="4711" id="token-61-1" morph="none" pos="word" start_char="4705">Escrito</TOKEN>
<TOKEN end_char="4715" id="token-61-2" morph="none" pos="word" start_char="4713">por</TOKEN>
<TOKEN end_char="4722" id="token-61-3" morph="none" pos="word" start_char="4717">zirick</TOKEN>
<TOKEN end_char="4725" id="token-61-4" morph="none" pos="word" start_char="4724">Lo</TOKEN>
<TOKEN end_char="4731" id="token-61-5" morph="none" pos="word" start_char="4727">fácil</TOKEN>
<TOKEN end_char="4735" id="token-61-6" morph="none" pos="word" start_char="4733">era</TOKEN>
<TOKEN end_char="4742" id="token-61-7" morph="none" pos="word" start_char="4737">cargar</TOKEN>
<TOKEN end_char="4745" id="token-61-8" morph="none" pos="word" start_char="4744">la</TOKEN>
<TOKEN end_char="4751" id="token-61-9" morph="none" pos="word" start_char="4747">culpa</TOKEN>
<TOKEN end_char="4753" id="token-61-10" morph="none" pos="word" start_char="4753">a</TOKEN>
<TOKEN end_char="4756" id="token-61-11" morph="none" pos="word" start_char="4755">un</TOKEN>
<TOKEN end_char="4765" id="token-61-12" morph="none" pos="word" start_char="4758">pangolin</TOKEN>
<TOKEN end_char="4766" id="token-61-13" morph="none" pos="punct" start_char="4766">.</TOKEN>
<TRANSLATED_TEXT>Originally written by zirick The easy thing was to charge a pangolin.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4839" id="segment-62" start_char="4768">
<ORIGINAL_TEXT>Pero no coló Quién se cree que esta cosa tan bonita puede hacernos daño?</ORIGINAL_TEXT>
<TOKEN end_char="4771" id="token-62-0" morph="none" pos="word" start_char="4768">Pero</TOKEN>
<TOKEN end_char="4774" id="token-62-1" morph="none" pos="word" start_char="4773">no</TOKEN>
<TOKEN end_char="4779" id="token-62-2" morph="none" pos="word" start_char="4776">coló</TOKEN>
<TOKEN end_char="4785" id="token-62-3" morph="none" pos="word" start_char="4781">Quién</TOKEN>
<TOKEN end_char="4788" id="token-62-4" morph="none" pos="word" start_char="4787">se</TOKEN>
<TOKEN end_char="4793" id="token-62-5" morph="none" pos="word" start_char="4790">cree</TOKEN>
<TOKEN end_char="4797" id="token-62-6" morph="none" pos="word" start_char="4795">que</TOKEN>
<TOKEN end_char="4802" id="token-62-7" morph="none" pos="word" start_char="4799">esta</TOKEN>
<TOKEN end_char="4807" id="token-62-8" morph="none" pos="word" start_char="4804">cosa</TOKEN>
<TOKEN end_char="4811" id="token-62-9" morph="none" pos="word" start_char="4809">tan</TOKEN>
<TOKEN end_char="4818" id="token-62-10" morph="none" pos="word" start_char="4813">bonita</TOKEN>
<TOKEN end_char="4824" id="token-62-11" morph="none" pos="word" start_char="4820">puede</TOKEN>
<TOKEN end_char="4833" id="token-62-12" morph="none" pos="word" start_char="4826">hacernos</TOKEN>
<TOKEN end_char="4838" id="token-62-13" morph="none" pos="word" start_char="4835">daño</TOKEN>
<TOKEN end_char="4839" id="token-62-14" morph="none" pos="punct" start_char="4839">?</TOKEN>
<TRANSLATED_TEXT>Who thinks this beautiful thing can hurt us?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4847" id="segment-63" start_char="4841">
<ORIGINAL_TEXT>Naaadie</ORIGINAL_TEXT>
<TOKEN end_char="4847" id="token-63-0" morph="none" pos="word" start_char="4841">Naaadie</TOKEN>
<TRANSLATED_TEXT>Naaadi</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="4857" id="segment-64" start_char="4853">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN end_char="4856" id="token-64-0" morph="none" pos="word" start_char="4853">Cita</TOKEN>
<TOKEN end_char="4857" id="token-64-1" morph="none" pos="punct" start_char="4857">:</TOKEN>
<TRANSLATED_TEXT>Other:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="4948" id="segment-65" start_char="4862">
<ORIGINAL_TEXT>Originalmente Escrito por Castigator Ese tío es una eminencia en virologia..poco broma.</ORIGINAL_TEXT>
<TOKEN end_char="4874" id="token-65-0" morph="none" pos="word" start_char="4862">Originalmente</TOKEN>
<TOKEN end_char="4882" id="token-65-1" morph="none" pos="word" start_char="4876">Escrito</TOKEN>
<TOKEN end_char="4886" id="token-65-2" morph="none" pos="word" start_char="4884">por</TOKEN>
<TOKEN end_char="4897" id="token-65-3" morph="none" pos="word" start_char="4888">Castigator</TOKEN>
<TOKEN end_char="4901" id="token-65-4" morph="none" pos="word" start_char="4899">Ese</TOKEN>
<TOKEN end_char="4905" id="token-65-5" morph="none" pos="word" start_char="4903">tío</TOKEN>
<TOKEN end_char="4908" id="token-65-6" morph="none" pos="word" start_char="4907">es</TOKEN>
<TOKEN end_char="4912" id="token-65-7" morph="none" pos="word" start_char="4910">una</TOKEN>
<TOKEN end_char="4922" id="token-65-8" morph="none" pos="word" start_char="4914">eminencia</TOKEN>
<TOKEN end_char="4925" id="token-65-9" morph="none" pos="word" start_char="4924">en</TOKEN>
<TOKEN end_char="4941" id="token-65-10" morph="none" pos="unknown" start_char="4927">virologia..poco</TOKEN>
<TOKEN end_char="4947" id="token-65-11" morph="none" pos="word" start_char="4943">broma</TOKEN>
<TOKEN end_char="4948" id="token-65-12" morph="none" pos="punct" start_char="4948">.</TOKEN>
<TRANSLATED_TEXT>Originally written by Castigator That guy is an eminence in virology.. little joke.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4968" id="segment-66" start_char="4953">
<ORIGINAL_TEXT>Es premio Nobel.</ORIGINAL_TEXT>
<TOKEN end_char="4954" id="token-66-0" morph="none" pos="word" start_char="4953">Es</TOKEN>
<TOKEN end_char="4961" id="token-66-1" morph="none" pos="word" start_char="4956">premio</TOKEN>
<TOKEN end_char="4967" id="token-66-2" morph="none" pos="word" start_char="4963">Nobel</TOKEN>
<TOKEN end_char="4968" id="token-66-3" morph="none" pos="punct" start_char="4968">.</TOKEN>
<TRANSLATED_TEXT>Nobel Prize.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4996" id="segment-67" start_char="4974">
<ORIGINAL_TEXT>Falacia Ad Verecundiam.</ORIGINAL_TEXT>
<TOKEN end_char="4980" id="token-67-0" morph="none" pos="word" start_char="4974">Falacia</TOKEN>
<TOKEN end_char="4983" id="token-67-1" morph="none" pos="word" start_char="4982">Ad</TOKEN>
<TOKEN end_char="4995" id="token-67-2" morph="none" pos="word" start_char="4985">Verecundiam</TOKEN>
<TOKEN end_char="4996" id="token-67-3" morph="none" pos="punct" start_char="4996">.</TOKEN>
<TRANSLATED_TEXT>Falacia ad Verecindiam.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5021" id="segment-68" start_char="4998">
<ORIGINAL_TEXT>De primero de magufería.</ORIGINAL_TEXT>
<TOKEN end_char="4999" id="token-68-0" morph="none" pos="word" start_char="4998">De</TOKEN>
<TOKEN end_char="5007" id="token-68-1" morph="none" pos="word" start_char="5001">primero</TOKEN>
<TOKEN end_char="5010" id="token-68-2" morph="none" pos="word" start_char="5009">de</TOKEN>
<TOKEN end_char="5020" id="token-68-3" morph="none" pos="word" start_char="5012">magufería</TOKEN>
<TOKEN end_char="5021" id="token-68-4" morph="none" pos="punct" start_char="5021">.</TOKEN>
<TRANSLATED_TEXT>The first of maguferies.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5053" id="segment-69" start_char="5023">
<ORIGINAL_TEXT>Os la cuelan como a corderitos.</ORIGINAL_TEXT>
<TOKEN end_char="5024" id="token-69-0" morph="none" pos="word" start_char="5023">Os</TOKEN>
<TOKEN end_char="5027" id="token-69-1" morph="none" pos="word" start_char="5026">la</TOKEN>
<TOKEN end_char="5034" id="token-69-2" morph="none" pos="word" start_char="5029">cuelan</TOKEN>
<TOKEN end_char="5039" id="token-69-3" morph="none" pos="word" start_char="5036">como</TOKEN>
<TOKEN end_char="5041" id="token-69-4" morph="none" pos="word" start_char="5041">a</TOKEN>
<TOKEN end_char="5052" id="token-69-5" morph="none" pos="word" start_char="5043">corderitos</TOKEN>
<TOKEN end_char="5053" id="token-69-6" morph="none" pos="punct" start_char="5053">.</TOKEN>
<TRANSLATED_TEXT>They dress her like lambs.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5280" id="segment-70" start_char="5055">
<ORIGINAL_TEXT>¿Qué os da más confianza, un grupo de investigadores que trabajan en un laboratorio día y noche secuenciando el genoma del virus o un Nobel de 87 años que hace 20 años que no pisa un laboratorio y opina desde la barra del bar?</ORIGINAL_TEXT>
<TOKEN end_char="5055" id="token-70-0" morph="none" pos="punct" start_char="5055">¿</TOKEN>
<TOKEN end_char="5058" id="token-70-1" morph="none" pos="word" start_char="5056">Qué</TOKEN>
<TOKEN end_char="5061" id="token-70-2" morph="none" pos="word" start_char="5060">os</TOKEN>
<TOKEN end_char="5064" id="token-70-3" morph="none" pos="word" start_char="5063">da</TOKEN>
<TOKEN end_char="5068" id="token-70-4" morph="none" pos="word" start_char="5066">más</TOKEN>
<TOKEN end_char="5078" id="token-70-5" morph="none" pos="word" start_char="5070">confianza</TOKEN>
<TOKEN end_char="5079" id="token-70-6" morph="none" pos="punct" start_char="5079">,</TOKEN>
<TOKEN end_char="5082" id="token-70-7" morph="none" pos="word" start_char="5081">un</TOKEN>
<TOKEN end_char="5088" id="token-70-8" morph="none" pos="word" start_char="5084">grupo</TOKEN>
<TOKEN end_char="5091" id="token-70-9" morph="none" pos="word" start_char="5090">de</TOKEN>
<TOKEN end_char="5106" id="token-70-10" morph="none" pos="word" start_char="5093">investigadores</TOKEN>
<TOKEN end_char="5110" id="token-70-11" morph="none" pos="word" start_char="5108">que</TOKEN>
<TOKEN end_char="5119" id="token-70-12" morph="none" pos="word" start_char="5112">trabajan</TOKEN>
<TOKEN end_char="5122" id="token-70-13" morph="none" pos="word" start_char="5121">en</TOKEN>
<TOKEN end_char="5125" id="token-70-14" morph="none" pos="word" start_char="5124">un</TOKEN>
<TOKEN end_char="5137" id="token-70-15" morph="none" pos="word" start_char="5127">laboratorio</TOKEN>
<TOKEN end_char="5141" id="token-70-16" morph="none" pos="word" start_char="5139">día</TOKEN>
<TOKEN end_char="5143" id="token-70-17" morph="none" pos="word" start_char="5143">y</TOKEN>
<TOKEN end_char="5149" id="token-70-18" morph="none" pos="word" start_char="5145">noche</TOKEN>
<TOKEN end_char="5162" id="token-70-19" morph="none" pos="word" start_char="5151">secuenciando</TOKEN>
<TOKEN end_char="5165" id="token-70-20" morph="none" pos="word" start_char="5164">el</TOKEN>
<TOKEN end_char="5172" id="token-70-21" morph="none" pos="word" start_char="5167">genoma</TOKEN>
<TOKEN end_char="5176" id="token-70-22" morph="none" pos="word" start_char="5174">del</TOKEN>
<TOKEN end_char="5182" id="token-70-23" morph="none" pos="word" start_char="5178">virus</TOKEN>
<TOKEN end_char="5184" id="token-70-24" morph="none" pos="word" start_char="5184">o</TOKEN>
<TOKEN end_char="5187" id="token-70-25" morph="none" pos="word" start_char="5186">un</TOKEN>
<TOKEN end_char="5193" id="token-70-26" morph="none" pos="word" start_char="5189">Nobel</TOKEN>
<TOKEN end_char="5196" id="token-70-27" morph="none" pos="word" start_char="5195">de</TOKEN>
<TOKEN end_char="5199" id="token-70-28" morph="none" pos="word" start_char="5198">87</TOKEN>
<TOKEN end_char="5204" id="token-70-29" morph="none" pos="word" start_char="5201">años</TOKEN>
<TOKEN end_char="5208" id="token-70-30" morph="none" pos="word" start_char="5206">que</TOKEN>
<TOKEN end_char="5213" id="token-70-31" morph="none" pos="word" start_char="5210">hace</TOKEN>
<TOKEN end_char="5216" id="token-70-32" morph="none" pos="word" start_char="5215">20</TOKEN>
<TOKEN end_char="5221" id="token-70-33" morph="none" pos="word" start_char="5218">años</TOKEN>
<TOKEN end_char="5225" id="token-70-34" morph="none" pos="word" start_char="5223">que</TOKEN>
<TOKEN end_char="5228" id="token-70-35" morph="none" pos="word" start_char="5227">no</TOKEN>
<TOKEN end_char="5233" id="token-70-36" morph="none" pos="word" start_char="5230">pisa</TOKEN>
<TOKEN end_char="5236" id="token-70-37" morph="none" pos="word" start_char="5235">un</TOKEN>
<TOKEN end_char="5248" id="token-70-38" morph="none" pos="word" start_char="5238">laboratorio</TOKEN>
<TOKEN end_char="5250" id="token-70-39" morph="none" pos="word" start_char="5250">y</TOKEN>
<TOKEN end_char="5256" id="token-70-40" morph="none" pos="word" start_char="5252">opina</TOKEN>
<TOKEN end_char="5262" id="token-70-41" morph="none" pos="word" start_char="5258">desde</TOKEN>
<TOKEN end_char="5265" id="token-70-42" morph="none" pos="word" start_char="5264">la</TOKEN>
<TOKEN end_char="5271" id="token-70-43" morph="none" pos="word" start_char="5267">barra</TOKEN>
<TOKEN end_char="5275" id="token-70-44" morph="none" pos="word" start_char="5273">del</TOKEN>
<TOKEN end_char="5279" id="token-70-45" morph="none" pos="word" start_char="5277">bar</TOKEN>
<TOKEN end_char="5280" id="token-70-46" morph="none" pos="punct" start_char="5280">?</TOKEN>
<TRANSLATED_TEXT>What gives you more confidence, a group of researchers working in a lab day and night sequencing the virus genome, or an 87-year-old Nobel who 20 years ago didn 't step on a lab and stare out of the bar?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5293" id="segment-71" start_char="5282">
<ORIGINAL_TEXT>Vamos joder.</ORIGINAL_TEXT>
<TOKEN end_char="5286" id="token-71-0" morph="none" pos="word" start_char="5282">Vamos</TOKEN>
<TOKEN end_char="5292" id="token-71-1" morph="none" pos="word" start_char="5288">joder</TOKEN>
<TOKEN end_char="5293" id="token-71-2" morph="none" pos="punct" start_char="5293">.</TOKEN>
<TRANSLATED_TEXT>Let's fuck off.</TRANSLATED_TEXT><DETECTED_LANGUAGE>lt</DETECTED_LANGUAGE></SEG>
<SEG end_char="5303" id="segment-72" start_char="5299">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN end_char="5302" id="token-72-0" morph="none" pos="word" start_char="5299">Cita</TOKEN>
<TOKEN end_char="5303" id="token-72-1" morph="none" pos="punct" start_char="5303">:</TOKEN>
<TRANSLATED_TEXT>Other:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="5405" id="segment-73" start_char="5308">
<ORIGINAL_TEXT>Originalmente Escrito por Nostradonuts Quién se cree que esta cosa tan bonita puede hacernos daño?</ORIGINAL_TEXT>
<TOKEN end_char="5320" id="token-73-0" morph="none" pos="word" start_char="5308">Originalmente</TOKEN>
<TOKEN end_char="5328" id="token-73-1" morph="none" pos="word" start_char="5322">Escrito</TOKEN>
<TOKEN end_char="5332" id="token-73-2" morph="none" pos="word" start_char="5330">por</TOKEN>
<TOKEN end_char="5345" id="token-73-3" morph="none" pos="word" start_char="5334">Nostradonuts</TOKEN>
<TOKEN end_char="5351" id="token-73-4" morph="none" pos="word" start_char="5347">Quién</TOKEN>
<TOKEN end_char="5354" id="token-73-5" morph="none" pos="word" start_char="5353">se</TOKEN>
<TOKEN end_char="5359" id="token-73-6" morph="none" pos="word" start_char="5356">cree</TOKEN>
<TOKEN end_char="5363" id="token-73-7" morph="none" pos="word" start_char="5361">que</TOKEN>
<TOKEN end_char="5368" id="token-73-8" morph="none" pos="word" start_char="5365">esta</TOKEN>
<TOKEN end_char="5373" id="token-73-9" morph="none" pos="word" start_char="5370">cosa</TOKEN>
<TOKEN end_char="5377" id="token-73-10" morph="none" pos="word" start_char="5375">tan</TOKEN>
<TOKEN end_char="5384" id="token-73-11" morph="none" pos="word" start_char="5379">bonita</TOKEN>
<TOKEN end_char="5390" id="token-73-12" morph="none" pos="word" start_char="5386">puede</TOKEN>
<TOKEN end_char="5399" id="token-73-13" morph="none" pos="word" start_char="5392">hacernos</TOKEN>
<TOKEN end_char="5404" id="token-73-14" morph="none" pos="word" start_char="5401">daño</TOKEN>
<TOKEN end_char="5405" id="token-73-15" morph="none" pos="punct" start_char="5405">?</TOKEN>
<TRANSLATED_TEXT>Originally Written by Nostradonuts Who thinks this beautiful thing can hurt us?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5413" id="segment-74" start_char="5407">
<ORIGINAL_TEXT>Naaadie</ORIGINAL_TEXT>
<TOKEN end_char="5413" id="token-74-0" morph="none" pos="word" start_char="5407">Naaadie</TOKEN>
<TRANSLATED_TEXT>Naaadi</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="5440" id="segment-75" start_char="5418">
<ORIGINAL_TEXT>Más majete que el copón</ORIGINAL_TEXT>
<TOKEN end_char="5420" id="token-75-0" morph="none" pos="word" start_char="5418">Más</TOKEN>
<TOKEN end_char="5427" id="token-75-1" morph="none" pos="word" start_char="5422">majete</TOKEN>
<TOKEN end_char="5431" id="token-75-2" morph="none" pos="word" start_char="5429">que</TOKEN>
<TOKEN end_char="5434" id="token-75-3" morph="none" pos="word" start_char="5433">el</TOKEN>
<TOKEN end_char="5440" id="token-75-4" morph="none" pos="word" start_char="5436">copón</TOKEN>
<TRANSLATED_TEXT>More than the cup</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5450" id="segment-76" start_char="5446">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN end_char="5449" id="token-76-0" morph="none" pos="word" start_char="5446">Cita</TOKEN>
<TOKEN end_char="5450" id="token-76-1" morph="none" pos="punct" start_char="5450">:</TOKEN>
<TRANSLATED_TEXT>Other:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="5572" id="segment-77" start_char="5455">
<ORIGINAL_TEXT>Originalmente Escrito por sipotons Unos dicen una cosa y otros otra, al final me creo más JL que a los demás, total...</ORIGINAL_TEXT>
<TOKEN end_char="5467" id="token-77-0" morph="none" pos="word" start_char="5455">Originalmente</TOKEN>
<TOKEN end_char="5475" id="token-77-1" morph="none" pos="word" start_char="5469">Escrito</TOKEN>
<TOKEN end_char="5479" id="token-77-2" morph="none" pos="word" start_char="5477">por</TOKEN>
<TOKEN end_char="5488" id="token-77-3" morph="none" pos="word" start_char="5481">sipotons</TOKEN>
<TOKEN end_char="5493" id="token-77-4" morph="none" pos="word" start_char="5490">Unos</TOKEN>
<TOKEN end_char="5499" id="token-77-5" morph="none" pos="word" start_char="5495">dicen</TOKEN>
<TOKEN end_char="5503" id="token-77-6" morph="none" pos="word" start_char="5501">una</TOKEN>
<TOKEN end_char="5508" id="token-77-7" morph="none" pos="word" start_char="5505">cosa</TOKEN>
<TOKEN end_char="5510" id="token-77-8" morph="none" pos="word" start_char="5510">y</TOKEN>
<TOKEN end_char="5516" id="token-77-9" morph="none" pos="word" start_char="5512">otros</TOKEN>
<TOKEN end_char="5521" id="token-77-10" morph="none" pos="word" start_char="5518">otra</TOKEN>
<TOKEN end_char="5522" id="token-77-11" morph="none" pos="punct" start_char="5522">,</TOKEN>
<TOKEN end_char="5525" id="token-77-12" morph="none" pos="word" start_char="5524">al</TOKEN>
<TOKEN end_char="5531" id="token-77-13" morph="none" pos="word" start_char="5527">final</TOKEN>
<TOKEN end_char="5534" id="token-77-14" morph="none" pos="word" start_char="5533">me</TOKEN>
<TOKEN end_char="5539" id="token-77-15" morph="none" pos="word" start_char="5536">creo</TOKEN>
<TOKEN end_char="5543" id="token-77-16" morph="none" pos="word" start_char="5541">más</TOKEN>
<TOKEN end_char="5546" id="token-77-17" morph="none" pos="word" start_char="5545">JL</TOKEN>
<TOKEN end_char="5550" id="token-77-18" morph="none" pos="word" start_char="5548">que</TOKEN>
<TOKEN end_char="5552" id="token-77-19" morph="none" pos="word" start_char="5552">a</TOKEN>
<TOKEN end_char="5556" id="token-77-20" morph="none" pos="word" start_char="5554">los</TOKEN>
<TOKEN end_char="5562" id="token-77-21" morph="none" pos="word" start_char="5558">demás</TOKEN>
<TOKEN end_char="5563" id="token-77-22" morph="none" pos="punct" start_char="5563">,</TOKEN>
<TOKEN end_char="5569" id="token-77-23" morph="none" pos="word" start_char="5565">total</TOKEN>
<TOKEN end_char="5572" id="token-77-24" morph="none" pos="punct" start_char="5570">...</TOKEN>
<TRANSLATED_TEXT>Originally written by sipotons Some say one thing and others, at the end I believe more JL than others, total...</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5906" id="segment-78" start_char="5577">
<ORIGINAL_TEXT>En mi opinión, la diferencia está en que al principio nadie sabía nada y se tenía mucho miedo a expresar una opinión mínimamente polémica en parte por corrección política y en parte por posibles represalias (económicas sobre todo) de China, que por cierto lanzó una ofensiva mediática en occidente al grito de "no seáis racistas".</ORIGINAL_TEXT>
<TOKEN end_char="5578" id="token-78-0" morph="none" pos="word" start_char="5577">En</TOKEN>
<TOKEN end_char="5581" id="token-78-1" morph="none" pos="word" start_char="5580">mi</TOKEN>
<TOKEN end_char="5589" id="token-78-2" morph="none" pos="word" start_char="5583">opinión</TOKEN>
<TOKEN end_char="5590" id="token-78-3" morph="none" pos="punct" start_char="5590">,</TOKEN>
<TOKEN end_char="5593" id="token-78-4" morph="none" pos="word" start_char="5592">la</TOKEN>
<TOKEN end_char="5604" id="token-78-5" morph="none" pos="word" start_char="5595">diferencia</TOKEN>
<TOKEN end_char="5609" id="token-78-6" morph="none" pos="word" start_char="5606">está</TOKEN>
<TOKEN end_char="5612" id="token-78-7" morph="none" pos="word" start_char="5611">en</TOKEN>
<TOKEN end_char="5616" id="token-78-8" morph="none" pos="word" start_char="5614">que</TOKEN>
<TOKEN end_char="5619" id="token-78-9" morph="none" pos="word" start_char="5618">al</TOKEN>
<TOKEN end_char="5629" id="token-78-10" morph="none" pos="word" start_char="5621">principio</TOKEN>
<TOKEN end_char="5635" id="token-78-11" morph="none" pos="word" start_char="5631">nadie</TOKEN>
<TOKEN end_char="5641" id="token-78-12" morph="none" pos="word" start_char="5637">sabía</TOKEN>
<TOKEN end_char="5646" id="token-78-13" morph="none" pos="word" start_char="5643">nada</TOKEN>
<TOKEN end_char="5648" id="token-78-14" morph="none" pos="word" start_char="5648">y</TOKEN>
<TOKEN end_char="5651" id="token-78-15" morph="none" pos="word" start_char="5650">se</TOKEN>
<TOKEN end_char="5657" id="token-78-16" morph="none" pos="word" start_char="5653">tenía</TOKEN>
<TOKEN end_char="5663" id="token-78-17" morph="none" pos="word" start_char="5659">mucho</TOKEN>
<TOKEN end_char="5669" id="token-78-18" morph="none" pos="word" start_char="5665">miedo</TOKEN>
<TOKEN end_char="5671" id="token-78-19" morph="none" pos="word" start_char="5671">a</TOKEN>
<TOKEN end_char="5680" id="token-78-20" morph="none" pos="word" start_char="5673">expresar</TOKEN>
<TOKEN end_char="5684" id="token-78-21" morph="none" pos="word" start_char="5682">una</TOKEN>
<TOKEN end_char="5692" id="token-78-22" morph="none" pos="word" start_char="5686">opinión</TOKEN>
<TOKEN end_char="5704" id="token-78-23" morph="none" pos="word" start_char="5694">mínimamente</TOKEN>
<TOKEN end_char="5713" id="token-78-24" morph="none" pos="word" start_char="5706">polémica</TOKEN>
<TOKEN end_char="5716" id="token-78-25" morph="none" pos="word" start_char="5715">en</TOKEN>
<TOKEN end_char="5722" id="token-78-26" morph="none" pos="word" start_char="5718">parte</TOKEN>
<TOKEN end_char="5726" id="token-78-27" morph="none" pos="word" start_char="5724">por</TOKEN>
<TOKEN end_char="5737" id="token-78-28" morph="none" pos="word" start_char="5728">corrección</TOKEN>
<TOKEN end_char="5746" id="token-78-29" morph="none" pos="word" start_char="5739">política</TOKEN>
<TOKEN end_char="5748" id="token-78-30" morph="none" pos="word" start_char="5748">y</TOKEN>
<TOKEN end_char="5751" id="token-78-31" morph="none" pos="word" start_char="5750">en</TOKEN>
<TOKEN end_char="5757" id="token-78-32" morph="none" pos="word" start_char="5753">parte</TOKEN>
<TOKEN end_char="5761" id="token-78-33" morph="none" pos="word" start_char="5759">por</TOKEN>
<TOKEN end_char="5770" id="token-78-34" morph="none" pos="word" start_char="5763">posibles</TOKEN>
<TOKEN end_char="5782" id="token-78-35" morph="none" pos="word" start_char="5772">represalias</TOKEN>
<TOKEN end_char="5784" id="token-78-36" morph="none" pos="punct" start_char="5784">(</TOKEN>
<TOKEN end_char="5794" id="token-78-37" morph="none" pos="word" start_char="5785">económicas</TOKEN>
<TOKEN end_char="5800" id="token-78-38" morph="none" pos="word" start_char="5796">sobre</TOKEN>
<TOKEN end_char="5805" id="token-78-39" morph="none" pos="word" start_char="5802">todo</TOKEN>
<TOKEN end_char="5806" id="token-78-40" morph="none" pos="punct" start_char="5806">)</TOKEN>
<TOKEN end_char="5809" id="token-78-41" morph="none" pos="word" start_char="5808">de</TOKEN>
<TOKEN end_char="5815" id="token-78-42" morph="none" pos="word" start_char="5811">China</TOKEN>
<TOKEN end_char="5816" id="token-78-43" morph="none" pos="punct" start_char="5816">,</TOKEN>
<TOKEN end_char="5820" id="token-78-44" morph="none" pos="word" start_char="5818">que</TOKEN>
<TOKEN end_char="5824" id="token-78-45" morph="none" pos="word" start_char="5822">por</TOKEN>
<TOKEN end_char="5831" id="token-78-46" morph="none" pos="word" start_char="5826">cierto</TOKEN>
<TOKEN end_char="5837" id="token-78-47" morph="none" pos="word" start_char="5833">lanzó</TOKEN>
<TOKEN end_char="5841" id="token-78-48" morph="none" pos="word" start_char="5839">una</TOKEN>
<TOKEN end_char="5850" id="token-78-49" morph="none" pos="word" start_char="5843">ofensiva</TOKEN>
<TOKEN end_char="5860" id="token-78-50" morph="none" pos="word" start_char="5852">mediática</TOKEN>
<TOKEN end_char="5863" id="token-78-51" morph="none" pos="word" start_char="5862">en</TOKEN>
<TOKEN end_char="5873" id="token-78-52" morph="none" pos="word" start_char="5865">occidente</TOKEN>
<TOKEN end_char="5876" id="token-78-53" morph="none" pos="word" start_char="5875">al</TOKEN>
<TOKEN end_char="5882" id="token-78-54" morph="none" pos="word" start_char="5878">grito</TOKEN>
<TOKEN end_char="5885" id="token-78-55" morph="none" pos="word" start_char="5884">de</TOKEN>
<TOKEN end_char="5887" id="token-78-56" morph="none" pos="punct" start_char="5887">"</TOKEN>
<TOKEN end_char="5889" id="token-78-57" morph="none" pos="word" start_char="5888">no</TOKEN>
<TOKEN end_char="5895" id="token-78-58" morph="none" pos="word" start_char="5891">seáis</TOKEN>
<TOKEN end_char="5904" id="token-78-59" morph="none" pos="word" start_char="5897">racistas</TOKEN>
<TOKEN end_char="5906" id="token-78-60" morph="none" pos="punct" start_char="5905">".</TOKEN>
<TRANSLATED_TEXT>In my view, the difference is that at first no one knew anything and was very afraid to express a minimally controversial opinion partly because of political correctness and partly because of possible (mainly economic) reprisals from China, which in fact launched a media offensive in the West to the cry of "don't be racist."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6136" id="segment-79" start_char="5908">
<ORIGINAL_TEXT>Ahora ese miedo a la opinión pública se ha perdido porque la gente ha dejado la corrección política a un lado ante la tragedia y la evidente mentira que nos hemos comido como poco en el conteo de muertos y pide respuestas claras.</ORIGINAL_TEXT>
<TOKEN end_char="5912" id="token-79-0" morph="none" pos="word" start_char="5908">Ahora</TOKEN>
<TOKEN end_char="5916" id="token-79-1" morph="none" pos="word" start_char="5914">ese</TOKEN>
<TOKEN end_char="5922" id="token-79-2" morph="none" pos="word" start_char="5918">miedo</TOKEN>
<TOKEN end_char="5924" id="token-79-3" morph="none" pos="word" start_char="5924">a</TOKEN>
<TOKEN end_char="5927" id="token-79-4" morph="none" pos="word" start_char="5926">la</TOKEN>
<TOKEN end_char="5935" id="token-79-5" morph="none" pos="word" start_char="5929">opinión</TOKEN>
<TOKEN end_char="5943" id="token-79-6" morph="none" pos="word" start_char="5937">pública</TOKEN>
<TOKEN end_char="5946" id="token-79-7" morph="none" pos="word" start_char="5945">se</TOKEN>
<TOKEN end_char="5949" id="token-79-8" morph="none" pos="word" start_char="5948">ha</TOKEN>
<TOKEN end_char="5957" id="token-79-9" morph="none" pos="word" start_char="5951">perdido</TOKEN>
<TOKEN end_char="5964" id="token-79-10" morph="none" pos="word" start_char="5959">porque</TOKEN>
<TOKEN end_char="5967" id="token-79-11" morph="none" pos="word" start_char="5966">la</TOKEN>
<TOKEN end_char="5973" id="token-79-12" morph="none" pos="word" start_char="5969">gente</TOKEN>
<TOKEN end_char="5976" id="token-79-13" morph="none" pos="word" start_char="5975">ha</TOKEN>
<TOKEN end_char="5983" id="token-79-14" morph="none" pos="word" start_char="5978">dejado</TOKEN>
<TOKEN end_char="5986" id="token-79-15" morph="none" pos="word" start_char="5985">la</TOKEN>
<TOKEN end_char="5997" id="token-79-16" morph="none" pos="word" start_char="5988">corrección</TOKEN>
<TOKEN end_char="6006" id="token-79-17" morph="none" pos="word" start_char="5999">política</TOKEN>
<TOKEN end_char="6008" id="token-79-18" morph="none" pos="word" start_char="6008">a</TOKEN>
<TOKEN end_char="6011" id="token-79-19" morph="none" pos="word" start_char="6010">un</TOKEN>
<TOKEN end_char="6016" id="token-79-20" morph="none" pos="word" start_char="6013">lado</TOKEN>
<TOKEN end_char="6021" id="token-79-21" morph="none" pos="word" start_char="6018">ante</TOKEN>
<TOKEN end_char="6024" id="token-79-22" morph="none" pos="word" start_char="6023">la</TOKEN>
<TOKEN end_char="6033" id="token-79-23" morph="none" pos="word" start_char="6026">tragedia</TOKEN>
<TOKEN end_char="6035" id="token-79-24" morph="none" pos="word" start_char="6035">y</TOKEN>
<TOKEN end_char="6038" id="token-79-25" morph="none" pos="word" start_char="6037">la</TOKEN>
<TOKEN end_char="6047" id="token-79-26" morph="none" pos="word" start_char="6040">evidente</TOKEN>
<TOKEN end_char="6055" id="token-79-27" morph="none" pos="word" start_char="6049">mentira</TOKEN>
<TOKEN end_char="6059" id="token-79-28" morph="none" pos="word" start_char="6057">que</TOKEN>
<TOKEN end_char="6063" id="token-79-29" morph="none" pos="word" start_char="6061">nos</TOKEN>
<TOKEN end_char="6069" id="token-79-30" morph="none" pos="word" start_char="6065">hemos</TOKEN>
<TOKEN end_char="6076" id="token-79-31" morph="none" pos="word" start_char="6071">comido</TOKEN>
<TOKEN end_char="6081" id="token-79-32" morph="none" pos="word" start_char="6078">como</TOKEN>
<TOKEN end_char="6086" id="token-79-33" morph="none" pos="word" start_char="6083">poco</TOKEN>
<TOKEN end_char="6089" id="token-79-34" morph="none" pos="word" start_char="6088">en</TOKEN>
<TOKEN end_char="6092" id="token-79-35" morph="none" pos="word" start_char="6091">el</TOKEN>
<TOKEN end_char="6099" id="token-79-36" morph="none" pos="word" start_char="6094">conteo</TOKEN>
<TOKEN end_char="6102" id="token-79-37" morph="none" pos="word" start_char="6101">de</TOKEN>
<TOKEN end_char="6110" id="token-79-38" morph="none" pos="word" start_char="6104">muertos</TOKEN>
<TOKEN end_char="6112" id="token-79-39" morph="none" pos="word" start_char="6112">y</TOKEN>
<TOKEN end_char="6117" id="token-79-40" morph="none" pos="word" start_char="6114">pide</TOKEN>
<TOKEN end_char="6128" id="token-79-41" morph="none" pos="word" start_char="6119">respuestas</TOKEN>
<TOKEN end_char="6135" id="token-79-42" morph="none" pos="word" start_char="6130">claras</TOKEN>
<TOKEN end_char="6136" id="token-79-43" morph="none" pos="punct" start_char="6136">.</TOKEN>
<TRANSLATED_TEXT>Now that fear of public opinion has been lost because people have left political correctness aside in the face of tragedy and the obvious lie that we have eaten little in the count of the dead and are asking for clear answers.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6310" id="segment-80" start_char="6138">
<ORIGINAL_TEXT>Además, cada vez se sabe un poco más del virus, tanto por el paso del tiempo como porque la información ya no viene sesgada desde su origen y pueden estudiarlo directamente.</ORIGINAL_TEXT>
<TOKEN end_char="6143" id="token-80-0" morph="none" pos="word" start_char="6138">Además</TOKEN>
<TOKEN end_char="6144" id="token-80-1" morph="none" pos="punct" start_char="6144">,</TOKEN>
<TOKEN end_char="6149" id="token-80-2" morph="none" pos="word" start_char="6146">cada</TOKEN>
<TOKEN end_char="6153" id="token-80-3" morph="none" pos="word" start_char="6151">vez</TOKEN>
<TOKEN end_char="6156" id="token-80-4" morph="none" pos="word" start_char="6155">se</TOKEN>
<TOKEN end_char="6161" id="token-80-5" morph="none" pos="word" start_char="6158">sabe</TOKEN>
<TOKEN end_char="6164" id="token-80-6" morph="none" pos="word" start_char="6163">un</TOKEN>
<TOKEN end_char="6169" id="token-80-7" morph="none" pos="word" start_char="6166">poco</TOKEN>
<TOKEN end_char="6173" id="token-80-8" morph="none" pos="word" start_char="6171">más</TOKEN>
<TOKEN end_char="6177" id="token-80-9" morph="none" pos="word" start_char="6175">del</TOKEN>
<TOKEN end_char="6183" id="token-80-10" morph="none" pos="word" start_char="6179">virus</TOKEN>
<TOKEN end_char="6184" id="token-80-11" morph="none" pos="punct" start_char="6184">,</TOKEN>
<TOKEN end_char="6190" id="token-80-12" morph="none" pos="word" start_char="6186">tanto</TOKEN>
<TOKEN end_char="6194" id="token-80-13" morph="none" pos="word" start_char="6192">por</TOKEN>
<TOKEN end_char="6197" id="token-80-14" morph="none" pos="word" start_char="6196">el</TOKEN>
<TOKEN end_char="6202" id="token-80-15" morph="none" pos="word" start_char="6199">paso</TOKEN>
<TOKEN end_char="6206" id="token-80-16" morph="none" pos="word" start_char="6204">del</TOKEN>
<TOKEN end_char="6213" id="token-80-17" morph="none" pos="word" start_char="6208">tiempo</TOKEN>
<TOKEN end_char="6218" id="token-80-18" morph="none" pos="word" start_char="6215">como</TOKEN>
<TOKEN end_char="6225" id="token-80-19" morph="none" pos="word" start_char="6220">porque</TOKEN>
<TOKEN end_char="6228" id="token-80-20" morph="none" pos="word" start_char="6227">la</TOKEN>
<TOKEN end_char="6240" id="token-80-21" morph="none" pos="word" start_char="6230">información</TOKEN>
<TOKEN end_char="6243" id="token-80-22" morph="none" pos="word" start_char="6242">ya</TOKEN>
<TOKEN end_char="6246" id="token-80-23" morph="none" pos="word" start_char="6245">no</TOKEN>
<TOKEN end_char="6252" id="token-80-24" morph="none" pos="word" start_char="6248">viene</TOKEN>
<TOKEN end_char="6260" id="token-80-25" morph="none" pos="word" start_char="6254">sesgada</TOKEN>
<TOKEN end_char="6266" id="token-80-26" morph="none" pos="word" start_char="6262">desde</TOKEN>
<TOKEN end_char="6269" id="token-80-27" morph="none" pos="word" start_char="6268">su</TOKEN>
<TOKEN end_char="6276" id="token-80-28" morph="none" pos="word" start_char="6271">origen</TOKEN>
<TOKEN end_char="6278" id="token-80-29" morph="none" pos="word" start_char="6278">y</TOKEN>
<TOKEN end_char="6285" id="token-80-30" morph="none" pos="word" start_char="6280">pueden</TOKEN>
<TOKEN end_char="6296" id="token-80-31" morph="none" pos="word" start_char="6287">estudiarlo</TOKEN>
<TOKEN end_char="6309" id="token-80-32" morph="none" pos="word" start_char="6298">directamente</TOKEN>
<TOKEN end_char="6310" id="token-80-33" morph="none" pos="punct" start_char="6310">.</TOKEN>
<TRANSLATED_TEXT>In addition, a little more is known about the virus, both over time and because the information no longer comes from its origin and can be studied directly.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6320" id="segment-81" start_char="6316">
<ORIGINAL_TEXT>Cita:</ORIGINAL_TEXT>
<TOKEN end_char="6319" id="token-81-0" morph="none" pos="word" start_char="6316">Cita</TOKEN>
<TOKEN end_char="6320" id="token-81-1" morph="none" pos="punct" start_char="6320">:</TOKEN>
<TRANSLATED_TEXT>Other:</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="6400" id="segment-82" start_char="6325">
<ORIGINAL_TEXT>Originalmente Escrito por zirick Lo fácil era cargar la culpa a un pangolin.</ORIGINAL_TEXT>
<TOKEN end_char="6337" id="token-82-0" morph="none" pos="word" start_char="6325">Originalmente</TOKEN>
<TOKEN end_char="6345" id="token-82-1" morph="none" pos="word" start_char="6339">Escrito</TOKEN>
<TOKEN end_char="6349" id="token-82-2" morph="none" pos="word" start_char="6347">por</TOKEN>
<TOKEN end_char="6356" id="token-82-3" morph="none" pos="word" start_char="6351">zirick</TOKEN>
<TOKEN end_char="6359" id="token-82-4" morph="none" pos="word" start_char="6358">Lo</TOKEN>
<TOKEN end_char="6365" id="token-82-5" morph="none" pos="word" start_char="6361">fácil</TOKEN>
<TOKEN end_char="6369" id="token-82-6" morph="none" pos="word" start_char="6367">era</TOKEN>
<TOKEN end_char="6376" id="token-82-7" morph="none" pos="word" start_char="6371">cargar</TOKEN>
<TOKEN end_char="6379" id="token-82-8" morph="none" pos="word" start_char="6378">la</TOKEN>
<TOKEN end_char="6385" id="token-82-9" morph="none" pos="word" start_char="6381">culpa</TOKEN>
<TOKEN end_char="6387" id="token-82-10" morph="none" pos="word" start_char="6387">a</TOKEN>
<TOKEN end_char="6390" id="token-82-11" morph="none" pos="word" start_char="6389">un</TOKEN>
<TOKEN end_char="6399" id="token-82-12" morph="none" pos="word" start_char="6392">pangolin</TOKEN>
<TOKEN end_char="6400" id="token-82-13" morph="none" pos="punct" start_char="6400">.</TOKEN>
<TRANSLATED_TEXT>Originally written by zirick The easy thing was to charge a pangolin.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6453" id="segment-83" start_char="6402">
<ORIGINAL_TEXT>Pero no coló Perdon por haber sospechado de ti, bebé</ORIGINAL_TEXT>
<TOKEN end_char="6405" id="token-83-0" morph="none" pos="word" start_char="6402">Pero</TOKEN>
<TOKEN end_char="6408" id="token-83-1" morph="none" pos="word" start_char="6407">no</TOKEN>
<TOKEN end_char="6413" id="token-83-2" morph="none" pos="word" start_char="6410">coló</TOKEN>
<TOKEN end_char="6420" id="token-83-3" morph="none" pos="word" start_char="6415">Perdon</TOKEN>
<TOKEN end_char="6424" id="token-83-4" morph="none" pos="word" start_char="6422">por</TOKEN>
<TOKEN end_char="6430" id="token-83-5" morph="none" pos="word" start_char="6426">haber</TOKEN>
<TOKEN end_char="6441" id="token-83-6" morph="none" pos="word" start_char="6432">sospechado</TOKEN>
<TOKEN end_char="6444" id="token-83-7" morph="none" pos="word" start_char="6443">de</TOKEN>
<TOKEN end_char="6447" id="token-83-8" morph="none" pos="word" start_char="6446">ti</TOKEN>
<TOKEN end_char="6448" id="token-83-9" morph="none" pos="punct" start_char="6448">,</TOKEN>
<TOKEN end_char="6453" id="token-83-10" morph="none" pos="word" start_char="6450">bebé</TOKEN>
<TRANSLATED_TEXT>I'm sorry I suspected you, baby.</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="6587" id="segment-84" start_char="6459">
<ORIGINAL_TEXT>De todas las ciudades que hay en el mundo resulta que el virus aparece en una ciudad china donde hay un laboratorio de virología.</ORIGINAL_TEXT>
<TOKEN end_char="6460" id="token-84-0" morph="none" pos="word" start_char="6459">De</TOKEN>
<TOKEN end_char="6466" id="token-84-1" morph="none" pos="word" start_char="6462">todas</TOKEN>
<TOKEN end_char="6470" id="token-84-2" morph="none" pos="word" start_char="6468">las</TOKEN>
<TOKEN end_char="6479" id="token-84-3" morph="none" pos="word" start_char="6472">ciudades</TOKEN>
<TOKEN end_char="6483" id="token-84-4" morph="none" pos="word" start_char="6481">que</TOKEN>
<TOKEN end_char="6487" id="token-84-5" morph="none" pos="word" start_char="6485">hay</TOKEN>
<TOKEN end_char="6490" id="token-84-6" morph="none" pos="word" start_char="6489">en</TOKEN>
<TOKEN end_char="6493" id="token-84-7" morph="none" pos="word" start_char="6492">el</TOKEN>
<TOKEN end_char="6499" id="token-84-8" morph="none" pos="word" start_char="6495">mundo</TOKEN>
<TOKEN end_char="6507" id="token-84-9" morph="none" pos="word" start_char="6501">resulta</TOKEN>
<TOKEN end_char="6511" id="token-84-10" morph="none" pos="word" start_char="6509">que</TOKEN>
<TOKEN end_char="6514" id="token-84-11" morph="none" pos="word" start_char="6513">el</TOKEN>
<TOKEN end_char="6520" id="token-84-12" morph="none" pos="word" start_char="6516">virus</TOKEN>
<TOKEN end_char="6528" id="token-84-13" morph="none" pos="word" start_char="6522">aparece</TOKEN>
<TOKEN end_char="6531" id="token-84-14" morph="none" pos="word" start_char="6530">en</TOKEN>
<TOKEN end_char="6535" id="token-84-15" morph="none" pos="word" start_char="6533">una</TOKEN>
<TOKEN end_char="6542" id="token-84-16" morph="none" pos="word" start_char="6537">ciudad</TOKEN>
<TOKEN end_char="6548" id="token-84-17" morph="none" pos="word" start_char="6544">china</TOKEN>
<TOKEN end_char="6554" id="token-84-18" morph="none" pos="word" start_char="6550">donde</TOKEN>
<TOKEN end_char="6558" id="token-84-19" morph="none" pos="word" start_char="6556">hay</TOKEN>
<TOKEN end_char="6561" id="token-84-20" morph="none" pos="word" start_char="6560">un</TOKEN>
<TOKEN end_char="6573" id="token-84-21" morph="none" pos="word" start_char="6563">laboratorio</TOKEN>
<TOKEN end_char="6576" id="token-84-22" morph="none" pos="word" start_char="6575">de</TOKEN>
<TOKEN end_char="6586" id="token-84-23" morph="none" pos="word" start_char="6578">virología</TOKEN>
<TOKEN end_char="6587" id="token-84-24" morph="none" pos="punct" start_char="6587">.</TOKEN>
<TRANSLATED_TEXT>From every city in the world, it turns out that the virus appears in a Chinese city where there 's a virology lab.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6657" id="segment-85" start_char="6589">
<ORIGINAL_TEXT>Un laboratorio que había tenido quejas por su seguridad en el pasado.</ORIGINAL_TEXT>
<TOKEN end_char="6590" id="token-85-0" morph="none" pos="word" start_char="6589">Un</TOKEN>
<TOKEN end_char="6602" id="token-85-1" morph="none" pos="word" start_char="6592">laboratorio</TOKEN>
<TOKEN end_char="6606" id="token-85-2" morph="none" pos="word" start_char="6604">que</TOKEN>
<TOKEN end_char="6612" id="token-85-3" morph="none" pos="word" start_char="6608">había</TOKEN>
<TOKEN end_char="6619" id="token-85-4" morph="none" pos="word" start_char="6614">tenido</TOKEN>
<TOKEN end_char="6626" id="token-85-5" morph="none" pos="word" start_char="6621">quejas</TOKEN>
<TOKEN end_char="6630" id="token-85-6" morph="none" pos="word" start_char="6628">por</TOKEN>
<TOKEN end_char="6633" id="token-85-7" morph="none" pos="word" start_char="6632">su</TOKEN>
<TOKEN end_char="6643" id="token-85-8" morph="none" pos="word" start_char="6635">seguridad</TOKEN>
<TOKEN end_char="6646" id="token-85-9" morph="none" pos="word" start_char="6645">en</TOKEN>
<TOKEN end_char="6649" id="token-85-10" morph="none" pos="word" start_char="6648">el</TOKEN>
<TOKEN end_char="6656" id="token-85-11" morph="none" pos="word" start_char="6651">pasado</TOKEN>
<TOKEN end_char="6657" id="token-85-12" morph="none" pos="punct" start_char="6657">.</TOKEN>
<TRANSLATED_TEXT>A lab that had had complaints about its safety in the past.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6780" id="segment-86" start_char="6659">
<ORIGINAL_TEXT>Pero lo que me hace pensar que se les ha escapado es sobretodo que se pusieron a construir hospitales desde el minuto uno.</ORIGINAL_TEXT>
<TOKEN end_char="6662" id="token-86-0" morph="none" pos="word" start_char="6659">Pero</TOKEN>
<TOKEN end_char="6665" id="token-86-1" morph="none" pos="word" start_char="6664">lo</TOKEN>
<TOKEN end_char="6669" id="token-86-2" morph="none" pos="word" start_char="6667">que</TOKEN>
<TOKEN end_char="6672" id="token-86-3" morph="none" pos="word" start_char="6671">me</TOKEN>
<TOKEN end_char="6677" id="token-86-4" morph="none" pos="word" start_char="6674">hace</TOKEN>
<TOKEN end_char="6684" id="token-86-5" morph="none" pos="word" start_char="6679">pensar</TOKEN>
<TOKEN end_char="6688" id="token-86-6" morph="none" pos="word" start_char="6686">que</TOKEN>
<TOKEN end_char="6691" id="token-86-7" morph="none" pos="word" start_char="6690">se</TOKEN>
<TOKEN end_char="6695" id="token-86-8" morph="none" pos="word" start_char="6693">les</TOKEN>
<TOKEN end_char="6698" id="token-86-9" morph="none" pos="word" start_char="6697">ha</TOKEN>
<TOKEN end_char="6707" id="token-86-10" morph="none" pos="word" start_char="6700">escapado</TOKEN>
<TOKEN end_char="6710" id="token-86-11" morph="none" pos="word" start_char="6709">es</TOKEN>
<TOKEN end_char="6720" id="token-86-12" morph="none" pos="word" start_char="6712">sobretodo</TOKEN>
<TOKEN end_char="6724" id="token-86-13" morph="none" pos="word" start_char="6722">que</TOKEN>
<TOKEN end_char="6727" id="token-86-14" morph="none" pos="word" start_char="6726">se</TOKEN>
<TOKEN end_char="6736" id="token-86-15" morph="none" pos="word" start_char="6729">pusieron</TOKEN>
<TOKEN end_char="6738" id="token-86-16" morph="none" pos="word" start_char="6738">a</TOKEN>
<TOKEN end_char="6748" id="token-86-17" morph="none" pos="word" start_char="6740">construir</TOKEN>
<TOKEN end_char="6759" id="token-86-18" morph="none" pos="word" start_char="6750">hospitales</TOKEN>
<TOKEN end_char="6765" id="token-86-19" morph="none" pos="word" start_char="6761">desde</TOKEN>
<TOKEN end_char="6768" id="token-86-20" morph="none" pos="word" start_char="6767">el</TOKEN>
<TOKEN end_char="6775" id="token-86-21" morph="none" pos="word" start_char="6770">minuto</TOKEN>
<TOKEN end_char="6779" id="token-86-22" morph="none" pos="word" start_char="6777">uno</TOKEN>
<TOKEN end_char="6780" id="token-86-23" morph="none" pos="punct" start_char="6780">.</TOKEN>
<TRANSLATED_TEXT>But what makes me think they got away with it is mostly that they started building hospitals in minute one.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6941" id="segment-87" start_char="6782">
<ORIGINAL_TEXT>Coño, eso no lo haces hasta analizar bien la letalidad y la tasa de contagio del virus porque desconoces su gravedad; lo que ha pasado en occidente básicamente.</ORIGINAL_TEXT>
<TOKEN end_char="6785" id="token-87-0" morph="none" pos="word" start_char="6782">Coño</TOKEN>
<TOKEN end_char="6786" id="token-87-1" morph="none" pos="punct" start_char="6786">,</TOKEN>
<TOKEN end_char="6790" id="token-87-2" morph="none" pos="word" start_char="6788">eso</TOKEN>
<TOKEN end_char="6793" id="token-87-3" morph="none" pos="word" start_char="6792">no</TOKEN>
<TOKEN end_char="6796" id="token-87-4" morph="none" pos="word" start_char="6795">lo</TOKEN>
<TOKEN end_char="6802" id="token-87-5" morph="none" pos="word" start_char="6798">haces</TOKEN>
<TOKEN end_char="6808" id="token-87-6" morph="none" pos="word" start_char="6804">hasta</TOKEN>
<TOKEN end_char="6817" id="token-87-7" morph="none" pos="word" start_char="6810">analizar</TOKEN>
<TOKEN end_char="6822" id="token-87-8" morph="none" pos="word" start_char="6819">bien</TOKEN>
<TOKEN end_char="6825" id="token-87-9" morph="none" pos="word" start_char="6824">la</TOKEN>
<TOKEN end_char="6835" id="token-87-10" morph="none" pos="word" start_char="6827">letalidad</TOKEN>
<TOKEN end_char="6837" id="token-87-11" morph="none" pos="word" start_char="6837">y</TOKEN>
<TOKEN end_char="6840" id="token-87-12" morph="none" pos="word" start_char="6839">la</TOKEN>
<TOKEN end_char="6845" id="token-87-13" morph="none" pos="word" start_char="6842">tasa</TOKEN>
<TOKEN end_char="6848" id="token-87-14" morph="none" pos="word" start_char="6847">de</TOKEN>
<TOKEN end_char="6857" id="token-87-15" morph="none" pos="word" start_char="6850">contagio</TOKEN>
<TOKEN end_char="6861" id="token-87-16" morph="none" pos="word" start_char="6859">del</TOKEN>
<TOKEN end_char="6867" id="token-87-17" morph="none" pos="word" start_char="6863">virus</TOKEN>
<TOKEN end_char="6874" id="token-87-18" morph="none" pos="word" start_char="6869">porque</TOKEN>
<TOKEN end_char="6885" id="token-87-19" morph="none" pos="word" start_char="6876">desconoces</TOKEN>
<TOKEN end_char="6888" id="token-87-20" morph="none" pos="word" start_char="6887">su</TOKEN>
<TOKEN end_char="6897" id="token-87-21" morph="none" pos="word" start_char="6890">gravedad</TOKEN>
<TOKEN end_char="6898" id="token-87-22" morph="none" pos="punct" start_char="6898">;</TOKEN>
<TOKEN end_char="6901" id="token-87-23" morph="none" pos="word" start_char="6900">lo</TOKEN>
<TOKEN end_char="6905" id="token-87-24" morph="none" pos="word" start_char="6903">que</TOKEN>
<TOKEN end_char="6908" id="token-87-25" morph="none" pos="word" start_char="6907">ha</TOKEN>
<TOKEN end_char="6915" id="token-87-26" morph="none" pos="word" start_char="6910">pasado</TOKEN>
<TOKEN end_char="6918" id="token-87-27" morph="none" pos="word" start_char="6917">en</TOKEN>
<TOKEN end_char="6928" id="token-87-28" morph="none" pos="word" start_char="6920">occidente</TOKEN>
<TOKEN end_char="6940" id="token-87-29" morph="none" pos="word" start_char="6930">básicamente</TOKEN>
<TOKEN end_char="6941" id="token-87-30" morph="none" pos="punct" start_char="6941">.</TOKEN>
<TRANSLATED_TEXT>I mean, you don 't do that until you get a good look at the lethality and rate of infection of the virus, because you don' t know its gravity; what 's happened in the West basically.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7030" id="segment-88" start_char="6943">
<ORIGINAL_TEXT>A no ser que lo supieses desde el primer momento.... porque lo tenías más que analizado.</ORIGINAL_TEXT>
<TOKEN end_char="6943" id="token-88-0" morph="none" pos="word" start_char="6943">A</TOKEN>
<TOKEN end_char="6946" id="token-88-1" morph="none" pos="word" start_char="6945">no</TOKEN>
<TOKEN end_char="6950" id="token-88-2" morph="none" pos="word" start_char="6948">ser</TOKEN>
<TOKEN end_char="6954" id="token-88-3" morph="none" pos="word" start_char="6952">que</TOKEN>
<TOKEN end_char="6957" id="token-88-4" morph="none" pos="word" start_char="6956">lo</TOKEN>
<TOKEN end_char="6966" id="token-88-5" morph="none" pos="word" start_char="6959">supieses</TOKEN>
<TOKEN end_char="6972" id="token-88-6" morph="none" pos="word" start_char="6968">desde</TOKEN>
<TOKEN end_char="6975" id="token-88-7" morph="none" pos="word" start_char="6974">el</TOKEN>
<TOKEN end_char="6982" id="token-88-8" morph="none" pos="word" start_char="6977">primer</TOKEN>
<TOKEN end_char="6990" id="token-88-9" morph="none" pos="word" start_char="6984">momento</TOKEN>
<TOKEN end_char="6994" id="token-88-10" morph="none" pos="punct" start_char="6991">....</TOKEN>
<TOKEN end_char="7001" id="token-88-11" morph="none" pos="word" start_char="6996">porque</TOKEN>
<TOKEN end_char="7004" id="token-88-12" morph="none" pos="word" start_char="7003">lo</TOKEN>
<TOKEN end_char="7011" id="token-88-13" morph="none" pos="word" start_char="7006">tenías</TOKEN>
<TOKEN end_char="7015" id="token-88-14" morph="none" pos="word" start_char="7013">más</TOKEN>
<TOKEN end_char="7019" id="token-88-15" morph="none" pos="word" start_char="7017">que</TOKEN>
<TOKEN end_char="7029" id="token-88-16" morph="none" pos="word" start_char="7021">analizado</TOKEN>
<TOKEN end_char="7030" id="token-88-17" morph="none" pos="punct" start_char="7030">.</TOKEN>
<TRANSLATED_TEXT>Unless you knew it from the very beginning... because you had it more than analyzed.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7062" id="segment-89" start_char="7032">
<ORIGINAL_TEXT>Vamos, que blanco y en botella.</ORIGINAL_TEXT>
<TOKEN end_char="7036" id="token-89-0" morph="none" pos="word" start_char="7032">Vamos</TOKEN>
<TOKEN end_char="7037" id="token-89-1" morph="none" pos="punct" start_char="7037">,</TOKEN>
<TOKEN end_char="7041" id="token-89-2" morph="none" pos="word" start_char="7039">que</TOKEN>
<TOKEN end_char="7048" id="token-89-3" morph="none" pos="word" start_char="7043">blanco</TOKEN>
<TOKEN end_char="7050" id="token-89-4" morph="none" pos="word" start_char="7050">y</TOKEN>
<TOKEN end_char="7053" id="token-89-5" morph="none" pos="word" start_char="7052">en</TOKEN>
<TOKEN end_char="7061" id="token-89-6" morph="none" pos="word" start_char="7055">botella</TOKEN>
<TOKEN end_char="7062" id="token-89-7" morph="none" pos="punct" start_char="7062">.</TOKEN>
<TRANSLATED_TEXT>Come on, white and in the bottle.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7120" id="segment-90" start_char="7068">
<ORIGINAL_TEXT>Montagnier lleva ya muchos años diciendo gilipolleces</ORIGINAL_TEXT>
<TOKEN end_char="7077" id="token-90-0" morph="none" pos="word" start_char="7068">Montagnier</TOKEN>
<TOKEN end_char="7083" id="token-90-1" morph="none" pos="word" start_char="7079">lleva</TOKEN>
<TOKEN end_char="7086" id="token-90-2" morph="none" pos="word" start_char="7085">ya</TOKEN>
<TOKEN end_char="7093" id="token-90-3" morph="none" pos="word" start_char="7088">muchos</TOKEN>
<TOKEN end_char="7098" id="token-90-4" morph="none" pos="word" start_char="7095">años</TOKEN>
<TOKEN end_char="7107" id="token-90-5" morph="none" pos="word" start_char="7100">diciendo</TOKEN>
<TOKEN end_char="7120" id="token-90-6" morph="none" pos="word" start_char="7109">gilipolleces</TOKEN>
<TRANSLATED_TEXT>Montagnier's been saying shit for years.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7139" id="segment-91" start_char="7126">
<ORIGINAL_TEXT>Foropangolines</ORIGINAL_TEXT>
<TOKEN end_char="7139" id="token-91-0" morph="none" pos="word" start_char="7126">Foropangolines</TOKEN>
<TRANSLATED_TEXT>Foropangolinas</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="7200" id="segment-92" start_char="7145">
<ORIGINAL_TEXT>si se descubre que asi es, hay que aniquilar al creador.</ORIGINAL_TEXT>
<TOKEN end_char="7146" id="token-92-0" morph="none" pos="word" start_char="7145">si</TOKEN>
<TOKEN end_char="7149" id="token-92-1" morph="none" pos="word" start_char="7148">se</TOKEN>
<TOKEN end_char="7158" id="token-92-2" morph="none" pos="word" start_char="7151">descubre</TOKEN>
<TOKEN end_char="7162" id="token-92-3" morph="none" pos="word" start_char="7160">que</TOKEN>
<TOKEN end_char="7166" id="token-92-4" morph="none" pos="word" start_char="7164">asi</TOKEN>
<TOKEN end_char="7169" id="token-92-5" morph="none" pos="word" start_char="7168">es</TOKEN>
<TOKEN end_char="7170" id="token-92-6" morph="none" pos="punct" start_char="7170">,</TOKEN>
<TOKEN end_char="7174" id="token-92-7" morph="none" pos="word" start_char="7172">hay</TOKEN>
<TOKEN end_char="7178" id="token-92-8" morph="none" pos="word" start_char="7176">que</TOKEN>
<TOKEN end_char="7188" id="token-92-9" morph="none" pos="word" start_char="7180">aniquilar</TOKEN>
<TOKEN end_char="7191" id="token-92-10" morph="none" pos="word" start_char="7190">al</TOKEN>
<TOKEN end_char="7199" id="token-92-11" morph="none" pos="word" start_char="7193">creador</TOKEN>
<TOKEN end_char="7200" id="token-92-12" morph="none" pos="punct" start_char="7200">.</TOKEN>
<TRANSLATED_TEXT>If it is discovered, the creator must be annihilated.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="7254" id="segment-93" start_char="7206">
<ORIGINAL_TEXT>Este no es también el que defendia la homeopatia?</ORIGINAL_TEXT>
<TOKEN end_char="7209" id="token-93-0" morph="none" pos="word" start_char="7206">Este</TOKEN>
<TOKEN end_char="7212" id="token-93-1" morph="none" pos="word" start_char="7211">no</TOKEN>
<TOKEN end_char="7215" id="token-93-2" morph="none" pos="word" start_char="7214">es</TOKEN>
<TOKEN end_char="7223" id="token-93-3" morph="none" pos="word" start_char="7217">también</TOKEN>
<TOKEN end_char="7226" id="token-93-4" morph="none" pos="word" start_char="7225">el</TOKEN>
<TOKEN end_char="7230" id="token-93-5" morph="none" pos="word" start_char="7228">que</TOKEN>
<TOKEN end_char="7239" id="token-93-6" morph="none" pos="word" start_char="7232">defendia</TOKEN>
<TOKEN end_char="7242" id="token-93-7" morph="none" pos="word" start_char="7241">la</TOKEN>
<TOKEN end_char="7253" id="token-93-8" morph="none" pos="word" start_char="7244">homeopatia</TOKEN>
<TOKEN end_char="7254" id="token-93-9" morph="none" pos="punct" start_char="7254">?</TOKEN>
<TRANSLATED_TEXT>Isn't this also the one that defended homeopathy?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7266" id="segment-94" start_char="7260">
<ORIGINAL_TEXT>Y esto?</ORIGINAL_TEXT>
<TOKEN end_char="7260" id="token-94-0" morph="none" pos="word" start_char="7260">Y</TOKEN>
<TOKEN end_char="7265" id="token-94-1" morph="none" pos="word" start_char="7262">esto</TOKEN>
<TOKEN end_char="7266" id="token-94-2" morph="none" pos="punct" start_char="7266">?</TOKEN>
<TRANSLATED_TEXT>And this?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7357" id="segment-95" start_char="7268">
<ORIGINAL_TEXT>Jaaaaaaaaaaaaaaaaaaaaaaaaaa El premio nobel Luc Montagnier se toma la homeopatía en serio.</ORIGINAL_TEXT>
<TOKEN end_char="7294" id="token-95-0" morph="none" pos="word" start_char="7268">Jaaaaaaaaaaaaaaaaaaaaaaaaaa</TOKEN>
<TOKEN end_char="7297" id="token-95-1" morph="none" pos="word" start_char="7296">El</TOKEN>
<TOKEN end_char="7304" id="token-95-2" morph="none" pos="word" start_char="7299">premio</TOKEN>
<TOKEN end_char="7310" id="token-95-3" morph="none" pos="word" start_char="7306">nobel</TOKEN>
<TOKEN end_char="7314" id="token-95-4" morph="none" pos="word" start_char="7312">Luc</TOKEN>
<TOKEN end_char="7325" id="token-95-5" morph="none" pos="word" start_char="7316">Montagnier</TOKEN>
<TOKEN end_char="7328" id="token-95-6" morph="none" pos="word" start_char="7327">se</TOKEN>
<TOKEN end_char="7333" id="token-95-7" morph="none" pos="word" start_char="7330">toma</TOKEN>
<TOKEN end_char="7336" id="token-95-8" morph="none" pos="word" start_char="7335">la</TOKEN>
<TOKEN end_char="7347" id="token-95-9" morph="none" pos="word" start_char="7338">homeopatía</TOKEN>
<TOKEN end_char="7350" id="token-95-10" morph="none" pos="word" start_char="7349">en</TOKEN>
<TOKEN end_char="7356" id="token-95-11" morph="none" pos="word" start_char="7352">serio</TOKEN>
<TOKEN end_char="7357" id="token-95-12" morph="none" pos="punct" start_char="7357">.</TOKEN>
<TRANSLATED_TEXT>The Nobel Prize laureate Luc Montagnier takes homeopathy seriously.</TRANSLATED_TEXT><DETECTED_LANGUAGE>so</DETECTED_LANGUAGE></SEG>
<SEG end_char="7585" id="segment-96" start_char="7359">
<ORIGINAL_TEXT>https://www.elsevier.es/es-revista-r...88852611700947 El Nobel Luc Montagnier:"La base científica de la homeopatía se ignora porque se silencia lo que molesta a la economía" https://www.google.es/amp/s/amp.20mi...esta-economia/</ORIGINAL_TEXT>
<TOKEN end_char="7411" id="token-96-0" morph="none" pos="url" start_char="7359">https://www.elsevier.es/es-revista-r...88852611700947</TOKEN>
<TOKEN end_char="7414" id="token-96-1" morph="none" pos="word" start_char="7413">El</TOKEN>
<TOKEN end_char="7420" id="token-96-2" morph="none" pos="word" start_char="7416">Nobel</TOKEN>
<TOKEN end_char="7424" id="token-96-3" morph="none" pos="word" start_char="7422">Luc</TOKEN>
<TOKEN end_char="7439" id="token-96-4" morph="none" pos="unknown" start_char="7426">Montagnier:"La</TOKEN>
<TOKEN end_char="7444" id="token-96-5" morph="none" pos="word" start_char="7441">base</TOKEN>
<TOKEN end_char="7455" id="token-96-6" morph="none" pos="word" start_char="7446">científica</TOKEN>
<TOKEN end_char="7458" id="token-96-7" morph="none" pos="word" start_char="7457">de</TOKEN>
<TOKEN end_char="7461" id="token-96-8" morph="none" pos="word" start_char="7460">la</TOKEN>
<TOKEN end_char="7472" id="token-96-9" morph="none" pos="word" start_char="7463">homeopatía</TOKEN>
<TOKEN end_char="7475" id="token-96-10" morph="none" pos="word" start_char="7474">se</TOKEN>
<TOKEN end_char="7482" id="token-96-11" morph="none" pos="word" start_char="7477">ignora</TOKEN>
<TOKEN end_char="7489" id="token-96-12" morph="none" pos="word" start_char="7484">porque</TOKEN>
<TOKEN end_char="7492" id="token-96-13" morph="none" pos="word" start_char="7491">se</TOKEN>
<TOKEN end_char="7501" id="token-96-14" morph="none" pos="word" start_char="7494">silencia</TOKEN>
<TOKEN end_char="7504" id="token-96-15" morph="none" pos="word" start_char="7503">lo</TOKEN>
<TOKEN end_char="7508" id="token-96-16" morph="none" pos="word" start_char="7506">que</TOKEN>
<TOKEN end_char="7516" id="token-96-17" morph="none" pos="word" start_char="7510">molesta</TOKEN>
<TOKEN end_char="7518" id="token-96-18" morph="none" pos="word" start_char="7518">a</TOKEN>
<TOKEN end_char="7521" id="token-96-19" morph="none" pos="word" start_char="7520">la</TOKEN>
<TOKEN end_char="7530" id="token-96-20" morph="none" pos="word" start_char="7523">economía</TOKEN>
<TOKEN end_char="7531" id="token-96-21" morph="none" pos="punct" start_char="7531">"</TOKEN>
<TOKEN end_char="7585" id="token-96-22" morph="none" pos="url" start_char="7533">https://www.google.es/amp/s/amp.20mi...esta-economia/</TOKEN>
<TRANSLATED_TEXT>https: / / www.elsevier.es / es-revista-r... 88852611700947 Nobel Luc Montagnier: "The scientific basis of homeopathy is ignored because it silences what disturbs the economy" https: / / www.googlees / amp / s / amp.20mi... this-economy /</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7637" id="segment-97" start_char="7592">
<ORIGINAL_TEXT>Instagram Embed (@forocoches) Recarga para ver</ORIGINAL_TEXT>
<TOKEN end_char="7600" id="token-97-0" morph="none" pos="word" start_char="7592">Instagram</TOKEN>
<TOKEN end_char="7606" id="token-97-1" morph="none" pos="word" start_char="7602">Embed</TOKEN>
<TOKEN end_char="7609" id="token-97-2" morph="none" pos="punct" start_char="7608">(@</TOKEN>
<TOKEN end_char="7619" id="token-97-3" morph="none" pos="word" start_char="7610">forocoches</TOKEN>
<TOKEN end_char="7620" id="token-97-4" morph="none" pos="punct" start_char="7620">)</TOKEN>
<TOKEN end_char="7628" id="token-97-5" morph="none" pos="word" start_char="7622">Recarga</TOKEN>
<TOKEN end_char="7633" id="token-97-6" morph="none" pos="word" start_char="7630">para</TOKEN>
<TOKEN end_char="7637" id="token-97-7" morph="none" pos="word" start_char="7635">ver</TOKEN>
</SEG>
<SEG end_char="7670" id="segment-98" start_char="7640">
<ORIGINAL_TEXT>Dejaros de conspiraciones anda.</ORIGINAL_TEXT>
<TOKEN end_char="7646" id="token-98-0" morph="none" pos="word" start_char="7640">Dejaros</TOKEN>
<TOKEN end_char="7649" id="token-98-1" morph="none" pos="word" start_char="7648">de</TOKEN>
<TOKEN end_char="7664" id="token-98-2" morph="none" pos="word" start_char="7651">conspiraciones</TOKEN>
<TOKEN end_char="7669" id="token-98-3" morph="none" pos="word" start_char="7666">anda</TOKEN>
<TOKEN end_char="7670" id="token-98-4" morph="none" pos="punct" start_char="7670">.</TOKEN>
<TRANSLATED_TEXT>Leave conspiracy behind.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7773" id="segment-99" start_char="7672">
<ORIGINAL_TEXT>La comunidad científica es clara respecto a esto Ese hombre esta ya chocheando por mucho nobel que sea</ORIGINAL_TEXT>
<TOKEN end_char="7673" id="token-99-0" morph="none" pos="word" start_char="7672">La</TOKEN>
<TOKEN end_char="7683" id="token-99-1" morph="none" pos="word" start_char="7675">comunidad</TOKEN>
<TOKEN end_char="7694" id="token-99-2" morph="none" pos="word" start_char="7685">científica</TOKEN>
<TOKEN end_char="7697" id="token-99-3" morph="none" pos="word" start_char="7696">es</TOKEN>
<TOKEN end_char="7703" id="token-99-4" morph="none" pos="word" start_char="7699">clara</TOKEN>
<TOKEN end_char="7712" id="token-99-5" morph="none" pos="word" start_char="7705">respecto</TOKEN>
<TOKEN end_char="7714" id="token-99-6" morph="none" pos="word" start_char="7714">a</TOKEN>
<TOKEN end_char="7719" id="token-99-7" morph="none" pos="word" start_char="7716">esto</TOKEN>
<TOKEN end_char="7723" id="token-99-8" morph="none" pos="word" start_char="7721">Ese</TOKEN>
<TOKEN end_char="7730" id="token-99-9" morph="none" pos="word" start_char="7725">hombre</TOKEN>
<TOKEN end_char="7735" id="token-99-10" morph="none" pos="word" start_char="7732">esta</TOKEN>
<TOKEN end_char="7738" id="token-99-11" morph="none" pos="word" start_char="7737">ya</TOKEN>
<TOKEN end_char="7749" id="token-99-12" morph="none" pos="word" start_char="7740">chocheando</TOKEN>
<TOKEN end_char="7753" id="token-99-13" morph="none" pos="word" start_char="7751">por</TOKEN>
<TOKEN end_char="7759" id="token-99-14" morph="none" pos="word" start_char="7755">mucho</TOKEN>
<TOKEN end_char="7765" id="token-99-15" morph="none" pos="word" start_char="7761">nobel</TOKEN>
<TOKEN end_char="7769" id="token-99-16" morph="none" pos="word" start_char="7767">que</TOKEN>
<TOKEN end_char="7773" id="token-99-17" morph="none" pos="word" start_char="7771">sea</TOKEN>
<TRANSLATED_TEXT>The scientific community is clear about this. That man is already poking around for a lot of fiction.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
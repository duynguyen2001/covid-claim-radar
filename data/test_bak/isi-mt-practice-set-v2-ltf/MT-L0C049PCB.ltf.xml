<LCTL_TEXT lang="ukr">
<DOC grammar="none" id="L0C049PCB" lang="ukr" raw_text_char_length="13709" raw_text_md5="b2c129ede33b0de828b98af0360c64c5" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="68" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Baseless Conspiracy Theories Claim New Coronavirus Was Bioengineered</ORIGINAL_TEXT>
<TOKEN end_char="8" id="token-0-0" morph="none" pos="word" start_char="1">Baseless</TOKEN>
<TOKEN end_char="19" id="token-0-1" morph="none" pos="word" start_char="10">Conspiracy</TOKEN>
<TOKEN end_char="28" id="token-0-2" morph="none" pos="word" start_char="21">Theories</TOKEN>
<TOKEN end_char="34" id="token-0-3" morph="none" pos="word" start_char="30">Claim</TOKEN>
<TOKEN end_char="38" id="token-0-4" morph="none" pos="word" start_char="36">New</TOKEN>
<TOKEN end_char="50" id="token-0-5" morph="none" pos="word" start_char="40">Coronavirus</TOKEN>
<TOKEN end_char="54" id="token-0-6" morph="none" pos="word" start_char="52">Was</TOKEN>
<TOKEN end_char="68" id="token-0-7" morph="none" pos="word" start_char="56">Bioengineered</TOKEN>
</SEG>
<SEG end_char="81" id="segment-1" start_char="72">
<ORIGINAL_TEXT>Quick Take</ORIGINAL_TEXT>
<TOKEN end_char="76" id="token-1-0" morph="none" pos="word" start_char="72">Quick</TOKEN>
<TOKEN end_char="81" id="token-1-1" morph="none" pos="word" start_char="78">Take</TOKEN>
</SEG>
<SEG end_char="219" id="segment-2" start_char="85">
<ORIGINAL_TEXT>Several online stories inaccurately claim that the new coronavirus contains HIV "insertions" and shows signs of being created in a lab.</ORIGINAL_TEXT>
<TOKEN end_char="91" id="token-2-0" morph="none" pos="word" start_char="85">Several</TOKEN>
<TOKEN end_char="98" id="token-2-1" morph="none" pos="word" start_char="93">online</TOKEN>
<TOKEN end_char="106" id="token-2-2" morph="none" pos="word" start_char="100">stories</TOKEN>
<TOKEN end_char="119" id="token-2-3" morph="none" pos="word" start_char="108">inaccurately</TOKEN>
<TOKEN end_char="125" id="token-2-4" morph="none" pos="word" start_char="121">claim</TOKEN>
<TOKEN end_char="130" id="token-2-5" morph="none" pos="word" start_char="127">that</TOKEN>
<TOKEN end_char="134" id="token-2-6" morph="none" pos="word" start_char="132">the</TOKEN>
<TOKEN end_char="138" id="token-2-7" morph="none" pos="word" start_char="136">new</TOKEN>
<TOKEN end_char="150" id="token-2-8" morph="none" pos="word" start_char="140">coronavirus</TOKEN>
<TOKEN end_char="159" id="token-2-9" morph="none" pos="word" start_char="152">contains</TOKEN>
<TOKEN end_char="163" id="token-2-10" morph="none" pos="word" start_char="161">HIV</TOKEN>
<TOKEN end_char="165" id="token-2-11" morph="none" pos="punct" start_char="165">"</TOKEN>
<TOKEN end_char="175" id="token-2-12" morph="none" pos="word" start_char="166">insertions</TOKEN>
<TOKEN end_char="176" id="token-2-13" morph="none" pos="punct" start_char="176">"</TOKEN>
<TOKEN end_char="180" id="token-2-14" morph="none" pos="word" start_char="178">and</TOKEN>
<TOKEN end_char="186" id="token-2-15" morph="none" pos="word" start_char="182">shows</TOKEN>
<TOKEN end_char="192" id="token-2-16" morph="none" pos="word" start_char="188">signs</TOKEN>
<TOKEN end_char="195" id="token-2-17" morph="none" pos="word" start_char="194">of</TOKEN>
<TOKEN end_char="201" id="token-2-18" morph="none" pos="word" start_char="197">being</TOKEN>
<TOKEN end_char="209" id="token-2-19" morph="none" pos="word" start_char="203">created</TOKEN>
<TOKEN end_char="212" id="token-2-20" morph="none" pos="word" start_char="211">in</TOKEN>
<TOKEN end_char="214" id="token-2-21" morph="none" pos="word" start_char="214">a</TOKEN>
<TOKEN end_char="218" id="token-2-22" morph="none" pos="word" start_char="216">lab</TOKEN>
<TOKEN end_char="219" id="token-2-23" morph="none" pos="punct" start_char="219">.</TOKEN>
</SEG>
<SEG end_char="327" id="segment-3" start_char="221">
<ORIGINAL_TEXT>But there is no evidence that the new virus was bioengineered, and every indication it came from an animal.</ORIGINAL_TEXT>
<TOKEN end_char="223" id="token-3-0" morph="none" pos="word" start_char="221">But</TOKEN>
<TOKEN end_char="229" id="token-3-1" morph="none" pos="word" start_char="225">there</TOKEN>
<TOKEN end_char="232" id="token-3-2" morph="none" pos="word" start_char="231">is</TOKEN>
<TOKEN end_char="235" id="token-3-3" morph="none" pos="word" start_char="234">no</TOKEN>
<TOKEN end_char="244" id="token-3-4" morph="none" pos="word" start_char="237">evidence</TOKEN>
<TOKEN end_char="249" id="token-3-5" morph="none" pos="word" start_char="246">that</TOKEN>
<TOKEN end_char="253" id="token-3-6" morph="none" pos="word" start_char="251">the</TOKEN>
<TOKEN end_char="257" id="token-3-7" morph="none" pos="word" start_char="255">new</TOKEN>
<TOKEN end_char="263" id="token-3-8" morph="none" pos="word" start_char="259">virus</TOKEN>
<TOKEN end_char="267" id="token-3-9" morph="none" pos="word" start_char="265">was</TOKEN>
<TOKEN end_char="281" id="token-3-10" morph="none" pos="word" start_char="269">bioengineered</TOKEN>
<TOKEN end_char="282" id="token-3-11" morph="none" pos="punct" start_char="282">,</TOKEN>
<TOKEN end_char="286" id="token-3-12" morph="none" pos="word" start_char="284">and</TOKEN>
<TOKEN end_char="292" id="token-3-13" morph="none" pos="word" start_char="288">every</TOKEN>
<TOKEN end_char="303" id="token-3-14" morph="none" pos="word" start_char="294">indication</TOKEN>
<TOKEN end_char="306" id="token-3-15" morph="none" pos="word" start_char="305">it</TOKEN>
<TOKEN end_char="311" id="token-3-16" morph="none" pos="word" start_char="308">came</TOKEN>
<TOKEN end_char="316" id="token-3-17" morph="none" pos="word" start_char="313">from</TOKEN>
<TOKEN end_char="319" id="token-3-18" morph="none" pos="word" start_char="318">an</TOKEN>
<TOKEN end_char="326" id="token-3-19" morph="none" pos="word" start_char="321">animal</TOKEN>
<TOKEN end_char="327" id="token-3-20" morph="none" pos="punct" start_char="327">.</TOKEN>
</SEG>
<SEG end_char="339" id="segment-4" start_char="330">
<ORIGINAL_TEXT>Full Story</ORIGINAL_TEXT>
<TOKEN end_char="333" id="token-4-0" morph="none" pos="word" start_char="330">Full</TOKEN>
<TOKEN end_char="339" id="token-4-1" morph="none" pos="word" start_char="335">Story</TOKEN>
</SEG>
<SEG end_char="576" id="segment-5" start_char="343">
<ORIGINAL_TEXT>The latest conspiracy theories about the new coronavirus, which first led to an outbreak in Wuhan, China in late 2019, allege that the virus was man-made, rather than the natural result of people coming into contact with wild animals.</ORIGINAL_TEXT>
<TOKEN end_char="345" id="token-5-0" morph="none" pos="word" start_char="343">The</TOKEN>
<TOKEN end_char="352" id="token-5-1" morph="none" pos="word" start_char="347">latest</TOKEN>
<TOKEN end_char="363" id="token-5-2" morph="none" pos="word" start_char="354">conspiracy</TOKEN>
<TOKEN end_char="372" id="token-5-3" morph="none" pos="word" start_char="365">theories</TOKEN>
<TOKEN end_char="378" id="token-5-4" morph="none" pos="word" start_char="374">about</TOKEN>
<TOKEN end_char="382" id="token-5-5" morph="none" pos="word" start_char="380">the</TOKEN>
<TOKEN end_char="386" id="token-5-6" morph="none" pos="word" start_char="384">new</TOKEN>
<TOKEN end_char="398" id="token-5-7" morph="none" pos="word" start_char="388">coronavirus</TOKEN>
<TOKEN end_char="399" id="token-5-8" morph="none" pos="punct" start_char="399">,</TOKEN>
<TOKEN end_char="405" id="token-5-9" morph="none" pos="word" start_char="401">which</TOKEN>
<TOKEN end_char="411" id="token-5-10" morph="none" pos="word" start_char="407">first</TOKEN>
<TOKEN end_char="415" id="token-5-11" morph="none" pos="word" start_char="413">led</TOKEN>
<TOKEN end_char="418" id="token-5-12" morph="none" pos="word" start_char="417">to</TOKEN>
<TOKEN end_char="421" id="token-5-13" morph="none" pos="word" start_char="420">an</TOKEN>
<TOKEN end_char="430" id="token-5-14" morph="none" pos="word" start_char="423">outbreak</TOKEN>
<TOKEN end_char="433" id="token-5-15" morph="none" pos="word" start_char="432">in</TOKEN>
<TOKEN end_char="439" id="token-5-16" morph="none" pos="word" start_char="435">Wuhan</TOKEN>
<TOKEN end_char="440" id="token-5-17" morph="none" pos="punct" start_char="440">,</TOKEN>
<TOKEN end_char="446" id="token-5-18" morph="none" pos="word" start_char="442">China</TOKEN>
<TOKEN end_char="449" id="token-5-19" morph="none" pos="word" start_char="448">in</TOKEN>
<TOKEN end_char="454" id="token-5-20" morph="none" pos="word" start_char="451">late</TOKEN>
<TOKEN end_char="459" id="token-5-21" morph="none" pos="word" start_char="456">2019</TOKEN>
<TOKEN end_char="460" id="token-5-22" morph="none" pos="punct" start_char="460">,</TOKEN>
<TOKEN end_char="467" id="token-5-23" morph="none" pos="word" start_char="462">allege</TOKEN>
<TOKEN end_char="472" id="token-5-24" morph="none" pos="word" start_char="469">that</TOKEN>
<TOKEN end_char="476" id="token-5-25" morph="none" pos="word" start_char="474">the</TOKEN>
<TOKEN end_char="482" id="token-5-26" morph="none" pos="word" start_char="478">virus</TOKEN>
<TOKEN end_char="486" id="token-5-27" morph="none" pos="word" start_char="484">was</TOKEN>
<TOKEN end_char="495" id="token-5-28" morph="none" pos="unknown" start_char="488">man-made</TOKEN>
<TOKEN end_char="496" id="token-5-29" morph="none" pos="punct" start_char="496">,</TOKEN>
<TOKEN end_char="503" id="token-5-30" morph="none" pos="word" start_char="498">rather</TOKEN>
<TOKEN end_char="508" id="token-5-31" morph="none" pos="word" start_char="505">than</TOKEN>
<TOKEN end_char="512" id="token-5-32" morph="none" pos="word" start_char="510">the</TOKEN>
<TOKEN end_char="520" id="token-5-33" morph="none" pos="word" start_char="514">natural</TOKEN>
<TOKEN end_char="527" id="token-5-34" morph="none" pos="word" start_char="522">result</TOKEN>
<TOKEN end_char="530" id="token-5-35" morph="none" pos="word" start_char="529">of</TOKEN>
<TOKEN end_char="537" id="token-5-36" morph="none" pos="word" start_char="532">people</TOKEN>
<TOKEN end_char="544" id="token-5-37" morph="none" pos="word" start_char="539">coming</TOKEN>
<TOKEN end_char="549" id="token-5-38" morph="none" pos="word" start_char="546">into</TOKEN>
<TOKEN end_char="557" id="token-5-39" morph="none" pos="word" start_char="551">contact</TOKEN>
<TOKEN end_char="562" id="token-5-40" morph="none" pos="word" start_char="559">with</TOKEN>
<TOKEN end_char="567" id="token-5-41" morph="none" pos="word" start_char="564">wild</TOKEN>
<TOKEN end_char="575" id="token-5-42" morph="none" pos="word" start_char="569">animals</TOKEN>
<TOKEN end_char="576" id="token-5-43" morph="none" pos="punct" start_char="576">.</TOKEN>
</SEG>
<SEG end_char="713" id="segment-6" start_char="579">
<ORIGINAL_TEXT>We’ve seen similar claims before, but this time many claims are being fueled by an unpublished — and highly dubious — scientific paper.</ORIGINAL_TEXT>
<TOKEN end_char="583" id="token-6-0" morph="none" pos="word" start_char="579">We’ve</TOKEN>
<TOKEN end_char="588" id="token-6-1" morph="none" pos="word" start_char="585">seen</TOKEN>
<TOKEN end_char="596" id="token-6-2" morph="none" pos="word" start_char="590">similar</TOKEN>
<TOKEN end_char="603" id="token-6-3" morph="none" pos="word" start_char="598">claims</TOKEN>
<TOKEN end_char="610" id="token-6-4" morph="none" pos="word" start_char="605">before</TOKEN>
<TOKEN end_char="611" id="token-6-5" morph="none" pos="punct" start_char="611">,</TOKEN>
<TOKEN end_char="615" id="token-6-6" morph="none" pos="word" start_char="613">but</TOKEN>
<TOKEN end_char="620" id="token-6-7" morph="none" pos="word" start_char="617">this</TOKEN>
<TOKEN end_char="625" id="token-6-8" morph="none" pos="word" start_char="622">time</TOKEN>
<TOKEN end_char="630" id="token-6-9" morph="none" pos="word" start_char="627">many</TOKEN>
<TOKEN end_char="637" id="token-6-10" morph="none" pos="word" start_char="632">claims</TOKEN>
<TOKEN end_char="641" id="token-6-11" morph="none" pos="word" start_char="639">are</TOKEN>
<TOKEN end_char="647" id="token-6-12" morph="none" pos="word" start_char="643">being</TOKEN>
<TOKEN end_char="654" id="token-6-13" morph="none" pos="word" start_char="649">fueled</TOKEN>
<TOKEN end_char="657" id="token-6-14" morph="none" pos="word" start_char="656">by</TOKEN>
<TOKEN end_char="660" id="token-6-15" morph="none" pos="word" start_char="659">an</TOKEN>
<TOKEN end_char="672" id="token-6-16" morph="none" pos="word" start_char="662">unpublished</TOKEN>
<TOKEN end_char="674" id="token-6-17" morph="none" pos="punct" start_char="674">—</TOKEN>
<TOKEN end_char="678" id="token-6-18" morph="none" pos="word" start_char="676">and</TOKEN>
<TOKEN end_char="685" id="token-6-19" morph="none" pos="word" start_char="680">highly</TOKEN>
<TOKEN end_char="693" id="token-6-20" morph="none" pos="word" start_char="687">dubious</TOKEN>
<TOKEN end_char="695" id="token-6-21" morph="none" pos="punct" start_char="695">—</TOKEN>
<TOKEN end_char="706" id="token-6-22" morph="none" pos="word" start_char="697">scientific</TOKEN>
<TOKEN end_char="712" id="token-6-23" morph="none" pos="word" start_char="708">paper</TOKEN>
<TOKEN end_char="713" id="token-6-24" morph="none" pos="punct" start_char="713">.</TOKEN>
</SEG>
<SEG end_char="838" id="segment-7" start_char="715">
<ORIGINAL_TEXT>By delving into the genetic or protein sequences of the virus, many of these stories have an aura of scientific credibility.</ORIGINAL_TEXT>
<TOKEN end_char="716" id="token-7-0" morph="none" pos="word" start_char="715">By</TOKEN>
<TOKEN end_char="724" id="token-7-1" morph="none" pos="word" start_char="718">delving</TOKEN>
<TOKEN end_char="729" id="token-7-2" morph="none" pos="word" start_char="726">into</TOKEN>
<TOKEN end_char="733" id="token-7-3" morph="none" pos="word" start_char="731">the</TOKEN>
<TOKEN end_char="741" id="token-7-4" morph="none" pos="word" start_char="735">genetic</TOKEN>
<TOKEN end_char="744" id="token-7-5" morph="none" pos="word" start_char="743">or</TOKEN>
<TOKEN end_char="752" id="token-7-6" morph="none" pos="word" start_char="746">protein</TOKEN>
<TOKEN end_char="762" id="token-7-7" morph="none" pos="word" start_char="754">sequences</TOKEN>
<TOKEN end_char="765" id="token-7-8" morph="none" pos="word" start_char="764">of</TOKEN>
<TOKEN end_char="769" id="token-7-9" morph="none" pos="word" start_char="767">the</TOKEN>
<TOKEN end_char="775" id="token-7-10" morph="none" pos="word" start_char="771">virus</TOKEN>
<TOKEN end_char="776" id="token-7-11" morph="none" pos="punct" start_char="776">,</TOKEN>
<TOKEN end_char="781" id="token-7-12" morph="none" pos="word" start_char="778">many</TOKEN>
<TOKEN end_char="784" id="token-7-13" morph="none" pos="word" start_char="783">of</TOKEN>
<TOKEN end_char="790" id="token-7-14" morph="none" pos="word" start_char="786">these</TOKEN>
<TOKEN end_char="798" id="token-7-15" morph="none" pos="word" start_char="792">stories</TOKEN>
<TOKEN end_char="803" id="token-7-16" morph="none" pos="word" start_char="800">have</TOKEN>
<TOKEN end_char="806" id="token-7-17" morph="none" pos="word" start_char="805">an</TOKEN>
<TOKEN end_char="811" id="token-7-18" morph="none" pos="word" start_char="808">aura</TOKEN>
<TOKEN end_char="814" id="token-7-19" morph="none" pos="word" start_char="813">of</TOKEN>
<TOKEN end_char="825" id="token-7-20" morph="none" pos="word" start_char="816">scientific</TOKEN>
<TOKEN end_char="837" id="token-7-21" morph="none" pos="word" start_char="827">credibility</TOKEN>
<TOKEN end_char="838" id="token-7-22" morph="none" pos="punct" start_char="838">.</TOKEN>
</SEG>
<SEG end_char="895" id="segment-8" start_char="840">
<ORIGINAL_TEXT>But scientists who study viruses say they are incorrect.</ORIGINAL_TEXT>
<TOKEN end_char="842" id="token-8-0" morph="none" pos="word" start_char="840">But</TOKEN>
<TOKEN end_char="853" id="token-8-1" morph="none" pos="word" start_char="844">scientists</TOKEN>
<TOKEN end_char="857" id="token-8-2" morph="none" pos="word" start_char="855">who</TOKEN>
<TOKEN end_char="863" id="token-8-3" morph="none" pos="word" start_char="859">study</TOKEN>
<TOKEN end_char="871" id="token-8-4" morph="none" pos="word" start_char="865">viruses</TOKEN>
<TOKEN end_char="875" id="token-8-5" morph="none" pos="word" start_char="873">say</TOKEN>
<TOKEN end_char="880" id="token-8-6" morph="none" pos="word" start_char="877">they</TOKEN>
<TOKEN end_char="884" id="token-8-7" morph="none" pos="word" start_char="882">are</TOKEN>
<TOKEN end_char="894" id="token-8-8" morph="none" pos="word" start_char="886">incorrect</TOKEN>
<TOKEN end_char="895" id="token-8-9" morph="none" pos="punct" start_char="895">.</TOKEN>
</SEG>
<SEG end_char="1134" id="segment-9" start_char="898">
<ORIGINAL_TEXT>One set of stories, subsequently shared on Facebook, inaccurately asserts a link between the new coronavirus, also known as 2019 novel coronavirus, or 2019-nCoV, and HIV, largely based on an unpublished manuscript by scientists in India.</ORIGINAL_TEXT>
<TOKEN end_char="900" id="token-9-0" morph="none" pos="word" start_char="898">One</TOKEN>
<TOKEN end_char="904" id="token-9-1" morph="none" pos="word" start_char="902">set</TOKEN>
<TOKEN end_char="907" id="token-9-2" morph="none" pos="word" start_char="906">of</TOKEN>
<TOKEN end_char="915" id="token-9-3" morph="none" pos="word" start_char="909">stories</TOKEN>
<TOKEN end_char="916" id="token-9-4" morph="none" pos="punct" start_char="916">,</TOKEN>
<TOKEN end_char="929" id="token-9-5" morph="none" pos="word" start_char="918">subsequently</TOKEN>
<TOKEN end_char="936" id="token-9-6" morph="none" pos="word" start_char="931">shared</TOKEN>
<TOKEN end_char="939" id="token-9-7" morph="none" pos="word" start_char="938">on</TOKEN>
<TOKEN end_char="948" id="token-9-8" morph="none" pos="word" start_char="941">Facebook</TOKEN>
<TOKEN end_char="949" id="token-9-9" morph="none" pos="punct" start_char="949">,</TOKEN>
<TOKEN end_char="962" id="token-9-10" morph="none" pos="word" start_char="951">inaccurately</TOKEN>
<TOKEN end_char="970" id="token-9-11" morph="none" pos="word" start_char="964">asserts</TOKEN>
<TOKEN end_char="972" id="token-9-12" morph="none" pos="word" start_char="972">a</TOKEN>
<TOKEN end_char="977" id="token-9-13" morph="none" pos="word" start_char="974">link</TOKEN>
<TOKEN end_char="985" id="token-9-14" morph="none" pos="word" start_char="979">between</TOKEN>
<TOKEN end_char="989" id="token-9-15" morph="none" pos="word" start_char="987">the</TOKEN>
<TOKEN end_char="993" id="token-9-16" morph="none" pos="word" start_char="991">new</TOKEN>
<TOKEN end_char="1005" id="token-9-17" morph="none" pos="word" start_char="995">coronavirus</TOKEN>
<TOKEN end_char="1006" id="token-9-18" morph="none" pos="punct" start_char="1006">,</TOKEN>
<TOKEN end_char="1011" id="token-9-19" morph="none" pos="word" start_char="1008">also</TOKEN>
<TOKEN end_char="1017" id="token-9-20" morph="none" pos="word" start_char="1013">known</TOKEN>
<TOKEN end_char="1020" id="token-9-21" morph="none" pos="word" start_char="1019">as</TOKEN>
<TOKEN end_char="1025" id="token-9-22" morph="none" pos="word" start_char="1022">2019</TOKEN>
<TOKEN end_char="1031" id="token-9-23" morph="none" pos="word" start_char="1027">novel</TOKEN>
<TOKEN end_char="1043" id="token-9-24" morph="none" pos="word" start_char="1033">coronavirus</TOKEN>
<TOKEN end_char="1044" id="token-9-25" morph="none" pos="punct" start_char="1044">,</TOKEN>
<TOKEN end_char="1047" id="token-9-26" morph="none" pos="word" start_char="1046">or</TOKEN>
<TOKEN end_char="1057" id="token-9-27" morph="none" pos="unknown" start_char="1049">2019-nCoV</TOKEN>
<TOKEN end_char="1058" id="token-9-28" morph="none" pos="punct" start_char="1058">,</TOKEN>
<TOKEN end_char="1062" id="token-9-29" morph="none" pos="word" start_char="1060">and</TOKEN>
<TOKEN end_char="1066" id="token-9-30" morph="none" pos="word" start_char="1064">HIV</TOKEN>
<TOKEN end_char="1067" id="token-9-31" morph="none" pos="punct" start_char="1067">,</TOKEN>
<TOKEN end_char="1075" id="token-9-32" morph="none" pos="word" start_char="1069">largely</TOKEN>
<TOKEN end_char="1081" id="token-9-33" morph="none" pos="word" start_char="1077">based</TOKEN>
<TOKEN end_char="1084" id="token-9-34" morph="none" pos="word" start_char="1083">on</TOKEN>
<TOKEN end_char="1087" id="token-9-35" morph="none" pos="word" start_char="1086">an</TOKEN>
<TOKEN end_char="1099" id="token-9-36" morph="none" pos="word" start_char="1089">unpublished</TOKEN>
<TOKEN end_char="1110" id="token-9-37" morph="none" pos="word" start_char="1101">manuscript</TOKEN>
<TOKEN end_char="1113" id="token-9-38" morph="none" pos="word" start_char="1112">by</TOKEN>
<TOKEN end_char="1124" id="token-9-39" morph="none" pos="word" start_char="1115">scientists</TOKEN>
<TOKEN end_char="1127" id="token-9-40" morph="none" pos="word" start_char="1126">in</TOKEN>
<TOKEN end_char="1133" id="token-9-41" morph="none" pos="word" start_char="1129">India</TOKEN>
<TOKEN end_char="1134" id="token-9-42" morph="none" pos="punct" start_char="1134">.</TOKEN>
</SEG>
<SEG end_char="1230" id="segment-10" start_char="1137">
<ORIGINAL_TEXT>The paper, which was posted on the preprint website bioRxiv (pronounced "bio-archive") on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="1139" id="token-10-0" morph="none" pos="word" start_char="1137">The</TOKEN>
<TOKEN end_char="1145" id="token-10-1" morph="none" pos="word" start_char="1141">paper</TOKEN>
<TOKEN end_char="1146" id="token-10-2" morph="none" pos="punct" start_char="1146">,</TOKEN>
<TOKEN end_char="1152" id="token-10-3" morph="none" pos="word" start_char="1148">which</TOKEN>
<TOKEN end_char="1156" id="token-10-4" morph="none" pos="word" start_char="1154">was</TOKEN>
<TOKEN end_char="1163" id="token-10-5" morph="none" pos="word" start_char="1158">posted</TOKEN>
<TOKEN end_char="1166" id="token-10-6" morph="none" pos="word" start_char="1165">on</TOKEN>
<TOKEN end_char="1170" id="token-10-7" morph="none" pos="word" start_char="1168">the</TOKEN>
<TOKEN end_char="1179" id="token-10-8" morph="none" pos="word" start_char="1172">preprint</TOKEN>
<TOKEN end_char="1187" id="token-10-9" morph="none" pos="word" start_char="1181">website</TOKEN>
<TOKEN end_char="1195" id="token-10-10" morph="none" pos="word" start_char="1189">bioRxiv</TOKEN>
<TOKEN end_char="1197" id="token-10-11" morph="none" pos="punct" start_char="1197">(</TOKEN>
<TOKEN end_char="1207" id="token-10-12" morph="none" pos="word" start_char="1198">pronounced</TOKEN>
<TOKEN end_char="1209" id="token-10-13" morph="none" pos="punct" start_char="1209">"</TOKEN>
<TOKEN end_char="1220" id="token-10-14" morph="none" pos="unknown" start_char="1210">bio-archive</TOKEN>
<TOKEN end_char="1222" id="token-10-15" morph="none" pos="punct" start_char="1221">")</TOKEN>
<TOKEN end_char="1225" id="token-10-16" morph="none" pos="word" start_char="1224">on</TOKEN>
<TOKEN end_char="1229" id="token-10-17" morph="none" pos="word" start_char="1227">Jan</TOKEN>
<TOKEN end_char="1230" id="token-10-18" morph="none" pos="punct" start_char="1230">.</TOKEN>
</SEG>
<SEG end_char="1357" id="segment-11" start_char="1232">
<ORIGINAL_TEXT>31, claimed to have identified very short "insertions" in the virus’ protein sequence that had an "uncanny similarity" to HIV.</ORIGINAL_TEXT>
<TOKEN end_char="1233" id="token-11-0" morph="none" pos="word" start_char="1232">31</TOKEN>
<TOKEN end_char="1234" id="token-11-1" morph="none" pos="punct" start_char="1234">,</TOKEN>
<TOKEN end_char="1242" id="token-11-2" morph="none" pos="word" start_char="1236">claimed</TOKEN>
<TOKEN end_char="1245" id="token-11-3" morph="none" pos="word" start_char="1244">to</TOKEN>
<TOKEN end_char="1250" id="token-11-4" morph="none" pos="word" start_char="1247">have</TOKEN>
<TOKEN end_char="1261" id="token-11-5" morph="none" pos="word" start_char="1252">identified</TOKEN>
<TOKEN end_char="1266" id="token-11-6" morph="none" pos="word" start_char="1263">very</TOKEN>
<TOKEN end_char="1272" id="token-11-7" morph="none" pos="word" start_char="1268">short</TOKEN>
<TOKEN end_char="1274" id="token-11-8" morph="none" pos="punct" start_char="1274">"</TOKEN>
<TOKEN end_char="1284" id="token-11-9" morph="none" pos="word" start_char="1275">insertions</TOKEN>
<TOKEN end_char="1285" id="token-11-10" morph="none" pos="punct" start_char="1285">"</TOKEN>
<TOKEN end_char="1288" id="token-11-11" morph="none" pos="word" start_char="1287">in</TOKEN>
<TOKEN end_char="1292" id="token-11-12" morph="none" pos="word" start_char="1290">the</TOKEN>
<TOKEN end_char="1298" id="token-11-13" morph="none" pos="word" start_char="1294">virus</TOKEN>
<TOKEN end_char="1299" id="token-11-14" morph="none" pos="punct" start_char="1299">’</TOKEN>
<TOKEN end_char="1307" id="token-11-15" morph="none" pos="word" start_char="1301">protein</TOKEN>
<TOKEN end_char="1316" id="token-11-16" morph="none" pos="word" start_char="1309">sequence</TOKEN>
<TOKEN end_char="1321" id="token-11-17" morph="none" pos="word" start_char="1318">that</TOKEN>
<TOKEN end_char="1325" id="token-11-18" morph="none" pos="word" start_char="1323">had</TOKEN>
<TOKEN end_char="1328" id="token-11-19" morph="none" pos="word" start_char="1327">an</TOKEN>
<TOKEN end_char="1330" id="token-11-20" morph="none" pos="punct" start_char="1330">"</TOKEN>
<TOKEN end_char="1337" id="token-11-21" morph="none" pos="word" start_char="1331">uncanny</TOKEN>
<TOKEN end_char="1348" id="token-11-22" morph="none" pos="word" start_char="1339">similarity</TOKEN>
<TOKEN end_char="1349" id="token-11-23" morph="none" pos="punct" start_char="1349">"</TOKEN>
<TOKEN end_char="1352" id="token-11-24" morph="none" pos="word" start_char="1351">to</TOKEN>
<TOKEN end_char="1356" id="token-11-25" morph="none" pos="word" start_char="1354">HIV</TOKEN>
<TOKEN end_char="1357" id="token-11-26" morph="none" pos="punct" start_char="1357">.</TOKEN>
</SEG>
<SEG end_char="1576" id="segment-12" start_char="1359">
<ORIGINAL_TEXT>Numerous scientists, however, almost immediately pointed out flaws in the analysis, noting that the sequences are so short, they match a bevy of other organisms — and there’s no reason to conclude they derive from HIV.</ORIGINAL_TEXT>
<TOKEN end_char="1366" id="token-12-0" morph="none" pos="word" start_char="1359">Numerous</TOKEN>
<TOKEN end_char="1377" id="token-12-1" morph="none" pos="word" start_char="1368">scientists</TOKEN>
<TOKEN end_char="1378" id="token-12-2" morph="none" pos="punct" start_char="1378">,</TOKEN>
<TOKEN end_char="1386" id="token-12-3" morph="none" pos="word" start_char="1380">however</TOKEN>
<TOKEN end_char="1387" id="token-12-4" morph="none" pos="punct" start_char="1387">,</TOKEN>
<TOKEN end_char="1394" id="token-12-5" morph="none" pos="word" start_char="1389">almost</TOKEN>
<TOKEN end_char="1406" id="token-12-6" morph="none" pos="word" start_char="1396">immediately</TOKEN>
<TOKEN end_char="1414" id="token-12-7" morph="none" pos="word" start_char="1408">pointed</TOKEN>
<TOKEN end_char="1418" id="token-12-8" morph="none" pos="word" start_char="1416">out</TOKEN>
<TOKEN end_char="1424" id="token-12-9" morph="none" pos="word" start_char="1420">flaws</TOKEN>
<TOKEN end_char="1427" id="token-12-10" morph="none" pos="word" start_char="1426">in</TOKEN>
<TOKEN end_char="1431" id="token-12-11" morph="none" pos="word" start_char="1429">the</TOKEN>
<TOKEN end_char="1440" id="token-12-12" morph="none" pos="word" start_char="1433">analysis</TOKEN>
<TOKEN end_char="1441" id="token-12-13" morph="none" pos="punct" start_char="1441">,</TOKEN>
<TOKEN end_char="1448" id="token-12-14" morph="none" pos="word" start_char="1443">noting</TOKEN>
<TOKEN end_char="1453" id="token-12-15" morph="none" pos="word" start_char="1450">that</TOKEN>
<TOKEN end_char="1457" id="token-12-16" morph="none" pos="word" start_char="1455">the</TOKEN>
<TOKEN end_char="1467" id="token-12-17" morph="none" pos="word" start_char="1459">sequences</TOKEN>
<TOKEN end_char="1471" id="token-12-18" morph="none" pos="word" start_char="1469">are</TOKEN>
<TOKEN end_char="1474" id="token-12-19" morph="none" pos="word" start_char="1473">so</TOKEN>
<TOKEN end_char="1480" id="token-12-20" morph="none" pos="word" start_char="1476">short</TOKEN>
<TOKEN end_char="1481" id="token-12-21" morph="none" pos="punct" start_char="1481">,</TOKEN>
<TOKEN end_char="1486" id="token-12-22" morph="none" pos="word" start_char="1483">they</TOKEN>
<TOKEN end_char="1492" id="token-12-23" morph="none" pos="word" start_char="1488">match</TOKEN>
<TOKEN end_char="1494" id="token-12-24" morph="none" pos="word" start_char="1494">a</TOKEN>
<TOKEN end_char="1499" id="token-12-25" morph="none" pos="word" start_char="1496">bevy</TOKEN>
<TOKEN end_char="1502" id="token-12-26" morph="none" pos="word" start_char="1501">of</TOKEN>
<TOKEN end_char="1508" id="token-12-27" morph="none" pos="word" start_char="1504">other</TOKEN>
<TOKEN end_char="1518" id="token-12-28" morph="none" pos="word" start_char="1510">organisms</TOKEN>
<TOKEN end_char="1520" id="token-12-29" morph="none" pos="punct" start_char="1520">—</TOKEN>
<TOKEN end_char="1524" id="token-12-30" morph="none" pos="word" start_char="1522">and</TOKEN>
<TOKEN end_char="1532" id="token-12-31" morph="none" pos="word" start_char="1526">there’s</TOKEN>
<TOKEN end_char="1535" id="token-12-32" morph="none" pos="word" start_char="1534">no</TOKEN>
<TOKEN end_char="1542" id="token-12-33" morph="none" pos="word" start_char="1537">reason</TOKEN>
<TOKEN end_char="1545" id="token-12-34" morph="none" pos="word" start_char="1544">to</TOKEN>
<TOKEN end_char="1554" id="token-12-35" morph="none" pos="word" start_char="1547">conclude</TOKEN>
<TOKEN end_char="1559" id="token-12-36" morph="none" pos="word" start_char="1556">they</TOKEN>
<TOKEN end_char="1566" id="token-12-37" morph="none" pos="word" start_char="1561">derive</TOKEN>
<TOKEN end_char="1571" id="token-12-38" morph="none" pos="word" start_char="1568">from</TOKEN>
<TOKEN end_char="1575" id="token-12-39" morph="none" pos="word" start_char="1573">HIV</TOKEN>
<TOKEN end_char="1576" id="token-12-40" morph="none" pos="punct" start_char="1576">.</TOKEN>
</SEG>
<SEG end_char="1763" id="segment-13" start_char="1578">
<ORIGINAL_TEXT>The paper was voluntarily withdrawn by its authors just two days later, with one saying, "It was not our intention to feed into the conspiracy theories and no such claims are made here."</ORIGINAL_TEXT>
<TOKEN end_char="1580" id="token-13-0" morph="none" pos="word" start_char="1578">The</TOKEN>
<TOKEN end_char="1586" id="token-13-1" morph="none" pos="word" start_char="1582">paper</TOKEN>
<TOKEN end_char="1590" id="token-13-2" morph="none" pos="word" start_char="1588">was</TOKEN>
<TOKEN end_char="1602" id="token-13-3" morph="none" pos="word" start_char="1592">voluntarily</TOKEN>
<TOKEN end_char="1612" id="token-13-4" morph="none" pos="word" start_char="1604">withdrawn</TOKEN>
<TOKEN end_char="1615" id="token-13-5" morph="none" pos="word" start_char="1614">by</TOKEN>
<TOKEN end_char="1619" id="token-13-6" morph="none" pos="word" start_char="1617">its</TOKEN>
<TOKEN end_char="1627" id="token-13-7" morph="none" pos="word" start_char="1621">authors</TOKEN>
<TOKEN end_char="1632" id="token-13-8" morph="none" pos="word" start_char="1629">just</TOKEN>
<TOKEN end_char="1636" id="token-13-9" morph="none" pos="word" start_char="1634">two</TOKEN>
<TOKEN end_char="1641" id="token-13-10" morph="none" pos="word" start_char="1638">days</TOKEN>
<TOKEN end_char="1647" id="token-13-11" morph="none" pos="word" start_char="1643">later</TOKEN>
<TOKEN end_char="1648" id="token-13-12" morph="none" pos="punct" start_char="1648">,</TOKEN>
<TOKEN end_char="1653" id="token-13-13" morph="none" pos="word" start_char="1650">with</TOKEN>
<TOKEN end_char="1657" id="token-13-14" morph="none" pos="word" start_char="1655">one</TOKEN>
<TOKEN end_char="1664" id="token-13-15" morph="none" pos="word" start_char="1659">saying</TOKEN>
<TOKEN end_char="1665" id="token-13-16" morph="none" pos="punct" start_char="1665">,</TOKEN>
<TOKEN end_char="1667" id="token-13-17" morph="none" pos="punct" start_char="1667">"</TOKEN>
<TOKEN end_char="1669" id="token-13-18" morph="none" pos="word" start_char="1668">It</TOKEN>
<TOKEN end_char="1673" id="token-13-19" morph="none" pos="word" start_char="1671">was</TOKEN>
<TOKEN end_char="1677" id="token-13-20" morph="none" pos="word" start_char="1675">not</TOKEN>
<TOKEN end_char="1681" id="token-13-21" morph="none" pos="word" start_char="1679">our</TOKEN>
<TOKEN end_char="1691" id="token-13-22" morph="none" pos="word" start_char="1683">intention</TOKEN>
<TOKEN end_char="1694" id="token-13-23" morph="none" pos="word" start_char="1693">to</TOKEN>
<TOKEN end_char="1699" id="token-13-24" morph="none" pos="word" start_char="1696">feed</TOKEN>
<TOKEN end_char="1704" id="token-13-25" morph="none" pos="word" start_char="1701">into</TOKEN>
<TOKEN end_char="1708" id="token-13-26" morph="none" pos="word" start_char="1706">the</TOKEN>
<TOKEN end_char="1719" id="token-13-27" morph="none" pos="word" start_char="1710">conspiracy</TOKEN>
<TOKEN end_char="1728" id="token-13-28" morph="none" pos="word" start_char="1721">theories</TOKEN>
<TOKEN end_char="1732" id="token-13-29" morph="none" pos="word" start_char="1730">and</TOKEN>
<TOKEN end_char="1735" id="token-13-30" morph="none" pos="word" start_char="1734">no</TOKEN>
<TOKEN end_char="1740" id="token-13-31" morph="none" pos="word" start_char="1737">such</TOKEN>
<TOKEN end_char="1747" id="token-13-32" morph="none" pos="word" start_char="1742">claims</TOKEN>
<TOKEN end_char="1751" id="token-13-33" morph="none" pos="word" start_char="1749">are</TOKEN>
<TOKEN end_char="1756" id="token-13-34" morph="none" pos="word" start_char="1753">made</TOKEN>
<TOKEN end_char="1761" id="token-13-35" morph="none" pos="word" start_char="1758">here</TOKEN>
<TOKEN end_char="1763" id="token-13-36" morph="none" pos="punct" start_char="1762">."</TOKEN>
</SEG>
<SEG end_char="1934" id="segment-14" start_char="1766">
<ORIGINAL_TEXT>But the speedy withdrawal wasn’t fast enough to prevent some websites from picking up the story and concluding that the new coronavirus had been crafted in a laboratory.</ORIGINAL_TEXT>
<TOKEN end_char="1768" id="token-14-0" morph="none" pos="word" start_char="1766">But</TOKEN>
<TOKEN end_char="1772" id="token-14-1" morph="none" pos="word" start_char="1770">the</TOKEN>
<TOKEN end_char="1779" id="token-14-2" morph="none" pos="word" start_char="1774">speedy</TOKEN>
<TOKEN end_char="1790" id="token-14-3" morph="none" pos="word" start_char="1781">withdrawal</TOKEN>
<TOKEN end_char="1797" id="token-14-4" morph="none" pos="word" start_char="1792">wasn’t</TOKEN>
<TOKEN end_char="1802" id="token-14-5" morph="none" pos="word" start_char="1799">fast</TOKEN>
<TOKEN end_char="1809" id="token-14-6" morph="none" pos="word" start_char="1804">enough</TOKEN>
<TOKEN end_char="1812" id="token-14-7" morph="none" pos="word" start_char="1811">to</TOKEN>
<TOKEN end_char="1820" id="token-14-8" morph="none" pos="word" start_char="1814">prevent</TOKEN>
<TOKEN end_char="1825" id="token-14-9" morph="none" pos="word" start_char="1822">some</TOKEN>
<TOKEN end_char="1834" id="token-14-10" morph="none" pos="word" start_char="1827">websites</TOKEN>
<TOKEN end_char="1839" id="token-14-11" morph="none" pos="word" start_char="1836">from</TOKEN>
<TOKEN end_char="1847" id="token-14-12" morph="none" pos="word" start_char="1841">picking</TOKEN>
<TOKEN end_char="1850" id="token-14-13" morph="none" pos="word" start_char="1849">up</TOKEN>
<TOKEN end_char="1854" id="token-14-14" morph="none" pos="word" start_char="1852">the</TOKEN>
<TOKEN end_char="1860" id="token-14-15" morph="none" pos="word" start_char="1856">story</TOKEN>
<TOKEN end_char="1864" id="token-14-16" morph="none" pos="word" start_char="1862">and</TOKEN>
<TOKEN end_char="1875" id="token-14-17" morph="none" pos="word" start_char="1866">concluding</TOKEN>
<TOKEN end_char="1880" id="token-14-18" morph="none" pos="word" start_char="1877">that</TOKEN>
<TOKEN end_char="1884" id="token-14-19" morph="none" pos="word" start_char="1882">the</TOKEN>
<TOKEN end_char="1888" id="token-14-20" morph="none" pos="word" start_char="1886">new</TOKEN>
<TOKEN end_char="1900" id="token-14-21" morph="none" pos="word" start_char="1890">coronavirus</TOKEN>
<TOKEN end_char="1904" id="token-14-22" morph="none" pos="word" start_char="1902">had</TOKEN>
<TOKEN end_char="1909" id="token-14-23" morph="none" pos="word" start_char="1906">been</TOKEN>
<TOKEN end_char="1917" id="token-14-24" morph="none" pos="word" start_char="1911">crafted</TOKEN>
<TOKEN end_char="1920" id="token-14-25" morph="none" pos="word" start_char="1919">in</TOKEN>
<TOKEN end_char="1922" id="token-14-26" morph="none" pos="word" start_char="1922">a</TOKEN>
<TOKEN end_char="1933" id="token-14-27" morph="none" pos="word" start_char="1924">laboratory</TOKEN>
<TOKEN end_char="1934" id="token-14-28" morph="none" pos="punct" start_char="1934">.</TOKEN>
</SEG>
<SEG end_char="2186" id="segment-15" start_char="1937">
<ORIGINAL_TEXT>A ZeroHedge article with the headline, "Coronavirus Contains ‘HIV Insertions,’ Stoking Fears Over Artificially Created Bioweapon," pounced on some of the language in the preprint to argue that the scientists were saying the virus might be "man-made."</ORIGINAL_TEXT>
<TOKEN end_char="1937" id="token-15-0" morph="none" pos="word" start_char="1937">A</TOKEN>
<TOKEN end_char="1947" id="token-15-1" morph="none" pos="word" start_char="1939">ZeroHedge</TOKEN>
<TOKEN end_char="1955" id="token-15-2" morph="none" pos="word" start_char="1949">article</TOKEN>
<TOKEN end_char="1960" id="token-15-3" morph="none" pos="word" start_char="1957">with</TOKEN>
<TOKEN end_char="1964" id="token-15-4" morph="none" pos="word" start_char="1962">the</TOKEN>
<TOKEN end_char="1973" id="token-15-5" morph="none" pos="word" start_char="1966">headline</TOKEN>
<TOKEN end_char="1974" id="token-15-6" morph="none" pos="punct" start_char="1974">,</TOKEN>
<TOKEN end_char="1976" id="token-15-7" morph="none" pos="punct" start_char="1976">"</TOKEN>
<TOKEN end_char="1987" id="token-15-8" morph="none" pos="word" start_char="1977">Coronavirus</TOKEN>
<TOKEN end_char="1996" id="token-15-9" morph="none" pos="word" start_char="1989">Contains</TOKEN>
<TOKEN end_char="1998" id="token-15-10" morph="none" pos="punct" start_char="1998">‘</TOKEN>
<TOKEN end_char="2001" id="token-15-11" morph="none" pos="word" start_char="1999">HIV</TOKEN>
<TOKEN end_char="2012" id="token-15-12" morph="none" pos="word" start_char="2003">Insertions</TOKEN>
<TOKEN end_char="2014" id="token-15-13" morph="none" pos="punct" start_char="2013">,’</TOKEN>
<TOKEN end_char="2022" id="token-15-14" morph="none" pos="word" start_char="2016">Stoking</TOKEN>
<TOKEN end_char="2028" id="token-15-15" morph="none" pos="word" start_char="2024">Fears</TOKEN>
<TOKEN end_char="2033" id="token-15-16" morph="none" pos="word" start_char="2030">Over</TOKEN>
<TOKEN end_char="2046" id="token-15-17" morph="none" pos="word" start_char="2035">Artificially</TOKEN>
<TOKEN end_char="2054" id="token-15-18" morph="none" pos="word" start_char="2048">Created</TOKEN>
<TOKEN end_char="2064" id="token-15-19" morph="none" pos="word" start_char="2056">Bioweapon</TOKEN>
<TOKEN end_char="2066" id="token-15-20" morph="none" pos="punct" start_char="2065">,"</TOKEN>
<TOKEN end_char="2074" id="token-15-21" morph="none" pos="word" start_char="2068">pounced</TOKEN>
<TOKEN end_char="2077" id="token-15-22" morph="none" pos="word" start_char="2076">on</TOKEN>
<TOKEN end_char="2082" id="token-15-23" morph="none" pos="word" start_char="2079">some</TOKEN>
<TOKEN end_char="2085" id="token-15-24" morph="none" pos="word" start_char="2084">of</TOKEN>
<TOKEN end_char="2089" id="token-15-25" morph="none" pos="word" start_char="2087">the</TOKEN>
<TOKEN end_char="2098" id="token-15-26" morph="none" pos="word" start_char="2091">language</TOKEN>
<TOKEN end_char="2101" id="token-15-27" morph="none" pos="word" start_char="2100">in</TOKEN>
<TOKEN end_char="2105" id="token-15-28" morph="none" pos="word" start_char="2103">the</TOKEN>
<TOKEN end_char="2114" id="token-15-29" morph="none" pos="word" start_char="2107">preprint</TOKEN>
<TOKEN end_char="2117" id="token-15-30" morph="none" pos="word" start_char="2116">to</TOKEN>
<TOKEN end_char="2123" id="token-15-31" morph="none" pos="word" start_char="2119">argue</TOKEN>
<TOKEN end_char="2128" id="token-15-32" morph="none" pos="word" start_char="2125">that</TOKEN>
<TOKEN end_char="2132" id="token-15-33" morph="none" pos="word" start_char="2130">the</TOKEN>
<TOKEN end_char="2143" id="token-15-34" morph="none" pos="word" start_char="2134">scientists</TOKEN>
<TOKEN end_char="2148" id="token-15-35" morph="none" pos="word" start_char="2145">were</TOKEN>
<TOKEN end_char="2155" id="token-15-36" morph="none" pos="word" start_char="2150">saying</TOKEN>
<TOKEN end_char="2159" id="token-15-37" morph="none" pos="word" start_char="2157">the</TOKEN>
<TOKEN end_char="2165" id="token-15-38" morph="none" pos="word" start_char="2161">virus</TOKEN>
<TOKEN end_char="2171" id="token-15-39" morph="none" pos="word" start_char="2167">might</TOKEN>
<TOKEN end_char="2174" id="token-15-40" morph="none" pos="word" start_char="2173">be</TOKEN>
<TOKEN end_char="2176" id="token-15-41" morph="none" pos="punct" start_char="2176">"</TOKEN>
<TOKEN end_char="2184" id="token-15-42" morph="none" pos="unknown" start_char="2177">man-made</TOKEN>
<TOKEN end_char="2186" id="token-15-43" morph="none" pos="punct" start_char="2185">."</TOKEN>
</SEG>
<SEG end_char="2420" id="segment-16" start_char="2188">
<ORIGINAL_TEXT>The story also cited tweets from a visiting scientist at Harvard who had commented on the preprint and stated that the scientist’s tweets suggested that the virus "might have been genetically engineered for the purposes of a weapon."</ORIGINAL_TEXT>
<TOKEN end_char="2190" id="token-16-0" morph="none" pos="word" start_char="2188">The</TOKEN>
<TOKEN end_char="2196" id="token-16-1" morph="none" pos="word" start_char="2192">story</TOKEN>
<TOKEN end_char="2201" id="token-16-2" morph="none" pos="word" start_char="2198">also</TOKEN>
<TOKEN end_char="2207" id="token-16-3" morph="none" pos="word" start_char="2203">cited</TOKEN>
<TOKEN end_char="2214" id="token-16-4" morph="none" pos="word" start_char="2209">tweets</TOKEN>
<TOKEN end_char="2219" id="token-16-5" morph="none" pos="word" start_char="2216">from</TOKEN>
<TOKEN end_char="2221" id="token-16-6" morph="none" pos="word" start_char="2221">a</TOKEN>
<TOKEN end_char="2230" id="token-16-7" morph="none" pos="word" start_char="2223">visiting</TOKEN>
<TOKEN end_char="2240" id="token-16-8" morph="none" pos="word" start_char="2232">scientist</TOKEN>
<TOKEN end_char="2243" id="token-16-9" morph="none" pos="word" start_char="2242">at</TOKEN>
<TOKEN end_char="2251" id="token-16-10" morph="none" pos="word" start_char="2245">Harvard</TOKEN>
<TOKEN end_char="2255" id="token-16-11" morph="none" pos="word" start_char="2253">who</TOKEN>
<TOKEN end_char="2259" id="token-16-12" morph="none" pos="word" start_char="2257">had</TOKEN>
<TOKEN end_char="2269" id="token-16-13" morph="none" pos="word" start_char="2261">commented</TOKEN>
<TOKEN end_char="2272" id="token-16-14" morph="none" pos="word" start_char="2271">on</TOKEN>
<TOKEN end_char="2276" id="token-16-15" morph="none" pos="word" start_char="2274">the</TOKEN>
<TOKEN end_char="2285" id="token-16-16" morph="none" pos="word" start_char="2278">preprint</TOKEN>
<TOKEN end_char="2289" id="token-16-17" morph="none" pos="word" start_char="2287">and</TOKEN>
<TOKEN end_char="2296" id="token-16-18" morph="none" pos="word" start_char="2291">stated</TOKEN>
<TOKEN end_char="2301" id="token-16-19" morph="none" pos="word" start_char="2298">that</TOKEN>
<TOKEN end_char="2305" id="token-16-20" morph="none" pos="word" start_char="2303">the</TOKEN>
<TOKEN end_char="2317" id="token-16-21" morph="none" pos="word" start_char="2307">scientist’s</TOKEN>
<TOKEN end_char="2324" id="token-16-22" morph="none" pos="word" start_char="2319">tweets</TOKEN>
<TOKEN end_char="2334" id="token-16-23" morph="none" pos="word" start_char="2326">suggested</TOKEN>
<TOKEN end_char="2339" id="token-16-24" morph="none" pos="word" start_char="2336">that</TOKEN>
<TOKEN end_char="2343" id="token-16-25" morph="none" pos="word" start_char="2341">the</TOKEN>
<TOKEN end_char="2349" id="token-16-26" morph="none" pos="word" start_char="2345">virus</TOKEN>
<TOKEN end_char="2351" id="token-16-27" morph="none" pos="punct" start_char="2351">"</TOKEN>
<TOKEN end_char="2356" id="token-16-28" morph="none" pos="word" start_char="2352">might</TOKEN>
<TOKEN end_char="2361" id="token-16-29" morph="none" pos="word" start_char="2358">have</TOKEN>
<TOKEN end_char="2366" id="token-16-30" morph="none" pos="word" start_char="2363">been</TOKEN>
<TOKEN end_char="2378" id="token-16-31" morph="none" pos="word" start_char="2368">genetically</TOKEN>
<TOKEN end_char="2389" id="token-16-32" morph="none" pos="word" start_char="2380">engineered</TOKEN>
<TOKEN end_char="2393" id="token-16-33" morph="none" pos="word" start_char="2391">for</TOKEN>
<TOKEN end_char="2397" id="token-16-34" morph="none" pos="word" start_char="2395">the</TOKEN>
<TOKEN end_char="2406" id="token-16-35" morph="none" pos="word" start_char="2399">purposes</TOKEN>
<TOKEN end_char="2409" id="token-16-36" morph="none" pos="word" start_char="2408">of</TOKEN>
<TOKEN end_char="2411" id="token-16-37" morph="none" pos="word" start_char="2411">a</TOKEN>
<TOKEN end_char="2418" id="token-16-38" morph="none" pos="word" start_char="2413">weapon</TOKEN>
<TOKEN end_char="2420" id="token-16-39" morph="none" pos="punct" start_char="2419">."</TOKEN>
</SEG>
<SEG end_char="2620" id="segment-17" start_char="2423">
<ORIGINAL_TEXT>ZeroHedge is a website that we’ve written about before, including for spreading the false idea that the new coronavirus was stolen from a lab in Canada and then weaponized by the Chinese government.</ORIGINAL_TEXT>
<TOKEN end_char="2431" id="token-17-0" morph="none" pos="word" start_char="2423">ZeroHedge</TOKEN>
<TOKEN end_char="2434" id="token-17-1" morph="none" pos="word" start_char="2433">is</TOKEN>
<TOKEN end_char="2436" id="token-17-2" morph="none" pos="word" start_char="2436">a</TOKEN>
<TOKEN end_char="2444" id="token-17-3" morph="none" pos="word" start_char="2438">website</TOKEN>
<TOKEN end_char="2449" id="token-17-4" morph="none" pos="word" start_char="2446">that</TOKEN>
<TOKEN end_char="2455" id="token-17-5" morph="none" pos="word" start_char="2451">we’ve</TOKEN>
<TOKEN end_char="2463" id="token-17-6" morph="none" pos="word" start_char="2457">written</TOKEN>
<TOKEN end_char="2469" id="token-17-7" morph="none" pos="word" start_char="2465">about</TOKEN>
<TOKEN end_char="2476" id="token-17-8" morph="none" pos="word" start_char="2471">before</TOKEN>
<TOKEN end_char="2477" id="token-17-9" morph="none" pos="punct" start_char="2477">,</TOKEN>
<TOKEN end_char="2487" id="token-17-10" morph="none" pos="word" start_char="2479">including</TOKEN>
<TOKEN end_char="2491" id="token-17-11" morph="none" pos="word" start_char="2489">for</TOKEN>
<TOKEN end_char="2501" id="token-17-12" morph="none" pos="word" start_char="2493">spreading</TOKEN>
<TOKEN end_char="2505" id="token-17-13" morph="none" pos="word" start_char="2503">the</TOKEN>
<TOKEN end_char="2511" id="token-17-14" morph="none" pos="word" start_char="2507">false</TOKEN>
<TOKEN end_char="2516" id="token-17-15" morph="none" pos="word" start_char="2513">idea</TOKEN>
<TOKEN end_char="2521" id="token-17-16" morph="none" pos="word" start_char="2518">that</TOKEN>
<TOKEN end_char="2525" id="token-17-17" morph="none" pos="word" start_char="2523">the</TOKEN>
<TOKEN end_char="2529" id="token-17-18" morph="none" pos="word" start_char="2527">new</TOKEN>
<TOKEN end_char="2541" id="token-17-19" morph="none" pos="word" start_char="2531">coronavirus</TOKEN>
<TOKEN end_char="2545" id="token-17-20" morph="none" pos="word" start_char="2543">was</TOKEN>
<TOKEN end_char="2552" id="token-17-21" morph="none" pos="word" start_char="2547">stolen</TOKEN>
<TOKEN end_char="2557" id="token-17-22" morph="none" pos="word" start_char="2554">from</TOKEN>
<TOKEN end_char="2559" id="token-17-23" morph="none" pos="word" start_char="2559">a</TOKEN>
<TOKEN end_char="2563" id="token-17-24" morph="none" pos="word" start_char="2561">lab</TOKEN>
<TOKEN end_char="2566" id="token-17-25" morph="none" pos="word" start_char="2565">in</TOKEN>
<TOKEN end_char="2573" id="token-17-26" morph="none" pos="word" start_char="2568">Canada</TOKEN>
<TOKEN end_char="2577" id="token-17-27" morph="none" pos="word" start_char="2575">and</TOKEN>
<TOKEN end_char="2582" id="token-17-28" morph="none" pos="word" start_char="2579">then</TOKEN>
<TOKEN end_char="2593" id="token-17-29" morph="none" pos="word" start_char="2584">weaponized</TOKEN>
<TOKEN end_char="2596" id="token-17-30" morph="none" pos="word" start_char="2595">by</TOKEN>
<TOKEN end_char="2600" id="token-17-31" morph="none" pos="word" start_char="2598">the</TOKEN>
<TOKEN end_char="2608" id="token-17-32" morph="none" pos="word" start_char="2602">Chinese</TOKEN>
<TOKEN end_char="2619" id="token-17-33" morph="none" pos="word" start_char="2610">government</TOKEN>
<TOKEN end_char="2620" id="token-17-34" morph="none" pos="punct" start_char="2620">.</TOKEN>
</SEG>
<SEG end_char="2931" id="segment-18" start_char="2623">
<ORIGINAL_TEXT>Originally published the same day of the preprint, the ZeroHedge article was updated the following day to include tweets from the Harvard visiting scientist, who by then had seen some of the criticisms of the preprint and was now advocating for additional studies to be done before jumping to any conclusions.</ORIGINAL_TEXT>
<TOKEN end_char="2632" id="token-18-0" morph="none" pos="word" start_char="2623">Originally</TOKEN>
<TOKEN end_char="2642" id="token-18-1" morph="none" pos="word" start_char="2634">published</TOKEN>
<TOKEN end_char="2646" id="token-18-2" morph="none" pos="word" start_char="2644">the</TOKEN>
<TOKEN end_char="2651" id="token-18-3" morph="none" pos="word" start_char="2648">same</TOKEN>
<TOKEN end_char="2655" id="token-18-4" morph="none" pos="word" start_char="2653">day</TOKEN>
<TOKEN end_char="2658" id="token-18-5" morph="none" pos="word" start_char="2657">of</TOKEN>
<TOKEN end_char="2662" id="token-18-6" morph="none" pos="word" start_char="2660">the</TOKEN>
<TOKEN end_char="2671" id="token-18-7" morph="none" pos="word" start_char="2664">preprint</TOKEN>
<TOKEN end_char="2672" id="token-18-8" morph="none" pos="punct" start_char="2672">,</TOKEN>
<TOKEN end_char="2676" id="token-18-9" morph="none" pos="word" start_char="2674">the</TOKEN>
<TOKEN end_char="2686" id="token-18-10" morph="none" pos="word" start_char="2678">ZeroHedge</TOKEN>
<TOKEN end_char="2694" id="token-18-11" morph="none" pos="word" start_char="2688">article</TOKEN>
<TOKEN end_char="2698" id="token-18-12" morph="none" pos="word" start_char="2696">was</TOKEN>
<TOKEN end_char="2706" id="token-18-13" morph="none" pos="word" start_char="2700">updated</TOKEN>
<TOKEN end_char="2710" id="token-18-14" morph="none" pos="word" start_char="2708">the</TOKEN>
<TOKEN end_char="2720" id="token-18-15" morph="none" pos="word" start_char="2712">following</TOKEN>
<TOKEN end_char="2724" id="token-18-16" morph="none" pos="word" start_char="2722">day</TOKEN>
<TOKEN end_char="2727" id="token-18-17" morph="none" pos="word" start_char="2726">to</TOKEN>
<TOKEN end_char="2735" id="token-18-18" morph="none" pos="word" start_char="2729">include</TOKEN>
<TOKEN end_char="2742" id="token-18-19" morph="none" pos="word" start_char="2737">tweets</TOKEN>
<TOKEN end_char="2747" id="token-18-20" morph="none" pos="word" start_char="2744">from</TOKEN>
<TOKEN end_char="2751" id="token-18-21" morph="none" pos="word" start_char="2749">the</TOKEN>
<TOKEN end_char="2759" id="token-18-22" morph="none" pos="word" start_char="2753">Harvard</TOKEN>
<TOKEN end_char="2768" id="token-18-23" morph="none" pos="word" start_char="2761">visiting</TOKEN>
<TOKEN end_char="2778" id="token-18-24" morph="none" pos="word" start_char="2770">scientist</TOKEN>
<TOKEN end_char="2779" id="token-18-25" morph="none" pos="punct" start_char="2779">,</TOKEN>
<TOKEN end_char="2783" id="token-18-26" morph="none" pos="word" start_char="2781">who</TOKEN>
<TOKEN end_char="2786" id="token-18-27" morph="none" pos="word" start_char="2785">by</TOKEN>
<TOKEN end_char="2791" id="token-18-28" morph="none" pos="word" start_char="2788">then</TOKEN>
<TOKEN end_char="2795" id="token-18-29" morph="none" pos="word" start_char="2793">had</TOKEN>
<TOKEN end_char="2800" id="token-18-30" morph="none" pos="word" start_char="2797">seen</TOKEN>
<TOKEN end_char="2805" id="token-18-31" morph="none" pos="word" start_char="2802">some</TOKEN>
<TOKEN end_char="2808" id="token-18-32" morph="none" pos="word" start_char="2807">of</TOKEN>
<TOKEN end_char="2812" id="token-18-33" morph="none" pos="word" start_char="2810">the</TOKEN>
<TOKEN end_char="2823" id="token-18-34" morph="none" pos="word" start_char="2814">criticisms</TOKEN>
<TOKEN end_char="2826" id="token-18-35" morph="none" pos="word" start_char="2825">of</TOKEN>
<TOKEN end_char="2830" id="token-18-36" morph="none" pos="word" start_char="2828">the</TOKEN>
<TOKEN end_char="2839" id="token-18-37" morph="none" pos="word" start_char="2832">preprint</TOKEN>
<TOKEN end_char="2843" id="token-18-38" morph="none" pos="word" start_char="2841">and</TOKEN>
<TOKEN end_char="2847" id="token-18-39" morph="none" pos="word" start_char="2845">was</TOKEN>
<TOKEN end_char="2851" id="token-18-40" morph="none" pos="word" start_char="2849">now</TOKEN>
<TOKEN end_char="2862" id="token-18-41" morph="none" pos="word" start_char="2853">advocating</TOKEN>
<TOKEN end_char="2866" id="token-18-42" morph="none" pos="word" start_char="2864">for</TOKEN>
<TOKEN end_char="2877" id="token-18-43" morph="none" pos="word" start_char="2868">additional</TOKEN>
<TOKEN end_char="2885" id="token-18-44" morph="none" pos="word" start_char="2879">studies</TOKEN>
<TOKEN end_char="2888" id="token-18-45" morph="none" pos="word" start_char="2887">to</TOKEN>
<TOKEN end_char="2891" id="token-18-46" morph="none" pos="word" start_char="2890">be</TOKEN>
<TOKEN end_char="2896" id="token-18-47" morph="none" pos="word" start_char="2893">done</TOKEN>
<TOKEN end_char="2903" id="token-18-48" morph="none" pos="word" start_char="2898">before</TOKEN>
<TOKEN end_char="2911" id="token-18-49" morph="none" pos="word" start_char="2905">jumping</TOKEN>
<TOKEN end_char="2914" id="token-18-50" morph="none" pos="word" start_char="2913">to</TOKEN>
<TOKEN end_char="2918" id="token-18-51" morph="none" pos="word" start_char="2916">any</TOKEN>
<TOKEN end_char="2930" id="token-18-52" morph="none" pos="word" start_char="2920">conclusions</TOKEN>
<TOKEN end_char="2931" id="token-18-53" morph="none" pos="punct" start_char="2931">.</TOKEN>
</SEG>
<SEG end_char="3089" id="segment-19" start_char="2933">
<ORIGINAL_TEXT>The Harvard scientist, it should be said, is an epidemiologist, health economist and nutritionist, and does not have expertise in virology or bioinformatics.</ORIGINAL_TEXT>
<TOKEN end_char="2935" id="token-19-0" morph="none" pos="word" start_char="2933">The</TOKEN>
<TOKEN end_char="2943" id="token-19-1" morph="none" pos="word" start_char="2937">Harvard</TOKEN>
<TOKEN end_char="2953" id="token-19-2" morph="none" pos="word" start_char="2945">scientist</TOKEN>
<TOKEN end_char="2954" id="token-19-3" morph="none" pos="punct" start_char="2954">,</TOKEN>
<TOKEN end_char="2957" id="token-19-4" morph="none" pos="word" start_char="2956">it</TOKEN>
<TOKEN end_char="2964" id="token-19-5" morph="none" pos="word" start_char="2959">should</TOKEN>
<TOKEN end_char="2967" id="token-19-6" morph="none" pos="word" start_char="2966">be</TOKEN>
<TOKEN end_char="2972" id="token-19-7" morph="none" pos="word" start_char="2969">said</TOKEN>
<TOKEN end_char="2973" id="token-19-8" morph="none" pos="punct" start_char="2973">,</TOKEN>
<TOKEN end_char="2976" id="token-19-9" morph="none" pos="word" start_char="2975">is</TOKEN>
<TOKEN end_char="2979" id="token-19-10" morph="none" pos="word" start_char="2978">an</TOKEN>
<TOKEN end_char="2994" id="token-19-11" morph="none" pos="word" start_char="2981">epidemiologist</TOKEN>
<TOKEN end_char="2995" id="token-19-12" morph="none" pos="punct" start_char="2995">,</TOKEN>
<TOKEN end_char="3002" id="token-19-13" morph="none" pos="word" start_char="2997">health</TOKEN>
<TOKEN end_char="3012" id="token-19-14" morph="none" pos="word" start_char="3004">economist</TOKEN>
<TOKEN end_char="3016" id="token-19-15" morph="none" pos="word" start_char="3014">and</TOKEN>
<TOKEN end_char="3029" id="token-19-16" morph="none" pos="word" start_char="3018">nutritionist</TOKEN>
<TOKEN end_char="3030" id="token-19-17" morph="none" pos="punct" start_char="3030">,</TOKEN>
<TOKEN end_char="3034" id="token-19-18" morph="none" pos="word" start_char="3032">and</TOKEN>
<TOKEN end_char="3039" id="token-19-19" morph="none" pos="word" start_char="3036">does</TOKEN>
<TOKEN end_char="3043" id="token-19-20" morph="none" pos="word" start_char="3041">not</TOKEN>
<TOKEN end_char="3048" id="token-19-21" morph="none" pos="word" start_char="3045">have</TOKEN>
<TOKEN end_char="3058" id="token-19-22" morph="none" pos="word" start_char="3050">expertise</TOKEN>
<TOKEN end_char="3061" id="token-19-23" morph="none" pos="word" start_char="3060">in</TOKEN>
<TOKEN end_char="3070" id="token-19-24" morph="none" pos="word" start_char="3063">virology</TOKEN>
<TOKEN end_char="3073" id="token-19-25" morph="none" pos="word" start_char="3072">or</TOKEN>
<TOKEN end_char="3088" id="token-19-26" morph="none" pos="word" start_char="3075">bioinformatics</TOKEN>
<TOKEN end_char="3089" id="token-19-27" morph="none" pos="punct" start_char="3089">.</TOKEN>
</SEG>
<SEG end_char="3142" id="segment-20" start_char="3091">
<ORIGINAL_TEXT>The bulk of the article, however, remains unchanged.</ORIGINAL_TEXT>
<TOKEN end_char="3093" id="token-20-0" morph="none" pos="word" start_char="3091">The</TOKEN>
<TOKEN end_char="3098" id="token-20-1" morph="none" pos="word" start_char="3095">bulk</TOKEN>
<TOKEN end_char="3101" id="token-20-2" morph="none" pos="word" start_char="3100">of</TOKEN>
<TOKEN end_char="3105" id="token-20-3" morph="none" pos="word" start_char="3103">the</TOKEN>
<TOKEN end_char="3113" id="token-20-4" morph="none" pos="word" start_char="3107">article</TOKEN>
<TOKEN end_char="3114" id="token-20-5" morph="none" pos="punct" start_char="3114">,</TOKEN>
<TOKEN end_char="3122" id="token-20-6" morph="none" pos="word" start_char="3116">however</TOKEN>
<TOKEN end_char="3123" id="token-20-7" morph="none" pos="punct" start_char="3123">,</TOKEN>
<TOKEN end_char="3131" id="token-20-8" morph="none" pos="word" start_char="3125">remains</TOKEN>
<TOKEN end_char="3141" id="token-20-9" morph="none" pos="word" start_char="3133">unchanged</TOKEN>
<TOKEN end_char="3142" id="token-20-10" morph="none" pos="punct" start_char="3142">.</TOKEN>
</SEG>
<SEG end_char="3298" id="segment-21" start_char="3145">
<ORIGINAL_TEXT>Well after the preprint was withdrawn, a website that traffics in vaccine misinformation, Health Impact News, also highlighted the invalid HIV connection.</ORIGINAL_TEXT>
<TOKEN end_char="3148" id="token-21-0" morph="none" pos="word" start_char="3145">Well</TOKEN>
<TOKEN end_char="3154" id="token-21-1" morph="none" pos="word" start_char="3150">after</TOKEN>
<TOKEN end_char="3158" id="token-21-2" morph="none" pos="word" start_char="3156">the</TOKEN>
<TOKEN end_char="3167" id="token-21-3" morph="none" pos="word" start_char="3160">preprint</TOKEN>
<TOKEN end_char="3171" id="token-21-4" morph="none" pos="word" start_char="3169">was</TOKEN>
<TOKEN end_char="3181" id="token-21-5" morph="none" pos="word" start_char="3173">withdrawn</TOKEN>
<TOKEN end_char="3182" id="token-21-6" morph="none" pos="punct" start_char="3182">,</TOKEN>
<TOKEN end_char="3184" id="token-21-7" morph="none" pos="word" start_char="3184">a</TOKEN>
<TOKEN end_char="3192" id="token-21-8" morph="none" pos="word" start_char="3186">website</TOKEN>
<TOKEN end_char="3197" id="token-21-9" morph="none" pos="word" start_char="3194">that</TOKEN>
<TOKEN end_char="3206" id="token-21-10" morph="none" pos="word" start_char="3199">traffics</TOKEN>
<TOKEN end_char="3209" id="token-21-11" morph="none" pos="word" start_char="3208">in</TOKEN>
<TOKEN end_char="3217" id="token-21-12" morph="none" pos="word" start_char="3211">vaccine</TOKEN>
<TOKEN end_char="3232" id="token-21-13" morph="none" pos="word" start_char="3219">misinformation</TOKEN>
<TOKEN end_char="3233" id="token-21-14" morph="none" pos="punct" start_char="3233">,</TOKEN>
<TOKEN end_char="3240" id="token-21-15" morph="none" pos="word" start_char="3235">Health</TOKEN>
<TOKEN end_char="3247" id="token-21-16" morph="none" pos="word" start_char="3242">Impact</TOKEN>
<TOKEN end_char="3252" id="token-21-17" morph="none" pos="word" start_char="3249">News</TOKEN>
<TOKEN end_char="3253" id="token-21-18" morph="none" pos="punct" start_char="3253">,</TOKEN>
<TOKEN end_char="3258" id="token-21-19" morph="none" pos="word" start_char="3255">also</TOKEN>
<TOKEN end_char="3270" id="token-21-20" morph="none" pos="word" start_char="3260">highlighted</TOKEN>
<TOKEN end_char="3274" id="token-21-21" morph="none" pos="word" start_char="3272">the</TOKEN>
<TOKEN end_char="3282" id="token-21-22" morph="none" pos="word" start_char="3276">invalid</TOKEN>
<TOKEN end_char="3286" id="token-21-23" morph="none" pos="word" start_char="3284">HIV</TOKEN>
<TOKEN end_char="3297" id="token-21-24" morph="none" pos="word" start_char="3288">connection</TOKEN>
<TOKEN end_char="3298" id="token-21-25" morph="none" pos="punct" start_char="3298">.</TOKEN>
</SEG>
<SEG end_char="3576" id="segment-22" start_char="3301">
<ORIGINAL_TEXT>Separately, a blogger posted a different bogus analysis — also making the rounds on Facebook — that posits a portion of the new coronavirus genome is similar to part of a viral vector that was used in previous research on the severe acute respiratory syndrome, or SARS, virus.</ORIGINAL_TEXT>
<TOKEN end_char="3310" id="token-22-0" morph="none" pos="word" start_char="3301">Separately</TOKEN>
<TOKEN end_char="3311" id="token-22-1" morph="none" pos="punct" start_char="3311">,</TOKEN>
<TOKEN end_char="3313" id="token-22-2" morph="none" pos="word" start_char="3313">a</TOKEN>
<TOKEN end_char="3321" id="token-22-3" morph="none" pos="word" start_char="3315">blogger</TOKEN>
<TOKEN end_char="3328" id="token-22-4" morph="none" pos="word" start_char="3323">posted</TOKEN>
<TOKEN end_char="3330" id="token-22-5" morph="none" pos="word" start_char="3330">a</TOKEN>
<TOKEN end_char="3340" id="token-22-6" morph="none" pos="word" start_char="3332">different</TOKEN>
<TOKEN end_char="3346" id="token-22-7" morph="none" pos="word" start_char="3342">bogus</TOKEN>
<TOKEN end_char="3355" id="token-22-8" morph="none" pos="word" start_char="3348">analysis</TOKEN>
<TOKEN end_char="3357" id="token-22-9" morph="none" pos="punct" start_char="3357">—</TOKEN>
<TOKEN end_char="3362" id="token-22-10" morph="none" pos="word" start_char="3359">also</TOKEN>
<TOKEN end_char="3369" id="token-22-11" morph="none" pos="word" start_char="3364">making</TOKEN>
<TOKEN end_char="3373" id="token-22-12" morph="none" pos="word" start_char="3371">the</TOKEN>
<TOKEN end_char="3380" id="token-22-13" morph="none" pos="word" start_char="3375">rounds</TOKEN>
<TOKEN end_char="3383" id="token-22-14" morph="none" pos="word" start_char="3382">on</TOKEN>
<TOKEN end_char="3392" id="token-22-15" morph="none" pos="word" start_char="3385">Facebook</TOKEN>
<TOKEN end_char="3394" id="token-22-16" morph="none" pos="punct" start_char="3394">—</TOKEN>
<TOKEN end_char="3399" id="token-22-17" morph="none" pos="word" start_char="3396">that</TOKEN>
<TOKEN end_char="3406" id="token-22-18" morph="none" pos="word" start_char="3401">posits</TOKEN>
<TOKEN end_char="3408" id="token-22-19" morph="none" pos="word" start_char="3408">a</TOKEN>
<TOKEN end_char="3416" id="token-22-20" morph="none" pos="word" start_char="3410">portion</TOKEN>
<TOKEN end_char="3419" id="token-22-21" morph="none" pos="word" start_char="3418">of</TOKEN>
<TOKEN end_char="3423" id="token-22-22" morph="none" pos="word" start_char="3421">the</TOKEN>
<TOKEN end_char="3427" id="token-22-23" morph="none" pos="word" start_char="3425">new</TOKEN>
<TOKEN end_char="3439" id="token-22-24" morph="none" pos="word" start_char="3429">coronavirus</TOKEN>
<TOKEN end_char="3446" id="token-22-25" morph="none" pos="word" start_char="3441">genome</TOKEN>
<TOKEN end_char="3449" id="token-22-26" morph="none" pos="word" start_char="3448">is</TOKEN>
<TOKEN end_char="3457" id="token-22-27" morph="none" pos="word" start_char="3451">similar</TOKEN>
<TOKEN end_char="3460" id="token-22-28" morph="none" pos="word" start_char="3459">to</TOKEN>
<TOKEN end_char="3465" id="token-22-29" morph="none" pos="word" start_char="3462">part</TOKEN>
<TOKEN end_char="3468" id="token-22-30" morph="none" pos="word" start_char="3467">of</TOKEN>
<TOKEN end_char="3470" id="token-22-31" morph="none" pos="word" start_char="3470">a</TOKEN>
<TOKEN end_char="3476" id="token-22-32" morph="none" pos="word" start_char="3472">viral</TOKEN>
<TOKEN end_char="3483" id="token-22-33" morph="none" pos="word" start_char="3478">vector</TOKEN>
<TOKEN end_char="3488" id="token-22-34" morph="none" pos="word" start_char="3485">that</TOKEN>
<TOKEN end_char="3492" id="token-22-35" morph="none" pos="word" start_char="3490">was</TOKEN>
<TOKEN end_char="3497" id="token-22-36" morph="none" pos="word" start_char="3494">used</TOKEN>
<TOKEN end_char="3500" id="token-22-37" morph="none" pos="word" start_char="3499">in</TOKEN>
<TOKEN end_char="3509" id="token-22-38" morph="none" pos="word" start_char="3502">previous</TOKEN>
<TOKEN end_char="3518" id="token-22-39" morph="none" pos="word" start_char="3511">research</TOKEN>
<TOKEN end_char="3521" id="token-22-40" morph="none" pos="word" start_char="3520">on</TOKEN>
<TOKEN end_char="3525" id="token-22-41" morph="none" pos="word" start_char="3523">the</TOKEN>
<TOKEN end_char="3532" id="token-22-42" morph="none" pos="word" start_char="3527">severe</TOKEN>
<TOKEN end_char="3538" id="token-22-43" morph="none" pos="word" start_char="3534">acute</TOKEN>
<TOKEN end_char="3550" id="token-22-44" morph="none" pos="word" start_char="3540">respiratory</TOKEN>
<TOKEN end_char="3559" id="token-22-45" morph="none" pos="word" start_char="3552">syndrome</TOKEN>
<TOKEN end_char="3560" id="token-22-46" morph="none" pos="punct" start_char="3560">,</TOKEN>
<TOKEN end_char="3563" id="token-22-47" morph="none" pos="word" start_char="3562">or</TOKEN>
<TOKEN end_char="3568" id="token-22-48" morph="none" pos="word" start_char="3565">SARS</TOKEN>
<TOKEN end_char="3569" id="token-22-49" morph="none" pos="punct" start_char="3569">,</TOKEN>
<TOKEN end_char="3575" id="token-22-50" morph="none" pos="word" start_char="3571">virus</TOKEN>
<TOKEN end_char="3576" id="token-22-51" morph="none" pos="punct" start_char="3576">.</TOKEN>
</SEG>
<SEG end_char="3687" id="segment-23" start_char="3578">
<ORIGINAL_TEXT>Based on this, the author argues that the new virus could have leaked from a Chinese lab working on a vaccine.</ORIGINAL_TEXT>
<TOKEN end_char="3582" id="token-23-0" morph="none" pos="word" start_char="3578">Based</TOKEN>
<TOKEN end_char="3585" id="token-23-1" morph="none" pos="word" start_char="3584">on</TOKEN>
<TOKEN end_char="3590" id="token-23-2" morph="none" pos="word" start_char="3587">this</TOKEN>
<TOKEN end_char="3591" id="token-23-3" morph="none" pos="punct" start_char="3591">,</TOKEN>
<TOKEN end_char="3595" id="token-23-4" morph="none" pos="word" start_char="3593">the</TOKEN>
<TOKEN end_char="3602" id="token-23-5" morph="none" pos="word" start_char="3597">author</TOKEN>
<TOKEN end_char="3609" id="token-23-6" morph="none" pos="word" start_char="3604">argues</TOKEN>
<TOKEN end_char="3614" id="token-23-7" morph="none" pos="word" start_char="3611">that</TOKEN>
<TOKEN end_char="3618" id="token-23-8" morph="none" pos="word" start_char="3616">the</TOKEN>
<TOKEN end_char="3622" id="token-23-9" morph="none" pos="word" start_char="3620">new</TOKEN>
<TOKEN end_char="3628" id="token-23-10" morph="none" pos="word" start_char="3624">virus</TOKEN>
<TOKEN end_char="3634" id="token-23-11" morph="none" pos="word" start_char="3630">could</TOKEN>
<TOKEN end_char="3639" id="token-23-12" morph="none" pos="word" start_char="3636">have</TOKEN>
<TOKEN end_char="3646" id="token-23-13" morph="none" pos="word" start_char="3641">leaked</TOKEN>
<TOKEN end_char="3651" id="token-23-14" morph="none" pos="word" start_char="3648">from</TOKEN>
<TOKEN end_char="3653" id="token-23-15" morph="none" pos="word" start_char="3653">a</TOKEN>
<TOKEN end_char="3661" id="token-23-16" morph="none" pos="word" start_char="3655">Chinese</TOKEN>
<TOKEN end_char="3665" id="token-23-17" morph="none" pos="word" start_char="3663">lab</TOKEN>
<TOKEN end_char="3673" id="token-23-18" morph="none" pos="word" start_char="3667">working</TOKEN>
<TOKEN end_char="3676" id="token-23-19" morph="none" pos="word" start_char="3675">on</TOKEN>
<TOKEN end_char="3678" id="token-23-20" morph="none" pos="word" start_char="3678">a</TOKEN>
<TOKEN end_char="3686" id="token-23-21" morph="none" pos="word" start_char="3680">vaccine</TOKEN>
<TOKEN end_char="3687" id="token-23-22" morph="none" pos="punct" start_char="3687">.</TOKEN>
</SEG>
<SEG end_char="3779" id="segment-24" start_char="3689">
<ORIGINAL_TEXT>The SARS virus caused a global outbreak in 2003 and is similar but distinct from 2019-nCoV.</ORIGINAL_TEXT>
<TOKEN end_char="3691" id="token-24-0" morph="none" pos="word" start_char="3689">The</TOKEN>
<TOKEN end_char="3696" id="token-24-1" morph="none" pos="word" start_char="3693">SARS</TOKEN>
<TOKEN end_char="3702" id="token-24-2" morph="none" pos="word" start_char="3698">virus</TOKEN>
<TOKEN end_char="3709" id="token-24-3" morph="none" pos="word" start_char="3704">caused</TOKEN>
<TOKEN end_char="3711" id="token-24-4" morph="none" pos="word" start_char="3711">a</TOKEN>
<TOKEN end_char="3718" id="token-24-5" morph="none" pos="word" start_char="3713">global</TOKEN>
<TOKEN end_char="3727" id="token-24-6" morph="none" pos="word" start_char="3720">outbreak</TOKEN>
<TOKEN end_char="3730" id="token-24-7" morph="none" pos="word" start_char="3729">in</TOKEN>
<TOKEN end_char="3735" id="token-24-8" morph="none" pos="word" start_char="3732">2003</TOKEN>
<TOKEN end_char="3739" id="token-24-9" morph="none" pos="word" start_char="3737">and</TOKEN>
<TOKEN end_char="3742" id="token-24-10" morph="none" pos="word" start_char="3741">is</TOKEN>
<TOKEN end_char="3750" id="token-24-11" morph="none" pos="word" start_char="3744">similar</TOKEN>
<TOKEN end_char="3754" id="token-24-12" morph="none" pos="word" start_char="3752">but</TOKEN>
<TOKEN end_char="3763" id="token-24-13" morph="none" pos="word" start_char="3756">distinct</TOKEN>
<TOKEN end_char="3768" id="token-24-14" morph="none" pos="word" start_char="3765">from</TOKEN>
<TOKEN end_char="3778" id="token-24-15" morph="none" pos="unknown" start_char="3770">2019-nCoV</TOKEN>
<TOKEN end_char="3779" id="token-24-16" morph="none" pos="punct" start_char="3779">.</TOKEN>
</SEG>
<SEG end_char="3960" id="segment-25" start_char="3782">
<ORIGINAL_TEXT>Alex Jones, the conspiracy theorist behind InfoWars and the false idea that the Sandy Hook school shooting in 2012 was a hoax, also waded into the coronavirus misinformation pool.</ORIGINAL_TEXT>
<TOKEN end_char="3785" id="token-25-0" morph="none" pos="word" start_char="3782">Alex</TOKEN>
<TOKEN end_char="3791" id="token-25-1" morph="none" pos="word" start_char="3787">Jones</TOKEN>
<TOKEN end_char="3792" id="token-25-2" morph="none" pos="punct" start_char="3792">,</TOKEN>
<TOKEN end_char="3796" id="token-25-3" morph="none" pos="word" start_char="3794">the</TOKEN>
<TOKEN end_char="3807" id="token-25-4" morph="none" pos="word" start_char="3798">conspiracy</TOKEN>
<TOKEN end_char="3816" id="token-25-5" morph="none" pos="word" start_char="3809">theorist</TOKEN>
<TOKEN end_char="3823" id="token-25-6" morph="none" pos="word" start_char="3818">behind</TOKEN>
<TOKEN end_char="3832" id="token-25-7" morph="none" pos="word" start_char="3825">InfoWars</TOKEN>
<TOKEN end_char="3836" id="token-25-8" morph="none" pos="word" start_char="3834">and</TOKEN>
<TOKEN end_char="3840" id="token-25-9" morph="none" pos="word" start_char="3838">the</TOKEN>
<TOKEN end_char="3846" id="token-25-10" morph="none" pos="word" start_char="3842">false</TOKEN>
<TOKEN end_char="3851" id="token-25-11" morph="none" pos="word" start_char="3848">idea</TOKEN>
<TOKEN end_char="3856" id="token-25-12" morph="none" pos="word" start_char="3853">that</TOKEN>
<TOKEN end_char="3860" id="token-25-13" morph="none" pos="word" start_char="3858">the</TOKEN>
<TOKEN end_char="3866" id="token-25-14" morph="none" pos="word" start_char="3862">Sandy</TOKEN>
<TOKEN end_char="3871" id="token-25-15" morph="none" pos="word" start_char="3868">Hook</TOKEN>
<TOKEN end_char="3878" id="token-25-16" morph="none" pos="word" start_char="3873">school</TOKEN>
<TOKEN end_char="3887" id="token-25-17" morph="none" pos="word" start_char="3880">shooting</TOKEN>
<TOKEN end_char="3890" id="token-25-18" morph="none" pos="word" start_char="3889">in</TOKEN>
<TOKEN end_char="3895" id="token-25-19" morph="none" pos="word" start_char="3892">2012</TOKEN>
<TOKEN end_char="3899" id="token-25-20" morph="none" pos="word" start_char="3897">was</TOKEN>
<TOKEN end_char="3901" id="token-25-21" morph="none" pos="word" start_char="3901">a</TOKEN>
<TOKEN end_char="3906" id="token-25-22" morph="none" pos="word" start_char="3903">hoax</TOKEN>
<TOKEN end_char="3907" id="token-25-23" morph="none" pos="punct" start_char="3907">,</TOKEN>
<TOKEN end_char="3912" id="token-25-24" morph="none" pos="word" start_char="3909">also</TOKEN>
<TOKEN end_char="3918" id="token-25-25" morph="none" pos="word" start_char="3914">waded</TOKEN>
<TOKEN end_char="3923" id="token-25-26" morph="none" pos="word" start_char="3920">into</TOKEN>
<TOKEN end_char="3927" id="token-25-27" morph="none" pos="word" start_char="3925">the</TOKEN>
<TOKEN end_char="3939" id="token-25-28" morph="none" pos="word" start_char="3929">coronavirus</TOKEN>
<TOKEN end_char="3954" id="token-25-29" morph="none" pos="word" start_char="3941">misinformation</TOKEN>
<TOKEN end_char="3959" id="token-25-30" morph="none" pos="word" start_char="3956">pool</TOKEN>
<TOKEN end_char="3960" id="token-25-31" morph="none" pos="punct" start_char="3960">.</TOKEN>
</SEG>
<SEG end_char="4115" id="segment-26" start_char="3962">
<ORIGINAL_TEXT>Multiple episodes of his talk show address both of these groundless theories and claim there is evidence that "proves" the new coronavirus was "man-made."</ORIGINAL_TEXT>
<TOKEN end_char="3969" id="token-26-0" morph="none" pos="word" start_char="3962">Multiple</TOKEN>
<TOKEN end_char="3978" id="token-26-1" morph="none" pos="word" start_char="3971">episodes</TOKEN>
<TOKEN end_char="3981" id="token-26-2" morph="none" pos="word" start_char="3980">of</TOKEN>
<TOKEN end_char="3985" id="token-26-3" morph="none" pos="word" start_char="3983">his</TOKEN>
<TOKEN end_char="3990" id="token-26-4" morph="none" pos="word" start_char="3987">talk</TOKEN>
<TOKEN end_char="3995" id="token-26-5" morph="none" pos="word" start_char="3992">show</TOKEN>
<TOKEN end_char="4003" id="token-26-6" morph="none" pos="word" start_char="3997">address</TOKEN>
<TOKEN end_char="4008" id="token-26-7" morph="none" pos="word" start_char="4005">both</TOKEN>
<TOKEN end_char="4011" id="token-26-8" morph="none" pos="word" start_char="4010">of</TOKEN>
<TOKEN end_char="4017" id="token-26-9" morph="none" pos="word" start_char="4013">these</TOKEN>
<TOKEN end_char="4028" id="token-26-10" morph="none" pos="word" start_char="4019">groundless</TOKEN>
<TOKEN end_char="4037" id="token-26-11" morph="none" pos="word" start_char="4030">theories</TOKEN>
<TOKEN end_char="4041" id="token-26-12" morph="none" pos="word" start_char="4039">and</TOKEN>
<TOKEN end_char="4047" id="token-26-13" morph="none" pos="word" start_char="4043">claim</TOKEN>
<TOKEN end_char="4053" id="token-26-14" morph="none" pos="word" start_char="4049">there</TOKEN>
<TOKEN end_char="4056" id="token-26-15" morph="none" pos="word" start_char="4055">is</TOKEN>
<TOKEN end_char="4065" id="token-26-16" morph="none" pos="word" start_char="4058">evidence</TOKEN>
<TOKEN end_char="4070" id="token-26-17" morph="none" pos="word" start_char="4067">that</TOKEN>
<TOKEN end_char="4072" id="token-26-18" morph="none" pos="punct" start_char="4072">"</TOKEN>
<TOKEN end_char="4078" id="token-26-19" morph="none" pos="word" start_char="4073">proves</TOKEN>
<TOKEN end_char="4079" id="token-26-20" morph="none" pos="punct" start_char="4079">"</TOKEN>
<TOKEN end_char="4083" id="token-26-21" morph="none" pos="word" start_char="4081">the</TOKEN>
<TOKEN end_char="4087" id="token-26-22" morph="none" pos="word" start_char="4085">new</TOKEN>
<TOKEN end_char="4099" id="token-26-23" morph="none" pos="word" start_char="4089">coronavirus</TOKEN>
<TOKEN end_char="4103" id="token-26-24" morph="none" pos="word" start_char="4101">was</TOKEN>
<TOKEN end_char="4105" id="token-26-25" morph="none" pos="punct" start_char="4105">"</TOKEN>
<TOKEN end_char="4113" id="token-26-26" morph="none" pos="unknown" start_char="4106">man-made</TOKEN>
<TOKEN end_char="4115" id="token-26-27" morph="none" pos="punct" start_char="4114">."</TOKEN>
</SEG>
<SEG end_char="4204" id="segment-27" start_char="4118">
<ORIGINAL_TEXT>Scientists with expertise in viral genomics, however, say that no such evidence exists.</ORIGINAL_TEXT>
<TOKEN end_char="4127" id="token-27-0" morph="none" pos="word" start_char="4118">Scientists</TOKEN>
<TOKEN end_char="4132" id="token-27-1" morph="none" pos="word" start_char="4129">with</TOKEN>
<TOKEN end_char="4142" id="token-27-2" morph="none" pos="word" start_char="4134">expertise</TOKEN>
<TOKEN end_char="4145" id="token-27-3" morph="none" pos="word" start_char="4144">in</TOKEN>
<TOKEN end_char="4151" id="token-27-4" morph="none" pos="word" start_char="4147">viral</TOKEN>
<TOKEN end_char="4160" id="token-27-5" morph="none" pos="word" start_char="4153">genomics</TOKEN>
<TOKEN end_char="4161" id="token-27-6" morph="none" pos="punct" start_char="4161">,</TOKEN>
<TOKEN end_char="4169" id="token-27-7" morph="none" pos="word" start_char="4163">however</TOKEN>
<TOKEN end_char="4170" id="token-27-8" morph="none" pos="punct" start_char="4170">,</TOKEN>
<TOKEN end_char="4174" id="token-27-9" morph="none" pos="word" start_char="4172">say</TOKEN>
<TOKEN end_char="4179" id="token-27-10" morph="none" pos="word" start_char="4176">that</TOKEN>
<TOKEN end_char="4182" id="token-27-11" morph="none" pos="word" start_char="4181">no</TOKEN>
<TOKEN end_char="4187" id="token-27-12" morph="none" pos="word" start_char="4184">such</TOKEN>
<TOKEN end_char="4196" id="token-27-13" morph="none" pos="word" start_char="4189">evidence</TOKEN>
<TOKEN end_char="4203" id="token-27-14" morph="none" pos="word" start_char="4198">exists</TOKEN>
<TOKEN end_char="4204" id="token-27-15" morph="none" pos="punct" start_char="4204">.</TOKEN>
</SEG>
<SEG end_char="4393" id="segment-28" start_char="4206">
<ORIGINAL_TEXT>Kristian Andersen, the director of infectious disease genomics at the Scripps Research Translational Institute, told us in an email that in both cases, the analyses are "completely wrong."</ORIGINAL_TEXT>
<TOKEN end_char="4213" id="token-28-0" morph="none" pos="word" start_char="4206">Kristian</TOKEN>
<TOKEN end_char="4222" id="token-28-1" morph="none" pos="word" start_char="4215">Andersen</TOKEN>
<TOKEN end_char="4223" id="token-28-2" morph="none" pos="punct" start_char="4223">,</TOKEN>
<TOKEN end_char="4227" id="token-28-3" morph="none" pos="word" start_char="4225">the</TOKEN>
<TOKEN end_char="4236" id="token-28-4" morph="none" pos="word" start_char="4229">director</TOKEN>
<TOKEN end_char="4239" id="token-28-5" morph="none" pos="word" start_char="4238">of</TOKEN>
<TOKEN end_char="4250" id="token-28-6" morph="none" pos="word" start_char="4241">infectious</TOKEN>
<TOKEN end_char="4258" id="token-28-7" morph="none" pos="word" start_char="4252">disease</TOKEN>
<TOKEN end_char="4267" id="token-28-8" morph="none" pos="word" start_char="4260">genomics</TOKEN>
<TOKEN end_char="4270" id="token-28-9" morph="none" pos="word" start_char="4269">at</TOKEN>
<TOKEN end_char="4274" id="token-28-10" morph="none" pos="word" start_char="4272">the</TOKEN>
<TOKEN end_char="4282" id="token-28-11" morph="none" pos="word" start_char="4276">Scripps</TOKEN>
<TOKEN end_char="4291" id="token-28-12" morph="none" pos="word" start_char="4284">Research</TOKEN>
<TOKEN end_char="4305" id="token-28-13" morph="none" pos="word" start_char="4293">Translational</TOKEN>
<TOKEN end_char="4315" id="token-28-14" morph="none" pos="word" start_char="4307">Institute</TOKEN>
<TOKEN end_char="4316" id="token-28-15" morph="none" pos="punct" start_char="4316">,</TOKEN>
<TOKEN end_char="4321" id="token-28-16" morph="none" pos="word" start_char="4318">told</TOKEN>
<TOKEN end_char="4324" id="token-28-17" morph="none" pos="word" start_char="4323">us</TOKEN>
<TOKEN end_char="4327" id="token-28-18" morph="none" pos="word" start_char="4326">in</TOKEN>
<TOKEN end_char="4330" id="token-28-19" morph="none" pos="word" start_char="4329">an</TOKEN>
<TOKEN end_char="4336" id="token-28-20" morph="none" pos="word" start_char="4332">email</TOKEN>
<TOKEN end_char="4341" id="token-28-21" morph="none" pos="word" start_char="4338">that</TOKEN>
<TOKEN end_char="4344" id="token-28-22" morph="none" pos="word" start_char="4343">in</TOKEN>
<TOKEN end_char="4349" id="token-28-23" morph="none" pos="word" start_char="4346">both</TOKEN>
<TOKEN end_char="4355" id="token-28-24" morph="none" pos="word" start_char="4351">cases</TOKEN>
<TOKEN end_char="4356" id="token-28-25" morph="none" pos="punct" start_char="4356">,</TOKEN>
<TOKEN end_char="4360" id="token-28-26" morph="none" pos="word" start_char="4358">the</TOKEN>
<TOKEN end_char="4369" id="token-28-27" morph="none" pos="word" start_char="4362">analyses</TOKEN>
<TOKEN end_char="4373" id="token-28-28" morph="none" pos="word" start_char="4371">are</TOKEN>
<TOKEN end_char="4375" id="token-28-29" morph="none" pos="punct" start_char="4375">"</TOKEN>
<TOKEN end_char="4385" id="token-28-30" morph="none" pos="word" start_char="4376">completely</TOKEN>
<TOKEN end_char="4391" id="token-28-31" morph="none" pos="word" start_char="4387">wrong</TOKEN>
<TOKEN end_char="4393" id="token-28-32" morph="none" pos="punct" start_char="4392">."</TOKEN>
</SEG>
<SEG end_char="4523" id="segment-29" start_char="4396">
<ORIGINAL_TEXT>The HIV study, he said, was a "misunderstanding of how to perform these types of analyses" that also cherry-picked its findings.</ORIGINAL_TEXT>
<TOKEN end_char="4398" id="token-29-0" morph="none" pos="word" start_char="4396">The</TOKEN>
<TOKEN end_char="4402" id="token-29-1" morph="none" pos="word" start_char="4400">HIV</TOKEN>
<TOKEN end_char="4408" id="token-29-2" morph="none" pos="word" start_char="4404">study</TOKEN>
<TOKEN end_char="4409" id="token-29-3" morph="none" pos="punct" start_char="4409">,</TOKEN>
<TOKEN end_char="4412" id="token-29-4" morph="none" pos="word" start_char="4411">he</TOKEN>
<TOKEN end_char="4417" id="token-29-5" morph="none" pos="word" start_char="4414">said</TOKEN>
<TOKEN end_char="4418" id="token-29-6" morph="none" pos="punct" start_char="4418">,</TOKEN>
<TOKEN end_char="4422" id="token-29-7" morph="none" pos="word" start_char="4420">was</TOKEN>
<TOKEN end_char="4424" id="token-29-8" morph="none" pos="word" start_char="4424">a</TOKEN>
<TOKEN end_char="4426" id="token-29-9" morph="none" pos="punct" start_char="4426">"</TOKEN>
<TOKEN end_char="4442" id="token-29-10" morph="none" pos="word" start_char="4427">misunderstanding</TOKEN>
<TOKEN end_char="4445" id="token-29-11" morph="none" pos="word" start_char="4444">of</TOKEN>
<TOKEN end_char="4449" id="token-29-12" morph="none" pos="word" start_char="4447">how</TOKEN>
<TOKEN end_char="4452" id="token-29-13" morph="none" pos="word" start_char="4451">to</TOKEN>
<TOKEN end_char="4460" id="token-29-14" morph="none" pos="word" start_char="4454">perform</TOKEN>
<TOKEN end_char="4466" id="token-29-15" morph="none" pos="word" start_char="4462">these</TOKEN>
<TOKEN end_char="4472" id="token-29-16" morph="none" pos="word" start_char="4468">types</TOKEN>
<TOKEN end_char="4475" id="token-29-17" morph="none" pos="word" start_char="4474">of</TOKEN>
<TOKEN end_char="4484" id="token-29-18" morph="none" pos="word" start_char="4477">analyses</TOKEN>
<TOKEN end_char="4485" id="token-29-19" morph="none" pos="punct" start_char="4485">"</TOKEN>
<TOKEN end_char="4490" id="token-29-20" morph="none" pos="word" start_char="4487">that</TOKEN>
<TOKEN end_char="4495" id="token-29-21" morph="none" pos="word" start_char="4492">also</TOKEN>
<TOKEN end_char="4509" id="token-29-22" morph="none" pos="unknown" start_char="4497">cherry-picked</TOKEN>
<TOKEN end_char="4513" id="token-29-23" morph="none" pos="word" start_char="4511">its</TOKEN>
<TOKEN end_char="4522" id="token-29-24" morph="none" pos="word" start_char="4515">findings</TOKEN>
<TOKEN end_char="4523" id="token-29-25" morph="none" pos="punct" start_char="4523">.</TOKEN>
</SEG>
<SEG end_char="4693" id="segment-30" start_char="4525">
<ORIGINAL_TEXT>The short proteins the Indian scientists found to be similar to HIV are not from HIV at all, Andersen said, but are the result of the natural evolution of coronaviruses.</ORIGINAL_TEXT>
<TOKEN end_char="4527" id="token-30-0" morph="none" pos="word" start_char="4525">The</TOKEN>
<TOKEN end_char="4533" id="token-30-1" morph="none" pos="word" start_char="4529">short</TOKEN>
<TOKEN end_char="4542" id="token-30-2" morph="none" pos="word" start_char="4535">proteins</TOKEN>
<TOKEN end_char="4546" id="token-30-3" morph="none" pos="word" start_char="4544">the</TOKEN>
<TOKEN end_char="4553" id="token-30-4" morph="none" pos="word" start_char="4548">Indian</TOKEN>
<TOKEN end_char="4564" id="token-30-5" morph="none" pos="word" start_char="4555">scientists</TOKEN>
<TOKEN end_char="4570" id="token-30-6" morph="none" pos="word" start_char="4566">found</TOKEN>
<TOKEN end_char="4573" id="token-30-7" morph="none" pos="word" start_char="4572">to</TOKEN>
<TOKEN end_char="4576" id="token-30-8" morph="none" pos="word" start_char="4575">be</TOKEN>
<TOKEN end_char="4584" id="token-30-9" morph="none" pos="word" start_char="4578">similar</TOKEN>
<TOKEN end_char="4587" id="token-30-10" morph="none" pos="word" start_char="4586">to</TOKEN>
<TOKEN end_char="4591" id="token-30-11" morph="none" pos="word" start_char="4589">HIV</TOKEN>
<TOKEN end_char="4595" id="token-30-12" morph="none" pos="word" start_char="4593">are</TOKEN>
<TOKEN end_char="4599" id="token-30-13" morph="none" pos="word" start_char="4597">not</TOKEN>
<TOKEN end_char="4604" id="token-30-14" morph="none" pos="word" start_char="4601">from</TOKEN>
<TOKEN end_char="4608" id="token-30-15" morph="none" pos="word" start_char="4606">HIV</TOKEN>
<TOKEN end_char="4611" id="token-30-16" morph="none" pos="word" start_char="4610">at</TOKEN>
<TOKEN end_char="4615" id="token-30-17" morph="none" pos="word" start_char="4613">all</TOKEN>
<TOKEN end_char="4616" id="token-30-18" morph="none" pos="punct" start_char="4616">,</TOKEN>
<TOKEN end_char="4625" id="token-30-19" morph="none" pos="word" start_char="4618">Andersen</TOKEN>
<TOKEN end_char="4630" id="token-30-20" morph="none" pos="word" start_char="4627">said</TOKEN>
<TOKEN end_char="4631" id="token-30-21" morph="none" pos="punct" start_char="4631">,</TOKEN>
<TOKEN end_char="4635" id="token-30-22" morph="none" pos="word" start_char="4633">but</TOKEN>
<TOKEN end_char="4639" id="token-30-23" morph="none" pos="word" start_char="4637">are</TOKEN>
<TOKEN end_char="4643" id="token-30-24" morph="none" pos="word" start_char="4641">the</TOKEN>
<TOKEN end_char="4650" id="token-30-25" morph="none" pos="word" start_char="4645">result</TOKEN>
<TOKEN end_char="4653" id="token-30-26" morph="none" pos="word" start_char="4652">of</TOKEN>
<TOKEN end_char="4657" id="token-30-27" morph="none" pos="word" start_char="4655">the</TOKEN>
<TOKEN end_char="4665" id="token-30-28" morph="none" pos="word" start_char="4659">natural</TOKEN>
<TOKEN end_char="4675" id="token-30-29" morph="none" pos="word" start_char="4667">evolution</TOKEN>
<TOKEN end_char="4678" id="token-30-30" morph="none" pos="word" start_char="4677">of</TOKEN>
<TOKEN end_char="4692" id="token-30-31" morph="none" pos="word" start_char="4680">coronaviruses</TOKEN>
<TOKEN end_char="4693" id="token-30-32" morph="none" pos="punct" start_char="4693">.</TOKEN>
</SEG>
<SEG end_char="4914" id="segment-31" start_char="4695">
<ORIGINAL_TEXT>"Had the authors compared nCoV to related bat viruses (and not just SARS as they did)," he wrote, "they would have realized that the peptides are also present in the bat viruses — and most certainly don’t come from HIV."</ORIGINAL_TEXT>
<TOKEN end_char="4695" id="token-31-0" morph="none" pos="punct" start_char="4695">"</TOKEN>
<TOKEN end_char="4698" id="token-31-1" morph="none" pos="word" start_char="4696">Had</TOKEN>
<TOKEN end_char="4702" id="token-31-2" morph="none" pos="word" start_char="4700">the</TOKEN>
<TOKEN end_char="4710" id="token-31-3" morph="none" pos="word" start_char="4704">authors</TOKEN>
<TOKEN end_char="4719" id="token-31-4" morph="none" pos="word" start_char="4712">compared</TOKEN>
<TOKEN end_char="4724" id="token-31-5" morph="none" pos="word" start_char="4721">nCoV</TOKEN>
<TOKEN end_char="4727" id="token-31-6" morph="none" pos="word" start_char="4726">to</TOKEN>
<TOKEN end_char="4735" id="token-31-7" morph="none" pos="word" start_char="4729">related</TOKEN>
<TOKEN end_char="4739" id="token-31-8" morph="none" pos="word" start_char="4737">bat</TOKEN>
<TOKEN end_char="4747" id="token-31-9" morph="none" pos="word" start_char="4741">viruses</TOKEN>
<TOKEN end_char="4749" id="token-31-10" morph="none" pos="punct" start_char="4749">(</TOKEN>
<TOKEN end_char="4752" id="token-31-11" morph="none" pos="word" start_char="4750">and</TOKEN>
<TOKEN end_char="4756" id="token-31-12" morph="none" pos="word" start_char="4754">not</TOKEN>
<TOKEN end_char="4761" id="token-31-13" morph="none" pos="word" start_char="4758">just</TOKEN>
<TOKEN end_char="4766" id="token-31-14" morph="none" pos="word" start_char="4763">SARS</TOKEN>
<TOKEN end_char="4769" id="token-31-15" morph="none" pos="word" start_char="4768">as</TOKEN>
<TOKEN end_char="4774" id="token-31-16" morph="none" pos="word" start_char="4771">they</TOKEN>
<TOKEN end_char="4778" id="token-31-17" morph="none" pos="word" start_char="4776">did</TOKEN>
<TOKEN end_char="4781" id="token-31-18" morph="none" pos="punct" start_char="4779">),"</TOKEN>
<TOKEN end_char="4784" id="token-31-19" morph="none" pos="word" start_char="4783">he</TOKEN>
<TOKEN end_char="4790" id="token-31-20" morph="none" pos="word" start_char="4786">wrote</TOKEN>
<TOKEN end_char="4791" id="token-31-21" morph="none" pos="punct" start_char="4791">,</TOKEN>
<TOKEN end_char="4793" id="token-31-22" morph="none" pos="punct" start_char="4793">"</TOKEN>
<TOKEN end_char="4797" id="token-31-23" morph="none" pos="word" start_char="4794">they</TOKEN>
<TOKEN end_char="4803" id="token-31-24" morph="none" pos="word" start_char="4799">would</TOKEN>
<TOKEN end_char="4808" id="token-31-25" morph="none" pos="word" start_char="4805">have</TOKEN>
<TOKEN end_char="4817" id="token-31-26" morph="none" pos="word" start_char="4810">realized</TOKEN>
<TOKEN end_char="4822" id="token-31-27" morph="none" pos="word" start_char="4819">that</TOKEN>
<TOKEN end_char="4826" id="token-31-28" morph="none" pos="word" start_char="4824">the</TOKEN>
<TOKEN end_char="4835" id="token-31-29" morph="none" pos="word" start_char="4828">peptides</TOKEN>
<TOKEN end_char="4839" id="token-31-30" morph="none" pos="word" start_char="4837">are</TOKEN>
<TOKEN end_char="4844" id="token-31-31" morph="none" pos="word" start_char="4841">also</TOKEN>
<TOKEN end_char="4852" id="token-31-32" morph="none" pos="word" start_char="4846">present</TOKEN>
<TOKEN end_char="4855" id="token-31-33" morph="none" pos="word" start_char="4854">in</TOKEN>
<TOKEN end_char="4859" id="token-31-34" morph="none" pos="word" start_char="4857">the</TOKEN>
<TOKEN end_char="4863" id="token-31-35" morph="none" pos="word" start_char="4861">bat</TOKEN>
<TOKEN end_char="4871" id="token-31-36" morph="none" pos="word" start_char="4865">viruses</TOKEN>
<TOKEN end_char="4873" id="token-31-37" morph="none" pos="punct" start_char="4873">—</TOKEN>
<TOKEN end_char="4877" id="token-31-38" morph="none" pos="word" start_char="4875">and</TOKEN>
<TOKEN end_char="4882" id="token-31-39" morph="none" pos="word" start_char="4879">most</TOKEN>
<TOKEN end_char="4892" id="token-31-40" morph="none" pos="word" start_char="4884">certainly</TOKEN>
<TOKEN end_char="4898" id="token-31-41" morph="none" pos="word" start_char="4894">don’t</TOKEN>
<TOKEN end_char="4903" id="token-31-42" morph="none" pos="word" start_char="4900">come</TOKEN>
<TOKEN end_char="4908" id="token-31-43" morph="none" pos="word" start_char="4905">from</TOKEN>
<TOKEN end_char="4912" id="token-31-44" morph="none" pos="word" start_char="4910">HIV</TOKEN>
<TOKEN end_char="4914" id="token-31-45" morph="none" pos="punct" start_char="4913">."</TOKEN>
</SEG>
<SEG end_char="5170" id="segment-32" start_char="4917">
<ORIGINAL_TEXT>Indeed, other experts have noted the same shortcomings, including Trevor Bedford, a computational biologist at the Fred Hutchinson Cancer Research Center in Seattle, who performed the proper sequence alignments and shared the results in a Twitter thread.</ORIGINAL_TEXT>
<TOKEN end_char="4922" id="token-32-0" morph="none" pos="word" start_char="4917">Indeed</TOKEN>
<TOKEN end_char="4923" id="token-32-1" morph="none" pos="punct" start_char="4923">,</TOKEN>
<TOKEN end_char="4929" id="token-32-2" morph="none" pos="word" start_char="4925">other</TOKEN>
<TOKEN end_char="4937" id="token-32-3" morph="none" pos="word" start_char="4931">experts</TOKEN>
<TOKEN end_char="4942" id="token-32-4" morph="none" pos="word" start_char="4939">have</TOKEN>
<TOKEN end_char="4948" id="token-32-5" morph="none" pos="word" start_char="4944">noted</TOKEN>
<TOKEN end_char="4952" id="token-32-6" morph="none" pos="word" start_char="4950">the</TOKEN>
<TOKEN end_char="4957" id="token-32-7" morph="none" pos="word" start_char="4954">same</TOKEN>
<TOKEN end_char="4970" id="token-32-8" morph="none" pos="word" start_char="4959">shortcomings</TOKEN>
<TOKEN end_char="4971" id="token-32-9" morph="none" pos="punct" start_char="4971">,</TOKEN>
<TOKEN end_char="4981" id="token-32-10" morph="none" pos="word" start_char="4973">including</TOKEN>
<TOKEN end_char="4988" id="token-32-11" morph="none" pos="word" start_char="4983">Trevor</TOKEN>
<TOKEN end_char="4996" id="token-32-12" morph="none" pos="word" start_char="4990">Bedford</TOKEN>
<TOKEN end_char="4997" id="token-32-13" morph="none" pos="punct" start_char="4997">,</TOKEN>
<TOKEN end_char="4999" id="token-32-14" morph="none" pos="word" start_char="4999">a</TOKEN>
<TOKEN end_char="5013" id="token-32-15" morph="none" pos="word" start_char="5001">computational</TOKEN>
<TOKEN end_char="5023" id="token-32-16" morph="none" pos="word" start_char="5015">biologist</TOKEN>
<TOKEN end_char="5026" id="token-32-17" morph="none" pos="word" start_char="5025">at</TOKEN>
<TOKEN end_char="5030" id="token-32-18" morph="none" pos="word" start_char="5028">the</TOKEN>
<TOKEN end_char="5035" id="token-32-19" morph="none" pos="word" start_char="5032">Fred</TOKEN>
<TOKEN end_char="5046" id="token-32-20" morph="none" pos="word" start_char="5037">Hutchinson</TOKEN>
<TOKEN end_char="5053" id="token-32-21" morph="none" pos="word" start_char="5048">Cancer</TOKEN>
<TOKEN end_char="5062" id="token-32-22" morph="none" pos="word" start_char="5055">Research</TOKEN>
<TOKEN end_char="5069" id="token-32-23" morph="none" pos="word" start_char="5064">Center</TOKEN>
<TOKEN end_char="5072" id="token-32-24" morph="none" pos="word" start_char="5071">in</TOKEN>
<TOKEN end_char="5080" id="token-32-25" morph="none" pos="word" start_char="5074">Seattle</TOKEN>
<TOKEN end_char="5081" id="token-32-26" morph="none" pos="punct" start_char="5081">,</TOKEN>
<TOKEN end_char="5085" id="token-32-27" morph="none" pos="word" start_char="5083">who</TOKEN>
<TOKEN end_char="5095" id="token-32-28" morph="none" pos="word" start_char="5087">performed</TOKEN>
<TOKEN end_char="5099" id="token-32-29" morph="none" pos="word" start_char="5097">the</TOKEN>
<TOKEN end_char="5106" id="token-32-30" morph="none" pos="word" start_char="5101">proper</TOKEN>
<TOKEN end_char="5115" id="token-32-31" morph="none" pos="word" start_char="5108">sequence</TOKEN>
<TOKEN end_char="5126" id="token-32-32" morph="none" pos="word" start_char="5117">alignments</TOKEN>
<TOKEN end_char="5130" id="token-32-33" morph="none" pos="word" start_char="5128">and</TOKEN>
<TOKEN end_char="5137" id="token-32-34" morph="none" pos="word" start_char="5132">shared</TOKEN>
<TOKEN end_char="5141" id="token-32-35" morph="none" pos="word" start_char="5139">the</TOKEN>
<TOKEN end_char="5149" id="token-32-36" morph="none" pos="word" start_char="5143">results</TOKEN>
<TOKEN end_char="5152" id="token-32-37" morph="none" pos="word" start_char="5151">in</TOKEN>
<TOKEN end_char="5154" id="token-32-38" morph="none" pos="word" start_char="5154">a</TOKEN>
<TOKEN end_char="5162" id="token-32-39" morph="none" pos="word" start_char="5156">Twitter</TOKEN>
<TOKEN end_char="5169" id="token-32-40" morph="none" pos="word" start_char="5164">thread</TOKEN>
<TOKEN end_char="5170" id="token-32-41" morph="none" pos="punct" start_char="5170">.</TOKEN>
</SEG>
<SEG end_char="5323" id="segment-33" start_char="5172">
<ORIGINAL_TEXT>He found that all of the so-called "insertions" appear in a bat virus identified from a cave in Yunnan, China — or were artifacts of improper alignment.</ORIGINAL_TEXT>
<TOKEN end_char="5173" id="token-33-0" morph="none" pos="word" start_char="5172">He</TOKEN>
<TOKEN end_char="5179" id="token-33-1" morph="none" pos="word" start_char="5175">found</TOKEN>
<TOKEN end_char="5184" id="token-33-2" morph="none" pos="word" start_char="5181">that</TOKEN>
<TOKEN end_char="5188" id="token-33-3" morph="none" pos="word" start_char="5186">all</TOKEN>
<TOKEN end_char="5191" id="token-33-4" morph="none" pos="word" start_char="5190">of</TOKEN>
<TOKEN end_char="5195" id="token-33-5" morph="none" pos="word" start_char="5193">the</TOKEN>
<TOKEN end_char="5205" id="token-33-6" morph="none" pos="unknown" start_char="5197">so-called</TOKEN>
<TOKEN end_char="5207" id="token-33-7" morph="none" pos="punct" start_char="5207">"</TOKEN>
<TOKEN end_char="5217" id="token-33-8" morph="none" pos="word" start_char="5208">insertions</TOKEN>
<TOKEN end_char="5218" id="token-33-9" morph="none" pos="punct" start_char="5218">"</TOKEN>
<TOKEN end_char="5225" id="token-33-10" morph="none" pos="word" start_char="5220">appear</TOKEN>
<TOKEN end_char="5228" id="token-33-11" morph="none" pos="word" start_char="5227">in</TOKEN>
<TOKEN end_char="5230" id="token-33-12" morph="none" pos="word" start_char="5230">a</TOKEN>
<TOKEN end_char="5234" id="token-33-13" morph="none" pos="word" start_char="5232">bat</TOKEN>
<TOKEN end_char="5240" id="token-33-14" morph="none" pos="word" start_char="5236">virus</TOKEN>
<TOKEN end_char="5251" id="token-33-15" morph="none" pos="word" start_char="5242">identified</TOKEN>
<TOKEN end_char="5256" id="token-33-16" morph="none" pos="word" start_char="5253">from</TOKEN>
<TOKEN end_char="5258" id="token-33-17" morph="none" pos="word" start_char="5258">a</TOKEN>
<TOKEN end_char="5263" id="token-33-18" morph="none" pos="word" start_char="5260">cave</TOKEN>
<TOKEN end_char="5266" id="token-33-19" morph="none" pos="word" start_char="5265">in</TOKEN>
<TOKEN end_char="5273" id="token-33-20" morph="none" pos="word" start_char="5268">Yunnan</TOKEN>
<TOKEN end_char="5274" id="token-33-21" morph="none" pos="punct" start_char="5274">,</TOKEN>
<TOKEN end_char="5280" id="token-33-22" morph="none" pos="word" start_char="5276">China</TOKEN>
<TOKEN end_char="5282" id="token-33-23" morph="none" pos="punct" start_char="5282">—</TOKEN>
<TOKEN end_char="5285" id="token-33-24" morph="none" pos="word" start_char="5284">or</TOKEN>
<TOKEN end_char="5290" id="token-33-25" morph="none" pos="word" start_char="5287">were</TOKEN>
<TOKEN end_char="5300" id="token-33-26" morph="none" pos="word" start_char="5292">artifacts</TOKEN>
<TOKEN end_char="5303" id="token-33-27" morph="none" pos="word" start_char="5302">of</TOKEN>
<TOKEN end_char="5312" id="token-33-28" morph="none" pos="word" start_char="5305">improper</TOKEN>
<TOKEN end_char="5322" id="token-33-29" morph="none" pos="word" start_char="5314">alignment</TOKEN>
<TOKEN end_char="5323" id="token-33-30" morph="none" pos="punct" start_char="5323">.</TOKEN>
</SEG>
<SEG end_char="5537" id="segment-34" start_char="5326">
<ORIGINAL_TEXT>Only one "insertion" is not fully shared with the bat virus, Bedford explained, and "in no way suggests engineering" since it is consistent with the types of insertions and deletions that happen in coronaviruses.</ORIGINAL_TEXT>
<TOKEN end_char="5329" id="token-34-0" morph="none" pos="word" start_char="5326">Only</TOKEN>
<TOKEN end_char="5333" id="token-34-1" morph="none" pos="word" start_char="5331">one</TOKEN>
<TOKEN end_char="5335" id="token-34-2" morph="none" pos="punct" start_char="5335">"</TOKEN>
<TOKEN end_char="5344" id="token-34-3" morph="none" pos="word" start_char="5336">insertion</TOKEN>
<TOKEN end_char="5345" id="token-34-4" morph="none" pos="punct" start_char="5345">"</TOKEN>
<TOKEN end_char="5348" id="token-34-5" morph="none" pos="word" start_char="5347">is</TOKEN>
<TOKEN end_char="5352" id="token-34-6" morph="none" pos="word" start_char="5350">not</TOKEN>
<TOKEN end_char="5358" id="token-34-7" morph="none" pos="word" start_char="5354">fully</TOKEN>
<TOKEN end_char="5365" id="token-34-8" morph="none" pos="word" start_char="5360">shared</TOKEN>
<TOKEN end_char="5370" id="token-34-9" morph="none" pos="word" start_char="5367">with</TOKEN>
<TOKEN end_char="5374" id="token-34-10" morph="none" pos="word" start_char="5372">the</TOKEN>
<TOKEN end_char="5378" id="token-34-11" morph="none" pos="word" start_char="5376">bat</TOKEN>
<TOKEN end_char="5384" id="token-34-12" morph="none" pos="word" start_char="5380">virus</TOKEN>
<TOKEN end_char="5385" id="token-34-13" morph="none" pos="punct" start_char="5385">,</TOKEN>
<TOKEN end_char="5393" id="token-34-14" morph="none" pos="word" start_char="5387">Bedford</TOKEN>
<TOKEN end_char="5403" id="token-34-15" morph="none" pos="word" start_char="5395">explained</TOKEN>
<TOKEN end_char="5404" id="token-34-16" morph="none" pos="punct" start_char="5404">,</TOKEN>
<TOKEN end_char="5408" id="token-34-17" morph="none" pos="word" start_char="5406">and</TOKEN>
<TOKEN end_char="5410" id="token-34-18" morph="none" pos="punct" start_char="5410">"</TOKEN>
<TOKEN end_char="5412" id="token-34-19" morph="none" pos="word" start_char="5411">in</TOKEN>
<TOKEN end_char="5415" id="token-34-20" morph="none" pos="word" start_char="5414">no</TOKEN>
<TOKEN end_char="5419" id="token-34-21" morph="none" pos="word" start_char="5417">way</TOKEN>
<TOKEN end_char="5428" id="token-34-22" morph="none" pos="word" start_char="5421">suggests</TOKEN>
<TOKEN end_char="5440" id="token-34-23" morph="none" pos="word" start_char="5430">engineering</TOKEN>
<TOKEN end_char="5441" id="token-34-24" morph="none" pos="punct" start_char="5441">"</TOKEN>
<TOKEN end_char="5447" id="token-34-25" morph="none" pos="word" start_char="5443">since</TOKEN>
<TOKEN end_char="5450" id="token-34-26" morph="none" pos="word" start_char="5449">it</TOKEN>
<TOKEN end_char="5453" id="token-34-27" morph="none" pos="word" start_char="5452">is</TOKEN>
<TOKEN end_char="5464" id="token-34-28" morph="none" pos="word" start_char="5455">consistent</TOKEN>
<TOKEN end_char="5469" id="token-34-29" morph="none" pos="word" start_char="5466">with</TOKEN>
<TOKEN end_char="5473" id="token-34-30" morph="none" pos="word" start_char="5471">the</TOKEN>
<TOKEN end_char="5479" id="token-34-31" morph="none" pos="word" start_char="5475">types</TOKEN>
<TOKEN end_char="5482" id="token-34-32" morph="none" pos="word" start_char="5481">of</TOKEN>
<TOKEN end_char="5493" id="token-34-33" morph="none" pos="word" start_char="5484">insertions</TOKEN>
<TOKEN end_char="5497" id="token-34-34" morph="none" pos="word" start_char="5495">and</TOKEN>
<TOKEN end_char="5507" id="token-34-35" morph="none" pos="word" start_char="5499">deletions</TOKEN>
<TOKEN end_char="5512" id="token-34-36" morph="none" pos="word" start_char="5509">that</TOKEN>
<TOKEN end_char="5519" id="token-34-37" morph="none" pos="word" start_char="5514">happen</TOKEN>
<TOKEN end_char="5522" id="token-34-38" morph="none" pos="word" start_char="5521">in</TOKEN>
<TOKEN end_char="5536" id="token-34-39" morph="none" pos="word" start_char="5524">coronaviruses</TOKEN>
<TOKEN end_char="5537" id="token-34-40" morph="none" pos="punct" start_char="5537">.</TOKEN>
</SEG>
<SEG end_char="5654" id="segment-35" start_char="5539">
<ORIGINAL_TEXT>"There is absolutely no evidence for either (1) sequence insertions or (2) their relationship to HIV," he concluded.</ORIGINAL_TEXT>
<TOKEN end_char="5539" id="token-35-0" morph="none" pos="punct" start_char="5539">"</TOKEN>
<TOKEN end_char="5544" id="token-35-1" morph="none" pos="word" start_char="5540">There</TOKEN>
<TOKEN end_char="5547" id="token-35-2" morph="none" pos="word" start_char="5546">is</TOKEN>
<TOKEN end_char="5558" id="token-35-3" morph="none" pos="word" start_char="5549">absolutely</TOKEN>
<TOKEN end_char="5561" id="token-35-4" morph="none" pos="word" start_char="5560">no</TOKEN>
<TOKEN end_char="5570" id="token-35-5" morph="none" pos="word" start_char="5563">evidence</TOKEN>
<TOKEN end_char="5574" id="token-35-6" morph="none" pos="word" start_char="5572">for</TOKEN>
<TOKEN end_char="5581" id="token-35-7" morph="none" pos="word" start_char="5576">either</TOKEN>
<TOKEN end_char="5583" id="token-35-8" morph="none" pos="punct" start_char="5583">(</TOKEN>
<TOKEN end_char="5584" id="token-35-9" morph="none" pos="word" start_char="5584">1</TOKEN>
<TOKEN end_char="5585" id="token-35-10" morph="none" pos="punct" start_char="5585">)</TOKEN>
<TOKEN end_char="5594" id="token-35-11" morph="none" pos="word" start_char="5587">sequence</TOKEN>
<TOKEN end_char="5605" id="token-35-12" morph="none" pos="word" start_char="5596">insertions</TOKEN>
<TOKEN end_char="5608" id="token-35-13" morph="none" pos="word" start_char="5607">or</TOKEN>
<TOKEN end_char="5610" id="token-35-14" morph="none" pos="punct" start_char="5610">(</TOKEN>
<TOKEN end_char="5611" id="token-35-15" morph="none" pos="word" start_char="5611">2</TOKEN>
<TOKEN end_char="5612" id="token-35-16" morph="none" pos="punct" start_char="5612">)</TOKEN>
<TOKEN end_char="5618" id="token-35-17" morph="none" pos="word" start_char="5614">their</TOKEN>
<TOKEN end_char="5631" id="token-35-18" morph="none" pos="word" start_char="5620">relationship</TOKEN>
<TOKEN end_char="5634" id="token-35-19" morph="none" pos="word" start_char="5633">to</TOKEN>
<TOKEN end_char="5638" id="token-35-20" morph="none" pos="word" start_char="5636">HIV</TOKEN>
<TOKEN end_char="5640" id="token-35-21" morph="none" pos="punct" start_char="5639">,"</TOKEN>
<TOKEN end_char="5643" id="token-35-22" morph="none" pos="word" start_char="5642">he</TOKEN>
<TOKEN end_char="5653" id="token-35-23" morph="none" pos="word" start_char="5645">concluded</TOKEN>
<TOKEN end_char="5654" id="token-35-24" morph="none" pos="punct" start_char="5654">.</TOKEN>
</SEG>
<SEG end_char="5811" id="segment-36" start_char="5657">
<ORIGINAL_TEXT>The blogger’s contention that the new coronavirus may have been engineered using a SARS viral vector, Andersen said, is "just as absurd" as the HIV theory.</ORIGINAL_TEXT>
<TOKEN end_char="5659" id="token-36-0" morph="none" pos="word" start_char="5657">The</TOKEN>
<TOKEN end_char="5669" id="token-36-1" morph="none" pos="word" start_char="5661">blogger’s</TOKEN>
<TOKEN end_char="5680" id="token-36-2" morph="none" pos="word" start_char="5671">contention</TOKEN>
<TOKEN end_char="5685" id="token-36-3" morph="none" pos="word" start_char="5682">that</TOKEN>
<TOKEN end_char="5689" id="token-36-4" morph="none" pos="word" start_char="5687">the</TOKEN>
<TOKEN end_char="5693" id="token-36-5" morph="none" pos="word" start_char="5691">new</TOKEN>
<TOKEN end_char="5705" id="token-36-6" morph="none" pos="word" start_char="5695">coronavirus</TOKEN>
<TOKEN end_char="5709" id="token-36-7" morph="none" pos="word" start_char="5707">may</TOKEN>
<TOKEN end_char="5714" id="token-36-8" morph="none" pos="word" start_char="5711">have</TOKEN>
<TOKEN end_char="5719" id="token-36-9" morph="none" pos="word" start_char="5716">been</TOKEN>
<TOKEN end_char="5730" id="token-36-10" morph="none" pos="word" start_char="5721">engineered</TOKEN>
<TOKEN end_char="5736" id="token-36-11" morph="none" pos="word" start_char="5732">using</TOKEN>
<TOKEN end_char="5738" id="token-36-12" morph="none" pos="word" start_char="5738">a</TOKEN>
<TOKEN end_char="5743" id="token-36-13" morph="none" pos="word" start_char="5740">SARS</TOKEN>
<TOKEN end_char="5749" id="token-36-14" morph="none" pos="word" start_char="5745">viral</TOKEN>
<TOKEN end_char="5756" id="token-36-15" morph="none" pos="word" start_char="5751">vector</TOKEN>
<TOKEN end_char="5757" id="token-36-16" morph="none" pos="punct" start_char="5757">,</TOKEN>
<TOKEN end_char="5766" id="token-36-17" morph="none" pos="word" start_char="5759">Andersen</TOKEN>
<TOKEN end_char="5771" id="token-36-18" morph="none" pos="word" start_char="5768">said</TOKEN>
<TOKEN end_char="5772" id="token-36-19" morph="none" pos="punct" start_char="5772">,</TOKEN>
<TOKEN end_char="5775" id="token-36-20" morph="none" pos="word" start_char="5774">is</TOKEN>
<TOKEN end_char="5777" id="token-36-21" morph="none" pos="punct" start_char="5777">"</TOKEN>
<TOKEN end_char="5781" id="token-36-22" morph="none" pos="word" start_char="5778">just</TOKEN>
<TOKEN end_char="5784" id="token-36-23" morph="none" pos="word" start_char="5783">as</TOKEN>
<TOKEN end_char="5791" id="token-36-24" morph="none" pos="word" start_char="5786">absurd</TOKEN>
<TOKEN end_char="5792" id="token-36-25" morph="none" pos="punct" start_char="5792">"</TOKEN>
<TOKEN end_char="5795" id="token-36-26" morph="none" pos="word" start_char="5794">as</TOKEN>
<TOKEN end_char="5799" id="token-36-27" morph="none" pos="word" start_char="5797">the</TOKEN>
<TOKEN end_char="5803" id="token-36-28" morph="none" pos="word" start_char="5801">HIV</TOKEN>
<TOKEN end_char="5810" id="token-36-29" morph="none" pos="word" start_char="5805">theory</TOKEN>
<TOKEN end_char="5811" id="token-36-30" morph="none" pos="punct" start_char="5811">.</TOKEN>
</SEG>
<SEG end_char="5924" id="segment-37" start_char="5813">
<ORIGINAL_TEXT>The vector, he said, was used to understand coronaviruses and develop vaccines — but is different from 2019nCoV.</ORIGINAL_TEXT>
<TOKEN end_char="5815" id="token-37-0" morph="none" pos="word" start_char="5813">The</TOKEN>
<TOKEN end_char="5822" id="token-37-1" morph="none" pos="word" start_char="5817">vector</TOKEN>
<TOKEN end_char="5823" id="token-37-2" morph="none" pos="punct" start_char="5823">,</TOKEN>
<TOKEN end_char="5826" id="token-37-3" morph="none" pos="word" start_char="5825">he</TOKEN>
<TOKEN end_char="5831" id="token-37-4" morph="none" pos="word" start_char="5828">said</TOKEN>
<TOKEN end_char="5832" id="token-37-5" morph="none" pos="punct" start_char="5832">,</TOKEN>
<TOKEN end_char="5836" id="token-37-6" morph="none" pos="word" start_char="5834">was</TOKEN>
<TOKEN end_char="5841" id="token-37-7" morph="none" pos="word" start_char="5838">used</TOKEN>
<TOKEN end_char="5844" id="token-37-8" morph="none" pos="word" start_char="5843">to</TOKEN>
<TOKEN end_char="5855" id="token-37-9" morph="none" pos="word" start_char="5846">understand</TOKEN>
<TOKEN end_char="5869" id="token-37-10" morph="none" pos="word" start_char="5857">coronaviruses</TOKEN>
<TOKEN end_char="5873" id="token-37-11" morph="none" pos="word" start_char="5871">and</TOKEN>
<TOKEN end_char="5881" id="token-37-12" morph="none" pos="word" start_char="5875">develop</TOKEN>
<TOKEN end_char="5890" id="token-37-13" morph="none" pos="word" start_char="5883">vaccines</TOKEN>
<TOKEN end_char="5892" id="token-37-14" morph="none" pos="punct" start_char="5892">—</TOKEN>
<TOKEN end_char="5896" id="token-37-15" morph="none" pos="word" start_char="5894">but</TOKEN>
<TOKEN end_char="5899" id="token-37-16" morph="none" pos="word" start_char="5898">is</TOKEN>
<TOKEN end_char="5909" id="token-37-17" morph="none" pos="word" start_char="5901">different</TOKEN>
<TOKEN end_char="5914" id="token-37-18" morph="none" pos="word" start_char="5911">from</TOKEN>
<TOKEN end_char="5923" id="token-37-19" morph="none" pos="word" start_char="5916">2019nCoV</TOKEN>
<TOKEN end_char="5924" id="token-37-20" morph="none" pos="punct" start_char="5924">.</TOKEN>
</SEG>
<SEG end_char="6054" id="segment-38" start_char="5927">
<ORIGINAL_TEXT>"While they’re similar (like worms and people are similar) there is absolutely no way that nCoV is in any way related," he said.</ORIGINAL_TEXT>
<TOKEN end_char="5927" id="token-38-0" morph="none" pos="punct" start_char="5927">"</TOKEN>
<TOKEN end_char="5932" id="token-38-1" morph="none" pos="word" start_char="5928">While</TOKEN>
<TOKEN end_char="5940" id="token-38-2" morph="none" pos="word" start_char="5934">they’re</TOKEN>
<TOKEN end_char="5948" id="token-38-3" morph="none" pos="word" start_char="5942">similar</TOKEN>
<TOKEN end_char="5950" id="token-38-4" morph="none" pos="punct" start_char="5950">(</TOKEN>
<TOKEN end_char="5954" id="token-38-5" morph="none" pos="word" start_char="5951">like</TOKEN>
<TOKEN end_char="5960" id="token-38-6" morph="none" pos="word" start_char="5956">worms</TOKEN>
<TOKEN end_char="5964" id="token-38-7" morph="none" pos="word" start_char="5962">and</TOKEN>
<TOKEN end_char="5971" id="token-38-8" morph="none" pos="word" start_char="5966">people</TOKEN>
<TOKEN end_char="5975" id="token-38-9" morph="none" pos="word" start_char="5973">are</TOKEN>
<TOKEN end_char="5983" id="token-38-10" morph="none" pos="word" start_char="5977">similar</TOKEN>
<TOKEN end_char="5984" id="token-38-11" morph="none" pos="punct" start_char="5984">)</TOKEN>
<TOKEN end_char="5990" id="token-38-12" morph="none" pos="word" start_char="5986">there</TOKEN>
<TOKEN end_char="5993" id="token-38-13" morph="none" pos="word" start_char="5992">is</TOKEN>
<TOKEN end_char="6004" id="token-38-14" morph="none" pos="word" start_char="5995">absolutely</TOKEN>
<TOKEN end_char="6007" id="token-38-15" morph="none" pos="word" start_char="6006">no</TOKEN>
<TOKEN end_char="6011" id="token-38-16" morph="none" pos="word" start_char="6009">way</TOKEN>
<TOKEN end_char="6016" id="token-38-17" morph="none" pos="word" start_char="6013">that</TOKEN>
<TOKEN end_char="6021" id="token-38-18" morph="none" pos="word" start_char="6018">nCoV</TOKEN>
<TOKEN end_char="6024" id="token-38-19" morph="none" pos="word" start_char="6023">is</TOKEN>
<TOKEN end_char="6027" id="token-38-20" morph="none" pos="word" start_char="6026">in</TOKEN>
<TOKEN end_char="6031" id="token-38-21" morph="none" pos="word" start_char="6029">any</TOKEN>
<TOKEN end_char="6035" id="token-38-22" morph="none" pos="word" start_char="6033">way</TOKEN>
<TOKEN end_char="6043" id="token-38-23" morph="none" pos="word" start_char="6037">related</TOKEN>
<TOKEN end_char="6045" id="token-38-24" morph="none" pos="punct" start_char="6044">,"</TOKEN>
<TOKEN end_char="6048" id="token-38-25" morph="none" pos="word" start_char="6047">he</TOKEN>
<TOKEN end_char="6053" id="token-38-26" morph="none" pos="word" start_char="6050">said</TOKEN>
<TOKEN end_char="6054" id="token-38-27" morph="none" pos="punct" start_char="6054">.</TOKEN>
</SEG>
<SEG end_char="6208" id="segment-39" start_char="6056">
<ORIGINAL_TEXT>"If one were to look at the two genomes side by side, it’s very easy to show that they’re obviously not the same — or that one somehow led to the other."</ORIGINAL_TEXT>
<TOKEN end_char="6056" id="token-39-0" morph="none" pos="punct" start_char="6056">"</TOKEN>
<TOKEN end_char="6058" id="token-39-1" morph="none" pos="word" start_char="6057">If</TOKEN>
<TOKEN end_char="6062" id="token-39-2" morph="none" pos="word" start_char="6060">one</TOKEN>
<TOKEN end_char="6067" id="token-39-3" morph="none" pos="word" start_char="6064">were</TOKEN>
<TOKEN end_char="6070" id="token-39-4" morph="none" pos="word" start_char="6069">to</TOKEN>
<TOKEN end_char="6075" id="token-39-5" morph="none" pos="word" start_char="6072">look</TOKEN>
<TOKEN end_char="6078" id="token-39-6" morph="none" pos="word" start_char="6077">at</TOKEN>
<TOKEN end_char="6082" id="token-39-7" morph="none" pos="word" start_char="6080">the</TOKEN>
<TOKEN end_char="6086" id="token-39-8" morph="none" pos="word" start_char="6084">two</TOKEN>
<TOKEN end_char="6094" id="token-39-9" morph="none" pos="word" start_char="6088">genomes</TOKEN>
<TOKEN end_char="6099" id="token-39-10" morph="none" pos="word" start_char="6096">side</TOKEN>
<TOKEN end_char="6102" id="token-39-11" morph="none" pos="word" start_char="6101">by</TOKEN>
<TOKEN end_char="6107" id="token-39-12" morph="none" pos="word" start_char="6104">side</TOKEN>
<TOKEN end_char="6108" id="token-39-13" morph="none" pos="punct" start_char="6108">,</TOKEN>
<TOKEN end_char="6113" id="token-39-14" morph="none" pos="word" start_char="6110">it’s</TOKEN>
<TOKEN end_char="6118" id="token-39-15" morph="none" pos="word" start_char="6115">very</TOKEN>
<TOKEN end_char="6123" id="token-39-16" morph="none" pos="word" start_char="6120">easy</TOKEN>
<TOKEN end_char="6126" id="token-39-17" morph="none" pos="word" start_char="6125">to</TOKEN>
<TOKEN end_char="6131" id="token-39-18" morph="none" pos="word" start_char="6128">show</TOKEN>
<TOKEN end_char="6136" id="token-39-19" morph="none" pos="word" start_char="6133">that</TOKEN>
<TOKEN end_char="6144" id="token-39-20" morph="none" pos="word" start_char="6138">they’re</TOKEN>
<TOKEN end_char="6154" id="token-39-21" morph="none" pos="word" start_char="6146">obviously</TOKEN>
<TOKEN end_char="6158" id="token-39-22" morph="none" pos="word" start_char="6156">not</TOKEN>
<TOKEN end_char="6162" id="token-39-23" morph="none" pos="word" start_char="6160">the</TOKEN>
<TOKEN end_char="6167" id="token-39-24" morph="none" pos="word" start_char="6164">same</TOKEN>
<TOKEN end_char="6169" id="token-39-25" morph="none" pos="punct" start_char="6169">—</TOKEN>
<TOKEN end_char="6172" id="token-39-26" morph="none" pos="word" start_char="6171">or</TOKEN>
<TOKEN end_char="6177" id="token-39-27" morph="none" pos="word" start_char="6174">that</TOKEN>
<TOKEN end_char="6181" id="token-39-28" morph="none" pos="word" start_char="6179">one</TOKEN>
<TOKEN end_char="6189" id="token-39-29" morph="none" pos="word" start_char="6183">somehow</TOKEN>
<TOKEN end_char="6193" id="token-39-30" morph="none" pos="word" start_char="6191">led</TOKEN>
<TOKEN end_char="6196" id="token-39-31" morph="none" pos="word" start_char="6195">to</TOKEN>
<TOKEN end_char="6200" id="token-39-32" morph="none" pos="word" start_char="6198">the</TOKEN>
<TOKEN end_char="6206" id="token-39-33" morph="none" pos="word" start_char="6202">other</TOKEN>
<TOKEN end_char="6208" id="token-39-34" morph="none" pos="punct" start_char="6207">."</TOKEN>
</SEG>
<SEG end_char="6219" id="segment-40" start_char="6211">
<ORIGINAL_TEXT>HIV Drugs</ORIGINAL_TEXT>
<TOKEN end_char="6213" id="token-40-0" morph="none" pos="word" start_char="6211">HIV</TOKEN>
<TOKEN end_char="6219" id="token-40-1" morph="none" pos="word" start_char="6215">Drugs</TOKEN>
<TRANSLATED_TEXT>HIV drugs</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="6473" id="segment-41" start_char="6223">
<ORIGINAL_TEXT>As we’ve just established, there’s no connection between HIV and the new coronavirus, but the fact that some countries are using HIV drugs to treat the new coronavirus is included in many of the social media posts to lend credence to the bogus theory.</ORIGINAL_TEXT>
<TOKEN end_char="6224" id="token-41-0" morph="none" pos="word" start_char="6223">As</TOKEN>
<TOKEN end_char="6230" id="token-41-1" morph="none" pos="word" start_char="6226">we’ve</TOKEN>
<TOKEN end_char="6235" id="token-41-2" morph="none" pos="word" start_char="6232">just</TOKEN>
<TOKEN end_char="6247" id="token-41-3" morph="none" pos="word" start_char="6237">established</TOKEN>
<TOKEN end_char="6248" id="token-41-4" morph="none" pos="punct" start_char="6248">,</TOKEN>
<TOKEN end_char="6256" id="token-41-5" morph="none" pos="word" start_char="6250">there’s</TOKEN>
<TOKEN end_char="6259" id="token-41-6" morph="none" pos="word" start_char="6258">no</TOKEN>
<TOKEN end_char="6270" id="token-41-7" morph="none" pos="word" start_char="6261">connection</TOKEN>
<TOKEN end_char="6278" id="token-41-8" morph="none" pos="word" start_char="6272">between</TOKEN>
<TOKEN end_char="6282" id="token-41-9" morph="none" pos="word" start_char="6280">HIV</TOKEN>
<TOKEN end_char="6286" id="token-41-10" morph="none" pos="word" start_char="6284">and</TOKEN>
<TOKEN end_char="6290" id="token-41-11" morph="none" pos="word" start_char="6288">the</TOKEN>
<TOKEN end_char="6294" id="token-41-12" morph="none" pos="word" start_char="6292">new</TOKEN>
<TOKEN end_char="6306" id="token-41-13" morph="none" pos="word" start_char="6296">coronavirus</TOKEN>
<TOKEN end_char="6307" id="token-41-14" morph="none" pos="punct" start_char="6307">,</TOKEN>
<TOKEN end_char="6311" id="token-41-15" morph="none" pos="word" start_char="6309">but</TOKEN>
<TOKEN end_char="6315" id="token-41-16" morph="none" pos="word" start_char="6313">the</TOKEN>
<TOKEN end_char="6320" id="token-41-17" morph="none" pos="word" start_char="6317">fact</TOKEN>
<TOKEN end_char="6325" id="token-41-18" morph="none" pos="word" start_char="6322">that</TOKEN>
<TOKEN end_char="6330" id="token-41-19" morph="none" pos="word" start_char="6327">some</TOKEN>
<TOKEN end_char="6340" id="token-41-20" morph="none" pos="word" start_char="6332">countries</TOKEN>
<TOKEN end_char="6344" id="token-41-21" morph="none" pos="word" start_char="6342">are</TOKEN>
<TOKEN end_char="6350" id="token-41-22" morph="none" pos="word" start_char="6346">using</TOKEN>
<TOKEN end_char="6354" id="token-41-23" morph="none" pos="word" start_char="6352">HIV</TOKEN>
<TOKEN end_char="6360" id="token-41-24" morph="none" pos="word" start_char="6356">drugs</TOKEN>
<TOKEN end_char="6363" id="token-41-25" morph="none" pos="word" start_char="6362">to</TOKEN>
<TOKEN end_char="6369" id="token-41-26" morph="none" pos="word" start_char="6365">treat</TOKEN>
<TOKEN end_char="6373" id="token-41-27" morph="none" pos="word" start_char="6371">the</TOKEN>
<TOKEN end_char="6377" id="token-41-28" morph="none" pos="word" start_char="6375">new</TOKEN>
<TOKEN end_char="6389" id="token-41-29" morph="none" pos="word" start_char="6379">coronavirus</TOKEN>
<TOKEN end_char="6392" id="token-41-30" morph="none" pos="word" start_char="6391">is</TOKEN>
<TOKEN end_char="6401" id="token-41-31" morph="none" pos="word" start_char="6394">included</TOKEN>
<TOKEN end_char="6404" id="token-41-32" morph="none" pos="word" start_char="6403">in</TOKEN>
<TOKEN end_char="6409" id="token-41-33" morph="none" pos="word" start_char="6406">many</TOKEN>
<TOKEN end_char="6412" id="token-41-34" morph="none" pos="word" start_char="6411">of</TOKEN>
<TOKEN end_char="6416" id="token-41-35" morph="none" pos="word" start_char="6414">the</TOKEN>
<TOKEN end_char="6423" id="token-41-36" morph="none" pos="word" start_char="6418">social</TOKEN>
<TOKEN end_char="6429" id="token-41-37" morph="none" pos="word" start_char="6425">media</TOKEN>
<TOKEN end_char="6435" id="token-41-38" morph="none" pos="word" start_char="6431">posts</TOKEN>
<TOKEN end_char="6438" id="token-41-39" morph="none" pos="word" start_char="6437">to</TOKEN>
<TOKEN end_char="6443" id="token-41-40" morph="none" pos="word" start_char="6440">lend</TOKEN>
<TOKEN end_char="6452" id="token-41-41" morph="none" pos="word" start_char="6445">credence</TOKEN>
<TOKEN end_char="6455" id="token-41-42" morph="none" pos="word" start_char="6454">to</TOKEN>
<TOKEN end_char="6459" id="token-41-43" morph="none" pos="word" start_char="6457">the</TOKEN>
<TOKEN end_char="6465" id="token-41-44" morph="none" pos="word" start_char="6461">bogus</TOKEN>
<TOKEN end_char="6472" id="token-41-45" morph="none" pos="word" start_char="6467">theory</TOKEN>
<TOKEN end_char="6473" id="token-41-46" morph="none" pos="punct" start_char="6473">.</TOKEN>
</SEG>
<SEG end_char="6666" id="segment-42" start_char="6476">
<ORIGINAL_TEXT>One Facebook post says, "Ask yourself why they have been treating with HIV drugs from the start," and the ZeroHedge story proclaims, "The virus even responds to treatment by HIV medications."</ORIGINAL_TEXT>
<TOKEN end_char="6478" id="token-42-0" morph="none" pos="word" start_char="6476">One</TOKEN>
<TOKEN end_char="6487" id="token-42-1" morph="none" pos="word" start_char="6480">Facebook</TOKEN>
<TOKEN end_char="6492" id="token-42-2" morph="none" pos="word" start_char="6489">post</TOKEN>
<TOKEN end_char="6497" id="token-42-3" morph="none" pos="word" start_char="6494">says</TOKEN>
<TOKEN end_char="6498" id="token-42-4" morph="none" pos="punct" start_char="6498">,</TOKEN>
<TOKEN end_char="6500" id="token-42-5" morph="none" pos="punct" start_char="6500">"</TOKEN>
<TOKEN end_char="6503" id="token-42-6" morph="none" pos="word" start_char="6501">Ask</TOKEN>
<TOKEN end_char="6512" id="token-42-7" morph="none" pos="word" start_char="6505">yourself</TOKEN>
<TOKEN end_char="6516" id="token-42-8" morph="none" pos="word" start_char="6514">why</TOKEN>
<TOKEN end_char="6521" id="token-42-9" morph="none" pos="word" start_char="6518">they</TOKEN>
<TOKEN end_char="6526" id="token-42-10" morph="none" pos="word" start_char="6523">have</TOKEN>
<TOKEN end_char="6531" id="token-42-11" morph="none" pos="word" start_char="6528">been</TOKEN>
<TOKEN end_char="6540" id="token-42-12" morph="none" pos="word" start_char="6533">treating</TOKEN>
<TOKEN end_char="6545" id="token-42-13" morph="none" pos="word" start_char="6542">with</TOKEN>
<TOKEN end_char="6549" id="token-42-14" morph="none" pos="word" start_char="6547">HIV</TOKEN>
<TOKEN end_char="6555" id="token-42-15" morph="none" pos="word" start_char="6551">drugs</TOKEN>
<TOKEN end_char="6560" id="token-42-16" morph="none" pos="word" start_char="6557">from</TOKEN>
<TOKEN end_char="6564" id="token-42-17" morph="none" pos="word" start_char="6562">the</TOKEN>
<TOKEN end_char="6570" id="token-42-18" morph="none" pos="word" start_char="6566">start</TOKEN>
<TOKEN end_char="6572" id="token-42-19" morph="none" pos="punct" start_char="6571">,"</TOKEN>
<TOKEN end_char="6576" id="token-42-20" morph="none" pos="word" start_char="6574">and</TOKEN>
<TOKEN end_char="6580" id="token-42-21" morph="none" pos="word" start_char="6578">the</TOKEN>
<TOKEN end_char="6590" id="token-42-22" morph="none" pos="word" start_char="6582">ZeroHedge</TOKEN>
<TOKEN end_char="6596" id="token-42-23" morph="none" pos="word" start_char="6592">story</TOKEN>
<TOKEN end_char="6606" id="token-42-24" morph="none" pos="word" start_char="6598">proclaims</TOKEN>
<TOKEN end_char="6607" id="token-42-25" morph="none" pos="punct" start_char="6607">,</TOKEN>
<TOKEN end_char="6609" id="token-42-26" morph="none" pos="punct" start_char="6609">"</TOKEN>
<TOKEN end_char="6612" id="token-42-27" morph="none" pos="word" start_char="6610">The</TOKEN>
<TOKEN end_char="6618" id="token-42-28" morph="none" pos="word" start_char="6614">virus</TOKEN>
<TOKEN end_char="6623" id="token-42-29" morph="none" pos="word" start_char="6620">even</TOKEN>
<TOKEN end_char="6632" id="token-42-30" morph="none" pos="word" start_char="6625">responds</TOKEN>
<TOKEN end_char="6635" id="token-42-31" morph="none" pos="word" start_char="6634">to</TOKEN>
<TOKEN end_char="6645" id="token-42-32" morph="none" pos="word" start_char="6637">treatment</TOKEN>
<TOKEN end_char="6648" id="token-42-33" morph="none" pos="word" start_char="6647">by</TOKEN>
<TOKEN end_char="6652" id="token-42-34" morph="none" pos="word" start_char="6650">HIV</TOKEN>
<TOKEN end_char="6664" id="token-42-35" morph="none" pos="word" start_char="6654">medications</TOKEN>
<TOKEN end_char="6666" id="token-42-36" morph="none" pos="punct" start_char="6665">."</TOKEN>
</SEG>
<SEG end_char="6782" id="segment-43" start_char="6669">
<ORIGINAL_TEXT>In fact, it’s not yet clear if the virus does respond to HIV drugs — but the rationale to try it is pretty simple.</ORIGINAL_TEXT>
<TOKEN end_char="6670" id="token-43-0" morph="none" pos="word" start_char="6669">In</TOKEN>
<TOKEN end_char="6675" id="token-43-1" morph="none" pos="word" start_char="6672">fact</TOKEN>
<TOKEN end_char="6676" id="token-43-2" morph="none" pos="punct" start_char="6676">,</TOKEN>
<TOKEN end_char="6681" id="token-43-3" morph="none" pos="word" start_char="6678">it’s</TOKEN>
<TOKEN end_char="6685" id="token-43-4" morph="none" pos="word" start_char="6683">not</TOKEN>
<TOKEN end_char="6689" id="token-43-5" morph="none" pos="word" start_char="6687">yet</TOKEN>
<TOKEN end_char="6695" id="token-43-6" morph="none" pos="word" start_char="6691">clear</TOKEN>
<TOKEN end_char="6698" id="token-43-7" morph="none" pos="word" start_char="6697">if</TOKEN>
<TOKEN end_char="6702" id="token-43-8" morph="none" pos="word" start_char="6700">the</TOKEN>
<TOKEN end_char="6708" id="token-43-9" morph="none" pos="word" start_char="6704">virus</TOKEN>
<TOKEN end_char="6713" id="token-43-10" morph="none" pos="word" start_char="6710">does</TOKEN>
<TOKEN end_char="6721" id="token-43-11" morph="none" pos="word" start_char="6715">respond</TOKEN>
<TOKEN end_char="6724" id="token-43-12" morph="none" pos="word" start_char="6723">to</TOKEN>
<TOKEN end_char="6728" id="token-43-13" morph="none" pos="word" start_char="6726">HIV</TOKEN>
<TOKEN end_char="6734" id="token-43-14" morph="none" pos="word" start_char="6730">drugs</TOKEN>
<TOKEN end_char="6736" id="token-43-15" morph="none" pos="punct" start_char="6736">—</TOKEN>
<TOKEN end_char="6740" id="token-43-16" morph="none" pos="word" start_char="6738">but</TOKEN>
<TOKEN end_char="6744" id="token-43-17" morph="none" pos="word" start_char="6742">the</TOKEN>
<TOKEN end_char="6754" id="token-43-18" morph="none" pos="word" start_char="6746">rationale</TOKEN>
<TOKEN end_char="6757" id="token-43-19" morph="none" pos="word" start_char="6756">to</TOKEN>
<TOKEN end_char="6761" id="token-43-20" morph="none" pos="word" start_char="6759">try</TOKEN>
<TOKEN end_char="6764" id="token-43-21" morph="none" pos="word" start_char="6763">it</TOKEN>
<TOKEN end_char="6767" id="token-43-22" morph="none" pos="word" start_char="6766">is</TOKEN>
<TOKEN end_char="6774" id="token-43-23" morph="none" pos="word" start_char="6769">pretty</TOKEN>
<TOKEN end_char="6781" id="token-43-24" morph="none" pos="word" start_char="6776">simple</TOKEN>
<TOKEN end_char="6782" id="token-43-25" morph="none" pos="punct" start_char="6782">.</TOKEN>
</SEG>
<SEG end_char="7041" id="segment-44" start_char="6784">
<ORIGINAL_TEXT>Timothy Sheahan, a virologist at the University of North Carolina at Chapel Hill, told us in a phone interview that there aren’t that many FDA-approved antiviral drugs, so when a new virus emerges, doctors just give patients "whatever they think might help."</ORIGINAL_TEXT>
<TOKEN end_char="6790" id="token-44-0" morph="none" pos="word" start_char="6784">Timothy</TOKEN>
<TOKEN end_char="6798" id="token-44-1" morph="none" pos="word" start_char="6792">Sheahan</TOKEN>
<TOKEN end_char="6799" id="token-44-2" morph="none" pos="punct" start_char="6799">,</TOKEN>
<TOKEN end_char="6801" id="token-44-3" morph="none" pos="word" start_char="6801">a</TOKEN>
<TOKEN end_char="6812" id="token-44-4" morph="none" pos="word" start_char="6803">virologist</TOKEN>
<TOKEN end_char="6815" id="token-44-5" morph="none" pos="word" start_char="6814">at</TOKEN>
<TOKEN end_char="6819" id="token-44-6" morph="none" pos="word" start_char="6817">the</TOKEN>
<TOKEN end_char="6830" id="token-44-7" morph="none" pos="word" start_char="6821">University</TOKEN>
<TOKEN end_char="6833" id="token-44-8" morph="none" pos="word" start_char="6832">of</TOKEN>
<TOKEN end_char="6839" id="token-44-9" morph="none" pos="word" start_char="6835">North</TOKEN>
<TOKEN end_char="6848" id="token-44-10" morph="none" pos="word" start_char="6841">Carolina</TOKEN>
<TOKEN end_char="6851" id="token-44-11" morph="none" pos="word" start_char="6850">at</TOKEN>
<TOKEN end_char="6858" id="token-44-12" morph="none" pos="word" start_char="6853">Chapel</TOKEN>
<TOKEN end_char="6863" id="token-44-13" morph="none" pos="word" start_char="6860">Hill</TOKEN>
<TOKEN end_char="6864" id="token-44-14" morph="none" pos="punct" start_char="6864">,</TOKEN>
<TOKEN end_char="6869" id="token-44-15" morph="none" pos="word" start_char="6866">told</TOKEN>
<TOKEN end_char="6872" id="token-44-16" morph="none" pos="word" start_char="6871">us</TOKEN>
<TOKEN end_char="6875" id="token-44-17" morph="none" pos="word" start_char="6874">in</TOKEN>
<TOKEN end_char="6877" id="token-44-18" morph="none" pos="word" start_char="6877">a</TOKEN>
<TOKEN end_char="6883" id="token-44-19" morph="none" pos="word" start_char="6879">phone</TOKEN>
<TOKEN end_char="6893" id="token-44-20" morph="none" pos="word" start_char="6885">interview</TOKEN>
<TOKEN end_char="6898" id="token-44-21" morph="none" pos="word" start_char="6895">that</TOKEN>
<TOKEN end_char="6904" id="token-44-22" morph="none" pos="word" start_char="6900">there</TOKEN>
<TOKEN end_char="6911" id="token-44-23" morph="none" pos="word" start_char="6906">aren’t</TOKEN>
<TOKEN end_char="6916" id="token-44-24" morph="none" pos="word" start_char="6913">that</TOKEN>
<TOKEN end_char="6921" id="token-44-25" morph="none" pos="word" start_char="6918">many</TOKEN>
<TOKEN end_char="6934" id="token-44-26" morph="none" pos="unknown" start_char="6923">FDA-approved</TOKEN>
<TOKEN end_char="6944" id="token-44-27" morph="none" pos="word" start_char="6936">antiviral</TOKEN>
<TOKEN end_char="6950" id="token-44-28" morph="none" pos="word" start_char="6946">drugs</TOKEN>
<TOKEN end_char="6951" id="token-44-29" morph="none" pos="punct" start_char="6951">,</TOKEN>
<TOKEN end_char="6954" id="token-44-30" morph="none" pos="word" start_char="6953">so</TOKEN>
<TOKEN end_char="6959" id="token-44-31" morph="none" pos="word" start_char="6956">when</TOKEN>
<TOKEN end_char="6961" id="token-44-32" morph="none" pos="word" start_char="6961">a</TOKEN>
<TOKEN end_char="6965" id="token-44-33" morph="none" pos="word" start_char="6963">new</TOKEN>
<TOKEN end_char="6971" id="token-44-34" morph="none" pos="word" start_char="6967">virus</TOKEN>
<TOKEN end_char="6979" id="token-44-35" morph="none" pos="word" start_char="6973">emerges</TOKEN>
<TOKEN end_char="6980" id="token-44-36" morph="none" pos="punct" start_char="6980">,</TOKEN>
<TOKEN end_char="6988" id="token-44-37" morph="none" pos="word" start_char="6982">doctors</TOKEN>
<TOKEN end_char="6993" id="token-44-38" morph="none" pos="word" start_char="6990">just</TOKEN>
<TOKEN end_char="6998" id="token-44-39" morph="none" pos="word" start_char="6995">give</TOKEN>
<TOKEN end_char="7007" id="token-44-40" morph="none" pos="word" start_char="7000">patients</TOKEN>
<TOKEN end_char="7009" id="token-44-41" morph="none" pos="punct" start_char="7009">"</TOKEN>
<TOKEN end_char="7017" id="token-44-42" morph="none" pos="word" start_char="7010">whatever</TOKEN>
<TOKEN end_char="7022" id="token-44-43" morph="none" pos="word" start_char="7019">they</TOKEN>
<TOKEN end_char="7028" id="token-44-44" morph="none" pos="word" start_char="7024">think</TOKEN>
<TOKEN end_char="7034" id="token-44-45" morph="none" pos="word" start_char="7030">might</TOKEN>
<TOKEN end_char="7039" id="token-44-46" morph="none" pos="word" start_char="7036">help</TOKEN>
<TOKEN end_char="7041" id="token-44-47" morph="none" pos="punct" start_char="7040">."</TOKEN>
</SEG>
<SEG end_char="7132" id="segment-45" start_char="7044">
<ORIGINAL_TEXT>Many existing antivirals, he said, are HIV medications, so it’s natural to turn to those.</ORIGINAL_TEXT>
<TOKEN end_char="7047" id="token-45-0" morph="none" pos="word" start_char="7044">Many</TOKEN>
<TOKEN end_char="7056" id="token-45-1" morph="none" pos="word" start_char="7049">existing</TOKEN>
<TOKEN end_char="7067" id="token-45-2" morph="none" pos="word" start_char="7058">antivirals</TOKEN>
<TOKEN end_char="7068" id="token-45-3" morph="none" pos="punct" start_char="7068">,</TOKEN>
<TOKEN end_char="7071" id="token-45-4" morph="none" pos="word" start_char="7070">he</TOKEN>
<TOKEN end_char="7076" id="token-45-5" morph="none" pos="word" start_char="7073">said</TOKEN>
<TOKEN end_char="7077" id="token-45-6" morph="none" pos="punct" start_char="7077">,</TOKEN>
<TOKEN end_char="7081" id="token-45-7" morph="none" pos="word" start_char="7079">are</TOKEN>
<TOKEN end_char="7085" id="token-45-8" morph="none" pos="word" start_char="7083">HIV</TOKEN>
<TOKEN end_char="7097" id="token-45-9" morph="none" pos="word" start_char="7087">medications</TOKEN>
<TOKEN end_char="7098" id="token-45-10" morph="none" pos="punct" start_char="7098">,</TOKEN>
<TOKEN end_char="7101" id="token-45-11" morph="none" pos="word" start_char="7100">so</TOKEN>
<TOKEN end_char="7106" id="token-45-12" morph="none" pos="word" start_char="7103">it’s</TOKEN>
<TOKEN end_char="7114" id="token-45-13" morph="none" pos="word" start_char="7108">natural</TOKEN>
<TOKEN end_char="7117" id="token-45-14" morph="none" pos="word" start_char="7116">to</TOKEN>
<TOKEN end_char="7122" id="token-45-15" morph="none" pos="word" start_char="7119">turn</TOKEN>
<TOKEN end_char="7125" id="token-45-16" morph="none" pos="word" start_char="7124">to</TOKEN>
<TOKEN end_char="7131" id="token-45-17" morph="none" pos="word" start_char="7127">those</TOKEN>
<TOKEN end_char="7132" id="token-45-18" morph="none" pos="punct" start_char="7132">.</TOKEN>
</SEG>
<SEG end_char="7214" id="segment-46" start_char="7134">
<ORIGINAL_TEXT>And there is some precedent for HIV drugs possibly working against coronaviruses.</ORIGINAL_TEXT>
<TOKEN end_char="7136" id="token-46-0" morph="none" pos="word" start_char="7134">And</TOKEN>
<TOKEN end_char="7142" id="token-46-1" morph="none" pos="word" start_char="7138">there</TOKEN>
<TOKEN end_char="7145" id="token-46-2" morph="none" pos="word" start_char="7144">is</TOKEN>
<TOKEN end_char="7150" id="token-46-3" morph="none" pos="word" start_char="7147">some</TOKEN>
<TOKEN end_char="7160" id="token-46-4" morph="none" pos="word" start_char="7152">precedent</TOKEN>
<TOKEN end_char="7164" id="token-46-5" morph="none" pos="word" start_char="7162">for</TOKEN>
<TOKEN end_char="7168" id="token-46-6" morph="none" pos="word" start_char="7166">HIV</TOKEN>
<TOKEN end_char="7174" id="token-46-7" morph="none" pos="word" start_char="7170">drugs</TOKEN>
<TOKEN end_char="7183" id="token-46-8" morph="none" pos="word" start_char="7176">possibly</TOKEN>
<TOKEN end_char="7191" id="token-46-9" morph="none" pos="word" start_char="7185">working</TOKEN>
<TOKEN end_char="7199" id="token-46-10" morph="none" pos="word" start_char="7193">against</TOKEN>
<TOKEN end_char="7213" id="token-46-11" morph="none" pos="word" start_char="7201">coronaviruses</TOKEN>
<TOKEN end_char="7214" id="token-46-12" morph="none" pos="punct" start_char="7214">.</TOKEN>
</SEG>
<SEG end_char="7406" id="segment-47" start_char="7217">
<ORIGINAL_TEXT>During the SARS outbreak, for example, scientists performed a drug screen and identified the HIV drug cocktail of lopinavir and ritonavir as having potential antiviral activity against SARS.</ORIGINAL_TEXT>
<TOKEN end_char="7222" id="token-47-0" morph="none" pos="word" start_char="7217">During</TOKEN>
<TOKEN end_char="7226" id="token-47-1" morph="none" pos="word" start_char="7224">the</TOKEN>
<TOKEN end_char="7231" id="token-47-2" morph="none" pos="word" start_char="7228">SARS</TOKEN>
<TOKEN end_char="7240" id="token-47-3" morph="none" pos="word" start_char="7233">outbreak</TOKEN>
<TOKEN end_char="7241" id="token-47-4" morph="none" pos="punct" start_char="7241">,</TOKEN>
<TOKEN end_char="7245" id="token-47-5" morph="none" pos="word" start_char="7243">for</TOKEN>
<TOKEN end_char="7253" id="token-47-6" morph="none" pos="word" start_char="7247">example</TOKEN>
<TOKEN end_char="7254" id="token-47-7" morph="none" pos="punct" start_char="7254">,</TOKEN>
<TOKEN end_char="7265" id="token-47-8" morph="none" pos="word" start_char="7256">scientists</TOKEN>
<TOKEN end_char="7275" id="token-47-9" morph="none" pos="word" start_char="7267">performed</TOKEN>
<TOKEN end_char="7277" id="token-47-10" morph="none" pos="word" start_char="7277">a</TOKEN>
<TOKEN end_char="7282" id="token-47-11" morph="none" pos="word" start_char="7279">drug</TOKEN>
<TOKEN end_char="7289" id="token-47-12" morph="none" pos="word" start_char="7284">screen</TOKEN>
<TOKEN end_char="7293" id="token-47-13" morph="none" pos="word" start_char="7291">and</TOKEN>
<TOKEN end_char="7304" id="token-47-14" morph="none" pos="word" start_char="7295">identified</TOKEN>
<TOKEN end_char="7308" id="token-47-15" morph="none" pos="word" start_char="7306">the</TOKEN>
<TOKEN end_char="7312" id="token-47-16" morph="none" pos="word" start_char="7310">HIV</TOKEN>
<TOKEN end_char="7317" id="token-47-17" morph="none" pos="word" start_char="7314">drug</TOKEN>
<TOKEN end_char="7326" id="token-47-18" morph="none" pos="word" start_char="7319">cocktail</TOKEN>
<TOKEN end_char="7329" id="token-47-19" morph="none" pos="word" start_char="7328">of</TOKEN>
<TOKEN end_char="7339" id="token-47-20" morph="none" pos="word" start_char="7331">lopinavir</TOKEN>
<TOKEN end_char="7343" id="token-47-21" morph="none" pos="word" start_char="7341">and</TOKEN>
<TOKEN end_char="7353" id="token-47-22" morph="none" pos="word" start_char="7345">ritonavir</TOKEN>
<TOKEN end_char="7356" id="token-47-23" morph="none" pos="word" start_char="7355">as</TOKEN>
<TOKEN end_char="7363" id="token-47-24" morph="none" pos="word" start_char="7358">having</TOKEN>
<TOKEN end_char="7373" id="token-47-25" morph="none" pos="word" start_char="7365">potential</TOKEN>
<TOKEN end_char="7383" id="token-47-26" morph="none" pos="word" start_char="7375">antiviral</TOKEN>
<TOKEN end_char="7392" id="token-47-27" morph="none" pos="word" start_char="7385">activity</TOKEN>
<TOKEN end_char="7400" id="token-47-28" morph="none" pos="word" start_char="7394">against</TOKEN>
<TOKEN end_char="7405" id="token-47-29" morph="none" pos="word" start_char="7402">SARS</TOKEN>
<TOKEN end_char="7406" id="token-47-30" morph="none" pos="punct" start_char="7406">.</TOKEN>
</SEG>
<SEG end_char="7598" id="segment-48" start_char="7408">
<ORIGINAL_TEXT>That drug combo was also associated with better outcomes among a small group of SARS patients, although it was never tested in a clinical trial, so it’s hard to say if it was truly effective.</ORIGINAL_TEXT>
<TOKEN end_char="7411" id="token-48-0" morph="none" pos="word" start_char="7408">That</TOKEN>
<TOKEN end_char="7416" id="token-48-1" morph="none" pos="word" start_char="7413">drug</TOKEN>
<TOKEN end_char="7422" id="token-48-2" morph="none" pos="word" start_char="7418">combo</TOKEN>
<TOKEN end_char="7426" id="token-48-3" morph="none" pos="word" start_char="7424">was</TOKEN>
<TOKEN end_char="7431" id="token-48-4" morph="none" pos="word" start_char="7428">also</TOKEN>
<TOKEN end_char="7442" id="token-48-5" morph="none" pos="word" start_char="7433">associated</TOKEN>
<TOKEN end_char="7447" id="token-48-6" morph="none" pos="word" start_char="7444">with</TOKEN>
<TOKEN end_char="7454" id="token-48-7" morph="none" pos="word" start_char="7449">better</TOKEN>
<TOKEN end_char="7463" id="token-48-8" morph="none" pos="word" start_char="7456">outcomes</TOKEN>
<TOKEN end_char="7469" id="token-48-9" morph="none" pos="word" start_char="7465">among</TOKEN>
<TOKEN end_char="7471" id="token-48-10" morph="none" pos="word" start_char="7471">a</TOKEN>
<TOKEN end_char="7477" id="token-48-11" morph="none" pos="word" start_char="7473">small</TOKEN>
<TOKEN end_char="7483" id="token-48-12" morph="none" pos="word" start_char="7479">group</TOKEN>
<TOKEN end_char="7486" id="token-48-13" morph="none" pos="word" start_char="7485">of</TOKEN>
<TOKEN end_char="7491" id="token-48-14" morph="none" pos="word" start_char="7488">SARS</TOKEN>
<TOKEN end_char="7500" id="token-48-15" morph="none" pos="word" start_char="7493">patients</TOKEN>
<TOKEN end_char="7501" id="token-48-16" morph="none" pos="punct" start_char="7501">,</TOKEN>
<TOKEN end_char="7510" id="token-48-17" morph="none" pos="word" start_char="7503">although</TOKEN>
<TOKEN end_char="7513" id="token-48-18" morph="none" pos="word" start_char="7512">it</TOKEN>
<TOKEN end_char="7517" id="token-48-19" morph="none" pos="word" start_char="7515">was</TOKEN>
<TOKEN end_char="7523" id="token-48-20" morph="none" pos="word" start_char="7519">never</TOKEN>
<TOKEN end_char="7530" id="token-48-21" morph="none" pos="word" start_char="7525">tested</TOKEN>
<TOKEN end_char="7533" id="token-48-22" morph="none" pos="word" start_char="7532">in</TOKEN>
<TOKEN end_char="7535" id="token-48-23" morph="none" pos="word" start_char="7535">a</TOKEN>
<TOKEN end_char="7544" id="token-48-24" morph="none" pos="word" start_char="7537">clinical</TOKEN>
<TOKEN end_char="7550" id="token-48-25" morph="none" pos="word" start_char="7546">trial</TOKEN>
<TOKEN end_char="7551" id="token-48-26" morph="none" pos="punct" start_char="7551">,</TOKEN>
<TOKEN end_char="7554" id="token-48-27" morph="none" pos="word" start_char="7553">so</TOKEN>
<TOKEN end_char="7559" id="token-48-28" morph="none" pos="word" start_char="7556">it’s</TOKEN>
<TOKEN end_char="7564" id="token-48-29" morph="none" pos="word" start_char="7561">hard</TOKEN>
<TOKEN end_char="7567" id="token-48-30" morph="none" pos="word" start_char="7566">to</TOKEN>
<TOKEN end_char="7571" id="token-48-31" morph="none" pos="word" start_char="7569">say</TOKEN>
<TOKEN end_char="7574" id="token-48-32" morph="none" pos="word" start_char="7573">if</TOKEN>
<TOKEN end_char="7577" id="token-48-33" morph="none" pos="word" start_char="7576">it</TOKEN>
<TOKEN end_char="7581" id="token-48-34" morph="none" pos="word" start_char="7579">was</TOKEN>
<TOKEN end_char="7587" id="token-48-35" morph="none" pos="word" start_char="7583">truly</TOKEN>
<TOKEN end_char="7597" id="token-48-36" morph="none" pos="word" start_char="7589">effective</TOKEN>
<TOKEN end_char="7598" id="token-48-37" morph="none" pos="punct" start_char="7598">.</TOKEN>
</SEG>
<SEG end_char="7760" id="segment-49" start_char="7600">
<ORIGINAL_TEXT>It is also currently being tested in a clinical trial in Saudi Arabia against another disease caused by a coronavirus, Middle East respiratory syndrome, or MERS.</ORIGINAL_TEXT>
<TOKEN end_char="7601" id="token-49-0" morph="none" pos="word" start_char="7600">It</TOKEN>
<TOKEN end_char="7604" id="token-49-1" morph="none" pos="word" start_char="7603">is</TOKEN>
<TOKEN end_char="7609" id="token-49-2" morph="none" pos="word" start_char="7606">also</TOKEN>
<TOKEN end_char="7619" id="token-49-3" morph="none" pos="word" start_char="7611">currently</TOKEN>
<TOKEN end_char="7625" id="token-49-4" morph="none" pos="word" start_char="7621">being</TOKEN>
<TOKEN end_char="7632" id="token-49-5" morph="none" pos="word" start_char="7627">tested</TOKEN>
<TOKEN end_char="7635" id="token-49-6" morph="none" pos="word" start_char="7634">in</TOKEN>
<TOKEN end_char="7637" id="token-49-7" morph="none" pos="word" start_char="7637">a</TOKEN>
<TOKEN end_char="7646" id="token-49-8" morph="none" pos="word" start_char="7639">clinical</TOKEN>
<TOKEN end_char="7652" id="token-49-9" morph="none" pos="word" start_char="7648">trial</TOKEN>
<TOKEN end_char="7655" id="token-49-10" morph="none" pos="word" start_char="7654">in</TOKEN>
<TOKEN end_char="7661" id="token-49-11" morph="none" pos="word" start_char="7657">Saudi</TOKEN>
<TOKEN end_char="7668" id="token-49-12" morph="none" pos="word" start_char="7663">Arabia</TOKEN>
<TOKEN end_char="7676" id="token-49-13" morph="none" pos="word" start_char="7670">against</TOKEN>
<TOKEN end_char="7684" id="token-49-14" morph="none" pos="word" start_char="7678">another</TOKEN>
<TOKEN end_char="7692" id="token-49-15" morph="none" pos="word" start_char="7686">disease</TOKEN>
<TOKEN end_char="7699" id="token-49-16" morph="none" pos="word" start_char="7694">caused</TOKEN>
<TOKEN end_char="7702" id="token-49-17" morph="none" pos="word" start_char="7701">by</TOKEN>
<TOKEN end_char="7704" id="token-49-18" morph="none" pos="word" start_char="7704">a</TOKEN>
<TOKEN end_char="7716" id="token-49-19" morph="none" pos="word" start_char="7706">coronavirus</TOKEN>
<TOKEN end_char="7717" id="token-49-20" morph="none" pos="punct" start_char="7717">,</TOKEN>
<TOKEN end_char="7724" id="token-49-21" morph="none" pos="word" start_char="7719">Middle</TOKEN>
<TOKEN end_char="7729" id="token-49-22" morph="none" pos="word" start_char="7726">East</TOKEN>
<TOKEN end_char="7741" id="token-49-23" morph="none" pos="word" start_char="7731">respiratory</TOKEN>
<TOKEN end_char="7750" id="token-49-24" morph="none" pos="word" start_char="7743">syndrome</TOKEN>
<TOKEN end_char="7751" id="token-49-25" morph="none" pos="punct" start_char="7751">,</TOKEN>
<TOKEN end_char="7754" id="token-49-26" morph="none" pos="word" start_char="7753">or</TOKEN>
<TOKEN end_char="7759" id="token-49-27" morph="none" pos="word" start_char="7756">MERS</TOKEN>
<TOKEN end_char="7760" id="token-49-28" morph="none" pos="punct" start_char="7760">.</TOKEN>
</SEG>
<SEG end_char="7853" id="segment-50" start_char="7763">
<ORIGINAL_TEXT>Sheahan, however, is skeptical that HIV drugs will be very effective against the new virus.</ORIGINAL_TEXT>
<TOKEN end_char="7769" id="token-50-0" morph="none" pos="word" start_char="7763">Sheahan</TOKEN>
<TOKEN end_char="7770" id="token-50-1" morph="none" pos="punct" start_char="7770">,</TOKEN>
<TOKEN end_char="7778" id="token-50-2" morph="none" pos="word" start_char="7772">however</TOKEN>
<TOKEN end_char="7779" id="token-50-3" morph="none" pos="punct" start_char="7779">,</TOKEN>
<TOKEN end_char="7782" id="token-50-4" morph="none" pos="word" start_char="7781">is</TOKEN>
<TOKEN end_char="7792" id="token-50-5" morph="none" pos="word" start_char="7784">skeptical</TOKEN>
<TOKEN end_char="7797" id="token-50-6" morph="none" pos="word" start_char="7794">that</TOKEN>
<TOKEN end_char="7801" id="token-50-7" morph="none" pos="word" start_char="7799">HIV</TOKEN>
<TOKEN end_char="7807" id="token-50-8" morph="none" pos="word" start_char="7803">drugs</TOKEN>
<TOKEN end_char="7812" id="token-50-9" morph="none" pos="word" start_char="7809">will</TOKEN>
<TOKEN end_char="7815" id="token-50-10" morph="none" pos="word" start_char="7814">be</TOKEN>
<TOKEN end_char="7820" id="token-50-11" morph="none" pos="word" start_char="7817">very</TOKEN>
<TOKEN end_char="7830" id="token-50-12" morph="none" pos="word" start_char="7822">effective</TOKEN>
<TOKEN end_char="7838" id="token-50-13" morph="none" pos="word" start_char="7832">against</TOKEN>
<TOKEN end_char="7842" id="token-50-14" morph="none" pos="word" start_char="7840">the</TOKEN>
<TOKEN end_char="7846" id="token-50-15" morph="none" pos="word" start_char="7844">new</TOKEN>
<TOKEN end_char="7852" id="token-50-16" morph="none" pos="word" start_char="7848">virus</TOKEN>
<TOKEN end_char="7853" id="token-50-17" morph="none" pos="punct" start_char="7853">.</TOKEN>
</SEG>
<SEG end_char="7973" id="segment-51" start_char="7855">
<ORIGINAL_TEXT>The levels of the drug that are likely required to diminish viral replication, he said, "are not achievable" in people.</ORIGINAL_TEXT>
<TOKEN end_char="7857" id="token-51-0" morph="none" pos="word" start_char="7855">The</TOKEN>
<TOKEN end_char="7864" id="token-51-1" morph="none" pos="word" start_char="7859">levels</TOKEN>
<TOKEN end_char="7867" id="token-51-2" morph="none" pos="word" start_char="7866">of</TOKEN>
<TOKEN end_char="7871" id="token-51-3" morph="none" pos="word" start_char="7869">the</TOKEN>
<TOKEN end_char="7876" id="token-51-4" morph="none" pos="word" start_char="7873">drug</TOKEN>
<TOKEN end_char="7881" id="token-51-5" morph="none" pos="word" start_char="7878">that</TOKEN>
<TOKEN end_char="7885" id="token-51-6" morph="none" pos="word" start_char="7883">are</TOKEN>
<TOKEN end_char="7892" id="token-51-7" morph="none" pos="word" start_char="7887">likely</TOKEN>
<TOKEN end_char="7901" id="token-51-8" morph="none" pos="word" start_char="7894">required</TOKEN>
<TOKEN end_char="7904" id="token-51-9" morph="none" pos="word" start_char="7903">to</TOKEN>
<TOKEN end_char="7913" id="token-51-10" morph="none" pos="word" start_char="7906">diminish</TOKEN>
<TOKEN end_char="7919" id="token-51-11" morph="none" pos="word" start_char="7915">viral</TOKEN>
<TOKEN end_char="7931" id="token-51-12" morph="none" pos="word" start_char="7921">replication</TOKEN>
<TOKEN end_char="7932" id="token-51-13" morph="none" pos="punct" start_char="7932">,</TOKEN>
<TOKEN end_char="7935" id="token-51-14" morph="none" pos="word" start_char="7934">he</TOKEN>
<TOKEN end_char="7940" id="token-51-15" morph="none" pos="word" start_char="7937">said</TOKEN>
<TOKEN end_char="7941" id="token-51-16" morph="none" pos="punct" start_char="7941">,</TOKEN>
<TOKEN end_char="7943" id="token-51-17" morph="none" pos="punct" start_char="7943">"</TOKEN>
<TOKEN end_char="7946" id="token-51-18" morph="none" pos="word" start_char="7944">are</TOKEN>
<TOKEN end_char="7950" id="token-51-19" morph="none" pos="word" start_char="7948">not</TOKEN>
<TOKEN end_char="7961" id="token-51-20" morph="none" pos="word" start_char="7952">achievable</TOKEN>
<TOKEN end_char="7962" id="token-51-21" morph="none" pos="punct" start_char="7962">"</TOKEN>
<TOKEN end_char="7965" id="token-51-22" morph="none" pos="word" start_char="7964">in</TOKEN>
<TOKEN end_char="7972" id="token-51-23" morph="none" pos="word" start_char="7967">people</TOKEN>
<TOKEN end_char="7973" id="token-51-24" morph="none" pos="punct" start_char="7973">.</TOKEN>
</SEG>
<SEG end_char="8153" id="segment-52" start_char="7975">
<ORIGINAL_TEXT>And in his experiments against the MERS virus in cell culture and in mice, he found lopinavir and ritonavir offered little improvement in severe lung disease or viral replication.</ORIGINAL_TEXT>
<TOKEN end_char="7977" id="token-52-0" morph="none" pos="word" start_char="7975">And</TOKEN>
<TOKEN end_char="7980" id="token-52-1" morph="none" pos="word" start_char="7979">in</TOKEN>
<TOKEN end_char="7984" id="token-52-2" morph="none" pos="word" start_char="7982">his</TOKEN>
<TOKEN end_char="7996" id="token-52-3" morph="none" pos="word" start_char="7986">experiments</TOKEN>
<TOKEN end_char="8004" id="token-52-4" morph="none" pos="word" start_char="7998">against</TOKEN>
<TOKEN end_char="8008" id="token-52-5" morph="none" pos="word" start_char="8006">the</TOKEN>
<TOKEN end_char="8013" id="token-52-6" morph="none" pos="word" start_char="8010">MERS</TOKEN>
<TOKEN end_char="8019" id="token-52-7" morph="none" pos="word" start_char="8015">virus</TOKEN>
<TOKEN end_char="8022" id="token-52-8" morph="none" pos="word" start_char="8021">in</TOKEN>
<TOKEN end_char="8027" id="token-52-9" morph="none" pos="word" start_char="8024">cell</TOKEN>
<TOKEN end_char="8035" id="token-52-10" morph="none" pos="word" start_char="8029">culture</TOKEN>
<TOKEN end_char="8039" id="token-52-11" morph="none" pos="word" start_char="8037">and</TOKEN>
<TOKEN end_char="8042" id="token-52-12" morph="none" pos="word" start_char="8041">in</TOKEN>
<TOKEN end_char="8047" id="token-52-13" morph="none" pos="word" start_char="8044">mice</TOKEN>
<TOKEN end_char="8048" id="token-52-14" morph="none" pos="punct" start_char="8048">,</TOKEN>
<TOKEN end_char="8051" id="token-52-15" morph="none" pos="word" start_char="8050">he</TOKEN>
<TOKEN end_char="8057" id="token-52-16" morph="none" pos="word" start_char="8053">found</TOKEN>
<TOKEN end_char="8067" id="token-52-17" morph="none" pos="word" start_char="8059">lopinavir</TOKEN>
<TOKEN end_char="8071" id="token-52-18" morph="none" pos="word" start_char="8069">and</TOKEN>
<TOKEN end_char="8081" id="token-52-19" morph="none" pos="word" start_char="8073">ritonavir</TOKEN>
<TOKEN end_char="8089" id="token-52-20" morph="none" pos="word" start_char="8083">offered</TOKEN>
<TOKEN end_char="8096" id="token-52-21" morph="none" pos="word" start_char="8091">little</TOKEN>
<TOKEN end_char="8108" id="token-52-22" morph="none" pos="word" start_char="8098">improvement</TOKEN>
<TOKEN end_char="8111" id="token-52-23" morph="none" pos="word" start_char="8110">in</TOKEN>
<TOKEN end_char="8118" id="token-52-24" morph="none" pos="word" start_char="8113">severe</TOKEN>
<TOKEN end_char="8123" id="token-52-25" morph="none" pos="word" start_char="8120">lung</TOKEN>
<TOKEN end_char="8131" id="token-52-26" morph="none" pos="word" start_char="8125">disease</TOKEN>
<TOKEN end_char="8134" id="token-52-27" morph="none" pos="word" start_char="8133">or</TOKEN>
<TOKEN end_char="8140" id="token-52-28" morph="none" pos="word" start_char="8136">viral</TOKEN>
<TOKEN end_char="8152" id="token-52-29" morph="none" pos="word" start_char="8142">replication</TOKEN>
<TOKEN end_char="8153" id="token-52-30" morph="none" pos="punct" start_char="8153">.</TOKEN>
</SEG>
<SEG end_char="8181" id="segment-53" start_char="8156">
<ORIGINAL_TEXT>No Signs of Bioengineering</ORIGINAL_TEXT>
<TOKEN end_char="8157" id="token-53-0" morph="none" pos="word" start_char="8156">No</TOKEN>
<TOKEN end_char="8163" id="token-53-1" morph="none" pos="word" start_char="8159">Signs</TOKEN>
<TOKEN end_char="8166" id="token-53-2" morph="none" pos="word" start_char="8165">of</TOKEN>
<TOKEN end_char="8181" id="token-53-3" morph="none" pos="word" start_char="8168">Bioengineering</TOKEN>
</SEG>
<SEG end_char="8281" id="segment-54" start_char="8185">
<ORIGINAL_TEXT>As for the general notion that the virus has been bioengineered, there’s no evidence that’s true.</ORIGINAL_TEXT>
<TOKEN end_char="8186" id="token-54-0" morph="none" pos="word" start_char="8185">As</TOKEN>
<TOKEN end_char="8190" id="token-54-1" morph="none" pos="word" start_char="8188">for</TOKEN>
<TOKEN end_char="8194" id="token-54-2" morph="none" pos="word" start_char="8192">the</TOKEN>
<TOKEN end_char="8202" id="token-54-3" morph="none" pos="word" start_char="8196">general</TOKEN>
<TOKEN end_char="8209" id="token-54-4" morph="none" pos="word" start_char="8204">notion</TOKEN>
<TOKEN end_char="8214" id="token-54-5" morph="none" pos="word" start_char="8211">that</TOKEN>
<TOKEN end_char="8218" id="token-54-6" morph="none" pos="word" start_char="8216">the</TOKEN>
<TOKEN end_char="8224" id="token-54-7" morph="none" pos="word" start_char="8220">virus</TOKEN>
<TOKEN end_char="8228" id="token-54-8" morph="none" pos="word" start_char="8226">has</TOKEN>
<TOKEN end_char="8233" id="token-54-9" morph="none" pos="word" start_char="8230">been</TOKEN>
<TOKEN end_char="8247" id="token-54-10" morph="none" pos="word" start_char="8235">bioengineered</TOKEN>
<TOKEN end_char="8248" id="token-54-11" morph="none" pos="punct" start_char="8248">,</TOKEN>
<TOKEN end_char="8256" id="token-54-12" morph="none" pos="word" start_char="8250">there’s</TOKEN>
<TOKEN end_char="8259" id="token-54-13" morph="none" pos="word" start_char="8258">no</TOKEN>
<TOKEN end_char="8268" id="token-54-14" morph="none" pos="word" start_char="8261">evidence</TOKEN>
<TOKEN end_char="8275" id="token-54-15" morph="none" pos="word" start_char="8270">that’s</TOKEN>
<TOKEN end_char="8280" id="token-54-16" morph="none" pos="word" start_char="8277">true</TOKEN>
<TOKEN end_char="8281" id="token-54-17" morph="none" pos="punct" start_char="8281">.</TOKEN>
</SEG>
<SEG end_char="8389" id="segment-55" start_char="8283">
<ORIGINAL_TEXT>On the contrary, as we’ve explained before, all lines of evidence point to the virus coming from an animal.</ORIGINAL_TEXT>
<TOKEN end_char="8284" id="token-55-0" morph="none" pos="word" start_char="8283">On</TOKEN>
<TOKEN end_char="8288" id="token-55-1" morph="none" pos="word" start_char="8286">the</TOKEN>
<TOKEN end_char="8297" id="token-55-2" morph="none" pos="word" start_char="8290">contrary</TOKEN>
<TOKEN end_char="8298" id="token-55-3" morph="none" pos="punct" start_char="8298">,</TOKEN>
<TOKEN end_char="8301" id="token-55-4" morph="none" pos="word" start_char="8300">as</TOKEN>
<TOKEN end_char="8307" id="token-55-5" morph="none" pos="word" start_char="8303">we’ve</TOKEN>
<TOKEN end_char="8317" id="token-55-6" morph="none" pos="word" start_char="8309">explained</TOKEN>
<TOKEN end_char="8324" id="token-55-7" morph="none" pos="word" start_char="8319">before</TOKEN>
<TOKEN end_char="8325" id="token-55-8" morph="none" pos="punct" start_char="8325">,</TOKEN>
<TOKEN end_char="8329" id="token-55-9" morph="none" pos="word" start_char="8327">all</TOKEN>
<TOKEN end_char="8335" id="token-55-10" morph="none" pos="word" start_char="8331">lines</TOKEN>
<TOKEN end_char="8338" id="token-55-11" morph="none" pos="word" start_char="8337">of</TOKEN>
<TOKEN end_char="8347" id="token-55-12" morph="none" pos="word" start_char="8340">evidence</TOKEN>
<TOKEN end_char="8353" id="token-55-13" morph="none" pos="word" start_char="8349">point</TOKEN>
<TOKEN end_char="8356" id="token-55-14" morph="none" pos="word" start_char="8355">to</TOKEN>
<TOKEN end_char="8360" id="token-55-15" morph="none" pos="word" start_char="8358">the</TOKEN>
<TOKEN end_char="8366" id="token-55-16" morph="none" pos="word" start_char="8362">virus</TOKEN>
<TOKEN end_char="8373" id="token-55-17" morph="none" pos="word" start_char="8368">coming</TOKEN>
<TOKEN end_char="8378" id="token-55-18" morph="none" pos="word" start_char="8375">from</TOKEN>
<TOKEN end_char="8381" id="token-55-19" morph="none" pos="word" start_char="8380">an</TOKEN>
<TOKEN end_char="8388" id="token-55-20" morph="none" pos="word" start_char="8383">animal</TOKEN>
<TOKEN end_char="8389" id="token-55-21" morph="none" pos="punct" start_char="8389">.</TOKEN>
</SEG>
<SEG end_char="8622" id="segment-56" start_char="8391">
<ORIGINAL_TEXT>That’s consistent with what scientists have learned about the ecology of coronaviruses in the last 20 years, Sheahan said, including SARS and MERS — and it fits with the fact that the virus shares 96% of its genome with a bat virus.</ORIGINAL_TEXT>
<TOKEN end_char="8396" id="token-56-0" morph="none" pos="word" start_char="8391">That’s</TOKEN>
<TOKEN end_char="8407" id="token-56-1" morph="none" pos="word" start_char="8398">consistent</TOKEN>
<TOKEN end_char="8412" id="token-56-2" morph="none" pos="word" start_char="8409">with</TOKEN>
<TOKEN end_char="8417" id="token-56-3" morph="none" pos="word" start_char="8414">what</TOKEN>
<TOKEN end_char="8428" id="token-56-4" morph="none" pos="word" start_char="8419">scientists</TOKEN>
<TOKEN end_char="8433" id="token-56-5" morph="none" pos="word" start_char="8430">have</TOKEN>
<TOKEN end_char="8441" id="token-56-6" morph="none" pos="word" start_char="8435">learned</TOKEN>
<TOKEN end_char="8447" id="token-56-7" morph="none" pos="word" start_char="8443">about</TOKEN>
<TOKEN end_char="8451" id="token-56-8" morph="none" pos="word" start_char="8449">the</TOKEN>
<TOKEN end_char="8459" id="token-56-9" morph="none" pos="word" start_char="8453">ecology</TOKEN>
<TOKEN end_char="8462" id="token-56-10" morph="none" pos="word" start_char="8461">of</TOKEN>
<TOKEN end_char="8476" id="token-56-11" morph="none" pos="word" start_char="8464">coronaviruses</TOKEN>
<TOKEN end_char="8479" id="token-56-12" morph="none" pos="word" start_char="8478">in</TOKEN>
<TOKEN end_char="8483" id="token-56-13" morph="none" pos="word" start_char="8481">the</TOKEN>
<TOKEN end_char="8488" id="token-56-14" morph="none" pos="word" start_char="8485">last</TOKEN>
<TOKEN end_char="8491" id="token-56-15" morph="none" pos="word" start_char="8490">20</TOKEN>
<TOKEN end_char="8497" id="token-56-16" morph="none" pos="word" start_char="8493">years</TOKEN>
<TOKEN end_char="8498" id="token-56-17" morph="none" pos="punct" start_char="8498">,</TOKEN>
<TOKEN end_char="8506" id="token-56-18" morph="none" pos="word" start_char="8500">Sheahan</TOKEN>
<TOKEN end_char="8511" id="token-56-19" morph="none" pos="word" start_char="8508">said</TOKEN>
<TOKEN end_char="8512" id="token-56-20" morph="none" pos="punct" start_char="8512">,</TOKEN>
<TOKEN end_char="8522" id="token-56-21" morph="none" pos="word" start_char="8514">including</TOKEN>
<TOKEN end_char="8527" id="token-56-22" morph="none" pos="word" start_char="8524">SARS</TOKEN>
<TOKEN end_char="8531" id="token-56-23" morph="none" pos="word" start_char="8529">and</TOKEN>
<TOKEN end_char="8536" id="token-56-24" morph="none" pos="word" start_char="8533">MERS</TOKEN>
<TOKEN end_char="8538" id="token-56-25" morph="none" pos="punct" start_char="8538">—</TOKEN>
<TOKEN end_char="8542" id="token-56-26" morph="none" pos="word" start_char="8540">and</TOKEN>
<TOKEN end_char="8545" id="token-56-27" morph="none" pos="word" start_char="8544">it</TOKEN>
<TOKEN end_char="8550" id="token-56-28" morph="none" pos="word" start_char="8547">fits</TOKEN>
<TOKEN end_char="8555" id="token-56-29" morph="none" pos="word" start_char="8552">with</TOKEN>
<TOKEN end_char="8559" id="token-56-30" morph="none" pos="word" start_char="8557">the</TOKEN>
<TOKEN end_char="8564" id="token-56-31" morph="none" pos="word" start_char="8561">fact</TOKEN>
<TOKEN end_char="8569" id="token-56-32" morph="none" pos="word" start_char="8566">that</TOKEN>
<TOKEN end_char="8573" id="token-56-33" morph="none" pos="word" start_char="8571">the</TOKEN>
<TOKEN end_char="8579" id="token-56-34" morph="none" pos="word" start_char="8575">virus</TOKEN>
<TOKEN end_char="8586" id="token-56-35" morph="none" pos="word" start_char="8581">shares</TOKEN>
<TOKEN end_char="8589" id="token-56-36" morph="none" pos="word" start_char="8588">96</TOKEN>
<TOKEN end_char="8590" id="token-56-37" morph="none" pos="punct" start_char="8590">%</TOKEN>
<TOKEN end_char="8593" id="token-56-38" morph="none" pos="word" start_char="8592">of</TOKEN>
<TOKEN end_char="8597" id="token-56-39" morph="none" pos="word" start_char="8595">its</TOKEN>
<TOKEN end_char="8604" id="token-56-40" morph="none" pos="word" start_char="8599">genome</TOKEN>
<TOKEN end_char="8609" id="token-56-41" morph="none" pos="word" start_char="8606">with</TOKEN>
<TOKEN end_char="8611" id="token-56-42" morph="none" pos="word" start_char="8611">a</TOKEN>
<TOKEN end_char="8615" id="token-56-43" morph="none" pos="word" start_char="8613">bat</TOKEN>
<TOKEN end_char="8621" id="token-56-44" morph="none" pos="word" start_char="8617">virus</TOKEN>
<TOKEN end_char="8622" id="token-56-45" morph="none" pos="punct" start_char="8622">.</TOKEN>
</SEG>
<SEG end_char="8719" id="segment-57" start_char="8625">
<ORIGINAL_TEXT>"The genetic data is pointing to this virus coming from a bat reservoir," he said, "not a lab."</ORIGINAL_TEXT>
<TOKEN end_char="8625" id="token-57-0" morph="none" pos="punct" start_char="8625">"</TOKEN>
<TOKEN end_char="8628" id="token-57-1" morph="none" pos="word" start_char="8626">The</TOKEN>
<TOKEN end_char="8636" id="token-57-2" morph="none" pos="word" start_char="8630">genetic</TOKEN>
<TOKEN end_char="8641" id="token-57-3" morph="none" pos="word" start_char="8638">data</TOKEN>
<TOKEN end_char="8644" id="token-57-4" morph="none" pos="word" start_char="8643">is</TOKEN>
<TOKEN end_char="8653" id="token-57-5" morph="none" pos="word" start_char="8646">pointing</TOKEN>
<TOKEN end_char="8656" id="token-57-6" morph="none" pos="word" start_char="8655">to</TOKEN>
<TOKEN end_char="8661" id="token-57-7" morph="none" pos="word" start_char="8658">this</TOKEN>
<TOKEN end_char="8667" id="token-57-8" morph="none" pos="word" start_char="8663">virus</TOKEN>
<TOKEN end_char="8674" id="token-57-9" morph="none" pos="word" start_char="8669">coming</TOKEN>
<TOKEN end_char="8679" id="token-57-10" morph="none" pos="word" start_char="8676">from</TOKEN>
<TOKEN end_char="8681" id="token-57-11" morph="none" pos="word" start_char="8681">a</TOKEN>
<TOKEN end_char="8685" id="token-57-12" morph="none" pos="word" start_char="8683">bat</TOKEN>
<TOKEN end_char="8695" id="token-57-13" morph="none" pos="word" start_char="8687">reservoir</TOKEN>
<TOKEN end_char="8697" id="token-57-14" morph="none" pos="punct" start_char="8696">,"</TOKEN>
<TOKEN end_char="8700" id="token-57-15" morph="none" pos="word" start_char="8699">he</TOKEN>
<TOKEN end_char="8705" id="token-57-16" morph="none" pos="word" start_char="8702">said</TOKEN>
<TOKEN end_char="8706" id="token-57-17" morph="none" pos="punct" start_char="8706">,</TOKEN>
<TOKEN end_char="8708" id="token-57-18" morph="none" pos="punct" start_char="8708">"</TOKEN>
<TOKEN end_char="8711" id="token-57-19" morph="none" pos="word" start_char="8709">not</TOKEN>
<TOKEN end_char="8713" id="token-57-20" morph="none" pos="word" start_char="8713">a</TOKEN>
<TOKEN end_char="8717" id="token-57-21" morph="none" pos="word" start_char="8715">lab</TOKEN>
<TOKEN end_char="8719" id="token-57-22" morph="none" pos="punct" start_char="8718">."</TOKEN>
</SEG>
<SEG end_char="8865" id="segment-58" start_char="8722">
<ORIGINAL_TEXT>And not only are there no HIV "insertions" in the virus, but by looking at the virus’ genome, scientists also see zero signs of human tampering.</ORIGINAL_TEXT>
<TOKEN end_char="8724" id="token-58-0" morph="none" pos="word" start_char="8722">And</TOKEN>
<TOKEN end_char="8728" id="token-58-1" morph="none" pos="word" start_char="8726">not</TOKEN>
<TOKEN end_char="8733" id="token-58-2" morph="none" pos="word" start_char="8730">only</TOKEN>
<TOKEN end_char="8737" id="token-58-3" morph="none" pos="word" start_char="8735">are</TOKEN>
<TOKEN end_char="8743" id="token-58-4" morph="none" pos="word" start_char="8739">there</TOKEN>
<TOKEN end_char="8746" id="token-58-5" morph="none" pos="word" start_char="8745">no</TOKEN>
<TOKEN end_char="8750" id="token-58-6" morph="none" pos="word" start_char="8748">HIV</TOKEN>
<TOKEN end_char="8752" id="token-58-7" morph="none" pos="punct" start_char="8752">"</TOKEN>
<TOKEN end_char="8762" id="token-58-8" morph="none" pos="word" start_char="8753">insertions</TOKEN>
<TOKEN end_char="8763" id="token-58-9" morph="none" pos="punct" start_char="8763">"</TOKEN>
<TOKEN end_char="8766" id="token-58-10" morph="none" pos="word" start_char="8765">in</TOKEN>
<TOKEN end_char="8770" id="token-58-11" morph="none" pos="word" start_char="8768">the</TOKEN>
<TOKEN end_char="8776" id="token-58-12" morph="none" pos="word" start_char="8772">virus</TOKEN>
<TOKEN end_char="8777" id="token-58-13" morph="none" pos="punct" start_char="8777">,</TOKEN>
<TOKEN end_char="8781" id="token-58-14" morph="none" pos="word" start_char="8779">but</TOKEN>
<TOKEN end_char="8784" id="token-58-15" morph="none" pos="word" start_char="8783">by</TOKEN>
<TOKEN end_char="8792" id="token-58-16" morph="none" pos="word" start_char="8786">looking</TOKEN>
<TOKEN end_char="8795" id="token-58-17" morph="none" pos="word" start_char="8794">at</TOKEN>
<TOKEN end_char="8799" id="token-58-18" morph="none" pos="word" start_char="8797">the</TOKEN>
<TOKEN end_char="8805" id="token-58-19" morph="none" pos="word" start_char="8801">virus</TOKEN>
<TOKEN end_char="8806" id="token-58-20" morph="none" pos="punct" start_char="8806">’</TOKEN>
<TOKEN end_char="8813" id="token-58-21" morph="none" pos="word" start_char="8808">genome</TOKEN>
<TOKEN end_char="8814" id="token-58-22" morph="none" pos="punct" start_char="8814">,</TOKEN>
<TOKEN end_char="8825" id="token-58-23" morph="none" pos="word" start_char="8816">scientists</TOKEN>
<TOKEN end_char="8830" id="token-58-24" morph="none" pos="word" start_char="8827">also</TOKEN>
<TOKEN end_char="8834" id="token-58-25" morph="none" pos="word" start_char="8832">see</TOKEN>
<TOKEN end_char="8839" id="token-58-26" morph="none" pos="word" start_char="8836">zero</TOKEN>
<TOKEN end_char="8845" id="token-58-27" morph="none" pos="word" start_char="8841">signs</TOKEN>
<TOKEN end_char="8848" id="token-58-28" morph="none" pos="word" start_char="8847">of</TOKEN>
<TOKEN end_char="8854" id="token-58-29" morph="none" pos="word" start_char="8850">human</TOKEN>
<TOKEN end_char="8864" id="token-58-30" morph="none" pos="word" start_char="8856">tampering</TOKEN>
<TOKEN end_char="8865" id="token-58-31" morph="none" pos="punct" start_char="8865">.</TOKEN>
</SEG>
<SEG end_char="9092" id="segment-59" start_char="8868">
<ORIGINAL_TEXT>Bedford, the Fred Hutchinson computational biologist, pointed out on Twitter that the virus’ genetic differences to its most recent common ancestor are "consistent with differences expected to arise during natural evolution."</ORIGINAL_TEXT>
<TOKEN end_char="8874" id="token-59-0" morph="none" pos="word" start_char="8868">Bedford</TOKEN>
<TOKEN end_char="8875" id="token-59-1" morph="none" pos="punct" start_char="8875">,</TOKEN>
<TOKEN end_char="8879" id="token-59-2" morph="none" pos="word" start_char="8877">the</TOKEN>
<TOKEN end_char="8884" id="token-59-3" morph="none" pos="word" start_char="8881">Fred</TOKEN>
<TOKEN end_char="8895" id="token-59-4" morph="none" pos="word" start_char="8886">Hutchinson</TOKEN>
<TOKEN end_char="8909" id="token-59-5" morph="none" pos="word" start_char="8897">computational</TOKEN>
<TOKEN end_char="8919" id="token-59-6" morph="none" pos="word" start_char="8911">biologist</TOKEN>
<TOKEN end_char="8920" id="token-59-7" morph="none" pos="punct" start_char="8920">,</TOKEN>
<TOKEN end_char="8928" id="token-59-8" morph="none" pos="word" start_char="8922">pointed</TOKEN>
<TOKEN end_char="8932" id="token-59-9" morph="none" pos="word" start_char="8930">out</TOKEN>
<TOKEN end_char="8935" id="token-59-10" morph="none" pos="word" start_char="8934">on</TOKEN>
<TOKEN end_char="8943" id="token-59-11" morph="none" pos="word" start_char="8937">Twitter</TOKEN>
<TOKEN end_char="8948" id="token-59-12" morph="none" pos="word" start_char="8945">that</TOKEN>
<TOKEN end_char="8952" id="token-59-13" morph="none" pos="word" start_char="8950">the</TOKEN>
<TOKEN end_char="8958" id="token-59-14" morph="none" pos="word" start_char="8954">virus</TOKEN>
<TOKEN end_char="8959" id="token-59-15" morph="none" pos="punct" start_char="8959">’</TOKEN>
<TOKEN end_char="8967" id="token-59-16" morph="none" pos="word" start_char="8961">genetic</TOKEN>
<TOKEN end_char="8979" id="token-59-17" morph="none" pos="word" start_char="8969">differences</TOKEN>
<TOKEN end_char="8982" id="token-59-18" morph="none" pos="word" start_char="8981">to</TOKEN>
<TOKEN end_char="8986" id="token-59-19" morph="none" pos="word" start_char="8984">its</TOKEN>
<TOKEN end_char="8991" id="token-59-20" morph="none" pos="word" start_char="8988">most</TOKEN>
<TOKEN end_char="8998" id="token-59-21" morph="none" pos="word" start_char="8993">recent</TOKEN>
<TOKEN end_char="9005" id="token-59-22" morph="none" pos="word" start_char="9000">common</TOKEN>
<TOKEN end_char="9014" id="token-59-23" morph="none" pos="word" start_char="9007">ancestor</TOKEN>
<TOKEN end_char="9018" id="token-59-24" morph="none" pos="word" start_char="9016">are</TOKEN>
<TOKEN end_char="9020" id="token-59-25" morph="none" pos="punct" start_char="9020">"</TOKEN>
<TOKEN end_char="9030" id="token-59-26" morph="none" pos="word" start_char="9021">consistent</TOKEN>
<TOKEN end_char="9035" id="token-59-27" morph="none" pos="word" start_char="9032">with</TOKEN>
<TOKEN end_char="9047" id="token-59-28" morph="none" pos="word" start_char="9037">differences</TOKEN>
<TOKEN end_char="9056" id="token-59-29" morph="none" pos="word" start_char="9049">expected</TOKEN>
<TOKEN end_char="9059" id="token-59-30" morph="none" pos="word" start_char="9058">to</TOKEN>
<TOKEN end_char="9065" id="token-59-31" morph="none" pos="word" start_char="9061">arise</TOKEN>
<TOKEN end_char="9072" id="token-59-32" morph="none" pos="word" start_char="9067">during</TOKEN>
<TOKEN end_char="9080" id="token-59-33" morph="none" pos="word" start_char="9074">natural</TOKEN>
<TOKEN end_char="9090" id="token-59-34" morph="none" pos="word" start_char="9082">evolution</TOKEN>
<TOKEN end_char="9092" id="token-59-35" morph="none" pos="punct" start_char="9091">."</TOKEN>
</SEG>
<SEG end_char="9249" id="segment-60" start_char="9095">
<ORIGINAL_TEXT>An engineered virus, he explained, would likely have a "distorted" amino acid to nucleotide ratio, and also have changes focused in on a "subset of genes."</ORIGINAL_TEXT>
<TOKEN end_char="9096" id="token-60-0" morph="none" pos="word" start_char="9095">An</TOKEN>
<TOKEN end_char="9107" id="token-60-1" morph="none" pos="word" start_char="9098">engineered</TOKEN>
<TOKEN end_char="9113" id="token-60-2" morph="none" pos="word" start_char="9109">virus</TOKEN>
<TOKEN end_char="9114" id="token-60-3" morph="none" pos="punct" start_char="9114">,</TOKEN>
<TOKEN end_char="9117" id="token-60-4" morph="none" pos="word" start_char="9116">he</TOKEN>
<TOKEN end_char="9127" id="token-60-5" morph="none" pos="word" start_char="9119">explained</TOKEN>
<TOKEN end_char="9128" id="token-60-6" morph="none" pos="punct" start_char="9128">,</TOKEN>
<TOKEN end_char="9134" id="token-60-7" morph="none" pos="word" start_char="9130">would</TOKEN>
<TOKEN end_char="9141" id="token-60-8" morph="none" pos="word" start_char="9136">likely</TOKEN>
<TOKEN end_char="9146" id="token-60-9" morph="none" pos="word" start_char="9143">have</TOKEN>
<TOKEN end_char="9148" id="token-60-10" morph="none" pos="word" start_char="9148">a</TOKEN>
<TOKEN end_char="9150" id="token-60-11" morph="none" pos="punct" start_char="9150">"</TOKEN>
<TOKEN end_char="9159" id="token-60-12" morph="none" pos="word" start_char="9151">distorted</TOKEN>
<TOKEN end_char="9160" id="token-60-13" morph="none" pos="punct" start_char="9160">"</TOKEN>
<TOKEN end_char="9166" id="token-60-14" morph="none" pos="word" start_char="9162">amino</TOKEN>
<TOKEN end_char="9171" id="token-60-15" morph="none" pos="word" start_char="9168">acid</TOKEN>
<TOKEN end_char="9174" id="token-60-16" morph="none" pos="word" start_char="9173">to</TOKEN>
<TOKEN end_char="9185" id="token-60-17" morph="none" pos="word" start_char="9176">nucleotide</TOKEN>
<TOKEN end_char="9191" id="token-60-18" morph="none" pos="word" start_char="9187">ratio</TOKEN>
<TOKEN end_char="9192" id="token-60-19" morph="none" pos="punct" start_char="9192">,</TOKEN>
<TOKEN end_char="9196" id="token-60-20" morph="none" pos="word" start_char="9194">and</TOKEN>
<TOKEN end_char="9201" id="token-60-21" morph="none" pos="word" start_char="9198">also</TOKEN>
<TOKEN end_char="9206" id="token-60-22" morph="none" pos="word" start_char="9203">have</TOKEN>
<TOKEN end_char="9214" id="token-60-23" morph="none" pos="word" start_char="9208">changes</TOKEN>
<TOKEN end_char="9222" id="token-60-24" morph="none" pos="word" start_char="9216">focused</TOKEN>
<TOKEN end_char="9225" id="token-60-25" morph="none" pos="word" start_char="9224">in</TOKEN>
<TOKEN end_char="9228" id="token-60-26" morph="none" pos="word" start_char="9227">on</TOKEN>
<TOKEN end_char="9230" id="token-60-27" morph="none" pos="word" start_char="9230">a</TOKEN>
<TOKEN end_char="9232" id="token-60-28" morph="none" pos="punct" start_char="9232">"</TOKEN>
<TOKEN end_char="9238" id="token-60-29" morph="none" pos="word" start_char="9233">subset</TOKEN>
<TOKEN end_char="9241" id="token-60-30" morph="none" pos="word" start_char="9240">of</TOKEN>
<TOKEN end_char="9247" id="token-60-31" morph="none" pos="word" start_char="9243">genes</TOKEN>
<TOKEN end_char="9249" id="token-60-32" morph="none" pos="punct" start_char="9248">."</TOKEN>
</SEG>
<SEG end_char="9410" id="segment-61" start_char="9251">
<ORIGINAL_TEXT>In other words, when engineering occurs, it’s usually to bring about a meaningful change to the virus — but there’s no evidence of that in the 2019-nCoV genome.</ORIGINAL_TEXT>
<TOKEN end_char="9252" id="token-61-0" morph="none" pos="word" start_char="9251">In</TOKEN>
<TOKEN end_char="9258" id="token-61-1" morph="none" pos="word" start_char="9254">other</TOKEN>
<TOKEN end_char="9264" id="token-61-2" morph="none" pos="word" start_char="9260">words</TOKEN>
<TOKEN end_char="9265" id="token-61-3" morph="none" pos="punct" start_char="9265">,</TOKEN>
<TOKEN end_char="9270" id="token-61-4" morph="none" pos="word" start_char="9267">when</TOKEN>
<TOKEN end_char="9282" id="token-61-5" morph="none" pos="word" start_char="9272">engineering</TOKEN>
<TOKEN end_char="9289" id="token-61-6" morph="none" pos="word" start_char="9284">occurs</TOKEN>
<TOKEN end_char="9290" id="token-61-7" morph="none" pos="punct" start_char="9290">,</TOKEN>
<TOKEN end_char="9295" id="token-61-8" morph="none" pos="word" start_char="9292">it’s</TOKEN>
<TOKEN end_char="9303" id="token-61-9" morph="none" pos="word" start_char="9297">usually</TOKEN>
<TOKEN end_char="9306" id="token-61-10" morph="none" pos="word" start_char="9305">to</TOKEN>
<TOKEN end_char="9312" id="token-61-11" morph="none" pos="word" start_char="9308">bring</TOKEN>
<TOKEN end_char="9318" id="token-61-12" morph="none" pos="word" start_char="9314">about</TOKEN>
<TOKEN end_char="9320" id="token-61-13" morph="none" pos="word" start_char="9320">a</TOKEN>
<TOKEN end_char="9331" id="token-61-14" morph="none" pos="word" start_char="9322">meaningful</TOKEN>
<TOKEN end_char="9338" id="token-61-15" morph="none" pos="word" start_char="9333">change</TOKEN>
<TOKEN end_char="9341" id="token-61-16" morph="none" pos="word" start_char="9340">to</TOKEN>
<TOKEN end_char="9345" id="token-61-17" morph="none" pos="word" start_char="9343">the</TOKEN>
<TOKEN end_char="9351" id="token-61-18" morph="none" pos="word" start_char="9347">virus</TOKEN>
<TOKEN end_char="9353" id="token-61-19" morph="none" pos="punct" start_char="9353">—</TOKEN>
<TOKEN end_char="9357" id="token-61-20" morph="none" pos="word" start_char="9355">but</TOKEN>
<TOKEN end_char="9365" id="token-61-21" morph="none" pos="word" start_char="9359">there’s</TOKEN>
<TOKEN end_char="9368" id="token-61-22" morph="none" pos="word" start_char="9367">no</TOKEN>
<TOKEN end_char="9377" id="token-61-23" morph="none" pos="word" start_char="9370">evidence</TOKEN>
<TOKEN end_char="9380" id="token-61-24" morph="none" pos="word" start_char="9379">of</TOKEN>
<TOKEN end_char="9385" id="token-61-25" morph="none" pos="word" start_char="9382">that</TOKEN>
<TOKEN end_char="9388" id="token-61-26" morph="none" pos="word" start_char="9387">in</TOKEN>
<TOKEN end_char="9392" id="token-61-27" morph="none" pos="word" start_char="9390">the</TOKEN>
<TOKEN end_char="9402" id="token-61-28" morph="none" pos="unknown" start_char="9394">2019-nCoV</TOKEN>
<TOKEN end_char="9409" id="token-61-29" morph="none" pos="word" start_char="9404">genome</TOKEN>
<TOKEN end_char="9410" id="token-61-30" morph="none" pos="punct" start_char="9410">.</TOKEN>
</SEG>
<SEG end_char="9522" id="segment-62" start_char="9413">
<ORIGINAL_TEXT>Typically, scientists change nucleotides in a targeted way to create changes in the amino acids they code for.</ORIGINAL_TEXT>
<TOKEN end_char="9421" id="token-62-0" morph="none" pos="word" start_char="9413">Typically</TOKEN>
<TOKEN end_char="9422" id="token-62-1" morph="none" pos="punct" start_char="9422">,</TOKEN>
<TOKEN end_char="9433" id="token-62-2" morph="none" pos="word" start_char="9424">scientists</TOKEN>
<TOKEN end_char="9440" id="token-62-3" morph="none" pos="word" start_char="9435">change</TOKEN>
<TOKEN end_char="9452" id="token-62-4" morph="none" pos="word" start_char="9442">nucleotides</TOKEN>
<TOKEN end_char="9455" id="token-62-5" morph="none" pos="word" start_char="9454">in</TOKEN>
<TOKEN end_char="9457" id="token-62-6" morph="none" pos="word" start_char="9457">a</TOKEN>
<TOKEN end_char="9466" id="token-62-7" morph="none" pos="word" start_char="9459">targeted</TOKEN>
<TOKEN end_char="9470" id="token-62-8" morph="none" pos="word" start_char="9468">way</TOKEN>
<TOKEN end_char="9473" id="token-62-9" morph="none" pos="word" start_char="9472">to</TOKEN>
<TOKEN end_char="9480" id="token-62-10" morph="none" pos="word" start_char="9475">create</TOKEN>
<TOKEN end_char="9488" id="token-62-11" morph="none" pos="word" start_char="9482">changes</TOKEN>
<TOKEN end_char="9491" id="token-62-12" morph="none" pos="word" start_char="9490">in</TOKEN>
<TOKEN end_char="9495" id="token-62-13" morph="none" pos="word" start_char="9493">the</TOKEN>
<TOKEN end_char="9501" id="token-62-14" morph="none" pos="word" start_char="9497">amino</TOKEN>
<TOKEN end_char="9507" id="token-62-15" morph="none" pos="word" start_char="9503">acids</TOKEN>
<TOKEN end_char="9512" id="token-62-16" morph="none" pos="word" start_char="9509">they</TOKEN>
<TOKEN end_char="9517" id="token-62-17" morph="none" pos="word" start_char="9514">code</TOKEN>
<TOKEN end_char="9521" id="token-62-18" morph="none" pos="word" start_char="9519">for</TOKEN>
<TOKEN end_char="9522" id="token-62-19" morph="none" pos="punct" start_char="9522">.</TOKEN>
</SEG>
<SEG end_char="9635" id="segment-63" start_char="9524">
<ORIGINAL_TEXT>Since amino acids are the building blocks of proteins, that’s the way to change the proteins the virus produces.</ORIGINAL_TEXT>
<TOKEN end_char="9528" id="token-63-0" morph="none" pos="word" start_char="9524">Since</TOKEN>
<TOKEN end_char="9534" id="token-63-1" morph="none" pos="word" start_char="9530">amino</TOKEN>
<TOKEN end_char="9540" id="token-63-2" morph="none" pos="word" start_char="9536">acids</TOKEN>
<TOKEN end_char="9544" id="token-63-3" morph="none" pos="word" start_char="9542">are</TOKEN>
<TOKEN end_char="9548" id="token-63-4" morph="none" pos="word" start_char="9546">the</TOKEN>
<TOKEN end_char="9557" id="token-63-5" morph="none" pos="word" start_char="9550">building</TOKEN>
<TOKEN end_char="9564" id="token-63-6" morph="none" pos="word" start_char="9559">blocks</TOKEN>
<TOKEN end_char="9567" id="token-63-7" morph="none" pos="word" start_char="9566">of</TOKEN>
<TOKEN end_char="9576" id="token-63-8" morph="none" pos="word" start_char="9569">proteins</TOKEN>
<TOKEN end_char="9577" id="token-63-9" morph="none" pos="punct" start_char="9577">,</TOKEN>
<TOKEN end_char="9584" id="token-63-10" morph="none" pos="word" start_char="9579">that’s</TOKEN>
<TOKEN end_char="9588" id="token-63-11" morph="none" pos="word" start_char="9586">the</TOKEN>
<TOKEN end_char="9592" id="token-63-12" morph="none" pos="word" start_char="9590">way</TOKEN>
<TOKEN end_char="9595" id="token-63-13" morph="none" pos="word" start_char="9594">to</TOKEN>
<TOKEN end_char="9602" id="token-63-14" morph="none" pos="word" start_char="9597">change</TOKEN>
<TOKEN end_char="9606" id="token-63-15" morph="none" pos="word" start_char="9604">the</TOKEN>
<TOKEN end_char="9615" id="token-63-16" morph="none" pos="word" start_char="9608">proteins</TOKEN>
<TOKEN end_char="9619" id="token-63-17" morph="none" pos="word" start_char="9617">the</TOKEN>
<TOKEN end_char="9625" id="token-63-18" morph="none" pos="word" start_char="9621">virus</TOKEN>
<TOKEN end_char="9634" id="token-63-19" morph="none" pos="word" start_char="9627">produces</TOKEN>
<TOKEN end_char="9635" id="token-63-20" morph="none" pos="punct" start_char="9635">.</TOKEN>
</SEG>
<SEG end_char="9820" id="segment-64" start_char="9638">
<ORIGINAL_TEXT>But as Bedford said, out of all the nucleotide changes, relatively few — around 14% — alter the corresponding amino acid, or about what you would expect in a naturally evolving virus.</ORIGINAL_TEXT>
<TOKEN end_char="9640" id="token-64-0" morph="none" pos="word" start_char="9638">But</TOKEN>
<TOKEN end_char="9643" id="token-64-1" morph="none" pos="word" start_char="9642">as</TOKEN>
<TOKEN end_char="9651" id="token-64-2" morph="none" pos="word" start_char="9645">Bedford</TOKEN>
<TOKEN end_char="9656" id="token-64-3" morph="none" pos="word" start_char="9653">said</TOKEN>
<TOKEN end_char="9657" id="token-64-4" morph="none" pos="punct" start_char="9657">,</TOKEN>
<TOKEN end_char="9661" id="token-64-5" morph="none" pos="word" start_char="9659">out</TOKEN>
<TOKEN end_char="9664" id="token-64-6" morph="none" pos="word" start_char="9663">of</TOKEN>
<TOKEN end_char="9668" id="token-64-7" morph="none" pos="word" start_char="9666">all</TOKEN>
<TOKEN end_char="9672" id="token-64-8" morph="none" pos="word" start_char="9670">the</TOKEN>
<TOKEN end_char="9683" id="token-64-9" morph="none" pos="word" start_char="9674">nucleotide</TOKEN>
<TOKEN end_char="9691" id="token-64-10" morph="none" pos="word" start_char="9685">changes</TOKEN>
<TOKEN end_char="9692" id="token-64-11" morph="none" pos="punct" start_char="9692">,</TOKEN>
<TOKEN end_char="9703" id="token-64-12" morph="none" pos="word" start_char="9694">relatively</TOKEN>
<TOKEN end_char="9707" id="token-64-13" morph="none" pos="word" start_char="9705">few</TOKEN>
<TOKEN end_char="9709" id="token-64-14" morph="none" pos="punct" start_char="9709">—</TOKEN>
<TOKEN end_char="9716" id="token-64-15" morph="none" pos="word" start_char="9711">around</TOKEN>
<TOKEN end_char="9719" id="token-64-16" morph="none" pos="word" start_char="9718">14</TOKEN>
<TOKEN end_char="9720" id="token-64-17" morph="none" pos="punct" start_char="9720">%</TOKEN>
<TOKEN end_char="9722" id="token-64-18" morph="none" pos="punct" start_char="9722">—</TOKEN>
<TOKEN end_char="9728" id="token-64-19" morph="none" pos="word" start_char="9724">alter</TOKEN>
<TOKEN end_char="9732" id="token-64-20" morph="none" pos="word" start_char="9730">the</TOKEN>
<TOKEN end_char="9746" id="token-64-21" morph="none" pos="word" start_char="9734">corresponding</TOKEN>
<TOKEN end_char="9752" id="token-64-22" morph="none" pos="word" start_char="9748">amino</TOKEN>
<TOKEN end_char="9757" id="token-64-23" morph="none" pos="word" start_char="9754">acid</TOKEN>
<TOKEN end_char="9758" id="token-64-24" morph="none" pos="punct" start_char="9758">,</TOKEN>
<TOKEN end_char="9761" id="token-64-25" morph="none" pos="word" start_char="9760">or</TOKEN>
<TOKEN end_char="9767" id="token-64-26" morph="none" pos="word" start_char="9763">about</TOKEN>
<TOKEN end_char="9772" id="token-64-27" morph="none" pos="word" start_char="9769">what</TOKEN>
<TOKEN end_char="9776" id="token-64-28" morph="none" pos="word" start_char="9774">you</TOKEN>
<TOKEN end_char="9782" id="token-64-29" morph="none" pos="word" start_char="9778">would</TOKEN>
<TOKEN end_char="9789" id="token-64-30" morph="none" pos="word" start_char="9784">expect</TOKEN>
<TOKEN end_char="9792" id="token-64-31" morph="none" pos="word" start_char="9791">in</TOKEN>
<TOKEN end_char="9794" id="token-64-32" morph="none" pos="word" start_char="9794">a</TOKEN>
<TOKEN end_char="9804" id="token-64-33" morph="none" pos="word" start_char="9796">naturally</TOKEN>
<TOKEN end_char="9813" id="token-64-34" morph="none" pos="word" start_char="9806">evolving</TOKEN>
<TOKEN end_char="9819" id="token-64-35" morph="none" pos="word" start_char="9815">virus</TOKEN>
<TOKEN end_char="9820" id="token-64-36" morph="none" pos="punct" start_char="9820">.</TOKEN>
</SEG>
<SEG end_char="9916" id="segment-65" start_char="9822">
<ORIGINAL_TEXT>This ratio also matches that of the bat virus that’s found to be the most similar to 2019-nCoV.</ORIGINAL_TEXT>
<TOKEN end_char="9825" id="token-65-0" morph="none" pos="word" start_char="9822">This</TOKEN>
<TOKEN end_char="9831" id="token-65-1" morph="none" pos="word" start_char="9827">ratio</TOKEN>
<TOKEN end_char="9836" id="token-65-2" morph="none" pos="word" start_char="9833">also</TOKEN>
<TOKEN end_char="9844" id="token-65-3" morph="none" pos="word" start_char="9838">matches</TOKEN>
<TOKEN end_char="9849" id="token-65-4" morph="none" pos="word" start_char="9846">that</TOKEN>
<TOKEN end_char="9852" id="token-65-5" morph="none" pos="word" start_char="9851">of</TOKEN>
<TOKEN end_char="9856" id="token-65-6" morph="none" pos="word" start_char="9854">the</TOKEN>
<TOKEN end_char="9860" id="token-65-7" morph="none" pos="word" start_char="9858">bat</TOKEN>
<TOKEN end_char="9866" id="token-65-8" morph="none" pos="word" start_char="9862">virus</TOKEN>
<TOKEN end_char="9873" id="token-65-9" morph="none" pos="word" start_char="9868">that’s</TOKEN>
<TOKEN end_char="9879" id="token-65-10" morph="none" pos="word" start_char="9875">found</TOKEN>
<TOKEN end_char="9882" id="token-65-11" morph="none" pos="word" start_char="9881">to</TOKEN>
<TOKEN end_char="9885" id="token-65-12" morph="none" pos="word" start_char="9884">be</TOKEN>
<TOKEN end_char="9889" id="token-65-13" morph="none" pos="word" start_char="9887">the</TOKEN>
<TOKEN end_char="9894" id="token-65-14" morph="none" pos="word" start_char="9891">most</TOKEN>
<TOKEN end_char="9902" id="token-65-15" morph="none" pos="word" start_char="9896">similar</TOKEN>
<TOKEN end_char="9905" id="token-65-16" morph="none" pos="word" start_char="9904">to</TOKEN>
<TOKEN end_char="9915" id="token-65-17" morph="none" pos="unknown" start_char="9907">2019-nCoV</TOKEN>
<TOKEN end_char="9916" id="token-65-18" morph="none" pos="punct" start_char="9916">.</TOKEN>
</SEG>
<SEG end_char="10081" id="segment-66" start_char="9919">
<ORIGINAL_TEXT>Further, when comparing the amino acid changes that do exist, the number of changes in the respective genes in both 2019-nCoV and the bat virus are highly similar.</ORIGINAL_TEXT>
<TOKEN end_char="9925" id="token-66-0" morph="none" pos="word" start_char="9919">Further</TOKEN>
<TOKEN end_char="9926" id="token-66-1" morph="none" pos="punct" start_char="9926">,</TOKEN>
<TOKEN end_char="9931" id="token-66-2" morph="none" pos="word" start_char="9928">when</TOKEN>
<TOKEN end_char="9941" id="token-66-3" morph="none" pos="word" start_char="9933">comparing</TOKEN>
<TOKEN end_char="9945" id="token-66-4" morph="none" pos="word" start_char="9943">the</TOKEN>
<TOKEN end_char="9951" id="token-66-5" morph="none" pos="word" start_char="9947">amino</TOKEN>
<TOKEN end_char="9956" id="token-66-6" morph="none" pos="word" start_char="9953">acid</TOKEN>
<TOKEN end_char="9964" id="token-66-7" morph="none" pos="word" start_char="9958">changes</TOKEN>
<TOKEN end_char="9969" id="token-66-8" morph="none" pos="word" start_char="9966">that</TOKEN>
<TOKEN end_char="9972" id="token-66-9" morph="none" pos="word" start_char="9971">do</TOKEN>
<TOKEN end_char="9978" id="token-66-10" morph="none" pos="word" start_char="9974">exist</TOKEN>
<TOKEN end_char="9979" id="token-66-11" morph="none" pos="punct" start_char="9979">,</TOKEN>
<TOKEN end_char="9983" id="token-66-12" morph="none" pos="word" start_char="9981">the</TOKEN>
<TOKEN end_char="9990" id="token-66-13" morph="none" pos="word" start_char="9985">number</TOKEN>
<TOKEN end_char="9993" id="token-66-14" morph="none" pos="word" start_char="9992">of</TOKEN>
<TOKEN end_char="10001" id="token-66-15" morph="none" pos="word" start_char="9995">changes</TOKEN>
<TOKEN end_char="10004" id="token-66-16" morph="none" pos="word" start_char="10003">in</TOKEN>
<TOKEN end_char="10008" id="token-66-17" morph="none" pos="word" start_char="10006">the</TOKEN>
<TOKEN end_char="10019" id="token-66-18" morph="none" pos="word" start_char="10010">respective</TOKEN>
<TOKEN end_char="10025" id="token-66-19" morph="none" pos="word" start_char="10021">genes</TOKEN>
<TOKEN end_char="10028" id="token-66-20" morph="none" pos="word" start_char="10027">in</TOKEN>
<TOKEN end_char="10033" id="token-66-21" morph="none" pos="word" start_char="10030">both</TOKEN>
<TOKEN end_char="10043" id="token-66-22" morph="none" pos="unknown" start_char="10035">2019-nCoV</TOKEN>
<TOKEN end_char="10047" id="token-66-23" morph="none" pos="word" start_char="10045">and</TOKEN>
<TOKEN end_char="10051" id="token-66-24" morph="none" pos="word" start_char="10049">the</TOKEN>
<TOKEN end_char="10055" id="token-66-25" morph="none" pos="word" start_char="10053">bat</TOKEN>
<TOKEN end_char="10061" id="token-66-26" morph="none" pos="word" start_char="10057">virus</TOKEN>
<TOKEN end_char="10065" id="token-66-27" morph="none" pos="word" start_char="10063">are</TOKEN>
<TOKEN end_char="10072" id="token-66-28" morph="none" pos="word" start_char="10067">highly</TOKEN>
<TOKEN end_char="10080" id="token-66-29" morph="none" pos="word" start_char="10074">similar</TOKEN>
<TOKEN end_char="10081" id="token-66-30" morph="none" pos="punct" start_char="10081">.</TOKEN>
</SEG>
<SEG end_char="10221" id="segment-67" start_char="10083">
<ORIGINAL_TEXT>Again, if the virus had been engineered, one might expect many of the changes to cluster in one or two genes, but that’s not the case here.</ORIGINAL_TEXT>
<TOKEN end_char="10087" id="token-67-0" morph="none" pos="word" start_char="10083">Again</TOKEN>
<TOKEN end_char="10088" id="token-67-1" morph="none" pos="punct" start_char="10088">,</TOKEN>
<TOKEN end_char="10091" id="token-67-2" morph="none" pos="word" start_char="10090">if</TOKEN>
<TOKEN end_char="10095" id="token-67-3" morph="none" pos="word" start_char="10093">the</TOKEN>
<TOKEN end_char="10101" id="token-67-4" morph="none" pos="word" start_char="10097">virus</TOKEN>
<TOKEN end_char="10105" id="token-67-5" morph="none" pos="word" start_char="10103">had</TOKEN>
<TOKEN end_char="10110" id="token-67-6" morph="none" pos="word" start_char="10107">been</TOKEN>
<TOKEN end_char="10121" id="token-67-7" morph="none" pos="word" start_char="10112">engineered</TOKEN>
<TOKEN end_char="10122" id="token-67-8" morph="none" pos="punct" start_char="10122">,</TOKEN>
<TOKEN end_char="10126" id="token-67-9" morph="none" pos="word" start_char="10124">one</TOKEN>
<TOKEN end_char="10132" id="token-67-10" morph="none" pos="word" start_char="10128">might</TOKEN>
<TOKEN end_char="10139" id="token-67-11" morph="none" pos="word" start_char="10134">expect</TOKEN>
<TOKEN end_char="10144" id="token-67-12" morph="none" pos="word" start_char="10141">many</TOKEN>
<TOKEN end_char="10147" id="token-67-13" morph="none" pos="word" start_char="10146">of</TOKEN>
<TOKEN end_char="10151" id="token-67-14" morph="none" pos="word" start_char="10149">the</TOKEN>
<TOKEN end_char="10159" id="token-67-15" morph="none" pos="word" start_char="10153">changes</TOKEN>
<TOKEN end_char="10162" id="token-67-16" morph="none" pos="word" start_char="10161">to</TOKEN>
<TOKEN end_char="10170" id="token-67-17" morph="none" pos="word" start_char="10164">cluster</TOKEN>
<TOKEN end_char="10173" id="token-67-18" morph="none" pos="word" start_char="10172">in</TOKEN>
<TOKEN end_char="10177" id="token-67-19" morph="none" pos="word" start_char="10175">one</TOKEN>
<TOKEN end_char="10180" id="token-67-20" morph="none" pos="word" start_char="10179">or</TOKEN>
<TOKEN end_char="10184" id="token-67-21" morph="none" pos="word" start_char="10182">two</TOKEN>
<TOKEN end_char="10190" id="token-67-22" morph="none" pos="word" start_char="10186">genes</TOKEN>
<TOKEN end_char="10191" id="token-67-23" morph="none" pos="punct" start_char="10191">,</TOKEN>
<TOKEN end_char="10195" id="token-67-24" morph="none" pos="word" start_char="10193">but</TOKEN>
<TOKEN end_char="10202" id="token-67-25" morph="none" pos="word" start_char="10197">that’s</TOKEN>
<TOKEN end_char="10206" id="token-67-26" morph="none" pos="word" start_char="10204">not</TOKEN>
<TOKEN end_char="10210" id="token-67-27" morph="none" pos="word" start_char="10208">the</TOKEN>
<TOKEN end_char="10215" id="token-67-28" morph="none" pos="word" start_char="10212">case</TOKEN>
<TOKEN end_char="10220" id="token-67-29" morph="none" pos="word" start_char="10217">here</TOKEN>
<TOKEN end_char="10221" id="token-67-30" morph="none" pos="punct" start_char="10221">.</TOKEN>
</SEG>
<SEG end_char="10300" id="segment-68" start_char="10223">
<ORIGINAL_TEXT>All of this argues against the idea of the new virus having come out of a lab.</ORIGINAL_TEXT>
<TOKEN end_char="10225" id="token-68-0" morph="none" pos="word" start_char="10223">All</TOKEN>
<TOKEN end_char="10228" id="token-68-1" morph="none" pos="word" start_char="10227">of</TOKEN>
<TOKEN end_char="10233" id="token-68-2" morph="none" pos="word" start_char="10230">this</TOKEN>
<TOKEN end_char="10240" id="token-68-3" morph="none" pos="word" start_char="10235">argues</TOKEN>
<TOKEN end_char="10248" id="token-68-4" morph="none" pos="word" start_char="10242">against</TOKEN>
<TOKEN end_char="10252" id="token-68-5" morph="none" pos="word" start_char="10250">the</TOKEN>
<TOKEN end_char="10257" id="token-68-6" morph="none" pos="word" start_char="10254">idea</TOKEN>
<TOKEN end_char="10260" id="token-68-7" morph="none" pos="word" start_char="10259">of</TOKEN>
<TOKEN end_char="10264" id="token-68-8" morph="none" pos="word" start_char="10262">the</TOKEN>
<TOKEN end_char="10268" id="token-68-9" morph="none" pos="word" start_char="10266">new</TOKEN>
<TOKEN end_char="10274" id="token-68-10" morph="none" pos="word" start_char="10270">virus</TOKEN>
<TOKEN end_char="10281" id="token-68-11" morph="none" pos="word" start_char="10276">having</TOKEN>
<TOKEN end_char="10286" id="token-68-12" morph="none" pos="word" start_char="10283">come</TOKEN>
<TOKEN end_char="10290" id="token-68-13" morph="none" pos="word" start_char="10288">out</TOKEN>
<TOKEN end_char="10293" id="token-68-14" morph="none" pos="word" start_char="10292">of</TOKEN>
<TOKEN end_char="10295" id="token-68-15" morph="none" pos="word" start_char="10295">a</TOKEN>
<TOKEN end_char="10299" id="token-68-16" morph="none" pos="word" start_char="10297">lab</TOKEN>
<TOKEN end_char="10300" id="token-68-17" morph="none" pos="punct" start_char="10300">.</TOKEN>
</SEG>
<SEG end_char="10362" id="segment-69" start_char="10303">
<ORIGINAL_TEXT>Editor’s note: FactCheck.org is one of several organizations</ORIGINAL_TEXT>
<TOKEN end_char="10310" id="token-69-0" morph="none" pos="word" start_char="10303">Editor’s</TOKEN>
<TOKEN end_char="10315" id="token-69-1" morph="none" pos="word" start_char="10312">note</TOKEN>
<TOKEN end_char="10316" id="token-69-2" morph="none" pos="punct" start_char="10316">:</TOKEN>
<TOKEN end_char="10330" id="token-69-3" morph="none" pos="unknown" start_char="10318">FactCheck.org</TOKEN>
<TOKEN end_char="10333" id="token-69-4" morph="none" pos="word" start_char="10332">is</TOKEN>
<TOKEN end_char="10337" id="token-69-5" morph="none" pos="word" start_char="10335">one</TOKEN>
<TOKEN end_char="10340" id="token-69-6" morph="none" pos="word" start_char="10339">of</TOKEN>
<TOKEN end_char="10348" id="token-69-7" morph="none" pos="word" start_char="10342">several</TOKEN>
<TOKEN end_char="10362" id="token-69-8" morph="none" pos="word" start_char="10350">organizations</TOKEN>
</SEG>
<SEG end_char="10385" id="segment-70" start_char="10365">
<ORIGINAL_TEXT>working with Facebook</ORIGINAL_TEXT>
<TOKEN end_char="10371" id="token-70-0" morph="none" pos="word" start_char="10365">working</TOKEN>
<TOKEN end_char="10376" id="token-70-1" morph="none" pos="word" start_char="10373">with</TOKEN>
<TOKEN end_char="10385" id="token-70-2" morph="none" pos="word" start_char="10378">Facebook</TOKEN>
</SEG>
<SEG end_char="10435" id="segment-71" start_char="10388">
<ORIGINAL_TEXT>to debunk misinformation shared on social media.</ORIGINAL_TEXT>
<TOKEN end_char="10389" id="token-71-0" morph="none" pos="word" start_char="10388">to</TOKEN>
<TOKEN end_char="10396" id="token-71-1" morph="none" pos="word" start_char="10391">debunk</TOKEN>
<TOKEN end_char="10411" id="token-71-2" morph="none" pos="word" start_char="10398">misinformation</TOKEN>
<TOKEN end_char="10418" id="token-71-3" morph="none" pos="word" start_char="10413">shared</TOKEN>
<TOKEN end_char="10421" id="token-71-4" morph="none" pos="word" start_char="10420">on</TOKEN>
<TOKEN end_char="10428" id="token-71-5" morph="none" pos="word" start_char="10423">social</TOKEN>
<TOKEN end_char="10434" id="token-71-6" morph="none" pos="word" start_char="10430">media</TOKEN>
<TOKEN end_char="10435" id="token-71-7" morph="none" pos="punct" start_char="10435">.</TOKEN>
</SEG>
<SEG end_char="10475" id="segment-72" start_char="10437">
<ORIGINAL_TEXT>Our previous stories can be found here.</ORIGINAL_TEXT>
<TOKEN end_char="10439" id="token-72-0" morph="none" pos="word" start_char="10437">Our</TOKEN>
<TOKEN end_char="10448" id="token-72-1" morph="none" pos="word" start_char="10441">previous</TOKEN>
<TOKEN end_char="10456" id="token-72-2" morph="none" pos="word" start_char="10450">stories</TOKEN>
<TOKEN end_char="10460" id="token-72-3" morph="none" pos="word" start_char="10458">can</TOKEN>
<TOKEN end_char="10463" id="token-72-4" morph="none" pos="word" start_char="10462">be</TOKEN>
<TOKEN end_char="10469" id="token-72-5" morph="none" pos="word" start_char="10465">found</TOKEN>
<TOKEN end_char="10474" id="token-72-6" morph="none" pos="word" start_char="10471">here</TOKEN>
<TOKEN end_char="10475" id="token-72-7" morph="none" pos="punct" start_char="10475">.</TOKEN>
</SEG>
<SEG end_char="10485" id="segment-73" start_char="10479">
<ORIGINAL_TEXT>Sources</ORIGINAL_TEXT>
<TOKEN end_char="10485" id="token-73-0" morph="none" pos="word" start_char="10479">Sources</TOKEN>
</SEG>
<SEG end_char="10506" id="segment-74" start_char="10489">
<ORIGINAL_TEXT>McDonald, Jessica.</ORIGINAL_TEXT>
<TOKEN end_char="10496" id="token-74-0" morph="none" pos="word" start_char="10489">McDonald</TOKEN>
<TOKEN end_char="10497" id="token-74-1" morph="none" pos="punct" start_char="10497">,</TOKEN>
<TOKEN end_char="10505" id="token-74-2" morph="none" pos="word" start_char="10499">Jessica</TOKEN>
<TOKEN end_char="10506" id="token-74-3" morph="none" pos="punct" start_char="10506">.</TOKEN>
</SEG>
<SEG end_char="10536" id="segment-75" start_char="10508">
<ORIGINAL_TEXT>"Q on the Wuhan Coronavirus."</ORIGINAL_TEXT>
<TOKEN end_char="10508" id="token-75-0" morph="none" pos="punct" start_char="10508">"</TOKEN>
<TOKEN end_char="10509" id="token-75-1" morph="none" pos="word" start_char="10509">Q</TOKEN>
<TOKEN end_char="10512" id="token-75-2" morph="none" pos="word" start_char="10511">on</TOKEN>
<TOKEN end_char="10516" id="token-75-3" morph="none" pos="word" start_char="10514">the</TOKEN>
<TOKEN end_char="10522" id="token-75-4" morph="none" pos="word" start_char="10518">Wuhan</TOKEN>
<TOKEN end_char="10534" id="token-75-5" morph="none" pos="word" start_char="10524">Coronavirus</TOKEN>
<TOKEN end_char="10536" id="token-75-6" morph="none" pos="punct" start_char="10535">."</TOKEN>
</SEG>
<SEG end_char="10551" id="segment-76" start_char="10538">
<ORIGINAL_TEXT>FactCheck.org.</ORIGINAL_TEXT>
<TOKEN end_char="10550" id="token-76-0" morph="none" pos="unknown" start_char="10538">FactCheck.org</TOKEN>
<TOKEN end_char="10551" id="token-76-1" morph="none" pos="punct" start_char="10551">.</TOKEN>
</SEG>
<SEG end_char="10564" id="segment-77" start_char="10553">
<ORIGINAL_TEXT>30 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="10554" id="token-77-0" morph="none" pos="word" start_char="10553">30</TOKEN>
<TOKEN end_char="10558" id="token-77-1" morph="none" pos="word" start_char="10556">Jan</TOKEN>
<TOKEN end_char="10563" id="token-77-2" morph="none" pos="word" start_char="10560">2020</TOKEN>
<TOKEN end_char="10564" id="token-77-3" morph="none" pos="punct" start_char="10564">.</TOKEN>
</SEG>
<SEG end_char="10584" id="segment-78" start_char="10567">
<ORIGINAL_TEXT>McDonald, Jessica.</ORIGINAL_TEXT>
<TOKEN end_char="10574" id="token-78-0" morph="none" pos="word" start_char="10567">McDonald</TOKEN>
<TOKEN end_char="10575" id="token-78-1" morph="none" pos="punct" start_char="10575">,</TOKEN>
<TOKEN end_char="10583" id="token-78-2" morph="none" pos="word" start_char="10577">Jessica</TOKEN>
<TOKEN end_char="10584" id="token-78-3" morph="none" pos="punct" start_char="10584">.</TOKEN>
</SEG>
<SEG end_char="10649" id="segment-79" start_char="10586">
<ORIGINAL_TEXT>"Social Media Posts Spread Bogus Coronavirus Conspiracy Theory."</ORIGINAL_TEXT>
<TOKEN end_char="10586" id="token-79-0" morph="none" pos="punct" start_char="10586">"</TOKEN>
<TOKEN end_char="10592" id="token-79-1" morph="none" pos="word" start_char="10587">Social</TOKEN>
<TOKEN end_char="10598" id="token-79-2" morph="none" pos="word" start_char="10594">Media</TOKEN>
<TOKEN end_char="10604" id="token-79-3" morph="none" pos="word" start_char="10600">Posts</TOKEN>
<TOKEN end_char="10611" id="token-79-4" morph="none" pos="word" start_char="10606">Spread</TOKEN>
<TOKEN end_char="10617" id="token-79-5" morph="none" pos="word" start_char="10613">Bogus</TOKEN>
<TOKEN end_char="10629" id="token-79-6" morph="none" pos="word" start_char="10619">Coronavirus</TOKEN>
<TOKEN end_char="10640" id="token-79-7" morph="none" pos="word" start_char="10631">Conspiracy</TOKEN>
<TOKEN end_char="10647" id="token-79-8" morph="none" pos="word" start_char="10642">Theory</TOKEN>
<TOKEN end_char="10649" id="token-79-9" morph="none" pos="punct" start_char="10648">."</TOKEN>
</SEG>
<SEG end_char="10664" id="segment-80" start_char="10651">
<ORIGINAL_TEXT>FactCheck.org.</ORIGINAL_TEXT>
<TOKEN end_char="10663" id="token-80-0" morph="none" pos="unknown" start_char="10651">FactCheck.org</TOKEN>
<TOKEN end_char="10664" id="token-80-1" morph="none" pos="punct" start_char="10664">.</TOKEN>
</SEG>
<SEG end_char="10677" id="segment-81" start_char="10666">
<ORIGINAL_TEXT>24 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="10667" id="token-81-0" morph="none" pos="word" start_char="10666">24</TOKEN>
<TOKEN end_char="10671" id="token-81-1" morph="none" pos="word" start_char="10669">Jan</TOKEN>
<TOKEN end_char="10676" id="token-81-2" morph="none" pos="word" start_char="10673">2020</TOKEN>
<TOKEN end_char="10677" id="token-81-3" morph="none" pos="punct" start_char="10677">.</TOKEN>
</SEG>
<SEG end_char="10709" id="segment-82" start_char="10680">
<ORIGINAL_TEXT>Novel coronavirus (2019-nCoV).</ORIGINAL_TEXT>
<TOKEN end_char="10684" id="token-82-0" morph="none" pos="word" start_char="10680">Novel</TOKEN>
<TOKEN end_char="10696" id="token-82-1" morph="none" pos="word" start_char="10686">coronavirus</TOKEN>
<TOKEN end_char="10698" id="token-82-2" morph="none" pos="punct" start_char="10698">(</TOKEN>
<TOKEN end_char="10707" id="token-82-3" morph="none" pos="unknown" start_char="10699">2019-nCoV</TOKEN>
<TOKEN end_char="10709" id="token-82-4" morph="none" pos="punct" start_char="10708">).</TOKEN>
</SEG>
<SEG end_char="10736" id="segment-83" start_char="10711">
<ORIGINAL_TEXT>World Health Organization.</ORIGINAL_TEXT>
<TOKEN end_char="10715" id="token-83-0" morph="none" pos="word" start_char="10711">World</TOKEN>
<TOKEN end_char="10722" id="token-83-1" morph="none" pos="word" start_char="10717">Health</TOKEN>
<TOKEN end_char="10735" id="token-83-2" morph="none" pos="word" start_char="10724">Organization</TOKEN>
<TOKEN end_char="10736" id="token-83-3" morph="none" pos="punct" start_char="10736">.</TOKEN>
</SEG>
<SEG end_char="10757" id="segment-84" start_char="10738">
<ORIGINAL_TEXT>Accessed 7 Feb 2020.</ORIGINAL_TEXT>
<TOKEN end_char="10745" id="token-84-0" morph="none" pos="word" start_char="10738">Accessed</TOKEN>
<TOKEN end_char="10747" id="token-84-1" morph="none" pos="word" start_char="10747">7</TOKEN>
<TOKEN end_char="10751" id="token-84-2" morph="none" pos="word" start_char="10749">Feb</TOKEN>
<TOKEN end_char="10756" id="token-84-3" morph="none" pos="word" start_char="10753">2020</TOKEN>
<TOKEN end_char="10757" id="token-84-4" morph="none" pos="punct" start_char="10757">.</TOKEN>
</SEG>
<SEG end_char="10780" id="segment-85" start_char="10760">
<ORIGINAL_TEXT>Pradhan, Prashant et.</ORIGINAL_TEXT>
<TOKEN end_char="10766" id="token-85-0" morph="none" pos="word" start_char="10760">Pradhan</TOKEN>
<TOKEN end_char="10767" id="token-85-1" morph="none" pos="punct" start_char="10767">,</TOKEN>
<TOKEN end_char="10776" id="token-85-2" morph="none" pos="word" start_char="10769">Prashant</TOKEN>
<TOKEN end_char="10779" id="token-85-3" morph="none" pos="word" start_char="10778">et</TOKEN>
<TOKEN end_char="10780" id="token-85-4" morph="none" pos="punct" start_char="10780">.</TOKEN>
</SEG>
<SEG end_char="10784" id="segment-86" start_char="10782">
<ORIGINAL_TEXT>al.</ORIGINAL_TEXT>
<TOKEN end_char="10783" id="token-86-0" morph="none" pos="word" start_char="10782">al</TOKEN>
<TOKEN end_char="10784" id="token-86-1" morph="none" pos="punct" start_char="10784">.</TOKEN>
<TRANSLATED_TEXT>Here.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="10876" id="segment-87" start_char="10786">
<ORIGINAL_TEXT>Uncanny similarity of unique inserts in the 2019-nCoV spike protein to HIV-1 gp120 and Gag.</ORIGINAL_TEXT>
<TOKEN end_char="10792" id="token-87-0" morph="none" pos="word" start_char="10786">Uncanny</TOKEN>
<TOKEN end_char="10803" id="token-87-1" morph="none" pos="word" start_char="10794">similarity</TOKEN>
<TOKEN end_char="10806" id="token-87-2" morph="none" pos="word" start_char="10805">of</TOKEN>
<TOKEN end_char="10813" id="token-87-3" morph="none" pos="word" start_char="10808">unique</TOKEN>
<TOKEN end_char="10821" id="token-87-4" morph="none" pos="word" start_char="10815">inserts</TOKEN>
<TOKEN end_char="10824" id="token-87-5" morph="none" pos="word" start_char="10823">in</TOKEN>
<TOKEN end_char="10828" id="token-87-6" morph="none" pos="word" start_char="10826">the</TOKEN>
<TOKEN end_char="10838" id="token-87-7" morph="none" pos="unknown" start_char="10830">2019-nCoV</TOKEN>
<TOKEN end_char="10844" id="token-87-8" morph="none" pos="word" start_char="10840">spike</TOKEN>
<TOKEN end_char="10852" id="token-87-9" morph="none" pos="word" start_char="10846">protein</TOKEN>
<TOKEN end_char="10855" id="token-87-10" morph="none" pos="word" start_char="10854">to</TOKEN>
<TOKEN end_char="10861" id="token-87-11" morph="none" pos="unknown" start_char="10857">HIV-1</TOKEN>
<TOKEN end_char="10867" id="token-87-12" morph="none" pos="word" start_char="10863">gp120</TOKEN>
<TOKEN end_char="10871" id="token-87-13" morph="none" pos="word" start_char="10869">and</TOKEN>
<TOKEN end_char="10875" id="token-87-14" morph="none" pos="word" start_char="10873">Gag</TOKEN>
<TOKEN end_char="10876" id="token-87-15" morph="none" pos="punct" start_char="10876">.</TOKEN>
</SEG>
<SEG end_char="10885" id="segment-88" start_char="10878">
<ORIGINAL_TEXT>bioRxiv.</ORIGINAL_TEXT>
<TOKEN end_char="10884" id="token-88-0" morph="none" pos="word" start_char="10878">bioRxiv</TOKEN>
<TOKEN end_char="10885" id="token-88-1" morph="none" pos="punct" start_char="10885">.</TOKEN>
<TRANSLATED_TEXT>BioRxiv.</TRANSLATED_TEXT><DETECTED_LANGUAGE>hr</DETECTED_LANGUAGE></SEG>
<SEG end_char="10898" id="segment-89" start_char="10887">
<ORIGINAL_TEXT>31 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="10888" id="token-89-0" morph="none" pos="word" start_char="10887">31</TOKEN>
<TOKEN end_char="10892" id="token-89-1" morph="none" pos="word" start_char="10890">Jan</TOKEN>
<TOKEN end_char="10897" id="token-89-2" morph="none" pos="word" start_char="10894">2020</TOKEN>
<TOKEN end_char="10898" id="token-89-3" morph="none" pos="punct" start_char="10898">.</TOKEN>
</SEG>
<SEG end_char="10933" id="segment-90" start_char="10901">
<ORIGINAL_TEXT>Konermann, Silvana (@SKonermann).</ORIGINAL_TEXT>
<TOKEN end_char="10909" id="token-90-0" morph="none" pos="word" start_char="10901">Konermann</TOKEN>
<TOKEN end_char="10910" id="token-90-1" morph="none" pos="punct" start_char="10910">,</TOKEN>
<TOKEN end_char="10918" id="token-90-2" morph="none" pos="word" start_char="10912">Silvana</TOKEN>
<TOKEN end_char="10921" id="token-90-3" morph="none" pos="punct" start_char="10920">(@</TOKEN>
<TOKEN end_char="10931" id="token-90-4" morph="none" pos="word" start_char="10922">SKonermann</TOKEN>
<TOKEN end_char="10933" id="token-90-5" morph="none" pos="punct" start_char="10932">).</TOKEN>
</SEG>
<SEG end_char="10962" id="segment-91" start_char="10935">
<ORIGINAL_TEXT>"Just checked their results.</ORIGINAL_TEXT>
<TOKEN end_char="10935" id="token-91-0" morph="none" pos="punct" start_char="10935">"</TOKEN>
<TOKEN end_char="10939" id="token-91-1" morph="none" pos="word" start_char="10936">Just</TOKEN>
<TOKEN end_char="10947" id="token-91-2" morph="none" pos="word" start_char="10941">checked</TOKEN>
<TOKEN end_char="10953" id="token-91-3" morph="none" pos="word" start_char="10949">their</TOKEN>
<TOKEN end_char="10961" id="token-91-4" morph="none" pos="word" start_char="10955">results</TOKEN>
<TOKEN end_char="10962" id="token-91-5" morph="none" pos="punct" start_char="10962">.</TOKEN>
</SEG>
<SEG end_char="10990" id="segment-92" start_char="10964">
<ORIGINAL_TEXT>The similarity is spurious.</ORIGINAL_TEXT>
<TOKEN end_char="10966" id="token-92-0" morph="none" pos="word" start_char="10964">The</TOKEN>
<TOKEN end_char="10977" id="token-92-1" morph="none" pos="word" start_char="10968">similarity</TOKEN>
<TOKEN end_char="10980" id="token-92-2" morph="none" pos="word" start_char="10979">is</TOKEN>
<TOKEN end_char="10989" id="token-92-3" morph="none" pos="word" start_char="10982">spurious</TOKEN>
<TOKEN end_char="10990" id="token-92-4" morph="none" pos="punct" start_char="10990">.</TOKEN>
</SEG>
<SEG end_char="11076" id="segment-93" start_char="10992">
<ORIGINAL_TEXT>Out of 4 inserts they identify between NCov and SARS, 2 are found in bat coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="10994" id="token-93-0" morph="none" pos="word" start_char="10992">Out</TOKEN>
<TOKEN end_char="10997" id="token-93-1" morph="none" pos="word" start_char="10996">of</TOKEN>
<TOKEN end_char="10999" id="token-93-2" morph="none" pos="word" start_char="10999">4</TOKEN>
<TOKEN end_char="11007" id="token-93-3" morph="none" pos="word" start_char="11001">inserts</TOKEN>
<TOKEN end_char="11012" id="token-93-4" morph="none" pos="word" start_char="11009">they</TOKEN>
<TOKEN end_char="11021" id="token-93-5" morph="none" pos="word" start_char="11014">identify</TOKEN>
<TOKEN end_char="11029" id="token-93-6" morph="none" pos="word" start_char="11023">between</TOKEN>
<TOKEN end_char="11034" id="token-93-7" morph="none" pos="word" start_char="11031">NCov</TOKEN>
<TOKEN end_char="11038" id="token-93-8" morph="none" pos="word" start_char="11036">and</TOKEN>
<TOKEN end_char="11043" id="token-93-9" morph="none" pos="word" start_char="11040">SARS</TOKEN>
<TOKEN end_char="11044" id="token-93-10" morph="none" pos="punct" start_char="11044">,</TOKEN>
<TOKEN end_char="11046" id="token-93-11" morph="none" pos="word" start_char="11046">2</TOKEN>
<TOKEN end_char="11050" id="token-93-12" morph="none" pos="word" start_char="11048">are</TOKEN>
<TOKEN end_char="11056" id="token-93-13" morph="none" pos="word" start_char="11052">found</TOKEN>
<TOKEN end_char="11059" id="token-93-14" morph="none" pos="word" start_char="11058">in</TOKEN>
<TOKEN end_char="11063" id="token-93-15" morph="none" pos="word" start_char="11061">bat</TOKEN>
<TOKEN end_char="11075" id="token-93-16" morph="none" pos="word" start_char="11065">coronavirus</TOKEN>
<TOKEN end_char="11076" id="token-93-17" morph="none" pos="punct" start_char="11076">.</TOKEN>
</SEG>
<SEG end_char="11217" id="segment-94" start_char="11078">
<ORIGINAL_TEXT>Of the remaining two, only one is most similar to HIV, and is so short (6 AA) that the similarity is not higher than chance given database."</ORIGINAL_TEXT>
<TOKEN end_char="11079" id="token-94-0" morph="none" pos="word" start_char="11078">Of</TOKEN>
<TOKEN end_char="11083" id="token-94-1" morph="none" pos="word" start_char="11081">the</TOKEN>
<TOKEN end_char="11093" id="token-94-2" morph="none" pos="word" start_char="11085">remaining</TOKEN>
<TOKEN end_char="11097" id="token-94-3" morph="none" pos="word" start_char="11095">two</TOKEN>
<TOKEN end_char="11098" id="token-94-4" morph="none" pos="punct" start_char="11098">,</TOKEN>
<TOKEN end_char="11103" id="token-94-5" morph="none" pos="word" start_char="11100">only</TOKEN>
<TOKEN end_char="11107" id="token-94-6" morph="none" pos="word" start_char="11105">one</TOKEN>
<TOKEN end_char="11110" id="token-94-7" morph="none" pos="word" start_char="11109">is</TOKEN>
<TOKEN end_char="11115" id="token-94-8" morph="none" pos="word" start_char="11112">most</TOKEN>
<TOKEN end_char="11123" id="token-94-9" morph="none" pos="word" start_char="11117">similar</TOKEN>
<TOKEN end_char="11126" id="token-94-10" morph="none" pos="word" start_char="11125">to</TOKEN>
<TOKEN end_char="11130" id="token-94-11" morph="none" pos="word" start_char="11128">HIV</TOKEN>
<TOKEN end_char="11131" id="token-94-12" morph="none" pos="punct" start_char="11131">,</TOKEN>
<TOKEN end_char="11135" id="token-94-13" morph="none" pos="word" start_char="11133">and</TOKEN>
<TOKEN end_char="11138" id="token-94-14" morph="none" pos="word" start_char="11137">is</TOKEN>
<TOKEN end_char="11141" id="token-94-15" morph="none" pos="word" start_char="11140">so</TOKEN>
<TOKEN end_char="11147" id="token-94-16" morph="none" pos="word" start_char="11143">short</TOKEN>
<TOKEN end_char="11149" id="token-94-17" morph="none" pos="punct" start_char="11149">(</TOKEN>
<TOKEN end_char="11150" id="token-94-18" morph="none" pos="word" start_char="11150">6</TOKEN>
<TOKEN end_char="11153" id="token-94-19" morph="none" pos="word" start_char="11152">AA</TOKEN>
<TOKEN end_char="11154" id="token-94-20" morph="none" pos="punct" start_char="11154">)</TOKEN>
<TOKEN end_char="11159" id="token-94-21" morph="none" pos="word" start_char="11156">that</TOKEN>
<TOKEN end_char="11163" id="token-94-22" morph="none" pos="word" start_char="11161">the</TOKEN>
<TOKEN end_char="11174" id="token-94-23" morph="none" pos="word" start_char="11165">similarity</TOKEN>
<TOKEN end_char="11177" id="token-94-24" morph="none" pos="word" start_char="11176">is</TOKEN>
<TOKEN end_char="11181" id="token-94-25" morph="none" pos="word" start_char="11179">not</TOKEN>
<TOKEN end_char="11188" id="token-94-26" morph="none" pos="word" start_char="11183">higher</TOKEN>
<TOKEN end_char="11193" id="token-94-27" morph="none" pos="word" start_char="11190">than</TOKEN>
<TOKEN end_char="11200" id="token-94-28" morph="none" pos="word" start_char="11195">chance</TOKEN>
<TOKEN end_char="11206" id="token-94-29" morph="none" pos="word" start_char="11202">given</TOKEN>
<TOKEN end_char="11215" id="token-94-30" morph="none" pos="word" start_char="11208">database</TOKEN>
<TOKEN end_char="11217" id="token-94-31" morph="none" pos="punct" start_char="11216">."</TOKEN>
</SEG>
<SEG end_char="11226" id="segment-95" start_char="11219">
<ORIGINAL_TEXT>Twitter.</ORIGINAL_TEXT>
<TOKEN end_char="11225" id="token-95-0" morph="none" pos="word" start_char="11219">Twitter</TOKEN>
<TOKEN end_char="11226" id="token-95-1" morph="none" pos="punct" start_char="11226">.</TOKEN>
</SEG>
<SEG end_char="11239" id="segment-96" start_char="11228">
<ORIGINAL_TEXT>31 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="11229" id="token-96-0" morph="none" pos="word" start_char="11228">31</TOKEN>
<TOKEN end_char="11233" id="token-96-1" morph="none" pos="word" start_char="11231">Jan</TOKEN>
<TOKEN end_char="11238" id="token-96-2" morph="none" pos="word" start_char="11235">2020</TOKEN>
<TOKEN end_char="11239" id="token-96-3" morph="none" pos="punct" start_char="11239">.</TOKEN>
</SEG>
<SEG end_char="11266" id="segment-97" start_char="11242">
<ORIGINAL_TEXT>Bedford, Trevor (@trvrb).</ORIGINAL_TEXT>
<TOKEN end_char="11248" id="token-97-0" morph="none" pos="word" start_char="11242">Bedford</TOKEN>
<TOKEN end_char="11249" id="token-97-1" morph="none" pos="punct" start_char="11249">,</TOKEN>
<TOKEN end_char="11256" id="token-97-2" morph="none" pos="word" start_char="11251">Trevor</TOKEN>
<TOKEN end_char="11259" id="token-97-3" morph="none" pos="punct" start_char="11258">(@</TOKEN>
<TOKEN end_char="11264" id="token-97-4" morph="none" pos="word" start_char="11260">trvrb</TOKEN>
<TOKEN end_char="11266" id="token-97-5" morph="none" pos="punct" start_char="11265">).</TOKEN>
</SEG>
<SEG end_char="11453" id="segment-98" start_char="11268">
<ORIGINAL_TEXT>"These short inserts do indeed exist in #nCoV2019 relative to its closest sequenced relative (BetaCoV/bat/Yunnan/RaTG13/2013, seen here https://nextstrain.org/groups/blab/sars-like-cov).</ORIGINAL_TEXT>
<TOKEN end_char="11268" id="token-98-0" morph="none" pos="punct" start_char="11268">"</TOKEN>
<TOKEN end_char="11273" id="token-98-1" morph="none" pos="word" start_char="11269">These</TOKEN>
<TOKEN end_char="11279" id="token-98-2" morph="none" pos="word" start_char="11275">short</TOKEN>
<TOKEN end_char="11287" id="token-98-3" morph="none" pos="word" start_char="11281">inserts</TOKEN>
<TOKEN end_char="11290" id="token-98-4" morph="none" pos="word" start_char="11289">do</TOKEN>
<TOKEN end_char="11297" id="token-98-5" morph="none" pos="word" start_char="11292">indeed</TOKEN>
<TOKEN end_char="11303" id="token-98-6" morph="none" pos="word" start_char="11299">exist</TOKEN>
<TOKEN end_char="11306" id="token-98-7" morph="none" pos="word" start_char="11305">in</TOKEN>
<TOKEN end_char="11316" id="token-98-8" morph="none" pos="tag" start_char="11308">#nCoV2019</TOKEN>
<TOKEN end_char="11325" id="token-98-9" morph="none" pos="word" start_char="11318">relative</TOKEN>
<TOKEN end_char="11328" id="token-98-10" morph="none" pos="word" start_char="11327">to</TOKEN>
<TOKEN end_char="11332" id="token-98-11" morph="none" pos="word" start_char="11330">its</TOKEN>
<TOKEN end_char="11340" id="token-98-12" morph="none" pos="word" start_char="11334">closest</TOKEN>
<TOKEN end_char="11350" id="token-98-13" morph="none" pos="word" start_char="11342">sequenced</TOKEN>
<TOKEN end_char="11359" id="token-98-14" morph="none" pos="word" start_char="11352">relative</TOKEN>
<TOKEN end_char="11361" id="token-98-15" morph="none" pos="punct" start_char="11361">(</TOKEN>
<TOKEN end_char="11391" id="token-98-16" morph="none" pos="unknown" start_char="11362">BetaCoV/bat/Yunnan/RaTG13/2013</TOKEN>
<TOKEN end_char="11392" id="token-98-17" morph="none" pos="punct" start_char="11392">,</TOKEN>
<TOKEN end_char="11397" id="token-98-18" morph="none" pos="word" start_char="11394">seen</TOKEN>
<TOKEN end_char="11402" id="token-98-19" morph="none" pos="word" start_char="11399">here</TOKEN>
<TOKEN end_char="11453" id="token-98-20" morph="none" pos="url" start_char="11404">https://nextstrain.org/groups/blab/sars-like-cov).</TOKEN>
</SEG>
<SEG end_char="11545" id="segment-99" start_char="11455">
<ORIGINAL_TEXT>However, a simple BLAST of such short sequences shows match to a huge variety of organisms.</ORIGINAL_TEXT>
<TOKEN end_char="11461" id="token-99-0" morph="none" pos="word" start_char="11455">However</TOKEN>
<TOKEN end_char="11462" id="token-99-1" morph="none" pos="punct" start_char="11462">,</TOKEN>
<TOKEN end_char="11464" id="token-99-2" morph="none" pos="word" start_char="11464">a</TOKEN>
<TOKEN end_char="11471" id="token-99-3" morph="none" pos="word" start_char="11466">simple</TOKEN>
<TOKEN end_char="11477" id="token-99-4" morph="none" pos="word" start_char="11473">BLAST</TOKEN>
<TOKEN end_char="11480" id="token-99-5" morph="none" pos="word" start_char="11479">of</TOKEN>
<TOKEN end_char="11485" id="token-99-6" morph="none" pos="word" start_char="11482">such</TOKEN>
<TOKEN end_char="11491" id="token-99-7" morph="none" pos="word" start_char="11487">short</TOKEN>
<TOKEN end_char="11501" id="token-99-8" morph="none" pos="word" start_char="11493">sequences</TOKEN>
<TOKEN end_char="11507" id="token-99-9" morph="none" pos="word" start_char="11503">shows</TOKEN>
<TOKEN end_char="11513" id="token-99-10" morph="none" pos="word" start_char="11509">match</TOKEN>
<TOKEN end_char="11516" id="token-99-11" morph="none" pos="word" start_char="11515">to</TOKEN>
<TOKEN end_char="11518" id="token-99-12" morph="none" pos="word" start_char="11518">a</TOKEN>
<TOKEN end_char="11523" id="token-99-13" morph="none" pos="word" start_char="11520">huge</TOKEN>
<TOKEN end_char="11531" id="token-99-14" morph="none" pos="word" start_char="11525">variety</TOKEN>
<TOKEN end_char="11534" id="token-99-15" morph="none" pos="word" start_char="11533">of</TOKEN>
<TOKEN end_char="11544" id="token-99-16" morph="none" pos="word" start_char="11536">organisms</TOKEN>
<TOKEN end_char="11545" id="token-99-17" morph="none" pos="punct" start_char="11545">.</TOKEN>
</SEG>
<SEG end_char="11573" id="segment-100" start_char="11547">
<ORIGINAL_TEXT>No reason to conclude HIV."</ORIGINAL_TEXT>
<TOKEN end_char="11548" id="token-100-0" morph="none" pos="word" start_char="11547">No</TOKEN>
<TOKEN end_char="11555" id="token-100-1" morph="none" pos="word" start_char="11550">reason</TOKEN>
<TOKEN end_char="11558" id="token-100-2" morph="none" pos="word" start_char="11557">to</TOKEN>
<TOKEN end_char="11567" id="token-100-3" morph="none" pos="word" start_char="11560">conclude</TOKEN>
<TOKEN end_char="11571" id="token-100-4" morph="none" pos="word" start_char="11569">HIV</TOKEN>
<TOKEN end_char="11573" id="token-100-5" morph="none" pos="punct" start_char="11572">."</TOKEN>
</SEG>
<SEG end_char="11582" id="segment-101" start_char="11575">
<ORIGINAL_TEXT>Twitter.</ORIGINAL_TEXT>
<TOKEN end_char="11581" id="token-101-0" morph="none" pos="word" start_char="11575">Twitter</TOKEN>
<TOKEN end_char="11582" id="token-101-1" morph="none" pos="punct" start_char="11582">.</TOKEN>
</SEG>
<SEG end_char="11595" id="segment-102" start_char="11584">
<ORIGINAL_TEXT>31 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="11585" id="token-102-0" morph="none" pos="word" start_char="11584">31</TOKEN>
<TOKEN end_char="11589" id="token-102-1" morph="none" pos="word" start_char="11587">Jan</TOKEN>
<TOKEN end_char="11594" id="token-102-2" morph="none" pos="word" start_char="11591">2020</TOKEN>
<TOKEN end_char="11595" id="token-102-3" morph="none" pos="punct" start_char="11595">.</TOKEN>
</SEG>
<SEG end_char="11638" id="segment-103" start_char="11598">
<ORIGINAL_TEXT>Severe Acute Respiratory Syndrome (SARS).</ORIGINAL_TEXT>
<TOKEN end_char="11603" id="token-103-0" morph="none" pos="word" start_char="11598">Severe</TOKEN>
<TOKEN end_char="11609" id="token-103-1" morph="none" pos="word" start_char="11605">Acute</TOKEN>
<TOKEN end_char="11621" id="token-103-2" morph="none" pos="word" start_char="11611">Respiratory</TOKEN>
<TOKEN end_char="11630" id="token-103-3" morph="none" pos="word" start_char="11623">Syndrome</TOKEN>
<TOKEN end_char="11632" id="token-103-4" morph="none" pos="punct" start_char="11632">(</TOKEN>
<TOKEN end_char="11636" id="token-103-5" morph="none" pos="word" start_char="11633">SARS</TOKEN>
<TOKEN end_char="11638" id="token-103-6" morph="none" pos="punct" start_char="11637">).</TOKEN>
</SEG>
<SEG end_char="11643" id="segment-104" start_char="11640">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN end_char="11642" id="token-104-0" morph="none" pos="word" start_char="11640">CDC</TOKEN>
<TOKEN end_char="11643" id="token-104-1" morph="none" pos="punct" start_char="11643">.</TOKEN>
<TRANSLATED_TEXT>- CDC.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="11664" id="segment-105" start_char="11645">
<ORIGINAL_TEXT>Accessed 7 Feb 2020.</ORIGINAL_TEXT>
<TOKEN end_char="11652" id="token-105-0" morph="none" pos="word" start_char="11645">Accessed</TOKEN>
<TOKEN end_char="11654" id="token-105-1" morph="none" pos="word" start_char="11654">7</TOKEN>
<TOKEN end_char="11658" id="token-105-2" morph="none" pos="word" start_char="11656">Feb</TOKEN>
<TOKEN end_char="11663" id="token-105-3" morph="none" pos="word" start_char="11660">2020</TOKEN>
<TOKEN end_char="11664" id="token-105-4" morph="none" pos="punct" start_char="11664">.</TOKEN>
</SEG>
<SEG end_char="11691" id="segment-106" start_char="11667">
<ORIGINAL_TEXT>Bedford, Trevor (@trvrb).</ORIGINAL_TEXT>
<TOKEN end_char="11673" id="token-106-0" morph="none" pos="word" start_char="11667">Bedford</TOKEN>
<TOKEN end_char="11674" id="token-106-1" morph="none" pos="punct" start_char="11674">,</TOKEN>
<TOKEN end_char="11681" id="token-106-2" morph="none" pos="word" start_char="11676">Trevor</TOKEN>
<TOKEN end_char="11684" id="token-106-3" morph="none" pos="punct" start_char="11683">(@</TOKEN>
<TOKEN end_char="11689" id="token-106-4" morph="none" pos="word" start_char="11685">trvrb</TOKEN>
<TOKEN end_char="11691" id="token-106-5" morph="none" pos="punct" start_char="11690">).</TOKEN>
</SEG>
<SEG end_char="11809" id="segment-107" start_char="11693">
<ORIGINAL_TEXT>"Based on the content of my mentions, I feel like I need to further debunk crazy #nCoV2019 / HIV conspiracy preprint.</ORIGINAL_TEXT>
<TOKEN end_char="11693" id="token-107-0" morph="none" pos="punct" start_char="11693">"</TOKEN>
<TOKEN end_char="11698" id="token-107-1" morph="none" pos="word" start_char="11694">Based</TOKEN>
<TOKEN end_char="11701" id="token-107-2" morph="none" pos="word" start_char="11700">on</TOKEN>
<TOKEN end_char="11705" id="token-107-3" morph="none" pos="word" start_char="11703">the</TOKEN>
<TOKEN end_char="11713" id="token-107-4" morph="none" pos="word" start_char="11707">content</TOKEN>
<TOKEN end_char="11716" id="token-107-5" morph="none" pos="word" start_char="11715">of</TOKEN>
<TOKEN end_char="11719" id="token-107-6" morph="none" pos="word" start_char="11718">my</TOKEN>
<TOKEN end_char="11728" id="token-107-7" morph="none" pos="word" start_char="11721">mentions</TOKEN>
<TOKEN end_char="11729" id="token-107-8" morph="none" pos="punct" start_char="11729">,</TOKEN>
<TOKEN end_char="11731" id="token-107-9" morph="none" pos="word" start_char="11731">I</TOKEN>
<TOKEN end_char="11736" id="token-107-10" morph="none" pos="word" start_char="11733">feel</TOKEN>
<TOKEN end_char="11741" id="token-107-11" morph="none" pos="word" start_char="11738">like</TOKEN>
<TOKEN end_char="11743" id="token-107-12" morph="none" pos="word" start_char="11743">I</TOKEN>
<TOKEN end_char="11748" id="token-107-13" morph="none" pos="word" start_char="11745">need</TOKEN>
<TOKEN end_char="11751" id="token-107-14" morph="none" pos="word" start_char="11750">to</TOKEN>
<TOKEN end_char="11759" id="token-107-15" morph="none" pos="word" start_char="11753">further</TOKEN>
<TOKEN end_char="11766" id="token-107-16" morph="none" pos="word" start_char="11761">debunk</TOKEN>
<TOKEN end_char="11772" id="token-107-17" morph="none" pos="word" start_char="11768">crazy</TOKEN>
<TOKEN end_char="11782" id="token-107-18" morph="none" pos="tag" start_char="11774">#nCoV2019</TOKEN>
<TOKEN end_char="11784" id="token-107-19" morph="none" pos="punct" start_char="11784">/</TOKEN>
<TOKEN end_char="11788" id="token-107-20" morph="none" pos="word" start_char="11786">HIV</TOKEN>
<TOKEN end_char="11799" id="token-107-21" morph="none" pos="word" start_char="11790">conspiracy</TOKEN>
<TOKEN end_char="11808" id="token-107-22" morph="none" pos="word" start_char="11801">preprint</TOKEN>
<TOKEN end_char="11809" id="token-107-23" morph="none" pos="punct" start_char="11809">.</TOKEN>
</SEG>
<SEG end_char="11836" id="segment-108" start_char="11811">
<ORIGINAL_TEXT>This is a thread doing so.</ORIGINAL_TEXT>
<TOKEN end_char="11814" id="token-108-0" morph="none" pos="word" start_char="11811">This</TOKEN>
<TOKEN end_char="11817" id="token-108-1" morph="none" pos="word" start_char="11816">is</TOKEN>
<TOKEN end_char="11819" id="token-108-2" morph="none" pos="word" start_char="11819">a</TOKEN>
<TOKEN end_char="11826" id="token-108-3" morph="none" pos="word" start_char="11821">thread</TOKEN>
<TOKEN end_char="11832" id="token-108-4" morph="none" pos="word" start_char="11828">doing</TOKEN>
<TOKEN end_char="11835" id="token-108-5" morph="none" pos="word" start_char="11834">so</TOKEN>
<TOKEN end_char="11836" id="token-108-6" morph="none" pos="punct" start_char="11836">.</TOKEN>
</SEG>
<SEG end_char="11864" id="segment-109" start_char="11838">
<ORIGINAL_TEXT>1/9, and following thread."</ORIGINAL_TEXT>
<TOKEN end_char="11840" id="token-109-0" morph="none" pos="unknown" start_char="11838">1/9</TOKEN>
<TOKEN end_char="11841" id="token-109-1" morph="none" pos="punct" start_char="11841">,</TOKEN>
<TOKEN end_char="11845" id="token-109-2" morph="none" pos="word" start_char="11843">and</TOKEN>
<TOKEN end_char="11855" id="token-109-3" morph="none" pos="word" start_char="11847">following</TOKEN>
<TOKEN end_char="11862" id="token-109-4" morph="none" pos="word" start_char="11857">thread</TOKEN>
<TOKEN end_char="11864" id="token-109-5" morph="none" pos="punct" start_char="11863">."</TOKEN>
</SEG>
<SEG end_char="11873" id="segment-110" start_char="11866">
<ORIGINAL_TEXT>Twitter.</ORIGINAL_TEXT>
<TOKEN end_char="11872" id="token-110-0" morph="none" pos="word" start_char="11866">Twitter</TOKEN>
<TOKEN end_char="11873" id="token-110-1" morph="none" pos="punct" start_char="11873">.</TOKEN>
</SEG>
<SEG end_char="11885" id="segment-111" start_char="11875">
<ORIGINAL_TEXT>1 Feb 2020.</ORIGINAL_TEXT>
<TOKEN end_char="11875" id="token-111-0" morph="none" pos="word" start_char="11875">1</TOKEN>
<TOKEN end_char="11879" id="token-111-1" morph="none" pos="word" start_char="11877">Feb</TOKEN>
<TOKEN end_char="11884" id="token-111-2" morph="none" pos="word" start_char="11881">2020</TOKEN>
<TOKEN end_char="11885" id="token-111-3" morph="none" pos="punct" start_char="11885">.</TOKEN>
<TRANSLATED_TEXT>1. Februar 2020</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="11906" id="segment-112" start_char="11888">
<ORIGINAL_TEXT>Andersen, Kristian.</ORIGINAL_TEXT>
<TOKEN end_char="11895" id="token-112-0" morph="none" pos="word" start_char="11888">Andersen</TOKEN>
<TOKEN end_char="11896" id="token-112-1" morph="none" pos="punct" start_char="11896">,</TOKEN>
<TOKEN end_char="11905" id="token-112-2" morph="none" pos="word" start_char="11898">Kristian</TOKEN>
<TOKEN end_char="11906" id="token-112-3" morph="none" pos="punct" start_char="11906">.</TOKEN>
</SEG>
<SEG end_char="12023" id="segment-113" start_char="11908">
<ORIGINAL_TEXT>Associate Professor, Department of Integrative Structural and Computational Biology, The Scripps Research Institute.</ORIGINAL_TEXT>
<TOKEN end_char="11916" id="token-113-0" morph="none" pos="word" start_char="11908">Associate</TOKEN>
<TOKEN end_char="11926" id="token-113-1" morph="none" pos="word" start_char="11918">Professor</TOKEN>
<TOKEN end_char="11927" id="token-113-2" morph="none" pos="punct" start_char="11927">,</TOKEN>
<TOKEN end_char="11938" id="token-113-3" morph="none" pos="word" start_char="11929">Department</TOKEN>
<TOKEN end_char="11941" id="token-113-4" morph="none" pos="word" start_char="11940">of</TOKEN>
<TOKEN end_char="11953" id="token-113-5" morph="none" pos="word" start_char="11943">Integrative</TOKEN>
<TOKEN end_char="11964" id="token-113-6" morph="none" pos="word" start_char="11955">Structural</TOKEN>
<TOKEN end_char="11968" id="token-113-7" morph="none" pos="word" start_char="11966">and</TOKEN>
<TOKEN end_char="11982" id="token-113-8" morph="none" pos="word" start_char="11970">Computational</TOKEN>
<TOKEN end_char="11990" id="token-113-9" morph="none" pos="word" start_char="11984">Biology</TOKEN>
<TOKEN end_char="11991" id="token-113-10" morph="none" pos="punct" start_char="11991">,</TOKEN>
<TOKEN end_char="11995" id="token-113-11" morph="none" pos="word" start_char="11993">The</TOKEN>
<TOKEN end_char="12003" id="token-113-12" morph="none" pos="word" start_char="11997">Scripps</TOKEN>
<TOKEN end_char="12012" id="token-113-13" morph="none" pos="word" start_char="12005">Research</TOKEN>
<TOKEN end_char="12022" id="token-113-14" morph="none" pos="word" start_char="12014">Institute</TOKEN>
<TOKEN end_char="12023" id="token-113-15" morph="none" pos="punct" start_char="12023">.</TOKEN>
</SEG>
<SEG end_char="12052" id="segment-114" start_char="12025">
<ORIGINAL_TEXT>Email sent to FactCheck.org.</ORIGINAL_TEXT>
<TOKEN end_char="12029" id="token-114-0" morph="none" pos="word" start_char="12025">Email</TOKEN>
<TOKEN end_char="12034" id="token-114-1" morph="none" pos="word" start_char="12031">sent</TOKEN>
<TOKEN end_char="12037" id="token-114-2" morph="none" pos="word" start_char="12036">to</TOKEN>
<TOKEN end_char="12051" id="token-114-3" morph="none" pos="unknown" start_char="12039">FactCheck.org</TOKEN>
<TOKEN end_char="12052" id="token-114-4" morph="none" pos="punct" start_char="12052">.</TOKEN>
</SEG>
<SEG end_char="12064" id="segment-115" start_char="12054">
<ORIGINAL_TEXT>3 Feb 2020.</ORIGINAL_TEXT>
<TOKEN end_char="12054" id="token-115-0" morph="none" pos="word" start_char="12054">3</TOKEN>
<TOKEN end_char="12058" id="token-115-1" morph="none" pos="word" start_char="12056">Feb</TOKEN>
<TOKEN end_char="12063" id="token-115-2" morph="none" pos="word" start_char="12060">2020</TOKEN>
<TOKEN end_char="12064" id="token-115-3" morph="none" pos="punct" start_char="12064">.</TOKEN>
</SEG>
<SEG end_char="12137" id="segment-116" start_char="12067">
<ORIGINAL_TEXT>"China testing HIV drug as treatment for new coronavirus, AbbVie says."</ORIGINAL_TEXT>
<TOKEN end_char="12067" id="token-116-0" morph="none" pos="punct" start_char="12067">"</TOKEN>
<TOKEN end_char="12072" id="token-116-1" morph="none" pos="word" start_char="12068">China</TOKEN>
<TOKEN end_char="12080" id="token-116-2" morph="none" pos="word" start_char="12074">testing</TOKEN>
<TOKEN end_char="12084" id="token-116-3" morph="none" pos="word" start_char="12082">HIV</TOKEN>
<TOKEN end_char="12089" id="token-116-4" morph="none" pos="word" start_char="12086">drug</TOKEN>
<TOKEN end_char="12092" id="token-116-5" morph="none" pos="word" start_char="12091">as</TOKEN>
<TOKEN end_char="12102" id="token-116-6" morph="none" pos="word" start_char="12094">treatment</TOKEN>
<TOKEN end_char="12106" id="token-116-7" morph="none" pos="word" start_char="12104">for</TOKEN>
<TOKEN end_char="12110" id="token-116-8" morph="none" pos="word" start_char="12108">new</TOKEN>
<TOKEN end_char="12122" id="token-116-9" morph="none" pos="word" start_char="12112">coronavirus</TOKEN>
<TOKEN end_char="12123" id="token-116-10" morph="none" pos="punct" start_char="12123">,</TOKEN>
<TOKEN end_char="12130" id="token-116-11" morph="none" pos="word" start_char="12125">AbbVie</TOKEN>
<TOKEN end_char="12135" id="token-116-12" morph="none" pos="word" start_char="12132">says</TOKEN>
<TOKEN end_char="12137" id="token-116-13" morph="none" pos="punct" start_char="12136">."</TOKEN>
</SEG>
<SEG end_char="12146" id="segment-117" start_char="12139">
<ORIGINAL_TEXT>Reuters.</ORIGINAL_TEXT>
<TOKEN end_char="12145" id="token-117-0" morph="none" pos="word" start_char="12139">Reuters</TOKEN>
<TOKEN end_char="12146" id="token-117-1" morph="none" pos="punct" start_char="12146">.</TOKEN>
<TRANSLATED_TEXT>- Reuters.</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="12159" id="segment-118" start_char="12148">
<ORIGINAL_TEXT>26 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="12149" id="token-118-0" morph="none" pos="word" start_char="12148">26</TOKEN>
<TOKEN end_char="12153" id="token-118-1" morph="none" pos="word" start_char="12151">Jan</TOKEN>
<TOKEN end_char="12158" id="token-118-2" morph="none" pos="word" start_char="12155">2020</TOKEN>
<TOKEN end_char="12159" id="token-118-3" morph="none" pos="punct" start_char="12159">.</TOKEN>
</SEG>
<SEG end_char="12178" id="segment-119" start_char="12162">
<ORIGINAL_TEXT>Wongcha-um, Panu.</ORIGINAL_TEXT>
<TOKEN end_char="12171" id="token-119-0" morph="none" pos="unknown" start_char="12162">Wongcha-um</TOKEN>
<TOKEN end_char="12172" id="token-119-1" morph="none" pos="punct" start_char="12172">,</TOKEN>
<TOKEN end_char="12177" id="token-119-2" morph="none" pos="word" start_char="12174">Panu</TOKEN>
<TOKEN end_char="12178" id="token-119-3" morph="none" pos="punct" start_char="12178">.</TOKEN>
</SEG>
<SEG end_char="12256" id="segment-120" start_char="12180">
<ORIGINAL_TEXT>"Cocktail of flu, HIV drugs appears to help fight coronavirus: Thai doctors."</ORIGINAL_TEXT>
<TOKEN end_char="12180" id="token-120-0" morph="none" pos="punct" start_char="12180">"</TOKEN>
<TOKEN end_char="12188" id="token-120-1" morph="none" pos="word" start_char="12181">Cocktail</TOKEN>
<TOKEN end_char="12191" id="token-120-2" morph="none" pos="word" start_char="12190">of</TOKEN>
<TOKEN end_char="12195" id="token-120-3" morph="none" pos="word" start_char="12193">flu</TOKEN>
<TOKEN end_char="12196" id="token-120-4" morph="none" pos="punct" start_char="12196">,</TOKEN>
<TOKEN end_char="12200" id="token-120-5" morph="none" pos="word" start_char="12198">HIV</TOKEN>
<TOKEN end_char="12206" id="token-120-6" morph="none" pos="word" start_char="12202">drugs</TOKEN>
<TOKEN end_char="12214" id="token-120-7" morph="none" pos="word" start_char="12208">appears</TOKEN>
<TOKEN end_char="12217" id="token-120-8" morph="none" pos="word" start_char="12216">to</TOKEN>
<TOKEN end_char="12222" id="token-120-9" morph="none" pos="word" start_char="12219">help</TOKEN>
<TOKEN end_char="12228" id="token-120-10" morph="none" pos="word" start_char="12224">fight</TOKEN>
<TOKEN end_char="12240" id="token-120-11" morph="none" pos="word" start_char="12230">coronavirus</TOKEN>
<TOKEN end_char="12241" id="token-120-12" morph="none" pos="punct" start_char="12241">:</TOKEN>
<TOKEN end_char="12246" id="token-120-13" morph="none" pos="word" start_char="12243">Thai</TOKEN>
<TOKEN end_char="12254" id="token-120-14" morph="none" pos="word" start_char="12248">doctors</TOKEN>
<TOKEN end_char="12256" id="token-120-15" morph="none" pos="punct" start_char="12255">."</TOKEN>
</SEG>
<SEG end_char="12265" id="segment-121" start_char="12258">
<ORIGINAL_TEXT>Reuters.</ORIGINAL_TEXT>
<TOKEN end_char="12264" id="token-121-0" morph="none" pos="word" start_char="12258">Reuters</TOKEN>
<TOKEN end_char="12265" id="token-121-1" morph="none" pos="punct" start_char="12265">.</TOKEN>
<TRANSLATED_TEXT>- Reuters.</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="12277" id="segment-122" start_char="12267">
<ORIGINAL_TEXT>2 Feb 2020.</ORIGINAL_TEXT>
<TOKEN end_char="12267" id="token-122-0" morph="none" pos="word" start_char="12267">2</TOKEN>
<TOKEN end_char="12271" id="token-122-1" morph="none" pos="word" start_char="12269">Feb</TOKEN>
<TOKEN end_char="12276" id="token-122-2" morph="none" pos="word" start_char="12273">2020</TOKEN>
<TOKEN end_char="12277" id="token-122-3" morph="none" pos="punct" start_char="12277">.</TOKEN>
<TRANSLATED_TEXT>2. Februar 2020</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="12296" id="segment-123" start_char="12280">
<ORIGINAL_TEXT>Sheahan, Timothy.</ORIGINAL_TEXT>
<TOKEN end_char="12286" id="token-123-0" morph="none" pos="word" start_char="12280">Sheahan</TOKEN>
<TOKEN end_char="12287" id="token-123-1" morph="none" pos="punct" start_char="12287">,</TOKEN>
<TOKEN end_char="12295" id="token-123-2" morph="none" pos="word" start_char="12289">Timothy</TOKEN>
<TOKEN end_char="12296" id="token-123-3" morph="none" pos="punct" start_char="12296">.</TOKEN>
</SEG>
<SEG end_char="12435" id="segment-124" start_char="12298">
<ORIGINAL_TEXT>Assistant Professor, Department of Epidemiology, the Gillings School of Global Public Health, University of North Carolina at Chapel Hill.</ORIGINAL_TEXT>
<TOKEN end_char="12306" id="token-124-0" morph="none" pos="word" start_char="12298">Assistant</TOKEN>
<TOKEN end_char="12316" id="token-124-1" morph="none" pos="word" start_char="12308">Professor</TOKEN>
<TOKEN end_char="12317" id="token-124-2" morph="none" pos="punct" start_char="12317">,</TOKEN>
<TOKEN end_char="12328" id="token-124-3" morph="none" pos="word" start_char="12319">Department</TOKEN>
<TOKEN end_char="12331" id="token-124-4" morph="none" pos="word" start_char="12330">of</TOKEN>
<TOKEN end_char="12344" id="token-124-5" morph="none" pos="word" start_char="12333">Epidemiology</TOKEN>
<TOKEN end_char="12345" id="token-124-6" morph="none" pos="punct" start_char="12345">,</TOKEN>
<TOKEN end_char="12349" id="token-124-7" morph="none" pos="word" start_char="12347">the</TOKEN>
<TOKEN end_char="12358" id="token-124-8" morph="none" pos="word" start_char="12351">Gillings</TOKEN>
<TOKEN end_char="12365" id="token-124-9" morph="none" pos="word" start_char="12360">School</TOKEN>
<TOKEN end_char="12368" id="token-124-10" morph="none" pos="word" start_char="12367">of</TOKEN>
<TOKEN end_char="12375" id="token-124-11" morph="none" pos="word" start_char="12370">Global</TOKEN>
<TOKEN end_char="12382" id="token-124-12" morph="none" pos="word" start_char="12377">Public</TOKEN>
<TOKEN end_char="12389" id="token-124-13" morph="none" pos="word" start_char="12384">Health</TOKEN>
<TOKEN end_char="12390" id="token-124-14" morph="none" pos="punct" start_char="12390">,</TOKEN>
<TOKEN end_char="12401" id="token-124-15" morph="none" pos="word" start_char="12392">University</TOKEN>
<TOKEN end_char="12404" id="token-124-16" morph="none" pos="word" start_char="12403">of</TOKEN>
<TOKEN end_char="12410" id="token-124-17" morph="none" pos="word" start_char="12406">North</TOKEN>
<TOKEN end_char="12419" id="token-124-18" morph="none" pos="word" start_char="12412">Carolina</TOKEN>
<TOKEN end_char="12422" id="token-124-19" morph="none" pos="word" start_char="12421">at</TOKEN>
<TOKEN end_char="12429" id="token-124-20" morph="none" pos="word" start_char="12424">Chapel</TOKEN>
<TOKEN end_char="12434" id="token-124-21" morph="none" pos="word" start_char="12431">Hill</TOKEN>
<TOKEN end_char="12435" id="token-124-22" morph="none" pos="punct" start_char="12435">.</TOKEN>
</SEG>
<SEG end_char="12465" id="segment-125" start_char="12437">
<ORIGINAL_TEXT>Interview with FactCheck.org.</ORIGINAL_TEXT>
<TOKEN end_char="12445" id="token-125-0" morph="none" pos="word" start_char="12437">Interview</TOKEN>
<TOKEN end_char="12450" id="token-125-1" morph="none" pos="word" start_char="12447">with</TOKEN>
<TOKEN end_char="12464" id="token-125-2" morph="none" pos="unknown" start_char="12452">FactCheck.org</TOKEN>
<TOKEN end_char="12465" id="token-125-3" morph="none" pos="punct" start_char="12465">.</TOKEN>
</SEG>
<SEG end_char="12477" id="segment-126" start_char="12467">
<ORIGINAL_TEXT>5 Feb 2020.</ORIGINAL_TEXT>
<TOKEN end_char="12467" id="token-126-0" morph="none" pos="word" start_char="12467">5</TOKEN>
<TOKEN end_char="12471" id="token-126-1" morph="none" pos="word" start_char="12469">Feb</TOKEN>
<TOKEN end_char="12476" id="token-126-2" morph="none" pos="word" start_char="12473">2020</TOKEN>
<TOKEN end_char="12477" id="token-126-3" morph="none" pos="punct" start_char="12477">.</TOKEN>
</SEG>
<SEG end_char="12490" id="segment-127" start_char="12480">
<ORIGINAL_TEXT>Chu, C. et.</ORIGINAL_TEXT>
<TOKEN end_char="12482" id="token-127-0" morph="none" pos="word" start_char="12480">Chu</TOKEN>
<TOKEN end_char="12483" id="token-127-1" morph="none" pos="punct" start_char="12483">,</TOKEN>
<TOKEN end_char="12485" id="token-127-2" morph="none" pos="word" start_char="12485">C</TOKEN>
<TOKEN end_char="12486" id="token-127-3" morph="none" pos="punct" start_char="12486">.</TOKEN>
<TOKEN end_char="12489" id="token-127-4" morph="none" pos="word" start_char="12488">et</TOKEN>
<TOKEN end_char="12490" id="token-127-5" morph="none" pos="punct" start_char="12490">.</TOKEN>
</SEG>
<SEG end_char="12494" id="segment-128" start_char="12492">
<ORIGINAL_TEXT>al.</ORIGINAL_TEXT>
<TOKEN end_char="12493" id="token-128-0" morph="none" pos="word" start_char="12492">al</TOKEN>
<TOKEN end_char="12494" id="token-128-1" morph="none" pos="punct" start_char="12494">.</TOKEN>
<TRANSLATED_TEXT>Here.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="12593" id="segment-129" start_char="12496">
<ORIGINAL_TEXT>"Role of lopinavir/ritonavir in the treatment of SARS: initial virological and clinical findings."</ORIGINAL_TEXT>
<TOKEN end_char="12496" id="token-129-0" morph="none" pos="punct" start_char="12496">"</TOKEN>
<TOKEN end_char="12500" id="token-129-1" morph="none" pos="word" start_char="12497">Role</TOKEN>
<TOKEN end_char="12503" id="token-129-2" morph="none" pos="word" start_char="12502">of</TOKEN>
<TOKEN end_char="12523" id="token-129-3" morph="none" pos="unknown" start_char="12505">lopinavir/ritonavir</TOKEN>
<TOKEN end_char="12526" id="token-129-4" morph="none" pos="word" start_char="12525">in</TOKEN>
<TOKEN end_char="12530" id="token-129-5" morph="none" pos="word" start_char="12528">the</TOKEN>
<TOKEN end_char="12540" id="token-129-6" morph="none" pos="word" start_char="12532">treatment</TOKEN>
<TOKEN end_char="12543" id="token-129-7" morph="none" pos="word" start_char="12542">of</TOKEN>
<TOKEN end_char="12548" id="token-129-8" morph="none" pos="word" start_char="12545">SARS</TOKEN>
<TOKEN end_char="12549" id="token-129-9" morph="none" pos="punct" start_char="12549">:</TOKEN>
<TOKEN end_char="12557" id="token-129-10" morph="none" pos="word" start_char="12551">initial</TOKEN>
<TOKEN end_char="12569" id="token-129-11" morph="none" pos="word" start_char="12559">virological</TOKEN>
<TOKEN end_char="12573" id="token-129-12" morph="none" pos="word" start_char="12571">and</TOKEN>
<TOKEN end_char="12582" id="token-129-13" morph="none" pos="word" start_char="12575">clinical</TOKEN>
<TOKEN end_char="12591" id="token-129-14" morph="none" pos="word" start_char="12584">findings</TOKEN>
<TOKEN end_char="12593" id="token-129-15" morph="none" pos="punct" start_char="12592">."</TOKEN>
</SEG>
<SEG end_char="12601" id="segment-130" start_char="12595">
<ORIGINAL_TEXT>Thorax.</ORIGINAL_TEXT>
<TOKEN end_char="12600" id="token-130-0" morph="none" pos="word" start_char="12595">Thorax</TOKEN>
<TOKEN end_char="12601" id="token-130-1" morph="none" pos="punct" start_char="12601">.</TOKEN>
</SEG>
<SEG end_char="12614" id="segment-131" start_char="12603">
<ORIGINAL_TEXT>59(3), 2004.</ORIGINAL_TEXT>
<TOKEN end_char="12606" id="token-131-0" morph="none" pos="unknown" start_char="12603">59(3</TOKEN>
<TOKEN end_char="12608" id="token-131-1" morph="none" pos="punct" start_char="12607">),</TOKEN>
<TOKEN end_char="12613" id="token-131-2" morph="none" pos="word" start_char="12610">2004</TOKEN>
<TOKEN end_char="12614" id="token-131-3" morph="none" pos="punct" start_char="12614">.</TOKEN>
<TRANSLATED_TEXT>59 (3): 2004.</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="12639" id="segment-132" start_char="12617">
<ORIGINAL_TEXT>Sheahan, Timothy P. et.</ORIGINAL_TEXT>
<TOKEN end_char="12623" id="token-132-0" morph="none" pos="word" start_char="12617">Sheahan</TOKEN>
<TOKEN end_char="12624" id="token-132-1" morph="none" pos="punct" start_char="12624">,</TOKEN>
<TOKEN end_char="12632" id="token-132-2" morph="none" pos="word" start_char="12626">Timothy</TOKEN>
<TOKEN end_char="12634" id="token-132-3" morph="none" pos="word" start_char="12634">P</TOKEN>
<TOKEN end_char="12635" id="token-132-4" morph="none" pos="punct" start_char="12635">.</TOKEN>
<TOKEN end_char="12638" id="token-132-5" morph="none" pos="word" start_char="12637">et</TOKEN>
<TOKEN end_char="12639" id="token-132-6" morph="none" pos="punct" start_char="12639">.</TOKEN>
</SEG>
<SEG end_char="12643" id="segment-133" start_char="12641">
<ORIGINAL_TEXT>al.</ORIGINAL_TEXT>
<TOKEN end_char="12642" id="token-133-0" morph="none" pos="word" start_char="12641">al</TOKEN>
<TOKEN end_char="12643" id="token-133-1" morph="none" pos="punct" start_char="12643">.</TOKEN>
<TRANSLATED_TEXT>Here.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="12768" id="segment-134" start_char="12645">
<ORIGINAL_TEXT>"Comparative therapeutic efficacy of remdesivir and combination lopinavir, ritonavir, and interferon beta against MERS-CoV."</ORIGINAL_TEXT>
<TOKEN end_char="12645" id="token-134-0" morph="none" pos="punct" start_char="12645">"</TOKEN>
<TOKEN end_char="12656" id="token-134-1" morph="none" pos="word" start_char="12646">Comparative</TOKEN>
<TOKEN end_char="12668" id="token-134-2" morph="none" pos="word" start_char="12658">therapeutic</TOKEN>
<TOKEN end_char="12677" id="token-134-3" morph="none" pos="word" start_char="12670">efficacy</TOKEN>
<TOKEN end_char="12680" id="token-134-4" morph="none" pos="word" start_char="12679">of</TOKEN>
<TOKEN end_char="12691" id="token-134-5" morph="none" pos="word" start_char="12682">remdesivir</TOKEN>
<TOKEN end_char="12695" id="token-134-6" morph="none" pos="word" start_char="12693">and</TOKEN>
<TOKEN end_char="12707" id="token-134-7" morph="none" pos="word" start_char="12697">combination</TOKEN>
<TOKEN end_char="12717" id="token-134-8" morph="none" pos="word" start_char="12709">lopinavir</TOKEN>
<TOKEN end_char="12718" id="token-134-9" morph="none" pos="punct" start_char="12718">,</TOKEN>
<TOKEN end_char="12728" id="token-134-10" morph="none" pos="word" start_char="12720">ritonavir</TOKEN>
<TOKEN end_char="12729" id="token-134-11" morph="none" pos="punct" start_char="12729">,</TOKEN>
<TOKEN end_char="12733" id="token-134-12" morph="none" pos="word" start_char="12731">and</TOKEN>
<TOKEN end_char="12744" id="token-134-13" morph="none" pos="word" start_char="12735">interferon</TOKEN>
<TOKEN end_char="12749" id="token-134-14" morph="none" pos="word" start_char="12746">beta</TOKEN>
<TOKEN end_char="12757" id="token-134-15" morph="none" pos="word" start_char="12751">against</TOKEN>
<TOKEN end_char="12766" id="token-134-16" morph="none" pos="unknown" start_char="12759">MERS-CoV</TOKEN>
<TOKEN end_char="12768" id="token-134-17" morph="none" pos="punct" start_char="12767">."</TOKEN>
</SEG>
<SEG end_char="12791" id="segment-135" start_char="12770">
<ORIGINAL_TEXT>Nature Communications.</ORIGINAL_TEXT>
<TOKEN end_char="12775" id="token-135-0" morph="none" pos="word" start_char="12770">Nature</TOKEN>
<TOKEN end_char="12790" id="token-135-1" morph="none" pos="word" start_char="12777">Communications</TOKEN>
<TOKEN end_char="12791" id="token-135-2" morph="none" pos="punct" start_char="12791">.</TOKEN>
</SEG>
<SEG end_char="12801" id="segment-136" start_char="12793">
<ORIGINAL_TEXT>11, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="12794" id="token-136-0" morph="none" pos="word" start_char="12793">11</TOKEN>
<TOKEN end_char="12795" id="token-136-1" morph="none" pos="punct" start_char="12795">,</TOKEN>
<TOKEN end_char="12800" id="token-136-2" morph="none" pos="word" start_char="12797">2020</TOKEN>
<TOKEN end_char="12801" id="token-136-3" morph="none" pos="punct" start_char="12801">.</TOKEN>
</SEG>
<SEG end_char="12823" id="segment-137" start_char="12804">
<ORIGINAL_TEXT>Arabi, Yaseen M. et.</ORIGINAL_TEXT>
<TOKEN end_char="12808" id="token-137-0" morph="none" pos="word" start_char="12804">Arabi</TOKEN>
<TOKEN end_char="12809" id="token-137-1" morph="none" pos="punct" start_char="12809">,</TOKEN>
<TOKEN end_char="12816" id="token-137-2" morph="none" pos="word" start_char="12811">Yaseen</TOKEN>
<TOKEN end_char="12818" id="token-137-3" morph="none" pos="word" start_char="12818">M</TOKEN>
<TOKEN end_char="12819" id="token-137-4" morph="none" pos="punct" start_char="12819">.</TOKEN>
<TOKEN end_char="12822" id="token-137-5" morph="none" pos="word" start_char="12821">et</TOKEN>
<TOKEN end_char="12823" id="token-137-6" morph="none" pos="punct" start_char="12823">.</TOKEN>
<TRANSLATED_TEXT>Arabi, Yaseen M. et al.</TRANSLATED_TEXT><DETECTED_LANGUAGE>tr</DETECTED_LANGUAGE></SEG>
<SEG end_char="12827" id="segment-138" start_char="12825">
<ORIGINAL_TEXT>al.</ORIGINAL_TEXT>
<TOKEN end_char="12826" id="token-138-0" morph="none" pos="word" start_char="12825">al</TOKEN>
<TOKEN end_char="12827" id="token-138-1" morph="none" pos="punct" start_char="12827">.</TOKEN>
<TRANSLATED_TEXT>Here.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="13003" id="segment-139" start_char="12829">
<ORIGINAL_TEXT>"Treatment of Middle East Respiratory Syndrome with a combination of lopinavir-ritonavir and interferon-β1b (MIRACLE trial): study protocol for a randomized controlled trial."</ORIGINAL_TEXT>
<TOKEN end_char="12829" id="token-139-0" morph="none" pos="punct" start_char="12829">"</TOKEN>
<TOKEN end_char="12838" id="token-139-1" morph="none" pos="word" start_char="12830">Treatment</TOKEN>
<TOKEN end_char="12841" id="token-139-2" morph="none" pos="word" start_char="12840">of</TOKEN>
<TOKEN end_char="12848" id="token-139-3" morph="none" pos="word" start_char="12843">Middle</TOKEN>
<TOKEN end_char="12853" id="token-139-4" morph="none" pos="word" start_char="12850">East</TOKEN>
<TOKEN end_char="12865" id="token-139-5" morph="none" pos="word" start_char="12855">Respiratory</TOKEN>
<TOKEN end_char="12874" id="token-139-6" morph="none" pos="word" start_char="12867">Syndrome</TOKEN>
<TOKEN end_char="12879" id="token-139-7" morph="none" pos="word" start_char="12876">with</TOKEN>
<TOKEN end_char="12881" id="token-139-8" morph="none" pos="word" start_char="12881">a</TOKEN>
<TOKEN end_char="12893" id="token-139-9" morph="none" pos="word" start_char="12883">combination</TOKEN>
<TOKEN end_char="12896" id="token-139-10" morph="none" pos="word" start_char="12895">of</TOKEN>
<TOKEN end_char="12916" id="token-139-11" morph="none" pos="unknown" start_char="12898">lopinavir-ritonavir</TOKEN>
<TOKEN end_char="12920" id="token-139-12" morph="none" pos="word" start_char="12918">and</TOKEN>
<TOKEN end_char="12935" id="token-139-13" morph="none" pos="unknown" start_char="12922">interferon-β1b</TOKEN>
<TOKEN end_char="12937" id="token-139-14" morph="none" pos="punct" start_char="12937">(</TOKEN>
<TOKEN end_char="12944" id="token-139-15" morph="none" pos="word" start_char="12938">MIRACLE</TOKEN>
<TOKEN end_char="12950" id="token-139-16" morph="none" pos="word" start_char="12946">trial</TOKEN>
<TOKEN end_char="12952" id="token-139-17" morph="none" pos="punct" start_char="12951">):</TOKEN>
<TOKEN end_char="12958" id="token-139-18" morph="none" pos="word" start_char="12954">study</TOKEN>
<TOKEN end_char="12967" id="token-139-19" morph="none" pos="word" start_char="12960">protocol</TOKEN>
<TOKEN end_char="12971" id="token-139-20" morph="none" pos="word" start_char="12969">for</TOKEN>
<TOKEN end_char="12973" id="token-139-21" morph="none" pos="word" start_char="12973">a</TOKEN>
<TOKEN end_char="12984" id="token-139-22" morph="none" pos="word" start_char="12975">randomized</TOKEN>
<TOKEN end_char="12995" id="token-139-23" morph="none" pos="word" start_char="12986">controlled</TOKEN>
<TOKEN end_char="13001" id="token-139-24" morph="none" pos="word" start_char="12997">trial</TOKEN>
<TOKEN end_char="13003" id="token-139-25" morph="none" pos="punct" start_char="13002">."</TOKEN>
</SEG>
<SEG end_char="13011" id="segment-140" start_char="13005">
<ORIGINAL_TEXT>Trials.</ORIGINAL_TEXT>
<TOKEN end_char="13010" id="token-140-0" morph="none" pos="word" start_char="13005">Trials</TOKEN>
<TOKEN end_char="13011" id="token-140-1" morph="none" pos="punct" start_char="13011">.</TOKEN>
</SEG>
<SEG end_char="13025" id="segment-141" start_char="13013">
<ORIGINAL_TEXT>19(81), 2018.</ORIGINAL_TEXT>
<TOKEN end_char="13017" id="token-141-0" morph="none" pos="unknown" start_char="13013">19(81</TOKEN>
<TOKEN end_char="13019" id="token-141-1" morph="none" pos="punct" start_char="13018">),</TOKEN>
<TOKEN end_char="13024" id="token-141-2" morph="none" pos="word" start_char="13021">2018</TOKEN>
<TOKEN end_char="13025" id="token-141-3" morph="none" pos="punct" start_char="13025">.</TOKEN>
<TRANSLATED_TEXT>18 (81), 2018.</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="13047" id="segment-142" start_char="13028">
<ORIGINAL_TEXT>Arabi, Yaseen M. et.</ORIGINAL_TEXT>
<TOKEN end_char="13032" id="token-142-0" morph="none" pos="word" start_char="13028">Arabi</TOKEN>
<TOKEN end_char="13033" id="token-142-1" morph="none" pos="punct" start_char="13033">,</TOKEN>
<TOKEN end_char="13040" id="token-142-2" morph="none" pos="word" start_char="13035">Yaseen</TOKEN>
<TOKEN end_char="13042" id="token-142-3" morph="none" pos="word" start_char="13042">M</TOKEN>
<TOKEN end_char="13043" id="token-142-4" morph="none" pos="punct" start_char="13043">.</TOKEN>
<TOKEN end_char="13046" id="token-142-5" morph="none" pos="word" start_char="13045">et</TOKEN>
<TOKEN end_char="13047" id="token-142-6" morph="none" pos="punct" start_char="13047">.</TOKEN>
<TRANSLATED_TEXT>Arabi, Yaseen M. et al.</TRANSLATED_TEXT><DETECTED_LANGUAGE>tr</DETECTED_LANGUAGE></SEG>
<SEG end_char="13051" id="segment-143" start_char="13049">
<ORIGINAL_TEXT>al.</ORIGINAL_TEXT>
<TOKEN end_char="13050" id="token-143-0" morph="none" pos="word" start_char="13049">al</TOKEN>
<TOKEN end_char="13051" id="token-143-1" morph="none" pos="punct" start_char="13051">.</TOKEN>
<TRANSLATED_TEXT>Here.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="13275" id="segment-144" start_char="13053">
<ORIGINAL_TEXT>"Treatment of Middle East respiratory syndrome with a combination of lopinavir/ritonavir and interferon-β1b (MIRACLE trial): statistical analysis plan for a recursive two-stage group sequential randomized controlled trial."</ORIGINAL_TEXT>
<TOKEN end_char="13053" id="token-144-0" morph="none" pos="punct" start_char="13053">"</TOKEN>
<TOKEN end_char="13062" id="token-144-1" morph="none" pos="word" start_char="13054">Treatment</TOKEN>
<TOKEN end_char="13065" id="token-144-2" morph="none" pos="word" start_char="13064">of</TOKEN>
<TOKEN end_char="13072" id="token-144-3" morph="none" pos="word" start_char="13067">Middle</TOKEN>
<TOKEN end_char="13077" id="token-144-4" morph="none" pos="word" start_char="13074">East</TOKEN>
<TOKEN end_char="13089" id="token-144-5" morph="none" pos="word" start_char="13079">respiratory</TOKEN>
<TOKEN end_char="13098" id="token-144-6" morph="none" pos="word" start_char="13091">syndrome</TOKEN>
<TOKEN end_char="13103" id="token-144-7" morph="none" pos="word" start_char="13100">with</TOKEN>
<TOKEN end_char="13105" id="token-144-8" morph="none" pos="word" start_char="13105">a</TOKEN>
<TOKEN end_char="13117" id="token-144-9" morph="none" pos="word" start_char="13107">combination</TOKEN>
<TOKEN end_char="13120" id="token-144-10" morph="none" pos="word" start_char="13119">of</TOKEN>
<TOKEN end_char="13140" id="token-144-11" morph="none" pos="unknown" start_char="13122">lopinavir/ritonavir</TOKEN>
<TOKEN end_char="13144" id="token-144-12" morph="none" pos="word" start_char="13142">and</TOKEN>
<TOKEN end_char="13159" id="token-144-13" morph="none" pos="unknown" start_char="13146">interferon-β1b</TOKEN>
<TOKEN end_char="13161" id="token-144-14" morph="none" pos="punct" start_char="13161">(</TOKEN>
<TOKEN end_char="13168" id="token-144-15" morph="none" pos="word" start_char="13162">MIRACLE</TOKEN>
<TOKEN end_char="13174" id="token-144-16" morph="none" pos="word" start_char="13170">trial</TOKEN>
<TOKEN end_char="13176" id="token-144-17" morph="none" pos="punct" start_char="13175">):</TOKEN>
<TOKEN end_char="13188" id="token-144-18" morph="none" pos="word" start_char="13178">statistical</TOKEN>
<TOKEN end_char="13197" id="token-144-19" morph="none" pos="word" start_char="13190">analysis</TOKEN>
<TOKEN end_char="13202" id="token-144-20" morph="none" pos="word" start_char="13199">plan</TOKEN>
<TOKEN end_char="13206" id="token-144-21" morph="none" pos="word" start_char="13204">for</TOKEN>
<TOKEN end_char="13208" id="token-144-22" morph="none" pos="word" start_char="13208">a</TOKEN>
<TOKEN end_char="13218" id="token-144-23" morph="none" pos="word" start_char="13210">recursive</TOKEN>
<TOKEN end_char="13228" id="token-144-24" morph="none" pos="unknown" start_char="13220">two-stage</TOKEN>
<TOKEN end_char="13234" id="token-144-25" morph="none" pos="word" start_char="13230">group</TOKEN>
<TOKEN end_char="13245" id="token-144-26" morph="none" pos="word" start_char="13236">sequential</TOKEN>
<TOKEN end_char="13256" id="token-144-27" morph="none" pos="word" start_char="13247">randomized</TOKEN>
<TOKEN end_char="13267" id="token-144-28" morph="none" pos="word" start_char="13258">controlled</TOKEN>
<TOKEN end_char="13273" id="token-144-29" morph="none" pos="word" start_char="13269">trial</TOKEN>
<TOKEN end_char="13275" id="token-144-30" morph="none" pos="punct" start_char="13274">."</TOKEN>
</SEG>
<SEG end_char="13283" id="segment-145" start_char="13277">
<ORIGINAL_TEXT>Trials.</ORIGINAL_TEXT>
<TOKEN end_char="13282" id="token-145-0" morph="none" pos="word" start_char="13277">Trials</TOKEN>
<TOKEN end_char="13283" id="token-145-1" morph="none" pos="punct" start_char="13283">.</TOKEN>
</SEG>
<SEG end_char="13296" id="segment-146" start_char="13285">
<ORIGINAL_TEXT>21(8), 2020.</ORIGINAL_TEXT>
<TOKEN end_char="13288" id="token-146-0" morph="none" pos="unknown" start_char="13285">21(8</TOKEN>
<TOKEN end_char="13290" id="token-146-1" morph="none" pos="punct" start_char="13289">),</TOKEN>
<TOKEN end_char="13295" id="token-146-2" morph="none" pos="word" start_char="13292">2020</TOKEN>
<TOKEN end_char="13296" id="token-146-3" morph="none" pos="punct" start_char="13296">.</TOKEN>
<TRANSLATED_TEXT>21 (8): 2020.</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="13312" id="segment-147" start_char="13299">
<ORIGINAL_TEXT>Zhou, Peng et.</ORIGINAL_TEXT>
<TOKEN end_char="13302" id="token-147-0" morph="none" pos="word" start_char="13299">Zhou</TOKEN>
<TOKEN end_char="13303" id="token-147-1" morph="none" pos="punct" start_char="13303">,</TOKEN>
<TOKEN end_char="13308" id="token-147-2" morph="none" pos="word" start_char="13305">Peng</TOKEN>
<TOKEN end_char="13311" id="token-147-3" morph="none" pos="word" start_char="13310">et</TOKEN>
<TOKEN end_char="13312" id="token-147-4" morph="none" pos="punct" start_char="13312">.</TOKEN>
<TRANSLATED_TEXT>Zhou, Peng.</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="13316" id="segment-148" start_char="13314">
<ORIGINAL_TEXT>al.</ORIGINAL_TEXT>
<TOKEN end_char="13315" id="token-148-0" morph="none" pos="word" start_char="13314">al</TOKEN>
<TOKEN end_char="13316" id="token-148-1" morph="none" pos="punct" start_char="13316">.</TOKEN>
<TRANSLATED_TEXT>Here.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="13397" id="segment-149" start_char="13318">
<ORIGINAL_TEXT>"A pneumonia outbreak associated with a new coronavirus of probable bat origin."</ORIGINAL_TEXT>
<TOKEN end_char="13318" id="token-149-0" morph="none" pos="punct" start_char="13318">"</TOKEN>
<TOKEN end_char="13319" id="token-149-1" morph="none" pos="word" start_char="13319">A</TOKEN>
<TOKEN end_char="13329" id="token-149-2" morph="none" pos="word" start_char="13321">pneumonia</TOKEN>
<TOKEN end_char="13338" id="token-149-3" morph="none" pos="word" start_char="13331">outbreak</TOKEN>
<TOKEN end_char="13349" id="token-149-4" morph="none" pos="word" start_char="13340">associated</TOKEN>
<TOKEN end_char="13354" id="token-149-5" morph="none" pos="word" start_char="13351">with</TOKEN>
<TOKEN end_char="13356" id="token-149-6" morph="none" pos="word" start_char="13356">a</TOKEN>
<TOKEN end_char="13360" id="token-149-7" morph="none" pos="word" start_char="13358">new</TOKEN>
<TOKEN end_char="13372" id="token-149-8" morph="none" pos="word" start_char="13362">coronavirus</TOKEN>
<TOKEN end_char="13375" id="token-149-9" morph="none" pos="word" start_char="13374">of</TOKEN>
<TOKEN end_char="13384" id="token-149-10" morph="none" pos="word" start_char="13377">probable</TOKEN>
<TOKEN end_char="13388" id="token-149-11" morph="none" pos="word" start_char="13386">bat</TOKEN>
<TOKEN end_char="13395" id="token-149-12" morph="none" pos="word" start_char="13390">origin</TOKEN>
<TOKEN end_char="13397" id="token-149-13" morph="none" pos="punct" start_char="13396">."</TOKEN>
</SEG>
<SEG end_char="13411" id="segment-150" start_char="13399">
<ORIGINAL_TEXT>Nature, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="13404" id="token-150-0" morph="none" pos="word" start_char="13399">Nature</TOKEN>
<TOKEN end_char="13405" id="token-150-1" morph="none" pos="punct" start_char="13405">,</TOKEN>
<TOKEN end_char="13410" id="token-150-2" morph="none" pos="word" start_char="13407">2020</TOKEN>
<TOKEN end_char="13411" id="token-150-3" morph="none" pos="punct" start_char="13411">.</TOKEN>
</SEG>
<SEG end_char="13438" id="segment-151" start_char="13414">
<ORIGINAL_TEXT>Bedford, Trevor (@trvrb).</ORIGINAL_TEXT>
<TOKEN end_char="13420" id="token-151-0" morph="none" pos="word" start_char="13414">Bedford</TOKEN>
<TOKEN end_char="13421" id="token-151-1" morph="none" pos="punct" start_char="13421">,</TOKEN>
<TOKEN end_char="13428" id="token-151-2" morph="none" pos="word" start_char="13423">Trevor</TOKEN>
<TOKEN end_char="13431" id="token-151-3" morph="none" pos="punct" start_char="13430">(@</TOKEN>
<TOKEN end_char="13436" id="token-151-4" morph="none" pos="word" start_char="13432">trvrb</TOKEN>
<TOKEN end_char="13438" id="token-151-5" morph="none" pos="punct" start_char="13437">).</TOKEN>
</SEG>
<SEG end_char="13684" id="segment-152" start_char="13440">
<ORIGINAL_TEXT>"I thought to examine signal of natural evolution in #nCoV2019 by looking at distribution of mutations in the lineage leading to nCoV and compare this distribution to mutations occurring in other SARS-like bat viruses 1/9, and following thread."</ORIGINAL_TEXT>
<TOKEN end_char="13440" id="token-152-0" morph="none" pos="punct" start_char="13440">"</TOKEN>
<TOKEN end_char="13441" id="token-152-1" morph="none" pos="word" start_char="13441">I</TOKEN>
<TOKEN end_char="13449" id="token-152-2" morph="none" pos="word" start_char="13443">thought</TOKEN>
<TOKEN end_char="13452" id="token-152-3" morph="none" pos="word" start_char="13451">to</TOKEN>
<TOKEN end_char="13460" id="token-152-4" morph="none" pos="word" start_char="13454">examine</TOKEN>
<TOKEN end_char="13467" id="token-152-5" morph="none" pos="word" start_char="13462">signal</TOKEN>
<TOKEN end_char="13470" id="token-152-6" morph="none" pos="word" start_char="13469">of</TOKEN>
<TOKEN end_char="13478" id="token-152-7" morph="none" pos="word" start_char="13472">natural</TOKEN>
<TOKEN end_char="13488" id="token-152-8" morph="none" pos="word" start_char="13480">evolution</TOKEN>
<TOKEN end_char="13491" id="token-152-9" morph="none" pos="word" start_char="13490">in</TOKEN>
<TOKEN end_char="13501" id="token-152-10" morph="none" pos="tag" start_char="13493">#nCoV2019</TOKEN>
<TOKEN end_char="13504" id="token-152-11" morph="none" pos="word" start_char="13503">by</TOKEN>
<TOKEN end_char="13512" id="token-152-12" morph="none" pos="word" start_char="13506">looking</TOKEN>
<TOKEN end_char="13515" id="token-152-13" morph="none" pos="word" start_char="13514">at</TOKEN>
<TOKEN end_char="13528" id="token-152-14" morph="none" pos="word" start_char="13517">distribution</TOKEN>
<TOKEN end_char="13531" id="token-152-15" morph="none" pos="word" start_char="13530">of</TOKEN>
<TOKEN end_char="13541" id="token-152-16" morph="none" pos="word" start_char="13533">mutations</TOKEN>
<TOKEN end_char="13544" id="token-152-17" morph="none" pos="word" start_char="13543">in</TOKEN>
<TOKEN end_char="13548" id="token-152-18" morph="none" pos="word" start_char="13546">the</TOKEN>
<TOKEN end_char="13556" id="token-152-19" morph="none" pos="word" start_char="13550">lineage</TOKEN>
<TOKEN end_char="13564" id="token-152-20" morph="none" pos="word" start_char="13558">leading</TOKEN>
<TOKEN end_char="13567" id="token-152-21" morph="none" pos="word" start_char="13566">to</TOKEN>
<TOKEN end_char="13572" id="token-152-22" morph="none" pos="word" start_char="13569">nCoV</TOKEN>
<TOKEN end_char="13576" id="token-152-23" morph="none" pos="word" start_char="13574">and</TOKEN>
<TOKEN end_char="13584" id="token-152-24" morph="none" pos="word" start_char="13578">compare</TOKEN>
<TOKEN end_char="13589" id="token-152-25" morph="none" pos="word" start_char="13586">this</TOKEN>
<TOKEN end_char="13602" id="token-152-26" morph="none" pos="word" start_char="13591">distribution</TOKEN>
<TOKEN end_char="13605" id="token-152-27" morph="none" pos="word" start_char="13604">to</TOKEN>
<TOKEN end_char="13615" id="token-152-28" morph="none" pos="word" start_char="13607">mutations</TOKEN>
<TOKEN end_char="13625" id="token-152-29" morph="none" pos="word" start_char="13617">occurring</TOKEN>
<TOKEN end_char="13628" id="token-152-30" morph="none" pos="word" start_char="13627">in</TOKEN>
<TOKEN end_char="13634" id="token-152-31" morph="none" pos="word" start_char="13630">other</TOKEN>
<TOKEN end_char="13644" id="token-152-32" morph="none" pos="unknown" start_char="13636">SARS-like</TOKEN>
<TOKEN end_char="13648" id="token-152-33" morph="none" pos="word" start_char="13646">bat</TOKEN>
<TOKEN end_char="13656" id="token-152-34" morph="none" pos="word" start_char="13650">viruses</TOKEN>
<TOKEN end_char="13660" id="token-152-35" morph="none" pos="unknown" start_char="13658">1/9</TOKEN>
<TOKEN end_char="13661" id="token-152-36" morph="none" pos="punct" start_char="13661">,</TOKEN>
<TOKEN end_char="13665" id="token-152-37" morph="none" pos="word" start_char="13663">and</TOKEN>
<TOKEN end_char="13675" id="token-152-38" morph="none" pos="word" start_char="13667">following</TOKEN>
<TOKEN end_char="13682" id="token-152-39" morph="none" pos="word" start_char="13677">thread</TOKEN>
<TOKEN end_char="13684" id="token-152-40" morph="none" pos="punct" start_char="13683">."</TOKEN>
</SEG>
<SEG end_char="13693" id="segment-153" start_char="13686">
<ORIGINAL_TEXT>Twitter.</ORIGINAL_TEXT>
<TOKEN end_char="13692" id="token-153-0" morph="none" pos="word" start_char="13686">Twitter</TOKEN>
<TOKEN end_char="13693" id="token-153-1" morph="none" pos="punct" start_char="13693">.</TOKEN>
</SEG>
<SEG end_char="13705" id="segment-154" start_char="13695">
<ORIGINAL_TEXT>3 Feb 2020.</ORIGINAL_TEXT>
<TOKEN end_char="13695" id="token-154-0" morph="none" pos="word" start_char="13695">3</TOKEN>
<TOKEN end_char="13699" id="token-154-1" morph="none" pos="word" start_char="13697">Feb</TOKEN>
<TOKEN end_char="13704" id="token-154-2" morph="none" pos="word" start_char="13701">2020</TOKEN>
<TOKEN end_char="13705" id="token-154-3" morph="none" pos="punct" start_char="13705">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
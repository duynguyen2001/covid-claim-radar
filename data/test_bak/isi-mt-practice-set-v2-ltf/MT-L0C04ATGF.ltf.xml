<LCTL_TEXT lang="eng">
<DOC grammar="none" id="L0C04ATGF" lang="eng" raw_text_char_length="3514" raw_text_md5="f1143da2ad0b055276b61c15052dc8f1" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="67" id="segment-0" start_char="1">
<ORIGINAL_TEXT>WHO and other experts say no evidence of coronavirus losing potency</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">WHO</TOKEN>
<TOKEN end_char="7" id="token-0-1" morph="none" pos="word" start_char="5">and</TOKEN>
<TOKEN end_char="13" id="token-0-2" morph="none" pos="word" start_char="9">other</TOKEN>
<TOKEN end_char="21" id="token-0-3" morph="none" pos="word" start_char="15">experts</TOKEN>
<TOKEN end_char="25" id="token-0-4" morph="none" pos="word" start_char="23">say</TOKEN>
<TOKEN end_char="28" id="token-0-5" morph="none" pos="word" start_char="27">no</TOKEN>
<TOKEN end_char="37" id="token-0-6" morph="none" pos="word" start_char="30">evidence</TOKEN>
<TOKEN end_char="40" id="token-0-7" morph="none" pos="word" start_char="39">of</TOKEN>
<TOKEN end_char="52" id="token-0-8" morph="none" pos="word" start_char="42">coronavirus</TOKEN>
<TOKEN end_char="59" id="token-0-9" morph="none" pos="word" start_char="54">losing</TOKEN>
<TOKEN end_char="67" id="token-0-10" morph="none" pos="word" start_char="61">potency</TOKEN>
</SEG>
<SEG end_char="330" id="segment-1" start_char="71">
<ORIGINAL_TEXT>LONDON/MILAN (Reuters) - World Health Organization experts and a range of other scientists said on Monday there was no evidence to support an assertion by a high-profile Italian doctor that the coronavirus causing the COVID-19 pandemic has been losing potency.</ORIGINAL_TEXT>
<TOKEN end_char="82" id="token-1-0" morph="none" pos="unknown" start_char="71">LONDON/MILAN</TOKEN>
<TOKEN end_char="84" id="token-1-1" morph="none" pos="punct" start_char="84">(</TOKEN>
<TOKEN end_char="91" id="token-1-2" morph="none" pos="word" start_char="85">Reuters</TOKEN>
<TOKEN end_char="92" id="token-1-3" morph="none" pos="punct" start_char="92">)</TOKEN>
<TOKEN end_char="94" id="token-1-4" morph="none" pos="punct" start_char="94">-</TOKEN>
<TOKEN end_char="100" id="token-1-5" morph="none" pos="word" start_char="96">World</TOKEN>
<TOKEN end_char="107" id="token-1-6" morph="none" pos="word" start_char="102">Health</TOKEN>
<TOKEN end_char="120" id="token-1-7" morph="none" pos="word" start_char="109">Organization</TOKEN>
<TOKEN end_char="128" id="token-1-8" morph="none" pos="word" start_char="122">experts</TOKEN>
<TOKEN end_char="132" id="token-1-9" morph="none" pos="word" start_char="130">and</TOKEN>
<TOKEN end_char="134" id="token-1-10" morph="none" pos="word" start_char="134">a</TOKEN>
<TOKEN end_char="140" id="token-1-11" morph="none" pos="word" start_char="136">range</TOKEN>
<TOKEN end_char="143" id="token-1-12" morph="none" pos="word" start_char="142">of</TOKEN>
<TOKEN end_char="149" id="token-1-13" morph="none" pos="word" start_char="145">other</TOKEN>
<TOKEN end_char="160" id="token-1-14" morph="none" pos="word" start_char="151">scientists</TOKEN>
<TOKEN end_char="165" id="token-1-15" morph="none" pos="word" start_char="162">said</TOKEN>
<TOKEN end_char="168" id="token-1-16" morph="none" pos="word" start_char="167">on</TOKEN>
<TOKEN end_char="175" id="token-1-17" morph="none" pos="word" start_char="170">Monday</TOKEN>
<TOKEN end_char="181" id="token-1-18" morph="none" pos="word" start_char="177">there</TOKEN>
<TOKEN end_char="185" id="token-1-19" morph="none" pos="word" start_char="183">was</TOKEN>
<TOKEN end_char="188" id="token-1-20" morph="none" pos="word" start_char="187">no</TOKEN>
<TOKEN end_char="197" id="token-1-21" morph="none" pos="word" start_char="190">evidence</TOKEN>
<TOKEN end_char="200" id="token-1-22" morph="none" pos="word" start_char="199">to</TOKEN>
<TOKEN end_char="208" id="token-1-23" morph="none" pos="word" start_char="202">support</TOKEN>
<TOKEN end_char="211" id="token-1-24" morph="none" pos="word" start_char="210">an</TOKEN>
<TOKEN end_char="221" id="token-1-25" morph="none" pos="word" start_char="213">assertion</TOKEN>
<TOKEN end_char="224" id="token-1-26" morph="none" pos="word" start_char="223">by</TOKEN>
<TOKEN end_char="226" id="token-1-27" morph="none" pos="word" start_char="226">a</TOKEN>
<TOKEN end_char="239" id="token-1-28" morph="none" pos="unknown" start_char="228">high-profile</TOKEN>
<TOKEN end_char="247" id="token-1-29" morph="none" pos="word" start_char="241">Italian</TOKEN>
<TOKEN end_char="254" id="token-1-30" morph="none" pos="word" start_char="249">doctor</TOKEN>
<TOKEN end_char="259" id="token-1-31" morph="none" pos="word" start_char="256">that</TOKEN>
<TOKEN end_char="263" id="token-1-32" morph="none" pos="word" start_char="261">the</TOKEN>
<TOKEN end_char="275" id="token-1-33" morph="none" pos="word" start_char="265">coronavirus</TOKEN>
<TOKEN end_char="283" id="token-1-34" morph="none" pos="word" start_char="277">causing</TOKEN>
<TOKEN end_char="287" id="token-1-35" morph="none" pos="word" start_char="285">the</TOKEN>
<TOKEN end_char="296" id="token-1-36" morph="none" pos="unknown" start_char="289">COVID-19</TOKEN>
<TOKEN end_char="305" id="token-1-37" morph="none" pos="word" start_char="298">pandemic</TOKEN>
<TOKEN end_char="309" id="token-1-38" morph="none" pos="word" start_char="307">has</TOKEN>
<TOKEN end_char="314" id="token-1-39" morph="none" pos="word" start_char="311">been</TOKEN>
<TOKEN end_char="321" id="token-1-40" morph="none" pos="word" start_char="316">losing</TOKEN>
<TOKEN end_char="329" id="token-1-41" morph="none" pos="word" start_char="323">potency</TOKEN>
<TOKEN end_char="330" id="token-1-42" morph="none" pos="punct" start_char="330">.</TOKEN>
</SEG>
<SEG end_char="354" id="segment-2" start_char="333">
<ORIGINAL_TEXT>Slideshow ( 2 images )</ORIGINAL_TEXT>
<TOKEN end_char="341" id="token-2-0" morph="none" pos="word" start_char="333">Slideshow</TOKEN>
<TOKEN end_char="343" id="token-2-1" morph="none" pos="punct" start_char="343">(</TOKEN>
<TOKEN end_char="345" id="token-2-2" morph="none" pos="word" start_char="345">2</TOKEN>
<TOKEN end_char="352" id="token-2-3" morph="none" pos="word" start_char="347">images</TOKEN>
<TOKEN end_char="354" id="token-2-4" morph="none" pos="punct" start_char="354">)</TOKEN>
</SEG>
<SEG end_char="584" id="segment-3" start_char="358">
<ORIGINAL_TEXT>Professor Alberto Zangrillo, head of intensive care at Italy’s San Raffaele Hospital in Lombardy, which bore the brunt of Italy’s epidemic, on Sunday told state television that the new coronavirus "clinically no longer exists".</ORIGINAL_TEXT>
<TOKEN end_char="366" id="token-3-0" morph="none" pos="word" start_char="358">Professor</TOKEN>
<TOKEN end_char="374" id="token-3-1" morph="none" pos="word" start_char="368">Alberto</TOKEN>
<TOKEN end_char="384" id="token-3-2" morph="none" pos="word" start_char="376">Zangrillo</TOKEN>
<TOKEN end_char="385" id="token-3-3" morph="none" pos="punct" start_char="385">,</TOKEN>
<TOKEN end_char="390" id="token-3-4" morph="none" pos="word" start_char="387">head</TOKEN>
<TOKEN end_char="393" id="token-3-5" morph="none" pos="word" start_char="392">of</TOKEN>
<TOKEN end_char="403" id="token-3-6" morph="none" pos="word" start_char="395">intensive</TOKEN>
<TOKEN end_char="408" id="token-3-7" morph="none" pos="word" start_char="405">care</TOKEN>
<TOKEN end_char="411" id="token-3-8" morph="none" pos="word" start_char="410">at</TOKEN>
<TOKEN end_char="419" id="token-3-9" morph="none" pos="word" start_char="413">Italy’s</TOKEN>
<TOKEN end_char="423" id="token-3-10" morph="none" pos="word" start_char="421">San</TOKEN>
<TOKEN end_char="432" id="token-3-11" morph="none" pos="word" start_char="425">Raffaele</TOKEN>
<TOKEN end_char="441" id="token-3-12" morph="none" pos="word" start_char="434">Hospital</TOKEN>
<TOKEN end_char="444" id="token-3-13" morph="none" pos="word" start_char="443">in</TOKEN>
<TOKEN end_char="453" id="token-3-14" morph="none" pos="word" start_char="446">Lombardy</TOKEN>
<TOKEN end_char="454" id="token-3-15" morph="none" pos="punct" start_char="454">,</TOKEN>
<TOKEN end_char="460" id="token-3-16" morph="none" pos="word" start_char="456">which</TOKEN>
<TOKEN end_char="465" id="token-3-17" morph="none" pos="word" start_char="462">bore</TOKEN>
<TOKEN end_char="469" id="token-3-18" morph="none" pos="word" start_char="467">the</TOKEN>
<TOKEN end_char="475" id="token-3-19" morph="none" pos="word" start_char="471">brunt</TOKEN>
<TOKEN end_char="478" id="token-3-20" morph="none" pos="word" start_char="477">of</TOKEN>
<TOKEN end_char="486" id="token-3-21" morph="none" pos="word" start_char="480">Italy’s</TOKEN>
<TOKEN end_char="495" id="token-3-22" morph="none" pos="word" start_char="488">epidemic</TOKEN>
<TOKEN end_char="496" id="token-3-23" morph="none" pos="punct" start_char="496">,</TOKEN>
<TOKEN end_char="499" id="token-3-24" morph="none" pos="word" start_char="498">on</TOKEN>
<TOKEN end_char="506" id="token-3-25" morph="none" pos="word" start_char="501">Sunday</TOKEN>
<TOKEN end_char="511" id="token-3-26" morph="none" pos="word" start_char="508">told</TOKEN>
<TOKEN end_char="517" id="token-3-27" morph="none" pos="word" start_char="513">state</TOKEN>
<TOKEN end_char="528" id="token-3-28" morph="none" pos="word" start_char="519">television</TOKEN>
<TOKEN end_char="533" id="token-3-29" morph="none" pos="word" start_char="530">that</TOKEN>
<TOKEN end_char="537" id="token-3-30" morph="none" pos="word" start_char="535">the</TOKEN>
<TOKEN end_char="541" id="token-3-31" morph="none" pos="word" start_char="539">new</TOKEN>
<TOKEN end_char="553" id="token-3-32" morph="none" pos="word" start_char="543">coronavirus</TOKEN>
<TOKEN end_char="555" id="token-3-33" morph="none" pos="punct" start_char="555">"</TOKEN>
<TOKEN end_char="565" id="token-3-34" morph="none" pos="word" start_char="556">clinically</TOKEN>
<TOKEN end_char="568" id="token-3-35" morph="none" pos="word" start_char="567">no</TOKEN>
<TOKEN end_char="575" id="token-3-36" morph="none" pos="word" start_char="570">longer</TOKEN>
<TOKEN end_char="582" id="token-3-37" morph="none" pos="word" start_char="577">exists</TOKEN>
<TOKEN end_char="584" id="token-3-38" morph="none" pos="punct" start_char="583">".</TOKEN>
</SEG>
<SEG end_char="758" id="segment-4" start_char="587">
<ORIGINAL_TEXT>But WHO epidemiologist Maria Van Kerkhove and several other experts on viruses and infectious diseases, said Zangrillo’s comments were not supported by scientific evidence.</ORIGINAL_TEXT>
<TOKEN end_char="589" id="token-4-0" morph="none" pos="word" start_char="587">But</TOKEN>
<TOKEN end_char="593" id="token-4-1" morph="none" pos="word" start_char="591">WHO</TOKEN>
<TOKEN end_char="608" id="token-4-2" morph="none" pos="word" start_char="595">epidemiologist</TOKEN>
<TOKEN end_char="614" id="token-4-3" morph="none" pos="word" start_char="610">Maria</TOKEN>
<TOKEN end_char="618" id="token-4-4" morph="none" pos="word" start_char="616">Van</TOKEN>
<TOKEN end_char="627" id="token-4-5" morph="none" pos="word" start_char="620">Kerkhove</TOKEN>
<TOKEN end_char="631" id="token-4-6" morph="none" pos="word" start_char="629">and</TOKEN>
<TOKEN end_char="639" id="token-4-7" morph="none" pos="word" start_char="633">several</TOKEN>
<TOKEN end_char="645" id="token-4-8" morph="none" pos="word" start_char="641">other</TOKEN>
<TOKEN end_char="653" id="token-4-9" morph="none" pos="word" start_char="647">experts</TOKEN>
<TOKEN end_char="656" id="token-4-10" morph="none" pos="word" start_char="655">on</TOKEN>
<TOKEN end_char="664" id="token-4-11" morph="none" pos="word" start_char="658">viruses</TOKEN>
<TOKEN end_char="668" id="token-4-12" morph="none" pos="word" start_char="666">and</TOKEN>
<TOKEN end_char="679" id="token-4-13" morph="none" pos="word" start_char="670">infectious</TOKEN>
<TOKEN end_char="688" id="token-4-14" morph="none" pos="word" start_char="681">diseases</TOKEN>
<TOKEN end_char="689" id="token-4-15" morph="none" pos="punct" start_char="689">,</TOKEN>
<TOKEN end_char="694" id="token-4-16" morph="none" pos="word" start_char="691">said</TOKEN>
<TOKEN end_char="706" id="token-4-17" morph="none" pos="word" start_char="696">Zangrillo’s</TOKEN>
<TOKEN end_char="715" id="token-4-18" morph="none" pos="word" start_char="708">comments</TOKEN>
<TOKEN end_char="720" id="token-4-19" morph="none" pos="word" start_char="717">were</TOKEN>
<TOKEN end_char="724" id="token-4-20" morph="none" pos="word" start_char="722">not</TOKEN>
<TOKEN end_char="734" id="token-4-21" morph="none" pos="word" start_char="726">supported</TOKEN>
<TOKEN end_char="737" id="token-4-22" morph="none" pos="word" start_char="736">by</TOKEN>
<TOKEN end_char="748" id="token-4-23" morph="none" pos="word" start_char="739">scientific</TOKEN>
<TOKEN end_char="757" id="token-4-24" morph="none" pos="word" start_char="750">evidence</TOKEN>
<TOKEN end_char="758" id="token-4-25" morph="none" pos="punct" start_char="758">.</TOKEN>
</SEG>
<SEG end_char="922" id="segment-5" start_char="761">
<ORIGINAL_TEXT>There is no data to show the new coronavirus is changing significantly, either in its form of transmission or in the severity of the disease it causes, they said.</ORIGINAL_TEXT>
<TOKEN end_char="765" id="token-5-0" morph="none" pos="word" start_char="761">There</TOKEN>
<TOKEN end_char="768" id="token-5-1" morph="none" pos="word" start_char="767">is</TOKEN>
<TOKEN end_char="771" id="token-5-2" morph="none" pos="word" start_char="770">no</TOKEN>
<TOKEN end_char="776" id="token-5-3" morph="none" pos="word" start_char="773">data</TOKEN>
<TOKEN end_char="779" id="token-5-4" morph="none" pos="word" start_char="778">to</TOKEN>
<TOKEN end_char="784" id="token-5-5" morph="none" pos="word" start_char="781">show</TOKEN>
<TOKEN end_char="788" id="token-5-6" morph="none" pos="word" start_char="786">the</TOKEN>
<TOKEN end_char="792" id="token-5-7" morph="none" pos="word" start_char="790">new</TOKEN>
<TOKEN end_char="804" id="token-5-8" morph="none" pos="word" start_char="794">coronavirus</TOKEN>
<TOKEN end_char="807" id="token-5-9" morph="none" pos="word" start_char="806">is</TOKEN>
<TOKEN end_char="816" id="token-5-10" morph="none" pos="word" start_char="809">changing</TOKEN>
<TOKEN end_char="830" id="token-5-11" morph="none" pos="word" start_char="818">significantly</TOKEN>
<TOKEN end_char="831" id="token-5-12" morph="none" pos="punct" start_char="831">,</TOKEN>
<TOKEN end_char="838" id="token-5-13" morph="none" pos="word" start_char="833">either</TOKEN>
<TOKEN end_char="841" id="token-5-14" morph="none" pos="word" start_char="840">in</TOKEN>
<TOKEN end_char="845" id="token-5-15" morph="none" pos="word" start_char="843">its</TOKEN>
<TOKEN end_char="850" id="token-5-16" morph="none" pos="word" start_char="847">form</TOKEN>
<TOKEN end_char="853" id="token-5-17" morph="none" pos="word" start_char="852">of</TOKEN>
<TOKEN end_char="866" id="token-5-18" morph="none" pos="word" start_char="855">transmission</TOKEN>
<TOKEN end_char="869" id="token-5-19" morph="none" pos="word" start_char="868">or</TOKEN>
<TOKEN end_char="872" id="token-5-20" morph="none" pos="word" start_char="871">in</TOKEN>
<TOKEN end_char="876" id="token-5-21" morph="none" pos="word" start_char="874">the</TOKEN>
<TOKEN end_char="885" id="token-5-22" morph="none" pos="word" start_char="878">severity</TOKEN>
<TOKEN end_char="888" id="token-5-23" morph="none" pos="word" start_char="887">of</TOKEN>
<TOKEN end_char="892" id="token-5-24" morph="none" pos="word" start_char="890">the</TOKEN>
<TOKEN end_char="900" id="token-5-25" morph="none" pos="word" start_char="894">disease</TOKEN>
<TOKEN end_char="903" id="token-5-26" morph="none" pos="word" start_char="902">it</TOKEN>
<TOKEN end_char="910" id="token-5-27" morph="none" pos="word" start_char="905">causes</TOKEN>
<TOKEN end_char="911" id="token-5-28" morph="none" pos="punct" start_char="911">,</TOKEN>
<TOKEN end_char="916" id="token-5-29" morph="none" pos="word" start_char="913">they</TOKEN>
<TOKEN end_char="921" id="token-5-30" morph="none" pos="word" start_char="918">said</TOKEN>
<TOKEN end_char="922" id="token-5-31" morph="none" pos="punct" start_char="922">.</TOKEN>
</SEG>
<SEG end_char="1050" id="segment-6" start_char="925">
<ORIGINAL_TEXT>"In terms of transmissibility, that has not changed, in terms of severity, that has not changed," Van Kerkhove told reporters.</ORIGINAL_TEXT>
<TOKEN end_char="925" id="token-6-0" morph="none" pos="punct" start_char="925">"</TOKEN>
<TOKEN end_char="927" id="token-6-1" morph="none" pos="word" start_char="926">In</TOKEN>
<TOKEN end_char="933" id="token-6-2" morph="none" pos="word" start_char="929">terms</TOKEN>
<TOKEN end_char="936" id="token-6-3" morph="none" pos="word" start_char="935">of</TOKEN>
<TOKEN end_char="953" id="token-6-4" morph="none" pos="word" start_char="938">transmissibility</TOKEN>
<TOKEN end_char="954" id="token-6-5" morph="none" pos="punct" start_char="954">,</TOKEN>
<TOKEN end_char="959" id="token-6-6" morph="none" pos="word" start_char="956">that</TOKEN>
<TOKEN end_char="963" id="token-6-7" morph="none" pos="word" start_char="961">has</TOKEN>
<TOKEN end_char="967" id="token-6-8" morph="none" pos="word" start_char="965">not</TOKEN>
<TOKEN end_char="975" id="token-6-9" morph="none" pos="word" start_char="969">changed</TOKEN>
<TOKEN end_char="976" id="token-6-10" morph="none" pos="punct" start_char="976">,</TOKEN>
<TOKEN end_char="979" id="token-6-11" morph="none" pos="word" start_char="978">in</TOKEN>
<TOKEN end_char="985" id="token-6-12" morph="none" pos="word" start_char="981">terms</TOKEN>
<TOKEN end_char="988" id="token-6-13" morph="none" pos="word" start_char="987">of</TOKEN>
<TOKEN end_char="997" id="token-6-14" morph="none" pos="word" start_char="990">severity</TOKEN>
<TOKEN end_char="998" id="token-6-15" morph="none" pos="punct" start_char="998">,</TOKEN>
<TOKEN end_char="1003" id="token-6-16" morph="none" pos="word" start_char="1000">that</TOKEN>
<TOKEN end_char="1007" id="token-6-17" morph="none" pos="word" start_char="1005">has</TOKEN>
<TOKEN end_char="1011" id="token-6-18" morph="none" pos="word" start_char="1009">not</TOKEN>
<TOKEN end_char="1019" id="token-6-19" morph="none" pos="word" start_char="1013">changed</TOKEN>
<TOKEN end_char="1021" id="token-6-20" morph="none" pos="punct" start_char="1020">,"</TOKEN>
<TOKEN end_char="1025" id="token-6-21" morph="none" pos="word" start_char="1023">Van</TOKEN>
<TOKEN end_char="1034" id="token-6-22" morph="none" pos="word" start_char="1027">Kerkhove</TOKEN>
<TOKEN end_char="1039" id="token-6-23" morph="none" pos="word" start_char="1036">told</TOKEN>
<TOKEN end_char="1049" id="token-6-24" morph="none" pos="word" start_char="1041">reporters</TOKEN>
<TOKEN end_char="1050" id="token-6-25" morph="none" pos="punct" start_char="1050">.</TOKEN>
</SEG>
<SEG end_char="1117" id="segment-7" start_char="1053">
<ORIGINAL_TEXT>It is not unusual for viruses to mutate and adapt as they spread.</ORIGINAL_TEXT>
<TOKEN end_char="1054" id="token-7-0" morph="none" pos="word" start_char="1053">It</TOKEN>
<TOKEN end_char="1057" id="token-7-1" morph="none" pos="word" start_char="1056">is</TOKEN>
<TOKEN end_char="1061" id="token-7-2" morph="none" pos="word" start_char="1059">not</TOKEN>
<TOKEN end_char="1069" id="token-7-3" morph="none" pos="word" start_char="1063">unusual</TOKEN>
<TOKEN end_char="1073" id="token-7-4" morph="none" pos="word" start_char="1071">for</TOKEN>
<TOKEN end_char="1081" id="token-7-5" morph="none" pos="word" start_char="1075">viruses</TOKEN>
<TOKEN end_char="1084" id="token-7-6" morph="none" pos="word" start_char="1083">to</TOKEN>
<TOKEN end_char="1091" id="token-7-7" morph="none" pos="word" start_char="1086">mutate</TOKEN>
<TOKEN end_char="1095" id="token-7-8" morph="none" pos="word" start_char="1093">and</TOKEN>
<TOKEN end_char="1101" id="token-7-9" morph="none" pos="word" start_char="1097">adapt</TOKEN>
<TOKEN end_char="1104" id="token-7-10" morph="none" pos="word" start_char="1103">as</TOKEN>
<TOKEN end_char="1109" id="token-7-11" morph="none" pos="word" start_char="1106">they</TOKEN>
<TOKEN end_char="1116" id="token-7-12" morph="none" pos="word" start_char="1111">spread</TOKEN>
<TOKEN end_char="1117" id="token-7-13" morph="none" pos="punct" start_char="1117">.</TOKEN>
</SEG>
<SEG end_char="1207" id="segment-8" start_char="1119">
<ORIGINAL_TEXT>The pandemic has so far killed more than 370,000 people and infected more than 6 million.</ORIGINAL_TEXT>
<TOKEN end_char="1121" id="token-8-0" morph="none" pos="word" start_char="1119">The</TOKEN>
<TOKEN end_char="1130" id="token-8-1" morph="none" pos="word" start_char="1123">pandemic</TOKEN>
<TOKEN end_char="1134" id="token-8-2" morph="none" pos="word" start_char="1132">has</TOKEN>
<TOKEN end_char="1137" id="token-8-3" morph="none" pos="word" start_char="1136">so</TOKEN>
<TOKEN end_char="1141" id="token-8-4" morph="none" pos="word" start_char="1139">far</TOKEN>
<TOKEN end_char="1148" id="token-8-5" morph="none" pos="word" start_char="1143">killed</TOKEN>
<TOKEN end_char="1153" id="token-8-6" morph="none" pos="word" start_char="1150">more</TOKEN>
<TOKEN end_char="1158" id="token-8-7" morph="none" pos="word" start_char="1155">than</TOKEN>
<TOKEN end_char="1166" id="token-8-8" morph="none" pos="unknown" start_char="1160">370,000</TOKEN>
<TOKEN end_char="1173" id="token-8-9" morph="none" pos="word" start_char="1168">people</TOKEN>
<TOKEN end_char="1177" id="token-8-10" morph="none" pos="word" start_char="1175">and</TOKEN>
<TOKEN end_char="1186" id="token-8-11" morph="none" pos="word" start_char="1179">infected</TOKEN>
<TOKEN end_char="1191" id="token-8-12" morph="none" pos="word" start_char="1188">more</TOKEN>
<TOKEN end_char="1196" id="token-8-13" morph="none" pos="word" start_char="1193">than</TOKEN>
<TOKEN end_char="1198" id="token-8-14" morph="none" pos="word" start_char="1198">6</TOKEN>
<TOKEN end_char="1206" id="token-8-15" morph="none" pos="word" start_char="1200">million</TOKEN>
<TOKEN end_char="1207" id="token-8-16" morph="none" pos="punct" start_char="1207">.</TOKEN>
</SEG>
<SEG end_char="1493" id="segment-9" start_char="1210">
<ORIGINAL_TEXT>Martin Hibberd, a professor of emerging infectious disease at the London School of Hygiene Tropical Medicine, said major studies looking at genetic changes in the SARS-CoV-2 virus that causes COVID-19 did not support the idea that it was becoming less potent, or weakening in any way.</ORIGINAL_TEXT>
<TOKEN end_char="1215" id="token-9-0" morph="none" pos="word" start_char="1210">Martin</TOKEN>
<TOKEN end_char="1223" id="token-9-1" morph="none" pos="word" start_char="1217">Hibberd</TOKEN>
<TOKEN end_char="1224" id="token-9-2" morph="none" pos="punct" start_char="1224">,</TOKEN>
<TOKEN end_char="1226" id="token-9-3" morph="none" pos="word" start_char="1226">a</TOKEN>
<TOKEN end_char="1236" id="token-9-4" morph="none" pos="word" start_char="1228">professor</TOKEN>
<TOKEN end_char="1239" id="token-9-5" morph="none" pos="word" start_char="1238">of</TOKEN>
<TOKEN end_char="1248" id="token-9-6" morph="none" pos="word" start_char="1241">emerging</TOKEN>
<TOKEN end_char="1259" id="token-9-7" morph="none" pos="word" start_char="1250">infectious</TOKEN>
<TOKEN end_char="1267" id="token-9-8" morph="none" pos="word" start_char="1261">disease</TOKEN>
<TOKEN end_char="1270" id="token-9-9" morph="none" pos="word" start_char="1269">at</TOKEN>
<TOKEN end_char="1274" id="token-9-10" morph="none" pos="word" start_char="1272">the</TOKEN>
<TOKEN end_char="1281" id="token-9-11" morph="none" pos="word" start_char="1276">London</TOKEN>
<TOKEN end_char="1288" id="token-9-12" morph="none" pos="word" start_char="1283">School</TOKEN>
<TOKEN end_char="1291" id="token-9-13" morph="none" pos="word" start_char="1290">of</TOKEN>
<TOKEN end_char="1299" id="token-9-14" morph="none" pos="word" start_char="1293">Hygiene</TOKEN>
<TOKEN end_char="1308" id="token-9-15" morph="none" pos="word" start_char="1301">Tropical</TOKEN>
<TOKEN end_char="1317" id="token-9-16" morph="none" pos="word" start_char="1310">Medicine</TOKEN>
<TOKEN end_char="1318" id="token-9-17" morph="none" pos="punct" start_char="1318">,</TOKEN>
<TOKEN end_char="1323" id="token-9-18" morph="none" pos="word" start_char="1320">said</TOKEN>
<TOKEN end_char="1329" id="token-9-19" morph="none" pos="word" start_char="1325">major</TOKEN>
<TOKEN end_char="1337" id="token-9-20" morph="none" pos="word" start_char="1331">studies</TOKEN>
<TOKEN end_char="1345" id="token-9-21" morph="none" pos="word" start_char="1339">looking</TOKEN>
<TOKEN end_char="1348" id="token-9-22" morph="none" pos="word" start_char="1347">at</TOKEN>
<TOKEN end_char="1356" id="token-9-23" morph="none" pos="word" start_char="1350">genetic</TOKEN>
<TOKEN end_char="1364" id="token-9-24" morph="none" pos="word" start_char="1358">changes</TOKEN>
<TOKEN end_char="1367" id="token-9-25" morph="none" pos="word" start_char="1366">in</TOKEN>
<TOKEN end_char="1371" id="token-9-26" morph="none" pos="word" start_char="1369">the</TOKEN>
<TOKEN end_char="1382" id="token-9-27" morph="none" pos="unknown" start_char="1373">SARS-CoV-2</TOKEN>
<TOKEN end_char="1388" id="token-9-28" morph="none" pos="word" start_char="1384">virus</TOKEN>
<TOKEN end_char="1393" id="token-9-29" morph="none" pos="word" start_char="1390">that</TOKEN>
<TOKEN end_char="1400" id="token-9-30" morph="none" pos="word" start_char="1395">causes</TOKEN>
<TOKEN end_char="1409" id="token-9-31" morph="none" pos="unknown" start_char="1402">COVID-19</TOKEN>
<TOKEN end_char="1413" id="token-9-32" morph="none" pos="word" start_char="1411">did</TOKEN>
<TOKEN end_char="1417" id="token-9-33" morph="none" pos="word" start_char="1415">not</TOKEN>
<TOKEN end_char="1425" id="token-9-34" morph="none" pos="word" start_char="1419">support</TOKEN>
<TOKEN end_char="1429" id="token-9-35" morph="none" pos="word" start_char="1427">the</TOKEN>
<TOKEN end_char="1434" id="token-9-36" morph="none" pos="word" start_char="1431">idea</TOKEN>
<TOKEN end_char="1439" id="token-9-37" morph="none" pos="word" start_char="1436">that</TOKEN>
<TOKEN end_char="1442" id="token-9-38" morph="none" pos="word" start_char="1441">it</TOKEN>
<TOKEN end_char="1446" id="token-9-39" morph="none" pos="word" start_char="1444">was</TOKEN>
<TOKEN end_char="1455" id="token-9-40" morph="none" pos="word" start_char="1448">becoming</TOKEN>
<TOKEN end_char="1460" id="token-9-41" morph="none" pos="word" start_char="1457">less</TOKEN>
<TOKEN end_char="1467" id="token-9-42" morph="none" pos="word" start_char="1462">potent</TOKEN>
<TOKEN end_char="1468" id="token-9-43" morph="none" pos="punct" start_char="1468">,</TOKEN>
<TOKEN end_char="1471" id="token-9-44" morph="none" pos="word" start_char="1470">or</TOKEN>
<TOKEN end_char="1481" id="token-9-45" morph="none" pos="word" start_char="1473">weakening</TOKEN>
<TOKEN end_char="1484" id="token-9-46" morph="none" pos="word" start_char="1483">in</TOKEN>
<TOKEN end_char="1488" id="token-9-47" morph="none" pos="word" start_char="1486">any</TOKEN>
<TOKEN end_char="1492" id="token-9-48" morph="none" pos="word" start_char="1490">way</TOKEN>
<TOKEN end_char="1493" id="token-9-49" morph="none" pos="punct" start_char="1493">.</TOKEN>
</SEG>
<SEG end_char="1674" id="segment-10" start_char="1496">
<ORIGINAL_TEXT>"With data from more than 35,000 whole virus genomes, there is currently no evidence that there is any significant difference relating to severity," he said in an emailed comment.</ORIGINAL_TEXT>
<TOKEN end_char="1496" id="token-10-0" morph="none" pos="punct" start_char="1496">"</TOKEN>
<TOKEN end_char="1500" id="token-10-1" morph="none" pos="word" start_char="1497">With</TOKEN>
<TOKEN end_char="1505" id="token-10-2" morph="none" pos="word" start_char="1502">data</TOKEN>
<TOKEN end_char="1510" id="token-10-3" morph="none" pos="word" start_char="1507">from</TOKEN>
<TOKEN end_char="1515" id="token-10-4" morph="none" pos="word" start_char="1512">more</TOKEN>
<TOKEN end_char="1520" id="token-10-5" morph="none" pos="word" start_char="1517">than</TOKEN>
<TOKEN end_char="1527" id="token-10-6" morph="none" pos="unknown" start_char="1522">35,000</TOKEN>
<TOKEN end_char="1533" id="token-10-7" morph="none" pos="word" start_char="1529">whole</TOKEN>
<TOKEN end_char="1539" id="token-10-8" morph="none" pos="word" start_char="1535">virus</TOKEN>
<TOKEN end_char="1547" id="token-10-9" morph="none" pos="word" start_char="1541">genomes</TOKEN>
<TOKEN end_char="1548" id="token-10-10" morph="none" pos="punct" start_char="1548">,</TOKEN>
<TOKEN end_char="1554" id="token-10-11" morph="none" pos="word" start_char="1550">there</TOKEN>
<TOKEN end_char="1557" id="token-10-12" morph="none" pos="word" start_char="1556">is</TOKEN>
<TOKEN end_char="1567" id="token-10-13" morph="none" pos="word" start_char="1559">currently</TOKEN>
<TOKEN end_char="1570" id="token-10-14" morph="none" pos="word" start_char="1569">no</TOKEN>
<TOKEN end_char="1579" id="token-10-15" morph="none" pos="word" start_char="1572">evidence</TOKEN>
<TOKEN end_char="1584" id="token-10-16" morph="none" pos="word" start_char="1581">that</TOKEN>
<TOKEN end_char="1590" id="token-10-17" morph="none" pos="word" start_char="1586">there</TOKEN>
<TOKEN end_char="1593" id="token-10-18" morph="none" pos="word" start_char="1592">is</TOKEN>
<TOKEN end_char="1597" id="token-10-19" morph="none" pos="word" start_char="1595">any</TOKEN>
<TOKEN end_char="1609" id="token-10-20" morph="none" pos="word" start_char="1599">significant</TOKEN>
<TOKEN end_char="1620" id="token-10-21" morph="none" pos="word" start_char="1611">difference</TOKEN>
<TOKEN end_char="1629" id="token-10-22" morph="none" pos="word" start_char="1622">relating</TOKEN>
<TOKEN end_char="1632" id="token-10-23" morph="none" pos="word" start_char="1631">to</TOKEN>
<TOKEN end_char="1641" id="token-10-24" morph="none" pos="word" start_char="1634">severity</TOKEN>
<TOKEN end_char="1643" id="token-10-25" morph="none" pos="punct" start_char="1642">,"</TOKEN>
<TOKEN end_char="1646" id="token-10-26" morph="none" pos="word" start_char="1645">he</TOKEN>
<TOKEN end_char="1651" id="token-10-27" morph="none" pos="word" start_char="1648">said</TOKEN>
<TOKEN end_char="1654" id="token-10-28" morph="none" pos="word" start_char="1653">in</TOKEN>
<TOKEN end_char="1657" id="token-10-29" morph="none" pos="word" start_char="1656">an</TOKEN>
<TOKEN end_char="1665" id="token-10-30" morph="none" pos="word" start_char="1659">emailed</TOKEN>
<TOKEN end_char="1673" id="token-10-31" morph="none" pos="word" start_char="1667">comment</TOKEN>
<TOKEN end_char="1674" id="token-10-32" morph="none" pos="punct" start_char="1674">.</TOKEN>
</SEG>
<SEG end_char="1919" id="segment-11" start_char="1677">
<ORIGINAL_TEXT>Zangrillo, well known in Italy as the personal doctor of former Prime Minister Silvio Berlusconi, said his comments were backed up by a study conducted by a fellow scientist, Massimo Clementi, which Zangrillo said would be published next week.</ORIGINAL_TEXT>
<TOKEN end_char="1685" id="token-11-0" morph="none" pos="word" start_char="1677">Zangrillo</TOKEN>
<TOKEN end_char="1686" id="token-11-1" morph="none" pos="punct" start_char="1686">,</TOKEN>
<TOKEN end_char="1691" id="token-11-2" morph="none" pos="word" start_char="1688">well</TOKEN>
<TOKEN end_char="1697" id="token-11-3" morph="none" pos="word" start_char="1693">known</TOKEN>
<TOKEN end_char="1700" id="token-11-4" morph="none" pos="word" start_char="1699">in</TOKEN>
<TOKEN end_char="1706" id="token-11-5" morph="none" pos="word" start_char="1702">Italy</TOKEN>
<TOKEN end_char="1709" id="token-11-6" morph="none" pos="word" start_char="1708">as</TOKEN>
<TOKEN end_char="1713" id="token-11-7" morph="none" pos="word" start_char="1711">the</TOKEN>
<TOKEN end_char="1722" id="token-11-8" morph="none" pos="word" start_char="1715">personal</TOKEN>
<TOKEN end_char="1729" id="token-11-9" morph="none" pos="word" start_char="1724">doctor</TOKEN>
<TOKEN end_char="1732" id="token-11-10" morph="none" pos="word" start_char="1731">of</TOKEN>
<TOKEN end_char="1739" id="token-11-11" morph="none" pos="word" start_char="1734">former</TOKEN>
<TOKEN end_char="1745" id="token-11-12" morph="none" pos="word" start_char="1741">Prime</TOKEN>
<TOKEN end_char="1754" id="token-11-13" morph="none" pos="word" start_char="1747">Minister</TOKEN>
<TOKEN end_char="1761" id="token-11-14" morph="none" pos="word" start_char="1756">Silvio</TOKEN>
<TOKEN end_char="1772" id="token-11-15" morph="none" pos="word" start_char="1763">Berlusconi</TOKEN>
<TOKEN end_char="1773" id="token-11-16" morph="none" pos="punct" start_char="1773">,</TOKEN>
<TOKEN end_char="1778" id="token-11-17" morph="none" pos="word" start_char="1775">said</TOKEN>
<TOKEN end_char="1782" id="token-11-18" morph="none" pos="word" start_char="1780">his</TOKEN>
<TOKEN end_char="1791" id="token-11-19" morph="none" pos="word" start_char="1784">comments</TOKEN>
<TOKEN end_char="1796" id="token-11-20" morph="none" pos="word" start_char="1793">were</TOKEN>
<TOKEN end_char="1803" id="token-11-21" morph="none" pos="word" start_char="1798">backed</TOKEN>
<TOKEN end_char="1806" id="token-11-22" morph="none" pos="word" start_char="1805">up</TOKEN>
<TOKEN end_char="1809" id="token-11-23" morph="none" pos="word" start_char="1808">by</TOKEN>
<TOKEN end_char="1811" id="token-11-24" morph="none" pos="word" start_char="1811">a</TOKEN>
<TOKEN end_char="1817" id="token-11-25" morph="none" pos="word" start_char="1813">study</TOKEN>
<TOKEN end_char="1827" id="token-11-26" morph="none" pos="word" start_char="1819">conducted</TOKEN>
<TOKEN end_char="1830" id="token-11-27" morph="none" pos="word" start_char="1829">by</TOKEN>
<TOKEN end_char="1832" id="token-11-28" morph="none" pos="word" start_char="1832">a</TOKEN>
<TOKEN end_char="1839" id="token-11-29" morph="none" pos="word" start_char="1834">fellow</TOKEN>
<TOKEN end_char="1849" id="token-11-30" morph="none" pos="word" start_char="1841">scientist</TOKEN>
<TOKEN end_char="1850" id="token-11-31" morph="none" pos="punct" start_char="1850">,</TOKEN>
<TOKEN end_char="1858" id="token-11-32" morph="none" pos="word" start_char="1852">Massimo</TOKEN>
<TOKEN end_char="1867" id="token-11-33" morph="none" pos="word" start_char="1860">Clementi</TOKEN>
<TOKEN end_char="1868" id="token-11-34" morph="none" pos="punct" start_char="1868">,</TOKEN>
<TOKEN end_char="1874" id="token-11-35" morph="none" pos="word" start_char="1870">which</TOKEN>
<TOKEN end_char="1884" id="token-11-36" morph="none" pos="word" start_char="1876">Zangrillo</TOKEN>
<TOKEN end_char="1889" id="token-11-37" morph="none" pos="word" start_char="1886">said</TOKEN>
<TOKEN end_char="1895" id="token-11-38" morph="none" pos="word" start_char="1891">would</TOKEN>
<TOKEN end_char="1898" id="token-11-39" morph="none" pos="word" start_char="1897">be</TOKEN>
<TOKEN end_char="1908" id="token-11-40" morph="none" pos="word" start_char="1900">published</TOKEN>
<TOKEN end_char="1913" id="token-11-41" morph="none" pos="word" start_char="1910">next</TOKEN>
<TOKEN end_char="1918" id="token-11-42" morph="none" pos="word" start_char="1915">week</TOKEN>
<TOKEN end_char="1919" id="token-11-43" morph="none" pos="punct" start_char="1919">.</TOKEN>
</SEG>
<SEG end_char="2077" id="segment-12" start_char="1922">
<ORIGINAL_TEXT>Zangrillo told Reuters: "We have never said that the virus has changed, we said that the interaction between the virus and the host has definitely changed."</ORIGINAL_TEXT>
<TOKEN end_char="1930" id="token-12-0" morph="none" pos="word" start_char="1922">Zangrillo</TOKEN>
<TOKEN end_char="1935" id="token-12-1" morph="none" pos="word" start_char="1932">told</TOKEN>
<TOKEN end_char="1943" id="token-12-2" morph="none" pos="word" start_char="1937">Reuters</TOKEN>
<TOKEN end_char="1944" id="token-12-3" morph="none" pos="punct" start_char="1944">:</TOKEN>
<TOKEN end_char="1946" id="token-12-4" morph="none" pos="punct" start_char="1946">"</TOKEN>
<TOKEN end_char="1948" id="token-12-5" morph="none" pos="word" start_char="1947">We</TOKEN>
<TOKEN end_char="1953" id="token-12-6" morph="none" pos="word" start_char="1950">have</TOKEN>
<TOKEN end_char="1959" id="token-12-7" morph="none" pos="word" start_char="1955">never</TOKEN>
<TOKEN end_char="1964" id="token-12-8" morph="none" pos="word" start_char="1961">said</TOKEN>
<TOKEN end_char="1969" id="token-12-9" morph="none" pos="word" start_char="1966">that</TOKEN>
<TOKEN end_char="1973" id="token-12-10" morph="none" pos="word" start_char="1971">the</TOKEN>
<TOKEN end_char="1979" id="token-12-11" morph="none" pos="word" start_char="1975">virus</TOKEN>
<TOKEN end_char="1983" id="token-12-12" morph="none" pos="word" start_char="1981">has</TOKEN>
<TOKEN end_char="1991" id="token-12-13" morph="none" pos="word" start_char="1985">changed</TOKEN>
<TOKEN end_char="1992" id="token-12-14" morph="none" pos="punct" start_char="1992">,</TOKEN>
<TOKEN end_char="1995" id="token-12-15" morph="none" pos="word" start_char="1994">we</TOKEN>
<TOKEN end_char="2000" id="token-12-16" morph="none" pos="word" start_char="1997">said</TOKEN>
<TOKEN end_char="2005" id="token-12-17" morph="none" pos="word" start_char="2002">that</TOKEN>
<TOKEN end_char="2009" id="token-12-18" morph="none" pos="word" start_char="2007">the</TOKEN>
<TOKEN end_char="2021" id="token-12-19" morph="none" pos="word" start_char="2011">interaction</TOKEN>
<TOKEN end_char="2029" id="token-12-20" morph="none" pos="word" start_char="2023">between</TOKEN>
<TOKEN end_char="2033" id="token-12-21" morph="none" pos="word" start_char="2031">the</TOKEN>
<TOKEN end_char="2039" id="token-12-22" morph="none" pos="word" start_char="2035">virus</TOKEN>
<TOKEN end_char="2043" id="token-12-23" morph="none" pos="word" start_char="2041">and</TOKEN>
<TOKEN end_char="2047" id="token-12-24" morph="none" pos="word" start_char="2045">the</TOKEN>
<TOKEN end_char="2052" id="token-12-25" morph="none" pos="word" start_char="2049">host</TOKEN>
<TOKEN end_char="2056" id="token-12-26" morph="none" pos="word" start_char="2054">has</TOKEN>
<TOKEN end_char="2067" id="token-12-27" morph="none" pos="word" start_char="2058">definitely</TOKEN>
<TOKEN end_char="2075" id="token-12-28" morph="none" pos="word" start_char="2069">changed</TOKEN>
<TOKEN end_char="2077" id="token-12-29" morph="none" pos="punct" start_char="2076">."</TOKEN>
</SEG>
<SEG end_char="2245" id="segment-13" start_char="2080">
<ORIGINAL_TEXT>He said this could be due either to different characteristics of the virus, which he said they had not yet identified, or different characteristics in those infected.</ORIGINAL_TEXT>
<TOKEN end_char="2081" id="token-13-0" morph="none" pos="word" start_char="2080">He</TOKEN>
<TOKEN end_char="2086" id="token-13-1" morph="none" pos="word" start_char="2083">said</TOKEN>
<TOKEN end_char="2091" id="token-13-2" morph="none" pos="word" start_char="2088">this</TOKEN>
<TOKEN end_char="2097" id="token-13-3" morph="none" pos="word" start_char="2093">could</TOKEN>
<TOKEN end_char="2100" id="token-13-4" morph="none" pos="word" start_char="2099">be</TOKEN>
<TOKEN end_char="2104" id="token-13-5" morph="none" pos="word" start_char="2102">due</TOKEN>
<TOKEN end_char="2111" id="token-13-6" morph="none" pos="word" start_char="2106">either</TOKEN>
<TOKEN end_char="2114" id="token-13-7" morph="none" pos="word" start_char="2113">to</TOKEN>
<TOKEN end_char="2124" id="token-13-8" morph="none" pos="word" start_char="2116">different</TOKEN>
<TOKEN end_char="2140" id="token-13-9" morph="none" pos="word" start_char="2126">characteristics</TOKEN>
<TOKEN end_char="2143" id="token-13-10" morph="none" pos="word" start_char="2142">of</TOKEN>
<TOKEN end_char="2147" id="token-13-11" morph="none" pos="word" start_char="2145">the</TOKEN>
<TOKEN end_char="2153" id="token-13-12" morph="none" pos="word" start_char="2149">virus</TOKEN>
<TOKEN end_char="2154" id="token-13-13" morph="none" pos="punct" start_char="2154">,</TOKEN>
<TOKEN end_char="2160" id="token-13-14" morph="none" pos="word" start_char="2156">which</TOKEN>
<TOKEN end_char="2163" id="token-13-15" morph="none" pos="word" start_char="2162">he</TOKEN>
<TOKEN end_char="2168" id="token-13-16" morph="none" pos="word" start_char="2165">said</TOKEN>
<TOKEN end_char="2173" id="token-13-17" morph="none" pos="word" start_char="2170">they</TOKEN>
<TOKEN end_char="2177" id="token-13-18" morph="none" pos="word" start_char="2175">had</TOKEN>
<TOKEN end_char="2181" id="token-13-19" morph="none" pos="word" start_char="2179">not</TOKEN>
<TOKEN end_char="2185" id="token-13-20" morph="none" pos="word" start_char="2183">yet</TOKEN>
<TOKEN end_char="2196" id="token-13-21" morph="none" pos="word" start_char="2187">identified</TOKEN>
<TOKEN end_char="2197" id="token-13-22" morph="none" pos="punct" start_char="2197">,</TOKEN>
<TOKEN end_char="2200" id="token-13-23" morph="none" pos="word" start_char="2199">or</TOKEN>
<TOKEN end_char="2210" id="token-13-24" morph="none" pos="word" start_char="2202">different</TOKEN>
<TOKEN end_char="2226" id="token-13-25" morph="none" pos="word" start_char="2212">characteristics</TOKEN>
<TOKEN end_char="2229" id="token-13-26" morph="none" pos="word" start_char="2228">in</TOKEN>
<TOKEN end_char="2235" id="token-13-27" morph="none" pos="word" start_char="2231">those</TOKEN>
<TOKEN end_char="2244" id="token-13-28" morph="none" pos="word" start_char="2237">infected</TOKEN>
<TOKEN end_char="2245" id="token-13-29" morph="none" pos="punct" start_char="2245">.</TOKEN>
</SEG>
<SEG end_char="2481" id="segment-14" start_char="2248">
<ORIGINAL_TEXT>The study by Clementi, who is director of the microbiology and virology laboratory of San Raffaele, compared virus samples from COVID-19 patients at the Milan-based hospital in March with samples from patients with the disease in May.</ORIGINAL_TEXT>
<TOKEN end_char="2250" id="token-14-0" morph="none" pos="word" start_char="2248">The</TOKEN>
<TOKEN end_char="2256" id="token-14-1" morph="none" pos="word" start_char="2252">study</TOKEN>
<TOKEN end_char="2259" id="token-14-2" morph="none" pos="word" start_char="2258">by</TOKEN>
<TOKEN end_char="2268" id="token-14-3" morph="none" pos="word" start_char="2261">Clementi</TOKEN>
<TOKEN end_char="2269" id="token-14-4" morph="none" pos="punct" start_char="2269">,</TOKEN>
<TOKEN end_char="2273" id="token-14-5" morph="none" pos="word" start_char="2271">who</TOKEN>
<TOKEN end_char="2276" id="token-14-6" morph="none" pos="word" start_char="2275">is</TOKEN>
<TOKEN end_char="2285" id="token-14-7" morph="none" pos="word" start_char="2278">director</TOKEN>
<TOKEN end_char="2288" id="token-14-8" morph="none" pos="word" start_char="2287">of</TOKEN>
<TOKEN end_char="2292" id="token-14-9" morph="none" pos="word" start_char="2290">the</TOKEN>
<TOKEN end_char="2305" id="token-14-10" morph="none" pos="word" start_char="2294">microbiology</TOKEN>
<TOKEN end_char="2309" id="token-14-11" morph="none" pos="word" start_char="2307">and</TOKEN>
<TOKEN end_char="2318" id="token-14-12" morph="none" pos="word" start_char="2311">virology</TOKEN>
<TOKEN end_char="2329" id="token-14-13" morph="none" pos="word" start_char="2320">laboratory</TOKEN>
<TOKEN end_char="2332" id="token-14-14" morph="none" pos="word" start_char="2331">of</TOKEN>
<TOKEN end_char="2336" id="token-14-15" morph="none" pos="word" start_char="2334">San</TOKEN>
<TOKEN end_char="2345" id="token-14-16" morph="none" pos="word" start_char="2338">Raffaele</TOKEN>
<TOKEN end_char="2346" id="token-14-17" morph="none" pos="punct" start_char="2346">,</TOKEN>
<TOKEN end_char="2355" id="token-14-18" morph="none" pos="word" start_char="2348">compared</TOKEN>
<TOKEN end_char="2361" id="token-14-19" morph="none" pos="word" start_char="2357">virus</TOKEN>
<TOKEN end_char="2369" id="token-14-20" morph="none" pos="word" start_char="2363">samples</TOKEN>
<TOKEN end_char="2374" id="token-14-21" morph="none" pos="word" start_char="2371">from</TOKEN>
<TOKEN end_char="2383" id="token-14-22" morph="none" pos="unknown" start_char="2376">COVID-19</TOKEN>
<TOKEN end_char="2392" id="token-14-23" morph="none" pos="word" start_char="2385">patients</TOKEN>
<TOKEN end_char="2395" id="token-14-24" morph="none" pos="word" start_char="2394">at</TOKEN>
<TOKEN end_char="2399" id="token-14-25" morph="none" pos="word" start_char="2397">the</TOKEN>
<TOKEN end_char="2411" id="token-14-26" morph="none" pos="unknown" start_char="2401">Milan-based</TOKEN>
<TOKEN end_char="2420" id="token-14-27" morph="none" pos="word" start_char="2413">hospital</TOKEN>
<TOKEN end_char="2423" id="token-14-28" morph="none" pos="word" start_char="2422">in</TOKEN>
<TOKEN end_char="2429" id="token-14-29" morph="none" pos="word" start_char="2425">March</TOKEN>
<TOKEN end_char="2434" id="token-14-30" morph="none" pos="word" start_char="2431">with</TOKEN>
<TOKEN end_char="2442" id="token-14-31" morph="none" pos="word" start_char="2436">samples</TOKEN>
<TOKEN end_char="2447" id="token-14-32" morph="none" pos="word" start_char="2444">from</TOKEN>
<TOKEN end_char="2456" id="token-14-33" morph="none" pos="word" start_char="2449">patients</TOKEN>
<TOKEN end_char="2461" id="token-14-34" morph="none" pos="word" start_char="2458">with</TOKEN>
<TOKEN end_char="2465" id="token-14-35" morph="none" pos="word" start_char="2463">the</TOKEN>
<TOKEN end_char="2473" id="token-14-36" morph="none" pos="word" start_char="2467">disease</TOKEN>
<TOKEN end_char="2476" id="token-14-37" morph="none" pos="word" start_char="2475">in</TOKEN>
<TOKEN end_char="2480" id="token-14-38" morph="none" pos="word" start_char="2478">May</TOKEN>
<TOKEN end_char="2481" id="token-14-39" morph="none" pos="punct" start_char="2481">.</TOKEN>
</SEG>
<SEG end_char="2656" id="segment-15" start_char="2484">
<ORIGINAL_TEXT>"The result was unambiguous: an extremely significant difference between the viral load of patients admitted in March compared to" those admitted last month, Zangrillo said.</ORIGINAL_TEXT>
<TOKEN end_char="2484" id="token-15-0" morph="none" pos="punct" start_char="2484">"</TOKEN>
<TOKEN end_char="2487" id="token-15-1" morph="none" pos="word" start_char="2485">The</TOKEN>
<TOKEN end_char="2494" id="token-15-2" morph="none" pos="word" start_char="2489">result</TOKEN>
<TOKEN end_char="2498" id="token-15-3" morph="none" pos="word" start_char="2496">was</TOKEN>
<TOKEN end_char="2510" id="token-15-4" morph="none" pos="word" start_char="2500">unambiguous</TOKEN>
<TOKEN end_char="2511" id="token-15-5" morph="none" pos="punct" start_char="2511">:</TOKEN>
<TOKEN end_char="2514" id="token-15-6" morph="none" pos="word" start_char="2513">an</TOKEN>
<TOKEN end_char="2524" id="token-15-7" morph="none" pos="word" start_char="2516">extremely</TOKEN>
<TOKEN end_char="2536" id="token-15-8" morph="none" pos="word" start_char="2526">significant</TOKEN>
<TOKEN end_char="2547" id="token-15-9" morph="none" pos="word" start_char="2538">difference</TOKEN>
<TOKEN end_char="2555" id="token-15-10" morph="none" pos="word" start_char="2549">between</TOKEN>
<TOKEN end_char="2559" id="token-15-11" morph="none" pos="word" start_char="2557">the</TOKEN>
<TOKEN end_char="2565" id="token-15-12" morph="none" pos="word" start_char="2561">viral</TOKEN>
<TOKEN end_char="2570" id="token-15-13" morph="none" pos="word" start_char="2567">load</TOKEN>
<TOKEN end_char="2573" id="token-15-14" morph="none" pos="word" start_char="2572">of</TOKEN>
<TOKEN end_char="2582" id="token-15-15" morph="none" pos="word" start_char="2575">patients</TOKEN>
<TOKEN end_char="2591" id="token-15-16" morph="none" pos="word" start_char="2584">admitted</TOKEN>
<TOKEN end_char="2594" id="token-15-17" morph="none" pos="word" start_char="2593">in</TOKEN>
<TOKEN end_char="2600" id="token-15-18" morph="none" pos="word" start_char="2596">March</TOKEN>
<TOKEN end_char="2609" id="token-15-19" morph="none" pos="word" start_char="2602">compared</TOKEN>
<TOKEN end_char="2612" id="token-15-20" morph="none" pos="word" start_char="2611">to</TOKEN>
<TOKEN end_char="2613" id="token-15-21" morph="none" pos="punct" start_char="2613">"</TOKEN>
<TOKEN end_char="2619" id="token-15-22" morph="none" pos="word" start_char="2615">those</TOKEN>
<TOKEN end_char="2628" id="token-15-23" morph="none" pos="word" start_char="2621">admitted</TOKEN>
<TOKEN end_char="2633" id="token-15-24" morph="none" pos="word" start_char="2630">last</TOKEN>
<TOKEN end_char="2639" id="token-15-25" morph="none" pos="word" start_char="2635">month</TOKEN>
<TOKEN end_char="2640" id="token-15-26" morph="none" pos="punct" start_char="2640">,</TOKEN>
<TOKEN end_char="2650" id="token-15-27" morph="none" pos="word" start_char="2642">Zangrillo</TOKEN>
<TOKEN end_char="2655" id="token-15-28" morph="none" pos="word" start_char="2652">said</TOKEN>
<TOKEN end_char="2656" id="token-15-29" morph="none" pos="punct" start_char="2656">.</TOKEN>
</SEG>
<SEG end_char="2889" id="segment-16" start_char="2659">
<ORIGINAL_TEXT>Oscar MacLean of the University of Glasgow’s Centre for Virus Research said suggestions that the virus was weakening were "not supported by anything in the scientific literature and also seem fairly implausible on genetic grounds."</ORIGINAL_TEXT>
<TOKEN end_char="2663" id="token-16-0" morph="none" pos="word" start_char="2659">Oscar</TOKEN>
<TOKEN end_char="2671" id="token-16-1" morph="none" pos="word" start_char="2665">MacLean</TOKEN>
<TOKEN end_char="2674" id="token-16-2" morph="none" pos="word" start_char="2673">of</TOKEN>
<TOKEN end_char="2678" id="token-16-3" morph="none" pos="word" start_char="2676">the</TOKEN>
<TOKEN end_char="2689" id="token-16-4" morph="none" pos="word" start_char="2680">University</TOKEN>
<TOKEN end_char="2692" id="token-16-5" morph="none" pos="word" start_char="2691">of</TOKEN>
<TOKEN end_char="2702" id="token-16-6" morph="none" pos="word" start_char="2694">Glasgow’s</TOKEN>
<TOKEN end_char="2709" id="token-16-7" morph="none" pos="word" start_char="2704">Centre</TOKEN>
<TOKEN end_char="2713" id="token-16-8" morph="none" pos="word" start_char="2711">for</TOKEN>
<TOKEN end_char="2719" id="token-16-9" morph="none" pos="word" start_char="2715">Virus</TOKEN>
<TOKEN end_char="2728" id="token-16-10" morph="none" pos="word" start_char="2721">Research</TOKEN>
<TOKEN end_char="2733" id="token-16-11" morph="none" pos="word" start_char="2730">said</TOKEN>
<TOKEN end_char="2745" id="token-16-12" morph="none" pos="word" start_char="2735">suggestions</TOKEN>
<TOKEN end_char="2750" id="token-16-13" morph="none" pos="word" start_char="2747">that</TOKEN>
<TOKEN end_char="2754" id="token-16-14" morph="none" pos="word" start_char="2752">the</TOKEN>
<TOKEN end_char="2760" id="token-16-15" morph="none" pos="word" start_char="2756">virus</TOKEN>
<TOKEN end_char="2764" id="token-16-16" morph="none" pos="word" start_char="2762">was</TOKEN>
<TOKEN end_char="2774" id="token-16-17" morph="none" pos="word" start_char="2766">weakening</TOKEN>
<TOKEN end_char="2779" id="token-16-18" morph="none" pos="word" start_char="2776">were</TOKEN>
<TOKEN end_char="2781" id="token-16-19" morph="none" pos="punct" start_char="2781">"</TOKEN>
<TOKEN end_char="2784" id="token-16-20" morph="none" pos="word" start_char="2782">not</TOKEN>
<TOKEN end_char="2794" id="token-16-21" morph="none" pos="word" start_char="2786">supported</TOKEN>
<TOKEN end_char="2797" id="token-16-22" morph="none" pos="word" start_char="2796">by</TOKEN>
<TOKEN end_char="2806" id="token-16-23" morph="none" pos="word" start_char="2799">anything</TOKEN>
<TOKEN end_char="2809" id="token-16-24" morph="none" pos="word" start_char="2808">in</TOKEN>
<TOKEN end_char="2813" id="token-16-25" morph="none" pos="word" start_char="2811">the</TOKEN>
<TOKEN end_char="2824" id="token-16-26" morph="none" pos="word" start_char="2815">scientific</TOKEN>
<TOKEN end_char="2835" id="token-16-27" morph="none" pos="word" start_char="2826">literature</TOKEN>
<TOKEN end_char="2839" id="token-16-28" morph="none" pos="word" start_char="2837">and</TOKEN>
<TOKEN end_char="2844" id="token-16-29" morph="none" pos="word" start_char="2841">also</TOKEN>
<TOKEN end_char="2849" id="token-16-30" morph="none" pos="word" start_char="2846">seem</TOKEN>
<TOKEN end_char="2856" id="token-16-31" morph="none" pos="word" start_char="2851">fairly</TOKEN>
<TOKEN end_char="2868" id="token-16-32" morph="none" pos="word" start_char="2858">implausible</TOKEN>
<TOKEN end_char="2871" id="token-16-33" morph="none" pos="word" start_char="2870">on</TOKEN>
<TOKEN end_char="2879" id="token-16-34" morph="none" pos="word" start_char="2873">genetic</TOKEN>
<TOKEN end_char="2887" id="token-16-35" morph="none" pos="word" start_char="2881">grounds</TOKEN>
<TOKEN end_char="2889" id="token-16-36" morph="none" pos="punct" start_char="2888">."</TOKEN>
</SEG>
<SEG end_char="3114" id="segment-17" start_char="2892">
<ORIGINAL_TEXT>Experts and representatives of Johns Hopkins University, Wake Forest Baptist Medical Center, George Washington University and Northwell Health also said they were not aware of evidence suggesting that the virus had changed.</ORIGINAL_TEXT>
<TOKEN end_char="2898" id="token-17-0" morph="none" pos="word" start_char="2892">Experts</TOKEN>
<TOKEN end_char="2902" id="token-17-1" morph="none" pos="word" start_char="2900">and</TOKEN>
<TOKEN end_char="2918" id="token-17-2" morph="none" pos="word" start_char="2904">representatives</TOKEN>
<TOKEN end_char="2921" id="token-17-3" morph="none" pos="word" start_char="2920">of</TOKEN>
<TOKEN end_char="2927" id="token-17-4" morph="none" pos="word" start_char="2923">Johns</TOKEN>
<TOKEN end_char="2935" id="token-17-5" morph="none" pos="word" start_char="2929">Hopkins</TOKEN>
<TOKEN end_char="2946" id="token-17-6" morph="none" pos="word" start_char="2937">University</TOKEN>
<TOKEN end_char="2947" id="token-17-7" morph="none" pos="punct" start_char="2947">,</TOKEN>
<TOKEN end_char="2952" id="token-17-8" morph="none" pos="word" start_char="2949">Wake</TOKEN>
<TOKEN end_char="2959" id="token-17-9" morph="none" pos="word" start_char="2954">Forest</TOKEN>
<TOKEN end_char="2967" id="token-17-10" morph="none" pos="word" start_char="2961">Baptist</TOKEN>
<TOKEN end_char="2975" id="token-17-11" morph="none" pos="word" start_char="2969">Medical</TOKEN>
<TOKEN end_char="2982" id="token-17-12" morph="none" pos="word" start_char="2977">Center</TOKEN>
<TOKEN end_char="2983" id="token-17-13" morph="none" pos="punct" start_char="2983">,</TOKEN>
<TOKEN end_char="2990" id="token-17-14" morph="none" pos="word" start_char="2985">George</TOKEN>
<TOKEN end_char="3001" id="token-17-15" morph="none" pos="word" start_char="2992">Washington</TOKEN>
<TOKEN end_char="3012" id="token-17-16" morph="none" pos="word" start_char="3003">University</TOKEN>
<TOKEN end_char="3016" id="token-17-17" morph="none" pos="word" start_char="3014">and</TOKEN>
<TOKEN end_char="3026" id="token-17-18" morph="none" pos="word" start_char="3018">Northwell</TOKEN>
<TOKEN end_char="3033" id="token-17-19" morph="none" pos="word" start_char="3028">Health</TOKEN>
<TOKEN end_char="3038" id="token-17-20" morph="none" pos="word" start_char="3035">also</TOKEN>
<TOKEN end_char="3043" id="token-17-21" morph="none" pos="word" start_char="3040">said</TOKEN>
<TOKEN end_char="3048" id="token-17-22" morph="none" pos="word" start_char="3045">they</TOKEN>
<TOKEN end_char="3053" id="token-17-23" morph="none" pos="word" start_char="3050">were</TOKEN>
<TOKEN end_char="3057" id="token-17-24" morph="none" pos="word" start_char="3055">not</TOKEN>
<TOKEN end_char="3063" id="token-17-25" morph="none" pos="word" start_char="3059">aware</TOKEN>
<TOKEN end_char="3066" id="token-17-26" morph="none" pos="word" start_char="3065">of</TOKEN>
<TOKEN end_char="3075" id="token-17-27" morph="none" pos="word" start_char="3068">evidence</TOKEN>
<TOKEN end_char="3086" id="token-17-28" morph="none" pos="word" start_char="3077">suggesting</TOKEN>
<TOKEN end_char="3091" id="token-17-29" morph="none" pos="word" start_char="3088">that</TOKEN>
<TOKEN end_char="3095" id="token-17-30" morph="none" pos="word" start_char="3093">the</TOKEN>
<TOKEN end_char="3101" id="token-17-31" morph="none" pos="word" start_char="3097">virus</TOKEN>
<TOKEN end_char="3105" id="token-17-32" morph="none" pos="word" start_char="3103">had</TOKEN>
<TOKEN end_char="3113" id="token-17-33" morph="none" pos="word" start_char="3107">changed</TOKEN>
<TOKEN end_char="3114" id="token-17-34" morph="none" pos="punct" start_char="3114">.</TOKEN>
</SEG>
<SEG end_char="3331" id="segment-18" start_char="3117">
<ORIGINAL_TEXT>"The suggestion by the Italian doctor is potentially dangerous as it gives false reassurance based on no evidence," said Leana Wen, an emergency physician and public health professor at George Washington University.</ORIGINAL_TEXT>
<TOKEN end_char="3117" id="token-18-0" morph="none" pos="punct" start_char="3117">"</TOKEN>
<TOKEN end_char="3120" id="token-18-1" morph="none" pos="word" start_char="3118">The</TOKEN>
<TOKEN end_char="3131" id="token-18-2" morph="none" pos="word" start_char="3122">suggestion</TOKEN>
<TOKEN end_char="3134" id="token-18-3" morph="none" pos="word" start_char="3133">by</TOKEN>
<TOKEN end_char="3138" id="token-18-4" morph="none" pos="word" start_char="3136">the</TOKEN>
<TOKEN end_char="3146" id="token-18-5" morph="none" pos="word" start_char="3140">Italian</TOKEN>
<TOKEN end_char="3153" id="token-18-6" morph="none" pos="word" start_char="3148">doctor</TOKEN>
<TOKEN end_char="3156" id="token-18-7" morph="none" pos="word" start_char="3155">is</TOKEN>
<TOKEN end_char="3168" id="token-18-8" morph="none" pos="word" start_char="3158">potentially</TOKEN>
<TOKEN end_char="3178" id="token-18-9" morph="none" pos="word" start_char="3170">dangerous</TOKEN>
<TOKEN end_char="3181" id="token-18-10" morph="none" pos="word" start_char="3180">as</TOKEN>
<TOKEN end_char="3184" id="token-18-11" morph="none" pos="word" start_char="3183">it</TOKEN>
<TOKEN end_char="3190" id="token-18-12" morph="none" pos="word" start_char="3186">gives</TOKEN>
<TOKEN end_char="3196" id="token-18-13" morph="none" pos="word" start_char="3192">false</TOKEN>
<TOKEN end_char="3208" id="token-18-14" morph="none" pos="word" start_char="3198">reassurance</TOKEN>
<TOKEN end_char="3214" id="token-18-15" morph="none" pos="word" start_char="3210">based</TOKEN>
<TOKEN end_char="3217" id="token-18-16" morph="none" pos="word" start_char="3216">on</TOKEN>
<TOKEN end_char="3220" id="token-18-17" morph="none" pos="word" start_char="3219">no</TOKEN>
<TOKEN end_char="3229" id="token-18-18" morph="none" pos="word" start_char="3222">evidence</TOKEN>
<TOKEN end_char="3231" id="token-18-19" morph="none" pos="punct" start_char="3230">,"</TOKEN>
<TOKEN end_char="3236" id="token-18-20" morph="none" pos="word" start_char="3233">said</TOKEN>
<TOKEN end_char="3242" id="token-18-21" morph="none" pos="word" start_char="3238">Leana</TOKEN>
<TOKEN end_char="3246" id="token-18-22" morph="none" pos="word" start_char="3244">Wen</TOKEN>
<TOKEN end_char="3247" id="token-18-23" morph="none" pos="punct" start_char="3247">,</TOKEN>
<TOKEN end_char="3250" id="token-18-24" morph="none" pos="word" start_char="3249">an</TOKEN>
<TOKEN end_char="3260" id="token-18-25" morph="none" pos="word" start_char="3252">emergency</TOKEN>
<TOKEN end_char="3270" id="token-18-26" morph="none" pos="word" start_char="3262">physician</TOKEN>
<TOKEN end_char="3274" id="token-18-27" morph="none" pos="word" start_char="3272">and</TOKEN>
<TOKEN end_char="3281" id="token-18-28" morph="none" pos="word" start_char="3276">public</TOKEN>
<TOKEN end_char="3288" id="token-18-29" morph="none" pos="word" start_char="3283">health</TOKEN>
<TOKEN end_char="3298" id="token-18-30" morph="none" pos="word" start_char="3290">professor</TOKEN>
<TOKEN end_char="3301" id="token-18-31" morph="none" pos="word" start_char="3300">at</TOKEN>
<TOKEN end_char="3308" id="token-18-32" morph="none" pos="word" start_char="3303">George</TOKEN>
<TOKEN end_char="3319" id="token-18-33" morph="none" pos="word" start_char="3310">Washington</TOKEN>
<TOKEN end_char="3330" id="token-18-34" morph="none" pos="word" start_char="3321">University</TOKEN>
<TOKEN end_char="3331" id="token-18-35" morph="none" pos="punct" start_char="3331">.</TOKEN>
</SEG>
<SEG end_char="3415" id="segment-19" start_char="3333">
<ORIGINAL_TEXT>"There is no scientific evidence for there having been a change in the coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="3333" id="token-19-0" morph="none" pos="punct" start_char="3333">"</TOKEN>
<TOKEN end_char="3338" id="token-19-1" morph="none" pos="word" start_char="3334">There</TOKEN>
<TOKEN end_char="3341" id="token-19-2" morph="none" pos="word" start_char="3340">is</TOKEN>
<TOKEN end_char="3344" id="token-19-3" morph="none" pos="word" start_char="3343">no</TOKEN>
<TOKEN end_char="3355" id="token-19-4" morph="none" pos="word" start_char="3346">scientific</TOKEN>
<TOKEN end_char="3364" id="token-19-5" morph="none" pos="word" start_char="3357">evidence</TOKEN>
<TOKEN end_char="3368" id="token-19-6" morph="none" pos="word" start_char="3366">for</TOKEN>
<TOKEN end_char="3374" id="token-19-7" morph="none" pos="word" start_char="3370">there</TOKEN>
<TOKEN end_char="3381" id="token-19-8" morph="none" pos="word" start_char="3376">having</TOKEN>
<TOKEN end_char="3386" id="token-19-9" morph="none" pos="word" start_char="3383">been</TOKEN>
<TOKEN end_char="3388" id="token-19-10" morph="none" pos="word" start_char="3388">a</TOKEN>
<TOKEN end_char="3395" id="token-19-11" morph="none" pos="word" start_char="3390">change</TOKEN>
<TOKEN end_char="3398" id="token-19-12" morph="none" pos="word" start_char="3397">in</TOKEN>
<TOKEN end_char="3402" id="token-19-13" morph="none" pos="word" start_char="3400">the</TOKEN>
<TOKEN end_char="3414" id="token-19-14" morph="none" pos="word" start_char="3404">coronavirus</TOKEN>
<TOKEN end_char="3415" id="token-19-15" morph="none" pos="punct" start_char="3415">.</TOKEN>
</SEG>
<SEG end_char="3474" id="segment-20" start_char="3417">
<ORIGINAL_TEXT>It’s a highly transmittable and highly contagious disease.</ORIGINAL_TEXT>
<TOKEN end_char="3420" id="token-20-0" morph="none" pos="word" start_char="3417">It’s</TOKEN>
<TOKEN end_char="3422" id="token-20-1" morph="none" pos="word" start_char="3422">a</TOKEN>
<TOKEN end_char="3429" id="token-20-2" morph="none" pos="word" start_char="3424">highly</TOKEN>
<TOKEN end_char="3443" id="token-20-3" morph="none" pos="word" start_char="3431">transmittable</TOKEN>
<TOKEN end_char="3447" id="token-20-4" morph="none" pos="word" start_char="3445">and</TOKEN>
<TOKEN end_char="3454" id="token-20-5" morph="none" pos="word" start_char="3449">highly</TOKEN>
<TOKEN end_char="3465" id="token-20-6" morph="none" pos="word" start_char="3456">contagious</TOKEN>
<TOKEN end_char="3473" id="token-20-7" morph="none" pos="word" start_char="3467">disease</TOKEN>
<TOKEN end_char="3474" id="token-20-8" morph="none" pos="punct" start_char="3474">.</TOKEN>
</SEG>
<SEG end_char="3510" id="segment-21" start_char="3476">
<ORIGINAL_TEXT>We need to be as on guard as ever."</ORIGINAL_TEXT>
<TOKEN end_char="3477" id="token-21-0" morph="none" pos="word" start_char="3476">We</TOKEN>
<TOKEN end_char="3482" id="token-21-1" morph="none" pos="word" start_char="3479">need</TOKEN>
<TOKEN end_char="3485" id="token-21-2" morph="none" pos="word" start_char="3484">to</TOKEN>
<TOKEN end_char="3488" id="token-21-3" morph="none" pos="word" start_char="3487">be</TOKEN>
<TOKEN end_char="3491" id="token-21-4" morph="none" pos="word" start_char="3490">as</TOKEN>
<TOKEN end_char="3494" id="token-21-5" morph="none" pos="word" start_char="3493">on</TOKEN>
<TOKEN end_char="3500" id="token-21-6" morph="none" pos="word" start_char="3496">guard</TOKEN>
<TOKEN end_char="3503" id="token-21-7" morph="none" pos="word" start_char="3502">as</TOKEN>
<TOKEN end_char="3508" id="token-21-8" morph="none" pos="word" start_char="3505">ever</TOKEN>
<TOKEN end_char="3510" id="token-21-9" morph="none" pos="punct" start_char="3509">."</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
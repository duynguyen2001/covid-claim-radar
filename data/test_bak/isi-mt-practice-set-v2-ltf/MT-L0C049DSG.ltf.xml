<LCTL_TEXT lang="eng">
<DOC grammar="none" id="L0C049DSG" lang="eng" raw_text_char_length="1986" raw_text_md5="1c9e9781bed6be75f4032b15d68080df" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="82" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Giuliani says Dr. Fauci funded Wuhan virology lab in spite of official prohibition</ORIGINAL_TEXT>
<TOKEN end_char="8" id="token-0-0" morph="none" pos="word" start_char="1">Giuliani</TOKEN>
<TOKEN end_char="13" id="token-0-1" morph="none" pos="word" start_char="10">says</TOKEN>
<TOKEN end_char="16" id="token-0-2" morph="none" pos="word" start_char="15">Dr</TOKEN>
<TOKEN end_char="17" id="token-0-3" morph="none" pos="punct" start_char="17">.</TOKEN>
<TOKEN end_char="23" id="token-0-4" morph="none" pos="word" start_char="19">Fauci</TOKEN>
<TOKEN end_char="30" id="token-0-5" morph="none" pos="word" start_char="25">funded</TOKEN>
<TOKEN end_char="36" id="token-0-6" morph="none" pos="word" start_char="32">Wuhan</TOKEN>
<TOKEN end_char="45" id="token-0-7" morph="none" pos="word" start_char="38">virology</TOKEN>
<TOKEN end_char="49" id="token-0-8" morph="none" pos="word" start_char="47">lab</TOKEN>
<TOKEN end_char="52" id="token-0-9" morph="none" pos="word" start_char="51">in</TOKEN>
<TOKEN end_char="58" id="token-0-10" morph="none" pos="word" start_char="54">spite</TOKEN>
<TOKEN end_char="61" id="token-0-11" morph="none" pos="word" start_char="60">of</TOKEN>
<TOKEN end_char="70" id="token-0-12" morph="none" pos="word" start_char="63">official</TOKEN>
<TOKEN end_char="82" id="token-0-13" morph="none" pos="word" start_char="72">prohibition</TOKEN>
</SEG>
<SEG end_char="192" id="segment-1" start_char="86">
<ORIGINAL_TEXT>Donald Trump’s personal lawyer, Rudy Giuliani, revealed that he believes White House coronavirus expert Dr.</ORIGINAL_TEXT>
<TOKEN end_char="91" id="token-1-0" morph="none" pos="word" start_char="86">Donald</TOKEN>
<TOKEN end_char="99" id="token-1-1" morph="none" pos="word" start_char="93">Trump’s</TOKEN>
<TOKEN end_char="108" id="token-1-2" morph="none" pos="word" start_char="101">personal</TOKEN>
<TOKEN end_char="115" id="token-1-3" morph="none" pos="word" start_char="110">lawyer</TOKEN>
<TOKEN end_char="116" id="token-1-4" morph="none" pos="punct" start_char="116">,</TOKEN>
<TOKEN end_char="121" id="token-1-5" morph="none" pos="word" start_char="118">Rudy</TOKEN>
<TOKEN end_char="130" id="token-1-6" morph="none" pos="word" start_char="123">Giuliani</TOKEN>
<TOKEN end_char="131" id="token-1-7" morph="none" pos="punct" start_char="131">,</TOKEN>
<TOKEN end_char="140" id="token-1-8" morph="none" pos="word" start_char="133">revealed</TOKEN>
<TOKEN end_char="145" id="token-1-9" morph="none" pos="word" start_char="142">that</TOKEN>
<TOKEN end_char="148" id="token-1-10" morph="none" pos="word" start_char="147">he</TOKEN>
<TOKEN end_char="157" id="token-1-11" morph="none" pos="word" start_char="150">believes</TOKEN>
<TOKEN end_char="163" id="token-1-12" morph="none" pos="word" start_char="159">White</TOKEN>
<TOKEN end_char="169" id="token-1-13" morph="none" pos="word" start_char="165">House</TOKEN>
<TOKEN end_char="181" id="token-1-14" morph="none" pos="word" start_char="171">coronavirus</TOKEN>
<TOKEN end_char="188" id="token-1-15" morph="none" pos="word" start_char="183">expert</TOKEN>
<TOKEN end_char="191" id="token-1-16" morph="none" pos="word" start_char="190">Dr</TOKEN>
<TOKEN end_char="192" id="token-1-17" morph="none" pos="punct" start_char="192">.</TOKEN>
</SEG>
<SEG end_char="263" id="segment-2" start_char="194">
<ORIGINAL_TEXT>Anthony Fauci knew more about the Wuhan virology lab he is letting on.</ORIGINAL_TEXT>
<TOKEN end_char="200" id="token-2-0" morph="none" pos="word" start_char="194">Anthony</TOKEN>
<TOKEN end_char="206" id="token-2-1" morph="none" pos="word" start_char="202">Fauci</TOKEN>
<TOKEN end_char="211" id="token-2-2" morph="none" pos="word" start_char="208">knew</TOKEN>
<TOKEN end_char="216" id="token-2-3" morph="none" pos="word" start_char="213">more</TOKEN>
<TOKEN end_char="222" id="token-2-4" morph="none" pos="word" start_char="218">about</TOKEN>
<TOKEN end_char="226" id="token-2-5" morph="none" pos="word" start_char="224">the</TOKEN>
<TOKEN end_char="232" id="token-2-6" morph="none" pos="word" start_char="228">Wuhan</TOKEN>
<TOKEN end_char="241" id="token-2-7" morph="none" pos="word" start_char="234">virology</TOKEN>
<TOKEN end_char="245" id="token-2-8" morph="none" pos="word" start_char="243">lab</TOKEN>
<TOKEN end_char="248" id="token-2-9" morph="none" pos="word" start_char="247">he</TOKEN>
<TOKEN end_char="251" id="token-2-10" morph="none" pos="word" start_char="250">is</TOKEN>
<TOKEN end_char="259" id="token-2-11" morph="none" pos="word" start_char="253">letting</TOKEN>
<TOKEN end_char="262" id="token-2-12" morph="none" pos="word" start_char="261">on</TOKEN>
<TOKEN end_char="263" id="token-2-13" morph="none" pos="punct" start_char="263">.</TOKEN>
</SEG>
<SEG end_char="314" id="segment-3" start_char="266">
<ORIGINAL_TEXT>Giuliani explained during a Sunday interview with</ORIGINAL_TEXT>
<TOKEN end_char="273" id="token-3-0" morph="none" pos="word" start_char="266">Giuliani</TOKEN>
<TOKEN end_char="283" id="token-3-1" morph="none" pos="word" start_char="275">explained</TOKEN>
<TOKEN end_char="290" id="token-3-2" morph="none" pos="word" start_char="285">during</TOKEN>
<TOKEN end_char="292" id="token-3-3" morph="none" pos="word" start_char="292">a</TOKEN>
<TOKEN end_char="299" id="token-3-4" morph="none" pos="word" start_char="294">Sunday</TOKEN>
<TOKEN end_char="309" id="token-3-5" morph="none" pos="word" start_char="301">interview</TOKEN>
<TOKEN end_char="314" id="token-3-6" morph="none" pos="word" start_char="311">with</TOKEN>
</SEG>
<SEG end_char="335" id="segment-4" start_char="317">
<ORIGINAL_TEXT>The Cats Roundtable</ORIGINAL_TEXT>
<TOKEN end_char="319" id="token-4-0" morph="none" pos="word" start_char="317">The</TOKEN>
<TOKEN end_char="324" id="token-4-1" morph="none" pos="word" start_char="321">Cats</TOKEN>
<TOKEN end_char="335" id="token-4-2" morph="none" pos="word" start_char="326">Roundtable</TOKEN>
</SEG>
<SEG end_char="462" id="segment-5" start_char="338">
<ORIGINAL_TEXT>that in 2014, the Obama administration had "prohibited" the allocation of federal funds to all virology labs, even in the US.</ORIGINAL_TEXT>
<TOKEN end_char="341" id="token-5-0" morph="none" pos="word" start_char="338">that</TOKEN>
<TOKEN end_char="344" id="token-5-1" morph="none" pos="word" start_char="343">in</TOKEN>
<TOKEN end_char="349" id="token-5-2" morph="none" pos="word" start_char="346">2014</TOKEN>
<TOKEN end_char="350" id="token-5-3" morph="none" pos="punct" start_char="350">,</TOKEN>
<TOKEN end_char="354" id="token-5-4" morph="none" pos="word" start_char="352">the</TOKEN>
<TOKEN end_char="360" id="token-5-5" morph="none" pos="word" start_char="356">Obama</TOKEN>
<TOKEN end_char="375" id="token-5-6" morph="none" pos="word" start_char="362">administration</TOKEN>
<TOKEN end_char="379" id="token-5-7" morph="none" pos="word" start_char="377">had</TOKEN>
<TOKEN end_char="381" id="token-5-8" morph="none" pos="punct" start_char="381">"</TOKEN>
<TOKEN end_char="391" id="token-5-9" morph="none" pos="word" start_char="382">prohibited</TOKEN>
<TOKEN end_char="392" id="token-5-10" morph="none" pos="punct" start_char="392">"</TOKEN>
<TOKEN end_char="396" id="token-5-11" morph="none" pos="word" start_char="394">the</TOKEN>
<TOKEN end_char="407" id="token-5-12" morph="none" pos="word" start_char="398">allocation</TOKEN>
<TOKEN end_char="410" id="token-5-13" morph="none" pos="word" start_char="409">of</TOKEN>
<TOKEN end_char="418" id="token-5-14" morph="none" pos="word" start_char="412">federal</TOKEN>
<TOKEN end_char="424" id="token-5-15" morph="none" pos="word" start_char="420">funds</TOKEN>
<TOKEN end_char="427" id="token-5-16" morph="none" pos="word" start_char="426">to</TOKEN>
<TOKEN end_char="431" id="token-5-17" morph="none" pos="word" start_char="429">all</TOKEN>
<TOKEN end_char="440" id="token-5-18" morph="none" pos="word" start_char="433">virology</TOKEN>
<TOKEN end_char="445" id="token-5-19" morph="none" pos="word" start_char="442">labs</TOKEN>
<TOKEN end_char="446" id="token-5-20" morph="none" pos="punct" start_char="446">,</TOKEN>
<TOKEN end_char="451" id="token-5-21" morph="none" pos="word" start_char="448">even</TOKEN>
<TOKEN end_char="454" id="token-5-22" morph="none" pos="word" start_char="453">in</TOKEN>
<TOKEN end_char="458" id="token-5-23" morph="none" pos="word" start_char="456">the</TOKEN>
<TOKEN end_char="461" id="token-5-24" morph="none" pos="word" start_char="460">US</TOKEN>
<TOKEN end_char="462" id="token-5-25" morph="none" pos="punct" start_char="462">.</TOKEN>
</SEG>
<SEG end_char="550" id="segment-6" start_char="465">
<ORIGINAL_TEXT>"Despite that, Dr. Fauci gave $3.7 million to the Wuhan laboratory," Giuliani claimed.</ORIGINAL_TEXT>
<TOKEN end_char="465" id="token-6-0" morph="none" pos="punct" start_char="465">"</TOKEN>
<TOKEN end_char="472" id="token-6-1" morph="none" pos="word" start_char="466">Despite</TOKEN>
<TOKEN end_char="477" id="token-6-2" morph="none" pos="word" start_char="474">that</TOKEN>
<TOKEN end_char="478" id="token-6-3" morph="none" pos="punct" start_char="478">,</TOKEN>
<TOKEN end_char="481" id="token-6-4" morph="none" pos="word" start_char="480">Dr</TOKEN>
<TOKEN end_char="482" id="token-6-5" morph="none" pos="punct" start_char="482">.</TOKEN>
<TOKEN end_char="488" id="token-6-6" morph="none" pos="word" start_char="484">Fauci</TOKEN>
<TOKEN end_char="493" id="token-6-7" morph="none" pos="word" start_char="490">gave</TOKEN>
<TOKEN end_char="498" id="token-6-8" morph="none" pos="unknown" start_char="495">$3.7</TOKEN>
<TOKEN end_char="506" id="token-6-9" morph="none" pos="word" start_char="500">million</TOKEN>
<TOKEN end_char="509" id="token-6-10" morph="none" pos="word" start_char="508">to</TOKEN>
<TOKEN end_char="513" id="token-6-11" morph="none" pos="word" start_char="511">the</TOKEN>
<TOKEN end_char="519" id="token-6-12" morph="none" pos="word" start_char="515">Wuhan</TOKEN>
<TOKEN end_char="530" id="token-6-13" morph="none" pos="word" start_char="521">laboratory</TOKEN>
<TOKEN end_char="532" id="token-6-14" morph="none" pos="punct" start_char="531">,"</TOKEN>
<TOKEN end_char="541" id="token-6-15" morph="none" pos="word" start_char="534">Giuliani</TOKEN>
<TOKEN end_char="549" id="token-6-16" morph="none" pos="word" start_char="543">claimed</TOKEN>
<TOKEN end_char="550" id="token-6-17" morph="none" pos="punct" start_char="550">.</TOKEN>
</SEG>
<SEG end_char="780" id="segment-7" start_char="552">
<ORIGINAL_TEXT>"And then even after the State Department issued reports about how unsafe that laboratory was, and how suspicious they were in the way they were developing a virus that could be transmitted to humans, we never pulled that money."</ORIGINAL_TEXT>
<TOKEN end_char="552" id="token-7-0" morph="none" pos="punct" start_char="552">"</TOKEN>
<TOKEN end_char="555" id="token-7-1" morph="none" pos="word" start_char="553">And</TOKEN>
<TOKEN end_char="560" id="token-7-2" morph="none" pos="word" start_char="557">then</TOKEN>
<TOKEN end_char="565" id="token-7-3" morph="none" pos="word" start_char="562">even</TOKEN>
<TOKEN end_char="571" id="token-7-4" morph="none" pos="word" start_char="567">after</TOKEN>
<TOKEN end_char="575" id="token-7-5" morph="none" pos="word" start_char="573">the</TOKEN>
<TOKEN end_char="581" id="token-7-6" morph="none" pos="word" start_char="577">State</TOKEN>
<TOKEN end_char="592" id="token-7-7" morph="none" pos="word" start_char="583">Department</TOKEN>
<TOKEN end_char="599" id="token-7-8" morph="none" pos="word" start_char="594">issued</TOKEN>
<TOKEN end_char="607" id="token-7-9" morph="none" pos="word" start_char="601">reports</TOKEN>
<TOKEN end_char="613" id="token-7-10" morph="none" pos="word" start_char="609">about</TOKEN>
<TOKEN end_char="617" id="token-7-11" morph="none" pos="word" start_char="615">how</TOKEN>
<TOKEN end_char="624" id="token-7-12" morph="none" pos="word" start_char="619">unsafe</TOKEN>
<TOKEN end_char="629" id="token-7-13" morph="none" pos="word" start_char="626">that</TOKEN>
<TOKEN end_char="640" id="token-7-14" morph="none" pos="word" start_char="631">laboratory</TOKEN>
<TOKEN end_char="644" id="token-7-15" morph="none" pos="word" start_char="642">was</TOKEN>
<TOKEN end_char="645" id="token-7-16" morph="none" pos="punct" start_char="645">,</TOKEN>
<TOKEN end_char="649" id="token-7-17" morph="none" pos="word" start_char="647">and</TOKEN>
<TOKEN end_char="653" id="token-7-18" morph="none" pos="word" start_char="651">how</TOKEN>
<TOKEN end_char="664" id="token-7-19" morph="none" pos="word" start_char="655">suspicious</TOKEN>
<TOKEN end_char="669" id="token-7-20" morph="none" pos="word" start_char="666">they</TOKEN>
<TOKEN end_char="674" id="token-7-21" morph="none" pos="word" start_char="671">were</TOKEN>
<TOKEN end_char="677" id="token-7-22" morph="none" pos="word" start_char="676">in</TOKEN>
<TOKEN end_char="681" id="token-7-23" morph="none" pos="word" start_char="679">the</TOKEN>
<TOKEN end_char="685" id="token-7-24" morph="none" pos="word" start_char="683">way</TOKEN>
<TOKEN end_char="690" id="token-7-25" morph="none" pos="word" start_char="687">they</TOKEN>
<TOKEN end_char="695" id="token-7-26" morph="none" pos="word" start_char="692">were</TOKEN>
<TOKEN end_char="706" id="token-7-27" morph="none" pos="word" start_char="697">developing</TOKEN>
<TOKEN end_char="708" id="token-7-28" morph="none" pos="word" start_char="708">a</TOKEN>
<TOKEN end_char="714" id="token-7-29" morph="none" pos="word" start_char="710">virus</TOKEN>
<TOKEN end_char="719" id="token-7-30" morph="none" pos="word" start_char="716">that</TOKEN>
<TOKEN end_char="725" id="token-7-31" morph="none" pos="word" start_char="721">could</TOKEN>
<TOKEN end_char="728" id="token-7-32" morph="none" pos="word" start_char="727">be</TOKEN>
<TOKEN end_char="740" id="token-7-33" morph="none" pos="word" start_char="730">transmitted</TOKEN>
<TOKEN end_char="743" id="token-7-34" morph="none" pos="word" start_char="742">to</TOKEN>
<TOKEN end_char="750" id="token-7-35" morph="none" pos="word" start_char="745">humans</TOKEN>
<TOKEN end_char="751" id="token-7-36" morph="none" pos="punct" start_char="751">,</TOKEN>
<TOKEN end_char="754" id="token-7-37" morph="none" pos="word" start_char="753">we</TOKEN>
<TOKEN end_char="760" id="token-7-38" morph="none" pos="word" start_char="756">never</TOKEN>
<TOKEN end_char="767" id="token-7-39" morph="none" pos="word" start_char="762">pulled</TOKEN>
<TOKEN end_char="772" id="token-7-40" morph="none" pos="word" start_char="769">that</TOKEN>
<TOKEN end_char="778" id="token-7-41" morph="none" pos="word" start_char="774">money</TOKEN>
<TOKEN end_char="780" id="token-7-42" morph="none" pos="punct" start_char="779">."</TOKEN>
</SEG>
<SEG end_char="935" id="segment-8" start_char="784">
<ORIGINAL_TEXT>The Daily Mail reported that the National Institutes for Health, which is headed up by Dr. Fauci, awarded a $3.7 million grant to the Wuhan lab in 2015.</ORIGINAL_TEXT>
<TOKEN end_char="786" id="token-8-0" morph="none" pos="word" start_char="784">The</TOKEN>
<TOKEN end_char="792" id="token-8-1" morph="none" pos="word" start_char="788">Daily</TOKEN>
<TOKEN end_char="797" id="token-8-2" morph="none" pos="word" start_char="794">Mail</TOKEN>
<TOKEN end_char="806" id="token-8-3" morph="none" pos="word" start_char="799">reported</TOKEN>
<TOKEN end_char="811" id="token-8-4" morph="none" pos="word" start_char="808">that</TOKEN>
<TOKEN end_char="815" id="token-8-5" morph="none" pos="word" start_char="813">the</TOKEN>
<TOKEN end_char="824" id="token-8-6" morph="none" pos="word" start_char="817">National</TOKEN>
<TOKEN end_char="835" id="token-8-7" morph="none" pos="word" start_char="826">Institutes</TOKEN>
<TOKEN end_char="839" id="token-8-8" morph="none" pos="word" start_char="837">for</TOKEN>
<TOKEN end_char="846" id="token-8-9" morph="none" pos="word" start_char="841">Health</TOKEN>
<TOKEN end_char="847" id="token-8-10" morph="none" pos="punct" start_char="847">,</TOKEN>
<TOKEN end_char="853" id="token-8-11" morph="none" pos="word" start_char="849">which</TOKEN>
<TOKEN end_char="856" id="token-8-12" morph="none" pos="word" start_char="855">is</TOKEN>
<TOKEN end_char="863" id="token-8-13" morph="none" pos="word" start_char="858">headed</TOKEN>
<TOKEN end_char="866" id="token-8-14" morph="none" pos="word" start_char="865">up</TOKEN>
<TOKEN end_char="869" id="token-8-15" morph="none" pos="word" start_char="868">by</TOKEN>
<TOKEN end_char="872" id="token-8-16" morph="none" pos="word" start_char="871">Dr</TOKEN>
<TOKEN end_char="873" id="token-8-17" morph="none" pos="punct" start_char="873">.</TOKEN>
<TOKEN end_char="879" id="token-8-18" morph="none" pos="word" start_char="875">Fauci</TOKEN>
<TOKEN end_char="880" id="token-8-19" morph="none" pos="punct" start_char="880">,</TOKEN>
<TOKEN end_char="888" id="token-8-20" morph="none" pos="word" start_char="882">awarded</TOKEN>
<TOKEN end_char="890" id="token-8-21" morph="none" pos="word" start_char="890">a</TOKEN>
<TOKEN end_char="895" id="token-8-22" morph="none" pos="unknown" start_char="892">$3.7</TOKEN>
<TOKEN end_char="903" id="token-8-23" morph="none" pos="word" start_char="897">million</TOKEN>
<TOKEN end_char="909" id="token-8-24" morph="none" pos="word" start_char="905">grant</TOKEN>
<TOKEN end_char="912" id="token-8-25" morph="none" pos="word" start_char="911">to</TOKEN>
<TOKEN end_char="916" id="token-8-26" morph="none" pos="word" start_char="914">the</TOKEN>
<TOKEN end_char="922" id="token-8-27" morph="none" pos="word" start_char="918">Wuhan</TOKEN>
<TOKEN end_char="926" id="token-8-28" morph="none" pos="word" start_char="924">lab</TOKEN>
<TOKEN end_char="929" id="token-8-29" morph="none" pos="word" start_char="928">in</TOKEN>
<TOKEN end_char="934" id="token-8-30" morph="none" pos="word" start_char="931">2015</TOKEN>
<TOKEN end_char="935" id="token-8-31" morph="none" pos="punct" start_char="935">.</TOKEN>
</SEG>
<SEG end_char="975" id="segment-9" start_char="938">
<ORIGINAL_TEXT>"So, something here is going on, John.</ORIGINAL_TEXT>
<TOKEN end_char="938" id="token-9-0" morph="none" pos="punct" start_char="938">"</TOKEN>
<TOKEN end_char="940" id="token-9-1" morph="none" pos="word" start_char="939">So</TOKEN>
<TOKEN end_char="941" id="token-9-2" morph="none" pos="punct" start_char="941">,</TOKEN>
<TOKEN end_char="951" id="token-9-3" morph="none" pos="word" start_char="943">something</TOKEN>
<TOKEN end_char="956" id="token-9-4" morph="none" pos="word" start_char="953">here</TOKEN>
<TOKEN end_char="959" id="token-9-5" morph="none" pos="word" start_char="958">is</TOKEN>
<TOKEN end_char="965" id="token-9-6" morph="none" pos="word" start_char="961">going</TOKEN>
<TOKEN end_char="968" id="token-9-7" morph="none" pos="word" start_char="967">on</TOKEN>
<TOKEN end_char="969" id="token-9-8" morph="none" pos="punct" start_char="969">,</TOKEN>
<TOKEN end_char="974" id="token-9-9" morph="none" pos="word" start_char="971">John</TOKEN>
<TOKEN end_char="975" id="token-9-10" morph="none" pos="punct" start_char="975">.</TOKEN>
</SEG>
<SEG end_char="1042" id="segment-10" start_char="977">
<ORIGINAL_TEXT>I don’t want to make any accusations," the former NYC mayor added.</ORIGINAL_TEXT>
<TOKEN end_char="977" id="token-10-0" morph="none" pos="word" start_char="977">I</TOKEN>
<TOKEN end_char="983" id="token-10-1" morph="none" pos="word" start_char="979">don’t</TOKEN>
<TOKEN end_char="988" id="token-10-2" morph="none" pos="word" start_char="985">want</TOKEN>
<TOKEN end_char="991" id="token-10-3" morph="none" pos="word" start_char="990">to</TOKEN>
<TOKEN end_char="996" id="token-10-4" morph="none" pos="word" start_char="993">make</TOKEN>
<TOKEN end_char="1000" id="token-10-5" morph="none" pos="word" start_char="998">any</TOKEN>
<TOKEN end_char="1012" id="token-10-6" morph="none" pos="word" start_char="1002">accusations</TOKEN>
<TOKEN end_char="1014" id="token-10-7" morph="none" pos="punct" start_char="1013">,"</TOKEN>
<TOKEN end_char="1018" id="token-10-8" morph="none" pos="word" start_char="1016">the</TOKEN>
<TOKEN end_char="1025" id="token-10-9" morph="none" pos="word" start_char="1020">former</TOKEN>
<TOKEN end_char="1029" id="token-10-10" morph="none" pos="word" start_char="1027">NYC</TOKEN>
<TOKEN end_char="1035" id="token-10-11" morph="none" pos="word" start_char="1031">mayor</TOKEN>
<TOKEN end_char="1041" id="token-10-12" morph="none" pos="word" start_char="1037">added</TOKEN>
<TOKEN end_char="1042" id="token-10-13" morph="none" pos="punct" start_char="1042">.</TOKEN>
</SEG>
<SEG end_char="1186" id="segment-11" start_char="1046">
<ORIGINAL_TEXT>"But there was more knowledge about what was going on in China with our scientific people than they disclosed to us when this first came out.</ORIGINAL_TEXT>
<TOKEN end_char="1046" id="token-11-0" morph="none" pos="punct" start_char="1046">"</TOKEN>
<TOKEN end_char="1049" id="token-11-1" morph="none" pos="word" start_char="1047">But</TOKEN>
<TOKEN end_char="1055" id="token-11-2" morph="none" pos="word" start_char="1051">there</TOKEN>
<TOKEN end_char="1059" id="token-11-3" morph="none" pos="word" start_char="1057">was</TOKEN>
<TOKEN end_char="1064" id="token-11-4" morph="none" pos="word" start_char="1061">more</TOKEN>
<TOKEN end_char="1074" id="token-11-5" morph="none" pos="word" start_char="1066">knowledge</TOKEN>
<TOKEN end_char="1080" id="token-11-6" morph="none" pos="word" start_char="1076">about</TOKEN>
<TOKEN end_char="1085" id="token-11-7" morph="none" pos="word" start_char="1082">what</TOKEN>
<TOKEN end_char="1089" id="token-11-8" morph="none" pos="word" start_char="1087">was</TOKEN>
<TOKEN end_char="1095" id="token-11-9" morph="none" pos="word" start_char="1091">going</TOKEN>
<TOKEN end_char="1098" id="token-11-10" morph="none" pos="word" start_char="1097">on</TOKEN>
<TOKEN end_char="1101" id="token-11-11" morph="none" pos="word" start_char="1100">in</TOKEN>
<TOKEN end_char="1107" id="token-11-12" morph="none" pos="word" start_char="1103">China</TOKEN>
<TOKEN end_char="1112" id="token-11-13" morph="none" pos="word" start_char="1109">with</TOKEN>
<TOKEN end_char="1116" id="token-11-14" morph="none" pos="word" start_char="1114">our</TOKEN>
<TOKEN end_char="1127" id="token-11-15" morph="none" pos="word" start_char="1118">scientific</TOKEN>
<TOKEN end_char="1134" id="token-11-16" morph="none" pos="word" start_char="1129">people</TOKEN>
<TOKEN end_char="1139" id="token-11-17" morph="none" pos="word" start_char="1136">than</TOKEN>
<TOKEN end_char="1144" id="token-11-18" morph="none" pos="word" start_char="1141">they</TOKEN>
<TOKEN end_char="1154" id="token-11-19" morph="none" pos="word" start_char="1146">disclosed</TOKEN>
<TOKEN end_char="1157" id="token-11-20" morph="none" pos="word" start_char="1156">to</TOKEN>
<TOKEN end_char="1160" id="token-11-21" morph="none" pos="word" start_char="1159">us</TOKEN>
<TOKEN end_char="1165" id="token-11-22" morph="none" pos="word" start_char="1162">when</TOKEN>
<TOKEN end_char="1170" id="token-11-23" morph="none" pos="word" start_char="1167">this</TOKEN>
<TOKEN end_char="1176" id="token-11-24" morph="none" pos="word" start_char="1172">first</TOKEN>
<TOKEN end_char="1181" id="token-11-25" morph="none" pos="word" start_char="1178">came</TOKEN>
<TOKEN end_char="1185" id="token-11-26" morph="none" pos="word" start_char="1183">out</TOKEN>
<TOKEN end_char="1186" id="token-11-27" morph="none" pos="punct" start_char="1186">.</TOKEN>
</SEG>
<SEG end_char="1292" id="segment-12" start_char="1188">
<ORIGINAL_TEXT>Just think of it: If this laboratory turns out to be the place where the virus came from, we paid for it.</ORIGINAL_TEXT>
<TOKEN end_char="1191" id="token-12-0" morph="none" pos="word" start_char="1188">Just</TOKEN>
<TOKEN end_char="1197" id="token-12-1" morph="none" pos="word" start_char="1193">think</TOKEN>
<TOKEN end_char="1200" id="token-12-2" morph="none" pos="word" start_char="1199">of</TOKEN>
<TOKEN end_char="1203" id="token-12-3" morph="none" pos="word" start_char="1202">it</TOKEN>
<TOKEN end_char="1204" id="token-12-4" morph="none" pos="punct" start_char="1204">:</TOKEN>
<TOKEN end_char="1207" id="token-12-5" morph="none" pos="word" start_char="1206">If</TOKEN>
<TOKEN end_char="1212" id="token-12-6" morph="none" pos="word" start_char="1209">this</TOKEN>
<TOKEN end_char="1223" id="token-12-7" morph="none" pos="word" start_char="1214">laboratory</TOKEN>
<TOKEN end_char="1229" id="token-12-8" morph="none" pos="word" start_char="1225">turns</TOKEN>
<TOKEN end_char="1233" id="token-12-9" morph="none" pos="word" start_char="1231">out</TOKEN>
<TOKEN end_char="1236" id="token-12-10" morph="none" pos="word" start_char="1235">to</TOKEN>
<TOKEN end_char="1239" id="token-12-11" morph="none" pos="word" start_char="1238">be</TOKEN>
<TOKEN end_char="1243" id="token-12-12" morph="none" pos="word" start_char="1241">the</TOKEN>
<TOKEN end_char="1249" id="token-12-13" morph="none" pos="word" start_char="1245">place</TOKEN>
<TOKEN end_char="1255" id="token-12-14" morph="none" pos="word" start_char="1251">where</TOKEN>
<TOKEN end_char="1259" id="token-12-15" morph="none" pos="word" start_char="1257">the</TOKEN>
<TOKEN end_char="1265" id="token-12-16" morph="none" pos="word" start_char="1261">virus</TOKEN>
<TOKEN end_char="1270" id="token-12-17" morph="none" pos="word" start_char="1267">came</TOKEN>
<TOKEN end_char="1275" id="token-12-18" morph="none" pos="word" start_char="1272">from</TOKEN>
<TOKEN end_char="1276" id="token-12-19" morph="none" pos="punct" start_char="1276">,</TOKEN>
<TOKEN end_char="1279" id="token-12-20" morph="none" pos="word" start_char="1278">we</TOKEN>
<TOKEN end_char="1284" id="token-12-21" morph="none" pos="word" start_char="1281">paid</TOKEN>
<TOKEN end_char="1288" id="token-12-22" morph="none" pos="word" start_char="1286">for</TOKEN>
<TOKEN end_char="1291" id="token-12-23" morph="none" pos="word" start_char="1290">it</TOKEN>
<TOKEN end_char="1292" id="token-12-24" morph="none" pos="punct" start_char="1292">.</TOKEN>
</SEG>
<SEG end_char="1339" id="segment-13" start_char="1294">
<ORIGINAL_TEXT>We paid for the damn virus that’s killing us."</ORIGINAL_TEXT>
<TOKEN end_char="1295" id="token-13-0" morph="none" pos="word" start_char="1294">We</TOKEN>
<TOKEN end_char="1300" id="token-13-1" morph="none" pos="word" start_char="1297">paid</TOKEN>
<TOKEN end_char="1304" id="token-13-2" morph="none" pos="word" start_char="1302">for</TOKEN>
<TOKEN end_char="1308" id="token-13-3" morph="none" pos="word" start_char="1306">the</TOKEN>
<TOKEN end_char="1313" id="token-13-4" morph="none" pos="word" start_char="1310">damn</TOKEN>
<TOKEN end_char="1319" id="token-13-5" morph="none" pos="word" start_char="1315">virus</TOKEN>
<TOKEN end_char="1326" id="token-13-6" morph="none" pos="word" start_char="1321">that’s</TOKEN>
<TOKEN end_char="1334" id="token-13-7" morph="none" pos="word" start_char="1328">killing</TOKEN>
<TOKEN end_char="1337" id="token-13-8" morph="none" pos="word" start_char="1336">us</TOKEN>
<TOKEN end_char="1339" id="token-13-9" morph="none" pos="punct" start_char="1338">."</TOKEN>
</SEG>
<SEG end_char="1520" id="segment-14" start_char="1342">
<ORIGINAL_TEXT>Reports are mounting that the virus was leaked from a virology lab located just miles from the controversial wet market in Wuhan that was originally blamed for spawning the virus.</ORIGINAL_TEXT>
<TOKEN end_char="1348" id="token-14-0" morph="none" pos="word" start_char="1342">Reports</TOKEN>
<TOKEN end_char="1352" id="token-14-1" morph="none" pos="word" start_char="1350">are</TOKEN>
<TOKEN end_char="1361" id="token-14-2" morph="none" pos="word" start_char="1354">mounting</TOKEN>
<TOKEN end_char="1366" id="token-14-3" morph="none" pos="word" start_char="1363">that</TOKEN>
<TOKEN end_char="1370" id="token-14-4" morph="none" pos="word" start_char="1368">the</TOKEN>
<TOKEN end_char="1376" id="token-14-5" morph="none" pos="word" start_char="1372">virus</TOKEN>
<TOKEN end_char="1380" id="token-14-6" morph="none" pos="word" start_char="1378">was</TOKEN>
<TOKEN end_char="1387" id="token-14-7" morph="none" pos="word" start_char="1382">leaked</TOKEN>
<TOKEN end_char="1392" id="token-14-8" morph="none" pos="word" start_char="1389">from</TOKEN>
<TOKEN end_char="1394" id="token-14-9" morph="none" pos="word" start_char="1394">a</TOKEN>
<TOKEN end_char="1403" id="token-14-10" morph="none" pos="word" start_char="1396">virology</TOKEN>
<TOKEN end_char="1407" id="token-14-11" morph="none" pos="word" start_char="1405">lab</TOKEN>
<TOKEN end_char="1415" id="token-14-12" morph="none" pos="word" start_char="1409">located</TOKEN>
<TOKEN end_char="1420" id="token-14-13" morph="none" pos="word" start_char="1417">just</TOKEN>
<TOKEN end_char="1426" id="token-14-14" morph="none" pos="word" start_char="1422">miles</TOKEN>
<TOKEN end_char="1431" id="token-14-15" morph="none" pos="word" start_char="1428">from</TOKEN>
<TOKEN end_char="1435" id="token-14-16" morph="none" pos="word" start_char="1433">the</TOKEN>
<TOKEN end_char="1449" id="token-14-17" morph="none" pos="word" start_char="1437">controversial</TOKEN>
<TOKEN end_char="1453" id="token-14-18" morph="none" pos="word" start_char="1451">wet</TOKEN>
<TOKEN end_char="1460" id="token-14-19" morph="none" pos="word" start_char="1455">market</TOKEN>
<TOKEN end_char="1463" id="token-14-20" morph="none" pos="word" start_char="1462">in</TOKEN>
<TOKEN end_char="1469" id="token-14-21" morph="none" pos="word" start_char="1465">Wuhan</TOKEN>
<TOKEN end_char="1474" id="token-14-22" morph="none" pos="word" start_char="1471">that</TOKEN>
<TOKEN end_char="1478" id="token-14-23" morph="none" pos="word" start_char="1476">was</TOKEN>
<TOKEN end_char="1489" id="token-14-24" morph="none" pos="word" start_char="1480">originally</TOKEN>
<TOKEN end_char="1496" id="token-14-25" morph="none" pos="word" start_char="1491">blamed</TOKEN>
<TOKEN end_char="1500" id="token-14-26" morph="none" pos="word" start_char="1498">for</TOKEN>
<TOKEN end_char="1509" id="token-14-27" morph="none" pos="word" start_char="1502">spawning</TOKEN>
<TOKEN end_char="1513" id="token-14-28" morph="none" pos="word" start_char="1511">the</TOKEN>
<TOKEN end_char="1519" id="token-14-29" morph="none" pos="word" start_char="1515">virus</TOKEN>
<TOKEN end_char="1520" id="token-14-30" morph="none" pos="punct" start_char="1520">.</TOKEN>
</SEG>
<SEG end_char="1561" id="segment-15" start_char="1522">
<ORIGINAL_TEXT>The matter is still under investigation.</ORIGINAL_TEXT>
<TOKEN end_char="1524" id="token-15-0" morph="none" pos="word" start_char="1522">The</TOKEN>
<TOKEN end_char="1531" id="token-15-1" morph="none" pos="word" start_char="1526">matter</TOKEN>
<TOKEN end_char="1534" id="token-15-2" morph="none" pos="word" start_char="1533">is</TOKEN>
<TOKEN end_char="1540" id="token-15-3" morph="none" pos="word" start_char="1536">still</TOKEN>
<TOKEN end_char="1546" id="token-15-4" morph="none" pos="word" start_char="1542">under</TOKEN>
<TOKEN end_char="1560" id="token-15-5" morph="none" pos="word" start_char="1548">investigation</TOKEN>
<TOKEN end_char="1561" id="token-15-6" morph="none" pos="punct" start_char="1561">.</TOKEN>
</SEG>
<SEG end_char="1717" id="segment-16" start_char="1564">
<ORIGINAL_TEXT>Giuliani pressed for a more official probe, however, remarking that "today, if I were U.S. attorney, I’d open an investigation into the Wuhan laboratory."</ORIGINAL_TEXT>
<TOKEN end_char="1571" id="token-16-0" morph="none" pos="word" start_char="1564">Giuliani</TOKEN>
<TOKEN end_char="1579" id="token-16-1" morph="none" pos="word" start_char="1573">pressed</TOKEN>
<TOKEN end_char="1583" id="token-16-2" morph="none" pos="word" start_char="1581">for</TOKEN>
<TOKEN end_char="1585" id="token-16-3" morph="none" pos="word" start_char="1585">a</TOKEN>
<TOKEN end_char="1590" id="token-16-4" morph="none" pos="word" start_char="1587">more</TOKEN>
<TOKEN end_char="1599" id="token-16-5" morph="none" pos="word" start_char="1592">official</TOKEN>
<TOKEN end_char="1605" id="token-16-6" morph="none" pos="word" start_char="1601">probe</TOKEN>
<TOKEN end_char="1606" id="token-16-7" morph="none" pos="punct" start_char="1606">,</TOKEN>
<TOKEN end_char="1614" id="token-16-8" morph="none" pos="word" start_char="1608">however</TOKEN>
<TOKEN end_char="1615" id="token-16-9" morph="none" pos="punct" start_char="1615">,</TOKEN>
<TOKEN end_char="1625" id="token-16-10" morph="none" pos="word" start_char="1617">remarking</TOKEN>
<TOKEN end_char="1630" id="token-16-11" morph="none" pos="word" start_char="1627">that</TOKEN>
<TOKEN end_char="1632" id="token-16-12" morph="none" pos="punct" start_char="1632">"</TOKEN>
<TOKEN end_char="1637" id="token-16-13" morph="none" pos="word" start_char="1633">today</TOKEN>
<TOKEN end_char="1638" id="token-16-14" morph="none" pos="punct" start_char="1638">,</TOKEN>
<TOKEN end_char="1641" id="token-16-15" morph="none" pos="word" start_char="1640">if</TOKEN>
<TOKEN end_char="1643" id="token-16-16" morph="none" pos="word" start_char="1643">I</TOKEN>
<TOKEN end_char="1648" id="token-16-17" morph="none" pos="word" start_char="1645">were</TOKEN>
<TOKEN end_char="1652" id="token-16-18" morph="none" pos="unknown" start_char="1650">U.S</TOKEN>
<TOKEN end_char="1653" id="token-16-19" morph="none" pos="punct" start_char="1653">.</TOKEN>
<TOKEN end_char="1662" id="token-16-20" morph="none" pos="word" start_char="1655">attorney</TOKEN>
<TOKEN end_char="1663" id="token-16-21" morph="none" pos="punct" start_char="1663">,</TOKEN>
<TOKEN end_char="1667" id="token-16-22" morph="none" pos="word" start_char="1665">I’d</TOKEN>
<TOKEN end_char="1672" id="token-16-23" morph="none" pos="word" start_char="1669">open</TOKEN>
<TOKEN end_char="1675" id="token-16-24" morph="none" pos="word" start_char="1674">an</TOKEN>
<TOKEN end_char="1689" id="token-16-25" morph="none" pos="word" start_char="1677">investigation</TOKEN>
<TOKEN end_char="1694" id="token-16-26" morph="none" pos="word" start_char="1691">into</TOKEN>
<TOKEN end_char="1698" id="token-16-27" morph="none" pos="word" start_char="1696">the</TOKEN>
<TOKEN end_char="1704" id="token-16-28" morph="none" pos="word" start_char="1700">Wuhan</TOKEN>
<TOKEN end_char="1715" id="token-16-29" morph="none" pos="word" start_char="1706">laboratory</TOKEN>
<TOKEN end_char="1717" id="token-16-30" morph="none" pos="punct" start_char="1716">."</TOKEN>
</SEG>
<SEG end_char="1759" id="segment-17" start_char="1720">
<ORIGINAL_TEXT>"And I’d want to know, what did we know?</ORIGINAL_TEXT>
<TOKEN end_char="1720" id="token-17-0" morph="none" pos="punct" start_char="1720">"</TOKEN>
<TOKEN end_char="1723" id="token-17-1" morph="none" pos="word" start_char="1721">And</TOKEN>
<TOKEN end_char="1727" id="token-17-2" morph="none" pos="word" start_char="1725">I’d</TOKEN>
<TOKEN end_char="1732" id="token-17-3" morph="none" pos="word" start_char="1729">want</TOKEN>
<TOKEN end_char="1735" id="token-17-4" morph="none" pos="word" start_char="1734">to</TOKEN>
<TOKEN end_char="1740" id="token-17-5" morph="none" pos="word" start_char="1737">know</TOKEN>
<TOKEN end_char="1741" id="token-17-6" morph="none" pos="punct" start_char="1741">,</TOKEN>
<TOKEN end_char="1746" id="token-17-7" morph="none" pos="word" start_char="1743">what</TOKEN>
<TOKEN end_char="1750" id="token-17-8" morph="none" pos="word" start_char="1748">did</TOKEN>
<TOKEN end_char="1753" id="token-17-9" morph="none" pos="word" start_char="1752">we</TOKEN>
<TOKEN end_char="1758" id="token-17-10" morph="none" pos="word" start_char="1755">know</TOKEN>
<TOKEN end_char="1759" id="token-17-11" morph="none" pos="punct" start_char="1759">?</TOKEN>
</SEG>
<SEG end_char="1820" id="segment-18" start_char="1761">
<ORIGINAL_TEXT>How much did we know about how bad the practices were there?</ORIGINAL_TEXT>
<TOKEN end_char="1763" id="token-18-0" morph="none" pos="word" start_char="1761">How</TOKEN>
<TOKEN end_char="1768" id="token-18-1" morph="none" pos="word" start_char="1765">much</TOKEN>
<TOKEN end_char="1772" id="token-18-2" morph="none" pos="word" start_char="1770">did</TOKEN>
<TOKEN end_char="1775" id="token-18-3" morph="none" pos="word" start_char="1774">we</TOKEN>
<TOKEN end_char="1780" id="token-18-4" morph="none" pos="word" start_char="1777">know</TOKEN>
<TOKEN end_char="1786" id="token-18-5" morph="none" pos="word" start_char="1782">about</TOKEN>
<TOKEN end_char="1790" id="token-18-6" morph="none" pos="word" start_char="1788">how</TOKEN>
<TOKEN end_char="1794" id="token-18-7" morph="none" pos="word" start_char="1792">bad</TOKEN>
<TOKEN end_char="1798" id="token-18-8" morph="none" pos="word" start_char="1796">the</TOKEN>
<TOKEN end_char="1808" id="token-18-9" morph="none" pos="word" start_char="1800">practices</TOKEN>
<TOKEN end_char="1813" id="token-18-10" morph="none" pos="word" start_char="1810">were</TOKEN>
<TOKEN end_char="1819" id="token-18-11" morph="none" pos="word" start_char="1815">there</TOKEN>
<TOKEN end_char="1820" id="token-18-12" morph="none" pos="punct" start_char="1820">?</TOKEN>
</SEG>
<SEG end_char="1839" id="segment-19" start_char="1822">
<ORIGINAL_TEXT>Who knew about it?</ORIGINAL_TEXT>
<TOKEN end_char="1824" id="token-19-0" morph="none" pos="word" start_char="1822">Who</TOKEN>
<TOKEN end_char="1829" id="token-19-1" morph="none" pos="word" start_char="1826">knew</TOKEN>
<TOKEN end_char="1835" id="token-19-2" morph="none" pos="word" start_char="1831">about</TOKEN>
<TOKEN end_char="1838" id="token-19-3" morph="none" pos="word" start_char="1837">it</TOKEN>
<TOKEN end_char="1839" id="token-19-4" morph="none" pos="punct" start_char="1839">?</TOKEN>
</SEG>
<SEG end_char="1871" id="segment-20" start_char="1841">
<ORIGINAL_TEXT>And who sent them money anyway?</ORIGINAL_TEXT>
<TOKEN end_char="1843" id="token-20-0" morph="none" pos="word" start_char="1841">And</TOKEN>
<TOKEN end_char="1847" id="token-20-1" morph="none" pos="word" start_char="1845">who</TOKEN>
<TOKEN end_char="1852" id="token-20-2" morph="none" pos="word" start_char="1849">sent</TOKEN>
<TOKEN end_char="1857" id="token-20-3" morph="none" pos="word" start_char="1854">them</TOKEN>
<TOKEN end_char="1863" id="token-20-4" morph="none" pos="word" start_char="1859">money</TOKEN>
<TOKEN end_char="1870" id="token-20-5" morph="none" pos="word" start_char="1865">anyway</TOKEN>
<TOKEN end_char="1871" id="token-20-6" morph="none" pos="punct" start_char="1871">?</TOKEN>
</SEG>
<SEG end_char="1982" id="segment-21" start_char="1873">
<ORIGINAL_TEXT>And that person would sure as heck be in front of a grand jury trying to explain to me — what are you asleep?"</ORIGINAL_TEXT>
<TOKEN end_char="1875" id="token-21-0" morph="none" pos="word" start_char="1873">And</TOKEN>
<TOKEN end_char="1880" id="token-21-1" morph="none" pos="word" start_char="1877">that</TOKEN>
<TOKEN end_char="1887" id="token-21-2" morph="none" pos="word" start_char="1882">person</TOKEN>
<TOKEN end_char="1893" id="token-21-3" morph="none" pos="word" start_char="1889">would</TOKEN>
<TOKEN end_char="1898" id="token-21-4" morph="none" pos="word" start_char="1895">sure</TOKEN>
<TOKEN end_char="1901" id="token-21-5" morph="none" pos="word" start_char="1900">as</TOKEN>
<TOKEN end_char="1906" id="token-21-6" morph="none" pos="word" start_char="1903">heck</TOKEN>
<TOKEN end_char="1909" id="token-21-7" morph="none" pos="word" start_char="1908">be</TOKEN>
<TOKEN end_char="1912" id="token-21-8" morph="none" pos="word" start_char="1911">in</TOKEN>
<TOKEN end_char="1918" id="token-21-9" morph="none" pos="word" start_char="1914">front</TOKEN>
<TOKEN end_char="1921" id="token-21-10" morph="none" pos="word" start_char="1920">of</TOKEN>
<TOKEN end_char="1923" id="token-21-11" morph="none" pos="word" start_char="1923">a</TOKEN>
<TOKEN end_char="1929" id="token-21-12" morph="none" pos="word" start_char="1925">grand</TOKEN>
<TOKEN end_char="1934" id="token-21-13" morph="none" pos="word" start_char="1931">jury</TOKEN>
<TOKEN end_char="1941" id="token-21-14" morph="none" pos="word" start_char="1936">trying</TOKEN>
<TOKEN end_char="1944" id="token-21-15" morph="none" pos="word" start_char="1943">to</TOKEN>
<TOKEN end_char="1952" id="token-21-16" morph="none" pos="word" start_char="1946">explain</TOKEN>
<TOKEN end_char="1955" id="token-21-17" morph="none" pos="word" start_char="1954">to</TOKEN>
<TOKEN end_char="1958" id="token-21-18" morph="none" pos="word" start_char="1957">me</TOKEN>
<TOKEN end_char="1960" id="token-21-19" morph="none" pos="punct" start_char="1960">—</TOKEN>
<TOKEN end_char="1965" id="token-21-20" morph="none" pos="word" start_char="1962">what</TOKEN>
<TOKEN end_char="1969" id="token-21-21" morph="none" pos="word" start_char="1967">are</TOKEN>
<TOKEN end_char="1973" id="token-21-22" morph="none" pos="word" start_char="1971">you</TOKEN>
<TOKEN end_char="1980" id="token-21-23" morph="none" pos="word" start_char="1975">asleep</TOKEN>
<TOKEN end_char="1982" id="token-21-24" morph="none" pos="punct" start_char="1981">?"</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATB1" lang="spa" raw_text_char_length="9211" raw_text_md5="fa67bc500dd117519fd6b9577c776065" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="22" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Mascarillas, ¿sí o no?</ORIGINAL_TEXT>
<TOKEN end_char="11" id="token-0-0" morph="none" pos="word" start_char="1">Mascarillas</TOKEN>
<TOKEN end_char="12" id="token-0-1" morph="none" pos="punct" start_char="12">,</TOKEN>
<TOKEN end_char="14" id="token-0-2" morph="none" pos="punct" start_char="14">¿</TOKEN>
<TOKEN end_char="16" id="token-0-3" morph="none" pos="word" start_char="15">sí</TOKEN>
<TOKEN end_char="18" id="token-0-4" morph="none" pos="word" start_char="18">o</TOKEN>
<TOKEN end_char="21" id="token-0-5" morph="none" pos="word" start_char="20">no</TOKEN>
<TOKEN end_char="22" id="token-0-6" morph="none" pos="punct" start_char="22">?</TOKEN>
<TRANSLATED_TEXT>Masquerades, yes or no?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="98" id="segment-1" start_char="24">
<ORIGINAL_TEXT>Los expertos y Europa piden utilizarlas pero el Gobierno aún no aclara cómo</ORIGINAL_TEXT>
<TOKEN end_char="26" id="token-1-0" morph="none" pos="word" start_char="24">Los</TOKEN>
<TOKEN end_char="35" id="token-1-1" morph="none" pos="word" start_char="28">expertos</TOKEN>
<TOKEN end_char="37" id="token-1-2" morph="none" pos="word" start_char="37">y</TOKEN>
<TOKEN end_char="44" id="token-1-3" morph="none" pos="word" start_char="39">Europa</TOKEN>
<TOKEN end_char="50" id="token-1-4" morph="none" pos="word" start_char="46">piden</TOKEN>
<TOKEN end_char="62" id="token-1-5" morph="none" pos="word" start_char="52">utilizarlas</TOKEN>
<TOKEN end_char="67" id="token-1-6" morph="none" pos="word" start_char="64">pero</TOKEN>
<TOKEN end_char="70" id="token-1-7" morph="none" pos="word" start_char="69">el</TOKEN>
<TOKEN end_char="79" id="token-1-8" morph="none" pos="word" start_char="72">Gobierno</TOKEN>
<TOKEN end_char="83" id="token-1-9" morph="none" pos="word" start_char="81">aún</TOKEN>
<TOKEN end_char="86" id="token-1-10" morph="none" pos="word" start_char="85">no</TOKEN>
<TOKEN end_char="93" id="token-1-11" morph="none" pos="word" start_char="88">aclara</TOKEN>
<TOKEN end_char="98" id="token-1-12" morph="none" pos="word" start_char="95">cómo</TOKEN>
<TRANSLATED_TEXT>Experts and Europe ask to use them, but the government has not yet clarified how</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="159" id="segment-2" start_char="102">
<ORIGINAL_TEXT>Sobran comentarios periodísticos y discursos del Gobierno.</ORIGINAL_TEXT>
<TOKEN end_char="107" id="token-2-0" morph="none" pos="word" start_char="102">Sobran</TOKEN>
<TOKEN end_char="119" id="token-2-1" morph="none" pos="word" start_char="109">comentarios</TOKEN>
<TOKEN end_char="133" id="token-2-2" morph="none" pos="word" start_char="121">periodísticos</TOKEN>
<TOKEN end_char="135" id="token-2-3" morph="none" pos="word" start_char="135">y</TOKEN>
<TOKEN end_char="145" id="token-2-4" morph="none" pos="word" start_char="137">discursos</TOKEN>
<TOKEN end_char="149" id="token-2-5" morph="none" pos="word" start_char="147">del</TOKEN>
<TOKEN end_char="158" id="token-2-6" morph="none" pos="word" start_char="151">Gobierno</TOKEN>
<TOKEN end_char="159" id="token-2-7" morph="none" pos="punct" start_char="159">.</TOKEN>
<TRANSLATED_TEXT>There are press reports and speeches from the government.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="520" id="segment-3" start_char="161">
<ORIGINAL_TEXT>Nuestro idioma es tan extenso que permite decir y no decir a la misma vez, Este asunto es diáfano como la luz del Sol, NO HAY mascarillas suficientes para todos (47 millones de habitantes y 8/10 mascarillas al menos a cada uno para usarlas el primer mes suman 470 millones), nos explican hasta como lavarlas y se intenta justificar con argumentos de todo tipo.</ORIGINAL_TEXT>
<TOKEN end_char="167" id="token-3-0" morph="none" pos="word" start_char="161">Nuestro</TOKEN>
<TOKEN end_char="174" id="token-3-1" morph="none" pos="word" start_char="169">idioma</TOKEN>
<TOKEN end_char="177" id="token-3-2" morph="none" pos="word" start_char="176">es</TOKEN>
<TOKEN end_char="181" id="token-3-3" morph="none" pos="word" start_char="179">tan</TOKEN>
<TOKEN end_char="189" id="token-3-4" morph="none" pos="word" start_char="183">extenso</TOKEN>
<TOKEN end_char="193" id="token-3-5" morph="none" pos="word" start_char="191">que</TOKEN>
<TOKEN end_char="201" id="token-3-6" morph="none" pos="word" start_char="195">permite</TOKEN>
<TOKEN end_char="207" id="token-3-7" morph="none" pos="word" start_char="203">decir</TOKEN>
<TOKEN end_char="209" id="token-3-8" morph="none" pos="word" start_char="209">y</TOKEN>
<TOKEN end_char="212" id="token-3-9" morph="none" pos="word" start_char="211">no</TOKEN>
<TOKEN end_char="218" id="token-3-10" morph="none" pos="word" start_char="214">decir</TOKEN>
<TOKEN end_char="220" id="token-3-11" morph="none" pos="word" start_char="220">a</TOKEN>
<TOKEN end_char="223" id="token-3-12" morph="none" pos="word" start_char="222">la</TOKEN>
<TOKEN end_char="229" id="token-3-13" morph="none" pos="word" start_char="225">misma</TOKEN>
<TOKEN end_char="233" id="token-3-14" morph="none" pos="word" start_char="231">vez</TOKEN>
<TOKEN end_char="234" id="token-3-15" morph="none" pos="punct" start_char="234">,</TOKEN>
<TOKEN end_char="239" id="token-3-16" morph="none" pos="word" start_char="236">Este</TOKEN>
<TOKEN end_char="246" id="token-3-17" morph="none" pos="word" start_char="241">asunto</TOKEN>
<TOKEN end_char="249" id="token-3-18" morph="none" pos="word" start_char="248">es</TOKEN>
<TOKEN end_char="257" id="token-3-19" morph="none" pos="word" start_char="251">diáfano</TOKEN>
<TOKEN end_char="262" id="token-3-20" morph="none" pos="word" start_char="259">como</TOKEN>
<TOKEN end_char="265" id="token-3-21" morph="none" pos="word" start_char="264">la</TOKEN>
<TOKEN end_char="269" id="token-3-22" morph="none" pos="word" start_char="267">luz</TOKEN>
<TOKEN end_char="273" id="token-3-23" morph="none" pos="word" start_char="271">del</TOKEN>
<TOKEN end_char="277" id="token-3-24" morph="none" pos="word" start_char="275">Sol</TOKEN>
<TOKEN end_char="278" id="token-3-25" morph="none" pos="punct" start_char="278">,</TOKEN>
<TOKEN end_char="281" id="token-3-26" morph="none" pos="word" start_char="280">NO</TOKEN>
<TOKEN end_char="285" id="token-3-27" morph="none" pos="word" start_char="283">HAY</TOKEN>
<TOKEN end_char="297" id="token-3-28" morph="none" pos="word" start_char="287">mascarillas</TOKEN>
<TOKEN end_char="309" id="token-3-29" morph="none" pos="word" start_char="299">suficientes</TOKEN>
<TOKEN end_char="314" id="token-3-30" morph="none" pos="word" start_char="311">para</TOKEN>
<TOKEN end_char="320" id="token-3-31" morph="none" pos="word" start_char="316">todos</TOKEN>
<TOKEN end_char="322" id="token-3-32" morph="none" pos="punct" start_char="322">(</TOKEN>
<TOKEN end_char="324" id="token-3-33" morph="none" pos="word" start_char="323">47</TOKEN>
<TOKEN end_char="333" id="token-3-34" morph="none" pos="word" start_char="326">millones</TOKEN>
<TOKEN end_char="336" id="token-3-35" morph="none" pos="word" start_char="335">de</TOKEN>
<TOKEN end_char="347" id="token-3-36" morph="none" pos="word" start_char="338">habitantes</TOKEN>
<TOKEN end_char="349" id="token-3-37" morph="none" pos="word" start_char="349">y</TOKEN>
<TOKEN end_char="354" id="token-3-38" morph="none" pos="unknown" start_char="351">8/10</TOKEN>
<TOKEN end_char="366" id="token-3-39" morph="none" pos="word" start_char="356">mascarillas</TOKEN>
<TOKEN end_char="369" id="token-3-40" morph="none" pos="word" start_char="368">al</TOKEN>
<TOKEN end_char="375" id="token-3-41" morph="none" pos="word" start_char="371">menos</TOKEN>
<TOKEN end_char="377" id="token-3-42" morph="none" pos="word" start_char="377">a</TOKEN>
<TOKEN end_char="382" id="token-3-43" morph="none" pos="word" start_char="379">cada</TOKEN>
<TOKEN end_char="386" id="token-3-44" morph="none" pos="word" start_char="384">uno</TOKEN>
<TOKEN end_char="391" id="token-3-45" morph="none" pos="word" start_char="388">para</TOKEN>
<TOKEN end_char="399" id="token-3-46" morph="none" pos="word" start_char="393">usarlas</TOKEN>
<TOKEN end_char="402" id="token-3-47" morph="none" pos="word" start_char="401">el</TOKEN>
<TOKEN end_char="409" id="token-3-48" morph="none" pos="word" start_char="404">primer</TOKEN>
<TOKEN end_char="413" id="token-3-49" morph="none" pos="word" start_char="411">mes</TOKEN>
<TOKEN end_char="419" id="token-3-50" morph="none" pos="word" start_char="415">suman</TOKEN>
<TOKEN end_char="423" id="token-3-51" morph="none" pos="word" start_char="421">470</TOKEN>
<TOKEN end_char="432" id="token-3-52" morph="none" pos="word" start_char="425">millones</TOKEN>
<TOKEN end_char="434" id="token-3-53" morph="none" pos="punct" start_char="433">),</TOKEN>
<TOKEN end_char="438" id="token-3-54" morph="none" pos="word" start_char="436">nos</TOKEN>
<TOKEN end_char="447" id="token-3-55" morph="none" pos="word" start_char="440">explican</TOKEN>
<TOKEN end_char="453" id="token-3-56" morph="none" pos="word" start_char="449">hasta</TOKEN>
<TOKEN end_char="458" id="token-3-57" morph="none" pos="word" start_char="455">como</TOKEN>
<TOKEN end_char="467" id="token-3-58" morph="none" pos="word" start_char="460">lavarlas</TOKEN>
<TOKEN end_char="469" id="token-3-59" morph="none" pos="word" start_char="469">y</TOKEN>
<TOKEN end_char="472" id="token-3-60" morph="none" pos="word" start_char="471">se</TOKEN>
<TOKEN end_char="480" id="token-3-61" morph="none" pos="word" start_char="474">intenta</TOKEN>
<TOKEN end_char="491" id="token-3-62" morph="none" pos="word" start_char="482">justificar</TOKEN>
<TOKEN end_char="495" id="token-3-63" morph="none" pos="word" start_char="493">con</TOKEN>
<TOKEN end_char="506" id="token-3-64" morph="none" pos="word" start_char="497">argumentos</TOKEN>
<TOKEN end_char="509" id="token-3-65" morph="none" pos="word" start_char="508">de</TOKEN>
<TOKEN end_char="514" id="token-3-66" morph="none" pos="word" start_char="511">todo</TOKEN>
<TOKEN end_char="519" id="token-3-67" morph="none" pos="word" start_char="516">tipo</TOKEN>
<TOKEN end_char="520" id="token-3-68" morph="none" pos="punct" start_char="520">.</TOKEN>
<TRANSLATED_TEXT>Our language is so extensive that it is possible to say and not to say at the same time, This subject is as diaphane as the light of the sun, THERE ARE NOT enough masks for everyone (47 million inhabitants and 8 / 10 masks at least for each to use them in the first month total 470 million), they explain to us how to wash them and try to justify it with arguments of all kinds.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="528" id="segment-4" start_char="522">
<ORIGINAL_TEXT>NO HAY.</ORIGINAL_TEXT>
<TOKEN end_char="523" id="token-4-0" morph="none" pos="word" start_char="522">NO</TOKEN>
<TOKEN end_char="527" id="token-4-1" morph="none" pos="word" start_char="525">HAY</TOKEN>
<TOKEN end_char="528" id="token-4-2" morph="none" pos="punct" start_char="528">.</TOKEN>
</SEG>
<SEG end_char="849" id="segment-5" start_char="532">
<ORIGINAL_TEXT>Me parece un debate estéril si no exiten razones tales como la falta o escasez que se ha demostrado desde el inicio de la sesión de covid y que por algún motivo en el mes que llevamos no se ha generalizado su fabricación y de las buenas, sabiendo como sabemos que hoy día se diseña y se fabrica cualquier cosa en días.</ORIGINAL_TEXT>
<TOKEN end_char="533" id="token-5-0" morph="none" pos="word" start_char="532">Me</TOKEN>
<TOKEN end_char="540" id="token-5-1" morph="none" pos="word" start_char="535">parece</TOKEN>
<TOKEN end_char="543" id="token-5-2" morph="none" pos="word" start_char="542">un</TOKEN>
<TOKEN end_char="550" id="token-5-3" morph="none" pos="word" start_char="545">debate</TOKEN>
<TOKEN end_char="558" id="token-5-4" morph="none" pos="word" start_char="552">estéril</TOKEN>
<TOKEN end_char="561" id="token-5-5" morph="none" pos="word" start_char="560">si</TOKEN>
<TOKEN end_char="564" id="token-5-6" morph="none" pos="word" start_char="563">no</TOKEN>
<TOKEN end_char="571" id="token-5-7" morph="none" pos="word" start_char="566">exiten</TOKEN>
<TOKEN end_char="579" id="token-5-8" morph="none" pos="word" start_char="573">razones</TOKEN>
<TOKEN end_char="585" id="token-5-9" morph="none" pos="word" start_char="581">tales</TOKEN>
<TOKEN end_char="590" id="token-5-10" morph="none" pos="word" start_char="587">como</TOKEN>
<TOKEN end_char="593" id="token-5-11" morph="none" pos="word" start_char="592">la</TOKEN>
<TOKEN end_char="599" id="token-5-12" morph="none" pos="word" start_char="595">falta</TOKEN>
<TOKEN end_char="601" id="token-5-13" morph="none" pos="word" start_char="601">o</TOKEN>
<TOKEN end_char="609" id="token-5-14" morph="none" pos="word" start_char="603">escasez</TOKEN>
<TOKEN end_char="613" id="token-5-15" morph="none" pos="word" start_char="611">que</TOKEN>
<TOKEN end_char="616" id="token-5-16" morph="none" pos="word" start_char="615">se</TOKEN>
<TOKEN end_char="619" id="token-5-17" morph="none" pos="word" start_char="618">ha</TOKEN>
<TOKEN end_char="630" id="token-5-18" morph="none" pos="word" start_char="621">demostrado</TOKEN>
<TOKEN end_char="636" id="token-5-19" morph="none" pos="word" start_char="632">desde</TOKEN>
<TOKEN end_char="639" id="token-5-20" morph="none" pos="word" start_char="638">el</TOKEN>
<TOKEN end_char="646" id="token-5-21" morph="none" pos="word" start_char="641">inicio</TOKEN>
<TOKEN end_char="649" id="token-5-22" morph="none" pos="word" start_char="648">de</TOKEN>
<TOKEN end_char="652" id="token-5-23" morph="none" pos="word" start_char="651">la</TOKEN>
<TOKEN end_char="659" id="token-5-24" morph="none" pos="word" start_char="654">sesión</TOKEN>
<TOKEN end_char="662" id="token-5-25" morph="none" pos="word" start_char="661">de</TOKEN>
<TOKEN end_char="668" id="token-5-26" morph="none" pos="word" start_char="664">covid</TOKEN>
<TOKEN end_char="670" id="token-5-27" morph="none" pos="word" start_char="670">y</TOKEN>
<TOKEN end_char="674" id="token-5-28" morph="none" pos="word" start_char="672">que</TOKEN>
<TOKEN end_char="678" id="token-5-29" morph="none" pos="word" start_char="676">por</TOKEN>
<TOKEN end_char="684" id="token-5-30" morph="none" pos="word" start_char="680">algún</TOKEN>
<TOKEN end_char="691" id="token-5-31" morph="none" pos="word" start_char="686">motivo</TOKEN>
<TOKEN end_char="694" id="token-5-32" morph="none" pos="word" start_char="693">en</TOKEN>
<TOKEN end_char="697" id="token-5-33" morph="none" pos="word" start_char="696">el</TOKEN>
<TOKEN end_char="701" id="token-5-34" morph="none" pos="word" start_char="699">mes</TOKEN>
<TOKEN end_char="705" id="token-5-35" morph="none" pos="word" start_char="703">que</TOKEN>
<TOKEN end_char="714" id="token-5-36" morph="none" pos="word" start_char="707">llevamos</TOKEN>
<TOKEN end_char="717" id="token-5-37" morph="none" pos="word" start_char="716">no</TOKEN>
<TOKEN end_char="720" id="token-5-38" morph="none" pos="word" start_char="719">se</TOKEN>
<TOKEN end_char="723" id="token-5-39" morph="none" pos="word" start_char="722">ha</TOKEN>
<TOKEN end_char="736" id="token-5-40" morph="none" pos="word" start_char="725">generalizado</TOKEN>
<TOKEN end_char="739" id="token-5-41" morph="none" pos="word" start_char="738">su</TOKEN>
<TOKEN end_char="751" id="token-5-42" morph="none" pos="word" start_char="741">fabricación</TOKEN>
<TOKEN end_char="753" id="token-5-43" morph="none" pos="word" start_char="753">y</TOKEN>
<TOKEN end_char="756" id="token-5-44" morph="none" pos="word" start_char="755">de</TOKEN>
<TOKEN end_char="760" id="token-5-45" morph="none" pos="word" start_char="758">las</TOKEN>
<TOKEN end_char="767" id="token-5-46" morph="none" pos="word" start_char="762">buenas</TOKEN>
<TOKEN end_char="768" id="token-5-47" morph="none" pos="punct" start_char="768">,</TOKEN>
<TOKEN end_char="777" id="token-5-48" morph="none" pos="word" start_char="770">sabiendo</TOKEN>
<TOKEN end_char="782" id="token-5-49" morph="none" pos="word" start_char="779">como</TOKEN>
<TOKEN end_char="790" id="token-5-50" morph="none" pos="word" start_char="784">sabemos</TOKEN>
<TOKEN end_char="794" id="token-5-51" morph="none" pos="word" start_char="792">que</TOKEN>
<TOKEN end_char="798" id="token-5-52" morph="none" pos="word" start_char="796">hoy</TOKEN>
<TOKEN end_char="802" id="token-5-53" morph="none" pos="word" start_char="800">día</TOKEN>
<TOKEN end_char="805" id="token-5-54" morph="none" pos="word" start_char="804">se</TOKEN>
<TOKEN end_char="812" id="token-5-55" morph="none" pos="word" start_char="807">diseña</TOKEN>
<TOKEN end_char="814" id="token-5-56" morph="none" pos="word" start_char="814">y</TOKEN>
<TOKEN end_char="817" id="token-5-57" morph="none" pos="word" start_char="816">se</TOKEN>
<TOKEN end_char="825" id="token-5-58" morph="none" pos="word" start_char="819">fabrica</TOKEN>
<TOKEN end_char="835" id="token-5-59" morph="none" pos="word" start_char="827">cualquier</TOKEN>
<TOKEN end_char="840" id="token-5-60" morph="none" pos="word" start_char="837">cosa</TOKEN>
<TOKEN end_char="843" id="token-5-61" morph="none" pos="word" start_char="842">en</TOKEN>
<TOKEN end_char="848" id="token-5-62" morph="none" pos="word" start_char="845">días</TOKEN>
<TOKEN end_char="849" id="token-5-63" morph="none" pos="punct" start_char="849">.</TOKEN>
<TRANSLATED_TEXT>It seems to me to be a sterile debate if there are no reasons such as the lack or scarcity that has been demonstrated since the beginning of the covid session and that for some reason in the month we have been taking it has not been widespread and of the good, knowing how we know that today anything is designed and manufactured in days.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1115" id="segment-6" start_char="851">
<ORIGINAL_TEXT>Ya fuera las malas, las buenas, las muy buenas, o las excelentes y del material que fuera, el gobierno debería, Como ha hecho con otras cuestiones y actividades, caso hospitales de campaña, haber puesto la maquina y las empresas a fabricar mascarillas a todo trapo.</ORIGINAL_TEXT>
<TOKEN end_char="852" id="token-6-0" morph="none" pos="word" start_char="851">Ya</TOKEN>
<TOKEN end_char="858" id="token-6-1" morph="none" pos="word" start_char="854">fuera</TOKEN>
<TOKEN end_char="862" id="token-6-2" morph="none" pos="word" start_char="860">las</TOKEN>
<TOKEN end_char="868" id="token-6-3" morph="none" pos="word" start_char="864">malas</TOKEN>
<TOKEN end_char="869" id="token-6-4" morph="none" pos="punct" start_char="869">,</TOKEN>
<TOKEN end_char="873" id="token-6-5" morph="none" pos="word" start_char="871">las</TOKEN>
<TOKEN end_char="880" id="token-6-6" morph="none" pos="word" start_char="875">buenas</TOKEN>
<TOKEN end_char="881" id="token-6-7" morph="none" pos="punct" start_char="881">,</TOKEN>
<TOKEN end_char="885" id="token-6-8" morph="none" pos="word" start_char="883">las</TOKEN>
<TOKEN end_char="889" id="token-6-9" morph="none" pos="word" start_char="887">muy</TOKEN>
<TOKEN end_char="896" id="token-6-10" morph="none" pos="word" start_char="891">buenas</TOKEN>
<TOKEN end_char="897" id="token-6-11" morph="none" pos="punct" start_char="897">,</TOKEN>
<TOKEN end_char="899" id="token-6-12" morph="none" pos="word" start_char="899">o</TOKEN>
<TOKEN end_char="903" id="token-6-13" morph="none" pos="word" start_char="901">las</TOKEN>
<TOKEN end_char="914" id="token-6-14" morph="none" pos="word" start_char="905">excelentes</TOKEN>
<TOKEN end_char="916" id="token-6-15" morph="none" pos="word" start_char="916">y</TOKEN>
<TOKEN end_char="920" id="token-6-16" morph="none" pos="word" start_char="918">del</TOKEN>
<TOKEN end_char="929" id="token-6-17" morph="none" pos="word" start_char="922">material</TOKEN>
<TOKEN end_char="933" id="token-6-18" morph="none" pos="word" start_char="931">que</TOKEN>
<TOKEN end_char="939" id="token-6-19" morph="none" pos="word" start_char="935">fuera</TOKEN>
<TOKEN end_char="940" id="token-6-20" morph="none" pos="punct" start_char="940">,</TOKEN>
<TOKEN end_char="943" id="token-6-21" morph="none" pos="word" start_char="942">el</TOKEN>
<TOKEN end_char="952" id="token-6-22" morph="none" pos="word" start_char="945">gobierno</TOKEN>
<TOKEN end_char="960" id="token-6-23" morph="none" pos="word" start_char="954">debería</TOKEN>
<TOKEN end_char="961" id="token-6-24" morph="none" pos="punct" start_char="961">,</TOKEN>
<TOKEN end_char="966" id="token-6-25" morph="none" pos="word" start_char="963">Como</TOKEN>
<TOKEN end_char="969" id="token-6-26" morph="none" pos="word" start_char="968">ha</TOKEN>
<TOKEN end_char="975" id="token-6-27" morph="none" pos="word" start_char="971">hecho</TOKEN>
<TOKEN end_char="979" id="token-6-28" morph="none" pos="word" start_char="977">con</TOKEN>
<TOKEN end_char="985" id="token-6-29" morph="none" pos="word" start_char="981">otras</TOKEN>
<TOKEN end_char="996" id="token-6-30" morph="none" pos="word" start_char="987">cuestiones</TOKEN>
<TOKEN end_char="998" id="token-6-31" morph="none" pos="word" start_char="998">y</TOKEN>
<TOKEN end_char="1010" id="token-6-32" morph="none" pos="word" start_char="1000">actividades</TOKEN>
<TOKEN end_char="1011" id="token-6-33" morph="none" pos="punct" start_char="1011">,</TOKEN>
<TOKEN end_char="1016" id="token-6-34" morph="none" pos="word" start_char="1013">caso</TOKEN>
<TOKEN end_char="1027" id="token-6-35" morph="none" pos="word" start_char="1018">hospitales</TOKEN>
<TOKEN end_char="1030" id="token-6-36" morph="none" pos="word" start_char="1029">de</TOKEN>
<TOKEN end_char="1038" id="token-6-37" morph="none" pos="word" start_char="1032">campaña</TOKEN>
<TOKEN end_char="1039" id="token-6-38" morph="none" pos="punct" start_char="1039">,</TOKEN>
<TOKEN end_char="1045" id="token-6-39" morph="none" pos="word" start_char="1041">haber</TOKEN>
<TOKEN end_char="1052" id="token-6-40" morph="none" pos="word" start_char="1047">puesto</TOKEN>
<TOKEN end_char="1055" id="token-6-41" morph="none" pos="word" start_char="1054">la</TOKEN>
<TOKEN end_char="1063" id="token-6-42" morph="none" pos="word" start_char="1057">maquina</TOKEN>
<TOKEN end_char="1065" id="token-6-43" morph="none" pos="word" start_char="1065">y</TOKEN>
<TOKEN end_char="1069" id="token-6-44" morph="none" pos="word" start_char="1067">las</TOKEN>
<TOKEN end_char="1078" id="token-6-45" morph="none" pos="word" start_char="1071">empresas</TOKEN>
<TOKEN end_char="1080" id="token-6-46" morph="none" pos="word" start_char="1080">a</TOKEN>
<TOKEN end_char="1089" id="token-6-47" morph="none" pos="word" start_char="1082">fabricar</TOKEN>
<TOKEN end_char="1101" id="token-6-48" morph="none" pos="word" start_char="1091">mascarillas</TOKEN>
<TOKEN end_char="1103" id="token-6-49" morph="none" pos="word" start_char="1103">a</TOKEN>
<TOKEN end_char="1108" id="token-6-50" morph="none" pos="word" start_char="1105">todo</TOKEN>
<TOKEN end_char="1114" id="token-6-51" morph="none" pos="word" start_char="1110">trapo</TOKEN>
<TOKEN end_char="1115" id="token-6-52" morph="none" pos="punct" start_char="1115">.</TOKEN>
<TRANSLATED_TEXT>Whether it was the bad, the good, the very good, or the excellent and the material that was, the government should, as it has done with other issues and activities, in case of field hospitals, have put the machine and companies to make masquerades to every rag.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1139" id="segment-7" start_char="1117">
<ORIGINAL_TEXT>Por una sencilla razón.</ORIGINAL_TEXT>
<TOKEN end_char="1119" id="token-7-0" morph="none" pos="word" start_char="1117">Por</TOKEN>
<TOKEN end_char="1123" id="token-7-1" morph="none" pos="word" start_char="1121">una</TOKEN>
<TOKEN end_char="1132" id="token-7-2" morph="none" pos="word" start_char="1125">sencilla</TOKEN>
<TOKEN end_char="1138" id="token-7-3" morph="none" pos="word" start_char="1134">razón</TOKEN>
<TOKEN end_char="1139" id="token-7-4" morph="none" pos="punct" start_char="1139">.</TOKEN>
<TRANSLATED_TEXT>For a simple reason.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1167" id="segment-8" start_char="1141">
<ORIGINAL_TEXT>EL PRINCIPIO DE PROTECCIÓN.</ORIGINAL_TEXT>
<TOKEN end_char="1142" id="token-8-0" morph="none" pos="word" start_char="1141">EL</TOKEN>
<TOKEN end_char="1152" id="token-8-1" morph="none" pos="word" start_char="1144">PRINCIPIO</TOKEN>
<TOKEN end_char="1155" id="token-8-2" morph="none" pos="word" start_char="1154">DE</TOKEN>
<TOKEN end_char="1166" id="token-8-3" morph="none" pos="word" start_char="1157">PROTECCIÓN</TOKEN>
<TOKEN end_char="1167" id="token-8-4" morph="none" pos="punct" start_char="1167">.</TOKEN>
<TRANSLATED_TEXT>The Protection Principle.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="1196" id="segment-9" start_char="1169">
<ORIGINAL_TEXT>No las había de ningún tipo.</ORIGINAL_TEXT>
<TOKEN end_char="1170" id="token-9-0" morph="none" pos="word" start_char="1169">No</TOKEN>
<TOKEN end_char="1174" id="token-9-1" morph="none" pos="word" start_char="1172">las</TOKEN>
<TOKEN end_char="1180" id="token-9-2" morph="none" pos="word" start_char="1176">había</TOKEN>
<TOKEN end_char="1183" id="token-9-3" morph="none" pos="word" start_char="1182">de</TOKEN>
<TOKEN end_char="1190" id="token-9-4" morph="none" pos="word" start_char="1185">ningún</TOKEN>
<TOKEN end_char="1195" id="token-9-5" morph="none" pos="word" start_char="1192">tipo</TOKEN>
<TOKEN end_char="1196" id="token-9-6" morph="none" pos="punct" start_char="1196">.</TOKEN>
<TRANSLATED_TEXT>There were none.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1274" id="segment-10" start_char="1198">
<ORIGINAL_TEXT>Cuando llueve el paraguas no es obligatorio, pero lo usamos para no mojarnos.</ORIGINAL_TEXT>
<TOKEN end_char="1203" id="token-10-0" morph="none" pos="word" start_char="1198">Cuando</TOKEN>
<TOKEN end_char="1210" id="token-10-1" morph="none" pos="word" start_char="1205">llueve</TOKEN>
<TOKEN end_char="1213" id="token-10-2" morph="none" pos="word" start_char="1212">el</TOKEN>
<TOKEN end_char="1222" id="token-10-3" morph="none" pos="word" start_char="1215">paraguas</TOKEN>
<TOKEN end_char="1225" id="token-10-4" morph="none" pos="word" start_char="1224">no</TOKEN>
<TOKEN end_char="1228" id="token-10-5" morph="none" pos="word" start_char="1227">es</TOKEN>
<TOKEN end_char="1240" id="token-10-6" morph="none" pos="word" start_char="1230">obligatorio</TOKEN>
<TOKEN end_char="1241" id="token-10-7" morph="none" pos="punct" start_char="1241">,</TOKEN>
<TOKEN end_char="1246" id="token-10-8" morph="none" pos="word" start_char="1243">pero</TOKEN>
<TOKEN end_char="1249" id="token-10-9" morph="none" pos="word" start_char="1248">lo</TOKEN>
<TOKEN end_char="1256" id="token-10-10" morph="none" pos="word" start_char="1251">usamos</TOKEN>
<TOKEN end_char="1261" id="token-10-11" morph="none" pos="word" start_char="1258">para</TOKEN>
<TOKEN end_char="1264" id="token-10-12" morph="none" pos="word" start_char="1263">no</TOKEN>
<TOKEN end_char="1273" id="token-10-13" morph="none" pos="word" start_char="1266">mojarnos</TOKEN>
<TOKEN end_char="1274" id="token-10-14" morph="none" pos="punct" start_char="1274">.</TOKEN>
<TRANSLATED_TEXT>When it rains, the umbrella is not mandatory, but we use it to keep from getting wet.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1297" id="segment-11" start_char="1276">
<ORIGINAL_TEXT>Porqué no se ha hecho?</ORIGINAL_TEXT>
<TOKEN end_char="1281" id="token-11-0" morph="none" pos="word" start_char="1276">Porqué</TOKEN>
<TOKEN end_char="1284" id="token-11-1" morph="none" pos="word" start_char="1283">no</TOKEN>
<TOKEN end_char="1287" id="token-11-2" morph="none" pos="word" start_char="1286">se</TOKEN>
<TOKEN end_char="1290" id="token-11-3" morph="none" pos="word" start_char="1289">ha</TOKEN>
<TOKEN end_char="1296" id="token-11-4" morph="none" pos="word" start_char="1292">hecho</TOKEN>
<TOKEN end_char="1297" id="token-11-5" morph="none" pos="punct" start_char="1297">?</TOKEN>
<TRANSLATED_TEXT>Why hasn't it been done?</TRANSLATED_TEXT><DETECTED_LANGUAGE>pt</DETECTED_LANGUAGE></SEG>
<SEG end_char="1338" id="segment-12" start_char="1299">
<ORIGINAL_TEXT>O volvemos a lo de siempre y así nos va.</ORIGINAL_TEXT>
<TOKEN end_char="1299" id="token-12-0" morph="none" pos="word" start_char="1299">O</TOKEN>
<TOKEN end_char="1308" id="token-12-1" morph="none" pos="word" start_char="1301">volvemos</TOKEN>
<TOKEN end_char="1310" id="token-12-2" morph="none" pos="word" start_char="1310">a</TOKEN>
<TOKEN end_char="1313" id="token-12-3" morph="none" pos="word" start_char="1312">lo</TOKEN>
<TOKEN end_char="1316" id="token-12-4" morph="none" pos="word" start_char="1315">de</TOKEN>
<TOKEN end_char="1324" id="token-12-5" morph="none" pos="word" start_char="1318">siempre</TOKEN>
<TOKEN end_char="1326" id="token-12-6" morph="none" pos="word" start_char="1326">y</TOKEN>
<TOKEN end_char="1330" id="token-12-7" morph="none" pos="word" start_char="1328">así</TOKEN>
<TOKEN end_char="1334" id="token-12-8" morph="none" pos="word" start_char="1332">nos</TOKEN>
<TOKEN end_char="1337" id="token-12-9" morph="none" pos="word" start_char="1336">va</TOKEN>
<TOKEN end_char="1338" id="token-12-10" morph="none" pos="punct" start_char="1338">.</TOKEN>
<TRANSLATED_TEXT>Or we go back to normal and that's how it goes.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1365" id="segment-13" start_char="1340">
<ORIGINAL_TEXT>¡¡¡Qué fabriquen ellos !!!</ORIGINAL_TEXT>
<TOKEN end_char="1342" id="token-13-0" morph="none" pos="punct" start_char="1340">¡¡¡</TOKEN>
<TOKEN end_char="1345" id="token-13-1" morph="none" pos="word" start_char="1343">Qué</TOKEN>
<TOKEN end_char="1355" id="token-13-2" morph="none" pos="word" start_char="1347">fabriquen</TOKEN>
<TOKEN end_char="1361" id="token-13-3" morph="none" pos="word" start_char="1357">ellos</TOKEN>
<TOKEN end_char="1365" id="token-13-4" morph="none" pos="punct" start_char="1363">!!!</TOKEN>
<TRANSLATED_TEXT>What do they make!!!!</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="1377" id="segment-14" start_char="1367">
<ORIGINAL_TEXT>Así pienso.</ORIGINAL_TEXT>
<TOKEN end_char="1369" id="token-14-0" morph="none" pos="word" start_char="1367">Así</TOKEN>
<TOKEN end_char="1376" id="token-14-1" morph="none" pos="word" start_char="1371">pienso</TOKEN>
<TOKEN end_char="1377" id="token-14-2" morph="none" pos="punct" start_char="1377">.</TOKEN>
<TRANSLATED_TEXT>I think so.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1527" id="segment-15" start_char="1381">
<ORIGINAL_TEXT>La mejor de las noticias dsd q el virus llegó a España: el gobierno aprueba ESPECIFICACION UNE 0064-1:2020 Mascarillas higiénicas no reutilizables.</ORIGINAL_TEXT>
<TOKEN end_char="1382" id="token-15-0" morph="none" pos="word" start_char="1381">La</TOKEN>
<TOKEN end_char="1388" id="token-15-1" morph="none" pos="word" start_char="1384">mejor</TOKEN>
<TOKEN end_char="1391" id="token-15-2" morph="none" pos="word" start_char="1390">de</TOKEN>
<TOKEN end_char="1395" id="token-15-3" morph="none" pos="word" start_char="1393">las</TOKEN>
<TOKEN end_char="1404" id="token-15-4" morph="none" pos="word" start_char="1397">noticias</TOKEN>
<TOKEN end_char="1408" id="token-15-5" morph="none" pos="word" start_char="1406">dsd</TOKEN>
<TOKEN end_char="1410" id="token-15-6" morph="none" pos="word" start_char="1410">q</TOKEN>
<TOKEN end_char="1413" id="token-15-7" morph="none" pos="word" start_char="1412">el</TOKEN>
<TOKEN end_char="1419" id="token-15-8" morph="none" pos="word" start_char="1415">virus</TOKEN>
<TOKEN end_char="1425" id="token-15-9" morph="none" pos="word" start_char="1421">llegó</TOKEN>
<TOKEN end_char="1427" id="token-15-10" morph="none" pos="word" start_char="1427">a</TOKEN>
<TOKEN end_char="1434" id="token-15-11" morph="none" pos="word" start_char="1429">España</TOKEN>
<TOKEN end_char="1435" id="token-15-12" morph="none" pos="punct" start_char="1435">:</TOKEN>
<TOKEN end_char="1438" id="token-15-13" morph="none" pos="word" start_char="1437">el</TOKEN>
<TOKEN end_char="1447" id="token-15-14" morph="none" pos="word" start_char="1440">gobierno</TOKEN>
<TOKEN end_char="1455" id="token-15-15" morph="none" pos="word" start_char="1449">aprueba</TOKEN>
<TOKEN end_char="1470" id="token-15-16" morph="none" pos="word" start_char="1457">ESPECIFICACION</TOKEN>
<TOKEN end_char="1474" id="token-15-17" morph="none" pos="word" start_char="1472">UNE</TOKEN>
<TOKEN end_char="1486" id="token-15-18" morph="none" pos="unknown" start_char="1476">0064-1:2020</TOKEN>
<TOKEN end_char="1498" id="token-15-19" morph="none" pos="word" start_char="1488">Mascarillas</TOKEN>
<TOKEN end_char="1509" id="token-15-20" morph="none" pos="word" start_char="1500">higiénicas</TOKEN>
<TOKEN end_char="1512" id="token-15-21" morph="none" pos="word" start_char="1511">no</TOKEN>
<TOKEN end_char="1526" id="token-15-22" morph="none" pos="word" start_char="1514">reutilizables</TOKEN>
<TOKEN end_char="1527" id="token-15-23" morph="none" pos="punct" start_char="1527">.</TOKEN>
<TRANSLATED_TEXT>The best of the news dsd q the virus arrived in Spain: the government approves SPECIFICATION UNE 0064-1: 2020 Unreusable sanitary masks.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1588" id="segment-16" start_char="1529">
<ORIGINAL_TEXT>Requisitos de materiales, diseño, confección, marcado y uso.</ORIGINAL_TEXT>
<TOKEN end_char="1538" id="token-16-0" morph="none" pos="word" start_char="1529">Requisitos</TOKEN>
<TOKEN end_char="1541" id="token-16-1" morph="none" pos="word" start_char="1540">de</TOKEN>
<TOKEN end_char="1552" id="token-16-2" morph="none" pos="word" start_char="1543">materiales</TOKEN>
<TOKEN end_char="1553" id="token-16-3" morph="none" pos="punct" start_char="1553">,</TOKEN>
<TOKEN end_char="1560" id="token-16-4" morph="none" pos="word" start_char="1555">diseño</TOKEN>
<TOKEN end_char="1561" id="token-16-5" morph="none" pos="punct" start_char="1561">,</TOKEN>
<TOKEN end_char="1572" id="token-16-6" morph="none" pos="word" start_char="1563">confección</TOKEN>
<TOKEN end_char="1573" id="token-16-7" morph="none" pos="punct" start_char="1573">,</TOKEN>
<TOKEN end_char="1581" id="token-16-8" morph="none" pos="word" start_char="1575">marcado</TOKEN>
<TOKEN end_char="1583" id="token-16-9" morph="none" pos="word" start_char="1583">y</TOKEN>
<TOKEN end_char="1587" id="token-16-10" morph="none" pos="word" start_char="1585">uso</TOKEN>
<TOKEN end_char="1588" id="token-16-11" morph="none" pos="punct" start_char="1588">.</TOKEN>
<TRANSLATED_TEXT>Materials requirements, design, manufacture, marking and use.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1673" id="segment-17" start_char="1590">
<ORIGINAL_TEXT>Parte 1: Para uso en adultos para la generalización de su uso ESTAMOS DE ENHORABUENA</ORIGINAL_TEXT>
<TOKEN end_char="1594" id="token-17-0" morph="none" pos="word" start_char="1590">Parte</TOKEN>
<TOKEN end_char="1596" id="token-17-1" morph="none" pos="word" start_char="1596">1</TOKEN>
<TOKEN end_char="1597" id="token-17-2" morph="none" pos="punct" start_char="1597">:</TOKEN>
<TOKEN end_char="1602" id="token-17-3" morph="none" pos="word" start_char="1599">Para</TOKEN>
<TOKEN end_char="1606" id="token-17-4" morph="none" pos="word" start_char="1604">uso</TOKEN>
<TOKEN end_char="1609" id="token-17-5" morph="none" pos="word" start_char="1608">en</TOKEN>
<TOKEN end_char="1617" id="token-17-6" morph="none" pos="word" start_char="1611">adultos</TOKEN>
<TOKEN end_char="1622" id="token-17-7" morph="none" pos="word" start_char="1619">para</TOKEN>
<TOKEN end_char="1625" id="token-17-8" morph="none" pos="word" start_char="1624">la</TOKEN>
<TOKEN end_char="1640" id="token-17-9" morph="none" pos="word" start_char="1627">generalización</TOKEN>
<TOKEN end_char="1643" id="token-17-10" morph="none" pos="word" start_char="1642">de</TOKEN>
<TOKEN end_char="1646" id="token-17-11" morph="none" pos="word" start_char="1645">su</TOKEN>
<TOKEN end_char="1650" id="token-17-12" morph="none" pos="word" start_char="1648">uso</TOKEN>
<TOKEN end_char="1658" id="token-17-13" morph="none" pos="word" start_char="1652">ESTAMOS</TOKEN>
<TOKEN end_char="1661" id="token-17-14" morph="none" pos="word" start_char="1660">DE</TOKEN>
<TOKEN end_char="1673" id="token-17-15" morph="none" pos="word" start_char="1663">ENHORABUENA</TOKEN>
<TRANSLATED_TEXT>Part 1: For use in adults to generalize their use WE ARE ENHORABUEN</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2042" id="segment-18" start_char="1677">
<ORIGINAL_TEXT>La mascarilla si aunque sea un pañuelo y gafas y guantes, comprendo que la OMS y los gobiernos fueran cautos por la srncilla razon de que no había ni hay mascarillas para todo el mundo, yo cre que lo primero era asegurar que el personal sanitario las tuviera y asegurar que se evitaba el acaparamiento, aconsejando que cada uno se hiciera la suya, cosa nada dificil.</ORIGINAL_TEXT>
<TOKEN end_char="1678" id="token-18-0" morph="none" pos="word" start_char="1677">La</TOKEN>
<TOKEN end_char="1689" id="token-18-1" morph="none" pos="word" start_char="1680">mascarilla</TOKEN>
<TOKEN end_char="1692" id="token-18-2" morph="none" pos="word" start_char="1691">si</TOKEN>
<TOKEN end_char="1699" id="token-18-3" morph="none" pos="word" start_char="1694">aunque</TOKEN>
<TOKEN end_char="1703" id="token-18-4" morph="none" pos="word" start_char="1701">sea</TOKEN>
<TOKEN end_char="1706" id="token-18-5" morph="none" pos="word" start_char="1705">un</TOKEN>
<TOKEN end_char="1714" id="token-18-6" morph="none" pos="word" start_char="1708">pañuelo</TOKEN>
<TOKEN end_char="1716" id="token-18-7" morph="none" pos="word" start_char="1716">y</TOKEN>
<TOKEN end_char="1722" id="token-18-8" morph="none" pos="word" start_char="1718">gafas</TOKEN>
<TOKEN end_char="1724" id="token-18-9" morph="none" pos="word" start_char="1724">y</TOKEN>
<TOKEN end_char="1732" id="token-18-10" morph="none" pos="word" start_char="1726">guantes</TOKEN>
<TOKEN end_char="1733" id="token-18-11" morph="none" pos="punct" start_char="1733">,</TOKEN>
<TOKEN end_char="1743" id="token-18-12" morph="none" pos="word" start_char="1735">comprendo</TOKEN>
<TOKEN end_char="1747" id="token-18-13" morph="none" pos="word" start_char="1745">que</TOKEN>
<TOKEN end_char="1750" id="token-18-14" morph="none" pos="word" start_char="1749">la</TOKEN>
<TOKEN end_char="1754" id="token-18-15" morph="none" pos="word" start_char="1752">OMS</TOKEN>
<TOKEN end_char="1756" id="token-18-16" morph="none" pos="word" start_char="1756">y</TOKEN>
<TOKEN end_char="1760" id="token-18-17" morph="none" pos="word" start_char="1758">los</TOKEN>
<TOKEN end_char="1770" id="token-18-18" morph="none" pos="word" start_char="1762">gobiernos</TOKEN>
<TOKEN end_char="1777" id="token-18-19" morph="none" pos="word" start_char="1772">fueran</TOKEN>
<TOKEN end_char="1784" id="token-18-20" morph="none" pos="word" start_char="1779">cautos</TOKEN>
<TOKEN end_char="1788" id="token-18-21" morph="none" pos="word" start_char="1786">por</TOKEN>
<TOKEN end_char="1791" id="token-18-22" morph="none" pos="word" start_char="1790">la</TOKEN>
<TOKEN end_char="1800" id="token-18-23" morph="none" pos="word" start_char="1793">srncilla</TOKEN>
<TOKEN end_char="1806" id="token-18-24" morph="none" pos="word" start_char="1802">razon</TOKEN>
<TOKEN end_char="1809" id="token-18-25" morph="none" pos="word" start_char="1808">de</TOKEN>
<TOKEN end_char="1813" id="token-18-26" morph="none" pos="word" start_char="1811">que</TOKEN>
<TOKEN end_char="1816" id="token-18-27" morph="none" pos="word" start_char="1815">no</TOKEN>
<TOKEN end_char="1822" id="token-18-28" morph="none" pos="word" start_char="1818">había</TOKEN>
<TOKEN end_char="1825" id="token-18-29" morph="none" pos="word" start_char="1824">ni</TOKEN>
<TOKEN end_char="1829" id="token-18-30" morph="none" pos="word" start_char="1827">hay</TOKEN>
<TOKEN end_char="1841" id="token-18-31" morph="none" pos="word" start_char="1831">mascarillas</TOKEN>
<TOKEN end_char="1846" id="token-18-32" morph="none" pos="word" start_char="1843">para</TOKEN>
<TOKEN end_char="1851" id="token-18-33" morph="none" pos="word" start_char="1848">todo</TOKEN>
<TOKEN end_char="1854" id="token-18-34" morph="none" pos="word" start_char="1853">el</TOKEN>
<TOKEN end_char="1860" id="token-18-35" morph="none" pos="word" start_char="1856">mundo</TOKEN>
<TOKEN end_char="1861" id="token-18-36" morph="none" pos="punct" start_char="1861">,</TOKEN>
<TOKEN end_char="1864" id="token-18-37" morph="none" pos="word" start_char="1863">yo</TOKEN>
<TOKEN end_char="1868" id="token-18-38" morph="none" pos="word" start_char="1866">cre</TOKEN>
<TOKEN end_char="1872" id="token-18-39" morph="none" pos="word" start_char="1870">que</TOKEN>
<TOKEN end_char="1875" id="token-18-40" morph="none" pos="word" start_char="1874">lo</TOKEN>
<TOKEN end_char="1883" id="token-18-41" morph="none" pos="word" start_char="1877">primero</TOKEN>
<TOKEN end_char="1887" id="token-18-42" morph="none" pos="word" start_char="1885">era</TOKEN>
<TOKEN end_char="1896" id="token-18-43" morph="none" pos="word" start_char="1889">asegurar</TOKEN>
<TOKEN end_char="1900" id="token-18-44" morph="none" pos="word" start_char="1898">que</TOKEN>
<TOKEN end_char="1903" id="token-18-45" morph="none" pos="word" start_char="1902">el</TOKEN>
<TOKEN end_char="1912" id="token-18-46" morph="none" pos="word" start_char="1905">personal</TOKEN>
<TOKEN end_char="1922" id="token-18-47" morph="none" pos="word" start_char="1914">sanitario</TOKEN>
<TOKEN end_char="1926" id="token-18-48" morph="none" pos="word" start_char="1924">las</TOKEN>
<TOKEN end_char="1934" id="token-18-49" morph="none" pos="word" start_char="1928">tuviera</TOKEN>
<TOKEN end_char="1936" id="token-18-50" morph="none" pos="word" start_char="1936">y</TOKEN>
<TOKEN end_char="1945" id="token-18-51" morph="none" pos="word" start_char="1938">asegurar</TOKEN>
<TOKEN end_char="1949" id="token-18-52" morph="none" pos="word" start_char="1947">que</TOKEN>
<TOKEN end_char="1952" id="token-18-53" morph="none" pos="word" start_char="1951">se</TOKEN>
<TOKEN end_char="1960" id="token-18-54" morph="none" pos="word" start_char="1954">evitaba</TOKEN>
<TOKEN end_char="1963" id="token-18-55" morph="none" pos="word" start_char="1962">el</TOKEN>
<TOKEN end_char="1977" id="token-18-56" morph="none" pos="word" start_char="1965">acaparamiento</TOKEN>
<TOKEN end_char="1978" id="token-18-57" morph="none" pos="punct" start_char="1978">,</TOKEN>
<TOKEN end_char="1990" id="token-18-58" morph="none" pos="word" start_char="1980">aconsejando</TOKEN>
<TOKEN end_char="1994" id="token-18-59" morph="none" pos="word" start_char="1992">que</TOKEN>
<TOKEN end_char="1999" id="token-18-60" morph="none" pos="word" start_char="1996">cada</TOKEN>
<TOKEN end_char="2003" id="token-18-61" morph="none" pos="word" start_char="2001">uno</TOKEN>
<TOKEN end_char="2006" id="token-18-62" morph="none" pos="word" start_char="2005">se</TOKEN>
<TOKEN end_char="2014" id="token-18-63" morph="none" pos="word" start_char="2008">hiciera</TOKEN>
<TOKEN end_char="2017" id="token-18-64" morph="none" pos="word" start_char="2016">la</TOKEN>
<TOKEN end_char="2022" id="token-18-65" morph="none" pos="word" start_char="2019">suya</TOKEN>
<TOKEN end_char="2023" id="token-18-66" morph="none" pos="punct" start_char="2023">,</TOKEN>
<TOKEN end_char="2028" id="token-18-67" morph="none" pos="word" start_char="2025">cosa</TOKEN>
<TOKEN end_char="2033" id="token-18-68" morph="none" pos="word" start_char="2030">nada</TOKEN>
<TOKEN end_char="2041" id="token-18-69" morph="none" pos="word" start_char="2035">dificil</TOKEN>
<TOKEN end_char="2042" id="token-18-70" morph="none" pos="punct" start_char="2042">.</TOKEN>
<TRANSLATED_TEXT>The mask, if it is a handkerchief and glasses and gloves, I understand that the WHO and governments were cautious because there were no masks for everyone, I think the first thing was to ensure that health personnel had them and to ensure that hoarding was avoided, by advising everyone to do their own, which is not difficult.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2172" id="segment-19" start_char="2046">
<ORIGINAL_TEXT>Lo mejor suele coincidir con lo correcto... deberían reconocer su error, se equivocaron y punto ... hay que ponerse mascarilla.</ORIGINAL_TEXT>
<TOKEN end_char="2047" id="token-19-0" morph="none" pos="word" start_char="2046">Lo</TOKEN>
<TOKEN end_char="2053" id="token-19-1" morph="none" pos="word" start_char="2049">mejor</TOKEN>
<TOKEN end_char="2059" id="token-19-2" morph="none" pos="word" start_char="2055">suele</TOKEN>
<TOKEN end_char="2069" id="token-19-3" morph="none" pos="word" start_char="2061">coincidir</TOKEN>
<TOKEN end_char="2073" id="token-19-4" morph="none" pos="word" start_char="2071">con</TOKEN>
<TOKEN end_char="2076" id="token-19-5" morph="none" pos="word" start_char="2075">lo</TOKEN>
<TOKEN end_char="2085" id="token-19-6" morph="none" pos="word" start_char="2078">correcto</TOKEN>
<TOKEN end_char="2088" id="token-19-7" morph="none" pos="punct" start_char="2086">...</TOKEN>
<TOKEN end_char="2097" id="token-19-8" morph="none" pos="word" start_char="2090">deberían</TOKEN>
<TOKEN end_char="2107" id="token-19-9" morph="none" pos="word" start_char="2099">reconocer</TOKEN>
<TOKEN end_char="2110" id="token-19-10" morph="none" pos="word" start_char="2109">su</TOKEN>
<TOKEN end_char="2116" id="token-19-11" morph="none" pos="word" start_char="2112">error</TOKEN>
<TOKEN end_char="2117" id="token-19-12" morph="none" pos="punct" start_char="2117">,</TOKEN>
<TOKEN end_char="2120" id="token-19-13" morph="none" pos="word" start_char="2119">se</TOKEN>
<TOKEN end_char="2132" id="token-19-14" morph="none" pos="word" start_char="2122">equivocaron</TOKEN>
<TOKEN end_char="2134" id="token-19-15" morph="none" pos="word" start_char="2134">y</TOKEN>
<TOKEN end_char="2140" id="token-19-16" morph="none" pos="word" start_char="2136">punto</TOKEN>
<TOKEN end_char="2144" id="token-19-17" morph="none" pos="punct" start_char="2142">...</TOKEN>
<TOKEN end_char="2148" id="token-19-18" morph="none" pos="word" start_char="2146">hay</TOKEN>
<TOKEN end_char="2152" id="token-19-19" morph="none" pos="word" start_char="2150">que</TOKEN>
<TOKEN end_char="2160" id="token-19-20" morph="none" pos="word" start_char="2154">ponerse</TOKEN>
<TOKEN end_char="2171" id="token-19-21" morph="none" pos="word" start_char="2162">mascarilla</TOKEN>
<TOKEN end_char="2172" id="token-19-22" morph="none" pos="punct" start_char="2172">.</TOKEN>
<TRANSLATED_TEXT>The best usually coincides with the right... they should recognize their mistake, they were wrong and point... you have to put on a mask.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2250" id="segment-20" start_char="2175">
<ORIGINAL_TEXT>Todo esto que estáis montando dando vueltas al rollito de siempre apesta ...</ORIGINAL_TEXT>
<TOKEN end_char="2178" id="token-20-0" morph="none" pos="word" start_char="2175">Todo</TOKEN>
<TOKEN end_char="2183" id="token-20-1" morph="none" pos="word" start_char="2180">esto</TOKEN>
<TOKEN end_char="2187" id="token-20-2" morph="none" pos="word" start_char="2185">que</TOKEN>
<TOKEN end_char="2194" id="token-20-3" morph="none" pos="word" start_char="2189">estáis</TOKEN>
<TOKEN end_char="2203" id="token-20-4" morph="none" pos="word" start_char="2196">montando</TOKEN>
<TOKEN end_char="2209" id="token-20-5" morph="none" pos="word" start_char="2205">dando</TOKEN>
<TOKEN end_char="2217" id="token-20-6" morph="none" pos="word" start_char="2211">vueltas</TOKEN>
<TOKEN end_char="2220" id="token-20-7" morph="none" pos="word" start_char="2219">al</TOKEN>
<TOKEN end_char="2228" id="token-20-8" morph="none" pos="word" start_char="2222">rollito</TOKEN>
<TOKEN end_char="2231" id="token-20-9" morph="none" pos="word" start_char="2230">de</TOKEN>
<TOKEN end_char="2239" id="token-20-10" morph="none" pos="word" start_char="2233">siempre</TOKEN>
<TOKEN end_char="2246" id="token-20-11" morph="none" pos="word" start_char="2241">apesta</TOKEN>
<TOKEN end_char="2250" id="token-20-12" morph="none" pos="punct" start_char="2248">...</TOKEN>
<TRANSLATED_TEXT>All this stuff that you're riding around the wheel always sucks...</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2256" id="segment-21" start_char="2253">
<ORIGINAL_TEXT>P.D.</ORIGINAL_TEXT>
<TOKEN end_char="2255" id="token-21-0" morph="none" pos="unknown" start_char="2253">P.D</TOKEN>
<TOKEN end_char="2256" id="token-21-1" morph="none" pos="punct" start_char="2256">.</TOKEN>
</SEG>
<SEG end_char="2363" id="segment-22" start_char="2258">
<ORIGINAL_TEXT>: Siento haberme saltado mi cuarentena forera pero no lo he podido evitar ... vuelvo a mi silencio monacal</ORIGINAL_TEXT>
<TOKEN end_char="2258" id="token-22-0" morph="none" pos="punct" start_char="2258">:</TOKEN>
<TOKEN end_char="2265" id="token-22-1" morph="none" pos="word" start_char="2260">Siento</TOKEN>
<TOKEN end_char="2273" id="token-22-2" morph="none" pos="word" start_char="2267">haberme</TOKEN>
<TOKEN end_char="2281" id="token-22-3" morph="none" pos="word" start_char="2275">saltado</TOKEN>
<TOKEN end_char="2284" id="token-22-4" morph="none" pos="word" start_char="2283">mi</TOKEN>
<TOKEN end_char="2295" id="token-22-5" morph="none" pos="word" start_char="2286">cuarentena</TOKEN>
<TOKEN end_char="2302" id="token-22-6" morph="none" pos="word" start_char="2297">forera</TOKEN>
<TOKEN end_char="2307" id="token-22-7" morph="none" pos="word" start_char="2304">pero</TOKEN>
<TOKEN end_char="2310" id="token-22-8" morph="none" pos="word" start_char="2309">no</TOKEN>
<TOKEN end_char="2313" id="token-22-9" morph="none" pos="word" start_char="2312">lo</TOKEN>
<TOKEN end_char="2316" id="token-22-10" morph="none" pos="word" start_char="2315">he</TOKEN>
<TOKEN end_char="2323" id="token-22-11" morph="none" pos="word" start_char="2318">podido</TOKEN>
<TOKEN end_char="2330" id="token-22-12" morph="none" pos="word" start_char="2325">evitar</TOKEN>
<TOKEN end_char="2334" id="token-22-13" morph="none" pos="punct" start_char="2332">...</TOKEN>
<TOKEN end_char="2341" id="token-22-14" morph="none" pos="word" start_char="2336">vuelvo</TOKEN>
<TOKEN end_char="2343" id="token-22-15" morph="none" pos="word" start_char="2343">a</TOKEN>
<TOKEN end_char="2346" id="token-22-16" morph="none" pos="word" start_char="2345">mi</TOKEN>
<TOKEN end_char="2355" id="token-22-17" morph="none" pos="word" start_char="2348">silencio</TOKEN>
<TOKEN end_char="2363" id="token-22-18" morph="none" pos="word" start_char="2357">monacal</TOKEN>
<TRANSLATED_TEXT>: I'm sorry I skipped my quarantine but I couldn't help it... I return to my monastic silence</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2415" id="segment-23" start_char="2367">
<ORIGINAL_TEXT>Antes del cómo el Gobierno deberá aclarar el qué.</ORIGINAL_TEXT>
<TOKEN end_char="2371" id="token-23-0" morph="none" pos="word" start_char="2367">Antes</TOKEN>
<TOKEN end_char="2375" id="token-23-1" morph="none" pos="word" start_char="2373">del</TOKEN>
<TOKEN end_char="2380" id="token-23-2" morph="none" pos="word" start_char="2377">cómo</TOKEN>
<TOKEN end_char="2383" id="token-23-3" morph="none" pos="word" start_char="2382">el</TOKEN>
<TOKEN end_char="2392" id="token-23-4" morph="none" pos="word" start_char="2385">Gobierno</TOKEN>
<TOKEN end_char="2399" id="token-23-5" morph="none" pos="word" start_char="2394">deberá</TOKEN>
<TOKEN end_char="2407" id="token-23-6" morph="none" pos="word" start_char="2401">aclarar</TOKEN>
<TOKEN end_char="2410" id="token-23-7" morph="none" pos="word" start_char="2409">el</TOKEN>
<TOKEN end_char="2414" id="token-23-8" morph="none" pos="word" start_char="2412">qué</TOKEN>
<TOKEN end_char="2415" id="token-23-9" morph="none" pos="punct" start_char="2415">.</TOKEN>
<TRANSLATED_TEXT>Before the Government should clarify what.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2451" id="segment-24" start_char="2417">
<ORIGINAL_TEXT>Porque sigue sin haber mascarillas.</ORIGINAL_TEXT>
<TOKEN end_char="2422" id="token-24-0" morph="none" pos="word" start_char="2417">Porque</TOKEN>
<TOKEN end_char="2428" id="token-24-1" morph="none" pos="word" start_char="2424">sigue</TOKEN>
<TOKEN end_char="2432" id="token-24-2" morph="none" pos="word" start_char="2430">sin</TOKEN>
<TOKEN end_char="2438" id="token-24-3" morph="none" pos="word" start_char="2434">haber</TOKEN>
<TOKEN end_char="2450" id="token-24-4" morph="none" pos="word" start_char="2440">mascarillas</TOKEN>
<TOKEN end_char="2451" id="token-24-5" morph="none" pos="punct" start_char="2451">.</TOKEN>
<TRANSLATED_TEXT>Because there's still no masks.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2552" id="segment-25" start_char="2453">
<ORIGINAL_TEXT>Me pregunto quién fabrica nuestro papel, ya sea higiénico, de cocina o los folios para la impresora.</ORIGINAL_TEXT>
<TOKEN end_char="2454" id="token-25-0" morph="none" pos="word" start_char="2453">Me</TOKEN>
<TOKEN end_char="2463" id="token-25-1" morph="none" pos="word" start_char="2456">pregunto</TOKEN>
<TOKEN end_char="2469" id="token-25-2" morph="none" pos="word" start_char="2465">quién</TOKEN>
<TOKEN end_char="2477" id="token-25-3" morph="none" pos="word" start_char="2471">fabrica</TOKEN>
<TOKEN end_char="2485" id="token-25-4" morph="none" pos="word" start_char="2479">nuestro</TOKEN>
<TOKEN end_char="2491" id="token-25-5" morph="none" pos="word" start_char="2487">papel</TOKEN>
<TOKEN end_char="2492" id="token-25-6" morph="none" pos="punct" start_char="2492">,</TOKEN>
<TOKEN end_char="2495" id="token-25-7" morph="none" pos="word" start_char="2494">ya</TOKEN>
<TOKEN end_char="2499" id="token-25-8" morph="none" pos="word" start_char="2497">sea</TOKEN>
<TOKEN end_char="2509" id="token-25-9" morph="none" pos="word" start_char="2501">higiénico</TOKEN>
<TOKEN end_char="2510" id="token-25-10" morph="none" pos="punct" start_char="2510">,</TOKEN>
<TOKEN end_char="2513" id="token-25-11" morph="none" pos="word" start_char="2512">de</TOKEN>
<TOKEN end_char="2520" id="token-25-12" morph="none" pos="word" start_char="2515">cocina</TOKEN>
<TOKEN end_char="2522" id="token-25-13" morph="none" pos="word" start_char="2522">o</TOKEN>
<TOKEN end_char="2526" id="token-25-14" morph="none" pos="word" start_char="2524">los</TOKEN>
<TOKEN end_char="2533" id="token-25-15" morph="none" pos="word" start_char="2528">folios</TOKEN>
<TOKEN end_char="2538" id="token-25-16" morph="none" pos="word" start_char="2535">para</TOKEN>
<TOKEN end_char="2541" id="token-25-17" morph="none" pos="word" start_char="2540">la</TOKEN>
<TOKEN end_char="2551" id="token-25-18" morph="none" pos="word" start_char="2543">impresora</TOKEN>
<TOKEN end_char="2552" id="token-25-19" morph="none" pos="punct" start_char="2552">.</TOKEN>
<TRANSLATED_TEXT>I wonder who makes our paper, whether it's toilet, kitchen or the sheets for the printer.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2608" id="segment-26" start_char="2554">
<ORIGINAL_TEXT>Porque fabricar mascarillas no tiene mucha más ciencia.</ORIGINAL_TEXT>
<TOKEN end_char="2559" id="token-26-0" morph="none" pos="word" start_char="2554">Porque</TOKEN>
<TOKEN end_char="2568" id="token-26-1" morph="none" pos="word" start_char="2561">fabricar</TOKEN>
<TOKEN end_char="2580" id="token-26-2" morph="none" pos="word" start_char="2570">mascarillas</TOKEN>
<TOKEN end_char="2583" id="token-26-3" morph="none" pos="word" start_char="2582">no</TOKEN>
<TOKEN end_char="2589" id="token-26-4" morph="none" pos="word" start_char="2585">tiene</TOKEN>
<TOKEN end_char="2595" id="token-26-5" morph="none" pos="word" start_char="2591">mucha</TOKEN>
<TOKEN end_char="2599" id="token-26-6" morph="none" pos="word" start_char="2597">más</TOKEN>
<TOKEN end_char="2607" id="token-26-7" morph="none" pos="word" start_char="2601">ciencia</TOKEN>
<TOKEN end_char="2608" id="token-26-8" morph="none" pos="punct" start_char="2608">.</TOKEN>
<TRANSLATED_TEXT>Because making masks doesn 't have much more science.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2845" id="segment-27" start_char="2610">
<ORIGINAL_TEXT>O, ejem, quién fabrica los sostenes de las señoras (que, en caso de apuro, de uno viejo se pueden sacar dos mascarillas: ya lleva la goma puesta) que parecen más complicados que una mascarilla, por lo menos de las que no llevan válvula.</ORIGINAL_TEXT>
<TOKEN end_char="2610" id="token-27-0" morph="none" pos="word" start_char="2610">O</TOKEN>
<TOKEN end_char="2611" id="token-27-1" morph="none" pos="punct" start_char="2611">,</TOKEN>
<TOKEN end_char="2616" id="token-27-2" morph="none" pos="word" start_char="2613">ejem</TOKEN>
<TOKEN end_char="2617" id="token-27-3" morph="none" pos="punct" start_char="2617">,</TOKEN>
<TOKEN end_char="2623" id="token-27-4" morph="none" pos="word" start_char="2619">quién</TOKEN>
<TOKEN end_char="2631" id="token-27-5" morph="none" pos="word" start_char="2625">fabrica</TOKEN>
<TOKEN end_char="2635" id="token-27-6" morph="none" pos="word" start_char="2633">los</TOKEN>
<TOKEN end_char="2644" id="token-27-7" morph="none" pos="word" start_char="2637">sostenes</TOKEN>
<TOKEN end_char="2647" id="token-27-8" morph="none" pos="word" start_char="2646">de</TOKEN>
<TOKEN end_char="2651" id="token-27-9" morph="none" pos="word" start_char="2649">las</TOKEN>
<TOKEN end_char="2659" id="token-27-10" morph="none" pos="word" start_char="2653">señoras</TOKEN>
<TOKEN end_char="2661" id="token-27-11" morph="none" pos="punct" start_char="2661">(</TOKEN>
<TOKEN end_char="2664" id="token-27-12" morph="none" pos="word" start_char="2662">que</TOKEN>
<TOKEN end_char="2665" id="token-27-13" morph="none" pos="punct" start_char="2665">,</TOKEN>
<TOKEN end_char="2668" id="token-27-14" morph="none" pos="word" start_char="2667">en</TOKEN>
<TOKEN end_char="2673" id="token-27-15" morph="none" pos="word" start_char="2670">caso</TOKEN>
<TOKEN end_char="2676" id="token-27-16" morph="none" pos="word" start_char="2675">de</TOKEN>
<TOKEN end_char="2682" id="token-27-17" morph="none" pos="word" start_char="2678">apuro</TOKEN>
<TOKEN end_char="2683" id="token-27-18" morph="none" pos="punct" start_char="2683">,</TOKEN>
<TOKEN end_char="2686" id="token-27-19" morph="none" pos="word" start_char="2685">de</TOKEN>
<TOKEN end_char="2690" id="token-27-20" morph="none" pos="word" start_char="2688">uno</TOKEN>
<TOKEN end_char="2696" id="token-27-21" morph="none" pos="word" start_char="2692">viejo</TOKEN>
<TOKEN end_char="2699" id="token-27-22" morph="none" pos="word" start_char="2698">se</TOKEN>
<TOKEN end_char="2706" id="token-27-23" morph="none" pos="word" start_char="2701">pueden</TOKEN>
<TOKEN end_char="2712" id="token-27-24" morph="none" pos="word" start_char="2708">sacar</TOKEN>
<TOKEN end_char="2716" id="token-27-25" morph="none" pos="word" start_char="2714">dos</TOKEN>
<TOKEN end_char="2728" id="token-27-26" morph="none" pos="word" start_char="2718">mascarillas</TOKEN>
<TOKEN end_char="2729" id="token-27-27" morph="none" pos="punct" start_char="2729">:</TOKEN>
<TOKEN end_char="2732" id="token-27-28" morph="none" pos="word" start_char="2731">ya</TOKEN>
<TOKEN end_char="2738" id="token-27-29" morph="none" pos="word" start_char="2734">lleva</TOKEN>
<TOKEN end_char="2741" id="token-27-30" morph="none" pos="word" start_char="2740">la</TOKEN>
<TOKEN end_char="2746" id="token-27-31" morph="none" pos="word" start_char="2743">goma</TOKEN>
<TOKEN end_char="2753" id="token-27-32" morph="none" pos="word" start_char="2748">puesta</TOKEN>
<TOKEN end_char="2754" id="token-27-33" morph="none" pos="punct" start_char="2754">)</TOKEN>
<TOKEN end_char="2758" id="token-27-34" morph="none" pos="word" start_char="2756">que</TOKEN>
<TOKEN end_char="2766" id="token-27-35" morph="none" pos="word" start_char="2760">parecen</TOKEN>
<TOKEN end_char="2770" id="token-27-36" morph="none" pos="word" start_char="2768">más</TOKEN>
<TOKEN end_char="2782" id="token-27-37" morph="none" pos="word" start_char="2772">complicados</TOKEN>
<TOKEN end_char="2786" id="token-27-38" morph="none" pos="word" start_char="2784">que</TOKEN>
<TOKEN end_char="2790" id="token-27-39" morph="none" pos="word" start_char="2788">una</TOKEN>
<TOKEN end_char="2801" id="token-27-40" morph="none" pos="word" start_char="2792">mascarilla</TOKEN>
<TOKEN end_char="2802" id="token-27-41" morph="none" pos="punct" start_char="2802">,</TOKEN>
<TOKEN end_char="2806" id="token-27-42" morph="none" pos="word" start_char="2804">por</TOKEN>
<TOKEN end_char="2809" id="token-27-43" morph="none" pos="word" start_char="2808">lo</TOKEN>
<TOKEN end_char="2815" id="token-27-44" morph="none" pos="word" start_char="2811">menos</TOKEN>
<TOKEN end_char="2818" id="token-27-45" morph="none" pos="word" start_char="2817">de</TOKEN>
<TOKEN end_char="2822" id="token-27-46" morph="none" pos="word" start_char="2820">las</TOKEN>
<TOKEN end_char="2826" id="token-27-47" morph="none" pos="word" start_char="2824">que</TOKEN>
<TOKEN end_char="2829" id="token-27-48" morph="none" pos="word" start_char="2828">no</TOKEN>
<TOKEN end_char="2836" id="token-27-49" morph="none" pos="word" start_char="2831">llevan</TOKEN>
<TOKEN end_char="2844" id="token-27-50" morph="none" pos="word" start_char="2838">válvula</TOKEN>
<TOKEN end_char="2845" id="token-27-51" morph="none" pos="punct" start_char="2845">.</TOKEN>
<TRANSLATED_TEXT>Or, well, who makes the ladies' bras (which, in case of trouble, can take two masks from an old man: he already wears the rubber put on) that seem more complicated than a mask, at least those that don't carry a valve.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3053" id="segment-28" start_char="2847">
<ORIGINAL_TEXT>¿Pasa como con casi todo lo demás, que el papel de España se limita a poner un etiqueta con el nombre del importador pero, si busca uno con cuidado, al final encuentra que aquello está fabricado... en China?</ORIGINAL_TEXT>
<TOKEN end_char="2847" id="token-28-0" morph="none" pos="punct" start_char="2847">¿</TOKEN>
<TOKEN end_char="2851" id="token-28-1" morph="none" pos="word" start_char="2848">Pasa</TOKEN>
<TOKEN end_char="2856" id="token-28-2" morph="none" pos="word" start_char="2853">como</TOKEN>
<TOKEN end_char="2860" id="token-28-3" morph="none" pos="word" start_char="2858">con</TOKEN>
<TOKEN end_char="2865" id="token-28-4" morph="none" pos="word" start_char="2862">casi</TOKEN>
<TOKEN end_char="2870" id="token-28-5" morph="none" pos="word" start_char="2867">todo</TOKEN>
<TOKEN end_char="2873" id="token-28-6" morph="none" pos="word" start_char="2872">lo</TOKEN>
<TOKEN end_char="2879" id="token-28-7" morph="none" pos="word" start_char="2875">demás</TOKEN>
<TOKEN end_char="2880" id="token-28-8" morph="none" pos="punct" start_char="2880">,</TOKEN>
<TOKEN end_char="2884" id="token-28-9" morph="none" pos="word" start_char="2882">que</TOKEN>
<TOKEN end_char="2887" id="token-28-10" morph="none" pos="word" start_char="2886">el</TOKEN>
<TOKEN end_char="2893" id="token-28-11" morph="none" pos="word" start_char="2889">papel</TOKEN>
<TOKEN end_char="2896" id="token-28-12" morph="none" pos="word" start_char="2895">de</TOKEN>
<TOKEN end_char="2903" id="token-28-13" morph="none" pos="word" start_char="2898">España</TOKEN>
<TOKEN end_char="2906" id="token-28-14" morph="none" pos="word" start_char="2905">se</TOKEN>
<TOKEN end_char="2913" id="token-28-15" morph="none" pos="word" start_char="2908">limita</TOKEN>
<TOKEN end_char="2915" id="token-28-16" morph="none" pos="word" start_char="2915">a</TOKEN>
<TOKEN end_char="2921" id="token-28-17" morph="none" pos="word" start_char="2917">poner</TOKEN>
<TOKEN end_char="2924" id="token-28-18" morph="none" pos="word" start_char="2923">un</TOKEN>
<TOKEN end_char="2933" id="token-28-19" morph="none" pos="word" start_char="2926">etiqueta</TOKEN>
<TOKEN end_char="2937" id="token-28-20" morph="none" pos="word" start_char="2935">con</TOKEN>
<TOKEN end_char="2940" id="token-28-21" morph="none" pos="word" start_char="2939">el</TOKEN>
<TOKEN end_char="2947" id="token-28-22" morph="none" pos="word" start_char="2942">nombre</TOKEN>
<TOKEN end_char="2951" id="token-28-23" morph="none" pos="word" start_char="2949">del</TOKEN>
<TOKEN end_char="2962" id="token-28-24" morph="none" pos="word" start_char="2953">importador</TOKEN>
<TOKEN end_char="2967" id="token-28-25" morph="none" pos="word" start_char="2964">pero</TOKEN>
<TOKEN end_char="2968" id="token-28-26" morph="none" pos="punct" start_char="2968">,</TOKEN>
<TOKEN end_char="2971" id="token-28-27" morph="none" pos="word" start_char="2970">si</TOKEN>
<TOKEN end_char="2977" id="token-28-28" morph="none" pos="word" start_char="2973">busca</TOKEN>
<TOKEN end_char="2981" id="token-28-29" morph="none" pos="word" start_char="2979">uno</TOKEN>
<TOKEN end_char="2985" id="token-28-30" morph="none" pos="word" start_char="2983">con</TOKEN>
<TOKEN end_char="2993" id="token-28-31" morph="none" pos="word" start_char="2987">cuidado</TOKEN>
<TOKEN end_char="2994" id="token-28-32" morph="none" pos="punct" start_char="2994">,</TOKEN>
<TOKEN end_char="2997" id="token-28-33" morph="none" pos="word" start_char="2996">al</TOKEN>
<TOKEN end_char="3003" id="token-28-34" morph="none" pos="word" start_char="2999">final</TOKEN>
<TOKEN end_char="3013" id="token-28-35" morph="none" pos="word" start_char="3005">encuentra</TOKEN>
<TOKEN end_char="3017" id="token-28-36" morph="none" pos="word" start_char="3015">que</TOKEN>
<TOKEN end_char="3025" id="token-28-37" morph="none" pos="word" start_char="3019">aquello</TOKEN>
<TOKEN end_char="3030" id="token-28-38" morph="none" pos="word" start_char="3027">está</TOKEN>
<TOKEN end_char="3040" id="token-28-39" morph="none" pos="word" start_char="3032">fabricado</TOKEN>
<TOKEN end_char="3043" id="token-28-40" morph="none" pos="punct" start_char="3041">...</TOKEN>
<TOKEN end_char="3046" id="token-28-41" morph="none" pos="word" start_char="3045">en</TOKEN>
<TOKEN end_char="3052" id="token-28-42" morph="none" pos="word" start_char="3048">China</TOKEN>
<TOKEN end_char="3053" id="token-28-43" morph="none" pos="punct" start_char="3053">?</TOKEN>
<TRANSLATED_TEXT>Does it happen as with almost everything else, that the role of Spain is limited to putting a label with the name of the importer but, if you look carefully for one, in the end you find that that is manufactured... in China?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3164" id="segment-29" start_char="3057">
<ORIGINAL_TEXT>Hasta fechas muy recientes la OMS solo las recomendaba para los infectados y profesionales que los trataban.</ORIGINAL_TEXT>
<TOKEN end_char="3061" id="token-29-0" morph="none" pos="word" start_char="3057">Hasta</TOKEN>
<TOKEN end_char="3068" id="token-29-1" morph="none" pos="word" start_char="3063">fechas</TOKEN>
<TOKEN end_char="3072" id="token-29-2" morph="none" pos="word" start_char="3070">muy</TOKEN>
<TOKEN end_char="3082" id="token-29-3" morph="none" pos="word" start_char="3074">recientes</TOKEN>
<TOKEN end_char="3085" id="token-29-4" morph="none" pos="word" start_char="3084">la</TOKEN>
<TOKEN end_char="3089" id="token-29-5" morph="none" pos="word" start_char="3087">OMS</TOKEN>
<TOKEN end_char="3094" id="token-29-6" morph="none" pos="word" start_char="3091">solo</TOKEN>
<TOKEN end_char="3098" id="token-29-7" morph="none" pos="word" start_char="3096">las</TOKEN>
<TOKEN end_char="3110" id="token-29-8" morph="none" pos="word" start_char="3100">recomendaba</TOKEN>
<TOKEN end_char="3115" id="token-29-9" morph="none" pos="word" start_char="3112">para</TOKEN>
<TOKEN end_char="3119" id="token-29-10" morph="none" pos="word" start_char="3117">los</TOKEN>
<TOKEN end_char="3130" id="token-29-11" morph="none" pos="word" start_char="3121">infectados</TOKEN>
<TOKEN end_char="3132" id="token-29-12" morph="none" pos="word" start_char="3132">y</TOKEN>
<TOKEN end_char="3146" id="token-29-13" morph="none" pos="word" start_char="3134">profesionales</TOKEN>
<TOKEN end_char="3150" id="token-29-14" morph="none" pos="word" start_char="3148">que</TOKEN>
<TOKEN end_char="3154" id="token-29-15" morph="none" pos="word" start_char="3152">los</TOKEN>
<TOKEN end_char="3163" id="token-29-16" morph="none" pos="word" start_char="3156">trataban</TOKEN>
<TOKEN end_char="3164" id="token-29-17" morph="none" pos="punct" start_char="3164">.</TOKEN>
<TRANSLATED_TEXT>Until very recently, the WHO only recommended them for infected people and professionals who treated them.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3300" id="segment-30" start_char="3167">
<ORIGINAL_TEXT>Se trataría de limitar la difusión de las gotitas de Flügge expulsadas por los contaminados al estornudar, toser o simplemente hablar.</ORIGINAL_TEXT>
<TOKEN end_char="3168" id="token-30-0" morph="none" pos="word" start_char="3167">Se</TOKEN>
<TOKEN end_char="3177" id="token-30-1" morph="none" pos="word" start_char="3170">trataría</TOKEN>
<TOKEN end_char="3180" id="token-30-2" morph="none" pos="word" start_char="3179">de</TOKEN>
<TOKEN end_char="3188" id="token-30-3" morph="none" pos="word" start_char="3182">limitar</TOKEN>
<TOKEN end_char="3191" id="token-30-4" morph="none" pos="word" start_char="3190">la</TOKEN>
<TOKEN end_char="3200" id="token-30-5" morph="none" pos="word" start_char="3193">difusión</TOKEN>
<TOKEN end_char="3203" id="token-30-6" morph="none" pos="word" start_char="3202">de</TOKEN>
<TOKEN end_char="3207" id="token-30-7" morph="none" pos="word" start_char="3205">las</TOKEN>
<TOKEN end_char="3215" id="token-30-8" morph="none" pos="word" start_char="3209">gotitas</TOKEN>
<TOKEN end_char="3218" id="token-30-9" morph="none" pos="word" start_char="3217">de</TOKEN>
<TOKEN end_char="3225" id="token-30-10" morph="none" pos="word" start_char="3220">Flügge</TOKEN>
<TOKEN end_char="3236" id="token-30-11" morph="none" pos="word" start_char="3227">expulsadas</TOKEN>
<TOKEN end_char="3240" id="token-30-12" morph="none" pos="word" start_char="3238">por</TOKEN>
<TOKEN end_char="3244" id="token-30-13" morph="none" pos="word" start_char="3242">los</TOKEN>
<TOKEN end_char="3257" id="token-30-14" morph="none" pos="word" start_char="3246">contaminados</TOKEN>
<TOKEN end_char="3260" id="token-30-15" morph="none" pos="word" start_char="3259">al</TOKEN>
<TOKEN end_char="3271" id="token-30-16" morph="none" pos="word" start_char="3262">estornudar</TOKEN>
<TOKEN end_char="3272" id="token-30-17" morph="none" pos="punct" start_char="3272">,</TOKEN>
<TOKEN end_char="3278" id="token-30-18" morph="none" pos="word" start_char="3274">toser</TOKEN>
<TOKEN end_char="3280" id="token-30-19" morph="none" pos="word" start_char="3280">o</TOKEN>
<TOKEN end_char="3292" id="token-30-20" morph="none" pos="word" start_char="3282">simplemente</TOKEN>
<TOKEN end_char="3299" id="token-30-21" morph="none" pos="word" start_char="3294">hablar</TOKEN>
<TOKEN end_char="3300" id="token-30-22" morph="none" pos="punct" start_char="3300">.</TOKEN>
<TRANSLATED_TEXT>It would try to limit the spread of Flügge droplets expelled by the contaminated ones by sneezing, coughing or simply speaking.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3516" id="segment-31" start_char="3303">
<ORIGINAL_TEXT>Y es que las mascarillas más restrictivas (FFP3) que deben filtrar hasta el 99% de partículas de hasta 0,6 micras (0,006 milímetros) dejarían pasar sin problemas el Covid-19 cuyo diámetro es de 0,000130 milímetros.</ORIGINAL_TEXT>
<TOKEN end_char="3303" id="token-31-0" morph="none" pos="word" start_char="3303">Y</TOKEN>
<TOKEN end_char="3306" id="token-31-1" morph="none" pos="word" start_char="3305">es</TOKEN>
<TOKEN end_char="3310" id="token-31-2" morph="none" pos="word" start_char="3308">que</TOKEN>
<TOKEN end_char="3314" id="token-31-3" morph="none" pos="word" start_char="3312">las</TOKEN>
<TOKEN end_char="3326" id="token-31-4" morph="none" pos="word" start_char="3316">mascarillas</TOKEN>
<TOKEN end_char="3330" id="token-31-5" morph="none" pos="word" start_char="3328">más</TOKEN>
<TOKEN end_char="3343" id="token-31-6" morph="none" pos="word" start_char="3332">restrictivas</TOKEN>
<TOKEN end_char="3345" id="token-31-7" morph="none" pos="punct" start_char="3345">(</TOKEN>
<TOKEN end_char="3349" id="token-31-8" morph="none" pos="word" start_char="3346">FFP3</TOKEN>
<TOKEN end_char="3350" id="token-31-9" morph="none" pos="punct" start_char="3350">)</TOKEN>
<TOKEN end_char="3354" id="token-31-10" morph="none" pos="word" start_char="3352">que</TOKEN>
<TOKEN end_char="3360" id="token-31-11" morph="none" pos="word" start_char="3356">deben</TOKEN>
<TOKEN end_char="3368" id="token-31-12" morph="none" pos="word" start_char="3362">filtrar</TOKEN>
<TOKEN end_char="3374" id="token-31-13" morph="none" pos="word" start_char="3370">hasta</TOKEN>
<TOKEN end_char="3377" id="token-31-14" morph="none" pos="word" start_char="3376">el</TOKEN>
<TOKEN end_char="3380" id="token-31-15" morph="none" pos="word" start_char="3379">99</TOKEN>
<TOKEN end_char="3381" id="token-31-16" morph="none" pos="punct" start_char="3381">%</TOKEN>
<TOKEN end_char="3384" id="token-31-17" morph="none" pos="word" start_char="3383">de</TOKEN>
<TOKEN end_char="3395" id="token-31-18" morph="none" pos="word" start_char="3386">partículas</TOKEN>
<TOKEN end_char="3398" id="token-31-19" morph="none" pos="word" start_char="3397">de</TOKEN>
<TOKEN end_char="3404" id="token-31-20" morph="none" pos="word" start_char="3400">hasta</TOKEN>
<TOKEN end_char="3408" id="token-31-21" morph="none" pos="unknown" start_char="3406">0,6</TOKEN>
<TOKEN end_char="3415" id="token-31-22" morph="none" pos="word" start_char="3410">micras</TOKEN>
<TOKEN end_char="3417" id="token-31-23" morph="none" pos="punct" start_char="3417">(</TOKEN>
<TOKEN end_char="3422" id="token-31-24" morph="none" pos="unknown" start_char="3418">0,006</TOKEN>
<TOKEN end_char="3433" id="token-31-25" morph="none" pos="word" start_char="3424">milímetros</TOKEN>
<TOKEN end_char="3434" id="token-31-26" morph="none" pos="punct" start_char="3434">)</TOKEN>
<TOKEN end_char="3443" id="token-31-27" morph="none" pos="word" start_char="3436">dejarían</TOKEN>
<TOKEN end_char="3449" id="token-31-28" morph="none" pos="word" start_char="3445">pasar</TOKEN>
<TOKEN end_char="3453" id="token-31-29" morph="none" pos="word" start_char="3451">sin</TOKEN>
<TOKEN end_char="3463" id="token-31-30" morph="none" pos="word" start_char="3455">problemas</TOKEN>
<TOKEN end_char="3466" id="token-31-31" morph="none" pos="word" start_char="3465">el</TOKEN>
<TOKEN end_char="3475" id="token-31-32" morph="none" pos="unknown" start_char="3468">Covid-19</TOKEN>
<TOKEN end_char="3480" id="token-31-33" morph="none" pos="word" start_char="3477">cuyo</TOKEN>
<TOKEN end_char="3489" id="token-31-34" morph="none" pos="word" start_char="3482">diámetro</TOKEN>
<TOKEN end_char="3492" id="token-31-35" morph="none" pos="word" start_char="3491">es</TOKEN>
<TOKEN end_char="3495" id="token-31-36" morph="none" pos="word" start_char="3494">de</TOKEN>
<TOKEN end_char="3504" id="token-31-37" morph="none" pos="unknown" start_char="3497">0,000130</TOKEN>
<TOKEN end_char="3515" id="token-31-38" morph="none" pos="word" start_char="3506">milímetros</TOKEN>
<TOKEN end_char="3516" id="token-31-39" morph="none" pos="punct" start_char="3516">.</TOKEN>
<TRANSLATED_TEXT>And it is that the more restrictive masks (FFP3) that must filter up to 99% of particles up to 0.6 µm (0.006 mm) would let through the Covid-19 with a diameter of 0.000130 mm.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="3884" id="segment-32" start_char="3519">
<ORIGINAL_TEXT>No se puede pues culpar a la OMS o los gobiernos de seguir sus dictados ya que se postulaba que serían las gotitas de Flügge, que se depositarían en las manos o en las superficies y objetos de alrededor, los principales agentes de transmisión y las mascarillas, en ningún caso podrían atrapar un virus, que es órdenes de magnitud más pequeño que su alcance efectivo.</ORIGINAL_TEXT>
<TOKEN end_char="3520" id="token-32-0" morph="none" pos="word" start_char="3519">No</TOKEN>
<TOKEN end_char="3523" id="token-32-1" morph="none" pos="word" start_char="3522">se</TOKEN>
<TOKEN end_char="3529" id="token-32-2" morph="none" pos="word" start_char="3525">puede</TOKEN>
<TOKEN end_char="3534" id="token-32-3" morph="none" pos="word" start_char="3531">pues</TOKEN>
<TOKEN end_char="3541" id="token-32-4" morph="none" pos="word" start_char="3536">culpar</TOKEN>
<TOKEN end_char="3543" id="token-32-5" morph="none" pos="word" start_char="3543">a</TOKEN>
<TOKEN end_char="3546" id="token-32-6" morph="none" pos="word" start_char="3545">la</TOKEN>
<TOKEN end_char="3550" id="token-32-7" morph="none" pos="word" start_char="3548">OMS</TOKEN>
<TOKEN end_char="3552" id="token-32-8" morph="none" pos="word" start_char="3552">o</TOKEN>
<TOKEN end_char="3556" id="token-32-9" morph="none" pos="word" start_char="3554">los</TOKEN>
<TOKEN end_char="3566" id="token-32-10" morph="none" pos="word" start_char="3558">gobiernos</TOKEN>
<TOKEN end_char="3569" id="token-32-11" morph="none" pos="word" start_char="3568">de</TOKEN>
<TOKEN end_char="3576" id="token-32-12" morph="none" pos="word" start_char="3571">seguir</TOKEN>
<TOKEN end_char="3580" id="token-32-13" morph="none" pos="word" start_char="3578">sus</TOKEN>
<TOKEN end_char="3589" id="token-32-14" morph="none" pos="word" start_char="3582">dictados</TOKEN>
<TOKEN end_char="3592" id="token-32-15" morph="none" pos="word" start_char="3591">ya</TOKEN>
<TOKEN end_char="3596" id="token-32-16" morph="none" pos="word" start_char="3594">que</TOKEN>
<TOKEN end_char="3599" id="token-32-17" morph="none" pos="word" start_char="3598">se</TOKEN>
<TOKEN end_char="3609" id="token-32-18" morph="none" pos="word" start_char="3601">postulaba</TOKEN>
<TOKEN end_char="3613" id="token-32-19" morph="none" pos="word" start_char="3611">que</TOKEN>
<TOKEN end_char="3620" id="token-32-20" morph="none" pos="word" start_char="3615">serían</TOKEN>
<TOKEN end_char="3624" id="token-32-21" morph="none" pos="word" start_char="3622">las</TOKEN>
<TOKEN end_char="3632" id="token-32-22" morph="none" pos="word" start_char="3626">gotitas</TOKEN>
<TOKEN end_char="3635" id="token-32-23" morph="none" pos="word" start_char="3634">de</TOKEN>
<TOKEN end_char="3642" id="token-32-24" morph="none" pos="word" start_char="3637">Flügge</TOKEN>
<TOKEN end_char="3643" id="token-32-25" morph="none" pos="punct" start_char="3643">,</TOKEN>
<TOKEN end_char="3647" id="token-32-26" morph="none" pos="word" start_char="3645">que</TOKEN>
<TOKEN end_char="3650" id="token-32-27" morph="none" pos="word" start_char="3649">se</TOKEN>
<TOKEN end_char="3663" id="token-32-28" morph="none" pos="word" start_char="3652">depositarían</TOKEN>
<TOKEN end_char="3666" id="token-32-29" morph="none" pos="word" start_char="3665">en</TOKEN>
<TOKEN end_char="3670" id="token-32-30" morph="none" pos="word" start_char="3668">las</TOKEN>
<TOKEN end_char="3676" id="token-32-31" morph="none" pos="word" start_char="3672">manos</TOKEN>
<TOKEN end_char="3678" id="token-32-32" morph="none" pos="word" start_char="3678">o</TOKEN>
<TOKEN end_char="3681" id="token-32-33" morph="none" pos="word" start_char="3680">en</TOKEN>
<TOKEN end_char="3685" id="token-32-34" morph="none" pos="word" start_char="3683">las</TOKEN>
<TOKEN end_char="3697" id="token-32-35" morph="none" pos="word" start_char="3687">superficies</TOKEN>
<TOKEN end_char="3699" id="token-32-36" morph="none" pos="word" start_char="3699">y</TOKEN>
<TOKEN end_char="3707" id="token-32-37" morph="none" pos="word" start_char="3701">objetos</TOKEN>
<TOKEN end_char="3710" id="token-32-38" morph="none" pos="word" start_char="3709">de</TOKEN>
<TOKEN end_char="3720" id="token-32-39" morph="none" pos="word" start_char="3712">alrededor</TOKEN>
<TOKEN end_char="3721" id="token-32-40" morph="none" pos="punct" start_char="3721">,</TOKEN>
<TOKEN end_char="3725" id="token-32-41" morph="none" pos="word" start_char="3723">los</TOKEN>
<TOKEN end_char="3737" id="token-32-42" morph="none" pos="word" start_char="3727">principales</TOKEN>
<TOKEN end_char="3745" id="token-32-43" morph="none" pos="word" start_char="3739">agentes</TOKEN>
<TOKEN end_char="3748" id="token-32-44" morph="none" pos="word" start_char="3747">de</TOKEN>
<TOKEN end_char="3760" id="token-32-45" morph="none" pos="word" start_char="3750">transmisión</TOKEN>
<TOKEN end_char="3762" id="token-32-46" morph="none" pos="word" start_char="3762">y</TOKEN>
<TOKEN end_char="3766" id="token-32-47" morph="none" pos="word" start_char="3764">las</TOKEN>
<TOKEN end_char="3778" id="token-32-48" morph="none" pos="word" start_char="3768">mascarillas</TOKEN>
<TOKEN end_char="3779" id="token-32-49" morph="none" pos="punct" start_char="3779">,</TOKEN>
<TOKEN end_char="3782" id="token-32-50" morph="none" pos="word" start_char="3781">en</TOKEN>
<TOKEN end_char="3789" id="token-32-51" morph="none" pos="word" start_char="3784">ningún</TOKEN>
<TOKEN end_char="3794" id="token-32-52" morph="none" pos="word" start_char="3791">caso</TOKEN>
<TOKEN end_char="3802" id="token-32-53" morph="none" pos="word" start_char="3796">podrían</TOKEN>
<TOKEN end_char="3810" id="token-32-54" morph="none" pos="word" start_char="3804">atrapar</TOKEN>
<TOKEN end_char="3813" id="token-32-55" morph="none" pos="word" start_char="3812">un</TOKEN>
<TOKEN end_char="3819" id="token-32-56" morph="none" pos="word" start_char="3815">virus</TOKEN>
<TOKEN end_char="3820" id="token-32-57" morph="none" pos="punct" start_char="3820">,</TOKEN>
<TOKEN end_char="3824" id="token-32-58" morph="none" pos="word" start_char="3822">que</TOKEN>
<TOKEN end_char="3827" id="token-32-59" morph="none" pos="word" start_char="3826">es</TOKEN>
<TOKEN end_char="3835" id="token-32-60" morph="none" pos="word" start_char="3829">órdenes</TOKEN>
<TOKEN end_char="3838" id="token-32-61" morph="none" pos="word" start_char="3837">de</TOKEN>
<TOKEN end_char="3847" id="token-32-62" morph="none" pos="word" start_char="3840">magnitud</TOKEN>
<TOKEN end_char="3851" id="token-32-63" morph="none" pos="word" start_char="3849">más</TOKEN>
<TOKEN end_char="3859" id="token-32-64" morph="none" pos="word" start_char="3853">pequeño</TOKEN>
<TOKEN end_char="3863" id="token-32-65" morph="none" pos="word" start_char="3861">que</TOKEN>
<TOKEN end_char="3866" id="token-32-66" morph="none" pos="word" start_char="3865">su</TOKEN>
<TOKEN end_char="3874" id="token-32-67" morph="none" pos="word" start_char="3868">alcance</TOKEN>
<TOKEN end_char="3883" id="token-32-68" morph="none" pos="word" start_char="3876">efectivo</TOKEN>
<TOKEN end_char="3884" id="token-32-69" morph="none" pos="punct" start_char="3884">.</TOKEN>
<TRANSLATED_TEXT>The WHO or governments cannot therefore be blamed for following their dictates, as it was postulated that they would be Flügge droplets, which would be deposited in the hands or on the surfaces and objects around them, the main transmission agents, and the masks, in no case could catch a virus, which is orders of magnitude smaller than its effective range.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4322" id="segment-33" start_char="3887">
<ORIGINAL_TEXT>Pero, en el aire que respiramos hay en suspensión una ingente cantidad de partículas contaminantes de tamaños mucho mayores que los virus y sería casi imposible que en ellas no se depositasen virus como el Covid-19 cuya latencia vendría dada por el tipo de partícula, temperatura y humedad relativa y cuya efectividad de contagio sería mayor cuanto mayor fuera la partícula, ya que en partículas grandes se depositaría más carga vírica.</ORIGINAL_TEXT>
<TOKEN end_char="3890" id="token-33-0" morph="none" pos="word" start_char="3887">Pero</TOKEN>
<TOKEN end_char="3891" id="token-33-1" morph="none" pos="punct" start_char="3891">,</TOKEN>
<TOKEN end_char="3894" id="token-33-2" morph="none" pos="word" start_char="3893">en</TOKEN>
<TOKEN end_char="3897" id="token-33-3" morph="none" pos="word" start_char="3896">el</TOKEN>
<TOKEN end_char="3902" id="token-33-4" morph="none" pos="word" start_char="3899">aire</TOKEN>
<TOKEN end_char="3906" id="token-33-5" morph="none" pos="word" start_char="3904">que</TOKEN>
<TOKEN end_char="3917" id="token-33-6" morph="none" pos="word" start_char="3908">respiramos</TOKEN>
<TOKEN end_char="3921" id="token-33-7" morph="none" pos="word" start_char="3919">hay</TOKEN>
<TOKEN end_char="3924" id="token-33-8" morph="none" pos="word" start_char="3923">en</TOKEN>
<TOKEN end_char="3935" id="token-33-9" morph="none" pos="word" start_char="3926">suspensión</TOKEN>
<TOKEN end_char="3939" id="token-33-10" morph="none" pos="word" start_char="3937">una</TOKEN>
<TOKEN end_char="3947" id="token-33-11" morph="none" pos="word" start_char="3941">ingente</TOKEN>
<TOKEN end_char="3956" id="token-33-12" morph="none" pos="word" start_char="3949">cantidad</TOKEN>
<TOKEN end_char="3959" id="token-33-13" morph="none" pos="word" start_char="3958">de</TOKEN>
<TOKEN end_char="3970" id="token-33-14" morph="none" pos="word" start_char="3961">partículas</TOKEN>
<TOKEN end_char="3984" id="token-33-15" morph="none" pos="word" start_char="3972">contaminantes</TOKEN>
<TOKEN end_char="3987" id="token-33-16" morph="none" pos="word" start_char="3986">de</TOKEN>
<TOKEN end_char="3995" id="token-33-17" morph="none" pos="word" start_char="3989">tamaños</TOKEN>
<TOKEN end_char="4001" id="token-33-18" morph="none" pos="word" start_char="3997">mucho</TOKEN>
<TOKEN end_char="4009" id="token-33-19" morph="none" pos="word" start_char="4003">mayores</TOKEN>
<TOKEN end_char="4013" id="token-33-20" morph="none" pos="word" start_char="4011">que</TOKEN>
<TOKEN end_char="4017" id="token-33-21" morph="none" pos="word" start_char="4015">los</TOKEN>
<TOKEN end_char="4023" id="token-33-22" morph="none" pos="word" start_char="4019">virus</TOKEN>
<TOKEN end_char="4025" id="token-33-23" morph="none" pos="word" start_char="4025">y</TOKEN>
<TOKEN end_char="4031" id="token-33-24" morph="none" pos="word" start_char="4027">sería</TOKEN>
<TOKEN end_char="4036" id="token-33-25" morph="none" pos="word" start_char="4033">casi</TOKEN>
<TOKEN end_char="4046" id="token-33-26" morph="none" pos="word" start_char="4038">imposible</TOKEN>
<TOKEN end_char="4050" id="token-33-27" morph="none" pos="word" start_char="4048">que</TOKEN>
<TOKEN end_char="4053" id="token-33-28" morph="none" pos="word" start_char="4052">en</TOKEN>
<TOKEN end_char="4059" id="token-33-29" morph="none" pos="word" start_char="4055">ellas</TOKEN>
<TOKEN end_char="4062" id="token-33-30" morph="none" pos="word" start_char="4061">no</TOKEN>
<TOKEN end_char="4065" id="token-33-31" morph="none" pos="word" start_char="4064">se</TOKEN>
<TOKEN end_char="4077" id="token-33-32" morph="none" pos="word" start_char="4067">depositasen</TOKEN>
<TOKEN end_char="4083" id="token-33-33" morph="none" pos="word" start_char="4079">virus</TOKEN>
<TOKEN end_char="4088" id="token-33-34" morph="none" pos="word" start_char="4085">como</TOKEN>
<TOKEN end_char="4091" id="token-33-35" morph="none" pos="word" start_char="4090">el</TOKEN>
<TOKEN end_char="4100" id="token-33-36" morph="none" pos="unknown" start_char="4093">Covid-19</TOKEN>
<TOKEN end_char="4105" id="token-33-37" morph="none" pos="word" start_char="4102">cuya</TOKEN>
<TOKEN end_char="4114" id="token-33-38" morph="none" pos="word" start_char="4107">latencia</TOKEN>
<TOKEN end_char="4122" id="token-33-39" morph="none" pos="word" start_char="4116">vendría</TOKEN>
<TOKEN end_char="4127" id="token-33-40" morph="none" pos="word" start_char="4124">dada</TOKEN>
<TOKEN end_char="4131" id="token-33-41" morph="none" pos="word" start_char="4129">por</TOKEN>
<TOKEN end_char="4134" id="token-33-42" morph="none" pos="word" start_char="4133">el</TOKEN>
<TOKEN end_char="4139" id="token-33-43" morph="none" pos="word" start_char="4136">tipo</TOKEN>
<TOKEN end_char="4142" id="token-33-44" morph="none" pos="word" start_char="4141">de</TOKEN>
<TOKEN end_char="4152" id="token-33-45" morph="none" pos="word" start_char="4144">partícula</TOKEN>
<TOKEN end_char="4153" id="token-33-46" morph="none" pos="punct" start_char="4153">,</TOKEN>
<TOKEN end_char="4165" id="token-33-47" morph="none" pos="word" start_char="4155">temperatura</TOKEN>
<TOKEN end_char="4167" id="token-33-48" morph="none" pos="word" start_char="4167">y</TOKEN>
<TOKEN end_char="4175" id="token-33-49" morph="none" pos="word" start_char="4169">humedad</TOKEN>
<TOKEN end_char="4184" id="token-33-50" morph="none" pos="word" start_char="4177">relativa</TOKEN>
<TOKEN end_char="4186" id="token-33-51" morph="none" pos="word" start_char="4186">y</TOKEN>
<TOKEN end_char="4191" id="token-33-52" morph="none" pos="word" start_char="4188">cuya</TOKEN>
<TOKEN end_char="4203" id="token-33-53" morph="none" pos="word" start_char="4193">efectividad</TOKEN>
<TOKEN end_char="4206" id="token-33-54" morph="none" pos="word" start_char="4205">de</TOKEN>
<TOKEN end_char="4215" id="token-33-55" morph="none" pos="word" start_char="4208">contagio</TOKEN>
<TOKEN end_char="4221" id="token-33-56" morph="none" pos="word" start_char="4217">sería</TOKEN>
<TOKEN end_char="4227" id="token-33-57" morph="none" pos="word" start_char="4223">mayor</TOKEN>
<TOKEN end_char="4234" id="token-33-58" morph="none" pos="word" start_char="4229">cuanto</TOKEN>
<TOKEN end_char="4240" id="token-33-59" morph="none" pos="word" start_char="4236">mayor</TOKEN>
<TOKEN end_char="4246" id="token-33-60" morph="none" pos="word" start_char="4242">fuera</TOKEN>
<TOKEN end_char="4249" id="token-33-61" morph="none" pos="word" start_char="4248">la</TOKEN>
<TOKEN end_char="4259" id="token-33-62" morph="none" pos="word" start_char="4251">partícula</TOKEN>
<TOKEN end_char="4260" id="token-33-63" morph="none" pos="punct" start_char="4260">,</TOKEN>
<TOKEN end_char="4263" id="token-33-64" morph="none" pos="word" start_char="4262">ya</TOKEN>
<TOKEN end_char="4267" id="token-33-65" morph="none" pos="word" start_char="4265">que</TOKEN>
<TOKEN end_char="4270" id="token-33-66" morph="none" pos="word" start_char="4269">en</TOKEN>
<TOKEN end_char="4281" id="token-33-67" morph="none" pos="word" start_char="4272">partículas</TOKEN>
<TOKEN end_char="4289" id="token-33-68" morph="none" pos="word" start_char="4283">grandes</TOKEN>
<TOKEN end_char="4292" id="token-33-69" morph="none" pos="word" start_char="4291">se</TOKEN>
<TOKEN end_char="4304" id="token-33-70" morph="none" pos="word" start_char="4294">depositaría</TOKEN>
<TOKEN end_char="4308" id="token-33-71" morph="none" pos="word" start_char="4306">más</TOKEN>
<TOKEN end_char="4314" id="token-33-72" morph="none" pos="word" start_char="4310">carga</TOKEN>
<TOKEN end_char="4321" id="token-33-73" morph="none" pos="word" start_char="4316">vírica</TOKEN>
<TOKEN end_char="4322" id="token-33-74" morph="none" pos="punct" start_char="4322">.</TOKEN>
<TRANSLATED_TEXT>However, in the air we breathe there is a huge amount of pollutants in suspension of much larger sizes than viruses, and it would be almost impossible for viruses like Covid-19 not to be deposited in them, whose latency would be due to particle type, temperature and relative humidity, and whose contagion effectiveness would be greater the larger the particle, since larger particles would deposit more viral charge.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4612" id="segment-34" start_char="4325">
<ORIGINAL_TEXT>Así, mascarillas que en teoría NO podrían servir para proteger de un virus que las atravesaría con facilidad por su tamaño, se mostrarían MUY ÚTILES para atrapar una carga viral, que es en realidad transportada por partículas contaminantes que si atrapan y neutralizarían las mascarillas.</ORIGINAL_TEXT>
<TOKEN end_char="4327" id="token-34-0" morph="none" pos="word" start_char="4325">Así</TOKEN>
<TOKEN end_char="4328" id="token-34-1" morph="none" pos="punct" start_char="4328">,</TOKEN>
<TOKEN end_char="4340" id="token-34-2" morph="none" pos="word" start_char="4330">mascarillas</TOKEN>
<TOKEN end_char="4344" id="token-34-3" morph="none" pos="word" start_char="4342">que</TOKEN>
<TOKEN end_char="4347" id="token-34-4" morph="none" pos="word" start_char="4346">en</TOKEN>
<TOKEN end_char="4354" id="token-34-5" morph="none" pos="word" start_char="4349">teoría</TOKEN>
<TOKEN end_char="4357" id="token-34-6" morph="none" pos="word" start_char="4356">NO</TOKEN>
<TOKEN end_char="4365" id="token-34-7" morph="none" pos="word" start_char="4359">podrían</TOKEN>
<TOKEN end_char="4372" id="token-34-8" morph="none" pos="word" start_char="4367">servir</TOKEN>
<TOKEN end_char="4377" id="token-34-9" morph="none" pos="word" start_char="4374">para</TOKEN>
<TOKEN end_char="4386" id="token-34-10" morph="none" pos="word" start_char="4379">proteger</TOKEN>
<TOKEN end_char="4389" id="token-34-11" morph="none" pos="word" start_char="4388">de</TOKEN>
<TOKEN end_char="4392" id="token-34-12" morph="none" pos="word" start_char="4391">un</TOKEN>
<TOKEN end_char="4398" id="token-34-13" morph="none" pos="word" start_char="4394">virus</TOKEN>
<TOKEN end_char="4402" id="token-34-14" morph="none" pos="word" start_char="4400">que</TOKEN>
<TOKEN end_char="4406" id="token-34-15" morph="none" pos="word" start_char="4404">las</TOKEN>
<TOKEN end_char="4418" id="token-34-16" morph="none" pos="word" start_char="4408">atravesaría</TOKEN>
<TOKEN end_char="4422" id="token-34-17" morph="none" pos="word" start_char="4420">con</TOKEN>
<TOKEN end_char="4432" id="token-34-18" morph="none" pos="word" start_char="4424">facilidad</TOKEN>
<TOKEN end_char="4436" id="token-34-19" morph="none" pos="word" start_char="4434">por</TOKEN>
<TOKEN end_char="4439" id="token-34-20" morph="none" pos="word" start_char="4438">su</TOKEN>
<TOKEN end_char="4446" id="token-34-21" morph="none" pos="word" start_char="4441">tamaño</TOKEN>
<TOKEN end_char="4447" id="token-34-22" morph="none" pos="punct" start_char="4447">,</TOKEN>
<TOKEN end_char="4450" id="token-34-23" morph="none" pos="word" start_char="4449">se</TOKEN>
<TOKEN end_char="4461" id="token-34-24" morph="none" pos="word" start_char="4452">mostrarían</TOKEN>
<TOKEN end_char="4465" id="token-34-25" morph="none" pos="word" start_char="4463">MUY</TOKEN>
<TOKEN end_char="4472" id="token-34-26" morph="none" pos="word" start_char="4467">ÚTILES</TOKEN>
<TOKEN end_char="4477" id="token-34-27" morph="none" pos="word" start_char="4474">para</TOKEN>
<TOKEN end_char="4485" id="token-34-28" morph="none" pos="word" start_char="4479">atrapar</TOKEN>
<TOKEN end_char="4489" id="token-34-29" morph="none" pos="word" start_char="4487">una</TOKEN>
<TOKEN end_char="4495" id="token-34-30" morph="none" pos="word" start_char="4491">carga</TOKEN>
<TOKEN end_char="4501" id="token-34-31" morph="none" pos="word" start_char="4497">viral</TOKEN>
<TOKEN end_char="4502" id="token-34-32" morph="none" pos="punct" start_char="4502">,</TOKEN>
<TOKEN end_char="4506" id="token-34-33" morph="none" pos="word" start_char="4504">que</TOKEN>
<TOKEN end_char="4509" id="token-34-34" morph="none" pos="word" start_char="4508">es</TOKEN>
<TOKEN end_char="4512" id="token-34-35" morph="none" pos="word" start_char="4511">en</TOKEN>
<TOKEN end_char="4521" id="token-34-36" morph="none" pos="word" start_char="4514">realidad</TOKEN>
<TOKEN end_char="4534" id="token-34-37" morph="none" pos="word" start_char="4523">transportada</TOKEN>
<TOKEN end_char="4538" id="token-34-38" morph="none" pos="word" start_char="4536">por</TOKEN>
<TOKEN end_char="4549" id="token-34-39" morph="none" pos="word" start_char="4540">partículas</TOKEN>
<TOKEN end_char="4563" id="token-34-40" morph="none" pos="word" start_char="4551">contaminantes</TOKEN>
<TOKEN end_char="4567" id="token-34-41" morph="none" pos="word" start_char="4565">que</TOKEN>
<TOKEN end_char="4570" id="token-34-42" morph="none" pos="word" start_char="4569">si</TOKEN>
<TOKEN end_char="4578" id="token-34-43" morph="none" pos="word" start_char="4572">atrapan</TOKEN>
<TOKEN end_char="4580" id="token-34-44" morph="none" pos="word" start_char="4580">y</TOKEN>
<TOKEN end_char="4595" id="token-34-45" morph="none" pos="word" start_char="4582">neutralizarían</TOKEN>
<TOKEN end_char="4599" id="token-34-46" morph="none" pos="word" start_char="4597">las</TOKEN>
<TOKEN end_char="4611" id="token-34-47" morph="none" pos="word" start_char="4601">mascarillas</TOKEN>
<TOKEN end_char="4612" id="token-34-48" morph="none" pos="punct" start_char="4612">.</TOKEN>
<TRANSLATED_TEXT>Thus, masks that in theory could not be used to protect against a virus that would easily penetrate them by their size, would be shown USE to catch a viral load, which is actually transported by polluting particles that if they were to trap and neutralize the masks.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4942" id="segment-35" start_char="4615">
<ORIGINAL_TEXT>De aquí se podrían extraer 3 conclusiones: 1ª.- No sería cierto que 3 metros sea distancia de seguridad, 2ª.- que incluso mascarillas de confección artesanal podrían ser efectivas y 3ª.-que sería conveniente desecharlas o desinfectarlas (con lejía por ejemplo) con frecuencia, porque podrían acumular una peligrosa carga vírica.</ORIGINAL_TEXT>
<TOKEN end_char="4616" id="token-35-0" morph="none" pos="word" start_char="4615">De</TOKEN>
<TOKEN end_char="4621" id="token-35-1" morph="none" pos="word" start_char="4618">aquí</TOKEN>
<TOKEN end_char="4624" id="token-35-2" morph="none" pos="word" start_char="4623">se</TOKEN>
<TOKEN end_char="4632" id="token-35-3" morph="none" pos="word" start_char="4626">podrían</TOKEN>
<TOKEN end_char="4640" id="token-35-4" morph="none" pos="word" start_char="4634">extraer</TOKEN>
<TOKEN end_char="4642" id="token-35-5" morph="none" pos="word" start_char="4642">3</TOKEN>
<TOKEN end_char="4655" id="token-35-6" morph="none" pos="word" start_char="4644">conclusiones</TOKEN>
<TOKEN end_char="4656" id="token-35-7" morph="none" pos="punct" start_char="4656">:</TOKEN>
<TOKEN end_char="4659" id="token-35-8" morph="none" pos="word" start_char="4658">1ª</TOKEN>
<TOKEN end_char="4661" id="token-35-9" morph="none" pos="punct" start_char="4660">.-</TOKEN>
<TOKEN end_char="4664" id="token-35-10" morph="none" pos="word" start_char="4663">No</TOKEN>
<TOKEN end_char="4670" id="token-35-11" morph="none" pos="word" start_char="4666">sería</TOKEN>
<TOKEN end_char="4677" id="token-35-12" morph="none" pos="word" start_char="4672">cierto</TOKEN>
<TOKEN end_char="4681" id="token-35-13" morph="none" pos="word" start_char="4679">que</TOKEN>
<TOKEN end_char="4683" id="token-35-14" morph="none" pos="word" start_char="4683">3</TOKEN>
<TOKEN end_char="4690" id="token-35-15" morph="none" pos="word" start_char="4685">metros</TOKEN>
<TOKEN end_char="4694" id="token-35-16" morph="none" pos="word" start_char="4692">sea</TOKEN>
<TOKEN end_char="4704" id="token-35-17" morph="none" pos="word" start_char="4696">distancia</TOKEN>
<TOKEN end_char="4707" id="token-35-18" morph="none" pos="word" start_char="4706">de</TOKEN>
<TOKEN end_char="4717" id="token-35-19" morph="none" pos="word" start_char="4709">seguridad</TOKEN>
<TOKEN end_char="4718" id="token-35-20" morph="none" pos="punct" start_char="4718">,</TOKEN>
<TOKEN end_char="4721" id="token-35-21" morph="none" pos="word" start_char="4720">2ª</TOKEN>
<TOKEN end_char="4723" id="token-35-22" morph="none" pos="punct" start_char="4722">.-</TOKEN>
<TOKEN end_char="4727" id="token-35-23" morph="none" pos="word" start_char="4725">que</TOKEN>
<TOKEN end_char="4735" id="token-35-24" morph="none" pos="word" start_char="4729">incluso</TOKEN>
<TOKEN end_char="4747" id="token-35-25" morph="none" pos="word" start_char="4737">mascarillas</TOKEN>
<TOKEN end_char="4750" id="token-35-26" morph="none" pos="word" start_char="4749">de</TOKEN>
<TOKEN end_char="4761" id="token-35-27" morph="none" pos="word" start_char="4752">confección</TOKEN>
<TOKEN end_char="4771" id="token-35-28" morph="none" pos="word" start_char="4763">artesanal</TOKEN>
<TOKEN end_char="4779" id="token-35-29" morph="none" pos="word" start_char="4773">podrían</TOKEN>
<TOKEN end_char="4783" id="token-35-30" morph="none" pos="word" start_char="4781">ser</TOKEN>
<TOKEN end_char="4793" id="token-35-31" morph="none" pos="word" start_char="4785">efectivas</TOKEN>
<TOKEN end_char="4795" id="token-35-32" morph="none" pos="word" start_char="4795">y</TOKEN>
<TOKEN end_char="4803" id="token-35-33" morph="none" pos="unknown" start_char="4797">3ª.-que</TOKEN>
<TOKEN end_char="4809" id="token-35-34" morph="none" pos="word" start_char="4805">sería</TOKEN>
<TOKEN end_char="4821" id="token-35-35" morph="none" pos="word" start_char="4811">conveniente</TOKEN>
<TOKEN end_char="4833" id="token-35-36" morph="none" pos="word" start_char="4823">desecharlas</TOKEN>
<TOKEN end_char="4835" id="token-35-37" morph="none" pos="word" start_char="4835">o</TOKEN>
<TOKEN end_char="4850" id="token-35-38" morph="none" pos="word" start_char="4837">desinfectarlas</TOKEN>
<TOKEN end_char="4852" id="token-35-39" morph="none" pos="punct" start_char="4852">(</TOKEN>
<TOKEN end_char="4855" id="token-35-40" morph="none" pos="word" start_char="4853">con</TOKEN>
<TOKEN end_char="4861" id="token-35-41" morph="none" pos="word" start_char="4857">lejía</TOKEN>
<TOKEN end_char="4865" id="token-35-42" morph="none" pos="word" start_char="4863">por</TOKEN>
<TOKEN end_char="4873" id="token-35-43" morph="none" pos="word" start_char="4867">ejemplo</TOKEN>
<TOKEN end_char="4874" id="token-35-44" morph="none" pos="punct" start_char="4874">)</TOKEN>
<TOKEN end_char="4878" id="token-35-45" morph="none" pos="word" start_char="4876">con</TOKEN>
<TOKEN end_char="4889" id="token-35-46" morph="none" pos="word" start_char="4880">frecuencia</TOKEN>
<TOKEN end_char="4890" id="token-35-47" morph="none" pos="punct" start_char="4890">,</TOKEN>
<TOKEN end_char="4897" id="token-35-48" morph="none" pos="word" start_char="4892">porque</TOKEN>
<TOKEN end_char="4905" id="token-35-49" morph="none" pos="word" start_char="4899">podrían</TOKEN>
<TOKEN end_char="4914" id="token-35-50" morph="none" pos="word" start_char="4907">acumular</TOKEN>
<TOKEN end_char="4918" id="token-35-51" morph="none" pos="word" start_char="4916">una</TOKEN>
<TOKEN end_char="4928" id="token-35-52" morph="none" pos="word" start_char="4920">peligrosa</TOKEN>
<TOKEN end_char="4934" id="token-35-53" morph="none" pos="word" start_char="4930">carga</TOKEN>
<TOKEN end_char="4941" id="token-35-54" morph="none" pos="word" start_char="4936">vírica</TOKEN>
<TOKEN end_char="4942" id="token-35-55" morph="none" pos="punct" start_char="4942">.</TOKEN>
<TRANSLATED_TEXT>Three conclusions could be drawn from this: 1.- it would not be true that 3 metres is a safety distance, 2.- that even handmade clothing masks could be effective, and 3.- it would be convenient to discard or disinfect them (for example) frequently, because they could accumulate a dangerous viral load.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4953" id="segment-36" start_char="4945">
<ORIGINAL_TEXT>Responder</ORIGINAL_TEXT>
<TOKEN end_char="4953" id="token-36-0" morph="none" pos="word" start_char="4945">Responder</TOKEN>
</SEG>
<SEG end_char="4975" id="segment-37" start_char="4956">
<ORIGINAL_TEXT>Denunciar comentario</ORIGINAL_TEXT>
<TOKEN end_char="4964" id="token-37-0" morph="none" pos="word" start_char="4956">Denunciar</TOKEN>
<TOKEN end_char="4975" id="token-37-1" morph="none" pos="word" start_char="4966">comentario</TOKEN>
<TRANSLATED_TEXT>Deny comment</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="4997" id="segment-38" start_char="4978">
<ORIGINAL_TEXT>Ocultar 4 Respuestas</ORIGINAL_TEXT>
<TOKEN end_char="4984" id="token-38-0" morph="none" pos="word" start_char="4978">Ocultar</TOKEN>
<TOKEN end_char="4986" id="token-38-1" morph="none" pos="word" start_char="4986">4</TOKEN>
<TOKEN end_char="4997" id="token-38-2" morph="none" pos="word" start_char="4988">Respuestas</TOKEN>
<TRANSLATED_TEXT>Hide 4 Answers</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5000" id="segment-39" start_char="5000">
<ORIGINAL_TEXT>1</ORIGINAL_TEXT>
<TOKEN end_char="5000" id="token-39-0" morph="none" pos="word" start_char="5000">1</TOKEN>
</SEG>
<SEG end_char="5003" id="segment-40" start_char="5003">
<ORIGINAL_TEXT>2</ORIGINAL_TEXT>
<TOKEN end_char="5003" id="token-40-0" morph="none" pos="word" start_char="5003">2</TOKEN>
</SEG>
<SEG end_char="5012" id="segment-41" start_char="5006">
<ORIGINAL_TEXT>Cambris</ORIGINAL_TEXT>
<TOKEN end_char="5012" id="token-41-0" morph="none" pos="word" start_char="5006">Cambris</TOKEN>
<TRANSLATED_TEXT>CAMBRIS</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="5028" id="segment-42" start_char="5015">
<ORIGINAL_TEXT>09/04/20 12:07</ORIGINAL_TEXT>
<TOKEN end_char="5022" id="token-42-0" morph="none" pos="unknown" start_char="5015">09/04/20</TOKEN>
<TOKEN end_char="5028" id="token-42-1" morph="none" pos="unknown" start_char="5024">12:07</TOKEN>
<TRANSLATED_TEXT>09 / 04 / 20 12: 07</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="5111" id="segment-43" start_char="5031">
<ORIGINAL_TEXT>La OMS sigue diciendo q solo para personas contagiadas y para quienes las cuiden.</ORIGINAL_TEXT>
<TOKEN end_char="5032" id="token-43-0" morph="none" pos="word" start_char="5031">La</TOKEN>
<TOKEN end_char="5036" id="token-43-1" morph="none" pos="word" start_char="5034">OMS</TOKEN>
<TOKEN end_char="5042" id="token-43-2" morph="none" pos="word" start_char="5038">sigue</TOKEN>
<TOKEN end_char="5051" id="token-43-3" morph="none" pos="word" start_char="5044">diciendo</TOKEN>
<TOKEN end_char="5053" id="token-43-4" morph="none" pos="word" start_char="5053">q</TOKEN>
<TOKEN end_char="5058" id="token-43-5" morph="none" pos="word" start_char="5055">solo</TOKEN>
<TOKEN end_char="5063" id="token-43-6" morph="none" pos="word" start_char="5060">para</TOKEN>
<TOKEN end_char="5072" id="token-43-7" morph="none" pos="word" start_char="5065">personas</TOKEN>
<TOKEN end_char="5084" id="token-43-8" morph="none" pos="word" start_char="5074">contagiadas</TOKEN>
<TOKEN end_char="5086" id="token-43-9" morph="none" pos="word" start_char="5086">y</TOKEN>
<TOKEN end_char="5091" id="token-43-10" morph="none" pos="word" start_char="5088">para</TOKEN>
<TOKEN end_char="5099" id="token-43-11" morph="none" pos="word" start_char="5093">quienes</TOKEN>
<TOKEN end_char="5103" id="token-43-12" morph="none" pos="word" start_char="5101">las</TOKEN>
<TOKEN end_char="5110" id="token-43-13" morph="none" pos="word" start_char="5105">cuiden</TOKEN>
<TOKEN end_char="5111" id="token-43-14" morph="none" pos="punct" start_char="5111">.</TOKEN>
<TRANSLATED_TEXT>WHO continues to say q only for infected people and those who care for them.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5195" id="segment-44" start_char="5113">
<ORIGINAL_TEXT>Al menos hasta ayer, a pesar de que lógicamente reducen el Ro, número reproductivo.</ORIGINAL_TEXT>
<TOKEN end_char="5114" id="token-44-0" morph="none" pos="word" start_char="5113">Al</TOKEN>
<TOKEN end_char="5120" id="token-44-1" morph="none" pos="word" start_char="5116">menos</TOKEN>
<TOKEN end_char="5126" id="token-44-2" morph="none" pos="word" start_char="5122">hasta</TOKEN>
<TOKEN end_char="5131" id="token-44-3" morph="none" pos="word" start_char="5128">ayer</TOKEN>
<TOKEN end_char="5132" id="token-44-4" morph="none" pos="punct" start_char="5132">,</TOKEN>
<TOKEN end_char="5134" id="token-44-5" morph="none" pos="word" start_char="5134">a</TOKEN>
<TOKEN end_char="5140" id="token-44-6" morph="none" pos="word" start_char="5136">pesar</TOKEN>
<TOKEN end_char="5143" id="token-44-7" morph="none" pos="word" start_char="5142">de</TOKEN>
<TOKEN end_char="5147" id="token-44-8" morph="none" pos="word" start_char="5145">que</TOKEN>
<TOKEN end_char="5159" id="token-44-9" morph="none" pos="word" start_char="5149">lógicamente</TOKEN>
<TOKEN end_char="5167" id="token-44-10" morph="none" pos="word" start_char="5161">reducen</TOKEN>
<TOKEN end_char="5170" id="token-44-11" morph="none" pos="word" start_char="5169">el</TOKEN>
<TOKEN end_char="5173" id="token-44-12" morph="none" pos="word" start_char="5172">Ro</TOKEN>
<TOKEN end_char="5174" id="token-44-13" morph="none" pos="punct" start_char="5174">,</TOKEN>
<TOKEN end_char="5181" id="token-44-14" morph="none" pos="word" start_char="5176">número</TOKEN>
<TOKEN end_char="5194" id="token-44-15" morph="none" pos="word" start_char="5183">reproductivo</TOKEN>
<TOKEN end_char="5195" id="token-44-16" morph="none" pos="punct" start_char="5195">.</TOKEN>
<TRANSLATED_TEXT>At least until yesterday, although they logically reduce the Ro, reproductive number.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5272" id="segment-45" start_char="5197">
<ORIGINAL_TEXT>Ese Ro parece q es igual a 3: cada persona contagiada contagia a otras tres.</ORIGINAL_TEXT>
<TOKEN end_char="5199" id="token-45-0" morph="none" pos="word" start_char="5197">Ese</TOKEN>
<TOKEN end_char="5202" id="token-45-1" morph="none" pos="word" start_char="5201">Ro</TOKEN>
<TOKEN end_char="5209" id="token-45-2" morph="none" pos="word" start_char="5204">parece</TOKEN>
<TOKEN end_char="5211" id="token-45-3" morph="none" pos="word" start_char="5211">q</TOKEN>
<TOKEN end_char="5214" id="token-45-4" morph="none" pos="word" start_char="5213">es</TOKEN>
<TOKEN end_char="5220" id="token-45-5" morph="none" pos="word" start_char="5216">igual</TOKEN>
<TOKEN end_char="5222" id="token-45-6" morph="none" pos="word" start_char="5222">a</TOKEN>
<TOKEN end_char="5224" id="token-45-7" morph="none" pos="word" start_char="5224">3</TOKEN>
<TOKEN end_char="5225" id="token-45-8" morph="none" pos="punct" start_char="5225">:</TOKEN>
<TOKEN end_char="5230" id="token-45-9" morph="none" pos="word" start_char="5227">cada</TOKEN>
<TOKEN end_char="5238" id="token-45-10" morph="none" pos="word" start_char="5232">persona</TOKEN>
<TOKEN end_char="5249" id="token-45-11" morph="none" pos="word" start_char="5240">contagiada</TOKEN>
<TOKEN end_char="5258" id="token-45-12" morph="none" pos="word" start_char="5251">contagia</TOKEN>
<TOKEN end_char="5260" id="token-45-13" morph="none" pos="word" start_char="5260">a</TOKEN>
<TOKEN end_char="5266" id="token-45-14" morph="none" pos="word" start_char="5262">otras</TOKEN>
<TOKEN end_char="5271" id="token-45-15" morph="none" pos="word" start_char="5268">tres</TOKEN>
<TOKEN end_char="5272" id="token-45-16" morph="none" pos="punct" start_char="5272">.</TOKEN>
<TRANSLATED_TEXT>That Ro looks like q is equal to 3: each infected person infects three others.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5356" id="segment-46" start_char="5274">
<ORIGINAL_TEXT>Generalizar el uso de mascarilla lógicamente hace disminuir el número reproductivo.</ORIGINAL_TEXT>
<TOKEN end_char="5284" id="token-46-0" morph="none" pos="word" start_char="5274">Generalizar</TOKEN>
<TOKEN end_char="5287" id="token-46-1" morph="none" pos="word" start_char="5286">el</TOKEN>
<TOKEN end_char="5291" id="token-46-2" morph="none" pos="word" start_char="5289">uso</TOKEN>
<TOKEN end_char="5294" id="token-46-3" morph="none" pos="word" start_char="5293">de</TOKEN>
<TOKEN end_char="5305" id="token-46-4" morph="none" pos="word" start_char="5296">mascarilla</TOKEN>
<TOKEN end_char="5317" id="token-46-5" morph="none" pos="word" start_char="5307">lógicamente</TOKEN>
<TOKEN end_char="5322" id="token-46-6" morph="none" pos="word" start_char="5319">hace</TOKEN>
<TOKEN end_char="5332" id="token-46-7" morph="none" pos="word" start_char="5324">disminuir</TOKEN>
<TOKEN end_char="5335" id="token-46-8" morph="none" pos="word" start_char="5334">el</TOKEN>
<TOKEN end_char="5342" id="token-46-9" morph="none" pos="word" start_char="5337">número</TOKEN>
<TOKEN end_char="5355" id="token-46-10" morph="none" pos="word" start_char="5344">reproductivo</TOKEN>
<TOKEN end_char="5356" id="token-46-11" morph="none" pos="punct" start_char="5356">.</TOKEN>
<TRANSLATED_TEXT>Generalizing the use of mascara logically decreases the reproductive number.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5464" id="segment-47" start_char="5358">
<ORIGINAL_TEXT>Y esto disminuye la demanda de servicios sanitarios Responder Denunciar comentario Ocultar 3 Respuestas 1 2</ORIGINAL_TEXT>
<TOKEN end_char="5358" id="token-47-0" morph="none" pos="word" start_char="5358">Y</TOKEN>
<TOKEN end_char="5363" id="token-47-1" morph="none" pos="word" start_char="5360">esto</TOKEN>
<TOKEN end_char="5373" id="token-47-2" morph="none" pos="word" start_char="5365">disminuye</TOKEN>
<TOKEN end_char="5376" id="token-47-3" morph="none" pos="word" start_char="5375">la</TOKEN>
<TOKEN end_char="5384" id="token-47-4" morph="none" pos="word" start_char="5378">demanda</TOKEN>
<TOKEN end_char="5387" id="token-47-5" morph="none" pos="word" start_char="5386">de</TOKEN>
<TOKEN end_char="5397" id="token-47-6" morph="none" pos="word" start_char="5389">servicios</TOKEN>
<TOKEN end_char="5408" id="token-47-7" morph="none" pos="word" start_char="5399">sanitarios</TOKEN>
<TOKEN end_char="5418" id="token-47-8" morph="none" pos="word" start_char="5410">Responder</TOKEN>
<TOKEN end_char="5428" id="token-47-9" morph="none" pos="word" start_char="5420">Denunciar</TOKEN>
<TOKEN end_char="5439" id="token-47-10" morph="none" pos="word" start_char="5430">comentario</TOKEN>
<TOKEN end_char="5447" id="token-47-11" morph="none" pos="word" start_char="5441">Ocultar</TOKEN>
<TOKEN end_char="5449" id="token-47-12" morph="none" pos="word" start_char="5449">3</TOKEN>
<TOKEN end_char="5460" id="token-47-13" morph="none" pos="word" start_char="5451">Respuestas</TOKEN>
<TOKEN end_char="5462" id="token-47-14" morph="none" pos="word" start_char="5462">1</TOKEN>
<TOKEN end_char="5464" id="token-47-15" morph="none" pos="word" start_char="5464">2</TOKEN>
<TRANSLATED_TEXT>And this decreases demand for health services Respond Denial comment Hide 3 Answers 1 2</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="5473" id="segment-48" start_char="5467">
<ORIGINAL_TEXT>Macrons</ORIGINAL_TEXT>
<TOKEN end_char="5473" id="token-48-0" morph="none" pos="word" start_char="5467">Macrons</TOKEN>
<TRANSLATED_TEXT>Macron</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="5489" id="segment-49" start_char="5476">
<ORIGINAL_TEXT>09/04/20 13:41</ORIGINAL_TEXT>
<TOKEN end_char="5483" id="token-49-0" morph="none" pos="unknown" start_char="5476">09/04/20</TOKEN>
<TOKEN end_char="5489" id="token-49-1" morph="none" pos="unknown" start_char="5485">13:41</TOKEN>
<TRANSLATED_TEXT>09 / 04 / 20 13: 41</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="6711" id="segment-50" start_char="5492">
<ORIGINAL_TEXT>Desafortunadamente los expertos en las distintas ramas de salud, parecen saber poco de física del aire.Soy físico de la especialidad y sé que resultaría prácticamente imposible que las gotitas de Flügge expulsadas -por ejemplo al hablar un enfermo (incluso asintomático)- no se depositaran en los millones de partículas que pueblan el aire que respiramos.Así, la distancia de 3 metros que aguantarían en el aire (olvidando las partículas que lo acarrearían) las gotitas de Flügge podría ser un gran error, sobre todo en lugares cerrados.Recientemente he leído una entrevista muy interesante a Sergio Romagnan: https://www.elconfidencial.com/mundo/europa/2020-04-07/coronavirus-oms-italia-veneto-romagnani_2537147/Resalto lo siguiente:"Llegamos a la conclusión de que la circulación del virus alrededor de una misma persona, aunque ya esté infectada, agrava su patología.Es una hipótesis, pero creemos que cuando el virus circula muchas veces por el mismo ambiente, potencia su acción.El virus es muy peligroso en ambientes cerrados donde hay muchas personas.Aún no está del todo claro, pero parece que aunque no estés delante de la persona infectada, aunque no la veas, te puedes llegar a infectar en ambientes cerrados.</ORIGINAL_TEXT>
<TOKEN end_char="5509" id="token-50-0" morph="none" pos="word" start_char="5492">Desafortunadamente</TOKEN>
<TOKEN end_char="5513" id="token-50-1" morph="none" pos="word" start_char="5511">los</TOKEN>
<TOKEN end_char="5522" id="token-50-2" morph="none" pos="word" start_char="5515">expertos</TOKEN>
<TOKEN end_char="5525" id="token-50-3" morph="none" pos="word" start_char="5524">en</TOKEN>
<TOKEN end_char="5529" id="token-50-4" morph="none" pos="word" start_char="5527">las</TOKEN>
<TOKEN end_char="5539" id="token-50-5" morph="none" pos="word" start_char="5531">distintas</TOKEN>
<TOKEN end_char="5545" id="token-50-6" morph="none" pos="word" start_char="5541">ramas</TOKEN>
<TOKEN end_char="5548" id="token-50-7" morph="none" pos="word" start_char="5547">de</TOKEN>
<TOKEN end_char="5554" id="token-50-8" morph="none" pos="word" start_char="5550">salud</TOKEN>
<TOKEN end_char="5555" id="token-50-9" morph="none" pos="punct" start_char="5555">,</TOKEN>
<TOKEN end_char="5563" id="token-50-10" morph="none" pos="word" start_char="5557">parecen</TOKEN>
<TOKEN end_char="5569" id="token-50-11" morph="none" pos="word" start_char="5565">saber</TOKEN>
<TOKEN end_char="5574" id="token-50-12" morph="none" pos="word" start_char="5571">poco</TOKEN>
<TOKEN end_char="5577" id="token-50-13" morph="none" pos="word" start_char="5576">de</TOKEN>
<TOKEN end_char="5584" id="token-50-14" morph="none" pos="word" start_char="5579">física</TOKEN>
<TOKEN end_char="5588" id="token-50-15" morph="none" pos="word" start_char="5586">del</TOKEN>
<TOKEN end_char="5597" id="token-50-16" morph="none" pos="unknown" start_char="5590">aire.Soy</TOKEN>
<TOKEN end_char="5604" id="token-50-17" morph="none" pos="word" start_char="5599">físico</TOKEN>
<TOKEN end_char="5607" id="token-50-18" morph="none" pos="word" start_char="5606">de</TOKEN>
<TOKEN end_char="5610" id="token-50-19" morph="none" pos="word" start_char="5609">la</TOKEN>
<TOKEN end_char="5623" id="token-50-20" morph="none" pos="word" start_char="5612">especialidad</TOKEN>
<TOKEN end_char="5625" id="token-50-21" morph="none" pos="word" start_char="5625">y</TOKEN>
<TOKEN end_char="5628" id="token-50-22" morph="none" pos="word" start_char="5627">sé</TOKEN>
<TOKEN end_char="5632" id="token-50-23" morph="none" pos="word" start_char="5630">que</TOKEN>
<TOKEN end_char="5643" id="token-50-24" morph="none" pos="word" start_char="5634">resultaría</TOKEN>
<TOKEN end_char="5657" id="token-50-25" morph="none" pos="word" start_char="5645">prácticamente</TOKEN>
<TOKEN end_char="5667" id="token-50-26" morph="none" pos="word" start_char="5659">imposible</TOKEN>
<TOKEN end_char="5671" id="token-50-27" morph="none" pos="word" start_char="5669">que</TOKEN>
<TOKEN end_char="5675" id="token-50-28" morph="none" pos="word" start_char="5673">las</TOKEN>
<TOKEN end_char="5683" id="token-50-29" morph="none" pos="word" start_char="5677">gotitas</TOKEN>
<TOKEN end_char="5686" id="token-50-30" morph="none" pos="word" start_char="5685">de</TOKEN>
<TOKEN end_char="5693" id="token-50-31" morph="none" pos="word" start_char="5688">Flügge</TOKEN>
<TOKEN end_char="5704" id="token-50-32" morph="none" pos="word" start_char="5695">expulsadas</TOKEN>
<TOKEN end_char="5706" id="token-50-33" morph="none" pos="punct" start_char="5706">-</TOKEN>
<TOKEN end_char="5709" id="token-50-34" morph="none" pos="word" start_char="5707">por</TOKEN>
<TOKEN end_char="5717" id="token-50-35" morph="none" pos="word" start_char="5711">ejemplo</TOKEN>
<TOKEN end_char="5720" id="token-50-36" morph="none" pos="word" start_char="5719">al</TOKEN>
<TOKEN end_char="5727" id="token-50-37" morph="none" pos="word" start_char="5722">hablar</TOKEN>
<TOKEN end_char="5730" id="token-50-38" morph="none" pos="word" start_char="5729">un</TOKEN>
<TOKEN end_char="5738" id="token-50-39" morph="none" pos="word" start_char="5732">enfermo</TOKEN>
<TOKEN end_char="5740" id="token-50-40" morph="none" pos="punct" start_char="5740">(</TOKEN>
<TOKEN end_char="5747" id="token-50-41" morph="none" pos="word" start_char="5741">incluso</TOKEN>
<TOKEN end_char="5760" id="token-50-42" morph="none" pos="word" start_char="5749">asintomático</TOKEN>
<TOKEN end_char="5762" id="token-50-43" morph="none" pos="punct" start_char="5761">)-</TOKEN>
<TOKEN end_char="5765" id="token-50-44" morph="none" pos="word" start_char="5764">no</TOKEN>
<TOKEN end_char="5768" id="token-50-45" morph="none" pos="word" start_char="5767">se</TOKEN>
<TOKEN end_char="5780" id="token-50-46" morph="none" pos="word" start_char="5770">depositaran</TOKEN>
<TOKEN end_char="5783" id="token-50-47" morph="none" pos="word" start_char="5782">en</TOKEN>
<TOKEN end_char="5787" id="token-50-48" morph="none" pos="word" start_char="5785">los</TOKEN>
<TOKEN end_char="5796" id="token-50-49" morph="none" pos="word" start_char="5789">millones</TOKEN>
<TOKEN end_char="5799" id="token-50-50" morph="none" pos="word" start_char="5798">de</TOKEN>
<TOKEN end_char="5810" id="token-50-51" morph="none" pos="word" start_char="5801">partículas</TOKEN>
<TOKEN end_char="5814" id="token-50-52" morph="none" pos="word" start_char="5812">que</TOKEN>
<TOKEN end_char="5822" id="token-50-53" morph="none" pos="word" start_char="5816">pueblan</TOKEN>
<TOKEN end_char="5825" id="token-50-54" morph="none" pos="word" start_char="5824">el</TOKEN>
<TOKEN end_char="5830" id="token-50-55" morph="none" pos="word" start_char="5827">aire</TOKEN>
<TOKEN end_char="5834" id="token-50-56" morph="none" pos="word" start_char="5832">que</TOKEN>
<TOKEN end_char="5849" id="token-50-57" morph="none" pos="unknown" start_char="5836">respiramos.Así</TOKEN>
<TOKEN end_char="5850" id="token-50-58" morph="none" pos="punct" start_char="5850">,</TOKEN>
<TOKEN end_char="5853" id="token-50-59" morph="none" pos="word" start_char="5852">la</TOKEN>
<TOKEN end_char="5863" id="token-50-60" morph="none" pos="word" start_char="5855">distancia</TOKEN>
<TOKEN end_char="5866" id="token-50-61" morph="none" pos="word" start_char="5865">de</TOKEN>
<TOKEN end_char="5868" id="token-50-62" morph="none" pos="word" start_char="5868">3</TOKEN>
<TOKEN end_char="5875" id="token-50-63" morph="none" pos="word" start_char="5870">metros</TOKEN>
<TOKEN end_char="5879" id="token-50-64" morph="none" pos="word" start_char="5877">que</TOKEN>
<TOKEN end_char="5891" id="token-50-65" morph="none" pos="word" start_char="5881">aguantarían</TOKEN>
<TOKEN end_char="5894" id="token-50-66" morph="none" pos="word" start_char="5893">en</TOKEN>
<TOKEN end_char="5897" id="token-50-67" morph="none" pos="word" start_char="5896">el</TOKEN>
<TOKEN end_char="5902" id="token-50-68" morph="none" pos="word" start_char="5899">aire</TOKEN>
<TOKEN end_char="5904" id="token-50-69" morph="none" pos="punct" start_char="5904">(</TOKEN>
<TOKEN end_char="5913" id="token-50-70" morph="none" pos="word" start_char="5905">olvidando</TOKEN>
<TOKEN end_char="5917" id="token-50-71" morph="none" pos="word" start_char="5915">las</TOKEN>
<TOKEN end_char="5928" id="token-50-72" morph="none" pos="word" start_char="5919">partículas</TOKEN>
<TOKEN end_char="5932" id="token-50-73" morph="none" pos="word" start_char="5930">que</TOKEN>
<TOKEN end_char="5935" id="token-50-74" morph="none" pos="word" start_char="5934">lo</TOKEN>
<TOKEN end_char="5947" id="token-50-75" morph="none" pos="word" start_char="5937">acarrearían</TOKEN>
<TOKEN end_char="5948" id="token-50-76" morph="none" pos="punct" start_char="5948">)</TOKEN>
<TOKEN end_char="5952" id="token-50-77" morph="none" pos="word" start_char="5950">las</TOKEN>
<TOKEN end_char="5960" id="token-50-78" morph="none" pos="word" start_char="5954">gotitas</TOKEN>
<TOKEN end_char="5963" id="token-50-79" morph="none" pos="word" start_char="5962">de</TOKEN>
<TOKEN end_char="5970" id="token-50-80" morph="none" pos="word" start_char="5965">Flügge</TOKEN>
<TOKEN end_char="5977" id="token-50-81" morph="none" pos="word" start_char="5972">podría</TOKEN>
<TOKEN end_char="5981" id="token-50-82" morph="none" pos="word" start_char="5979">ser</TOKEN>
<TOKEN end_char="5984" id="token-50-83" morph="none" pos="word" start_char="5983">un</TOKEN>
<TOKEN end_char="5989" id="token-50-84" morph="none" pos="word" start_char="5986">gran</TOKEN>
<TOKEN end_char="5995" id="token-50-85" morph="none" pos="word" start_char="5991">error</TOKEN>
<TOKEN end_char="5996" id="token-50-86" morph="none" pos="punct" start_char="5996">,</TOKEN>
<TOKEN end_char="6002" id="token-50-87" morph="none" pos="word" start_char="5998">sobre</TOKEN>
<TOKEN end_char="6007" id="token-50-88" morph="none" pos="word" start_char="6004">todo</TOKEN>
<TOKEN end_char="6010" id="token-50-89" morph="none" pos="word" start_char="6009">en</TOKEN>
<TOKEN end_char="6018" id="token-50-90" morph="none" pos="word" start_char="6012">lugares</TOKEN>
<TOKEN end_char="6041" id="token-50-91" morph="none" pos="unknown" start_char="6020">cerrados.Recientemente</TOKEN>
<TOKEN end_char="6044" id="token-50-92" morph="none" pos="word" start_char="6043">he</TOKEN>
<TOKEN end_char="6050" id="token-50-93" morph="none" pos="word" start_char="6046">leído</TOKEN>
<TOKEN end_char="6054" id="token-50-94" morph="none" pos="word" start_char="6052">una</TOKEN>
<TOKEN end_char="6065" id="token-50-95" morph="none" pos="word" start_char="6056">entrevista</TOKEN>
<TOKEN end_char="6069" id="token-50-96" morph="none" pos="word" start_char="6067">muy</TOKEN>
<TOKEN end_char="6081" id="token-50-97" morph="none" pos="word" start_char="6071">interesante</TOKEN>
<TOKEN end_char="6083" id="token-50-98" morph="none" pos="word" start_char="6083">a</TOKEN>
<TOKEN end_char="6090" id="token-50-99" morph="none" pos="word" start_char="6085">Sergio</TOKEN>
<TOKEN end_char="6099" id="token-50-100" morph="none" pos="word" start_char="6092">Romagnan</TOKEN>
<TOKEN end_char="6100" id="token-50-101" morph="none" pos="punct" start_char="6100">:</TOKEN>
<TOKEN end_char="6211" id="token-50-102" morph="none" pos="url" start_char="6102">https://www.elconfidencial.com/mundo/europa/2020-04-07/coronavirus-oms-italia-veneto-romagnani_2537147/Resalto</TOKEN>
<TOKEN end_char="6214" id="token-50-103" morph="none" pos="word" start_char="6213">lo</TOKEN>
<TOKEN end_char="6234" id="token-50-104" morph="none" pos="unknown" start_char="6216">siguiente:"Llegamos</TOKEN>
<TOKEN end_char="6236" id="token-50-105" morph="none" pos="word" start_char="6236">a</TOKEN>
<TOKEN end_char="6239" id="token-50-106" morph="none" pos="word" start_char="6238">la</TOKEN>
<TOKEN end_char="6250" id="token-50-107" morph="none" pos="word" start_char="6241">conclusión</TOKEN>
<TOKEN end_char="6253" id="token-50-108" morph="none" pos="word" start_char="6252">de</TOKEN>
<TOKEN end_char="6257" id="token-50-109" morph="none" pos="word" start_char="6255">que</TOKEN>
<TOKEN end_char="6260" id="token-50-110" morph="none" pos="word" start_char="6259">la</TOKEN>
<TOKEN end_char="6272" id="token-50-111" morph="none" pos="word" start_char="6262">circulación</TOKEN>
<TOKEN end_char="6276" id="token-50-112" morph="none" pos="word" start_char="6274">del</TOKEN>
<TOKEN end_char="6282" id="token-50-113" morph="none" pos="word" start_char="6278">virus</TOKEN>
<TOKEN end_char="6292" id="token-50-114" morph="none" pos="word" start_char="6284">alrededor</TOKEN>
<TOKEN end_char="6295" id="token-50-115" morph="none" pos="word" start_char="6294">de</TOKEN>
<TOKEN end_char="6299" id="token-50-116" morph="none" pos="word" start_char="6297">una</TOKEN>
<TOKEN end_char="6305" id="token-50-117" morph="none" pos="word" start_char="6301">misma</TOKEN>
<TOKEN end_char="6313" id="token-50-118" morph="none" pos="word" start_char="6307">persona</TOKEN>
<TOKEN end_char="6314" id="token-50-119" morph="none" pos="punct" start_char="6314">,</TOKEN>
<TOKEN end_char="6321" id="token-50-120" morph="none" pos="word" start_char="6316">aunque</TOKEN>
<TOKEN end_char="6324" id="token-50-121" morph="none" pos="word" start_char="6323">ya</TOKEN>
<TOKEN end_char="6329" id="token-50-122" morph="none" pos="word" start_char="6326">esté</TOKEN>
<TOKEN end_char="6339" id="token-50-123" morph="none" pos="word" start_char="6331">infectada</TOKEN>
<TOKEN end_char="6340" id="token-50-124" morph="none" pos="punct" start_char="6340">,</TOKEN>
<TOKEN end_char="6347" id="token-50-125" morph="none" pos="word" start_char="6342">agrava</TOKEN>
<TOKEN end_char="6350" id="token-50-126" morph="none" pos="word" start_char="6349">su</TOKEN>
<TOKEN end_char="6363" id="token-50-127" morph="none" pos="unknown" start_char="6352">patología.Es</TOKEN>
<TOKEN end_char="6367" id="token-50-128" morph="none" pos="word" start_char="6365">una</TOKEN>
<TOKEN end_char="6377" id="token-50-129" morph="none" pos="word" start_char="6369">hipótesis</TOKEN>
<TOKEN end_char="6378" id="token-50-130" morph="none" pos="punct" start_char="6378">,</TOKEN>
<TOKEN end_char="6383" id="token-50-131" morph="none" pos="word" start_char="6380">pero</TOKEN>
<TOKEN end_char="6391" id="token-50-132" morph="none" pos="word" start_char="6385">creemos</TOKEN>
<TOKEN end_char="6395" id="token-50-133" morph="none" pos="word" start_char="6393">que</TOKEN>
<TOKEN end_char="6402" id="token-50-134" morph="none" pos="word" start_char="6397">cuando</TOKEN>
<TOKEN end_char="6405" id="token-50-135" morph="none" pos="word" start_char="6404">el</TOKEN>
<TOKEN end_char="6411" id="token-50-136" morph="none" pos="word" start_char="6407">virus</TOKEN>
<TOKEN end_char="6419" id="token-50-137" morph="none" pos="word" start_char="6413">circula</TOKEN>
<TOKEN end_char="6426" id="token-50-138" morph="none" pos="word" start_char="6421">muchas</TOKEN>
<TOKEN end_char="6432" id="token-50-139" morph="none" pos="word" start_char="6428">veces</TOKEN>
<TOKEN end_char="6436" id="token-50-140" morph="none" pos="word" start_char="6434">por</TOKEN>
<TOKEN end_char="6439" id="token-50-141" morph="none" pos="word" start_char="6438">el</TOKEN>
<TOKEN end_char="6445" id="token-50-142" morph="none" pos="word" start_char="6441">mismo</TOKEN>
<TOKEN end_char="6454" id="token-50-143" morph="none" pos="word" start_char="6447">ambiente</TOKEN>
<TOKEN end_char="6455" id="token-50-144" morph="none" pos="punct" start_char="6455">,</TOKEN>
<TOKEN end_char="6464" id="token-50-145" morph="none" pos="word" start_char="6457">potencia</TOKEN>
<TOKEN end_char="6467" id="token-50-146" morph="none" pos="word" start_char="6466">su</TOKEN>
<TOKEN end_char="6477" id="token-50-147" morph="none" pos="unknown" start_char="6469">acción.El</TOKEN>
<TOKEN end_char="6483" id="token-50-148" morph="none" pos="word" start_char="6479">virus</TOKEN>
<TOKEN end_char="6486" id="token-50-149" morph="none" pos="word" start_char="6485">es</TOKEN>
<TOKEN end_char="6490" id="token-50-150" morph="none" pos="word" start_char="6488">muy</TOKEN>
<TOKEN end_char="6500" id="token-50-151" morph="none" pos="word" start_char="6492">peligroso</TOKEN>
<TOKEN end_char="6503" id="token-50-152" morph="none" pos="word" start_char="6502">en</TOKEN>
<TOKEN end_char="6513" id="token-50-153" morph="none" pos="word" start_char="6505">ambientes</TOKEN>
<TOKEN end_char="6522" id="token-50-154" morph="none" pos="word" start_char="6515">cerrados</TOKEN>
<TOKEN end_char="6528" id="token-50-155" morph="none" pos="word" start_char="6524">donde</TOKEN>
<TOKEN end_char="6532" id="token-50-156" morph="none" pos="word" start_char="6530">hay</TOKEN>
<TOKEN end_char="6539" id="token-50-157" morph="none" pos="word" start_char="6534">muchas</TOKEN>
<TOKEN end_char="6552" id="token-50-158" morph="none" pos="unknown" start_char="6541">personas.Aún</TOKEN>
<TOKEN end_char="6555" id="token-50-159" morph="none" pos="word" start_char="6554">no</TOKEN>
<TOKEN end_char="6560" id="token-50-160" morph="none" pos="word" start_char="6557">está</TOKEN>
<TOKEN end_char="6564" id="token-50-161" morph="none" pos="word" start_char="6562">del</TOKEN>
<TOKEN end_char="6569" id="token-50-162" morph="none" pos="word" start_char="6566">todo</TOKEN>
<TOKEN end_char="6575" id="token-50-163" morph="none" pos="word" start_char="6571">claro</TOKEN>
<TOKEN end_char="6576" id="token-50-164" morph="none" pos="punct" start_char="6576">,</TOKEN>
<TOKEN end_char="6581" id="token-50-165" morph="none" pos="word" start_char="6578">pero</TOKEN>
<TOKEN end_char="6588" id="token-50-166" morph="none" pos="word" start_char="6583">parece</TOKEN>
<TOKEN end_char="6592" id="token-50-167" morph="none" pos="word" start_char="6590">que</TOKEN>
<TOKEN end_char="6599" id="token-50-168" morph="none" pos="word" start_char="6594">aunque</TOKEN>
<TOKEN end_char="6602" id="token-50-169" morph="none" pos="word" start_char="6601">no</TOKEN>
<TOKEN end_char="6608" id="token-50-170" morph="none" pos="word" start_char="6604">estés</TOKEN>
<TOKEN end_char="6616" id="token-50-171" morph="none" pos="word" start_char="6610">delante</TOKEN>
<TOKEN end_char="6619" id="token-50-172" morph="none" pos="word" start_char="6618">de</TOKEN>
<TOKEN end_char="6622" id="token-50-173" morph="none" pos="word" start_char="6621">la</TOKEN>
<TOKEN end_char="6630" id="token-50-174" morph="none" pos="word" start_char="6624">persona</TOKEN>
<TOKEN end_char="6640" id="token-50-175" morph="none" pos="word" start_char="6632">infectada</TOKEN>
<TOKEN end_char="6641" id="token-50-176" morph="none" pos="punct" start_char="6641">,</TOKEN>
<TOKEN end_char="6648" id="token-50-177" morph="none" pos="word" start_char="6643">aunque</TOKEN>
<TOKEN end_char="6651" id="token-50-178" morph="none" pos="word" start_char="6650">no</TOKEN>
<TOKEN end_char="6654" id="token-50-179" morph="none" pos="word" start_char="6653">la</TOKEN>
<TOKEN end_char="6659" id="token-50-180" morph="none" pos="word" start_char="6656">veas</TOKEN>
<TOKEN end_char="6660" id="token-50-181" morph="none" pos="punct" start_char="6660">,</TOKEN>
<TOKEN end_char="6663" id="token-50-182" morph="none" pos="word" start_char="6662">te</TOKEN>
<TOKEN end_char="6670" id="token-50-183" morph="none" pos="word" start_char="6665">puedes</TOKEN>
<TOKEN end_char="6677" id="token-50-184" morph="none" pos="word" start_char="6672">llegar</TOKEN>
<TOKEN end_char="6679" id="token-50-185" morph="none" pos="word" start_char="6679">a</TOKEN>
<TOKEN end_char="6688" id="token-50-186" morph="none" pos="word" start_char="6681">infectar</TOKEN>
<TOKEN end_char="6691" id="token-50-187" morph="none" pos="word" start_char="6690">en</TOKEN>
<TOKEN end_char="6701" id="token-50-188" morph="none" pos="word" start_char="6693">ambientes</TOKEN>
<TOKEN end_char="6710" id="token-50-189" morph="none" pos="word" start_char="6703">cerrados</TOKEN>
<TOKEN end_char="6711" id="token-50-190" morph="none" pos="punct" start_char="6711">.</TOKEN>
<TRANSLATED_TEXT>Unfortunately experts in the various branches of health seem to know little about air physics. I am a specialist physicist and I know that it would be virtually impossible for the droplets of Flügge expelled - for example when speaking to a patient (even asymptomatic) - not to be deposited in the millions of particles that populate the air we breathe.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6902" id="segment-51" start_char="6713">
<ORIGINAL_TEXT>"Lo que casaría perfectamente con la tesis que vengo manteniendo afirmando que serían las partículas en suspensión en el aire, que acarrearían el COVID-19, agentes activos de su transmisión.</ORIGINAL_TEXT>
<TOKEN end_char="6713" id="token-51-0" morph="none" pos="punct" start_char="6713">"</TOKEN>
<TOKEN end_char="6715" id="token-51-1" morph="none" pos="word" start_char="6714">Lo</TOKEN>
<TOKEN end_char="6719" id="token-51-2" morph="none" pos="word" start_char="6717">que</TOKEN>
<TOKEN end_char="6727" id="token-51-3" morph="none" pos="word" start_char="6721">casaría</TOKEN>
<TOKEN end_char="6741" id="token-51-4" morph="none" pos="word" start_char="6729">perfectamente</TOKEN>
<TOKEN end_char="6745" id="token-51-5" morph="none" pos="word" start_char="6743">con</TOKEN>
<TOKEN end_char="6748" id="token-51-6" morph="none" pos="word" start_char="6747">la</TOKEN>
<TOKEN end_char="6754" id="token-51-7" morph="none" pos="word" start_char="6750">tesis</TOKEN>
<TOKEN end_char="6758" id="token-51-8" morph="none" pos="word" start_char="6756">que</TOKEN>
<TOKEN end_char="6764" id="token-51-9" morph="none" pos="word" start_char="6760">vengo</TOKEN>
<TOKEN end_char="6776" id="token-51-10" morph="none" pos="word" start_char="6766">manteniendo</TOKEN>
<TOKEN end_char="6786" id="token-51-11" morph="none" pos="word" start_char="6778">afirmando</TOKEN>
<TOKEN end_char="6790" id="token-51-12" morph="none" pos="word" start_char="6788">que</TOKEN>
<TOKEN end_char="6797" id="token-51-13" morph="none" pos="word" start_char="6792">serían</TOKEN>
<TOKEN end_char="6801" id="token-51-14" morph="none" pos="word" start_char="6799">las</TOKEN>
<TOKEN end_char="6812" id="token-51-15" morph="none" pos="word" start_char="6803">partículas</TOKEN>
<TOKEN end_char="6815" id="token-51-16" morph="none" pos="word" start_char="6814">en</TOKEN>
<TOKEN end_char="6826" id="token-51-17" morph="none" pos="word" start_char="6817">suspensión</TOKEN>
<TOKEN end_char="6829" id="token-51-18" morph="none" pos="word" start_char="6828">en</TOKEN>
<TOKEN end_char="6832" id="token-51-19" morph="none" pos="word" start_char="6831">el</TOKEN>
<TOKEN end_char="6837" id="token-51-20" morph="none" pos="word" start_char="6834">aire</TOKEN>
<TOKEN end_char="6838" id="token-51-21" morph="none" pos="punct" start_char="6838">,</TOKEN>
<TOKEN end_char="6842" id="token-51-22" morph="none" pos="word" start_char="6840">que</TOKEN>
<TOKEN end_char="6854" id="token-51-23" morph="none" pos="word" start_char="6844">acarrearían</TOKEN>
<TOKEN end_char="6857" id="token-51-24" morph="none" pos="word" start_char="6856">el</TOKEN>
<TOKEN end_char="6866" id="token-51-25" morph="none" pos="unknown" start_char="6859">COVID-19</TOKEN>
<TOKEN end_char="6867" id="token-51-26" morph="none" pos="punct" start_char="6867">,</TOKEN>
<TOKEN end_char="6875" id="token-51-27" morph="none" pos="word" start_char="6869">agentes</TOKEN>
<TOKEN end_char="6883" id="token-51-28" morph="none" pos="word" start_char="6877">activos</TOKEN>
<TOKEN end_char="6886" id="token-51-29" morph="none" pos="word" start_char="6885">de</TOKEN>
<TOKEN end_char="6889" id="token-51-30" morph="none" pos="word" start_char="6888">su</TOKEN>
<TOKEN end_char="6901" id="token-51-31" morph="none" pos="word" start_char="6891">transmisión</TOKEN>
<TOKEN end_char="6902" id="token-51-32" morph="none" pos="punct" start_char="6902">.</TOKEN>
<TRANSLATED_TEXT>It would fit perfectly with the thesis that I am maintaining that it would be the suspended particles in the air, which would carry COVID-19, active agents of its transmission.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6958" id="segment-52" start_char="6904">
<ORIGINAL_TEXT>Responder Denunciar comentario Ocultar 2 Respuestas 0 2</ORIGINAL_TEXT>
<TOKEN end_char="6912" id="token-52-0" morph="none" pos="word" start_char="6904">Responder</TOKEN>
<TOKEN end_char="6922" id="token-52-1" morph="none" pos="word" start_char="6914">Denunciar</TOKEN>
<TOKEN end_char="6933" id="token-52-2" morph="none" pos="word" start_char="6924">comentario</TOKEN>
<TOKEN end_char="6941" id="token-52-3" morph="none" pos="word" start_char="6935">Ocultar</TOKEN>
<TOKEN end_char="6943" id="token-52-4" morph="none" pos="word" start_char="6943">2</TOKEN>
<TOKEN end_char="6954" id="token-52-5" morph="none" pos="word" start_char="6945">Respuestas</TOKEN>
<TOKEN end_char="6956" id="token-52-6" morph="none" pos="word" start_char="6956">0</TOKEN>
<TOKEN end_char="6958" id="token-52-7" morph="none" pos="word" start_char="6958">2</TOKEN>
<TRANSLATED_TEXT>Reply Deny comment Hide 2 Answers 0 2</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="6967" id="segment-53" start_char="6961">
<ORIGINAL_TEXT>Cambris</ORIGINAL_TEXT>
<TOKEN end_char="6967" id="token-53-0" morph="none" pos="word" start_char="6961">Cambris</TOKEN>
<TRANSLATED_TEXT>CAMBRIS</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="6983" id="segment-54" start_char="6970">
<ORIGINAL_TEXT>09/04/20 14:51</ORIGINAL_TEXT>
<TOKEN end_char="6977" id="token-54-0" morph="none" pos="unknown" start_char="6970">09/04/20</TOKEN>
<TOKEN end_char="6983" id="token-54-1" morph="none" pos="unknown" start_char="6979">14:51</TOKEN>
<TRANSLATED_TEXT>09 / 04 / 20 14: 51</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="7002" id="segment-55" start_char="6986">
<ORIGINAL_TEXT>Estoy de acuerdo.</ORIGINAL_TEXT>
<TOKEN end_char="6990" id="token-55-0" morph="none" pos="word" start_char="6986">Estoy</TOKEN>
<TOKEN end_char="6993" id="token-55-1" morph="none" pos="word" start_char="6992">de</TOKEN>
<TOKEN end_char="7001" id="token-55-2" morph="none" pos="word" start_char="6995">acuerdo</TOKEN>
<TOKEN end_char="7002" id="token-55-3" morph="none" pos="punct" start_char="7002">.</TOKEN>
<TRANSLATED_TEXT>I agree.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7113" id="segment-56" start_char="7004">
<ORIGINAL_TEXT>Y si las gotas de Flugge permanecen en el aire y la cola del supermercado la hacemos sin mascarilla ¿qué pasa?</ORIGINAL_TEXT>
<TOKEN end_char="7004" id="token-56-0" morph="none" pos="word" start_char="7004">Y</TOKEN>
<TOKEN end_char="7007" id="token-56-1" morph="none" pos="word" start_char="7006">si</TOKEN>
<TOKEN end_char="7011" id="token-56-2" morph="none" pos="word" start_char="7009">las</TOKEN>
<TOKEN end_char="7017" id="token-56-3" morph="none" pos="word" start_char="7013">gotas</TOKEN>
<TOKEN end_char="7020" id="token-56-4" morph="none" pos="word" start_char="7019">de</TOKEN>
<TOKEN end_char="7027" id="token-56-5" morph="none" pos="word" start_char="7022">Flugge</TOKEN>
<TOKEN end_char="7038" id="token-56-6" morph="none" pos="word" start_char="7029">permanecen</TOKEN>
<TOKEN end_char="7041" id="token-56-7" morph="none" pos="word" start_char="7040">en</TOKEN>
<TOKEN end_char="7044" id="token-56-8" morph="none" pos="word" start_char="7043">el</TOKEN>
<TOKEN end_char="7049" id="token-56-9" morph="none" pos="word" start_char="7046">aire</TOKEN>
<TOKEN end_char="7051" id="token-56-10" morph="none" pos="word" start_char="7051">y</TOKEN>
<TOKEN end_char="7054" id="token-56-11" morph="none" pos="word" start_char="7053">la</TOKEN>
<TOKEN end_char="7059" id="token-56-12" morph="none" pos="word" start_char="7056">cola</TOKEN>
<TOKEN end_char="7063" id="token-56-13" morph="none" pos="word" start_char="7061">del</TOKEN>
<TOKEN end_char="7076" id="token-56-14" morph="none" pos="word" start_char="7065">supermercado</TOKEN>
<TOKEN end_char="7079" id="token-56-15" morph="none" pos="word" start_char="7078">la</TOKEN>
<TOKEN end_char="7087" id="token-56-16" morph="none" pos="word" start_char="7081">hacemos</TOKEN>
<TOKEN end_char="7091" id="token-56-17" morph="none" pos="word" start_char="7089">sin</TOKEN>
<TOKEN end_char="7102" id="token-56-18" morph="none" pos="word" start_char="7093">mascarilla</TOKEN>
<TOKEN end_char="7104" id="token-56-19" morph="none" pos="punct" start_char="7104">¿</TOKEN>
<TOKEN end_char="7107" id="token-56-20" morph="none" pos="word" start_char="7105">qué</TOKEN>
<TOKEN end_char="7112" id="token-56-21" morph="none" pos="word" start_char="7109">pasa</TOKEN>
<TOKEN end_char="7113" id="token-56-22" morph="none" pos="punct" start_char="7113">?</TOKEN>
<TRANSLATED_TEXT>And if Flugge 's droplets stay in the air and the supermarket' s tail is unmasked, what happens?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7243" id="segment-57" start_char="7115">
<ORIGINAL_TEXT>Qué quien venga detrás, si tampoco lleva mascarilla... será otro contagio Responder Denunciar comentario Ocultar 1 Respuestas 0 0</ORIGINAL_TEXT>
<TOKEN end_char="7117" id="token-57-0" morph="none" pos="word" start_char="7115">Qué</TOKEN>
<TOKEN end_char="7123" id="token-57-1" morph="none" pos="word" start_char="7119">quien</TOKEN>
<TOKEN end_char="7129" id="token-57-2" morph="none" pos="word" start_char="7125">venga</TOKEN>
<TOKEN end_char="7136" id="token-57-3" morph="none" pos="word" start_char="7131">detrás</TOKEN>
<TOKEN end_char="7137" id="token-57-4" morph="none" pos="punct" start_char="7137">,</TOKEN>
<TOKEN end_char="7140" id="token-57-5" morph="none" pos="word" start_char="7139">si</TOKEN>
<TOKEN end_char="7148" id="token-57-6" morph="none" pos="word" start_char="7142">tampoco</TOKEN>
<TOKEN end_char="7154" id="token-57-7" morph="none" pos="word" start_char="7150">lleva</TOKEN>
<TOKEN end_char="7165" id="token-57-8" morph="none" pos="word" start_char="7156">mascarilla</TOKEN>
<TOKEN end_char="7168" id="token-57-9" morph="none" pos="punct" start_char="7166">...</TOKEN>
<TOKEN end_char="7173" id="token-57-10" morph="none" pos="word" start_char="7170">será</TOKEN>
<TOKEN end_char="7178" id="token-57-11" morph="none" pos="word" start_char="7175">otro</TOKEN>
<TOKEN end_char="7187" id="token-57-12" morph="none" pos="word" start_char="7180">contagio</TOKEN>
<TOKEN end_char="7197" id="token-57-13" morph="none" pos="word" start_char="7189">Responder</TOKEN>
<TOKEN end_char="7207" id="token-57-14" morph="none" pos="word" start_char="7199">Denunciar</TOKEN>
<TOKEN end_char="7218" id="token-57-15" morph="none" pos="word" start_char="7209">comentario</TOKEN>
<TOKEN end_char="7226" id="token-57-16" morph="none" pos="word" start_char="7220">Ocultar</TOKEN>
<TOKEN end_char="7228" id="token-57-17" morph="none" pos="word" start_char="7228">1</TOKEN>
<TOKEN end_char="7239" id="token-57-18" morph="none" pos="word" start_char="7230">Respuestas</TOKEN>
<TOKEN end_char="7241" id="token-57-19" morph="none" pos="word" start_char="7241">0</TOKEN>
<TOKEN end_char="7243" id="token-57-20" morph="none" pos="word" start_char="7243">0</TOKEN>
<TRANSLATED_TEXT>What comes behind, if not wearing a mask... will be another contagion Reply Denial comment Hide 1 Answers 0 0</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="7252" id="segment-58" start_char="7246">
<ORIGINAL_TEXT>Macrons</ORIGINAL_TEXT>
<TOKEN end_char="7252" id="token-58-0" morph="none" pos="word" start_char="7246">Macrons</TOKEN>
<TRANSLATED_TEXT>Macron</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="7268" id="segment-59" start_char="7255">
<ORIGINAL_TEXT>09/04/20 16:28</ORIGINAL_TEXT>
<TOKEN end_char="7262" id="token-59-0" morph="none" pos="unknown" start_char="7255">09/04/20</TOKEN>
<TOKEN end_char="7268" id="token-59-1" morph="none" pos="unknown" start_char="7264">16:28</TOKEN>
<TRANSLATED_TEXT>09 / 04 / 20 16: 28</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="7316" id="segment-60" start_char="7271">
<ORIGINAL_TEXT>Desgraciadamente las cosas no son tan simples.</ORIGINAL_TEXT>
<TOKEN end_char="7286" id="token-60-0" morph="none" pos="word" start_char="7271">Desgraciadamente</TOKEN>
<TOKEN end_char="7290" id="token-60-1" morph="none" pos="word" start_char="7288">las</TOKEN>
<TOKEN end_char="7296" id="token-60-2" morph="none" pos="word" start_char="7292">cosas</TOKEN>
<TOKEN end_char="7299" id="token-60-3" morph="none" pos="word" start_char="7298">no</TOKEN>
<TOKEN end_char="7303" id="token-60-4" morph="none" pos="word" start_char="7301">son</TOKEN>
<TOKEN end_char="7307" id="token-60-5" morph="none" pos="word" start_char="7305">tan</TOKEN>
<TOKEN end_char="7315" id="token-60-6" morph="none" pos="word" start_char="7309">simples</TOKEN>
<TOKEN end_char="7316" id="token-60-7" morph="none" pos="punct" start_char="7316">.</TOKEN>
<TRANSLATED_TEXT>Unfortunately, things are not that simple.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="8034" id="segment-61" start_char="7318">
<ORIGINAL_TEXT>Dejando sentada la utilidad de lasa mascarillas, incluso las artesanales, la eficacia nunca será del 100%.Se deben usar, porque con toda probabilidad reducen el número de infecciones, pero dado que habría coronavirus que escaparían, en ambientes cerrados y pasadas unas horas desde una desinfección efectiva, se seguirían produciendo -aunque en menor número- contagios.Y ahí están las cifras de profesionales muy protegidos (pelo, gafas, mascarilla y cuerpo) que todavía resultan infectados.La razón estaría en que el COVID-19 de tamaño 0,000130 milímetros, podría viajar en partículas en el rango 0,005-0009 milímetros, que no son interceptados ni siquiera por las FFP3, que solo alcanzan hasta los 0,006 milímetros.</ORIGINAL_TEXT>
<TOKEN end_char="7324" id="token-61-0" morph="none" pos="word" start_char="7318">Dejando</TOKEN>
<TOKEN end_char="7332" id="token-61-1" morph="none" pos="word" start_char="7326">sentada</TOKEN>
<TOKEN end_char="7335" id="token-61-2" morph="none" pos="word" start_char="7334">la</TOKEN>
<TOKEN end_char="7344" id="token-61-3" morph="none" pos="word" start_char="7337">utilidad</TOKEN>
<TOKEN end_char="7347" id="token-61-4" morph="none" pos="word" start_char="7346">de</TOKEN>
<TOKEN end_char="7352" id="token-61-5" morph="none" pos="word" start_char="7349">lasa</TOKEN>
<TOKEN end_char="7364" id="token-61-6" morph="none" pos="word" start_char="7354">mascarillas</TOKEN>
<TOKEN end_char="7365" id="token-61-7" morph="none" pos="punct" start_char="7365">,</TOKEN>
<TOKEN end_char="7373" id="token-61-8" morph="none" pos="word" start_char="7367">incluso</TOKEN>
<TOKEN end_char="7377" id="token-61-9" morph="none" pos="word" start_char="7375">las</TOKEN>
<TOKEN end_char="7389" id="token-61-10" morph="none" pos="word" start_char="7379">artesanales</TOKEN>
<TOKEN end_char="7390" id="token-61-11" morph="none" pos="punct" start_char="7390">,</TOKEN>
<TOKEN end_char="7393" id="token-61-12" morph="none" pos="word" start_char="7392">la</TOKEN>
<TOKEN end_char="7402" id="token-61-13" morph="none" pos="word" start_char="7395">eficacia</TOKEN>
<TOKEN end_char="7408" id="token-61-14" morph="none" pos="word" start_char="7404">nunca</TOKEN>
<TOKEN end_char="7413" id="token-61-15" morph="none" pos="word" start_char="7410">será</TOKEN>
<TOKEN end_char="7417" id="token-61-16" morph="none" pos="word" start_char="7415">del</TOKEN>
<TOKEN end_char="7425" id="token-61-17" morph="none" pos="unknown" start_char="7419">100%.Se</TOKEN>
<TOKEN end_char="7431" id="token-61-18" morph="none" pos="word" start_char="7427">deben</TOKEN>
<TOKEN end_char="7436" id="token-61-19" morph="none" pos="word" start_char="7433">usar</TOKEN>
<TOKEN end_char="7437" id="token-61-20" morph="none" pos="punct" start_char="7437">,</TOKEN>
<TOKEN end_char="7444" id="token-61-21" morph="none" pos="word" start_char="7439">porque</TOKEN>
<TOKEN end_char="7448" id="token-61-22" morph="none" pos="word" start_char="7446">con</TOKEN>
<TOKEN end_char="7453" id="token-61-23" morph="none" pos="word" start_char="7450">toda</TOKEN>
<TOKEN end_char="7466" id="token-61-24" morph="none" pos="word" start_char="7455">probabilidad</TOKEN>
<TOKEN end_char="7474" id="token-61-25" morph="none" pos="word" start_char="7468">reducen</TOKEN>
<TOKEN end_char="7477" id="token-61-26" morph="none" pos="word" start_char="7476">el</TOKEN>
<TOKEN end_char="7484" id="token-61-27" morph="none" pos="word" start_char="7479">número</TOKEN>
<TOKEN end_char="7487" id="token-61-28" morph="none" pos="word" start_char="7486">de</TOKEN>
<TOKEN end_char="7499" id="token-61-29" morph="none" pos="word" start_char="7489">infecciones</TOKEN>
<TOKEN end_char="7500" id="token-61-30" morph="none" pos="punct" start_char="7500">,</TOKEN>
<TOKEN end_char="7505" id="token-61-31" morph="none" pos="word" start_char="7502">pero</TOKEN>
<TOKEN end_char="7510" id="token-61-32" morph="none" pos="word" start_char="7507">dado</TOKEN>
<TOKEN end_char="7514" id="token-61-33" morph="none" pos="word" start_char="7512">que</TOKEN>
<TOKEN end_char="7521" id="token-61-34" morph="none" pos="word" start_char="7516">habría</TOKEN>
<TOKEN end_char="7533" id="token-61-35" morph="none" pos="word" start_char="7523">coronavirus</TOKEN>
<TOKEN end_char="7537" id="token-61-36" morph="none" pos="word" start_char="7535">que</TOKEN>
<TOKEN end_char="7548" id="token-61-37" morph="none" pos="word" start_char="7539">escaparían</TOKEN>
<TOKEN end_char="7549" id="token-61-38" morph="none" pos="punct" start_char="7549">,</TOKEN>
<TOKEN end_char="7552" id="token-61-39" morph="none" pos="word" start_char="7551">en</TOKEN>
<TOKEN end_char="7562" id="token-61-40" morph="none" pos="word" start_char="7554">ambientes</TOKEN>
<TOKEN end_char="7571" id="token-61-41" morph="none" pos="word" start_char="7564">cerrados</TOKEN>
<TOKEN end_char="7573" id="token-61-42" morph="none" pos="word" start_char="7573">y</TOKEN>
<TOKEN end_char="7581" id="token-61-43" morph="none" pos="word" start_char="7575">pasadas</TOKEN>
<TOKEN end_char="7586" id="token-61-44" morph="none" pos="word" start_char="7583">unas</TOKEN>
<TOKEN end_char="7592" id="token-61-45" morph="none" pos="word" start_char="7588">horas</TOKEN>
<TOKEN end_char="7598" id="token-61-46" morph="none" pos="word" start_char="7594">desde</TOKEN>
<TOKEN end_char="7602" id="token-61-47" morph="none" pos="word" start_char="7600">una</TOKEN>
<TOKEN end_char="7615" id="token-61-48" morph="none" pos="word" start_char="7604">desinfección</TOKEN>
<TOKEN end_char="7624" id="token-61-49" morph="none" pos="word" start_char="7617">efectiva</TOKEN>
<TOKEN end_char="7625" id="token-61-50" morph="none" pos="punct" start_char="7625">,</TOKEN>
<TOKEN end_char="7628" id="token-61-51" morph="none" pos="word" start_char="7627">se</TOKEN>
<TOKEN end_char="7638" id="token-61-52" morph="none" pos="word" start_char="7630">seguirían</TOKEN>
<TOKEN end_char="7650" id="token-61-53" morph="none" pos="word" start_char="7640">produciendo</TOKEN>
<TOKEN end_char="7652" id="token-61-54" morph="none" pos="punct" start_char="7652">-</TOKEN>
<TOKEN end_char="7658" id="token-61-55" morph="none" pos="word" start_char="7653">aunque</TOKEN>
<TOKEN end_char="7661" id="token-61-56" morph="none" pos="word" start_char="7660">en</TOKEN>
<TOKEN end_char="7667" id="token-61-57" morph="none" pos="word" start_char="7663">menor</TOKEN>
<TOKEN end_char="7674" id="token-61-58" morph="none" pos="word" start_char="7669">número</TOKEN>
<TOKEN end_char="7675" id="token-61-59" morph="none" pos="punct" start_char="7675">-</TOKEN>
<TOKEN end_char="7687" id="token-61-60" morph="none" pos="unknown" start_char="7677">contagios.Y</TOKEN>
<TOKEN end_char="7691" id="token-61-61" morph="none" pos="word" start_char="7689">ahí</TOKEN>
<TOKEN end_char="7697" id="token-61-62" morph="none" pos="word" start_char="7693">están</TOKEN>
<TOKEN end_char="7701" id="token-61-63" morph="none" pos="word" start_char="7699">las</TOKEN>
<TOKEN end_char="7708" id="token-61-64" morph="none" pos="word" start_char="7703">cifras</TOKEN>
<TOKEN end_char="7711" id="token-61-65" morph="none" pos="word" start_char="7710">de</TOKEN>
<TOKEN end_char="7725" id="token-61-66" morph="none" pos="word" start_char="7713">profesionales</TOKEN>
<TOKEN end_char="7729" id="token-61-67" morph="none" pos="word" start_char="7727">muy</TOKEN>
<TOKEN end_char="7740" id="token-61-68" morph="none" pos="word" start_char="7731">protegidos</TOKEN>
<TOKEN end_char="7742" id="token-61-69" morph="none" pos="punct" start_char="7742">(</TOKEN>
<TOKEN end_char="7746" id="token-61-70" morph="none" pos="word" start_char="7743">pelo</TOKEN>
<TOKEN end_char="7747" id="token-61-71" morph="none" pos="punct" start_char="7747">,</TOKEN>
<TOKEN end_char="7753" id="token-61-72" morph="none" pos="word" start_char="7749">gafas</TOKEN>
<TOKEN end_char="7754" id="token-61-73" morph="none" pos="punct" start_char="7754">,</TOKEN>
<TOKEN end_char="7765" id="token-61-74" morph="none" pos="word" start_char="7756">mascarilla</TOKEN>
<TOKEN end_char="7767" id="token-61-75" morph="none" pos="word" start_char="7767">y</TOKEN>
<TOKEN end_char="7774" id="token-61-76" morph="none" pos="word" start_char="7769">cuerpo</TOKEN>
<TOKEN end_char="7775" id="token-61-77" morph="none" pos="punct" start_char="7775">)</TOKEN>
<TOKEN end_char="7779" id="token-61-78" morph="none" pos="word" start_char="7777">que</TOKEN>
<TOKEN end_char="7787" id="token-61-79" morph="none" pos="word" start_char="7781">todavía</TOKEN>
<TOKEN end_char="7796" id="token-61-80" morph="none" pos="word" start_char="7789">resultan</TOKEN>
<TOKEN end_char="7810" id="token-61-81" morph="none" pos="unknown" start_char="7798">infectados.La</TOKEN>
<TOKEN end_char="7816" id="token-61-82" morph="none" pos="word" start_char="7812">razón</TOKEN>
<TOKEN end_char="7824" id="token-61-83" morph="none" pos="word" start_char="7818">estaría</TOKEN>
<TOKEN end_char="7827" id="token-61-84" morph="none" pos="word" start_char="7826">en</TOKEN>
<TOKEN end_char="7831" id="token-61-85" morph="none" pos="word" start_char="7829">que</TOKEN>
<TOKEN end_char="7834" id="token-61-86" morph="none" pos="word" start_char="7833">el</TOKEN>
<TOKEN end_char="7843" id="token-61-87" morph="none" pos="unknown" start_char="7836">COVID-19</TOKEN>
<TOKEN end_char="7846" id="token-61-88" morph="none" pos="word" start_char="7845">de</TOKEN>
<TOKEN end_char="7853" id="token-61-89" morph="none" pos="word" start_char="7848">tamaño</TOKEN>
<TOKEN end_char="7862" id="token-61-90" morph="none" pos="unknown" start_char="7855">0,000130</TOKEN>
<TOKEN end_char="7873" id="token-61-91" morph="none" pos="word" start_char="7864">milímetros</TOKEN>
<TOKEN end_char="7874" id="token-61-92" morph="none" pos="punct" start_char="7874">,</TOKEN>
<TOKEN end_char="7881" id="token-61-93" morph="none" pos="word" start_char="7876">podría</TOKEN>
<TOKEN end_char="7888" id="token-61-94" morph="none" pos="word" start_char="7883">viajar</TOKEN>
<TOKEN end_char="7891" id="token-61-95" morph="none" pos="word" start_char="7890">en</TOKEN>
<TOKEN end_char="7902" id="token-61-96" morph="none" pos="word" start_char="7893">partículas</TOKEN>
<TOKEN end_char="7905" id="token-61-97" morph="none" pos="word" start_char="7904">en</TOKEN>
<TOKEN end_char="7908" id="token-61-98" morph="none" pos="word" start_char="7907">el</TOKEN>
<TOKEN end_char="7914" id="token-61-99" morph="none" pos="word" start_char="7910">rango</TOKEN>
<TOKEN end_char="7925" id="token-61-100" morph="none" pos="unknown" start_char="7916">0,005-0009</TOKEN>
<TOKEN end_char="7936" id="token-61-101" morph="none" pos="word" start_char="7927">milímetros</TOKEN>
<TOKEN end_char="7937" id="token-61-102" morph="none" pos="punct" start_char="7937">,</TOKEN>
<TOKEN end_char="7941" id="token-61-103" morph="none" pos="word" start_char="7939">que</TOKEN>
<TOKEN end_char="7944" id="token-61-104" morph="none" pos="word" start_char="7943">no</TOKEN>
<TOKEN end_char="7948" id="token-61-105" morph="none" pos="word" start_char="7946">son</TOKEN>
<TOKEN end_char="7962" id="token-61-106" morph="none" pos="word" start_char="7950">interceptados</TOKEN>
<TOKEN end_char="7965" id="token-61-107" morph="none" pos="word" start_char="7964">ni</TOKEN>
<TOKEN end_char="7974" id="token-61-108" morph="none" pos="word" start_char="7967">siquiera</TOKEN>
<TOKEN end_char="7978" id="token-61-109" morph="none" pos="word" start_char="7976">por</TOKEN>
<TOKEN end_char="7982" id="token-61-110" morph="none" pos="word" start_char="7980">las</TOKEN>
<TOKEN end_char="7987" id="token-61-111" morph="none" pos="word" start_char="7984">FFP3</TOKEN>
<TOKEN end_char="7988" id="token-61-112" morph="none" pos="punct" start_char="7988">,</TOKEN>
<TOKEN end_char="7992" id="token-61-113" morph="none" pos="word" start_char="7990">que</TOKEN>
<TOKEN end_char="7997" id="token-61-114" morph="none" pos="word" start_char="7994">solo</TOKEN>
<TOKEN end_char="8006" id="token-61-115" morph="none" pos="word" start_char="7999">alcanzan</TOKEN>
<TOKEN end_char="8012" id="token-61-116" morph="none" pos="word" start_char="8008">hasta</TOKEN>
<TOKEN end_char="8016" id="token-61-117" morph="none" pos="word" start_char="8014">los</TOKEN>
<TOKEN end_char="8022" id="token-61-118" morph="none" pos="unknown" start_char="8018">0,006</TOKEN>
<TOKEN end_char="8033" id="token-61-119" morph="none" pos="word" start_char="8024">milímetros</TOKEN>
<TOKEN end_char="8034" id="token-61-120" morph="none" pos="punct" start_char="8034">.</TOKEN>
<TRANSLATED_TEXT>They should be used, because in all probability they reduce the number of infections, but since there would be coronaviruses that would escape, in closed environments and after a few hours from effective disinfection, they would continue to produce - albeit in smaller numbers - infectives.And there are the numbers of highly protected professionals (hair, glasses, masks and body) that are still infected.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="8305" id="segment-62" start_char="8036">
<ORIGINAL_TEXT>Como físico, debo atenerme a los hechos, aunque lamentablemente veo muy poco rigor rodeando el debate sobre la utilidad (que para mí, insisto, es evidente) de las mascarillas.En ausencia de inmunidad o vacuna, la única estrategia realmente efectiva, es el confinamiento.</ORIGINAL_TEXT>
<TOKEN end_char="8039" id="token-62-0" morph="none" pos="word" start_char="8036">Como</TOKEN>
<TOKEN end_char="8046" id="token-62-1" morph="none" pos="word" start_char="8041">físico</TOKEN>
<TOKEN end_char="8047" id="token-62-2" morph="none" pos="punct" start_char="8047">,</TOKEN>
<TOKEN end_char="8052" id="token-62-3" morph="none" pos="word" start_char="8049">debo</TOKEN>
<TOKEN end_char="8061" id="token-62-4" morph="none" pos="word" start_char="8054">atenerme</TOKEN>
<TOKEN end_char="8063" id="token-62-5" morph="none" pos="word" start_char="8063">a</TOKEN>
<TOKEN end_char="8067" id="token-62-6" morph="none" pos="word" start_char="8065">los</TOKEN>
<TOKEN end_char="8074" id="token-62-7" morph="none" pos="word" start_char="8069">hechos</TOKEN>
<TOKEN end_char="8075" id="token-62-8" morph="none" pos="punct" start_char="8075">,</TOKEN>
<TOKEN end_char="8082" id="token-62-9" morph="none" pos="word" start_char="8077">aunque</TOKEN>
<TOKEN end_char="8098" id="token-62-10" morph="none" pos="word" start_char="8084">lamentablemente</TOKEN>
<TOKEN end_char="8102" id="token-62-11" morph="none" pos="word" start_char="8100">veo</TOKEN>
<TOKEN end_char="8106" id="token-62-12" morph="none" pos="word" start_char="8104">muy</TOKEN>
<TOKEN end_char="8111" id="token-62-13" morph="none" pos="word" start_char="8108">poco</TOKEN>
<TOKEN end_char="8117" id="token-62-14" morph="none" pos="word" start_char="8113">rigor</TOKEN>
<TOKEN end_char="8126" id="token-62-15" morph="none" pos="word" start_char="8119">rodeando</TOKEN>
<TOKEN end_char="8129" id="token-62-16" morph="none" pos="word" start_char="8128">el</TOKEN>
<TOKEN end_char="8136" id="token-62-17" morph="none" pos="word" start_char="8131">debate</TOKEN>
<TOKEN end_char="8142" id="token-62-18" morph="none" pos="word" start_char="8138">sobre</TOKEN>
<TOKEN end_char="8145" id="token-62-19" morph="none" pos="word" start_char="8144">la</TOKEN>
<TOKEN end_char="8154" id="token-62-20" morph="none" pos="word" start_char="8147">utilidad</TOKEN>
<TOKEN end_char="8156" id="token-62-21" morph="none" pos="punct" start_char="8156">(</TOKEN>
<TOKEN end_char="8159" id="token-62-22" morph="none" pos="word" start_char="8157">que</TOKEN>
<TOKEN end_char="8164" id="token-62-23" morph="none" pos="word" start_char="8161">para</TOKEN>
<TOKEN end_char="8167" id="token-62-24" morph="none" pos="word" start_char="8166">mí</TOKEN>
<TOKEN end_char="8168" id="token-62-25" morph="none" pos="punct" start_char="8168">,</TOKEN>
<TOKEN end_char="8176" id="token-62-26" morph="none" pos="word" start_char="8170">insisto</TOKEN>
<TOKEN end_char="8177" id="token-62-27" morph="none" pos="punct" start_char="8177">,</TOKEN>
<TOKEN end_char="8180" id="token-62-28" morph="none" pos="word" start_char="8179">es</TOKEN>
<TOKEN end_char="8189" id="token-62-29" morph="none" pos="word" start_char="8182">evidente</TOKEN>
<TOKEN end_char="8190" id="token-62-30" morph="none" pos="punct" start_char="8190">)</TOKEN>
<TOKEN end_char="8193" id="token-62-31" morph="none" pos="word" start_char="8192">de</TOKEN>
<TOKEN end_char="8197" id="token-62-32" morph="none" pos="word" start_char="8195">las</TOKEN>
<TOKEN end_char="8212" id="token-62-33" morph="none" pos="unknown" start_char="8199">mascarillas.En</TOKEN>
<TOKEN end_char="8221" id="token-62-34" morph="none" pos="word" start_char="8214">ausencia</TOKEN>
<TOKEN end_char="8224" id="token-62-35" morph="none" pos="word" start_char="8223">de</TOKEN>
<TOKEN end_char="8234" id="token-62-36" morph="none" pos="word" start_char="8226">inmunidad</TOKEN>
<TOKEN end_char="8236" id="token-62-37" morph="none" pos="word" start_char="8236">o</TOKEN>
<TOKEN end_char="8243" id="token-62-38" morph="none" pos="word" start_char="8238">vacuna</TOKEN>
<TOKEN end_char="8244" id="token-62-39" morph="none" pos="punct" start_char="8244">,</TOKEN>
<TOKEN end_char="8247" id="token-62-40" morph="none" pos="word" start_char="8246">la</TOKEN>
<TOKEN end_char="8253" id="token-62-41" morph="none" pos="word" start_char="8249">única</TOKEN>
<TOKEN end_char="8264" id="token-62-42" morph="none" pos="word" start_char="8255">estrategia</TOKEN>
<TOKEN end_char="8274" id="token-62-43" morph="none" pos="word" start_char="8266">realmente</TOKEN>
<TOKEN end_char="8283" id="token-62-44" morph="none" pos="word" start_char="8276">efectiva</TOKEN>
<TOKEN end_char="8284" id="token-62-45" morph="none" pos="punct" start_char="8284">,</TOKEN>
<TOKEN end_char="8287" id="token-62-46" morph="none" pos="word" start_char="8286">es</TOKEN>
<TOKEN end_char="8290" id="token-62-47" morph="none" pos="word" start_char="8289">el</TOKEN>
<TOKEN end_char="8304" id="token-62-48" morph="none" pos="word" start_char="8292">confinamiento</TOKEN>
<TOKEN end_char="8305" id="token-62-49" morph="none" pos="punct" start_char="8305">.</TOKEN>
<TRANSLATED_TEXT>As a physicist, I must stick to the facts, although unfortunately I see very little rigour surrounding the debate on the usefulness (which, I insist, is obvious) of masquerades. In the absence of immunity or vaccine, the only really effective strategy is confinement.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="8340" id="segment-63" start_char="8307">
<ORIGINAL_TEXT>Responder Denunciar comentario 0 2</ORIGINAL_TEXT>
<TOKEN end_char="8315" id="token-63-0" morph="none" pos="word" start_char="8307">Responder</TOKEN>
<TOKEN end_char="8325" id="token-63-1" morph="none" pos="word" start_char="8317">Denunciar</TOKEN>
<TOKEN end_char="8336" id="token-63-2" morph="none" pos="word" start_char="8327">comentario</TOKEN>
<TOKEN end_char="8338" id="token-63-3" morph="none" pos="word" start_char="8338">0</TOKEN>
<TOKEN end_char="8340" id="token-63-4" morph="none" pos="word" start_char="8340">2</TOKEN>
<TRANSLATED_TEXT>Reply Deny comment 0 2</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="8402" id="segment-64" start_char="8344">
<ORIGINAL_TEXT>La ansiedad del confinamiento y la necesidad de decir algo.</ORIGINAL_TEXT>
<TOKEN end_char="8345" id="token-64-0" morph="none" pos="word" start_char="8344">La</TOKEN>
<TOKEN end_char="8354" id="token-64-1" morph="none" pos="word" start_char="8347">ansiedad</TOKEN>
<TOKEN end_char="8358" id="token-64-2" morph="none" pos="word" start_char="8356">del</TOKEN>
<TOKEN end_char="8372" id="token-64-3" morph="none" pos="word" start_char="8360">confinamiento</TOKEN>
<TOKEN end_char="8374" id="token-64-4" morph="none" pos="word" start_char="8374">y</TOKEN>
<TOKEN end_char="8377" id="token-64-5" morph="none" pos="word" start_char="8376">la</TOKEN>
<TOKEN end_char="8387" id="token-64-6" morph="none" pos="word" start_char="8379">necesidad</TOKEN>
<TOKEN end_char="8390" id="token-64-7" morph="none" pos="word" start_char="8389">de</TOKEN>
<TOKEN end_char="8396" id="token-64-8" morph="none" pos="word" start_char="8392">decir</TOKEN>
<TOKEN end_char="8401" id="token-64-9" morph="none" pos="word" start_char="8398">algo</TOKEN>
<TOKEN end_char="8402" id="token-64-10" morph="none" pos="punct" start_char="8402">.</TOKEN>
<TRANSLATED_TEXT>The anxiety of confinement and the need to say something.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="8480" id="segment-65" start_char="8404">
<ORIGINAL_TEXT>Todavía queda hasta el 25 de abril para definir si llevamos mascarillas o no.</ORIGINAL_TEXT>
<TOKEN end_char="8410" id="token-65-0" morph="none" pos="word" start_char="8404">Todavía</TOKEN>
<TOKEN end_char="8416" id="token-65-1" morph="none" pos="word" start_char="8412">queda</TOKEN>
<TOKEN end_char="8422" id="token-65-2" morph="none" pos="word" start_char="8418">hasta</TOKEN>
<TOKEN end_char="8425" id="token-65-3" morph="none" pos="word" start_char="8424">el</TOKEN>
<TOKEN end_char="8428" id="token-65-4" morph="none" pos="word" start_char="8427">25</TOKEN>
<TOKEN end_char="8431" id="token-65-5" morph="none" pos="word" start_char="8430">de</TOKEN>
<TOKEN end_char="8437" id="token-65-6" morph="none" pos="word" start_char="8433">abril</TOKEN>
<TOKEN end_char="8442" id="token-65-7" morph="none" pos="word" start_char="8439">para</TOKEN>
<TOKEN end_char="8450" id="token-65-8" morph="none" pos="word" start_char="8444">definir</TOKEN>
<TOKEN end_char="8453" id="token-65-9" morph="none" pos="word" start_char="8452">si</TOKEN>
<TOKEN end_char="8462" id="token-65-10" morph="none" pos="word" start_char="8455">llevamos</TOKEN>
<TOKEN end_char="8474" id="token-65-11" morph="none" pos="word" start_char="8464">mascarillas</TOKEN>
<TOKEN end_char="8476" id="token-65-12" morph="none" pos="word" start_char="8476">o</TOKEN>
<TOKEN end_char="8479" id="token-65-13" morph="none" pos="word" start_char="8478">no</TOKEN>
<TOKEN end_char="8480" id="token-65-14" morph="none" pos="punct" start_char="8480">.</TOKEN>
<TRANSLATED_TEXT>It is still until April 25 to define whether or not we wear masks.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="8510" id="segment-66" start_char="8482">
<ORIGINAL_TEXT>En mi farmacia ya había ayer.</ORIGINAL_TEXT>
<TOKEN end_char="8483" id="token-66-0" morph="none" pos="word" start_char="8482">En</TOKEN>
<TOKEN end_char="8486" id="token-66-1" morph="none" pos="word" start_char="8485">mi</TOKEN>
<TOKEN end_char="8495" id="token-66-2" morph="none" pos="word" start_char="8488">farmacia</TOKEN>
<TOKEN end_char="8498" id="token-66-3" morph="none" pos="word" start_char="8497">ya</TOKEN>
<TOKEN end_char="8504" id="token-66-4" morph="none" pos="word" start_char="8500">había</TOKEN>
<TOKEN end_char="8509" id="token-66-5" morph="none" pos="word" start_char="8506">ayer</TOKEN>
<TOKEN end_char="8510" id="token-66-6" morph="none" pos="punct" start_char="8510">.</TOKEN>
<TRANSLATED_TEXT>There was yesterday in my pharmacy.</TRANSLATED_TEXT><DETECTED_LANGUAGE>so</DETECTED_LANGUAGE></SEG>
<SEG end_char="8534" id="segment-67" start_char="8512">
<ORIGINAL_TEXT>Las quirúrgicas a 1,50.</ORIGINAL_TEXT>
<TOKEN end_char="8514" id="token-67-0" morph="none" pos="word" start_char="8512">Las</TOKEN>
<TOKEN end_char="8526" id="token-67-1" morph="none" pos="word" start_char="8516">quirúrgicas</TOKEN>
<TOKEN end_char="8528" id="token-67-2" morph="none" pos="word" start_char="8528">a</TOKEN>
<TOKEN end_char="8533" id="token-67-3" morph="none" pos="unknown" start_char="8530">1,50</TOKEN>
<TOKEN end_char="8534" id="token-67-4" morph="none" pos="punct" start_char="8534">.</TOKEN>
<TRANSLATED_TEXT>Surgery at 1.50.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="8561" id="segment-68" start_char="8536">
<ORIGINAL_TEXT>¿Es tan urgente definirlo?</ORIGINAL_TEXT>
<TOKEN end_char="8536" id="token-68-0" morph="none" pos="punct" start_char="8536">¿</TOKEN>
<TOKEN end_char="8538" id="token-68-1" morph="none" pos="word" start_char="8537">Es</TOKEN>
<TOKEN end_char="8542" id="token-68-2" morph="none" pos="word" start_char="8540">tan</TOKEN>
<TOKEN end_char="8550" id="token-68-3" morph="none" pos="word" start_char="8544">urgente</TOKEN>
<TOKEN end_char="8560" id="token-68-4" morph="none" pos="word" start_char="8552">definirlo</TOKEN>
<TOKEN end_char="8561" id="token-68-5" morph="none" pos="punct" start_char="8561">?</TOKEN>
<TRANSLATED_TEXT>Is it that urgent to define it?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="8824" id="segment-69" start_char="8565">
<ORIGINAL_TEXT>Los expertos nos dicen que el viros es contagioso a través de la boca, la nariz, y a su vez les vemos a los asiáticos, cubrirse con mascarillas, blanco y en botella, otra cosa es que no haya para TODOS,y que lógicamente por prioridades estén los PROFESIONALES.</ORIGINAL_TEXT>
<TOKEN end_char="8567" id="token-69-0" morph="none" pos="word" start_char="8565">Los</TOKEN>
<TOKEN end_char="8576" id="token-69-1" morph="none" pos="word" start_char="8569">expertos</TOKEN>
<TOKEN end_char="8580" id="token-69-2" morph="none" pos="word" start_char="8578">nos</TOKEN>
<TOKEN end_char="8586" id="token-69-3" morph="none" pos="word" start_char="8582">dicen</TOKEN>
<TOKEN end_char="8590" id="token-69-4" morph="none" pos="word" start_char="8588">que</TOKEN>
<TOKEN end_char="8593" id="token-69-5" morph="none" pos="word" start_char="8592">el</TOKEN>
<TOKEN end_char="8599" id="token-69-6" morph="none" pos="word" start_char="8595">viros</TOKEN>
<TOKEN end_char="8602" id="token-69-7" morph="none" pos="word" start_char="8601">es</TOKEN>
<TOKEN end_char="8613" id="token-69-8" morph="none" pos="word" start_char="8604">contagioso</TOKEN>
<TOKEN end_char="8615" id="token-69-9" morph="none" pos="word" start_char="8615">a</TOKEN>
<TOKEN end_char="8622" id="token-69-10" morph="none" pos="word" start_char="8617">través</TOKEN>
<TOKEN end_char="8625" id="token-69-11" morph="none" pos="word" start_char="8624">de</TOKEN>
<TOKEN end_char="8628" id="token-69-12" morph="none" pos="word" start_char="8627">la</TOKEN>
<TOKEN end_char="8633" id="token-69-13" morph="none" pos="word" start_char="8630">boca</TOKEN>
<TOKEN end_char="8634" id="token-69-14" morph="none" pos="punct" start_char="8634">,</TOKEN>
<TOKEN end_char="8637" id="token-69-15" morph="none" pos="word" start_char="8636">la</TOKEN>
<TOKEN end_char="8643" id="token-69-16" morph="none" pos="word" start_char="8639">nariz</TOKEN>
<TOKEN end_char="8644" id="token-69-17" morph="none" pos="punct" start_char="8644">,</TOKEN>
<TOKEN end_char="8646" id="token-69-18" morph="none" pos="word" start_char="8646">y</TOKEN>
<TOKEN end_char="8648" id="token-69-19" morph="none" pos="word" start_char="8648">a</TOKEN>
<TOKEN end_char="8651" id="token-69-20" morph="none" pos="word" start_char="8650">su</TOKEN>
<TOKEN end_char="8655" id="token-69-21" morph="none" pos="word" start_char="8653">vez</TOKEN>
<TOKEN end_char="8659" id="token-69-22" morph="none" pos="word" start_char="8657">les</TOKEN>
<TOKEN end_char="8665" id="token-69-23" morph="none" pos="word" start_char="8661">vemos</TOKEN>
<TOKEN end_char="8667" id="token-69-24" morph="none" pos="word" start_char="8667">a</TOKEN>
<TOKEN end_char="8671" id="token-69-25" morph="none" pos="word" start_char="8669">los</TOKEN>
<TOKEN end_char="8681" id="token-69-26" morph="none" pos="word" start_char="8673">asiáticos</TOKEN>
<TOKEN end_char="8682" id="token-69-27" morph="none" pos="punct" start_char="8682">,</TOKEN>
<TOKEN end_char="8691" id="token-69-28" morph="none" pos="word" start_char="8684">cubrirse</TOKEN>
<TOKEN end_char="8695" id="token-69-29" morph="none" pos="word" start_char="8693">con</TOKEN>
<TOKEN end_char="8707" id="token-69-30" morph="none" pos="word" start_char="8697">mascarillas</TOKEN>
<TOKEN end_char="8708" id="token-69-31" morph="none" pos="punct" start_char="8708">,</TOKEN>
<TOKEN end_char="8715" id="token-69-32" morph="none" pos="word" start_char="8710">blanco</TOKEN>
<TOKEN end_char="8717" id="token-69-33" morph="none" pos="word" start_char="8717">y</TOKEN>
<TOKEN end_char="8720" id="token-69-34" morph="none" pos="word" start_char="8719">en</TOKEN>
<TOKEN end_char="8728" id="token-69-35" morph="none" pos="word" start_char="8722">botella</TOKEN>
<TOKEN end_char="8729" id="token-69-36" morph="none" pos="punct" start_char="8729">,</TOKEN>
<TOKEN end_char="8734" id="token-69-37" morph="none" pos="word" start_char="8731">otra</TOKEN>
<TOKEN end_char="8739" id="token-69-38" morph="none" pos="word" start_char="8736">cosa</TOKEN>
<TOKEN end_char="8742" id="token-69-39" morph="none" pos="word" start_char="8741">es</TOKEN>
<TOKEN end_char="8746" id="token-69-40" morph="none" pos="word" start_char="8744">que</TOKEN>
<TOKEN end_char="8749" id="token-69-41" morph="none" pos="word" start_char="8748">no</TOKEN>
<TOKEN end_char="8754" id="token-69-42" morph="none" pos="word" start_char="8751">haya</TOKEN>
<TOKEN end_char="8759" id="token-69-43" morph="none" pos="word" start_char="8756">para</TOKEN>
<TOKEN end_char="8767" id="token-69-44" morph="none" pos="unknown" start_char="8761">TODOS,y</TOKEN>
<TOKEN end_char="8771" id="token-69-45" morph="none" pos="word" start_char="8769">que</TOKEN>
<TOKEN end_char="8783" id="token-69-46" morph="none" pos="word" start_char="8773">lógicamente</TOKEN>
<TOKEN end_char="8787" id="token-69-47" morph="none" pos="word" start_char="8785">por</TOKEN>
<TOKEN end_char="8799" id="token-69-48" morph="none" pos="word" start_char="8789">prioridades</TOKEN>
<TOKEN end_char="8805" id="token-69-49" morph="none" pos="word" start_char="8801">estén</TOKEN>
<TOKEN end_char="8809" id="token-69-50" morph="none" pos="word" start_char="8807">los</TOKEN>
<TOKEN end_char="8823" id="token-69-51" morph="none" pos="word" start_char="8811">PROFESIONALES</TOKEN>
<TOKEN end_char="8824" id="token-69-52" morph="none" pos="punct" start_char="8824">.</TOKEN>
<TRANSLATED_TEXT>The experts tell us that the man is contagious through the mouth, the nose, and in turn we see Asians, covered in masks, white and in bottles, another thing is that there is not for EVERYONE, and that logically the priorities are the PROFESSIONALS.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="9077" id="segment-70" start_char="8826">
<ORIGINAL_TEXT>pero hoy por hoy,todos nos podemos hacer una mascarilla casera,que también funciona para lo poco que debemos SALIR.Resumiendo,las mascarillas debemos ponerlas,para evitar contagios,perdonarme por el EJEMPLO, pero cómo el condón en su día para evitar...</ORIGINAL_TEXT>
<TOKEN end_char="8829" id="token-70-0" morph="none" pos="word" start_char="8826">pero</TOKEN>
<TOKEN end_char="8833" id="token-70-1" morph="none" pos="word" start_char="8831">hoy</TOKEN>
<TOKEN end_char="8837" id="token-70-2" morph="none" pos="word" start_char="8835">por</TOKEN>
<TOKEN end_char="8847" id="token-70-3" morph="none" pos="unknown" start_char="8839">hoy,todos</TOKEN>
<TOKEN end_char="8851" id="token-70-4" morph="none" pos="word" start_char="8849">nos</TOKEN>
<TOKEN end_char="8859" id="token-70-5" morph="none" pos="word" start_char="8853">podemos</TOKEN>
<TOKEN end_char="8865" id="token-70-6" morph="none" pos="word" start_char="8861">hacer</TOKEN>
<TOKEN end_char="8869" id="token-70-7" morph="none" pos="word" start_char="8867">una</TOKEN>
<TOKEN end_char="8880" id="token-70-8" morph="none" pos="word" start_char="8871">mascarilla</TOKEN>
<TOKEN end_char="8891" id="token-70-9" morph="none" pos="unknown" start_char="8882">casera,que</TOKEN>
<TOKEN end_char="8899" id="token-70-10" morph="none" pos="word" start_char="8893">también</TOKEN>
<TOKEN end_char="8908" id="token-70-11" morph="none" pos="word" start_char="8901">funciona</TOKEN>
<TOKEN end_char="8913" id="token-70-12" morph="none" pos="word" start_char="8910">para</TOKEN>
<TOKEN end_char="8916" id="token-70-13" morph="none" pos="word" start_char="8915">lo</TOKEN>
<TOKEN end_char="8921" id="token-70-14" morph="none" pos="word" start_char="8918">poco</TOKEN>
<TOKEN end_char="8925" id="token-70-15" morph="none" pos="word" start_char="8923">que</TOKEN>
<TOKEN end_char="8933" id="token-70-16" morph="none" pos="word" start_char="8927">debemos</TOKEN>
<TOKEN end_char="8954" id="token-70-17" morph="none" pos="unknown" start_char="8935">SALIR.Resumiendo,las</TOKEN>
<TOKEN end_char="8966" id="token-70-18" morph="none" pos="word" start_char="8956">mascarillas</TOKEN>
<TOKEN end_char="8974" id="token-70-19" morph="none" pos="word" start_char="8968">debemos</TOKEN>
<TOKEN end_char="8988" id="token-70-20" morph="none" pos="unknown" start_char="8976">ponerlas,para</TOKEN>
<TOKEN end_char="8995" id="token-70-21" morph="none" pos="word" start_char="8990">evitar</TOKEN>
<TOKEN end_char="9016" id="token-70-22" morph="none" pos="unknown" start_char="8997">contagios,perdonarme</TOKEN>
<TOKEN end_char="9020" id="token-70-23" morph="none" pos="word" start_char="9018">por</TOKEN>
<TOKEN end_char="9023" id="token-70-24" morph="none" pos="word" start_char="9022">el</TOKEN>
<TOKEN end_char="9031" id="token-70-25" morph="none" pos="word" start_char="9025">EJEMPLO</TOKEN>
<TOKEN end_char="9032" id="token-70-26" morph="none" pos="punct" start_char="9032">,</TOKEN>
<TOKEN end_char="9037" id="token-70-27" morph="none" pos="word" start_char="9034">pero</TOKEN>
<TOKEN end_char="9042" id="token-70-28" morph="none" pos="word" start_char="9039">cómo</TOKEN>
<TOKEN end_char="9045" id="token-70-29" morph="none" pos="word" start_char="9044">el</TOKEN>
<TOKEN end_char="9052" id="token-70-30" morph="none" pos="word" start_char="9047">condón</TOKEN>
<TOKEN end_char="9055" id="token-70-31" morph="none" pos="word" start_char="9054">en</TOKEN>
<TOKEN end_char="9058" id="token-70-32" morph="none" pos="word" start_char="9057">su</TOKEN>
<TOKEN end_char="9062" id="token-70-33" morph="none" pos="word" start_char="9060">día</TOKEN>
<TOKEN end_char="9067" id="token-70-34" morph="none" pos="word" start_char="9064">para</TOKEN>
<TOKEN end_char="9074" id="token-70-35" morph="none" pos="word" start_char="9069">evitar</TOKEN>
<TOKEN end_char="9077" id="token-70-36" morph="none" pos="punct" start_char="9075">...</TOKEN>
<TRANSLATED_TEXT>But today for today, we can all make a home mask, which also works for as little as we should SALIR. In short, we should put on masks, to avoid contagion, forgive me for the example, but how the condom in its day to avoid...</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="9114" id="segment-71" start_char="9081">
<ORIGINAL_TEXT>¿Qué tendría peores consecuencias?</ORIGINAL_TEXT>
<TOKEN end_char="9081" id="token-71-0" morph="none" pos="punct" start_char="9081">¿</TOKEN>
<TOKEN end_char="9084" id="token-71-1" morph="none" pos="word" start_char="9082">Qué</TOKEN>
<TOKEN end_char="9092" id="token-71-2" morph="none" pos="word" start_char="9086">tendría</TOKEN>
<TOKEN end_char="9099" id="token-71-3" morph="none" pos="word" start_char="9094">peores</TOKEN>
<TOKEN end_char="9113" id="token-71-4" morph="none" pos="word" start_char="9101">consecuencias</TOKEN>
<TOKEN end_char="9114" id="token-71-5" morph="none" pos="punct" start_char="9114">?</TOKEN>
<TRANSLATED_TEXT>What would be worse?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="9207" id="segment-72" start_char="9116">
<ORIGINAL_TEXT>Equivocarse por generalizar el uso de mascarillas o equivocarse por no haberlo generslizado?</ORIGINAL_TEXT>
<TOKEN end_char="9126" id="token-72-0" morph="none" pos="word" start_char="9116">Equivocarse</TOKEN>
<TOKEN end_char="9130" id="token-72-1" morph="none" pos="word" start_char="9128">por</TOKEN>
<TOKEN end_char="9142" id="token-72-2" morph="none" pos="word" start_char="9132">generalizar</TOKEN>
<TOKEN end_char="9145" id="token-72-3" morph="none" pos="word" start_char="9144">el</TOKEN>
<TOKEN end_char="9149" id="token-72-4" morph="none" pos="word" start_char="9147">uso</TOKEN>
<TOKEN end_char="9152" id="token-72-5" morph="none" pos="word" start_char="9151">de</TOKEN>
<TOKEN end_char="9164" id="token-72-6" morph="none" pos="word" start_char="9154">mascarillas</TOKEN>
<TOKEN end_char="9166" id="token-72-7" morph="none" pos="word" start_char="9166">o</TOKEN>
<TOKEN end_char="9178" id="token-72-8" morph="none" pos="word" start_char="9168">equivocarse</TOKEN>
<TOKEN end_char="9182" id="token-72-9" morph="none" pos="word" start_char="9180">por</TOKEN>
<TOKEN end_char="9185" id="token-72-10" morph="none" pos="word" start_char="9184">no</TOKEN>
<TOKEN end_char="9193" id="token-72-11" morph="none" pos="word" start_char="9187">haberlo</TOKEN>
<TOKEN end_char="9206" id="token-72-12" morph="none" pos="word" start_char="9195">generslizado</TOKEN>
<TOKEN end_char="9207" id="token-72-13" morph="none" pos="punct" start_char="9207">?</TOKEN>
<TRANSLATED_TEXT>To be mistaken for generalizing the use of masquerades or to be mistaken for not generalizing it?</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04ATQ7" lang="spa" raw_text_char_length="2364" raw_text_md5="8117dfeb42df1bcf100867092a811875" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="76" id="segment-0" start_char="1">
<ORIGINAL_TEXT>La COVID-19 ya circulaba en Brasil antes del primer caso confirmado en Wuhan</ORIGINAL_TEXT>
<TOKEN end_char="2" id="token-0-0" morph="none" pos="word" start_char="1">La</TOKEN>
<TOKEN end_char="11" id="token-0-1" morph="none" pos="unknown" start_char="4">COVID-19</TOKEN>
<TOKEN end_char="14" id="token-0-2" morph="none" pos="word" start_char="13">ya</TOKEN>
<TOKEN end_char="24" id="token-0-3" morph="none" pos="word" start_char="16">circulaba</TOKEN>
<TOKEN end_char="27" id="token-0-4" morph="none" pos="word" start_char="26">en</TOKEN>
<TOKEN end_char="34" id="token-0-5" morph="none" pos="word" start_char="29">Brasil</TOKEN>
<TOKEN end_char="40" id="token-0-6" morph="none" pos="word" start_char="36">antes</TOKEN>
<TOKEN end_char="44" id="token-0-7" morph="none" pos="word" start_char="42">del</TOKEN>
<TOKEN end_char="51" id="token-0-8" morph="none" pos="word" start_char="46">primer</TOKEN>
<TOKEN end_char="56" id="token-0-9" morph="none" pos="word" start_char="53">caso</TOKEN>
<TOKEN end_char="67" id="token-0-10" morph="none" pos="word" start_char="58">confirmado</TOKEN>
<TOKEN end_char="70" id="token-0-11" morph="none" pos="word" start_char="69">en</TOKEN>
<TOKEN end_char="76" id="token-0-12" morph="none" pos="word" start_char="72">Wuhan</TOKEN>
<TRANSLATED_TEXT>COVID-19 was already circulating in Brazil before the first confirmed case in Wuhan</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="99" id="segment-1" start_char="80">
<ORIGINAL_TEXT>Fernando Bizerra EFE</ORIGINAL_TEXT>
<TOKEN end_char="87" id="token-1-0" morph="none" pos="word" start_char="80">Fernando</TOKEN>
<TOKEN end_char="95" id="token-1-1" morph="none" pos="word" start_char="89">Bizerra</TOKEN>
<TOKEN end_char="99" id="token-1-2" morph="none" pos="word" start_char="97">EFE</TOKEN>
</SEG>
<SEG end_char="180" id="segment-2" start_char="103">
<ORIGINAL_TEXT>El coronavirus ya circulaba antes de la confirmación del primer caso en Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="104" id="token-2-0" morph="none" pos="word" start_char="103">El</TOKEN>
<TOKEN end_char="116" id="token-2-1" morph="none" pos="word" start_char="106">coronavirus</TOKEN>
<TOKEN end_char="119" id="token-2-2" morph="none" pos="word" start_char="118">ya</TOKEN>
<TOKEN end_char="129" id="token-2-3" morph="none" pos="word" start_char="121">circulaba</TOKEN>
<TOKEN end_char="135" id="token-2-4" morph="none" pos="word" start_char="131">antes</TOKEN>
<TOKEN end_char="138" id="token-2-5" morph="none" pos="word" start_char="137">de</TOKEN>
<TOKEN end_char="141" id="token-2-6" morph="none" pos="word" start_char="140">la</TOKEN>
<TOKEN end_char="154" id="token-2-7" morph="none" pos="word" start_char="143">confirmación</TOKEN>
<TOKEN end_char="158" id="token-2-8" morph="none" pos="word" start_char="156">del</TOKEN>
<TOKEN end_char="165" id="token-2-9" morph="none" pos="word" start_char="160">primer</TOKEN>
<TOKEN end_char="170" id="token-2-10" morph="none" pos="word" start_char="167">caso</TOKEN>
<TOKEN end_char="173" id="token-2-11" morph="none" pos="word" start_char="172">en</TOKEN>
<TOKEN end_char="179" id="token-2-12" morph="none" pos="word" start_char="175">Wuhan</TOKEN>
<TOKEN end_char="180" id="token-2-13" morph="none" pos="punct" start_char="180">.</TOKEN>
<TRANSLATED_TEXT>The coronavirus was already circulating before the confirmation of the first case in Wuhan.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="392" id="segment-3" start_char="182">
<ORIGINAL_TEXT>Es lo que ha revelado un estudio en colaboración con la Universidad Federal de Santa Catalina, en Florianópolis (Brasil), en el cual han encontrado restos del virus en las aguas fecales del país latinoamericano.</ORIGINAL_TEXT>
<TOKEN end_char="183" id="token-3-0" morph="none" pos="word" start_char="182">Es</TOKEN>
<TOKEN end_char="186" id="token-3-1" morph="none" pos="word" start_char="185">lo</TOKEN>
<TOKEN end_char="190" id="token-3-2" morph="none" pos="word" start_char="188">que</TOKEN>
<TOKEN end_char="193" id="token-3-3" morph="none" pos="word" start_char="192">ha</TOKEN>
<TOKEN end_char="202" id="token-3-4" morph="none" pos="word" start_char="195">revelado</TOKEN>
<TOKEN end_char="205" id="token-3-5" morph="none" pos="word" start_char="204">un</TOKEN>
<TOKEN end_char="213" id="token-3-6" morph="none" pos="word" start_char="207">estudio</TOKEN>
<TOKEN end_char="216" id="token-3-7" morph="none" pos="word" start_char="215">en</TOKEN>
<TOKEN end_char="229" id="token-3-8" morph="none" pos="word" start_char="218">colaboración</TOKEN>
<TOKEN end_char="233" id="token-3-9" morph="none" pos="word" start_char="231">con</TOKEN>
<TOKEN end_char="236" id="token-3-10" morph="none" pos="word" start_char="235">la</TOKEN>
<TOKEN end_char="248" id="token-3-11" morph="none" pos="word" start_char="238">Universidad</TOKEN>
<TOKEN end_char="256" id="token-3-12" morph="none" pos="word" start_char="250">Federal</TOKEN>
<TOKEN end_char="259" id="token-3-13" morph="none" pos="word" start_char="258">de</TOKEN>
<TOKEN end_char="265" id="token-3-14" morph="none" pos="word" start_char="261">Santa</TOKEN>
<TOKEN end_char="274" id="token-3-15" morph="none" pos="word" start_char="267">Catalina</TOKEN>
<TOKEN end_char="275" id="token-3-16" morph="none" pos="punct" start_char="275">,</TOKEN>
<TOKEN end_char="278" id="token-3-17" morph="none" pos="word" start_char="277">en</TOKEN>
<TOKEN end_char="292" id="token-3-18" morph="none" pos="word" start_char="280">Florianópolis</TOKEN>
<TOKEN end_char="294" id="token-3-19" morph="none" pos="punct" start_char="294">(</TOKEN>
<TOKEN end_char="300" id="token-3-20" morph="none" pos="word" start_char="295">Brasil</TOKEN>
<TOKEN end_char="302" id="token-3-21" morph="none" pos="punct" start_char="301">),</TOKEN>
<TOKEN end_char="305" id="token-3-22" morph="none" pos="word" start_char="304">en</TOKEN>
<TOKEN end_char="308" id="token-3-23" morph="none" pos="word" start_char="307">el</TOKEN>
<TOKEN end_char="313" id="token-3-24" morph="none" pos="word" start_char="310">cual</TOKEN>
<TOKEN end_char="317" id="token-3-25" morph="none" pos="word" start_char="315">han</TOKEN>
<TOKEN end_char="328" id="token-3-26" morph="none" pos="word" start_char="319">encontrado</TOKEN>
<TOKEN end_char="335" id="token-3-27" morph="none" pos="word" start_char="330">restos</TOKEN>
<TOKEN end_char="339" id="token-3-28" morph="none" pos="word" start_char="337">del</TOKEN>
<TOKEN end_char="345" id="token-3-29" morph="none" pos="word" start_char="341">virus</TOKEN>
<TOKEN end_char="348" id="token-3-30" morph="none" pos="word" start_char="347">en</TOKEN>
<TOKEN end_char="352" id="token-3-31" morph="none" pos="word" start_char="350">las</TOKEN>
<TOKEN end_char="358" id="token-3-32" morph="none" pos="word" start_char="354">aguas</TOKEN>
<TOKEN end_char="366" id="token-3-33" morph="none" pos="word" start_char="360">fecales</TOKEN>
<TOKEN end_char="370" id="token-3-34" morph="none" pos="word" start_char="368">del</TOKEN>
<TOKEN end_char="375" id="token-3-35" morph="none" pos="word" start_char="372">país</TOKEN>
<TOKEN end_char="391" id="token-3-36" morph="none" pos="word" start_char="377">latinoamericano</TOKEN>
<TOKEN end_char="392" id="token-3-37" morph="none" pos="punct" start_char="392">.</TOKEN>
<TRANSLATED_TEXT>This is what a study in collaboration with the Federal University of Santa Catalina in Florianópolis (Brazil) revealed, in which remains of the virus have been found in the fecal waters of the Latin American country.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="611" id="segment-4" start_char="394">
<ORIGINAL_TEXT>Este descubrimiento dataría del 27 de noviembre de 2019, no siendo hasta diciembre cuando se confirmaba el primer caso de la COVID-19 por parte de las autoridades chinas hacia la Organización Mundial de la Salud (OMS).</ORIGINAL_TEXT>
<TOKEN end_char="397" id="token-4-0" morph="none" pos="word" start_char="394">Este</TOKEN>
<TOKEN end_char="412" id="token-4-1" morph="none" pos="word" start_char="399">descubrimiento</TOKEN>
<TOKEN end_char="420" id="token-4-2" morph="none" pos="word" start_char="414">dataría</TOKEN>
<TOKEN end_char="424" id="token-4-3" morph="none" pos="word" start_char="422">del</TOKEN>
<TOKEN end_char="427" id="token-4-4" morph="none" pos="word" start_char="426">27</TOKEN>
<TOKEN end_char="430" id="token-4-5" morph="none" pos="word" start_char="429">de</TOKEN>
<TOKEN end_char="440" id="token-4-6" morph="none" pos="word" start_char="432">noviembre</TOKEN>
<TOKEN end_char="443" id="token-4-7" morph="none" pos="word" start_char="442">de</TOKEN>
<TOKEN end_char="448" id="token-4-8" morph="none" pos="word" start_char="445">2019</TOKEN>
<TOKEN end_char="449" id="token-4-9" morph="none" pos="punct" start_char="449">,</TOKEN>
<TOKEN end_char="452" id="token-4-10" morph="none" pos="word" start_char="451">no</TOKEN>
<TOKEN end_char="459" id="token-4-11" morph="none" pos="word" start_char="454">siendo</TOKEN>
<TOKEN end_char="465" id="token-4-12" morph="none" pos="word" start_char="461">hasta</TOKEN>
<TOKEN end_char="475" id="token-4-13" morph="none" pos="word" start_char="467">diciembre</TOKEN>
<TOKEN end_char="482" id="token-4-14" morph="none" pos="word" start_char="477">cuando</TOKEN>
<TOKEN end_char="485" id="token-4-15" morph="none" pos="word" start_char="484">se</TOKEN>
<TOKEN end_char="496" id="token-4-16" morph="none" pos="word" start_char="487">confirmaba</TOKEN>
<TOKEN end_char="499" id="token-4-17" morph="none" pos="word" start_char="498">el</TOKEN>
<TOKEN end_char="506" id="token-4-18" morph="none" pos="word" start_char="501">primer</TOKEN>
<TOKEN end_char="511" id="token-4-19" morph="none" pos="word" start_char="508">caso</TOKEN>
<TOKEN end_char="514" id="token-4-20" morph="none" pos="word" start_char="513">de</TOKEN>
<TOKEN end_char="517" id="token-4-21" morph="none" pos="word" start_char="516">la</TOKEN>
<TOKEN end_char="526" id="token-4-22" morph="none" pos="unknown" start_char="519">COVID-19</TOKEN>
<TOKEN end_char="530" id="token-4-23" morph="none" pos="word" start_char="528">por</TOKEN>
<TOKEN end_char="536" id="token-4-24" morph="none" pos="word" start_char="532">parte</TOKEN>
<TOKEN end_char="539" id="token-4-25" morph="none" pos="word" start_char="538">de</TOKEN>
<TOKEN end_char="543" id="token-4-26" morph="none" pos="word" start_char="541">las</TOKEN>
<TOKEN end_char="555" id="token-4-27" morph="none" pos="word" start_char="545">autoridades</TOKEN>
<TOKEN end_char="562" id="token-4-28" morph="none" pos="word" start_char="557">chinas</TOKEN>
<TOKEN end_char="568" id="token-4-29" morph="none" pos="word" start_char="564">hacia</TOKEN>
<TOKEN end_char="571" id="token-4-30" morph="none" pos="word" start_char="570">la</TOKEN>
<TOKEN end_char="584" id="token-4-31" morph="none" pos="word" start_char="573">Organización</TOKEN>
<TOKEN end_char="592" id="token-4-32" morph="none" pos="word" start_char="586">Mundial</TOKEN>
<TOKEN end_char="595" id="token-4-33" morph="none" pos="word" start_char="594">de</TOKEN>
<TOKEN end_char="598" id="token-4-34" morph="none" pos="word" start_char="597">la</TOKEN>
<TOKEN end_char="604" id="token-4-35" morph="none" pos="word" start_char="600">Salud</TOKEN>
<TOKEN end_char="606" id="token-4-36" morph="none" pos="punct" start_char="606">(</TOKEN>
<TOKEN end_char="609" id="token-4-37" morph="none" pos="word" start_char="607">OMS</TOKEN>
<TOKEN end_char="611" id="token-4-38" morph="none" pos="punct" start_char="610">).</TOKEN>
<TRANSLATED_TEXT>The first case of COVID-19 was confirmed by the Chinese authorities to the World Health Organization (WHO) on 27 November 2019.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="845" id="segment-5" start_char="614">
<ORIGINAL_TEXT>Así lo ha explicado David Rodríguez Lázaro, uno de los expertos que han participado en este estudio, en el cual pudieron recoger muestras desde inicio del otoño de 2019 hasta marzo de 2020, cuando se decretó la cuarentena en Brasil.</ORIGINAL_TEXT>
<TOKEN end_char="616" id="token-5-0" morph="none" pos="word" start_char="614">Así</TOKEN>
<TOKEN end_char="619" id="token-5-1" morph="none" pos="word" start_char="618">lo</TOKEN>
<TOKEN end_char="622" id="token-5-2" morph="none" pos="word" start_char="621">ha</TOKEN>
<TOKEN end_char="632" id="token-5-3" morph="none" pos="word" start_char="624">explicado</TOKEN>
<TOKEN end_char="638" id="token-5-4" morph="none" pos="word" start_char="634">David</TOKEN>
<TOKEN end_char="648" id="token-5-5" morph="none" pos="word" start_char="640">Rodríguez</TOKEN>
<TOKEN end_char="655" id="token-5-6" morph="none" pos="word" start_char="650">Lázaro</TOKEN>
<TOKEN end_char="656" id="token-5-7" morph="none" pos="punct" start_char="656">,</TOKEN>
<TOKEN end_char="660" id="token-5-8" morph="none" pos="word" start_char="658">uno</TOKEN>
<TOKEN end_char="663" id="token-5-9" morph="none" pos="word" start_char="662">de</TOKEN>
<TOKEN end_char="667" id="token-5-10" morph="none" pos="word" start_char="665">los</TOKEN>
<TOKEN end_char="676" id="token-5-11" morph="none" pos="word" start_char="669">expertos</TOKEN>
<TOKEN end_char="680" id="token-5-12" morph="none" pos="word" start_char="678">que</TOKEN>
<TOKEN end_char="684" id="token-5-13" morph="none" pos="word" start_char="682">han</TOKEN>
<TOKEN end_char="696" id="token-5-14" morph="none" pos="word" start_char="686">participado</TOKEN>
<TOKEN end_char="699" id="token-5-15" morph="none" pos="word" start_char="698">en</TOKEN>
<TOKEN end_char="704" id="token-5-16" morph="none" pos="word" start_char="701">este</TOKEN>
<TOKEN end_char="712" id="token-5-17" morph="none" pos="word" start_char="706">estudio</TOKEN>
<TOKEN end_char="713" id="token-5-18" morph="none" pos="punct" start_char="713">,</TOKEN>
<TOKEN end_char="716" id="token-5-19" morph="none" pos="word" start_char="715">en</TOKEN>
<TOKEN end_char="719" id="token-5-20" morph="none" pos="word" start_char="718">el</TOKEN>
<TOKEN end_char="724" id="token-5-21" morph="none" pos="word" start_char="721">cual</TOKEN>
<TOKEN end_char="733" id="token-5-22" morph="none" pos="word" start_char="726">pudieron</TOKEN>
<TOKEN end_char="741" id="token-5-23" morph="none" pos="word" start_char="735">recoger</TOKEN>
<TOKEN end_char="750" id="token-5-24" morph="none" pos="word" start_char="743">muestras</TOKEN>
<TOKEN end_char="756" id="token-5-25" morph="none" pos="word" start_char="752">desde</TOKEN>
<TOKEN end_char="763" id="token-5-26" morph="none" pos="word" start_char="758">inicio</TOKEN>
<TOKEN end_char="767" id="token-5-27" morph="none" pos="word" start_char="765">del</TOKEN>
<TOKEN end_char="773" id="token-5-28" morph="none" pos="word" start_char="769">otoño</TOKEN>
<TOKEN end_char="776" id="token-5-29" morph="none" pos="word" start_char="775">de</TOKEN>
<TOKEN end_char="781" id="token-5-30" morph="none" pos="word" start_char="778">2019</TOKEN>
<TOKEN end_char="787" id="token-5-31" morph="none" pos="word" start_char="783">hasta</TOKEN>
<TOKEN end_char="793" id="token-5-32" morph="none" pos="word" start_char="789">marzo</TOKEN>
<TOKEN end_char="796" id="token-5-33" morph="none" pos="word" start_char="795">de</TOKEN>
<TOKEN end_char="801" id="token-5-34" morph="none" pos="word" start_char="798">2020</TOKEN>
<TOKEN end_char="802" id="token-5-35" morph="none" pos="punct" start_char="802">,</TOKEN>
<TOKEN end_char="809" id="token-5-36" morph="none" pos="word" start_char="804">cuando</TOKEN>
<TOKEN end_char="812" id="token-5-37" morph="none" pos="word" start_char="811">se</TOKEN>
<TOKEN end_char="820" id="token-5-38" morph="none" pos="word" start_char="814">decretó</TOKEN>
<TOKEN end_char="823" id="token-5-39" morph="none" pos="word" start_char="822">la</TOKEN>
<TOKEN end_char="834" id="token-5-40" morph="none" pos="word" start_char="825">cuarentena</TOKEN>
<TOKEN end_char="837" id="token-5-41" morph="none" pos="word" start_char="836">en</TOKEN>
<TOKEN end_char="844" id="token-5-42" morph="none" pos="word" start_char="839">Brasil</TOKEN>
<TOKEN end_char="845" id="token-5-43" morph="none" pos="punct" start_char="845">.</TOKEN>
<TRANSLATED_TEXT>This was explained by David Rodríguez Lázaro, one of the experts who participated in this study, in which they were able to collect samples from the beginning of autumn 2019 until March 2020, when quarantine was decreed in Brazil.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1081" id="segment-6" start_char="847">
<ORIGINAL_TEXT>Con su análisis, bajo "un protocolo estándar de concentración de virus y posterior detección por PCR", pudieron ver que, efectivamente, el virus ya circulaba por el país hasta casi tres meses antes del primer caso confirmado en Brasil.</ORIGINAL_TEXT>
<TOKEN end_char="849" id="token-6-0" morph="none" pos="word" start_char="847">Con</TOKEN>
<TOKEN end_char="852" id="token-6-1" morph="none" pos="word" start_char="851">su</TOKEN>
<TOKEN end_char="861" id="token-6-2" morph="none" pos="word" start_char="854">análisis</TOKEN>
<TOKEN end_char="862" id="token-6-3" morph="none" pos="punct" start_char="862">,</TOKEN>
<TOKEN end_char="867" id="token-6-4" morph="none" pos="word" start_char="864">bajo</TOKEN>
<TOKEN end_char="869" id="token-6-5" morph="none" pos="punct" start_char="869">"</TOKEN>
<TOKEN end_char="871" id="token-6-6" morph="none" pos="word" start_char="870">un</TOKEN>
<TOKEN end_char="881" id="token-6-7" morph="none" pos="word" start_char="873">protocolo</TOKEN>
<TOKEN end_char="890" id="token-6-8" morph="none" pos="word" start_char="883">estándar</TOKEN>
<TOKEN end_char="893" id="token-6-9" morph="none" pos="word" start_char="892">de</TOKEN>
<TOKEN end_char="907" id="token-6-10" morph="none" pos="word" start_char="895">concentración</TOKEN>
<TOKEN end_char="910" id="token-6-11" morph="none" pos="word" start_char="909">de</TOKEN>
<TOKEN end_char="916" id="token-6-12" morph="none" pos="word" start_char="912">virus</TOKEN>
<TOKEN end_char="918" id="token-6-13" morph="none" pos="word" start_char="918">y</TOKEN>
<TOKEN end_char="928" id="token-6-14" morph="none" pos="word" start_char="920">posterior</TOKEN>
<TOKEN end_char="938" id="token-6-15" morph="none" pos="word" start_char="930">detección</TOKEN>
<TOKEN end_char="942" id="token-6-16" morph="none" pos="word" start_char="940">por</TOKEN>
<TOKEN end_char="946" id="token-6-17" morph="none" pos="word" start_char="944">PCR</TOKEN>
<TOKEN end_char="948" id="token-6-18" morph="none" pos="punct" start_char="947">",</TOKEN>
<TOKEN end_char="957" id="token-6-19" morph="none" pos="word" start_char="950">pudieron</TOKEN>
<TOKEN end_char="961" id="token-6-20" morph="none" pos="word" start_char="959">ver</TOKEN>
<TOKEN end_char="965" id="token-6-21" morph="none" pos="word" start_char="963">que</TOKEN>
<TOKEN end_char="966" id="token-6-22" morph="none" pos="punct" start_char="966">,</TOKEN>
<TOKEN end_char="980" id="token-6-23" morph="none" pos="word" start_char="968">efectivamente</TOKEN>
<TOKEN end_char="981" id="token-6-24" morph="none" pos="punct" start_char="981">,</TOKEN>
<TOKEN end_char="984" id="token-6-25" morph="none" pos="word" start_char="983">el</TOKEN>
<TOKEN end_char="990" id="token-6-26" morph="none" pos="word" start_char="986">virus</TOKEN>
<TOKEN end_char="993" id="token-6-27" morph="none" pos="word" start_char="992">ya</TOKEN>
<TOKEN end_char="1003" id="token-6-28" morph="none" pos="word" start_char="995">circulaba</TOKEN>
<TOKEN end_char="1007" id="token-6-29" morph="none" pos="word" start_char="1005">por</TOKEN>
<TOKEN end_char="1010" id="token-6-30" morph="none" pos="word" start_char="1009">el</TOKEN>
<TOKEN end_char="1015" id="token-6-31" morph="none" pos="word" start_char="1012">país</TOKEN>
<TOKEN end_char="1021" id="token-6-32" morph="none" pos="word" start_char="1017">hasta</TOKEN>
<TOKEN end_char="1026" id="token-6-33" morph="none" pos="word" start_char="1023">casi</TOKEN>
<TOKEN end_char="1031" id="token-6-34" morph="none" pos="word" start_char="1028">tres</TOKEN>
<TOKEN end_char="1037" id="token-6-35" morph="none" pos="word" start_char="1033">meses</TOKEN>
<TOKEN end_char="1043" id="token-6-36" morph="none" pos="word" start_char="1039">antes</TOKEN>
<TOKEN end_char="1047" id="token-6-37" morph="none" pos="word" start_char="1045">del</TOKEN>
<TOKEN end_char="1054" id="token-6-38" morph="none" pos="word" start_char="1049">primer</TOKEN>
<TOKEN end_char="1059" id="token-6-39" morph="none" pos="word" start_char="1056">caso</TOKEN>
<TOKEN end_char="1070" id="token-6-40" morph="none" pos="word" start_char="1061">confirmado</TOKEN>
<TOKEN end_char="1073" id="token-6-41" morph="none" pos="word" start_char="1072">en</TOKEN>
<TOKEN end_char="1080" id="token-6-42" morph="none" pos="word" start_char="1075">Brasil</TOKEN>
<TOKEN end_char="1081" id="token-6-43" morph="none" pos="punct" start_char="1081">.</TOKEN>
<TRANSLATED_TEXT>With their analysis, under "a standard protocol of virus concentration and subsequent PCR detection," they were able to see that, effectively, the virus was already circulating in the country until almost three months before the first confirmed case in Brazil..</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1217" id="segment-7" start_char="1084">
<ORIGINAL_TEXT>"Es casi dos meses, 56 días exactamente, antes de la primera descripción", comentaba el español en el programa ‘Horizonte’, de Cuatro.</ORIGINAL_TEXT>
<TOKEN end_char="1084" id="token-7-0" morph="none" pos="punct" start_char="1084">"</TOKEN>
<TOKEN end_char="1086" id="token-7-1" morph="none" pos="word" start_char="1085">Es</TOKEN>
<TOKEN end_char="1091" id="token-7-2" morph="none" pos="word" start_char="1088">casi</TOKEN>
<TOKEN end_char="1095" id="token-7-3" morph="none" pos="word" start_char="1093">dos</TOKEN>
<TOKEN end_char="1101" id="token-7-4" morph="none" pos="word" start_char="1097">meses</TOKEN>
<TOKEN end_char="1102" id="token-7-5" morph="none" pos="punct" start_char="1102">,</TOKEN>
<TOKEN end_char="1105" id="token-7-6" morph="none" pos="word" start_char="1104">56</TOKEN>
<TOKEN end_char="1110" id="token-7-7" morph="none" pos="word" start_char="1107">días</TOKEN>
<TOKEN end_char="1122" id="token-7-8" morph="none" pos="word" start_char="1112">exactamente</TOKEN>
<TOKEN end_char="1123" id="token-7-9" morph="none" pos="punct" start_char="1123">,</TOKEN>
<TOKEN end_char="1129" id="token-7-10" morph="none" pos="word" start_char="1125">antes</TOKEN>
<TOKEN end_char="1132" id="token-7-11" morph="none" pos="word" start_char="1131">de</TOKEN>
<TOKEN end_char="1135" id="token-7-12" morph="none" pos="word" start_char="1134">la</TOKEN>
<TOKEN end_char="1143" id="token-7-13" morph="none" pos="word" start_char="1137">primera</TOKEN>
<TOKEN end_char="1155" id="token-7-14" morph="none" pos="word" start_char="1145">descripción</TOKEN>
<TOKEN end_char="1157" id="token-7-15" morph="none" pos="punct" start_char="1156">",</TOKEN>
<TOKEN end_char="1167" id="token-7-16" morph="none" pos="word" start_char="1159">comentaba</TOKEN>
<TOKEN end_char="1170" id="token-7-17" morph="none" pos="word" start_char="1169">el</TOKEN>
<TOKEN end_char="1178" id="token-7-18" morph="none" pos="word" start_char="1172">español</TOKEN>
<TOKEN end_char="1181" id="token-7-19" morph="none" pos="word" start_char="1180">en</TOKEN>
<TOKEN end_char="1184" id="token-7-20" morph="none" pos="word" start_char="1183">el</TOKEN>
<TOKEN end_char="1193" id="token-7-21" morph="none" pos="word" start_char="1186">programa</TOKEN>
<TOKEN end_char="1195" id="token-7-22" morph="none" pos="punct" start_char="1195">‘</TOKEN>
<TOKEN end_char="1204" id="token-7-23" morph="none" pos="word" start_char="1196">Horizonte</TOKEN>
<TOKEN end_char="1206" id="token-7-24" morph="none" pos="punct" start_char="1205">’,</TOKEN>
<TOKEN end_char="1209" id="token-7-25" morph="none" pos="word" start_char="1208">de</TOKEN>
<TOKEN end_char="1216" id="token-7-26" morph="none" pos="word" start_char="1211">Cuatro</TOKEN>
<TOKEN end_char="1217" id="token-7-27" morph="none" pos="punct" start_char="1217">.</TOKEN>
<TRANSLATED_TEXT>"It's almost two months, 56 days exactly, before the first description," commented the Spanish in the program 'Horizonte', of Cuatro.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1334" id="segment-8" start_char="1219">
<ORIGINAL_TEXT>"El primer mensaje que obtenemos de este estudio es que el virus estaba circulando mucho antes de lo que pensábamos.</ORIGINAL_TEXT>
<TOKEN end_char="1219" id="token-8-0" morph="none" pos="punct" start_char="1219">"</TOKEN>
<TOKEN end_char="1221" id="token-8-1" morph="none" pos="word" start_char="1220">El</TOKEN>
<TOKEN end_char="1228" id="token-8-2" morph="none" pos="word" start_char="1223">primer</TOKEN>
<TOKEN end_char="1236" id="token-8-3" morph="none" pos="word" start_char="1230">mensaje</TOKEN>
<TOKEN end_char="1240" id="token-8-4" morph="none" pos="word" start_char="1238">que</TOKEN>
<TOKEN end_char="1250" id="token-8-5" morph="none" pos="word" start_char="1242">obtenemos</TOKEN>
<TOKEN end_char="1253" id="token-8-6" morph="none" pos="word" start_char="1252">de</TOKEN>
<TOKEN end_char="1258" id="token-8-7" morph="none" pos="word" start_char="1255">este</TOKEN>
<TOKEN end_char="1266" id="token-8-8" morph="none" pos="word" start_char="1260">estudio</TOKEN>
<TOKEN end_char="1269" id="token-8-9" morph="none" pos="word" start_char="1268">es</TOKEN>
<TOKEN end_char="1273" id="token-8-10" morph="none" pos="word" start_char="1271">que</TOKEN>
<TOKEN end_char="1276" id="token-8-11" morph="none" pos="word" start_char="1275">el</TOKEN>
<TOKEN end_char="1282" id="token-8-12" morph="none" pos="word" start_char="1278">virus</TOKEN>
<TOKEN end_char="1289" id="token-8-13" morph="none" pos="word" start_char="1284">estaba</TOKEN>
<TOKEN end_char="1300" id="token-8-14" morph="none" pos="word" start_char="1291">circulando</TOKEN>
<TOKEN end_char="1306" id="token-8-15" morph="none" pos="word" start_char="1302">mucho</TOKEN>
<TOKEN end_char="1312" id="token-8-16" morph="none" pos="word" start_char="1308">antes</TOKEN>
<TOKEN end_char="1315" id="token-8-17" morph="none" pos="word" start_char="1314">de</TOKEN>
<TOKEN end_char="1318" id="token-8-18" morph="none" pos="word" start_char="1317">lo</TOKEN>
<TOKEN end_char="1322" id="token-8-19" morph="none" pos="word" start_char="1320">que</TOKEN>
<TOKEN end_char="1333" id="token-8-20" morph="none" pos="word" start_char="1324">pensábamos</TOKEN>
<TOKEN end_char="1334" id="token-8-21" morph="none" pos="punct" start_char="1334">.</TOKEN>
<TRANSLATED_TEXT>The first message we get from this study is that the virus was circulating long before we thought.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1458" id="segment-9" start_char="1336">
<ORIGINAL_TEXT>Y lo segundo es que tenemos que plantearnos cuándo, realmente, este virus empezó a estar presente en la comunidad mundial".</ORIGINAL_TEXT>
<TOKEN end_char="1336" id="token-9-0" morph="none" pos="word" start_char="1336">Y</TOKEN>
<TOKEN end_char="1339" id="token-9-1" morph="none" pos="word" start_char="1338">lo</TOKEN>
<TOKEN end_char="1347" id="token-9-2" morph="none" pos="word" start_char="1341">segundo</TOKEN>
<TOKEN end_char="1350" id="token-9-3" morph="none" pos="word" start_char="1349">es</TOKEN>
<TOKEN end_char="1354" id="token-9-4" morph="none" pos="word" start_char="1352">que</TOKEN>
<TOKEN end_char="1362" id="token-9-5" morph="none" pos="word" start_char="1356">tenemos</TOKEN>
<TOKEN end_char="1366" id="token-9-6" morph="none" pos="word" start_char="1364">que</TOKEN>
<TOKEN end_char="1378" id="token-9-7" morph="none" pos="word" start_char="1368">plantearnos</TOKEN>
<TOKEN end_char="1385" id="token-9-8" morph="none" pos="word" start_char="1380">cuándo</TOKEN>
<TOKEN end_char="1386" id="token-9-9" morph="none" pos="punct" start_char="1386">,</TOKEN>
<TOKEN end_char="1396" id="token-9-10" morph="none" pos="word" start_char="1388">realmente</TOKEN>
<TOKEN end_char="1397" id="token-9-11" morph="none" pos="punct" start_char="1397">,</TOKEN>
<TOKEN end_char="1402" id="token-9-12" morph="none" pos="word" start_char="1399">este</TOKEN>
<TOKEN end_char="1408" id="token-9-13" morph="none" pos="word" start_char="1404">virus</TOKEN>
<TOKEN end_char="1415" id="token-9-14" morph="none" pos="word" start_char="1410">empezó</TOKEN>
<TOKEN end_char="1417" id="token-9-15" morph="none" pos="word" start_char="1417">a</TOKEN>
<TOKEN end_char="1423" id="token-9-16" morph="none" pos="word" start_char="1419">estar</TOKEN>
<TOKEN end_char="1432" id="token-9-17" morph="none" pos="word" start_char="1425">presente</TOKEN>
<TOKEN end_char="1435" id="token-9-18" morph="none" pos="word" start_char="1434">en</TOKEN>
<TOKEN end_char="1438" id="token-9-19" morph="none" pos="word" start_char="1437">la</TOKEN>
<TOKEN end_char="1448" id="token-9-20" morph="none" pos="word" start_char="1440">comunidad</TOKEN>
<TOKEN end_char="1456" id="token-9-21" morph="none" pos="word" start_char="1450">mundial</TOKEN>
<TOKEN end_char="1458" id="token-9-22" morph="none" pos="punct" start_char="1457">".</TOKEN>
<TRANSLATED_TEXT>And the second is that we have to ask ourselves when, really, this virus began to be present in the global community. "</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1505" id="segment-10" start_char="1461">
<ORIGINAL_TEXT>La fecha exacta del origen del virus, en duda</ORIGINAL_TEXT>
<TOKEN end_char="1462" id="token-10-0" morph="none" pos="word" start_char="1461">La</TOKEN>
<TOKEN end_char="1468" id="token-10-1" morph="none" pos="word" start_char="1464">fecha</TOKEN>
<TOKEN end_char="1475" id="token-10-2" morph="none" pos="word" start_char="1470">exacta</TOKEN>
<TOKEN end_char="1479" id="token-10-3" morph="none" pos="word" start_char="1477">del</TOKEN>
<TOKEN end_char="1486" id="token-10-4" morph="none" pos="word" start_char="1481">origen</TOKEN>
<TOKEN end_char="1490" id="token-10-5" morph="none" pos="word" start_char="1488">del</TOKEN>
<TOKEN end_char="1496" id="token-10-6" morph="none" pos="word" start_char="1492">virus</TOKEN>
<TOKEN end_char="1497" id="token-10-7" morph="none" pos="punct" start_char="1497">,</TOKEN>
<TOKEN end_char="1500" id="token-10-8" morph="none" pos="word" start_char="1499">en</TOKEN>
<TOKEN end_char="1505" id="token-10-9" morph="none" pos="word" start_char="1502">duda</TOKEN>
<TRANSLATED_TEXT>The exact date of the virus's origin, in doubt</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1598" id="segment-11" start_char="1509">
<ORIGINAL_TEXT>Estos resultados hacen que la fecha exacta de la aparición del virus sea todo un misterio.</ORIGINAL_TEXT>
<TOKEN end_char="1513" id="token-11-0" morph="none" pos="word" start_char="1509">Estos</TOKEN>
<TOKEN end_char="1524" id="token-11-1" morph="none" pos="word" start_char="1515">resultados</TOKEN>
<TOKEN end_char="1530" id="token-11-2" morph="none" pos="word" start_char="1526">hacen</TOKEN>
<TOKEN end_char="1534" id="token-11-3" morph="none" pos="word" start_char="1532">que</TOKEN>
<TOKEN end_char="1537" id="token-11-4" morph="none" pos="word" start_char="1536">la</TOKEN>
<TOKEN end_char="1543" id="token-11-5" morph="none" pos="word" start_char="1539">fecha</TOKEN>
<TOKEN end_char="1550" id="token-11-6" morph="none" pos="word" start_char="1545">exacta</TOKEN>
<TOKEN end_char="1553" id="token-11-7" morph="none" pos="word" start_char="1552">de</TOKEN>
<TOKEN end_char="1556" id="token-11-8" morph="none" pos="word" start_char="1555">la</TOKEN>
<TOKEN end_char="1566" id="token-11-9" morph="none" pos="word" start_char="1558">aparición</TOKEN>
<TOKEN end_char="1570" id="token-11-10" morph="none" pos="word" start_char="1568">del</TOKEN>
<TOKEN end_char="1576" id="token-11-11" morph="none" pos="word" start_char="1572">virus</TOKEN>
<TOKEN end_char="1580" id="token-11-12" morph="none" pos="word" start_char="1578">sea</TOKEN>
<TOKEN end_char="1585" id="token-11-13" morph="none" pos="word" start_char="1582">todo</TOKEN>
<TOKEN end_char="1588" id="token-11-14" morph="none" pos="word" start_char="1587">un</TOKEN>
<TOKEN end_char="1597" id="token-11-15" morph="none" pos="word" start_char="1590">misterio</TOKEN>
<TOKEN end_char="1598" id="token-11-16" morph="none" pos="punct" start_char="1598">.</TOKEN>
<TRANSLATED_TEXT>These results make the exact date of the virus's appearance a mystery.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1795" id="segment-12" start_char="1600">
<ORIGINAL_TEXT>Según Rodríguez Lázaro, el origen de la COVID-19 sigue siendo un misterio aunque, todos los expertos, coinciden en que "es indudable que se trata de un virus de origen animal, un virus zoonótico".</ORIGINAL_TEXT>
<TOKEN end_char="1604" id="token-12-0" morph="none" pos="word" start_char="1600">Según</TOKEN>
<TOKEN end_char="1614" id="token-12-1" morph="none" pos="word" start_char="1606">Rodríguez</TOKEN>
<TOKEN end_char="1621" id="token-12-2" morph="none" pos="word" start_char="1616">Lázaro</TOKEN>
<TOKEN end_char="1622" id="token-12-3" morph="none" pos="punct" start_char="1622">,</TOKEN>
<TOKEN end_char="1625" id="token-12-4" morph="none" pos="word" start_char="1624">el</TOKEN>
<TOKEN end_char="1632" id="token-12-5" morph="none" pos="word" start_char="1627">origen</TOKEN>
<TOKEN end_char="1635" id="token-12-6" morph="none" pos="word" start_char="1634">de</TOKEN>
<TOKEN end_char="1638" id="token-12-7" morph="none" pos="word" start_char="1637">la</TOKEN>
<TOKEN end_char="1647" id="token-12-8" morph="none" pos="unknown" start_char="1640">COVID-19</TOKEN>
<TOKEN end_char="1653" id="token-12-9" morph="none" pos="word" start_char="1649">sigue</TOKEN>
<TOKEN end_char="1660" id="token-12-10" morph="none" pos="word" start_char="1655">siendo</TOKEN>
<TOKEN end_char="1663" id="token-12-11" morph="none" pos="word" start_char="1662">un</TOKEN>
<TOKEN end_char="1672" id="token-12-12" morph="none" pos="word" start_char="1665">misterio</TOKEN>
<TOKEN end_char="1679" id="token-12-13" morph="none" pos="word" start_char="1674">aunque</TOKEN>
<TOKEN end_char="1680" id="token-12-14" morph="none" pos="punct" start_char="1680">,</TOKEN>
<TOKEN end_char="1686" id="token-12-15" morph="none" pos="word" start_char="1682">todos</TOKEN>
<TOKEN end_char="1690" id="token-12-16" morph="none" pos="word" start_char="1688">los</TOKEN>
<TOKEN end_char="1699" id="token-12-17" morph="none" pos="word" start_char="1692">expertos</TOKEN>
<TOKEN end_char="1700" id="token-12-18" morph="none" pos="punct" start_char="1700">,</TOKEN>
<TOKEN end_char="1710" id="token-12-19" morph="none" pos="word" start_char="1702">coinciden</TOKEN>
<TOKEN end_char="1713" id="token-12-20" morph="none" pos="word" start_char="1712">en</TOKEN>
<TOKEN end_char="1717" id="token-12-21" morph="none" pos="word" start_char="1715">que</TOKEN>
<TOKEN end_char="1719" id="token-12-22" morph="none" pos="punct" start_char="1719">"</TOKEN>
<TOKEN end_char="1721" id="token-12-23" morph="none" pos="word" start_char="1720">es</TOKEN>
<TOKEN end_char="1731" id="token-12-24" morph="none" pos="word" start_char="1723">indudable</TOKEN>
<TOKEN end_char="1735" id="token-12-25" morph="none" pos="word" start_char="1733">que</TOKEN>
<TOKEN end_char="1738" id="token-12-26" morph="none" pos="word" start_char="1737">se</TOKEN>
<TOKEN end_char="1744" id="token-12-27" morph="none" pos="word" start_char="1740">trata</TOKEN>
<TOKEN end_char="1747" id="token-12-28" morph="none" pos="word" start_char="1746">de</TOKEN>
<TOKEN end_char="1750" id="token-12-29" morph="none" pos="word" start_char="1749">un</TOKEN>
<TOKEN end_char="1756" id="token-12-30" morph="none" pos="word" start_char="1752">virus</TOKEN>
<TOKEN end_char="1759" id="token-12-31" morph="none" pos="word" start_char="1758">de</TOKEN>
<TOKEN end_char="1766" id="token-12-32" morph="none" pos="word" start_char="1761">origen</TOKEN>
<TOKEN end_char="1773" id="token-12-33" morph="none" pos="word" start_char="1768">animal</TOKEN>
<TOKEN end_char="1774" id="token-12-34" morph="none" pos="punct" start_char="1774">,</TOKEN>
<TOKEN end_char="1777" id="token-12-35" morph="none" pos="word" start_char="1776">un</TOKEN>
<TOKEN end_char="1783" id="token-12-36" morph="none" pos="word" start_char="1779">virus</TOKEN>
<TOKEN end_char="1793" id="token-12-37" morph="none" pos="word" start_char="1785">zoonótico</TOKEN>
<TOKEN end_char="1795" id="token-12-38" morph="none" pos="punct" start_char="1794">".</TOKEN>
<TRANSLATED_TEXT>According to Rodriguez Lázaro, the origin of COVID-19 remains a mystery although, all experts agree that "it is undoubtedly an animal virus, a zoonotic virus."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="1939" id="segment-13" start_char="1797">
<ORIGINAL_TEXT>Además, pese a que el mercado de Wuhan no haya sido el origen principal del coronavirus, sí ha sido "un detonante" para al expansión del mismo.</ORIGINAL_TEXT>
<TOKEN end_char="1802" id="token-13-0" morph="none" pos="word" start_char="1797">Además</TOKEN>
<TOKEN end_char="1803" id="token-13-1" morph="none" pos="punct" start_char="1803">,</TOKEN>
<TOKEN end_char="1808" id="token-13-2" morph="none" pos="word" start_char="1805">pese</TOKEN>
<TOKEN end_char="1810" id="token-13-3" morph="none" pos="word" start_char="1810">a</TOKEN>
<TOKEN end_char="1814" id="token-13-4" morph="none" pos="word" start_char="1812">que</TOKEN>
<TOKEN end_char="1817" id="token-13-5" morph="none" pos="word" start_char="1816">el</TOKEN>
<TOKEN end_char="1825" id="token-13-6" morph="none" pos="word" start_char="1819">mercado</TOKEN>
<TOKEN end_char="1828" id="token-13-7" morph="none" pos="word" start_char="1827">de</TOKEN>
<TOKEN end_char="1834" id="token-13-8" morph="none" pos="word" start_char="1830">Wuhan</TOKEN>
<TOKEN end_char="1837" id="token-13-9" morph="none" pos="word" start_char="1836">no</TOKEN>
<TOKEN end_char="1842" id="token-13-10" morph="none" pos="word" start_char="1839">haya</TOKEN>
<TOKEN end_char="1847" id="token-13-11" morph="none" pos="word" start_char="1844">sido</TOKEN>
<TOKEN end_char="1850" id="token-13-12" morph="none" pos="word" start_char="1849">el</TOKEN>
<TOKEN end_char="1857" id="token-13-13" morph="none" pos="word" start_char="1852">origen</TOKEN>
<TOKEN end_char="1867" id="token-13-14" morph="none" pos="word" start_char="1859">principal</TOKEN>
<TOKEN end_char="1871" id="token-13-15" morph="none" pos="word" start_char="1869">del</TOKEN>
<TOKEN end_char="1883" id="token-13-16" morph="none" pos="word" start_char="1873">coronavirus</TOKEN>
<TOKEN end_char="1884" id="token-13-17" morph="none" pos="punct" start_char="1884">,</TOKEN>
<TOKEN end_char="1887" id="token-13-18" morph="none" pos="word" start_char="1886">sí</TOKEN>
<TOKEN end_char="1890" id="token-13-19" morph="none" pos="word" start_char="1889">ha</TOKEN>
<TOKEN end_char="1895" id="token-13-20" morph="none" pos="word" start_char="1892">sido</TOKEN>
<TOKEN end_char="1897" id="token-13-21" morph="none" pos="punct" start_char="1897">"</TOKEN>
<TOKEN end_char="1899" id="token-13-22" morph="none" pos="word" start_char="1898">un</TOKEN>
<TOKEN end_char="1909" id="token-13-23" morph="none" pos="word" start_char="1901">detonante</TOKEN>
<TOKEN end_char="1910" id="token-13-24" morph="none" pos="punct" start_char="1910">"</TOKEN>
<TOKEN end_char="1915" id="token-13-25" morph="none" pos="word" start_char="1912">para</TOKEN>
<TOKEN end_char="1918" id="token-13-26" morph="none" pos="word" start_char="1917">al</TOKEN>
<TOKEN end_char="1928" id="token-13-27" morph="none" pos="word" start_char="1920">expansión</TOKEN>
<TOKEN end_char="1932" id="token-13-28" morph="none" pos="word" start_char="1930">del</TOKEN>
<TOKEN end_char="1938" id="token-13-29" morph="none" pos="word" start_char="1934">mismo</TOKEN>
<TOKEN end_char="1939" id="token-13-30" morph="none" pos="punct" start_char="1939">.</TOKEN>
<TRANSLATED_TEXT>Furthermore, although the Wuhan market has not been the main source of coronavirus, it has been a "trigger" for its expansion.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2042" id="segment-14" start_char="1941">
<ORIGINAL_TEXT>"Es muy posible", indica el español, teniendo en cuenta la costumbre de "consumo de animales exótico".</ORIGINAL_TEXT>
<TOKEN end_char="1941" id="token-14-0" morph="none" pos="punct" start_char="1941">"</TOKEN>
<TOKEN end_char="1943" id="token-14-1" morph="none" pos="word" start_char="1942">Es</TOKEN>
<TOKEN end_char="1947" id="token-14-2" morph="none" pos="word" start_char="1945">muy</TOKEN>
<TOKEN end_char="1955" id="token-14-3" morph="none" pos="word" start_char="1949">posible</TOKEN>
<TOKEN end_char="1957" id="token-14-4" morph="none" pos="punct" start_char="1956">",</TOKEN>
<TOKEN end_char="1964" id="token-14-5" morph="none" pos="word" start_char="1959">indica</TOKEN>
<TOKEN end_char="1967" id="token-14-6" morph="none" pos="word" start_char="1966">el</TOKEN>
<TOKEN end_char="1975" id="token-14-7" morph="none" pos="word" start_char="1969">español</TOKEN>
<TOKEN end_char="1976" id="token-14-8" morph="none" pos="punct" start_char="1976">,</TOKEN>
<TOKEN end_char="1985" id="token-14-9" morph="none" pos="word" start_char="1978">teniendo</TOKEN>
<TOKEN end_char="1988" id="token-14-10" morph="none" pos="word" start_char="1987">en</TOKEN>
<TOKEN end_char="1995" id="token-14-11" morph="none" pos="word" start_char="1990">cuenta</TOKEN>
<TOKEN end_char="1998" id="token-14-12" morph="none" pos="word" start_char="1997">la</TOKEN>
<TOKEN end_char="2008" id="token-14-13" morph="none" pos="word" start_char="2000">costumbre</TOKEN>
<TOKEN end_char="2011" id="token-14-14" morph="none" pos="word" start_char="2010">de</TOKEN>
<TOKEN end_char="2013" id="token-14-15" morph="none" pos="punct" start_char="2013">"</TOKEN>
<TOKEN end_char="2020" id="token-14-16" morph="none" pos="word" start_char="2014">consumo</TOKEN>
<TOKEN end_char="2023" id="token-14-17" morph="none" pos="word" start_char="2022">de</TOKEN>
<TOKEN end_char="2032" id="token-14-18" morph="none" pos="word" start_char="2025">animales</TOKEN>
<TOKEN end_char="2040" id="token-14-19" morph="none" pos="word" start_char="2034">exótico</TOKEN>
<TOKEN end_char="2042" id="token-14-20" morph="none" pos="punct" start_char="2041">".</TOKEN>
<TRANSLATED_TEXT>"It's very possible," says the Spanish, taking into account the custom of "eating exotic animals."</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2167" id="segment-15" start_char="2045">
<ORIGINAL_TEXT>"Que lo hayamos encontrado en Brasil, en noviembre de 2019, lo único que significa es que el virus estaba circulando antes.</ORIGINAL_TEXT>
<TOKEN end_char="2045" id="token-15-0" morph="none" pos="punct" start_char="2045">"</TOKEN>
<TOKEN end_char="2048" id="token-15-1" morph="none" pos="word" start_char="2046">Que</TOKEN>
<TOKEN end_char="2051" id="token-15-2" morph="none" pos="word" start_char="2050">lo</TOKEN>
<TOKEN end_char="2059" id="token-15-3" morph="none" pos="word" start_char="2053">hayamos</TOKEN>
<TOKEN end_char="2070" id="token-15-4" morph="none" pos="word" start_char="2061">encontrado</TOKEN>
<TOKEN end_char="2073" id="token-15-5" morph="none" pos="word" start_char="2072">en</TOKEN>
<TOKEN end_char="2080" id="token-15-6" morph="none" pos="word" start_char="2075">Brasil</TOKEN>
<TOKEN end_char="2081" id="token-15-7" morph="none" pos="punct" start_char="2081">,</TOKEN>
<TOKEN end_char="2084" id="token-15-8" morph="none" pos="word" start_char="2083">en</TOKEN>
<TOKEN end_char="2094" id="token-15-9" morph="none" pos="word" start_char="2086">noviembre</TOKEN>
<TOKEN end_char="2097" id="token-15-10" morph="none" pos="word" start_char="2096">de</TOKEN>
<TOKEN end_char="2102" id="token-15-11" morph="none" pos="word" start_char="2099">2019</TOKEN>
<TOKEN end_char="2103" id="token-15-12" morph="none" pos="punct" start_char="2103">,</TOKEN>
<TOKEN end_char="2106" id="token-15-13" morph="none" pos="word" start_char="2105">lo</TOKEN>
<TOKEN end_char="2112" id="token-15-14" morph="none" pos="word" start_char="2108">único</TOKEN>
<TOKEN end_char="2116" id="token-15-15" morph="none" pos="word" start_char="2114">que</TOKEN>
<TOKEN end_char="2126" id="token-15-16" morph="none" pos="word" start_char="2118">significa</TOKEN>
<TOKEN end_char="2129" id="token-15-17" morph="none" pos="word" start_char="2128">es</TOKEN>
<TOKEN end_char="2133" id="token-15-18" morph="none" pos="word" start_char="2131">que</TOKEN>
<TOKEN end_char="2136" id="token-15-19" morph="none" pos="word" start_char="2135">el</TOKEN>
<TOKEN end_char="2142" id="token-15-20" morph="none" pos="word" start_char="2138">virus</TOKEN>
<TOKEN end_char="2149" id="token-15-21" morph="none" pos="word" start_char="2144">estaba</TOKEN>
<TOKEN end_char="2160" id="token-15-22" morph="none" pos="word" start_char="2151">circulando</TOKEN>
<TOKEN end_char="2166" id="token-15-23" morph="none" pos="word" start_char="2162">antes</TOKEN>
<TOKEN end_char="2167" id="token-15-24" morph="none" pos="punct" start_char="2167">.</TOKEN>
<TRANSLATED_TEXT>That we found it in Brazil, in November 2019, all it means is that the virus was circulating before.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
<SEG end_char="2360" id="segment-16" start_char="2169">
<ORIGINAL_TEXT>Todos estamos de acuerdo es que no podemos datar de manera segura cuándo apareció, pero lo que podemos decir es que el virus estaba presente antes de los casos reportados", explica el experto.</ORIGINAL_TEXT>
<TOKEN end_char="2173" id="token-16-0" morph="none" pos="word" start_char="2169">Todos</TOKEN>
<TOKEN end_char="2181" id="token-16-1" morph="none" pos="word" start_char="2175">estamos</TOKEN>
<TOKEN end_char="2184" id="token-16-2" morph="none" pos="word" start_char="2183">de</TOKEN>
<TOKEN end_char="2192" id="token-16-3" morph="none" pos="word" start_char="2186">acuerdo</TOKEN>
<TOKEN end_char="2195" id="token-16-4" morph="none" pos="word" start_char="2194">es</TOKEN>
<TOKEN end_char="2199" id="token-16-5" morph="none" pos="word" start_char="2197">que</TOKEN>
<TOKEN end_char="2202" id="token-16-6" morph="none" pos="word" start_char="2201">no</TOKEN>
<TOKEN end_char="2210" id="token-16-7" morph="none" pos="word" start_char="2204">podemos</TOKEN>
<TOKEN end_char="2216" id="token-16-8" morph="none" pos="word" start_char="2212">datar</TOKEN>
<TOKEN end_char="2219" id="token-16-9" morph="none" pos="word" start_char="2218">de</TOKEN>
<TOKEN end_char="2226" id="token-16-10" morph="none" pos="word" start_char="2221">manera</TOKEN>
<TOKEN end_char="2233" id="token-16-11" morph="none" pos="word" start_char="2228">segura</TOKEN>
<TOKEN end_char="2240" id="token-16-12" morph="none" pos="word" start_char="2235">cuándo</TOKEN>
<TOKEN end_char="2249" id="token-16-13" morph="none" pos="word" start_char="2242">apareció</TOKEN>
<TOKEN end_char="2250" id="token-16-14" morph="none" pos="punct" start_char="2250">,</TOKEN>
<TOKEN end_char="2255" id="token-16-15" morph="none" pos="word" start_char="2252">pero</TOKEN>
<TOKEN end_char="2258" id="token-16-16" morph="none" pos="word" start_char="2257">lo</TOKEN>
<TOKEN end_char="2262" id="token-16-17" morph="none" pos="word" start_char="2260">que</TOKEN>
<TOKEN end_char="2270" id="token-16-18" morph="none" pos="word" start_char="2264">podemos</TOKEN>
<TOKEN end_char="2276" id="token-16-19" morph="none" pos="word" start_char="2272">decir</TOKEN>
<TOKEN end_char="2279" id="token-16-20" morph="none" pos="word" start_char="2278">es</TOKEN>
<TOKEN end_char="2283" id="token-16-21" morph="none" pos="word" start_char="2281">que</TOKEN>
<TOKEN end_char="2286" id="token-16-22" morph="none" pos="word" start_char="2285">el</TOKEN>
<TOKEN end_char="2292" id="token-16-23" morph="none" pos="word" start_char="2288">virus</TOKEN>
<TOKEN end_char="2299" id="token-16-24" morph="none" pos="word" start_char="2294">estaba</TOKEN>
<TOKEN end_char="2308" id="token-16-25" morph="none" pos="word" start_char="2301">presente</TOKEN>
<TOKEN end_char="2314" id="token-16-26" morph="none" pos="word" start_char="2310">antes</TOKEN>
<TOKEN end_char="2317" id="token-16-27" morph="none" pos="word" start_char="2316">de</TOKEN>
<TOKEN end_char="2321" id="token-16-28" morph="none" pos="word" start_char="2319">los</TOKEN>
<TOKEN end_char="2327" id="token-16-29" morph="none" pos="word" start_char="2323">casos</TOKEN>
<TOKEN end_char="2338" id="token-16-30" morph="none" pos="word" start_char="2329">reportados</TOKEN>
<TOKEN end_char="2340" id="token-16-31" morph="none" pos="punct" start_char="2339">",</TOKEN>
<TOKEN end_char="2348" id="token-16-32" morph="none" pos="word" start_char="2342">explica</TOKEN>
<TOKEN end_char="2351" id="token-16-33" morph="none" pos="word" start_char="2350">el</TOKEN>
<TOKEN end_char="2359" id="token-16-34" morph="none" pos="word" start_char="2353">experto</TOKEN>
<TOKEN end_char="2360" id="token-16-35" morph="none" pos="punct" start_char="2360">.</TOKEN>
<TRANSLATED_TEXT>We all agree that we cannot date reliably when it appeared, but what we can say is that the virus was present before the reported cases, "explains the expert.</TRANSLATED_TEXT><DETECTED_LANGUAGE>es</DETECTED_LANGUAGE></SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
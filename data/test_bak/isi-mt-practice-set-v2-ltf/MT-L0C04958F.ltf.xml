<LCTL_TEXT lang="rus">
<DOC grammar="none" id="L0C04958F" lang="rus" raw_text_char_length="19522" raw_text_md5="6894a1c1a6d48b6421cf1c8d18283a71" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="89" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Coronavirus: Institut Pasteur warns against false information circulating on social media</ORIGINAL_TEXT>
<TOKEN end_char="11" id="token-0-0" morph="none" pos="word" start_char="1">Coronavirus</TOKEN>
<TOKEN end_char="12" id="token-0-1" morph="none" pos="punct" start_char="12">:</TOKEN>
<TOKEN end_char="21" id="token-0-2" morph="none" pos="word" start_char="14">Institut</TOKEN>
<TOKEN end_char="29" id="token-0-3" morph="none" pos="word" start_char="23">Pasteur</TOKEN>
<TOKEN end_char="35" id="token-0-4" morph="none" pos="word" start_char="31">warns</TOKEN>
<TOKEN end_char="43" id="token-0-5" morph="none" pos="word" start_char="37">against</TOKEN>
<TOKEN end_char="49" id="token-0-6" morph="none" pos="word" start_char="45">false</TOKEN>
<TOKEN end_char="61" id="token-0-7" morph="none" pos="word" start_char="51">information</TOKEN>
<TOKEN end_char="73" id="token-0-8" morph="none" pos="word" start_char="63">circulating</TOKEN>
<TOKEN end_char="76" id="token-0-9" morph="none" pos="word" start_char="75">on</TOKEN>
<TOKEN end_char="83" id="token-0-10" morph="none" pos="word" start_char="78">social</TOKEN>
<TOKEN end_char="89" id="token-0-11" morph="none" pos="word" start_char="85">media</TOKEN>
</SEG>
<SEG end_char="225" id="segment-1" start_char="93">
<ORIGINAL_TEXT>As the Covid-19 outbreak continues to spread in France, multiple information are circulating on social media and messaging platforms.</ORIGINAL_TEXT>
<TOKEN end_char="94" id="token-1-0" morph="none" pos="word" start_char="93">As</TOKEN>
<TOKEN end_char="98" id="token-1-1" morph="none" pos="word" start_char="96">the</TOKEN>
<TOKEN end_char="107" id="token-1-2" morph="none" pos="unknown" start_char="100">Covid-19</TOKEN>
<TOKEN end_char="116" id="token-1-3" morph="none" pos="word" start_char="109">outbreak</TOKEN>
<TOKEN end_char="126" id="token-1-4" morph="none" pos="word" start_char="118">continues</TOKEN>
<TOKEN end_char="129" id="token-1-5" morph="none" pos="word" start_char="128">to</TOKEN>
<TOKEN end_char="136" id="token-1-6" morph="none" pos="word" start_char="131">spread</TOKEN>
<TOKEN end_char="139" id="token-1-7" morph="none" pos="word" start_char="138">in</TOKEN>
<TOKEN end_char="146" id="token-1-8" morph="none" pos="word" start_char="141">France</TOKEN>
<TOKEN end_char="147" id="token-1-9" morph="none" pos="punct" start_char="147">,</TOKEN>
<TOKEN end_char="156" id="token-1-10" morph="none" pos="word" start_char="149">multiple</TOKEN>
<TOKEN end_char="168" id="token-1-11" morph="none" pos="word" start_char="158">information</TOKEN>
<TOKEN end_char="172" id="token-1-12" morph="none" pos="word" start_char="170">are</TOKEN>
<TOKEN end_char="184" id="token-1-13" morph="none" pos="word" start_char="174">circulating</TOKEN>
<TOKEN end_char="187" id="token-1-14" morph="none" pos="word" start_char="186">on</TOKEN>
<TOKEN end_char="194" id="token-1-15" morph="none" pos="word" start_char="189">social</TOKEN>
<TOKEN end_char="200" id="token-1-16" morph="none" pos="word" start_char="196">media</TOKEN>
<TOKEN end_char="204" id="token-1-17" morph="none" pos="word" start_char="202">and</TOKEN>
<TOKEN end_char="214" id="token-1-18" morph="none" pos="word" start_char="206">messaging</TOKEN>
<TOKEN end_char="224" id="token-1-19" morph="none" pos="word" start_char="216">platforms</TOKEN>
<TOKEN end_char="225" id="token-1-20" morph="none" pos="punct" start_char="225">.</TOKEN>
</SEG>
<SEG end_char="366" id="segment-2" start_char="227">
<ORIGINAL_TEXT>Some of these messages contain misleading information, and some are supposedly based on the expertise of scientists at the Institut Pasteur.</ORIGINAL_TEXT>
<TOKEN end_char="230" id="token-2-0" morph="none" pos="word" start_char="227">Some</TOKEN>
<TOKEN end_char="233" id="token-2-1" morph="none" pos="word" start_char="232">of</TOKEN>
<TOKEN end_char="239" id="token-2-2" morph="none" pos="word" start_char="235">these</TOKEN>
<TOKEN end_char="248" id="token-2-3" morph="none" pos="word" start_char="241">messages</TOKEN>
<TOKEN end_char="256" id="token-2-4" morph="none" pos="word" start_char="250">contain</TOKEN>
<TOKEN end_char="267" id="token-2-5" morph="none" pos="word" start_char="258">misleading</TOKEN>
<TOKEN end_char="279" id="token-2-6" morph="none" pos="word" start_char="269">information</TOKEN>
<TOKEN end_char="280" id="token-2-7" morph="none" pos="punct" start_char="280">,</TOKEN>
<TOKEN end_char="284" id="token-2-8" morph="none" pos="word" start_char="282">and</TOKEN>
<TOKEN end_char="289" id="token-2-9" morph="none" pos="word" start_char="286">some</TOKEN>
<TOKEN end_char="293" id="token-2-10" morph="none" pos="word" start_char="291">are</TOKEN>
<TOKEN end_char="304" id="token-2-11" morph="none" pos="word" start_char="295">supposedly</TOKEN>
<TOKEN end_char="310" id="token-2-12" morph="none" pos="word" start_char="306">based</TOKEN>
<TOKEN end_char="313" id="token-2-13" morph="none" pos="word" start_char="312">on</TOKEN>
<TOKEN end_char="317" id="token-2-14" morph="none" pos="word" start_char="315">the</TOKEN>
<TOKEN end_char="327" id="token-2-15" morph="none" pos="word" start_char="319">expertise</TOKEN>
<TOKEN end_char="330" id="token-2-16" morph="none" pos="word" start_char="329">of</TOKEN>
<TOKEN end_char="341" id="token-2-17" morph="none" pos="word" start_char="332">scientists</TOKEN>
<TOKEN end_char="344" id="token-2-18" morph="none" pos="word" start_char="343">at</TOKEN>
<TOKEN end_char="348" id="token-2-19" morph="none" pos="word" start_char="346">the</TOKEN>
<TOKEN end_char="357" id="token-2-20" morph="none" pos="word" start_char="350">Institut</TOKEN>
<TOKEN end_char="365" id="token-2-21" morph="none" pos="word" start_char="359">Pasteur</TOKEN>
<TOKEN end_char="366" id="token-2-22" morph="none" pos="punct" start_char="366">.</TOKEN>
</SEG>
<SEG end_char="462" id="segment-3" start_char="368">
<ORIGINAL_TEXT>The Institut Pasteur asks you not to take any notice of this information and not to pass it on.</ORIGINAL_TEXT>
<TOKEN end_char="370" id="token-3-0" morph="none" pos="word" start_char="368">The</TOKEN>
<TOKEN end_char="379" id="token-3-1" morph="none" pos="word" start_char="372">Institut</TOKEN>
<TOKEN end_char="387" id="token-3-2" morph="none" pos="word" start_char="381">Pasteur</TOKEN>
<TOKEN end_char="392" id="token-3-3" morph="none" pos="word" start_char="389">asks</TOKEN>
<TOKEN end_char="396" id="token-3-4" morph="none" pos="word" start_char="394">you</TOKEN>
<TOKEN end_char="400" id="token-3-5" morph="none" pos="word" start_char="398">not</TOKEN>
<TOKEN end_char="403" id="token-3-6" morph="none" pos="word" start_char="402">to</TOKEN>
<TOKEN end_char="408" id="token-3-7" morph="none" pos="word" start_char="405">take</TOKEN>
<TOKEN end_char="412" id="token-3-8" morph="none" pos="word" start_char="410">any</TOKEN>
<TOKEN end_char="419" id="token-3-9" morph="none" pos="word" start_char="414">notice</TOKEN>
<TOKEN end_char="422" id="token-3-10" morph="none" pos="word" start_char="421">of</TOKEN>
<TOKEN end_char="427" id="token-3-11" morph="none" pos="word" start_char="424">this</TOKEN>
<TOKEN end_char="439" id="token-3-12" morph="none" pos="word" start_char="429">information</TOKEN>
<TOKEN end_char="443" id="token-3-13" morph="none" pos="word" start_char="441">and</TOKEN>
<TOKEN end_char="447" id="token-3-14" morph="none" pos="word" start_char="445">not</TOKEN>
<TOKEN end_char="450" id="token-3-15" morph="none" pos="word" start_char="449">to</TOKEN>
<TOKEN end_char="455" id="token-3-16" morph="none" pos="word" start_char="452">pass</TOKEN>
<TOKEN end_char="458" id="token-3-17" morph="none" pos="word" start_char="457">it</TOKEN>
<TOKEN end_char="461" id="token-3-18" morph="none" pos="word" start_char="460">on</TOKEN>
<TOKEN end_char="462" id="token-3-19" morph="none" pos="punct" start_char="462">.</TOKEN>
</SEG>
<SEG end_char="556" id="segment-4" start_char="465">
<ORIGINAL_TEXT>For official information about the research carried out at the Institut Pasteur, click here.</ORIGINAL_TEXT>
<TOKEN end_char="467" id="token-4-0" morph="none" pos="word" start_char="465">For</TOKEN>
<TOKEN end_char="476" id="token-4-1" morph="none" pos="word" start_char="469">official</TOKEN>
<TOKEN end_char="488" id="token-4-2" morph="none" pos="word" start_char="478">information</TOKEN>
<TOKEN end_char="494" id="token-4-3" morph="none" pos="word" start_char="490">about</TOKEN>
<TOKEN end_char="498" id="token-4-4" morph="none" pos="word" start_char="496">the</TOKEN>
<TOKEN end_char="507" id="token-4-5" morph="none" pos="word" start_char="500">research</TOKEN>
<TOKEN end_char="515" id="token-4-6" morph="none" pos="word" start_char="509">carried</TOKEN>
<TOKEN end_char="519" id="token-4-7" morph="none" pos="word" start_char="517">out</TOKEN>
<TOKEN end_char="522" id="token-4-8" morph="none" pos="word" start_char="521">at</TOKEN>
<TOKEN end_char="526" id="token-4-9" morph="none" pos="word" start_char="524">the</TOKEN>
<TOKEN end_char="535" id="token-4-10" morph="none" pos="word" start_char="528">Institut</TOKEN>
<TOKEN end_char="543" id="token-4-11" morph="none" pos="word" start_char="537">Pasteur</TOKEN>
<TOKEN end_char="544" id="token-4-12" morph="none" pos="punct" start_char="544">,</TOKEN>
<TOKEN end_char="550" id="token-4-13" morph="none" pos="word" start_char="546">click</TOKEN>
<TOKEN end_char="555" id="token-4-14" morph="none" pos="word" start_char="552">here</TOKEN>
<TOKEN end_char="556" id="token-4-15" morph="none" pos="punct" start_char="556">.</TOKEN>
</SEG>
<SEG end_char="667" id="segment-5" start_char="559">
<ORIGINAL_TEXT>You can also follow the Institut Pasteur via its official Facebook, Twitter, LinkedIn and Instagram accounts.</ORIGINAL_TEXT>
<TOKEN end_char="561" id="token-5-0" morph="none" pos="word" start_char="559">You</TOKEN>
<TOKEN end_char="565" id="token-5-1" morph="none" pos="word" start_char="563">can</TOKEN>
<TOKEN end_char="570" id="token-5-2" morph="none" pos="word" start_char="567">also</TOKEN>
<TOKEN end_char="577" id="token-5-3" morph="none" pos="word" start_char="572">follow</TOKEN>
<TOKEN end_char="581" id="token-5-4" morph="none" pos="word" start_char="579">the</TOKEN>
<TOKEN end_char="590" id="token-5-5" morph="none" pos="word" start_char="583">Institut</TOKEN>
<TOKEN end_char="598" id="token-5-6" morph="none" pos="word" start_char="592">Pasteur</TOKEN>
<TOKEN end_char="602" id="token-5-7" morph="none" pos="word" start_char="600">via</TOKEN>
<TOKEN end_char="606" id="token-5-8" morph="none" pos="word" start_char="604">its</TOKEN>
<TOKEN end_char="615" id="token-5-9" morph="none" pos="word" start_char="608">official</TOKEN>
<TOKEN end_char="624" id="token-5-10" morph="none" pos="word" start_char="617">Facebook</TOKEN>
<TOKEN end_char="625" id="token-5-11" morph="none" pos="punct" start_char="625">,</TOKEN>
<TOKEN end_char="633" id="token-5-12" morph="none" pos="word" start_char="627">Twitter</TOKEN>
<TOKEN end_char="634" id="token-5-13" morph="none" pos="punct" start_char="634">,</TOKEN>
<TOKEN end_char="643" id="token-5-14" morph="none" pos="word" start_char="636">LinkedIn</TOKEN>
<TOKEN end_char="647" id="token-5-15" morph="none" pos="word" start_char="645">and</TOKEN>
<TOKEN end_char="657" id="token-5-16" morph="none" pos="word" start_char="649">Instagram</TOKEN>
<TOKEN end_char="666" id="token-5-17" morph="none" pos="word" start_char="659">accounts</TOKEN>
<TOKEN end_char="667" id="token-5-18" morph="none" pos="punct" start_char="667">.</TOKEN>
</SEG>
<SEG end_char="809" id="segment-6" start_char="670">
<ORIGINAL_TEXT>The Institut Pasteur's scientists have been working since the early days of the Covid-19 outbreak to deal with this unprecedented situation.</ORIGINAL_TEXT>
<TOKEN end_char="672" id="token-6-0" morph="none" pos="word" start_char="670">The</TOKEN>
<TOKEN end_char="681" id="token-6-1" morph="none" pos="word" start_char="674">Institut</TOKEN>
<TOKEN end_char="691" id="token-6-2" morph="none" pos="word" start_char="683">Pasteur's</TOKEN>
<TOKEN end_char="702" id="token-6-3" morph="none" pos="word" start_char="693">scientists</TOKEN>
<TOKEN end_char="707" id="token-6-4" morph="none" pos="word" start_char="704">have</TOKEN>
<TOKEN end_char="712" id="token-6-5" morph="none" pos="word" start_char="709">been</TOKEN>
<TOKEN end_char="720" id="token-6-6" morph="none" pos="word" start_char="714">working</TOKEN>
<TOKEN end_char="726" id="token-6-7" morph="none" pos="word" start_char="722">since</TOKEN>
<TOKEN end_char="730" id="token-6-8" morph="none" pos="word" start_char="728">the</TOKEN>
<TOKEN end_char="736" id="token-6-9" morph="none" pos="word" start_char="732">early</TOKEN>
<TOKEN end_char="741" id="token-6-10" morph="none" pos="word" start_char="738">days</TOKEN>
<TOKEN end_char="744" id="token-6-11" morph="none" pos="word" start_char="743">of</TOKEN>
<TOKEN end_char="748" id="token-6-12" morph="none" pos="word" start_char="746">the</TOKEN>
<TOKEN end_char="757" id="token-6-13" morph="none" pos="unknown" start_char="750">Covid-19</TOKEN>
<TOKEN end_char="766" id="token-6-14" morph="none" pos="word" start_char="759">outbreak</TOKEN>
<TOKEN end_char="769" id="token-6-15" morph="none" pos="word" start_char="768">to</TOKEN>
<TOKEN end_char="774" id="token-6-16" morph="none" pos="word" start_char="771">deal</TOKEN>
<TOKEN end_char="779" id="token-6-17" morph="none" pos="word" start_char="776">with</TOKEN>
<TOKEN end_char="784" id="token-6-18" morph="none" pos="word" start_char="781">this</TOKEN>
<TOKEN end_char="798" id="token-6-19" morph="none" pos="word" start_char="786">unprecedented</TOKEN>
<TOKEN end_char="808" id="token-6-20" morph="none" pos="word" start_char="800">situation</TOKEN>
<TOKEN end_char="809" id="token-6-21" morph="none" pos="punct" start_char="809">.</TOKEN>
</SEG>
<SEG end_char="835" id="segment-7" start_char="812">
<ORIGINAL_TEXT>Updated December 1, 2020</ORIGINAL_TEXT>
<TOKEN end_char="818" id="token-7-0" morph="none" pos="word" start_char="812">Updated</TOKEN>
<TOKEN end_char="827" id="token-7-1" morph="none" pos="word" start_char="820">December</TOKEN>
<TOKEN end_char="829" id="token-7-2" morph="none" pos="word" start_char="829">1</TOKEN>
<TOKEN end_char="830" id="token-7-3" morph="none" pos="punct" start_char="830">,</TOKEN>
<TOKEN end_char="835" id="token-7-4" morph="none" pos="word" start_char="832">2020</TOKEN>
</SEG>
<SEG end_char="994" id="segment-8" start_char="839">
<ORIGINAL_TEXT>NO, the Institut Pasteur did not create the SARS-CoV-2 virus and release it in the city of Wuhan to cause the pandemic and implicate the Chinese authorities</ORIGINAL_TEXT>
<TOKEN end_char="840" id="token-8-0" morph="none" pos="word" start_char="839">NO</TOKEN>
<TOKEN end_char="841" id="token-8-1" morph="none" pos="punct" start_char="841">,</TOKEN>
<TOKEN end_char="845" id="token-8-2" morph="none" pos="word" start_char="843">the</TOKEN>
<TOKEN end_char="854" id="token-8-3" morph="none" pos="word" start_char="847">Institut</TOKEN>
<TOKEN end_char="862" id="token-8-4" morph="none" pos="word" start_char="856">Pasteur</TOKEN>
<TOKEN end_char="866" id="token-8-5" morph="none" pos="word" start_char="864">did</TOKEN>
<TOKEN end_char="870" id="token-8-6" morph="none" pos="word" start_char="868">not</TOKEN>
<TOKEN end_char="877" id="token-8-7" morph="none" pos="word" start_char="872">create</TOKEN>
<TOKEN end_char="881" id="token-8-8" morph="none" pos="word" start_char="879">the</TOKEN>
<TOKEN end_char="892" id="token-8-9" morph="none" pos="unknown" start_char="883">SARS-CoV-2</TOKEN>
<TOKEN end_char="898" id="token-8-10" morph="none" pos="word" start_char="894">virus</TOKEN>
<TOKEN end_char="902" id="token-8-11" morph="none" pos="word" start_char="900">and</TOKEN>
<TOKEN end_char="910" id="token-8-12" morph="none" pos="word" start_char="904">release</TOKEN>
<TOKEN end_char="913" id="token-8-13" morph="none" pos="word" start_char="912">it</TOKEN>
<TOKEN end_char="916" id="token-8-14" morph="none" pos="word" start_char="915">in</TOKEN>
<TOKEN end_char="920" id="token-8-15" morph="none" pos="word" start_char="918">the</TOKEN>
<TOKEN end_char="925" id="token-8-16" morph="none" pos="word" start_char="922">city</TOKEN>
<TOKEN end_char="928" id="token-8-17" morph="none" pos="word" start_char="927">of</TOKEN>
<TOKEN end_char="934" id="token-8-18" morph="none" pos="word" start_char="930">Wuhan</TOKEN>
<TOKEN end_char="937" id="token-8-19" morph="none" pos="word" start_char="936">to</TOKEN>
<TOKEN end_char="943" id="token-8-20" morph="none" pos="word" start_char="939">cause</TOKEN>
<TOKEN end_char="947" id="token-8-21" morph="none" pos="word" start_char="945">the</TOKEN>
<TOKEN end_char="956" id="token-8-22" morph="none" pos="word" start_char="949">pandemic</TOKEN>
<TOKEN end_char="960" id="token-8-23" morph="none" pos="word" start_char="958">and</TOKEN>
<TOKEN end_char="970" id="token-8-24" morph="none" pos="word" start_char="962">implicate</TOKEN>
<TOKEN end_char="974" id="token-8-25" morph="none" pos="word" start_char="972">the</TOKEN>
<TOKEN end_char="982" id="token-8-26" morph="none" pos="word" start_char="976">Chinese</TOKEN>
<TOKEN end_char="994" id="token-8-27" morph="none" pos="word" start_char="984">authorities</TOKEN>
</SEG>
<SEG end_char="1021" id="segment-9" start_char="997">
<ORIGINAL_TEXT>Text of October 22, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="1000" id="token-9-0" morph="none" pos="word" start_char="997">Text</TOKEN>
<TOKEN end_char="1003" id="token-9-1" morph="none" pos="word" start_char="1002">of</TOKEN>
<TOKEN end_char="1011" id="token-9-2" morph="none" pos="word" start_char="1005">October</TOKEN>
<TOKEN end_char="1014" id="token-9-3" morph="none" pos="word" start_char="1013">22</TOKEN>
<TOKEN end_char="1015" id="token-9-4" morph="none" pos="punct" start_char="1015">,</TOKEN>
<TOKEN end_char="1020" id="token-9-5" morph="none" pos="word" start_char="1017">2020</TOKEN>
<TOKEN end_char="1021" id="token-9-6" morph="none" pos="punct" start_char="1021">.</TOKEN>
</SEG>
<SEG end_char="1047" id="segment-10" start_char="1024">
<ORIGINAL_TEXT>Updated December 1, 2020</ORIGINAL_TEXT>
<TOKEN end_char="1030" id="token-10-0" morph="none" pos="word" start_char="1024">Updated</TOKEN>
<TOKEN end_char="1039" id="token-10-1" morph="none" pos="word" start_char="1032">December</TOKEN>
<TOKEN end_char="1041" id="token-10-2" morph="none" pos="word" start_char="1041">1</TOKEN>
<TOKEN end_char="1042" id="token-10-3" morph="none" pos="punct" start_char="1042">,</TOKEN>
<TOKEN end_char="1047" id="token-10-4" morph="none" pos="word" start_char="1044">2020</TOKEN>
</SEG>
<SEG end_char="1050" id="segment-11" start_char="1050">
<ORIGINAL_TEXT>.</ORIGINAL_TEXT>
<TOKEN end_char="1050" id="token-11-0" morph="none" pos="punct" start_char="1050">.</TOKEN>
</SEG>
<SEG end_char="1241" id="segment-12" start_char="1054">
<ORIGINAL_TEXT>After a first defamatory video in March 2020, new videos have been circulating online since late August 2020 claiming to trace the supposedly premeditated history of the COVID-19 pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="1058" id="token-12-0" morph="none" pos="word" start_char="1054">After</TOKEN>
<TOKEN end_char="1060" id="token-12-1" morph="none" pos="word" start_char="1060">a</TOKEN>
<TOKEN end_char="1066" id="token-12-2" morph="none" pos="word" start_char="1062">first</TOKEN>
<TOKEN end_char="1077" id="token-12-3" morph="none" pos="word" start_char="1068">defamatory</TOKEN>
<TOKEN end_char="1083" id="token-12-4" morph="none" pos="word" start_char="1079">video</TOKEN>
<TOKEN end_char="1086" id="token-12-5" morph="none" pos="word" start_char="1085">in</TOKEN>
<TOKEN end_char="1092" id="token-12-6" morph="none" pos="word" start_char="1088">March</TOKEN>
<TOKEN end_char="1097" id="token-12-7" morph="none" pos="word" start_char="1094">2020</TOKEN>
<TOKEN end_char="1098" id="token-12-8" morph="none" pos="punct" start_char="1098">,</TOKEN>
<TOKEN end_char="1102" id="token-12-9" morph="none" pos="word" start_char="1100">new</TOKEN>
<TOKEN end_char="1109" id="token-12-10" morph="none" pos="word" start_char="1104">videos</TOKEN>
<TOKEN end_char="1114" id="token-12-11" morph="none" pos="word" start_char="1111">have</TOKEN>
<TOKEN end_char="1119" id="token-12-12" morph="none" pos="word" start_char="1116">been</TOKEN>
<TOKEN end_char="1131" id="token-12-13" morph="none" pos="word" start_char="1121">circulating</TOKEN>
<TOKEN end_char="1138" id="token-12-14" morph="none" pos="word" start_char="1133">online</TOKEN>
<TOKEN end_char="1144" id="token-12-15" morph="none" pos="word" start_char="1140">since</TOKEN>
<TOKEN end_char="1149" id="token-12-16" morph="none" pos="word" start_char="1146">late</TOKEN>
<TOKEN end_char="1156" id="token-12-17" morph="none" pos="word" start_char="1151">August</TOKEN>
<TOKEN end_char="1161" id="token-12-18" morph="none" pos="word" start_char="1158">2020</TOKEN>
<TOKEN end_char="1170" id="token-12-19" morph="none" pos="word" start_char="1163">claiming</TOKEN>
<TOKEN end_char="1173" id="token-12-20" morph="none" pos="word" start_char="1172">to</TOKEN>
<TOKEN end_char="1179" id="token-12-21" morph="none" pos="word" start_char="1175">trace</TOKEN>
<TOKEN end_char="1183" id="token-12-22" morph="none" pos="word" start_char="1181">the</TOKEN>
<TOKEN end_char="1194" id="token-12-23" morph="none" pos="word" start_char="1185">supposedly</TOKEN>
<TOKEN end_char="1207" id="token-12-24" morph="none" pos="word" start_char="1196">premeditated</TOKEN>
<TOKEN end_char="1215" id="token-12-25" morph="none" pos="word" start_char="1209">history</TOKEN>
<TOKEN end_char="1218" id="token-12-26" morph="none" pos="word" start_char="1217">of</TOKEN>
<TOKEN end_char="1222" id="token-12-27" morph="none" pos="word" start_char="1220">the</TOKEN>
<TOKEN end_char="1231" id="token-12-28" morph="none" pos="unknown" start_char="1224">COVID-19</TOKEN>
<TOKEN end_char="1240" id="token-12-29" morph="none" pos="word" start_char="1233">pandemic</TOKEN>
<TOKEN end_char="1241" id="token-12-30" morph="none" pos="punct" start_char="1241">.</TOKEN>
</SEG>
<SEG end_char="1323" id="segment-13" start_char="1243">
<ORIGINAL_TEXT>The information contained in these videos is pure conspiracy and of course false.</ORIGINAL_TEXT>
<TOKEN end_char="1245" id="token-13-0" morph="none" pos="word" start_char="1243">The</TOKEN>
<TOKEN end_char="1257" id="token-13-1" morph="none" pos="word" start_char="1247">information</TOKEN>
<TOKEN end_char="1267" id="token-13-2" morph="none" pos="word" start_char="1259">contained</TOKEN>
<TOKEN end_char="1270" id="token-13-3" morph="none" pos="word" start_char="1269">in</TOKEN>
<TOKEN end_char="1276" id="token-13-4" morph="none" pos="word" start_char="1272">these</TOKEN>
<TOKEN end_char="1283" id="token-13-5" morph="none" pos="word" start_char="1278">videos</TOKEN>
<TOKEN end_char="1286" id="token-13-6" morph="none" pos="word" start_char="1285">is</TOKEN>
<TOKEN end_char="1291" id="token-13-7" morph="none" pos="word" start_char="1288">pure</TOKEN>
<TOKEN end_char="1302" id="token-13-8" morph="none" pos="word" start_char="1293">conspiracy</TOKEN>
<TOKEN end_char="1306" id="token-13-9" morph="none" pos="word" start_char="1304">and</TOKEN>
<TOKEN end_char="1309" id="token-13-10" morph="none" pos="word" start_char="1308">of</TOKEN>
<TOKEN end_char="1316" id="token-13-11" morph="none" pos="word" start_char="1311">course</TOKEN>
<TOKEN end_char="1322" id="token-13-12" morph="none" pos="word" start_char="1318">false</TOKEN>
<TOKEN end_char="1323" id="token-13-13" morph="none" pos="punct" start_char="1323">.</TOKEN>
</SEG>
<SEG end_char="1393" id="segment-14" start_char="1327">
<ORIGINAL_TEXT>The SARS-CoV-2 coronavirus was not created by the Institut Pasteur.</ORIGINAL_TEXT>
<TOKEN end_char="1329" id="token-14-0" morph="none" pos="word" start_char="1327">The</TOKEN>
<TOKEN end_char="1340" id="token-14-1" morph="none" pos="unknown" start_char="1331">SARS-CoV-2</TOKEN>
<TOKEN end_char="1352" id="token-14-2" morph="none" pos="word" start_char="1342">coronavirus</TOKEN>
<TOKEN end_char="1356" id="token-14-3" morph="none" pos="word" start_char="1354">was</TOKEN>
<TOKEN end_char="1360" id="token-14-4" morph="none" pos="word" start_char="1358">not</TOKEN>
<TOKEN end_char="1368" id="token-14-5" morph="none" pos="word" start_char="1362">created</TOKEN>
<TOKEN end_char="1371" id="token-14-6" morph="none" pos="word" start_char="1370">by</TOKEN>
<TOKEN end_char="1375" id="token-14-7" morph="none" pos="word" start_char="1373">the</TOKEN>
<TOKEN end_char="1384" id="token-14-8" morph="none" pos="word" start_char="1377">Institut</TOKEN>
<TOKEN end_char="1392" id="token-14-9" morph="none" pos="word" start_char="1386">Pasteur</TOKEN>
<TOKEN end_char="1393" id="token-14-10" morph="none" pos="punct" start_char="1393">.</TOKEN>
</SEG>
<SEG end_char="1477" id="segment-15" start_char="1399">
<ORIGINAL_TEXT>The Institut Pasteur did not release any viruses in the city of Wuhan in China!</ORIGINAL_TEXT>
<TOKEN end_char="1401" id="token-15-0" morph="none" pos="word" start_char="1399">The</TOKEN>
<TOKEN end_char="1410" id="token-15-1" morph="none" pos="word" start_char="1403">Institut</TOKEN>
<TOKEN end_char="1418" id="token-15-2" morph="none" pos="word" start_char="1412">Pasteur</TOKEN>
<TOKEN end_char="1422" id="token-15-3" morph="none" pos="word" start_char="1420">did</TOKEN>
<TOKEN end_char="1426" id="token-15-4" morph="none" pos="word" start_char="1424">not</TOKEN>
<TOKEN end_char="1434" id="token-15-5" morph="none" pos="word" start_char="1428">release</TOKEN>
<TOKEN end_char="1438" id="token-15-6" morph="none" pos="word" start_char="1436">any</TOKEN>
<TOKEN end_char="1446" id="token-15-7" morph="none" pos="word" start_char="1440">viruses</TOKEN>
<TOKEN end_char="1449" id="token-15-8" morph="none" pos="word" start_char="1448">in</TOKEN>
<TOKEN end_char="1453" id="token-15-9" morph="none" pos="word" start_char="1451">the</TOKEN>
<TOKEN end_char="1458" id="token-15-10" morph="none" pos="word" start_char="1455">city</TOKEN>
<TOKEN end_char="1461" id="token-15-11" morph="none" pos="word" start_char="1460">of</TOKEN>
<TOKEN end_char="1467" id="token-15-12" morph="none" pos="word" start_char="1463">Wuhan</TOKEN>
<TOKEN end_char="1470" id="token-15-13" morph="none" pos="word" start_char="1469">in</TOKEN>
<TOKEN end_char="1476" id="token-15-14" morph="none" pos="word" start_char="1472">China</TOKEN>
<TOKEN end_char="1477" id="token-15-15" morph="none" pos="punct" start_char="1477">!</TOKEN>
</SEG>
<SEG end_char="1645" id="segment-16" start_char="1483">
<ORIGINAL_TEXT>The Institut Pasteur is not a laboratory belonging to the Sanofi pharmaceutical group or its subsidiary Sanofi-Pasteur; it is an independent non-profit foundation.</ORIGINAL_TEXT>
<TOKEN end_char="1485" id="token-16-0" morph="none" pos="word" start_char="1483">The</TOKEN>
<TOKEN end_char="1494" id="token-16-1" morph="none" pos="word" start_char="1487">Institut</TOKEN>
<TOKEN end_char="1502" id="token-16-2" morph="none" pos="word" start_char="1496">Pasteur</TOKEN>
<TOKEN end_char="1505" id="token-16-3" morph="none" pos="word" start_char="1504">is</TOKEN>
<TOKEN end_char="1509" id="token-16-4" morph="none" pos="word" start_char="1507">not</TOKEN>
<TOKEN end_char="1511" id="token-16-5" morph="none" pos="word" start_char="1511">a</TOKEN>
<TOKEN end_char="1522" id="token-16-6" morph="none" pos="word" start_char="1513">laboratory</TOKEN>
<TOKEN end_char="1532" id="token-16-7" morph="none" pos="word" start_char="1524">belonging</TOKEN>
<TOKEN end_char="1535" id="token-16-8" morph="none" pos="word" start_char="1534">to</TOKEN>
<TOKEN end_char="1539" id="token-16-9" morph="none" pos="word" start_char="1537">the</TOKEN>
<TOKEN end_char="1546" id="token-16-10" morph="none" pos="word" start_char="1541">Sanofi</TOKEN>
<TOKEN end_char="1561" id="token-16-11" morph="none" pos="word" start_char="1548">pharmaceutical</TOKEN>
<TOKEN end_char="1567" id="token-16-12" morph="none" pos="word" start_char="1563">group</TOKEN>
<TOKEN end_char="1570" id="token-16-13" morph="none" pos="word" start_char="1569">or</TOKEN>
<TOKEN end_char="1574" id="token-16-14" morph="none" pos="word" start_char="1572">its</TOKEN>
<TOKEN end_char="1585" id="token-16-15" morph="none" pos="word" start_char="1576">subsidiary</TOKEN>
<TOKEN end_char="1600" id="token-16-16" morph="none" pos="unknown" start_char="1587">Sanofi-Pasteur</TOKEN>
<TOKEN end_char="1601" id="token-16-17" morph="none" pos="punct" start_char="1601">;</TOKEN>
<TOKEN end_char="1604" id="token-16-18" morph="none" pos="word" start_char="1603">it</TOKEN>
<TOKEN end_char="1607" id="token-16-19" morph="none" pos="word" start_char="1606">is</TOKEN>
<TOKEN end_char="1610" id="token-16-20" morph="none" pos="word" start_char="1609">an</TOKEN>
<TOKEN end_char="1622" id="token-16-21" morph="none" pos="word" start_char="1612">independent</TOKEN>
<TOKEN end_char="1633" id="token-16-22" morph="none" pos="unknown" start_char="1624">non-profit</TOKEN>
<TOKEN end_char="1644" id="token-16-23" morph="none" pos="word" start_char="1635">foundation</TOKEN>
<TOKEN end_char="1645" id="token-16-24" morph="none" pos="punct" start_char="1645">.</TOKEN>
</SEG>
<SEG end_char="1789" id="segment-17" start_char="1651">
<ORIGINAL_TEXT>Asserting that the Institut Pasteur is planning to enslave and control the global population is utterly false and devoid of all foundation.</ORIGINAL_TEXT>
<TOKEN end_char="1659" id="token-17-0" morph="none" pos="word" start_char="1651">Asserting</TOKEN>
<TOKEN end_char="1664" id="token-17-1" morph="none" pos="word" start_char="1661">that</TOKEN>
<TOKEN end_char="1668" id="token-17-2" morph="none" pos="word" start_char="1666">the</TOKEN>
<TOKEN end_char="1677" id="token-17-3" morph="none" pos="word" start_char="1670">Institut</TOKEN>
<TOKEN end_char="1685" id="token-17-4" morph="none" pos="word" start_char="1679">Pasteur</TOKEN>
<TOKEN end_char="1688" id="token-17-5" morph="none" pos="word" start_char="1687">is</TOKEN>
<TOKEN end_char="1697" id="token-17-6" morph="none" pos="word" start_char="1690">planning</TOKEN>
<TOKEN end_char="1700" id="token-17-7" morph="none" pos="word" start_char="1699">to</TOKEN>
<TOKEN end_char="1708" id="token-17-8" morph="none" pos="word" start_char="1702">enslave</TOKEN>
<TOKEN end_char="1712" id="token-17-9" morph="none" pos="word" start_char="1710">and</TOKEN>
<TOKEN end_char="1720" id="token-17-10" morph="none" pos="word" start_char="1714">control</TOKEN>
<TOKEN end_char="1724" id="token-17-11" morph="none" pos="word" start_char="1722">the</TOKEN>
<TOKEN end_char="1731" id="token-17-12" morph="none" pos="word" start_char="1726">global</TOKEN>
<TOKEN end_char="1742" id="token-17-13" morph="none" pos="word" start_char="1733">population</TOKEN>
<TOKEN end_char="1745" id="token-17-14" morph="none" pos="word" start_char="1744">is</TOKEN>
<TOKEN end_char="1753" id="token-17-15" morph="none" pos="word" start_char="1747">utterly</TOKEN>
<TOKEN end_char="1759" id="token-17-16" morph="none" pos="word" start_char="1755">false</TOKEN>
<TOKEN end_char="1763" id="token-17-17" morph="none" pos="word" start_char="1761">and</TOKEN>
<TOKEN end_char="1770" id="token-17-18" morph="none" pos="word" start_char="1765">devoid</TOKEN>
<TOKEN end_char="1773" id="token-17-19" morph="none" pos="word" start_char="1772">of</TOKEN>
<TOKEN end_char="1777" id="token-17-20" morph="none" pos="word" start_char="1775">all</TOKEN>
<TOKEN end_char="1788" id="token-17-21" morph="none" pos="word" start_char="1779">foundation</TOKEN>
<TOKEN end_char="1789" id="token-17-22" morph="none" pos="punct" start_char="1789">.</TOKEN>
</SEG>
<SEG end_char="1922" id="segment-18" start_char="1795">
<ORIGINAL_TEXT>In response to these defamatory claims, and for the first time since its inception, the Institut Pasteur has lodged a complaint.</ORIGINAL_TEXT>
<TOKEN end_char="1796" id="token-18-0" morph="none" pos="word" start_char="1795">In</TOKEN>
<TOKEN end_char="1805" id="token-18-1" morph="none" pos="word" start_char="1798">response</TOKEN>
<TOKEN end_char="1808" id="token-18-2" morph="none" pos="word" start_char="1807">to</TOKEN>
<TOKEN end_char="1814" id="token-18-3" morph="none" pos="word" start_char="1810">these</TOKEN>
<TOKEN end_char="1825" id="token-18-4" morph="none" pos="word" start_char="1816">defamatory</TOKEN>
<TOKEN end_char="1832" id="token-18-5" morph="none" pos="word" start_char="1827">claims</TOKEN>
<TOKEN end_char="1833" id="token-18-6" morph="none" pos="punct" start_char="1833">,</TOKEN>
<TOKEN end_char="1837" id="token-18-7" morph="none" pos="word" start_char="1835">and</TOKEN>
<TOKEN end_char="1841" id="token-18-8" morph="none" pos="word" start_char="1839">for</TOKEN>
<TOKEN end_char="1845" id="token-18-9" morph="none" pos="word" start_char="1843">the</TOKEN>
<TOKEN end_char="1851" id="token-18-10" morph="none" pos="word" start_char="1847">first</TOKEN>
<TOKEN end_char="1856" id="token-18-11" morph="none" pos="word" start_char="1853">time</TOKEN>
<TOKEN end_char="1862" id="token-18-12" morph="none" pos="word" start_char="1858">since</TOKEN>
<TOKEN end_char="1866" id="token-18-13" morph="none" pos="word" start_char="1864">its</TOKEN>
<TOKEN end_char="1876" id="token-18-14" morph="none" pos="word" start_char="1868">inception</TOKEN>
<TOKEN end_char="1877" id="token-18-15" morph="none" pos="punct" start_char="1877">,</TOKEN>
<TOKEN end_char="1881" id="token-18-16" morph="none" pos="word" start_char="1879">the</TOKEN>
<TOKEN end_char="1890" id="token-18-17" morph="none" pos="word" start_char="1883">Institut</TOKEN>
<TOKEN end_char="1898" id="token-18-18" morph="none" pos="word" start_char="1892">Pasteur</TOKEN>
<TOKEN end_char="1902" id="token-18-19" morph="none" pos="word" start_char="1900">has</TOKEN>
<TOKEN end_char="1909" id="token-18-20" morph="none" pos="word" start_char="1904">lodged</TOKEN>
<TOKEN end_char="1911" id="token-18-21" morph="none" pos="word" start_char="1911">a</TOKEN>
<TOKEN end_char="1921" id="token-18-22" morph="none" pos="word" start_char="1913">complaint</TOKEN>
<TOKEN end_char="1922" id="token-18-23" morph="none" pos="punct" start_char="1922">.</TOKEN>
</SEG>
<SEG end_char="1939" id="segment-19" start_char="1928">
<ORIGINAL_TEXT>Explications</ORIGINAL_TEXT>
<TOKEN end_char="1939" id="token-19-0" morph="none" pos="word" start_char="1928">Explications</TOKEN>
</SEG>
<SEG end_char="2035" id="segment-20" start_char="1943">
<ORIGINAL_TEXT>1 _ The Institut Pasteur did not invent Covid-19 or the virus responsible for it, SARS-CoV-2!</ORIGINAL_TEXT>
<TOKEN end_char="1943" id="token-20-0" morph="none" pos="word" start_char="1943">1</TOKEN>
<TOKEN end_char="1945" id="token-20-1" morph="none" pos="word" start_char="1945">_</TOKEN>
<TOKEN end_char="1949" id="token-20-2" morph="none" pos="word" start_char="1947">The</TOKEN>
<TOKEN end_char="1958" id="token-20-3" morph="none" pos="word" start_char="1951">Institut</TOKEN>
<TOKEN end_char="1966" id="token-20-4" morph="none" pos="word" start_char="1960">Pasteur</TOKEN>
<TOKEN end_char="1970" id="token-20-5" morph="none" pos="word" start_char="1968">did</TOKEN>
<TOKEN end_char="1974" id="token-20-6" morph="none" pos="word" start_char="1972">not</TOKEN>
<TOKEN end_char="1981" id="token-20-7" morph="none" pos="word" start_char="1976">invent</TOKEN>
<TOKEN end_char="1990" id="token-20-8" morph="none" pos="unknown" start_char="1983">Covid-19</TOKEN>
<TOKEN end_char="1993" id="token-20-9" morph="none" pos="word" start_char="1992">or</TOKEN>
<TOKEN end_char="1997" id="token-20-10" morph="none" pos="word" start_char="1995">the</TOKEN>
<TOKEN end_char="2003" id="token-20-11" morph="none" pos="word" start_char="1999">virus</TOKEN>
<TOKEN end_char="2015" id="token-20-12" morph="none" pos="word" start_char="2005">responsible</TOKEN>
<TOKEN end_char="2019" id="token-20-13" morph="none" pos="word" start_char="2017">for</TOKEN>
<TOKEN end_char="2022" id="token-20-14" morph="none" pos="word" start_char="2021">it</TOKEN>
<TOKEN end_char="2023" id="token-20-15" morph="none" pos="punct" start_char="2023">,</TOKEN>
<TOKEN end_char="2034" id="token-20-16" morph="none" pos="unknown" start_char="2025">SARS-CoV-2</TOKEN>
<TOKEN end_char="2035" id="token-20-17" morph="none" pos="punct" start_char="2035">!</TOKEN>
</SEG>
<SEG end_char="2170" id="segment-21" start_char="2039">
<ORIGINAL_TEXT>A scientific paper published on March 17, 2020 refutes the theory that a creation by a laboratory may be behind this emerging virus.</ORIGINAL_TEXT>
<TOKEN end_char="2039" id="token-21-0" morph="none" pos="word" start_char="2039">A</TOKEN>
<TOKEN end_char="2050" id="token-21-1" morph="none" pos="word" start_char="2041">scientific</TOKEN>
<TOKEN end_char="2056" id="token-21-2" morph="none" pos="word" start_char="2052">paper</TOKEN>
<TOKEN end_char="2066" id="token-21-3" morph="none" pos="word" start_char="2058">published</TOKEN>
<TOKEN end_char="2069" id="token-21-4" morph="none" pos="word" start_char="2068">on</TOKEN>
<TOKEN end_char="2075" id="token-21-5" morph="none" pos="word" start_char="2071">March</TOKEN>
<TOKEN end_char="2078" id="token-21-6" morph="none" pos="word" start_char="2077">17</TOKEN>
<TOKEN end_char="2079" id="token-21-7" morph="none" pos="punct" start_char="2079">,</TOKEN>
<TOKEN end_char="2084" id="token-21-8" morph="none" pos="word" start_char="2081">2020</TOKEN>
<TOKEN end_char="2092" id="token-21-9" morph="none" pos="word" start_char="2086">refutes</TOKEN>
<TOKEN end_char="2096" id="token-21-10" morph="none" pos="word" start_char="2094">the</TOKEN>
<TOKEN end_char="2103" id="token-21-11" morph="none" pos="word" start_char="2098">theory</TOKEN>
<TOKEN end_char="2108" id="token-21-12" morph="none" pos="word" start_char="2105">that</TOKEN>
<TOKEN end_char="2110" id="token-21-13" morph="none" pos="word" start_char="2110">a</TOKEN>
<TOKEN end_char="2119" id="token-21-14" morph="none" pos="word" start_char="2112">creation</TOKEN>
<TOKEN end_char="2122" id="token-21-15" morph="none" pos="word" start_char="2121">by</TOKEN>
<TOKEN end_char="2124" id="token-21-16" morph="none" pos="word" start_char="2124">a</TOKEN>
<TOKEN end_char="2135" id="token-21-17" morph="none" pos="word" start_char="2126">laboratory</TOKEN>
<TOKEN end_char="2139" id="token-21-18" morph="none" pos="word" start_char="2137">may</TOKEN>
<TOKEN end_char="2142" id="token-21-19" morph="none" pos="word" start_char="2141">be</TOKEN>
<TOKEN end_char="2149" id="token-21-20" morph="none" pos="word" start_char="2144">behind</TOKEN>
<TOKEN end_char="2154" id="token-21-21" morph="none" pos="word" start_char="2151">this</TOKEN>
<TOKEN end_char="2163" id="token-21-22" morph="none" pos="word" start_char="2156">emerging</TOKEN>
<TOKEN end_char="2169" id="token-21-23" morph="none" pos="word" start_char="2165">virus</TOKEN>
<TOKEN end_char="2170" id="token-21-24" morph="none" pos="punct" start_char="2170">.</TOKEN>
</SEG>
<SEG end_char="2255" id="segment-22" start_char="2173">
<ORIGINAL_TEXT>See below "There is no evidence that SARS-CoV-2 coronavirus was created by humans".</ORIGINAL_TEXT>
<TOKEN end_char="2175" id="token-22-0" morph="none" pos="word" start_char="2173">See</TOKEN>
<TOKEN end_char="2181" id="token-22-1" morph="none" pos="word" start_char="2177">below</TOKEN>
<TOKEN end_char="2183" id="token-22-2" morph="none" pos="punct" start_char="2183">"</TOKEN>
<TOKEN end_char="2188" id="token-22-3" morph="none" pos="word" start_char="2184">There</TOKEN>
<TOKEN end_char="2191" id="token-22-4" morph="none" pos="word" start_char="2190">is</TOKEN>
<TOKEN end_char="2194" id="token-22-5" morph="none" pos="word" start_char="2193">no</TOKEN>
<TOKEN end_char="2203" id="token-22-6" morph="none" pos="word" start_char="2196">evidence</TOKEN>
<TOKEN end_char="2208" id="token-22-7" morph="none" pos="word" start_char="2205">that</TOKEN>
<TOKEN end_char="2219" id="token-22-8" morph="none" pos="unknown" start_char="2210">SARS-CoV-2</TOKEN>
<TOKEN end_char="2231" id="token-22-9" morph="none" pos="word" start_char="2221">coronavirus</TOKEN>
<TOKEN end_char="2235" id="token-22-10" morph="none" pos="word" start_char="2233">was</TOKEN>
<TOKEN end_char="2243" id="token-22-11" morph="none" pos="word" start_char="2237">created</TOKEN>
<TOKEN end_char="2246" id="token-22-12" morph="none" pos="word" start_char="2245">by</TOKEN>
<TOKEN end_char="2253" id="token-22-13" morph="none" pos="word" start_char="2248">humans</TOKEN>
<TOKEN end_char="2255" id="token-22-14" morph="none" pos="punct" start_char="2254">".</TOKEN>
</SEG>
<SEG end_char="2447" id="segment-23" start_char="2258">
<ORIGINAL_TEXT>We would remind you that the SARS-CoV-2 coronavirus, responsible for the current Covid-19 pandemic, is different from the SARS-CoV-1 virus that caused an outbreak in South-East Asia in 2003.</ORIGINAL_TEXT>
<TOKEN end_char="2259" id="token-23-0" morph="none" pos="word" start_char="2258">We</TOKEN>
<TOKEN end_char="2265" id="token-23-1" morph="none" pos="word" start_char="2261">would</TOKEN>
<TOKEN end_char="2272" id="token-23-2" morph="none" pos="word" start_char="2267">remind</TOKEN>
<TOKEN end_char="2276" id="token-23-3" morph="none" pos="word" start_char="2274">you</TOKEN>
<TOKEN end_char="2281" id="token-23-4" morph="none" pos="word" start_char="2278">that</TOKEN>
<TOKEN end_char="2285" id="token-23-5" morph="none" pos="word" start_char="2283">the</TOKEN>
<TOKEN end_char="2296" id="token-23-6" morph="none" pos="unknown" start_char="2287">SARS-CoV-2</TOKEN>
<TOKEN end_char="2308" id="token-23-7" morph="none" pos="word" start_char="2298">coronavirus</TOKEN>
<TOKEN end_char="2309" id="token-23-8" morph="none" pos="punct" start_char="2309">,</TOKEN>
<TOKEN end_char="2321" id="token-23-9" morph="none" pos="word" start_char="2311">responsible</TOKEN>
<TOKEN end_char="2325" id="token-23-10" morph="none" pos="word" start_char="2323">for</TOKEN>
<TOKEN end_char="2329" id="token-23-11" morph="none" pos="word" start_char="2327">the</TOKEN>
<TOKEN end_char="2337" id="token-23-12" morph="none" pos="word" start_char="2331">current</TOKEN>
<TOKEN end_char="2346" id="token-23-13" morph="none" pos="unknown" start_char="2339">Covid-19</TOKEN>
<TOKEN end_char="2355" id="token-23-14" morph="none" pos="word" start_char="2348">pandemic</TOKEN>
<TOKEN end_char="2356" id="token-23-15" morph="none" pos="punct" start_char="2356">,</TOKEN>
<TOKEN end_char="2359" id="token-23-16" morph="none" pos="word" start_char="2358">is</TOKEN>
<TOKEN end_char="2369" id="token-23-17" morph="none" pos="word" start_char="2361">different</TOKEN>
<TOKEN end_char="2374" id="token-23-18" morph="none" pos="word" start_char="2371">from</TOKEN>
<TOKEN end_char="2378" id="token-23-19" morph="none" pos="word" start_char="2376">the</TOKEN>
<TOKEN end_char="2389" id="token-23-20" morph="none" pos="unknown" start_char="2380">SARS-CoV-1</TOKEN>
<TOKEN end_char="2395" id="token-23-21" morph="none" pos="word" start_char="2391">virus</TOKEN>
<TOKEN end_char="2400" id="token-23-22" morph="none" pos="word" start_char="2397">that</TOKEN>
<TOKEN end_char="2407" id="token-23-23" morph="none" pos="word" start_char="2402">caused</TOKEN>
<TOKEN end_char="2410" id="token-23-24" morph="none" pos="word" start_char="2409">an</TOKEN>
<TOKEN end_char="2419" id="token-23-25" morph="none" pos="word" start_char="2412">outbreak</TOKEN>
<TOKEN end_char="2422" id="token-23-26" morph="none" pos="word" start_char="2421">in</TOKEN>
<TOKEN end_char="2433" id="token-23-27" morph="none" pos="unknown" start_char="2424">South-East</TOKEN>
<TOKEN end_char="2438" id="token-23-28" morph="none" pos="word" start_char="2435">Asia</TOKEN>
<TOKEN end_char="2441" id="token-23-29" morph="none" pos="word" start_char="2440">in</TOKEN>
<TOKEN end_char="2446" id="token-23-30" morph="none" pos="word" start_char="2443">2003</TOKEN>
<TOKEN end_char="2447" id="token-23-31" morph="none" pos="punct" start_char="2447">.</TOKEN>
</SEG>
<SEG end_char="2648" id="segment-24" start_char="2449">
<ORIGINAL_TEXT>It is scientifically false to say that they are genetically identical in every way or that the only difference in their sequence lies in a few elements allegedly derived from the HIV genome sequence..</ORIGINAL_TEXT>
<TOKEN end_char="2450" id="token-24-0" morph="none" pos="word" start_char="2449">It</TOKEN>
<TOKEN end_char="2453" id="token-24-1" morph="none" pos="word" start_char="2452">is</TOKEN>
<TOKEN end_char="2468" id="token-24-2" morph="none" pos="word" start_char="2455">scientifically</TOKEN>
<TOKEN end_char="2474" id="token-24-3" morph="none" pos="word" start_char="2470">false</TOKEN>
<TOKEN end_char="2477" id="token-24-4" morph="none" pos="word" start_char="2476">to</TOKEN>
<TOKEN end_char="2481" id="token-24-5" morph="none" pos="word" start_char="2479">say</TOKEN>
<TOKEN end_char="2486" id="token-24-6" morph="none" pos="word" start_char="2483">that</TOKEN>
<TOKEN end_char="2491" id="token-24-7" morph="none" pos="word" start_char="2488">they</TOKEN>
<TOKEN end_char="2495" id="token-24-8" morph="none" pos="word" start_char="2493">are</TOKEN>
<TOKEN end_char="2507" id="token-24-9" morph="none" pos="word" start_char="2497">genetically</TOKEN>
<TOKEN end_char="2517" id="token-24-10" morph="none" pos="word" start_char="2509">identical</TOKEN>
<TOKEN end_char="2520" id="token-24-11" morph="none" pos="word" start_char="2519">in</TOKEN>
<TOKEN end_char="2526" id="token-24-12" morph="none" pos="word" start_char="2522">every</TOKEN>
<TOKEN end_char="2530" id="token-24-13" morph="none" pos="word" start_char="2528">way</TOKEN>
<TOKEN end_char="2533" id="token-24-14" morph="none" pos="word" start_char="2532">or</TOKEN>
<TOKEN end_char="2538" id="token-24-15" morph="none" pos="word" start_char="2535">that</TOKEN>
<TOKEN end_char="2542" id="token-24-16" morph="none" pos="word" start_char="2540">the</TOKEN>
<TOKEN end_char="2547" id="token-24-17" morph="none" pos="word" start_char="2544">only</TOKEN>
<TOKEN end_char="2558" id="token-24-18" morph="none" pos="word" start_char="2549">difference</TOKEN>
<TOKEN end_char="2561" id="token-24-19" morph="none" pos="word" start_char="2560">in</TOKEN>
<TOKEN end_char="2567" id="token-24-20" morph="none" pos="word" start_char="2563">their</TOKEN>
<TOKEN end_char="2576" id="token-24-21" morph="none" pos="word" start_char="2569">sequence</TOKEN>
<TOKEN end_char="2581" id="token-24-22" morph="none" pos="word" start_char="2578">lies</TOKEN>
<TOKEN end_char="2584" id="token-24-23" morph="none" pos="word" start_char="2583">in</TOKEN>
<TOKEN end_char="2586" id="token-24-24" morph="none" pos="word" start_char="2586">a</TOKEN>
<TOKEN end_char="2590" id="token-24-25" morph="none" pos="word" start_char="2588">few</TOKEN>
<TOKEN end_char="2599" id="token-24-26" morph="none" pos="word" start_char="2592">elements</TOKEN>
<TOKEN end_char="2609" id="token-24-27" morph="none" pos="word" start_char="2601">allegedly</TOKEN>
<TOKEN end_char="2617" id="token-24-28" morph="none" pos="word" start_char="2611">derived</TOKEN>
<TOKEN end_char="2622" id="token-24-29" morph="none" pos="word" start_char="2619">from</TOKEN>
<TOKEN end_char="2626" id="token-24-30" morph="none" pos="word" start_char="2624">the</TOKEN>
<TOKEN end_char="2630" id="token-24-31" morph="none" pos="word" start_char="2628">HIV</TOKEN>
<TOKEN end_char="2637" id="token-24-32" morph="none" pos="word" start_char="2632">genome</TOKEN>
<TOKEN end_char="2646" id="token-24-33" morph="none" pos="word" start_char="2639">sequence</TOKEN>
<TOKEN end_char="2648" id="token-24-34" morph="none" pos="punct" start_char="2647">..</TOKEN>
</SEG>
<SEG end_char="2802" id="segment-25" start_char="2651">
<ORIGINAL_TEXT>These two viruses, SARS-CoV-1 and SARS-CoV-2, do both belong to the coronavirus family (which also includes other viruses) but are two separate viruses.</ORIGINAL_TEXT>
<TOKEN end_char="2655" id="token-25-0" morph="none" pos="word" start_char="2651">These</TOKEN>
<TOKEN end_char="2659" id="token-25-1" morph="none" pos="word" start_char="2657">two</TOKEN>
<TOKEN end_char="2667" id="token-25-2" morph="none" pos="word" start_char="2661">viruses</TOKEN>
<TOKEN end_char="2668" id="token-25-3" morph="none" pos="punct" start_char="2668">,</TOKEN>
<TOKEN end_char="2679" id="token-25-4" morph="none" pos="unknown" start_char="2670">SARS-CoV-1</TOKEN>
<TOKEN end_char="2683" id="token-25-5" morph="none" pos="word" start_char="2681">and</TOKEN>
<TOKEN end_char="2694" id="token-25-6" morph="none" pos="unknown" start_char="2685">SARS-CoV-2</TOKEN>
<TOKEN end_char="2695" id="token-25-7" morph="none" pos="punct" start_char="2695">,</TOKEN>
<TOKEN end_char="2698" id="token-25-8" morph="none" pos="word" start_char="2697">do</TOKEN>
<TOKEN end_char="2703" id="token-25-9" morph="none" pos="word" start_char="2700">both</TOKEN>
<TOKEN end_char="2710" id="token-25-10" morph="none" pos="word" start_char="2705">belong</TOKEN>
<TOKEN end_char="2713" id="token-25-11" morph="none" pos="word" start_char="2712">to</TOKEN>
<TOKEN end_char="2717" id="token-25-12" morph="none" pos="word" start_char="2715">the</TOKEN>
<TOKEN end_char="2729" id="token-25-13" morph="none" pos="word" start_char="2719">coronavirus</TOKEN>
<TOKEN end_char="2736" id="token-25-14" morph="none" pos="word" start_char="2731">family</TOKEN>
<TOKEN end_char="2738" id="token-25-15" morph="none" pos="punct" start_char="2738">(</TOKEN>
<TOKEN end_char="2743" id="token-25-16" morph="none" pos="word" start_char="2739">which</TOKEN>
<TOKEN end_char="2748" id="token-25-17" morph="none" pos="word" start_char="2745">also</TOKEN>
<TOKEN end_char="2757" id="token-25-18" morph="none" pos="word" start_char="2750">includes</TOKEN>
<TOKEN end_char="2763" id="token-25-19" morph="none" pos="word" start_char="2759">other</TOKEN>
<TOKEN end_char="2771" id="token-25-20" morph="none" pos="word" start_char="2765">viruses</TOKEN>
<TOKEN end_char="2772" id="token-25-21" morph="none" pos="punct" start_char="2772">)</TOKEN>
<TOKEN end_char="2776" id="token-25-22" morph="none" pos="word" start_char="2774">but</TOKEN>
<TOKEN end_char="2780" id="token-25-23" morph="none" pos="word" start_char="2778">are</TOKEN>
<TOKEN end_char="2784" id="token-25-24" morph="none" pos="word" start_char="2782">two</TOKEN>
<TOKEN end_char="2793" id="token-25-25" morph="none" pos="word" start_char="2786">separate</TOKEN>
<TOKEN end_char="2801" id="token-25-26" morph="none" pos="word" start_char="2795">viruses</TOKEN>
<TOKEN end_char="2802" id="token-25-27" morph="none" pos="punct" start_char="2802">.</TOKEN>
</SEG>
<SEG end_char="2982" id="segment-26" start_char="2805">
<ORIGINAL_TEXT>The Institut Pasteur did not invent any viruses (neither SARS-CoV-2 nor SARS-CoV-1) but, in 2004, did invent a vaccine candidate for the previous coronavirus known as SARS-CoV-1.</ORIGINAL_TEXT>
<TOKEN end_char="2807" id="token-26-0" morph="none" pos="word" start_char="2805">The</TOKEN>
<TOKEN end_char="2816" id="token-26-1" morph="none" pos="word" start_char="2809">Institut</TOKEN>
<TOKEN end_char="2824" id="token-26-2" morph="none" pos="word" start_char="2818">Pasteur</TOKEN>
<TOKEN end_char="2828" id="token-26-3" morph="none" pos="word" start_char="2826">did</TOKEN>
<TOKEN end_char="2832" id="token-26-4" morph="none" pos="word" start_char="2830">not</TOKEN>
<TOKEN end_char="2839" id="token-26-5" morph="none" pos="word" start_char="2834">invent</TOKEN>
<TOKEN end_char="2843" id="token-26-6" morph="none" pos="word" start_char="2841">any</TOKEN>
<TOKEN end_char="2851" id="token-26-7" morph="none" pos="word" start_char="2845">viruses</TOKEN>
<TOKEN end_char="2853" id="token-26-8" morph="none" pos="punct" start_char="2853">(</TOKEN>
<TOKEN end_char="2860" id="token-26-9" morph="none" pos="word" start_char="2854">neither</TOKEN>
<TOKEN end_char="2871" id="token-26-10" morph="none" pos="unknown" start_char="2862">SARS-CoV-2</TOKEN>
<TOKEN end_char="2875" id="token-26-11" morph="none" pos="word" start_char="2873">nor</TOKEN>
<TOKEN end_char="2886" id="token-26-12" morph="none" pos="unknown" start_char="2877">SARS-CoV-1</TOKEN>
<TOKEN end_char="2887" id="token-26-13" morph="none" pos="punct" start_char="2887">)</TOKEN>
<TOKEN end_char="2891" id="token-26-14" morph="none" pos="word" start_char="2889">but</TOKEN>
<TOKEN end_char="2892" id="token-26-15" morph="none" pos="punct" start_char="2892">,</TOKEN>
<TOKEN end_char="2895" id="token-26-16" morph="none" pos="word" start_char="2894">in</TOKEN>
<TOKEN end_char="2900" id="token-26-17" morph="none" pos="word" start_char="2897">2004</TOKEN>
<TOKEN end_char="2901" id="token-26-18" morph="none" pos="punct" start_char="2901">,</TOKEN>
<TOKEN end_char="2905" id="token-26-19" morph="none" pos="word" start_char="2903">did</TOKEN>
<TOKEN end_char="2912" id="token-26-20" morph="none" pos="word" start_char="2907">invent</TOKEN>
<TOKEN end_char="2914" id="token-26-21" morph="none" pos="word" start_char="2914">a</TOKEN>
<TOKEN end_char="2922" id="token-26-22" morph="none" pos="word" start_char="2916">vaccine</TOKEN>
<TOKEN end_char="2932" id="token-26-23" morph="none" pos="word" start_char="2924">candidate</TOKEN>
<TOKEN end_char="2936" id="token-26-24" morph="none" pos="word" start_char="2934">for</TOKEN>
<TOKEN end_char="2940" id="token-26-25" morph="none" pos="word" start_char="2938">the</TOKEN>
<TOKEN end_char="2949" id="token-26-26" morph="none" pos="word" start_char="2942">previous</TOKEN>
<TOKEN end_char="2961" id="token-26-27" morph="none" pos="word" start_char="2951">coronavirus</TOKEN>
<TOKEN end_char="2967" id="token-26-28" morph="none" pos="word" start_char="2963">known</TOKEN>
<TOKEN end_char="2970" id="token-26-29" morph="none" pos="word" start_char="2969">as</TOKEN>
<TOKEN end_char="2981" id="token-26-30" morph="none" pos="unknown" start_char="2972">SARS-CoV-1</TOKEN>
<TOKEN end_char="2982" id="token-26-31" morph="none" pos="punct" start_char="2982">.</TOKEN>
</SEG>
<SEG end_char="3085" id="segment-27" start_char="2985">
<ORIGINAL_TEXT>See below "The Institut Pasteur did not invent Covid-19 or the virus responsible for it, SARS-CoV-2!"</ORIGINAL_TEXT>
<TOKEN end_char="2987" id="token-27-0" morph="none" pos="word" start_char="2985">See</TOKEN>
<TOKEN end_char="2993" id="token-27-1" morph="none" pos="word" start_char="2989">below</TOKEN>
<TOKEN end_char="2995" id="token-27-2" morph="none" pos="punct" start_char="2995">"</TOKEN>
<TOKEN end_char="2998" id="token-27-3" morph="none" pos="word" start_char="2996">The</TOKEN>
<TOKEN end_char="3007" id="token-27-4" morph="none" pos="word" start_char="3000">Institut</TOKEN>
<TOKEN end_char="3015" id="token-27-5" morph="none" pos="word" start_char="3009">Pasteur</TOKEN>
<TOKEN end_char="3019" id="token-27-6" morph="none" pos="word" start_char="3017">did</TOKEN>
<TOKEN end_char="3023" id="token-27-7" morph="none" pos="word" start_char="3021">not</TOKEN>
<TOKEN end_char="3030" id="token-27-8" morph="none" pos="word" start_char="3025">invent</TOKEN>
<TOKEN end_char="3039" id="token-27-9" morph="none" pos="unknown" start_char="3032">Covid-19</TOKEN>
<TOKEN end_char="3042" id="token-27-10" morph="none" pos="word" start_char="3041">or</TOKEN>
<TOKEN end_char="3046" id="token-27-11" morph="none" pos="word" start_char="3044">the</TOKEN>
<TOKEN end_char="3052" id="token-27-12" morph="none" pos="word" start_char="3048">virus</TOKEN>
<TOKEN end_char="3064" id="token-27-13" morph="none" pos="word" start_char="3054">responsible</TOKEN>
<TOKEN end_char="3068" id="token-27-14" morph="none" pos="word" start_char="3066">for</TOKEN>
<TOKEN end_char="3071" id="token-27-15" morph="none" pos="word" start_char="3070">it</TOKEN>
<TOKEN end_char="3072" id="token-27-16" morph="none" pos="punct" start_char="3072">,</TOKEN>
<TOKEN end_char="3083" id="token-27-17" morph="none" pos="unknown" start_char="3074">SARS-CoV-2</TOKEN>
<TOKEN end_char="3085" id="token-27-18" morph="none" pos="punct" start_char="3084">!"</TOKEN>
</SEG>
<SEG end_char="3345" id="segment-28" start_char="3088">
<ORIGINAL_TEXT>This vaccine candidate for SARS-CoV-1 was the subject of a patent application filed in 2004, which mentions a particular strain of the SARS-CoV-1 virus, which was itself discovered and described in March 2003, i.e. several months before the patent was filed.</ORIGINAL_TEXT>
<TOKEN end_char="3091" id="token-28-0" morph="none" pos="word" start_char="3088">This</TOKEN>
<TOKEN end_char="3099" id="token-28-1" morph="none" pos="word" start_char="3093">vaccine</TOKEN>
<TOKEN end_char="3109" id="token-28-2" morph="none" pos="word" start_char="3101">candidate</TOKEN>
<TOKEN end_char="3113" id="token-28-3" morph="none" pos="word" start_char="3111">for</TOKEN>
<TOKEN end_char="3124" id="token-28-4" morph="none" pos="unknown" start_char="3115">SARS-CoV-1</TOKEN>
<TOKEN end_char="3128" id="token-28-5" morph="none" pos="word" start_char="3126">was</TOKEN>
<TOKEN end_char="3132" id="token-28-6" morph="none" pos="word" start_char="3130">the</TOKEN>
<TOKEN end_char="3140" id="token-28-7" morph="none" pos="word" start_char="3134">subject</TOKEN>
<TOKEN end_char="3143" id="token-28-8" morph="none" pos="word" start_char="3142">of</TOKEN>
<TOKEN end_char="3145" id="token-28-9" morph="none" pos="word" start_char="3145">a</TOKEN>
<TOKEN end_char="3152" id="token-28-10" morph="none" pos="word" start_char="3147">patent</TOKEN>
<TOKEN end_char="3164" id="token-28-11" morph="none" pos="word" start_char="3154">application</TOKEN>
<TOKEN end_char="3170" id="token-28-12" morph="none" pos="word" start_char="3166">filed</TOKEN>
<TOKEN end_char="3173" id="token-28-13" morph="none" pos="word" start_char="3172">in</TOKEN>
<TOKEN end_char="3178" id="token-28-14" morph="none" pos="word" start_char="3175">2004</TOKEN>
<TOKEN end_char="3179" id="token-28-15" morph="none" pos="punct" start_char="3179">,</TOKEN>
<TOKEN end_char="3185" id="token-28-16" morph="none" pos="word" start_char="3181">which</TOKEN>
<TOKEN end_char="3194" id="token-28-17" morph="none" pos="word" start_char="3187">mentions</TOKEN>
<TOKEN end_char="3196" id="token-28-18" morph="none" pos="word" start_char="3196">a</TOKEN>
<TOKEN end_char="3207" id="token-28-19" morph="none" pos="word" start_char="3198">particular</TOKEN>
<TOKEN end_char="3214" id="token-28-20" morph="none" pos="word" start_char="3209">strain</TOKEN>
<TOKEN end_char="3217" id="token-28-21" morph="none" pos="word" start_char="3216">of</TOKEN>
<TOKEN end_char="3221" id="token-28-22" morph="none" pos="word" start_char="3219">the</TOKEN>
<TOKEN end_char="3232" id="token-28-23" morph="none" pos="unknown" start_char="3223">SARS-CoV-1</TOKEN>
<TOKEN end_char="3238" id="token-28-24" morph="none" pos="word" start_char="3234">virus</TOKEN>
<TOKEN end_char="3239" id="token-28-25" morph="none" pos="punct" start_char="3239">,</TOKEN>
<TOKEN end_char="3245" id="token-28-26" morph="none" pos="word" start_char="3241">which</TOKEN>
<TOKEN end_char="3249" id="token-28-27" morph="none" pos="word" start_char="3247">was</TOKEN>
<TOKEN end_char="3256" id="token-28-28" morph="none" pos="word" start_char="3251">itself</TOKEN>
<TOKEN end_char="3267" id="token-28-29" morph="none" pos="word" start_char="3258">discovered</TOKEN>
<TOKEN end_char="3271" id="token-28-30" morph="none" pos="word" start_char="3269">and</TOKEN>
<TOKEN end_char="3281" id="token-28-31" morph="none" pos="word" start_char="3273">described</TOKEN>
<TOKEN end_char="3284" id="token-28-32" morph="none" pos="word" start_char="3283">in</TOKEN>
<TOKEN end_char="3290" id="token-28-33" morph="none" pos="word" start_char="3286">March</TOKEN>
<TOKEN end_char="3295" id="token-28-34" morph="none" pos="word" start_char="3292">2003</TOKEN>
<TOKEN end_char="3296" id="token-28-35" morph="none" pos="punct" start_char="3296">,</TOKEN>
<TOKEN end_char="3300" id="token-28-36" morph="none" pos="unknown" start_char="3298">i.e</TOKEN>
<TOKEN end_char="3301" id="token-28-37" morph="none" pos="punct" start_char="3301">.</TOKEN>
<TOKEN end_char="3309" id="token-28-38" morph="none" pos="word" start_char="3303">several</TOKEN>
<TOKEN end_char="3316" id="token-28-39" morph="none" pos="word" start_char="3311">months</TOKEN>
<TOKEN end_char="3323" id="token-28-40" morph="none" pos="word" start_char="3318">before</TOKEN>
<TOKEN end_char="3327" id="token-28-41" morph="none" pos="word" start_char="3325">the</TOKEN>
<TOKEN end_char="3334" id="token-28-42" morph="none" pos="word" start_char="3329">patent</TOKEN>
<TOKEN end_char="3338" id="token-28-43" morph="none" pos="word" start_char="3336">was</TOKEN>
<TOKEN end_char="3344" id="token-28-44" morph="none" pos="word" start_char="3340">filed</TOKEN>
<TOKEN end_char="3345" id="token-28-45" morph="none" pos="punct" start_char="3345">.</TOKEN>
</SEG>
<SEG end_char="3601" id="segment-29" start_char="3347">
<ORIGINAL_TEXT>At the time, the Institut Pasteur proposed several strategies that could enable development of a vaccine (those described in the patent), which included a vaccine based on the virus used in the measles vaccine and another one based on a lentiviral vector.</ORIGINAL_TEXT>
<TOKEN end_char="3348" id="token-29-0" morph="none" pos="word" start_char="3347">At</TOKEN>
<TOKEN end_char="3352" id="token-29-1" morph="none" pos="word" start_char="3350">the</TOKEN>
<TOKEN end_char="3357" id="token-29-2" morph="none" pos="word" start_char="3354">time</TOKEN>
<TOKEN end_char="3358" id="token-29-3" morph="none" pos="punct" start_char="3358">,</TOKEN>
<TOKEN end_char="3362" id="token-29-4" morph="none" pos="word" start_char="3360">the</TOKEN>
<TOKEN end_char="3371" id="token-29-5" morph="none" pos="word" start_char="3364">Institut</TOKEN>
<TOKEN end_char="3379" id="token-29-6" morph="none" pos="word" start_char="3373">Pasteur</TOKEN>
<TOKEN end_char="3388" id="token-29-7" morph="none" pos="word" start_char="3381">proposed</TOKEN>
<TOKEN end_char="3396" id="token-29-8" morph="none" pos="word" start_char="3390">several</TOKEN>
<TOKEN end_char="3407" id="token-29-9" morph="none" pos="word" start_char="3398">strategies</TOKEN>
<TOKEN end_char="3412" id="token-29-10" morph="none" pos="word" start_char="3409">that</TOKEN>
<TOKEN end_char="3418" id="token-29-11" morph="none" pos="word" start_char="3414">could</TOKEN>
<TOKEN end_char="3425" id="token-29-12" morph="none" pos="word" start_char="3420">enable</TOKEN>
<TOKEN end_char="3437" id="token-29-13" morph="none" pos="word" start_char="3427">development</TOKEN>
<TOKEN end_char="3440" id="token-29-14" morph="none" pos="word" start_char="3439">of</TOKEN>
<TOKEN end_char="3442" id="token-29-15" morph="none" pos="word" start_char="3442">a</TOKEN>
<TOKEN end_char="3450" id="token-29-16" morph="none" pos="word" start_char="3444">vaccine</TOKEN>
<TOKEN end_char="3452" id="token-29-17" morph="none" pos="punct" start_char="3452">(</TOKEN>
<TOKEN end_char="3457" id="token-29-18" morph="none" pos="word" start_char="3453">those</TOKEN>
<TOKEN end_char="3467" id="token-29-19" morph="none" pos="word" start_char="3459">described</TOKEN>
<TOKEN end_char="3470" id="token-29-20" morph="none" pos="word" start_char="3469">in</TOKEN>
<TOKEN end_char="3474" id="token-29-21" morph="none" pos="word" start_char="3472">the</TOKEN>
<TOKEN end_char="3481" id="token-29-22" morph="none" pos="word" start_char="3476">patent</TOKEN>
<TOKEN end_char="3483" id="token-29-23" morph="none" pos="punct" start_char="3482">),</TOKEN>
<TOKEN end_char="3489" id="token-29-24" morph="none" pos="word" start_char="3485">which</TOKEN>
<TOKEN end_char="3498" id="token-29-25" morph="none" pos="word" start_char="3491">included</TOKEN>
<TOKEN end_char="3500" id="token-29-26" morph="none" pos="word" start_char="3500">a</TOKEN>
<TOKEN end_char="3508" id="token-29-27" morph="none" pos="word" start_char="3502">vaccine</TOKEN>
<TOKEN end_char="3514" id="token-29-28" morph="none" pos="word" start_char="3510">based</TOKEN>
<TOKEN end_char="3517" id="token-29-29" morph="none" pos="word" start_char="3516">on</TOKEN>
<TOKEN end_char="3521" id="token-29-30" morph="none" pos="word" start_char="3519">the</TOKEN>
<TOKEN end_char="3527" id="token-29-31" morph="none" pos="word" start_char="3523">virus</TOKEN>
<TOKEN end_char="3532" id="token-29-32" morph="none" pos="word" start_char="3529">used</TOKEN>
<TOKEN end_char="3535" id="token-29-33" morph="none" pos="word" start_char="3534">in</TOKEN>
<TOKEN end_char="3539" id="token-29-34" morph="none" pos="word" start_char="3537">the</TOKEN>
<TOKEN end_char="3547" id="token-29-35" morph="none" pos="word" start_char="3541">measles</TOKEN>
<TOKEN end_char="3555" id="token-29-36" morph="none" pos="word" start_char="3549">vaccine</TOKEN>
<TOKEN end_char="3559" id="token-29-37" morph="none" pos="word" start_char="3557">and</TOKEN>
<TOKEN end_char="3567" id="token-29-38" morph="none" pos="word" start_char="3561">another</TOKEN>
<TOKEN end_char="3571" id="token-29-39" morph="none" pos="word" start_char="3569">one</TOKEN>
<TOKEN end_char="3577" id="token-29-40" morph="none" pos="word" start_char="3573">based</TOKEN>
<TOKEN end_char="3580" id="token-29-41" morph="none" pos="word" start_char="3579">on</TOKEN>
<TOKEN end_char="3582" id="token-29-42" morph="none" pos="word" start_char="3582">a</TOKEN>
<TOKEN end_char="3593" id="token-29-43" morph="none" pos="word" start_char="3584">lentiviral</TOKEN>
<TOKEN end_char="3600" id="token-29-44" morph="none" pos="word" start_char="3595">vector</TOKEN>
<TOKEN end_char="3601" id="token-29-45" morph="none" pos="punct" start_char="3601">.</TOKEN>
</SEG>
<SEG end_char="3906" id="segment-30" start_char="3603">
<ORIGINAL_TEXT>These two scientific approaches to develop a vaccine candidate, proposed for the SARS-CoV-1 virus at the time, are today the subject of new research to tackle the SARS-CoV-2 virus and the Covid-19 pandemic (new avenues measles vector-based SARS-CoV-2 vaccine; lentiviral vector-based SARS-CoV-2 vaccine).</ORIGINAL_TEXT>
<TOKEN end_char="3607" id="token-30-0" morph="none" pos="word" start_char="3603">These</TOKEN>
<TOKEN end_char="3611" id="token-30-1" morph="none" pos="word" start_char="3609">two</TOKEN>
<TOKEN end_char="3622" id="token-30-2" morph="none" pos="word" start_char="3613">scientific</TOKEN>
<TOKEN end_char="3633" id="token-30-3" morph="none" pos="word" start_char="3624">approaches</TOKEN>
<TOKEN end_char="3636" id="token-30-4" morph="none" pos="word" start_char="3635">to</TOKEN>
<TOKEN end_char="3644" id="token-30-5" morph="none" pos="word" start_char="3638">develop</TOKEN>
<TOKEN end_char="3646" id="token-30-6" morph="none" pos="word" start_char="3646">a</TOKEN>
<TOKEN end_char="3654" id="token-30-7" morph="none" pos="word" start_char="3648">vaccine</TOKEN>
<TOKEN end_char="3664" id="token-30-8" morph="none" pos="word" start_char="3656">candidate</TOKEN>
<TOKEN end_char="3665" id="token-30-9" morph="none" pos="punct" start_char="3665">,</TOKEN>
<TOKEN end_char="3674" id="token-30-10" morph="none" pos="word" start_char="3667">proposed</TOKEN>
<TOKEN end_char="3678" id="token-30-11" morph="none" pos="word" start_char="3676">for</TOKEN>
<TOKEN end_char="3682" id="token-30-12" morph="none" pos="word" start_char="3680">the</TOKEN>
<TOKEN end_char="3693" id="token-30-13" morph="none" pos="unknown" start_char="3684">SARS-CoV-1</TOKEN>
<TOKEN end_char="3699" id="token-30-14" morph="none" pos="word" start_char="3695">virus</TOKEN>
<TOKEN end_char="3702" id="token-30-15" morph="none" pos="word" start_char="3701">at</TOKEN>
<TOKEN end_char="3706" id="token-30-16" morph="none" pos="word" start_char="3704">the</TOKEN>
<TOKEN end_char="3711" id="token-30-17" morph="none" pos="word" start_char="3708">time</TOKEN>
<TOKEN end_char="3712" id="token-30-18" morph="none" pos="punct" start_char="3712">,</TOKEN>
<TOKEN end_char="3716" id="token-30-19" morph="none" pos="word" start_char="3714">are</TOKEN>
<TOKEN end_char="3722" id="token-30-20" morph="none" pos="word" start_char="3718">today</TOKEN>
<TOKEN end_char="3726" id="token-30-21" morph="none" pos="word" start_char="3724">the</TOKEN>
<TOKEN end_char="3734" id="token-30-22" morph="none" pos="word" start_char="3728">subject</TOKEN>
<TOKEN end_char="3737" id="token-30-23" morph="none" pos="word" start_char="3736">of</TOKEN>
<TOKEN end_char="3741" id="token-30-24" morph="none" pos="word" start_char="3739">new</TOKEN>
<TOKEN end_char="3750" id="token-30-25" morph="none" pos="word" start_char="3743">research</TOKEN>
<TOKEN end_char="3753" id="token-30-26" morph="none" pos="word" start_char="3752">to</TOKEN>
<TOKEN end_char="3760" id="token-30-27" morph="none" pos="word" start_char="3755">tackle</TOKEN>
<TOKEN end_char="3764" id="token-30-28" morph="none" pos="word" start_char="3762">the</TOKEN>
<TOKEN end_char="3775" id="token-30-29" morph="none" pos="unknown" start_char="3766">SARS-CoV-2</TOKEN>
<TOKEN end_char="3781" id="token-30-30" morph="none" pos="word" start_char="3777">virus</TOKEN>
<TOKEN end_char="3785" id="token-30-31" morph="none" pos="word" start_char="3783">and</TOKEN>
<TOKEN end_char="3789" id="token-30-32" morph="none" pos="word" start_char="3787">the</TOKEN>
<TOKEN end_char="3798" id="token-30-33" morph="none" pos="unknown" start_char="3791">Covid-19</TOKEN>
<TOKEN end_char="3807" id="token-30-34" morph="none" pos="word" start_char="3800">pandemic</TOKEN>
<TOKEN end_char="3809" id="token-30-35" morph="none" pos="punct" start_char="3809">(</TOKEN>
<TOKEN end_char="3812" id="token-30-36" morph="none" pos="word" start_char="3810">new</TOKEN>
<TOKEN end_char="3820" id="token-30-37" morph="none" pos="word" start_char="3814">avenues</TOKEN>
<TOKEN end_char="3828" id="token-30-38" morph="none" pos="word" start_char="3822">measles</TOKEN>
<TOKEN end_char="3841" id="token-30-39" morph="none" pos="unknown" start_char="3830">vector-based</TOKEN>
<TOKEN end_char="3852" id="token-30-40" morph="none" pos="unknown" start_char="3843">SARS-CoV-2</TOKEN>
<TOKEN end_char="3860" id="token-30-41" morph="none" pos="word" start_char="3854">vaccine</TOKEN>
<TOKEN end_char="3861" id="token-30-42" morph="none" pos="punct" start_char="3861">;</TOKEN>
<TOKEN end_char="3872" id="token-30-43" morph="none" pos="word" start_char="3863">lentiviral</TOKEN>
<TOKEN end_char="3885" id="token-30-44" morph="none" pos="unknown" start_char="3874">vector-based</TOKEN>
<TOKEN end_char="3896" id="token-30-45" morph="none" pos="unknown" start_char="3887">SARS-CoV-2</TOKEN>
<TOKEN end_char="3904" id="token-30-46" morph="none" pos="word" start_char="3898">vaccine</TOKEN>
<TOKEN end_char="3906" id="token-30-47" morph="none" pos="punct" start_char="3905">).</TOKEN>
</SEG>
<SEG end_char="4102" id="segment-31" start_char="3909">
<ORIGINAL_TEXT>It should be noted that the vaccine candidate for SARS-CoV-1 was successfully tested on an animal model for the 2002-2003 SARS epidemics(disease caused by SARS-CoV-1 virus) outbreak at the time.</ORIGINAL_TEXT>
<TOKEN end_char="3910" id="token-31-0" morph="none" pos="word" start_char="3909">It</TOKEN>
<TOKEN end_char="3917" id="token-31-1" morph="none" pos="word" start_char="3912">should</TOKEN>
<TOKEN end_char="3920" id="token-31-2" morph="none" pos="word" start_char="3919">be</TOKEN>
<TOKEN end_char="3926" id="token-31-3" morph="none" pos="word" start_char="3922">noted</TOKEN>
<TOKEN end_char="3931" id="token-31-4" morph="none" pos="word" start_char="3928">that</TOKEN>
<TOKEN end_char="3935" id="token-31-5" morph="none" pos="word" start_char="3933">the</TOKEN>
<TOKEN end_char="3943" id="token-31-6" morph="none" pos="word" start_char="3937">vaccine</TOKEN>
<TOKEN end_char="3953" id="token-31-7" morph="none" pos="word" start_char="3945">candidate</TOKEN>
<TOKEN end_char="3957" id="token-31-8" morph="none" pos="word" start_char="3955">for</TOKEN>
<TOKEN end_char="3968" id="token-31-9" morph="none" pos="unknown" start_char="3959">SARS-CoV-1</TOKEN>
<TOKEN end_char="3972" id="token-31-10" morph="none" pos="word" start_char="3970">was</TOKEN>
<TOKEN end_char="3985" id="token-31-11" morph="none" pos="word" start_char="3974">successfully</TOKEN>
<TOKEN end_char="3992" id="token-31-12" morph="none" pos="word" start_char="3987">tested</TOKEN>
<TOKEN end_char="3995" id="token-31-13" morph="none" pos="word" start_char="3994">on</TOKEN>
<TOKEN end_char="3998" id="token-31-14" morph="none" pos="word" start_char="3997">an</TOKEN>
<TOKEN end_char="4005" id="token-31-15" morph="none" pos="word" start_char="4000">animal</TOKEN>
<TOKEN end_char="4011" id="token-31-16" morph="none" pos="word" start_char="4007">model</TOKEN>
<TOKEN end_char="4015" id="token-31-17" morph="none" pos="word" start_char="4013">for</TOKEN>
<TOKEN end_char="4019" id="token-31-18" morph="none" pos="word" start_char="4017">the</TOKEN>
<TOKEN end_char="4029" id="token-31-19" morph="none" pos="unknown" start_char="4021">2002-2003</TOKEN>
<TOKEN end_char="4034" id="token-31-20" morph="none" pos="word" start_char="4031">SARS</TOKEN>
<TOKEN end_char="4052" id="token-31-21" morph="none" pos="unknown" start_char="4036">epidemics(disease</TOKEN>
<TOKEN end_char="4059" id="token-31-22" morph="none" pos="word" start_char="4054">caused</TOKEN>
<TOKEN end_char="4062" id="token-31-23" morph="none" pos="word" start_char="4061">by</TOKEN>
<TOKEN end_char="4073" id="token-31-24" morph="none" pos="unknown" start_char="4064">SARS-CoV-1</TOKEN>
<TOKEN end_char="4079" id="token-31-25" morph="none" pos="word" start_char="4075">virus</TOKEN>
<TOKEN end_char="4080" id="token-31-26" morph="none" pos="punct" start_char="4080">)</TOKEN>
<TOKEN end_char="4089" id="token-31-27" morph="none" pos="word" start_char="4082">outbreak</TOKEN>
<TOKEN end_char="4092" id="token-31-28" morph="none" pos="word" start_char="4091">at</TOKEN>
<TOKEN end_char="4096" id="token-31-29" morph="none" pos="word" start_char="4094">the</TOKEN>
<TOKEN end_char="4101" id="token-31-30" morph="none" pos="word" start_char="4098">time</TOKEN>
<TOKEN end_char="4102" id="token-31-31" morph="none" pos="punct" start_char="4102">.</TOKEN>
</SEG>
<SEG end_char="4214" id="segment-32" start_char="4104">
<ORIGINAL_TEXT>But this vaccine candidate was neither ever tested on humans nor marketed as the outbreak had thankfully ended.</ORIGINAL_TEXT>
<TOKEN end_char="4106" id="token-32-0" morph="none" pos="word" start_char="4104">But</TOKEN>
<TOKEN end_char="4111" id="token-32-1" morph="none" pos="word" start_char="4108">this</TOKEN>
<TOKEN end_char="4119" id="token-32-2" morph="none" pos="word" start_char="4113">vaccine</TOKEN>
<TOKEN end_char="4129" id="token-32-3" morph="none" pos="word" start_char="4121">candidate</TOKEN>
<TOKEN end_char="4133" id="token-32-4" morph="none" pos="word" start_char="4131">was</TOKEN>
<TOKEN end_char="4141" id="token-32-5" morph="none" pos="word" start_char="4135">neither</TOKEN>
<TOKEN end_char="4146" id="token-32-6" morph="none" pos="word" start_char="4143">ever</TOKEN>
<TOKEN end_char="4153" id="token-32-7" morph="none" pos="word" start_char="4148">tested</TOKEN>
<TOKEN end_char="4156" id="token-32-8" morph="none" pos="word" start_char="4155">on</TOKEN>
<TOKEN end_char="4163" id="token-32-9" morph="none" pos="word" start_char="4158">humans</TOKEN>
<TOKEN end_char="4167" id="token-32-10" morph="none" pos="word" start_char="4165">nor</TOKEN>
<TOKEN end_char="4176" id="token-32-11" morph="none" pos="word" start_char="4169">marketed</TOKEN>
<TOKEN end_char="4179" id="token-32-12" morph="none" pos="word" start_char="4178">as</TOKEN>
<TOKEN end_char="4183" id="token-32-13" morph="none" pos="word" start_char="4181">the</TOKEN>
<TOKEN end_char="4192" id="token-32-14" morph="none" pos="word" start_char="4185">outbreak</TOKEN>
<TOKEN end_char="4196" id="token-32-15" morph="none" pos="word" start_char="4194">had</TOKEN>
<TOKEN end_char="4207" id="token-32-16" morph="none" pos="word" start_char="4198">thankfully</TOKEN>
<TOKEN end_char="4213" id="token-32-17" morph="none" pos="word" start_char="4209">ended</TOKEN>
<TOKEN end_char="4214" id="token-32-18" morph="none" pos="punct" start_char="4214">.</TOKEN>
</SEG>
<SEG end_char="4299" id="segment-33" start_char="4217">
<ORIGINAL_TEXT>2 _ The Institut Pasteur did not release any viruses in the city of Wuhan in China!</ORIGINAL_TEXT>
<TOKEN end_char="4217" id="token-33-0" morph="none" pos="word" start_char="4217">2</TOKEN>
<TOKEN end_char="4219" id="token-33-1" morph="none" pos="word" start_char="4219">_</TOKEN>
<TOKEN end_char="4223" id="token-33-2" morph="none" pos="word" start_char="4221">The</TOKEN>
<TOKEN end_char="4232" id="token-33-3" morph="none" pos="word" start_char="4225">Institut</TOKEN>
<TOKEN end_char="4240" id="token-33-4" morph="none" pos="word" start_char="4234">Pasteur</TOKEN>
<TOKEN end_char="4244" id="token-33-5" morph="none" pos="word" start_char="4242">did</TOKEN>
<TOKEN end_char="4248" id="token-33-6" morph="none" pos="word" start_char="4246">not</TOKEN>
<TOKEN end_char="4256" id="token-33-7" morph="none" pos="word" start_char="4250">release</TOKEN>
<TOKEN end_char="4260" id="token-33-8" morph="none" pos="word" start_char="4258">any</TOKEN>
<TOKEN end_char="4268" id="token-33-9" morph="none" pos="word" start_char="4262">viruses</TOKEN>
<TOKEN end_char="4271" id="token-33-10" morph="none" pos="word" start_char="4270">in</TOKEN>
<TOKEN end_char="4275" id="token-33-11" morph="none" pos="word" start_char="4273">the</TOKEN>
<TOKEN end_char="4280" id="token-33-12" morph="none" pos="word" start_char="4277">city</TOKEN>
<TOKEN end_char="4283" id="token-33-13" morph="none" pos="word" start_char="4282">of</TOKEN>
<TOKEN end_char="4289" id="token-33-14" morph="none" pos="word" start_char="4285">Wuhan</TOKEN>
<TOKEN end_char="4292" id="token-33-15" morph="none" pos="word" start_char="4291">in</TOKEN>
<TOKEN end_char="4298" id="token-33-16" morph="none" pos="word" start_char="4294">China</TOKEN>
<TOKEN end_char="4299" id="token-33-17" morph="none" pos="punct" start_char="4299">!</TOKEN>
</SEG>
<SEG end_char="4420" id="segment-34" start_char="4303">
<ORIGINAL_TEXT>It is false and slanderous to assert that the Institut Pasteur released the coronavirus in the city of Wuhan in China.</ORIGINAL_TEXT>
<TOKEN end_char="4304" id="token-34-0" morph="none" pos="word" start_char="4303">It</TOKEN>
<TOKEN end_char="4307" id="token-34-1" morph="none" pos="word" start_char="4306">is</TOKEN>
<TOKEN end_char="4313" id="token-34-2" morph="none" pos="word" start_char="4309">false</TOKEN>
<TOKEN end_char="4317" id="token-34-3" morph="none" pos="word" start_char="4315">and</TOKEN>
<TOKEN end_char="4328" id="token-34-4" morph="none" pos="word" start_char="4319">slanderous</TOKEN>
<TOKEN end_char="4331" id="token-34-5" morph="none" pos="word" start_char="4330">to</TOKEN>
<TOKEN end_char="4338" id="token-34-6" morph="none" pos="word" start_char="4333">assert</TOKEN>
<TOKEN end_char="4343" id="token-34-7" morph="none" pos="word" start_char="4340">that</TOKEN>
<TOKEN end_char="4347" id="token-34-8" morph="none" pos="word" start_char="4345">the</TOKEN>
<TOKEN end_char="4356" id="token-34-9" morph="none" pos="word" start_char="4349">Institut</TOKEN>
<TOKEN end_char="4364" id="token-34-10" morph="none" pos="word" start_char="4358">Pasteur</TOKEN>
<TOKEN end_char="4373" id="token-34-11" morph="none" pos="word" start_char="4366">released</TOKEN>
<TOKEN end_char="4377" id="token-34-12" morph="none" pos="word" start_char="4375">the</TOKEN>
<TOKEN end_char="4389" id="token-34-13" morph="none" pos="word" start_char="4379">coronavirus</TOKEN>
<TOKEN end_char="4392" id="token-34-14" morph="none" pos="word" start_char="4391">in</TOKEN>
<TOKEN end_char="4396" id="token-34-15" morph="none" pos="word" start_char="4394">the</TOKEN>
<TOKEN end_char="4401" id="token-34-16" morph="none" pos="word" start_char="4398">city</TOKEN>
<TOKEN end_char="4404" id="token-34-17" morph="none" pos="word" start_char="4403">of</TOKEN>
<TOKEN end_char="4410" id="token-34-18" morph="none" pos="word" start_char="4406">Wuhan</TOKEN>
<TOKEN end_char="4413" id="token-34-19" morph="none" pos="word" start_char="4412">in</TOKEN>
<TOKEN end_char="4419" id="token-34-20" morph="none" pos="word" start_char="4415">China</TOKEN>
<TOKEN end_char="4420" id="token-34-21" morph="none" pos="punct" start_char="4420">.</TOKEN>
</SEG>
<SEG end_char="4632" id="segment-35" start_char="4423">
<ORIGINAL_TEXT>The "BSL-4 laboratory" in Wuhan, which is mentioned in this video, is a research institute that strictly depends on the Chinese authorities and one with which the Institut Pasteur has no scientific interaction.</ORIGINAL_TEXT>
<TOKEN end_char="4425" id="token-35-0" morph="none" pos="word" start_char="4423">The</TOKEN>
<TOKEN end_char="4427" id="token-35-1" morph="none" pos="punct" start_char="4427">"</TOKEN>
<TOKEN end_char="4432" id="token-35-2" morph="none" pos="unknown" start_char="4428">BSL-4</TOKEN>
<TOKEN end_char="4443" id="token-35-3" morph="none" pos="word" start_char="4434">laboratory</TOKEN>
<TOKEN end_char="4444" id="token-35-4" morph="none" pos="punct" start_char="4444">"</TOKEN>
<TOKEN end_char="4447" id="token-35-5" morph="none" pos="word" start_char="4446">in</TOKEN>
<TOKEN end_char="4453" id="token-35-6" morph="none" pos="word" start_char="4449">Wuhan</TOKEN>
<TOKEN end_char="4454" id="token-35-7" morph="none" pos="punct" start_char="4454">,</TOKEN>
<TOKEN end_char="4460" id="token-35-8" morph="none" pos="word" start_char="4456">which</TOKEN>
<TOKEN end_char="4463" id="token-35-9" morph="none" pos="word" start_char="4462">is</TOKEN>
<TOKEN end_char="4473" id="token-35-10" morph="none" pos="word" start_char="4465">mentioned</TOKEN>
<TOKEN end_char="4476" id="token-35-11" morph="none" pos="word" start_char="4475">in</TOKEN>
<TOKEN end_char="4481" id="token-35-12" morph="none" pos="word" start_char="4478">this</TOKEN>
<TOKEN end_char="4487" id="token-35-13" morph="none" pos="word" start_char="4483">video</TOKEN>
<TOKEN end_char="4488" id="token-35-14" morph="none" pos="punct" start_char="4488">,</TOKEN>
<TOKEN end_char="4491" id="token-35-15" morph="none" pos="word" start_char="4490">is</TOKEN>
<TOKEN end_char="4493" id="token-35-16" morph="none" pos="word" start_char="4493">a</TOKEN>
<TOKEN end_char="4502" id="token-35-17" morph="none" pos="word" start_char="4495">research</TOKEN>
<TOKEN end_char="4512" id="token-35-18" morph="none" pos="word" start_char="4504">institute</TOKEN>
<TOKEN end_char="4517" id="token-35-19" morph="none" pos="word" start_char="4514">that</TOKEN>
<TOKEN end_char="4526" id="token-35-20" morph="none" pos="word" start_char="4519">strictly</TOKEN>
<TOKEN end_char="4534" id="token-35-21" morph="none" pos="word" start_char="4528">depends</TOKEN>
<TOKEN end_char="4537" id="token-35-22" morph="none" pos="word" start_char="4536">on</TOKEN>
<TOKEN end_char="4541" id="token-35-23" morph="none" pos="word" start_char="4539">the</TOKEN>
<TOKEN end_char="4549" id="token-35-24" morph="none" pos="word" start_char="4543">Chinese</TOKEN>
<TOKEN end_char="4561" id="token-35-25" morph="none" pos="word" start_char="4551">authorities</TOKEN>
<TOKEN end_char="4565" id="token-35-26" morph="none" pos="word" start_char="4563">and</TOKEN>
<TOKEN end_char="4569" id="token-35-27" morph="none" pos="word" start_char="4567">one</TOKEN>
<TOKEN end_char="4574" id="token-35-28" morph="none" pos="word" start_char="4571">with</TOKEN>
<TOKEN end_char="4580" id="token-35-29" morph="none" pos="word" start_char="4576">which</TOKEN>
<TOKEN end_char="4584" id="token-35-30" morph="none" pos="word" start_char="4582">the</TOKEN>
<TOKEN end_char="4593" id="token-35-31" morph="none" pos="word" start_char="4586">Institut</TOKEN>
<TOKEN end_char="4601" id="token-35-32" morph="none" pos="word" start_char="4595">Pasteur</TOKEN>
<TOKEN end_char="4605" id="token-35-33" morph="none" pos="word" start_char="4603">has</TOKEN>
<TOKEN end_char="4608" id="token-35-34" morph="none" pos="word" start_char="4607">no</TOKEN>
<TOKEN end_char="4619" id="token-35-35" morph="none" pos="word" start_char="4610">scientific</TOKEN>
<TOKEN end_char="4631" id="token-35-36" morph="none" pos="word" start_char="4621">interaction</TOKEN>
<TOKEN end_char="4632" id="token-35-37" morph="none" pos="punct" start_char="4632">.</TOKEN>
</SEG>
<SEG end_char="4782" id="segment-36" start_char="4635">
<ORIGINAL_TEXT>See below "The Institut Pasteur of Shanghai (IPS) did not work on coronaviruses in the Wuhan BSL-4 laboratory which depends on a Chinese institute."</ORIGINAL_TEXT>
<TOKEN end_char="4637" id="token-36-0" morph="none" pos="word" start_char="4635">See</TOKEN>
<TOKEN end_char="4643" id="token-36-1" morph="none" pos="word" start_char="4639">below</TOKEN>
<TOKEN end_char="4645" id="token-36-2" morph="none" pos="punct" start_char="4645">"</TOKEN>
<TOKEN end_char="4648" id="token-36-3" morph="none" pos="word" start_char="4646">The</TOKEN>
<TOKEN end_char="4657" id="token-36-4" morph="none" pos="word" start_char="4650">Institut</TOKEN>
<TOKEN end_char="4665" id="token-36-5" morph="none" pos="word" start_char="4659">Pasteur</TOKEN>
<TOKEN end_char="4668" id="token-36-6" morph="none" pos="word" start_char="4667">of</TOKEN>
<TOKEN end_char="4677" id="token-36-7" morph="none" pos="word" start_char="4670">Shanghai</TOKEN>
<TOKEN end_char="4679" id="token-36-8" morph="none" pos="punct" start_char="4679">(</TOKEN>
<TOKEN end_char="4682" id="token-36-9" morph="none" pos="word" start_char="4680">IPS</TOKEN>
<TOKEN end_char="4683" id="token-36-10" morph="none" pos="punct" start_char="4683">)</TOKEN>
<TOKEN end_char="4687" id="token-36-11" morph="none" pos="word" start_char="4685">did</TOKEN>
<TOKEN end_char="4691" id="token-36-12" morph="none" pos="word" start_char="4689">not</TOKEN>
<TOKEN end_char="4696" id="token-36-13" morph="none" pos="word" start_char="4693">work</TOKEN>
<TOKEN end_char="4699" id="token-36-14" morph="none" pos="word" start_char="4698">on</TOKEN>
<TOKEN end_char="4713" id="token-36-15" morph="none" pos="word" start_char="4701">coronaviruses</TOKEN>
<TOKEN end_char="4716" id="token-36-16" morph="none" pos="word" start_char="4715">in</TOKEN>
<TOKEN end_char="4720" id="token-36-17" morph="none" pos="word" start_char="4718">the</TOKEN>
<TOKEN end_char="4726" id="token-36-18" morph="none" pos="word" start_char="4722">Wuhan</TOKEN>
<TOKEN end_char="4732" id="token-36-19" morph="none" pos="unknown" start_char="4728">BSL-4</TOKEN>
<TOKEN end_char="4743" id="token-36-20" morph="none" pos="word" start_char="4734">laboratory</TOKEN>
<TOKEN end_char="4749" id="token-36-21" morph="none" pos="word" start_char="4745">which</TOKEN>
<TOKEN end_char="4757" id="token-36-22" morph="none" pos="word" start_char="4751">depends</TOKEN>
<TOKEN end_char="4760" id="token-36-23" morph="none" pos="word" start_char="4759">on</TOKEN>
<TOKEN end_char="4762" id="token-36-24" morph="none" pos="word" start_char="4762">a</TOKEN>
<TOKEN end_char="4770" id="token-36-25" morph="none" pos="word" start_char="4764">Chinese</TOKEN>
<TOKEN end_char="4780" id="token-36-26" morph="none" pos="word" start_char="4772">institute</TOKEN>
<TOKEN end_char="4782" id="token-36-27" morph="none" pos="punct" start_char="4781">."</TOKEN>
</SEG>
<SEG end_char="4959" id="segment-37" start_char="4785">
<ORIGINAL_TEXT>3 _ The Institut Pasteur is an independent, non-profit foundation with recognized charitable status, and not a laboratory – or subsidiary – of the Sanofi pharmaceutical group.</ORIGINAL_TEXT>
<TOKEN end_char="4785" id="token-37-0" morph="none" pos="word" start_char="4785">3</TOKEN>
<TOKEN end_char="4787" id="token-37-1" morph="none" pos="word" start_char="4787">_</TOKEN>
<TOKEN end_char="4791" id="token-37-2" morph="none" pos="word" start_char="4789">The</TOKEN>
<TOKEN end_char="4800" id="token-37-3" morph="none" pos="word" start_char="4793">Institut</TOKEN>
<TOKEN end_char="4808" id="token-37-4" morph="none" pos="word" start_char="4802">Pasteur</TOKEN>
<TOKEN end_char="4811" id="token-37-5" morph="none" pos="word" start_char="4810">is</TOKEN>
<TOKEN end_char="4814" id="token-37-6" morph="none" pos="word" start_char="4813">an</TOKEN>
<TOKEN end_char="4826" id="token-37-7" morph="none" pos="word" start_char="4816">independent</TOKEN>
<TOKEN end_char="4827" id="token-37-8" morph="none" pos="punct" start_char="4827">,</TOKEN>
<TOKEN end_char="4838" id="token-37-9" morph="none" pos="unknown" start_char="4829">non-profit</TOKEN>
<TOKEN end_char="4849" id="token-37-10" morph="none" pos="word" start_char="4840">foundation</TOKEN>
<TOKEN end_char="4854" id="token-37-11" morph="none" pos="word" start_char="4851">with</TOKEN>
<TOKEN end_char="4865" id="token-37-12" morph="none" pos="word" start_char="4856">recognized</TOKEN>
<TOKEN end_char="4876" id="token-37-13" morph="none" pos="word" start_char="4867">charitable</TOKEN>
<TOKEN end_char="4883" id="token-37-14" morph="none" pos="word" start_char="4878">status</TOKEN>
<TOKEN end_char="4884" id="token-37-15" morph="none" pos="punct" start_char="4884">,</TOKEN>
<TOKEN end_char="4888" id="token-37-16" morph="none" pos="word" start_char="4886">and</TOKEN>
<TOKEN end_char="4892" id="token-37-17" morph="none" pos="word" start_char="4890">not</TOKEN>
<TOKEN end_char="4894" id="token-37-18" morph="none" pos="word" start_char="4894">a</TOKEN>
<TOKEN end_char="4905" id="token-37-19" morph="none" pos="word" start_char="4896">laboratory</TOKEN>
<TOKEN end_char="4907" id="token-37-20" morph="none" pos="punct" start_char="4907">–</TOKEN>
<TOKEN end_char="4910" id="token-37-21" morph="none" pos="word" start_char="4909">or</TOKEN>
<TOKEN end_char="4921" id="token-37-22" morph="none" pos="word" start_char="4912">subsidiary</TOKEN>
<TOKEN end_char="4923" id="token-37-23" morph="none" pos="punct" start_char="4923">–</TOKEN>
<TOKEN end_char="4926" id="token-37-24" morph="none" pos="word" start_char="4925">of</TOKEN>
<TOKEN end_char="4930" id="token-37-25" morph="none" pos="word" start_char="4928">the</TOKEN>
<TOKEN end_char="4937" id="token-37-26" morph="none" pos="word" start_char="4932">Sanofi</TOKEN>
<TOKEN end_char="4952" id="token-37-27" morph="none" pos="word" start_char="4939">pharmaceutical</TOKEN>
<TOKEN end_char="4958" id="token-37-28" morph="none" pos="word" start_char="4954">group</TOKEN>
<TOKEN end_char="4959" id="token-37-29" morph="none" pos="punct" start_char="4959">.</TOKEN>
</SEG>
<SEG end_char="5010" id="segment-38" start_char="4963">
<ORIGINAL_TEXT>The Institut Pasteur is a non-profit foundation.</ORIGINAL_TEXT>
<TOKEN end_char="4965" id="token-38-0" morph="none" pos="word" start_char="4963">The</TOKEN>
<TOKEN end_char="4974" id="token-38-1" morph="none" pos="word" start_char="4967">Institut</TOKEN>
<TOKEN end_char="4982" id="token-38-2" morph="none" pos="word" start_char="4976">Pasteur</TOKEN>
<TOKEN end_char="4985" id="token-38-3" morph="none" pos="word" start_char="4984">is</TOKEN>
<TOKEN end_char="4987" id="token-38-4" morph="none" pos="word" start_char="4987">a</TOKEN>
<TOKEN end_char="4998" id="token-38-5" morph="none" pos="unknown" start_char="4989">non-profit</TOKEN>
<TOKEN end_char="5009" id="token-38-6" morph="none" pos="word" start_char="5000">foundation</TOKEN>
<TOKEN end_char="5010" id="token-38-7" morph="none" pos="punct" start_char="5010">.</TOKEN>
</SEG>
<SEG end_char="5156" id="segment-39" start_char="5012">
<ORIGINAL_TEXT>Its mission is to help prevent and treat diseases, mainly those of infectious origin, through research, education, and public health initiatives.</ORIGINAL_TEXT>
<TOKEN end_char="5014" id="token-39-0" morph="none" pos="word" start_char="5012">Its</TOKEN>
<TOKEN end_char="5022" id="token-39-1" morph="none" pos="word" start_char="5016">mission</TOKEN>
<TOKEN end_char="5025" id="token-39-2" morph="none" pos="word" start_char="5024">is</TOKEN>
<TOKEN end_char="5028" id="token-39-3" morph="none" pos="word" start_char="5027">to</TOKEN>
<TOKEN end_char="5033" id="token-39-4" morph="none" pos="word" start_char="5030">help</TOKEN>
<TOKEN end_char="5041" id="token-39-5" morph="none" pos="word" start_char="5035">prevent</TOKEN>
<TOKEN end_char="5045" id="token-39-6" morph="none" pos="word" start_char="5043">and</TOKEN>
<TOKEN end_char="5051" id="token-39-7" morph="none" pos="word" start_char="5047">treat</TOKEN>
<TOKEN end_char="5060" id="token-39-8" morph="none" pos="word" start_char="5053">diseases</TOKEN>
<TOKEN end_char="5061" id="token-39-9" morph="none" pos="punct" start_char="5061">,</TOKEN>
<TOKEN end_char="5068" id="token-39-10" morph="none" pos="word" start_char="5063">mainly</TOKEN>
<TOKEN end_char="5074" id="token-39-11" morph="none" pos="word" start_char="5070">those</TOKEN>
<TOKEN end_char="5077" id="token-39-12" morph="none" pos="word" start_char="5076">of</TOKEN>
<TOKEN end_char="5088" id="token-39-13" morph="none" pos="word" start_char="5079">infectious</TOKEN>
<TOKEN end_char="5095" id="token-39-14" morph="none" pos="word" start_char="5090">origin</TOKEN>
<TOKEN end_char="5096" id="token-39-15" morph="none" pos="punct" start_char="5096">,</TOKEN>
<TOKEN end_char="5104" id="token-39-16" morph="none" pos="word" start_char="5098">through</TOKEN>
<TOKEN end_char="5113" id="token-39-17" morph="none" pos="word" start_char="5106">research</TOKEN>
<TOKEN end_char="5114" id="token-39-18" morph="none" pos="punct" start_char="5114">,</TOKEN>
<TOKEN end_char="5124" id="token-39-19" morph="none" pos="word" start_char="5116">education</TOKEN>
<TOKEN end_char="5125" id="token-39-20" morph="none" pos="punct" start_char="5125">,</TOKEN>
<TOKEN end_char="5129" id="token-39-21" morph="none" pos="word" start_char="5127">and</TOKEN>
<TOKEN end_char="5136" id="token-39-22" morph="none" pos="word" start_char="5131">public</TOKEN>
<TOKEN end_char="5143" id="token-39-23" morph="none" pos="word" start_char="5138">health</TOKEN>
<TOKEN end_char="5155" id="token-39-24" morph="none" pos="word" start_char="5145">initiatives</TOKEN>
<TOKEN end_char="5156" id="token-39-25" morph="none" pos="punct" start_char="5156">.</TOKEN>
</SEG>
<SEG end_char="5430" id="segment-40" start_char="5159">
<ORIGINAL_TEXT>The Institut Pasteur carries out research – including in vaccinology – in a bid to improve understanding of the processes that induce immune responses and interactions between microbes and their hosts in a certain number of diseases (dengue, AIDS, yellow fever, Zika, etc.</ORIGINAL_TEXT>
<TOKEN end_char="5161" id="token-40-0" morph="none" pos="word" start_char="5159">The</TOKEN>
<TOKEN end_char="5170" id="token-40-1" morph="none" pos="word" start_char="5163">Institut</TOKEN>
<TOKEN end_char="5178" id="token-40-2" morph="none" pos="word" start_char="5172">Pasteur</TOKEN>
<TOKEN end_char="5186" id="token-40-3" morph="none" pos="word" start_char="5180">carries</TOKEN>
<TOKEN end_char="5190" id="token-40-4" morph="none" pos="word" start_char="5188">out</TOKEN>
<TOKEN end_char="5199" id="token-40-5" morph="none" pos="word" start_char="5192">research</TOKEN>
<TOKEN end_char="5201" id="token-40-6" morph="none" pos="punct" start_char="5201">–</TOKEN>
<TOKEN end_char="5211" id="token-40-7" morph="none" pos="word" start_char="5203">including</TOKEN>
<TOKEN end_char="5214" id="token-40-8" morph="none" pos="word" start_char="5213">in</TOKEN>
<TOKEN end_char="5226" id="token-40-9" morph="none" pos="word" start_char="5216">vaccinology</TOKEN>
<TOKEN end_char="5228" id="token-40-10" morph="none" pos="punct" start_char="5228">–</TOKEN>
<TOKEN end_char="5231" id="token-40-11" morph="none" pos="word" start_char="5230">in</TOKEN>
<TOKEN end_char="5233" id="token-40-12" morph="none" pos="word" start_char="5233">a</TOKEN>
<TOKEN end_char="5237" id="token-40-13" morph="none" pos="word" start_char="5235">bid</TOKEN>
<TOKEN end_char="5240" id="token-40-14" morph="none" pos="word" start_char="5239">to</TOKEN>
<TOKEN end_char="5248" id="token-40-15" morph="none" pos="word" start_char="5242">improve</TOKEN>
<TOKEN end_char="5262" id="token-40-16" morph="none" pos="word" start_char="5250">understanding</TOKEN>
<TOKEN end_char="5265" id="token-40-17" morph="none" pos="word" start_char="5264">of</TOKEN>
<TOKEN end_char="5269" id="token-40-18" morph="none" pos="word" start_char="5267">the</TOKEN>
<TOKEN end_char="5279" id="token-40-19" morph="none" pos="word" start_char="5271">processes</TOKEN>
<TOKEN end_char="5284" id="token-40-20" morph="none" pos="word" start_char="5281">that</TOKEN>
<TOKEN end_char="5291" id="token-40-21" morph="none" pos="word" start_char="5286">induce</TOKEN>
<TOKEN end_char="5298" id="token-40-22" morph="none" pos="word" start_char="5293">immune</TOKEN>
<TOKEN end_char="5308" id="token-40-23" morph="none" pos="word" start_char="5300">responses</TOKEN>
<TOKEN end_char="5312" id="token-40-24" morph="none" pos="word" start_char="5310">and</TOKEN>
<TOKEN end_char="5325" id="token-40-25" morph="none" pos="word" start_char="5314">interactions</TOKEN>
<TOKEN end_char="5333" id="token-40-26" morph="none" pos="word" start_char="5327">between</TOKEN>
<TOKEN end_char="5342" id="token-40-27" morph="none" pos="word" start_char="5335">microbes</TOKEN>
<TOKEN end_char="5346" id="token-40-28" morph="none" pos="word" start_char="5344">and</TOKEN>
<TOKEN end_char="5352" id="token-40-29" morph="none" pos="word" start_char="5348">their</TOKEN>
<TOKEN end_char="5358" id="token-40-30" morph="none" pos="word" start_char="5354">hosts</TOKEN>
<TOKEN end_char="5361" id="token-40-31" morph="none" pos="word" start_char="5360">in</TOKEN>
<TOKEN end_char="5363" id="token-40-32" morph="none" pos="word" start_char="5363">a</TOKEN>
<TOKEN end_char="5371" id="token-40-33" morph="none" pos="word" start_char="5365">certain</TOKEN>
<TOKEN end_char="5378" id="token-40-34" morph="none" pos="word" start_char="5373">number</TOKEN>
<TOKEN end_char="5381" id="token-40-35" morph="none" pos="word" start_char="5380">of</TOKEN>
<TOKEN end_char="5390" id="token-40-36" morph="none" pos="word" start_char="5383">diseases</TOKEN>
<TOKEN end_char="5392" id="token-40-37" morph="none" pos="punct" start_char="5392">(</TOKEN>
<TOKEN end_char="5398" id="token-40-38" morph="none" pos="word" start_char="5393">dengue</TOKEN>
<TOKEN end_char="5399" id="token-40-39" morph="none" pos="punct" start_char="5399">,</TOKEN>
<TOKEN end_char="5404" id="token-40-40" morph="none" pos="word" start_char="5401">AIDS</TOKEN>
<TOKEN end_char="5405" id="token-40-41" morph="none" pos="punct" start_char="5405">,</TOKEN>
<TOKEN end_char="5412" id="token-40-42" morph="none" pos="word" start_char="5407">yellow</TOKEN>
<TOKEN end_char="5418" id="token-40-43" morph="none" pos="word" start_char="5414">fever</TOKEN>
<TOKEN end_char="5419" id="token-40-44" morph="none" pos="punct" start_char="5419">,</TOKEN>
<TOKEN end_char="5424" id="token-40-45" morph="none" pos="word" start_char="5421">Zika</TOKEN>
<TOKEN end_char="5425" id="token-40-46" morph="none" pos="punct" start_char="5425">,</TOKEN>
<TOKEN end_char="5429" id="token-40-47" morph="none" pos="word" start_char="5427">etc</TOKEN>
<TOKEN end_char="5430" id="token-40-48" morph="none" pos="punct" start_char="5430">.</TOKEN>
</SEG>
<SEG end_char="5624" id="segment-41" start_char="5432">
<ORIGINAL_TEXT>and now SARS-CoV-2/Covid-19 infection), to pave the way for the design of innovative prevention strategies and propose vaccine candidates for developments that may be produced by manufacturers.</ORIGINAL_TEXT>
<TOKEN end_char="5434" id="token-41-0" morph="none" pos="word" start_char="5432">and</TOKEN>
<TOKEN end_char="5438" id="token-41-1" morph="none" pos="word" start_char="5436">now</TOKEN>
<TOKEN end_char="5458" id="token-41-2" morph="none" pos="unknown" start_char="5440">SARS-CoV-2/Covid-19</TOKEN>
<TOKEN end_char="5468" id="token-41-3" morph="none" pos="word" start_char="5460">infection</TOKEN>
<TOKEN end_char="5470" id="token-41-4" morph="none" pos="punct" start_char="5469">),</TOKEN>
<TOKEN end_char="5473" id="token-41-5" morph="none" pos="word" start_char="5472">to</TOKEN>
<TOKEN end_char="5478" id="token-41-6" morph="none" pos="word" start_char="5475">pave</TOKEN>
<TOKEN end_char="5482" id="token-41-7" morph="none" pos="word" start_char="5480">the</TOKEN>
<TOKEN end_char="5486" id="token-41-8" morph="none" pos="word" start_char="5484">way</TOKEN>
<TOKEN end_char="5490" id="token-41-9" morph="none" pos="word" start_char="5488">for</TOKEN>
<TOKEN end_char="5494" id="token-41-10" morph="none" pos="word" start_char="5492">the</TOKEN>
<TOKEN end_char="5501" id="token-41-11" morph="none" pos="word" start_char="5496">design</TOKEN>
<TOKEN end_char="5504" id="token-41-12" morph="none" pos="word" start_char="5503">of</TOKEN>
<TOKEN end_char="5515" id="token-41-13" morph="none" pos="word" start_char="5506">innovative</TOKEN>
<TOKEN end_char="5526" id="token-41-14" morph="none" pos="word" start_char="5517">prevention</TOKEN>
<TOKEN end_char="5537" id="token-41-15" morph="none" pos="word" start_char="5528">strategies</TOKEN>
<TOKEN end_char="5541" id="token-41-16" morph="none" pos="word" start_char="5539">and</TOKEN>
<TOKEN end_char="5549" id="token-41-17" morph="none" pos="word" start_char="5543">propose</TOKEN>
<TOKEN end_char="5557" id="token-41-18" morph="none" pos="word" start_char="5551">vaccine</TOKEN>
<TOKEN end_char="5568" id="token-41-19" morph="none" pos="word" start_char="5559">candidates</TOKEN>
<TOKEN end_char="5572" id="token-41-20" morph="none" pos="word" start_char="5570">for</TOKEN>
<TOKEN end_char="5585" id="token-41-21" morph="none" pos="word" start_char="5574">developments</TOKEN>
<TOKEN end_char="5590" id="token-41-22" morph="none" pos="word" start_char="5587">that</TOKEN>
<TOKEN end_char="5594" id="token-41-23" morph="none" pos="word" start_char="5592">may</TOKEN>
<TOKEN end_char="5597" id="token-41-24" morph="none" pos="word" start_char="5596">be</TOKEN>
<TOKEN end_char="5606" id="token-41-25" morph="none" pos="word" start_char="5599">produced</TOKEN>
<TOKEN end_char="5609" id="token-41-26" morph="none" pos="word" start_char="5608">by</TOKEN>
<TOKEN end_char="5623" id="token-41-27" morph="none" pos="word" start_char="5611">manufacturers</TOKEN>
<TOKEN end_char="5624" id="token-41-28" morph="none" pos="punct" start_char="5624">.</TOKEN>
</SEG>
<SEG end_char="5703" id="segment-42" start_char="5627">
<ORIGINAL_TEXT>Today, the Institut Pasteur neither manufactures nor markets vaccines itself.</ORIGINAL_TEXT>
<TOKEN end_char="5631" id="token-42-0" morph="none" pos="word" start_char="5627">Today</TOKEN>
<TOKEN end_char="5632" id="token-42-1" morph="none" pos="punct" start_char="5632">,</TOKEN>
<TOKEN end_char="5636" id="token-42-2" morph="none" pos="word" start_char="5634">the</TOKEN>
<TOKEN end_char="5645" id="token-42-3" morph="none" pos="word" start_char="5638">Institut</TOKEN>
<TOKEN end_char="5653" id="token-42-4" morph="none" pos="word" start_char="5647">Pasteur</TOKEN>
<TOKEN end_char="5661" id="token-42-5" morph="none" pos="word" start_char="5655">neither</TOKEN>
<TOKEN end_char="5674" id="token-42-6" morph="none" pos="word" start_char="5663">manufactures</TOKEN>
<TOKEN end_char="5678" id="token-42-7" morph="none" pos="word" start_char="5676">nor</TOKEN>
<TOKEN end_char="5686" id="token-42-8" morph="none" pos="word" start_char="5680">markets</TOKEN>
<TOKEN end_char="5695" id="token-42-9" morph="none" pos="word" start_char="5688">vaccines</TOKEN>
<TOKEN end_char="5702" id="token-42-10" morph="none" pos="word" start_char="5697">itself</TOKEN>
<TOKEN end_char="5703" id="token-42-11" morph="none" pos="punct" start_char="5703">.</TOKEN>
</SEG>
<SEG end_char="5748" id="segment-43" start_char="5706">
<ORIGINAL_TEXT>More information about the Institut Pasteur</ORIGINAL_TEXT>
<TOKEN end_char="5709" id="token-43-0" morph="none" pos="word" start_char="5706">More</TOKEN>
<TOKEN end_char="5721" id="token-43-1" morph="none" pos="word" start_char="5711">information</TOKEN>
<TOKEN end_char="5727" id="token-43-2" morph="none" pos="word" start_char="5723">about</TOKEN>
<TOKEN end_char="5731" id="token-43-3" morph="none" pos="word" start_char="5729">the</TOKEN>
<TOKEN end_char="5740" id="token-43-4" morph="none" pos="word" start_char="5733">Institut</TOKEN>
<TOKEN end_char="5748" id="token-43-5" morph="none" pos="word" start_char="5742">Pasteur</TOKEN>
</SEG>
<SEG end_char="5893" id="segment-44" start_char="5751">
<ORIGINAL_TEXT>4 _ Asserting that the Institut Pasteur is planning to enslave and control the global population is utterly false and devoid of all foundation.</ORIGINAL_TEXT>
<TOKEN end_char="5751" id="token-44-0" morph="none" pos="word" start_char="5751">4</TOKEN>
<TOKEN end_char="5753" id="token-44-1" morph="none" pos="word" start_char="5753">_</TOKEN>
<TOKEN end_char="5763" id="token-44-2" morph="none" pos="word" start_char="5755">Asserting</TOKEN>
<TOKEN end_char="5768" id="token-44-3" morph="none" pos="word" start_char="5765">that</TOKEN>
<TOKEN end_char="5772" id="token-44-4" morph="none" pos="word" start_char="5770">the</TOKEN>
<TOKEN end_char="5781" id="token-44-5" morph="none" pos="word" start_char="5774">Institut</TOKEN>
<TOKEN end_char="5789" id="token-44-6" morph="none" pos="word" start_char="5783">Pasteur</TOKEN>
<TOKEN end_char="5792" id="token-44-7" morph="none" pos="word" start_char="5791">is</TOKEN>
<TOKEN end_char="5801" id="token-44-8" morph="none" pos="word" start_char="5794">planning</TOKEN>
<TOKEN end_char="5804" id="token-44-9" morph="none" pos="word" start_char="5803">to</TOKEN>
<TOKEN end_char="5812" id="token-44-10" morph="none" pos="word" start_char="5806">enslave</TOKEN>
<TOKEN end_char="5816" id="token-44-11" morph="none" pos="word" start_char="5814">and</TOKEN>
<TOKEN end_char="5824" id="token-44-12" morph="none" pos="word" start_char="5818">control</TOKEN>
<TOKEN end_char="5828" id="token-44-13" morph="none" pos="word" start_char="5826">the</TOKEN>
<TOKEN end_char="5835" id="token-44-14" morph="none" pos="word" start_char="5830">global</TOKEN>
<TOKEN end_char="5846" id="token-44-15" morph="none" pos="word" start_char="5837">population</TOKEN>
<TOKEN end_char="5849" id="token-44-16" morph="none" pos="word" start_char="5848">is</TOKEN>
<TOKEN end_char="5857" id="token-44-17" morph="none" pos="word" start_char="5851">utterly</TOKEN>
<TOKEN end_char="5863" id="token-44-18" morph="none" pos="word" start_char="5859">false</TOKEN>
<TOKEN end_char="5867" id="token-44-19" morph="none" pos="word" start_char="5865">and</TOKEN>
<TOKEN end_char="5874" id="token-44-20" morph="none" pos="word" start_char="5869">devoid</TOKEN>
<TOKEN end_char="5877" id="token-44-21" morph="none" pos="word" start_char="5876">of</TOKEN>
<TOKEN end_char="5881" id="token-44-22" morph="none" pos="word" start_char="5879">all</TOKEN>
<TOKEN end_char="5892" id="token-44-23" morph="none" pos="word" start_char="5883">foundation</TOKEN>
<TOKEN end_char="5893" id="token-44-24" morph="none" pos="punct" start_char="5893">.</TOKEN>
</SEG>
<SEG end_char="6039" id="segment-45" start_char="5897">
<ORIGINAL_TEXT>Falsely incriminating a natural and / or legal person for deeds that they have evidently not committed constitutes a grave and serious offense.</ORIGINAL_TEXT>
<TOKEN end_char="5903" id="token-45-0" morph="none" pos="word" start_char="5897">Falsely</TOKEN>
<TOKEN end_char="5917" id="token-45-1" morph="none" pos="word" start_char="5905">incriminating</TOKEN>
<TOKEN end_char="5919" id="token-45-2" morph="none" pos="word" start_char="5919">a</TOKEN>
<TOKEN end_char="5927" id="token-45-3" morph="none" pos="word" start_char="5921">natural</TOKEN>
<TOKEN end_char="5931" id="token-45-4" morph="none" pos="word" start_char="5929">and</TOKEN>
<TOKEN end_char="5933" id="token-45-5" morph="none" pos="punct" start_char="5933">/</TOKEN>
<TOKEN end_char="5936" id="token-45-6" morph="none" pos="word" start_char="5935">or</TOKEN>
<TOKEN end_char="5942" id="token-45-7" morph="none" pos="word" start_char="5938">legal</TOKEN>
<TOKEN end_char="5949" id="token-45-8" morph="none" pos="word" start_char="5944">person</TOKEN>
<TOKEN end_char="5953" id="token-45-9" morph="none" pos="word" start_char="5951">for</TOKEN>
<TOKEN end_char="5959" id="token-45-10" morph="none" pos="word" start_char="5955">deeds</TOKEN>
<TOKEN end_char="5964" id="token-45-11" morph="none" pos="word" start_char="5961">that</TOKEN>
<TOKEN end_char="5969" id="token-45-12" morph="none" pos="word" start_char="5966">they</TOKEN>
<TOKEN end_char="5974" id="token-45-13" morph="none" pos="word" start_char="5971">have</TOKEN>
<TOKEN end_char="5984" id="token-45-14" morph="none" pos="word" start_char="5976">evidently</TOKEN>
<TOKEN end_char="5988" id="token-45-15" morph="none" pos="word" start_char="5986">not</TOKEN>
<TOKEN end_char="5998" id="token-45-16" morph="none" pos="word" start_char="5990">committed</TOKEN>
<TOKEN end_char="6010" id="token-45-17" morph="none" pos="word" start_char="6000">constitutes</TOKEN>
<TOKEN end_char="6012" id="token-45-18" morph="none" pos="word" start_char="6012">a</TOKEN>
<TOKEN end_char="6018" id="token-45-19" morph="none" pos="word" start_char="6014">grave</TOKEN>
<TOKEN end_char="6022" id="token-45-20" morph="none" pos="word" start_char="6020">and</TOKEN>
<TOKEN end_char="6030" id="token-45-21" morph="none" pos="word" start_char="6024">serious</TOKEN>
<TOKEN end_char="6038" id="token-45-22" morph="none" pos="word" start_char="6032">offense</TOKEN>
<TOKEN end_char="6039" id="token-45-23" morph="none" pos="punct" start_char="6039">.</TOKEN>
</SEG>
<SEG end_char="6228" id="segment-46" start_char="6041">
<ORIGINAL_TEXT>These public defamations, spread on social media without any consideration and relayed with no prior analysis of, or investigation into, the facts, deliberately feed a climate of distrust.</ORIGINAL_TEXT>
<TOKEN end_char="6045" id="token-46-0" morph="none" pos="word" start_char="6041">These</TOKEN>
<TOKEN end_char="6052" id="token-46-1" morph="none" pos="word" start_char="6047">public</TOKEN>
<TOKEN end_char="6064" id="token-46-2" morph="none" pos="word" start_char="6054">defamations</TOKEN>
<TOKEN end_char="6065" id="token-46-3" morph="none" pos="punct" start_char="6065">,</TOKEN>
<TOKEN end_char="6072" id="token-46-4" morph="none" pos="word" start_char="6067">spread</TOKEN>
<TOKEN end_char="6075" id="token-46-5" morph="none" pos="word" start_char="6074">on</TOKEN>
<TOKEN end_char="6082" id="token-46-6" morph="none" pos="word" start_char="6077">social</TOKEN>
<TOKEN end_char="6088" id="token-46-7" morph="none" pos="word" start_char="6084">media</TOKEN>
<TOKEN end_char="6096" id="token-46-8" morph="none" pos="word" start_char="6090">without</TOKEN>
<TOKEN end_char="6100" id="token-46-9" morph="none" pos="word" start_char="6098">any</TOKEN>
<TOKEN end_char="6114" id="token-46-10" morph="none" pos="word" start_char="6102">consideration</TOKEN>
<TOKEN end_char="6118" id="token-46-11" morph="none" pos="word" start_char="6116">and</TOKEN>
<TOKEN end_char="6126" id="token-46-12" morph="none" pos="word" start_char="6120">relayed</TOKEN>
<TOKEN end_char="6131" id="token-46-13" morph="none" pos="word" start_char="6128">with</TOKEN>
<TOKEN end_char="6134" id="token-46-14" morph="none" pos="word" start_char="6133">no</TOKEN>
<TOKEN end_char="6140" id="token-46-15" morph="none" pos="word" start_char="6136">prior</TOKEN>
<TOKEN end_char="6149" id="token-46-16" morph="none" pos="word" start_char="6142">analysis</TOKEN>
<TOKEN end_char="6152" id="token-46-17" morph="none" pos="word" start_char="6151">of</TOKEN>
<TOKEN end_char="6153" id="token-46-18" morph="none" pos="punct" start_char="6153">,</TOKEN>
<TOKEN end_char="6156" id="token-46-19" morph="none" pos="word" start_char="6155">or</TOKEN>
<TOKEN end_char="6170" id="token-46-20" morph="none" pos="word" start_char="6158">investigation</TOKEN>
<TOKEN end_char="6175" id="token-46-21" morph="none" pos="word" start_char="6172">into</TOKEN>
<TOKEN end_char="6176" id="token-46-22" morph="none" pos="punct" start_char="6176">,</TOKEN>
<TOKEN end_char="6180" id="token-46-23" morph="none" pos="word" start_char="6178">the</TOKEN>
<TOKEN end_char="6186" id="token-46-24" morph="none" pos="word" start_char="6182">facts</TOKEN>
<TOKEN end_char="6187" id="token-46-25" morph="none" pos="punct" start_char="6187">,</TOKEN>
<TOKEN end_char="6200" id="token-46-26" morph="none" pos="word" start_char="6189">deliberately</TOKEN>
<TOKEN end_char="6205" id="token-46-27" morph="none" pos="word" start_char="6202">feed</TOKEN>
<TOKEN end_char="6207" id="token-46-28" morph="none" pos="word" start_char="6207">a</TOKEN>
<TOKEN end_char="6215" id="token-46-29" morph="none" pos="word" start_char="6209">climate</TOKEN>
<TOKEN end_char="6218" id="token-46-30" morph="none" pos="word" start_char="6217">of</TOKEN>
<TOKEN end_char="6227" id="token-46-31" morph="none" pos="word" start_char="6220">distrust</TOKEN>
<TOKEN end_char="6228" id="token-46-32" morph="none" pos="punct" start_char="6228">.</TOKEN>
</SEG>
<SEG end_char="6348" id="segment-47" start_char="6231">
<ORIGINAL_TEXT>5 _ The Institut Pasteur has initiated legal proceedings for misleading and defamatory information circulating online.</ORIGINAL_TEXT>
<TOKEN end_char="6231" id="token-47-0" morph="none" pos="word" start_char="6231">5</TOKEN>
<TOKEN end_char="6233" id="token-47-1" morph="none" pos="word" start_char="6233">_</TOKEN>
<TOKEN end_char="6237" id="token-47-2" morph="none" pos="word" start_char="6235">The</TOKEN>
<TOKEN end_char="6246" id="token-47-3" morph="none" pos="word" start_char="6239">Institut</TOKEN>
<TOKEN end_char="6254" id="token-47-4" morph="none" pos="word" start_char="6248">Pasteur</TOKEN>
<TOKEN end_char="6258" id="token-47-5" morph="none" pos="word" start_char="6256">has</TOKEN>
<TOKEN end_char="6268" id="token-47-6" morph="none" pos="word" start_char="6260">initiated</TOKEN>
<TOKEN end_char="6274" id="token-47-7" morph="none" pos="word" start_char="6270">legal</TOKEN>
<TOKEN end_char="6286" id="token-47-8" morph="none" pos="word" start_char="6276">proceedings</TOKEN>
<TOKEN end_char="6290" id="token-47-9" morph="none" pos="word" start_char="6288">for</TOKEN>
<TOKEN end_char="6301" id="token-47-10" morph="none" pos="word" start_char="6292">misleading</TOKEN>
<TOKEN end_char="6305" id="token-47-11" morph="none" pos="word" start_char="6303">and</TOKEN>
<TOKEN end_char="6316" id="token-47-12" morph="none" pos="word" start_char="6307">defamatory</TOKEN>
<TOKEN end_char="6328" id="token-47-13" morph="none" pos="word" start_char="6318">information</TOKEN>
<TOKEN end_char="6340" id="token-47-14" morph="none" pos="word" start_char="6330">circulating</TOKEN>
<TOKEN end_char="6347" id="token-47-15" morph="none" pos="word" start_char="6342">online</TOKEN>
<TOKEN end_char="6348" id="token-47-16" morph="none" pos="punct" start_char="6348">.</TOKEN>
</SEG>
<SEG end_char="6465" id="segment-48" start_char="6352">
<ORIGINAL_TEXT>Based on a misinterpretation of a patent, several videos accuse the Institut Pasteur of creating the #Coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="6356" id="token-48-0" morph="none" pos="word" start_char="6352">Based</TOKEN>
<TOKEN end_char="6359" id="token-48-1" morph="none" pos="word" start_char="6358">on</TOKEN>
<TOKEN end_char="6361" id="token-48-2" morph="none" pos="word" start_char="6361">a</TOKEN>
<TOKEN end_char="6379" id="token-48-3" morph="none" pos="word" start_char="6363">misinterpretation</TOKEN>
<TOKEN end_char="6382" id="token-48-4" morph="none" pos="word" start_char="6381">of</TOKEN>
<TOKEN end_char="6384" id="token-48-5" morph="none" pos="word" start_char="6384">a</TOKEN>
<TOKEN end_char="6391" id="token-48-6" morph="none" pos="word" start_char="6386">patent</TOKEN>
<TOKEN end_char="6392" id="token-48-7" morph="none" pos="punct" start_char="6392">,</TOKEN>
<TOKEN end_char="6400" id="token-48-8" morph="none" pos="word" start_char="6394">several</TOKEN>
<TOKEN end_char="6407" id="token-48-9" morph="none" pos="word" start_char="6402">videos</TOKEN>
<TOKEN end_char="6414" id="token-48-10" morph="none" pos="word" start_char="6409">accuse</TOKEN>
<TOKEN end_char="6418" id="token-48-11" morph="none" pos="word" start_char="6416">the</TOKEN>
<TOKEN end_char="6427" id="token-48-12" morph="none" pos="word" start_char="6420">Institut</TOKEN>
<TOKEN end_char="6435" id="token-48-13" morph="none" pos="word" start_char="6429">Pasteur</TOKEN>
<TOKEN end_char="6438" id="token-48-14" morph="none" pos="word" start_char="6437">of</TOKEN>
<TOKEN end_char="6447" id="token-48-15" morph="none" pos="word" start_char="6440">creating</TOKEN>
<TOKEN end_char="6451" id="token-48-16" morph="none" pos="word" start_char="6449">the</TOKEN>
<TOKEN end_char="6465" id="token-48-17" morph="none" pos="tag" start_char="6453">#Coronavirus.</TOKEN>
</SEG>
<SEG end_char="6652" id="segment-49" start_char="6467">
<ORIGINAL_TEXT>In response to these false and defamatory claims, the Institut Pasteur once again lodged a complaint for defamation with the Senior Investigating Judge at the Paris Court this September.</ORIGINAL_TEXT>
<TOKEN end_char="6468" id="token-49-0" morph="none" pos="word" start_char="6467">In</TOKEN>
<TOKEN end_char="6477" id="token-49-1" morph="none" pos="word" start_char="6470">response</TOKEN>
<TOKEN end_char="6480" id="token-49-2" morph="none" pos="word" start_char="6479">to</TOKEN>
<TOKEN end_char="6486" id="token-49-3" morph="none" pos="word" start_char="6482">these</TOKEN>
<TOKEN end_char="6492" id="token-49-4" morph="none" pos="word" start_char="6488">false</TOKEN>
<TOKEN end_char="6496" id="token-49-5" morph="none" pos="word" start_char="6494">and</TOKEN>
<TOKEN end_char="6507" id="token-49-6" morph="none" pos="word" start_char="6498">defamatory</TOKEN>
<TOKEN end_char="6514" id="token-49-7" morph="none" pos="word" start_char="6509">claims</TOKEN>
<TOKEN end_char="6515" id="token-49-8" morph="none" pos="punct" start_char="6515">,</TOKEN>
<TOKEN end_char="6519" id="token-49-9" morph="none" pos="word" start_char="6517">the</TOKEN>
<TOKEN end_char="6528" id="token-49-10" morph="none" pos="word" start_char="6521">Institut</TOKEN>
<TOKEN end_char="6536" id="token-49-11" morph="none" pos="word" start_char="6530">Pasteur</TOKEN>
<TOKEN end_char="6541" id="token-49-12" morph="none" pos="word" start_char="6538">once</TOKEN>
<TOKEN end_char="6547" id="token-49-13" morph="none" pos="word" start_char="6543">again</TOKEN>
<TOKEN end_char="6554" id="token-49-14" morph="none" pos="word" start_char="6549">lodged</TOKEN>
<TOKEN end_char="6556" id="token-49-15" morph="none" pos="word" start_char="6556">a</TOKEN>
<TOKEN end_char="6566" id="token-49-16" morph="none" pos="word" start_char="6558">complaint</TOKEN>
<TOKEN end_char="6570" id="token-49-17" morph="none" pos="word" start_char="6568">for</TOKEN>
<TOKEN end_char="6581" id="token-49-18" morph="none" pos="word" start_char="6572">defamation</TOKEN>
<TOKEN end_char="6586" id="token-49-19" morph="none" pos="word" start_char="6583">with</TOKEN>
<TOKEN end_char="6590" id="token-49-20" morph="none" pos="word" start_char="6588">the</TOKEN>
<TOKEN end_char="6597" id="token-49-21" morph="none" pos="word" start_char="6592">Senior</TOKEN>
<TOKEN end_char="6611" id="token-49-22" morph="none" pos="word" start_char="6599">Investigating</TOKEN>
<TOKEN end_char="6617" id="token-49-23" morph="none" pos="word" start_char="6613">Judge</TOKEN>
<TOKEN end_char="6620" id="token-49-24" morph="none" pos="word" start_char="6619">at</TOKEN>
<TOKEN end_char="6624" id="token-49-25" morph="none" pos="word" start_char="6622">the</TOKEN>
<TOKEN end_char="6630" id="token-49-26" morph="none" pos="word" start_char="6626">Paris</TOKEN>
<TOKEN end_char="6636" id="token-49-27" morph="none" pos="word" start_char="6632">Court</TOKEN>
<TOKEN end_char="6641" id="token-49-28" morph="none" pos="word" start_char="6638">this</TOKEN>
<TOKEN end_char="6651" id="token-49-29" morph="none" pos="word" start_char="6643">September</TOKEN>
<TOKEN end_char="6652" id="token-49-30" morph="none" pos="punct" start_char="6652">.</TOKEN>
</SEG>
<SEG end_char="6722" id="segment-50" start_char="6655">
<ORIGINAL_TEXT>The accusations have already been refuted several times since March.</ORIGINAL_TEXT>
<TOKEN end_char="6657" id="token-50-0" morph="none" pos="word" start_char="6655">The</TOKEN>
<TOKEN end_char="6669" id="token-50-1" morph="none" pos="word" start_char="6659">accusations</TOKEN>
<TOKEN end_char="6674" id="token-50-2" morph="none" pos="word" start_char="6671">have</TOKEN>
<TOKEN end_char="6682" id="token-50-3" morph="none" pos="word" start_char="6676">already</TOKEN>
<TOKEN end_char="6687" id="token-50-4" morph="none" pos="word" start_char="6684">been</TOKEN>
<TOKEN end_char="6695" id="token-50-5" morph="none" pos="word" start_char="6689">refuted</TOKEN>
<TOKEN end_char="6703" id="token-50-6" morph="none" pos="word" start_char="6697">several</TOKEN>
<TOKEN end_char="6709" id="token-50-7" morph="none" pos="word" start_char="6705">times</TOKEN>
<TOKEN end_char="6715" id="token-50-8" morph="none" pos="word" start_char="6711">since</TOKEN>
<TOKEN end_char="6721" id="token-50-9" morph="none" pos="word" start_char="6717">March</TOKEN>
<TOKEN end_char="6722" id="token-50-10" morph="none" pos="punct" start_char="6722">.</TOKEN>
</SEG>
<SEG end_char="6908" id="segment-51" start_char="6724">
<ORIGINAL_TEXT>Following the publication of the first defamatory video in March 2020, the court ruled in favor of the Institut Pasteur on November 2, 2020, convicting the video's author of defamation.</ORIGINAL_TEXT>
<TOKEN end_char="6732" id="token-51-0" morph="none" pos="word" start_char="6724">Following</TOKEN>
<TOKEN end_char="6736" id="token-51-1" morph="none" pos="word" start_char="6734">the</TOKEN>
<TOKEN end_char="6748" id="token-51-2" morph="none" pos="word" start_char="6738">publication</TOKEN>
<TOKEN end_char="6751" id="token-51-3" morph="none" pos="word" start_char="6750">of</TOKEN>
<TOKEN end_char="6755" id="token-51-4" morph="none" pos="word" start_char="6753">the</TOKEN>
<TOKEN end_char="6761" id="token-51-5" morph="none" pos="word" start_char="6757">first</TOKEN>
<TOKEN end_char="6772" id="token-51-6" morph="none" pos="word" start_char="6763">defamatory</TOKEN>
<TOKEN end_char="6778" id="token-51-7" morph="none" pos="word" start_char="6774">video</TOKEN>
<TOKEN end_char="6781" id="token-51-8" morph="none" pos="word" start_char="6780">in</TOKEN>
<TOKEN end_char="6787" id="token-51-9" morph="none" pos="word" start_char="6783">March</TOKEN>
<TOKEN end_char="6792" id="token-51-10" morph="none" pos="word" start_char="6789">2020</TOKEN>
<TOKEN end_char="6793" id="token-51-11" morph="none" pos="punct" start_char="6793">,</TOKEN>
<TOKEN end_char="6797" id="token-51-12" morph="none" pos="word" start_char="6795">the</TOKEN>
<TOKEN end_char="6803" id="token-51-13" morph="none" pos="word" start_char="6799">court</TOKEN>
<TOKEN end_char="6809" id="token-51-14" morph="none" pos="word" start_char="6805">ruled</TOKEN>
<TOKEN end_char="6812" id="token-51-15" morph="none" pos="word" start_char="6811">in</TOKEN>
<TOKEN end_char="6818" id="token-51-16" morph="none" pos="word" start_char="6814">favor</TOKEN>
<TOKEN end_char="6821" id="token-51-17" morph="none" pos="word" start_char="6820">of</TOKEN>
<TOKEN end_char="6825" id="token-51-18" morph="none" pos="word" start_char="6823">the</TOKEN>
<TOKEN end_char="6834" id="token-51-19" morph="none" pos="word" start_char="6827">Institut</TOKEN>
<TOKEN end_char="6842" id="token-51-20" morph="none" pos="word" start_char="6836">Pasteur</TOKEN>
<TOKEN end_char="6845" id="token-51-21" morph="none" pos="word" start_char="6844">on</TOKEN>
<TOKEN end_char="6854" id="token-51-22" morph="none" pos="word" start_char="6847">November</TOKEN>
<TOKEN end_char="6856" id="token-51-23" morph="none" pos="word" start_char="6856">2</TOKEN>
<TOKEN end_char="6857" id="token-51-24" morph="none" pos="punct" start_char="6857">,</TOKEN>
<TOKEN end_char="6862" id="token-51-25" morph="none" pos="word" start_char="6859">2020</TOKEN>
<TOKEN end_char="6863" id="token-51-26" morph="none" pos="punct" start_char="6863">,</TOKEN>
<TOKEN end_char="6874" id="token-51-27" morph="none" pos="word" start_char="6865">convicting</TOKEN>
<TOKEN end_char="6878" id="token-51-28" morph="none" pos="word" start_char="6876">the</TOKEN>
<TOKEN end_char="6886" id="token-51-29" morph="none" pos="word" start_char="6880">video's</TOKEN>
<TOKEN end_char="6893" id="token-51-30" morph="none" pos="word" start_char="6888">author</TOKEN>
<TOKEN end_char="6896" id="token-51-31" morph="none" pos="word" start_char="6895">of</TOKEN>
<TOKEN end_char="6907" id="token-51-32" morph="none" pos="word" start_char="6898">defamation</TOKEN>
<TOKEN end_char="6908" id="token-51-33" morph="none" pos="punct" start_char="6908">.</TOKEN>
</SEG>
<SEG end_char="7020" id="segment-52" start_char="6911">
<ORIGINAL_TEXT>Read the news article: COVID-19: Senlis Criminal Court convicts the author of a fake news video for defamation</ORIGINAL_TEXT>
<TOKEN end_char="6914" id="token-52-0" morph="none" pos="word" start_char="6911">Read</TOKEN>
<TOKEN end_char="6918" id="token-52-1" morph="none" pos="word" start_char="6916">the</TOKEN>
<TOKEN end_char="6923" id="token-52-2" morph="none" pos="word" start_char="6920">news</TOKEN>
<TOKEN end_char="6931" id="token-52-3" morph="none" pos="word" start_char="6925">article</TOKEN>
<TOKEN end_char="6932" id="token-52-4" morph="none" pos="punct" start_char="6932">:</TOKEN>
<TOKEN end_char="6941" id="token-52-5" morph="none" pos="unknown" start_char="6934">COVID-19</TOKEN>
<TOKEN end_char="6942" id="token-52-6" morph="none" pos="punct" start_char="6942">:</TOKEN>
<TOKEN end_char="6949" id="token-52-7" morph="none" pos="word" start_char="6944">Senlis</TOKEN>
<TOKEN end_char="6958" id="token-52-8" morph="none" pos="word" start_char="6951">Criminal</TOKEN>
<TOKEN end_char="6964" id="token-52-9" morph="none" pos="word" start_char="6960">Court</TOKEN>
<TOKEN end_char="6973" id="token-52-10" morph="none" pos="word" start_char="6966">convicts</TOKEN>
<TOKEN end_char="6977" id="token-52-11" morph="none" pos="word" start_char="6975">the</TOKEN>
<TOKEN end_char="6984" id="token-52-12" morph="none" pos="word" start_char="6979">author</TOKEN>
<TOKEN end_char="6987" id="token-52-13" morph="none" pos="word" start_char="6986">of</TOKEN>
<TOKEN end_char="6989" id="token-52-14" morph="none" pos="word" start_char="6989">a</TOKEN>
<TOKEN end_char="6994" id="token-52-15" morph="none" pos="word" start_char="6991">fake</TOKEN>
<TOKEN end_char="6999" id="token-52-16" morph="none" pos="word" start_char="6996">news</TOKEN>
<TOKEN end_char="7005" id="token-52-17" morph="none" pos="word" start_char="7001">video</TOKEN>
<TOKEN end_char="7009" id="token-52-18" morph="none" pos="word" start_char="7007">for</TOKEN>
<TOKEN end_char="7020" id="token-52-19" morph="none" pos="word" start_char="7011">defamation</TOKEN>
</SEG>
<SEG end_char="7314" id="segment-53" start_char="7023">
<ORIGINAL_TEXT>In addition to strongly refuting false allegations and clarifying the facts of the situation and the scientific basis, taking action in this way is a means of denouncing insults and threats to the Institut Pasteur's employees and scientists and preventing such incidents from happening again.</ORIGINAL_TEXT>
<TOKEN end_char="7024" id="token-53-0" morph="none" pos="word" start_char="7023">In</TOKEN>
<TOKEN end_char="7033" id="token-53-1" morph="none" pos="word" start_char="7026">addition</TOKEN>
<TOKEN end_char="7036" id="token-53-2" morph="none" pos="word" start_char="7035">to</TOKEN>
<TOKEN end_char="7045" id="token-53-3" morph="none" pos="word" start_char="7038">strongly</TOKEN>
<TOKEN end_char="7054" id="token-53-4" morph="none" pos="word" start_char="7047">refuting</TOKEN>
<TOKEN end_char="7060" id="token-53-5" morph="none" pos="word" start_char="7056">false</TOKEN>
<TOKEN end_char="7072" id="token-53-6" morph="none" pos="word" start_char="7062">allegations</TOKEN>
<TOKEN end_char="7076" id="token-53-7" morph="none" pos="word" start_char="7074">and</TOKEN>
<TOKEN end_char="7087" id="token-53-8" morph="none" pos="word" start_char="7078">clarifying</TOKEN>
<TOKEN end_char="7091" id="token-53-9" morph="none" pos="word" start_char="7089">the</TOKEN>
<TOKEN end_char="7097" id="token-53-10" morph="none" pos="word" start_char="7093">facts</TOKEN>
<TOKEN end_char="7100" id="token-53-11" morph="none" pos="word" start_char="7099">of</TOKEN>
<TOKEN end_char="7104" id="token-53-12" morph="none" pos="word" start_char="7102">the</TOKEN>
<TOKEN end_char="7114" id="token-53-13" morph="none" pos="word" start_char="7106">situation</TOKEN>
<TOKEN end_char="7118" id="token-53-14" morph="none" pos="word" start_char="7116">and</TOKEN>
<TOKEN end_char="7122" id="token-53-15" morph="none" pos="word" start_char="7120">the</TOKEN>
<TOKEN end_char="7133" id="token-53-16" morph="none" pos="word" start_char="7124">scientific</TOKEN>
<TOKEN end_char="7139" id="token-53-17" morph="none" pos="word" start_char="7135">basis</TOKEN>
<TOKEN end_char="7140" id="token-53-18" morph="none" pos="punct" start_char="7140">,</TOKEN>
<TOKEN end_char="7147" id="token-53-19" morph="none" pos="word" start_char="7142">taking</TOKEN>
<TOKEN end_char="7154" id="token-53-20" morph="none" pos="word" start_char="7149">action</TOKEN>
<TOKEN end_char="7157" id="token-53-21" morph="none" pos="word" start_char="7156">in</TOKEN>
<TOKEN end_char="7162" id="token-53-22" morph="none" pos="word" start_char="7159">this</TOKEN>
<TOKEN end_char="7166" id="token-53-23" morph="none" pos="word" start_char="7164">way</TOKEN>
<TOKEN end_char="7169" id="token-53-24" morph="none" pos="word" start_char="7168">is</TOKEN>
<TOKEN end_char="7171" id="token-53-25" morph="none" pos="word" start_char="7171">a</TOKEN>
<TOKEN end_char="7177" id="token-53-26" morph="none" pos="word" start_char="7173">means</TOKEN>
<TOKEN end_char="7180" id="token-53-27" morph="none" pos="word" start_char="7179">of</TOKEN>
<TOKEN end_char="7191" id="token-53-28" morph="none" pos="word" start_char="7182">denouncing</TOKEN>
<TOKEN end_char="7199" id="token-53-29" morph="none" pos="word" start_char="7193">insults</TOKEN>
<TOKEN end_char="7203" id="token-53-30" morph="none" pos="word" start_char="7201">and</TOKEN>
<TOKEN end_char="7211" id="token-53-31" morph="none" pos="word" start_char="7205">threats</TOKEN>
<TOKEN end_char="7214" id="token-53-32" morph="none" pos="word" start_char="7213">to</TOKEN>
<TOKEN end_char="7218" id="token-53-33" morph="none" pos="word" start_char="7216">the</TOKEN>
<TOKEN end_char="7227" id="token-53-34" morph="none" pos="word" start_char="7220">Institut</TOKEN>
<TOKEN end_char="7237" id="token-53-35" morph="none" pos="word" start_char="7229">Pasteur's</TOKEN>
<TOKEN end_char="7247" id="token-53-36" morph="none" pos="word" start_char="7239">employees</TOKEN>
<TOKEN end_char="7251" id="token-53-37" morph="none" pos="word" start_char="7249">and</TOKEN>
<TOKEN end_char="7262" id="token-53-38" morph="none" pos="word" start_char="7253">scientists</TOKEN>
<TOKEN end_char="7266" id="token-53-39" morph="none" pos="word" start_char="7264">and</TOKEN>
<TOKEN end_char="7277" id="token-53-40" morph="none" pos="word" start_char="7268">preventing</TOKEN>
<TOKEN end_char="7282" id="token-53-41" morph="none" pos="word" start_char="7279">such</TOKEN>
<TOKEN end_char="7292" id="token-53-42" morph="none" pos="word" start_char="7284">incidents</TOKEN>
<TOKEN end_char="7297" id="token-53-43" morph="none" pos="word" start_char="7294">from</TOKEN>
<TOKEN end_char="7307" id="token-53-44" morph="none" pos="word" start_char="7299">happening</TOKEN>
<TOKEN end_char="7313" id="token-53-45" morph="none" pos="word" start_char="7309">again</TOKEN>
<TOKEN end_char="7314" id="token-53-46" morph="none" pos="punct" start_char="7314">.</TOKEN>
</SEG>
<SEG end_char="7492" id="segment-54" start_char="7317">
<ORIGINAL_TEXT>If the Institut Pasteur is targeted by publicly disseminated misinformation and misleading claims, it will lodge an official complaint and do so whenever it deems it necessary.</ORIGINAL_TEXT>
<TOKEN end_char="7318" id="token-54-0" morph="none" pos="word" start_char="7317">If</TOKEN>
<TOKEN end_char="7322" id="token-54-1" morph="none" pos="word" start_char="7320">the</TOKEN>
<TOKEN end_char="7331" id="token-54-2" morph="none" pos="word" start_char="7324">Institut</TOKEN>
<TOKEN end_char="7339" id="token-54-3" morph="none" pos="word" start_char="7333">Pasteur</TOKEN>
<TOKEN end_char="7342" id="token-54-4" morph="none" pos="word" start_char="7341">is</TOKEN>
<TOKEN end_char="7351" id="token-54-5" morph="none" pos="word" start_char="7344">targeted</TOKEN>
<TOKEN end_char="7354" id="token-54-6" morph="none" pos="word" start_char="7353">by</TOKEN>
<TOKEN end_char="7363" id="token-54-7" morph="none" pos="word" start_char="7356">publicly</TOKEN>
<TOKEN end_char="7376" id="token-54-8" morph="none" pos="word" start_char="7365">disseminated</TOKEN>
<TOKEN end_char="7391" id="token-54-9" morph="none" pos="word" start_char="7378">misinformation</TOKEN>
<TOKEN end_char="7395" id="token-54-10" morph="none" pos="word" start_char="7393">and</TOKEN>
<TOKEN end_char="7406" id="token-54-11" morph="none" pos="word" start_char="7397">misleading</TOKEN>
<TOKEN end_char="7413" id="token-54-12" morph="none" pos="word" start_char="7408">claims</TOKEN>
<TOKEN end_char="7414" id="token-54-13" morph="none" pos="punct" start_char="7414">,</TOKEN>
<TOKEN end_char="7417" id="token-54-14" morph="none" pos="word" start_char="7416">it</TOKEN>
<TOKEN end_char="7422" id="token-54-15" morph="none" pos="word" start_char="7419">will</TOKEN>
<TOKEN end_char="7428" id="token-54-16" morph="none" pos="word" start_char="7424">lodge</TOKEN>
<TOKEN end_char="7431" id="token-54-17" morph="none" pos="word" start_char="7430">an</TOKEN>
<TOKEN end_char="7440" id="token-54-18" morph="none" pos="word" start_char="7433">official</TOKEN>
<TOKEN end_char="7450" id="token-54-19" morph="none" pos="word" start_char="7442">complaint</TOKEN>
<TOKEN end_char="7454" id="token-54-20" morph="none" pos="word" start_char="7452">and</TOKEN>
<TOKEN end_char="7457" id="token-54-21" morph="none" pos="word" start_char="7456">do</TOKEN>
<TOKEN end_char="7460" id="token-54-22" morph="none" pos="word" start_char="7459">so</TOKEN>
<TOKEN end_char="7469" id="token-54-23" morph="none" pos="word" start_char="7462">whenever</TOKEN>
<TOKEN end_char="7472" id="token-54-24" morph="none" pos="word" start_char="7471">it</TOKEN>
<TOKEN end_char="7478" id="token-54-25" morph="none" pos="word" start_char="7474">deems</TOKEN>
<TOKEN end_char="7481" id="token-54-26" morph="none" pos="word" start_char="7480">it</TOKEN>
<TOKEN end_char="7491" id="token-54-27" morph="none" pos="word" start_char="7483">necessary</TOKEN>
<TOKEN end_char="7492" id="token-54-28" morph="none" pos="punct" start_char="7492">.</TOKEN>
</SEG>
<SEG end_char="7549" id="segment-55" start_char="7495">
<ORIGINAL_TEXT>NO, SARS-CoV-2 wasn't created from HIV in a laboratory!</ORIGINAL_TEXT>
<TOKEN end_char="7496" id="token-55-0" morph="none" pos="word" start_char="7495">NO</TOKEN>
<TOKEN end_char="7497" id="token-55-1" morph="none" pos="punct" start_char="7497">,</TOKEN>
<TOKEN end_char="7508" id="token-55-2" morph="none" pos="unknown" start_char="7499">SARS-CoV-2</TOKEN>
<TOKEN end_char="7515" id="token-55-3" morph="none" pos="word" start_char="7510">wasn't</TOKEN>
<TOKEN end_char="7523" id="token-55-4" morph="none" pos="word" start_char="7517">created</TOKEN>
<TOKEN end_char="7528" id="token-55-5" morph="none" pos="word" start_char="7525">from</TOKEN>
<TOKEN end_char="7532" id="token-55-6" morph="none" pos="word" start_char="7530">HIV</TOKEN>
<TOKEN end_char="7535" id="token-55-7" morph="none" pos="word" start_char="7534">in</TOKEN>
<TOKEN end_char="7537" id="token-55-8" morph="none" pos="word" start_char="7537">a</TOKEN>
<TOKEN end_char="7548" id="token-55-9" morph="none" pos="word" start_char="7539">laboratory</TOKEN>
<TOKEN end_char="7549" id="token-55-10" morph="none" pos="punct" start_char="7549">!</TOKEN>
</SEG>
<SEG end_char="7574" id="segment-56" start_char="7552">
<ORIGINAL_TEXT>Text of April 18, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7555" id="token-56-0" morph="none" pos="word" start_char="7552">Text</TOKEN>
<TOKEN end_char="7558" id="token-56-1" morph="none" pos="word" start_char="7557">of</TOKEN>
<TOKEN end_char="7564" id="token-56-2" morph="none" pos="word" start_char="7560">April</TOKEN>
<TOKEN end_char="7567" id="token-56-3" morph="none" pos="word" start_char="7566">18</TOKEN>
<TOKEN end_char="7568" id="token-56-4" morph="none" pos="punct" start_char="7568">,</TOKEN>
<TOKEN end_char="7573" id="token-56-5" morph="none" pos="word" start_char="7570">2020</TOKEN>
<TOKEN end_char="7574" id="token-56-6" morph="none" pos="punct" start_char="7574">.</TOKEN>
</SEG>
<SEG end_char="7600" id="segment-57" start_char="7577">
<ORIGINAL_TEXT>Updated December 1, 2020</ORIGINAL_TEXT>
<TOKEN end_char="7583" id="token-57-0" morph="none" pos="word" start_char="7577">Updated</TOKEN>
<TOKEN end_char="7592" id="token-57-1" morph="none" pos="word" start_char="7585">December</TOKEN>
<TOKEN end_char="7594" id="token-57-2" morph="none" pos="word" start_char="7594">1</TOKEN>
<TOKEN end_char="7595" id="token-57-3" morph="none" pos="punct" start_char="7595">,</TOKEN>
<TOKEN end_char="7600" id="token-57-4" morph="none" pos="word" start_char="7597">2020</TOKEN>
</SEG>
<SEG end_char="7726" id="segment-58" start_char="7604">
<ORIGINAL_TEXT>A new controversy has emerged following claims that SARS-CoV-2 is the result of human error in a BSL-4 laboratory in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="7604" id="token-58-0" morph="none" pos="word" start_char="7604">A</TOKEN>
<TOKEN end_char="7608" id="token-58-1" morph="none" pos="word" start_char="7606">new</TOKEN>
<TOKEN end_char="7620" id="token-58-2" morph="none" pos="word" start_char="7610">controversy</TOKEN>
<TOKEN end_char="7624" id="token-58-3" morph="none" pos="word" start_char="7622">has</TOKEN>
<TOKEN end_char="7632" id="token-58-4" morph="none" pos="word" start_char="7626">emerged</TOKEN>
<TOKEN end_char="7642" id="token-58-5" morph="none" pos="word" start_char="7634">following</TOKEN>
<TOKEN end_char="7649" id="token-58-6" morph="none" pos="word" start_char="7644">claims</TOKEN>
<TOKEN end_char="7654" id="token-58-7" morph="none" pos="word" start_char="7651">that</TOKEN>
<TOKEN end_char="7665" id="token-58-8" morph="none" pos="unknown" start_char="7656">SARS-CoV-2</TOKEN>
<TOKEN end_char="7668" id="token-58-9" morph="none" pos="word" start_char="7667">is</TOKEN>
<TOKEN end_char="7672" id="token-58-10" morph="none" pos="word" start_char="7670">the</TOKEN>
<TOKEN end_char="7679" id="token-58-11" morph="none" pos="word" start_char="7674">result</TOKEN>
<TOKEN end_char="7682" id="token-58-12" morph="none" pos="word" start_char="7681">of</TOKEN>
<TOKEN end_char="7688" id="token-58-13" morph="none" pos="word" start_char="7684">human</TOKEN>
<TOKEN end_char="7694" id="token-58-14" morph="none" pos="word" start_char="7690">error</TOKEN>
<TOKEN end_char="7697" id="token-58-15" morph="none" pos="word" start_char="7696">in</TOKEN>
<TOKEN end_char="7699" id="token-58-16" morph="none" pos="word" start_char="7699">a</TOKEN>
<TOKEN end_char="7705" id="token-58-17" morph="none" pos="unknown" start_char="7701">BSL-4</TOKEN>
<TOKEN end_char="7716" id="token-58-18" morph="none" pos="word" start_char="7707">laboratory</TOKEN>
<TOKEN end_char="7719" id="token-58-19" morph="none" pos="word" start_char="7718">in</TOKEN>
<TOKEN end_char="7725" id="token-58-20" morph="none" pos="word" start_char="7721">Wuhan</TOKEN>
<TOKEN end_char="7726" id="token-58-21" morph="none" pos="punct" start_char="7726">.</TOKEN>
</SEG>
<SEG end_char="7841" id="segment-59" start_char="7728">
<ORIGINAL_TEXT>While carrying out research on an HIV vaccine, scientists are said to have accidentally let this new virus escape.</ORIGINAL_TEXT>
<TOKEN end_char="7732" id="token-59-0" morph="none" pos="word" start_char="7728">While</TOKEN>
<TOKEN end_char="7741" id="token-59-1" morph="none" pos="word" start_char="7734">carrying</TOKEN>
<TOKEN end_char="7745" id="token-59-2" morph="none" pos="word" start_char="7743">out</TOKEN>
<TOKEN end_char="7754" id="token-59-3" morph="none" pos="word" start_char="7747">research</TOKEN>
<TOKEN end_char="7757" id="token-59-4" morph="none" pos="word" start_char="7756">on</TOKEN>
<TOKEN end_char="7760" id="token-59-5" morph="none" pos="word" start_char="7759">an</TOKEN>
<TOKEN end_char="7764" id="token-59-6" morph="none" pos="word" start_char="7762">HIV</TOKEN>
<TOKEN end_char="7772" id="token-59-7" morph="none" pos="word" start_char="7766">vaccine</TOKEN>
<TOKEN end_char="7773" id="token-59-8" morph="none" pos="punct" start_char="7773">,</TOKEN>
<TOKEN end_char="7784" id="token-59-9" morph="none" pos="word" start_char="7775">scientists</TOKEN>
<TOKEN end_char="7788" id="token-59-10" morph="none" pos="word" start_char="7786">are</TOKEN>
<TOKEN end_char="7793" id="token-59-11" morph="none" pos="word" start_char="7790">said</TOKEN>
<TOKEN end_char="7796" id="token-59-12" morph="none" pos="word" start_char="7795">to</TOKEN>
<TOKEN end_char="7801" id="token-59-13" morph="none" pos="word" start_char="7798">have</TOKEN>
<TOKEN end_char="7814" id="token-59-14" morph="none" pos="word" start_char="7803">accidentally</TOKEN>
<TOKEN end_char="7818" id="token-59-15" morph="none" pos="word" start_char="7816">let</TOKEN>
<TOKEN end_char="7823" id="token-59-16" morph="none" pos="word" start_char="7820">this</TOKEN>
<TOKEN end_char="7827" id="token-59-17" morph="none" pos="word" start_char="7825">new</TOKEN>
<TOKEN end_char="7833" id="token-59-18" morph="none" pos="word" start_char="7829">virus</TOKEN>
<TOKEN end_char="7840" id="token-59-19" morph="none" pos="word" start_char="7835">escape</TOKEN>
<TOKEN end_char="7841" id="token-59-20" morph="none" pos="punct" start_char="7841">.</TOKEN>
</SEG>
<SEG end_char="8052" id="segment-60" start_char="7843">
<ORIGINAL_TEXT>One piece of evidence held up to support the theory is that the SARS-CoV-2 genome contains sequences that correspond to HIV, a hypothesis that is said to have been validated by an Indian scientific publication.</ORIGINAL_TEXT>
<TOKEN end_char="7845" id="token-60-0" morph="none" pos="word" start_char="7843">One</TOKEN>
<TOKEN end_char="7851" id="token-60-1" morph="none" pos="word" start_char="7847">piece</TOKEN>
<TOKEN end_char="7854" id="token-60-2" morph="none" pos="word" start_char="7853">of</TOKEN>
<TOKEN end_char="7863" id="token-60-3" morph="none" pos="word" start_char="7856">evidence</TOKEN>
<TOKEN end_char="7868" id="token-60-4" morph="none" pos="word" start_char="7865">held</TOKEN>
<TOKEN end_char="7871" id="token-60-5" morph="none" pos="word" start_char="7870">up</TOKEN>
<TOKEN end_char="7874" id="token-60-6" morph="none" pos="word" start_char="7873">to</TOKEN>
<TOKEN end_char="7882" id="token-60-7" morph="none" pos="word" start_char="7876">support</TOKEN>
<TOKEN end_char="7886" id="token-60-8" morph="none" pos="word" start_char="7884">the</TOKEN>
<TOKEN end_char="7893" id="token-60-9" morph="none" pos="word" start_char="7888">theory</TOKEN>
<TOKEN end_char="7896" id="token-60-10" morph="none" pos="word" start_char="7895">is</TOKEN>
<TOKEN end_char="7901" id="token-60-11" morph="none" pos="word" start_char="7898">that</TOKEN>
<TOKEN end_char="7905" id="token-60-12" morph="none" pos="word" start_char="7903">the</TOKEN>
<TOKEN end_char="7916" id="token-60-13" morph="none" pos="unknown" start_char="7907">SARS-CoV-2</TOKEN>
<TOKEN end_char="7923" id="token-60-14" morph="none" pos="word" start_char="7918">genome</TOKEN>
<TOKEN end_char="7932" id="token-60-15" morph="none" pos="word" start_char="7925">contains</TOKEN>
<TOKEN end_char="7942" id="token-60-16" morph="none" pos="word" start_char="7934">sequences</TOKEN>
<TOKEN end_char="7947" id="token-60-17" morph="none" pos="word" start_char="7944">that</TOKEN>
<TOKEN end_char="7958" id="token-60-18" morph="none" pos="word" start_char="7949">correspond</TOKEN>
<TOKEN end_char="7961" id="token-60-19" morph="none" pos="word" start_char="7960">to</TOKEN>
<TOKEN end_char="7965" id="token-60-20" morph="none" pos="word" start_char="7963">HIV</TOKEN>
<TOKEN end_char="7966" id="token-60-21" morph="none" pos="punct" start_char="7966">,</TOKEN>
<TOKEN end_char="7968" id="token-60-22" morph="none" pos="word" start_char="7968">a</TOKEN>
<TOKEN end_char="7979" id="token-60-23" morph="none" pos="word" start_char="7970">hypothesis</TOKEN>
<TOKEN end_char="7984" id="token-60-24" morph="none" pos="word" start_char="7981">that</TOKEN>
<TOKEN end_char="7987" id="token-60-25" morph="none" pos="word" start_char="7986">is</TOKEN>
<TOKEN end_char="7992" id="token-60-26" morph="none" pos="word" start_char="7989">said</TOKEN>
<TOKEN end_char="7995" id="token-60-27" morph="none" pos="word" start_char="7994">to</TOKEN>
<TOKEN end_char="8000" id="token-60-28" morph="none" pos="word" start_char="7997">have</TOKEN>
<TOKEN end_char="8005" id="token-60-29" morph="none" pos="word" start_char="8002">been</TOKEN>
<TOKEN end_char="8015" id="token-60-30" morph="none" pos="word" start_char="8007">validated</TOKEN>
<TOKEN end_char="8018" id="token-60-31" morph="none" pos="word" start_char="8017">by</TOKEN>
<TOKEN end_char="8021" id="token-60-32" morph="none" pos="word" start_char="8020">an</TOKEN>
<TOKEN end_char="8028" id="token-60-33" morph="none" pos="word" start_char="8023">Indian</TOKEN>
<TOKEN end_char="8039" id="token-60-34" morph="none" pos="word" start_char="8030">scientific</TOKEN>
<TOKEN end_char="8051" id="token-60-35" morph="none" pos="word" start_char="8041">publication</TOKEN>
<TOKEN end_char="8052" id="token-60-36" morph="none" pos="punct" start_char="8052">.</TOKEN>
</SEG>
<SEG end_char="8127" id="segment-61" start_char="8056">
<ORIGINAL_TEXT>The homologies between the HIV and SARS-CoV-2 sequences are meaningless.</ORIGINAL_TEXT>
<TOKEN end_char="8058" id="token-61-0" morph="none" pos="word" start_char="8056">The</TOKEN>
<TOKEN end_char="8069" id="token-61-1" morph="none" pos="word" start_char="8060">homologies</TOKEN>
<TOKEN end_char="8077" id="token-61-2" morph="none" pos="word" start_char="8071">between</TOKEN>
<TOKEN end_char="8081" id="token-61-3" morph="none" pos="word" start_char="8079">the</TOKEN>
<TOKEN end_char="8085" id="token-61-4" morph="none" pos="word" start_char="8083">HIV</TOKEN>
<TOKEN end_char="8089" id="token-61-5" morph="none" pos="word" start_char="8087">and</TOKEN>
<TOKEN end_char="8100" id="token-61-6" morph="none" pos="unknown" start_char="8091">SARS-CoV-2</TOKEN>
<TOKEN end_char="8110" id="token-61-7" morph="none" pos="word" start_char="8102">sequences</TOKEN>
<TOKEN end_char="8114" id="token-61-8" morph="none" pos="word" start_char="8112">are</TOKEN>
<TOKEN end_char="8126" id="token-61-9" morph="none" pos="word" start_char="8116">meaningless</TOKEN>
<TOKEN end_char="8127" id="token-61-10" morph="none" pos="punct" start_char="8127">.</TOKEN>
</SEG>
<SEG end_char="8234" id="segment-62" start_char="8133">
<ORIGINAL_TEXT>This theory is based on a misinterpretation of an article that appeared for a short time on a website.</ORIGINAL_TEXT>
<TOKEN end_char="8136" id="token-62-0" morph="none" pos="word" start_char="8133">This</TOKEN>
<TOKEN end_char="8143" id="token-62-1" morph="none" pos="word" start_char="8138">theory</TOKEN>
<TOKEN end_char="8146" id="token-62-2" morph="none" pos="word" start_char="8145">is</TOKEN>
<TOKEN end_char="8152" id="token-62-3" morph="none" pos="word" start_char="8148">based</TOKEN>
<TOKEN end_char="8155" id="token-62-4" morph="none" pos="word" start_char="8154">on</TOKEN>
<TOKEN end_char="8157" id="token-62-5" morph="none" pos="word" start_char="8157">a</TOKEN>
<TOKEN end_char="8175" id="token-62-6" morph="none" pos="word" start_char="8159">misinterpretation</TOKEN>
<TOKEN end_char="8178" id="token-62-7" morph="none" pos="word" start_char="8177">of</TOKEN>
<TOKEN end_char="8181" id="token-62-8" morph="none" pos="word" start_char="8180">an</TOKEN>
<TOKEN end_char="8189" id="token-62-9" morph="none" pos="word" start_char="8183">article</TOKEN>
<TOKEN end_char="8194" id="token-62-10" morph="none" pos="word" start_char="8191">that</TOKEN>
<TOKEN end_char="8203" id="token-62-11" morph="none" pos="word" start_char="8196">appeared</TOKEN>
<TOKEN end_char="8207" id="token-62-12" morph="none" pos="word" start_char="8205">for</TOKEN>
<TOKEN end_char="8209" id="token-62-13" morph="none" pos="word" start_char="8209">a</TOKEN>
<TOKEN end_char="8215" id="token-62-14" morph="none" pos="word" start_char="8211">short</TOKEN>
<TOKEN end_char="8220" id="token-62-15" morph="none" pos="word" start_char="8217">time</TOKEN>
<TOKEN end_char="8223" id="token-62-16" morph="none" pos="word" start_char="8222">on</TOKEN>
<TOKEN end_char="8225" id="token-62-17" morph="none" pos="word" start_char="8225">a</TOKEN>
<TOKEN end_char="8233" id="token-62-18" morph="none" pos="word" start_char="8227">website</TOKEN>
<TOKEN end_char="8234" id="token-62-19" morph="none" pos="punct" start_char="8234">.</TOKEN>
</SEG>
<SEG end_char="8409" id="segment-63" start_char="8236">
<ORIGINAL_TEXT>The research contained multiple methodological errors and inaccuracies that were subsequently exposed by the scientific community, leading the authors to retract the article.</ORIGINAL_TEXT>
<TOKEN end_char="8238" id="token-63-0" morph="none" pos="word" start_char="8236">The</TOKEN>
<TOKEN end_char="8247" id="token-63-1" morph="none" pos="word" start_char="8240">research</TOKEN>
<TOKEN end_char="8257" id="token-63-2" morph="none" pos="word" start_char="8249">contained</TOKEN>
<TOKEN end_char="8266" id="token-63-3" morph="none" pos="word" start_char="8259">multiple</TOKEN>
<TOKEN end_char="8281" id="token-63-4" morph="none" pos="word" start_char="8268">methodological</TOKEN>
<TOKEN end_char="8288" id="token-63-5" morph="none" pos="word" start_char="8283">errors</TOKEN>
<TOKEN end_char="8292" id="token-63-6" morph="none" pos="word" start_char="8290">and</TOKEN>
<TOKEN end_char="8305" id="token-63-7" morph="none" pos="word" start_char="8294">inaccuracies</TOKEN>
<TOKEN end_char="8310" id="token-63-8" morph="none" pos="word" start_char="8307">that</TOKEN>
<TOKEN end_char="8315" id="token-63-9" morph="none" pos="word" start_char="8312">were</TOKEN>
<TOKEN end_char="8328" id="token-63-10" morph="none" pos="word" start_char="8317">subsequently</TOKEN>
<TOKEN end_char="8336" id="token-63-11" morph="none" pos="word" start_char="8330">exposed</TOKEN>
<TOKEN end_char="8339" id="token-63-12" morph="none" pos="word" start_char="8338">by</TOKEN>
<TOKEN end_char="8343" id="token-63-13" morph="none" pos="word" start_char="8341">the</TOKEN>
<TOKEN end_char="8354" id="token-63-14" morph="none" pos="word" start_char="8345">scientific</TOKEN>
<TOKEN end_char="8364" id="token-63-15" morph="none" pos="word" start_char="8356">community</TOKEN>
<TOKEN end_char="8365" id="token-63-16" morph="none" pos="punct" start_char="8365">,</TOKEN>
<TOKEN end_char="8373" id="token-63-17" morph="none" pos="word" start_char="8367">leading</TOKEN>
<TOKEN end_char="8377" id="token-63-18" morph="none" pos="word" start_char="8375">the</TOKEN>
<TOKEN end_char="8385" id="token-63-19" morph="none" pos="word" start_char="8379">authors</TOKEN>
<TOKEN end_char="8388" id="token-63-20" morph="none" pos="word" start_char="8387">to</TOKEN>
<TOKEN end_char="8396" id="token-63-21" morph="none" pos="word" start_char="8390">retract</TOKEN>
<TOKEN end_char="8400" id="token-63-22" morph="none" pos="word" start_char="8398">the</TOKEN>
<TOKEN end_char="8408" id="token-63-23" morph="none" pos="word" start_char="8402">article</TOKEN>
<TOKEN end_char="8409" id="token-63-24" morph="none" pos="punct" start_char="8409">.</TOKEN>
</SEG>
<SEG end_char="8485" id="segment-64" start_char="8415">
<ORIGINAL_TEXT>There is no evidence that SARS-CoV-2 coronavirus was created by humans.</ORIGINAL_TEXT>
<TOKEN end_char="8419" id="token-64-0" morph="none" pos="word" start_char="8415">There</TOKEN>
<TOKEN end_char="8422" id="token-64-1" morph="none" pos="word" start_char="8421">is</TOKEN>
<TOKEN end_char="8425" id="token-64-2" morph="none" pos="word" start_char="8424">no</TOKEN>
<TOKEN end_char="8434" id="token-64-3" morph="none" pos="word" start_char="8427">evidence</TOKEN>
<TOKEN end_char="8439" id="token-64-4" morph="none" pos="word" start_char="8436">that</TOKEN>
<TOKEN end_char="8450" id="token-64-5" morph="none" pos="unknown" start_char="8441">SARS-CoV-2</TOKEN>
<TOKEN end_char="8462" id="token-64-6" morph="none" pos="word" start_char="8452">coronavirus</TOKEN>
<TOKEN end_char="8466" id="token-64-7" morph="none" pos="word" start_char="8464">was</TOKEN>
<TOKEN end_char="8474" id="token-64-8" morph="none" pos="word" start_char="8468">created</TOKEN>
<TOKEN end_char="8477" id="token-64-9" morph="none" pos="word" start_char="8476">by</TOKEN>
<TOKEN end_char="8484" id="token-64-10" morph="none" pos="word" start_char="8479">humans</TOKEN>
<TOKEN end_char="8485" id="token-64-11" morph="none" pos="punct" start_char="8485">.</TOKEN>
</SEG>
<SEG end_char="8502" id="segment-65" start_char="8491">
<ORIGINAL_TEXT>Explanations</ORIGINAL_TEXT>
<TOKEN end_char="8502" id="token-65-0" morph="none" pos="word" start_char="8491">Explanations</TOKEN>
</SEG>
<SEG end_char="8589" id="segment-66" start_char="8506">
<ORIGINAL_TEXT>1 _ Any homologies that exist between the HIV and SARS-CoV-2 genomes are meaningless</ORIGINAL_TEXT>
<TOKEN end_char="8506" id="token-66-0" morph="none" pos="word" start_char="8506">1</TOKEN>
<TOKEN end_char="8508" id="token-66-1" morph="none" pos="word" start_char="8508">_</TOKEN>
<TOKEN end_char="8512" id="token-66-2" morph="none" pos="word" start_char="8510">Any</TOKEN>
<TOKEN end_char="8523" id="token-66-3" morph="none" pos="word" start_char="8514">homologies</TOKEN>
<TOKEN end_char="8528" id="token-66-4" morph="none" pos="word" start_char="8525">that</TOKEN>
<TOKEN end_char="8534" id="token-66-5" morph="none" pos="word" start_char="8530">exist</TOKEN>
<TOKEN end_char="8542" id="token-66-6" morph="none" pos="word" start_char="8536">between</TOKEN>
<TOKEN end_char="8546" id="token-66-7" morph="none" pos="word" start_char="8544">the</TOKEN>
<TOKEN end_char="8550" id="token-66-8" morph="none" pos="word" start_char="8548">HIV</TOKEN>
<TOKEN end_char="8554" id="token-66-9" morph="none" pos="word" start_char="8552">and</TOKEN>
<TOKEN end_char="8565" id="token-66-10" morph="none" pos="unknown" start_char="8556">SARS-CoV-2</TOKEN>
<TOKEN end_char="8573" id="token-66-11" morph="none" pos="word" start_char="8567">genomes</TOKEN>
<TOKEN end_char="8577" id="token-66-12" morph="none" pos="word" start_char="8575">are</TOKEN>
<TOKEN end_char="8589" id="token-66-13" morph="none" pos="word" start_char="8579">meaningless</TOKEN>
</SEG>
<SEG end_char="8772" id="segment-67" start_char="8593">
<ORIGINAL_TEXT>Although it is true that there is in the genome of the SARS-CoV-2 coronavirus, a sequence also present in the genome of HIV, this does not mean that SARS-CoV-2 is derived from HIV.</ORIGINAL_TEXT>
<TOKEN end_char="8600" id="token-67-0" morph="none" pos="word" start_char="8593">Although</TOKEN>
<TOKEN end_char="8603" id="token-67-1" morph="none" pos="word" start_char="8602">it</TOKEN>
<TOKEN end_char="8606" id="token-67-2" morph="none" pos="word" start_char="8605">is</TOKEN>
<TOKEN end_char="8611" id="token-67-3" morph="none" pos="word" start_char="8608">true</TOKEN>
<TOKEN end_char="8616" id="token-67-4" morph="none" pos="word" start_char="8613">that</TOKEN>
<TOKEN end_char="8622" id="token-67-5" morph="none" pos="word" start_char="8618">there</TOKEN>
<TOKEN end_char="8625" id="token-67-6" morph="none" pos="word" start_char="8624">is</TOKEN>
<TOKEN end_char="8628" id="token-67-7" morph="none" pos="word" start_char="8627">in</TOKEN>
<TOKEN end_char="8632" id="token-67-8" morph="none" pos="word" start_char="8630">the</TOKEN>
<TOKEN end_char="8639" id="token-67-9" morph="none" pos="word" start_char="8634">genome</TOKEN>
<TOKEN end_char="8642" id="token-67-10" morph="none" pos="word" start_char="8641">of</TOKEN>
<TOKEN end_char="8646" id="token-67-11" morph="none" pos="word" start_char="8644">the</TOKEN>
<TOKEN end_char="8657" id="token-67-12" morph="none" pos="unknown" start_char="8648">SARS-CoV-2</TOKEN>
<TOKEN end_char="8669" id="token-67-13" morph="none" pos="word" start_char="8659">coronavirus</TOKEN>
<TOKEN end_char="8670" id="token-67-14" morph="none" pos="punct" start_char="8670">,</TOKEN>
<TOKEN end_char="8672" id="token-67-15" morph="none" pos="word" start_char="8672">a</TOKEN>
<TOKEN end_char="8681" id="token-67-16" morph="none" pos="word" start_char="8674">sequence</TOKEN>
<TOKEN end_char="8686" id="token-67-17" morph="none" pos="word" start_char="8683">also</TOKEN>
<TOKEN end_char="8694" id="token-67-18" morph="none" pos="word" start_char="8688">present</TOKEN>
<TOKEN end_char="8697" id="token-67-19" morph="none" pos="word" start_char="8696">in</TOKEN>
<TOKEN end_char="8701" id="token-67-20" morph="none" pos="word" start_char="8699">the</TOKEN>
<TOKEN end_char="8708" id="token-67-21" morph="none" pos="word" start_char="8703">genome</TOKEN>
<TOKEN end_char="8711" id="token-67-22" morph="none" pos="word" start_char="8710">of</TOKEN>
<TOKEN end_char="8715" id="token-67-23" morph="none" pos="word" start_char="8713">HIV</TOKEN>
<TOKEN end_char="8716" id="token-67-24" morph="none" pos="punct" start_char="8716">,</TOKEN>
<TOKEN end_char="8721" id="token-67-25" morph="none" pos="word" start_char="8718">this</TOKEN>
<TOKEN end_char="8726" id="token-67-26" morph="none" pos="word" start_char="8723">does</TOKEN>
<TOKEN end_char="8730" id="token-67-27" morph="none" pos="word" start_char="8728">not</TOKEN>
<TOKEN end_char="8735" id="token-67-28" morph="none" pos="word" start_char="8732">mean</TOKEN>
<TOKEN end_char="8740" id="token-67-29" morph="none" pos="word" start_char="8737">that</TOKEN>
<TOKEN end_char="8751" id="token-67-30" morph="none" pos="unknown" start_char="8742">SARS-CoV-2</TOKEN>
<TOKEN end_char="8754" id="token-67-31" morph="none" pos="word" start_char="8753">is</TOKEN>
<TOKEN end_char="8762" id="token-67-32" morph="none" pos="word" start_char="8756">derived</TOKEN>
<TOKEN end_char="8767" id="token-67-33" morph="none" pos="word" start_char="8764">from</TOKEN>
<TOKEN end_char="8771" id="token-67-34" morph="none" pos="word" start_char="8769">HIV</TOKEN>
<TOKEN end_char="8772" id="token-67-35" morph="none" pos="punct" start_char="8772">.</TOKEN>
</SEG>
<SEG end_char="8775" id="segment-68" start_char="8775">
<ORIGINAL_TEXT>"</ORIGINAL_TEXT>
<TOKEN end_char="8775" id="token-68-0" morph="none" pos="punct" start_char="8775">"</TOKEN>
</SEG>
<SEG end_char="8831" id="segment-69" start_char="8778">
<ORIGINAL_TEXT>Genetic sequences are composed of a series of letters.</ORIGINAL_TEXT>
<TOKEN end_char="8784" id="token-69-0" morph="none" pos="word" start_char="8778">Genetic</TOKEN>
<TOKEN end_char="8794" id="token-69-1" morph="none" pos="word" start_char="8786">sequences</TOKEN>
<TOKEN end_char="8798" id="token-69-2" morph="none" pos="word" start_char="8796">are</TOKEN>
<TOKEN end_char="8807" id="token-69-3" morph="none" pos="word" start_char="8800">composed</TOKEN>
<TOKEN end_char="8810" id="token-69-4" morph="none" pos="word" start_char="8809">of</TOKEN>
<TOKEN end_char="8812" id="token-69-5" morph="none" pos="word" start_char="8812">a</TOKEN>
<TOKEN end_char="8819" id="token-69-6" morph="none" pos="word" start_char="8814">series</TOKEN>
<TOKEN end_char="8822" id="token-69-7" morph="none" pos="word" start_char="8821">of</TOKEN>
<TOKEN end_char="8830" id="token-69-8" morph="none" pos="word" start_char="8824">letters</TOKEN>
<TOKEN end_char="8831" id="token-69-9" morph="none" pos="punct" start_char="8831">.</TOKEN>
</SEG>
<SEG end_char="8999" id="segment-70" start_char="8833">
<ORIGINAL_TEXT>If we examine a very short series of letters taken at random in a sequence, they may resemble a small fragment of another sequence without there being any direct link.</ORIGINAL_TEXT>
<TOKEN end_char="8834" id="token-70-0" morph="none" pos="word" start_char="8833">If</TOKEN>
<TOKEN end_char="8837" id="token-70-1" morph="none" pos="word" start_char="8836">we</TOKEN>
<TOKEN end_char="8845" id="token-70-2" morph="none" pos="word" start_char="8839">examine</TOKEN>
<TOKEN end_char="8847" id="token-70-3" morph="none" pos="word" start_char="8847">a</TOKEN>
<TOKEN end_char="8852" id="token-70-4" morph="none" pos="word" start_char="8849">very</TOKEN>
<TOKEN end_char="8858" id="token-70-5" morph="none" pos="word" start_char="8854">short</TOKEN>
<TOKEN end_char="8865" id="token-70-6" morph="none" pos="word" start_char="8860">series</TOKEN>
<TOKEN end_char="8868" id="token-70-7" morph="none" pos="word" start_char="8867">of</TOKEN>
<TOKEN end_char="8876" id="token-70-8" morph="none" pos="word" start_char="8870">letters</TOKEN>
<TOKEN end_char="8882" id="token-70-9" morph="none" pos="word" start_char="8878">taken</TOKEN>
<TOKEN end_char="8885" id="token-70-10" morph="none" pos="word" start_char="8884">at</TOKEN>
<TOKEN end_char="8892" id="token-70-11" morph="none" pos="word" start_char="8887">random</TOKEN>
<TOKEN end_char="8895" id="token-70-12" morph="none" pos="word" start_char="8894">in</TOKEN>
<TOKEN end_char="8897" id="token-70-13" morph="none" pos="word" start_char="8897">a</TOKEN>
<TOKEN end_char="8906" id="token-70-14" morph="none" pos="word" start_char="8899">sequence</TOKEN>
<TOKEN end_char="8907" id="token-70-15" morph="none" pos="punct" start_char="8907">,</TOKEN>
<TOKEN end_char="8912" id="token-70-16" morph="none" pos="word" start_char="8909">they</TOKEN>
<TOKEN end_char="8916" id="token-70-17" morph="none" pos="word" start_char="8914">may</TOKEN>
<TOKEN end_char="8925" id="token-70-18" morph="none" pos="word" start_char="8918">resemble</TOKEN>
<TOKEN end_char="8927" id="token-70-19" morph="none" pos="word" start_char="8927">a</TOKEN>
<TOKEN end_char="8933" id="token-70-20" morph="none" pos="word" start_char="8929">small</TOKEN>
<TOKEN end_char="8942" id="token-70-21" morph="none" pos="word" start_char="8935">fragment</TOKEN>
<TOKEN end_char="8945" id="token-70-22" morph="none" pos="word" start_char="8944">of</TOKEN>
<TOKEN end_char="8953" id="token-70-23" morph="none" pos="word" start_char="8947">another</TOKEN>
<TOKEN end_char="8962" id="token-70-24" morph="none" pos="word" start_char="8955">sequence</TOKEN>
<TOKEN end_char="8970" id="token-70-25" morph="none" pos="word" start_char="8964">without</TOKEN>
<TOKEN end_char="8976" id="token-70-26" morph="none" pos="word" start_char="8972">there</TOKEN>
<TOKEN end_char="8982" id="token-70-27" morph="none" pos="word" start_char="8978">being</TOKEN>
<TOKEN end_char="8986" id="token-70-28" morph="none" pos="word" start_char="8984">any</TOKEN>
<TOKEN end_char="8993" id="token-70-29" morph="none" pos="word" start_char="8988">direct</TOKEN>
<TOKEN end_char="8998" id="token-70-30" morph="none" pos="word" start_char="8995">link</TOKEN>
<TOKEN end_char="8999" id="token-70-31" morph="none" pos="punct" start_char="8999">.</TOKEN>
</SEG>
<SEG end_char="9109" id="segment-71" start_char="9001">
<ORIGINAL_TEXT>Imagine taking a book and choosing a word, and then finding that the same word was also used in another book.</ORIGINAL_TEXT>
<TOKEN end_char="9007" id="token-71-0" morph="none" pos="word" start_char="9001">Imagine</TOKEN>
<TOKEN end_char="9014" id="token-71-1" morph="none" pos="word" start_char="9009">taking</TOKEN>
<TOKEN end_char="9016" id="token-71-2" morph="none" pos="word" start_char="9016">a</TOKEN>
<TOKEN end_char="9021" id="token-71-3" morph="none" pos="word" start_char="9018">book</TOKEN>
<TOKEN end_char="9025" id="token-71-4" morph="none" pos="word" start_char="9023">and</TOKEN>
<TOKEN end_char="9034" id="token-71-5" morph="none" pos="word" start_char="9027">choosing</TOKEN>
<TOKEN end_char="9036" id="token-71-6" morph="none" pos="word" start_char="9036">a</TOKEN>
<TOKEN end_char="9041" id="token-71-7" morph="none" pos="word" start_char="9038">word</TOKEN>
<TOKEN end_char="9042" id="token-71-8" morph="none" pos="punct" start_char="9042">,</TOKEN>
<TOKEN end_char="9046" id="token-71-9" morph="none" pos="word" start_char="9044">and</TOKEN>
<TOKEN end_char="9051" id="token-71-10" morph="none" pos="word" start_char="9048">then</TOKEN>
<TOKEN end_char="9059" id="token-71-11" morph="none" pos="word" start_char="9053">finding</TOKEN>
<TOKEN end_char="9064" id="token-71-12" morph="none" pos="word" start_char="9061">that</TOKEN>
<TOKEN end_char="9068" id="token-71-13" morph="none" pos="word" start_char="9066">the</TOKEN>
<TOKEN end_char="9073" id="token-71-14" morph="none" pos="word" start_char="9070">same</TOKEN>
<TOKEN end_char="9078" id="token-71-15" morph="none" pos="word" start_char="9075">word</TOKEN>
<TOKEN end_char="9082" id="token-71-16" morph="none" pos="word" start_char="9080">was</TOKEN>
<TOKEN end_char="9087" id="token-71-17" morph="none" pos="word" start_char="9084">also</TOKEN>
<TOKEN end_char="9092" id="token-71-18" morph="none" pos="word" start_char="9089">used</TOKEN>
<TOKEN end_char="9095" id="token-71-19" morph="none" pos="word" start_char="9094">in</TOKEN>
<TOKEN end_char="9103" id="token-71-20" morph="none" pos="word" start_char="9097">another</TOKEN>
<TOKEN end_char="9108" id="token-71-21" morph="none" pos="word" start_char="9105">book</TOKEN>
<TOKEN end_char="9109" id="token-71-22" morph="none" pos="punct" start_char="9109">.</TOKEN>
</SEG>
<SEG end_char="9161" id="segment-72" start_char="9111">
<ORIGINAL_TEXT>That does not mean that one book copied the other!"</ORIGINAL_TEXT>
<TOKEN end_char="9114" id="token-72-0" morph="none" pos="word" start_char="9111">That</TOKEN>
<TOKEN end_char="9119" id="token-72-1" morph="none" pos="word" start_char="9116">does</TOKEN>
<TOKEN end_char="9123" id="token-72-2" morph="none" pos="word" start_char="9121">not</TOKEN>
<TOKEN end_char="9128" id="token-72-3" morph="none" pos="word" start_char="9125">mean</TOKEN>
<TOKEN end_char="9133" id="token-72-4" morph="none" pos="word" start_char="9130">that</TOKEN>
<TOKEN end_char="9137" id="token-72-5" morph="none" pos="word" start_char="9135">one</TOKEN>
<TOKEN end_char="9142" id="token-72-6" morph="none" pos="word" start_char="9139">book</TOKEN>
<TOKEN end_char="9149" id="token-72-7" morph="none" pos="word" start_char="9144">copied</TOKEN>
<TOKEN end_char="9153" id="token-72-8" morph="none" pos="word" start_char="9151">the</TOKEN>
<TOKEN end_char="9159" id="token-72-9" morph="none" pos="word" start_char="9155">other</TOKEN>
<TOKEN end_char="9161" id="token-72-10" morph="none" pos="punct" start_char="9160">!"</TOKEN>
</SEG>
<SEG end_char="9284" id="segment-73" start_char="9164">
<ORIGINAL_TEXT>explains Etienne Simon-Lorière, Head of the Evolutionary Genomics of RNA Viruses five-year group at the Institut Pasteur.</ORIGINAL_TEXT>
<TOKEN end_char="9171" id="token-73-0" morph="none" pos="word" start_char="9164">explains</TOKEN>
<TOKEN end_char="9179" id="token-73-1" morph="none" pos="word" start_char="9173">Etienne</TOKEN>
<TOKEN end_char="9193" id="token-73-2" morph="none" pos="unknown" start_char="9181">Simon-Lorière</TOKEN>
<TOKEN end_char="9194" id="token-73-3" morph="none" pos="punct" start_char="9194">,</TOKEN>
<TOKEN end_char="9199" id="token-73-4" morph="none" pos="word" start_char="9196">Head</TOKEN>
<TOKEN end_char="9202" id="token-73-5" morph="none" pos="word" start_char="9201">of</TOKEN>
<TOKEN end_char="9206" id="token-73-6" morph="none" pos="word" start_char="9204">the</TOKEN>
<TOKEN end_char="9219" id="token-73-7" morph="none" pos="word" start_char="9208">Evolutionary</TOKEN>
<TOKEN end_char="9228" id="token-73-8" morph="none" pos="word" start_char="9221">Genomics</TOKEN>
<TOKEN end_char="9231" id="token-73-9" morph="none" pos="word" start_char="9230">of</TOKEN>
<TOKEN end_char="9235" id="token-73-10" morph="none" pos="word" start_char="9233">RNA</TOKEN>
<TOKEN end_char="9243" id="token-73-11" morph="none" pos="word" start_char="9237">Viruses</TOKEN>
<TOKEN end_char="9253" id="token-73-12" morph="none" pos="unknown" start_char="9245">five-year</TOKEN>
<TOKEN end_char="9259" id="token-73-13" morph="none" pos="word" start_char="9255">group</TOKEN>
<TOKEN end_char="9262" id="token-73-14" morph="none" pos="word" start_char="9261">at</TOKEN>
<TOKEN end_char="9266" id="token-73-15" morph="none" pos="word" start_char="9264">the</TOKEN>
<TOKEN end_char="9275" id="token-73-16" morph="none" pos="word" start_char="9268">Institut</TOKEN>
<TOKEN end_char="9283" id="token-73-17" morph="none" pos="word" start_char="9277">Pasteur</TOKEN>
<TOKEN end_char="9284" id="token-73-18" morph="none" pos="punct" start_char="9284">.</TOKEN>
</SEG>
<SEG end_char="9463" id="segment-74" start_char="9287">
<ORIGINAL_TEXT>2 _ The hypothesis is based on a misinterpretation of an article with multiple methodological errors and inaccuracies which has since been repudiated by the scientific community</ORIGINAL_TEXT>
<TOKEN end_char="9287" id="token-74-0" morph="none" pos="word" start_char="9287">2</TOKEN>
<TOKEN end_char="9289" id="token-74-1" morph="none" pos="word" start_char="9289">_</TOKEN>
<TOKEN end_char="9293" id="token-74-2" morph="none" pos="word" start_char="9291">The</TOKEN>
<TOKEN end_char="9304" id="token-74-3" morph="none" pos="word" start_char="9295">hypothesis</TOKEN>
<TOKEN end_char="9307" id="token-74-4" morph="none" pos="word" start_char="9306">is</TOKEN>
<TOKEN end_char="9313" id="token-74-5" morph="none" pos="word" start_char="9309">based</TOKEN>
<TOKEN end_char="9316" id="token-74-6" morph="none" pos="word" start_char="9315">on</TOKEN>
<TOKEN end_char="9318" id="token-74-7" morph="none" pos="word" start_char="9318">a</TOKEN>
<TOKEN end_char="9336" id="token-74-8" morph="none" pos="word" start_char="9320">misinterpretation</TOKEN>
<TOKEN end_char="9339" id="token-74-9" morph="none" pos="word" start_char="9338">of</TOKEN>
<TOKEN end_char="9342" id="token-74-10" morph="none" pos="word" start_char="9341">an</TOKEN>
<TOKEN end_char="9350" id="token-74-11" morph="none" pos="word" start_char="9344">article</TOKEN>
<TOKEN end_char="9355" id="token-74-12" morph="none" pos="word" start_char="9352">with</TOKEN>
<TOKEN end_char="9364" id="token-74-13" morph="none" pos="word" start_char="9357">multiple</TOKEN>
<TOKEN end_char="9379" id="token-74-14" morph="none" pos="word" start_char="9366">methodological</TOKEN>
<TOKEN end_char="9386" id="token-74-15" morph="none" pos="word" start_char="9381">errors</TOKEN>
<TOKEN end_char="9390" id="token-74-16" morph="none" pos="word" start_char="9388">and</TOKEN>
<TOKEN end_char="9403" id="token-74-17" morph="none" pos="word" start_char="9392">inaccuracies</TOKEN>
<TOKEN end_char="9409" id="token-74-18" morph="none" pos="word" start_char="9405">which</TOKEN>
<TOKEN end_char="9413" id="token-74-19" morph="none" pos="word" start_char="9411">has</TOKEN>
<TOKEN end_char="9419" id="token-74-20" morph="none" pos="word" start_char="9415">since</TOKEN>
<TOKEN end_char="9424" id="token-74-21" morph="none" pos="word" start_char="9421">been</TOKEN>
<TOKEN end_char="9435" id="token-74-22" morph="none" pos="word" start_char="9426">repudiated</TOKEN>
<TOKEN end_char="9438" id="token-74-23" morph="none" pos="word" start_char="9437">by</TOKEN>
<TOKEN end_char="9442" id="token-74-24" morph="none" pos="word" start_char="9440">the</TOKEN>
<TOKEN end_char="9453" id="token-74-25" morph="none" pos="word" start_char="9444">scientific</TOKEN>
<TOKEN end_char="9463" id="token-74-26" morph="none" pos="word" start_char="9455">community</TOKEN>
</SEG>
<SEG end_char="9625" id="segment-75" start_char="9467">
<ORIGINAL_TEXT>The theory that SARS-CoV-2 derives from HIV is based on an incorrect analysis of an article published by Indian scientists on the open science website bioRxiv.</ORIGINAL_TEXT>
<TOKEN end_char="9469" id="token-75-0" morph="none" pos="word" start_char="9467">The</TOKEN>
<TOKEN end_char="9476" id="token-75-1" morph="none" pos="word" start_char="9471">theory</TOKEN>
<TOKEN end_char="9481" id="token-75-2" morph="none" pos="word" start_char="9478">that</TOKEN>
<TOKEN end_char="9492" id="token-75-3" morph="none" pos="unknown" start_char="9483">SARS-CoV-2</TOKEN>
<TOKEN end_char="9500" id="token-75-4" morph="none" pos="word" start_char="9494">derives</TOKEN>
<TOKEN end_char="9505" id="token-75-5" morph="none" pos="word" start_char="9502">from</TOKEN>
<TOKEN end_char="9509" id="token-75-6" morph="none" pos="word" start_char="9507">HIV</TOKEN>
<TOKEN end_char="9512" id="token-75-7" morph="none" pos="word" start_char="9511">is</TOKEN>
<TOKEN end_char="9518" id="token-75-8" morph="none" pos="word" start_char="9514">based</TOKEN>
<TOKEN end_char="9521" id="token-75-9" morph="none" pos="word" start_char="9520">on</TOKEN>
<TOKEN end_char="9524" id="token-75-10" morph="none" pos="word" start_char="9523">an</TOKEN>
<TOKEN end_char="9534" id="token-75-11" morph="none" pos="word" start_char="9526">incorrect</TOKEN>
<TOKEN end_char="9543" id="token-75-12" morph="none" pos="word" start_char="9536">analysis</TOKEN>
<TOKEN end_char="9546" id="token-75-13" morph="none" pos="word" start_char="9545">of</TOKEN>
<TOKEN end_char="9549" id="token-75-14" morph="none" pos="word" start_char="9548">an</TOKEN>
<TOKEN end_char="9557" id="token-75-15" morph="none" pos="word" start_char="9551">article</TOKEN>
<TOKEN end_char="9567" id="token-75-16" morph="none" pos="word" start_char="9559">published</TOKEN>
<TOKEN end_char="9570" id="token-75-17" morph="none" pos="word" start_char="9569">by</TOKEN>
<TOKEN end_char="9577" id="token-75-18" morph="none" pos="word" start_char="9572">Indian</TOKEN>
<TOKEN end_char="9588" id="token-75-19" morph="none" pos="word" start_char="9579">scientists</TOKEN>
<TOKEN end_char="9591" id="token-75-20" morph="none" pos="word" start_char="9590">on</TOKEN>
<TOKEN end_char="9595" id="token-75-21" morph="none" pos="word" start_char="9593">the</TOKEN>
<TOKEN end_char="9600" id="token-75-22" morph="none" pos="word" start_char="9597">open</TOKEN>
<TOKEN end_char="9608" id="token-75-23" morph="none" pos="word" start_char="9602">science</TOKEN>
<TOKEN end_char="9616" id="token-75-24" morph="none" pos="word" start_char="9610">website</TOKEN>
<TOKEN end_char="9624" id="token-75-25" morph="none" pos="word" start_char="9618">bioRxiv</TOKEN>
<TOKEN end_char="9625" id="token-75-26" morph="none" pos="punct" start_char="9625">.</TOKEN>
</SEG>
<SEG end_char="9874" id="segment-76" start_char="9627">
<ORIGINAL_TEXT>"A scientific study was submitted to the bioRxiv website, where scientists can post results that have not been validated," confirms Olivier Schwartz, Head of the Virus and Immunity Unit at the Institut Pasteur (see also France Culture - in French).</ORIGINAL_TEXT>
<TOKEN end_char="9627" id="token-76-0" morph="none" pos="punct" start_char="9627">"</TOKEN>
<TOKEN end_char="9628" id="token-76-1" morph="none" pos="word" start_char="9628">A</TOKEN>
<TOKEN end_char="9639" id="token-76-2" morph="none" pos="word" start_char="9630">scientific</TOKEN>
<TOKEN end_char="9645" id="token-76-3" morph="none" pos="word" start_char="9641">study</TOKEN>
<TOKEN end_char="9649" id="token-76-4" morph="none" pos="word" start_char="9647">was</TOKEN>
<TOKEN end_char="9659" id="token-76-5" morph="none" pos="word" start_char="9651">submitted</TOKEN>
<TOKEN end_char="9662" id="token-76-6" morph="none" pos="word" start_char="9661">to</TOKEN>
<TOKEN end_char="9666" id="token-76-7" morph="none" pos="word" start_char="9664">the</TOKEN>
<TOKEN end_char="9674" id="token-76-8" morph="none" pos="word" start_char="9668">bioRxiv</TOKEN>
<TOKEN end_char="9682" id="token-76-9" morph="none" pos="word" start_char="9676">website</TOKEN>
<TOKEN end_char="9683" id="token-76-10" morph="none" pos="punct" start_char="9683">,</TOKEN>
<TOKEN end_char="9689" id="token-76-11" morph="none" pos="word" start_char="9685">where</TOKEN>
<TOKEN end_char="9700" id="token-76-12" morph="none" pos="word" start_char="9691">scientists</TOKEN>
<TOKEN end_char="9704" id="token-76-13" morph="none" pos="word" start_char="9702">can</TOKEN>
<TOKEN end_char="9709" id="token-76-14" morph="none" pos="word" start_char="9706">post</TOKEN>
<TOKEN end_char="9717" id="token-76-15" morph="none" pos="word" start_char="9711">results</TOKEN>
<TOKEN end_char="9722" id="token-76-16" morph="none" pos="word" start_char="9719">that</TOKEN>
<TOKEN end_char="9727" id="token-76-17" morph="none" pos="word" start_char="9724">have</TOKEN>
<TOKEN end_char="9731" id="token-76-18" morph="none" pos="word" start_char="9729">not</TOKEN>
<TOKEN end_char="9736" id="token-76-19" morph="none" pos="word" start_char="9733">been</TOKEN>
<TOKEN end_char="9746" id="token-76-20" morph="none" pos="word" start_char="9738">validated</TOKEN>
<TOKEN end_char="9748" id="token-76-21" morph="none" pos="punct" start_char="9747">,"</TOKEN>
<TOKEN end_char="9757" id="token-76-22" morph="none" pos="word" start_char="9750">confirms</TOKEN>
<TOKEN end_char="9765" id="token-76-23" morph="none" pos="word" start_char="9759">Olivier</TOKEN>
<TOKEN end_char="9774" id="token-76-24" morph="none" pos="word" start_char="9767">Schwartz</TOKEN>
<TOKEN end_char="9775" id="token-76-25" morph="none" pos="punct" start_char="9775">,</TOKEN>
<TOKEN end_char="9780" id="token-76-26" morph="none" pos="word" start_char="9777">Head</TOKEN>
<TOKEN end_char="9783" id="token-76-27" morph="none" pos="word" start_char="9782">of</TOKEN>
<TOKEN end_char="9787" id="token-76-28" morph="none" pos="word" start_char="9785">the</TOKEN>
<TOKEN end_char="9793" id="token-76-29" morph="none" pos="word" start_char="9789">Virus</TOKEN>
<TOKEN end_char="9797" id="token-76-30" morph="none" pos="word" start_char="9795">and</TOKEN>
<TOKEN end_char="9806" id="token-76-31" morph="none" pos="word" start_char="9799">Immunity</TOKEN>
<TOKEN end_char="9811" id="token-76-32" morph="none" pos="word" start_char="9808">Unit</TOKEN>
<TOKEN end_char="9814" id="token-76-33" morph="none" pos="word" start_char="9813">at</TOKEN>
<TOKEN end_char="9818" id="token-76-34" morph="none" pos="word" start_char="9816">the</TOKEN>
<TOKEN end_char="9827" id="token-76-35" morph="none" pos="word" start_char="9820">Institut</TOKEN>
<TOKEN end_char="9835" id="token-76-36" morph="none" pos="word" start_char="9829">Pasteur</TOKEN>
<TOKEN end_char="9837" id="token-76-37" morph="none" pos="punct" start_char="9837">(</TOKEN>
<TOKEN end_char="9840" id="token-76-38" morph="none" pos="word" start_char="9838">see</TOKEN>
<TOKEN end_char="9845" id="token-76-39" morph="none" pos="word" start_char="9842">also</TOKEN>
<TOKEN end_char="9852" id="token-76-40" morph="none" pos="word" start_char="9847">France</TOKEN>
<TOKEN end_char="9860" id="token-76-41" morph="none" pos="word" start_char="9854">Culture</TOKEN>
<TOKEN end_char="9862" id="token-76-42" morph="none" pos="punct" start_char="9862">-</TOKEN>
<TOKEN end_char="9865" id="token-76-43" morph="none" pos="word" start_char="9864">in</TOKEN>
<TOKEN end_char="9872" id="token-76-44" morph="none" pos="word" start_char="9867">French</TOKEN>
<TOKEN end_char="9874" id="token-76-45" morph="none" pos="punct" start_char="9873">).</TOKEN>
</SEG>
<SEG end_char="10195" id="segment-77" start_char="9877">
<ORIGINAL_TEXT>The Indian paper, initially published without peer review (as is the norm for this type of open science website), was strongly criticized by the scientific community for its approximations and subsequently withdrawn by the authors themselves because of the methodological errors that had been flagged up by their peers.</ORIGINAL_TEXT>
<TOKEN end_char="9879" id="token-77-0" morph="none" pos="word" start_char="9877">The</TOKEN>
<TOKEN end_char="9886" id="token-77-1" morph="none" pos="word" start_char="9881">Indian</TOKEN>
<TOKEN end_char="9892" id="token-77-2" morph="none" pos="word" start_char="9888">paper</TOKEN>
<TOKEN end_char="9893" id="token-77-3" morph="none" pos="punct" start_char="9893">,</TOKEN>
<TOKEN end_char="9903" id="token-77-4" morph="none" pos="word" start_char="9895">initially</TOKEN>
<TOKEN end_char="9913" id="token-77-5" morph="none" pos="word" start_char="9905">published</TOKEN>
<TOKEN end_char="9921" id="token-77-6" morph="none" pos="word" start_char="9915">without</TOKEN>
<TOKEN end_char="9926" id="token-77-7" morph="none" pos="word" start_char="9923">peer</TOKEN>
<TOKEN end_char="9933" id="token-77-8" morph="none" pos="word" start_char="9928">review</TOKEN>
<TOKEN end_char="9935" id="token-77-9" morph="none" pos="punct" start_char="9935">(</TOKEN>
<TOKEN end_char="9937" id="token-77-10" morph="none" pos="word" start_char="9936">as</TOKEN>
<TOKEN end_char="9940" id="token-77-11" morph="none" pos="word" start_char="9939">is</TOKEN>
<TOKEN end_char="9944" id="token-77-12" morph="none" pos="word" start_char="9942">the</TOKEN>
<TOKEN end_char="9949" id="token-77-13" morph="none" pos="word" start_char="9946">norm</TOKEN>
<TOKEN end_char="9953" id="token-77-14" morph="none" pos="word" start_char="9951">for</TOKEN>
<TOKEN end_char="9958" id="token-77-15" morph="none" pos="word" start_char="9955">this</TOKEN>
<TOKEN end_char="9963" id="token-77-16" morph="none" pos="word" start_char="9960">type</TOKEN>
<TOKEN end_char="9966" id="token-77-17" morph="none" pos="word" start_char="9965">of</TOKEN>
<TOKEN end_char="9971" id="token-77-18" morph="none" pos="word" start_char="9968">open</TOKEN>
<TOKEN end_char="9979" id="token-77-19" morph="none" pos="word" start_char="9973">science</TOKEN>
<TOKEN end_char="9987" id="token-77-20" morph="none" pos="word" start_char="9981">website</TOKEN>
<TOKEN end_char="9989" id="token-77-21" morph="none" pos="punct" start_char="9988">),</TOKEN>
<TOKEN end_char="9993" id="token-77-22" morph="none" pos="word" start_char="9991">was</TOKEN>
<TOKEN end_char="10002" id="token-77-23" morph="none" pos="word" start_char="9995">strongly</TOKEN>
<TOKEN end_char="10013" id="token-77-24" morph="none" pos="word" start_char="10004">criticized</TOKEN>
<TOKEN end_char="10016" id="token-77-25" morph="none" pos="word" start_char="10015">by</TOKEN>
<TOKEN end_char="10020" id="token-77-26" morph="none" pos="word" start_char="10018">the</TOKEN>
<TOKEN end_char="10031" id="token-77-27" morph="none" pos="word" start_char="10022">scientific</TOKEN>
<TOKEN end_char="10041" id="token-77-28" morph="none" pos="word" start_char="10033">community</TOKEN>
<TOKEN end_char="10045" id="token-77-29" morph="none" pos="word" start_char="10043">for</TOKEN>
<TOKEN end_char="10049" id="token-77-30" morph="none" pos="word" start_char="10047">its</TOKEN>
<TOKEN end_char="10064" id="token-77-31" morph="none" pos="word" start_char="10051">approximations</TOKEN>
<TOKEN end_char="10068" id="token-77-32" morph="none" pos="word" start_char="10066">and</TOKEN>
<TOKEN end_char="10081" id="token-77-33" morph="none" pos="word" start_char="10070">subsequently</TOKEN>
<TOKEN end_char="10091" id="token-77-34" morph="none" pos="word" start_char="10083">withdrawn</TOKEN>
<TOKEN end_char="10094" id="token-77-35" morph="none" pos="word" start_char="10093">by</TOKEN>
<TOKEN end_char="10098" id="token-77-36" morph="none" pos="word" start_char="10096">the</TOKEN>
<TOKEN end_char="10106" id="token-77-37" morph="none" pos="word" start_char="10100">authors</TOKEN>
<TOKEN end_char="10117" id="token-77-38" morph="none" pos="word" start_char="10108">themselves</TOKEN>
<TOKEN end_char="10125" id="token-77-39" morph="none" pos="word" start_char="10119">because</TOKEN>
<TOKEN end_char="10128" id="token-77-40" morph="none" pos="word" start_char="10127">of</TOKEN>
<TOKEN end_char="10132" id="token-77-41" morph="none" pos="word" start_char="10130">the</TOKEN>
<TOKEN end_char="10147" id="token-77-42" morph="none" pos="word" start_char="10134">methodological</TOKEN>
<TOKEN end_char="10154" id="token-77-43" morph="none" pos="word" start_char="10149">errors</TOKEN>
<TOKEN end_char="10159" id="token-77-44" morph="none" pos="word" start_char="10156">that</TOKEN>
<TOKEN end_char="10163" id="token-77-45" morph="none" pos="word" start_char="10161">had</TOKEN>
<TOKEN end_char="10168" id="token-77-46" morph="none" pos="word" start_char="10165">been</TOKEN>
<TOKEN end_char="10176" id="token-77-47" morph="none" pos="word" start_char="10170">flagged</TOKEN>
<TOKEN end_char="10179" id="token-77-48" morph="none" pos="word" start_char="10178">up</TOKEN>
<TOKEN end_char="10182" id="token-77-49" morph="none" pos="word" start_char="10181">by</TOKEN>
<TOKEN end_char="10188" id="token-77-50" morph="none" pos="word" start_char="10184">their</TOKEN>
<TOKEN end_char="10194" id="token-77-51" morph="none" pos="word" start_char="10190">peers</TOKEN>
<TOKEN end_char="10195" id="token-77-52" morph="none" pos="punct" start_char="10195">.</TOKEN>
</SEG>
<SEG end_char="10339" id="segment-78" start_char="10198">
<ORIGINAL_TEXT>The open science website bioRxiv now displays a banner qindicating that the articles it hosts have not been peer reviewed (see also the column</ORIGINAL_TEXT>
<TOKEN end_char="10200" id="token-78-0" morph="none" pos="word" start_char="10198">The</TOKEN>
<TOKEN end_char="10205" id="token-78-1" morph="none" pos="word" start_char="10202">open</TOKEN>
<TOKEN end_char="10213" id="token-78-2" morph="none" pos="word" start_char="10207">science</TOKEN>
<TOKEN end_char="10221" id="token-78-3" morph="none" pos="word" start_char="10215">website</TOKEN>
<TOKEN end_char="10229" id="token-78-4" morph="none" pos="word" start_char="10223">bioRxiv</TOKEN>
<TOKEN end_char="10233" id="token-78-5" morph="none" pos="word" start_char="10231">now</TOKEN>
<TOKEN end_char="10242" id="token-78-6" morph="none" pos="word" start_char="10235">displays</TOKEN>
<TOKEN end_char="10244" id="token-78-7" morph="none" pos="word" start_char="10244">a</TOKEN>
<TOKEN end_char="10251" id="token-78-8" morph="none" pos="word" start_char="10246">banner</TOKEN>
<TOKEN end_char="10263" id="token-78-9" morph="none" pos="word" start_char="10253">qindicating</TOKEN>
<TOKEN end_char="10268" id="token-78-10" morph="none" pos="word" start_char="10265">that</TOKEN>
<TOKEN end_char="10272" id="token-78-11" morph="none" pos="word" start_char="10270">the</TOKEN>
<TOKEN end_char="10281" id="token-78-12" morph="none" pos="word" start_char="10274">articles</TOKEN>
<TOKEN end_char="10284" id="token-78-13" morph="none" pos="word" start_char="10283">it</TOKEN>
<TOKEN end_char="10290" id="token-78-14" morph="none" pos="word" start_char="10286">hosts</TOKEN>
<TOKEN end_char="10295" id="token-78-15" morph="none" pos="word" start_char="10292">have</TOKEN>
<TOKEN end_char="10299" id="token-78-16" morph="none" pos="word" start_char="10297">not</TOKEN>
<TOKEN end_char="10304" id="token-78-17" morph="none" pos="word" start_char="10301">been</TOKEN>
<TOKEN end_char="10309" id="token-78-18" morph="none" pos="word" start_char="10306">peer</TOKEN>
<TOKEN end_char="10318" id="token-78-19" morph="none" pos="word" start_char="10311">reviewed</TOKEN>
<TOKEN end_char="10320" id="token-78-20" morph="none" pos="punct" start_char="10320">(</TOKEN>
<TOKEN end_char="10323" id="token-78-21" morph="none" pos="word" start_char="10321">see</TOKEN>
<TOKEN end_char="10328" id="token-78-22" morph="none" pos="word" start_char="10325">also</TOKEN>
<TOKEN end_char="10332" id="token-78-23" morph="none" pos="word" start_char="10330">the</TOKEN>
<TOKEN end_char="10339" id="token-78-24" morph="none" pos="word" start_char="10334">column</TOKEN>
</SEG>
<SEG end_char="10354" id="segment-79" start_char="10342">
<ORIGINAL_TEXT>Les Décodeurs</ORIGINAL_TEXT>
<TOKEN end_char="10344" id="token-79-0" morph="none" pos="word" start_char="10342">Les</TOKEN>
<TOKEN end_char="10354" id="token-79-1" morph="none" pos="word" start_char="10346">Décodeurs</TOKEN>
<TRANSLATED_TEXT>Decoders</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="10383" id="segment-80" start_char="10357">
<ORIGINAL_TEXT>, in Le Monde - in French).</ORIGINAL_TEXT>
<TOKEN end_char="10357" id="token-80-0" morph="none" pos="punct" start_char="10357">,</TOKEN>
<TOKEN end_char="10360" id="token-80-1" morph="none" pos="word" start_char="10359">in</TOKEN>
<TOKEN end_char="10363" id="token-80-2" morph="none" pos="word" start_char="10362">Le</TOKEN>
<TOKEN end_char="10369" id="token-80-3" morph="none" pos="word" start_char="10365">Monde</TOKEN>
<TOKEN end_char="10371" id="token-80-4" morph="none" pos="punct" start_char="10371">-</TOKEN>
<TOKEN end_char="10374" id="token-80-5" morph="none" pos="word" start_char="10373">in</TOKEN>
<TOKEN end_char="10381" id="token-80-6" morph="none" pos="word" start_char="10376">French</TOKEN>
<TOKEN end_char="10383" id="token-80-7" morph="none" pos="punct" start_char="10382">).</TOKEN>
</SEG>
<SEG end_char="10412" id="segment-81" start_char="10386">
<ORIGINAL_TEXT>3 _ An article published in</ORIGINAL_TEXT>
<TOKEN end_char="10386" id="token-81-0" morph="none" pos="word" start_char="10386">3</TOKEN>
<TOKEN end_char="10388" id="token-81-1" morph="none" pos="word" start_char="10388">_</TOKEN>
<TOKEN end_char="10391" id="token-81-2" morph="none" pos="word" start_char="10390">An</TOKEN>
<TOKEN end_char="10399" id="token-81-3" morph="none" pos="word" start_char="10393">article</TOKEN>
<TOKEN end_char="10409" id="token-81-4" morph="none" pos="word" start_char="10401">published</TOKEN>
<TOKEN end_char="10412" id="token-81-5" morph="none" pos="word" start_char="10411">in</TOKEN>
</SEG>
<SEG end_char="10429" id="segment-82" start_char="10415">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN end_char="10420" id="token-82-0" morph="none" pos="word" start_char="10415">Nature</TOKEN>
<TOKEN end_char="10429" id="token-82-1" morph="none" pos="word" start_char="10422">Medicine</TOKEN>
<TRANSLATED_TEXT>Naturmedicin</TRANSLATED_TEXT><DETECTED_LANGUAGE>ro</DETECTED_LANGUAGE></SEG>
<SEG end_char="10542" id="segment-83" start_char="10432">
<ORIGINAL_TEXT>has since confirmed that there is no evidence that the SARS-CoV-2 coronavirus could have been created by humans</ORIGINAL_TEXT>
<TOKEN end_char="10434" id="token-83-0" morph="none" pos="word" start_char="10432">has</TOKEN>
<TOKEN end_char="10440" id="token-83-1" morph="none" pos="word" start_char="10436">since</TOKEN>
<TOKEN end_char="10450" id="token-83-2" morph="none" pos="word" start_char="10442">confirmed</TOKEN>
<TOKEN end_char="10455" id="token-83-3" morph="none" pos="word" start_char="10452">that</TOKEN>
<TOKEN end_char="10461" id="token-83-4" morph="none" pos="word" start_char="10457">there</TOKEN>
<TOKEN end_char="10464" id="token-83-5" morph="none" pos="word" start_char="10463">is</TOKEN>
<TOKEN end_char="10467" id="token-83-6" morph="none" pos="word" start_char="10466">no</TOKEN>
<TOKEN end_char="10476" id="token-83-7" morph="none" pos="word" start_char="10469">evidence</TOKEN>
<TOKEN end_char="10481" id="token-83-8" morph="none" pos="word" start_char="10478">that</TOKEN>
<TOKEN end_char="10485" id="token-83-9" morph="none" pos="word" start_char="10483">the</TOKEN>
<TOKEN end_char="10496" id="token-83-10" morph="none" pos="unknown" start_char="10487">SARS-CoV-2</TOKEN>
<TOKEN end_char="10508" id="token-83-11" morph="none" pos="word" start_char="10498">coronavirus</TOKEN>
<TOKEN end_char="10514" id="token-83-12" morph="none" pos="word" start_char="10510">could</TOKEN>
<TOKEN end_char="10519" id="token-83-13" morph="none" pos="word" start_char="10516">have</TOKEN>
<TOKEN end_char="10524" id="token-83-14" morph="none" pos="word" start_char="10521">been</TOKEN>
<TOKEN end_char="10532" id="token-83-15" morph="none" pos="word" start_char="10526">created</TOKEN>
<TOKEN end_char="10535" id="token-83-16" morph="none" pos="word" start_char="10534">by</TOKEN>
<TOKEN end_char="10542" id="token-83-17" morph="none" pos="word" start_char="10537">humans</TOKEN>
</SEG>
<SEG end_char="10732" id="segment-84" start_char="10546">
<ORIGINAL_TEXT>A scientific article dated March 17, 2020 refutes the idea of a laboratory-created virus (The proximal origin of SARS-CoV-2, Kristian G. Andersen, Andrew Rambaut, W. Ian Lipkin, Edward C.</ORIGINAL_TEXT>
<TOKEN end_char="10546" id="token-84-0" morph="none" pos="word" start_char="10546">A</TOKEN>
<TOKEN end_char="10557" id="token-84-1" morph="none" pos="word" start_char="10548">scientific</TOKEN>
<TOKEN end_char="10565" id="token-84-2" morph="none" pos="word" start_char="10559">article</TOKEN>
<TOKEN end_char="10571" id="token-84-3" morph="none" pos="word" start_char="10567">dated</TOKEN>
<TOKEN end_char="10577" id="token-84-4" morph="none" pos="word" start_char="10573">March</TOKEN>
<TOKEN end_char="10580" id="token-84-5" morph="none" pos="word" start_char="10579">17</TOKEN>
<TOKEN end_char="10581" id="token-84-6" morph="none" pos="punct" start_char="10581">,</TOKEN>
<TOKEN end_char="10586" id="token-84-7" morph="none" pos="word" start_char="10583">2020</TOKEN>
<TOKEN end_char="10594" id="token-84-8" morph="none" pos="word" start_char="10588">refutes</TOKEN>
<TOKEN end_char="10598" id="token-84-9" morph="none" pos="word" start_char="10596">the</TOKEN>
<TOKEN end_char="10603" id="token-84-10" morph="none" pos="word" start_char="10600">idea</TOKEN>
<TOKEN end_char="10606" id="token-84-11" morph="none" pos="word" start_char="10605">of</TOKEN>
<TOKEN end_char="10608" id="token-84-12" morph="none" pos="word" start_char="10608">a</TOKEN>
<TOKEN end_char="10627" id="token-84-13" morph="none" pos="unknown" start_char="10610">laboratory-created</TOKEN>
<TOKEN end_char="10633" id="token-84-14" morph="none" pos="word" start_char="10629">virus</TOKEN>
<TOKEN end_char="10635" id="token-84-15" morph="none" pos="punct" start_char="10635">(</TOKEN>
<TOKEN end_char="10638" id="token-84-16" morph="none" pos="word" start_char="10636">The</TOKEN>
<TOKEN end_char="10647" id="token-84-17" morph="none" pos="word" start_char="10640">proximal</TOKEN>
<TOKEN end_char="10654" id="token-84-18" morph="none" pos="word" start_char="10649">origin</TOKEN>
<TOKEN end_char="10657" id="token-84-19" morph="none" pos="word" start_char="10656">of</TOKEN>
<TOKEN end_char="10668" id="token-84-20" morph="none" pos="unknown" start_char="10659">SARS-CoV-2</TOKEN>
<TOKEN end_char="10669" id="token-84-21" morph="none" pos="punct" start_char="10669">,</TOKEN>
<TOKEN end_char="10678" id="token-84-22" morph="none" pos="word" start_char="10671">Kristian</TOKEN>
<TOKEN end_char="10680" id="token-84-23" morph="none" pos="word" start_char="10680">G</TOKEN>
<TOKEN end_char="10681" id="token-84-24" morph="none" pos="punct" start_char="10681">.</TOKEN>
<TOKEN end_char="10690" id="token-84-25" morph="none" pos="word" start_char="10683">Andersen</TOKEN>
<TOKEN end_char="10691" id="token-84-26" morph="none" pos="punct" start_char="10691">,</TOKEN>
<TOKEN end_char="10698" id="token-84-27" morph="none" pos="word" start_char="10693">Andrew</TOKEN>
<TOKEN end_char="10706" id="token-84-28" morph="none" pos="word" start_char="10700">Rambaut</TOKEN>
<TOKEN end_char="10707" id="token-84-29" morph="none" pos="punct" start_char="10707">,</TOKEN>
<TOKEN end_char="10709" id="token-84-30" morph="none" pos="word" start_char="10709">W</TOKEN>
<TOKEN end_char="10710" id="token-84-31" morph="none" pos="punct" start_char="10710">.</TOKEN>
<TOKEN end_char="10714" id="token-84-32" morph="none" pos="word" start_char="10712">Ian</TOKEN>
<TOKEN end_char="10721" id="token-84-33" morph="none" pos="word" start_char="10716">Lipkin</TOKEN>
<TOKEN end_char="10722" id="token-84-34" morph="none" pos="punct" start_char="10722">,</TOKEN>
<TOKEN end_char="10729" id="token-84-35" morph="none" pos="word" start_char="10724">Edward</TOKEN>
<TOKEN end_char="10731" id="token-84-36" morph="none" pos="word" start_char="10731">C</TOKEN>
<TOKEN end_char="10732" id="token-84-37" morph="none" pos="punct" start_char="10732">.</TOKEN>
</SEG>
<SEG end_char="10749" id="segment-85" start_char="10734">
<ORIGINAL_TEXT>Holmes Robert F.</ORIGINAL_TEXT>
<TOKEN end_char="10739" id="token-85-0" morph="none" pos="word" start_char="10734">Holmes</TOKEN>
<TOKEN end_char="10746" id="token-85-1" morph="none" pos="word" start_char="10741">Robert</TOKEN>
<TOKEN end_char="10748" id="token-85-2" morph="none" pos="word" start_char="10748">F</TOKEN>
<TOKEN end_char="10749" id="token-85-3" morph="none" pos="punct" start_char="10749">.</TOKEN>
<TRANSLATED_TEXT>Holmes, Robert F.</TRANSLATED_TEXT><DETECTED_LANGUAGE>da</DETECTED_LANGUAGE></SEG>
<SEG end_char="10756" id="segment-86" start_char="10751">
<ORIGINAL_TEXT>Garry.</ORIGINAL_TEXT>
<TOKEN end_char="10755" id="token-86-0" morph="none" pos="word" start_char="10751">Garry</TOKEN>
<TOKEN end_char="10756" id="token-86-1" morph="none" pos="punct" start_char="10756">.</TOKEN>
<TRANSLATED_TEXT>- Garry.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="10773" id="segment-87" start_char="10759">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN end_char="10764" id="token-87-0" morph="none" pos="word" start_char="10759">Nature</TOKEN>
<TOKEN end_char="10773" id="token-87-1" morph="none" pos="word" start_char="10766">Medicine</TOKEN>
<TRANSLATED_TEXT>Naturmedicin</TRANSLATED_TEXT><DETECTED_LANGUAGE>ro</DETECTED_LANGUAGE></SEG>
<SEG end_char="10783" id="segment-88" start_char="10776">
<ORIGINAL_TEXT>- 2020).</ORIGINAL_TEXT>
<TOKEN end_char="10776" id="token-88-0" morph="none" pos="punct" start_char="10776">-</TOKEN>
<TOKEN end_char="10781" id="token-88-1" morph="none" pos="word" start_char="10778">2020</TOKEN>
<TOKEN end_char="10783" id="token-88-2" morph="none" pos="punct" start_char="10782">).</TOKEN>
<TRANSLATED_TEXT>2020).</TRANSLATED_TEXT><DETECTED_LANGUAGE /></SEG>
<SEG end_char="10873" id="segment-89" start_char="10786">
<ORIGINAL_TEXT>See also below "There is no evidence that SARS-CoV-2 coronavirus was created by humans".</ORIGINAL_TEXT>
<TOKEN end_char="10788" id="token-89-0" morph="none" pos="word" start_char="10786">See</TOKEN>
<TOKEN end_char="10793" id="token-89-1" morph="none" pos="word" start_char="10790">also</TOKEN>
<TOKEN end_char="10799" id="token-89-2" morph="none" pos="word" start_char="10795">below</TOKEN>
<TOKEN end_char="10801" id="token-89-3" morph="none" pos="punct" start_char="10801">"</TOKEN>
<TOKEN end_char="10806" id="token-89-4" morph="none" pos="word" start_char="10802">There</TOKEN>
<TOKEN end_char="10809" id="token-89-5" morph="none" pos="word" start_char="10808">is</TOKEN>
<TOKEN end_char="10812" id="token-89-6" morph="none" pos="word" start_char="10811">no</TOKEN>
<TOKEN end_char="10821" id="token-89-7" morph="none" pos="word" start_char="10814">evidence</TOKEN>
<TOKEN end_char="10826" id="token-89-8" morph="none" pos="word" start_char="10823">that</TOKEN>
<TOKEN end_char="10837" id="token-89-9" morph="none" pos="unknown" start_char="10828">SARS-CoV-2</TOKEN>
<TOKEN end_char="10849" id="token-89-10" morph="none" pos="word" start_char="10839">coronavirus</TOKEN>
<TOKEN end_char="10853" id="token-89-11" morph="none" pos="word" start_char="10851">was</TOKEN>
<TOKEN end_char="10861" id="token-89-12" morph="none" pos="word" start_char="10855">created</TOKEN>
<TOKEN end_char="10864" id="token-89-13" morph="none" pos="word" start_char="10863">by</TOKEN>
<TOKEN end_char="10871" id="token-89-14" morph="none" pos="word" start_char="10866">humans</TOKEN>
<TOKEN end_char="10873" id="token-89-15" morph="none" pos="punct" start_char="10872">".</TOKEN>
</SEG>
<SEG end_char="10957" id="segment-90" start_char="10876">
<ORIGINAL_TEXT>NO, nothing proves that the coronavirus would have been created in the laboratory!</ORIGINAL_TEXT>
<TOKEN end_char="10877" id="token-90-0" morph="none" pos="word" start_char="10876">NO</TOKEN>
<TOKEN end_char="10878" id="token-90-1" morph="none" pos="punct" start_char="10878">,</TOKEN>
<TOKEN end_char="10886" id="token-90-2" morph="none" pos="word" start_char="10880">nothing</TOKEN>
<TOKEN end_char="10893" id="token-90-3" morph="none" pos="word" start_char="10888">proves</TOKEN>
<TOKEN end_char="10898" id="token-90-4" morph="none" pos="word" start_char="10895">that</TOKEN>
<TOKEN end_char="10902" id="token-90-5" morph="none" pos="word" start_char="10900">the</TOKEN>
<TOKEN end_char="10914" id="token-90-6" morph="none" pos="word" start_char="10904">coronavirus</TOKEN>
<TOKEN end_char="10920" id="token-90-7" morph="none" pos="word" start_char="10916">would</TOKEN>
<TOKEN end_char="10925" id="token-90-8" morph="none" pos="word" start_char="10922">have</TOKEN>
<TOKEN end_char="10930" id="token-90-9" morph="none" pos="word" start_char="10927">been</TOKEN>
<TOKEN end_char="10938" id="token-90-10" morph="none" pos="word" start_char="10932">created</TOKEN>
<TOKEN end_char="10941" id="token-90-11" morph="none" pos="word" start_char="10940">in</TOKEN>
<TOKEN end_char="10945" id="token-90-12" morph="none" pos="word" start_char="10943">the</TOKEN>
<TOKEN end_char="10956" id="token-90-13" morph="none" pos="word" start_char="10947">laboratory</TOKEN>
<TOKEN end_char="10957" id="token-90-14" morph="none" pos="punct" start_char="10957">!</TOKEN>
</SEG>
<SEG end_char="10988" id="segment-91" start_char="10960">
<ORIGINAL_TEXT>Disclaimer of March 23, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="10969" id="token-91-0" morph="none" pos="word" start_char="10960">Disclaimer</TOKEN>
<TOKEN end_char="10972" id="token-91-1" morph="none" pos="word" start_char="10971">of</TOKEN>
<TOKEN end_char="10978" id="token-91-2" morph="none" pos="word" start_char="10974">March</TOKEN>
<TOKEN end_char="10981" id="token-91-3" morph="none" pos="word" start_char="10980">23</TOKEN>
<TOKEN end_char="10982" id="token-91-4" morph="none" pos="punct" start_char="10982">,</TOKEN>
<TOKEN end_char="10987" id="token-91-5" morph="none" pos="word" start_char="10984">2020</TOKEN>
<TOKEN end_char="10988" id="token-91-6" morph="none" pos="punct" start_char="10988">.</TOKEN>
</SEG>
<SEG end_char="11014" id="segment-92" start_char="10991">
<ORIGINAL_TEXT>Updated December 1, 2020</ORIGINAL_TEXT>
<TOKEN end_char="10997" id="token-92-0" morph="none" pos="word" start_char="10991">Updated</TOKEN>
<TOKEN end_char="11006" id="token-92-1" morph="none" pos="word" start_char="10999">December</TOKEN>
<TOKEN end_char="11008" id="token-92-2" morph="none" pos="word" start_char="11008">1</TOKEN>
<TOKEN end_char="11009" id="token-92-3" morph="none" pos="punct" start_char="11009">,</TOKEN>
<TOKEN end_char="11014" id="token-92-4" morph="none" pos="word" start_char="11011">2020</TOKEN>
</SEG>
<SEG end_char="11200" id="segment-93" start_char="11018">
<ORIGINAL_TEXT>A recurring suspicion about the SARS-CoV-2 virus, held by conspiracy groups, is that it is linked to the presence of a P4 laboratory in Wuhan, the city where the virus first appeared.</ORIGINAL_TEXT>
<TOKEN end_char="11018" id="token-93-0" morph="none" pos="word" start_char="11018">A</TOKEN>
<TOKEN end_char="11028" id="token-93-1" morph="none" pos="word" start_char="11020">recurring</TOKEN>
<TOKEN end_char="11038" id="token-93-2" morph="none" pos="word" start_char="11030">suspicion</TOKEN>
<TOKEN end_char="11044" id="token-93-3" morph="none" pos="word" start_char="11040">about</TOKEN>
<TOKEN end_char="11048" id="token-93-4" morph="none" pos="word" start_char="11046">the</TOKEN>
<TOKEN end_char="11059" id="token-93-5" morph="none" pos="unknown" start_char="11050">SARS-CoV-2</TOKEN>
<TOKEN end_char="11065" id="token-93-6" morph="none" pos="word" start_char="11061">virus</TOKEN>
<TOKEN end_char="11066" id="token-93-7" morph="none" pos="punct" start_char="11066">,</TOKEN>
<TOKEN end_char="11071" id="token-93-8" morph="none" pos="word" start_char="11068">held</TOKEN>
<TOKEN end_char="11074" id="token-93-9" morph="none" pos="word" start_char="11073">by</TOKEN>
<TOKEN end_char="11085" id="token-93-10" morph="none" pos="word" start_char="11076">conspiracy</TOKEN>
<TOKEN end_char="11092" id="token-93-11" morph="none" pos="word" start_char="11087">groups</TOKEN>
<TOKEN end_char="11093" id="token-93-12" morph="none" pos="punct" start_char="11093">,</TOKEN>
<TOKEN end_char="11096" id="token-93-13" morph="none" pos="word" start_char="11095">is</TOKEN>
<TOKEN end_char="11101" id="token-93-14" morph="none" pos="word" start_char="11098">that</TOKEN>
<TOKEN end_char="11104" id="token-93-15" morph="none" pos="word" start_char="11103">it</TOKEN>
<TOKEN end_char="11107" id="token-93-16" morph="none" pos="word" start_char="11106">is</TOKEN>
<TOKEN end_char="11114" id="token-93-17" morph="none" pos="word" start_char="11109">linked</TOKEN>
<TOKEN end_char="11117" id="token-93-18" morph="none" pos="word" start_char="11116">to</TOKEN>
<TOKEN end_char="11121" id="token-93-19" morph="none" pos="word" start_char="11119">the</TOKEN>
<TOKEN end_char="11130" id="token-93-20" morph="none" pos="word" start_char="11123">presence</TOKEN>
<TOKEN end_char="11133" id="token-93-21" morph="none" pos="word" start_char="11132">of</TOKEN>
<TOKEN end_char="11135" id="token-93-22" morph="none" pos="word" start_char="11135">a</TOKEN>
<TOKEN end_char="11138" id="token-93-23" morph="none" pos="word" start_char="11137">P4</TOKEN>
<TOKEN end_char="11149" id="token-93-24" morph="none" pos="word" start_char="11140">laboratory</TOKEN>
<TOKEN end_char="11152" id="token-93-25" morph="none" pos="word" start_char="11151">in</TOKEN>
<TOKEN end_char="11158" id="token-93-26" morph="none" pos="word" start_char="11154">Wuhan</TOKEN>
<TOKEN end_char="11159" id="token-93-27" morph="none" pos="punct" start_char="11159">,</TOKEN>
<TOKEN end_char="11163" id="token-93-28" morph="none" pos="word" start_char="11161">the</TOKEN>
<TOKEN end_char="11168" id="token-93-29" morph="none" pos="word" start_char="11165">city</TOKEN>
<TOKEN end_char="11174" id="token-93-30" morph="none" pos="word" start_char="11170">where</TOKEN>
<TOKEN end_char="11178" id="token-93-31" morph="none" pos="word" start_char="11176">the</TOKEN>
<TOKEN end_char="11184" id="token-93-32" morph="none" pos="word" start_char="11180">virus</TOKEN>
<TOKEN end_char="11190" id="token-93-33" morph="none" pos="word" start_char="11186">first</TOKEN>
<TOKEN end_char="11199" id="token-93-34" morph="none" pos="word" start_char="11192">appeared</TOKEN>
<TOKEN end_char="11200" id="token-93-35" morph="none" pos="punct" start_char="11200">.</TOKEN>
</SEG>
<SEG end_char="11355" id="segment-94" start_char="11202">
<ORIGINAL_TEXT>According to conspiracy groups, SARS-CoV-2 was spread when a bat, on which tests had been performed, escaped, and the Institut Pasteur was linked to this.</ORIGINAL_TEXT>
<TOKEN end_char="11210" id="token-94-0" morph="none" pos="word" start_char="11202">According</TOKEN>
<TOKEN end_char="11213" id="token-94-1" morph="none" pos="word" start_char="11212">to</TOKEN>
<TOKEN end_char="11224" id="token-94-2" morph="none" pos="word" start_char="11215">conspiracy</TOKEN>
<TOKEN end_char="11231" id="token-94-3" morph="none" pos="word" start_char="11226">groups</TOKEN>
<TOKEN end_char="11232" id="token-94-4" morph="none" pos="punct" start_char="11232">,</TOKEN>
<TOKEN end_char="11243" id="token-94-5" morph="none" pos="unknown" start_char="11234">SARS-CoV-2</TOKEN>
<TOKEN end_char="11247" id="token-94-6" morph="none" pos="word" start_char="11245">was</TOKEN>
<TOKEN end_char="11254" id="token-94-7" morph="none" pos="word" start_char="11249">spread</TOKEN>
<TOKEN end_char="11259" id="token-94-8" morph="none" pos="word" start_char="11256">when</TOKEN>
<TOKEN end_char="11261" id="token-94-9" morph="none" pos="word" start_char="11261">a</TOKEN>
<TOKEN end_char="11265" id="token-94-10" morph="none" pos="word" start_char="11263">bat</TOKEN>
<TOKEN end_char="11266" id="token-94-11" morph="none" pos="punct" start_char="11266">,</TOKEN>
<TOKEN end_char="11269" id="token-94-12" morph="none" pos="word" start_char="11268">on</TOKEN>
<TOKEN end_char="11275" id="token-94-13" morph="none" pos="word" start_char="11271">which</TOKEN>
<TOKEN end_char="11281" id="token-94-14" morph="none" pos="word" start_char="11277">tests</TOKEN>
<TOKEN end_char="11285" id="token-94-15" morph="none" pos="word" start_char="11283">had</TOKEN>
<TOKEN end_char="11290" id="token-94-16" morph="none" pos="word" start_char="11287">been</TOKEN>
<TOKEN end_char="11300" id="token-94-17" morph="none" pos="word" start_char="11292">performed</TOKEN>
<TOKEN end_char="11301" id="token-94-18" morph="none" pos="punct" start_char="11301">,</TOKEN>
<TOKEN end_char="11309" id="token-94-19" morph="none" pos="word" start_char="11303">escaped</TOKEN>
<TOKEN end_char="11310" id="token-94-20" morph="none" pos="punct" start_char="11310">,</TOKEN>
<TOKEN end_char="11314" id="token-94-21" morph="none" pos="word" start_char="11312">and</TOKEN>
<TOKEN end_char="11318" id="token-94-22" morph="none" pos="word" start_char="11316">the</TOKEN>
<TOKEN end_char="11327" id="token-94-23" morph="none" pos="word" start_char="11320">Institut</TOKEN>
<TOKEN end_char="11335" id="token-94-24" morph="none" pos="word" start_char="11329">Pasteur</TOKEN>
<TOKEN end_char="11339" id="token-94-25" morph="none" pos="word" start_char="11337">was</TOKEN>
<TOKEN end_char="11346" id="token-94-26" morph="none" pos="word" start_char="11341">linked</TOKEN>
<TOKEN end_char="11349" id="token-94-27" morph="none" pos="word" start_char="11348">to</TOKEN>
<TOKEN end_char="11354" id="token-94-28" morph="none" pos="word" start_char="11351">this</TOKEN>
<TOKEN end_char="11355" id="token-94-29" morph="none" pos="punct" start_char="11355">.</TOKEN>
</SEG>
<SEG end_char="11381" id="segment-95" start_char="11357">
<ORIGINAL_TEXT>This is completely false.</ORIGINAL_TEXT>
<TOKEN end_char="11360" id="token-95-0" morph="none" pos="word" start_char="11357">This</TOKEN>
<TOKEN end_char="11363" id="token-95-1" morph="none" pos="word" start_char="11362">is</TOKEN>
<TOKEN end_char="11374" id="token-95-2" morph="none" pos="word" start_char="11365">completely</TOKEN>
<TOKEN end_char="11380" id="token-95-3" morph="none" pos="word" start_char="11376">false</TOKEN>
<TOKEN end_char="11381" id="token-95-4" morph="none" pos="punct" start_char="11381">.</TOKEN>
</SEG>
<SEG end_char="11416" id="segment-96" start_char="11383">
<ORIGINAL_TEXT>There are four things to remember:</ORIGINAL_TEXT>
<TOKEN end_char="11387" id="token-96-0" morph="none" pos="word" start_char="11383">There</TOKEN>
<TOKEN end_char="11391" id="token-96-1" morph="none" pos="word" start_char="11389">are</TOKEN>
<TOKEN end_char="11396" id="token-96-2" morph="none" pos="word" start_char="11393">four</TOKEN>
<TOKEN end_char="11403" id="token-96-3" morph="none" pos="word" start_char="11398">things</TOKEN>
<TOKEN end_char="11406" id="token-96-4" morph="none" pos="word" start_char="11405">to</TOKEN>
<TOKEN end_char="11415" id="token-96-5" morph="none" pos="word" start_char="11408">remember</TOKEN>
<TOKEN end_char="11416" id="token-96-6" morph="none" pos="punct" start_char="11416">:</TOKEN>
</SEG>
<SEG end_char="11490" id="segment-97" start_char="11420">
<ORIGINAL_TEXT>There is no evidence that SARS-CoV-2 coronavirus was created by humans.</ORIGINAL_TEXT>
<TOKEN end_char="11424" id="token-97-0" morph="none" pos="word" start_char="11420">There</TOKEN>
<TOKEN end_char="11427" id="token-97-1" morph="none" pos="word" start_char="11426">is</TOKEN>
<TOKEN end_char="11430" id="token-97-2" morph="none" pos="word" start_char="11429">no</TOKEN>
<TOKEN end_char="11439" id="token-97-3" morph="none" pos="word" start_char="11432">evidence</TOKEN>
<TOKEN end_char="11444" id="token-97-4" morph="none" pos="word" start_char="11441">that</TOKEN>
<TOKEN end_char="11455" id="token-97-5" morph="none" pos="unknown" start_char="11446">SARS-CoV-2</TOKEN>
<TOKEN end_char="11467" id="token-97-6" morph="none" pos="word" start_char="11457">coronavirus</TOKEN>
<TOKEN end_char="11471" id="token-97-7" morph="none" pos="word" start_char="11469">was</TOKEN>
<TOKEN end_char="11479" id="token-97-8" morph="none" pos="word" start_char="11473">created</TOKEN>
<TOKEN end_char="11482" id="token-97-9" morph="none" pos="word" start_char="11481">by</TOKEN>
<TOKEN end_char="11489" id="token-97-10" morph="none" pos="word" start_char="11484">humans</TOKEN>
<TOKEN end_char="11490" id="token-97-11" morph="none" pos="punct" start_char="11490">.</TOKEN>
</SEG>
<SEG end_char="11640" id="segment-98" start_char="11496">
<ORIGINAL_TEXT>The P4 laboratory in the city of Wuhan, where the virus SARS-CoV-2 first appeared, has nothing to do with the Institut Pasteur of Shanghai (IPS).</ORIGINAL_TEXT>
<TOKEN end_char="11498" id="token-98-0" morph="none" pos="word" start_char="11496">The</TOKEN>
<TOKEN end_char="11501" id="token-98-1" morph="none" pos="word" start_char="11500">P4</TOKEN>
<TOKEN end_char="11512" id="token-98-2" morph="none" pos="word" start_char="11503">laboratory</TOKEN>
<TOKEN end_char="11515" id="token-98-3" morph="none" pos="word" start_char="11514">in</TOKEN>
<TOKEN end_char="11519" id="token-98-4" morph="none" pos="word" start_char="11517">the</TOKEN>
<TOKEN end_char="11524" id="token-98-5" morph="none" pos="word" start_char="11521">city</TOKEN>
<TOKEN end_char="11527" id="token-98-6" morph="none" pos="word" start_char="11526">of</TOKEN>
<TOKEN end_char="11533" id="token-98-7" morph="none" pos="word" start_char="11529">Wuhan</TOKEN>
<TOKEN end_char="11534" id="token-98-8" morph="none" pos="punct" start_char="11534">,</TOKEN>
<TOKEN end_char="11540" id="token-98-9" morph="none" pos="word" start_char="11536">where</TOKEN>
<TOKEN end_char="11544" id="token-98-10" morph="none" pos="word" start_char="11542">the</TOKEN>
<TOKEN end_char="11550" id="token-98-11" morph="none" pos="word" start_char="11546">virus</TOKEN>
<TOKEN end_char="11561" id="token-98-12" morph="none" pos="unknown" start_char="11552">SARS-CoV-2</TOKEN>
<TOKEN end_char="11567" id="token-98-13" morph="none" pos="word" start_char="11563">first</TOKEN>
<TOKEN end_char="11576" id="token-98-14" morph="none" pos="word" start_char="11569">appeared</TOKEN>
<TOKEN end_char="11577" id="token-98-15" morph="none" pos="punct" start_char="11577">,</TOKEN>
<TOKEN end_char="11581" id="token-98-16" morph="none" pos="word" start_char="11579">has</TOKEN>
<TOKEN end_char="11589" id="token-98-17" morph="none" pos="word" start_char="11583">nothing</TOKEN>
<TOKEN end_char="11592" id="token-98-18" morph="none" pos="word" start_char="11591">to</TOKEN>
<TOKEN end_char="11595" id="token-98-19" morph="none" pos="word" start_char="11594">do</TOKEN>
<TOKEN end_char="11600" id="token-98-20" morph="none" pos="word" start_char="11597">with</TOKEN>
<TOKEN end_char="11604" id="token-98-21" morph="none" pos="word" start_char="11602">the</TOKEN>
<TOKEN end_char="11613" id="token-98-22" morph="none" pos="word" start_char="11606">Institut</TOKEN>
<TOKEN end_char="11621" id="token-98-23" morph="none" pos="word" start_char="11615">Pasteur</TOKEN>
<TOKEN end_char="11624" id="token-98-24" morph="none" pos="word" start_char="11623">of</TOKEN>
<TOKEN end_char="11633" id="token-98-25" morph="none" pos="word" start_char="11626">Shanghai</TOKEN>
<TOKEN end_char="11635" id="token-98-26" morph="none" pos="punct" start_char="11635">(</TOKEN>
<TOKEN end_char="11638" id="token-98-27" morph="none" pos="word" start_char="11636">IPS</TOKEN>
<TOKEN end_char="11640" id="token-98-28" morph="none" pos="punct" start_char="11639">).</TOKEN>
</SEG>
<SEG end_char="11792" id="segment-99" start_char="11646">
<ORIGINAL_TEXT>This hearsay has no link with the previous work of the Institut Pasteur (Paris) on SARS-CoV-1, the coronavirus that appeared in China in 2002-2003.</ORIGINAL_TEXT>
<TOKEN end_char="11649" id="token-99-0" morph="none" pos="word" start_char="11646">This</TOKEN>
<TOKEN end_char="11657" id="token-99-1" morph="none" pos="word" start_char="11651">hearsay</TOKEN>
<TOKEN end_char="11661" id="token-99-2" morph="none" pos="word" start_char="11659">has</TOKEN>
<TOKEN end_char="11664" id="token-99-3" morph="none" pos="word" start_char="11663">no</TOKEN>
<TOKEN end_char="11669" id="token-99-4" morph="none" pos="word" start_char="11666">link</TOKEN>
<TOKEN end_char="11674" id="token-99-5" morph="none" pos="word" start_char="11671">with</TOKEN>
<TOKEN end_char="11678" id="token-99-6" morph="none" pos="word" start_char="11676">the</TOKEN>
<TOKEN end_char="11687" id="token-99-7" morph="none" pos="word" start_char="11680">previous</TOKEN>
<TOKEN end_char="11692" id="token-99-8" morph="none" pos="word" start_char="11689">work</TOKEN>
<TOKEN end_char="11695" id="token-99-9" morph="none" pos="word" start_char="11694">of</TOKEN>
<TOKEN end_char="11699" id="token-99-10" morph="none" pos="word" start_char="11697">the</TOKEN>
<TOKEN end_char="11708" id="token-99-11" morph="none" pos="word" start_char="11701">Institut</TOKEN>
<TOKEN end_char="11716" id="token-99-12" morph="none" pos="word" start_char="11710">Pasteur</TOKEN>
<TOKEN end_char="11718" id="token-99-13" morph="none" pos="punct" start_char="11718">(</TOKEN>
<TOKEN end_char="11723" id="token-99-14" morph="none" pos="word" start_char="11719">Paris</TOKEN>
<TOKEN end_char="11724" id="token-99-15" morph="none" pos="punct" start_char="11724">)</TOKEN>
<TOKEN end_char="11727" id="token-99-16" morph="none" pos="word" start_char="11726">on</TOKEN>
<TOKEN end_char="11738" id="token-99-17" morph="none" pos="unknown" start_char="11729">SARS-CoV-1</TOKEN>
<TOKEN end_char="11739" id="token-99-18" morph="none" pos="punct" start_char="11739">,</TOKEN>
<TOKEN end_char="11743" id="token-99-19" morph="none" pos="word" start_char="11741">the</TOKEN>
<TOKEN end_char="11755" id="token-99-20" morph="none" pos="word" start_char="11745">coronavirus</TOKEN>
<TOKEN end_char="11760" id="token-99-21" morph="none" pos="word" start_char="11757">that</TOKEN>
<TOKEN end_char="11769" id="token-99-22" morph="none" pos="word" start_char="11762">appeared</TOKEN>
<TOKEN end_char="11772" id="token-99-23" morph="none" pos="word" start_char="11771">in</TOKEN>
<TOKEN end_char="11778" id="token-99-24" morph="none" pos="word" start_char="11774">China</TOKEN>
<TOKEN end_char="11781" id="token-99-25" morph="none" pos="word" start_char="11780">in</TOKEN>
<TOKEN end_char="11791" id="token-99-26" morph="none" pos="unknown" start_char="11783">2002-2003</TOKEN>
<TOKEN end_char="11792" id="token-99-27" morph="none" pos="punct" start_char="11792">.</TOKEN>
</SEG>
<SEG end_char="11906" id="segment-100" start_char="11798">
<ORIGINAL_TEXT>The videos based on this conspiracy theory, which are currently circulating on the web, are completely false.</ORIGINAL_TEXT>
<TOKEN end_char="11800" id="token-100-0" morph="none" pos="word" start_char="11798">The</TOKEN>
<TOKEN end_char="11807" id="token-100-1" morph="none" pos="word" start_char="11802">videos</TOKEN>
<TOKEN end_char="11813" id="token-100-2" morph="none" pos="word" start_char="11809">based</TOKEN>
<TOKEN end_char="11816" id="token-100-3" morph="none" pos="word" start_char="11815">on</TOKEN>
<TOKEN end_char="11821" id="token-100-4" morph="none" pos="word" start_char="11818">this</TOKEN>
<TOKEN end_char="11832" id="token-100-5" morph="none" pos="word" start_char="11823">conspiracy</TOKEN>
<TOKEN end_char="11839" id="token-100-6" morph="none" pos="word" start_char="11834">theory</TOKEN>
<TOKEN end_char="11840" id="token-100-7" morph="none" pos="punct" start_char="11840">,</TOKEN>
<TOKEN end_char="11846" id="token-100-8" morph="none" pos="word" start_char="11842">which</TOKEN>
<TOKEN end_char="11850" id="token-100-9" morph="none" pos="word" start_char="11848">are</TOKEN>
<TOKEN end_char="11860" id="token-100-10" morph="none" pos="word" start_char="11852">currently</TOKEN>
<TOKEN end_char="11872" id="token-100-11" morph="none" pos="word" start_char="11862">circulating</TOKEN>
<TOKEN end_char="11875" id="token-100-12" morph="none" pos="word" start_char="11874">on</TOKEN>
<TOKEN end_char="11879" id="token-100-13" morph="none" pos="word" start_char="11877">the</TOKEN>
<TOKEN end_char="11883" id="token-100-14" morph="none" pos="word" start_char="11881">web</TOKEN>
<TOKEN end_char="11884" id="token-100-15" morph="none" pos="punct" start_char="11884">,</TOKEN>
<TOKEN end_char="11888" id="token-100-16" morph="none" pos="word" start_char="11886">are</TOKEN>
<TOKEN end_char="11899" id="token-100-17" morph="none" pos="word" start_char="11890">completely</TOKEN>
<TOKEN end_char="11905" id="token-100-18" morph="none" pos="word" start_char="11901">false</TOKEN>
<TOKEN end_char="11906" id="token-100-19" morph="none" pos="punct" start_char="11906">.</TOKEN>
</SEG>
<SEG end_char="11923" id="segment-101" start_char="11912">
<ORIGINAL_TEXT>Explanations</ORIGINAL_TEXT>
<TOKEN end_char="11923" id="token-101-0" morph="none" pos="word" start_char="11912">Explanations</TOKEN>
</SEG>
<SEG end_char="12001" id="segment-102" start_char="11927">
<ORIGINAL_TEXT>1 _ There is no evidence that SARS-CoV-2 coronavirus was created by humans.</ORIGINAL_TEXT>
<TOKEN end_char="11927" id="token-102-0" morph="none" pos="word" start_char="11927">1</TOKEN>
<TOKEN end_char="11929" id="token-102-1" morph="none" pos="word" start_char="11929">_</TOKEN>
<TOKEN end_char="11935" id="token-102-2" morph="none" pos="word" start_char="11931">There</TOKEN>
<TOKEN end_char="11938" id="token-102-3" morph="none" pos="word" start_char="11937">is</TOKEN>
<TOKEN end_char="11941" id="token-102-4" morph="none" pos="word" start_char="11940">no</TOKEN>
<TOKEN end_char="11950" id="token-102-5" morph="none" pos="word" start_char="11943">evidence</TOKEN>
<TOKEN end_char="11955" id="token-102-6" morph="none" pos="word" start_char="11952">that</TOKEN>
<TOKEN end_char="11966" id="token-102-7" morph="none" pos="unknown" start_char="11957">SARS-CoV-2</TOKEN>
<TOKEN end_char="11978" id="token-102-8" morph="none" pos="word" start_char="11968">coronavirus</TOKEN>
<TOKEN end_char="11982" id="token-102-9" morph="none" pos="word" start_char="11980">was</TOKEN>
<TOKEN end_char="11990" id="token-102-10" morph="none" pos="word" start_char="11984">created</TOKEN>
<TOKEN end_char="11993" id="token-102-11" morph="none" pos="word" start_char="11992">by</TOKEN>
<TOKEN end_char="12000" id="token-102-12" morph="none" pos="word" start_char="11995">humans</TOKEN>
<TOKEN end_char="12001" id="token-102-13" morph="none" pos="punct" start_char="12001">.</TOKEN>
</SEG>
<SEG end_char="12124" id="segment-103" start_char="12005">
<ORIGINAL_TEXT>A scientific article published on March 17, 2020 disproved the idea that this virus resulted from a laboratory creation.</ORIGINAL_TEXT>
<TOKEN end_char="12005" id="token-103-0" morph="none" pos="word" start_char="12005">A</TOKEN>
<TOKEN end_char="12016" id="token-103-1" morph="none" pos="word" start_char="12007">scientific</TOKEN>
<TOKEN end_char="12024" id="token-103-2" morph="none" pos="word" start_char="12018">article</TOKEN>
<TOKEN end_char="12034" id="token-103-3" morph="none" pos="word" start_char="12026">published</TOKEN>
<TOKEN end_char="12037" id="token-103-4" morph="none" pos="word" start_char="12036">on</TOKEN>
<TOKEN end_char="12043" id="token-103-5" morph="none" pos="word" start_char="12039">March</TOKEN>
<TOKEN end_char="12046" id="token-103-6" morph="none" pos="word" start_char="12045">17</TOKEN>
<TOKEN end_char="12047" id="token-103-7" morph="none" pos="punct" start_char="12047">,</TOKEN>
<TOKEN end_char="12052" id="token-103-8" morph="none" pos="word" start_char="12049">2020</TOKEN>
<TOKEN end_char="12062" id="token-103-9" morph="none" pos="word" start_char="12054">disproved</TOKEN>
<TOKEN end_char="12066" id="token-103-10" morph="none" pos="word" start_char="12064">the</TOKEN>
<TOKEN end_char="12071" id="token-103-11" morph="none" pos="word" start_char="12068">idea</TOKEN>
<TOKEN end_char="12076" id="token-103-12" morph="none" pos="word" start_char="12073">that</TOKEN>
<TOKEN end_char="12081" id="token-103-13" morph="none" pos="word" start_char="12078">this</TOKEN>
<TOKEN end_char="12087" id="token-103-14" morph="none" pos="word" start_char="12083">virus</TOKEN>
<TOKEN end_char="12096" id="token-103-15" morph="none" pos="word" start_char="12089">resulted</TOKEN>
<TOKEN end_char="12101" id="token-103-16" morph="none" pos="word" start_char="12098">from</TOKEN>
<TOKEN end_char="12103" id="token-103-17" morph="none" pos="word" start_char="12103">a</TOKEN>
<TOKEN end_char="12114" id="token-103-18" morph="none" pos="word" start_char="12105">laboratory</TOKEN>
<TOKEN end_char="12123" id="token-103-19" morph="none" pos="word" start_char="12116">creation</TOKEN>
<TOKEN end_char="12124" id="token-103-20" morph="none" pos="punct" start_char="12124">.</TOKEN>
</SEG>
<SEG end_char="12261" id="segment-104" start_char="12126">
<ORIGINAL_TEXT>In the study, the researchers examined what could be deduced from the origin of SARS-CoV-2, from a comparative analysis of genetic data.</ORIGINAL_TEXT>
<TOKEN end_char="12127" id="token-104-0" morph="none" pos="word" start_char="12126">In</TOKEN>
<TOKEN end_char="12131" id="token-104-1" morph="none" pos="word" start_char="12129">the</TOKEN>
<TOKEN end_char="12137" id="token-104-2" morph="none" pos="word" start_char="12133">study</TOKEN>
<TOKEN end_char="12138" id="token-104-3" morph="none" pos="punct" start_char="12138">,</TOKEN>
<TOKEN end_char="12142" id="token-104-4" morph="none" pos="word" start_char="12140">the</TOKEN>
<TOKEN end_char="12154" id="token-104-5" morph="none" pos="word" start_char="12144">researchers</TOKEN>
<TOKEN end_char="12163" id="token-104-6" morph="none" pos="word" start_char="12156">examined</TOKEN>
<TOKEN end_char="12168" id="token-104-7" morph="none" pos="word" start_char="12165">what</TOKEN>
<TOKEN end_char="12174" id="token-104-8" morph="none" pos="word" start_char="12170">could</TOKEN>
<TOKEN end_char="12177" id="token-104-9" morph="none" pos="word" start_char="12176">be</TOKEN>
<TOKEN end_char="12185" id="token-104-10" morph="none" pos="word" start_char="12179">deduced</TOKEN>
<TOKEN end_char="12190" id="token-104-11" morph="none" pos="word" start_char="12187">from</TOKEN>
<TOKEN end_char="12194" id="token-104-12" morph="none" pos="word" start_char="12192">the</TOKEN>
<TOKEN end_char="12201" id="token-104-13" morph="none" pos="word" start_char="12196">origin</TOKEN>
<TOKEN end_char="12204" id="token-104-14" morph="none" pos="word" start_char="12203">of</TOKEN>
<TOKEN end_char="12215" id="token-104-15" morph="none" pos="unknown" start_char="12206">SARS-CoV-2</TOKEN>
<TOKEN end_char="12216" id="token-104-16" morph="none" pos="punct" start_char="12216">,</TOKEN>
<TOKEN end_char="12221" id="token-104-17" morph="none" pos="word" start_char="12218">from</TOKEN>
<TOKEN end_char="12223" id="token-104-18" morph="none" pos="word" start_char="12223">a</TOKEN>
<TOKEN end_char="12235" id="token-104-19" morph="none" pos="word" start_char="12225">comparative</TOKEN>
<TOKEN end_char="12244" id="token-104-20" morph="none" pos="word" start_char="12237">analysis</TOKEN>
<TOKEN end_char="12247" id="token-104-21" morph="none" pos="word" start_char="12246">of</TOKEN>
<TOKEN end_char="12255" id="token-104-22" morph="none" pos="word" start_char="12249">genetic</TOKEN>
<TOKEN end_char="12260" id="token-104-23" morph="none" pos="word" start_char="12257">data</TOKEN>
<TOKEN end_char="12261" id="token-104-24" morph="none" pos="punct" start_char="12261">.</TOKEN>
</SEG>
<SEG end_char="12392" id="segment-105" start_char="12263">
<ORIGINAL_TEXT>In the article, they describe the notable characteristics of its genome and discuss the scenarios in which it could have occurred.</ORIGINAL_TEXT>
<TOKEN end_char="12264" id="token-105-0" morph="none" pos="word" start_char="12263">In</TOKEN>
<TOKEN end_char="12268" id="token-105-1" morph="none" pos="word" start_char="12266">the</TOKEN>
<TOKEN end_char="12276" id="token-105-2" morph="none" pos="word" start_char="12270">article</TOKEN>
<TOKEN end_char="12277" id="token-105-3" morph="none" pos="punct" start_char="12277">,</TOKEN>
<TOKEN end_char="12282" id="token-105-4" morph="none" pos="word" start_char="12279">they</TOKEN>
<TOKEN end_char="12291" id="token-105-5" morph="none" pos="word" start_char="12284">describe</TOKEN>
<TOKEN end_char="12295" id="token-105-6" morph="none" pos="word" start_char="12293">the</TOKEN>
<TOKEN end_char="12303" id="token-105-7" morph="none" pos="word" start_char="12297">notable</TOKEN>
<TOKEN end_char="12319" id="token-105-8" morph="none" pos="word" start_char="12305">characteristics</TOKEN>
<TOKEN end_char="12322" id="token-105-9" morph="none" pos="word" start_char="12321">of</TOKEN>
<TOKEN end_char="12326" id="token-105-10" morph="none" pos="word" start_char="12324">its</TOKEN>
<TOKEN end_char="12333" id="token-105-11" morph="none" pos="word" start_char="12328">genome</TOKEN>
<TOKEN end_char="12337" id="token-105-12" morph="none" pos="word" start_char="12335">and</TOKEN>
<TOKEN end_char="12345" id="token-105-13" morph="none" pos="word" start_char="12339">discuss</TOKEN>
<TOKEN end_char="12349" id="token-105-14" morph="none" pos="word" start_char="12347">the</TOKEN>
<TOKEN end_char="12359" id="token-105-15" morph="none" pos="word" start_char="12351">scenarios</TOKEN>
<TOKEN end_char="12362" id="token-105-16" morph="none" pos="word" start_char="12361">in</TOKEN>
<TOKEN end_char="12368" id="token-105-17" morph="none" pos="word" start_char="12364">which</TOKEN>
<TOKEN end_char="12371" id="token-105-18" morph="none" pos="word" start_char="12370">it</TOKEN>
<TOKEN end_char="12377" id="token-105-19" morph="none" pos="word" start_char="12373">could</TOKEN>
<TOKEN end_char="12382" id="token-105-20" morph="none" pos="word" start_char="12379">have</TOKEN>
<TOKEN end_char="12391" id="token-105-21" morph="none" pos="word" start_char="12384">occurred</TOKEN>
<TOKEN end_char="12392" id="token-105-22" morph="none" pos="punct" start_char="12392">.</TOKEN>
</SEG>
<SEG end_char="12490" id="segment-106" start_char="12394">
<ORIGINAL_TEXT>Their analyses clearly show that there is no indication that SARS-CoV-2 could be a lab construct.</ORIGINAL_TEXT>
<TOKEN end_char="12398" id="token-106-0" morph="none" pos="word" start_char="12394">Their</TOKEN>
<TOKEN end_char="12407" id="token-106-1" morph="none" pos="word" start_char="12400">analyses</TOKEN>
<TOKEN end_char="12415" id="token-106-2" morph="none" pos="word" start_char="12409">clearly</TOKEN>
<TOKEN end_char="12420" id="token-106-3" morph="none" pos="word" start_char="12417">show</TOKEN>
<TOKEN end_char="12425" id="token-106-4" morph="none" pos="word" start_char="12422">that</TOKEN>
<TOKEN end_char="12431" id="token-106-5" morph="none" pos="word" start_char="12427">there</TOKEN>
<TOKEN end_char="12434" id="token-106-6" morph="none" pos="word" start_char="12433">is</TOKEN>
<TOKEN end_char="12437" id="token-106-7" morph="none" pos="word" start_char="12436">no</TOKEN>
<TOKEN end_char="12448" id="token-106-8" morph="none" pos="word" start_char="12439">indication</TOKEN>
<TOKEN end_char="12453" id="token-106-9" morph="none" pos="word" start_char="12450">that</TOKEN>
<TOKEN end_char="12464" id="token-106-10" morph="none" pos="unknown" start_char="12455">SARS-CoV-2</TOKEN>
<TOKEN end_char="12470" id="token-106-11" morph="none" pos="word" start_char="12466">could</TOKEN>
<TOKEN end_char="12473" id="token-106-12" morph="none" pos="word" start_char="12472">be</TOKEN>
<TOKEN end_char="12475" id="token-106-13" morph="none" pos="word" start_char="12475">a</TOKEN>
<TOKEN end_char="12479" id="token-106-14" morph="none" pos="word" start_char="12477">lab</TOKEN>
<TOKEN end_char="12489" id="token-106-15" morph="none" pos="word" start_char="12481">construct</TOKEN>
<TOKEN end_char="12490" id="token-106-16" morph="none" pos="punct" start_char="12490">.</TOKEN>
</SEG>
<SEG end_char="12589" id="segment-107" start_char="12493">
<ORIGINAL_TEXT>The proximal origin of SARS-CoV-2, Kristian G. Andersen, Andrew Rambaut, W. Ian Lipkin, Edward C.</ORIGINAL_TEXT>
<TOKEN end_char="12495" id="token-107-0" morph="none" pos="word" start_char="12493">The</TOKEN>
<TOKEN end_char="12504" id="token-107-1" morph="none" pos="word" start_char="12497">proximal</TOKEN>
<TOKEN end_char="12511" id="token-107-2" morph="none" pos="word" start_char="12506">origin</TOKEN>
<TOKEN end_char="12514" id="token-107-3" morph="none" pos="word" start_char="12513">of</TOKEN>
<TOKEN end_char="12525" id="token-107-4" morph="none" pos="unknown" start_char="12516">SARS-CoV-2</TOKEN>
<TOKEN end_char="12526" id="token-107-5" morph="none" pos="punct" start_char="12526">,</TOKEN>
<TOKEN end_char="12535" id="token-107-6" morph="none" pos="word" start_char="12528">Kristian</TOKEN>
<TOKEN end_char="12537" id="token-107-7" morph="none" pos="word" start_char="12537">G</TOKEN>
<TOKEN end_char="12538" id="token-107-8" morph="none" pos="punct" start_char="12538">.</TOKEN>
<TOKEN end_char="12547" id="token-107-9" morph="none" pos="word" start_char="12540">Andersen</TOKEN>
<TOKEN end_char="12548" id="token-107-10" morph="none" pos="punct" start_char="12548">,</TOKEN>
<TOKEN end_char="12555" id="token-107-11" morph="none" pos="word" start_char="12550">Andrew</TOKEN>
<TOKEN end_char="12563" id="token-107-12" morph="none" pos="word" start_char="12557">Rambaut</TOKEN>
<TOKEN end_char="12564" id="token-107-13" morph="none" pos="punct" start_char="12564">,</TOKEN>
<TOKEN end_char="12566" id="token-107-14" morph="none" pos="word" start_char="12566">W</TOKEN>
<TOKEN end_char="12567" id="token-107-15" morph="none" pos="punct" start_char="12567">.</TOKEN>
<TOKEN end_char="12571" id="token-107-16" morph="none" pos="word" start_char="12569">Ian</TOKEN>
<TOKEN end_char="12578" id="token-107-17" morph="none" pos="word" start_char="12573">Lipkin</TOKEN>
<TOKEN end_char="12579" id="token-107-18" morph="none" pos="punct" start_char="12579">,</TOKEN>
<TOKEN end_char="12586" id="token-107-19" morph="none" pos="word" start_char="12581">Edward</TOKEN>
<TOKEN end_char="12588" id="token-107-20" morph="none" pos="word" start_char="12588">C</TOKEN>
<TOKEN end_char="12589" id="token-107-21" morph="none" pos="punct" start_char="12589">.</TOKEN>
</SEG>
<SEG end_char="12606" id="segment-108" start_char="12591">
<ORIGINAL_TEXT>Holmes Robert F.</ORIGINAL_TEXT>
<TOKEN end_char="12596" id="token-108-0" morph="none" pos="word" start_char="12591">Holmes</TOKEN>
<TOKEN end_char="12603" id="token-108-1" morph="none" pos="word" start_char="12598">Robert</TOKEN>
<TOKEN end_char="12605" id="token-108-2" morph="none" pos="word" start_char="12605">F</TOKEN>
<TOKEN end_char="12606" id="token-108-3" morph="none" pos="punct" start_char="12606">.</TOKEN>
<TRANSLATED_TEXT>Holmes, Robert F.</TRANSLATED_TEXT><DETECTED_LANGUAGE>da</DETECTED_LANGUAGE></SEG>
<SEG end_char="12613" id="segment-109" start_char="12608">
<ORIGINAL_TEXT>Garry.</ORIGINAL_TEXT>
<TOKEN end_char="12612" id="token-109-0" morph="none" pos="word" start_char="12608">Garry</TOKEN>
<TOKEN end_char="12613" id="token-109-1" morph="none" pos="punct" start_char="12613">.</TOKEN>
<TRANSLATED_TEXT>- Garry.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="12630" id="segment-110" start_char="12616">
<ORIGINAL_TEXT>Nature Medicine</ORIGINAL_TEXT>
<TOKEN end_char="12621" id="token-110-0" morph="none" pos="word" start_char="12616">Nature</TOKEN>
<TOKEN end_char="12630" id="token-110-1" morph="none" pos="word" start_char="12623">Medicine</TOKEN>
<TRANSLATED_TEXT>Naturmedicin</TRANSLATED_TEXT><DETECTED_LANGUAGE>ro</DETECTED_LANGUAGE></SEG>
<SEG end_char="12638" id="segment-111" start_char="12633">
<ORIGINAL_TEXT>(2020)</ORIGINAL_TEXT>
<TOKEN end_char="12633" id="token-111-0" morph="none" pos="punct" start_char="12633">(</TOKEN>
<TOKEN end_char="12637" id="token-111-1" morph="none" pos="word" start_char="12634">2020</TOKEN>
<TOKEN end_char="12638" id="token-111-2" morph="none" pos="punct" start_char="12638">)</TOKEN>
</SEG>
<SEG end_char="12659" id="segment-112" start_char="12641">
<ORIGINAL_TEXT>Decryption by Prof.</ORIGINAL_TEXT>
<TOKEN end_char="12650" id="token-112-0" morph="none" pos="word" start_char="12641">Decryption</TOKEN>
<TOKEN end_char="12653" id="token-112-1" morph="none" pos="word" start_char="12652">by</TOKEN>
<TOKEN end_char="12658" id="token-112-2" morph="none" pos="word" start_char="12655">Prof</TOKEN>
<TOKEN end_char="12659" id="token-112-3" morph="none" pos="punct" start_char="12659">.</TOKEN>
</SEG>
<SEG end_char="12790" id="segment-113" start_char="12661">
<ORIGINAL_TEXT>Olivier Schwartz, former Scientific director of the Institut Pasteur (https://twitter.com/MinSoliSante/status/1240239777925881856)</ORIGINAL_TEXT>
<TOKEN end_char="12667" id="token-113-0" morph="none" pos="word" start_char="12661">Olivier</TOKEN>
<TOKEN end_char="12676" id="token-113-1" morph="none" pos="word" start_char="12669">Schwartz</TOKEN>
<TOKEN end_char="12677" id="token-113-2" morph="none" pos="punct" start_char="12677">,</TOKEN>
<TOKEN end_char="12684" id="token-113-3" morph="none" pos="word" start_char="12679">former</TOKEN>
<TOKEN end_char="12695" id="token-113-4" morph="none" pos="word" start_char="12686">Scientific</TOKEN>
<TOKEN end_char="12704" id="token-113-5" morph="none" pos="word" start_char="12697">director</TOKEN>
<TOKEN end_char="12707" id="token-113-6" morph="none" pos="word" start_char="12706">of</TOKEN>
<TOKEN end_char="12711" id="token-113-7" morph="none" pos="word" start_char="12709">the</TOKEN>
<TOKEN end_char="12720" id="token-113-8" morph="none" pos="word" start_char="12713">Institut</TOKEN>
<TOKEN end_char="12728" id="token-113-9" morph="none" pos="word" start_char="12722">Pasteur</TOKEN>
<TOKEN end_char="12730" id="token-113-10" morph="none" pos="punct" start_char="12730">(</TOKEN>
<TOKEN end_char="12789" id="token-113-11" morph="none" pos="unknown" start_char="12731">https://twitter.com/MinSoliSante/status/1240239777925881856</TOKEN>
<TOKEN end_char="12790" id="token-113-12" morph="none" pos="punct" start_char="12790">)</TOKEN>
</SEG>
<SEG end_char="12941" id="segment-114" start_char="12793">
<ORIGINAL_TEXT>2 _ The Institut Pasteur of Shanghai (IPS) did not work on coronaviruses in the P4 laboratory in Wuhan, which is associated with a Chinese institute.</ORIGINAL_TEXT>
<TOKEN end_char="12793" id="token-114-0" morph="none" pos="word" start_char="12793">2</TOKEN>
<TOKEN end_char="12795" id="token-114-1" morph="none" pos="word" start_char="12795">_</TOKEN>
<TOKEN end_char="12799" id="token-114-2" morph="none" pos="word" start_char="12797">The</TOKEN>
<TOKEN end_char="12808" id="token-114-3" morph="none" pos="word" start_char="12801">Institut</TOKEN>
<TOKEN end_char="12816" id="token-114-4" morph="none" pos="word" start_char="12810">Pasteur</TOKEN>
<TOKEN end_char="12819" id="token-114-5" morph="none" pos="word" start_char="12818">of</TOKEN>
<TOKEN end_char="12828" id="token-114-6" morph="none" pos="word" start_char="12821">Shanghai</TOKEN>
<TOKEN end_char="12830" id="token-114-7" morph="none" pos="punct" start_char="12830">(</TOKEN>
<TOKEN end_char="12833" id="token-114-8" morph="none" pos="word" start_char="12831">IPS</TOKEN>
<TOKEN end_char="12834" id="token-114-9" morph="none" pos="punct" start_char="12834">)</TOKEN>
<TOKEN end_char="12838" id="token-114-10" morph="none" pos="word" start_char="12836">did</TOKEN>
<TOKEN end_char="12842" id="token-114-11" morph="none" pos="word" start_char="12840">not</TOKEN>
<TOKEN end_char="12847" id="token-114-12" morph="none" pos="word" start_char="12844">work</TOKEN>
<TOKEN end_char="12850" id="token-114-13" morph="none" pos="word" start_char="12849">on</TOKEN>
<TOKEN end_char="12864" id="token-114-14" morph="none" pos="word" start_char="12852">coronaviruses</TOKEN>
<TOKEN end_char="12867" id="token-114-15" morph="none" pos="word" start_char="12866">in</TOKEN>
<TOKEN end_char="12871" id="token-114-16" morph="none" pos="word" start_char="12869">the</TOKEN>
<TOKEN end_char="12874" id="token-114-17" morph="none" pos="word" start_char="12873">P4</TOKEN>
<TOKEN end_char="12885" id="token-114-18" morph="none" pos="word" start_char="12876">laboratory</TOKEN>
<TOKEN end_char="12888" id="token-114-19" morph="none" pos="word" start_char="12887">in</TOKEN>
<TOKEN end_char="12894" id="token-114-20" morph="none" pos="word" start_char="12890">Wuhan</TOKEN>
<TOKEN end_char="12895" id="token-114-21" morph="none" pos="punct" start_char="12895">,</TOKEN>
<TOKEN end_char="12901" id="token-114-22" morph="none" pos="word" start_char="12897">which</TOKEN>
<TOKEN end_char="12904" id="token-114-23" morph="none" pos="word" start_char="12903">is</TOKEN>
<TOKEN end_char="12915" id="token-114-24" morph="none" pos="word" start_char="12906">associated</TOKEN>
<TOKEN end_char="12920" id="token-114-25" morph="none" pos="word" start_char="12917">with</TOKEN>
<TOKEN end_char="12922" id="token-114-26" morph="none" pos="word" start_char="12922">a</TOKEN>
<TOKEN end_char="12930" id="token-114-27" morph="none" pos="word" start_char="12924">Chinese</TOKEN>
<TOKEN end_char="12940" id="token-114-28" morph="none" pos="word" start_char="12932">institute</TOKEN>
<TOKEN end_char="12941" id="token-114-29" morph="none" pos="punct" start_char="12941">.</TOKEN>
</SEG>
<SEG end_char="13326" id="segment-115" start_char="12945">
<ORIGINAL_TEXT>Scientific collaboration with China, on the most dangerous pathogens (referred to as "class 4," denoting pathogens that can only be the object of research in extremely secure laboratories, designated as "P4"), and on emerging viruses, fits into the context of a French-Chinese agreement for preventing and combatting emerging infectious viruses, signed in Peking on October 9, 2004.</ORIGINAL_TEXT>
<TOKEN end_char="12954" id="token-115-0" morph="none" pos="word" start_char="12945">Scientific</TOKEN>
<TOKEN end_char="12968" id="token-115-1" morph="none" pos="word" start_char="12956">collaboration</TOKEN>
<TOKEN end_char="12973" id="token-115-2" morph="none" pos="word" start_char="12970">with</TOKEN>
<TOKEN end_char="12979" id="token-115-3" morph="none" pos="word" start_char="12975">China</TOKEN>
<TOKEN end_char="12980" id="token-115-4" morph="none" pos="punct" start_char="12980">,</TOKEN>
<TOKEN end_char="12983" id="token-115-5" morph="none" pos="word" start_char="12982">on</TOKEN>
<TOKEN end_char="12987" id="token-115-6" morph="none" pos="word" start_char="12985">the</TOKEN>
<TOKEN end_char="12992" id="token-115-7" morph="none" pos="word" start_char="12989">most</TOKEN>
<TOKEN end_char="13002" id="token-115-8" morph="none" pos="word" start_char="12994">dangerous</TOKEN>
<TOKEN end_char="13012" id="token-115-9" morph="none" pos="word" start_char="13004">pathogens</TOKEN>
<TOKEN end_char="13014" id="token-115-10" morph="none" pos="punct" start_char="13014">(</TOKEN>
<TOKEN end_char="13022" id="token-115-11" morph="none" pos="word" start_char="13015">referred</TOKEN>
<TOKEN end_char="13025" id="token-115-12" morph="none" pos="word" start_char="13024">to</TOKEN>
<TOKEN end_char="13028" id="token-115-13" morph="none" pos="word" start_char="13027">as</TOKEN>
<TOKEN end_char="13030" id="token-115-14" morph="none" pos="punct" start_char="13030">"</TOKEN>
<TOKEN end_char="13035" id="token-115-15" morph="none" pos="word" start_char="13031">class</TOKEN>
<TOKEN end_char="13037" id="token-115-16" morph="none" pos="word" start_char="13037">4</TOKEN>
<TOKEN end_char="13039" id="token-115-17" morph="none" pos="punct" start_char="13038">,"</TOKEN>
<TOKEN end_char="13048" id="token-115-18" morph="none" pos="word" start_char="13041">denoting</TOKEN>
<TOKEN end_char="13058" id="token-115-19" morph="none" pos="word" start_char="13050">pathogens</TOKEN>
<TOKEN end_char="13063" id="token-115-20" morph="none" pos="word" start_char="13060">that</TOKEN>
<TOKEN end_char="13067" id="token-115-21" morph="none" pos="word" start_char="13065">can</TOKEN>
<TOKEN end_char="13072" id="token-115-22" morph="none" pos="word" start_char="13069">only</TOKEN>
<TOKEN end_char="13075" id="token-115-23" morph="none" pos="word" start_char="13074">be</TOKEN>
<TOKEN end_char="13079" id="token-115-24" morph="none" pos="word" start_char="13077">the</TOKEN>
<TOKEN end_char="13086" id="token-115-25" morph="none" pos="word" start_char="13081">object</TOKEN>
<TOKEN end_char="13089" id="token-115-26" morph="none" pos="word" start_char="13088">of</TOKEN>
<TOKEN end_char="13098" id="token-115-27" morph="none" pos="word" start_char="13091">research</TOKEN>
<TOKEN end_char="13101" id="token-115-28" morph="none" pos="word" start_char="13100">in</TOKEN>
<TOKEN end_char="13111" id="token-115-29" morph="none" pos="word" start_char="13103">extremely</TOKEN>
<TOKEN end_char="13118" id="token-115-30" morph="none" pos="word" start_char="13113">secure</TOKEN>
<TOKEN end_char="13131" id="token-115-31" morph="none" pos="word" start_char="13120">laboratories</TOKEN>
<TOKEN end_char="13132" id="token-115-32" morph="none" pos="punct" start_char="13132">,</TOKEN>
<TOKEN end_char="13143" id="token-115-33" morph="none" pos="word" start_char="13134">designated</TOKEN>
<TOKEN end_char="13146" id="token-115-34" morph="none" pos="word" start_char="13145">as</TOKEN>
<TOKEN end_char="13148" id="token-115-35" morph="none" pos="punct" start_char="13148">"</TOKEN>
<TOKEN end_char="13150" id="token-115-36" morph="none" pos="word" start_char="13149">P4</TOKEN>
<TOKEN end_char="13153" id="token-115-37" morph="none" pos="punct" start_char="13151">"),</TOKEN>
<TOKEN end_char="13157" id="token-115-38" morph="none" pos="word" start_char="13155">and</TOKEN>
<TOKEN end_char="13160" id="token-115-39" morph="none" pos="word" start_char="13159">on</TOKEN>
<TOKEN end_char="13169" id="token-115-40" morph="none" pos="word" start_char="13162">emerging</TOKEN>
<TOKEN end_char="13177" id="token-115-41" morph="none" pos="word" start_char="13171">viruses</TOKEN>
<TOKEN end_char="13178" id="token-115-42" morph="none" pos="punct" start_char="13178">,</TOKEN>
<TOKEN end_char="13183" id="token-115-43" morph="none" pos="word" start_char="13180">fits</TOKEN>
<TOKEN end_char="13188" id="token-115-44" morph="none" pos="word" start_char="13185">into</TOKEN>
<TOKEN end_char="13192" id="token-115-45" morph="none" pos="word" start_char="13190">the</TOKEN>
<TOKEN end_char="13200" id="token-115-46" morph="none" pos="word" start_char="13194">context</TOKEN>
<TOKEN end_char="13203" id="token-115-47" morph="none" pos="word" start_char="13202">of</TOKEN>
<TOKEN end_char="13205" id="token-115-48" morph="none" pos="word" start_char="13205">a</TOKEN>
<TOKEN end_char="13220" id="token-115-49" morph="none" pos="unknown" start_char="13207">French-Chinese</TOKEN>
<TOKEN end_char="13230" id="token-115-50" morph="none" pos="word" start_char="13222">agreement</TOKEN>
<TOKEN end_char="13234" id="token-115-51" morph="none" pos="word" start_char="13232">for</TOKEN>
<TOKEN end_char="13245" id="token-115-52" morph="none" pos="word" start_char="13236">preventing</TOKEN>
<TOKEN end_char="13249" id="token-115-53" morph="none" pos="word" start_char="13247">and</TOKEN>
<TOKEN end_char="13260" id="token-115-54" morph="none" pos="word" start_char="13251">combatting</TOKEN>
<TOKEN end_char="13269" id="token-115-55" morph="none" pos="word" start_char="13262">emerging</TOKEN>
<TOKEN end_char="13280" id="token-115-56" morph="none" pos="word" start_char="13271">infectious</TOKEN>
<TOKEN end_char="13288" id="token-115-57" morph="none" pos="word" start_char="13282">viruses</TOKEN>
<TOKEN end_char="13289" id="token-115-58" morph="none" pos="punct" start_char="13289">,</TOKEN>
<TOKEN end_char="13296" id="token-115-59" morph="none" pos="word" start_char="13291">signed</TOKEN>
<TOKEN end_char="13299" id="token-115-60" morph="none" pos="word" start_char="13298">in</TOKEN>
<TOKEN end_char="13306" id="token-115-61" morph="none" pos="word" start_char="13301">Peking</TOKEN>
<TOKEN end_char="13309" id="token-115-62" morph="none" pos="word" start_char="13308">on</TOKEN>
<TOKEN end_char="13317" id="token-115-63" morph="none" pos="word" start_char="13311">October</TOKEN>
<TOKEN end_char="13319" id="token-115-64" morph="none" pos="word" start_char="13319">9</TOKEN>
<TOKEN end_char="13320" id="token-115-65" morph="none" pos="punct" start_char="13320">,</TOKEN>
<TOKEN end_char="13325" id="token-115-66" morph="none" pos="word" start_char="13322">2004</TOKEN>
<TOKEN end_char="13326" id="token-115-67" morph="none" pos="punct" start_char="13326">.</TOKEN>
</SEG>
<SEG end_char="13547" id="segment-116" start_char="13329">
<ORIGINAL_TEXT>It also fits into the context of the International Health Regulations of 2005, which entered into affect after the agreement, that uphold the principle of containment at source in the battle against infectious diseases.</ORIGINAL_TEXT>
<TOKEN end_char="13330" id="token-116-0" morph="none" pos="word" start_char="13329">It</TOKEN>
<TOKEN end_char="13335" id="token-116-1" morph="none" pos="word" start_char="13332">also</TOKEN>
<TOKEN end_char="13340" id="token-116-2" morph="none" pos="word" start_char="13337">fits</TOKEN>
<TOKEN end_char="13345" id="token-116-3" morph="none" pos="word" start_char="13342">into</TOKEN>
<TOKEN end_char="13349" id="token-116-4" morph="none" pos="word" start_char="13347">the</TOKEN>
<TOKEN end_char="13357" id="token-116-5" morph="none" pos="word" start_char="13351">context</TOKEN>
<TOKEN end_char="13360" id="token-116-6" morph="none" pos="word" start_char="13359">of</TOKEN>
<TOKEN end_char="13364" id="token-116-7" morph="none" pos="word" start_char="13362">the</TOKEN>
<TOKEN end_char="13378" id="token-116-8" morph="none" pos="word" start_char="13366">International</TOKEN>
<TOKEN end_char="13385" id="token-116-9" morph="none" pos="word" start_char="13380">Health</TOKEN>
<TOKEN end_char="13397" id="token-116-10" morph="none" pos="word" start_char="13387">Regulations</TOKEN>
<TOKEN end_char="13400" id="token-116-11" morph="none" pos="word" start_char="13399">of</TOKEN>
<TOKEN end_char="13405" id="token-116-12" morph="none" pos="word" start_char="13402">2005</TOKEN>
<TOKEN end_char="13406" id="token-116-13" morph="none" pos="punct" start_char="13406">,</TOKEN>
<TOKEN end_char="13412" id="token-116-14" morph="none" pos="word" start_char="13408">which</TOKEN>
<TOKEN end_char="13420" id="token-116-15" morph="none" pos="word" start_char="13414">entered</TOKEN>
<TOKEN end_char="13425" id="token-116-16" morph="none" pos="word" start_char="13422">into</TOKEN>
<TOKEN end_char="13432" id="token-116-17" morph="none" pos="word" start_char="13427">affect</TOKEN>
<TOKEN end_char="13438" id="token-116-18" morph="none" pos="word" start_char="13434">after</TOKEN>
<TOKEN end_char="13442" id="token-116-19" morph="none" pos="word" start_char="13440">the</TOKEN>
<TOKEN end_char="13452" id="token-116-20" morph="none" pos="word" start_char="13444">agreement</TOKEN>
<TOKEN end_char="13453" id="token-116-21" morph="none" pos="punct" start_char="13453">,</TOKEN>
<TOKEN end_char="13458" id="token-116-22" morph="none" pos="word" start_char="13455">that</TOKEN>
<TOKEN end_char="13465" id="token-116-23" morph="none" pos="word" start_char="13460">uphold</TOKEN>
<TOKEN end_char="13469" id="token-116-24" morph="none" pos="word" start_char="13467">the</TOKEN>
<TOKEN end_char="13479" id="token-116-25" morph="none" pos="word" start_char="13471">principle</TOKEN>
<TOKEN end_char="13482" id="token-116-26" morph="none" pos="word" start_char="13481">of</TOKEN>
<TOKEN end_char="13494" id="token-116-27" morph="none" pos="word" start_char="13484">containment</TOKEN>
<TOKEN end_char="13497" id="token-116-28" morph="none" pos="word" start_char="13496">at</TOKEN>
<TOKEN end_char="13504" id="token-116-29" morph="none" pos="word" start_char="13499">source</TOKEN>
<TOKEN end_char="13507" id="token-116-30" morph="none" pos="word" start_char="13506">in</TOKEN>
<TOKEN end_char="13511" id="token-116-31" morph="none" pos="word" start_char="13509">the</TOKEN>
<TOKEN end_char="13518" id="token-116-32" morph="none" pos="word" start_char="13513">battle</TOKEN>
<TOKEN end_char="13526" id="token-116-33" morph="none" pos="word" start_char="13520">against</TOKEN>
<TOKEN end_char="13537" id="token-116-34" morph="none" pos="word" start_char="13528">infectious</TOKEN>
<TOKEN end_char="13546" id="token-116-35" morph="none" pos="word" start_char="13539">diseases</TOKEN>
<TOKEN end_char="13547" id="token-116-36" morph="none" pos="punct" start_char="13547">.</TOKEN>
</SEG>
<SEG end_char="13595" id="segment-117" start_char="13550">
<ORIGINAL_TEXT>This intergovernmental collaboration directed:</ORIGINAL_TEXT>
<TOKEN end_char="13553" id="token-117-0" morph="none" pos="word" start_char="13550">This</TOKEN>
<TOKEN end_char="13571" id="token-117-1" morph="none" pos="word" start_char="13555">intergovernmental</TOKEN>
<TOKEN end_char="13585" id="token-117-2" morph="none" pos="word" start_char="13573">collaboration</TOKEN>
<TOKEN end_char="13594" id="token-117-3" morph="none" pos="word" start_char="13587">directed</TOKEN>
<TOKEN end_char="13595" id="token-117-4" morph="none" pos="punct" start_char="13595">:</TOKEN>
</SEG>
<SEG end_char="13999" id="segment-118" start_char="13598">
<ORIGINAL_TEXT>Firstly, the construction of the National laboratory of high-security biological containment (a P4 laboratory), in Wuhan on the campus of the Virology Institut of Wuhan (VIW).Under the authority of a Franco-Chinese steering committee, of which the Institut Pasteur is not a member, the activities of this P4 laboratory are the responsibility of a Chinese director, appointed by the Chinese authorities.</ORIGINAL_TEXT>
<TOKEN end_char="13604" id="token-118-0" morph="none" pos="word" start_char="13598">Firstly</TOKEN>
<TOKEN end_char="13605" id="token-118-1" morph="none" pos="punct" start_char="13605">,</TOKEN>
<TOKEN end_char="13609" id="token-118-2" morph="none" pos="word" start_char="13607">the</TOKEN>
<TOKEN end_char="13622" id="token-118-3" morph="none" pos="word" start_char="13611">construction</TOKEN>
<TOKEN end_char="13625" id="token-118-4" morph="none" pos="word" start_char="13624">of</TOKEN>
<TOKEN end_char="13629" id="token-118-5" morph="none" pos="word" start_char="13627">the</TOKEN>
<TOKEN end_char="13638" id="token-118-6" morph="none" pos="word" start_char="13631">National</TOKEN>
<TOKEN end_char="13649" id="token-118-7" morph="none" pos="word" start_char="13640">laboratory</TOKEN>
<TOKEN end_char="13652" id="token-118-8" morph="none" pos="word" start_char="13651">of</TOKEN>
<TOKEN end_char="13666" id="token-118-9" morph="none" pos="unknown" start_char="13654">high-security</TOKEN>
<TOKEN end_char="13677" id="token-118-10" morph="none" pos="word" start_char="13668">biological</TOKEN>
<TOKEN end_char="13689" id="token-118-11" morph="none" pos="word" start_char="13679">containment</TOKEN>
<TOKEN end_char="13691" id="token-118-12" morph="none" pos="punct" start_char="13691">(</TOKEN>
<TOKEN end_char="13692" id="token-118-13" morph="none" pos="word" start_char="13692">a</TOKEN>
<TOKEN end_char="13695" id="token-118-14" morph="none" pos="word" start_char="13694">P4</TOKEN>
<TOKEN end_char="13706" id="token-118-15" morph="none" pos="word" start_char="13697">laboratory</TOKEN>
<TOKEN end_char="13708" id="token-118-16" morph="none" pos="punct" start_char="13707">),</TOKEN>
<TOKEN end_char="13711" id="token-118-17" morph="none" pos="word" start_char="13710">in</TOKEN>
<TOKEN end_char="13717" id="token-118-18" morph="none" pos="word" start_char="13713">Wuhan</TOKEN>
<TOKEN end_char="13720" id="token-118-19" morph="none" pos="word" start_char="13719">on</TOKEN>
<TOKEN end_char="13724" id="token-118-20" morph="none" pos="word" start_char="13722">the</TOKEN>
<TOKEN end_char="13731" id="token-118-21" morph="none" pos="word" start_char="13726">campus</TOKEN>
<TOKEN end_char="13734" id="token-118-22" morph="none" pos="word" start_char="13733">of</TOKEN>
<TOKEN end_char="13738" id="token-118-23" morph="none" pos="word" start_char="13736">the</TOKEN>
<TOKEN end_char="13747" id="token-118-24" morph="none" pos="word" start_char="13740">Virology</TOKEN>
<TOKEN end_char="13756" id="token-118-25" morph="none" pos="word" start_char="13749">Institut</TOKEN>
<TOKEN end_char="13759" id="token-118-26" morph="none" pos="word" start_char="13758">of</TOKEN>
<TOKEN end_char="13765" id="token-118-27" morph="none" pos="word" start_char="13761">Wuhan</TOKEN>
<TOKEN end_char="13767" id="token-118-28" morph="none" pos="punct" start_char="13767">(</TOKEN>
<TOKEN end_char="13777" id="token-118-29" morph="none" pos="unknown" start_char="13768">VIW).Under</TOKEN>
<TOKEN end_char="13781" id="token-118-30" morph="none" pos="word" start_char="13779">the</TOKEN>
<TOKEN end_char="13791" id="token-118-31" morph="none" pos="word" start_char="13783">authority</TOKEN>
<TOKEN end_char="13794" id="token-118-32" morph="none" pos="word" start_char="13793">of</TOKEN>
<TOKEN end_char="13796" id="token-118-33" morph="none" pos="word" start_char="13796">a</TOKEN>
<TOKEN end_char="13811" id="token-118-34" morph="none" pos="unknown" start_char="13798">Franco-Chinese</TOKEN>
<TOKEN end_char="13820" id="token-118-35" morph="none" pos="word" start_char="13813">steering</TOKEN>
<TOKEN end_char="13830" id="token-118-36" morph="none" pos="word" start_char="13822">committee</TOKEN>
<TOKEN end_char="13831" id="token-118-37" morph="none" pos="punct" start_char="13831">,</TOKEN>
<TOKEN end_char="13834" id="token-118-38" morph="none" pos="word" start_char="13833">of</TOKEN>
<TOKEN end_char="13840" id="token-118-39" morph="none" pos="word" start_char="13836">which</TOKEN>
<TOKEN end_char="13844" id="token-118-40" morph="none" pos="word" start_char="13842">the</TOKEN>
<TOKEN end_char="13853" id="token-118-41" morph="none" pos="word" start_char="13846">Institut</TOKEN>
<TOKEN end_char="13861" id="token-118-42" morph="none" pos="word" start_char="13855">Pasteur</TOKEN>
<TOKEN end_char="13864" id="token-118-43" morph="none" pos="word" start_char="13863">is</TOKEN>
<TOKEN end_char="13868" id="token-118-44" morph="none" pos="word" start_char="13866">not</TOKEN>
<TOKEN end_char="13870" id="token-118-45" morph="none" pos="word" start_char="13870">a</TOKEN>
<TOKEN end_char="13877" id="token-118-46" morph="none" pos="word" start_char="13872">member</TOKEN>
<TOKEN end_char="13878" id="token-118-47" morph="none" pos="punct" start_char="13878">,</TOKEN>
<TOKEN end_char="13882" id="token-118-48" morph="none" pos="word" start_char="13880">the</TOKEN>
<TOKEN end_char="13893" id="token-118-49" morph="none" pos="word" start_char="13884">activities</TOKEN>
<TOKEN end_char="13896" id="token-118-50" morph="none" pos="word" start_char="13895">of</TOKEN>
<TOKEN end_char="13901" id="token-118-51" morph="none" pos="word" start_char="13898">this</TOKEN>
<TOKEN end_char="13904" id="token-118-52" morph="none" pos="word" start_char="13903">P4</TOKEN>
<TOKEN end_char="13915" id="token-118-53" morph="none" pos="word" start_char="13906">laboratory</TOKEN>
<TOKEN end_char="13919" id="token-118-54" morph="none" pos="word" start_char="13917">are</TOKEN>
<TOKEN end_char="13923" id="token-118-55" morph="none" pos="word" start_char="13921">the</TOKEN>
<TOKEN end_char="13938" id="token-118-56" morph="none" pos="word" start_char="13925">responsibility</TOKEN>
<TOKEN end_char="13941" id="token-118-57" morph="none" pos="word" start_char="13940">of</TOKEN>
<TOKEN end_char="13943" id="token-118-58" morph="none" pos="word" start_char="13943">a</TOKEN>
<TOKEN end_char="13951" id="token-118-59" morph="none" pos="word" start_char="13945">Chinese</TOKEN>
<TOKEN end_char="13960" id="token-118-60" morph="none" pos="word" start_char="13953">director</TOKEN>
<TOKEN end_char="13961" id="token-118-61" morph="none" pos="punct" start_char="13961">,</TOKEN>
<TOKEN end_char="13971" id="token-118-62" morph="none" pos="word" start_char="13963">appointed</TOKEN>
<TOKEN end_char="13974" id="token-118-63" morph="none" pos="word" start_char="13973">by</TOKEN>
<TOKEN end_char="13978" id="token-118-64" morph="none" pos="word" start_char="13976">the</TOKEN>
<TOKEN end_char="13986" id="token-118-65" morph="none" pos="word" start_char="13980">Chinese</TOKEN>
<TOKEN end_char="13998" id="token-118-66" morph="none" pos="word" start_char="13988">authorities</TOKEN>
<TOKEN end_char="13999" id="token-118-67" morph="none" pos="punct" start_char="13999">.</TOKEN>
</SEG>
<SEG end_char="14442" id="segment-119" start_char="14002">
<ORIGINAL_TEXT>Secondly, the creation of the Institut Pasteur of Shanghai (IPS), a research center that holds special status within the Academy of sciences in China (IPS-CAS).The IPS has a governing system based on a board of directors and a joint scientific committee, the former co-led by the President of the Institut Pasteur and the latter led by Mr. Kourilsky, honorary professor of the College de France, and former President of the Institut Pasteur.</ORIGINAL_TEXT>
<TOKEN end_char="14009" id="token-119-0" morph="none" pos="word" start_char="14002">Secondly</TOKEN>
<TOKEN end_char="14010" id="token-119-1" morph="none" pos="punct" start_char="14010">,</TOKEN>
<TOKEN end_char="14014" id="token-119-2" morph="none" pos="word" start_char="14012">the</TOKEN>
<TOKEN end_char="14023" id="token-119-3" morph="none" pos="word" start_char="14016">creation</TOKEN>
<TOKEN end_char="14026" id="token-119-4" morph="none" pos="word" start_char="14025">of</TOKEN>
<TOKEN end_char="14030" id="token-119-5" morph="none" pos="word" start_char="14028">the</TOKEN>
<TOKEN end_char="14039" id="token-119-6" morph="none" pos="word" start_char="14032">Institut</TOKEN>
<TOKEN end_char="14047" id="token-119-7" morph="none" pos="word" start_char="14041">Pasteur</TOKEN>
<TOKEN end_char="14050" id="token-119-8" morph="none" pos="word" start_char="14049">of</TOKEN>
<TOKEN end_char="14059" id="token-119-9" morph="none" pos="word" start_char="14052">Shanghai</TOKEN>
<TOKEN end_char="14061" id="token-119-10" morph="none" pos="punct" start_char="14061">(</TOKEN>
<TOKEN end_char="14064" id="token-119-11" morph="none" pos="word" start_char="14062">IPS</TOKEN>
<TOKEN end_char="14066" id="token-119-12" morph="none" pos="punct" start_char="14065">),</TOKEN>
<TOKEN end_char="14068" id="token-119-13" morph="none" pos="word" start_char="14068">a</TOKEN>
<TOKEN end_char="14077" id="token-119-14" morph="none" pos="word" start_char="14070">research</TOKEN>
<TOKEN end_char="14084" id="token-119-15" morph="none" pos="word" start_char="14079">center</TOKEN>
<TOKEN end_char="14089" id="token-119-16" morph="none" pos="word" start_char="14086">that</TOKEN>
<TOKEN end_char="14095" id="token-119-17" morph="none" pos="word" start_char="14091">holds</TOKEN>
<TOKEN end_char="14103" id="token-119-18" morph="none" pos="word" start_char="14097">special</TOKEN>
<TOKEN end_char="14110" id="token-119-19" morph="none" pos="word" start_char="14105">status</TOKEN>
<TOKEN end_char="14117" id="token-119-20" morph="none" pos="word" start_char="14112">within</TOKEN>
<TOKEN end_char="14121" id="token-119-21" morph="none" pos="word" start_char="14119">the</TOKEN>
<TOKEN end_char="14129" id="token-119-22" morph="none" pos="word" start_char="14123">Academy</TOKEN>
<TOKEN end_char="14132" id="token-119-23" morph="none" pos="word" start_char="14131">of</TOKEN>
<TOKEN end_char="14141" id="token-119-24" morph="none" pos="word" start_char="14134">sciences</TOKEN>
<TOKEN end_char="14144" id="token-119-25" morph="none" pos="word" start_char="14143">in</TOKEN>
<TOKEN end_char="14150" id="token-119-26" morph="none" pos="word" start_char="14146">China</TOKEN>
<TOKEN end_char="14152" id="token-119-27" morph="none" pos="punct" start_char="14152">(</TOKEN>
<TOKEN end_char="14164" id="token-119-28" morph="none" pos="unknown" start_char="14153">IPS-CAS).The</TOKEN>
<TOKEN end_char="14168" id="token-119-29" morph="none" pos="word" start_char="14166">IPS</TOKEN>
<TOKEN end_char="14172" id="token-119-30" morph="none" pos="word" start_char="14170">has</TOKEN>
<TOKEN end_char="14174" id="token-119-31" morph="none" pos="word" start_char="14174">a</TOKEN>
<TOKEN end_char="14184" id="token-119-32" morph="none" pos="word" start_char="14176">governing</TOKEN>
<TOKEN end_char="14191" id="token-119-33" morph="none" pos="word" start_char="14186">system</TOKEN>
<TOKEN end_char="14197" id="token-119-34" morph="none" pos="word" start_char="14193">based</TOKEN>
<TOKEN end_char="14200" id="token-119-35" morph="none" pos="word" start_char="14199">on</TOKEN>
<TOKEN end_char="14202" id="token-119-36" morph="none" pos="word" start_char="14202">a</TOKEN>
<TOKEN end_char="14208" id="token-119-37" morph="none" pos="word" start_char="14204">board</TOKEN>
<TOKEN end_char="14211" id="token-119-38" morph="none" pos="word" start_char="14210">of</TOKEN>
<TOKEN end_char="14221" id="token-119-39" morph="none" pos="word" start_char="14213">directors</TOKEN>
<TOKEN end_char="14225" id="token-119-40" morph="none" pos="word" start_char="14223">and</TOKEN>
<TOKEN end_char="14227" id="token-119-41" morph="none" pos="word" start_char="14227">a</TOKEN>
<TOKEN end_char="14233" id="token-119-42" morph="none" pos="word" start_char="14229">joint</TOKEN>
<TOKEN end_char="14244" id="token-119-43" morph="none" pos="word" start_char="14235">scientific</TOKEN>
<TOKEN end_char="14254" id="token-119-44" morph="none" pos="word" start_char="14246">committee</TOKEN>
<TOKEN end_char="14255" id="token-119-45" morph="none" pos="punct" start_char="14255">,</TOKEN>
<TOKEN end_char="14259" id="token-119-46" morph="none" pos="word" start_char="14257">the</TOKEN>
<TOKEN end_char="14266" id="token-119-47" morph="none" pos="word" start_char="14261">former</TOKEN>
<TOKEN end_char="14273" id="token-119-48" morph="none" pos="unknown" start_char="14268">co-led</TOKEN>
<TOKEN end_char="14276" id="token-119-49" morph="none" pos="word" start_char="14275">by</TOKEN>
<TOKEN end_char="14280" id="token-119-50" morph="none" pos="word" start_char="14278">the</TOKEN>
<TOKEN end_char="14290" id="token-119-51" morph="none" pos="word" start_char="14282">President</TOKEN>
<TOKEN end_char="14293" id="token-119-52" morph="none" pos="word" start_char="14292">of</TOKEN>
<TOKEN end_char="14297" id="token-119-53" morph="none" pos="word" start_char="14295">the</TOKEN>
<TOKEN end_char="14306" id="token-119-54" morph="none" pos="word" start_char="14299">Institut</TOKEN>
<TOKEN end_char="14314" id="token-119-55" morph="none" pos="word" start_char="14308">Pasteur</TOKEN>
<TOKEN end_char="14318" id="token-119-56" morph="none" pos="word" start_char="14316">and</TOKEN>
<TOKEN end_char="14322" id="token-119-57" morph="none" pos="word" start_char="14320">the</TOKEN>
<TOKEN end_char="14329" id="token-119-58" morph="none" pos="word" start_char="14324">latter</TOKEN>
<TOKEN end_char="14333" id="token-119-59" morph="none" pos="word" start_char="14331">led</TOKEN>
<TOKEN end_char="14336" id="token-119-60" morph="none" pos="word" start_char="14335">by</TOKEN>
<TOKEN end_char="14339" id="token-119-61" morph="none" pos="word" start_char="14338">Mr</TOKEN>
<TOKEN end_char="14340" id="token-119-62" morph="none" pos="punct" start_char="14340">.</TOKEN>
<TOKEN end_char="14350" id="token-119-63" morph="none" pos="word" start_char="14342">Kourilsky</TOKEN>
<TOKEN end_char="14351" id="token-119-64" morph="none" pos="punct" start_char="14351">,</TOKEN>
<TOKEN end_char="14360" id="token-119-65" morph="none" pos="word" start_char="14353">honorary</TOKEN>
<TOKEN end_char="14370" id="token-119-66" morph="none" pos="word" start_char="14362">professor</TOKEN>
<TOKEN end_char="14373" id="token-119-67" morph="none" pos="word" start_char="14372">of</TOKEN>
<TOKEN end_char="14377" id="token-119-68" morph="none" pos="word" start_char="14375">the</TOKEN>
<TOKEN end_char="14385" id="token-119-69" morph="none" pos="word" start_char="14379">College</TOKEN>
<TOKEN end_char="14388" id="token-119-70" morph="none" pos="word" start_char="14387">de</TOKEN>
<TOKEN end_char="14395" id="token-119-71" morph="none" pos="word" start_char="14390">France</TOKEN>
<TOKEN end_char="14396" id="token-119-72" morph="none" pos="punct" start_char="14396">,</TOKEN>
<TOKEN end_char="14400" id="token-119-73" morph="none" pos="word" start_char="14398">and</TOKEN>
<TOKEN end_char="14407" id="token-119-74" morph="none" pos="word" start_char="14402">former</TOKEN>
<TOKEN end_char="14417" id="token-119-75" morph="none" pos="word" start_char="14409">President</TOKEN>
<TOKEN end_char="14420" id="token-119-76" morph="none" pos="word" start_char="14419">of</TOKEN>
<TOKEN end_char="14424" id="token-119-77" morph="none" pos="word" start_char="14422">the</TOKEN>
<TOKEN end_char="14433" id="token-119-78" morph="none" pos="word" start_char="14426">Institut</TOKEN>
<TOKEN end_char="14441" id="token-119-79" morph="none" pos="word" start_char="14435">Pasteur</TOKEN>
<TOKEN end_char="14442" id="token-119-80" morph="none" pos="punct" start_char="14442">.</TOKEN>
</SEG>
<SEG end_char="14575" id="segment-120" start_char="14446">
<ORIGINAL_TEXT>The P4 laboratory was indeed planned and constructed with the help of France, in the context of the cooperation agreement of 2004.</ORIGINAL_TEXT>
<TOKEN end_char="14448" id="token-120-0" morph="none" pos="word" start_char="14446">The</TOKEN>
<TOKEN end_char="14451" id="token-120-1" morph="none" pos="word" start_char="14450">P4</TOKEN>
<TOKEN end_char="14462" id="token-120-2" morph="none" pos="word" start_char="14453">laboratory</TOKEN>
<TOKEN end_char="14466" id="token-120-3" morph="none" pos="word" start_char="14464">was</TOKEN>
<TOKEN end_char="14473" id="token-120-4" morph="none" pos="word" start_char="14468">indeed</TOKEN>
<TOKEN end_char="14481" id="token-120-5" morph="none" pos="word" start_char="14475">planned</TOKEN>
<TOKEN end_char="14485" id="token-120-6" morph="none" pos="word" start_char="14483">and</TOKEN>
<TOKEN end_char="14497" id="token-120-7" morph="none" pos="word" start_char="14487">constructed</TOKEN>
<TOKEN end_char="14502" id="token-120-8" morph="none" pos="word" start_char="14499">with</TOKEN>
<TOKEN end_char="14506" id="token-120-9" morph="none" pos="word" start_char="14504">the</TOKEN>
<TOKEN end_char="14511" id="token-120-10" morph="none" pos="word" start_char="14508">help</TOKEN>
<TOKEN end_char="14514" id="token-120-11" morph="none" pos="word" start_char="14513">of</TOKEN>
<TOKEN end_char="14521" id="token-120-12" morph="none" pos="word" start_char="14516">France</TOKEN>
<TOKEN end_char="14522" id="token-120-13" morph="none" pos="punct" start_char="14522">,</TOKEN>
<TOKEN end_char="14525" id="token-120-14" morph="none" pos="word" start_char="14524">in</TOKEN>
<TOKEN end_char="14529" id="token-120-15" morph="none" pos="word" start_char="14527">the</TOKEN>
<TOKEN end_char="14537" id="token-120-16" morph="none" pos="word" start_char="14531">context</TOKEN>
<TOKEN end_char="14540" id="token-120-17" morph="none" pos="word" start_char="14539">of</TOKEN>
<TOKEN end_char="14544" id="token-120-18" morph="none" pos="word" start_char="14542">the</TOKEN>
<TOKEN end_char="14556" id="token-120-19" morph="none" pos="word" start_char="14546">cooperation</TOKEN>
<TOKEN end_char="14566" id="token-120-20" morph="none" pos="word" start_char="14558">agreement</TOKEN>
<TOKEN end_char="14569" id="token-120-21" morph="none" pos="word" start_char="14568">of</TOKEN>
<TOKEN end_char="14574" id="token-120-22" morph="none" pos="word" start_char="14571">2004</TOKEN>
<TOKEN end_char="14575" id="token-120-23" morph="none" pos="punct" start_char="14575">.</TOKEN>
</SEG>
<SEG end_char="14690" id="segment-121" start_char="14577">
<ORIGINAL_TEXT>However, the Institut Pasteur of Shanghai (IPS) is absolutely an independent and distinct Franco-Chinese institut​</ORIGINAL_TEXT>
<TOKEN end_char="14583" id="token-121-0" morph="none" pos="word" start_char="14577">However</TOKEN>
<TOKEN end_char="14584" id="token-121-1" morph="none" pos="punct" start_char="14584">,</TOKEN>
<TOKEN end_char="14588" id="token-121-2" morph="none" pos="word" start_char="14586">the</TOKEN>
<TOKEN end_char="14597" id="token-121-3" morph="none" pos="word" start_char="14590">Institut</TOKEN>
<TOKEN end_char="14605" id="token-121-4" morph="none" pos="word" start_char="14599">Pasteur</TOKEN>
<TOKEN end_char="14608" id="token-121-5" morph="none" pos="word" start_char="14607">of</TOKEN>
<TOKEN end_char="14617" id="token-121-6" morph="none" pos="word" start_char="14610">Shanghai</TOKEN>
<TOKEN end_char="14619" id="token-121-7" morph="none" pos="punct" start_char="14619">(</TOKEN>
<TOKEN end_char="14622" id="token-121-8" morph="none" pos="word" start_char="14620">IPS</TOKEN>
<TOKEN end_char="14623" id="token-121-9" morph="none" pos="punct" start_char="14623">)</TOKEN>
<TOKEN end_char="14626" id="token-121-10" morph="none" pos="word" start_char="14625">is</TOKEN>
<TOKEN end_char="14637" id="token-121-11" morph="none" pos="word" start_char="14628">absolutely</TOKEN>
<TOKEN end_char="14640" id="token-121-12" morph="none" pos="word" start_char="14639">an</TOKEN>
<TOKEN end_char="14652" id="token-121-13" morph="none" pos="word" start_char="14642">independent</TOKEN>
<TOKEN end_char="14656" id="token-121-14" morph="none" pos="word" start_char="14654">and</TOKEN>
<TOKEN end_char="14665" id="token-121-15" morph="none" pos="word" start_char="14658">distinct</TOKEN>
<TOKEN end_char="14680" id="token-121-16" morph="none" pos="unknown" start_char="14667">Franco-Chinese</TOKEN>
<TOKEN end_char="14690" id="token-121-17" morph="none" pos="unknown" start_char="14682">institut​</TOKEN>
</SEG>
<SEG end_char="14777" id="segment-122" start_char="14693">
<ORIGINAL_TEXT>Regarding the alleged work of the Shanghai Pasteur Institute (IPS) on the coronavirus</ORIGINAL_TEXT>
<TOKEN end_char="14701" id="token-122-0" morph="none" pos="word" start_char="14693">Regarding</TOKEN>
<TOKEN end_char="14705" id="token-122-1" morph="none" pos="word" start_char="14703">the</TOKEN>
<TOKEN end_char="14713" id="token-122-2" morph="none" pos="word" start_char="14707">alleged</TOKEN>
<TOKEN end_char="14718" id="token-122-3" morph="none" pos="word" start_char="14715">work</TOKEN>
<TOKEN end_char="14721" id="token-122-4" morph="none" pos="word" start_char="14720">of</TOKEN>
<TOKEN end_char="14725" id="token-122-5" morph="none" pos="word" start_char="14723">the</TOKEN>
<TOKEN end_char="14734" id="token-122-6" morph="none" pos="word" start_char="14727">Shanghai</TOKEN>
<TOKEN end_char="14742" id="token-122-7" morph="none" pos="word" start_char="14736">Pasteur</TOKEN>
<TOKEN end_char="14752" id="token-122-8" morph="none" pos="word" start_char="14744">Institute</TOKEN>
<TOKEN end_char="14754" id="token-122-9" morph="none" pos="punct" start_char="14754">(</TOKEN>
<TOKEN end_char="14757" id="token-122-10" morph="none" pos="word" start_char="14755">IPS</TOKEN>
<TOKEN end_char="14758" id="token-122-11" morph="none" pos="punct" start_char="14758">)</TOKEN>
<TOKEN end_char="14761" id="token-122-12" morph="none" pos="word" start_char="14760">on</TOKEN>
<TOKEN end_char="14765" id="token-122-13" morph="none" pos="word" start_char="14763">the</TOKEN>
<TOKEN end_char="14777" id="token-122-14" morph="none" pos="word" start_char="14767">coronavirus</TOKEN>
</SEG>
<SEG end_char="15033" id="segment-123" start_char="14781">
<ORIGINAL_TEXT>Since the emergence of the nouvel coronavirus in Wuhan, the Institut Pasteur of Shanghai (IPS), in line with its mandate, fulfilled its role as a cooperative Franco-Chinese platform, facilitating a better understanding of the evolution of the new virus.</ORIGINAL_TEXT>
<TOKEN end_char="14785" id="token-123-0" morph="none" pos="word" start_char="14781">Since</TOKEN>
<TOKEN end_char="14789" id="token-123-1" morph="none" pos="word" start_char="14787">the</TOKEN>
<TOKEN end_char="14799" id="token-123-2" morph="none" pos="word" start_char="14791">emergence</TOKEN>
<TOKEN end_char="14802" id="token-123-3" morph="none" pos="word" start_char="14801">of</TOKEN>
<TOKEN end_char="14806" id="token-123-4" morph="none" pos="word" start_char="14804">the</TOKEN>
<TOKEN end_char="14813" id="token-123-5" morph="none" pos="word" start_char="14808">nouvel</TOKEN>
<TOKEN end_char="14825" id="token-123-6" morph="none" pos="word" start_char="14815">coronavirus</TOKEN>
<TOKEN end_char="14828" id="token-123-7" morph="none" pos="word" start_char="14827">in</TOKEN>
<TOKEN end_char="14834" id="token-123-8" morph="none" pos="word" start_char="14830">Wuhan</TOKEN>
<TOKEN end_char="14835" id="token-123-9" morph="none" pos="punct" start_char="14835">,</TOKEN>
<TOKEN end_char="14839" id="token-123-10" morph="none" pos="word" start_char="14837">the</TOKEN>
<TOKEN end_char="14848" id="token-123-11" morph="none" pos="word" start_char="14841">Institut</TOKEN>
<TOKEN end_char="14856" id="token-123-12" morph="none" pos="word" start_char="14850">Pasteur</TOKEN>
<TOKEN end_char="14859" id="token-123-13" morph="none" pos="word" start_char="14858">of</TOKEN>
<TOKEN end_char="14868" id="token-123-14" morph="none" pos="word" start_char="14861">Shanghai</TOKEN>
<TOKEN end_char="14870" id="token-123-15" morph="none" pos="punct" start_char="14870">(</TOKEN>
<TOKEN end_char="14873" id="token-123-16" morph="none" pos="word" start_char="14871">IPS</TOKEN>
<TOKEN end_char="14875" id="token-123-17" morph="none" pos="punct" start_char="14874">),</TOKEN>
<TOKEN end_char="14878" id="token-123-18" morph="none" pos="word" start_char="14877">in</TOKEN>
<TOKEN end_char="14883" id="token-123-19" morph="none" pos="word" start_char="14880">line</TOKEN>
<TOKEN end_char="14888" id="token-123-20" morph="none" pos="word" start_char="14885">with</TOKEN>
<TOKEN end_char="14892" id="token-123-21" morph="none" pos="word" start_char="14890">its</TOKEN>
<TOKEN end_char="14900" id="token-123-22" morph="none" pos="word" start_char="14894">mandate</TOKEN>
<TOKEN end_char="14901" id="token-123-23" morph="none" pos="punct" start_char="14901">,</TOKEN>
<TOKEN end_char="14911" id="token-123-24" morph="none" pos="word" start_char="14903">fulfilled</TOKEN>
<TOKEN end_char="14915" id="token-123-25" morph="none" pos="word" start_char="14913">its</TOKEN>
<TOKEN end_char="14920" id="token-123-26" morph="none" pos="word" start_char="14917">role</TOKEN>
<TOKEN end_char="14923" id="token-123-27" morph="none" pos="word" start_char="14922">as</TOKEN>
<TOKEN end_char="14925" id="token-123-28" morph="none" pos="word" start_char="14925">a</TOKEN>
<TOKEN end_char="14937" id="token-123-29" morph="none" pos="word" start_char="14927">cooperative</TOKEN>
<TOKEN end_char="14952" id="token-123-30" morph="none" pos="unknown" start_char="14939">Franco-Chinese</TOKEN>
<TOKEN end_char="14961" id="token-123-31" morph="none" pos="word" start_char="14954">platform</TOKEN>
<TOKEN end_char="14962" id="token-123-32" morph="none" pos="punct" start_char="14962">,</TOKEN>
<TOKEN end_char="14975" id="token-123-33" morph="none" pos="word" start_char="14964">facilitating</TOKEN>
<TOKEN end_char="14977" id="token-123-34" morph="none" pos="word" start_char="14977">a</TOKEN>
<TOKEN end_char="14984" id="token-123-35" morph="none" pos="word" start_char="14979">better</TOKEN>
<TOKEN end_char="14998" id="token-123-36" morph="none" pos="word" start_char="14986">understanding</TOKEN>
<TOKEN end_char="15001" id="token-123-37" morph="none" pos="word" start_char="15000">of</TOKEN>
<TOKEN end_char="15005" id="token-123-38" morph="none" pos="word" start_char="15003">the</TOKEN>
<TOKEN end_char="15015" id="token-123-39" morph="none" pos="word" start_char="15007">evolution</TOKEN>
<TOKEN end_char="15018" id="token-123-40" morph="none" pos="word" start_char="15017">of</TOKEN>
<TOKEN end_char="15022" id="token-123-41" morph="none" pos="word" start_char="15020">the</TOKEN>
<TOKEN end_char="15026" id="token-123-42" morph="none" pos="word" start_char="15024">new</TOKEN>
<TOKEN end_char="15032" id="token-123-43" morph="none" pos="word" start_char="15028">virus</TOKEN>
<TOKEN end_char="15033" id="token-123-44" morph="none" pos="punct" start_char="15033">.</TOKEN>
</SEG>
<SEG end_char="15139" id="segment-124" start_char="15035">
<ORIGINAL_TEXT>It published, as early as the first weeks, an article about the three-dimensional structure of the virus.</ORIGINAL_TEXT>
<TOKEN end_char="15036" id="token-124-0" morph="none" pos="word" start_char="15035">It</TOKEN>
<TOKEN end_char="15046" id="token-124-1" morph="none" pos="word" start_char="15038">published</TOKEN>
<TOKEN end_char="15047" id="token-124-2" morph="none" pos="punct" start_char="15047">,</TOKEN>
<TOKEN end_char="15050" id="token-124-3" morph="none" pos="word" start_char="15049">as</TOKEN>
<TOKEN end_char="15056" id="token-124-4" morph="none" pos="word" start_char="15052">early</TOKEN>
<TOKEN end_char="15059" id="token-124-5" morph="none" pos="word" start_char="15058">as</TOKEN>
<TOKEN end_char="15063" id="token-124-6" morph="none" pos="word" start_char="15061">the</TOKEN>
<TOKEN end_char="15069" id="token-124-7" morph="none" pos="word" start_char="15065">first</TOKEN>
<TOKEN end_char="15075" id="token-124-8" morph="none" pos="word" start_char="15071">weeks</TOKEN>
<TOKEN end_char="15076" id="token-124-9" morph="none" pos="punct" start_char="15076">,</TOKEN>
<TOKEN end_char="15079" id="token-124-10" morph="none" pos="word" start_char="15078">an</TOKEN>
<TOKEN end_char="15087" id="token-124-11" morph="none" pos="word" start_char="15081">article</TOKEN>
<TOKEN end_char="15093" id="token-124-12" morph="none" pos="word" start_char="15089">about</TOKEN>
<TOKEN end_char="15097" id="token-124-13" morph="none" pos="word" start_char="15095">the</TOKEN>
<TOKEN end_char="15115" id="token-124-14" morph="none" pos="unknown" start_char="15099">three-dimensional</TOKEN>
<TOKEN end_char="15125" id="token-124-15" morph="none" pos="word" start_char="15117">structure</TOKEN>
<TOKEN end_char="15128" id="token-124-16" morph="none" pos="word" start_char="15127">of</TOKEN>
<TOKEN end_char="15132" id="token-124-17" morph="none" pos="word" start_char="15130">the</TOKEN>
<TOKEN end_char="15138" id="token-124-18" morph="none" pos="word" start_char="15134">virus</TOKEN>
<TOKEN end_char="15139" id="token-124-19" morph="none" pos="punct" start_char="15139">.</TOKEN>
</SEG>
<SEG end_char="15356" id="segment-125" start_char="15141">
<ORIGINAL_TEXT>Its scientific experts furthermore proposed their services to the Chinese Center for Disease Control and Prevention, as well as the Virology Institut of Wuhan, to help the on-site staff, but they were not contacted.​</ORIGINAL_TEXT>
<TOKEN end_char="15143" id="token-125-0" morph="none" pos="word" start_char="15141">Its</TOKEN>
<TOKEN end_char="15154" id="token-125-1" morph="none" pos="word" start_char="15145">scientific</TOKEN>
<TOKEN end_char="15162" id="token-125-2" morph="none" pos="word" start_char="15156">experts</TOKEN>
<TOKEN end_char="15174" id="token-125-3" morph="none" pos="word" start_char="15164">furthermore</TOKEN>
<TOKEN end_char="15183" id="token-125-4" morph="none" pos="word" start_char="15176">proposed</TOKEN>
<TOKEN end_char="15189" id="token-125-5" morph="none" pos="word" start_char="15185">their</TOKEN>
<TOKEN end_char="15198" id="token-125-6" morph="none" pos="word" start_char="15191">services</TOKEN>
<TOKEN end_char="15201" id="token-125-7" morph="none" pos="word" start_char="15200">to</TOKEN>
<TOKEN end_char="15205" id="token-125-8" morph="none" pos="word" start_char="15203">the</TOKEN>
<TOKEN end_char="15213" id="token-125-9" morph="none" pos="word" start_char="15207">Chinese</TOKEN>
<TOKEN end_char="15220" id="token-125-10" morph="none" pos="word" start_char="15215">Center</TOKEN>
<TOKEN end_char="15224" id="token-125-11" morph="none" pos="word" start_char="15222">for</TOKEN>
<TOKEN end_char="15232" id="token-125-12" morph="none" pos="word" start_char="15226">Disease</TOKEN>
<TOKEN end_char="15240" id="token-125-13" morph="none" pos="word" start_char="15234">Control</TOKEN>
<TOKEN end_char="15244" id="token-125-14" morph="none" pos="word" start_char="15242">and</TOKEN>
<TOKEN end_char="15255" id="token-125-15" morph="none" pos="word" start_char="15246">Prevention</TOKEN>
<TOKEN end_char="15256" id="token-125-16" morph="none" pos="punct" start_char="15256">,</TOKEN>
<TOKEN end_char="15259" id="token-125-17" morph="none" pos="word" start_char="15258">as</TOKEN>
<TOKEN end_char="15264" id="token-125-18" morph="none" pos="word" start_char="15261">well</TOKEN>
<TOKEN end_char="15267" id="token-125-19" morph="none" pos="word" start_char="15266">as</TOKEN>
<TOKEN end_char="15271" id="token-125-20" morph="none" pos="word" start_char="15269">the</TOKEN>
<TOKEN end_char="15280" id="token-125-21" morph="none" pos="word" start_char="15273">Virology</TOKEN>
<TOKEN end_char="15289" id="token-125-22" morph="none" pos="word" start_char="15282">Institut</TOKEN>
<TOKEN end_char="15292" id="token-125-23" morph="none" pos="word" start_char="15291">of</TOKEN>
<TOKEN end_char="15298" id="token-125-24" morph="none" pos="word" start_char="15294">Wuhan</TOKEN>
<TOKEN end_char="15299" id="token-125-25" morph="none" pos="punct" start_char="15299">,</TOKEN>
<TOKEN end_char="15302" id="token-125-26" morph="none" pos="word" start_char="15301">to</TOKEN>
<TOKEN end_char="15307" id="token-125-27" morph="none" pos="word" start_char="15304">help</TOKEN>
<TOKEN end_char="15311" id="token-125-28" morph="none" pos="word" start_char="15309">the</TOKEN>
<TOKEN end_char="15319" id="token-125-29" morph="none" pos="unknown" start_char="15313">on-site</TOKEN>
<TOKEN end_char="15325" id="token-125-30" morph="none" pos="word" start_char="15321">staff</TOKEN>
<TOKEN end_char="15326" id="token-125-31" morph="none" pos="punct" start_char="15326">,</TOKEN>
<TOKEN end_char="15330" id="token-125-32" morph="none" pos="word" start_char="15328">but</TOKEN>
<TOKEN end_char="15335" id="token-125-33" morph="none" pos="word" start_char="15332">they</TOKEN>
<TOKEN end_char="15340" id="token-125-34" morph="none" pos="word" start_char="15337">were</TOKEN>
<TOKEN end_char="15344" id="token-125-35" morph="none" pos="word" start_char="15342">not</TOKEN>
<TOKEN end_char="15356" id="token-125-36" morph="none" pos="unknown" start_char="15346">contacted.​</TOKEN>
</SEG>
<SEG end_char="15487" id="segment-126" start_char="15359">
<ORIGINAL_TEXT>The IPS has neither active projects inside the P4 laboratory in Wuhan, nor active projets in any of the P3 laboratories in Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="15361" id="token-126-0" morph="none" pos="word" start_char="15359">The</TOKEN>
<TOKEN end_char="15365" id="token-126-1" morph="none" pos="word" start_char="15363">IPS</TOKEN>
<TOKEN end_char="15369" id="token-126-2" morph="none" pos="word" start_char="15367">has</TOKEN>
<TOKEN end_char="15377" id="token-126-3" morph="none" pos="word" start_char="15371">neither</TOKEN>
<TOKEN end_char="15384" id="token-126-4" morph="none" pos="word" start_char="15379">active</TOKEN>
<TOKEN end_char="15393" id="token-126-5" morph="none" pos="word" start_char="15386">projects</TOKEN>
<TOKEN end_char="15400" id="token-126-6" morph="none" pos="word" start_char="15395">inside</TOKEN>
<TOKEN end_char="15404" id="token-126-7" morph="none" pos="word" start_char="15402">the</TOKEN>
<TOKEN end_char="15407" id="token-126-8" morph="none" pos="word" start_char="15406">P4</TOKEN>
<TOKEN end_char="15418" id="token-126-9" morph="none" pos="word" start_char="15409">laboratory</TOKEN>
<TOKEN end_char="15421" id="token-126-10" morph="none" pos="word" start_char="15420">in</TOKEN>
<TOKEN end_char="15427" id="token-126-11" morph="none" pos="word" start_char="15423">Wuhan</TOKEN>
<TOKEN end_char="15428" id="token-126-12" morph="none" pos="punct" start_char="15428">,</TOKEN>
<TOKEN end_char="15432" id="token-126-13" morph="none" pos="word" start_char="15430">nor</TOKEN>
<TOKEN end_char="15439" id="token-126-14" morph="none" pos="word" start_char="15434">active</TOKEN>
<TOKEN end_char="15447" id="token-126-15" morph="none" pos="word" start_char="15441">projets</TOKEN>
<TOKEN end_char="15450" id="token-126-16" morph="none" pos="word" start_char="15449">in</TOKEN>
<TOKEN end_char="15454" id="token-126-17" morph="none" pos="word" start_char="15452">any</TOKEN>
<TOKEN end_char="15457" id="token-126-18" morph="none" pos="word" start_char="15456">of</TOKEN>
<TOKEN end_char="15461" id="token-126-19" morph="none" pos="word" start_char="15459">the</TOKEN>
<TOKEN end_char="15464" id="token-126-20" morph="none" pos="word" start_char="15463">P3</TOKEN>
<TOKEN end_char="15477" id="token-126-21" morph="none" pos="word" start_char="15466">laboratories</TOKEN>
<TOKEN end_char="15480" id="token-126-22" morph="none" pos="word" start_char="15479">in</TOKEN>
<TOKEN end_char="15486" id="token-126-23" morph="none" pos="word" start_char="15482">Wuhan</TOKEN>
<TOKEN end_char="15487" id="token-126-24" morph="none" pos="punct" start_char="15487">.</TOKEN>
</SEG>
<SEG end_char="15717" id="segment-127" start_char="15490">
<ORIGINAL_TEXT>The IPS thus brought its active support to other institutes in the Asia region (Hong Kong, Laos, and Cambodia, primarily) and mobilized itself to help preparations in the most vulnerable countries (including African institutes.)</ORIGINAL_TEXT>
<TOKEN end_char="15492" id="token-127-0" morph="none" pos="word" start_char="15490">The</TOKEN>
<TOKEN end_char="15496" id="token-127-1" morph="none" pos="word" start_char="15494">IPS</TOKEN>
<TOKEN end_char="15501" id="token-127-2" morph="none" pos="word" start_char="15498">thus</TOKEN>
<TOKEN end_char="15509" id="token-127-3" morph="none" pos="word" start_char="15503">brought</TOKEN>
<TOKEN end_char="15513" id="token-127-4" morph="none" pos="word" start_char="15511">its</TOKEN>
<TOKEN end_char="15520" id="token-127-5" morph="none" pos="word" start_char="15515">active</TOKEN>
<TOKEN end_char="15528" id="token-127-6" morph="none" pos="word" start_char="15522">support</TOKEN>
<TOKEN end_char="15531" id="token-127-7" morph="none" pos="word" start_char="15530">to</TOKEN>
<TOKEN end_char="15537" id="token-127-8" morph="none" pos="word" start_char="15533">other</TOKEN>
<TOKEN end_char="15548" id="token-127-9" morph="none" pos="word" start_char="15539">institutes</TOKEN>
<TOKEN end_char="15551" id="token-127-10" morph="none" pos="word" start_char="15550">in</TOKEN>
<TOKEN end_char="15555" id="token-127-11" morph="none" pos="word" start_char="15553">the</TOKEN>
<TOKEN end_char="15560" id="token-127-12" morph="none" pos="word" start_char="15557">Asia</TOKEN>
<TOKEN end_char="15567" id="token-127-13" morph="none" pos="word" start_char="15562">region</TOKEN>
<TOKEN end_char="15569" id="token-127-14" morph="none" pos="punct" start_char="15569">(</TOKEN>
<TOKEN end_char="15573" id="token-127-15" morph="none" pos="word" start_char="15570">Hong</TOKEN>
<TOKEN end_char="15578" id="token-127-16" morph="none" pos="word" start_char="15575">Kong</TOKEN>
<TOKEN end_char="15579" id="token-127-17" morph="none" pos="punct" start_char="15579">,</TOKEN>
<TOKEN end_char="15584" id="token-127-18" morph="none" pos="word" start_char="15581">Laos</TOKEN>
<TOKEN end_char="15585" id="token-127-19" morph="none" pos="punct" start_char="15585">,</TOKEN>
<TOKEN end_char="15589" id="token-127-20" morph="none" pos="word" start_char="15587">and</TOKEN>
<TOKEN end_char="15598" id="token-127-21" morph="none" pos="word" start_char="15591">Cambodia</TOKEN>
<TOKEN end_char="15599" id="token-127-22" morph="none" pos="punct" start_char="15599">,</TOKEN>
<TOKEN end_char="15609" id="token-127-23" morph="none" pos="word" start_char="15601">primarily</TOKEN>
<TOKEN end_char="15610" id="token-127-24" morph="none" pos="punct" start_char="15610">)</TOKEN>
<TOKEN end_char="15614" id="token-127-25" morph="none" pos="word" start_char="15612">and</TOKEN>
<TOKEN end_char="15624" id="token-127-26" morph="none" pos="word" start_char="15616">mobilized</TOKEN>
<TOKEN end_char="15631" id="token-127-27" morph="none" pos="word" start_char="15626">itself</TOKEN>
<TOKEN end_char="15634" id="token-127-28" morph="none" pos="word" start_char="15633">to</TOKEN>
<TOKEN end_char="15639" id="token-127-29" morph="none" pos="word" start_char="15636">help</TOKEN>
<TOKEN end_char="15652" id="token-127-30" morph="none" pos="word" start_char="15641">preparations</TOKEN>
<TOKEN end_char="15655" id="token-127-31" morph="none" pos="word" start_char="15654">in</TOKEN>
<TOKEN end_char="15659" id="token-127-32" morph="none" pos="word" start_char="15657">the</TOKEN>
<TOKEN end_char="15664" id="token-127-33" morph="none" pos="word" start_char="15661">most</TOKEN>
<TOKEN end_char="15675" id="token-127-34" morph="none" pos="word" start_char="15666">vulnerable</TOKEN>
<TOKEN end_char="15685" id="token-127-35" morph="none" pos="word" start_char="15677">countries</TOKEN>
<TOKEN end_char="15687" id="token-127-36" morph="none" pos="punct" start_char="15687">(</TOKEN>
<TOKEN end_char="15696" id="token-127-37" morph="none" pos="word" start_char="15688">including</TOKEN>
<TOKEN end_char="15704" id="token-127-38" morph="none" pos="word" start_char="15698">African</TOKEN>
<TOKEN end_char="15715" id="token-127-39" morph="none" pos="word" start_char="15706">institutes</TOKEN>
<TOKEN end_char="15717" id="token-127-40" morph="none" pos="punct" start_char="15716">.)</TOKEN>
</SEG>
<SEG end_char="15891" id="segment-128" start_char="15720">
<ORIGINAL_TEXT>3 _ The Institut Pasteur (Paris) indeed conducted research in France on a previous coronavirus (SARS-CoV-1), which has nothing to do with SARS-CoV-2, which causes Covid-19.</ORIGINAL_TEXT>
<TOKEN end_char="15720" id="token-128-0" morph="none" pos="word" start_char="15720">3</TOKEN>
<TOKEN end_char="15722" id="token-128-1" morph="none" pos="word" start_char="15722">_</TOKEN>
<TOKEN end_char="15726" id="token-128-2" morph="none" pos="word" start_char="15724">The</TOKEN>
<TOKEN end_char="15735" id="token-128-3" morph="none" pos="word" start_char="15728">Institut</TOKEN>
<TOKEN end_char="15743" id="token-128-4" morph="none" pos="word" start_char="15737">Pasteur</TOKEN>
<TOKEN end_char="15745" id="token-128-5" morph="none" pos="punct" start_char="15745">(</TOKEN>
<TOKEN end_char="15750" id="token-128-6" morph="none" pos="word" start_char="15746">Paris</TOKEN>
<TOKEN end_char="15751" id="token-128-7" morph="none" pos="punct" start_char="15751">)</TOKEN>
<TOKEN end_char="15758" id="token-128-8" morph="none" pos="word" start_char="15753">indeed</TOKEN>
<TOKEN end_char="15768" id="token-128-9" morph="none" pos="word" start_char="15760">conducted</TOKEN>
<TOKEN end_char="15777" id="token-128-10" morph="none" pos="word" start_char="15770">research</TOKEN>
<TOKEN end_char="15780" id="token-128-11" morph="none" pos="word" start_char="15779">in</TOKEN>
<TOKEN end_char="15787" id="token-128-12" morph="none" pos="word" start_char="15782">France</TOKEN>
<TOKEN end_char="15790" id="token-128-13" morph="none" pos="word" start_char="15789">on</TOKEN>
<TOKEN end_char="15792" id="token-128-14" morph="none" pos="word" start_char="15792">a</TOKEN>
<TOKEN end_char="15801" id="token-128-15" morph="none" pos="word" start_char="15794">previous</TOKEN>
<TOKEN end_char="15813" id="token-128-16" morph="none" pos="word" start_char="15803">coronavirus</TOKEN>
<TOKEN end_char="15815" id="token-128-17" morph="none" pos="punct" start_char="15815">(</TOKEN>
<TOKEN end_char="15825" id="token-128-18" morph="none" pos="unknown" start_char="15816">SARS-CoV-1</TOKEN>
<TOKEN end_char="15827" id="token-128-19" morph="none" pos="punct" start_char="15826">),</TOKEN>
<TOKEN end_char="15833" id="token-128-20" morph="none" pos="word" start_char="15829">which</TOKEN>
<TOKEN end_char="15837" id="token-128-21" morph="none" pos="word" start_char="15835">has</TOKEN>
<TOKEN end_char="15845" id="token-128-22" morph="none" pos="word" start_char="15839">nothing</TOKEN>
<TOKEN end_char="15848" id="token-128-23" morph="none" pos="word" start_char="15847">to</TOKEN>
<TOKEN end_char="15851" id="token-128-24" morph="none" pos="word" start_char="15850">do</TOKEN>
<TOKEN end_char="15856" id="token-128-25" morph="none" pos="word" start_char="15853">with</TOKEN>
<TOKEN end_char="15867" id="token-128-26" morph="none" pos="unknown" start_char="15858">SARS-CoV-2</TOKEN>
<TOKEN end_char="15868" id="token-128-27" morph="none" pos="punct" start_char="15868">,</TOKEN>
<TOKEN end_char="15874" id="token-128-28" morph="none" pos="word" start_char="15870">which</TOKEN>
<TOKEN end_char="15881" id="token-128-29" morph="none" pos="word" start_char="15876">causes</TOKEN>
<TOKEN end_char="15890" id="token-128-30" morph="none" pos="unknown" start_char="15883">Covid-19</TOKEN>
<TOKEN end_char="15891" id="token-128-31" morph="none" pos="punct" start_char="15891">.</TOKEN>
</SEG>
<SEG end_char="16064" id="segment-129" start_char="15895">
<ORIGINAL_TEXT>The Institut Pasteur (Paris) indeed conducted research in France, between 2002 and 2004, on a preceding coronavirus (SARS-CoV-1) which was the cause of the 2003 epidemic.</ORIGINAL_TEXT>
<TOKEN end_char="15897" id="token-129-0" morph="none" pos="word" start_char="15895">The</TOKEN>
<TOKEN end_char="15906" id="token-129-1" morph="none" pos="word" start_char="15899">Institut</TOKEN>
<TOKEN end_char="15914" id="token-129-2" morph="none" pos="word" start_char="15908">Pasteur</TOKEN>
<TOKEN end_char="15916" id="token-129-3" morph="none" pos="punct" start_char="15916">(</TOKEN>
<TOKEN end_char="15921" id="token-129-4" morph="none" pos="word" start_char="15917">Paris</TOKEN>
<TOKEN end_char="15922" id="token-129-5" morph="none" pos="punct" start_char="15922">)</TOKEN>
<TOKEN end_char="15929" id="token-129-6" morph="none" pos="word" start_char="15924">indeed</TOKEN>
<TOKEN end_char="15939" id="token-129-7" morph="none" pos="word" start_char="15931">conducted</TOKEN>
<TOKEN end_char="15948" id="token-129-8" morph="none" pos="word" start_char="15941">research</TOKEN>
<TOKEN end_char="15951" id="token-129-9" morph="none" pos="word" start_char="15950">in</TOKEN>
<TOKEN end_char="15958" id="token-129-10" morph="none" pos="word" start_char="15953">France</TOKEN>
<TOKEN end_char="15959" id="token-129-11" morph="none" pos="punct" start_char="15959">,</TOKEN>
<TOKEN end_char="15967" id="token-129-12" morph="none" pos="word" start_char="15961">between</TOKEN>
<TOKEN end_char="15972" id="token-129-13" morph="none" pos="word" start_char="15969">2002</TOKEN>
<TOKEN end_char="15976" id="token-129-14" morph="none" pos="word" start_char="15974">and</TOKEN>
<TOKEN end_char="15981" id="token-129-15" morph="none" pos="word" start_char="15978">2004</TOKEN>
<TOKEN end_char="15982" id="token-129-16" morph="none" pos="punct" start_char="15982">,</TOKEN>
<TOKEN end_char="15985" id="token-129-17" morph="none" pos="word" start_char="15984">on</TOKEN>
<TOKEN end_char="15987" id="token-129-18" morph="none" pos="word" start_char="15987">a</TOKEN>
<TOKEN end_char="15997" id="token-129-19" morph="none" pos="word" start_char="15989">preceding</TOKEN>
<TOKEN end_char="16009" id="token-129-20" morph="none" pos="word" start_char="15999">coronavirus</TOKEN>
<TOKEN end_char="16011" id="token-129-21" morph="none" pos="punct" start_char="16011">(</TOKEN>
<TOKEN end_char="16021" id="token-129-22" morph="none" pos="unknown" start_char="16012">SARS-CoV-1</TOKEN>
<TOKEN end_char="16022" id="token-129-23" morph="none" pos="punct" start_char="16022">)</TOKEN>
<TOKEN end_char="16028" id="token-129-24" morph="none" pos="word" start_char="16024">which</TOKEN>
<TOKEN end_char="16032" id="token-129-25" morph="none" pos="word" start_char="16030">was</TOKEN>
<TOKEN end_char="16036" id="token-129-26" morph="none" pos="word" start_char="16034">the</TOKEN>
<TOKEN end_char="16042" id="token-129-27" morph="none" pos="word" start_char="16038">cause</TOKEN>
<TOKEN end_char="16045" id="token-129-28" morph="none" pos="word" start_char="16044">of</TOKEN>
<TOKEN end_char="16049" id="token-129-29" morph="none" pos="word" start_char="16047">the</TOKEN>
<TOKEN end_char="16054" id="token-129-30" morph="none" pos="word" start_char="16051">2003</TOKEN>
<TOKEN end_char="16063" id="token-129-31" morph="none" pos="word" start_char="16056">epidemic</TOKEN>
<TOKEN end_char="16064" id="token-129-32" morph="none" pos="punct" start_char="16064">.</TOKEN>
</SEG>
<SEG end_char="16142" id="segment-130" start_char="16066">
<ORIGINAL_TEXT>Furthermore, in 2004 the Institut created a vaccine candidate for SARS-CoV-1.</ORIGINAL_TEXT>
<TOKEN end_char="16076" id="token-130-0" morph="none" pos="word" start_char="16066">Furthermore</TOKEN>
<TOKEN end_char="16077" id="token-130-1" morph="none" pos="punct" start_char="16077">,</TOKEN>
<TOKEN end_char="16080" id="token-130-2" morph="none" pos="word" start_char="16079">in</TOKEN>
<TOKEN end_char="16085" id="token-130-3" morph="none" pos="word" start_char="16082">2004</TOKEN>
<TOKEN end_char="16089" id="token-130-4" morph="none" pos="word" start_char="16087">the</TOKEN>
<TOKEN end_char="16098" id="token-130-5" morph="none" pos="word" start_char="16091">Institut</TOKEN>
<TOKEN end_char="16106" id="token-130-6" morph="none" pos="word" start_char="16100">created</TOKEN>
<TOKEN end_char="16108" id="token-130-7" morph="none" pos="word" start_char="16108">a</TOKEN>
<TOKEN end_char="16116" id="token-130-8" morph="none" pos="word" start_char="16110">vaccine</TOKEN>
<TOKEN end_char="16126" id="token-130-9" morph="none" pos="word" start_char="16118">candidate</TOKEN>
<TOKEN end_char="16130" id="token-130-10" morph="none" pos="word" start_char="16128">for</TOKEN>
<TOKEN end_char="16141" id="token-130-11" morph="none" pos="unknown" start_char="16132">SARS-CoV-1</TOKEN>
<TOKEN end_char="16142" id="token-130-12" morph="none" pos="punct" start_char="16142">.</TOKEN>
</SEG>
<SEG end_char="16355" id="segment-131" start_char="16145">
<ORIGINAL_TEXT>The construction of the P4 laboratory of Wuhan began in 2011 and was inaugurated in 2017, which is to say, a dozen years after the invention disclosure that was touted as evidence in the conspiracy theory video.</ORIGINAL_TEXT>
<TOKEN end_char="16147" id="token-131-0" morph="none" pos="word" start_char="16145">The</TOKEN>
<TOKEN end_char="16160" id="token-131-1" morph="none" pos="word" start_char="16149">construction</TOKEN>
<TOKEN end_char="16163" id="token-131-2" morph="none" pos="word" start_char="16162">of</TOKEN>
<TOKEN end_char="16167" id="token-131-3" morph="none" pos="word" start_char="16165">the</TOKEN>
<TOKEN end_char="16170" id="token-131-4" morph="none" pos="word" start_char="16169">P4</TOKEN>
<TOKEN end_char="16181" id="token-131-5" morph="none" pos="word" start_char="16172">laboratory</TOKEN>
<TOKEN end_char="16184" id="token-131-6" morph="none" pos="word" start_char="16183">of</TOKEN>
<TOKEN end_char="16190" id="token-131-7" morph="none" pos="word" start_char="16186">Wuhan</TOKEN>
<TOKEN end_char="16196" id="token-131-8" morph="none" pos="word" start_char="16192">began</TOKEN>
<TOKEN end_char="16199" id="token-131-9" morph="none" pos="word" start_char="16198">in</TOKEN>
<TOKEN end_char="16204" id="token-131-10" morph="none" pos="word" start_char="16201">2011</TOKEN>
<TOKEN end_char="16208" id="token-131-11" morph="none" pos="word" start_char="16206">and</TOKEN>
<TOKEN end_char="16212" id="token-131-12" morph="none" pos="word" start_char="16210">was</TOKEN>
<TOKEN end_char="16224" id="token-131-13" morph="none" pos="word" start_char="16214">inaugurated</TOKEN>
<TOKEN end_char="16227" id="token-131-14" morph="none" pos="word" start_char="16226">in</TOKEN>
<TOKEN end_char="16232" id="token-131-15" morph="none" pos="word" start_char="16229">2017</TOKEN>
<TOKEN end_char="16233" id="token-131-16" morph="none" pos="punct" start_char="16233">,</TOKEN>
<TOKEN end_char="16239" id="token-131-17" morph="none" pos="word" start_char="16235">which</TOKEN>
<TOKEN end_char="16242" id="token-131-18" morph="none" pos="word" start_char="16241">is</TOKEN>
<TOKEN end_char="16245" id="token-131-19" morph="none" pos="word" start_char="16244">to</TOKEN>
<TOKEN end_char="16249" id="token-131-20" morph="none" pos="word" start_char="16247">say</TOKEN>
<TOKEN end_char="16250" id="token-131-21" morph="none" pos="punct" start_char="16250">,</TOKEN>
<TOKEN end_char="16252" id="token-131-22" morph="none" pos="word" start_char="16252">a</TOKEN>
<TOKEN end_char="16258" id="token-131-23" morph="none" pos="word" start_char="16254">dozen</TOKEN>
<TOKEN end_char="16264" id="token-131-24" morph="none" pos="word" start_char="16260">years</TOKEN>
<TOKEN end_char="16270" id="token-131-25" morph="none" pos="word" start_char="16266">after</TOKEN>
<TOKEN end_char="16274" id="token-131-26" morph="none" pos="word" start_char="16272">the</TOKEN>
<TOKEN end_char="16284" id="token-131-27" morph="none" pos="word" start_char="16276">invention</TOKEN>
<TOKEN end_char="16295" id="token-131-28" morph="none" pos="word" start_char="16286">disclosure</TOKEN>
<TOKEN end_char="16300" id="token-131-29" morph="none" pos="word" start_char="16297">that</TOKEN>
<TOKEN end_char="16304" id="token-131-30" morph="none" pos="word" start_char="16302">was</TOKEN>
<TOKEN end_char="16311" id="token-131-31" morph="none" pos="word" start_char="16306">touted</TOKEN>
<TOKEN end_char="16314" id="token-131-32" morph="none" pos="word" start_char="16313">as</TOKEN>
<TOKEN end_char="16323" id="token-131-33" morph="none" pos="word" start_char="16316">evidence</TOKEN>
<TOKEN end_char="16326" id="token-131-34" morph="none" pos="word" start_char="16325">in</TOKEN>
<TOKEN end_char="16330" id="token-131-35" morph="none" pos="word" start_char="16328">the</TOKEN>
<TOKEN end_char="16341" id="token-131-36" morph="none" pos="word" start_char="16332">conspiracy</TOKEN>
<TOKEN end_char="16348" id="token-131-37" morph="none" pos="word" start_char="16343">theory</TOKEN>
<TOKEN end_char="16354" id="token-131-38" morph="none" pos="word" start_char="16350">video</TOKEN>
<TOKEN end_char="16355" id="token-131-39" morph="none" pos="punct" start_char="16355">.</TOKEN>
</SEG>
<SEG end_char="16450" id="segment-132" start_char="16358">
<ORIGINAL_TEXT>NO, the Institut Pasteur did not invent Covid-19 or the virus responsible for it, SARS-CoV-2!</ORIGINAL_TEXT>
<TOKEN end_char="16359" id="token-132-0" morph="none" pos="word" start_char="16358">NO</TOKEN>
<TOKEN end_char="16360" id="token-132-1" morph="none" pos="punct" start_char="16360">,</TOKEN>
<TOKEN end_char="16364" id="token-132-2" morph="none" pos="word" start_char="16362">the</TOKEN>
<TOKEN end_char="16373" id="token-132-3" morph="none" pos="word" start_char="16366">Institut</TOKEN>
<TOKEN end_char="16381" id="token-132-4" morph="none" pos="word" start_char="16375">Pasteur</TOKEN>
<TOKEN end_char="16385" id="token-132-5" morph="none" pos="word" start_char="16383">did</TOKEN>
<TOKEN end_char="16389" id="token-132-6" morph="none" pos="word" start_char="16387">not</TOKEN>
<TOKEN end_char="16396" id="token-132-7" morph="none" pos="word" start_char="16391">invent</TOKEN>
<TOKEN end_char="16405" id="token-132-8" morph="none" pos="unknown" start_char="16398">Covid-19</TOKEN>
<TOKEN end_char="16408" id="token-132-9" morph="none" pos="word" start_char="16407">or</TOKEN>
<TOKEN end_char="16412" id="token-132-10" morph="none" pos="word" start_char="16410">the</TOKEN>
<TOKEN end_char="16418" id="token-132-11" morph="none" pos="word" start_char="16414">virus</TOKEN>
<TOKEN end_char="16430" id="token-132-12" morph="none" pos="word" start_char="16420">responsible</TOKEN>
<TOKEN end_char="16434" id="token-132-13" morph="none" pos="word" start_char="16432">for</TOKEN>
<TOKEN end_char="16437" id="token-132-14" morph="none" pos="word" start_char="16436">it</TOKEN>
<TOKEN end_char="16438" id="token-132-15" morph="none" pos="punct" start_char="16438">,</TOKEN>
<TOKEN end_char="16449" id="token-132-16" morph="none" pos="unknown" start_char="16440">SARS-CoV-2</TOKEN>
<TOKEN end_char="16450" id="token-132-17" morph="none" pos="punct" start_char="16450">!</TOKEN>
</SEG>
<SEG end_char="16475" id="segment-133" start_char="16453">
<ORIGINAL_TEXT>Text of March 18, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="16456" id="token-133-0" morph="none" pos="word" start_char="16453">Text</TOKEN>
<TOKEN end_char="16459" id="token-133-1" morph="none" pos="word" start_char="16458">of</TOKEN>
<TOKEN end_char="16465" id="token-133-2" morph="none" pos="word" start_char="16461">March</TOKEN>
<TOKEN end_char="16468" id="token-133-3" morph="none" pos="word" start_char="16467">18</TOKEN>
<TOKEN end_char="16469" id="token-133-4" morph="none" pos="punct" start_char="16469">,</TOKEN>
<TOKEN end_char="16474" id="token-133-5" morph="none" pos="word" start_char="16471">2020</TOKEN>
<TOKEN end_char="16475" id="token-133-6" morph="none" pos="punct" start_char="16475">.</TOKEN>
</SEG>
<SEG end_char="16501" id="segment-134" start_char="16477">
<ORIGINAL_TEXT>Updated November 4, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="16483" id="token-134-0" morph="none" pos="word" start_char="16477">Updated</TOKEN>
<TOKEN end_char="16492" id="token-134-1" morph="none" pos="word" start_char="16485">November</TOKEN>
<TOKEN end_char="16494" id="token-134-2" morph="none" pos="word" start_char="16494">4</TOKEN>
<TOKEN end_char="16495" id="token-134-3" morph="none" pos="punct" start_char="16495">,</TOKEN>
<TOKEN end_char="16500" id="token-134-4" morph="none" pos="word" start_char="16497">2020</TOKEN>
<TOKEN end_char="16501" id="token-134-5" morph="none" pos="punct" start_char="16501">.</TOKEN>
</SEG>
<SEG end_char="16705" id="segment-135" start_char="16505">
<ORIGINAL_TEXT>A video posted on March 17, 2020, of a conspiratorial nature, claims - on a misinterpretation of a patent filed in 2004 - that the Institut Pasteur would have invented Covid-19 for commercial purposes.</ORIGINAL_TEXT>
<TOKEN end_char="16505" id="token-135-0" morph="none" pos="word" start_char="16505">A</TOKEN>
<TOKEN end_char="16511" id="token-135-1" morph="none" pos="word" start_char="16507">video</TOKEN>
<TOKEN end_char="16518" id="token-135-2" morph="none" pos="word" start_char="16513">posted</TOKEN>
<TOKEN end_char="16521" id="token-135-3" morph="none" pos="word" start_char="16520">on</TOKEN>
<TOKEN end_char="16527" id="token-135-4" morph="none" pos="word" start_char="16523">March</TOKEN>
<TOKEN end_char="16530" id="token-135-5" morph="none" pos="word" start_char="16529">17</TOKEN>
<TOKEN end_char="16531" id="token-135-6" morph="none" pos="punct" start_char="16531">,</TOKEN>
<TOKEN end_char="16536" id="token-135-7" morph="none" pos="word" start_char="16533">2020</TOKEN>
<TOKEN end_char="16537" id="token-135-8" morph="none" pos="punct" start_char="16537">,</TOKEN>
<TOKEN end_char="16540" id="token-135-9" morph="none" pos="word" start_char="16539">of</TOKEN>
<TOKEN end_char="16542" id="token-135-10" morph="none" pos="word" start_char="16542">a</TOKEN>
<TOKEN end_char="16557" id="token-135-11" morph="none" pos="word" start_char="16544">conspiratorial</TOKEN>
<TOKEN end_char="16564" id="token-135-12" morph="none" pos="word" start_char="16559">nature</TOKEN>
<TOKEN end_char="16565" id="token-135-13" morph="none" pos="punct" start_char="16565">,</TOKEN>
<TOKEN end_char="16572" id="token-135-14" morph="none" pos="word" start_char="16567">claims</TOKEN>
<TOKEN end_char="16574" id="token-135-15" morph="none" pos="punct" start_char="16574">-</TOKEN>
<TOKEN end_char="16577" id="token-135-16" morph="none" pos="word" start_char="16576">on</TOKEN>
<TOKEN end_char="16579" id="token-135-17" morph="none" pos="word" start_char="16579">a</TOKEN>
<TOKEN end_char="16597" id="token-135-18" morph="none" pos="word" start_char="16581">misinterpretation</TOKEN>
<TOKEN end_char="16600" id="token-135-19" morph="none" pos="word" start_char="16599">of</TOKEN>
<TOKEN end_char="16602" id="token-135-20" morph="none" pos="word" start_char="16602">a</TOKEN>
<TOKEN end_char="16609" id="token-135-21" morph="none" pos="word" start_char="16604">patent</TOKEN>
<TOKEN end_char="16615" id="token-135-22" morph="none" pos="word" start_char="16611">filed</TOKEN>
<TOKEN end_char="16618" id="token-135-23" morph="none" pos="word" start_char="16617">in</TOKEN>
<TOKEN end_char="16623" id="token-135-24" morph="none" pos="word" start_char="16620">2004</TOKEN>
<TOKEN end_char="16625" id="token-135-25" morph="none" pos="punct" start_char="16625">-</TOKEN>
<TOKEN end_char="16630" id="token-135-26" morph="none" pos="word" start_char="16627">that</TOKEN>
<TOKEN end_char="16634" id="token-135-27" morph="none" pos="word" start_char="16632">the</TOKEN>
<TOKEN end_char="16643" id="token-135-28" morph="none" pos="word" start_char="16636">Institut</TOKEN>
<TOKEN end_char="16651" id="token-135-29" morph="none" pos="word" start_char="16645">Pasteur</TOKEN>
<TOKEN end_char="16657" id="token-135-30" morph="none" pos="word" start_char="16653">would</TOKEN>
<TOKEN end_char="16662" id="token-135-31" morph="none" pos="word" start_char="16659">have</TOKEN>
<TOKEN end_char="16671" id="token-135-32" morph="none" pos="word" start_char="16664">invented</TOKEN>
<TOKEN end_char="16680" id="token-135-33" morph="none" pos="unknown" start_char="16673">Covid-19</TOKEN>
<TOKEN end_char="16684" id="token-135-34" morph="none" pos="word" start_char="16682">for</TOKEN>
<TOKEN end_char="16695" id="token-135-35" morph="none" pos="word" start_char="16686">commercial</TOKEN>
<TOKEN end_char="16704" id="token-135-36" morph="none" pos="word" start_char="16697">purposes</TOKEN>
<TOKEN end_char="16705" id="token-135-37" morph="none" pos="punct" start_char="16705">.</TOKEN>
</SEG>
<SEG end_char="16745" id="segment-136" start_char="16707">
<ORIGINAL_TEXT>It is false and without any foundation.</ORIGINAL_TEXT>
<TOKEN end_char="16708" id="token-136-0" morph="none" pos="word" start_char="16707">It</TOKEN>
<TOKEN end_char="16711" id="token-136-1" morph="none" pos="word" start_char="16710">is</TOKEN>
<TOKEN end_char="16717" id="token-136-2" morph="none" pos="word" start_char="16713">false</TOKEN>
<TOKEN end_char="16721" id="token-136-3" morph="none" pos="word" start_char="16719">and</TOKEN>
<TOKEN end_char="16729" id="token-136-4" morph="none" pos="word" start_char="16723">without</TOKEN>
<TOKEN end_char="16733" id="token-136-5" morph="none" pos="word" start_char="16731">any</TOKEN>
<TOKEN end_char="16744" id="token-136-6" morph="none" pos="word" start_char="16735">foundation</TOKEN>
<TOKEN end_char="16745" id="token-136-7" morph="none" pos="punct" start_char="16745">.</TOKEN>
</SEG>
<SEG end_char="16822" id="segment-137" start_char="16747">
<ORIGINAL_TEXT>These comments are defamatory of the Institut Pasteur and its collaborators.</ORIGINAL_TEXT>
<TOKEN end_char="16751" id="token-137-0" morph="none" pos="word" start_char="16747">These</TOKEN>
<TOKEN end_char="16760" id="token-137-1" morph="none" pos="word" start_char="16753">comments</TOKEN>
<TOKEN end_char="16764" id="token-137-2" morph="none" pos="word" start_char="16762">are</TOKEN>
<TOKEN end_char="16775" id="token-137-3" morph="none" pos="word" start_char="16766">defamatory</TOKEN>
<TOKEN end_char="16778" id="token-137-4" morph="none" pos="word" start_char="16777">of</TOKEN>
<TOKEN end_char="16782" id="token-137-5" morph="none" pos="word" start_char="16780">the</TOKEN>
<TOKEN end_char="16791" id="token-137-6" morph="none" pos="word" start_char="16784">Institut</TOKEN>
<TOKEN end_char="16799" id="token-137-7" morph="none" pos="word" start_char="16793">Pasteur</TOKEN>
<TOKEN end_char="16803" id="token-137-8" morph="none" pos="word" start_char="16801">and</TOKEN>
<TOKEN end_char="16807" id="token-137-9" morph="none" pos="word" start_char="16805">its</TOKEN>
<TOKEN end_char="16821" id="token-137-10" morph="none" pos="word" start_char="16809">collaborators</TOKEN>
<TOKEN end_char="16822" id="token-137-11" morph="none" pos="punct" start_char="16822">.</TOKEN>
</SEG>
<SEG end_char="16930" id="segment-138" start_char="16826">
<ORIGINAL_TEXT>The Institut Pasteur invented a vaccine candidate in 2004 for a previous coronavirus known as SARS-CoV-1.</ORIGINAL_TEXT>
<TOKEN end_char="16828" id="token-138-0" morph="none" pos="word" start_char="16826">The</TOKEN>
<TOKEN end_char="16837" id="token-138-1" morph="none" pos="word" start_char="16830">Institut</TOKEN>
<TOKEN end_char="16845" id="token-138-2" morph="none" pos="word" start_char="16839">Pasteur</TOKEN>
<TOKEN end_char="16854" id="token-138-3" morph="none" pos="word" start_char="16847">invented</TOKEN>
<TOKEN end_char="16856" id="token-138-4" morph="none" pos="word" start_char="16856">a</TOKEN>
<TOKEN end_char="16864" id="token-138-5" morph="none" pos="word" start_char="16858">vaccine</TOKEN>
<TOKEN end_char="16874" id="token-138-6" morph="none" pos="word" start_char="16866">candidate</TOKEN>
<TOKEN end_char="16877" id="token-138-7" morph="none" pos="word" start_char="16876">in</TOKEN>
<TOKEN end_char="16882" id="token-138-8" morph="none" pos="word" start_char="16879">2004</TOKEN>
<TOKEN end_char="16886" id="token-138-9" morph="none" pos="word" start_char="16884">for</TOKEN>
<TOKEN end_char="16888" id="token-138-10" morph="none" pos="word" start_char="16888">a</TOKEN>
<TOKEN end_char="16897" id="token-138-11" morph="none" pos="word" start_char="16890">previous</TOKEN>
<TOKEN end_char="16909" id="token-138-12" morph="none" pos="word" start_char="16899">coronavirus</TOKEN>
<TOKEN end_char="16915" id="token-138-13" morph="none" pos="word" start_char="16911">known</TOKEN>
<TOKEN end_char="16918" id="token-138-14" morph="none" pos="word" start_char="16917">as</TOKEN>
<TOKEN end_char="16929" id="token-138-15" morph="none" pos="unknown" start_char="16920">SARS-CoV-1</TOKEN>
<TOKEN end_char="16930" id="token-138-16" morph="none" pos="punct" start_char="16930">.</TOKEN>
</SEG>
<SEG end_char="17019" id="segment-139" start_char="16936">
<ORIGINAL_TEXT>The conspiracy theory video currently doing the rounds on the Web is entirely false.</ORIGINAL_TEXT>
<TOKEN end_char="16938" id="token-139-0" morph="none" pos="word" start_char="16936">The</TOKEN>
<TOKEN end_char="16949" id="token-139-1" morph="none" pos="word" start_char="16940">conspiracy</TOKEN>
<TOKEN end_char="16956" id="token-139-2" morph="none" pos="word" start_char="16951">theory</TOKEN>
<TOKEN end_char="16962" id="token-139-3" morph="none" pos="word" start_char="16958">video</TOKEN>
<TOKEN end_char="16972" id="token-139-4" morph="none" pos="word" start_char="16964">currently</TOKEN>
<TOKEN end_char="16978" id="token-139-5" morph="none" pos="word" start_char="16974">doing</TOKEN>
<TOKEN end_char="16982" id="token-139-6" morph="none" pos="word" start_char="16980">the</TOKEN>
<TOKEN end_char="16989" id="token-139-7" morph="none" pos="word" start_char="16984">rounds</TOKEN>
<TOKEN end_char="16992" id="token-139-8" morph="none" pos="word" start_char="16991">on</TOKEN>
<TOKEN end_char="16996" id="token-139-9" morph="none" pos="word" start_char="16994">the</TOKEN>
<TOKEN end_char="17000" id="token-139-10" morph="none" pos="word" start_char="16998">Web</TOKEN>
<TOKEN end_char="17003" id="token-139-11" morph="none" pos="word" start_char="17002">is</TOKEN>
<TOKEN end_char="17012" id="token-139-12" morph="none" pos="word" start_char="17005">entirely</TOKEN>
<TOKEN end_char="17018" id="token-139-13" morph="none" pos="word" start_char="17014">false</TOKEN>
<TOKEN end_char="17019" id="token-139-14" morph="none" pos="punct" start_char="17019">.</TOKEN>
</SEG>
<SEG end_char="17036" id="segment-140" start_char="17025">
<ORIGINAL_TEXT>Explanations</ORIGINAL_TEXT>
<TOKEN end_char="17036" id="token-140-0" morph="none" pos="word" start_char="17025">Explanations</TOKEN>
</SEG>
<SEG end_char="17138" id="segment-141" start_char="17040">
<ORIGINAL_TEXT>One of the Institut Pasteur's missions is to work on all emerging viruses, including coronaviruses.</ORIGINAL_TEXT>
<TOKEN end_char="17042" id="token-141-0" morph="none" pos="word" start_char="17040">One</TOKEN>
<TOKEN end_char="17045" id="token-141-1" morph="none" pos="word" start_char="17044">of</TOKEN>
<TOKEN end_char="17049" id="token-141-2" morph="none" pos="word" start_char="17047">the</TOKEN>
<TOKEN end_char="17058" id="token-141-3" morph="none" pos="word" start_char="17051">Institut</TOKEN>
<TOKEN end_char="17068" id="token-141-4" morph="none" pos="word" start_char="17060">Pasteur's</TOKEN>
<TOKEN end_char="17077" id="token-141-5" morph="none" pos="word" start_char="17070">missions</TOKEN>
<TOKEN end_char="17080" id="token-141-6" morph="none" pos="word" start_char="17079">is</TOKEN>
<TOKEN end_char="17083" id="token-141-7" morph="none" pos="word" start_char="17082">to</TOKEN>
<TOKEN end_char="17088" id="token-141-8" morph="none" pos="word" start_char="17085">work</TOKEN>
<TOKEN end_char="17091" id="token-141-9" morph="none" pos="word" start_char="17090">on</TOKEN>
<TOKEN end_char="17095" id="token-141-10" morph="none" pos="word" start_char="17093">all</TOKEN>
<TOKEN end_char="17104" id="token-141-11" morph="none" pos="word" start_char="17097">emerging</TOKEN>
<TOKEN end_char="17112" id="token-141-12" morph="none" pos="word" start_char="17106">viruses</TOKEN>
<TOKEN end_char="17113" id="token-141-13" morph="none" pos="punct" start_char="17113">,</TOKEN>
<TOKEN end_char="17123" id="token-141-14" morph="none" pos="word" start_char="17115">including</TOKEN>
<TOKEN end_char="17137" id="token-141-15" morph="none" pos="word" start_char="17125">coronaviruses</TOKEN>
<TOKEN end_char="17138" id="token-141-16" morph="none" pos="punct" start_char="17138">.</TOKEN>
</SEG>
<SEG end_char="17192" id="segment-142" start_char="17140">
<ORIGINAL_TEXT>And there are several different types of coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="17142" id="token-142-0" morph="none" pos="word" start_char="17140">And</TOKEN>
<TOKEN end_char="17148" id="token-142-1" morph="none" pos="word" start_char="17144">there</TOKEN>
<TOKEN end_char="17152" id="token-142-2" morph="none" pos="word" start_char="17150">are</TOKEN>
<TOKEN end_char="17160" id="token-142-3" morph="none" pos="word" start_char="17154">several</TOKEN>
<TOKEN end_char="17170" id="token-142-4" morph="none" pos="word" start_char="17162">different</TOKEN>
<TOKEN end_char="17176" id="token-142-5" morph="none" pos="word" start_char="17172">types</TOKEN>
<TOKEN end_char="17179" id="token-142-6" morph="none" pos="word" start_char="17178">of</TOKEN>
<TOKEN end_char="17191" id="token-142-7" morph="none" pos="word" start_char="17181">coronavirus</TOKEN>
<TOKEN end_char="17192" id="token-142-8" morph="none" pos="punct" start_char="17192">.</TOKEN>
</SEG>
<SEG end_char="17318" id="segment-143" start_char="17195">
<ORIGINAL_TEXT>In 2002, a first coronavirus, SARS-CoV-1, emerged in China, causing an outbreak of severe acute respiratory syndrome (SARS).</ORIGINAL_TEXT>
<TOKEN end_char="17196" id="token-143-0" morph="none" pos="word" start_char="17195">In</TOKEN>
<TOKEN end_char="17201" id="token-143-1" morph="none" pos="word" start_char="17198">2002</TOKEN>
<TOKEN end_char="17202" id="token-143-2" morph="none" pos="punct" start_char="17202">,</TOKEN>
<TOKEN end_char="17204" id="token-143-3" morph="none" pos="word" start_char="17204">a</TOKEN>
<TOKEN end_char="17210" id="token-143-4" morph="none" pos="word" start_char="17206">first</TOKEN>
<TOKEN end_char="17222" id="token-143-5" morph="none" pos="word" start_char="17212">coronavirus</TOKEN>
<TOKEN end_char="17223" id="token-143-6" morph="none" pos="punct" start_char="17223">,</TOKEN>
<TOKEN end_char="17234" id="token-143-7" morph="none" pos="unknown" start_char="17225">SARS-CoV-1</TOKEN>
<TOKEN end_char="17235" id="token-143-8" morph="none" pos="punct" start_char="17235">,</TOKEN>
<TOKEN end_char="17243" id="token-143-9" morph="none" pos="word" start_char="17237">emerged</TOKEN>
<TOKEN end_char="17246" id="token-143-10" morph="none" pos="word" start_char="17245">in</TOKEN>
<TOKEN end_char="17252" id="token-143-11" morph="none" pos="word" start_char="17248">China</TOKEN>
<TOKEN end_char="17253" id="token-143-12" morph="none" pos="punct" start_char="17253">,</TOKEN>
<TOKEN end_char="17261" id="token-143-13" morph="none" pos="word" start_char="17255">causing</TOKEN>
<TOKEN end_char="17264" id="token-143-14" morph="none" pos="word" start_char="17263">an</TOKEN>
<TOKEN end_char="17273" id="token-143-15" morph="none" pos="word" start_char="17266">outbreak</TOKEN>
<TOKEN end_char="17276" id="token-143-16" morph="none" pos="word" start_char="17275">of</TOKEN>
<TOKEN end_char="17283" id="token-143-17" morph="none" pos="word" start_char="17278">severe</TOKEN>
<TOKEN end_char="17289" id="token-143-18" morph="none" pos="word" start_char="17285">acute</TOKEN>
<TOKEN end_char="17301" id="token-143-19" morph="none" pos="word" start_char="17291">respiratory</TOKEN>
<TOKEN end_char="17310" id="token-143-20" morph="none" pos="word" start_char="17303">syndrome</TOKEN>
<TOKEN end_char="17312" id="token-143-21" morph="none" pos="punct" start_char="17312">(</TOKEN>
<TOKEN end_char="17316" id="token-143-22" morph="none" pos="word" start_char="17313">SARS</TOKEN>
<TOKEN end_char="17318" id="token-143-23" morph="none" pos="punct" start_char="17317">).</TOKEN>
</SEG>
<SEG end_char="17388" id="segment-144" start_char="17322">
<ORIGINAL_TEXT>​In 2003, this outbreak spread to several countries and continents.</ORIGINAL_TEXT>
<TOKEN end_char="17324" id="token-144-0" morph="none" pos="unknown" start_char="17322">​In</TOKEN>
<TOKEN end_char="17329" id="token-144-1" morph="none" pos="word" start_char="17326">2003</TOKEN>
<TOKEN end_char="17330" id="token-144-2" morph="none" pos="punct" start_char="17330">,</TOKEN>
<TOKEN end_char="17335" id="token-144-3" morph="none" pos="word" start_char="17332">this</TOKEN>
<TOKEN end_char="17344" id="token-144-4" morph="none" pos="word" start_char="17337">outbreak</TOKEN>
<TOKEN end_char="17351" id="token-144-5" morph="none" pos="word" start_char="17346">spread</TOKEN>
<TOKEN end_char="17354" id="token-144-6" morph="none" pos="word" start_char="17353">to</TOKEN>
<TOKEN end_char="17362" id="token-144-7" morph="none" pos="word" start_char="17356">several</TOKEN>
<TOKEN end_char="17372" id="token-144-8" morph="none" pos="word" start_char="17364">countries</TOKEN>
<TOKEN end_char="17376" id="token-144-9" morph="none" pos="word" start_char="17374">and</TOKEN>
<TOKEN end_char="17387" id="token-144-10" morph="none" pos="word" start_char="17378">continents</TOKEN>
<TOKEN end_char="17388" id="token-144-11" morph="none" pos="punct" start_char="17388">.</TOKEN>
</SEG>
<SEG end_char="17718" id="segment-145" start_char="17392">
<ORIGINAL_TEXT>At the time, the Institut Pasteur's teams responded to the outbreak by proposing a number of vaccine strategies, including a vaccine candidate based on the measles virus vaccine platform (the measles vaccine can be recombined and used as a means of inducing an immune response against other pathogens, in this case SARS-CoV-1).</ORIGINAL_TEXT>
<TOKEN end_char="17393" id="token-145-0" morph="none" pos="word" start_char="17392">At</TOKEN>
<TOKEN end_char="17397" id="token-145-1" morph="none" pos="word" start_char="17395">the</TOKEN>
<TOKEN end_char="17402" id="token-145-2" morph="none" pos="word" start_char="17399">time</TOKEN>
<TOKEN end_char="17403" id="token-145-3" morph="none" pos="punct" start_char="17403">,</TOKEN>
<TOKEN end_char="17407" id="token-145-4" morph="none" pos="word" start_char="17405">the</TOKEN>
<TOKEN end_char="17416" id="token-145-5" morph="none" pos="word" start_char="17409">Institut</TOKEN>
<TOKEN end_char="17426" id="token-145-6" morph="none" pos="word" start_char="17418">Pasteur's</TOKEN>
<TOKEN end_char="17432" id="token-145-7" morph="none" pos="word" start_char="17428">teams</TOKEN>
<TOKEN end_char="17442" id="token-145-8" morph="none" pos="word" start_char="17434">responded</TOKEN>
<TOKEN end_char="17445" id="token-145-9" morph="none" pos="word" start_char="17444">to</TOKEN>
<TOKEN end_char="17449" id="token-145-10" morph="none" pos="word" start_char="17447">the</TOKEN>
<TOKEN end_char="17458" id="token-145-11" morph="none" pos="word" start_char="17451">outbreak</TOKEN>
<TOKEN end_char="17461" id="token-145-12" morph="none" pos="word" start_char="17460">by</TOKEN>
<TOKEN end_char="17471" id="token-145-13" morph="none" pos="word" start_char="17463">proposing</TOKEN>
<TOKEN end_char="17473" id="token-145-14" morph="none" pos="word" start_char="17473">a</TOKEN>
<TOKEN end_char="17480" id="token-145-15" morph="none" pos="word" start_char="17475">number</TOKEN>
<TOKEN end_char="17483" id="token-145-16" morph="none" pos="word" start_char="17482">of</TOKEN>
<TOKEN end_char="17491" id="token-145-17" morph="none" pos="word" start_char="17485">vaccine</TOKEN>
<TOKEN end_char="17502" id="token-145-18" morph="none" pos="word" start_char="17493">strategies</TOKEN>
<TOKEN end_char="17503" id="token-145-19" morph="none" pos="punct" start_char="17503">,</TOKEN>
<TOKEN end_char="17513" id="token-145-20" morph="none" pos="word" start_char="17505">including</TOKEN>
<TOKEN end_char="17515" id="token-145-21" morph="none" pos="word" start_char="17515">a</TOKEN>
<TOKEN end_char="17523" id="token-145-22" morph="none" pos="word" start_char="17517">vaccine</TOKEN>
<TOKEN end_char="17533" id="token-145-23" morph="none" pos="word" start_char="17525">candidate</TOKEN>
<TOKEN end_char="17539" id="token-145-24" morph="none" pos="word" start_char="17535">based</TOKEN>
<TOKEN end_char="17542" id="token-145-25" morph="none" pos="word" start_char="17541">on</TOKEN>
<TOKEN end_char="17546" id="token-145-26" morph="none" pos="word" start_char="17544">the</TOKEN>
<TOKEN end_char="17554" id="token-145-27" morph="none" pos="word" start_char="17548">measles</TOKEN>
<TOKEN end_char="17560" id="token-145-28" morph="none" pos="word" start_char="17556">virus</TOKEN>
<TOKEN end_char="17568" id="token-145-29" morph="none" pos="word" start_char="17562">vaccine</TOKEN>
<TOKEN end_char="17577" id="token-145-30" morph="none" pos="word" start_char="17570">platform</TOKEN>
<TOKEN end_char="17579" id="token-145-31" morph="none" pos="punct" start_char="17579">(</TOKEN>
<TOKEN end_char="17582" id="token-145-32" morph="none" pos="word" start_char="17580">the</TOKEN>
<TOKEN end_char="17590" id="token-145-33" morph="none" pos="word" start_char="17584">measles</TOKEN>
<TOKEN end_char="17598" id="token-145-34" morph="none" pos="word" start_char="17592">vaccine</TOKEN>
<TOKEN end_char="17602" id="token-145-35" morph="none" pos="word" start_char="17600">can</TOKEN>
<TOKEN end_char="17605" id="token-145-36" morph="none" pos="word" start_char="17604">be</TOKEN>
<TOKEN end_char="17616" id="token-145-37" morph="none" pos="word" start_char="17607">recombined</TOKEN>
<TOKEN end_char="17620" id="token-145-38" morph="none" pos="word" start_char="17618">and</TOKEN>
<TOKEN end_char="17625" id="token-145-39" morph="none" pos="word" start_char="17622">used</TOKEN>
<TOKEN end_char="17628" id="token-145-40" morph="none" pos="word" start_char="17627">as</TOKEN>
<TOKEN end_char="17630" id="token-145-41" morph="none" pos="word" start_char="17630">a</TOKEN>
<TOKEN end_char="17636" id="token-145-42" morph="none" pos="word" start_char="17632">means</TOKEN>
<TOKEN end_char="17639" id="token-145-43" morph="none" pos="word" start_char="17638">of</TOKEN>
<TOKEN end_char="17648" id="token-145-44" morph="none" pos="word" start_char="17641">inducing</TOKEN>
<TOKEN end_char="17651" id="token-145-45" morph="none" pos="word" start_char="17650">an</TOKEN>
<TOKEN end_char="17658" id="token-145-46" morph="none" pos="word" start_char="17653">immune</TOKEN>
<TOKEN end_char="17667" id="token-145-47" morph="none" pos="word" start_char="17660">response</TOKEN>
<TOKEN end_char="17675" id="token-145-48" morph="none" pos="word" start_char="17669">against</TOKEN>
<TOKEN end_char="17681" id="token-145-49" morph="none" pos="word" start_char="17677">other</TOKEN>
<TOKEN end_char="17691" id="token-145-50" morph="none" pos="word" start_char="17683">pathogens</TOKEN>
<TOKEN end_char="17692" id="token-145-51" morph="none" pos="punct" start_char="17692">,</TOKEN>
<TOKEN end_char="17695" id="token-145-52" morph="none" pos="word" start_char="17694">in</TOKEN>
<TOKEN end_char="17700" id="token-145-53" morph="none" pos="word" start_char="17697">this</TOKEN>
<TOKEN end_char="17705" id="token-145-54" morph="none" pos="word" start_char="17702">case</TOKEN>
<TOKEN end_char="17716" id="token-145-55" morph="none" pos="unknown" start_char="17707">SARS-CoV-1</TOKEN>
<TOKEN end_char="17718" id="token-145-56" morph="none" pos="punct" start_char="17717">).</TOKEN>
</SEG>
<SEG end_char="18000" id="segment-146" start_char="17722">
<ORIGINAL_TEXT>In 2004, an invention disclosure was filed for the vaccine candidate for SARS-CoV-1.The patent filed was for SARS-CoV-1 (responsible for the illness known as SARS in 2002-2003), which is very different from SARS-CoV-2 (responsible for the illness known as Covid-19 in 2019-2020).</ORIGINAL_TEXT>
<TOKEN end_char="17723" id="token-146-0" morph="none" pos="word" start_char="17722">In</TOKEN>
<TOKEN end_char="17728" id="token-146-1" morph="none" pos="word" start_char="17725">2004</TOKEN>
<TOKEN end_char="17729" id="token-146-2" morph="none" pos="punct" start_char="17729">,</TOKEN>
<TOKEN end_char="17732" id="token-146-3" morph="none" pos="word" start_char="17731">an</TOKEN>
<TOKEN end_char="17742" id="token-146-4" morph="none" pos="word" start_char="17734">invention</TOKEN>
<TOKEN end_char="17753" id="token-146-5" morph="none" pos="word" start_char="17744">disclosure</TOKEN>
<TOKEN end_char="17757" id="token-146-6" morph="none" pos="word" start_char="17755">was</TOKEN>
<TOKEN end_char="17763" id="token-146-7" morph="none" pos="word" start_char="17759">filed</TOKEN>
<TOKEN end_char="17767" id="token-146-8" morph="none" pos="word" start_char="17765">for</TOKEN>
<TOKEN end_char="17771" id="token-146-9" morph="none" pos="word" start_char="17769">the</TOKEN>
<TOKEN end_char="17779" id="token-146-10" morph="none" pos="word" start_char="17773">vaccine</TOKEN>
<TOKEN end_char="17789" id="token-146-11" morph="none" pos="word" start_char="17781">candidate</TOKEN>
<TOKEN end_char="17793" id="token-146-12" morph="none" pos="word" start_char="17791">for</TOKEN>
<TOKEN end_char="17808" id="token-146-13" morph="none" pos="unknown" start_char="17795">SARS-CoV-1.The</TOKEN>
<TOKEN end_char="17815" id="token-146-14" morph="none" pos="word" start_char="17810">patent</TOKEN>
<TOKEN end_char="17821" id="token-146-15" morph="none" pos="word" start_char="17817">filed</TOKEN>
<TOKEN end_char="17825" id="token-146-16" morph="none" pos="word" start_char="17823">was</TOKEN>
<TOKEN end_char="17829" id="token-146-17" morph="none" pos="word" start_char="17827">for</TOKEN>
<TOKEN end_char="17840" id="token-146-18" morph="none" pos="unknown" start_char="17831">SARS-CoV-1</TOKEN>
<TOKEN end_char="17842" id="token-146-19" morph="none" pos="punct" start_char="17842">(</TOKEN>
<TOKEN end_char="17853" id="token-146-20" morph="none" pos="word" start_char="17843">responsible</TOKEN>
<TOKEN end_char="17857" id="token-146-21" morph="none" pos="word" start_char="17855">for</TOKEN>
<TOKEN end_char="17861" id="token-146-22" morph="none" pos="word" start_char="17859">the</TOKEN>
<TOKEN end_char="17869" id="token-146-23" morph="none" pos="word" start_char="17863">illness</TOKEN>
<TOKEN end_char="17875" id="token-146-24" morph="none" pos="word" start_char="17871">known</TOKEN>
<TOKEN end_char="17878" id="token-146-25" morph="none" pos="word" start_char="17877">as</TOKEN>
<TOKEN end_char="17883" id="token-146-26" morph="none" pos="word" start_char="17880">SARS</TOKEN>
<TOKEN end_char="17886" id="token-146-27" morph="none" pos="word" start_char="17885">in</TOKEN>
<TOKEN end_char="17896" id="token-146-28" morph="none" pos="unknown" start_char="17888">2002-2003</TOKEN>
<TOKEN end_char="17898" id="token-146-29" morph="none" pos="punct" start_char="17897">),</TOKEN>
<TOKEN end_char="17904" id="token-146-30" morph="none" pos="word" start_char="17900">which</TOKEN>
<TOKEN end_char="17907" id="token-146-31" morph="none" pos="word" start_char="17906">is</TOKEN>
<TOKEN end_char="17912" id="token-146-32" morph="none" pos="word" start_char="17909">very</TOKEN>
<TOKEN end_char="17922" id="token-146-33" morph="none" pos="word" start_char="17914">different</TOKEN>
<TOKEN end_char="17927" id="token-146-34" morph="none" pos="word" start_char="17924">from</TOKEN>
<TOKEN end_char="17938" id="token-146-35" morph="none" pos="unknown" start_char="17929">SARS-CoV-2</TOKEN>
<TOKEN end_char="17940" id="token-146-36" morph="none" pos="punct" start_char="17940">(</TOKEN>
<TOKEN end_char="17951" id="token-146-37" morph="none" pos="word" start_char="17941">responsible</TOKEN>
<TOKEN end_char="17955" id="token-146-38" morph="none" pos="word" start_char="17953">for</TOKEN>
<TOKEN end_char="17959" id="token-146-39" morph="none" pos="word" start_char="17957">the</TOKEN>
<TOKEN end_char="17967" id="token-146-40" morph="none" pos="word" start_char="17961">illness</TOKEN>
<TOKEN end_char="17973" id="token-146-41" morph="none" pos="word" start_char="17969">known</TOKEN>
<TOKEN end_char="17976" id="token-146-42" morph="none" pos="word" start_char="17975">as</TOKEN>
<TOKEN end_char="17985" id="token-146-43" morph="none" pos="unknown" start_char="17978">Covid-19</TOKEN>
<TOKEN end_char="17988" id="token-146-44" morph="none" pos="word" start_char="17987">in</TOKEN>
<TOKEN end_char="17998" id="token-146-45" morph="none" pos="unknown" start_char="17990">2019-2020</TOKEN>
<TOKEN end_char="18000" id="token-146-46" morph="none" pos="punct" start_char="17999">).</TOKEN>
</SEG>
<SEG end_char="18168" id="segment-147" start_char="18003">
<ORIGINAL_TEXT>The 2004 patent described the discovery of the virus and the subsequent invention of a vaccine strategy against the virus – and NOT the invention of the virus itself!</ORIGINAL_TEXT>
<TOKEN end_char="18005" id="token-147-0" morph="none" pos="word" start_char="18003">The</TOKEN>
<TOKEN end_char="18010" id="token-147-1" morph="none" pos="word" start_char="18007">2004</TOKEN>
<TOKEN end_char="18017" id="token-147-2" morph="none" pos="word" start_char="18012">patent</TOKEN>
<TOKEN end_char="18027" id="token-147-3" morph="none" pos="word" start_char="18019">described</TOKEN>
<TOKEN end_char="18031" id="token-147-4" morph="none" pos="word" start_char="18029">the</TOKEN>
<TOKEN end_char="18041" id="token-147-5" morph="none" pos="word" start_char="18033">discovery</TOKEN>
<TOKEN end_char="18044" id="token-147-6" morph="none" pos="word" start_char="18043">of</TOKEN>
<TOKEN end_char="18048" id="token-147-7" morph="none" pos="word" start_char="18046">the</TOKEN>
<TOKEN end_char="18054" id="token-147-8" morph="none" pos="word" start_char="18050">virus</TOKEN>
<TOKEN end_char="18058" id="token-147-9" morph="none" pos="word" start_char="18056">and</TOKEN>
<TOKEN end_char="18062" id="token-147-10" morph="none" pos="word" start_char="18060">the</TOKEN>
<TOKEN end_char="18073" id="token-147-11" morph="none" pos="word" start_char="18064">subsequent</TOKEN>
<TOKEN end_char="18083" id="token-147-12" morph="none" pos="word" start_char="18075">invention</TOKEN>
<TOKEN end_char="18086" id="token-147-13" morph="none" pos="word" start_char="18085">of</TOKEN>
<TOKEN end_char="18088" id="token-147-14" morph="none" pos="word" start_char="18088">a</TOKEN>
<TOKEN end_char="18096" id="token-147-15" morph="none" pos="word" start_char="18090">vaccine</TOKEN>
<TOKEN end_char="18105" id="token-147-16" morph="none" pos="word" start_char="18098">strategy</TOKEN>
<TOKEN end_char="18113" id="token-147-17" morph="none" pos="word" start_char="18107">against</TOKEN>
<TOKEN end_char="18117" id="token-147-18" morph="none" pos="word" start_char="18115">the</TOKEN>
<TOKEN end_char="18123" id="token-147-19" morph="none" pos="word" start_char="18119">virus</TOKEN>
<TOKEN end_char="18125" id="token-147-20" morph="none" pos="punct" start_char="18125">–</TOKEN>
<TOKEN end_char="18129" id="token-147-21" morph="none" pos="word" start_char="18127">and</TOKEN>
<TOKEN end_char="18133" id="token-147-22" morph="none" pos="word" start_char="18131">NOT</TOKEN>
<TOKEN end_char="18137" id="token-147-23" morph="none" pos="word" start_char="18135">the</TOKEN>
<TOKEN end_char="18147" id="token-147-24" morph="none" pos="word" start_char="18139">invention</TOKEN>
<TOKEN end_char="18150" id="token-147-25" morph="none" pos="word" start_char="18149">of</TOKEN>
<TOKEN end_char="18154" id="token-147-26" morph="none" pos="word" start_char="18152">the</TOKEN>
<TOKEN end_char="18160" id="token-147-27" morph="none" pos="word" start_char="18156">virus</TOKEN>
<TOKEN end_char="18167" id="token-147-28" morph="none" pos="word" start_char="18162">itself</TOKEN>
<TOKEN end_char="18168" id="token-147-29" morph="none" pos="punct" start_char="18168">!</TOKEN>
</SEG>
<SEG end_char="18358" id="segment-148" start_char="18172">
<ORIGINAL_TEXT>The vaccine candidate for SARS-CoV-1 was not tested on humans because, by the time it was ready, the outbreak had fortunately come to an end and there were no more patients to test it on.</ORIGINAL_TEXT>
<TOKEN end_char="18174" id="token-148-0" morph="none" pos="word" start_char="18172">The</TOKEN>
<TOKEN end_char="18182" id="token-148-1" morph="none" pos="word" start_char="18176">vaccine</TOKEN>
<TOKEN end_char="18192" id="token-148-2" morph="none" pos="word" start_char="18184">candidate</TOKEN>
<TOKEN end_char="18196" id="token-148-3" morph="none" pos="word" start_char="18194">for</TOKEN>
<TOKEN end_char="18207" id="token-148-4" morph="none" pos="unknown" start_char="18198">SARS-CoV-1</TOKEN>
<TOKEN end_char="18211" id="token-148-5" morph="none" pos="word" start_char="18209">was</TOKEN>
<TOKEN end_char="18215" id="token-148-6" morph="none" pos="word" start_char="18213">not</TOKEN>
<TOKEN end_char="18222" id="token-148-7" morph="none" pos="word" start_char="18217">tested</TOKEN>
<TOKEN end_char="18225" id="token-148-8" morph="none" pos="word" start_char="18224">on</TOKEN>
<TOKEN end_char="18232" id="token-148-9" morph="none" pos="word" start_char="18227">humans</TOKEN>
<TOKEN end_char="18240" id="token-148-10" morph="none" pos="word" start_char="18234">because</TOKEN>
<TOKEN end_char="18241" id="token-148-11" morph="none" pos="punct" start_char="18241">,</TOKEN>
<TOKEN end_char="18244" id="token-148-12" morph="none" pos="word" start_char="18243">by</TOKEN>
<TOKEN end_char="18248" id="token-148-13" morph="none" pos="word" start_char="18246">the</TOKEN>
<TOKEN end_char="18253" id="token-148-14" morph="none" pos="word" start_char="18250">time</TOKEN>
<TOKEN end_char="18256" id="token-148-15" morph="none" pos="word" start_char="18255">it</TOKEN>
<TOKEN end_char="18260" id="token-148-16" morph="none" pos="word" start_char="18258">was</TOKEN>
<TOKEN end_char="18266" id="token-148-17" morph="none" pos="word" start_char="18262">ready</TOKEN>
<TOKEN end_char="18267" id="token-148-18" morph="none" pos="punct" start_char="18267">,</TOKEN>
<TOKEN end_char="18271" id="token-148-19" morph="none" pos="word" start_char="18269">the</TOKEN>
<TOKEN end_char="18280" id="token-148-20" morph="none" pos="word" start_char="18273">outbreak</TOKEN>
<TOKEN end_char="18284" id="token-148-21" morph="none" pos="word" start_char="18282">had</TOKEN>
<TOKEN end_char="18296" id="token-148-22" morph="none" pos="word" start_char="18286">fortunately</TOKEN>
<TOKEN end_char="18301" id="token-148-23" morph="none" pos="word" start_char="18298">come</TOKEN>
<TOKEN end_char="18304" id="token-148-24" morph="none" pos="word" start_char="18303">to</TOKEN>
<TOKEN end_char="18307" id="token-148-25" morph="none" pos="word" start_char="18306">an</TOKEN>
<TOKEN end_char="18311" id="token-148-26" morph="none" pos="word" start_char="18309">end</TOKEN>
<TOKEN end_char="18315" id="token-148-27" morph="none" pos="word" start_char="18313">and</TOKEN>
<TOKEN end_char="18321" id="token-148-28" morph="none" pos="word" start_char="18317">there</TOKEN>
<TOKEN end_char="18326" id="token-148-29" morph="none" pos="word" start_char="18323">were</TOKEN>
<TOKEN end_char="18329" id="token-148-30" morph="none" pos="word" start_char="18328">no</TOKEN>
<TOKEN end_char="18334" id="token-148-31" morph="none" pos="word" start_char="18331">more</TOKEN>
<TOKEN end_char="18343" id="token-148-32" morph="none" pos="word" start_char="18336">patients</TOKEN>
<TOKEN end_char="18346" id="token-148-33" morph="none" pos="word" start_char="18345">to</TOKEN>
<TOKEN end_char="18351" id="token-148-34" morph="none" pos="word" start_char="18348">test</TOKEN>
<TOKEN end_char="18354" id="token-148-35" morph="none" pos="word" start_char="18353">it</TOKEN>
<TOKEN end_char="18357" id="token-148-36" morph="none" pos="word" start_char="18356">on</TOKEN>
<TOKEN end_char="18358" id="token-148-37" morph="none" pos="punct" start_char="18358">.</TOKEN>
</SEG>
<SEG end_char="18440" id="segment-149" start_char="18362">
<ORIGINAL_TEXT>In the coronavirus family, SARS-CoV-2 is one of a group of "SARS-like" viruses.</ORIGINAL_TEXT>
<TOKEN end_char="18363" id="token-149-0" morph="none" pos="word" start_char="18362">In</TOKEN>
<TOKEN end_char="18367" id="token-149-1" morph="none" pos="word" start_char="18365">the</TOKEN>
<TOKEN end_char="18379" id="token-149-2" morph="none" pos="word" start_char="18369">coronavirus</TOKEN>
<TOKEN end_char="18386" id="token-149-3" morph="none" pos="word" start_char="18381">family</TOKEN>
<TOKEN end_char="18387" id="token-149-4" morph="none" pos="punct" start_char="18387">,</TOKEN>
<TOKEN end_char="18398" id="token-149-5" morph="none" pos="unknown" start_char="18389">SARS-CoV-2</TOKEN>
<TOKEN end_char="18401" id="token-149-6" morph="none" pos="word" start_char="18400">is</TOKEN>
<TOKEN end_char="18405" id="token-149-7" morph="none" pos="word" start_char="18403">one</TOKEN>
<TOKEN end_char="18408" id="token-149-8" morph="none" pos="word" start_char="18407">of</TOKEN>
<TOKEN end_char="18410" id="token-149-9" morph="none" pos="word" start_char="18410">a</TOKEN>
<TOKEN end_char="18416" id="token-149-10" morph="none" pos="word" start_char="18412">group</TOKEN>
<TOKEN end_char="18419" id="token-149-11" morph="none" pos="word" start_char="18418">of</TOKEN>
<TOKEN end_char="18421" id="token-149-12" morph="none" pos="punct" start_char="18421">"</TOKEN>
<TOKEN end_char="18430" id="token-149-13" morph="none" pos="unknown" start_char="18422">SARS-like</TOKEN>
<TOKEN end_char="18431" id="token-149-14" morph="none" pos="punct" start_char="18431">"</TOKEN>
<TOKEN end_char="18439" id="token-149-15" morph="none" pos="word" start_char="18433">viruses</TOKEN>
<TOKEN end_char="18440" id="token-149-16" morph="none" pos="punct" start_char="18440">.</TOKEN>
</SEG>
<SEG end_char="18722" id="segment-150" start_char="18444">
<ORIGINAL_TEXT>The expertise developed in 2003 for SARS-CoV-1, and the vaccine candidate patented in 2004, are currently being put to use by the Institut Pasteur's scientists for the development of a potential vaccine for SARS-CoV-2 (responsible for Covid-19), again using the measles platform.</ORIGINAL_TEXT>
<TOKEN end_char="18446" id="token-150-0" morph="none" pos="word" start_char="18444">The</TOKEN>
<TOKEN end_char="18456" id="token-150-1" morph="none" pos="word" start_char="18448">expertise</TOKEN>
<TOKEN end_char="18466" id="token-150-2" morph="none" pos="word" start_char="18458">developed</TOKEN>
<TOKEN end_char="18469" id="token-150-3" morph="none" pos="word" start_char="18468">in</TOKEN>
<TOKEN end_char="18474" id="token-150-4" morph="none" pos="word" start_char="18471">2003</TOKEN>
<TOKEN end_char="18478" id="token-150-5" morph="none" pos="word" start_char="18476">for</TOKEN>
<TOKEN end_char="18489" id="token-150-6" morph="none" pos="unknown" start_char="18480">SARS-CoV-1</TOKEN>
<TOKEN end_char="18490" id="token-150-7" morph="none" pos="punct" start_char="18490">,</TOKEN>
<TOKEN end_char="18494" id="token-150-8" morph="none" pos="word" start_char="18492">and</TOKEN>
<TOKEN end_char="18498" id="token-150-9" morph="none" pos="word" start_char="18496">the</TOKEN>
<TOKEN end_char="18506" id="token-150-10" morph="none" pos="word" start_char="18500">vaccine</TOKEN>
<TOKEN end_char="18516" id="token-150-11" morph="none" pos="word" start_char="18508">candidate</TOKEN>
<TOKEN end_char="18525" id="token-150-12" morph="none" pos="word" start_char="18518">patented</TOKEN>
<TOKEN end_char="18528" id="token-150-13" morph="none" pos="word" start_char="18527">in</TOKEN>
<TOKEN end_char="18533" id="token-150-14" morph="none" pos="word" start_char="18530">2004</TOKEN>
<TOKEN end_char="18534" id="token-150-15" morph="none" pos="punct" start_char="18534">,</TOKEN>
<TOKEN end_char="18538" id="token-150-16" morph="none" pos="word" start_char="18536">are</TOKEN>
<TOKEN end_char="18548" id="token-150-17" morph="none" pos="word" start_char="18540">currently</TOKEN>
<TOKEN end_char="18554" id="token-150-18" morph="none" pos="word" start_char="18550">being</TOKEN>
<TOKEN end_char="18558" id="token-150-19" morph="none" pos="word" start_char="18556">put</TOKEN>
<TOKEN end_char="18561" id="token-150-20" morph="none" pos="word" start_char="18560">to</TOKEN>
<TOKEN end_char="18565" id="token-150-21" morph="none" pos="word" start_char="18563">use</TOKEN>
<TOKEN end_char="18568" id="token-150-22" morph="none" pos="word" start_char="18567">by</TOKEN>
<TOKEN end_char="18572" id="token-150-23" morph="none" pos="word" start_char="18570">the</TOKEN>
<TOKEN end_char="18581" id="token-150-24" morph="none" pos="word" start_char="18574">Institut</TOKEN>
<TOKEN end_char="18591" id="token-150-25" morph="none" pos="word" start_char="18583">Pasteur's</TOKEN>
<TOKEN end_char="18602" id="token-150-26" morph="none" pos="word" start_char="18593">scientists</TOKEN>
<TOKEN end_char="18606" id="token-150-27" morph="none" pos="word" start_char="18604">for</TOKEN>
<TOKEN end_char="18610" id="token-150-28" morph="none" pos="word" start_char="18608">the</TOKEN>
<TOKEN end_char="18622" id="token-150-29" morph="none" pos="word" start_char="18612">development</TOKEN>
<TOKEN end_char="18625" id="token-150-30" morph="none" pos="word" start_char="18624">of</TOKEN>
<TOKEN end_char="18627" id="token-150-31" morph="none" pos="word" start_char="18627">a</TOKEN>
<TOKEN end_char="18637" id="token-150-32" morph="none" pos="word" start_char="18629">potential</TOKEN>
<TOKEN end_char="18645" id="token-150-33" morph="none" pos="word" start_char="18639">vaccine</TOKEN>
<TOKEN end_char="18649" id="token-150-34" morph="none" pos="word" start_char="18647">for</TOKEN>
<TOKEN end_char="18660" id="token-150-35" morph="none" pos="unknown" start_char="18651">SARS-CoV-2</TOKEN>
<TOKEN end_char="18662" id="token-150-36" morph="none" pos="punct" start_char="18662">(</TOKEN>
<TOKEN end_char="18673" id="token-150-37" morph="none" pos="word" start_char="18663">responsible</TOKEN>
<TOKEN end_char="18677" id="token-150-38" morph="none" pos="word" start_char="18675">for</TOKEN>
<TOKEN end_char="18686" id="token-150-39" morph="none" pos="unknown" start_char="18679">Covid-19</TOKEN>
<TOKEN end_char="18688" id="token-150-40" morph="none" pos="punct" start_char="18687">),</TOKEN>
<TOKEN end_char="18694" id="token-150-41" morph="none" pos="word" start_char="18690">again</TOKEN>
<TOKEN end_char="18700" id="token-150-42" morph="none" pos="word" start_char="18696">using</TOKEN>
<TOKEN end_char="18704" id="token-150-43" morph="none" pos="word" start_char="18702">the</TOKEN>
<TOKEN end_char="18712" id="token-150-44" morph="none" pos="word" start_char="18706">measles</TOKEN>
<TOKEN end_char="18721" id="token-150-45" morph="none" pos="word" start_char="18714">platform</TOKEN>
<TOKEN end_char="18722" id="token-150-46" morph="none" pos="punct" start_char="18722">.</TOKEN>
</SEG>
<SEG end_char="18935" id="segment-151" start_char="18727">
<ORIGINAL_TEXT>In view of the various threats and violence following the broadcast of this video of March 2020, the Institut Pasteur was forced for the first time in its existence (since 1887) to file a defamation complaint.</ORIGINAL_TEXT>
<TOKEN end_char="18728" id="token-151-0" morph="none" pos="word" start_char="18727">In</TOKEN>
<TOKEN end_char="18733" id="token-151-1" morph="none" pos="word" start_char="18730">view</TOKEN>
<TOKEN end_char="18736" id="token-151-2" morph="none" pos="word" start_char="18735">of</TOKEN>
<TOKEN end_char="18740" id="token-151-3" morph="none" pos="word" start_char="18738">the</TOKEN>
<TOKEN end_char="18748" id="token-151-4" morph="none" pos="word" start_char="18742">various</TOKEN>
<TOKEN end_char="18756" id="token-151-5" morph="none" pos="word" start_char="18750">threats</TOKEN>
<TOKEN end_char="18760" id="token-151-6" morph="none" pos="word" start_char="18758">and</TOKEN>
<TOKEN end_char="18769" id="token-151-7" morph="none" pos="word" start_char="18762">violence</TOKEN>
<TOKEN end_char="18779" id="token-151-8" morph="none" pos="word" start_char="18771">following</TOKEN>
<TOKEN end_char="18783" id="token-151-9" morph="none" pos="word" start_char="18781">the</TOKEN>
<TOKEN end_char="18793" id="token-151-10" morph="none" pos="word" start_char="18785">broadcast</TOKEN>
<TOKEN end_char="18796" id="token-151-11" morph="none" pos="word" start_char="18795">of</TOKEN>
<TOKEN end_char="18801" id="token-151-12" morph="none" pos="word" start_char="18798">this</TOKEN>
<TOKEN end_char="18807" id="token-151-13" morph="none" pos="word" start_char="18803">video</TOKEN>
<TOKEN end_char="18810" id="token-151-14" morph="none" pos="word" start_char="18809">of</TOKEN>
<TOKEN end_char="18816" id="token-151-15" morph="none" pos="word" start_char="18812">March</TOKEN>
<TOKEN end_char="18821" id="token-151-16" morph="none" pos="word" start_char="18818">2020</TOKEN>
<TOKEN end_char="18822" id="token-151-17" morph="none" pos="punct" start_char="18822">,</TOKEN>
<TOKEN end_char="18826" id="token-151-18" morph="none" pos="word" start_char="18824">the</TOKEN>
<TOKEN end_char="18835" id="token-151-19" morph="none" pos="word" start_char="18828">Institut</TOKEN>
<TOKEN end_char="18843" id="token-151-20" morph="none" pos="word" start_char="18837">Pasteur</TOKEN>
<TOKEN end_char="18847" id="token-151-21" morph="none" pos="word" start_char="18845">was</TOKEN>
<TOKEN end_char="18854" id="token-151-22" morph="none" pos="word" start_char="18849">forced</TOKEN>
<TOKEN end_char="18858" id="token-151-23" morph="none" pos="word" start_char="18856">for</TOKEN>
<TOKEN end_char="18862" id="token-151-24" morph="none" pos="word" start_char="18860">the</TOKEN>
<TOKEN end_char="18868" id="token-151-25" morph="none" pos="word" start_char="18864">first</TOKEN>
<TOKEN end_char="18873" id="token-151-26" morph="none" pos="word" start_char="18870">time</TOKEN>
<TOKEN end_char="18876" id="token-151-27" morph="none" pos="word" start_char="18875">in</TOKEN>
<TOKEN end_char="18880" id="token-151-28" morph="none" pos="word" start_char="18878">its</TOKEN>
<TOKEN end_char="18890" id="token-151-29" morph="none" pos="word" start_char="18882">existence</TOKEN>
<TOKEN end_char="18892" id="token-151-30" morph="none" pos="punct" start_char="18892">(</TOKEN>
<TOKEN end_char="18897" id="token-151-31" morph="none" pos="word" start_char="18893">since</TOKEN>
<TOKEN end_char="18902" id="token-151-32" morph="none" pos="word" start_char="18899">1887</TOKEN>
<TOKEN end_char="18903" id="token-151-33" morph="none" pos="punct" start_char="18903">)</TOKEN>
<TOKEN end_char="18906" id="token-151-34" morph="none" pos="word" start_char="18905">to</TOKEN>
<TOKEN end_char="18911" id="token-151-35" morph="none" pos="word" start_char="18908">file</TOKEN>
<TOKEN end_char="18913" id="token-151-36" morph="none" pos="word" start_char="18913">a</TOKEN>
<TOKEN end_char="18924" id="token-151-37" morph="none" pos="word" start_char="18915">defamation</TOKEN>
<TOKEN end_char="18934" id="token-151-38" morph="none" pos="word" start_char="18926">complaint</TOKEN>
<TOKEN end_char="18935" id="token-151-39" morph="none" pos="punct" start_char="18935">.</TOKEN>
</SEG>
<SEG end_char="18974" id="segment-152" start_char="18938">
<ORIGINAL_TEXT>(paragraph added on November 4, 2020)</ORIGINAL_TEXT>
<TOKEN end_char="18938" id="token-152-0" morph="none" pos="punct" start_char="18938">(</TOKEN>
<TOKEN end_char="18947" id="token-152-1" morph="none" pos="word" start_char="18939">paragraph</TOKEN>
<TOKEN end_char="18953" id="token-152-2" morph="none" pos="word" start_char="18949">added</TOKEN>
<TOKEN end_char="18956" id="token-152-3" morph="none" pos="word" start_char="18955">on</TOKEN>
<TOKEN end_char="18965" id="token-152-4" morph="none" pos="word" start_char="18958">November</TOKEN>
<TOKEN end_char="18967" id="token-152-5" morph="none" pos="word" start_char="18967">4</TOKEN>
<TOKEN end_char="18968" id="token-152-6" morph="none" pos="punct" start_char="18968">,</TOKEN>
<TOKEN end_char="18973" id="token-152-7" morph="none" pos="word" start_char="18970">2020</TOKEN>
<TOKEN end_char="18974" id="token-152-8" morph="none" pos="punct" start_char="18974">)</TOKEN>
</SEG>
<SEG end_char="19085" id="segment-153" start_char="18978">
<ORIGINAL_TEXT>Read (in French) "Covid-19: Senlis Criminal Court condemns the author of a 'fake news' video for defamation"</ORIGINAL_TEXT>
<TOKEN end_char="18981" id="token-153-0" morph="none" pos="word" start_char="18978">Read</TOKEN>
<TOKEN end_char="18983" id="token-153-1" morph="none" pos="punct" start_char="18983">(</TOKEN>
<TOKEN end_char="18985" id="token-153-2" morph="none" pos="word" start_char="18984">in</TOKEN>
<TOKEN end_char="18992" id="token-153-3" morph="none" pos="word" start_char="18987">French</TOKEN>
<TOKEN end_char="18993" id="token-153-4" morph="none" pos="punct" start_char="18993">)</TOKEN>
<TOKEN end_char="18995" id="token-153-5" morph="none" pos="punct" start_char="18995">"</TOKEN>
<TOKEN end_char="19003" id="token-153-6" morph="none" pos="unknown" start_char="18996">Covid-19</TOKEN>
<TOKEN end_char="19004" id="token-153-7" morph="none" pos="punct" start_char="19004">:</TOKEN>
<TOKEN end_char="19011" id="token-153-8" morph="none" pos="word" start_char="19006">Senlis</TOKEN>
<TOKEN end_char="19020" id="token-153-9" morph="none" pos="word" start_char="19013">Criminal</TOKEN>
<TOKEN end_char="19026" id="token-153-10" morph="none" pos="word" start_char="19022">Court</TOKEN>
<TOKEN end_char="19035" id="token-153-11" morph="none" pos="word" start_char="19028">condemns</TOKEN>
<TOKEN end_char="19039" id="token-153-12" morph="none" pos="word" start_char="19037">the</TOKEN>
<TOKEN end_char="19046" id="token-153-13" morph="none" pos="word" start_char="19041">author</TOKEN>
<TOKEN end_char="19049" id="token-153-14" morph="none" pos="word" start_char="19048">of</TOKEN>
<TOKEN end_char="19051" id="token-153-15" morph="none" pos="word" start_char="19051">a</TOKEN>
<TOKEN end_char="19053" id="token-153-16" morph="none" pos="punct" start_char="19053">'</TOKEN>
<TOKEN end_char="19057" id="token-153-17" morph="none" pos="word" start_char="19054">fake</TOKEN>
<TOKEN end_char="19062" id="token-153-18" morph="none" pos="word" start_char="19059">news</TOKEN>
<TOKEN end_char="19063" id="token-153-19" morph="none" pos="punct" start_char="19063">'</TOKEN>
<TOKEN end_char="19069" id="token-153-20" morph="none" pos="word" start_char="19065">video</TOKEN>
<TOKEN end_char="19073" id="token-153-21" morph="none" pos="word" start_char="19071">for</TOKEN>
<TOKEN end_char="19084" id="token-153-22" morph="none" pos="word" start_char="19075">defamation</TOKEN>
<TOKEN end_char="19085" id="token-153-23" morph="none" pos="punct" start_char="19085">"</TOKEN>
</SEG>
<SEG end_char="19201" id="segment-154" start_char="19088">
<ORIGINAL_TEXT>NO, the Institut Pasteur does not have knowledge of the leak of a bacterial weapon intended for a third world war.</ORIGINAL_TEXT>
<TOKEN end_char="19089" id="token-154-0" morph="none" pos="word" start_char="19088">NO</TOKEN>
<TOKEN end_char="19090" id="token-154-1" morph="none" pos="punct" start_char="19090">,</TOKEN>
<TOKEN end_char="19094" id="token-154-2" morph="none" pos="word" start_char="19092">the</TOKEN>
<TOKEN end_char="19103" id="token-154-3" morph="none" pos="word" start_char="19096">Institut</TOKEN>
<TOKEN end_char="19111" id="token-154-4" morph="none" pos="word" start_char="19105">Pasteur</TOKEN>
<TOKEN end_char="19116" id="token-154-5" morph="none" pos="word" start_char="19113">does</TOKEN>
<TOKEN end_char="19120" id="token-154-6" morph="none" pos="word" start_char="19118">not</TOKEN>
<TOKEN end_char="19125" id="token-154-7" morph="none" pos="word" start_char="19122">have</TOKEN>
<TOKEN end_char="19135" id="token-154-8" morph="none" pos="word" start_char="19127">knowledge</TOKEN>
<TOKEN end_char="19138" id="token-154-9" morph="none" pos="word" start_char="19137">of</TOKEN>
<TOKEN end_char="19142" id="token-154-10" morph="none" pos="word" start_char="19140">the</TOKEN>
<TOKEN end_char="19147" id="token-154-11" morph="none" pos="word" start_char="19144">leak</TOKEN>
<TOKEN end_char="19150" id="token-154-12" morph="none" pos="word" start_char="19149">of</TOKEN>
<TOKEN end_char="19152" id="token-154-13" morph="none" pos="word" start_char="19152">a</TOKEN>
<TOKEN end_char="19162" id="token-154-14" morph="none" pos="word" start_char="19154">bacterial</TOKEN>
<TOKEN end_char="19169" id="token-154-15" morph="none" pos="word" start_char="19164">weapon</TOKEN>
<TOKEN end_char="19178" id="token-154-16" morph="none" pos="word" start_char="19171">intended</TOKEN>
<TOKEN end_char="19182" id="token-154-17" morph="none" pos="word" start_char="19180">for</TOKEN>
<TOKEN end_char="19184" id="token-154-18" morph="none" pos="word" start_char="19184">a</TOKEN>
<TOKEN end_char="19190" id="token-154-19" morph="none" pos="word" start_char="19186">third</TOKEN>
<TOKEN end_char="19196" id="token-154-20" morph="none" pos="word" start_char="19192">world</TOKEN>
<TOKEN end_char="19200" id="token-154-21" morph="none" pos="word" start_char="19198">war</TOKEN>
<TOKEN end_char="19201" id="token-154-22" morph="none" pos="punct" start_char="19201">.</TOKEN>
</SEG>
<SEG end_char="19226" id="segment-155" start_char="19204">
<ORIGINAL_TEXT>Text of March 20, 2020.</ORIGINAL_TEXT>
<TOKEN end_char="19207" id="token-155-0" morph="none" pos="word" start_char="19204">Text</TOKEN>
<TOKEN end_char="19210" id="token-155-1" morph="none" pos="word" start_char="19209">of</TOKEN>
<TOKEN end_char="19216" id="token-155-2" morph="none" pos="word" start_char="19212">March</TOKEN>
<TOKEN end_char="19219" id="token-155-3" morph="none" pos="word" start_char="19218">20</TOKEN>
<TOKEN end_char="19220" id="token-155-4" morph="none" pos="punct" start_char="19220">,</TOKEN>
<TOKEN end_char="19225" id="token-155-5" morph="none" pos="word" start_char="19222">2020</TOKEN>
<TOKEN end_char="19226" id="token-155-6" morph="none" pos="punct" start_char="19226">.</TOKEN>
</SEG>
<SEG end_char="19358" id="segment-156" start_char="19231">
<ORIGINAL_TEXT>An audio message disseminated widely on social networks evoked a "third world war" and the "leak" of a Chinese bacterial weapon.</ORIGINAL_TEXT>
<TOKEN end_char="19232" id="token-156-0" morph="none" pos="word" start_char="19231">An</TOKEN>
<TOKEN end_char="19238" id="token-156-1" morph="none" pos="word" start_char="19234">audio</TOKEN>
<TOKEN end_char="19246" id="token-156-2" morph="none" pos="word" start_char="19240">message</TOKEN>
<TOKEN end_char="19259" id="token-156-3" morph="none" pos="word" start_char="19248">disseminated</TOKEN>
<TOKEN end_char="19266" id="token-156-4" morph="none" pos="word" start_char="19261">widely</TOKEN>
<TOKEN end_char="19269" id="token-156-5" morph="none" pos="word" start_char="19268">on</TOKEN>
<TOKEN end_char="19276" id="token-156-6" morph="none" pos="word" start_char="19271">social</TOKEN>
<TOKEN end_char="19285" id="token-156-7" morph="none" pos="word" start_char="19278">networks</TOKEN>
<TOKEN end_char="19292" id="token-156-8" morph="none" pos="word" start_char="19287">evoked</TOKEN>
<TOKEN end_char="19294" id="token-156-9" morph="none" pos="word" start_char="19294">a</TOKEN>
<TOKEN end_char="19296" id="token-156-10" morph="none" pos="punct" start_char="19296">"</TOKEN>
<TOKEN end_char="19301" id="token-156-11" morph="none" pos="word" start_char="19297">third</TOKEN>
<TOKEN end_char="19307" id="token-156-12" morph="none" pos="word" start_char="19303">world</TOKEN>
<TOKEN end_char="19311" id="token-156-13" morph="none" pos="word" start_char="19309">war</TOKEN>
<TOKEN end_char="19312" id="token-156-14" morph="none" pos="punct" start_char="19312">"</TOKEN>
<TOKEN end_char="19316" id="token-156-15" morph="none" pos="word" start_char="19314">and</TOKEN>
<TOKEN end_char="19320" id="token-156-16" morph="none" pos="word" start_char="19318">the</TOKEN>
<TOKEN end_char="19322" id="token-156-17" morph="none" pos="punct" start_char="19322">"</TOKEN>
<TOKEN end_char="19326" id="token-156-18" morph="none" pos="word" start_char="19323">leak</TOKEN>
<TOKEN end_char="19327" id="token-156-19" morph="none" pos="punct" start_char="19327">"</TOKEN>
<TOKEN end_char="19330" id="token-156-20" morph="none" pos="word" start_char="19329">of</TOKEN>
<TOKEN end_char="19332" id="token-156-21" morph="none" pos="word" start_char="19332">a</TOKEN>
<TOKEN end_char="19340" id="token-156-22" morph="none" pos="word" start_char="19334">Chinese</TOKEN>
<TOKEN end_char="19350" id="token-156-23" morph="none" pos="word" start_char="19342">bacterial</TOKEN>
<TOKEN end_char="19357" id="token-156-24" morph="none" pos="word" start_char="19352">weapon</TOKEN>
<TOKEN end_char="19358" id="token-156-25" morph="none" pos="punct" start_char="19358">.</TOKEN>
</SEG>
<SEG end_char="19479" id="segment-157" start_char="19360">
<ORIGINAL_TEXT>The information is presented as originating from "the mother of my wife, her best friend works at the Institut Pasteur".</ORIGINAL_TEXT>
<TOKEN end_char="19362" id="token-157-0" morph="none" pos="word" start_char="19360">The</TOKEN>
<TOKEN end_char="19374" id="token-157-1" morph="none" pos="word" start_char="19364">information</TOKEN>
<TOKEN end_char="19377" id="token-157-2" morph="none" pos="word" start_char="19376">is</TOKEN>
<TOKEN end_char="19387" id="token-157-3" morph="none" pos="word" start_char="19379">presented</TOKEN>
<TOKEN end_char="19390" id="token-157-4" morph="none" pos="word" start_char="19389">as</TOKEN>
<TOKEN end_char="19402" id="token-157-5" morph="none" pos="word" start_char="19392">originating</TOKEN>
<TOKEN end_char="19407" id="token-157-6" morph="none" pos="word" start_char="19404">from</TOKEN>
<TOKEN end_char="19409" id="token-157-7" morph="none" pos="punct" start_char="19409">"</TOKEN>
<TOKEN end_char="19412" id="token-157-8" morph="none" pos="word" start_char="19410">the</TOKEN>
<TOKEN end_char="19419" id="token-157-9" morph="none" pos="word" start_char="19414">mother</TOKEN>
<TOKEN end_char="19422" id="token-157-10" morph="none" pos="word" start_char="19421">of</TOKEN>
<TOKEN end_char="19425" id="token-157-11" morph="none" pos="word" start_char="19424">my</TOKEN>
<TOKEN end_char="19430" id="token-157-12" morph="none" pos="word" start_char="19427">wife</TOKEN>
<TOKEN end_char="19431" id="token-157-13" morph="none" pos="punct" start_char="19431">,</TOKEN>
<TOKEN end_char="19435" id="token-157-14" morph="none" pos="word" start_char="19433">her</TOKEN>
<TOKEN end_char="19440" id="token-157-15" morph="none" pos="word" start_char="19437">best</TOKEN>
<TOKEN end_char="19447" id="token-157-16" morph="none" pos="word" start_char="19442">friend</TOKEN>
<TOKEN end_char="19453" id="token-157-17" morph="none" pos="word" start_char="19449">works</TOKEN>
<TOKEN end_char="19456" id="token-157-18" morph="none" pos="word" start_char="19455">at</TOKEN>
<TOKEN end_char="19460" id="token-157-19" morph="none" pos="word" start_char="19458">the</TOKEN>
<TOKEN end_char="19469" id="token-157-20" morph="none" pos="word" start_char="19462">Institut</TOKEN>
<TOKEN end_char="19477" id="token-157-21" morph="none" pos="word" start_char="19471">Pasteur</TOKEN>
<TOKEN end_char="19479" id="token-157-22" morph="none" pos="punct" start_char="19478">".</TOKEN>
</SEG>
<SEG end_char="19516" id="segment-158" start_char="19481">
<ORIGINAL_TEXT>This information is of course false.</ORIGINAL_TEXT>
<TOKEN end_char="19484" id="token-158-0" morph="none" pos="word" start_char="19481">This</TOKEN>
<TOKEN end_char="19496" id="token-158-1" morph="none" pos="word" start_char="19486">information</TOKEN>
<TOKEN end_char="19499" id="token-158-2" morph="none" pos="word" start_char="19498">is</TOKEN>
<TOKEN end_char="19502" id="token-158-3" morph="none" pos="word" start_char="19501">of</TOKEN>
<TOKEN end_char="19509" id="token-158-4" morph="none" pos="word" start_char="19504">course</TOKEN>
<TOKEN end_char="19515" id="token-158-5" morph="none" pos="word" start_char="19511">false</TOKEN>
<TOKEN end_char="19516" id="token-158-6" morph="none" pos="punct" start_char="19516">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
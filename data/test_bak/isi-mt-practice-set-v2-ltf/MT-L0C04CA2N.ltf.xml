<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CA2N" lang="spa" raw_text_char_length="8565" raw_text_md5="ee5a987222de2cf21f567d9fb5ecb69f" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="61" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Social Media Posts Spread Bogus Coronavirus Conspiracy Theory</ORIGINAL_TEXT>
<TOKEN end_char="6" id="token-0-0" morph="none" pos="word" start_char="1">Social</TOKEN>
<TOKEN end_char="12" id="token-0-1" morph="none" pos="word" start_char="8">Media</TOKEN>
<TOKEN end_char="18" id="token-0-2" morph="none" pos="word" start_char="14">Posts</TOKEN>
<TOKEN end_char="25" id="token-0-3" morph="none" pos="word" start_char="20">Spread</TOKEN>
<TOKEN end_char="31" id="token-0-4" morph="none" pos="word" start_char="27">Bogus</TOKEN>
<TOKEN end_char="43" id="token-0-5" morph="none" pos="word" start_char="33">Coronavirus</TOKEN>
<TOKEN end_char="54" id="token-0-6" morph="none" pos="word" start_char="45">Conspiracy</TOKEN>
<TOKEN end_char="61" id="token-0-7" morph="none" pos="word" start_char="56">Theory</TOKEN>
</SEG>
<SEG end_char="74" id="segment-1" start_char="65">
<ORIGINAL_TEXT>Quick Take</ORIGINAL_TEXT>
<TOKEN end_char="69" id="token-1-0" morph="none" pos="word" start_char="65">Quick</TOKEN>
<TOKEN end_char="74" id="token-1-1" morph="none" pos="word" start_char="71">Take</TOKEN>
</SEG>
<SEG end_char="174" id="segment-2" start_char="78">
<ORIGINAL_TEXT>Multiple social media posts are spreading a bogus conspiracy theory about the deadly Wuhan virus.</ORIGINAL_TEXT>
<TOKEN end_char="85" id="token-2-0" morph="none" pos="word" start_char="78">Multiple</TOKEN>
<TOKEN end_char="92" id="token-2-1" morph="none" pos="word" start_char="87">social</TOKEN>
<TOKEN end_char="98" id="token-2-2" morph="none" pos="word" start_char="94">media</TOKEN>
<TOKEN end_char="104" id="token-2-3" morph="none" pos="word" start_char="100">posts</TOKEN>
<TOKEN end_char="108" id="token-2-4" morph="none" pos="word" start_char="106">are</TOKEN>
<TOKEN end_char="118" id="token-2-5" morph="none" pos="word" start_char="110">spreading</TOKEN>
<TOKEN end_char="120" id="token-2-6" morph="none" pos="word" start_char="120">a</TOKEN>
<TOKEN end_char="126" id="token-2-7" morph="none" pos="word" start_char="122">bogus</TOKEN>
<TOKEN end_char="137" id="token-2-8" morph="none" pos="word" start_char="128">conspiracy</TOKEN>
<TOKEN end_char="144" id="token-2-9" morph="none" pos="word" start_char="139">theory</TOKEN>
<TOKEN end_char="150" id="token-2-10" morph="none" pos="word" start_char="146">about</TOKEN>
<TOKEN end_char="154" id="token-2-11" morph="none" pos="word" start_char="152">the</TOKEN>
<TOKEN end_char="161" id="token-2-12" morph="none" pos="word" start_char="156">deadly</TOKEN>
<TOKEN end_char="167" id="token-2-13" morph="none" pos="word" start_char="163">Wuhan</TOKEN>
<TOKEN end_char="173" id="token-2-14" morph="none" pos="word" start_char="169">virus</TOKEN>
<TOKEN end_char="174" id="token-2-15" morph="none" pos="punct" start_char="174">.</TOKEN>
</SEG>
<SEG end_char="267" id="segment-3" start_char="176">
<ORIGINAL_TEXT>The posts falsely claim that the virus has been patented and a vaccine is already available.</ORIGINAL_TEXT>
<TOKEN end_char="178" id="token-3-0" morph="none" pos="word" start_char="176">The</TOKEN>
<TOKEN end_char="184" id="token-3-1" morph="none" pos="word" start_char="180">posts</TOKEN>
<TOKEN end_char="192" id="token-3-2" morph="none" pos="word" start_char="186">falsely</TOKEN>
<TOKEN end_char="198" id="token-3-3" morph="none" pos="word" start_char="194">claim</TOKEN>
<TOKEN end_char="203" id="token-3-4" morph="none" pos="word" start_char="200">that</TOKEN>
<TOKEN end_char="207" id="token-3-5" morph="none" pos="word" start_char="205">the</TOKEN>
<TOKEN end_char="213" id="token-3-6" morph="none" pos="word" start_char="209">virus</TOKEN>
<TOKEN end_char="217" id="token-3-7" morph="none" pos="word" start_char="215">has</TOKEN>
<TOKEN end_char="222" id="token-3-8" morph="none" pos="word" start_char="219">been</TOKEN>
<TOKEN end_char="231" id="token-3-9" morph="none" pos="word" start_char="224">patented</TOKEN>
<TOKEN end_char="235" id="token-3-10" morph="none" pos="word" start_char="233">and</TOKEN>
<TOKEN end_char="237" id="token-3-11" morph="none" pos="word" start_char="237">a</TOKEN>
<TOKEN end_char="245" id="token-3-12" morph="none" pos="word" start_char="239">vaccine</TOKEN>
<TOKEN end_char="248" id="token-3-13" morph="none" pos="word" start_char="247">is</TOKEN>
<TOKEN end_char="256" id="token-3-14" morph="none" pos="word" start_char="250">already</TOKEN>
<TOKEN end_char="266" id="token-3-15" morph="none" pos="word" start_char="258">available</TOKEN>
<TOKEN end_char="267" id="token-3-16" morph="none" pos="punct" start_char="267">.</TOKEN>
</SEG>
<SEG end_char="345" id="segment-4" start_char="269">
<ORIGINAL_TEXT>That’s not true; the patents the posts refer to pertain to different viruses.</ORIGINAL_TEXT>
<TOKEN end_char="274" id="token-4-0" morph="none" pos="word" start_char="269">That’s</TOKEN>
<TOKEN end_char="278" id="token-4-1" morph="none" pos="word" start_char="276">not</TOKEN>
<TOKEN end_char="283" id="token-4-2" morph="none" pos="word" start_char="280">true</TOKEN>
<TOKEN end_char="284" id="token-4-3" morph="none" pos="punct" start_char="284">;</TOKEN>
<TOKEN end_char="288" id="token-4-4" morph="none" pos="word" start_char="286">the</TOKEN>
<TOKEN end_char="296" id="token-4-5" morph="none" pos="word" start_char="290">patents</TOKEN>
<TOKEN end_char="300" id="token-4-6" morph="none" pos="word" start_char="298">the</TOKEN>
<TOKEN end_char="306" id="token-4-7" morph="none" pos="word" start_char="302">posts</TOKEN>
<TOKEN end_char="312" id="token-4-8" morph="none" pos="word" start_char="308">refer</TOKEN>
<TOKEN end_char="315" id="token-4-9" morph="none" pos="word" start_char="314">to</TOKEN>
<TOKEN end_char="323" id="token-4-10" morph="none" pos="word" start_char="317">pertain</TOKEN>
<TOKEN end_char="326" id="token-4-11" morph="none" pos="word" start_char="325">to</TOKEN>
<TOKEN end_char="336" id="token-4-12" morph="none" pos="word" start_char="328">different</TOKEN>
<TOKEN end_char="344" id="token-4-13" morph="none" pos="word" start_char="338">viruses</TOKEN>
<TOKEN end_char="345" id="token-4-14" morph="none" pos="punct" start_char="345">.</TOKEN>
</SEG>
<SEG end_char="357" id="segment-5" start_char="348">
<ORIGINAL_TEXT>Full Story</ORIGINAL_TEXT>
<TOKEN end_char="351" id="token-5-0" morph="none" pos="word" start_char="348">Full</TOKEN>
<TOKEN end_char="357" id="token-5-1" morph="none" pos="word" start_char="353">Story</TOKEN>
</SEG>
<SEG end_char="525" id="segment-6" start_char="361">
<ORIGINAL_TEXT>Following the outbreak of a respiratory disease caused by a new coronavirus in Wuhan, China in December 2019, and the announcement of the first American case on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="369" id="token-6-0" morph="none" pos="word" start_char="361">Following</TOKEN>
<TOKEN end_char="373" id="token-6-1" morph="none" pos="word" start_char="371">the</TOKEN>
<TOKEN end_char="382" id="token-6-2" morph="none" pos="word" start_char="375">outbreak</TOKEN>
<TOKEN end_char="385" id="token-6-3" morph="none" pos="word" start_char="384">of</TOKEN>
<TOKEN end_char="387" id="token-6-4" morph="none" pos="word" start_char="387">a</TOKEN>
<TOKEN end_char="399" id="token-6-5" morph="none" pos="word" start_char="389">respiratory</TOKEN>
<TOKEN end_char="407" id="token-6-6" morph="none" pos="word" start_char="401">disease</TOKEN>
<TOKEN end_char="414" id="token-6-7" morph="none" pos="word" start_char="409">caused</TOKEN>
<TOKEN end_char="417" id="token-6-8" morph="none" pos="word" start_char="416">by</TOKEN>
<TOKEN end_char="419" id="token-6-9" morph="none" pos="word" start_char="419">a</TOKEN>
<TOKEN end_char="423" id="token-6-10" morph="none" pos="word" start_char="421">new</TOKEN>
<TOKEN end_char="435" id="token-6-11" morph="none" pos="word" start_char="425">coronavirus</TOKEN>
<TOKEN end_char="438" id="token-6-12" morph="none" pos="word" start_char="437">in</TOKEN>
<TOKEN end_char="444" id="token-6-13" morph="none" pos="word" start_char="440">Wuhan</TOKEN>
<TOKEN end_char="445" id="token-6-14" morph="none" pos="punct" start_char="445">,</TOKEN>
<TOKEN end_char="451" id="token-6-15" morph="none" pos="word" start_char="447">China</TOKEN>
<TOKEN end_char="454" id="token-6-16" morph="none" pos="word" start_char="453">in</TOKEN>
<TOKEN end_char="463" id="token-6-17" morph="none" pos="word" start_char="456">December</TOKEN>
<TOKEN end_char="468" id="token-6-18" morph="none" pos="word" start_char="465">2019</TOKEN>
<TOKEN end_char="469" id="token-6-19" morph="none" pos="punct" start_char="469">,</TOKEN>
<TOKEN end_char="473" id="token-6-20" morph="none" pos="word" start_char="471">and</TOKEN>
<TOKEN end_char="477" id="token-6-21" morph="none" pos="word" start_char="475">the</TOKEN>
<TOKEN end_char="490" id="token-6-22" morph="none" pos="word" start_char="479">announcement</TOKEN>
<TOKEN end_char="493" id="token-6-23" morph="none" pos="word" start_char="492">of</TOKEN>
<TOKEN end_char="497" id="token-6-24" morph="none" pos="word" start_char="495">the</TOKEN>
<TOKEN end_char="503" id="token-6-25" morph="none" pos="word" start_char="499">first</TOKEN>
<TOKEN end_char="512" id="token-6-26" morph="none" pos="word" start_char="505">American</TOKEN>
<TOKEN end_char="517" id="token-6-27" morph="none" pos="word" start_char="514">case</TOKEN>
<TOKEN end_char="520" id="token-6-28" morph="none" pos="word" start_char="519">on</TOKEN>
<TOKEN end_char="524" id="token-6-29" morph="none" pos="word" start_char="522">Jan</TOKEN>
<TOKEN end_char="525" id="token-6-30" morph="none" pos="punct" start_char="525">.</TOKEN>
</SEG>
<SEG end_char="629" id="segment-7" start_char="527">
<ORIGINAL_TEXT>21, several groups and individuals are circulating false rumors on Facebook about the mystery pathogen.</ORIGINAL_TEXT>
<TOKEN end_char="528" id="token-7-0" morph="none" pos="word" start_char="527">21</TOKEN>
<TOKEN end_char="529" id="token-7-1" morph="none" pos="punct" start_char="529">,</TOKEN>
<TOKEN end_char="537" id="token-7-2" morph="none" pos="word" start_char="531">several</TOKEN>
<TOKEN end_char="544" id="token-7-3" morph="none" pos="word" start_char="539">groups</TOKEN>
<TOKEN end_char="548" id="token-7-4" morph="none" pos="word" start_char="546">and</TOKEN>
<TOKEN end_char="560" id="token-7-5" morph="none" pos="word" start_char="550">individuals</TOKEN>
<TOKEN end_char="564" id="token-7-6" morph="none" pos="word" start_char="562">are</TOKEN>
<TOKEN end_char="576" id="token-7-7" morph="none" pos="word" start_char="566">circulating</TOKEN>
<TOKEN end_char="582" id="token-7-8" morph="none" pos="word" start_char="578">false</TOKEN>
<TOKEN end_char="589" id="token-7-9" morph="none" pos="word" start_char="584">rumors</TOKEN>
<TOKEN end_char="592" id="token-7-10" morph="none" pos="word" start_char="591">on</TOKEN>
<TOKEN end_char="601" id="token-7-11" morph="none" pos="word" start_char="594">Facebook</TOKEN>
<TOKEN end_char="607" id="token-7-12" morph="none" pos="word" start_char="603">about</TOKEN>
<TOKEN end_char="611" id="token-7-13" morph="none" pos="word" start_char="609">the</TOKEN>
<TOKEN end_char="619" id="token-7-14" morph="none" pos="word" start_char="613">mystery</TOKEN>
<TOKEN end_char="628" id="token-7-15" morph="none" pos="word" start_char="621">pathogen</TOKEN>
<TOKEN end_char="629" id="token-7-16" morph="none" pos="punct" start_char="629">.</TOKEN>
</SEG>
<SEG end_char="780" id="segment-8" start_char="632">
<ORIGINAL_TEXT>Numerous posts claim the virus has been patented — and some even suggest, incorrectly, that the virus was made in a lab and a vaccine already exists.</ORIGINAL_TEXT>
<TOKEN end_char="639" id="token-8-0" morph="none" pos="word" start_char="632">Numerous</TOKEN>
<TOKEN end_char="645" id="token-8-1" morph="none" pos="word" start_char="641">posts</TOKEN>
<TOKEN end_char="651" id="token-8-2" morph="none" pos="word" start_char="647">claim</TOKEN>
<TOKEN end_char="655" id="token-8-3" morph="none" pos="word" start_char="653">the</TOKEN>
<TOKEN end_char="661" id="token-8-4" morph="none" pos="word" start_char="657">virus</TOKEN>
<TOKEN end_char="665" id="token-8-5" morph="none" pos="word" start_char="663">has</TOKEN>
<TOKEN end_char="670" id="token-8-6" morph="none" pos="word" start_char="667">been</TOKEN>
<TOKEN end_char="679" id="token-8-7" morph="none" pos="word" start_char="672">patented</TOKEN>
<TOKEN end_char="681" id="token-8-8" morph="none" pos="punct" start_char="681">—</TOKEN>
<TOKEN end_char="685" id="token-8-9" morph="none" pos="word" start_char="683">and</TOKEN>
<TOKEN end_char="690" id="token-8-10" morph="none" pos="word" start_char="687">some</TOKEN>
<TOKEN end_char="695" id="token-8-11" morph="none" pos="word" start_char="692">even</TOKEN>
<TOKEN end_char="703" id="token-8-12" morph="none" pos="word" start_char="697">suggest</TOKEN>
<TOKEN end_char="704" id="token-8-13" morph="none" pos="punct" start_char="704">,</TOKEN>
<TOKEN end_char="716" id="token-8-14" morph="none" pos="word" start_char="706">incorrectly</TOKEN>
<TOKEN end_char="717" id="token-8-15" morph="none" pos="punct" start_char="717">,</TOKEN>
<TOKEN end_char="722" id="token-8-16" morph="none" pos="word" start_char="719">that</TOKEN>
<TOKEN end_char="726" id="token-8-17" morph="none" pos="word" start_char="724">the</TOKEN>
<TOKEN end_char="732" id="token-8-18" morph="none" pos="word" start_char="728">virus</TOKEN>
<TOKEN end_char="736" id="token-8-19" morph="none" pos="word" start_char="734">was</TOKEN>
<TOKEN end_char="741" id="token-8-20" morph="none" pos="word" start_char="738">made</TOKEN>
<TOKEN end_char="744" id="token-8-21" morph="none" pos="word" start_char="743">in</TOKEN>
<TOKEN end_char="746" id="token-8-22" morph="none" pos="word" start_char="746">a</TOKEN>
<TOKEN end_char="750" id="token-8-23" morph="none" pos="word" start_char="748">lab</TOKEN>
<TOKEN end_char="754" id="token-8-24" morph="none" pos="word" start_char="752">and</TOKEN>
<TOKEN end_char="756" id="token-8-25" morph="none" pos="word" start_char="756">a</TOKEN>
<TOKEN end_char="764" id="token-8-26" morph="none" pos="word" start_char="758">vaccine</TOKEN>
<TOKEN end_char="772" id="token-8-27" morph="none" pos="word" start_char="766">already</TOKEN>
<TOKEN end_char="779" id="token-8-28" morph="none" pos="word" start_char="774">exists</TOKEN>
<TOKEN end_char="780" id="token-8-29" morph="none" pos="punct" start_char="780">.</TOKEN>
</SEG>
<SEG end_char="897" id="segment-9" start_char="783">
<ORIGINAL_TEXT>"The new fad disease called the ‘coronavirus’ is sweeping headlines," one Facebook post, taken from Twitter, reads.</ORIGINAL_TEXT>
<TOKEN end_char="783" id="token-9-0" morph="none" pos="punct" start_char="783">"</TOKEN>
<TOKEN end_char="786" id="token-9-1" morph="none" pos="word" start_char="784">The</TOKEN>
<TOKEN end_char="790" id="token-9-2" morph="none" pos="word" start_char="788">new</TOKEN>
<TOKEN end_char="794" id="token-9-3" morph="none" pos="word" start_char="792">fad</TOKEN>
<TOKEN end_char="802" id="token-9-4" morph="none" pos="word" start_char="796">disease</TOKEN>
<TOKEN end_char="809" id="token-9-5" morph="none" pos="word" start_char="804">called</TOKEN>
<TOKEN end_char="813" id="token-9-6" morph="none" pos="word" start_char="811">the</TOKEN>
<TOKEN end_char="815" id="token-9-7" morph="none" pos="punct" start_char="815">‘</TOKEN>
<TOKEN end_char="826" id="token-9-8" morph="none" pos="word" start_char="816">coronavirus</TOKEN>
<TOKEN end_char="827" id="token-9-9" morph="none" pos="punct" start_char="827">’</TOKEN>
<TOKEN end_char="830" id="token-9-10" morph="none" pos="word" start_char="829">is</TOKEN>
<TOKEN end_char="839" id="token-9-11" morph="none" pos="word" start_char="832">sweeping</TOKEN>
<TOKEN end_char="849" id="token-9-12" morph="none" pos="word" start_char="841">headlines</TOKEN>
<TOKEN end_char="851" id="token-9-13" morph="none" pos="punct" start_char="850">,"</TOKEN>
<TOKEN end_char="855" id="token-9-14" morph="none" pos="word" start_char="853">one</TOKEN>
<TOKEN end_char="864" id="token-9-15" morph="none" pos="word" start_char="857">Facebook</TOKEN>
<TOKEN end_char="869" id="token-9-16" morph="none" pos="word" start_char="866">post</TOKEN>
<TOKEN end_char="870" id="token-9-17" morph="none" pos="punct" start_char="870">,</TOKEN>
<TOKEN end_char="876" id="token-9-18" morph="none" pos="word" start_char="872">taken</TOKEN>
<TOKEN end_char="881" id="token-9-19" morph="none" pos="word" start_char="878">from</TOKEN>
<TOKEN end_char="889" id="token-9-20" morph="none" pos="word" start_char="883">Twitter</TOKEN>
<TOKEN end_char="890" id="token-9-21" morph="none" pos="punct" start_char="890">,</TOKEN>
<TOKEN end_char="896" id="token-9-22" morph="none" pos="word" start_char="892">reads</TOKEN>
<TOKEN end_char="897" id="token-9-23" morph="none" pos="punct" start_char="897">.</TOKEN>
</SEG>
<SEG end_char="991" id="segment-10" start_char="899">
<ORIGINAL_TEXT>"Funny enough, there was a patent for the coronavirus was filed in 2015 and granted in 2018."</ORIGINAL_TEXT>
<TOKEN end_char="899" id="token-10-0" morph="none" pos="punct" start_char="899">"</TOKEN>
<TOKEN end_char="904" id="token-10-1" morph="none" pos="word" start_char="900">Funny</TOKEN>
<TOKEN end_char="911" id="token-10-2" morph="none" pos="word" start_char="906">enough</TOKEN>
<TOKEN end_char="912" id="token-10-3" morph="none" pos="punct" start_char="912">,</TOKEN>
<TOKEN end_char="918" id="token-10-4" morph="none" pos="word" start_char="914">there</TOKEN>
<TOKEN end_char="922" id="token-10-5" morph="none" pos="word" start_char="920">was</TOKEN>
<TOKEN end_char="924" id="token-10-6" morph="none" pos="word" start_char="924">a</TOKEN>
<TOKEN end_char="931" id="token-10-7" morph="none" pos="word" start_char="926">patent</TOKEN>
<TOKEN end_char="935" id="token-10-8" morph="none" pos="word" start_char="933">for</TOKEN>
<TOKEN end_char="939" id="token-10-9" morph="none" pos="word" start_char="937">the</TOKEN>
<TOKEN end_char="951" id="token-10-10" morph="none" pos="word" start_char="941">coronavirus</TOKEN>
<TOKEN end_char="955" id="token-10-11" morph="none" pos="word" start_char="953">was</TOKEN>
<TOKEN end_char="961" id="token-10-12" morph="none" pos="word" start_char="957">filed</TOKEN>
<TOKEN end_char="964" id="token-10-13" morph="none" pos="word" start_char="963">in</TOKEN>
<TOKEN end_char="969" id="token-10-14" morph="none" pos="word" start_char="966">2015</TOKEN>
<TOKEN end_char="973" id="token-10-15" morph="none" pos="word" start_char="971">and</TOKEN>
<TOKEN end_char="981" id="token-10-16" morph="none" pos="word" start_char="975">granted</TOKEN>
<TOKEN end_char="984" id="token-10-17" morph="none" pos="word" start_char="983">in</TOKEN>
<TOKEN end_char="989" id="token-10-18" morph="none" pos="word" start_char="986">2018</TOKEN>
<TOKEN end_char="991" id="token-10-19" morph="none" pos="punct" start_char="990">."</TOKEN>
</SEG>
<SEG end_char="1189" id="segment-11" start_char="994">
<ORIGINAL_TEXT>Another, which was shared by others, and is part of a series of false coronavirus posts, proclaims that the virus is "‘new’ yet it was lab created and patented in 2015 (in development since 03’)."</ORIGINAL_TEXT>
<TOKEN end_char="1000" id="token-11-0" morph="none" pos="word" start_char="994">Another</TOKEN>
<TOKEN end_char="1001" id="token-11-1" morph="none" pos="punct" start_char="1001">,</TOKEN>
<TOKEN end_char="1007" id="token-11-2" morph="none" pos="word" start_char="1003">which</TOKEN>
<TOKEN end_char="1011" id="token-11-3" morph="none" pos="word" start_char="1009">was</TOKEN>
<TOKEN end_char="1018" id="token-11-4" morph="none" pos="word" start_char="1013">shared</TOKEN>
<TOKEN end_char="1021" id="token-11-5" morph="none" pos="word" start_char="1020">by</TOKEN>
<TOKEN end_char="1028" id="token-11-6" morph="none" pos="word" start_char="1023">others</TOKEN>
<TOKEN end_char="1029" id="token-11-7" morph="none" pos="punct" start_char="1029">,</TOKEN>
<TOKEN end_char="1033" id="token-11-8" morph="none" pos="word" start_char="1031">and</TOKEN>
<TOKEN end_char="1036" id="token-11-9" morph="none" pos="word" start_char="1035">is</TOKEN>
<TOKEN end_char="1041" id="token-11-10" morph="none" pos="word" start_char="1038">part</TOKEN>
<TOKEN end_char="1044" id="token-11-11" morph="none" pos="word" start_char="1043">of</TOKEN>
<TOKEN end_char="1046" id="token-11-12" morph="none" pos="word" start_char="1046">a</TOKEN>
<TOKEN end_char="1053" id="token-11-13" morph="none" pos="word" start_char="1048">series</TOKEN>
<TOKEN end_char="1056" id="token-11-14" morph="none" pos="word" start_char="1055">of</TOKEN>
<TOKEN end_char="1062" id="token-11-15" morph="none" pos="word" start_char="1058">false</TOKEN>
<TOKEN end_char="1074" id="token-11-16" morph="none" pos="word" start_char="1064">coronavirus</TOKEN>
<TOKEN end_char="1080" id="token-11-17" morph="none" pos="word" start_char="1076">posts</TOKEN>
<TOKEN end_char="1081" id="token-11-18" morph="none" pos="punct" start_char="1081">,</TOKEN>
<TOKEN end_char="1091" id="token-11-19" morph="none" pos="word" start_char="1083">proclaims</TOKEN>
<TOKEN end_char="1096" id="token-11-20" morph="none" pos="word" start_char="1093">that</TOKEN>
<TOKEN end_char="1100" id="token-11-21" morph="none" pos="word" start_char="1098">the</TOKEN>
<TOKEN end_char="1106" id="token-11-22" morph="none" pos="word" start_char="1102">virus</TOKEN>
<TOKEN end_char="1109" id="token-11-23" morph="none" pos="word" start_char="1108">is</TOKEN>
<TOKEN end_char="1112" id="token-11-24" morph="none" pos="punct" start_char="1111">"‘</TOKEN>
<TOKEN end_char="1115" id="token-11-25" morph="none" pos="word" start_char="1113">new</TOKEN>
<TOKEN end_char="1116" id="token-11-26" morph="none" pos="punct" start_char="1116">’</TOKEN>
<TOKEN end_char="1120" id="token-11-27" morph="none" pos="word" start_char="1118">yet</TOKEN>
<TOKEN end_char="1123" id="token-11-28" morph="none" pos="word" start_char="1122">it</TOKEN>
<TOKEN end_char="1127" id="token-11-29" morph="none" pos="word" start_char="1125">was</TOKEN>
<TOKEN end_char="1131" id="token-11-30" morph="none" pos="word" start_char="1129">lab</TOKEN>
<TOKEN end_char="1139" id="token-11-31" morph="none" pos="word" start_char="1133">created</TOKEN>
<TOKEN end_char="1143" id="token-11-32" morph="none" pos="word" start_char="1141">and</TOKEN>
<TOKEN end_char="1152" id="token-11-33" morph="none" pos="word" start_char="1145">patented</TOKEN>
<TOKEN end_char="1155" id="token-11-34" morph="none" pos="word" start_char="1154">in</TOKEN>
<TOKEN end_char="1160" id="token-11-35" morph="none" pos="word" start_char="1157">2015</TOKEN>
<TOKEN end_char="1162" id="token-11-36" morph="none" pos="punct" start_char="1162">(</TOKEN>
<TOKEN end_char="1164" id="token-11-37" morph="none" pos="word" start_char="1163">in</TOKEN>
<TOKEN end_char="1176" id="token-11-38" morph="none" pos="word" start_char="1166">development</TOKEN>
<TOKEN end_char="1182" id="token-11-39" morph="none" pos="word" start_char="1178">since</TOKEN>
<TOKEN end_char="1185" id="token-11-40" morph="none" pos="word" start_char="1184">03</TOKEN>
<TOKEN end_char="1189" id="token-11-41" morph="none" pos="punct" start_char="1186">’)."</TOKEN>
</SEG>
<SEG end_char="1233" id="segment-12" start_char="1192">
<ORIGINAL_TEXT>Yet another proposes a similar conspiracy.</ORIGINAL_TEXT>
<TOKEN end_char="1194" id="token-12-0" morph="none" pos="word" start_char="1192">Yet</TOKEN>
<TOKEN end_char="1202" id="token-12-1" morph="none" pos="word" start_char="1196">another</TOKEN>
<TOKEN end_char="1211" id="token-12-2" morph="none" pos="word" start_char="1204">proposes</TOKEN>
<TOKEN end_char="1213" id="token-12-3" morph="none" pos="word" start_char="1213">a</TOKEN>
<TOKEN end_char="1221" id="token-12-4" morph="none" pos="word" start_char="1215">similar</TOKEN>
<TOKEN end_char="1232" id="token-12-5" morph="none" pos="word" start_char="1223">conspiracy</TOKEN>
<TOKEN end_char="1233" id="token-12-6" morph="none" pos="punct" start_char="1233">.</TOKEN>
</SEG>
<SEG end_char="1317" id="segment-13" start_char="1235">
<ORIGINAL_TEXT>"So.. patent on this ‘new’ Corona virus expired on the 22nd, today," the post says.</ORIGINAL_TEXT>
<TOKEN end_char="1235" id="token-13-0" morph="none" pos="punct" start_char="1235">"</TOKEN>
<TOKEN end_char="1237" id="token-13-1" morph="none" pos="word" start_char="1236">So</TOKEN>
<TOKEN end_char="1239" id="token-13-2" morph="none" pos="punct" start_char="1238">..</TOKEN>
<TOKEN end_char="1246" id="token-13-3" morph="none" pos="word" start_char="1241">patent</TOKEN>
<TOKEN end_char="1249" id="token-13-4" morph="none" pos="word" start_char="1248">on</TOKEN>
<TOKEN end_char="1254" id="token-13-5" morph="none" pos="word" start_char="1251">this</TOKEN>
<TOKEN end_char="1256" id="token-13-6" morph="none" pos="punct" start_char="1256">‘</TOKEN>
<TOKEN end_char="1259" id="token-13-7" morph="none" pos="word" start_char="1257">new</TOKEN>
<TOKEN end_char="1260" id="token-13-8" morph="none" pos="punct" start_char="1260">’</TOKEN>
<TOKEN end_char="1267" id="token-13-9" morph="none" pos="word" start_char="1262">Corona</TOKEN>
<TOKEN end_char="1273" id="token-13-10" morph="none" pos="word" start_char="1269">virus</TOKEN>
<TOKEN end_char="1281" id="token-13-11" morph="none" pos="word" start_char="1275">expired</TOKEN>
<TOKEN end_char="1284" id="token-13-12" morph="none" pos="word" start_char="1283">on</TOKEN>
<TOKEN end_char="1288" id="token-13-13" morph="none" pos="word" start_char="1286">the</TOKEN>
<TOKEN end_char="1293" id="token-13-14" morph="none" pos="word" start_char="1290">22nd</TOKEN>
<TOKEN end_char="1294" id="token-13-15" morph="none" pos="punct" start_char="1294">,</TOKEN>
<TOKEN end_char="1300" id="token-13-16" morph="none" pos="word" start_char="1296">today</TOKEN>
<TOKEN end_char="1302" id="token-13-17" morph="none" pos="punct" start_char="1301">,"</TOKEN>
<TOKEN end_char="1306" id="token-13-18" morph="none" pos="word" start_char="1304">the</TOKEN>
<TOKEN end_char="1311" id="token-13-19" morph="none" pos="word" start_char="1308">post</TOKEN>
<TOKEN end_char="1316" id="token-13-20" morph="none" pos="word" start_char="1313">says</TOKEN>
<TOKEN end_char="1317" id="token-13-21" morph="none" pos="punct" start_char="1317">.</TOKEN>
</SEG>
<SEG end_char="1345" id="segment-14" start_char="1319">
<ORIGINAL_TEXT>"We have a sudden outbreak.</ORIGINAL_TEXT>
<TOKEN end_char="1319" id="token-14-0" morph="none" pos="punct" start_char="1319">"</TOKEN>
<TOKEN end_char="1321" id="token-14-1" morph="none" pos="word" start_char="1320">We</TOKEN>
<TOKEN end_char="1326" id="token-14-2" morph="none" pos="word" start_char="1323">have</TOKEN>
<TOKEN end_char="1328" id="token-14-3" morph="none" pos="word" start_char="1328">a</TOKEN>
<TOKEN end_char="1335" id="token-14-4" morph="none" pos="word" start_char="1330">sudden</TOKEN>
<TOKEN end_char="1344" id="token-14-5" morph="none" pos="word" start_char="1337">outbreak</TOKEN>
<TOKEN end_char="1345" id="token-14-6" morph="none" pos="punct" start_char="1345">.</TOKEN>
</SEG>
<SEG end_char="1393" id="segment-15" start_char="1347">
<ORIGINAL_TEXT>There’s magically already a vaccine available."</ORIGINAL_TEXT>
<TOKEN end_char="1353" id="token-15-0" morph="none" pos="word" start_char="1347">There’s</TOKEN>
<TOKEN end_char="1363" id="token-15-1" morph="none" pos="word" start_char="1355">magically</TOKEN>
<TOKEN end_char="1371" id="token-15-2" morph="none" pos="word" start_char="1365">already</TOKEN>
<TOKEN end_char="1373" id="token-15-3" morph="none" pos="word" start_char="1373">a</TOKEN>
<TOKEN end_char="1381" id="token-15-4" morph="none" pos="word" start_char="1375">vaccine</TOKEN>
<TOKEN end_char="1391" id="token-15-5" morph="none" pos="word" start_char="1383">available</TOKEN>
<TOKEN end_char="1393" id="token-15-6" morph="none" pos="punct" start_char="1392">."</TOKEN>
</SEG>
<SEG end_char="1546" id="segment-16" start_char="1396">
<ORIGINAL_TEXT>In fact, there is no vaccine yet available for the new coronavirus, which for now goes by the unwieldy moniker of 2019 novel coronavirus, or 2019-nCoV.</ORIGINAL_TEXT>
<TOKEN end_char="1397" id="token-16-0" morph="none" pos="word" start_char="1396">In</TOKEN>
<TOKEN end_char="1402" id="token-16-1" morph="none" pos="word" start_char="1399">fact</TOKEN>
<TOKEN end_char="1403" id="token-16-2" morph="none" pos="punct" start_char="1403">,</TOKEN>
<TOKEN end_char="1409" id="token-16-3" morph="none" pos="word" start_char="1405">there</TOKEN>
<TOKEN end_char="1412" id="token-16-4" morph="none" pos="word" start_char="1411">is</TOKEN>
<TOKEN end_char="1415" id="token-16-5" morph="none" pos="word" start_char="1414">no</TOKEN>
<TOKEN end_char="1423" id="token-16-6" morph="none" pos="word" start_char="1417">vaccine</TOKEN>
<TOKEN end_char="1427" id="token-16-7" morph="none" pos="word" start_char="1425">yet</TOKEN>
<TOKEN end_char="1437" id="token-16-8" morph="none" pos="word" start_char="1429">available</TOKEN>
<TOKEN end_char="1441" id="token-16-9" morph="none" pos="word" start_char="1439">for</TOKEN>
<TOKEN end_char="1445" id="token-16-10" morph="none" pos="word" start_char="1443">the</TOKEN>
<TOKEN end_char="1449" id="token-16-11" morph="none" pos="word" start_char="1447">new</TOKEN>
<TOKEN end_char="1461" id="token-16-12" morph="none" pos="word" start_char="1451">coronavirus</TOKEN>
<TOKEN end_char="1462" id="token-16-13" morph="none" pos="punct" start_char="1462">,</TOKEN>
<TOKEN end_char="1468" id="token-16-14" morph="none" pos="word" start_char="1464">which</TOKEN>
<TOKEN end_char="1472" id="token-16-15" morph="none" pos="word" start_char="1470">for</TOKEN>
<TOKEN end_char="1476" id="token-16-16" morph="none" pos="word" start_char="1474">now</TOKEN>
<TOKEN end_char="1481" id="token-16-17" morph="none" pos="word" start_char="1478">goes</TOKEN>
<TOKEN end_char="1484" id="token-16-18" morph="none" pos="word" start_char="1483">by</TOKEN>
<TOKEN end_char="1488" id="token-16-19" morph="none" pos="word" start_char="1486">the</TOKEN>
<TOKEN end_char="1497" id="token-16-20" morph="none" pos="word" start_char="1490">unwieldy</TOKEN>
<TOKEN end_char="1505" id="token-16-21" morph="none" pos="word" start_char="1499">moniker</TOKEN>
<TOKEN end_char="1508" id="token-16-22" morph="none" pos="word" start_char="1507">of</TOKEN>
<TOKEN end_char="1513" id="token-16-23" morph="none" pos="word" start_char="1510">2019</TOKEN>
<TOKEN end_char="1519" id="token-16-24" morph="none" pos="word" start_char="1515">novel</TOKEN>
<TOKEN end_char="1531" id="token-16-25" morph="none" pos="word" start_char="1521">coronavirus</TOKEN>
<TOKEN end_char="1532" id="token-16-26" morph="none" pos="punct" start_char="1532">,</TOKEN>
<TOKEN end_char="1535" id="token-16-27" morph="none" pos="word" start_char="1534">or</TOKEN>
<TOKEN end_char="1545" id="token-16-28" morph="none" pos="unknown" start_char="1537">2019-nCoV</TOKEN>
<TOKEN end_char="1546" id="token-16-29" morph="none" pos="punct" start_char="1546">.</TOKEN>
</SEG>
<SEG end_char="1603" id="segment-17" start_char="1548">
<ORIGINAL_TEXT>And there is no patent related to the new virus, either.</ORIGINAL_TEXT>
<TOKEN end_char="1550" id="token-17-0" morph="none" pos="word" start_char="1548">And</TOKEN>
<TOKEN end_char="1556" id="token-17-1" morph="none" pos="word" start_char="1552">there</TOKEN>
<TOKEN end_char="1559" id="token-17-2" morph="none" pos="word" start_char="1558">is</TOKEN>
<TOKEN end_char="1562" id="token-17-3" morph="none" pos="word" start_char="1561">no</TOKEN>
<TOKEN end_char="1569" id="token-17-4" morph="none" pos="word" start_char="1564">patent</TOKEN>
<TOKEN end_char="1577" id="token-17-5" morph="none" pos="word" start_char="1571">related</TOKEN>
<TOKEN end_char="1580" id="token-17-6" morph="none" pos="word" start_char="1579">to</TOKEN>
<TOKEN end_char="1584" id="token-17-7" morph="none" pos="word" start_char="1582">the</TOKEN>
<TOKEN end_char="1588" id="token-17-8" morph="none" pos="word" start_char="1586">new</TOKEN>
<TOKEN end_char="1594" id="token-17-9" morph="none" pos="word" start_char="1590">virus</TOKEN>
<TOKEN end_char="1595" id="token-17-10" morph="none" pos="punct" start_char="1595">,</TOKEN>
<TOKEN end_char="1602" id="token-17-11" morph="none" pos="word" start_char="1597">either</TOKEN>
<TOKEN end_char="1603" id="token-17-12" morph="none" pos="punct" start_char="1603">.</TOKEN>
</SEG>
<SEG end_char="1706" id="segment-18" start_char="1606">
<ORIGINAL_TEXT>All of the posts link to patents that are related to two different viruses in the coronavirus family.</ORIGINAL_TEXT>
<TOKEN end_char="1608" id="token-18-0" morph="none" pos="word" start_char="1606">All</TOKEN>
<TOKEN end_char="1611" id="token-18-1" morph="none" pos="word" start_char="1610">of</TOKEN>
<TOKEN end_char="1615" id="token-18-2" morph="none" pos="word" start_char="1613">the</TOKEN>
<TOKEN end_char="1621" id="token-18-3" morph="none" pos="word" start_char="1617">posts</TOKEN>
<TOKEN end_char="1626" id="token-18-4" morph="none" pos="word" start_char="1623">link</TOKEN>
<TOKEN end_char="1629" id="token-18-5" morph="none" pos="word" start_char="1628">to</TOKEN>
<TOKEN end_char="1637" id="token-18-6" morph="none" pos="word" start_char="1631">patents</TOKEN>
<TOKEN end_char="1642" id="token-18-7" morph="none" pos="word" start_char="1639">that</TOKEN>
<TOKEN end_char="1646" id="token-18-8" morph="none" pos="word" start_char="1644">are</TOKEN>
<TOKEN end_char="1654" id="token-18-9" morph="none" pos="word" start_char="1648">related</TOKEN>
<TOKEN end_char="1657" id="token-18-10" morph="none" pos="word" start_char="1656">to</TOKEN>
<TOKEN end_char="1661" id="token-18-11" morph="none" pos="word" start_char="1659">two</TOKEN>
<TOKEN end_char="1671" id="token-18-12" morph="none" pos="word" start_char="1663">different</TOKEN>
<TOKEN end_char="1679" id="token-18-13" morph="none" pos="word" start_char="1673">viruses</TOKEN>
<TOKEN end_char="1682" id="token-18-14" morph="none" pos="word" start_char="1681">in</TOKEN>
<TOKEN end_char="1686" id="token-18-15" morph="none" pos="word" start_char="1684">the</TOKEN>
<TOKEN end_char="1698" id="token-18-16" morph="none" pos="word" start_char="1688">coronavirus</TOKEN>
<TOKEN end_char="1705" id="token-18-17" morph="none" pos="word" start_char="1700">family</TOKEN>
<TOKEN end_char="1706" id="token-18-18" morph="none" pos="punct" start_char="1706">.</TOKEN>
</SEG>
<SEG end_char="1912" id="segment-19" start_char="1709">
<ORIGINAL_TEXT>Coronaviruses are a group of viruses that tend to cause respiratory illnesses in humans and a variety of other illnesses in animals, the Centers for Disease Control and Prevention explains on its website.</ORIGINAL_TEXT>
<TOKEN end_char="1721" id="token-19-0" morph="none" pos="word" start_char="1709">Coronaviruses</TOKEN>
<TOKEN end_char="1725" id="token-19-1" morph="none" pos="word" start_char="1723">are</TOKEN>
<TOKEN end_char="1727" id="token-19-2" morph="none" pos="word" start_char="1727">a</TOKEN>
<TOKEN end_char="1733" id="token-19-3" morph="none" pos="word" start_char="1729">group</TOKEN>
<TOKEN end_char="1736" id="token-19-4" morph="none" pos="word" start_char="1735">of</TOKEN>
<TOKEN end_char="1744" id="token-19-5" morph="none" pos="word" start_char="1738">viruses</TOKEN>
<TOKEN end_char="1749" id="token-19-6" morph="none" pos="word" start_char="1746">that</TOKEN>
<TOKEN end_char="1754" id="token-19-7" morph="none" pos="word" start_char="1751">tend</TOKEN>
<TOKEN end_char="1757" id="token-19-8" morph="none" pos="word" start_char="1756">to</TOKEN>
<TOKEN end_char="1763" id="token-19-9" morph="none" pos="word" start_char="1759">cause</TOKEN>
<TOKEN end_char="1775" id="token-19-10" morph="none" pos="word" start_char="1765">respiratory</TOKEN>
<TOKEN end_char="1785" id="token-19-11" morph="none" pos="word" start_char="1777">illnesses</TOKEN>
<TOKEN end_char="1788" id="token-19-12" morph="none" pos="word" start_char="1787">in</TOKEN>
<TOKEN end_char="1795" id="token-19-13" morph="none" pos="word" start_char="1790">humans</TOKEN>
<TOKEN end_char="1799" id="token-19-14" morph="none" pos="word" start_char="1797">and</TOKEN>
<TOKEN end_char="1801" id="token-19-15" morph="none" pos="word" start_char="1801">a</TOKEN>
<TOKEN end_char="1809" id="token-19-16" morph="none" pos="word" start_char="1803">variety</TOKEN>
<TOKEN end_char="1812" id="token-19-17" morph="none" pos="word" start_char="1811">of</TOKEN>
<TOKEN end_char="1818" id="token-19-18" morph="none" pos="word" start_char="1814">other</TOKEN>
<TOKEN end_char="1828" id="token-19-19" morph="none" pos="word" start_char="1820">illnesses</TOKEN>
<TOKEN end_char="1831" id="token-19-20" morph="none" pos="word" start_char="1830">in</TOKEN>
<TOKEN end_char="1839" id="token-19-21" morph="none" pos="word" start_char="1833">animals</TOKEN>
<TOKEN end_char="1840" id="token-19-22" morph="none" pos="punct" start_char="1840">,</TOKEN>
<TOKEN end_char="1844" id="token-19-23" morph="none" pos="word" start_char="1842">the</TOKEN>
<TOKEN end_char="1852" id="token-19-24" morph="none" pos="word" start_char="1846">Centers</TOKEN>
<TOKEN end_char="1856" id="token-19-25" morph="none" pos="word" start_char="1854">for</TOKEN>
<TOKEN end_char="1864" id="token-19-26" morph="none" pos="word" start_char="1858">Disease</TOKEN>
<TOKEN end_char="1872" id="token-19-27" morph="none" pos="word" start_char="1866">Control</TOKEN>
<TOKEN end_char="1876" id="token-19-28" morph="none" pos="word" start_char="1874">and</TOKEN>
<TOKEN end_char="1887" id="token-19-29" morph="none" pos="word" start_char="1878">Prevention</TOKEN>
<TOKEN end_char="1896" id="token-19-30" morph="none" pos="word" start_char="1889">explains</TOKEN>
<TOKEN end_char="1899" id="token-19-31" morph="none" pos="word" start_char="1898">on</TOKEN>
<TOKEN end_char="1903" id="token-19-32" morph="none" pos="word" start_char="1901">its</TOKEN>
<TOKEN end_char="1911" id="token-19-33" morph="none" pos="word" start_char="1905">website</TOKEN>
<TOKEN end_char="1912" id="token-19-34" morph="none" pos="punct" start_char="1912">.</TOKEN>
</SEG>
<SEG end_char="2020" id="segment-20" start_char="1914">
<ORIGINAL_TEXT>The name comes from the crown, or corona-like appearance of infective viruses when seen under a microscope.</ORIGINAL_TEXT>
<TOKEN end_char="1916" id="token-20-0" morph="none" pos="word" start_char="1914">The</TOKEN>
<TOKEN end_char="1921" id="token-20-1" morph="none" pos="word" start_char="1918">name</TOKEN>
<TOKEN end_char="1927" id="token-20-2" morph="none" pos="word" start_char="1923">comes</TOKEN>
<TOKEN end_char="1932" id="token-20-3" morph="none" pos="word" start_char="1929">from</TOKEN>
<TOKEN end_char="1936" id="token-20-4" morph="none" pos="word" start_char="1934">the</TOKEN>
<TOKEN end_char="1942" id="token-20-5" morph="none" pos="word" start_char="1938">crown</TOKEN>
<TOKEN end_char="1943" id="token-20-6" morph="none" pos="punct" start_char="1943">,</TOKEN>
<TOKEN end_char="1946" id="token-20-7" morph="none" pos="word" start_char="1945">or</TOKEN>
<TOKEN end_char="1958" id="token-20-8" morph="none" pos="unknown" start_char="1948">corona-like</TOKEN>
<TOKEN end_char="1969" id="token-20-9" morph="none" pos="word" start_char="1960">appearance</TOKEN>
<TOKEN end_char="1972" id="token-20-10" morph="none" pos="word" start_char="1971">of</TOKEN>
<TOKEN end_char="1982" id="token-20-11" morph="none" pos="word" start_char="1974">infective</TOKEN>
<TOKEN end_char="1990" id="token-20-12" morph="none" pos="word" start_char="1984">viruses</TOKEN>
<TOKEN end_char="1995" id="token-20-13" morph="none" pos="word" start_char="1992">when</TOKEN>
<TOKEN end_char="2000" id="token-20-14" morph="none" pos="word" start_char="1997">seen</TOKEN>
<TOKEN end_char="2006" id="token-20-15" morph="none" pos="word" start_char="2002">under</TOKEN>
<TOKEN end_char="2008" id="token-20-16" morph="none" pos="word" start_char="2008">a</TOKEN>
<TOKEN end_char="2019" id="token-20-17" morph="none" pos="word" start_char="2010">microscope</TOKEN>
<TOKEN end_char="2020" id="token-20-18" morph="none" pos="punct" start_char="2020">.</TOKEN>
</SEG>
<SEG end_char="2231" id="segment-21" start_char="2023">
<ORIGINAL_TEXT>One patent is for a genetic sequence of the virus that causes SARS, or severe acute respiratory syndrome, a disease that spread to dozens of countries in 2003, sickening more than 8,000 people and killing 774.</ORIGINAL_TEXT>
<TOKEN end_char="2025" id="token-21-0" morph="none" pos="word" start_char="2023">One</TOKEN>
<TOKEN end_char="2032" id="token-21-1" morph="none" pos="word" start_char="2027">patent</TOKEN>
<TOKEN end_char="2035" id="token-21-2" morph="none" pos="word" start_char="2034">is</TOKEN>
<TOKEN end_char="2039" id="token-21-3" morph="none" pos="word" start_char="2037">for</TOKEN>
<TOKEN end_char="2041" id="token-21-4" morph="none" pos="word" start_char="2041">a</TOKEN>
<TOKEN end_char="2049" id="token-21-5" morph="none" pos="word" start_char="2043">genetic</TOKEN>
<TOKEN end_char="2058" id="token-21-6" morph="none" pos="word" start_char="2051">sequence</TOKEN>
<TOKEN end_char="2061" id="token-21-7" morph="none" pos="word" start_char="2060">of</TOKEN>
<TOKEN end_char="2065" id="token-21-8" morph="none" pos="word" start_char="2063">the</TOKEN>
<TOKEN end_char="2071" id="token-21-9" morph="none" pos="word" start_char="2067">virus</TOKEN>
<TOKEN end_char="2076" id="token-21-10" morph="none" pos="word" start_char="2073">that</TOKEN>
<TOKEN end_char="2083" id="token-21-11" morph="none" pos="word" start_char="2078">causes</TOKEN>
<TOKEN end_char="2088" id="token-21-12" morph="none" pos="word" start_char="2085">SARS</TOKEN>
<TOKEN end_char="2089" id="token-21-13" morph="none" pos="punct" start_char="2089">,</TOKEN>
<TOKEN end_char="2092" id="token-21-14" morph="none" pos="word" start_char="2091">or</TOKEN>
<TOKEN end_char="2099" id="token-21-15" morph="none" pos="word" start_char="2094">severe</TOKEN>
<TOKEN end_char="2105" id="token-21-16" morph="none" pos="word" start_char="2101">acute</TOKEN>
<TOKEN end_char="2117" id="token-21-17" morph="none" pos="word" start_char="2107">respiratory</TOKEN>
<TOKEN end_char="2126" id="token-21-18" morph="none" pos="word" start_char="2119">syndrome</TOKEN>
<TOKEN end_char="2127" id="token-21-19" morph="none" pos="punct" start_char="2127">,</TOKEN>
<TOKEN end_char="2129" id="token-21-20" morph="none" pos="word" start_char="2129">a</TOKEN>
<TOKEN end_char="2137" id="token-21-21" morph="none" pos="word" start_char="2131">disease</TOKEN>
<TOKEN end_char="2142" id="token-21-22" morph="none" pos="word" start_char="2139">that</TOKEN>
<TOKEN end_char="2149" id="token-21-23" morph="none" pos="word" start_char="2144">spread</TOKEN>
<TOKEN end_char="2152" id="token-21-24" morph="none" pos="word" start_char="2151">to</TOKEN>
<TOKEN end_char="2159" id="token-21-25" morph="none" pos="word" start_char="2154">dozens</TOKEN>
<TOKEN end_char="2162" id="token-21-26" morph="none" pos="word" start_char="2161">of</TOKEN>
<TOKEN end_char="2172" id="token-21-27" morph="none" pos="word" start_char="2164">countries</TOKEN>
<TOKEN end_char="2175" id="token-21-28" morph="none" pos="word" start_char="2174">in</TOKEN>
<TOKEN end_char="2180" id="token-21-29" morph="none" pos="word" start_char="2177">2003</TOKEN>
<TOKEN end_char="2181" id="token-21-30" morph="none" pos="punct" start_char="2181">,</TOKEN>
<TOKEN end_char="2191" id="token-21-31" morph="none" pos="word" start_char="2183">sickening</TOKEN>
<TOKEN end_char="2196" id="token-21-32" morph="none" pos="word" start_char="2193">more</TOKEN>
<TOKEN end_char="2201" id="token-21-33" morph="none" pos="word" start_char="2198">than</TOKEN>
<TOKEN end_char="2207" id="token-21-34" morph="none" pos="unknown" start_char="2203">8,000</TOKEN>
<TOKEN end_char="2214" id="token-21-35" morph="none" pos="word" start_char="2209">people</TOKEN>
<TOKEN end_char="2218" id="token-21-36" morph="none" pos="word" start_char="2216">and</TOKEN>
<TOKEN end_char="2226" id="token-21-37" morph="none" pos="word" start_char="2220">killing</TOKEN>
<TOKEN end_char="2230" id="token-21-38" morph="none" pos="word" start_char="2228">774</TOKEN>
<TOKEN end_char="2231" id="token-21-39" morph="none" pos="punct" start_char="2231">.</TOKEN>
</SEG>
<SEG end_char="2436" id="segment-22" start_char="2234">
<ORIGINAL_TEXT>"The sequencing was done at the CDC during the SARS outbreak and they were the ones that filed the patent," Matthew Frieman, a coronavirus researcher at the University of Maryland, explained in an email.</ORIGINAL_TEXT>
<TOKEN end_char="2234" id="token-22-0" morph="none" pos="punct" start_char="2234">"</TOKEN>
<TOKEN end_char="2237" id="token-22-1" morph="none" pos="word" start_char="2235">The</TOKEN>
<TOKEN end_char="2248" id="token-22-2" morph="none" pos="word" start_char="2239">sequencing</TOKEN>
<TOKEN end_char="2252" id="token-22-3" morph="none" pos="word" start_char="2250">was</TOKEN>
<TOKEN end_char="2257" id="token-22-4" morph="none" pos="word" start_char="2254">done</TOKEN>
<TOKEN end_char="2260" id="token-22-5" morph="none" pos="word" start_char="2259">at</TOKEN>
<TOKEN end_char="2264" id="token-22-6" morph="none" pos="word" start_char="2262">the</TOKEN>
<TOKEN end_char="2268" id="token-22-7" morph="none" pos="word" start_char="2266">CDC</TOKEN>
<TOKEN end_char="2275" id="token-22-8" morph="none" pos="word" start_char="2270">during</TOKEN>
<TOKEN end_char="2279" id="token-22-9" morph="none" pos="word" start_char="2277">the</TOKEN>
<TOKEN end_char="2284" id="token-22-10" morph="none" pos="word" start_char="2281">SARS</TOKEN>
<TOKEN end_char="2293" id="token-22-11" morph="none" pos="word" start_char="2286">outbreak</TOKEN>
<TOKEN end_char="2297" id="token-22-12" morph="none" pos="word" start_char="2295">and</TOKEN>
<TOKEN end_char="2302" id="token-22-13" morph="none" pos="word" start_char="2299">they</TOKEN>
<TOKEN end_char="2307" id="token-22-14" morph="none" pos="word" start_char="2304">were</TOKEN>
<TOKEN end_char="2311" id="token-22-15" morph="none" pos="word" start_char="2309">the</TOKEN>
<TOKEN end_char="2316" id="token-22-16" morph="none" pos="word" start_char="2313">ones</TOKEN>
<TOKEN end_char="2321" id="token-22-17" morph="none" pos="word" start_char="2318">that</TOKEN>
<TOKEN end_char="2327" id="token-22-18" morph="none" pos="word" start_char="2323">filed</TOKEN>
<TOKEN end_char="2331" id="token-22-19" morph="none" pos="word" start_char="2329">the</TOKEN>
<TOKEN end_char="2338" id="token-22-20" morph="none" pos="word" start_char="2333">patent</TOKEN>
<TOKEN end_char="2340" id="token-22-21" morph="none" pos="punct" start_char="2339">,"</TOKEN>
<TOKEN end_char="2348" id="token-22-22" morph="none" pos="word" start_char="2342">Matthew</TOKEN>
<TOKEN end_char="2356" id="token-22-23" morph="none" pos="word" start_char="2350">Frieman</TOKEN>
<TOKEN end_char="2357" id="token-22-24" morph="none" pos="punct" start_char="2357">,</TOKEN>
<TOKEN end_char="2359" id="token-22-25" morph="none" pos="word" start_char="2359">a</TOKEN>
<TOKEN end_char="2371" id="token-22-26" morph="none" pos="word" start_char="2361">coronavirus</TOKEN>
<TOKEN end_char="2382" id="token-22-27" morph="none" pos="word" start_char="2373">researcher</TOKEN>
<TOKEN end_char="2385" id="token-22-28" morph="none" pos="word" start_char="2384">at</TOKEN>
<TOKEN end_char="2389" id="token-22-29" morph="none" pos="word" start_char="2387">the</TOKEN>
<TOKEN end_char="2400" id="token-22-30" morph="none" pos="word" start_char="2391">University</TOKEN>
<TOKEN end_char="2403" id="token-22-31" morph="none" pos="word" start_char="2402">of</TOKEN>
<TOKEN end_char="2412" id="token-22-32" morph="none" pos="word" start_char="2405">Maryland</TOKEN>
<TOKEN end_char="2413" id="token-22-33" morph="none" pos="punct" start_char="2413">,</TOKEN>
<TOKEN end_char="2423" id="token-22-34" morph="none" pos="word" start_char="2415">explained</TOKEN>
<TOKEN end_char="2426" id="token-22-35" morph="none" pos="word" start_char="2425">in</TOKEN>
<TOKEN end_char="2429" id="token-22-36" morph="none" pos="word" start_char="2428">an</TOKEN>
<TOKEN end_char="2435" id="token-22-37" morph="none" pos="word" start_char="2431">email</TOKEN>
<TOKEN end_char="2436" id="token-22-38" morph="none" pos="punct" start_char="2436">.</TOKEN>
</SEG>
<SEG end_char="2591" id="segment-23" start_char="2439">
<ORIGINAL_TEXT>The CDC told the Associated Press in 2003 that the agency was claiming ownership to ensure access, and to prevent others from controlling the technology.</ORIGINAL_TEXT>
<TOKEN end_char="2441" id="token-23-0" morph="none" pos="word" start_char="2439">The</TOKEN>
<TOKEN end_char="2445" id="token-23-1" morph="none" pos="word" start_char="2443">CDC</TOKEN>
<TOKEN end_char="2450" id="token-23-2" morph="none" pos="word" start_char="2447">told</TOKEN>
<TOKEN end_char="2454" id="token-23-3" morph="none" pos="word" start_char="2452">the</TOKEN>
<TOKEN end_char="2465" id="token-23-4" morph="none" pos="word" start_char="2456">Associated</TOKEN>
<TOKEN end_char="2471" id="token-23-5" morph="none" pos="word" start_char="2467">Press</TOKEN>
<TOKEN end_char="2474" id="token-23-6" morph="none" pos="word" start_char="2473">in</TOKEN>
<TOKEN end_char="2479" id="token-23-7" morph="none" pos="word" start_char="2476">2003</TOKEN>
<TOKEN end_char="2484" id="token-23-8" morph="none" pos="word" start_char="2481">that</TOKEN>
<TOKEN end_char="2488" id="token-23-9" morph="none" pos="word" start_char="2486">the</TOKEN>
<TOKEN end_char="2495" id="token-23-10" morph="none" pos="word" start_char="2490">agency</TOKEN>
<TOKEN end_char="2499" id="token-23-11" morph="none" pos="word" start_char="2497">was</TOKEN>
<TOKEN end_char="2508" id="token-23-12" morph="none" pos="word" start_char="2501">claiming</TOKEN>
<TOKEN end_char="2518" id="token-23-13" morph="none" pos="word" start_char="2510">ownership</TOKEN>
<TOKEN end_char="2521" id="token-23-14" morph="none" pos="word" start_char="2520">to</TOKEN>
<TOKEN end_char="2528" id="token-23-15" morph="none" pos="word" start_char="2523">ensure</TOKEN>
<TOKEN end_char="2535" id="token-23-16" morph="none" pos="word" start_char="2530">access</TOKEN>
<TOKEN end_char="2536" id="token-23-17" morph="none" pos="punct" start_char="2536">,</TOKEN>
<TOKEN end_char="2540" id="token-23-18" morph="none" pos="word" start_char="2538">and</TOKEN>
<TOKEN end_char="2543" id="token-23-19" morph="none" pos="word" start_char="2542">to</TOKEN>
<TOKEN end_char="2551" id="token-23-20" morph="none" pos="word" start_char="2545">prevent</TOKEN>
<TOKEN end_char="2558" id="token-23-21" morph="none" pos="word" start_char="2553">others</TOKEN>
<TOKEN end_char="2563" id="token-23-22" morph="none" pos="word" start_char="2560">from</TOKEN>
<TOKEN end_char="2575" id="token-23-23" morph="none" pos="word" start_char="2565">controlling</TOKEN>
<TOKEN end_char="2579" id="token-23-24" morph="none" pos="word" start_char="2577">the</TOKEN>
<TOKEN end_char="2590" id="token-23-25" morph="none" pos="word" start_char="2581">technology</TOKEN>
<TOKEN end_char="2591" id="token-23-26" morph="none" pos="punct" start_char="2591">.</TOKEN>
</SEG>
<SEG end_char="2804" id="segment-24" start_char="2593">
<ORIGINAL_TEXT>In a phone interview, Columbia law professor Harold Edgar told us that following a U.S. Supreme Court case decided in 2013, U.S. patent law no longer allows for patents on viral sequences as they exist in nature.</ORIGINAL_TEXT>
<TOKEN end_char="2594" id="token-24-0" morph="none" pos="word" start_char="2593">In</TOKEN>
<TOKEN end_char="2596" id="token-24-1" morph="none" pos="word" start_char="2596">a</TOKEN>
<TOKEN end_char="2602" id="token-24-2" morph="none" pos="word" start_char="2598">phone</TOKEN>
<TOKEN end_char="2612" id="token-24-3" morph="none" pos="word" start_char="2604">interview</TOKEN>
<TOKEN end_char="2613" id="token-24-4" morph="none" pos="punct" start_char="2613">,</TOKEN>
<TOKEN end_char="2622" id="token-24-5" morph="none" pos="word" start_char="2615">Columbia</TOKEN>
<TOKEN end_char="2626" id="token-24-6" morph="none" pos="word" start_char="2624">law</TOKEN>
<TOKEN end_char="2636" id="token-24-7" morph="none" pos="word" start_char="2628">professor</TOKEN>
<TOKEN end_char="2643" id="token-24-8" morph="none" pos="word" start_char="2638">Harold</TOKEN>
<TOKEN end_char="2649" id="token-24-9" morph="none" pos="word" start_char="2645">Edgar</TOKEN>
<TOKEN end_char="2654" id="token-24-10" morph="none" pos="word" start_char="2651">told</TOKEN>
<TOKEN end_char="2657" id="token-24-11" morph="none" pos="word" start_char="2656">us</TOKEN>
<TOKEN end_char="2662" id="token-24-12" morph="none" pos="word" start_char="2659">that</TOKEN>
<TOKEN end_char="2672" id="token-24-13" morph="none" pos="word" start_char="2664">following</TOKEN>
<TOKEN end_char="2674" id="token-24-14" morph="none" pos="word" start_char="2674">a</TOKEN>
<TOKEN end_char="2678" id="token-24-15" morph="none" pos="unknown" start_char="2676">U.S</TOKEN>
<TOKEN end_char="2679" id="token-24-16" morph="none" pos="punct" start_char="2679">.</TOKEN>
<TOKEN end_char="2687" id="token-24-17" morph="none" pos="word" start_char="2681">Supreme</TOKEN>
<TOKEN end_char="2693" id="token-24-18" morph="none" pos="word" start_char="2689">Court</TOKEN>
<TOKEN end_char="2698" id="token-24-19" morph="none" pos="word" start_char="2695">case</TOKEN>
<TOKEN end_char="2706" id="token-24-20" morph="none" pos="word" start_char="2700">decided</TOKEN>
<TOKEN end_char="2709" id="token-24-21" morph="none" pos="word" start_char="2708">in</TOKEN>
<TOKEN end_char="2714" id="token-24-22" morph="none" pos="word" start_char="2711">2013</TOKEN>
<TOKEN end_char="2715" id="token-24-23" morph="none" pos="punct" start_char="2715">,</TOKEN>
<TOKEN end_char="2719" id="token-24-24" morph="none" pos="unknown" start_char="2717">U.S</TOKEN>
<TOKEN end_char="2720" id="token-24-25" morph="none" pos="punct" start_char="2720">.</TOKEN>
<TOKEN end_char="2727" id="token-24-26" morph="none" pos="word" start_char="2722">patent</TOKEN>
<TOKEN end_char="2731" id="token-24-27" morph="none" pos="word" start_char="2729">law</TOKEN>
<TOKEN end_char="2734" id="token-24-28" morph="none" pos="word" start_char="2733">no</TOKEN>
<TOKEN end_char="2741" id="token-24-29" morph="none" pos="word" start_char="2736">longer</TOKEN>
<TOKEN end_char="2748" id="token-24-30" morph="none" pos="word" start_char="2743">allows</TOKEN>
<TOKEN end_char="2752" id="token-24-31" morph="none" pos="word" start_char="2750">for</TOKEN>
<TOKEN end_char="2760" id="token-24-32" morph="none" pos="word" start_char="2754">patents</TOKEN>
<TOKEN end_char="2763" id="token-24-33" morph="none" pos="word" start_char="2762">on</TOKEN>
<TOKEN end_char="2769" id="token-24-34" morph="none" pos="word" start_char="2765">viral</TOKEN>
<TOKEN end_char="2779" id="token-24-35" morph="none" pos="word" start_char="2771">sequences</TOKEN>
<TOKEN end_char="2782" id="token-24-36" morph="none" pos="word" start_char="2781">as</TOKEN>
<TOKEN end_char="2787" id="token-24-37" morph="none" pos="word" start_char="2784">they</TOKEN>
<TOKEN end_char="2793" id="token-24-38" morph="none" pos="word" start_char="2789">exist</TOKEN>
<TOKEN end_char="2796" id="token-24-39" morph="none" pos="word" start_char="2795">in</TOKEN>
<TOKEN end_char="2803" id="token-24-40" morph="none" pos="word" start_char="2798">nature</TOKEN>
<TOKEN end_char="2804" id="token-24-41" morph="none" pos="punct" start_char="2804">.</TOKEN>
</SEG>
<SEG end_char="2948" id="segment-25" start_char="2807">
<ORIGINAL_TEXT>The other supposedly related patent is for a mutated form of avian infectious bronchitis virus, or IBV, which infects poultry, but not people.</ORIGINAL_TEXT>
<TOKEN end_char="2809" id="token-25-0" morph="none" pos="word" start_char="2807">The</TOKEN>
<TOKEN end_char="2815" id="token-25-1" morph="none" pos="word" start_char="2811">other</TOKEN>
<TOKEN end_char="2826" id="token-25-2" morph="none" pos="word" start_char="2817">supposedly</TOKEN>
<TOKEN end_char="2834" id="token-25-3" morph="none" pos="word" start_char="2828">related</TOKEN>
<TOKEN end_char="2841" id="token-25-4" morph="none" pos="word" start_char="2836">patent</TOKEN>
<TOKEN end_char="2844" id="token-25-5" morph="none" pos="word" start_char="2843">is</TOKEN>
<TOKEN end_char="2848" id="token-25-6" morph="none" pos="word" start_char="2846">for</TOKEN>
<TOKEN end_char="2850" id="token-25-7" morph="none" pos="word" start_char="2850">a</TOKEN>
<TOKEN end_char="2858" id="token-25-8" morph="none" pos="word" start_char="2852">mutated</TOKEN>
<TOKEN end_char="2863" id="token-25-9" morph="none" pos="word" start_char="2860">form</TOKEN>
<TOKEN end_char="2866" id="token-25-10" morph="none" pos="word" start_char="2865">of</TOKEN>
<TOKEN end_char="2872" id="token-25-11" morph="none" pos="word" start_char="2868">avian</TOKEN>
<TOKEN end_char="2883" id="token-25-12" morph="none" pos="word" start_char="2874">infectious</TOKEN>
<TOKEN end_char="2894" id="token-25-13" morph="none" pos="word" start_char="2885">bronchitis</TOKEN>
<TOKEN end_char="2900" id="token-25-14" morph="none" pos="word" start_char="2896">virus</TOKEN>
<TOKEN end_char="2901" id="token-25-15" morph="none" pos="punct" start_char="2901">,</TOKEN>
<TOKEN end_char="2904" id="token-25-16" morph="none" pos="word" start_char="2903">or</TOKEN>
<TOKEN end_char="2908" id="token-25-17" morph="none" pos="word" start_char="2906">IBV</TOKEN>
<TOKEN end_char="2909" id="token-25-18" morph="none" pos="punct" start_char="2909">,</TOKEN>
<TOKEN end_char="2915" id="token-25-19" morph="none" pos="word" start_char="2911">which</TOKEN>
<TOKEN end_char="2923" id="token-25-20" morph="none" pos="word" start_char="2917">infects</TOKEN>
<TOKEN end_char="2931" id="token-25-21" morph="none" pos="word" start_char="2925">poultry</TOKEN>
<TOKEN end_char="2932" id="token-25-22" morph="none" pos="punct" start_char="2932">,</TOKEN>
<TOKEN end_char="2936" id="token-25-23" morph="none" pos="word" start_char="2934">but</TOKEN>
<TOKEN end_char="2940" id="token-25-24" morph="none" pos="word" start_char="2938">not</TOKEN>
<TOKEN end_char="2947" id="token-25-25" morph="none" pos="word" start_char="2942">people</TOKEN>
<TOKEN end_char="2948" id="token-25-26" morph="none" pos="punct" start_char="2948">.</TOKEN>
</SEG>
<SEG end_char="3101" id="segment-26" start_char="2950">
<ORIGINAL_TEXT>The patent was filed by the Pirbright Institute, a research institute in the U.K. whose mission is to prevent and control "viral diseases of livestock."</ORIGINAL_TEXT>
<TOKEN end_char="2952" id="token-26-0" morph="none" pos="word" start_char="2950">The</TOKEN>
<TOKEN end_char="2959" id="token-26-1" morph="none" pos="word" start_char="2954">patent</TOKEN>
<TOKEN end_char="2963" id="token-26-2" morph="none" pos="word" start_char="2961">was</TOKEN>
<TOKEN end_char="2969" id="token-26-3" morph="none" pos="word" start_char="2965">filed</TOKEN>
<TOKEN end_char="2972" id="token-26-4" morph="none" pos="word" start_char="2971">by</TOKEN>
<TOKEN end_char="2976" id="token-26-5" morph="none" pos="word" start_char="2974">the</TOKEN>
<TOKEN end_char="2986" id="token-26-6" morph="none" pos="word" start_char="2978">Pirbright</TOKEN>
<TOKEN end_char="2996" id="token-26-7" morph="none" pos="word" start_char="2988">Institute</TOKEN>
<TOKEN end_char="2997" id="token-26-8" morph="none" pos="punct" start_char="2997">,</TOKEN>
<TOKEN end_char="2999" id="token-26-9" morph="none" pos="word" start_char="2999">a</TOKEN>
<TOKEN end_char="3008" id="token-26-10" morph="none" pos="word" start_char="3001">research</TOKEN>
<TOKEN end_char="3018" id="token-26-11" morph="none" pos="word" start_char="3010">institute</TOKEN>
<TOKEN end_char="3021" id="token-26-12" morph="none" pos="word" start_char="3020">in</TOKEN>
<TOKEN end_char="3025" id="token-26-13" morph="none" pos="word" start_char="3023">the</TOKEN>
<TOKEN end_char="3029" id="token-26-14" morph="none" pos="unknown" start_char="3027">U.K</TOKEN>
<TOKEN end_char="3030" id="token-26-15" morph="none" pos="punct" start_char="3030">.</TOKEN>
<TOKEN end_char="3036" id="token-26-16" morph="none" pos="word" start_char="3032">whose</TOKEN>
<TOKEN end_char="3044" id="token-26-17" morph="none" pos="word" start_char="3038">mission</TOKEN>
<TOKEN end_char="3047" id="token-26-18" morph="none" pos="word" start_char="3046">is</TOKEN>
<TOKEN end_char="3050" id="token-26-19" morph="none" pos="word" start_char="3049">to</TOKEN>
<TOKEN end_char="3058" id="token-26-20" morph="none" pos="word" start_char="3052">prevent</TOKEN>
<TOKEN end_char="3062" id="token-26-21" morph="none" pos="word" start_char="3060">and</TOKEN>
<TOKEN end_char="3070" id="token-26-22" morph="none" pos="word" start_char="3064">control</TOKEN>
<TOKEN end_char="3072" id="token-26-23" morph="none" pos="punct" start_char="3072">"</TOKEN>
<TOKEN end_char="3077" id="token-26-24" morph="none" pos="word" start_char="3073">viral</TOKEN>
<TOKEN end_char="3086" id="token-26-25" morph="none" pos="word" start_char="3079">diseases</TOKEN>
<TOKEN end_char="3089" id="token-26-26" morph="none" pos="word" start_char="3088">of</TOKEN>
<TOKEN end_char="3099" id="token-26-27" morph="none" pos="word" start_char="3091">livestock</TOKEN>
<TOKEN end_char="3101" id="token-26-28" morph="none" pos="punct" start_char="3100">."</TOKEN>
</SEG>
<SEG end_char="3240" id="segment-27" start_char="3103">
<ORIGINAL_TEXT>The mutations were created to attenuate, or weaken, the virus, so that it could be used as a vaccine to protect chickens from the disease.</ORIGINAL_TEXT>
<TOKEN end_char="3105" id="token-27-0" morph="none" pos="word" start_char="3103">The</TOKEN>
<TOKEN end_char="3115" id="token-27-1" morph="none" pos="word" start_char="3107">mutations</TOKEN>
<TOKEN end_char="3120" id="token-27-2" morph="none" pos="word" start_char="3117">were</TOKEN>
<TOKEN end_char="3128" id="token-27-3" morph="none" pos="word" start_char="3122">created</TOKEN>
<TOKEN end_char="3131" id="token-27-4" morph="none" pos="word" start_char="3130">to</TOKEN>
<TOKEN end_char="3141" id="token-27-5" morph="none" pos="word" start_char="3133">attenuate</TOKEN>
<TOKEN end_char="3142" id="token-27-6" morph="none" pos="punct" start_char="3142">,</TOKEN>
<TOKEN end_char="3145" id="token-27-7" morph="none" pos="word" start_char="3144">or</TOKEN>
<TOKEN end_char="3152" id="token-27-8" morph="none" pos="word" start_char="3147">weaken</TOKEN>
<TOKEN end_char="3153" id="token-27-9" morph="none" pos="punct" start_char="3153">,</TOKEN>
<TOKEN end_char="3157" id="token-27-10" morph="none" pos="word" start_char="3155">the</TOKEN>
<TOKEN end_char="3163" id="token-27-11" morph="none" pos="word" start_char="3159">virus</TOKEN>
<TOKEN end_char="3164" id="token-27-12" morph="none" pos="punct" start_char="3164">,</TOKEN>
<TOKEN end_char="3167" id="token-27-13" morph="none" pos="word" start_char="3166">so</TOKEN>
<TOKEN end_char="3172" id="token-27-14" morph="none" pos="word" start_char="3169">that</TOKEN>
<TOKEN end_char="3175" id="token-27-15" morph="none" pos="word" start_char="3174">it</TOKEN>
<TOKEN end_char="3181" id="token-27-16" morph="none" pos="word" start_char="3177">could</TOKEN>
<TOKEN end_char="3184" id="token-27-17" morph="none" pos="word" start_char="3183">be</TOKEN>
<TOKEN end_char="3189" id="token-27-18" morph="none" pos="word" start_char="3186">used</TOKEN>
<TOKEN end_char="3192" id="token-27-19" morph="none" pos="word" start_char="3191">as</TOKEN>
<TOKEN end_char="3194" id="token-27-20" morph="none" pos="word" start_char="3194">a</TOKEN>
<TOKEN end_char="3202" id="token-27-21" morph="none" pos="word" start_char="3196">vaccine</TOKEN>
<TOKEN end_char="3205" id="token-27-22" morph="none" pos="word" start_char="3204">to</TOKEN>
<TOKEN end_char="3213" id="token-27-23" morph="none" pos="word" start_char="3207">protect</TOKEN>
<TOKEN end_char="3222" id="token-27-24" morph="none" pos="word" start_char="3215">chickens</TOKEN>
<TOKEN end_char="3227" id="token-27-25" morph="none" pos="word" start_char="3224">from</TOKEN>
<TOKEN end_char="3231" id="token-27-26" morph="none" pos="word" start_char="3229">the</TOKEN>
<TOKEN end_char="3239" id="token-27-27" morph="none" pos="word" start_char="3233">disease</TOKEN>
<TOKEN end_char="3240" id="token-27-28" morph="none" pos="punct" start_char="3240">.</TOKEN>
</SEG>
<SEG end_char="3323" id="segment-28" start_char="3243">
<ORIGINAL_TEXT>"Neither of these has anything to do with the new 2019-nCoV virus," said Frieman.</ORIGINAL_TEXT>
<TOKEN end_char="3243" id="token-28-0" morph="none" pos="punct" start_char="3243">"</TOKEN>
<TOKEN end_char="3250" id="token-28-1" morph="none" pos="word" start_char="3244">Neither</TOKEN>
<TOKEN end_char="3253" id="token-28-2" morph="none" pos="word" start_char="3252">of</TOKEN>
<TOKEN end_char="3259" id="token-28-3" morph="none" pos="word" start_char="3255">these</TOKEN>
<TOKEN end_char="3263" id="token-28-4" morph="none" pos="word" start_char="3261">has</TOKEN>
<TOKEN end_char="3272" id="token-28-5" morph="none" pos="word" start_char="3265">anything</TOKEN>
<TOKEN end_char="3275" id="token-28-6" morph="none" pos="word" start_char="3274">to</TOKEN>
<TOKEN end_char="3278" id="token-28-7" morph="none" pos="word" start_char="3277">do</TOKEN>
<TOKEN end_char="3283" id="token-28-8" morph="none" pos="word" start_char="3280">with</TOKEN>
<TOKEN end_char="3287" id="token-28-9" morph="none" pos="word" start_char="3285">the</TOKEN>
<TOKEN end_char="3291" id="token-28-10" morph="none" pos="word" start_char="3289">new</TOKEN>
<TOKEN end_char="3301" id="token-28-11" morph="none" pos="unknown" start_char="3293">2019-nCoV</TOKEN>
<TOKEN end_char="3307" id="token-28-12" morph="none" pos="word" start_char="3303">virus</TOKEN>
<TOKEN end_char="3309" id="token-28-13" morph="none" pos="punct" start_char="3308">,"</TOKEN>
<TOKEN end_char="3314" id="token-28-14" morph="none" pos="word" start_char="3311">said</TOKEN>
<TOKEN end_char="3322" id="token-28-15" morph="none" pos="word" start_char="3316">Frieman</TOKEN>
<TOKEN end_char="3323" id="token-28-16" morph="none" pos="punct" start_char="3323">.</TOKEN>
</SEG>
<SEG end_char="3441" id="segment-29" start_char="3325">
<ORIGINAL_TEXT>"This is clearly a bogus theory that this virus was created in a lab, patented and has a vaccine already made to it."</ORIGINAL_TEXT>
<TOKEN end_char="3325" id="token-29-0" morph="none" pos="punct" start_char="3325">"</TOKEN>
<TOKEN end_char="3329" id="token-29-1" morph="none" pos="word" start_char="3326">This</TOKEN>
<TOKEN end_char="3332" id="token-29-2" morph="none" pos="word" start_char="3331">is</TOKEN>
<TOKEN end_char="3340" id="token-29-3" morph="none" pos="word" start_char="3334">clearly</TOKEN>
<TOKEN end_char="3342" id="token-29-4" morph="none" pos="word" start_char="3342">a</TOKEN>
<TOKEN end_char="3348" id="token-29-5" morph="none" pos="word" start_char="3344">bogus</TOKEN>
<TOKEN end_char="3355" id="token-29-6" morph="none" pos="word" start_char="3350">theory</TOKEN>
<TOKEN end_char="3360" id="token-29-7" morph="none" pos="word" start_char="3357">that</TOKEN>
<TOKEN end_char="3365" id="token-29-8" morph="none" pos="word" start_char="3362">this</TOKEN>
<TOKEN end_char="3371" id="token-29-9" morph="none" pos="word" start_char="3367">virus</TOKEN>
<TOKEN end_char="3375" id="token-29-10" morph="none" pos="word" start_char="3373">was</TOKEN>
<TOKEN end_char="3383" id="token-29-11" morph="none" pos="word" start_char="3377">created</TOKEN>
<TOKEN end_char="3386" id="token-29-12" morph="none" pos="word" start_char="3385">in</TOKEN>
<TOKEN end_char="3388" id="token-29-13" morph="none" pos="word" start_char="3388">a</TOKEN>
<TOKEN end_char="3392" id="token-29-14" morph="none" pos="word" start_char="3390">lab</TOKEN>
<TOKEN end_char="3393" id="token-29-15" morph="none" pos="punct" start_char="3393">,</TOKEN>
<TOKEN end_char="3402" id="token-29-16" morph="none" pos="word" start_char="3395">patented</TOKEN>
<TOKEN end_char="3406" id="token-29-17" morph="none" pos="word" start_char="3404">and</TOKEN>
<TOKEN end_char="3410" id="token-29-18" morph="none" pos="word" start_char="3408">has</TOKEN>
<TOKEN end_char="3412" id="token-29-19" morph="none" pos="word" start_char="3412">a</TOKEN>
<TOKEN end_char="3420" id="token-29-20" morph="none" pos="word" start_char="3414">vaccine</TOKEN>
<TOKEN end_char="3428" id="token-29-21" morph="none" pos="word" start_char="3422">already</TOKEN>
<TOKEN end_char="3433" id="token-29-22" morph="none" pos="word" start_char="3430">made</TOKEN>
<TOKEN end_char="3436" id="token-29-23" morph="none" pos="word" start_char="3435">to</TOKEN>
<TOKEN end_char="3439" id="token-29-24" morph="none" pos="word" start_char="3438">it</TOKEN>
<TOKEN end_char="3441" id="token-29-25" morph="none" pos="punct" start_char="3440">."</TOKEN>
</SEG>
<SEG end_char="3545" id="segment-30" start_char="3444">
<ORIGINAL_TEXT>Researchers are still working to understand the origin, spread and severity of the latest coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="3454" id="token-30-0" morph="none" pos="word" start_char="3444">Researchers</TOKEN>
<TOKEN end_char="3458" id="token-30-1" morph="none" pos="word" start_char="3456">are</TOKEN>
<TOKEN end_char="3464" id="token-30-2" morph="none" pos="word" start_char="3460">still</TOKEN>
<TOKEN end_char="3472" id="token-30-3" morph="none" pos="word" start_char="3466">working</TOKEN>
<TOKEN end_char="3475" id="token-30-4" morph="none" pos="word" start_char="3474">to</TOKEN>
<TOKEN end_char="3486" id="token-30-5" morph="none" pos="word" start_char="3477">understand</TOKEN>
<TOKEN end_char="3490" id="token-30-6" morph="none" pos="word" start_char="3488">the</TOKEN>
<TOKEN end_char="3497" id="token-30-7" morph="none" pos="word" start_char="3492">origin</TOKEN>
<TOKEN end_char="3498" id="token-30-8" morph="none" pos="punct" start_char="3498">,</TOKEN>
<TOKEN end_char="3505" id="token-30-9" morph="none" pos="word" start_char="3500">spread</TOKEN>
<TOKEN end_char="3509" id="token-30-10" morph="none" pos="word" start_char="3507">and</TOKEN>
<TOKEN end_char="3518" id="token-30-11" morph="none" pos="word" start_char="3511">severity</TOKEN>
<TOKEN end_char="3521" id="token-30-12" morph="none" pos="word" start_char="3520">of</TOKEN>
<TOKEN end_char="3525" id="token-30-13" morph="none" pos="word" start_char="3523">the</TOKEN>
<TOKEN end_char="3532" id="token-30-14" morph="none" pos="word" start_char="3527">latest</TOKEN>
<TOKEN end_char="3544" id="token-30-15" morph="none" pos="word" start_char="3534">coronavirus</TOKEN>
<TOKEN end_char="3545" id="token-30-16" morph="none" pos="punct" start_char="3545">.</TOKEN>
</SEG>
<SEG end_char="3645" id="segment-31" start_char="3547">
<ORIGINAL_TEXT>The outbreak began in early December in Wuhan, a city of around 11 million people in central China.</ORIGINAL_TEXT>
<TOKEN end_char="3549" id="token-31-0" morph="none" pos="word" start_char="3547">The</TOKEN>
<TOKEN end_char="3558" id="token-31-1" morph="none" pos="word" start_char="3551">outbreak</TOKEN>
<TOKEN end_char="3564" id="token-31-2" morph="none" pos="word" start_char="3560">began</TOKEN>
<TOKEN end_char="3567" id="token-31-3" morph="none" pos="word" start_char="3566">in</TOKEN>
<TOKEN end_char="3573" id="token-31-4" morph="none" pos="word" start_char="3569">early</TOKEN>
<TOKEN end_char="3582" id="token-31-5" morph="none" pos="word" start_char="3575">December</TOKEN>
<TOKEN end_char="3585" id="token-31-6" morph="none" pos="word" start_char="3584">in</TOKEN>
<TOKEN end_char="3591" id="token-31-7" morph="none" pos="word" start_char="3587">Wuhan</TOKEN>
<TOKEN end_char="3592" id="token-31-8" morph="none" pos="punct" start_char="3592">,</TOKEN>
<TOKEN end_char="3594" id="token-31-9" morph="none" pos="word" start_char="3594">a</TOKEN>
<TOKEN end_char="3599" id="token-31-10" morph="none" pos="word" start_char="3596">city</TOKEN>
<TOKEN end_char="3602" id="token-31-11" morph="none" pos="word" start_char="3601">of</TOKEN>
<TOKEN end_char="3609" id="token-31-12" morph="none" pos="word" start_char="3604">around</TOKEN>
<TOKEN end_char="3612" id="token-31-13" morph="none" pos="word" start_char="3611">11</TOKEN>
<TOKEN end_char="3620" id="token-31-14" morph="none" pos="word" start_char="3614">million</TOKEN>
<TOKEN end_char="3627" id="token-31-15" morph="none" pos="word" start_char="3622">people</TOKEN>
<TOKEN end_char="3630" id="token-31-16" morph="none" pos="word" start_char="3629">in</TOKEN>
<TOKEN end_char="3638" id="token-31-17" morph="none" pos="word" start_char="3632">central</TOKEN>
<TOKEN end_char="3644" id="token-31-18" morph="none" pos="word" start_char="3640">China</TOKEN>
<TOKEN end_char="3645" id="token-31-19" morph="none" pos="punct" start_char="3645">.</TOKEN>
</SEG>
<SEG end_char="3793" id="segment-32" start_char="3648">
<ORIGINAL_TEXT>Evidence suggests the virus likely spilled over to humans from an as-yet-unidentified animal, as has happened in the past for other coronaviruses.</ORIGINAL_TEXT>
<TOKEN end_char="3655" id="token-32-0" morph="none" pos="word" start_char="3648">Evidence</TOKEN>
<TOKEN end_char="3664" id="token-32-1" morph="none" pos="word" start_char="3657">suggests</TOKEN>
<TOKEN end_char="3668" id="token-32-2" morph="none" pos="word" start_char="3666">the</TOKEN>
<TOKEN end_char="3674" id="token-32-3" morph="none" pos="word" start_char="3670">virus</TOKEN>
<TOKEN end_char="3681" id="token-32-4" morph="none" pos="word" start_char="3676">likely</TOKEN>
<TOKEN end_char="3689" id="token-32-5" morph="none" pos="word" start_char="3683">spilled</TOKEN>
<TOKEN end_char="3694" id="token-32-6" morph="none" pos="word" start_char="3691">over</TOKEN>
<TOKEN end_char="3697" id="token-32-7" morph="none" pos="word" start_char="3696">to</TOKEN>
<TOKEN end_char="3704" id="token-32-8" morph="none" pos="word" start_char="3699">humans</TOKEN>
<TOKEN end_char="3709" id="token-32-9" morph="none" pos="word" start_char="3706">from</TOKEN>
<TOKEN end_char="3712" id="token-32-10" morph="none" pos="word" start_char="3711">an</TOKEN>
<TOKEN end_char="3732" id="token-32-11" morph="none" pos="unknown" start_char="3714">as-yet-unidentified</TOKEN>
<TOKEN end_char="3739" id="token-32-12" morph="none" pos="word" start_char="3734">animal</TOKEN>
<TOKEN end_char="3740" id="token-32-13" morph="none" pos="punct" start_char="3740">,</TOKEN>
<TOKEN end_char="3743" id="token-32-14" morph="none" pos="word" start_char="3742">as</TOKEN>
<TOKEN end_char="3747" id="token-32-15" morph="none" pos="word" start_char="3745">has</TOKEN>
<TOKEN end_char="3756" id="token-32-16" morph="none" pos="word" start_char="3749">happened</TOKEN>
<TOKEN end_char="3759" id="token-32-17" morph="none" pos="word" start_char="3758">in</TOKEN>
<TOKEN end_char="3763" id="token-32-18" morph="none" pos="word" start_char="3761">the</TOKEN>
<TOKEN end_char="3768" id="token-32-19" morph="none" pos="word" start_char="3765">past</TOKEN>
<TOKEN end_char="3772" id="token-32-20" morph="none" pos="word" start_char="3770">for</TOKEN>
<TOKEN end_char="3778" id="token-32-21" morph="none" pos="word" start_char="3774">other</TOKEN>
<TOKEN end_char="3792" id="token-32-22" morph="none" pos="word" start_char="3780">coronaviruses</TOKEN>
<TOKEN end_char="3793" id="token-32-23" morph="none" pos="punct" start_char="3793">.</TOKEN>
</SEG>
<SEG end_char="3947" id="segment-33" start_char="3795">
<ORIGINAL_TEXT>The SARS virus, for instance, is thought to have come from bats, and then spread to humans through civets, a cat-like animal eaten as a delicacy in Asia.</ORIGINAL_TEXT>
<TOKEN end_char="3797" id="token-33-0" morph="none" pos="word" start_char="3795">The</TOKEN>
<TOKEN end_char="3802" id="token-33-1" morph="none" pos="word" start_char="3799">SARS</TOKEN>
<TOKEN end_char="3808" id="token-33-2" morph="none" pos="word" start_char="3804">virus</TOKEN>
<TOKEN end_char="3809" id="token-33-3" morph="none" pos="punct" start_char="3809">,</TOKEN>
<TOKEN end_char="3813" id="token-33-4" morph="none" pos="word" start_char="3811">for</TOKEN>
<TOKEN end_char="3822" id="token-33-5" morph="none" pos="word" start_char="3815">instance</TOKEN>
<TOKEN end_char="3823" id="token-33-6" morph="none" pos="punct" start_char="3823">,</TOKEN>
<TOKEN end_char="3826" id="token-33-7" morph="none" pos="word" start_char="3825">is</TOKEN>
<TOKEN end_char="3834" id="token-33-8" morph="none" pos="word" start_char="3828">thought</TOKEN>
<TOKEN end_char="3837" id="token-33-9" morph="none" pos="word" start_char="3836">to</TOKEN>
<TOKEN end_char="3842" id="token-33-10" morph="none" pos="word" start_char="3839">have</TOKEN>
<TOKEN end_char="3847" id="token-33-11" morph="none" pos="word" start_char="3844">come</TOKEN>
<TOKEN end_char="3852" id="token-33-12" morph="none" pos="word" start_char="3849">from</TOKEN>
<TOKEN end_char="3857" id="token-33-13" morph="none" pos="word" start_char="3854">bats</TOKEN>
<TOKEN end_char="3858" id="token-33-14" morph="none" pos="punct" start_char="3858">,</TOKEN>
<TOKEN end_char="3862" id="token-33-15" morph="none" pos="word" start_char="3860">and</TOKEN>
<TOKEN end_char="3867" id="token-33-16" morph="none" pos="word" start_char="3864">then</TOKEN>
<TOKEN end_char="3874" id="token-33-17" morph="none" pos="word" start_char="3869">spread</TOKEN>
<TOKEN end_char="3877" id="token-33-18" morph="none" pos="word" start_char="3876">to</TOKEN>
<TOKEN end_char="3884" id="token-33-19" morph="none" pos="word" start_char="3879">humans</TOKEN>
<TOKEN end_char="3892" id="token-33-20" morph="none" pos="word" start_char="3886">through</TOKEN>
<TOKEN end_char="3899" id="token-33-21" morph="none" pos="word" start_char="3894">civets</TOKEN>
<TOKEN end_char="3900" id="token-33-22" morph="none" pos="punct" start_char="3900">,</TOKEN>
<TOKEN end_char="3902" id="token-33-23" morph="none" pos="word" start_char="3902">a</TOKEN>
<TOKEN end_char="3911" id="token-33-24" morph="none" pos="unknown" start_char="3904">cat-like</TOKEN>
<TOKEN end_char="3918" id="token-33-25" morph="none" pos="word" start_char="3913">animal</TOKEN>
<TOKEN end_char="3924" id="token-33-26" morph="none" pos="word" start_char="3920">eaten</TOKEN>
<TOKEN end_char="3927" id="token-33-27" morph="none" pos="word" start_char="3926">as</TOKEN>
<TOKEN end_char="3929" id="token-33-28" morph="none" pos="word" start_char="3929">a</TOKEN>
<TOKEN end_char="3938" id="token-33-29" morph="none" pos="word" start_char="3931">delicacy</TOKEN>
<TOKEN end_char="3941" id="token-33-30" morph="none" pos="word" start_char="3940">in</TOKEN>
<TOKEN end_char="3946" id="token-33-31" morph="none" pos="word" start_char="3943">Asia</TOKEN>
<TOKEN end_char="3947" id="token-33-32" morph="none" pos="punct" start_char="3947">.</TOKEN>
</SEG>
<SEG end_char="4017" id="segment-34" start_char="3949">
<ORIGINAL_TEXT>The SARS virus then proved to be transmissible from person to person.</ORIGINAL_TEXT>
<TOKEN end_char="3951" id="token-34-0" morph="none" pos="word" start_char="3949">The</TOKEN>
<TOKEN end_char="3956" id="token-34-1" morph="none" pos="word" start_char="3953">SARS</TOKEN>
<TOKEN end_char="3962" id="token-34-2" morph="none" pos="word" start_char="3958">virus</TOKEN>
<TOKEN end_char="3967" id="token-34-3" morph="none" pos="word" start_char="3964">then</TOKEN>
<TOKEN end_char="3974" id="token-34-4" morph="none" pos="word" start_char="3969">proved</TOKEN>
<TOKEN end_char="3977" id="token-34-5" morph="none" pos="word" start_char="3976">to</TOKEN>
<TOKEN end_char="3980" id="token-34-6" morph="none" pos="word" start_char="3979">be</TOKEN>
<TOKEN end_char="3994" id="token-34-7" morph="none" pos="word" start_char="3982">transmissible</TOKEN>
<TOKEN end_char="3999" id="token-34-8" morph="none" pos="word" start_char="3996">from</TOKEN>
<TOKEN end_char="4006" id="token-34-9" morph="none" pos="word" start_char="4001">person</TOKEN>
<TOKEN end_char="4009" id="token-34-10" morph="none" pos="word" start_char="4008">to</TOKEN>
<TOKEN end_char="4016" id="token-34-11" morph="none" pos="word" start_char="4011">person</TOKEN>
<TOKEN end_char="4017" id="token-34-12" morph="none" pos="punct" start_char="4017">.</TOKEN>
</SEG>
<SEG end_char="4204" id="segment-35" start_char="4020">
<ORIGINAL_TEXT>A similar story played out in 2012 with the virus responsible for Middle East Respiratory Syndrome, or MERS, which may also have originated in bats, and then spread to humans via camel.</ORIGINAL_TEXT>
<TOKEN end_char="4020" id="token-35-0" morph="none" pos="word" start_char="4020">A</TOKEN>
<TOKEN end_char="4028" id="token-35-1" morph="none" pos="word" start_char="4022">similar</TOKEN>
<TOKEN end_char="4034" id="token-35-2" morph="none" pos="word" start_char="4030">story</TOKEN>
<TOKEN end_char="4041" id="token-35-3" morph="none" pos="word" start_char="4036">played</TOKEN>
<TOKEN end_char="4045" id="token-35-4" morph="none" pos="word" start_char="4043">out</TOKEN>
<TOKEN end_char="4048" id="token-35-5" morph="none" pos="word" start_char="4047">in</TOKEN>
<TOKEN end_char="4053" id="token-35-6" morph="none" pos="word" start_char="4050">2012</TOKEN>
<TOKEN end_char="4058" id="token-35-7" morph="none" pos="word" start_char="4055">with</TOKEN>
<TOKEN end_char="4062" id="token-35-8" morph="none" pos="word" start_char="4060">the</TOKEN>
<TOKEN end_char="4068" id="token-35-9" morph="none" pos="word" start_char="4064">virus</TOKEN>
<TOKEN end_char="4080" id="token-35-10" morph="none" pos="word" start_char="4070">responsible</TOKEN>
<TOKEN end_char="4084" id="token-35-11" morph="none" pos="word" start_char="4082">for</TOKEN>
<TOKEN end_char="4091" id="token-35-12" morph="none" pos="word" start_char="4086">Middle</TOKEN>
<TOKEN end_char="4096" id="token-35-13" morph="none" pos="word" start_char="4093">East</TOKEN>
<TOKEN end_char="4108" id="token-35-14" morph="none" pos="word" start_char="4098">Respiratory</TOKEN>
<TOKEN end_char="4117" id="token-35-15" morph="none" pos="word" start_char="4110">Syndrome</TOKEN>
<TOKEN end_char="4118" id="token-35-16" morph="none" pos="punct" start_char="4118">,</TOKEN>
<TOKEN end_char="4121" id="token-35-17" morph="none" pos="word" start_char="4120">or</TOKEN>
<TOKEN end_char="4126" id="token-35-18" morph="none" pos="word" start_char="4123">MERS</TOKEN>
<TOKEN end_char="4127" id="token-35-19" morph="none" pos="punct" start_char="4127">,</TOKEN>
<TOKEN end_char="4133" id="token-35-20" morph="none" pos="word" start_char="4129">which</TOKEN>
<TOKEN end_char="4137" id="token-35-21" morph="none" pos="word" start_char="4135">may</TOKEN>
<TOKEN end_char="4142" id="token-35-22" morph="none" pos="word" start_char="4139">also</TOKEN>
<TOKEN end_char="4147" id="token-35-23" morph="none" pos="word" start_char="4144">have</TOKEN>
<TOKEN end_char="4158" id="token-35-24" morph="none" pos="word" start_char="4149">originated</TOKEN>
<TOKEN end_char="4161" id="token-35-25" morph="none" pos="word" start_char="4160">in</TOKEN>
<TOKEN end_char="4166" id="token-35-26" morph="none" pos="word" start_char="4163">bats</TOKEN>
<TOKEN end_char="4167" id="token-35-27" morph="none" pos="punct" start_char="4167">,</TOKEN>
<TOKEN end_char="4171" id="token-35-28" morph="none" pos="word" start_char="4169">and</TOKEN>
<TOKEN end_char="4176" id="token-35-29" morph="none" pos="word" start_char="4173">then</TOKEN>
<TOKEN end_char="4183" id="token-35-30" morph="none" pos="word" start_char="4178">spread</TOKEN>
<TOKEN end_char="4186" id="token-35-31" morph="none" pos="word" start_char="4185">to</TOKEN>
<TOKEN end_char="4193" id="token-35-32" morph="none" pos="word" start_char="4188">humans</TOKEN>
<TOKEN end_char="4197" id="token-35-33" morph="none" pos="word" start_char="4195">via</TOKEN>
<TOKEN end_char="4203" id="token-35-34" morph="none" pos="word" start_char="4199">camel</TOKEN>
<TOKEN end_char="4204" id="token-35-35" morph="none" pos="punct" start_char="4204">.</TOKEN>
</SEG>
<SEG end_char="4360" id="segment-36" start_char="4207">
<ORIGINAL_TEXT>Cases of the new respiratory illness were first reported in people who had connections to a fish market in Wuhan that also sold a variety of live animals.</ORIGINAL_TEXT>
<TOKEN end_char="4211" id="token-36-0" morph="none" pos="word" start_char="4207">Cases</TOKEN>
<TOKEN end_char="4214" id="token-36-1" morph="none" pos="word" start_char="4213">of</TOKEN>
<TOKEN end_char="4218" id="token-36-2" morph="none" pos="word" start_char="4216">the</TOKEN>
<TOKEN end_char="4222" id="token-36-3" morph="none" pos="word" start_char="4220">new</TOKEN>
<TOKEN end_char="4234" id="token-36-4" morph="none" pos="word" start_char="4224">respiratory</TOKEN>
<TOKEN end_char="4242" id="token-36-5" morph="none" pos="word" start_char="4236">illness</TOKEN>
<TOKEN end_char="4247" id="token-36-6" morph="none" pos="word" start_char="4244">were</TOKEN>
<TOKEN end_char="4253" id="token-36-7" morph="none" pos="word" start_char="4249">first</TOKEN>
<TOKEN end_char="4262" id="token-36-8" morph="none" pos="word" start_char="4255">reported</TOKEN>
<TOKEN end_char="4265" id="token-36-9" morph="none" pos="word" start_char="4264">in</TOKEN>
<TOKEN end_char="4272" id="token-36-10" morph="none" pos="word" start_char="4267">people</TOKEN>
<TOKEN end_char="4276" id="token-36-11" morph="none" pos="word" start_char="4274">who</TOKEN>
<TOKEN end_char="4280" id="token-36-12" morph="none" pos="word" start_char="4278">had</TOKEN>
<TOKEN end_char="4292" id="token-36-13" morph="none" pos="word" start_char="4282">connections</TOKEN>
<TOKEN end_char="4295" id="token-36-14" morph="none" pos="word" start_char="4294">to</TOKEN>
<TOKEN end_char="4297" id="token-36-15" morph="none" pos="word" start_char="4297">a</TOKEN>
<TOKEN end_char="4302" id="token-36-16" morph="none" pos="word" start_char="4299">fish</TOKEN>
<TOKEN end_char="4309" id="token-36-17" morph="none" pos="word" start_char="4304">market</TOKEN>
<TOKEN end_char="4312" id="token-36-18" morph="none" pos="word" start_char="4311">in</TOKEN>
<TOKEN end_char="4318" id="token-36-19" morph="none" pos="word" start_char="4314">Wuhan</TOKEN>
<TOKEN end_char="4323" id="token-36-20" morph="none" pos="word" start_char="4320">that</TOKEN>
<TOKEN end_char="4328" id="token-36-21" morph="none" pos="word" start_char="4325">also</TOKEN>
<TOKEN end_char="4333" id="token-36-22" morph="none" pos="word" start_char="4330">sold</TOKEN>
<TOKEN end_char="4335" id="token-36-23" morph="none" pos="word" start_char="4335">a</TOKEN>
<TOKEN end_char="4343" id="token-36-24" morph="none" pos="word" start_char="4337">variety</TOKEN>
<TOKEN end_char="4346" id="token-36-25" morph="none" pos="word" start_char="4345">of</TOKEN>
<TOKEN end_char="4351" id="token-36-26" morph="none" pos="word" start_char="4348">live</TOKEN>
<TOKEN end_char="4359" id="token-36-27" morph="none" pos="word" start_char="4353">animals</TOKEN>
<TOKEN end_char="4360" id="token-36-28" morph="none" pos="punct" start_char="4360">.</TOKEN>
</SEG>
<SEG end_char="4442" id="segment-37" start_char="4362">
<ORIGINAL_TEXT>National Institute of Allergy and Infectious Diseases director Anthony Fauci told</ORIGINAL_TEXT>
<TOKEN end_char="4369" id="token-37-0" morph="none" pos="word" start_char="4362">National</TOKEN>
<TOKEN end_char="4379" id="token-37-1" morph="none" pos="word" start_char="4371">Institute</TOKEN>
<TOKEN end_char="4382" id="token-37-2" morph="none" pos="word" start_char="4381">of</TOKEN>
<TOKEN end_char="4390" id="token-37-3" morph="none" pos="word" start_char="4384">Allergy</TOKEN>
<TOKEN end_char="4394" id="token-37-4" morph="none" pos="word" start_char="4392">and</TOKEN>
<TOKEN end_char="4405" id="token-37-5" morph="none" pos="word" start_char="4396">Infectious</TOKEN>
<TOKEN end_char="4414" id="token-37-6" morph="none" pos="word" start_char="4407">Diseases</TOKEN>
<TOKEN end_char="4423" id="token-37-7" morph="none" pos="word" start_char="4416">director</TOKEN>
<TOKEN end_char="4431" id="token-37-8" morph="none" pos="word" start_char="4425">Anthony</TOKEN>
<TOKEN end_char="4437" id="token-37-9" morph="none" pos="word" start_char="4433">Fauci</TOKEN>
<TOKEN end_char="4442" id="token-37-10" morph="none" pos="word" start_char="4439">told</TOKEN>
</SEG>
<SEG end_char="4463" id="segment-38" start_char="4445">
<ORIGINAL_TEXT>Scientific American</ORIGINAL_TEXT>
<TOKEN end_char="4454" id="token-38-0" morph="none" pos="word" start_char="4445">Scientific</TOKEN>
<TOKEN end_char="4463" id="token-38-1" morph="none" pos="word" start_char="4456">American</TOKEN>
</SEG>
<SEG end_char="4472" id="segment-39" start_char="4466">
<ORIGINAL_TEXT>on Jan.</ORIGINAL_TEXT>
<TOKEN end_char="4467" id="token-39-0" morph="none" pos="word" start_char="4466">on</TOKEN>
<TOKEN end_char="4471" id="token-39-1" morph="none" pos="word" start_char="4469">Jan</TOKEN>
<TOKEN end_char="4472" id="token-39-2" morph="none" pos="punct" start_char="4472">.</TOKEN>
</SEG>
<SEG end_char="4534" id="segment-40" start_char="4474">
<ORIGINAL_TEXT>22 that the new virus "almost certainly" came from an animal.</ORIGINAL_TEXT>
<TOKEN end_char="4475" id="token-40-0" morph="none" pos="word" start_char="4474">22</TOKEN>
<TOKEN end_char="4480" id="token-40-1" morph="none" pos="word" start_char="4477">that</TOKEN>
<TOKEN end_char="4484" id="token-40-2" morph="none" pos="word" start_char="4482">the</TOKEN>
<TOKEN end_char="4488" id="token-40-3" morph="none" pos="word" start_char="4486">new</TOKEN>
<TOKEN end_char="4494" id="token-40-4" morph="none" pos="word" start_char="4490">virus</TOKEN>
<TOKEN end_char="4496" id="token-40-5" morph="none" pos="punct" start_char="4496">"</TOKEN>
<TOKEN end_char="4502" id="token-40-6" morph="none" pos="word" start_char="4497">almost</TOKEN>
<TOKEN end_char="4512" id="token-40-7" morph="none" pos="word" start_char="4504">certainly</TOKEN>
<TOKEN end_char="4513" id="token-40-8" morph="none" pos="punct" start_char="4513">"</TOKEN>
<TOKEN end_char="4518" id="token-40-9" morph="none" pos="word" start_char="4515">came</TOKEN>
<TOKEN end_char="4523" id="token-40-10" morph="none" pos="word" start_char="4520">from</TOKEN>
<TOKEN end_char="4526" id="token-40-11" morph="none" pos="word" start_char="4525">an</TOKEN>
<TOKEN end_char="4533" id="token-40-12" morph="none" pos="word" start_char="4528">animal</TOKEN>
<TOKEN end_char="4534" id="token-40-13" morph="none" pos="punct" start_char="4534">.</TOKEN>
</SEG>
<SEG end_char="4661" id="segment-41" start_char="4537">
<ORIGINAL_TEXT>It is now clear that the new coronavirus can also pass from person to person, although it is not known how easily it spreads.</ORIGINAL_TEXT>
<TOKEN end_char="4538" id="token-41-0" morph="none" pos="word" start_char="4537">It</TOKEN>
<TOKEN end_char="4541" id="token-41-1" morph="none" pos="word" start_char="4540">is</TOKEN>
<TOKEN end_char="4545" id="token-41-2" morph="none" pos="word" start_char="4543">now</TOKEN>
<TOKEN end_char="4551" id="token-41-3" morph="none" pos="word" start_char="4547">clear</TOKEN>
<TOKEN end_char="4556" id="token-41-4" morph="none" pos="word" start_char="4553">that</TOKEN>
<TOKEN end_char="4560" id="token-41-5" morph="none" pos="word" start_char="4558">the</TOKEN>
<TOKEN end_char="4564" id="token-41-6" morph="none" pos="word" start_char="4562">new</TOKEN>
<TOKEN end_char="4576" id="token-41-7" morph="none" pos="word" start_char="4566">coronavirus</TOKEN>
<TOKEN end_char="4580" id="token-41-8" morph="none" pos="word" start_char="4578">can</TOKEN>
<TOKEN end_char="4585" id="token-41-9" morph="none" pos="word" start_char="4582">also</TOKEN>
<TOKEN end_char="4590" id="token-41-10" morph="none" pos="word" start_char="4587">pass</TOKEN>
<TOKEN end_char="4595" id="token-41-11" morph="none" pos="word" start_char="4592">from</TOKEN>
<TOKEN end_char="4602" id="token-41-12" morph="none" pos="word" start_char="4597">person</TOKEN>
<TOKEN end_char="4605" id="token-41-13" morph="none" pos="word" start_char="4604">to</TOKEN>
<TOKEN end_char="4612" id="token-41-14" morph="none" pos="word" start_char="4607">person</TOKEN>
<TOKEN end_char="4613" id="token-41-15" morph="none" pos="punct" start_char="4613">,</TOKEN>
<TOKEN end_char="4622" id="token-41-16" morph="none" pos="word" start_char="4615">although</TOKEN>
<TOKEN end_char="4625" id="token-41-17" morph="none" pos="word" start_char="4624">it</TOKEN>
<TOKEN end_char="4628" id="token-41-18" morph="none" pos="word" start_char="4627">is</TOKEN>
<TOKEN end_char="4632" id="token-41-19" morph="none" pos="word" start_char="4630">not</TOKEN>
<TOKEN end_char="4638" id="token-41-20" morph="none" pos="word" start_char="4634">known</TOKEN>
<TOKEN end_char="4642" id="token-41-21" morph="none" pos="word" start_char="4640">how</TOKEN>
<TOKEN end_char="4649" id="token-41-22" morph="none" pos="word" start_char="4644">easily</TOKEN>
<TOKEN end_char="4652" id="token-41-23" morph="none" pos="word" start_char="4651">it</TOKEN>
<TOKEN end_char="4660" id="token-41-24" morph="none" pos="word" start_char="4654">spreads</TOKEN>
<TOKEN end_char="4661" id="token-41-25" morph="none" pos="punct" start_char="4661">.</TOKEN>
</SEG>
<SEG end_char="4776" id="segment-42" start_char="4663">
<ORIGINAL_TEXT>It’s possible the disease may not be as severe as SARS, but health officials say it is too early to know for sure.</ORIGINAL_TEXT>
<TOKEN end_char="4666" id="token-42-0" morph="none" pos="word" start_char="4663">It’s</TOKEN>
<TOKEN end_char="4675" id="token-42-1" morph="none" pos="word" start_char="4668">possible</TOKEN>
<TOKEN end_char="4679" id="token-42-2" morph="none" pos="word" start_char="4677">the</TOKEN>
<TOKEN end_char="4687" id="token-42-3" morph="none" pos="word" start_char="4681">disease</TOKEN>
<TOKEN end_char="4691" id="token-42-4" morph="none" pos="word" start_char="4689">may</TOKEN>
<TOKEN end_char="4695" id="token-42-5" morph="none" pos="word" start_char="4693">not</TOKEN>
<TOKEN end_char="4698" id="token-42-6" morph="none" pos="word" start_char="4697">be</TOKEN>
<TOKEN end_char="4701" id="token-42-7" morph="none" pos="word" start_char="4700">as</TOKEN>
<TOKEN end_char="4708" id="token-42-8" morph="none" pos="word" start_char="4703">severe</TOKEN>
<TOKEN end_char="4711" id="token-42-9" morph="none" pos="word" start_char="4710">as</TOKEN>
<TOKEN end_char="4716" id="token-42-10" morph="none" pos="word" start_char="4713">SARS</TOKEN>
<TOKEN end_char="4717" id="token-42-11" morph="none" pos="punct" start_char="4717">,</TOKEN>
<TOKEN end_char="4721" id="token-42-12" morph="none" pos="word" start_char="4719">but</TOKEN>
<TOKEN end_char="4728" id="token-42-13" morph="none" pos="word" start_char="4723">health</TOKEN>
<TOKEN end_char="4738" id="token-42-14" morph="none" pos="word" start_char="4730">officials</TOKEN>
<TOKEN end_char="4742" id="token-42-15" morph="none" pos="word" start_char="4740">say</TOKEN>
<TOKEN end_char="4745" id="token-42-16" morph="none" pos="word" start_char="4744">it</TOKEN>
<TOKEN end_char="4748" id="token-42-17" morph="none" pos="word" start_char="4747">is</TOKEN>
<TOKEN end_char="4752" id="token-42-18" morph="none" pos="word" start_char="4750">too</TOKEN>
<TOKEN end_char="4758" id="token-42-19" morph="none" pos="word" start_char="4754">early</TOKEN>
<TOKEN end_char="4761" id="token-42-20" morph="none" pos="word" start_char="4760">to</TOKEN>
<TOKEN end_char="4766" id="token-42-21" morph="none" pos="word" start_char="4763">know</TOKEN>
<TOKEN end_char="4770" id="token-42-22" morph="none" pos="word" start_char="4768">for</TOKEN>
<TOKEN end_char="4775" id="token-42-23" morph="none" pos="word" start_char="4772">sure</TOKEN>
<TOKEN end_char="4776" id="token-42-24" morph="none" pos="punct" start_char="4776">.</TOKEN>
</SEG>
<SEG end_char="4831" id="segment-43" start_char="4778">
<ORIGINAL_TEXT>Symptoms include fever, cough and shortness of breath.</ORIGINAL_TEXT>
<TOKEN end_char="4785" id="token-43-0" morph="none" pos="word" start_char="4778">Symptoms</TOKEN>
<TOKEN end_char="4793" id="token-43-1" morph="none" pos="word" start_char="4787">include</TOKEN>
<TOKEN end_char="4799" id="token-43-2" morph="none" pos="word" start_char="4795">fever</TOKEN>
<TOKEN end_char="4800" id="token-43-3" morph="none" pos="punct" start_char="4800">,</TOKEN>
<TOKEN end_char="4806" id="token-43-4" morph="none" pos="word" start_char="4802">cough</TOKEN>
<TOKEN end_char="4810" id="token-43-5" morph="none" pos="word" start_char="4808">and</TOKEN>
<TOKEN end_char="4820" id="token-43-6" morph="none" pos="word" start_char="4812">shortness</TOKEN>
<TOKEN end_char="4823" id="token-43-7" morph="none" pos="word" start_char="4822">of</TOKEN>
<TOKEN end_char="4830" id="token-43-8" morph="none" pos="word" start_char="4825">breath</TOKEN>
<TOKEN end_char="4831" id="token-43-9" morph="none" pos="punct" start_char="4831">.</TOKEN>
</SEG>
<SEG end_char="4849" id="segment-44" start_char="4834">
<ORIGINAL_TEXT>As of early Jan.</ORIGINAL_TEXT>
<TOKEN end_char="4835" id="token-44-0" morph="none" pos="word" start_char="4834">As</TOKEN>
<TOKEN end_char="4838" id="token-44-1" morph="none" pos="word" start_char="4837">of</TOKEN>
<TOKEN end_char="4844" id="token-44-2" morph="none" pos="word" start_char="4840">early</TOKEN>
<TOKEN end_char="4848" id="token-44-3" morph="none" pos="word" start_char="4846">Jan</TOKEN>
<TOKEN end_char="4849" id="token-44-4" morph="none" pos="punct" start_char="4849">.</TOKEN>
</SEG>
<SEG end_char="4942" id="segment-45" start_char="4851">
<ORIGINAL_TEXT>24, at least 26 people have died, all in China, out of nearly 900 confirmed cases worldwide.</ORIGINAL_TEXT>
<TOKEN end_char="4852" id="token-45-0" morph="none" pos="word" start_char="4851">24</TOKEN>
<TOKEN end_char="4853" id="token-45-1" morph="none" pos="punct" start_char="4853">,</TOKEN>
<TOKEN end_char="4856" id="token-45-2" morph="none" pos="word" start_char="4855">at</TOKEN>
<TOKEN end_char="4862" id="token-45-3" morph="none" pos="word" start_char="4858">least</TOKEN>
<TOKEN end_char="4865" id="token-45-4" morph="none" pos="word" start_char="4864">26</TOKEN>
<TOKEN end_char="4872" id="token-45-5" morph="none" pos="word" start_char="4867">people</TOKEN>
<TOKEN end_char="4877" id="token-45-6" morph="none" pos="word" start_char="4874">have</TOKEN>
<TOKEN end_char="4882" id="token-45-7" morph="none" pos="word" start_char="4879">died</TOKEN>
<TOKEN end_char="4883" id="token-45-8" morph="none" pos="punct" start_char="4883">,</TOKEN>
<TOKEN end_char="4887" id="token-45-9" morph="none" pos="word" start_char="4885">all</TOKEN>
<TOKEN end_char="4890" id="token-45-10" morph="none" pos="word" start_char="4889">in</TOKEN>
<TOKEN end_char="4896" id="token-45-11" morph="none" pos="word" start_char="4892">China</TOKEN>
<TOKEN end_char="4897" id="token-45-12" morph="none" pos="punct" start_char="4897">,</TOKEN>
<TOKEN end_char="4901" id="token-45-13" morph="none" pos="word" start_char="4899">out</TOKEN>
<TOKEN end_char="4904" id="token-45-14" morph="none" pos="word" start_char="4903">of</TOKEN>
<TOKEN end_char="4911" id="token-45-15" morph="none" pos="word" start_char="4906">nearly</TOKEN>
<TOKEN end_char="4915" id="token-45-16" morph="none" pos="word" start_char="4913">900</TOKEN>
<TOKEN end_char="4925" id="token-45-17" morph="none" pos="word" start_char="4917">confirmed</TOKEN>
<TOKEN end_char="4931" id="token-45-18" morph="none" pos="word" start_char="4927">cases</TOKEN>
<TOKEN end_char="4941" id="token-45-19" morph="none" pos="word" start_char="4933">worldwide</TOKEN>
<TOKEN end_char="4942" id="token-45-20" morph="none" pos="punct" start_char="4942">.</TOKEN>
</SEG>
<SEG end_char="5031" id="segment-46" start_char="4944">
<ORIGINAL_TEXT>Deaths have primarily occurred in older people or those who had other health conditions.</ORIGINAL_TEXT>
<TOKEN end_char="4949" id="token-46-0" morph="none" pos="word" start_char="4944">Deaths</TOKEN>
<TOKEN end_char="4954" id="token-46-1" morph="none" pos="word" start_char="4951">have</TOKEN>
<TOKEN end_char="4964" id="token-46-2" morph="none" pos="word" start_char="4956">primarily</TOKEN>
<TOKEN end_char="4973" id="token-46-3" morph="none" pos="word" start_char="4966">occurred</TOKEN>
<TOKEN end_char="4976" id="token-46-4" morph="none" pos="word" start_char="4975">in</TOKEN>
<TOKEN end_char="4982" id="token-46-5" morph="none" pos="word" start_char="4978">older</TOKEN>
<TOKEN end_char="4989" id="token-46-6" morph="none" pos="word" start_char="4984">people</TOKEN>
<TOKEN end_char="4992" id="token-46-7" morph="none" pos="word" start_char="4991">or</TOKEN>
<TOKEN end_char="4998" id="token-46-8" morph="none" pos="word" start_char="4994">those</TOKEN>
<TOKEN end_char="5002" id="token-46-9" morph="none" pos="word" start_char="5000">who</TOKEN>
<TOKEN end_char="5006" id="token-46-10" morph="none" pos="word" start_char="5004">had</TOKEN>
<TOKEN end_char="5012" id="token-46-11" morph="none" pos="word" start_char="5008">other</TOKEN>
<TOKEN end_char="5019" id="token-46-12" morph="none" pos="word" start_char="5014">health</TOKEN>
<TOKEN end_char="5030" id="token-46-13" morph="none" pos="word" start_char="5021">conditions</TOKEN>
<TOKEN end_char="5031" id="token-46-14" morph="none" pos="punct" start_char="5031">.</TOKEN>
</SEG>
<SEG end_char="5105" id="segment-47" start_char="5033">
<ORIGINAL_TEXT>Cases have also been reported in Thailand, Taiwan, Japan and South Korea.</ORIGINAL_TEXT>
<TOKEN end_char="5037" id="token-47-0" morph="none" pos="word" start_char="5033">Cases</TOKEN>
<TOKEN end_char="5042" id="token-47-1" morph="none" pos="word" start_char="5039">have</TOKEN>
<TOKEN end_char="5047" id="token-47-2" morph="none" pos="word" start_char="5044">also</TOKEN>
<TOKEN end_char="5052" id="token-47-3" morph="none" pos="word" start_char="5049">been</TOKEN>
<TOKEN end_char="5061" id="token-47-4" morph="none" pos="word" start_char="5054">reported</TOKEN>
<TOKEN end_char="5064" id="token-47-5" morph="none" pos="word" start_char="5063">in</TOKEN>
<TOKEN end_char="5073" id="token-47-6" morph="none" pos="word" start_char="5066">Thailand</TOKEN>
<TOKEN end_char="5074" id="token-47-7" morph="none" pos="punct" start_char="5074">,</TOKEN>
<TOKEN end_char="5081" id="token-47-8" morph="none" pos="word" start_char="5076">Taiwan</TOKEN>
<TOKEN end_char="5082" id="token-47-9" morph="none" pos="punct" start_char="5082">,</TOKEN>
<TOKEN end_char="5088" id="token-47-10" morph="none" pos="word" start_char="5084">Japan</TOKEN>
<TOKEN end_char="5092" id="token-47-11" morph="none" pos="word" start_char="5090">and</TOKEN>
<TOKEN end_char="5098" id="token-47-12" morph="none" pos="word" start_char="5094">South</TOKEN>
<TOKEN end_char="5104" id="token-47-13" morph="none" pos="word" start_char="5100">Korea</TOKEN>
<TOKEN end_char="5105" id="token-47-14" morph="none" pos="punct" start_char="5105">.</TOKEN>
</SEG>
<SEG end_char="5203" id="segment-48" start_char="5107">
<ORIGINAL_TEXT>The U.S. patient had recently traveled from Wuhan and is in good condition, according to the CDC.</ORIGINAL_TEXT>
<TOKEN end_char="5109" id="token-48-0" morph="none" pos="word" start_char="5107">The</TOKEN>
<TOKEN end_char="5113" id="token-48-1" morph="none" pos="unknown" start_char="5111">U.S</TOKEN>
<TOKEN end_char="5114" id="token-48-2" morph="none" pos="punct" start_char="5114">.</TOKEN>
<TOKEN end_char="5122" id="token-48-3" morph="none" pos="word" start_char="5116">patient</TOKEN>
<TOKEN end_char="5126" id="token-48-4" morph="none" pos="word" start_char="5124">had</TOKEN>
<TOKEN end_char="5135" id="token-48-5" morph="none" pos="word" start_char="5128">recently</TOKEN>
<TOKEN end_char="5144" id="token-48-6" morph="none" pos="word" start_char="5137">traveled</TOKEN>
<TOKEN end_char="5149" id="token-48-7" morph="none" pos="word" start_char="5146">from</TOKEN>
<TOKEN end_char="5155" id="token-48-8" morph="none" pos="word" start_char="5151">Wuhan</TOKEN>
<TOKEN end_char="5159" id="token-48-9" morph="none" pos="word" start_char="5157">and</TOKEN>
<TOKEN end_char="5162" id="token-48-10" morph="none" pos="word" start_char="5161">is</TOKEN>
<TOKEN end_char="5165" id="token-48-11" morph="none" pos="word" start_char="5164">in</TOKEN>
<TOKEN end_char="5170" id="token-48-12" morph="none" pos="word" start_char="5167">good</TOKEN>
<TOKEN end_char="5180" id="token-48-13" morph="none" pos="word" start_char="5172">condition</TOKEN>
<TOKEN end_char="5181" id="token-48-14" morph="none" pos="punct" start_char="5181">,</TOKEN>
<TOKEN end_char="5191" id="token-48-15" morph="none" pos="word" start_char="5183">according</TOKEN>
<TOKEN end_char="5194" id="token-48-16" morph="none" pos="word" start_char="5193">to</TOKEN>
<TOKEN end_char="5198" id="token-48-17" morph="none" pos="word" start_char="5196">the</TOKEN>
<TOKEN end_char="5202" id="token-48-18" morph="none" pos="word" start_char="5200">CDC</TOKEN>
<TOKEN end_char="5203" id="token-48-19" morph="none" pos="punct" start_char="5203">.</TOKEN>
</SEG>
<SEG end_char="5321" id="segment-49" start_char="5206">
<ORIGINAL_TEXT>As for a vaccine, the CDC says it is already working on one with the NIH, but that it is still early in the process.</ORIGINAL_TEXT>
<TOKEN end_char="5207" id="token-49-0" morph="none" pos="word" start_char="5206">As</TOKEN>
<TOKEN end_char="5211" id="token-49-1" morph="none" pos="word" start_char="5209">for</TOKEN>
<TOKEN end_char="5213" id="token-49-2" morph="none" pos="word" start_char="5213">a</TOKEN>
<TOKEN end_char="5221" id="token-49-3" morph="none" pos="word" start_char="5215">vaccine</TOKEN>
<TOKEN end_char="5222" id="token-49-4" morph="none" pos="punct" start_char="5222">,</TOKEN>
<TOKEN end_char="5226" id="token-49-5" morph="none" pos="word" start_char="5224">the</TOKEN>
<TOKEN end_char="5230" id="token-49-6" morph="none" pos="word" start_char="5228">CDC</TOKEN>
<TOKEN end_char="5235" id="token-49-7" morph="none" pos="word" start_char="5232">says</TOKEN>
<TOKEN end_char="5238" id="token-49-8" morph="none" pos="word" start_char="5237">it</TOKEN>
<TOKEN end_char="5241" id="token-49-9" morph="none" pos="word" start_char="5240">is</TOKEN>
<TOKEN end_char="5249" id="token-49-10" morph="none" pos="word" start_char="5243">already</TOKEN>
<TOKEN end_char="5257" id="token-49-11" morph="none" pos="word" start_char="5251">working</TOKEN>
<TOKEN end_char="5260" id="token-49-12" morph="none" pos="word" start_char="5259">on</TOKEN>
<TOKEN end_char="5264" id="token-49-13" morph="none" pos="word" start_char="5262">one</TOKEN>
<TOKEN end_char="5269" id="token-49-14" morph="none" pos="word" start_char="5266">with</TOKEN>
<TOKEN end_char="5273" id="token-49-15" morph="none" pos="word" start_char="5271">the</TOKEN>
<TOKEN end_char="5277" id="token-49-16" morph="none" pos="word" start_char="5275">NIH</TOKEN>
<TOKEN end_char="5278" id="token-49-17" morph="none" pos="punct" start_char="5278">,</TOKEN>
<TOKEN end_char="5282" id="token-49-18" morph="none" pos="word" start_char="5280">but</TOKEN>
<TOKEN end_char="5287" id="token-49-19" morph="none" pos="word" start_char="5284">that</TOKEN>
<TOKEN end_char="5290" id="token-49-20" morph="none" pos="word" start_char="5289">it</TOKEN>
<TOKEN end_char="5293" id="token-49-21" morph="none" pos="word" start_char="5292">is</TOKEN>
<TOKEN end_char="5299" id="token-49-22" morph="none" pos="word" start_char="5295">still</TOKEN>
<TOKEN end_char="5305" id="token-49-23" morph="none" pos="word" start_char="5301">early</TOKEN>
<TOKEN end_char="5308" id="token-49-24" morph="none" pos="word" start_char="5307">in</TOKEN>
<TOKEN end_char="5312" id="token-49-25" morph="none" pos="word" start_char="5310">the</TOKEN>
<TOKEN end_char="5320" id="token-49-26" morph="none" pos="word" start_char="5314">process</TOKEN>
<TOKEN end_char="5321" id="token-49-27" morph="none" pos="punct" start_char="5321">.</TOKEN>
</SEG>
<SEG end_char="5344" id="segment-50" start_char="5323">
<ORIGINAL_TEXT>Fauci explained in his</ORIGINAL_TEXT>
<TOKEN end_char="5327" id="token-50-0" morph="none" pos="word" start_char="5323">Fauci</TOKEN>
<TOKEN end_char="5337" id="token-50-1" morph="none" pos="word" start_char="5329">explained</TOKEN>
<TOKEN end_char="5340" id="token-50-2" morph="none" pos="word" start_char="5339">in</TOKEN>
<TOKEN end_char="5344" id="token-50-3" morph="none" pos="word" start_char="5342">his</TOKEN>
</SEG>
<SEG end_char="5365" id="segment-51" start_char="5347">
<ORIGINAL_TEXT>Scientific American</ORIGINAL_TEXT>
<TOKEN end_char="5356" id="token-51-0" morph="none" pos="word" start_char="5347">Scientific</TOKEN>
<TOKEN end_char="5365" id="token-51-1" morph="none" pos="word" start_char="5358">American</TOKEN>
</SEG>
<SEG end_char="5480" id="segment-52" start_char="5368">
<ORIGINAL_TEXT>interview that the agency is partnering with Moderna, a biotech company, to create a messenger RNA-based vaccine.</ORIGINAL_TEXT>
<TOKEN end_char="5376" id="token-52-0" morph="none" pos="word" start_char="5368">interview</TOKEN>
<TOKEN end_char="5381" id="token-52-1" morph="none" pos="word" start_char="5378">that</TOKEN>
<TOKEN end_char="5385" id="token-52-2" morph="none" pos="word" start_char="5383">the</TOKEN>
<TOKEN end_char="5392" id="token-52-3" morph="none" pos="word" start_char="5387">agency</TOKEN>
<TOKEN end_char="5395" id="token-52-4" morph="none" pos="word" start_char="5394">is</TOKEN>
<TOKEN end_char="5406" id="token-52-5" morph="none" pos="word" start_char="5397">partnering</TOKEN>
<TOKEN end_char="5411" id="token-52-6" morph="none" pos="word" start_char="5408">with</TOKEN>
<TOKEN end_char="5419" id="token-52-7" morph="none" pos="word" start_char="5413">Moderna</TOKEN>
<TOKEN end_char="5420" id="token-52-8" morph="none" pos="punct" start_char="5420">,</TOKEN>
<TOKEN end_char="5422" id="token-52-9" morph="none" pos="word" start_char="5422">a</TOKEN>
<TOKEN end_char="5430" id="token-52-10" morph="none" pos="word" start_char="5424">biotech</TOKEN>
<TOKEN end_char="5438" id="token-52-11" morph="none" pos="word" start_char="5432">company</TOKEN>
<TOKEN end_char="5439" id="token-52-12" morph="none" pos="punct" start_char="5439">,</TOKEN>
<TOKEN end_char="5442" id="token-52-13" morph="none" pos="word" start_char="5441">to</TOKEN>
<TOKEN end_char="5449" id="token-52-14" morph="none" pos="word" start_char="5444">create</TOKEN>
<TOKEN end_char="5451" id="token-52-15" morph="none" pos="word" start_char="5451">a</TOKEN>
<TOKEN end_char="5461" id="token-52-16" morph="none" pos="word" start_char="5453">messenger</TOKEN>
<TOKEN end_char="5471" id="token-52-17" morph="none" pos="unknown" start_char="5463">RNA-based</TOKEN>
<TOKEN end_char="5479" id="token-52-18" morph="none" pos="word" start_char="5473">vaccine</TOKEN>
<TOKEN end_char="5480" id="token-52-19" morph="none" pos="punct" start_char="5480">.</TOKEN>
</SEG>
<SEG end_char="5582" id="segment-53" start_char="5483">
<ORIGINAL_TEXT>"We will likely have a candidate in early phase I trials for safety in about three months," he said.</ORIGINAL_TEXT>
<TOKEN end_char="5483" id="token-53-0" morph="none" pos="punct" start_char="5483">"</TOKEN>
<TOKEN end_char="5485" id="token-53-1" morph="none" pos="word" start_char="5484">We</TOKEN>
<TOKEN end_char="5490" id="token-53-2" morph="none" pos="word" start_char="5487">will</TOKEN>
<TOKEN end_char="5497" id="token-53-3" morph="none" pos="word" start_char="5492">likely</TOKEN>
<TOKEN end_char="5502" id="token-53-4" morph="none" pos="word" start_char="5499">have</TOKEN>
<TOKEN end_char="5504" id="token-53-5" morph="none" pos="word" start_char="5504">a</TOKEN>
<TOKEN end_char="5514" id="token-53-6" morph="none" pos="word" start_char="5506">candidate</TOKEN>
<TOKEN end_char="5517" id="token-53-7" morph="none" pos="word" start_char="5516">in</TOKEN>
<TOKEN end_char="5523" id="token-53-8" morph="none" pos="word" start_char="5519">early</TOKEN>
<TOKEN end_char="5529" id="token-53-9" morph="none" pos="word" start_char="5525">phase</TOKEN>
<TOKEN end_char="5531" id="token-53-10" morph="none" pos="word" start_char="5531">I</TOKEN>
<TOKEN end_char="5538" id="token-53-11" morph="none" pos="word" start_char="5533">trials</TOKEN>
<TOKEN end_char="5542" id="token-53-12" morph="none" pos="word" start_char="5540">for</TOKEN>
<TOKEN end_char="5549" id="token-53-13" morph="none" pos="word" start_char="5544">safety</TOKEN>
<TOKEN end_char="5552" id="token-53-14" morph="none" pos="word" start_char="5551">in</TOKEN>
<TOKEN end_char="5558" id="token-53-15" morph="none" pos="word" start_char="5554">about</TOKEN>
<TOKEN end_char="5564" id="token-53-16" morph="none" pos="word" start_char="5560">three</TOKEN>
<TOKEN end_char="5571" id="token-53-17" morph="none" pos="word" start_char="5566">months</TOKEN>
<TOKEN end_char="5573" id="token-53-18" morph="none" pos="punct" start_char="5572">,"</TOKEN>
<TOKEN end_char="5576" id="token-53-19" morph="none" pos="word" start_char="5575">he</TOKEN>
<TOKEN end_char="5581" id="token-53-20" morph="none" pos="word" start_char="5578">said</TOKEN>
<TOKEN end_char="5582" id="token-53-21" morph="none" pos="punct" start_char="5582">.</TOKEN>
</SEG>
<SEG end_char="5709" id="segment-54" start_char="5584">
<ORIGINAL_TEXT>"That doesn’t mean we will have a vaccine ready for use in three months; even in an emergency, that would take a year or more.</ORIGINAL_TEXT>
<TOKEN end_char="5584" id="token-54-0" morph="none" pos="punct" start_char="5584">"</TOKEN>
<TOKEN end_char="5588" id="token-54-1" morph="none" pos="word" start_char="5585">That</TOKEN>
<TOKEN end_char="5596" id="token-54-2" morph="none" pos="word" start_char="5590">doesn’t</TOKEN>
<TOKEN end_char="5601" id="token-54-3" morph="none" pos="word" start_char="5598">mean</TOKEN>
<TOKEN end_char="5604" id="token-54-4" morph="none" pos="word" start_char="5603">we</TOKEN>
<TOKEN end_char="5609" id="token-54-5" morph="none" pos="word" start_char="5606">will</TOKEN>
<TOKEN end_char="5614" id="token-54-6" morph="none" pos="word" start_char="5611">have</TOKEN>
<TOKEN end_char="5616" id="token-54-7" morph="none" pos="word" start_char="5616">a</TOKEN>
<TOKEN end_char="5624" id="token-54-8" morph="none" pos="word" start_char="5618">vaccine</TOKEN>
<TOKEN end_char="5630" id="token-54-9" morph="none" pos="word" start_char="5626">ready</TOKEN>
<TOKEN end_char="5634" id="token-54-10" morph="none" pos="word" start_char="5632">for</TOKEN>
<TOKEN end_char="5638" id="token-54-11" morph="none" pos="word" start_char="5636">use</TOKEN>
<TOKEN end_char="5641" id="token-54-12" morph="none" pos="word" start_char="5640">in</TOKEN>
<TOKEN end_char="5647" id="token-54-13" morph="none" pos="word" start_char="5643">three</TOKEN>
<TOKEN end_char="5654" id="token-54-14" morph="none" pos="word" start_char="5649">months</TOKEN>
<TOKEN end_char="5655" id="token-54-15" morph="none" pos="punct" start_char="5655">;</TOKEN>
<TOKEN end_char="5660" id="token-54-16" morph="none" pos="word" start_char="5657">even</TOKEN>
<TOKEN end_char="5663" id="token-54-17" morph="none" pos="word" start_char="5662">in</TOKEN>
<TOKEN end_char="5666" id="token-54-18" morph="none" pos="word" start_char="5665">an</TOKEN>
<TOKEN end_char="5676" id="token-54-19" morph="none" pos="word" start_char="5668">emergency</TOKEN>
<TOKEN end_char="5677" id="token-54-20" morph="none" pos="punct" start_char="5677">,</TOKEN>
<TOKEN end_char="5682" id="token-54-21" morph="none" pos="word" start_char="5679">that</TOKEN>
<TOKEN end_char="5688" id="token-54-22" morph="none" pos="word" start_char="5684">would</TOKEN>
<TOKEN end_char="5693" id="token-54-23" morph="none" pos="word" start_char="5690">take</TOKEN>
<TOKEN end_char="5695" id="token-54-24" morph="none" pos="word" start_char="5695">a</TOKEN>
<TOKEN end_char="5700" id="token-54-25" morph="none" pos="word" start_char="5697">year</TOKEN>
<TOKEN end_char="5703" id="token-54-26" morph="none" pos="word" start_char="5702">or</TOKEN>
<TOKEN end_char="5708" id="token-54-27" morph="none" pos="word" start_char="5705">more</TOKEN>
<TOKEN end_char="5709" id="token-54-28" morph="none" pos="punct" start_char="5709">.</TOKEN>
</SEG>
<SEG end_char="5735" id="segment-55" start_char="5711">
<ORIGINAL_TEXT>But we’re already on it."</ORIGINAL_TEXT>
<TOKEN end_char="5713" id="token-55-0" morph="none" pos="word" start_char="5711">But</TOKEN>
<TOKEN end_char="5719" id="token-55-1" morph="none" pos="word" start_char="5715">we’re</TOKEN>
<TOKEN end_char="5727" id="token-55-2" morph="none" pos="word" start_char="5721">already</TOKEN>
<TOKEN end_char="5730" id="token-55-3" morph="none" pos="word" start_char="5729">on</TOKEN>
<TOKEN end_char="5733" id="token-55-4" morph="none" pos="word" start_char="5732">it</TOKEN>
<TOKEN end_char="5735" id="token-55-5" morph="none" pos="punct" start_char="5734">."</TOKEN>
</SEG>
<SEG end_char="6023" id="segment-56" start_char="5738">
<ORIGINAL_TEXT>So while efforts have begun to make a vaccine, in part thanks to Chinese researchers who have already shared the sequence of the new virus, it is not true that a vaccine already exists — just as claims that the virus previously had a patent and was manufactured in a lab are also false.</ORIGINAL_TEXT>
<TOKEN end_char="5739" id="token-56-0" morph="none" pos="word" start_char="5738">So</TOKEN>
<TOKEN end_char="5745" id="token-56-1" morph="none" pos="word" start_char="5741">while</TOKEN>
<TOKEN end_char="5753" id="token-56-2" morph="none" pos="word" start_char="5747">efforts</TOKEN>
<TOKEN end_char="5758" id="token-56-3" morph="none" pos="word" start_char="5755">have</TOKEN>
<TOKEN end_char="5764" id="token-56-4" morph="none" pos="word" start_char="5760">begun</TOKEN>
<TOKEN end_char="5767" id="token-56-5" morph="none" pos="word" start_char="5766">to</TOKEN>
<TOKEN end_char="5772" id="token-56-6" morph="none" pos="word" start_char="5769">make</TOKEN>
<TOKEN end_char="5774" id="token-56-7" morph="none" pos="word" start_char="5774">a</TOKEN>
<TOKEN end_char="5782" id="token-56-8" morph="none" pos="word" start_char="5776">vaccine</TOKEN>
<TOKEN end_char="5783" id="token-56-9" morph="none" pos="punct" start_char="5783">,</TOKEN>
<TOKEN end_char="5786" id="token-56-10" morph="none" pos="word" start_char="5785">in</TOKEN>
<TOKEN end_char="5791" id="token-56-11" morph="none" pos="word" start_char="5788">part</TOKEN>
<TOKEN end_char="5798" id="token-56-12" morph="none" pos="word" start_char="5793">thanks</TOKEN>
<TOKEN end_char="5801" id="token-56-13" morph="none" pos="word" start_char="5800">to</TOKEN>
<TOKEN end_char="5809" id="token-56-14" morph="none" pos="word" start_char="5803">Chinese</TOKEN>
<TOKEN end_char="5821" id="token-56-15" morph="none" pos="word" start_char="5811">researchers</TOKEN>
<TOKEN end_char="5825" id="token-56-16" morph="none" pos="word" start_char="5823">who</TOKEN>
<TOKEN end_char="5830" id="token-56-17" morph="none" pos="word" start_char="5827">have</TOKEN>
<TOKEN end_char="5838" id="token-56-18" morph="none" pos="word" start_char="5832">already</TOKEN>
<TOKEN end_char="5845" id="token-56-19" morph="none" pos="word" start_char="5840">shared</TOKEN>
<TOKEN end_char="5849" id="token-56-20" morph="none" pos="word" start_char="5847">the</TOKEN>
<TOKEN end_char="5858" id="token-56-21" morph="none" pos="word" start_char="5851">sequence</TOKEN>
<TOKEN end_char="5861" id="token-56-22" morph="none" pos="word" start_char="5860">of</TOKEN>
<TOKEN end_char="5865" id="token-56-23" morph="none" pos="word" start_char="5863">the</TOKEN>
<TOKEN end_char="5869" id="token-56-24" morph="none" pos="word" start_char="5867">new</TOKEN>
<TOKEN end_char="5875" id="token-56-25" morph="none" pos="word" start_char="5871">virus</TOKEN>
<TOKEN end_char="5876" id="token-56-26" morph="none" pos="punct" start_char="5876">,</TOKEN>
<TOKEN end_char="5879" id="token-56-27" morph="none" pos="word" start_char="5878">it</TOKEN>
<TOKEN end_char="5882" id="token-56-28" morph="none" pos="word" start_char="5881">is</TOKEN>
<TOKEN end_char="5886" id="token-56-29" morph="none" pos="word" start_char="5884">not</TOKEN>
<TOKEN end_char="5891" id="token-56-30" morph="none" pos="word" start_char="5888">true</TOKEN>
<TOKEN end_char="5896" id="token-56-31" morph="none" pos="word" start_char="5893">that</TOKEN>
<TOKEN end_char="5898" id="token-56-32" morph="none" pos="word" start_char="5898">a</TOKEN>
<TOKEN end_char="5906" id="token-56-33" morph="none" pos="word" start_char="5900">vaccine</TOKEN>
<TOKEN end_char="5914" id="token-56-34" morph="none" pos="word" start_char="5908">already</TOKEN>
<TOKEN end_char="5921" id="token-56-35" morph="none" pos="word" start_char="5916">exists</TOKEN>
<TOKEN end_char="5923" id="token-56-36" morph="none" pos="punct" start_char="5923">—</TOKEN>
<TOKEN end_char="5928" id="token-56-37" morph="none" pos="word" start_char="5925">just</TOKEN>
<TOKEN end_char="5931" id="token-56-38" morph="none" pos="word" start_char="5930">as</TOKEN>
<TOKEN end_char="5938" id="token-56-39" morph="none" pos="word" start_char="5933">claims</TOKEN>
<TOKEN end_char="5943" id="token-56-40" morph="none" pos="word" start_char="5940">that</TOKEN>
<TOKEN end_char="5947" id="token-56-41" morph="none" pos="word" start_char="5945">the</TOKEN>
<TOKEN end_char="5953" id="token-56-42" morph="none" pos="word" start_char="5949">virus</TOKEN>
<TOKEN end_char="5964" id="token-56-43" morph="none" pos="word" start_char="5955">previously</TOKEN>
<TOKEN end_char="5968" id="token-56-44" morph="none" pos="word" start_char="5966">had</TOKEN>
<TOKEN end_char="5970" id="token-56-45" morph="none" pos="word" start_char="5970">a</TOKEN>
<TOKEN end_char="5977" id="token-56-46" morph="none" pos="word" start_char="5972">patent</TOKEN>
<TOKEN end_char="5981" id="token-56-47" morph="none" pos="word" start_char="5979">and</TOKEN>
<TOKEN end_char="5985" id="token-56-48" morph="none" pos="word" start_char="5983">was</TOKEN>
<TOKEN end_char="5998" id="token-56-49" morph="none" pos="word" start_char="5987">manufactured</TOKEN>
<TOKEN end_char="6001" id="token-56-50" morph="none" pos="word" start_char="6000">in</TOKEN>
<TOKEN end_char="6003" id="token-56-51" morph="none" pos="word" start_char="6003">a</TOKEN>
<TOKEN end_char="6007" id="token-56-52" morph="none" pos="word" start_char="6005">lab</TOKEN>
<TOKEN end_char="6011" id="token-56-53" morph="none" pos="word" start_char="6009">are</TOKEN>
<TOKEN end_char="6016" id="token-56-54" morph="none" pos="word" start_char="6013">also</TOKEN>
<TOKEN end_char="6022" id="token-56-55" morph="none" pos="word" start_char="6018">false</TOKEN>
<TOKEN end_char="6023" id="token-56-56" morph="none" pos="punct" start_char="6023">.</TOKEN>
</SEG>
<SEG end_char="6085" id="segment-57" start_char="6026">
<ORIGINAL_TEXT>Editor’s note: FactCheck.org is one of several organizations</ORIGINAL_TEXT>
<TOKEN end_char="6033" id="token-57-0" morph="none" pos="word" start_char="6026">Editor’s</TOKEN>
<TOKEN end_char="6038" id="token-57-1" morph="none" pos="word" start_char="6035">note</TOKEN>
<TOKEN end_char="6039" id="token-57-2" morph="none" pos="punct" start_char="6039">:</TOKEN>
<TOKEN end_char="6053" id="token-57-3" morph="none" pos="unknown" start_char="6041">FactCheck.org</TOKEN>
<TOKEN end_char="6056" id="token-57-4" morph="none" pos="word" start_char="6055">is</TOKEN>
<TOKEN end_char="6060" id="token-57-5" morph="none" pos="word" start_char="6058">one</TOKEN>
<TOKEN end_char="6063" id="token-57-6" morph="none" pos="word" start_char="6062">of</TOKEN>
<TOKEN end_char="6071" id="token-57-7" morph="none" pos="word" start_char="6065">several</TOKEN>
<TOKEN end_char="6085" id="token-57-8" morph="none" pos="word" start_char="6073">organizations</TOKEN>
</SEG>
<SEG end_char="6108" id="segment-58" start_char="6088">
<ORIGINAL_TEXT>working with Facebook</ORIGINAL_TEXT>
<TOKEN end_char="6094" id="token-58-0" morph="none" pos="word" start_char="6088">working</TOKEN>
<TOKEN end_char="6099" id="token-58-1" morph="none" pos="word" start_char="6096">with</TOKEN>
<TOKEN end_char="6108" id="token-58-2" morph="none" pos="word" start_char="6101">Facebook</TOKEN>
</SEG>
<SEG end_char="6158" id="segment-59" start_char="6111">
<ORIGINAL_TEXT>to debunk misinformation shared on social media.</ORIGINAL_TEXT>
<TOKEN end_char="6112" id="token-59-0" morph="none" pos="word" start_char="6111">to</TOKEN>
<TOKEN end_char="6119" id="token-59-1" morph="none" pos="word" start_char="6114">debunk</TOKEN>
<TOKEN end_char="6134" id="token-59-2" morph="none" pos="word" start_char="6121">misinformation</TOKEN>
<TOKEN end_char="6141" id="token-59-3" morph="none" pos="word" start_char="6136">shared</TOKEN>
<TOKEN end_char="6144" id="token-59-4" morph="none" pos="word" start_char="6143">on</TOKEN>
<TOKEN end_char="6151" id="token-59-5" morph="none" pos="word" start_char="6146">social</TOKEN>
<TOKEN end_char="6157" id="token-59-6" morph="none" pos="word" start_char="6153">media</TOKEN>
<TOKEN end_char="6158" id="token-59-7" morph="none" pos="punct" start_char="6158">.</TOKEN>
</SEG>
<SEG end_char="6198" id="segment-60" start_char="6160">
<ORIGINAL_TEXT>Our previous stories can be found here.</ORIGINAL_TEXT>
<TOKEN end_char="6162" id="token-60-0" morph="none" pos="word" start_char="6160">Our</TOKEN>
<TOKEN end_char="6171" id="token-60-1" morph="none" pos="word" start_char="6164">previous</TOKEN>
<TOKEN end_char="6179" id="token-60-2" morph="none" pos="word" start_char="6173">stories</TOKEN>
<TOKEN end_char="6183" id="token-60-3" morph="none" pos="word" start_char="6181">can</TOKEN>
<TOKEN end_char="6186" id="token-60-4" morph="none" pos="word" start_char="6185">be</TOKEN>
<TOKEN end_char="6192" id="token-60-5" morph="none" pos="word" start_char="6188">found</TOKEN>
<TOKEN end_char="6197" id="token-60-6" morph="none" pos="word" start_char="6194">here</TOKEN>
<TOKEN end_char="6198" id="token-60-7" morph="none" pos="punct" start_char="6198">.</TOKEN>
</SEG>
<SEG end_char="6208" id="segment-61" start_char="6202">
<ORIGINAL_TEXT>Sources</ORIGINAL_TEXT>
<TOKEN end_char="6208" id="token-61-0" morph="none" pos="word" start_char="6202">Sources</TOKEN>
</SEG>
<SEG end_char="6291" id="segment-62" start_char="6212">
<ORIGINAL_TEXT>"First Travel-related Case of 2019 Novel Coronavirus Detected in United States."</ORIGINAL_TEXT>
<TOKEN end_char="6212" id="token-62-0" morph="none" pos="punct" start_char="6212">"</TOKEN>
<TOKEN end_char="6217" id="token-62-1" morph="none" pos="word" start_char="6213">First</TOKEN>
<TOKEN end_char="6232" id="token-62-2" morph="none" pos="unknown" start_char="6219">Travel-related</TOKEN>
<TOKEN end_char="6237" id="token-62-3" morph="none" pos="word" start_char="6234">Case</TOKEN>
<TOKEN end_char="6240" id="token-62-4" morph="none" pos="word" start_char="6239">of</TOKEN>
<TOKEN end_char="6245" id="token-62-5" morph="none" pos="word" start_char="6242">2019</TOKEN>
<TOKEN end_char="6251" id="token-62-6" morph="none" pos="word" start_char="6247">Novel</TOKEN>
<TOKEN end_char="6263" id="token-62-7" morph="none" pos="word" start_char="6253">Coronavirus</TOKEN>
<TOKEN end_char="6272" id="token-62-8" morph="none" pos="word" start_char="6265">Detected</TOKEN>
<TOKEN end_char="6275" id="token-62-9" morph="none" pos="word" start_char="6274">in</TOKEN>
<TOKEN end_char="6282" id="token-62-10" morph="none" pos="word" start_char="6277">United</TOKEN>
<TOKEN end_char="6289" id="token-62-11" morph="none" pos="word" start_char="6284">States</TOKEN>
<TOKEN end_char="6291" id="token-62-12" morph="none" pos="punct" start_char="6290">."</TOKEN>
</SEG>
<SEG end_char="6306" id="segment-63" start_char="6293">
<ORIGINAL_TEXT>Press release.</ORIGINAL_TEXT>
<TOKEN end_char="6297" id="token-63-0" morph="none" pos="word" start_char="6293">Press</TOKEN>
<TOKEN end_char="6305" id="token-63-1" morph="none" pos="word" start_char="6299">release</TOKEN>
<TOKEN end_char="6306" id="token-63-2" morph="none" pos="punct" start_char="6306">.</TOKEN>
</SEG>
<SEG end_char="6311" id="segment-64" start_char="6308">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN end_char="6310" id="token-64-0" morph="none" pos="word" start_char="6308">CDC</TOKEN>
<TOKEN end_char="6311" id="token-64-1" morph="none" pos="punct" start_char="6311">.</TOKEN>
<TRANSLATED_TEXT>- CDC.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="6324" id="segment-65" start_char="6313">
<ORIGINAL_TEXT>21 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="6314" id="token-65-0" morph="none" pos="word" start_char="6313">21</TOKEN>
<TOKEN end_char="6318" id="token-65-1" morph="none" pos="word" start_char="6316">Jan</TOKEN>
<TOKEN end_char="6323" id="token-65-2" morph="none" pos="word" start_char="6320">2020</TOKEN>
<TOKEN end_char="6324" id="token-65-3" morph="none" pos="punct" start_char="6324">.</TOKEN>
</SEG>
<SEG end_char="6339" id="segment-66" start_char="6327">
<ORIGINAL_TEXT>Lewis, Tayna.</ORIGINAL_TEXT>
<TOKEN end_char="6331" id="token-66-0" morph="none" pos="word" start_char="6327">Lewis</TOKEN>
<TOKEN end_char="6332" id="token-66-1" morph="none" pos="punct" start_char="6332">,</TOKEN>
<TOKEN end_char="6338" id="token-66-2" morph="none" pos="word" start_char="6334">Tayna</TOKEN>
<TOKEN end_char="6339" id="token-66-3" morph="none" pos="punct" start_char="6339">.</TOKEN>
</SEG>
<SEG end_char="6419" id="segment-67" start_char="6341">
<ORIGINAL_TEXT>"Infectious Disease Expert Discusses What We Know about the New Chinese Virus."</ORIGINAL_TEXT>
<TOKEN end_char="6341" id="token-67-0" morph="none" pos="punct" start_char="6341">"</TOKEN>
<TOKEN end_char="6351" id="token-67-1" morph="none" pos="word" start_char="6342">Infectious</TOKEN>
<TOKEN end_char="6359" id="token-67-2" morph="none" pos="word" start_char="6353">Disease</TOKEN>
<TOKEN end_char="6366" id="token-67-3" morph="none" pos="word" start_char="6361">Expert</TOKEN>
<TOKEN end_char="6376" id="token-67-4" morph="none" pos="word" start_char="6368">Discusses</TOKEN>
<TOKEN end_char="6381" id="token-67-5" morph="none" pos="word" start_char="6378">What</TOKEN>
<TOKEN end_char="6384" id="token-67-6" morph="none" pos="word" start_char="6383">We</TOKEN>
<TOKEN end_char="6389" id="token-67-7" morph="none" pos="word" start_char="6386">Know</TOKEN>
<TOKEN end_char="6395" id="token-67-8" morph="none" pos="word" start_char="6391">about</TOKEN>
<TOKEN end_char="6399" id="token-67-9" morph="none" pos="word" start_char="6397">the</TOKEN>
<TOKEN end_char="6403" id="token-67-10" morph="none" pos="word" start_char="6401">New</TOKEN>
<TOKEN end_char="6411" id="token-67-11" morph="none" pos="word" start_char="6405">Chinese</TOKEN>
<TOKEN end_char="6417" id="token-67-12" morph="none" pos="word" start_char="6413">Virus</TOKEN>
<TOKEN end_char="6419" id="token-67-13" morph="none" pos="punct" start_char="6418">."</TOKEN>
</SEG>
<SEG end_char="6440" id="segment-68" start_char="6421">
<ORIGINAL_TEXT>Scientific American.</ORIGINAL_TEXT>
<TOKEN end_char="6430" id="token-68-0" morph="none" pos="word" start_char="6421">Scientific</TOKEN>
<TOKEN end_char="6439" id="token-68-1" morph="none" pos="word" start_char="6432">American</TOKEN>
<TOKEN end_char="6440" id="token-68-2" morph="none" pos="punct" start_char="6440">.</TOKEN>
</SEG>
<SEG end_char="6453" id="segment-69" start_char="6442">
<ORIGINAL_TEXT>22 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="6443" id="token-69-0" morph="none" pos="word" start_char="6442">22</TOKEN>
<TOKEN end_char="6447" id="token-69-1" morph="none" pos="word" start_char="6445">Jan</TOKEN>
<TOKEN end_char="6452" id="token-69-2" morph="none" pos="word" start_char="6449">2020</TOKEN>
<TOKEN end_char="6453" id="token-69-3" morph="none" pos="punct" start_char="6453">.</TOKEN>
</SEG>
<SEG end_char="6472" id="segment-70" start_char="6456">
<ORIGINAL_TEXT>Branswell, Helen.</ORIGINAL_TEXT>
<TOKEN end_char="6464" id="token-70-0" morph="none" pos="word" start_char="6456">Branswell</TOKEN>
<TOKEN end_char="6465" id="token-70-1" morph="none" pos="punct" start_char="6465">,</TOKEN>
<TOKEN end_char="6471" id="token-70-2" morph="none" pos="word" start_char="6467">Helen</TOKEN>
<TOKEN end_char="6472" id="token-70-3" morph="none" pos="punct" start_char="6472">.</TOKEN>
</SEG>
<SEG end_char="6494" id="segment-71" start_char="6474">
<ORIGINAL_TEXT>"It’s been sequenced.</ORIGINAL_TEXT>
<TOKEN end_char="6474" id="token-71-0" morph="none" pos="punct" start_char="6474">"</TOKEN>
<TOKEN end_char="6478" id="token-71-1" morph="none" pos="word" start_char="6475">It’s</TOKEN>
<TOKEN end_char="6483" id="token-71-2" morph="none" pos="word" start_char="6480">been</TOKEN>
<TOKEN end_char="6493" id="token-71-3" morph="none" pos="word" start_char="6485">sequenced</TOKEN>
<TOKEN end_char="6494" id="token-71-4" morph="none" pos="punct" start_char="6494">.</TOKEN>
</SEG>
<SEG end_char="6522" id="segment-72" start_char="6496">
<ORIGINAL_TEXT>It’s spread across borders.</ORIGINAL_TEXT>
<TOKEN end_char="6499" id="token-72-0" morph="none" pos="word" start_char="6496">It’s</TOKEN>
<TOKEN end_char="6506" id="token-72-1" morph="none" pos="word" start_char="6501">spread</TOKEN>
<TOKEN end_char="6513" id="token-72-2" morph="none" pos="word" start_char="6508">across</TOKEN>
<TOKEN end_char="6521" id="token-72-3" morph="none" pos="word" start_char="6515">borders</TOKEN>
<TOKEN end_char="6522" id="token-72-4" morph="none" pos="punct" start_char="6522">.</TOKEN>
</SEG>
<SEG end_char="6573" id="segment-73" start_char="6524">
<ORIGINAL_TEXT>Now the new pneumonia-causing virus needs a name."</ORIGINAL_TEXT>
<TOKEN end_char="6526" id="token-73-0" morph="none" pos="word" start_char="6524">Now</TOKEN>
<TOKEN end_char="6530" id="token-73-1" morph="none" pos="word" start_char="6528">the</TOKEN>
<TOKEN end_char="6534" id="token-73-2" morph="none" pos="word" start_char="6532">new</TOKEN>
<TOKEN end_char="6552" id="token-73-3" morph="none" pos="unknown" start_char="6536">pneumonia-causing</TOKEN>
<TOKEN end_char="6558" id="token-73-4" morph="none" pos="word" start_char="6554">virus</TOKEN>
<TOKEN end_char="6564" id="token-73-5" morph="none" pos="word" start_char="6560">needs</TOKEN>
<TOKEN end_char="6566" id="token-73-6" morph="none" pos="word" start_char="6566">a</TOKEN>
<TOKEN end_char="6571" id="token-73-7" morph="none" pos="word" start_char="6568">name</TOKEN>
<TOKEN end_char="6573" id="token-73-8" morph="none" pos="punct" start_char="6572">."</TOKEN>
</SEG>
<SEG end_char="6579" id="segment-74" start_char="6575">
<ORIGINAL_TEXT>STAT.</ORIGINAL_TEXT>
<TOKEN end_char="6578" id="token-74-0" morph="none" pos="word" start_char="6575">STAT</TOKEN>
<TOKEN end_char="6579" id="token-74-1" morph="none" pos="punct" start_char="6579">.</TOKEN>
<TRANSLATED_TEXT>State.</TRANSLATED_TEXT><DETECTED_LANGUAGE>id</DETECTED_LANGUAGE></SEG>
<SEG end_char="6592" id="segment-75" start_char="6581">
<ORIGINAL_TEXT>23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="6582" id="token-75-0" morph="none" pos="word" start_char="6581">23</TOKEN>
<TOKEN end_char="6586" id="token-75-1" morph="none" pos="word" start_char="6584">Jan</TOKEN>
<TOKEN end_char="6591" id="token-75-2" morph="none" pos="word" start_char="6588">2020</TOKEN>
<TOKEN end_char="6592" id="token-75-3" morph="none" pos="punct" start_char="6592">.</TOKEN>
</SEG>
<SEG end_char="6631" id="segment-76" start_char="6595">
<ORIGINAL_TEXT>2019 Novel Coronavirus, Wuhan, China.</ORIGINAL_TEXT>
<TOKEN end_char="6598" id="token-76-0" morph="none" pos="word" start_char="6595">2019</TOKEN>
<TOKEN end_char="6604" id="token-76-1" morph="none" pos="word" start_char="6600">Novel</TOKEN>
<TOKEN end_char="6616" id="token-76-2" morph="none" pos="word" start_char="6606">Coronavirus</TOKEN>
<TOKEN end_char="6617" id="token-76-3" morph="none" pos="punct" start_char="6617">,</TOKEN>
<TOKEN end_char="6623" id="token-76-4" morph="none" pos="word" start_char="6619">Wuhan</TOKEN>
<TOKEN end_char="6624" id="token-76-5" morph="none" pos="punct" start_char="6624">,</TOKEN>
<TOKEN end_char="6630" id="token-76-6" morph="none" pos="word" start_char="6626">China</TOKEN>
<TOKEN end_char="6631" id="token-76-7" morph="none" pos="punct" start_char="6631">.</TOKEN>
</SEG>
<SEG end_char="6636" id="segment-77" start_char="6633">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN end_char="6635" id="token-77-0" morph="none" pos="word" start_char="6633">CDC</TOKEN>
<TOKEN end_char="6636" id="token-77-1" morph="none" pos="punct" start_char="6636">.</TOKEN>
<TRANSLATED_TEXT>- CDC.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="6658" id="segment-78" start_char="6638">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="6645" id="token-78-0" morph="none" pos="word" start_char="6638">Accessed</TOKEN>
<TOKEN end_char="6648" id="token-78-1" morph="none" pos="word" start_char="6647">23</TOKEN>
<TOKEN end_char="6652" id="token-78-2" morph="none" pos="word" start_char="6650">Jan</TOKEN>
<TOKEN end_char="6657" id="token-78-3" morph="none" pos="word" start_char="6654">2020</TOKEN>
<TOKEN end_char="6658" id="token-78-4" morph="none" pos="punct" start_char="6658">.</TOKEN>
</SEG>
<SEG end_char="6701" id="segment-79" start_char="6661">
<ORIGINAL_TEXT>Severe Acute Respiratory Syndrome (SARS).</ORIGINAL_TEXT>
<TOKEN end_char="6666" id="token-79-0" morph="none" pos="word" start_char="6661">Severe</TOKEN>
<TOKEN end_char="6672" id="token-79-1" morph="none" pos="word" start_char="6668">Acute</TOKEN>
<TOKEN end_char="6684" id="token-79-2" morph="none" pos="word" start_char="6674">Respiratory</TOKEN>
<TOKEN end_char="6693" id="token-79-3" morph="none" pos="word" start_char="6686">Syndrome</TOKEN>
<TOKEN end_char="6695" id="token-79-4" morph="none" pos="punct" start_char="6695">(</TOKEN>
<TOKEN end_char="6699" id="token-79-5" morph="none" pos="word" start_char="6696">SARS</TOKEN>
<TOKEN end_char="6701" id="token-79-6" morph="none" pos="punct" start_char="6700">).</TOKEN>
</SEG>
<SEG end_char="6706" id="segment-80" start_char="6703">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN end_char="6705" id="token-80-0" morph="none" pos="word" start_char="6703">CDC</TOKEN>
<TOKEN end_char="6706" id="token-80-1" morph="none" pos="punct" start_char="6706">.</TOKEN>
<TRANSLATED_TEXT>- CDC.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="6728" id="segment-81" start_char="6708">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="6715" id="token-81-0" morph="none" pos="word" start_char="6708">Accessed</TOKEN>
<TOKEN end_char="6718" id="token-81-1" morph="none" pos="word" start_char="6717">23</TOKEN>
<TOKEN end_char="6722" id="token-81-2" morph="none" pos="word" start_char="6720">Jan</TOKEN>
<TOKEN end_char="6727" id="token-81-3" morph="none" pos="word" start_char="6724">2020</TOKEN>
<TOKEN end_char="6728" id="token-81-4" morph="none" pos="punct" start_char="6728">.</TOKEN>
</SEG>
<SEG end_char="6742" id="segment-82" start_char="6731">
<ORIGINAL_TEXT>Coronavirus.</ORIGINAL_TEXT>
<TOKEN end_char="6741" id="token-82-0" morph="none" pos="word" start_char="6731">Coronavirus</TOKEN>
<TOKEN end_char="6742" id="token-82-1" morph="none" pos="punct" start_char="6742">.</TOKEN>
</SEG>
<SEG end_char="6747" id="segment-83" start_char="6744">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN end_char="6746" id="token-83-0" morph="none" pos="word" start_char="6744">CDC</TOKEN>
<TOKEN end_char="6747" id="token-83-1" morph="none" pos="punct" start_char="6747">.</TOKEN>
<TRANSLATED_TEXT>- CDC.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="6769" id="segment-84" start_char="6749">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="6756" id="token-84-0" morph="none" pos="word" start_char="6749">Accessed</TOKEN>
<TOKEN end_char="6759" id="token-84-1" morph="none" pos="word" start_char="6758">23</TOKEN>
<TOKEN end_char="6763" id="token-84-2" morph="none" pos="word" start_char="6761">Jan</TOKEN>
<TOKEN end_char="6768" id="token-84-3" morph="none" pos="word" start_char="6765">2020</TOKEN>
<TOKEN end_char="6769" id="token-84-4" morph="none" pos="punct" start_char="6769">.</TOKEN>
</SEG>
<SEG end_char="6804" id="segment-85" start_char="6772">
<ORIGINAL_TEXT>Coronavirus isolated from humans.</ORIGINAL_TEXT>
<TOKEN end_char="6782" id="token-85-0" morph="none" pos="word" start_char="6772">Coronavirus</TOKEN>
<TOKEN end_char="6791" id="token-85-1" morph="none" pos="word" start_char="6784">isolated</TOKEN>
<TOKEN end_char="6796" id="token-85-2" morph="none" pos="word" start_char="6793">from</TOKEN>
<TOKEN end_char="6803" id="token-85-3" morph="none" pos="word" start_char="6798">humans</TOKEN>
<TOKEN end_char="6804" id="token-85-4" morph="none" pos="punct" start_char="6804">.</TOKEN>
</SEG>
<SEG end_char="6821" id="segment-86" start_char="6806">
<ORIGINAL_TEXT>U.S. Patent, no.</ORIGINAL_TEXT>
<TOKEN end_char="6808" id="token-86-0" morph="none" pos="unknown" start_char="6806">U.S</TOKEN>
<TOKEN end_char="6809" id="token-86-1" morph="none" pos="punct" start_char="6809">.</TOKEN>
<TOKEN end_char="6816" id="token-86-2" morph="none" pos="word" start_char="6811">Patent</TOKEN>
<TOKEN end_char="6817" id="token-86-3" morph="none" pos="punct" start_char="6817">,</TOKEN>
<TOKEN end_char="6820" id="token-86-4" morph="none" pos="word" start_char="6819">no</TOKEN>
<TOKEN end_char="6821" id="token-86-5" morph="none" pos="punct" start_char="6821">.</TOKEN>
</SEG>
<SEG end_char="6832" id="segment-87" start_char="6823">
<ORIGINAL_TEXT>7220852B1.</ORIGINAL_TEXT>
<TOKEN end_char="6831" id="token-87-0" morph="none" pos="word" start_char="6823">7220852B1</TOKEN>
<TOKEN end_char="6832" id="token-87-1" morph="none" pos="punct" start_char="6832">.</TOKEN>
</SEG>
<SEG end_char="6848" id="segment-88" start_char="6835">
<ORIGINAL_TEXT>Bickerton, et.</ORIGINAL_TEXT>
<TOKEN end_char="6843" id="token-88-0" morph="none" pos="word" start_char="6835">Bickerton</TOKEN>
<TOKEN end_char="6844" id="token-88-1" morph="none" pos="punct" start_char="6844">,</TOKEN>
<TOKEN end_char="6847" id="token-88-2" morph="none" pos="word" start_char="6846">et</TOKEN>
<TOKEN end_char="6848" id="token-88-3" morph="none" pos="punct" start_char="6848">.</TOKEN>
</SEG>
<SEG end_char="6852" id="segment-89" start_char="6850">
<ORIGINAL_TEXT>al.</ORIGINAL_TEXT>
<TOKEN end_char="6851" id="token-89-0" morph="none" pos="word" start_char="6850">al</TOKEN>
<TOKEN end_char="6852" id="token-89-1" morph="none" pos="punct" start_char="6852">.</TOKEN>
<TRANSLATED_TEXT>Here.</TRANSLATED_TEXT><DETECTED_LANGUAGE>ca</DETECTED_LANGUAGE></SEG>
<SEG end_char="6869" id="segment-90" start_char="6854">
<ORIGINAL_TEXT>U.S. Patent, no.</ORIGINAL_TEXT>
<TOKEN end_char="6856" id="token-90-0" morph="none" pos="unknown" start_char="6854">U.S</TOKEN>
<TOKEN end_char="6857" id="token-90-1" morph="none" pos="punct" start_char="6857">.</TOKEN>
<TOKEN end_char="6864" id="token-90-2" morph="none" pos="word" start_char="6859">Patent</TOKEN>
<TOKEN end_char="6865" id="token-90-3" morph="none" pos="punct" start_char="6865">,</TOKEN>
<TOKEN end_char="6868" id="token-90-4" morph="none" pos="word" start_char="6867">no</TOKEN>
<TOKEN end_char="6869" id="token-90-5" morph="none" pos="punct" start_char="6869">.</TOKEN>
</SEG>
<SEG end_char="6879" id="segment-91" start_char="6871">
<ORIGINAL_TEXT>10130701.</ORIGINAL_TEXT>
<TOKEN end_char="6878" id="token-91-0" morph="none" pos="word" start_char="6871">10130701</TOKEN>
<TOKEN end_char="6879" id="token-91-1" morph="none" pos="punct" start_char="6879">.</TOKEN>
</SEG>
<SEG end_char="6885" id="segment-92" start_char="6881">
<ORIGINAL_TEXT>2018.</ORIGINAL_TEXT>
<TOKEN end_char="6884" id="token-92-0" morph="none" pos="word" start_char="6881">2018</TOKEN>
<TOKEN end_char="6885" id="token-92-1" morph="none" pos="punct" start_char="6885">.</TOKEN>
</SEG>
<SEG end_char="6904" id="segment-93" start_char="6888">
<ORIGINAL_TEXT>Frieman, Matthew.</ORIGINAL_TEXT>
<TOKEN end_char="6894" id="token-93-0" morph="none" pos="word" start_char="6888">Frieman</TOKEN>
<TOKEN end_char="6895" id="token-93-1" morph="none" pos="punct" start_char="6895">,</TOKEN>
<TOKEN end_char="6903" id="token-93-2" morph="none" pos="word" start_char="6897">Matthew</TOKEN>
<TOKEN end_char="6904" id="token-93-3" morph="none" pos="punct" start_char="6904">.</TOKEN>
</SEG>
<SEG end_char="6997" id="segment-94" start_char="6906">
<ORIGINAL_TEXT>Associate Professor, Microbiology and Immunology, University of Maryland School of Medicine.</ORIGINAL_TEXT>
<TOKEN end_char="6914" id="token-94-0" morph="none" pos="word" start_char="6906">Associate</TOKEN>
<TOKEN end_char="6924" id="token-94-1" morph="none" pos="word" start_char="6916">Professor</TOKEN>
<TOKEN end_char="6925" id="token-94-2" morph="none" pos="punct" start_char="6925">,</TOKEN>
<TOKEN end_char="6938" id="token-94-3" morph="none" pos="word" start_char="6927">Microbiology</TOKEN>
<TOKEN end_char="6942" id="token-94-4" morph="none" pos="word" start_char="6940">and</TOKEN>
<TOKEN end_char="6953" id="token-94-5" morph="none" pos="word" start_char="6944">Immunology</TOKEN>
<TOKEN end_char="6954" id="token-94-6" morph="none" pos="punct" start_char="6954">,</TOKEN>
<TOKEN end_char="6965" id="token-94-7" morph="none" pos="word" start_char="6956">University</TOKEN>
<TOKEN end_char="6968" id="token-94-8" morph="none" pos="word" start_char="6967">of</TOKEN>
<TOKEN end_char="6977" id="token-94-9" morph="none" pos="word" start_char="6970">Maryland</TOKEN>
<TOKEN end_char="6984" id="token-94-10" morph="none" pos="word" start_char="6979">School</TOKEN>
<TOKEN end_char="6987" id="token-94-11" morph="none" pos="word" start_char="6986">of</TOKEN>
<TOKEN end_char="6996" id="token-94-12" morph="none" pos="word" start_char="6989">Medicine</TOKEN>
<TOKEN end_char="6997" id="token-94-13" morph="none" pos="punct" start_char="6997">.</TOKEN>
</SEG>
<SEG end_char="7026" id="segment-95" start_char="6999">
<ORIGINAL_TEXT>Email sent to FactCheck.org.</ORIGINAL_TEXT>
<TOKEN end_char="7003" id="token-95-0" morph="none" pos="word" start_char="6999">Email</TOKEN>
<TOKEN end_char="7008" id="token-95-1" morph="none" pos="word" start_char="7005">sent</TOKEN>
<TOKEN end_char="7011" id="token-95-2" morph="none" pos="word" start_char="7010">to</TOKEN>
<TOKEN end_char="7025" id="token-95-3" morph="none" pos="unknown" start_char="7013">FactCheck.org</TOKEN>
<TOKEN end_char="7026" id="token-95-4" morph="none" pos="punct" start_char="7026">.</TOKEN>
</SEG>
<SEG end_char="7039" id="segment-96" start_char="7028">
<ORIGINAL_TEXT>22 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7029" id="token-96-0" morph="none" pos="word" start_char="7028">22</TOKEN>
<TOKEN end_char="7033" id="token-96-1" morph="none" pos="word" start_char="7031">Jan</TOKEN>
<TOKEN end_char="7038" id="token-96-2" morph="none" pos="word" start_char="7035">2020</TOKEN>
<TOKEN end_char="7039" id="token-96-3" morph="none" pos="punct" start_char="7039">.</TOKEN>
</SEG>
<SEG end_char="7080" id="segment-97" start_char="7042">
<ORIGINAL_TEXT>"Scientists race to patent SARS virus."</ORIGINAL_TEXT>
<TOKEN end_char="7042" id="token-97-0" morph="none" pos="punct" start_char="7042">"</TOKEN>
<TOKEN end_char="7052" id="token-97-1" morph="none" pos="word" start_char="7043">Scientists</TOKEN>
<TOKEN end_char="7057" id="token-97-2" morph="none" pos="word" start_char="7054">race</TOKEN>
<TOKEN end_char="7060" id="token-97-3" morph="none" pos="word" start_char="7059">to</TOKEN>
<TOKEN end_char="7067" id="token-97-4" morph="none" pos="word" start_char="7062">patent</TOKEN>
<TOKEN end_char="7072" id="token-97-5" morph="none" pos="word" start_char="7069">SARS</TOKEN>
<TOKEN end_char="7078" id="token-97-6" morph="none" pos="word" start_char="7074">virus</TOKEN>
<TOKEN end_char="7080" id="token-97-7" morph="none" pos="punct" start_char="7079">."</TOKEN>
</SEG>
<SEG end_char="7098" id="segment-98" start_char="7082">
<ORIGINAL_TEXT>Associated Press.</ORIGINAL_TEXT>
<TOKEN end_char="7091" id="token-98-0" morph="none" pos="word" start_char="7082">Associated</TOKEN>
<TOKEN end_char="7097" id="token-98-1" morph="none" pos="word" start_char="7093">Press</TOKEN>
<TOKEN end_char="7098" id="token-98-2" morph="none" pos="punct" start_char="7098">.</TOKEN>
</SEG>
<SEG end_char="7118" id="segment-99" start_char="7100">
<ORIGINAL_TEXT>Updated 4 Nov 2003.</ORIGINAL_TEXT>
<TOKEN end_char="7106" id="token-99-0" morph="none" pos="word" start_char="7100">Updated</TOKEN>
<TOKEN end_char="7108" id="token-99-1" morph="none" pos="word" start_char="7108">4</TOKEN>
<TOKEN end_char="7112" id="token-99-2" morph="none" pos="word" start_char="7110">Nov</TOKEN>
<TOKEN end_char="7117" id="token-99-3" morph="none" pos="word" start_char="7114">2003</TOKEN>
<TOKEN end_char="7118" id="token-99-4" morph="none" pos="punct" start_char="7118">.</TOKEN>
</SEG>
<SEG end_char="7134" id="segment-100" start_char="7121">
<ORIGINAL_TEXT>Edgar, Harold.</ORIGINAL_TEXT>
<TOKEN end_char="7125" id="token-100-0" morph="none" pos="word" start_char="7121">Edgar</TOKEN>
<TOKEN end_char="7126" id="token-100-1" morph="none" pos="punct" start_char="7126">,</TOKEN>
<TOKEN end_char="7133" id="token-100-2" morph="none" pos="word" start_char="7128">Harold</TOKEN>
<TOKEN end_char="7134" id="token-100-3" morph="none" pos="punct" start_char="7134">.</TOKEN>
</SEG>
<SEG end_char="7220" id="segment-101" start_char="7136">
<ORIGINAL_TEXT>Julius Silver Professor Emeritus of Law, Science and Technology, Columbia Law School.</ORIGINAL_TEXT>
<TOKEN end_char="7141" id="token-101-0" morph="none" pos="word" start_char="7136">Julius</TOKEN>
<TOKEN end_char="7148" id="token-101-1" morph="none" pos="word" start_char="7143">Silver</TOKEN>
<TOKEN end_char="7158" id="token-101-2" morph="none" pos="word" start_char="7150">Professor</TOKEN>
<TOKEN end_char="7167" id="token-101-3" morph="none" pos="word" start_char="7160">Emeritus</TOKEN>
<TOKEN end_char="7170" id="token-101-4" morph="none" pos="word" start_char="7169">of</TOKEN>
<TOKEN end_char="7174" id="token-101-5" morph="none" pos="word" start_char="7172">Law</TOKEN>
<TOKEN end_char="7175" id="token-101-6" morph="none" pos="punct" start_char="7175">,</TOKEN>
<TOKEN end_char="7183" id="token-101-7" morph="none" pos="word" start_char="7177">Science</TOKEN>
<TOKEN end_char="7187" id="token-101-8" morph="none" pos="word" start_char="7185">and</TOKEN>
<TOKEN end_char="7198" id="token-101-9" morph="none" pos="word" start_char="7189">Technology</TOKEN>
<TOKEN end_char="7199" id="token-101-10" morph="none" pos="punct" start_char="7199">,</TOKEN>
<TOKEN end_char="7208" id="token-101-11" morph="none" pos="word" start_char="7201">Columbia</TOKEN>
<TOKEN end_char="7212" id="token-101-12" morph="none" pos="word" start_char="7210">Law</TOKEN>
<TOKEN end_char="7219" id="token-101-13" morph="none" pos="word" start_char="7214">School</TOKEN>
<TOKEN end_char="7220" id="token-101-14" morph="none" pos="punct" start_char="7220">.</TOKEN>
</SEG>
<SEG end_char="7250" id="segment-102" start_char="7222">
<ORIGINAL_TEXT>Interview with FactCheck.org.</ORIGINAL_TEXT>
<TOKEN end_char="7230" id="token-102-0" morph="none" pos="word" start_char="7222">Interview</TOKEN>
<TOKEN end_char="7235" id="token-102-1" morph="none" pos="word" start_char="7232">with</TOKEN>
<TOKEN end_char="7249" id="token-102-2" morph="none" pos="unknown" start_char="7237">FactCheck.org</TOKEN>
<TOKEN end_char="7250" id="token-102-3" morph="none" pos="punct" start_char="7250">.</TOKEN>
</SEG>
<SEG end_char="7263" id="segment-103" start_char="7252">
<ORIGINAL_TEXT>23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7253" id="token-103-0" morph="none" pos="word" start_char="7252">23</TOKEN>
<TOKEN end_char="7257" id="token-103-1" morph="none" pos="word" start_char="7255">Jan</TOKEN>
<TOKEN end_char="7262" id="token-103-2" morph="none" pos="word" start_char="7259">2020</TOKEN>
<TOKEN end_char="7263" id="token-103-3" morph="none" pos="punct" start_char="7263">.</TOKEN>
</SEG>
<SEG end_char="7299" id="segment-104" start_char="7266">
<ORIGINAL_TEXT>Novel Coronavirus in Wuhan, China.</ORIGINAL_TEXT>
<TOKEN end_char="7270" id="token-104-0" morph="none" pos="word" start_char="7266">Novel</TOKEN>
<TOKEN end_char="7282" id="token-104-1" morph="none" pos="word" start_char="7272">Coronavirus</TOKEN>
<TOKEN end_char="7285" id="token-104-2" morph="none" pos="word" start_char="7284">in</TOKEN>
<TOKEN end_char="7291" id="token-104-3" morph="none" pos="word" start_char="7287">Wuhan</TOKEN>
<TOKEN end_char="7292" id="token-104-4" morph="none" pos="punct" start_char="7292">,</TOKEN>
<TOKEN end_char="7298" id="token-104-5" morph="none" pos="word" start_char="7294">China</TOKEN>
<TOKEN end_char="7299" id="token-104-6" morph="none" pos="punct" start_char="7299">.</TOKEN>
</SEG>
<SEG end_char="7304" id="segment-105" start_char="7301">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN end_char="7303" id="token-105-0" morph="none" pos="word" start_char="7301">CDC</TOKEN>
<TOKEN end_char="7304" id="token-105-1" morph="none" pos="punct" start_char="7304">.</TOKEN>
<TRANSLATED_TEXT>- CDC.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="7326" id="segment-106" start_char="7306">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7313" id="token-106-0" morph="none" pos="word" start_char="7306">Accessed</TOKEN>
<TOKEN end_char="7316" id="token-106-1" morph="none" pos="word" start_char="7315">23</TOKEN>
<TOKEN end_char="7320" id="token-106-2" morph="none" pos="word" start_char="7318">Jan</TOKEN>
<TOKEN end_char="7325" id="token-106-3" morph="none" pos="word" start_char="7322">2020</TOKEN>
<TOKEN end_char="7326" id="token-106-4" morph="none" pos="punct" start_char="7326">.</TOKEN>
</SEG>
<SEG end_char="7357" id="segment-107" start_char="7329">
<ORIGINAL_TEXT>Davies, Will and Stephen Tan.</ORIGINAL_TEXT>
<TOKEN end_char="7334" id="token-107-0" morph="none" pos="word" start_char="7329">Davies</TOKEN>
<TOKEN end_char="7335" id="token-107-1" morph="none" pos="punct" start_char="7335">,</TOKEN>
<TOKEN end_char="7340" id="token-107-2" morph="none" pos="word" start_char="7337">Will</TOKEN>
<TOKEN end_char="7344" id="token-107-3" morph="none" pos="word" start_char="7342">and</TOKEN>
<TOKEN end_char="7352" id="token-107-4" morph="none" pos="word" start_char="7346">Stephen</TOKEN>
<TOKEN end_char="7356" id="token-107-5" morph="none" pos="word" start_char="7354">Tan</TOKEN>
<TOKEN end_char="7357" id="token-107-6" morph="none" pos="punct" start_char="7357">.</TOKEN>
</SEG>
<SEG end_char="7417" id="segment-108" start_char="7359">
<ORIGINAL_TEXT>"The Age, Sex and Symptoms of All the Coronavirus Victims."</ORIGINAL_TEXT>
<TOKEN end_char="7359" id="token-108-0" morph="none" pos="punct" start_char="7359">"</TOKEN>
<TOKEN end_char="7362" id="token-108-1" morph="none" pos="word" start_char="7360">The</TOKEN>
<TOKEN end_char="7366" id="token-108-2" morph="none" pos="word" start_char="7364">Age</TOKEN>
<TOKEN end_char="7367" id="token-108-3" morph="none" pos="punct" start_char="7367">,</TOKEN>
<TOKEN end_char="7371" id="token-108-4" morph="none" pos="word" start_char="7369">Sex</TOKEN>
<TOKEN end_char="7375" id="token-108-5" morph="none" pos="word" start_char="7373">and</TOKEN>
<TOKEN end_char="7384" id="token-108-6" morph="none" pos="word" start_char="7377">Symptoms</TOKEN>
<TOKEN end_char="7387" id="token-108-7" morph="none" pos="word" start_char="7386">of</TOKEN>
<TOKEN end_char="7391" id="token-108-8" morph="none" pos="word" start_char="7389">All</TOKEN>
<TOKEN end_char="7395" id="token-108-9" morph="none" pos="word" start_char="7393">the</TOKEN>
<TOKEN end_char="7407" id="token-108-10" morph="none" pos="word" start_char="7397">Coronavirus</TOKEN>
<TOKEN end_char="7415" id="token-108-11" morph="none" pos="word" start_char="7409">Victims</TOKEN>
<TOKEN end_char="7417" id="token-108-12" morph="none" pos="punct" start_char="7416">."</TOKEN>
</SEG>
<SEG end_char="7428" id="segment-109" start_char="7419">
<ORIGINAL_TEXT>Bloomberg.</ORIGINAL_TEXT>
<TOKEN end_char="7427" id="token-109-0" morph="none" pos="word" start_char="7419">Bloomberg</TOKEN>
<TOKEN end_char="7428" id="token-109-1" morph="none" pos="punct" start_char="7428">.</TOKEN>
<TRANSLATED_TEXT>Bloomberg!</TRANSLATED_TEXT><DETECTED_LANGUAGE>af</DETECTED_LANGUAGE></SEG>
<SEG end_char="7462" id="segment-110" start_char="7430">
<ORIGINAL_TEXT>22 Jan 2020, updated 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7431" id="token-110-0" morph="none" pos="word" start_char="7430">22</TOKEN>
<TOKEN end_char="7435" id="token-110-1" morph="none" pos="word" start_char="7433">Jan</TOKEN>
<TOKEN end_char="7440" id="token-110-2" morph="none" pos="word" start_char="7437">2020</TOKEN>
<TOKEN end_char="7441" id="token-110-3" morph="none" pos="punct" start_char="7441">,</TOKEN>
<TOKEN end_char="7449" id="token-110-4" morph="none" pos="word" start_char="7443">updated</TOKEN>
<TOKEN end_char="7452" id="token-110-5" morph="none" pos="word" start_char="7451">23</TOKEN>
<TOKEN end_char="7456" id="token-110-6" morph="none" pos="word" start_char="7454">Jan</TOKEN>
<TOKEN end_char="7461" id="token-110-7" morph="none" pos="word" start_char="7458">2020</TOKEN>
<TOKEN end_char="7462" id="token-110-8" morph="none" pos="punct" start_char="7462">.</TOKEN>
<TRANSLATED_TEXT>22 Jan 2020, bijgewerkt 23 Jan 2020.</TRANSLATED_TEXT><DETECTED_LANGUAGE>id</DETECTED_LANGUAGE></SEG>
<SEG end_char="7477" id="segment-111" start_char="7465">
<ORIGINAL_TEXT>Taylor, Adam.</ORIGINAL_TEXT>
<TOKEN end_char="7470" id="token-111-0" morph="none" pos="word" start_char="7465">Taylor</TOKEN>
<TOKEN end_char="7471" id="token-111-1" morph="none" pos="punct" start_char="7471">,</TOKEN>
<TOKEN end_char="7476" id="token-111-2" morph="none" pos="word" start_char="7473">Adam</TOKEN>
<TOKEN end_char="7477" id="token-111-3" morph="none" pos="punct" start_char="7477">.</TOKEN>
</SEG>
<SEG end_char="7547" id="segment-112" start_char="7479">
<ORIGINAL_TEXT>"Wuhan: The Chinese mega-city at the center of coronavirus outbreak."</ORIGINAL_TEXT>
<TOKEN end_char="7479" id="token-112-0" morph="none" pos="punct" start_char="7479">"</TOKEN>
<TOKEN end_char="7484" id="token-112-1" morph="none" pos="word" start_char="7480">Wuhan</TOKEN>
<TOKEN end_char="7485" id="token-112-2" morph="none" pos="punct" start_char="7485">:</TOKEN>
<TOKEN end_char="7489" id="token-112-3" morph="none" pos="word" start_char="7487">The</TOKEN>
<TOKEN end_char="7497" id="token-112-4" morph="none" pos="word" start_char="7491">Chinese</TOKEN>
<TOKEN end_char="7507" id="token-112-5" morph="none" pos="unknown" start_char="7499">mega-city</TOKEN>
<TOKEN end_char="7510" id="token-112-6" morph="none" pos="word" start_char="7509">at</TOKEN>
<TOKEN end_char="7514" id="token-112-7" morph="none" pos="word" start_char="7512">the</TOKEN>
<TOKEN end_char="7521" id="token-112-8" morph="none" pos="word" start_char="7516">center</TOKEN>
<TOKEN end_char="7524" id="token-112-9" morph="none" pos="word" start_char="7523">of</TOKEN>
<TOKEN end_char="7536" id="token-112-10" morph="none" pos="word" start_char="7526">coronavirus</TOKEN>
<TOKEN end_char="7545" id="token-112-11" morph="none" pos="word" start_char="7538">outbreak</TOKEN>
<TOKEN end_char="7547" id="token-112-12" morph="none" pos="punct" start_char="7546">."</TOKEN>
</SEG>
<SEG end_char="7564" id="segment-113" start_char="7549">
<ORIGINAL_TEXT>Washington Post.</ORIGINAL_TEXT>
<TOKEN end_char="7558" id="token-113-0" morph="none" pos="word" start_char="7549">Washington</TOKEN>
<TOKEN end_char="7563" id="token-113-1" morph="none" pos="word" start_char="7560">Post</TOKEN>
<TOKEN end_char="7564" id="token-113-2" morph="none" pos="punct" start_char="7564">.</TOKEN>
</SEG>
<SEG end_char="7577" id="segment-114" start_char="7566">
<ORIGINAL_TEXT>23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7567" id="token-114-0" morph="none" pos="word" start_char="7566">23</TOKEN>
<TOKEN end_char="7571" id="token-114-1" morph="none" pos="word" start_char="7569">Jan</TOKEN>
<TOKEN end_char="7576" id="token-114-2" morph="none" pos="word" start_char="7573">2020</TOKEN>
<TOKEN end_char="7577" id="token-114-3" morph="none" pos="punct" start_char="7577">.</TOKEN>
</SEG>
<SEG end_char="7632" id="segment-115" start_char="7580">
<ORIGINAL_TEXT>Jackwood, Mark W. "Infectious Bronchitis in Poultry."</ORIGINAL_TEXT>
<TOKEN end_char="7587" id="token-115-0" morph="none" pos="word" start_char="7580">Jackwood</TOKEN>
<TOKEN end_char="7588" id="token-115-1" morph="none" pos="punct" start_char="7588">,</TOKEN>
<TOKEN end_char="7593" id="token-115-2" morph="none" pos="word" start_char="7590">Mark</TOKEN>
<TOKEN end_char="7595" id="token-115-3" morph="none" pos="word" start_char="7595">W</TOKEN>
<TOKEN end_char="7596" id="token-115-4" morph="none" pos="punct" start_char="7596">.</TOKEN>
<TOKEN end_char="7598" id="token-115-5" morph="none" pos="punct" start_char="7598">"</TOKEN>
<TOKEN end_char="7608" id="token-115-6" morph="none" pos="word" start_char="7599">Infectious</TOKEN>
<TOKEN end_char="7619" id="token-115-7" morph="none" pos="word" start_char="7610">Bronchitis</TOKEN>
<TOKEN end_char="7622" id="token-115-8" morph="none" pos="word" start_char="7621">in</TOKEN>
<TOKEN end_char="7630" id="token-115-9" morph="none" pos="word" start_char="7624">Poultry</TOKEN>
<TOKEN end_char="7632" id="token-115-10" morph="none" pos="punct" start_char="7631">."</TOKEN>
</SEG>
<SEG end_char="7657" id="segment-116" start_char="7634">
<ORIGINAL_TEXT>Merck Veterinary Manual.</ORIGINAL_TEXT>
<TOKEN end_char="7638" id="token-116-0" morph="none" pos="word" start_char="7634">Merck</TOKEN>
<TOKEN end_char="7649" id="token-116-1" morph="none" pos="word" start_char="7640">Veterinary</TOKEN>
<TOKEN end_char="7656" id="token-116-2" morph="none" pos="word" start_char="7651">Manual</TOKEN>
<TOKEN end_char="7657" id="token-116-3" morph="none" pos="punct" start_char="7657">.</TOKEN>
</SEG>
<SEG end_char="7679" id="segment-117" start_char="7659">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7666" id="token-117-0" morph="none" pos="word" start_char="7659">Accessed</TOKEN>
<TOKEN end_char="7669" id="token-117-1" morph="none" pos="word" start_char="7668">23</TOKEN>
<TOKEN end_char="7673" id="token-117-2" morph="none" pos="word" start_char="7671">Jan</TOKEN>
<TOKEN end_char="7678" id="token-117-3" morph="none" pos="word" start_char="7675">2020</TOKEN>
<TOKEN end_char="7679" id="token-117-4" morph="none" pos="punct" start_char="7679">.</TOKEN>
</SEG>
<SEG end_char="7722" id="segment-118" start_char="7682">
<ORIGINAL_TEXT>SARS (Severe Acute Respiratory Syndrome).</ORIGINAL_TEXT>
<TOKEN end_char="7685" id="token-118-0" morph="none" pos="word" start_char="7682">SARS</TOKEN>
<TOKEN end_char="7687" id="token-118-1" morph="none" pos="punct" start_char="7687">(</TOKEN>
<TOKEN end_char="7693" id="token-118-2" morph="none" pos="word" start_char="7688">Severe</TOKEN>
<TOKEN end_char="7699" id="token-118-3" morph="none" pos="word" start_char="7695">Acute</TOKEN>
<TOKEN end_char="7711" id="token-118-4" morph="none" pos="word" start_char="7701">Respiratory</TOKEN>
<TOKEN end_char="7720" id="token-118-5" morph="none" pos="word" start_char="7713">Syndrome</TOKEN>
<TOKEN end_char="7722" id="token-118-6" morph="none" pos="punct" start_char="7721">).</TOKEN>
</SEG>
<SEG end_char="7749" id="segment-119" start_char="7724">
<ORIGINAL_TEXT>World Health Organization.</ORIGINAL_TEXT>
<TOKEN end_char="7728" id="token-119-0" morph="none" pos="word" start_char="7724">World</TOKEN>
<TOKEN end_char="7735" id="token-119-1" morph="none" pos="word" start_char="7730">Health</TOKEN>
<TOKEN end_char="7748" id="token-119-2" morph="none" pos="word" start_char="7737">Organization</TOKEN>
<TOKEN end_char="7749" id="token-119-3" morph="none" pos="punct" start_char="7749">.</TOKEN>
</SEG>
<SEG end_char="7771" id="segment-120" start_char="7751">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7758" id="token-120-0" morph="none" pos="word" start_char="7751">Accessed</TOKEN>
<TOKEN end_char="7761" id="token-120-1" morph="none" pos="word" start_char="7760">23</TOKEN>
<TOKEN end_char="7765" id="token-120-2" morph="none" pos="word" start_char="7763">Jan</TOKEN>
<TOKEN end_char="7770" id="token-120-3" morph="none" pos="word" start_char="7767">2020</TOKEN>
<TOKEN end_char="7771" id="token-120-4" morph="none" pos="punct" start_char="7771">.</TOKEN>
</SEG>
<SEG end_char="7803" id="segment-121" start_char="7774">
<ORIGINAL_TEXT>Sample, Ian and John Gittings.</ORIGINAL_TEXT>
<TOKEN end_char="7779" id="token-121-0" morph="none" pos="word" start_char="7774">Sample</TOKEN>
<TOKEN end_char="7780" id="token-121-1" morph="none" pos="punct" start_char="7780">,</TOKEN>
<TOKEN end_char="7784" id="token-121-2" morph="none" pos="word" start_char="7782">Ian</TOKEN>
<TOKEN end_char="7788" id="token-121-3" morph="none" pos="word" start_char="7786">and</TOKEN>
<TOKEN end_char="7793" id="token-121-4" morph="none" pos="word" start_char="7790">John</TOKEN>
<TOKEN end_char="7802" id="token-121-5" morph="none" pos="word" start_char="7795">Gittings</TOKEN>
<TOKEN end_char="7803" id="token-121-6" morph="none" pos="punct" start_char="7803">.</TOKEN>
</SEG>
<SEG end_char="7870" id="segment-122" start_char="7805">
<ORIGINAL_TEXT>"In China the civet cat is a delicacy – and may have caused Sars."</ORIGINAL_TEXT>
<TOKEN end_char="7805" id="token-122-0" morph="none" pos="punct" start_char="7805">"</TOKEN>
<TOKEN end_char="7807" id="token-122-1" morph="none" pos="word" start_char="7806">In</TOKEN>
<TOKEN end_char="7813" id="token-122-2" morph="none" pos="word" start_char="7809">China</TOKEN>
<TOKEN end_char="7817" id="token-122-3" morph="none" pos="word" start_char="7815">the</TOKEN>
<TOKEN end_char="7823" id="token-122-4" morph="none" pos="word" start_char="7819">civet</TOKEN>
<TOKEN end_char="7827" id="token-122-5" morph="none" pos="word" start_char="7825">cat</TOKEN>
<TOKEN end_char="7830" id="token-122-6" morph="none" pos="word" start_char="7829">is</TOKEN>
<TOKEN end_char="7832" id="token-122-7" morph="none" pos="word" start_char="7832">a</TOKEN>
<TOKEN end_char="7841" id="token-122-8" morph="none" pos="word" start_char="7834">delicacy</TOKEN>
<TOKEN end_char="7843" id="token-122-9" morph="none" pos="punct" start_char="7843">–</TOKEN>
<TOKEN end_char="7847" id="token-122-10" morph="none" pos="word" start_char="7845">and</TOKEN>
<TOKEN end_char="7851" id="token-122-11" morph="none" pos="word" start_char="7849">may</TOKEN>
<TOKEN end_char="7856" id="token-122-12" morph="none" pos="word" start_char="7853">have</TOKEN>
<TOKEN end_char="7863" id="token-122-13" morph="none" pos="word" start_char="7858">caused</TOKEN>
<TOKEN end_char="7868" id="token-122-14" morph="none" pos="word" start_char="7865">Sars</TOKEN>
<TOKEN end_char="7870" id="token-122-15" morph="none" pos="punct" start_char="7869">."</TOKEN>
</SEG>
<SEG end_char="7884" id="segment-123" start_char="7872">
<ORIGINAL_TEXT>The Guardian.</ORIGINAL_TEXT>
<TOKEN end_char="7874" id="token-123-0" morph="none" pos="word" start_char="7872">The</TOKEN>
<TOKEN end_char="7883" id="token-123-1" morph="none" pos="word" start_char="7876">Guardian</TOKEN>
<TOKEN end_char="7884" id="token-123-2" morph="none" pos="punct" start_char="7884">.</TOKEN>
</SEG>
<SEG end_char="7897" id="segment-124" start_char="7886">
<ORIGINAL_TEXT>23 May 2003.</ORIGINAL_TEXT>
<TOKEN end_char="7887" id="token-124-0" morph="none" pos="word" start_char="7886">23</TOKEN>
<TOKEN end_char="7891" id="token-124-1" morph="none" pos="word" start_char="7889">May</TOKEN>
<TOKEN end_char="7896" id="token-124-2" morph="none" pos="word" start_char="7893">2003</TOKEN>
<TOKEN end_char="7897" id="token-124-3" morph="none" pos="punct" start_char="7897">.</TOKEN>
<TRANSLATED_TEXT>23 de mayo de 2003..............</TRANSLATED_TEXT><DETECTED_LANGUAGE>tl</DETECTED_LANGUAGE></SEG>
<SEG end_char="7939" id="segment-125" start_char="7900">
<ORIGINAL_TEXT>Middle East Respiratory Syndrome (MERS).</ORIGINAL_TEXT>
<TOKEN end_char="7905" id="token-125-0" morph="none" pos="word" start_char="7900">Middle</TOKEN>
<TOKEN end_char="7910" id="token-125-1" morph="none" pos="word" start_char="7907">East</TOKEN>
<TOKEN end_char="7922" id="token-125-2" morph="none" pos="word" start_char="7912">Respiratory</TOKEN>
<TOKEN end_char="7931" id="token-125-3" morph="none" pos="word" start_char="7924">Syndrome</TOKEN>
<TOKEN end_char="7933" id="token-125-4" morph="none" pos="punct" start_char="7933">(</TOKEN>
<TOKEN end_char="7937" id="token-125-5" morph="none" pos="word" start_char="7934">MERS</TOKEN>
<TOKEN end_char="7939" id="token-125-6" morph="none" pos="punct" start_char="7938">).</TOKEN>
</SEG>
<SEG end_char="7944" id="segment-126" start_char="7941">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN end_char="7943" id="token-126-0" morph="none" pos="word" start_char="7941">CDC</TOKEN>
<TOKEN end_char="7944" id="token-126-1" morph="none" pos="punct" start_char="7944">.</TOKEN>
<TRANSLATED_TEXT>- CDC.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="7966" id="segment-127" start_char="7946">
<ORIGINAL_TEXT>Accessed 23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="7953" id="token-127-0" morph="none" pos="word" start_char="7946">Accessed</TOKEN>
<TOKEN end_char="7956" id="token-127-1" morph="none" pos="word" start_char="7955">23</TOKEN>
<TOKEN end_char="7960" id="token-127-2" morph="none" pos="word" start_char="7958">Jan</TOKEN>
<TOKEN end_char="7965" id="token-127-3" morph="none" pos="word" start_char="7962">2020</TOKEN>
<TOKEN end_char="7966" id="token-127-4" morph="none" pos="punct" start_char="7966">.</TOKEN>
</SEG>
<SEG end_char="8054" id="segment-128" start_char="7969">
<ORIGINAL_TEXT>Frequently asked questions on Middle East respiratory syndrome coronavirus (MERS‐CoV).</ORIGINAL_TEXT>
<TOKEN end_char="7978" id="token-128-0" morph="none" pos="word" start_char="7969">Frequently</TOKEN>
<TOKEN end_char="7984" id="token-128-1" morph="none" pos="word" start_char="7980">asked</TOKEN>
<TOKEN end_char="7994" id="token-128-2" morph="none" pos="word" start_char="7986">questions</TOKEN>
<TOKEN end_char="7997" id="token-128-3" morph="none" pos="word" start_char="7996">on</TOKEN>
<TOKEN end_char="8004" id="token-128-4" morph="none" pos="word" start_char="7999">Middle</TOKEN>
<TOKEN end_char="8009" id="token-128-5" morph="none" pos="word" start_char="8006">East</TOKEN>
<TOKEN end_char="8021" id="token-128-6" morph="none" pos="word" start_char="8011">respiratory</TOKEN>
<TOKEN end_char="8030" id="token-128-7" morph="none" pos="word" start_char="8023">syndrome</TOKEN>
<TOKEN end_char="8042" id="token-128-8" morph="none" pos="word" start_char="8032">coronavirus</TOKEN>
<TOKEN end_char="8044" id="token-128-9" morph="none" pos="punct" start_char="8044">(</TOKEN>
<TOKEN end_char="8052" id="token-128-10" morph="none" pos="unknown" start_char="8045">MERS‐CoV</TOKEN>
<TOKEN end_char="8054" id="token-128-11" morph="none" pos="punct" start_char="8053">).</TOKEN>
</SEG>
<SEG end_char="8081" id="segment-129" start_char="8056">
<ORIGINAL_TEXT>World Health Organization.</ORIGINAL_TEXT>
<TOKEN end_char="8060" id="token-129-0" morph="none" pos="word" start_char="8056">World</TOKEN>
<TOKEN end_char="8067" id="token-129-1" morph="none" pos="word" start_char="8062">Health</TOKEN>
<TOKEN end_char="8080" id="token-129-2" morph="none" pos="word" start_char="8069">Organization</TOKEN>
<TOKEN end_char="8081" id="token-129-3" morph="none" pos="punct" start_char="8081">.</TOKEN>
</SEG>
<SEG end_char="8102" id="segment-130" start_char="8083">
<ORIGINAL_TEXT>Updated 21 Jan 2019.</ORIGINAL_TEXT>
<TOKEN end_char="8089" id="token-130-0" morph="none" pos="word" start_char="8083">Updated</TOKEN>
<TOKEN end_char="8092" id="token-130-1" morph="none" pos="word" start_char="8091">21</TOKEN>
<TOKEN end_char="8096" id="token-130-2" morph="none" pos="word" start_char="8094">Jan</TOKEN>
<TOKEN end_char="8101" id="token-130-3" morph="none" pos="word" start_char="8098">2019</TOKEN>
<TOKEN end_char="8102" id="token-130-4" morph="none" pos="punct" start_char="8102">.</TOKEN>
</SEG>
<SEG end_char="8160" id="segment-131" start_char="8105">
<ORIGINAL_TEXT>Middle East respiratory syndrome coronavirus (MERS-CoV).</ORIGINAL_TEXT>
<TOKEN end_char="8110" id="token-131-0" morph="none" pos="word" start_char="8105">Middle</TOKEN>
<TOKEN end_char="8115" id="token-131-1" morph="none" pos="word" start_char="8112">East</TOKEN>
<TOKEN end_char="8127" id="token-131-2" morph="none" pos="word" start_char="8117">respiratory</TOKEN>
<TOKEN end_char="8136" id="token-131-3" morph="none" pos="word" start_char="8129">syndrome</TOKEN>
<TOKEN end_char="8148" id="token-131-4" morph="none" pos="word" start_char="8138">coronavirus</TOKEN>
<TOKEN end_char="8150" id="token-131-5" morph="none" pos="punct" start_char="8150">(</TOKEN>
<TOKEN end_char="8158" id="token-131-6" morph="none" pos="unknown" start_char="8151">MERS-CoV</TOKEN>
<TOKEN end_char="8160" id="token-131-7" morph="none" pos="punct" start_char="8159">).</TOKEN>
</SEG>
<SEG end_char="8187" id="segment-132" start_char="8162">
<ORIGINAL_TEXT>World Health Organization.</ORIGINAL_TEXT>
<TOKEN end_char="8166" id="token-132-0" morph="none" pos="word" start_char="8162">World</TOKEN>
<TOKEN end_char="8173" id="token-132-1" morph="none" pos="word" start_char="8168">Health</TOKEN>
<TOKEN end_char="8186" id="token-132-2" morph="none" pos="word" start_char="8175">Organization</TOKEN>
<TOKEN end_char="8187" id="token-132-3" morph="none" pos="punct" start_char="8187">.</TOKEN>
</SEG>
<SEG end_char="8200" id="segment-133" start_char="8189">
<ORIGINAL_TEXT>11 Mar 2019.</ORIGINAL_TEXT>
<TOKEN end_char="8190" id="token-133-0" morph="none" pos="word" start_char="8189">11</TOKEN>
<TOKEN end_char="8194" id="token-133-1" morph="none" pos="word" start_char="8192">Mar</TOKEN>
<TOKEN end_char="8199" id="token-133-2" morph="none" pos="word" start_char="8196">2019</TOKEN>
<TOKEN end_char="8200" id="token-133-3" morph="none" pos="punct" start_char="8200">.</TOKEN>
</SEG>
<SEG end_char="8330" id="segment-134" start_char="8203">
<ORIGINAL_TEXT>"Moderna Announces Funding Award from CEPI to Accelerate Development of Messenger RNA (mRNA) Vaccine Against Novel Coronavirus."</ORIGINAL_TEXT>
<TOKEN end_char="8203" id="token-134-0" morph="none" pos="punct" start_char="8203">"</TOKEN>
<TOKEN end_char="8210" id="token-134-1" morph="none" pos="word" start_char="8204">Moderna</TOKEN>
<TOKEN end_char="8220" id="token-134-2" morph="none" pos="word" start_char="8212">Announces</TOKEN>
<TOKEN end_char="8228" id="token-134-3" morph="none" pos="word" start_char="8222">Funding</TOKEN>
<TOKEN end_char="8234" id="token-134-4" morph="none" pos="word" start_char="8230">Award</TOKEN>
<TOKEN end_char="8239" id="token-134-5" morph="none" pos="word" start_char="8236">from</TOKEN>
<TOKEN end_char="8244" id="token-134-6" morph="none" pos="word" start_char="8241">CEPI</TOKEN>
<TOKEN end_char="8247" id="token-134-7" morph="none" pos="word" start_char="8246">to</TOKEN>
<TOKEN end_char="8258" id="token-134-8" morph="none" pos="word" start_char="8249">Accelerate</TOKEN>
<TOKEN end_char="8270" id="token-134-9" morph="none" pos="word" start_char="8260">Development</TOKEN>
<TOKEN end_char="8273" id="token-134-10" morph="none" pos="word" start_char="8272">of</TOKEN>
<TOKEN end_char="8283" id="token-134-11" morph="none" pos="word" start_char="8275">Messenger</TOKEN>
<TOKEN end_char="8287" id="token-134-12" morph="none" pos="word" start_char="8285">RNA</TOKEN>
<TOKEN end_char="8289" id="token-134-13" morph="none" pos="punct" start_char="8289">(</TOKEN>
<TOKEN end_char="8293" id="token-134-14" morph="none" pos="word" start_char="8290">mRNA</TOKEN>
<TOKEN end_char="8294" id="token-134-15" morph="none" pos="punct" start_char="8294">)</TOKEN>
<TOKEN end_char="8302" id="token-134-16" morph="none" pos="word" start_char="8296">Vaccine</TOKEN>
<TOKEN end_char="8310" id="token-134-17" morph="none" pos="word" start_char="8304">Against</TOKEN>
<TOKEN end_char="8316" id="token-134-18" morph="none" pos="word" start_char="8312">Novel</TOKEN>
<TOKEN end_char="8328" id="token-134-19" morph="none" pos="word" start_char="8318">Coronavirus</TOKEN>
<TOKEN end_char="8330" id="token-134-20" morph="none" pos="punct" start_char="8329">."</TOKEN>
</SEG>
<SEG end_char="8345" id="segment-135" start_char="8332">
<ORIGINAL_TEXT>Press release.</ORIGINAL_TEXT>
<TOKEN end_char="8336" id="token-135-0" morph="none" pos="word" start_char="8332">Press</TOKEN>
<TOKEN end_char="8344" id="token-135-1" morph="none" pos="word" start_char="8338">release</TOKEN>
<TOKEN end_char="8345" id="token-135-2" morph="none" pos="punct" start_char="8345">.</TOKEN>
</SEG>
<SEG end_char="8354" id="segment-136" start_char="8347">
<ORIGINAL_TEXT>Moderna.</ORIGINAL_TEXT>
<TOKEN end_char="8353" id="token-136-0" morph="none" pos="word" start_char="8347">Moderna</TOKEN>
<TOKEN end_char="8354" id="token-136-1" morph="none" pos="punct" start_char="8354">.</TOKEN>
<TRANSLATED_TEXT>Modern.</TRANSLATED_TEXT><DETECTED_LANGUAGE>de</DETECTED_LANGUAGE></SEG>
<SEG end_char="8367" id="segment-137" start_char="8356">
<ORIGINAL_TEXT>23 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="8357" id="token-137-0" morph="none" pos="word" start_char="8356">23</TOKEN>
<TOKEN end_char="8361" id="token-137-1" morph="none" pos="word" start_char="8359">Jan</TOKEN>
<TOKEN end_char="8366" id="token-137-2" morph="none" pos="word" start_char="8363">2020</TOKEN>
<TOKEN end_char="8367" id="token-137-3" morph="none" pos="punct" start_char="8367">.</TOKEN>
</SEG>
<SEG end_char="8428" id="segment-138" start_char="8370">
<ORIGINAL_TEXT>Transcript of Update on 2019 Novel Coronavirus (2019-nCoV).</ORIGINAL_TEXT>
<TOKEN end_char="8379" id="token-138-0" morph="none" pos="word" start_char="8370">Transcript</TOKEN>
<TOKEN end_char="8382" id="token-138-1" morph="none" pos="word" start_char="8381">of</TOKEN>
<TOKEN end_char="8389" id="token-138-2" morph="none" pos="word" start_char="8384">Update</TOKEN>
<TOKEN end_char="8392" id="token-138-3" morph="none" pos="word" start_char="8391">on</TOKEN>
<TOKEN end_char="8397" id="token-138-4" morph="none" pos="word" start_char="8394">2019</TOKEN>
<TOKEN end_char="8403" id="token-138-5" morph="none" pos="word" start_char="8399">Novel</TOKEN>
<TOKEN end_char="8415" id="token-138-6" morph="none" pos="word" start_char="8405">Coronavirus</TOKEN>
<TOKEN end_char="8417" id="token-138-7" morph="none" pos="punct" start_char="8417">(</TOKEN>
<TOKEN end_char="8426" id="token-138-8" morph="none" pos="unknown" start_char="8418">2019-nCoV</TOKEN>
<TOKEN end_char="8428" id="token-138-9" morph="none" pos="punct" start_char="8427">).</TOKEN>
</SEG>
<SEG end_char="8433" id="segment-139" start_char="8430">
<ORIGINAL_TEXT>CDC.</ORIGINAL_TEXT>
<TOKEN end_char="8432" id="token-139-0" morph="none" pos="word" start_char="8430">CDC</TOKEN>
<TOKEN end_char="8433" id="token-139-1" morph="none" pos="punct" start_char="8433">.</TOKEN>
<TRANSLATED_TEXT>- CDC.</TRANSLATED_TEXT><DETECTED_LANGUAGE>cy</DETECTED_LANGUAGE></SEG>
<SEG end_char="8446" id="segment-140" start_char="8435">
<ORIGINAL_TEXT>21 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="8436" id="token-140-0" morph="none" pos="word" start_char="8435">21</TOKEN>
<TOKEN end_char="8440" id="token-140-1" morph="none" pos="word" start_char="8438">Jan</TOKEN>
<TOKEN end_char="8445" id="token-140-2" morph="none" pos="word" start_char="8442">2020</TOKEN>
<TOKEN end_char="8446" id="token-140-3" morph="none" pos="punct" start_char="8446">.</TOKEN>
</SEG>
<SEG end_char="8491" id="segment-141" start_char="8449">
<ORIGINAL_TEXT>Wuhan Coronavirus (2019-nCoV) Global Cases.</ORIGINAL_TEXT>
<TOKEN end_char="8453" id="token-141-0" morph="none" pos="word" start_char="8449">Wuhan</TOKEN>
<TOKEN end_char="8465" id="token-141-1" morph="none" pos="word" start_char="8455">Coronavirus</TOKEN>
<TOKEN end_char="8467" id="token-141-2" morph="none" pos="punct" start_char="8467">(</TOKEN>
<TOKEN end_char="8476" id="token-141-3" morph="none" pos="unknown" start_char="8468">2019-nCoV</TOKEN>
<TOKEN end_char="8477" id="token-141-4" morph="none" pos="punct" start_char="8477">)</TOKEN>
<TOKEN end_char="8484" id="token-141-5" morph="none" pos="word" start_char="8479">Global</TOKEN>
<TOKEN end_char="8490" id="token-141-6" morph="none" pos="word" start_char="8486">Cases</TOKEN>
<TOKEN end_char="8491" id="token-141-7" morph="none" pos="punct" start_char="8491">.</TOKEN>
</SEG>
<SEG end_char="8539" id="segment-142" start_char="8493">
<ORIGINAL_TEXT>Data visualization by Johns Hopkins University.</ORIGINAL_TEXT>
<TOKEN end_char="8496" id="token-142-0" morph="none" pos="word" start_char="8493">Data</TOKEN>
<TOKEN end_char="8510" id="token-142-1" morph="none" pos="word" start_char="8498">visualization</TOKEN>
<TOKEN end_char="8513" id="token-142-2" morph="none" pos="word" start_char="8512">by</TOKEN>
<TOKEN end_char="8519" id="token-142-3" morph="none" pos="word" start_char="8515">Johns</TOKEN>
<TOKEN end_char="8527" id="token-142-4" morph="none" pos="word" start_char="8521">Hopkins</TOKEN>
<TOKEN end_char="8538" id="token-142-5" morph="none" pos="word" start_char="8529">University</TOKEN>
<TOKEN end_char="8539" id="token-142-6" morph="none" pos="punct" start_char="8539">.</TOKEN>
</SEG>
<SEG end_char="8561" id="segment-143" start_char="8541">
<ORIGINAL_TEXT>Accessed 24 Jan 2020.</ORIGINAL_TEXT>
<TOKEN end_char="8548" id="token-143-0" morph="none" pos="word" start_char="8541">Accessed</TOKEN>
<TOKEN end_char="8551" id="token-143-1" morph="none" pos="word" start_char="8550">24</TOKEN>
<TOKEN end_char="8555" id="token-143-2" morph="none" pos="word" start_char="8553">Jan</TOKEN>
<TOKEN end_char="8560" id="token-143-3" morph="none" pos="word" start_char="8557">2020</TOKEN>
<TOKEN end_char="8561" id="token-143-4" morph="none" pos="punct" start_char="8561">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
<LCTL_TEXT lang="spa">
<DOC grammar="none" id="L0C04CAAI" lang="spa" raw_text_char_length="15701" raw_text_md5="5a7ac8a76107e8f9b3d202f1183ae3c7" tokenization="tokenization_parameters.v5.0">
<TEXT>
<SEG end_char="146" id="segment-0" start_char="1">
<ORIGINAL_TEXT>Now Chinese scientists claim coronavirus originated in INDIA in summer 2019 amid heatwave 'that forced humans and animals to drink the same water'</ORIGINAL_TEXT>
<TOKEN end_char="3" id="token-0-0" morph="none" pos="word" start_char="1">Now</TOKEN>
<TOKEN end_char="11" id="token-0-1" morph="none" pos="word" start_char="5">Chinese</TOKEN>
<TOKEN end_char="22" id="token-0-2" morph="none" pos="word" start_char="13">scientists</TOKEN>
<TOKEN end_char="28" id="token-0-3" morph="none" pos="word" start_char="24">claim</TOKEN>
<TOKEN end_char="40" id="token-0-4" morph="none" pos="word" start_char="30">coronavirus</TOKEN>
<TOKEN end_char="51" id="token-0-5" morph="none" pos="word" start_char="42">originated</TOKEN>
<TOKEN end_char="54" id="token-0-6" morph="none" pos="word" start_char="53">in</TOKEN>
<TOKEN end_char="60" id="token-0-7" morph="none" pos="word" start_char="56">INDIA</TOKEN>
<TOKEN end_char="63" id="token-0-8" morph="none" pos="word" start_char="62">in</TOKEN>
<TOKEN end_char="70" id="token-0-9" morph="none" pos="word" start_char="65">summer</TOKEN>
<TOKEN end_char="75" id="token-0-10" morph="none" pos="word" start_char="72">2019</TOKEN>
<TOKEN end_char="80" id="token-0-11" morph="none" pos="word" start_char="77">amid</TOKEN>
<TOKEN end_char="89" id="token-0-12" morph="none" pos="word" start_char="82">heatwave</TOKEN>
<TOKEN end_char="91" id="token-0-13" morph="none" pos="punct" start_char="91">'</TOKEN>
<TOKEN end_char="95" id="token-0-14" morph="none" pos="word" start_char="92">that</TOKEN>
<TOKEN end_char="102" id="token-0-15" morph="none" pos="word" start_char="97">forced</TOKEN>
<TOKEN end_char="109" id="token-0-16" morph="none" pos="word" start_char="104">humans</TOKEN>
<TOKEN end_char="113" id="token-0-17" morph="none" pos="word" start_char="111">and</TOKEN>
<TOKEN end_char="121" id="token-0-18" morph="none" pos="word" start_char="115">animals</TOKEN>
<TOKEN end_char="124" id="token-0-19" morph="none" pos="word" start_char="123">to</TOKEN>
<TOKEN end_char="130" id="token-0-20" morph="none" pos="word" start_char="126">drink</TOKEN>
<TOKEN end_char="134" id="token-0-21" morph="none" pos="word" start_char="132">the</TOKEN>
<TOKEN end_char="139" id="token-0-22" morph="none" pos="word" start_char="136">same</TOKEN>
<TOKEN end_char="145" id="token-0-23" morph="none" pos="word" start_char="141">water</TOKEN>
<TOKEN end_char="146" id="token-0-24" morph="none" pos="punct" start_char="146">'</TOKEN>
</SEG>
<SEG end_char="307" id="segment-1" start_char="150">
<ORIGINAL_TEXT>Chinese researchers have claimed that coronavirus originated in India, in the latest attempt by academics to pin blame for the pandemic outside their borders.</ORIGINAL_TEXT>
<TOKEN end_char="156" id="token-1-0" morph="none" pos="word" start_char="150">Chinese</TOKEN>
<TOKEN end_char="168" id="token-1-1" morph="none" pos="word" start_char="158">researchers</TOKEN>
<TOKEN end_char="173" id="token-1-2" morph="none" pos="word" start_char="170">have</TOKEN>
<TOKEN end_char="181" id="token-1-3" morph="none" pos="word" start_char="175">claimed</TOKEN>
<TOKEN end_char="186" id="token-1-4" morph="none" pos="word" start_char="183">that</TOKEN>
<TOKEN end_char="198" id="token-1-5" morph="none" pos="word" start_char="188">coronavirus</TOKEN>
<TOKEN end_char="209" id="token-1-6" morph="none" pos="word" start_char="200">originated</TOKEN>
<TOKEN end_char="212" id="token-1-7" morph="none" pos="word" start_char="211">in</TOKEN>
<TOKEN end_char="218" id="token-1-8" morph="none" pos="word" start_char="214">India</TOKEN>
<TOKEN end_char="219" id="token-1-9" morph="none" pos="punct" start_char="219">,</TOKEN>
<TOKEN end_char="222" id="token-1-10" morph="none" pos="word" start_char="221">in</TOKEN>
<TOKEN end_char="226" id="token-1-11" morph="none" pos="word" start_char="224">the</TOKEN>
<TOKEN end_char="233" id="token-1-12" morph="none" pos="word" start_char="228">latest</TOKEN>
<TOKEN end_char="241" id="token-1-13" morph="none" pos="word" start_char="235">attempt</TOKEN>
<TOKEN end_char="244" id="token-1-14" morph="none" pos="word" start_char="243">by</TOKEN>
<TOKEN end_char="254" id="token-1-15" morph="none" pos="word" start_char="246">academics</TOKEN>
<TOKEN end_char="257" id="token-1-16" morph="none" pos="word" start_char="256">to</TOKEN>
<TOKEN end_char="261" id="token-1-17" morph="none" pos="word" start_char="259">pin</TOKEN>
<TOKEN end_char="267" id="token-1-18" morph="none" pos="word" start_char="263">blame</TOKEN>
<TOKEN end_char="271" id="token-1-19" morph="none" pos="word" start_char="269">for</TOKEN>
<TOKEN end_char="275" id="token-1-20" morph="none" pos="word" start_char="273">the</TOKEN>
<TOKEN end_char="284" id="token-1-21" morph="none" pos="word" start_char="277">pandemic</TOKEN>
<TOKEN end_char="292" id="token-1-22" morph="none" pos="word" start_char="286">outside</TOKEN>
<TOKEN end_char="298" id="token-1-23" morph="none" pos="word" start_char="294">their</TOKEN>
<TOKEN end_char="306" id="token-1-24" morph="none" pos="word" start_char="300">borders</TOKEN>
<TOKEN end_char="307" id="token-1-25" morph="none" pos="punct" start_char="307">.</TOKEN>
</SEG>
<SEG end_char="536" id="segment-2" start_char="310">
<ORIGINAL_TEXT>A team from the Chinese Academy of Sciences argues the virus likely originated in India in summer 2019 - jumping from animals to humans via contaminated water - before travelling unnoticed to Wuhan, where it was first detected.</ORIGINAL_TEXT>
<TOKEN end_char="310" id="token-2-0" morph="none" pos="word" start_char="310">A</TOKEN>
<TOKEN end_char="315" id="token-2-1" morph="none" pos="word" start_char="312">team</TOKEN>
<TOKEN end_char="320" id="token-2-2" morph="none" pos="word" start_char="317">from</TOKEN>
<TOKEN end_char="324" id="token-2-3" morph="none" pos="word" start_char="322">the</TOKEN>
<TOKEN end_char="332" id="token-2-4" morph="none" pos="word" start_char="326">Chinese</TOKEN>
<TOKEN end_char="340" id="token-2-5" morph="none" pos="word" start_char="334">Academy</TOKEN>
<TOKEN end_char="343" id="token-2-6" morph="none" pos="word" start_char="342">of</TOKEN>
<TOKEN end_char="352" id="token-2-7" morph="none" pos="word" start_char="345">Sciences</TOKEN>
<TOKEN end_char="359" id="token-2-8" morph="none" pos="word" start_char="354">argues</TOKEN>
<TOKEN end_char="363" id="token-2-9" morph="none" pos="word" start_char="361">the</TOKEN>
<TOKEN end_char="369" id="token-2-10" morph="none" pos="word" start_char="365">virus</TOKEN>
<TOKEN end_char="376" id="token-2-11" morph="none" pos="word" start_char="371">likely</TOKEN>
<TOKEN end_char="387" id="token-2-12" morph="none" pos="word" start_char="378">originated</TOKEN>
<TOKEN end_char="390" id="token-2-13" morph="none" pos="word" start_char="389">in</TOKEN>
<TOKEN end_char="396" id="token-2-14" morph="none" pos="word" start_char="392">India</TOKEN>
<TOKEN end_char="399" id="token-2-15" morph="none" pos="word" start_char="398">in</TOKEN>
<TOKEN end_char="406" id="token-2-16" morph="none" pos="word" start_char="401">summer</TOKEN>
<TOKEN end_char="411" id="token-2-17" morph="none" pos="word" start_char="408">2019</TOKEN>
<TOKEN end_char="413" id="token-2-18" morph="none" pos="punct" start_char="413">-</TOKEN>
<TOKEN end_char="421" id="token-2-19" morph="none" pos="word" start_char="415">jumping</TOKEN>
<TOKEN end_char="426" id="token-2-20" morph="none" pos="word" start_char="423">from</TOKEN>
<TOKEN end_char="434" id="token-2-21" morph="none" pos="word" start_char="428">animals</TOKEN>
<TOKEN end_char="437" id="token-2-22" morph="none" pos="word" start_char="436">to</TOKEN>
<TOKEN end_char="444" id="token-2-23" morph="none" pos="word" start_char="439">humans</TOKEN>
<TOKEN end_char="448" id="token-2-24" morph="none" pos="word" start_char="446">via</TOKEN>
<TOKEN end_char="461" id="token-2-25" morph="none" pos="word" start_char="450">contaminated</TOKEN>
<TOKEN end_char="467" id="token-2-26" morph="none" pos="word" start_char="463">water</TOKEN>
<TOKEN end_char="469" id="token-2-27" morph="none" pos="punct" start_char="469">-</TOKEN>
<TOKEN end_char="476" id="token-2-28" morph="none" pos="word" start_char="471">before</TOKEN>
<TOKEN end_char="487" id="token-2-29" morph="none" pos="word" start_char="478">travelling</TOKEN>
<TOKEN end_char="497" id="token-2-30" morph="none" pos="word" start_char="489">unnoticed</TOKEN>
<TOKEN end_char="500" id="token-2-31" morph="none" pos="word" start_char="499">to</TOKEN>
<TOKEN end_char="506" id="token-2-32" morph="none" pos="word" start_char="502">Wuhan</TOKEN>
<TOKEN end_char="507" id="token-2-33" morph="none" pos="punct" start_char="507">,</TOKEN>
<TOKEN end_char="513" id="token-2-34" morph="none" pos="word" start_char="509">where</TOKEN>
<TOKEN end_char="516" id="token-2-35" morph="none" pos="word" start_char="515">it</TOKEN>
<TOKEN end_char="520" id="token-2-36" morph="none" pos="word" start_char="518">was</TOKEN>
<TOKEN end_char="526" id="token-2-37" morph="none" pos="word" start_char="522">first</TOKEN>
<TOKEN end_char="535" id="token-2-38" morph="none" pos="word" start_char="528">detected</TOKEN>
<TOKEN end_char="536" id="token-2-39" morph="none" pos="punct" start_char="536">.</TOKEN>
</SEG>
<SEG end_char="694" id="segment-3" start_char="539">
<ORIGINAL_TEXT>But David Robertson, and expert from Glasgow University, called the paper 'very flawed' and concluded 'it adds nothing to our understanding of coronavirus'.</ORIGINAL_TEXT>
<TOKEN end_char="541" id="token-3-0" morph="none" pos="word" start_char="539">But</TOKEN>
<TOKEN end_char="547" id="token-3-1" morph="none" pos="word" start_char="543">David</TOKEN>
<TOKEN end_char="557" id="token-3-2" morph="none" pos="word" start_char="549">Robertson</TOKEN>
<TOKEN end_char="558" id="token-3-3" morph="none" pos="punct" start_char="558">,</TOKEN>
<TOKEN end_char="562" id="token-3-4" morph="none" pos="word" start_char="560">and</TOKEN>
<TOKEN end_char="569" id="token-3-5" morph="none" pos="word" start_char="564">expert</TOKEN>
<TOKEN end_char="574" id="token-3-6" morph="none" pos="word" start_char="571">from</TOKEN>
<TOKEN end_char="582" id="token-3-7" morph="none" pos="word" start_char="576">Glasgow</TOKEN>
<TOKEN end_char="593" id="token-3-8" morph="none" pos="word" start_char="584">University</TOKEN>
<TOKEN end_char="594" id="token-3-9" morph="none" pos="punct" start_char="594">,</TOKEN>
<TOKEN end_char="601" id="token-3-10" morph="none" pos="word" start_char="596">called</TOKEN>
<TOKEN end_char="605" id="token-3-11" morph="none" pos="word" start_char="603">the</TOKEN>
<TOKEN end_char="611" id="token-3-12" morph="none" pos="word" start_char="607">paper</TOKEN>
<TOKEN end_char="613" id="token-3-13" morph="none" pos="punct" start_char="613">'</TOKEN>
<TOKEN end_char="617" id="token-3-14" morph="none" pos="word" start_char="614">very</TOKEN>
<TOKEN end_char="624" id="token-3-15" morph="none" pos="word" start_char="619">flawed</TOKEN>
<TOKEN end_char="625" id="token-3-16" morph="none" pos="punct" start_char="625">'</TOKEN>
<TOKEN end_char="629" id="token-3-17" morph="none" pos="word" start_char="627">and</TOKEN>
<TOKEN end_char="639" id="token-3-18" morph="none" pos="word" start_char="631">concluded</TOKEN>
<TOKEN end_char="641" id="token-3-19" morph="none" pos="punct" start_char="641">'</TOKEN>
<TOKEN end_char="643" id="token-3-20" morph="none" pos="word" start_char="642">it</TOKEN>
<TOKEN end_char="648" id="token-3-21" morph="none" pos="word" start_char="645">adds</TOKEN>
<TOKEN end_char="656" id="token-3-22" morph="none" pos="word" start_char="650">nothing</TOKEN>
<TOKEN end_char="659" id="token-3-23" morph="none" pos="word" start_char="658">to</TOKEN>
<TOKEN end_char="663" id="token-3-24" morph="none" pos="word" start_char="661">our</TOKEN>
<TOKEN end_char="677" id="token-3-25" morph="none" pos="word" start_char="665">understanding</TOKEN>
<TOKEN end_char="680" id="token-3-26" morph="none" pos="word" start_char="679">of</TOKEN>
<TOKEN end_char="692" id="token-3-27" morph="none" pos="word" start_char="682">coronavirus</TOKEN>
<TOKEN end_char="694" id="token-3-28" morph="none" pos="punct" start_char="693">'.</TOKEN>
</SEG>
<SEG end_char="900" id="segment-4" start_char="697">
<ORIGINAL_TEXT>It is not the first time that Chinese authorities have pointed the finger of blame elsewhere - suggesting, largely without evidence, that both Italy and the US could be the site of the original infection.</ORIGINAL_TEXT>
<TOKEN end_char="698" id="token-4-0" morph="none" pos="word" start_char="697">It</TOKEN>
<TOKEN end_char="701" id="token-4-1" morph="none" pos="word" start_char="700">is</TOKEN>
<TOKEN end_char="705" id="token-4-2" morph="none" pos="word" start_char="703">not</TOKEN>
<TOKEN end_char="709" id="token-4-3" morph="none" pos="word" start_char="707">the</TOKEN>
<TOKEN end_char="715" id="token-4-4" morph="none" pos="word" start_char="711">first</TOKEN>
<TOKEN end_char="720" id="token-4-5" morph="none" pos="word" start_char="717">time</TOKEN>
<TOKEN end_char="725" id="token-4-6" morph="none" pos="word" start_char="722">that</TOKEN>
<TOKEN end_char="733" id="token-4-7" morph="none" pos="word" start_char="727">Chinese</TOKEN>
<TOKEN end_char="745" id="token-4-8" morph="none" pos="word" start_char="735">authorities</TOKEN>
<TOKEN end_char="750" id="token-4-9" morph="none" pos="word" start_char="747">have</TOKEN>
<TOKEN end_char="758" id="token-4-10" morph="none" pos="word" start_char="752">pointed</TOKEN>
<TOKEN end_char="762" id="token-4-11" morph="none" pos="word" start_char="760">the</TOKEN>
<TOKEN end_char="769" id="token-4-12" morph="none" pos="word" start_char="764">finger</TOKEN>
<TOKEN end_char="772" id="token-4-13" morph="none" pos="word" start_char="771">of</TOKEN>
<TOKEN end_char="778" id="token-4-14" morph="none" pos="word" start_char="774">blame</TOKEN>
<TOKEN end_char="788" id="token-4-15" morph="none" pos="word" start_char="780">elsewhere</TOKEN>
<TOKEN end_char="790" id="token-4-16" morph="none" pos="punct" start_char="790">-</TOKEN>
<TOKEN end_char="801" id="token-4-17" morph="none" pos="word" start_char="792">suggesting</TOKEN>
<TOKEN end_char="802" id="token-4-18" morph="none" pos="punct" start_char="802">,</TOKEN>
<TOKEN end_char="810" id="token-4-19" morph="none" pos="word" start_char="804">largely</TOKEN>
<TOKEN end_char="818" id="token-4-20" morph="none" pos="word" start_char="812">without</TOKEN>
<TOKEN end_char="827" id="token-4-21" morph="none" pos="word" start_char="820">evidence</TOKEN>
<TOKEN end_char="828" id="token-4-22" morph="none" pos="punct" start_char="828">,</TOKEN>
<TOKEN end_char="833" id="token-4-23" morph="none" pos="word" start_char="830">that</TOKEN>
<TOKEN end_char="838" id="token-4-24" morph="none" pos="word" start_char="835">both</TOKEN>
<TOKEN end_char="844" id="token-4-25" morph="none" pos="word" start_char="840">Italy</TOKEN>
<TOKEN end_char="848" id="token-4-26" morph="none" pos="word" start_char="846">and</TOKEN>
<TOKEN end_char="852" id="token-4-27" morph="none" pos="word" start_char="850">the</TOKEN>
<TOKEN end_char="855" id="token-4-28" morph="none" pos="word" start_char="854">US</TOKEN>
<TOKEN end_char="861" id="token-4-29" morph="none" pos="word" start_char="857">could</TOKEN>
<TOKEN end_char="864" id="token-4-30" morph="none" pos="word" start_char="863">be</TOKEN>
<TOKEN end_char="868" id="token-4-31" morph="none" pos="word" start_char="866">the</TOKEN>
<TOKEN end_char="873" id="token-4-32" morph="none" pos="word" start_char="870">site</TOKEN>
<TOKEN end_char="876" id="token-4-33" morph="none" pos="word" start_char="875">of</TOKEN>
<TOKEN end_char="880" id="token-4-34" morph="none" pos="word" start_char="878">the</TOKEN>
<TOKEN end_char="889" id="token-4-35" morph="none" pos="word" start_char="882">original</TOKEN>
<TOKEN end_char="899" id="token-4-36" morph="none" pos="word" start_char="891">infection</TOKEN>
<TOKEN end_char="900" id="token-4-37" morph="none" pos="punct" start_char="900">.</TOKEN>
</SEG>
<SEG end_char="1048" id="segment-5" start_char="903">
<ORIGINAL_TEXT>And it comes against a backdrop of increased political tensions between India and China, with troops attacking each-other along a disputed border.</ORIGINAL_TEXT>
<TOKEN end_char="905" id="token-5-0" morph="none" pos="word" start_char="903">And</TOKEN>
<TOKEN end_char="908" id="token-5-1" morph="none" pos="word" start_char="907">it</TOKEN>
<TOKEN end_char="914" id="token-5-2" morph="none" pos="word" start_char="910">comes</TOKEN>
<TOKEN end_char="922" id="token-5-3" morph="none" pos="word" start_char="916">against</TOKEN>
<TOKEN end_char="924" id="token-5-4" morph="none" pos="word" start_char="924">a</TOKEN>
<TOKEN end_char="933" id="token-5-5" morph="none" pos="word" start_char="926">backdrop</TOKEN>
<TOKEN end_char="936" id="token-5-6" morph="none" pos="word" start_char="935">of</TOKEN>
<TOKEN end_char="946" id="token-5-7" morph="none" pos="word" start_char="938">increased</TOKEN>
<TOKEN end_char="956" id="token-5-8" morph="none" pos="word" start_char="948">political</TOKEN>
<TOKEN end_char="965" id="token-5-9" morph="none" pos="word" start_char="958">tensions</TOKEN>
<TOKEN end_char="973" id="token-5-10" morph="none" pos="word" start_char="967">between</TOKEN>
<TOKEN end_char="979" id="token-5-11" morph="none" pos="word" start_char="975">India</TOKEN>
<TOKEN end_char="983" id="token-5-12" morph="none" pos="word" start_char="981">and</TOKEN>
<TOKEN end_char="989" id="token-5-13" morph="none" pos="word" start_char="985">China</TOKEN>
<TOKEN end_char="990" id="token-5-14" morph="none" pos="punct" start_char="990">,</TOKEN>
<TOKEN end_char="995" id="token-5-15" morph="none" pos="word" start_char="992">with</TOKEN>
<TOKEN end_char="1002" id="token-5-16" morph="none" pos="word" start_char="997">troops</TOKEN>
<TOKEN end_char="1012" id="token-5-17" morph="none" pos="word" start_char="1004">attacking</TOKEN>
<TOKEN end_char="1023" id="token-5-18" morph="none" pos="unknown" start_char="1014">each-other</TOKEN>
<TOKEN end_char="1029" id="token-5-19" morph="none" pos="word" start_char="1025">along</TOKEN>
<TOKEN end_char="1031" id="token-5-20" morph="none" pos="word" start_char="1031">a</TOKEN>
<TOKEN end_char="1040" id="token-5-21" morph="none" pos="word" start_char="1033">disputed</TOKEN>
<TOKEN end_char="1047" id="token-5-22" morph="none" pos="word" start_char="1042">border</TOKEN>
<TOKEN end_char="1048" id="token-5-23" morph="none" pos="punct" start_char="1048">.</TOKEN>
</SEG>
<SEG end_char="1197" id="segment-6" start_char="1053">
<ORIGINAL_TEXT>The WHO is currently looking for the source of coronavirus in China, while the body of scientific evidence suggests the disease originated there.</ORIGINAL_TEXT>
<TOKEN end_char="1055" id="token-6-0" morph="none" pos="word" start_char="1053">The</TOKEN>
<TOKEN end_char="1059" id="token-6-1" morph="none" pos="word" start_char="1057">WHO</TOKEN>
<TOKEN end_char="1062" id="token-6-2" morph="none" pos="word" start_char="1061">is</TOKEN>
<TOKEN end_char="1072" id="token-6-3" morph="none" pos="word" start_char="1064">currently</TOKEN>
<TOKEN end_char="1080" id="token-6-4" morph="none" pos="word" start_char="1074">looking</TOKEN>
<TOKEN end_char="1084" id="token-6-5" morph="none" pos="word" start_char="1082">for</TOKEN>
<TOKEN end_char="1088" id="token-6-6" morph="none" pos="word" start_char="1086">the</TOKEN>
<TOKEN end_char="1095" id="token-6-7" morph="none" pos="word" start_char="1090">source</TOKEN>
<TOKEN end_char="1098" id="token-6-8" morph="none" pos="word" start_char="1097">of</TOKEN>
<TOKEN end_char="1110" id="token-6-9" morph="none" pos="word" start_char="1100">coronavirus</TOKEN>
<TOKEN end_char="1113" id="token-6-10" morph="none" pos="word" start_char="1112">in</TOKEN>
<TOKEN end_char="1119" id="token-6-11" morph="none" pos="word" start_char="1115">China</TOKEN>
<TOKEN end_char="1120" id="token-6-12" morph="none" pos="punct" start_char="1120">,</TOKEN>
<TOKEN end_char="1126" id="token-6-13" morph="none" pos="word" start_char="1122">while</TOKEN>
<TOKEN end_char="1130" id="token-6-14" morph="none" pos="word" start_char="1128">the</TOKEN>
<TOKEN end_char="1135" id="token-6-15" morph="none" pos="word" start_char="1132">body</TOKEN>
<TOKEN end_char="1138" id="token-6-16" morph="none" pos="word" start_char="1137">of</TOKEN>
<TOKEN end_char="1149" id="token-6-17" morph="none" pos="word" start_char="1140">scientific</TOKEN>
<TOKEN end_char="1158" id="token-6-18" morph="none" pos="word" start_char="1151">evidence</TOKEN>
<TOKEN end_char="1167" id="token-6-19" morph="none" pos="word" start_char="1160">suggests</TOKEN>
<TOKEN end_char="1171" id="token-6-20" morph="none" pos="word" start_char="1169">the</TOKEN>
<TOKEN end_char="1179" id="token-6-21" morph="none" pos="word" start_char="1173">disease</TOKEN>
<TOKEN end_char="1190" id="token-6-22" morph="none" pos="word" start_char="1181">originated</TOKEN>
<TOKEN end_char="1196" id="token-6-23" morph="none" pos="word" start_char="1192">there</TOKEN>
<TOKEN end_char="1197" id="token-6-24" morph="none" pos="punct" start_char="1197">.</TOKEN>
</SEG>
<SEG end_char="1337" id="segment-7" start_char="1200">
<ORIGINAL_TEXT>In their paper, the Chinese team use phylogenetic analysis - a study of how a virus mutates - to attempt to trace the origins of Covid-19.</ORIGINAL_TEXT>
<TOKEN end_char="1201" id="token-7-0" morph="none" pos="word" start_char="1200">In</TOKEN>
<TOKEN end_char="1207" id="token-7-1" morph="none" pos="word" start_char="1203">their</TOKEN>
<TOKEN end_char="1213" id="token-7-2" morph="none" pos="word" start_char="1209">paper</TOKEN>
<TOKEN end_char="1214" id="token-7-3" morph="none" pos="punct" start_char="1214">,</TOKEN>
<TOKEN end_char="1218" id="token-7-4" morph="none" pos="word" start_char="1216">the</TOKEN>
<TOKEN end_char="1226" id="token-7-5" morph="none" pos="word" start_char="1220">Chinese</TOKEN>
<TOKEN end_char="1231" id="token-7-6" morph="none" pos="word" start_char="1228">team</TOKEN>
<TOKEN end_char="1235" id="token-7-7" morph="none" pos="word" start_char="1233">use</TOKEN>
<TOKEN end_char="1248" id="token-7-8" morph="none" pos="word" start_char="1237">phylogenetic</TOKEN>
<TOKEN end_char="1257" id="token-7-9" morph="none" pos="word" start_char="1250">analysis</TOKEN>
<TOKEN end_char="1259" id="token-7-10" morph="none" pos="punct" start_char="1259">-</TOKEN>
<TOKEN end_char="1261" id="token-7-11" morph="none" pos="word" start_char="1261">a</TOKEN>
<TOKEN end_char="1267" id="token-7-12" morph="none" pos="word" start_char="1263">study</TOKEN>
<TOKEN end_char="1270" id="token-7-13" morph="none" pos="word" start_char="1269">of</TOKEN>
<TOKEN end_char="1274" id="token-7-14" morph="none" pos="word" start_char="1272">how</TOKEN>
<TOKEN end_char="1276" id="token-7-15" morph="none" pos="word" start_char="1276">a</TOKEN>
<TOKEN end_char="1282" id="token-7-16" morph="none" pos="word" start_char="1278">virus</TOKEN>
<TOKEN end_char="1290" id="token-7-17" morph="none" pos="word" start_char="1284">mutates</TOKEN>
<TOKEN end_char="1292" id="token-7-18" morph="none" pos="punct" start_char="1292">-</TOKEN>
<TOKEN end_char="1295" id="token-7-19" morph="none" pos="word" start_char="1294">to</TOKEN>
<TOKEN end_char="1303" id="token-7-20" morph="none" pos="word" start_char="1297">attempt</TOKEN>
<TOKEN end_char="1306" id="token-7-21" morph="none" pos="word" start_char="1305">to</TOKEN>
<TOKEN end_char="1312" id="token-7-22" morph="none" pos="word" start_char="1308">trace</TOKEN>
<TOKEN end_char="1316" id="token-7-23" morph="none" pos="word" start_char="1314">the</TOKEN>
<TOKEN end_char="1324" id="token-7-24" morph="none" pos="word" start_char="1318">origins</TOKEN>
<TOKEN end_char="1327" id="token-7-25" morph="none" pos="word" start_char="1326">of</TOKEN>
<TOKEN end_char="1336" id="token-7-26" morph="none" pos="unknown" start_char="1329">Covid-19</TOKEN>
<TOKEN end_char="1337" id="token-7-27" morph="none" pos="punct" start_char="1337">.</TOKEN>
</SEG>
<SEG end_char="1466" id="segment-8" start_char="1340">
<ORIGINAL_TEXT>Viruses, like all cells, mutate as they reproduce, meaning tiny changes occur in their DNA each time they replicate themselves.</ORIGINAL_TEXT>
<TOKEN end_char="1346" id="token-8-0" morph="none" pos="word" start_char="1340">Viruses</TOKEN>
<TOKEN end_char="1347" id="token-8-1" morph="none" pos="punct" start_char="1347">,</TOKEN>
<TOKEN end_char="1352" id="token-8-2" morph="none" pos="word" start_char="1349">like</TOKEN>
<TOKEN end_char="1356" id="token-8-3" morph="none" pos="word" start_char="1354">all</TOKEN>
<TOKEN end_char="1362" id="token-8-4" morph="none" pos="word" start_char="1358">cells</TOKEN>
<TOKEN end_char="1363" id="token-8-5" morph="none" pos="punct" start_char="1363">,</TOKEN>
<TOKEN end_char="1370" id="token-8-6" morph="none" pos="word" start_char="1365">mutate</TOKEN>
<TOKEN end_char="1373" id="token-8-7" morph="none" pos="word" start_char="1372">as</TOKEN>
<TOKEN end_char="1378" id="token-8-8" morph="none" pos="word" start_char="1375">they</TOKEN>
<TOKEN end_char="1388" id="token-8-9" morph="none" pos="word" start_char="1380">reproduce</TOKEN>
<TOKEN end_char="1389" id="token-8-10" morph="none" pos="punct" start_char="1389">,</TOKEN>
<TOKEN end_char="1397" id="token-8-11" morph="none" pos="word" start_char="1391">meaning</TOKEN>
<TOKEN end_char="1402" id="token-8-12" morph="none" pos="word" start_char="1399">tiny</TOKEN>
<TOKEN end_char="1410" id="token-8-13" morph="none" pos="word" start_char="1404">changes</TOKEN>
<TOKEN end_char="1416" id="token-8-14" morph="none" pos="word" start_char="1412">occur</TOKEN>
<TOKEN end_char="1419" id="token-8-15" morph="none" pos="word" start_char="1418">in</TOKEN>
<TOKEN end_char="1425" id="token-8-16" morph="none" pos="word" start_char="1421">their</TOKEN>
<TOKEN end_char="1429" id="token-8-17" morph="none" pos="word" start_char="1427">DNA</TOKEN>
<TOKEN end_char="1434" id="token-8-18" morph="none" pos="word" start_char="1431">each</TOKEN>
<TOKEN end_char="1439" id="token-8-19" morph="none" pos="word" start_char="1436">time</TOKEN>
<TOKEN end_char="1444" id="token-8-20" morph="none" pos="word" start_char="1441">they</TOKEN>
<TOKEN end_char="1454" id="token-8-21" morph="none" pos="word" start_char="1446">replicate</TOKEN>
<TOKEN end_char="1465" id="token-8-22" morph="none" pos="word" start_char="1456">themselves</TOKEN>
<TOKEN end_char="1466" id="token-8-23" morph="none" pos="punct" start_char="1466">.</TOKEN>
</SEG>
<SEG end_char="1513" id="segment-9" start_char="1469">
<ORIGINAL_TEXT>China's official timeline vs The new evidence</ORIGINAL_TEXT>
<TOKEN end_char="1475" id="token-9-0" morph="none" pos="word" start_char="1469">China's</TOKEN>
<TOKEN end_char="1484" id="token-9-1" morph="none" pos="word" start_char="1477">official</TOKEN>
<TOKEN end_char="1493" id="token-9-2" morph="none" pos="word" start_char="1486">timeline</TOKEN>
<TOKEN end_char="1496" id="token-9-3" morph="none" pos="word" start_char="1495">vs</TOKEN>
<TOKEN end_char="1500" id="token-9-4" morph="none" pos="word" start_char="1498">The</TOKEN>
<TOKEN end_char="1504" id="token-9-5" morph="none" pos="word" start_char="1502">new</TOKEN>
<TOKEN end_char="1513" id="token-9-6" morph="none" pos="word" start_char="1506">evidence</TOKEN>
</SEG>
<SEG end_char="1533" id="segment-10" start_char="1517">
<ORIGINAL_TEXT>Official timeline</ORIGINAL_TEXT>
<TOKEN end_char="1524" id="token-10-0" morph="none" pos="word" start_char="1517">Official</TOKEN>
<TOKEN end_char="1533" id="token-10-1" morph="none" pos="word" start_char="1526">timeline</TOKEN>
<TRANSLATED_TEXT>Officiel tidspunkt</TRANSLATED_TEXT><DETECTED_LANGUAGE>it</DETECTED_LANGUAGE></SEG>
<SEG end_char="1597" id="segment-11" start_char="1536">
<ORIGINAL_TEXT>Dec 8 - Earliest date that China has acknowledged an infection</ORIGINAL_TEXT>
<TOKEN end_char="1538" id="token-11-0" morph="none" pos="word" start_char="1536">Dec</TOKEN>
<TOKEN end_char="1540" id="token-11-1" morph="none" pos="word" start_char="1540">8</TOKEN>
<TOKEN end_char="1542" id="token-11-2" morph="none" pos="punct" start_char="1542">-</TOKEN>
<TOKEN end_char="1551" id="token-11-3" morph="none" pos="word" start_char="1544">Earliest</TOKEN>
<TOKEN end_char="1556" id="token-11-4" morph="none" pos="word" start_char="1553">date</TOKEN>
<TOKEN end_char="1561" id="token-11-5" morph="none" pos="word" start_char="1558">that</TOKEN>
<TOKEN end_char="1567" id="token-11-6" morph="none" pos="word" start_char="1563">China</TOKEN>
<TOKEN end_char="1571" id="token-11-7" morph="none" pos="word" start_char="1569">has</TOKEN>
<TOKEN end_char="1584" id="token-11-8" morph="none" pos="word" start_char="1573">acknowledged</TOKEN>
<TOKEN end_char="1587" id="token-11-9" morph="none" pos="word" start_char="1586">an</TOKEN>
<TOKEN end_char="1597" id="token-11-10" morph="none" pos="word" start_char="1589">infection</TOKEN>
</SEG>
<SEG end_char="1690" id="segment-12" start_char="1600">
<ORIGINAL_TEXT>Dec 31 - China first reported 'pneumonia of unknown cause' to the World Health Organisation</ORIGINAL_TEXT>
<TOKEN end_char="1602" id="token-12-0" morph="none" pos="word" start_char="1600">Dec</TOKEN>
<TOKEN end_char="1605" id="token-12-1" morph="none" pos="word" start_char="1604">31</TOKEN>
<TOKEN end_char="1607" id="token-12-2" morph="none" pos="punct" start_char="1607">-</TOKEN>
<TOKEN end_char="1613" id="token-12-3" morph="none" pos="word" start_char="1609">China</TOKEN>
<TOKEN end_char="1619" id="token-12-4" morph="none" pos="word" start_char="1615">first</TOKEN>
<TOKEN end_char="1628" id="token-12-5" morph="none" pos="word" start_char="1621">reported</TOKEN>
<TOKEN end_char="1630" id="token-12-6" morph="none" pos="punct" start_char="1630">'</TOKEN>
<TOKEN end_char="1639" id="token-12-7" morph="none" pos="word" start_char="1631">pneumonia</TOKEN>
<TOKEN end_char="1642" id="token-12-8" morph="none" pos="word" start_char="1641">of</TOKEN>
<TOKEN end_char="1650" id="token-12-9" morph="none" pos="word" start_char="1644">unknown</TOKEN>
<TOKEN end_char="1656" id="token-12-10" morph="none" pos="word" start_char="1652">cause</TOKEN>
<TOKEN end_char="1657" id="token-12-11" morph="none" pos="punct" start_char="1657">'</TOKEN>
<TOKEN end_char="1660" id="token-12-12" morph="none" pos="word" start_char="1659">to</TOKEN>
<TOKEN end_char="1664" id="token-12-13" morph="none" pos="word" start_char="1662">the</TOKEN>
<TOKEN end_char="1670" id="token-12-14" morph="none" pos="word" start_char="1666">World</TOKEN>
<TOKEN end_char="1677" id="token-12-15" morph="none" pos="word" start_char="1672">Health</TOKEN>
<TOKEN end_char="1690" id="token-12-16" morph="none" pos="word" start_char="1679">Organisation</TOKEN>
</SEG>
<SEG end_char="1744" id="segment-13" start_char="1693">
<ORIGINAL_TEXT>Jan 1 - Wuhan seafood market closed for disinfection</ORIGINAL_TEXT>
<TOKEN end_char="1695" id="token-13-0" morph="none" pos="word" start_char="1693">Jan</TOKEN>
<TOKEN end_char="1697" id="token-13-1" morph="none" pos="word" start_char="1697">1</TOKEN>
<TOKEN end_char="1699" id="token-13-2" morph="none" pos="punct" start_char="1699">-</TOKEN>
<TOKEN end_char="1705" id="token-13-3" morph="none" pos="word" start_char="1701">Wuhan</TOKEN>
<TOKEN end_char="1713" id="token-13-4" morph="none" pos="word" start_char="1707">seafood</TOKEN>
<TOKEN end_char="1720" id="token-13-5" morph="none" pos="word" start_char="1715">market</TOKEN>
<TOKEN end_char="1727" id="token-13-6" morph="none" pos="word" start_char="1722">closed</TOKEN>
<TOKEN end_char="1731" id="token-13-7" morph="none" pos="word" start_char="1729">for</TOKEN>
<TOKEN end_char="1744" id="token-13-8" morph="none" pos="word" start_char="1733">disinfection</TOKEN>
</SEG>
<SEG end_char="1785" id="segment-14" start_char="1747">
<ORIGINAL_TEXT>Jan 11 - China reported its first death</ORIGINAL_TEXT>
<TOKEN end_char="1749" id="token-14-0" morph="none" pos="word" start_char="1747">Jan</TOKEN>
<TOKEN end_char="1752" id="token-14-1" morph="none" pos="word" start_char="1751">11</TOKEN>
<TOKEN end_char="1754" id="token-14-2" morph="none" pos="punct" start_char="1754">-</TOKEN>
<TOKEN end_char="1760" id="token-14-3" morph="none" pos="word" start_char="1756">China</TOKEN>
<TOKEN end_char="1769" id="token-14-4" morph="none" pos="word" start_char="1762">reported</TOKEN>
<TOKEN end_char="1773" id="token-14-5" morph="none" pos="word" start_char="1771">its</TOKEN>
<TOKEN end_char="1779" id="token-14-6" morph="none" pos="word" start_char="1775">first</TOKEN>
<TOKEN end_char="1785" id="token-14-7" morph="none" pos="word" start_char="1781">death</TOKEN>
</SEG>
<SEG end_char="1813" id="segment-15" start_char="1788">
<ORIGINAL_TEXT>Jan 23 - Wuhan locked down</ORIGINAL_TEXT>
<TOKEN end_char="1790" id="token-15-0" morph="none" pos="word" start_char="1788">Jan</TOKEN>
<TOKEN end_char="1793" id="token-15-1" morph="none" pos="word" start_char="1792">23</TOKEN>
<TOKEN end_char="1795" id="token-15-2" morph="none" pos="punct" start_char="1795">-</TOKEN>
<TOKEN end_char="1801" id="token-15-3" morph="none" pos="word" start_char="1797">Wuhan</TOKEN>
<TOKEN end_char="1808" id="token-15-4" morph="none" pos="word" start_char="1803">locked</TOKEN>
<TOKEN end_char="1813" id="token-15-5" morph="none" pos="word" start_char="1810">down</TOKEN>
</SEG>
<SEG end_char="1916" id="segment-16" start_char="1816">
<ORIGINAL_TEXT>Jan 31 - WHO declared 'outbreak of international concern' as China admitted having thousands of cases</ORIGINAL_TEXT>
<TOKEN end_char="1818" id="token-16-0" morph="none" pos="word" start_char="1816">Jan</TOKEN>
<TOKEN end_char="1821" id="token-16-1" morph="none" pos="word" start_char="1820">31</TOKEN>
<TOKEN end_char="1823" id="token-16-2" morph="none" pos="punct" start_char="1823">-</TOKEN>
<TOKEN end_char="1827" id="token-16-3" morph="none" pos="word" start_char="1825">WHO</TOKEN>
<TOKEN end_char="1836" id="token-16-4" morph="none" pos="word" start_char="1829">declared</TOKEN>
<TOKEN end_char="1838" id="token-16-5" morph="none" pos="punct" start_char="1838">'</TOKEN>
<TOKEN end_char="1846" id="token-16-6" morph="none" pos="word" start_char="1839">outbreak</TOKEN>
<TOKEN end_char="1849" id="token-16-7" morph="none" pos="word" start_char="1848">of</TOKEN>
<TOKEN end_char="1863" id="token-16-8" morph="none" pos="word" start_char="1851">international</TOKEN>
<TOKEN end_char="1871" id="token-16-9" morph="none" pos="word" start_char="1865">concern</TOKEN>
<TOKEN end_char="1872" id="token-16-10" morph="none" pos="punct" start_char="1872">'</TOKEN>
<TOKEN end_char="1875" id="token-16-11" morph="none" pos="word" start_char="1874">as</TOKEN>
<TOKEN end_char="1881" id="token-16-12" morph="none" pos="word" start_char="1877">China</TOKEN>
<TOKEN end_char="1890" id="token-16-13" morph="none" pos="word" start_char="1883">admitted</TOKEN>
<TOKEN end_char="1897" id="token-16-14" morph="none" pos="word" start_char="1892">having</TOKEN>
<TOKEN end_char="1907" id="token-16-15" morph="none" pos="word" start_char="1899">thousands</TOKEN>
<TOKEN end_char="1910" id="token-16-16" morph="none" pos="word" start_char="1909">of</TOKEN>
<TOKEN end_char="1916" id="token-16-17" morph="none" pos="word" start_char="1912">cases</TOKEN>
</SEG>
<SEG end_char="2017" id="segment-17" start_char="1919">
<ORIGINAL_TEXT>Feb 23 - Italy reports cluster of cases in first major outbreak not linked to travellers from China</ORIGINAL_TEXT>
<TOKEN end_char="1921" id="token-17-0" morph="none" pos="word" start_char="1919">Feb</TOKEN>
<TOKEN end_char="1924" id="token-17-1" morph="none" pos="word" start_char="1923">23</TOKEN>
<TOKEN end_char="1926" id="token-17-2" morph="none" pos="punct" start_char="1926">-</TOKEN>
<TOKEN end_char="1932" id="token-17-3" morph="none" pos="word" start_char="1928">Italy</TOKEN>
<TOKEN end_char="1940" id="token-17-4" morph="none" pos="word" start_char="1934">reports</TOKEN>
<TOKEN end_char="1948" id="token-17-5" morph="none" pos="word" start_char="1942">cluster</TOKEN>
<TOKEN end_char="1951" id="token-17-6" morph="none" pos="word" start_char="1950">of</TOKEN>
<TOKEN end_char="1957" id="token-17-7" morph="none" pos="word" start_char="1953">cases</TOKEN>
<TOKEN end_char="1960" id="token-17-8" morph="none" pos="word" start_char="1959">in</TOKEN>
<TOKEN end_char="1966" id="token-17-9" morph="none" pos="word" start_char="1962">first</TOKEN>
<TOKEN end_char="1972" id="token-17-10" morph="none" pos="word" start_char="1968">major</TOKEN>
<TOKEN end_char="1981" id="token-17-11" morph="none" pos="word" start_char="1974">outbreak</TOKEN>
<TOKEN end_char="1985" id="token-17-12" morph="none" pos="word" start_char="1983">not</TOKEN>
<TOKEN end_char="1992" id="token-17-13" morph="none" pos="word" start_char="1987">linked</TOKEN>
<TOKEN end_char="1995" id="token-17-14" morph="none" pos="word" start_char="1994">to</TOKEN>
<TOKEN end_char="2006" id="token-17-15" morph="none" pos="word" start_char="1997">travellers</TOKEN>
<TOKEN end_char="2011" id="token-17-16" morph="none" pos="word" start_char="2008">from</TOKEN>
<TOKEN end_char="2017" id="token-17-17" morph="none" pos="word" start_char="2013">China</TOKEN>
</SEG>
<SEG end_char="2031" id="segment-18" start_char="2020">
<ORIGINAL_TEXT>New evidence</ORIGINAL_TEXT>
<TOKEN end_char="2022" id="token-18-0" morph="none" pos="word" start_char="2020">New</TOKEN>
<TOKEN end_char="2031" id="token-18-1" morph="none" pos="word" start_char="2024">evidence</TOKEN>
</SEG>
<SEG end_char="2101" id="segment-19" start_char="2034">
<ORIGINAL_TEXT>Sep - Blood samples taken in Milan found to contain Covid antibodies</ORIGINAL_TEXT>
<TOKEN end_char="2036" id="token-19-0" morph="none" pos="word" start_char="2034">Sep</TOKEN>
<TOKEN end_char="2038" id="token-19-1" morph="none" pos="punct" start_char="2038">-</TOKEN>
<TOKEN end_char="2044" id="token-19-2" morph="none" pos="word" start_char="2040">Blood</TOKEN>
<TOKEN end_char="2052" id="token-19-3" morph="none" pos="word" start_char="2046">samples</TOKEN>
<TOKEN end_char="2058" id="token-19-4" morph="none" pos="word" start_char="2054">taken</TOKEN>
<TOKEN end_char="2061" id="token-19-5" morph="none" pos="word" start_char="2060">in</TOKEN>
<TOKEN end_char="2067" id="token-19-6" morph="none" pos="word" start_char="2063">Milan</TOKEN>
<TOKEN end_char="2073" id="token-19-7" morph="none" pos="word" start_char="2069">found</TOKEN>
<TOKEN end_char="2076" id="token-19-8" morph="none" pos="word" start_char="2075">to</TOKEN>
<TOKEN end_char="2084" id="token-19-9" morph="none" pos="word" start_char="2078">contain</TOKEN>
<TOKEN end_char="2090" id="token-19-10" morph="none" pos="word" start_char="2086">Covid</TOKEN>
<TOKEN end_char="2101" id="token-19-11" morph="none" pos="word" start_char="2092">antibodies</TOKEN>
</SEG>
<SEG end_char="2210" id="segment-20" start_char="2104">
<ORIGINAL_TEXT>Oct-Dec - Hundreds of 'pneumonia' cases near Milan may be linked to virus, and scientists are investigating</ORIGINAL_TEXT>
<TOKEN end_char="2110" id="token-20-0" morph="none" pos="unknown" start_char="2104">Oct-Dec</TOKEN>
<TOKEN end_char="2112" id="token-20-1" morph="none" pos="punct" start_char="2112">-</TOKEN>
<TOKEN end_char="2121" id="token-20-2" morph="none" pos="word" start_char="2114">Hundreds</TOKEN>
<TOKEN end_char="2124" id="token-20-3" morph="none" pos="word" start_char="2123">of</TOKEN>
<TOKEN end_char="2126" id="token-20-4" morph="none" pos="punct" start_char="2126">'</TOKEN>
<TOKEN end_char="2135" id="token-20-5" morph="none" pos="word" start_char="2127">pneumonia</TOKEN>
<TOKEN end_char="2136" id="token-20-6" morph="none" pos="punct" start_char="2136">'</TOKEN>
<TOKEN end_char="2142" id="token-20-7" morph="none" pos="word" start_char="2138">cases</TOKEN>
<TOKEN end_char="2147" id="token-20-8" morph="none" pos="word" start_char="2144">near</TOKEN>
<TOKEN end_char="2153" id="token-20-9" morph="none" pos="word" start_char="2149">Milan</TOKEN>
<TOKEN end_char="2157" id="token-20-10" morph="none" pos="word" start_char="2155">may</TOKEN>
<TOKEN end_char="2160" id="token-20-11" morph="none" pos="word" start_char="2159">be</TOKEN>
<TOKEN end_char="2167" id="token-20-12" morph="none" pos="word" start_char="2162">linked</TOKEN>
<TOKEN end_char="2170" id="token-20-13" morph="none" pos="word" start_char="2169">to</TOKEN>
<TOKEN end_char="2176" id="token-20-14" morph="none" pos="word" start_char="2172">virus</TOKEN>
<TOKEN end_char="2177" id="token-20-15" morph="none" pos="punct" start_char="2177">,</TOKEN>
<TOKEN end_char="2181" id="token-20-16" morph="none" pos="word" start_char="2179">and</TOKEN>
<TOKEN end_char="2192" id="token-20-17" morph="none" pos="word" start_char="2183">scientists</TOKEN>
<TOKEN end_char="2196" id="token-20-18" morph="none" pos="word" start_char="2194">are</TOKEN>
<TOKEN end_char="2210" id="token-20-19" morph="none" pos="word" start_char="2198">investigating</TOKEN>
</SEG>
<SEG end_char="2317" id="segment-21" start_char="2213">
<ORIGINAL_TEXT>Nov - Sewage samples taken in Florianópolis, Brazil, suggest virus was present and are being investigated</ORIGINAL_TEXT>
<TOKEN end_char="2215" id="token-21-0" morph="none" pos="word" start_char="2213">Nov</TOKEN>
<TOKEN end_char="2217" id="token-21-1" morph="none" pos="punct" start_char="2217">-</TOKEN>
<TOKEN end_char="2224" id="token-21-2" morph="none" pos="word" start_char="2219">Sewage</TOKEN>
<TOKEN end_char="2232" id="token-21-3" morph="none" pos="word" start_char="2226">samples</TOKEN>
<TOKEN end_char="2238" id="token-21-4" morph="none" pos="word" start_char="2234">taken</TOKEN>
<TOKEN end_char="2241" id="token-21-5" morph="none" pos="word" start_char="2240">in</TOKEN>
<TOKEN end_char="2255" id="token-21-6" morph="none" pos="word" start_char="2243">Florianópolis</TOKEN>
<TOKEN end_char="2256" id="token-21-7" morph="none" pos="punct" start_char="2256">,</TOKEN>
<TOKEN end_char="2263" id="token-21-8" morph="none" pos="word" start_char="2258">Brazil</TOKEN>
<TOKEN end_char="2264" id="token-21-9" morph="none" pos="punct" start_char="2264">,</TOKEN>
<TOKEN end_char="2272" id="token-21-10" morph="none" pos="word" start_char="2266">suggest</TOKEN>
<TOKEN end_char="2278" id="token-21-11" morph="none" pos="word" start_char="2274">virus</TOKEN>
<TOKEN end_char="2282" id="token-21-12" morph="none" pos="word" start_char="2280">was</TOKEN>
<TOKEN end_char="2290" id="token-21-13" morph="none" pos="word" start_char="2284">present</TOKEN>
<TOKEN end_char="2294" id="token-21-14" morph="none" pos="word" start_char="2292">and</TOKEN>
<TOKEN end_char="2298" id="token-21-15" morph="none" pos="word" start_char="2296">are</TOKEN>
<TOKEN end_char="2304" id="token-21-16" morph="none" pos="word" start_char="2300">being</TOKEN>
<TOKEN end_char="2317" id="token-21-17" morph="none" pos="word" start_char="2306">investigated</TOKEN>
</SEG>
<SEG end_char="2388" id="segment-22" start_char="2320">
<ORIGINAL_TEXT>Nov 17 - Leaked documents suggest case detected in China on this date</ORIGINAL_TEXT>
<TOKEN end_char="2322" id="token-22-0" morph="none" pos="word" start_char="2320">Nov</TOKEN>
<TOKEN end_char="2325" id="token-22-1" morph="none" pos="word" start_char="2324">17</TOKEN>
<TOKEN end_char="2327" id="token-22-2" morph="none" pos="punct" start_char="2327">-</TOKEN>
<TOKEN end_char="2334" id="token-22-3" morph="none" pos="word" start_char="2329">Leaked</TOKEN>
<TOKEN end_char="2344" id="token-22-4" morph="none" pos="word" start_char="2336">documents</TOKEN>
<TOKEN end_char="2352" id="token-22-5" morph="none" pos="word" start_char="2346">suggest</TOKEN>
<TOKEN end_char="2357" id="token-22-6" morph="none" pos="word" start_char="2354">case</TOKEN>
<TOKEN end_char="2366" id="token-22-7" morph="none" pos="word" start_char="2359">detected</TOKEN>
<TOKEN end_char="2369" id="token-22-8" morph="none" pos="word" start_char="2368">in</TOKEN>
<TOKEN end_char="2375" id="token-22-9" morph="none" pos="word" start_char="2371">China</TOKEN>
<TOKEN end_char="2378" id="token-22-10" morph="none" pos="word" start_char="2377">on</TOKEN>
<TOKEN end_char="2383" id="token-22-11" morph="none" pos="word" start_char="2380">this</TOKEN>
<TOKEN end_char="2388" id="token-22-12" morph="none" pos="word" start_char="2385">date</TOKEN>
</SEG>
<SEG end_char="2520" id="segment-23" start_char="2391">
<ORIGINAL_TEXT>Dec 1 - Chinese researchers report an infection on this date in a peer-reviewed study, but it has not been acknowledged by Beijing</ORIGINAL_TEXT>
<TOKEN end_char="2393" id="token-23-0" morph="none" pos="word" start_char="2391">Dec</TOKEN>
<TOKEN end_char="2395" id="token-23-1" morph="none" pos="word" start_char="2395">1</TOKEN>
<TOKEN end_char="2397" id="token-23-2" morph="none" pos="punct" start_char="2397">-</TOKEN>
<TOKEN end_char="2405" id="token-23-3" morph="none" pos="word" start_char="2399">Chinese</TOKEN>
<TOKEN end_char="2417" id="token-23-4" morph="none" pos="word" start_char="2407">researchers</TOKEN>
<TOKEN end_char="2424" id="token-23-5" morph="none" pos="word" start_char="2419">report</TOKEN>
<TOKEN end_char="2427" id="token-23-6" morph="none" pos="word" start_char="2426">an</TOKEN>
<TOKEN end_char="2437" id="token-23-7" morph="none" pos="word" start_char="2429">infection</TOKEN>
<TOKEN end_char="2440" id="token-23-8" morph="none" pos="word" start_char="2439">on</TOKEN>
<TOKEN end_char="2445" id="token-23-9" morph="none" pos="word" start_char="2442">this</TOKEN>
<TOKEN end_char="2450" id="token-23-10" morph="none" pos="word" start_char="2447">date</TOKEN>
<TOKEN end_char="2453" id="token-23-11" morph="none" pos="word" start_char="2452">in</TOKEN>
<TOKEN end_char="2455" id="token-23-12" morph="none" pos="word" start_char="2455">a</TOKEN>
<TOKEN end_char="2469" id="token-23-13" morph="none" pos="unknown" start_char="2457">peer-reviewed</TOKEN>
<TOKEN end_char="2475" id="token-23-14" morph="none" pos="word" start_char="2471">study</TOKEN>
<TOKEN end_char="2476" id="token-23-15" morph="none" pos="punct" start_char="2476">,</TOKEN>
<TOKEN end_char="2480" id="token-23-16" morph="none" pos="word" start_char="2478">but</TOKEN>
<TOKEN end_char="2483" id="token-23-17" morph="none" pos="word" start_char="2482">it</TOKEN>
<TOKEN end_char="2487" id="token-23-18" morph="none" pos="word" start_char="2485">has</TOKEN>
<TOKEN end_char="2491" id="token-23-19" morph="none" pos="word" start_char="2489">not</TOKEN>
<TOKEN end_char="2496" id="token-23-20" morph="none" pos="word" start_char="2493">been</TOKEN>
<TOKEN end_char="2509" id="token-23-21" morph="none" pos="word" start_char="2498">acknowledged</TOKEN>
<TOKEN end_char="2512" id="token-23-22" morph="none" pos="word" start_char="2511">by</TOKEN>
<TOKEN end_char="2520" id="token-23-23" morph="none" pos="word" start_char="2514">Beijing</TOKEN>
</SEG>
<SEG end_char="2614" id="segment-24" start_char="2523">
<ORIGINAL_TEXT>Dec 18 - Sewage samples taken in Milan and Turin suggest virus was circulating in the cities</ORIGINAL_TEXT>
<TOKEN end_char="2525" id="token-24-0" morph="none" pos="word" start_char="2523">Dec</TOKEN>
<TOKEN end_char="2528" id="token-24-1" morph="none" pos="word" start_char="2527">18</TOKEN>
<TOKEN end_char="2530" id="token-24-2" morph="none" pos="punct" start_char="2530">-</TOKEN>
<TOKEN end_char="2537" id="token-24-3" morph="none" pos="word" start_char="2532">Sewage</TOKEN>
<TOKEN end_char="2545" id="token-24-4" morph="none" pos="word" start_char="2539">samples</TOKEN>
<TOKEN end_char="2551" id="token-24-5" morph="none" pos="word" start_char="2547">taken</TOKEN>
<TOKEN end_char="2554" id="token-24-6" morph="none" pos="word" start_char="2553">in</TOKEN>
<TOKEN end_char="2560" id="token-24-7" morph="none" pos="word" start_char="2556">Milan</TOKEN>
<TOKEN end_char="2564" id="token-24-8" morph="none" pos="word" start_char="2562">and</TOKEN>
<TOKEN end_char="2570" id="token-24-9" morph="none" pos="word" start_char="2566">Turin</TOKEN>
<TOKEN end_char="2578" id="token-24-10" morph="none" pos="word" start_char="2572">suggest</TOKEN>
<TOKEN end_char="2584" id="token-24-11" morph="none" pos="word" start_char="2580">virus</TOKEN>
<TOKEN end_char="2588" id="token-24-12" morph="none" pos="word" start_char="2586">was</TOKEN>
<TOKEN end_char="2600" id="token-24-13" morph="none" pos="word" start_char="2590">circulating</TOKEN>
<TOKEN end_char="2603" id="token-24-14" morph="none" pos="word" start_char="2602">in</TOKEN>
<TOKEN end_char="2607" id="token-24-15" morph="none" pos="word" start_char="2605">the</TOKEN>
<TOKEN end_char="2614" id="token-24-16" morph="none" pos="word" start_char="2609">cities</TOKEN>
</SEG>
<SEG end_char="2686" id="segment-25" start_char="2617">
<ORIGINAL_TEXT>Jan 2020 - Sewage samples from Barcelona suggest virus was in the city</ORIGINAL_TEXT>
<TOKEN end_char="2619" id="token-25-0" morph="none" pos="word" start_char="2617">Jan</TOKEN>
<TOKEN end_char="2624" id="token-25-1" morph="none" pos="word" start_char="2621">2020</TOKEN>
<TOKEN end_char="2626" id="token-25-2" morph="none" pos="punct" start_char="2626">-</TOKEN>
<TOKEN end_char="2633" id="token-25-3" morph="none" pos="word" start_char="2628">Sewage</TOKEN>
<TOKEN end_char="2641" id="token-25-4" morph="none" pos="word" start_char="2635">samples</TOKEN>
<TOKEN end_char="2646" id="token-25-5" morph="none" pos="word" start_char="2643">from</TOKEN>
<TOKEN end_char="2656" id="token-25-6" morph="none" pos="word" start_char="2648">Barcelona</TOKEN>
<TOKEN end_char="2664" id="token-25-7" morph="none" pos="word" start_char="2658">suggest</TOKEN>
<TOKEN end_char="2670" id="token-25-8" morph="none" pos="word" start_char="2666">virus</TOKEN>
<TOKEN end_char="2674" id="token-25-9" morph="none" pos="word" start_char="2672">was</TOKEN>
<TOKEN end_char="2677" id="token-25-10" morph="none" pos="word" start_char="2676">in</TOKEN>
<TOKEN end_char="2681" id="token-25-11" morph="none" pos="word" start_char="2679">the</TOKEN>
<TOKEN end_char="2686" id="token-25-12" morph="none" pos="word" start_char="2683">city</TOKEN>
</SEG>
<SEG end_char="2701" id="segment-26" start_char="2689">
<ORIGINAL_TEXT>Advertisement</ORIGINAL_TEXT>
<TOKEN end_char="2701" id="token-26-0" morph="none" pos="word" start_char="2689">Advertisement</TOKEN>
<TRANSLATED_TEXT>Publicatie</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="2857" id="segment-27" start_char="2704">
<ORIGINAL_TEXT>The scientists argue that it should therefore be possible to track down the original version of the virus by finding the sample with the fewest mutations.</ORIGINAL_TEXT>
<TOKEN end_char="2706" id="token-27-0" morph="none" pos="word" start_char="2704">The</TOKEN>
<TOKEN end_char="2717" id="token-27-1" morph="none" pos="word" start_char="2708">scientists</TOKEN>
<TOKEN end_char="2723" id="token-27-2" morph="none" pos="word" start_char="2719">argue</TOKEN>
<TOKEN end_char="2728" id="token-27-3" morph="none" pos="word" start_char="2725">that</TOKEN>
<TOKEN end_char="2731" id="token-27-4" morph="none" pos="word" start_char="2730">it</TOKEN>
<TOKEN end_char="2738" id="token-27-5" morph="none" pos="word" start_char="2733">should</TOKEN>
<TOKEN end_char="2748" id="token-27-6" morph="none" pos="word" start_char="2740">therefore</TOKEN>
<TOKEN end_char="2751" id="token-27-7" morph="none" pos="word" start_char="2750">be</TOKEN>
<TOKEN end_char="2760" id="token-27-8" morph="none" pos="word" start_char="2753">possible</TOKEN>
<TOKEN end_char="2763" id="token-27-9" morph="none" pos="word" start_char="2762">to</TOKEN>
<TOKEN end_char="2769" id="token-27-10" morph="none" pos="word" start_char="2765">track</TOKEN>
<TOKEN end_char="2774" id="token-27-11" morph="none" pos="word" start_char="2771">down</TOKEN>
<TOKEN end_char="2778" id="token-27-12" morph="none" pos="word" start_char="2776">the</TOKEN>
<TOKEN end_char="2787" id="token-27-13" morph="none" pos="word" start_char="2780">original</TOKEN>
<TOKEN end_char="2795" id="token-27-14" morph="none" pos="word" start_char="2789">version</TOKEN>
<TOKEN end_char="2798" id="token-27-15" morph="none" pos="word" start_char="2797">of</TOKEN>
<TOKEN end_char="2802" id="token-27-16" morph="none" pos="word" start_char="2800">the</TOKEN>
<TOKEN end_char="2808" id="token-27-17" morph="none" pos="word" start_char="2804">virus</TOKEN>
<TOKEN end_char="2811" id="token-27-18" morph="none" pos="word" start_char="2810">by</TOKEN>
<TOKEN end_char="2819" id="token-27-19" morph="none" pos="word" start_char="2813">finding</TOKEN>
<TOKEN end_char="2823" id="token-27-20" morph="none" pos="word" start_char="2821">the</TOKEN>
<TOKEN end_char="2830" id="token-27-21" morph="none" pos="word" start_char="2825">sample</TOKEN>
<TOKEN end_char="2835" id="token-27-22" morph="none" pos="word" start_char="2832">with</TOKEN>
<TOKEN end_char="2839" id="token-27-23" morph="none" pos="word" start_char="2837">the</TOKEN>
<TOKEN end_char="2846" id="token-27-24" morph="none" pos="word" start_char="2841">fewest</TOKEN>
<TOKEN end_char="2856" id="token-27-25" morph="none" pos="word" start_char="2848">mutations</TOKEN>
<TOKEN end_char="2857" id="token-27-26" morph="none" pos="punct" start_char="2857">.</TOKEN>
</SEG>
<SEG end_char="3083" id="segment-28" start_char="2860">
<ORIGINAL_TEXT>They say that using this method rules out the virus found in Wuhan as the 'original' virus, and instead points to eight other countries: Bangladesh, the USA, Greece, Australia, India, Italy, Czech Republic, Russia or Serbia.</ORIGINAL_TEXT>
<TOKEN end_char="2863" id="token-28-0" morph="none" pos="word" start_char="2860">They</TOKEN>
<TOKEN end_char="2867" id="token-28-1" morph="none" pos="word" start_char="2865">say</TOKEN>
<TOKEN end_char="2872" id="token-28-2" morph="none" pos="word" start_char="2869">that</TOKEN>
<TOKEN end_char="2878" id="token-28-3" morph="none" pos="word" start_char="2874">using</TOKEN>
<TOKEN end_char="2883" id="token-28-4" morph="none" pos="word" start_char="2880">this</TOKEN>
<TOKEN end_char="2890" id="token-28-5" morph="none" pos="word" start_char="2885">method</TOKEN>
<TOKEN end_char="2896" id="token-28-6" morph="none" pos="word" start_char="2892">rules</TOKEN>
<TOKEN end_char="2900" id="token-28-7" morph="none" pos="word" start_char="2898">out</TOKEN>
<TOKEN end_char="2904" id="token-28-8" morph="none" pos="word" start_char="2902">the</TOKEN>
<TOKEN end_char="2910" id="token-28-9" morph="none" pos="word" start_char="2906">virus</TOKEN>
<TOKEN end_char="2916" id="token-28-10" morph="none" pos="word" start_char="2912">found</TOKEN>
<TOKEN end_char="2919" id="token-28-11" morph="none" pos="word" start_char="2918">in</TOKEN>
<TOKEN end_char="2925" id="token-28-12" morph="none" pos="word" start_char="2921">Wuhan</TOKEN>
<TOKEN end_char="2928" id="token-28-13" morph="none" pos="word" start_char="2927">as</TOKEN>
<TOKEN end_char="2932" id="token-28-14" morph="none" pos="word" start_char="2930">the</TOKEN>
<TOKEN end_char="2934" id="token-28-15" morph="none" pos="punct" start_char="2934">'</TOKEN>
<TOKEN end_char="2942" id="token-28-16" morph="none" pos="word" start_char="2935">original</TOKEN>
<TOKEN end_char="2943" id="token-28-17" morph="none" pos="punct" start_char="2943">'</TOKEN>
<TOKEN end_char="2949" id="token-28-18" morph="none" pos="word" start_char="2945">virus</TOKEN>
<TOKEN end_char="2950" id="token-28-19" morph="none" pos="punct" start_char="2950">,</TOKEN>
<TOKEN end_char="2954" id="token-28-20" morph="none" pos="word" start_char="2952">and</TOKEN>
<TOKEN end_char="2962" id="token-28-21" morph="none" pos="word" start_char="2956">instead</TOKEN>
<TOKEN end_char="2969" id="token-28-22" morph="none" pos="word" start_char="2964">points</TOKEN>
<TOKEN end_char="2972" id="token-28-23" morph="none" pos="word" start_char="2971">to</TOKEN>
<TOKEN end_char="2978" id="token-28-24" morph="none" pos="word" start_char="2974">eight</TOKEN>
<TOKEN end_char="2984" id="token-28-25" morph="none" pos="word" start_char="2980">other</TOKEN>
<TOKEN end_char="2994" id="token-28-26" morph="none" pos="word" start_char="2986">countries</TOKEN>
<TOKEN end_char="2995" id="token-28-27" morph="none" pos="punct" start_char="2995">:</TOKEN>
<TOKEN end_char="3006" id="token-28-28" morph="none" pos="word" start_char="2997">Bangladesh</TOKEN>
<TOKEN end_char="3007" id="token-28-29" morph="none" pos="punct" start_char="3007">,</TOKEN>
<TOKEN end_char="3011" id="token-28-30" morph="none" pos="word" start_char="3009">the</TOKEN>
<TOKEN end_char="3015" id="token-28-31" morph="none" pos="word" start_char="3013">USA</TOKEN>
<TOKEN end_char="3016" id="token-28-32" morph="none" pos="punct" start_char="3016">,</TOKEN>
<TOKEN end_char="3023" id="token-28-33" morph="none" pos="word" start_char="3018">Greece</TOKEN>
<TOKEN end_char="3024" id="token-28-34" morph="none" pos="punct" start_char="3024">,</TOKEN>
<TOKEN end_char="3034" id="token-28-35" morph="none" pos="word" start_char="3026">Australia</TOKEN>
<TOKEN end_char="3035" id="token-28-36" morph="none" pos="punct" start_char="3035">,</TOKEN>
<TOKEN end_char="3041" id="token-28-37" morph="none" pos="word" start_char="3037">India</TOKEN>
<TOKEN end_char="3042" id="token-28-38" morph="none" pos="punct" start_char="3042">,</TOKEN>
<TOKEN end_char="3048" id="token-28-39" morph="none" pos="word" start_char="3044">Italy</TOKEN>
<TOKEN end_char="3049" id="token-28-40" morph="none" pos="punct" start_char="3049">,</TOKEN>
<TOKEN end_char="3055" id="token-28-41" morph="none" pos="word" start_char="3051">Czech</TOKEN>
<TOKEN end_char="3064" id="token-28-42" morph="none" pos="word" start_char="3057">Republic</TOKEN>
<TOKEN end_char="3065" id="token-28-43" morph="none" pos="punct" start_char="3065">,</TOKEN>
<TOKEN end_char="3072" id="token-28-44" morph="none" pos="word" start_char="3067">Russia</TOKEN>
<TOKEN end_char="3075" id="token-28-45" morph="none" pos="word" start_char="3074">or</TOKEN>
<TOKEN end_char="3082" id="token-28-46" morph="none" pos="word" start_char="3077">Serbia</TOKEN>
<TOKEN end_char="3083" id="token-28-47" morph="none" pos="punct" start_char="3083">.</TOKEN>
</SEG>
<SEG end_char="3274" id="segment-29" start_char="3086">
<ORIGINAL_TEXT>Researchers go on to argue that because India and Bangladesh both recorded samples with low mutations and are geographic neighbours, it is likely that the first transmission occurred there.</ORIGINAL_TEXT>
<TOKEN end_char="3096" id="token-29-0" morph="none" pos="word" start_char="3086">Researchers</TOKEN>
<TOKEN end_char="3099" id="token-29-1" morph="none" pos="word" start_char="3098">go</TOKEN>
<TOKEN end_char="3102" id="token-29-2" morph="none" pos="word" start_char="3101">on</TOKEN>
<TOKEN end_char="3105" id="token-29-3" morph="none" pos="word" start_char="3104">to</TOKEN>
<TOKEN end_char="3111" id="token-29-4" morph="none" pos="word" start_char="3107">argue</TOKEN>
<TOKEN end_char="3116" id="token-29-5" morph="none" pos="word" start_char="3113">that</TOKEN>
<TOKEN end_char="3124" id="token-29-6" morph="none" pos="word" start_char="3118">because</TOKEN>
<TOKEN end_char="3130" id="token-29-7" morph="none" pos="word" start_char="3126">India</TOKEN>
<TOKEN end_char="3134" id="token-29-8" morph="none" pos="word" start_char="3132">and</TOKEN>
<TOKEN end_char="3145" id="token-29-9" morph="none" pos="word" start_char="3136">Bangladesh</TOKEN>
<TOKEN end_char="3150" id="token-29-10" morph="none" pos="word" start_char="3147">both</TOKEN>
<TOKEN end_char="3159" id="token-29-11" morph="none" pos="word" start_char="3152">recorded</TOKEN>
<TOKEN end_char="3167" id="token-29-12" morph="none" pos="word" start_char="3161">samples</TOKEN>
<TOKEN end_char="3172" id="token-29-13" morph="none" pos="word" start_char="3169">with</TOKEN>
<TOKEN end_char="3176" id="token-29-14" morph="none" pos="word" start_char="3174">low</TOKEN>
<TOKEN end_char="3186" id="token-29-15" morph="none" pos="word" start_char="3178">mutations</TOKEN>
<TOKEN end_char="3190" id="token-29-16" morph="none" pos="word" start_char="3188">and</TOKEN>
<TOKEN end_char="3194" id="token-29-17" morph="none" pos="word" start_char="3192">are</TOKEN>
<TOKEN end_char="3205" id="token-29-18" morph="none" pos="word" start_char="3196">geographic</TOKEN>
<TOKEN end_char="3216" id="token-29-19" morph="none" pos="word" start_char="3207">neighbours</TOKEN>
<TOKEN end_char="3217" id="token-29-20" morph="none" pos="punct" start_char="3217">,</TOKEN>
<TOKEN end_char="3220" id="token-29-21" morph="none" pos="word" start_char="3219">it</TOKEN>
<TOKEN end_char="3223" id="token-29-22" morph="none" pos="word" start_char="3222">is</TOKEN>
<TOKEN end_char="3230" id="token-29-23" morph="none" pos="word" start_char="3225">likely</TOKEN>
<TOKEN end_char="3235" id="token-29-24" morph="none" pos="word" start_char="3232">that</TOKEN>
<TOKEN end_char="3239" id="token-29-25" morph="none" pos="word" start_char="3237">the</TOKEN>
<TOKEN end_char="3245" id="token-29-26" morph="none" pos="word" start_char="3241">first</TOKEN>
<TOKEN end_char="3258" id="token-29-27" morph="none" pos="word" start_char="3247">transmission</TOKEN>
<TOKEN end_char="3267" id="token-29-28" morph="none" pos="word" start_char="3260">occurred</TOKEN>
<TOKEN end_char="3273" id="token-29-29" morph="none" pos="word" start_char="3269">there</TOKEN>
<TOKEN end_char="3274" id="token-29-30" morph="none" pos="punct" start_char="3274">.</TOKEN>
</SEG>
<SEG end_char="3472" id="segment-30" start_char="3277">
<ORIGINAL_TEXT>By estimating the amount of time it takes for the virus to mutate once, and comparing that to the samples taken there, they also theorise that the virus first emerged there in July or August 2019.</ORIGINAL_TEXT>
<TOKEN end_char="3278" id="token-30-0" morph="none" pos="word" start_char="3277">By</TOKEN>
<TOKEN end_char="3289" id="token-30-1" morph="none" pos="word" start_char="3280">estimating</TOKEN>
<TOKEN end_char="3293" id="token-30-2" morph="none" pos="word" start_char="3291">the</TOKEN>
<TOKEN end_char="3300" id="token-30-3" morph="none" pos="word" start_char="3295">amount</TOKEN>
<TOKEN end_char="3303" id="token-30-4" morph="none" pos="word" start_char="3302">of</TOKEN>
<TOKEN end_char="3308" id="token-30-5" morph="none" pos="word" start_char="3305">time</TOKEN>
<TOKEN end_char="3311" id="token-30-6" morph="none" pos="word" start_char="3310">it</TOKEN>
<TOKEN end_char="3317" id="token-30-7" morph="none" pos="word" start_char="3313">takes</TOKEN>
<TOKEN end_char="3321" id="token-30-8" morph="none" pos="word" start_char="3319">for</TOKEN>
<TOKEN end_char="3325" id="token-30-9" morph="none" pos="word" start_char="3323">the</TOKEN>
<TOKEN end_char="3331" id="token-30-10" morph="none" pos="word" start_char="3327">virus</TOKEN>
<TOKEN end_char="3334" id="token-30-11" morph="none" pos="word" start_char="3333">to</TOKEN>
<TOKEN end_char="3341" id="token-30-12" morph="none" pos="word" start_char="3336">mutate</TOKEN>
<TOKEN end_char="3346" id="token-30-13" morph="none" pos="word" start_char="3343">once</TOKEN>
<TOKEN end_char="3347" id="token-30-14" morph="none" pos="punct" start_char="3347">,</TOKEN>
<TOKEN end_char="3351" id="token-30-15" morph="none" pos="word" start_char="3349">and</TOKEN>
<TOKEN end_char="3361" id="token-30-16" morph="none" pos="word" start_char="3353">comparing</TOKEN>
<TOKEN end_char="3366" id="token-30-17" morph="none" pos="word" start_char="3363">that</TOKEN>
<TOKEN end_char="3369" id="token-30-18" morph="none" pos="word" start_char="3368">to</TOKEN>
<TOKEN end_char="3373" id="token-30-19" morph="none" pos="word" start_char="3371">the</TOKEN>
<TOKEN end_char="3381" id="token-30-20" morph="none" pos="word" start_char="3375">samples</TOKEN>
<TOKEN end_char="3387" id="token-30-21" morph="none" pos="word" start_char="3383">taken</TOKEN>
<TOKEN end_char="3393" id="token-30-22" morph="none" pos="word" start_char="3389">there</TOKEN>
<TOKEN end_char="3394" id="token-30-23" morph="none" pos="punct" start_char="3394">,</TOKEN>
<TOKEN end_char="3399" id="token-30-24" morph="none" pos="word" start_char="3396">they</TOKEN>
<TOKEN end_char="3404" id="token-30-25" morph="none" pos="word" start_char="3401">also</TOKEN>
<TOKEN end_char="3413" id="token-30-26" morph="none" pos="word" start_char="3406">theorise</TOKEN>
<TOKEN end_char="3418" id="token-30-27" morph="none" pos="word" start_char="3415">that</TOKEN>
<TOKEN end_char="3422" id="token-30-28" morph="none" pos="word" start_char="3420">the</TOKEN>
<TOKEN end_char="3428" id="token-30-29" morph="none" pos="word" start_char="3424">virus</TOKEN>
<TOKEN end_char="3434" id="token-30-30" morph="none" pos="word" start_char="3430">first</TOKEN>
<TOKEN end_char="3442" id="token-30-31" morph="none" pos="word" start_char="3436">emerged</TOKEN>
<TOKEN end_char="3448" id="token-30-32" morph="none" pos="word" start_char="3444">there</TOKEN>
<TOKEN end_char="3451" id="token-30-33" morph="none" pos="word" start_char="3450">in</TOKEN>
<TOKEN end_char="3456" id="token-30-34" morph="none" pos="word" start_char="3453">July</TOKEN>
<TOKEN end_char="3459" id="token-30-35" morph="none" pos="word" start_char="3458">or</TOKEN>
<TOKEN end_char="3466" id="token-30-36" morph="none" pos="word" start_char="3461">August</TOKEN>
<TOKEN end_char="3471" id="token-30-37" morph="none" pos="word" start_char="3468">2019</TOKEN>
<TOKEN end_char="3472" id="token-30-38" morph="none" pos="punct" start_char="3472">.</TOKEN>
</SEG>
<SEG end_char="3660" id="segment-31" start_char="3475">
<ORIGINAL_TEXT>They go on to say: 'From May to June 2019, the second longest recorded heat wave had rampaged in northern-central India and Pakistan, which created a serious water crisis in this region.</ORIGINAL_TEXT>
<TOKEN end_char="3478" id="token-31-0" morph="none" pos="word" start_char="3475">They</TOKEN>
<TOKEN end_char="3481" id="token-31-1" morph="none" pos="word" start_char="3480">go</TOKEN>
<TOKEN end_char="3484" id="token-31-2" morph="none" pos="word" start_char="3483">on</TOKEN>
<TOKEN end_char="3487" id="token-31-3" morph="none" pos="word" start_char="3486">to</TOKEN>
<TOKEN end_char="3491" id="token-31-4" morph="none" pos="word" start_char="3489">say</TOKEN>
<TOKEN end_char="3492" id="token-31-5" morph="none" pos="punct" start_char="3492">:</TOKEN>
<TOKEN end_char="3494" id="token-31-6" morph="none" pos="punct" start_char="3494">'</TOKEN>
<TOKEN end_char="3498" id="token-31-7" morph="none" pos="word" start_char="3495">From</TOKEN>
<TOKEN end_char="3502" id="token-31-8" morph="none" pos="word" start_char="3500">May</TOKEN>
<TOKEN end_char="3505" id="token-31-9" morph="none" pos="word" start_char="3504">to</TOKEN>
<TOKEN end_char="3510" id="token-31-10" morph="none" pos="word" start_char="3507">June</TOKEN>
<TOKEN end_char="3515" id="token-31-11" morph="none" pos="word" start_char="3512">2019</TOKEN>
<TOKEN end_char="3516" id="token-31-12" morph="none" pos="punct" start_char="3516">,</TOKEN>
<TOKEN end_char="3520" id="token-31-13" morph="none" pos="word" start_char="3518">the</TOKEN>
<TOKEN end_char="3527" id="token-31-14" morph="none" pos="word" start_char="3522">second</TOKEN>
<TOKEN end_char="3535" id="token-31-15" morph="none" pos="word" start_char="3529">longest</TOKEN>
<TOKEN end_char="3544" id="token-31-16" morph="none" pos="word" start_char="3537">recorded</TOKEN>
<TOKEN end_char="3549" id="token-31-17" morph="none" pos="word" start_char="3546">heat</TOKEN>
<TOKEN end_char="3554" id="token-31-18" morph="none" pos="word" start_char="3551">wave</TOKEN>
<TOKEN end_char="3558" id="token-31-19" morph="none" pos="word" start_char="3556">had</TOKEN>
<TOKEN end_char="3567" id="token-31-20" morph="none" pos="word" start_char="3560">rampaged</TOKEN>
<TOKEN end_char="3570" id="token-31-21" morph="none" pos="word" start_char="3569">in</TOKEN>
<TOKEN end_char="3587" id="token-31-22" morph="none" pos="unknown" start_char="3572">northern-central</TOKEN>
<TOKEN end_char="3593" id="token-31-23" morph="none" pos="word" start_char="3589">India</TOKEN>
<TOKEN end_char="3597" id="token-31-24" morph="none" pos="word" start_char="3595">and</TOKEN>
<TOKEN end_char="3606" id="token-31-25" morph="none" pos="word" start_char="3599">Pakistan</TOKEN>
<TOKEN end_char="3607" id="token-31-26" morph="none" pos="punct" start_char="3607">,</TOKEN>
<TOKEN end_char="3613" id="token-31-27" morph="none" pos="word" start_char="3609">which</TOKEN>
<TOKEN end_char="3621" id="token-31-28" morph="none" pos="word" start_char="3615">created</TOKEN>
<TOKEN end_char="3623" id="token-31-29" morph="none" pos="word" start_char="3623">a</TOKEN>
<TOKEN end_char="3631" id="token-31-30" morph="none" pos="word" start_char="3625">serious</TOKEN>
<TOKEN end_char="3637" id="token-31-31" morph="none" pos="word" start_char="3633">water</TOKEN>
<TOKEN end_char="3644" id="token-31-32" morph="none" pos="word" start_char="3639">crisis</TOKEN>
<TOKEN end_char="3647" id="token-31-33" morph="none" pos="word" start_char="3646">in</TOKEN>
<TOKEN end_char="3652" id="token-31-34" morph="none" pos="word" start_char="3649">this</TOKEN>
<TOKEN end_char="3659" id="token-31-35" morph="none" pos="word" start_char="3654">region</TOKEN>
<TOKEN end_char="3660" id="token-31-36" morph="none" pos="punct" start_char="3660">.</TOKEN>
</SEG>
<SEG end_char="3848" id="segment-32" start_char="3663">
<ORIGINAL_TEXT>'The water shortage made wild animals such as monkeys engage in the deadly fight over water among each other and would have surely increased the chance of human-wild animal interactions.</ORIGINAL_TEXT>
<TOKEN end_char="3663" id="token-32-0" morph="none" pos="punct" start_char="3663">'</TOKEN>
<TOKEN end_char="3666" id="token-32-1" morph="none" pos="word" start_char="3664">The</TOKEN>
<TOKEN end_char="3672" id="token-32-2" morph="none" pos="word" start_char="3668">water</TOKEN>
<TOKEN end_char="3681" id="token-32-3" morph="none" pos="word" start_char="3674">shortage</TOKEN>
<TOKEN end_char="3686" id="token-32-4" morph="none" pos="word" start_char="3683">made</TOKEN>
<TOKEN end_char="3691" id="token-32-5" morph="none" pos="word" start_char="3688">wild</TOKEN>
<TOKEN end_char="3699" id="token-32-6" morph="none" pos="word" start_char="3693">animals</TOKEN>
<TOKEN end_char="3704" id="token-32-7" morph="none" pos="word" start_char="3701">such</TOKEN>
<TOKEN end_char="3707" id="token-32-8" morph="none" pos="word" start_char="3706">as</TOKEN>
<TOKEN end_char="3715" id="token-32-9" morph="none" pos="word" start_char="3709">monkeys</TOKEN>
<TOKEN end_char="3722" id="token-32-10" morph="none" pos="word" start_char="3717">engage</TOKEN>
<TOKEN end_char="3725" id="token-32-11" morph="none" pos="word" start_char="3724">in</TOKEN>
<TOKEN end_char="3729" id="token-32-12" morph="none" pos="word" start_char="3727">the</TOKEN>
<TOKEN end_char="3736" id="token-32-13" morph="none" pos="word" start_char="3731">deadly</TOKEN>
<TOKEN end_char="3742" id="token-32-14" morph="none" pos="word" start_char="3738">fight</TOKEN>
<TOKEN end_char="3747" id="token-32-15" morph="none" pos="word" start_char="3744">over</TOKEN>
<TOKEN end_char="3753" id="token-32-16" morph="none" pos="word" start_char="3749">water</TOKEN>
<TOKEN end_char="3759" id="token-32-17" morph="none" pos="word" start_char="3755">among</TOKEN>
<TOKEN end_char="3764" id="token-32-18" morph="none" pos="word" start_char="3761">each</TOKEN>
<TOKEN end_char="3770" id="token-32-19" morph="none" pos="word" start_char="3766">other</TOKEN>
<TOKEN end_char="3774" id="token-32-20" morph="none" pos="word" start_char="3772">and</TOKEN>
<TOKEN end_char="3780" id="token-32-21" morph="none" pos="word" start_char="3776">would</TOKEN>
<TOKEN end_char="3785" id="token-32-22" morph="none" pos="word" start_char="3782">have</TOKEN>
<TOKEN end_char="3792" id="token-32-23" morph="none" pos="word" start_char="3787">surely</TOKEN>
<TOKEN end_char="3802" id="token-32-24" morph="none" pos="word" start_char="3794">increased</TOKEN>
<TOKEN end_char="3806" id="token-32-25" morph="none" pos="word" start_char="3804">the</TOKEN>
<TOKEN end_char="3813" id="token-32-26" morph="none" pos="word" start_char="3808">chance</TOKEN>
<TOKEN end_char="3816" id="token-32-27" morph="none" pos="word" start_char="3815">of</TOKEN>
<TOKEN end_char="3827" id="token-32-28" morph="none" pos="unknown" start_char="3818">human-wild</TOKEN>
<TOKEN end_char="3834" id="token-32-29" morph="none" pos="word" start_char="3829">animal</TOKEN>
<TOKEN end_char="3847" id="token-32-30" morph="none" pos="word" start_char="3836">interactions</TOKEN>
<TOKEN end_char="3848" id="token-32-31" morph="none" pos="punct" start_char="3848">.</TOKEN>
</SEG>
<SEG end_char="3968" id="segment-33" start_char="3851">
<ORIGINAL_TEXT>'We speculated that the [animal to human] transmission of SARS-CoV-2 might be associated with this unusual heat wave.'</ORIGINAL_TEXT>
<TOKEN end_char="3851" id="token-33-0" morph="none" pos="punct" start_char="3851">'</TOKEN>
<TOKEN end_char="3853" id="token-33-1" morph="none" pos="word" start_char="3852">We</TOKEN>
<TOKEN end_char="3864" id="token-33-2" morph="none" pos="word" start_char="3855">speculated</TOKEN>
<TOKEN end_char="3869" id="token-33-3" morph="none" pos="word" start_char="3866">that</TOKEN>
<TOKEN end_char="3873" id="token-33-4" morph="none" pos="word" start_char="3871">the</TOKEN>
<TOKEN end_char="3875" id="token-33-5" morph="none" pos="punct" start_char="3875">[</TOKEN>
<TOKEN end_char="3881" id="token-33-6" morph="none" pos="word" start_char="3876">animal</TOKEN>
<TOKEN end_char="3884" id="token-33-7" morph="none" pos="word" start_char="3883">to</TOKEN>
<TOKEN end_char="3890" id="token-33-8" morph="none" pos="word" start_char="3886">human</TOKEN>
<TOKEN end_char="3891" id="token-33-9" morph="none" pos="punct" start_char="3891">]</TOKEN>
<TOKEN end_char="3904" id="token-33-10" morph="none" pos="word" start_char="3893">transmission</TOKEN>
<TOKEN end_char="3907" id="token-33-11" morph="none" pos="word" start_char="3906">of</TOKEN>
<TOKEN end_char="3918" id="token-33-12" morph="none" pos="unknown" start_char="3909">SARS-CoV-2</TOKEN>
<TOKEN end_char="3924" id="token-33-13" morph="none" pos="word" start_char="3920">might</TOKEN>
<TOKEN end_char="3927" id="token-33-14" morph="none" pos="word" start_char="3926">be</TOKEN>
<TOKEN end_char="3938" id="token-33-15" morph="none" pos="word" start_char="3929">associated</TOKEN>
<TOKEN end_char="3943" id="token-33-16" morph="none" pos="word" start_char="3940">with</TOKEN>
<TOKEN end_char="3948" id="token-33-17" morph="none" pos="word" start_char="3945">this</TOKEN>
<TOKEN end_char="3956" id="token-33-18" morph="none" pos="word" start_char="3950">unusual</TOKEN>
<TOKEN end_char="3961" id="token-33-19" morph="none" pos="word" start_char="3958">heat</TOKEN>
<TOKEN end_char="3966" id="token-33-20" morph="none" pos="word" start_char="3963">wave</TOKEN>
<TOKEN end_char="3968" id="token-33-21" morph="none" pos="punct" start_char="3967">.'</TOKEN>
</SEG>
<SEG end_char="4156" id="segment-34" start_char="3971">
<ORIGINAL_TEXT>Researchers further argue that India's poor healthcare system and young population - who suffer less severe symptoms of Covid - allowed the virus to spread undetected for several months.</ORIGINAL_TEXT>
<TOKEN end_char="3981" id="token-34-0" morph="none" pos="word" start_char="3971">Researchers</TOKEN>
<TOKEN end_char="3989" id="token-34-1" morph="none" pos="word" start_char="3983">further</TOKEN>
<TOKEN end_char="3995" id="token-34-2" morph="none" pos="word" start_char="3991">argue</TOKEN>
<TOKEN end_char="4000" id="token-34-3" morph="none" pos="word" start_char="3997">that</TOKEN>
<TOKEN end_char="4008" id="token-34-4" morph="none" pos="word" start_char="4002">India's</TOKEN>
<TOKEN end_char="4013" id="token-34-5" morph="none" pos="word" start_char="4010">poor</TOKEN>
<TOKEN end_char="4024" id="token-34-6" morph="none" pos="word" start_char="4015">healthcare</TOKEN>
<TOKEN end_char="4031" id="token-34-7" morph="none" pos="word" start_char="4026">system</TOKEN>
<TOKEN end_char="4035" id="token-34-8" morph="none" pos="word" start_char="4033">and</TOKEN>
<TOKEN end_char="4041" id="token-34-9" morph="none" pos="word" start_char="4037">young</TOKEN>
<TOKEN end_char="4052" id="token-34-10" morph="none" pos="word" start_char="4043">population</TOKEN>
<TOKEN end_char="4054" id="token-34-11" morph="none" pos="punct" start_char="4054">-</TOKEN>
<TOKEN end_char="4058" id="token-34-12" morph="none" pos="word" start_char="4056">who</TOKEN>
<TOKEN end_char="4065" id="token-34-13" morph="none" pos="word" start_char="4060">suffer</TOKEN>
<TOKEN end_char="4070" id="token-34-14" morph="none" pos="word" start_char="4067">less</TOKEN>
<TOKEN end_char="4077" id="token-34-15" morph="none" pos="word" start_char="4072">severe</TOKEN>
<TOKEN end_char="4086" id="token-34-16" morph="none" pos="word" start_char="4079">symptoms</TOKEN>
<TOKEN end_char="4089" id="token-34-17" morph="none" pos="word" start_char="4088">of</TOKEN>
<TOKEN end_char="4095" id="token-34-18" morph="none" pos="word" start_char="4091">Covid</TOKEN>
<TOKEN end_char="4097" id="token-34-19" morph="none" pos="punct" start_char="4097">-</TOKEN>
<TOKEN end_char="4105" id="token-34-20" morph="none" pos="word" start_char="4099">allowed</TOKEN>
<TOKEN end_char="4109" id="token-34-21" morph="none" pos="word" start_char="4107">the</TOKEN>
<TOKEN end_char="4115" id="token-34-22" morph="none" pos="word" start_char="4111">virus</TOKEN>
<TOKEN end_char="4118" id="token-34-23" morph="none" pos="word" start_char="4117">to</TOKEN>
<TOKEN end_char="4125" id="token-34-24" morph="none" pos="word" start_char="4120">spread</TOKEN>
<TOKEN end_char="4136" id="token-34-25" morph="none" pos="word" start_char="4127">undetected</TOKEN>
<TOKEN end_char="4140" id="token-34-26" morph="none" pos="word" start_char="4138">for</TOKEN>
<TOKEN end_char="4148" id="token-34-27" morph="none" pos="word" start_char="4142">several</TOKEN>
<TOKEN end_char="4155" id="token-34-28" morph="none" pos="word" start_char="4150">months</TOKEN>
<TOKEN end_char="4156" id="token-34-29" morph="none" pos="punct" start_char="4156">.</TOKEN>
</SEG>
<SEG end_char="4287" id="segment-35" start_char="4159">
<ORIGINAL_TEXT>They speculate that the virus could have spread to the other countries on their list before coming to China, possibly via Europe.</ORIGINAL_TEXT>
<TOKEN end_char="4162" id="token-35-0" morph="none" pos="word" start_char="4159">They</TOKEN>
<TOKEN end_char="4172" id="token-35-1" morph="none" pos="word" start_char="4164">speculate</TOKEN>
<TOKEN end_char="4177" id="token-35-2" morph="none" pos="word" start_char="4174">that</TOKEN>
<TOKEN end_char="4181" id="token-35-3" morph="none" pos="word" start_char="4179">the</TOKEN>
<TOKEN end_char="4187" id="token-35-4" morph="none" pos="word" start_char="4183">virus</TOKEN>
<TOKEN end_char="4193" id="token-35-5" morph="none" pos="word" start_char="4189">could</TOKEN>
<TOKEN end_char="4198" id="token-35-6" morph="none" pos="word" start_char="4195">have</TOKEN>
<TOKEN end_char="4205" id="token-35-7" morph="none" pos="word" start_char="4200">spread</TOKEN>
<TOKEN end_char="4208" id="token-35-8" morph="none" pos="word" start_char="4207">to</TOKEN>
<TOKEN end_char="4212" id="token-35-9" morph="none" pos="word" start_char="4210">the</TOKEN>
<TOKEN end_char="4218" id="token-35-10" morph="none" pos="word" start_char="4214">other</TOKEN>
<TOKEN end_char="4228" id="token-35-11" morph="none" pos="word" start_char="4220">countries</TOKEN>
<TOKEN end_char="4231" id="token-35-12" morph="none" pos="word" start_char="4230">on</TOKEN>
<TOKEN end_char="4237" id="token-35-13" morph="none" pos="word" start_char="4233">their</TOKEN>
<TOKEN end_char="4242" id="token-35-14" morph="none" pos="word" start_char="4239">list</TOKEN>
<TOKEN end_char="4249" id="token-35-15" morph="none" pos="word" start_char="4244">before</TOKEN>
<TOKEN end_char="4256" id="token-35-16" morph="none" pos="word" start_char="4251">coming</TOKEN>
<TOKEN end_char="4259" id="token-35-17" morph="none" pos="word" start_char="4258">to</TOKEN>
<TOKEN end_char="4265" id="token-35-18" morph="none" pos="word" start_char="4261">China</TOKEN>
<TOKEN end_char="4266" id="token-35-19" morph="none" pos="punct" start_char="4266">,</TOKEN>
<TOKEN end_char="4275" id="token-35-20" morph="none" pos="word" start_char="4268">possibly</TOKEN>
<TOKEN end_char="4279" id="token-35-21" morph="none" pos="word" start_char="4277">via</TOKEN>
<TOKEN end_char="4286" id="token-35-22" morph="none" pos="word" start_char="4281">Europe</TOKEN>
<TOKEN end_char="4287" id="token-35-23" morph="none" pos="punct" start_char="4287">.</TOKEN>
</SEG>
<SEG end_char="4402" id="segment-36" start_char="4290">
<ORIGINAL_TEXT>'In this regard, the COVID-19 pandemic is inevitable and the Wuhan epidemic is only a part of it,' they conclude.</ORIGINAL_TEXT>
<TOKEN end_char="4290" id="token-36-0" morph="none" pos="punct" start_char="4290">'</TOKEN>
<TOKEN end_char="4292" id="token-36-1" morph="none" pos="word" start_char="4291">In</TOKEN>
<TOKEN end_char="4297" id="token-36-2" morph="none" pos="word" start_char="4294">this</TOKEN>
<TOKEN end_char="4304" id="token-36-3" morph="none" pos="word" start_char="4299">regard</TOKEN>
<TOKEN end_char="4305" id="token-36-4" morph="none" pos="punct" start_char="4305">,</TOKEN>
<TOKEN end_char="4309" id="token-36-5" morph="none" pos="word" start_char="4307">the</TOKEN>
<TOKEN end_char="4318" id="token-36-6" morph="none" pos="unknown" start_char="4311">COVID-19</TOKEN>
<TOKEN end_char="4327" id="token-36-7" morph="none" pos="word" start_char="4320">pandemic</TOKEN>
<TOKEN end_char="4330" id="token-36-8" morph="none" pos="word" start_char="4329">is</TOKEN>
<TOKEN end_char="4341" id="token-36-9" morph="none" pos="word" start_char="4332">inevitable</TOKEN>
<TOKEN end_char="4345" id="token-36-10" morph="none" pos="word" start_char="4343">and</TOKEN>
<TOKEN end_char="4349" id="token-36-11" morph="none" pos="word" start_char="4347">the</TOKEN>
<TOKEN end_char="4355" id="token-36-12" morph="none" pos="word" start_char="4351">Wuhan</TOKEN>
<TOKEN end_char="4364" id="token-36-13" morph="none" pos="word" start_char="4357">epidemic</TOKEN>
<TOKEN end_char="4367" id="token-36-14" morph="none" pos="word" start_char="4366">is</TOKEN>
<TOKEN end_char="4372" id="token-36-15" morph="none" pos="word" start_char="4369">only</TOKEN>
<TOKEN end_char="4374" id="token-36-16" morph="none" pos="word" start_char="4374">a</TOKEN>
<TOKEN end_char="4379" id="token-36-17" morph="none" pos="word" start_char="4376">part</TOKEN>
<TOKEN end_char="4382" id="token-36-18" morph="none" pos="word" start_char="4381">of</TOKEN>
<TOKEN end_char="4385" id="token-36-19" morph="none" pos="word" start_char="4384">it</TOKEN>
<TOKEN end_char="4387" id="token-36-20" morph="none" pos="punct" start_char="4386">,'</TOKEN>
<TOKEN end_char="4392" id="token-36-21" morph="none" pos="word" start_char="4389">they</TOKEN>
<TOKEN end_char="4401" id="token-36-22" morph="none" pos="word" start_char="4394">conclude</TOKEN>
<TOKEN end_char="4402" id="token-36-23" morph="none" pos="punct" start_char="4402">.</TOKEN>
</SEG>
<SEG end_char="4468" id="segment-37" start_char="4405">
<ORIGINAL_TEXT>However, other researchers were not impressed with the findings.</ORIGINAL_TEXT>
<TOKEN end_char="4411" id="token-37-0" morph="none" pos="word" start_char="4405">However</TOKEN>
<TOKEN end_char="4412" id="token-37-1" morph="none" pos="punct" start_char="4412">,</TOKEN>
<TOKEN end_char="4418" id="token-37-2" morph="none" pos="word" start_char="4414">other</TOKEN>
<TOKEN end_char="4430" id="token-37-3" morph="none" pos="word" start_char="4420">researchers</TOKEN>
<TOKEN end_char="4435" id="token-37-4" morph="none" pos="word" start_char="4432">were</TOKEN>
<TOKEN end_char="4439" id="token-37-5" morph="none" pos="word" start_char="4437">not</TOKEN>
<TOKEN end_char="4449" id="token-37-6" morph="none" pos="word" start_char="4441">impressed</TOKEN>
<TOKEN end_char="4454" id="token-37-7" morph="none" pos="word" start_char="4451">with</TOKEN>
<TOKEN end_char="4458" id="token-37-8" morph="none" pos="word" start_char="4456">the</TOKEN>
<TOKEN end_char="4467" id="token-37-9" morph="none" pos="word" start_char="4460">findings</TOKEN>
<TOKEN end_char="4468" id="token-37-10" morph="none" pos="punct" start_char="4468">.</TOKEN>
</SEG>
<SEG end_char="4625" id="segment-38" start_char="4471">
<ORIGINAL_TEXT>In a statement to Mail Online, Professor Robertson said: 'The author's approach of identifying the "least mutated" virus sequences is... inherently biased.</ORIGINAL_TEXT>
<TOKEN end_char="4472" id="token-38-0" morph="none" pos="word" start_char="4471">In</TOKEN>
<TOKEN end_char="4474" id="token-38-1" morph="none" pos="word" start_char="4474">a</TOKEN>
<TOKEN end_char="4484" id="token-38-2" morph="none" pos="word" start_char="4476">statement</TOKEN>
<TOKEN end_char="4487" id="token-38-3" morph="none" pos="word" start_char="4486">to</TOKEN>
<TOKEN end_char="4492" id="token-38-4" morph="none" pos="word" start_char="4489">Mail</TOKEN>
<TOKEN end_char="4499" id="token-38-5" morph="none" pos="word" start_char="4494">Online</TOKEN>
<TOKEN end_char="4500" id="token-38-6" morph="none" pos="punct" start_char="4500">,</TOKEN>
<TOKEN end_char="4510" id="token-38-7" morph="none" pos="word" start_char="4502">Professor</TOKEN>
<TOKEN end_char="4520" id="token-38-8" morph="none" pos="word" start_char="4512">Robertson</TOKEN>
<TOKEN end_char="4525" id="token-38-9" morph="none" pos="word" start_char="4522">said</TOKEN>
<TOKEN end_char="4526" id="token-38-10" morph="none" pos="punct" start_char="4526">:</TOKEN>
<TOKEN end_char="4528" id="token-38-11" morph="none" pos="punct" start_char="4528">'</TOKEN>
<TOKEN end_char="4531" id="token-38-12" morph="none" pos="word" start_char="4529">The</TOKEN>
<TOKEN end_char="4540" id="token-38-13" morph="none" pos="word" start_char="4533">author's</TOKEN>
<TOKEN end_char="4549" id="token-38-14" morph="none" pos="word" start_char="4542">approach</TOKEN>
<TOKEN end_char="4552" id="token-38-15" morph="none" pos="word" start_char="4551">of</TOKEN>
<TOKEN end_char="4564" id="token-38-16" morph="none" pos="word" start_char="4554">identifying</TOKEN>
<TOKEN end_char="4568" id="token-38-17" morph="none" pos="word" start_char="4566">the</TOKEN>
<TOKEN end_char="4570" id="token-38-18" morph="none" pos="punct" start_char="4570">"</TOKEN>
<TOKEN end_char="4575" id="token-38-19" morph="none" pos="word" start_char="4571">least</TOKEN>
<TOKEN end_char="4583" id="token-38-20" morph="none" pos="word" start_char="4577">mutated</TOKEN>
<TOKEN end_char="4584" id="token-38-21" morph="none" pos="punct" start_char="4584">"</TOKEN>
<TOKEN end_char="4590" id="token-38-22" morph="none" pos="word" start_char="4586">virus</TOKEN>
<TOKEN end_char="4600" id="token-38-23" morph="none" pos="word" start_char="4592">sequences</TOKEN>
<TOKEN end_char="4603" id="token-38-24" morph="none" pos="word" start_char="4602">is</TOKEN>
<TOKEN end_char="4606" id="token-38-25" morph="none" pos="punct" start_char="4604">...</TOKEN>
<TOKEN end_char="4617" id="token-38-26" morph="none" pos="word" start_char="4608">inherently</TOKEN>
<TOKEN end_char="4624" id="token-38-27" morph="none" pos="word" start_char="4619">biased</TOKEN>
<TOKEN end_char="4625" id="token-38-28" morph="none" pos="punct" start_char="4625">.</TOKEN>
</SEG>
<SEG end_char="4776" id="segment-39" start_char="4628">
<ORIGINAL_TEXT>'The authors have also ignored the extensive epidemiological data available that shows clear emergence in China and that the virus spread from there.</ORIGINAL_TEXT>
<TOKEN end_char="4628" id="token-39-0" morph="none" pos="punct" start_char="4628">'</TOKEN>
<TOKEN end_char="4631" id="token-39-1" morph="none" pos="word" start_char="4629">The</TOKEN>
<TOKEN end_char="4639" id="token-39-2" morph="none" pos="word" start_char="4633">authors</TOKEN>
<TOKEN end_char="4644" id="token-39-3" morph="none" pos="word" start_char="4641">have</TOKEN>
<TOKEN end_char="4649" id="token-39-4" morph="none" pos="word" start_char="4646">also</TOKEN>
<TOKEN end_char="4657" id="token-39-5" morph="none" pos="word" start_char="4651">ignored</TOKEN>
<TOKEN end_char="4661" id="token-39-6" morph="none" pos="word" start_char="4659">the</TOKEN>
<TOKEN end_char="4671" id="token-39-7" morph="none" pos="word" start_char="4663">extensive</TOKEN>
<TOKEN end_char="4687" id="token-39-8" morph="none" pos="word" start_char="4673">epidemiological</TOKEN>
<TOKEN end_char="4692" id="token-39-9" morph="none" pos="word" start_char="4689">data</TOKEN>
<TOKEN end_char="4702" id="token-39-10" morph="none" pos="word" start_char="4694">available</TOKEN>
<TOKEN end_char="4707" id="token-39-11" morph="none" pos="word" start_char="4704">that</TOKEN>
<TOKEN end_char="4713" id="token-39-12" morph="none" pos="word" start_char="4709">shows</TOKEN>
<TOKEN end_char="4719" id="token-39-13" morph="none" pos="word" start_char="4715">clear</TOKEN>
<TOKEN end_char="4729" id="token-39-14" morph="none" pos="word" start_char="4721">emergence</TOKEN>
<TOKEN end_char="4732" id="token-39-15" morph="none" pos="word" start_char="4731">in</TOKEN>
<TOKEN end_char="4738" id="token-39-16" morph="none" pos="word" start_char="4734">China</TOKEN>
<TOKEN end_char="4742" id="token-39-17" morph="none" pos="word" start_char="4740">and</TOKEN>
<TOKEN end_char="4747" id="token-39-18" morph="none" pos="word" start_char="4744">that</TOKEN>
<TOKEN end_char="4751" id="token-39-19" morph="none" pos="word" start_char="4749">the</TOKEN>
<TOKEN end_char="4757" id="token-39-20" morph="none" pos="word" start_char="4753">virus</TOKEN>
<TOKEN end_char="4764" id="token-39-21" morph="none" pos="word" start_char="4759">spread</TOKEN>
<TOKEN end_char="4769" id="token-39-22" morph="none" pos="word" start_char="4766">from</TOKEN>
<TOKEN end_char="4775" id="token-39-23" morph="none" pos="word" start_char="4771">there</TOKEN>
<TOKEN end_char="4776" id="token-39-24" morph="none" pos="punct" start_char="4776">.</TOKEN>
</SEG>
<SEG end_char="4839" id="segment-40" start_char="4779">
<ORIGINAL_TEXT>'This paper adds nothing to our understanding of SARS-CoV-2.'</ORIGINAL_TEXT>
<TOKEN end_char="4779" id="token-40-0" morph="none" pos="punct" start_char="4779">'</TOKEN>
<TOKEN end_char="4783" id="token-40-1" morph="none" pos="word" start_char="4780">This</TOKEN>
<TOKEN end_char="4789" id="token-40-2" morph="none" pos="word" start_char="4785">paper</TOKEN>
<TOKEN end_char="4794" id="token-40-3" morph="none" pos="word" start_char="4791">adds</TOKEN>
<TOKEN end_char="4802" id="token-40-4" morph="none" pos="word" start_char="4796">nothing</TOKEN>
<TOKEN end_char="4805" id="token-40-5" morph="none" pos="word" start_char="4804">to</TOKEN>
<TOKEN end_char="4809" id="token-40-6" morph="none" pos="word" start_char="4807">our</TOKEN>
<TOKEN end_char="4823" id="token-40-7" morph="none" pos="word" start_char="4811">understanding</TOKEN>
<TOKEN end_char="4826" id="token-40-8" morph="none" pos="word" start_char="4825">of</TOKEN>
<TOKEN end_char="4837" id="token-40-9" morph="none" pos="unknown" start_char="4828">SARS-CoV-2</TOKEN>
<TOKEN end_char="4839" id="token-40-10" morph="none" pos="punct" start_char="4838">.'</TOKEN>
</SEG>
<SEG end_char="5094" id="segment-41" start_char="4842">
<ORIGINAL_TEXT>Marc Suchard, an expert from the University of California, told the South China Morning Post: 'Picking the viral sequence that appears to have the least number of differences to the others in an arbitrary collection is unlikely to yield the progenitor.'</ORIGINAL_TEXT>
<TOKEN end_char="4845" id="token-41-0" morph="none" pos="word" start_char="4842">Marc</TOKEN>
<TOKEN end_char="4853" id="token-41-1" morph="none" pos="word" start_char="4847">Suchard</TOKEN>
<TOKEN end_char="4854" id="token-41-2" morph="none" pos="punct" start_char="4854">,</TOKEN>
<TOKEN end_char="4857" id="token-41-3" morph="none" pos="word" start_char="4856">an</TOKEN>
<TOKEN end_char="4864" id="token-41-4" morph="none" pos="word" start_char="4859">expert</TOKEN>
<TOKEN end_char="4869" id="token-41-5" morph="none" pos="word" start_char="4866">from</TOKEN>
<TOKEN end_char="4873" id="token-41-6" morph="none" pos="word" start_char="4871">the</TOKEN>
<TOKEN end_char="4884" id="token-41-7" morph="none" pos="word" start_char="4875">University</TOKEN>
<TOKEN end_char="4887" id="token-41-8" morph="none" pos="word" start_char="4886">of</TOKEN>
<TOKEN end_char="4898" id="token-41-9" morph="none" pos="word" start_char="4889">California</TOKEN>
<TOKEN end_char="4899" id="token-41-10" morph="none" pos="punct" start_char="4899">,</TOKEN>
<TOKEN end_char="4904" id="token-41-11" morph="none" pos="word" start_char="4901">told</TOKEN>
<TOKEN end_char="4908" id="token-41-12" morph="none" pos="word" start_char="4906">the</TOKEN>
<TOKEN end_char="4914" id="token-41-13" morph="none" pos="word" start_char="4910">South</TOKEN>
<TOKEN end_char="4920" id="token-41-14" morph="none" pos="word" start_char="4916">China</TOKEN>
<TOKEN end_char="4928" id="token-41-15" morph="none" pos="word" start_char="4922">Morning</TOKEN>
<TOKEN end_char="4933" id="token-41-16" morph="none" pos="word" start_char="4930">Post</TOKEN>
<TOKEN end_char="4934" id="token-41-17" morph="none" pos="punct" start_char="4934">:</TOKEN>
<TOKEN end_char="4936" id="token-41-18" morph="none" pos="punct" start_char="4936">'</TOKEN>
<TOKEN end_char="4943" id="token-41-19" morph="none" pos="word" start_char="4937">Picking</TOKEN>
<TOKEN end_char="4947" id="token-41-20" morph="none" pos="word" start_char="4945">the</TOKEN>
<TOKEN end_char="4953" id="token-41-21" morph="none" pos="word" start_char="4949">viral</TOKEN>
<TOKEN end_char="4962" id="token-41-22" morph="none" pos="word" start_char="4955">sequence</TOKEN>
<TOKEN end_char="4967" id="token-41-23" morph="none" pos="word" start_char="4964">that</TOKEN>
<TOKEN end_char="4975" id="token-41-24" morph="none" pos="word" start_char="4969">appears</TOKEN>
<TOKEN end_char="4978" id="token-41-25" morph="none" pos="word" start_char="4977">to</TOKEN>
<TOKEN end_char="4983" id="token-41-26" morph="none" pos="word" start_char="4980">have</TOKEN>
<TOKEN end_char="4987" id="token-41-27" morph="none" pos="word" start_char="4985">the</TOKEN>
<TOKEN end_char="4993" id="token-41-28" morph="none" pos="word" start_char="4989">least</TOKEN>
<TOKEN end_char="5000" id="token-41-29" morph="none" pos="word" start_char="4995">number</TOKEN>
<TOKEN end_char="5003" id="token-41-30" morph="none" pos="word" start_char="5002">of</TOKEN>
<TOKEN end_char="5015" id="token-41-31" morph="none" pos="word" start_char="5005">differences</TOKEN>
<TOKEN end_char="5018" id="token-41-32" morph="none" pos="word" start_char="5017">to</TOKEN>
<TOKEN end_char="5022" id="token-41-33" morph="none" pos="word" start_char="5020">the</TOKEN>
<TOKEN end_char="5029" id="token-41-34" morph="none" pos="word" start_char="5024">others</TOKEN>
<TOKEN end_char="5032" id="token-41-35" morph="none" pos="word" start_char="5031">in</TOKEN>
<TOKEN end_char="5035" id="token-41-36" morph="none" pos="word" start_char="5034">an</TOKEN>
<TOKEN end_char="5045" id="token-41-37" morph="none" pos="word" start_char="5037">arbitrary</TOKEN>
<TOKEN end_char="5056" id="token-41-38" morph="none" pos="word" start_char="5047">collection</TOKEN>
<TOKEN end_char="5059" id="token-41-39" morph="none" pos="word" start_char="5058">is</TOKEN>
<TOKEN end_char="5068" id="token-41-40" morph="none" pos="word" start_char="5061">unlikely</TOKEN>
<TOKEN end_char="5071" id="token-41-41" morph="none" pos="word" start_char="5070">to</TOKEN>
<TOKEN end_char="5077" id="token-41-42" morph="none" pos="word" start_char="5073">yield</TOKEN>
<TOKEN end_char="5081" id="token-41-43" morph="none" pos="word" start_char="5079">the</TOKEN>
<TOKEN end_char="5092" id="token-41-44" morph="none" pos="word" start_char="5083">progenitor</TOKEN>
<TOKEN end_char="5094" id="token-41-45" morph="none" pos="punct" start_char="5093">.'</TOKEN>
</SEG>
<SEG end_char="5221" id="segment-42" start_char="5097">
<ORIGINAL_TEXT>Another UK-based researcher told Mail Online that the study contains 'big claims' and that he is 'skeptical' of the findings.</ORIGINAL_TEXT>
<TOKEN end_char="5103" id="token-42-0" morph="none" pos="word" start_char="5097">Another</TOKEN>
<TOKEN end_char="5112" id="token-42-1" morph="none" pos="unknown" start_char="5105">UK-based</TOKEN>
<TOKEN end_char="5123" id="token-42-2" morph="none" pos="word" start_char="5114">researcher</TOKEN>
<TOKEN end_char="5128" id="token-42-3" morph="none" pos="word" start_char="5125">told</TOKEN>
<TOKEN end_char="5133" id="token-42-4" morph="none" pos="word" start_char="5130">Mail</TOKEN>
<TOKEN end_char="5140" id="token-42-5" morph="none" pos="word" start_char="5135">Online</TOKEN>
<TOKEN end_char="5145" id="token-42-6" morph="none" pos="word" start_char="5142">that</TOKEN>
<TOKEN end_char="5149" id="token-42-7" morph="none" pos="word" start_char="5147">the</TOKEN>
<TOKEN end_char="5155" id="token-42-8" morph="none" pos="word" start_char="5151">study</TOKEN>
<TOKEN end_char="5164" id="token-42-9" morph="none" pos="word" start_char="5157">contains</TOKEN>
<TOKEN end_char="5166" id="token-42-10" morph="none" pos="punct" start_char="5166">'</TOKEN>
<TOKEN end_char="5169" id="token-42-11" morph="none" pos="word" start_char="5167">big</TOKEN>
<TOKEN end_char="5176" id="token-42-12" morph="none" pos="word" start_char="5171">claims</TOKEN>
<TOKEN end_char="5177" id="token-42-13" morph="none" pos="punct" start_char="5177">'</TOKEN>
<TOKEN end_char="5181" id="token-42-14" morph="none" pos="word" start_char="5179">and</TOKEN>
<TOKEN end_char="5186" id="token-42-15" morph="none" pos="word" start_char="5183">that</TOKEN>
<TOKEN end_char="5189" id="token-42-16" morph="none" pos="word" start_char="5188">he</TOKEN>
<TOKEN end_char="5192" id="token-42-17" morph="none" pos="word" start_char="5191">is</TOKEN>
<TOKEN end_char="5194" id="token-42-18" morph="none" pos="punct" start_char="5194">'</TOKEN>
<TOKEN end_char="5203" id="token-42-19" morph="none" pos="word" start_char="5195">skeptical</TOKEN>
<TOKEN end_char="5204" id="token-42-20" morph="none" pos="punct" start_char="5204">'</TOKEN>
<TOKEN end_char="5207" id="token-42-21" morph="none" pos="word" start_char="5206">of</TOKEN>
<TOKEN end_char="5211" id="token-42-22" morph="none" pos="word" start_char="5209">the</TOKEN>
<TOKEN end_char="5220" id="token-42-23" morph="none" pos="word" start_char="5213">findings</TOKEN>
<TOKEN end_char="5221" id="token-42-24" morph="none" pos="punct" start_char="5221">.</TOKEN>
</SEG>
<SEG end_char="5388" id="segment-43" start_char="5225">
<ORIGINAL_TEXT>India suffered a near-record heatwave in 2019 as water ran in desperately short supply, forcing the government to trasport it into cities in large trucks (pictured)</ORIGINAL_TEXT>
<TOKEN end_char="5229" id="token-43-0" morph="none" pos="word" start_char="5225">India</TOKEN>
<TOKEN end_char="5238" id="token-43-1" morph="none" pos="word" start_char="5231">suffered</TOKEN>
<TOKEN end_char="5240" id="token-43-2" morph="none" pos="word" start_char="5240">a</TOKEN>
<TOKEN end_char="5252" id="token-43-3" morph="none" pos="unknown" start_char="5242">near-record</TOKEN>
<TOKEN end_char="5261" id="token-43-4" morph="none" pos="word" start_char="5254">heatwave</TOKEN>
<TOKEN end_char="5264" id="token-43-5" morph="none" pos="word" start_char="5263">in</TOKEN>
<TOKEN end_char="5269" id="token-43-6" morph="none" pos="word" start_char="5266">2019</TOKEN>
<TOKEN end_char="5272" id="token-43-7" morph="none" pos="word" start_char="5271">as</TOKEN>
<TOKEN end_char="5278" id="token-43-8" morph="none" pos="word" start_char="5274">water</TOKEN>
<TOKEN end_char="5282" id="token-43-9" morph="none" pos="word" start_char="5280">ran</TOKEN>
<TOKEN end_char="5285" id="token-43-10" morph="none" pos="word" start_char="5284">in</TOKEN>
<TOKEN end_char="5297" id="token-43-11" morph="none" pos="word" start_char="5287">desperately</TOKEN>
<TOKEN end_char="5303" id="token-43-12" morph="none" pos="word" start_char="5299">short</TOKEN>
<TOKEN end_char="5310" id="token-43-13" morph="none" pos="word" start_char="5305">supply</TOKEN>
<TOKEN end_char="5311" id="token-43-14" morph="none" pos="punct" start_char="5311">,</TOKEN>
<TOKEN end_char="5319" id="token-43-15" morph="none" pos="word" start_char="5313">forcing</TOKEN>
<TOKEN end_char="5323" id="token-43-16" morph="none" pos="word" start_char="5321">the</TOKEN>
<TOKEN end_char="5334" id="token-43-17" morph="none" pos="word" start_char="5325">government</TOKEN>
<TOKEN end_char="5337" id="token-43-18" morph="none" pos="word" start_char="5336">to</TOKEN>
<TOKEN end_char="5346" id="token-43-19" morph="none" pos="word" start_char="5339">trasport</TOKEN>
<TOKEN end_char="5349" id="token-43-20" morph="none" pos="word" start_char="5348">it</TOKEN>
<TOKEN end_char="5354" id="token-43-21" morph="none" pos="word" start_char="5351">into</TOKEN>
<TOKEN end_char="5361" id="token-43-22" morph="none" pos="word" start_char="5356">cities</TOKEN>
<TOKEN end_char="5364" id="token-43-23" morph="none" pos="word" start_char="5363">in</TOKEN>
<TOKEN end_char="5370" id="token-43-24" morph="none" pos="word" start_char="5366">large</TOKEN>
<TOKEN end_char="5377" id="token-43-25" morph="none" pos="word" start_char="5372">trucks</TOKEN>
<TOKEN end_char="5379" id="token-43-26" morph="none" pos="punct" start_char="5379">(</TOKEN>
<TOKEN end_char="5387" id="token-43-27" morph="none" pos="word" start_char="5380">pictured</TOKEN>
<TOKEN end_char="5388" id="token-43-28" morph="none" pos="punct" start_char="5388">)</TOKEN>
</SEG>
<SEG end_char="5537" id="segment-44" start_char="5391">
<ORIGINAL_TEXT>Coroanvirus first emerged in China in December 2019, linked to a cluster of cases of 'pneumonia of unknown origin' at a seafood market in the city.</ORIGINAL_TEXT>
<TOKEN end_char="5401" id="token-44-0" morph="none" pos="word" start_char="5391">Coroanvirus</TOKEN>
<TOKEN end_char="5407" id="token-44-1" morph="none" pos="word" start_char="5403">first</TOKEN>
<TOKEN end_char="5415" id="token-44-2" morph="none" pos="word" start_char="5409">emerged</TOKEN>
<TOKEN end_char="5418" id="token-44-3" morph="none" pos="word" start_char="5417">in</TOKEN>
<TOKEN end_char="5424" id="token-44-4" morph="none" pos="word" start_char="5420">China</TOKEN>
<TOKEN end_char="5427" id="token-44-5" morph="none" pos="word" start_char="5426">in</TOKEN>
<TOKEN end_char="5436" id="token-44-6" morph="none" pos="word" start_char="5429">December</TOKEN>
<TOKEN end_char="5441" id="token-44-7" morph="none" pos="word" start_char="5438">2019</TOKEN>
<TOKEN end_char="5442" id="token-44-8" morph="none" pos="punct" start_char="5442">,</TOKEN>
<TOKEN end_char="5449" id="token-44-9" morph="none" pos="word" start_char="5444">linked</TOKEN>
<TOKEN end_char="5452" id="token-44-10" morph="none" pos="word" start_char="5451">to</TOKEN>
<TOKEN end_char="5454" id="token-44-11" morph="none" pos="word" start_char="5454">a</TOKEN>
<TOKEN end_char="5462" id="token-44-12" morph="none" pos="word" start_char="5456">cluster</TOKEN>
<TOKEN end_char="5465" id="token-44-13" morph="none" pos="word" start_char="5464">of</TOKEN>
<TOKEN end_char="5471" id="token-44-14" morph="none" pos="word" start_char="5467">cases</TOKEN>
<TOKEN end_char="5474" id="token-44-15" morph="none" pos="word" start_char="5473">of</TOKEN>
<TOKEN end_char="5476" id="token-44-16" morph="none" pos="punct" start_char="5476">'</TOKEN>
<TOKEN end_char="5485" id="token-44-17" morph="none" pos="word" start_char="5477">pneumonia</TOKEN>
<TOKEN end_char="5488" id="token-44-18" morph="none" pos="word" start_char="5487">of</TOKEN>
<TOKEN end_char="5496" id="token-44-19" morph="none" pos="word" start_char="5490">unknown</TOKEN>
<TOKEN end_char="5503" id="token-44-20" morph="none" pos="word" start_char="5498">origin</TOKEN>
<TOKEN end_char="5504" id="token-44-21" morph="none" pos="punct" start_char="5504">'</TOKEN>
<TOKEN end_char="5507" id="token-44-22" morph="none" pos="word" start_char="5506">at</TOKEN>
<TOKEN end_char="5509" id="token-44-23" morph="none" pos="word" start_char="5509">a</TOKEN>
<TOKEN end_char="5517" id="token-44-24" morph="none" pos="word" start_char="5511">seafood</TOKEN>
<TOKEN end_char="5524" id="token-44-25" morph="none" pos="word" start_char="5519">market</TOKEN>
<TOKEN end_char="5527" id="token-44-26" morph="none" pos="word" start_char="5526">in</TOKEN>
<TOKEN end_char="5531" id="token-44-27" morph="none" pos="word" start_char="5529">the</TOKEN>
<TOKEN end_char="5536" id="token-44-28" morph="none" pos="word" start_char="5533">city</TOKEN>
<TOKEN end_char="5537" id="token-44-29" morph="none" pos="punct" start_char="5537">.</TOKEN>
</SEG>
<SEG end_char="5676" id="segment-45" start_char="5540">
<ORIGINAL_TEXT>It then spread across China before making its way to other countires, mostly via toursits, where it spread rapidly and caused a pandemic.</ORIGINAL_TEXT>
<TOKEN end_char="5541" id="token-45-0" morph="none" pos="word" start_char="5540">It</TOKEN>
<TOKEN end_char="5546" id="token-45-1" morph="none" pos="word" start_char="5543">then</TOKEN>
<TOKEN end_char="5553" id="token-45-2" morph="none" pos="word" start_char="5548">spread</TOKEN>
<TOKEN end_char="5560" id="token-45-3" morph="none" pos="word" start_char="5555">across</TOKEN>
<TOKEN end_char="5566" id="token-45-4" morph="none" pos="word" start_char="5562">China</TOKEN>
<TOKEN end_char="5573" id="token-45-5" morph="none" pos="word" start_char="5568">before</TOKEN>
<TOKEN end_char="5580" id="token-45-6" morph="none" pos="word" start_char="5575">making</TOKEN>
<TOKEN end_char="5584" id="token-45-7" morph="none" pos="word" start_char="5582">its</TOKEN>
<TOKEN end_char="5588" id="token-45-8" morph="none" pos="word" start_char="5586">way</TOKEN>
<TOKEN end_char="5591" id="token-45-9" morph="none" pos="word" start_char="5590">to</TOKEN>
<TOKEN end_char="5597" id="token-45-10" morph="none" pos="word" start_char="5593">other</TOKEN>
<TOKEN end_char="5607" id="token-45-11" morph="none" pos="word" start_char="5599">countires</TOKEN>
<TOKEN end_char="5608" id="token-45-12" morph="none" pos="punct" start_char="5608">,</TOKEN>
<TOKEN end_char="5615" id="token-45-13" morph="none" pos="word" start_char="5610">mostly</TOKEN>
<TOKEN end_char="5619" id="token-45-14" morph="none" pos="word" start_char="5617">via</TOKEN>
<TOKEN end_char="5628" id="token-45-15" morph="none" pos="word" start_char="5621">toursits</TOKEN>
<TOKEN end_char="5629" id="token-45-16" morph="none" pos="punct" start_char="5629">,</TOKEN>
<TOKEN end_char="5635" id="token-45-17" morph="none" pos="word" start_char="5631">where</TOKEN>
<TOKEN end_char="5638" id="token-45-18" morph="none" pos="word" start_char="5637">it</TOKEN>
<TOKEN end_char="5645" id="token-45-19" morph="none" pos="word" start_char="5640">spread</TOKEN>
<TOKEN end_char="5653" id="token-45-20" morph="none" pos="word" start_char="5647">rapidly</TOKEN>
<TOKEN end_char="5657" id="token-45-21" morph="none" pos="word" start_char="5655">and</TOKEN>
<TOKEN end_char="5664" id="token-45-22" morph="none" pos="word" start_char="5659">caused</TOKEN>
<TOKEN end_char="5666" id="token-45-23" morph="none" pos="word" start_char="5666">a</TOKEN>
<TOKEN end_char="5675" id="token-45-24" morph="none" pos="word" start_char="5668">pandemic</TOKEN>
<TOKEN end_char="5676" id="token-45-25" morph="none" pos="punct" start_char="5676">.</TOKEN>
</SEG>
<SEG end_char="5860" id="segment-46" start_char="5679">
<ORIGINAL_TEXT>But nobody has been able to identify 'patient zero' the first person known to have caught the disease, which means we do not known when or where exactly the first infection occurred.</ORIGINAL_TEXT>
<TOKEN end_char="5681" id="token-46-0" morph="none" pos="word" start_char="5679">But</TOKEN>
<TOKEN end_char="5688" id="token-46-1" morph="none" pos="word" start_char="5683">nobody</TOKEN>
<TOKEN end_char="5692" id="token-46-2" morph="none" pos="word" start_char="5690">has</TOKEN>
<TOKEN end_char="5697" id="token-46-3" morph="none" pos="word" start_char="5694">been</TOKEN>
<TOKEN end_char="5702" id="token-46-4" morph="none" pos="word" start_char="5699">able</TOKEN>
<TOKEN end_char="5705" id="token-46-5" morph="none" pos="word" start_char="5704">to</TOKEN>
<TOKEN end_char="5714" id="token-46-6" morph="none" pos="word" start_char="5707">identify</TOKEN>
<TOKEN end_char="5716" id="token-46-7" morph="none" pos="punct" start_char="5716">'</TOKEN>
<TOKEN end_char="5723" id="token-46-8" morph="none" pos="word" start_char="5717">patient</TOKEN>
<TOKEN end_char="5728" id="token-46-9" morph="none" pos="word" start_char="5725">zero</TOKEN>
<TOKEN end_char="5729" id="token-46-10" morph="none" pos="punct" start_char="5729">'</TOKEN>
<TOKEN end_char="5733" id="token-46-11" morph="none" pos="word" start_char="5731">the</TOKEN>
<TOKEN end_char="5739" id="token-46-12" morph="none" pos="word" start_char="5735">first</TOKEN>
<TOKEN end_char="5746" id="token-46-13" morph="none" pos="word" start_char="5741">person</TOKEN>
<TOKEN end_char="5752" id="token-46-14" morph="none" pos="word" start_char="5748">known</TOKEN>
<TOKEN end_char="5755" id="token-46-15" morph="none" pos="word" start_char="5754">to</TOKEN>
<TOKEN end_char="5760" id="token-46-16" morph="none" pos="word" start_char="5757">have</TOKEN>
<TOKEN end_char="5767" id="token-46-17" morph="none" pos="word" start_char="5762">caught</TOKEN>
<TOKEN end_char="5771" id="token-46-18" morph="none" pos="word" start_char="5769">the</TOKEN>
<TOKEN end_char="5779" id="token-46-19" morph="none" pos="word" start_char="5773">disease</TOKEN>
<TOKEN end_char="5780" id="token-46-20" morph="none" pos="punct" start_char="5780">,</TOKEN>
<TOKEN end_char="5786" id="token-46-21" morph="none" pos="word" start_char="5782">which</TOKEN>
<TOKEN end_char="5792" id="token-46-22" morph="none" pos="word" start_char="5788">means</TOKEN>
<TOKEN end_char="5795" id="token-46-23" morph="none" pos="word" start_char="5794">we</TOKEN>
<TOKEN end_char="5798" id="token-46-24" morph="none" pos="word" start_char="5797">do</TOKEN>
<TOKEN end_char="5802" id="token-46-25" morph="none" pos="word" start_char="5800">not</TOKEN>
<TOKEN end_char="5808" id="token-46-26" morph="none" pos="word" start_char="5804">known</TOKEN>
<TOKEN end_char="5813" id="token-46-27" morph="none" pos="word" start_char="5810">when</TOKEN>
<TOKEN end_char="5816" id="token-46-28" morph="none" pos="word" start_char="5815">or</TOKEN>
<TOKEN end_char="5822" id="token-46-29" morph="none" pos="word" start_char="5818">where</TOKEN>
<TOKEN end_char="5830" id="token-46-30" morph="none" pos="word" start_char="5824">exactly</TOKEN>
<TOKEN end_char="5834" id="token-46-31" morph="none" pos="word" start_char="5832">the</TOKEN>
<TOKEN end_char="5840" id="token-46-32" morph="none" pos="word" start_char="5836">first</TOKEN>
<TOKEN end_char="5850" id="token-46-33" morph="none" pos="word" start_char="5842">infection</TOKEN>
<TOKEN end_char="5859" id="token-46-34" morph="none" pos="word" start_char="5852">occurred</TOKEN>
<TOKEN end_char="5860" id="token-46-35" morph="none" pos="punct" start_char="5860">.</TOKEN>
</SEG>
<SEG end_char="5986" id="segment-47" start_char="5863">
<ORIGINAL_TEXT>That has led rise to intense speculation and founded many conspiracy theories, none of which have so far been substantiated.</ORIGINAL_TEXT>
<TOKEN end_char="5866" id="token-47-0" morph="none" pos="word" start_char="5863">That</TOKEN>
<TOKEN end_char="5870" id="token-47-1" morph="none" pos="word" start_char="5868">has</TOKEN>
<TOKEN end_char="5874" id="token-47-2" morph="none" pos="word" start_char="5872">led</TOKEN>
<TOKEN end_char="5879" id="token-47-3" morph="none" pos="word" start_char="5876">rise</TOKEN>
<TOKEN end_char="5882" id="token-47-4" morph="none" pos="word" start_char="5881">to</TOKEN>
<TOKEN end_char="5890" id="token-47-5" morph="none" pos="word" start_char="5884">intense</TOKEN>
<TOKEN end_char="5902" id="token-47-6" morph="none" pos="word" start_char="5892">speculation</TOKEN>
<TOKEN end_char="5906" id="token-47-7" morph="none" pos="word" start_char="5904">and</TOKEN>
<TOKEN end_char="5914" id="token-47-8" morph="none" pos="word" start_char="5908">founded</TOKEN>
<TOKEN end_char="5919" id="token-47-9" morph="none" pos="word" start_char="5916">many</TOKEN>
<TOKEN end_char="5930" id="token-47-10" morph="none" pos="word" start_char="5921">conspiracy</TOKEN>
<TOKEN end_char="5939" id="token-47-11" morph="none" pos="word" start_char="5932">theories</TOKEN>
<TOKEN end_char="5940" id="token-47-12" morph="none" pos="punct" start_char="5940">,</TOKEN>
<TOKEN end_char="5945" id="token-47-13" morph="none" pos="word" start_char="5942">none</TOKEN>
<TOKEN end_char="5948" id="token-47-14" morph="none" pos="word" start_char="5947">of</TOKEN>
<TOKEN end_char="5954" id="token-47-15" morph="none" pos="word" start_char="5950">which</TOKEN>
<TOKEN end_char="5959" id="token-47-16" morph="none" pos="word" start_char="5956">have</TOKEN>
<TOKEN end_char="5962" id="token-47-17" morph="none" pos="word" start_char="5961">so</TOKEN>
<TOKEN end_char="5966" id="token-47-18" morph="none" pos="word" start_char="5964">far</TOKEN>
<TOKEN end_char="5971" id="token-47-19" morph="none" pos="word" start_char="5968">been</TOKEN>
<TOKEN end_char="5985" id="token-47-20" morph="none" pos="word" start_char="5973">substantiated</TOKEN>
<TOKEN end_char="5986" id="token-47-21" morph="none" pos="punct" start_char="5986">.</TOKEN>
</SEG>
<SEG end_char="6129" id="segment-48" start_char="5989">
<ORIGINAL_TEXT>The World Health Organisation, under pressure because of its own response to the pandemic, has sent a 10-person team to China to investigate.</ORIGINAL_TEXT>
<TOKEN end_char="5991" id="token-48-0" morph="none" pos="word" start_char="5989">The</TOKEN>
<TOKEN end_char="5997" id="token-48-1" morph="none" pos="word" start_char="5993">World</TOKEN>
<TOKEN end_char="6004" id="token-48-2" morph="none" pos="word" start_char="5999">Health</TOKEN>
<TOKEN end_char="6017" id="token-48-3" morph="none" pos="word" start_char="6006">Organisation</TOKEN>
<TOKEN end_char="6018" id="token-48-4" morph="none" pos="punct" start_char="6018">,</TOKEN>
<TOKEN end_char="6024" id="token-48-5" morph="none" pos="word" start_char="6020">under</TOKEN>
<TOKEN end_char="6033" id="token-48-6" morph="none" pos="word" start_char="6026">pressure</TOKEN>
<TOKEN end_char="6041" id="token-48-7" morph="none" pos="word" start_char="6035">because</TOKEN>
<TOKEN end_char="6044" id="token-48-8" morph="none" pos="word" start_char="6043">of</TOKEN>
<TOKEN end_char="6048" id="token-48-9" morph="none" pos="word" start_char="6046">its</TOKEN>
<TOKEN end_char="6052" id="token-48-10" morph="none" pos="word" start_char="6050">own</TOKEN>
<TOKEN end_char="6061" id="token-48-11" morph="none" pos="word" start_char="6054">response</TOKEN>
<TOKEN end_char="6064" id="token-48-12" morph="none" pos="word" start_char="6063">to</TOKEN>
<TOKEN end_char="6068" id="token-48-13" morph="none" pos="word" start_char="6066">the</TOKEN>
<TOKEN end_char="6077" id="token-48-14" morph="none" pos="word" start_char="6070">pandemic</TOKEN>
<TOKEN end_char="6078" id="token-48-15" morph="none" pos="punct" start_char="6078">,</TOKEN>
<TOKEN end_char="6082" id="token-48-16" morph="none" pos="word" start_char="6080">has</TOKEN>
<TOKEN end_char="6087" id="token-48-17" morph="none" pos="word" start_char="6084">sent</TOKEN>
<TOKEN end_char="6089" id="token-48-18" morph="none" pos="word" start_char="6089">a</TOKEN>
<TOKEN end_char="6099" id="token-48-19" morph="none" pos="unknown" start_char="6091">10-person</TOKEN>
<TOKEN end_char="6104" id="token-48-20" morph="none" pos="word" start_char="6101">team</TOKEN>
<TOKEN end_char="6107" id="token-48-21" morph="none" pos="word" start_char="6106">to</TOKEN>
<TOKEN end_char="6113" id="token-48-22" morph="none" pos="word" start_char="6109">China</TOKEN>
<TOKEN end_char="6116" id="token-48-23" morph="none" pos="word" start_char="6115">to</TOKEN>
<TOKEN end_char="6128" id="token-48-24" morph="none" pos="word" start_char="6118">investigate</TOKEN>
<TOKEN end_char="6129" id="token-48-25" morph="none" pos="punct" start_char="6129">.</TOKEN>
</SEG>
<SEG end_char="6279" id="segment-49" start_char="6132">
<ORIGINAL_TEXT>While the team admit it is possible that the virus originated outside of the country, their initial searches are all focused within China's borders.</ORIGINAL_TEXT>
<TOKEN end_char="6136" id="token-49-0" morph="none" pos="word" start_char="6132">While</TOKEN>
<TOKEN end_char="6140" id="token-49-1" morph="none" pos="word" start_char="6138">the</TOKEN>
<TOKEN end_char="6145" id="token-49-2" morph="none" pos="word" start_char="6142">team</TOKEN>
<TOKEN end_char="6151" id="token-49-3" morph="none" pos="word" start_char="6147">admit</TOKEN>
<TOKEN end_char="6154" id="token-49-4" morph="none" pos="word" start_char="6153">it</TOKEN>
<TOKEN end_char="6157" id="token-49-5" morph="none" pos="word" start_char="6156">is</TOKEN>
<TOKEN end_char="6166" id="token-49-6" morph="none" pos="word" start_char="6159">possible</TOKEN>
<TOKEN end_char="6171" id="token-49-7" morph="none" pos="word" start_char="6168">that</TOKEN>
<TOKEN end_char="6175" id="token-49-8" morph="none" pos="word" start_char="6173">the</TOKEN>
<TOKEN end_char="6181" id="token-49-9" morph="none" pos="word" start_char="6177">virus</TOKEN>
<TOKEN end_char="6192" id="token-49-10" morph="none" pos="word" start_char="6183">originated</TOKEN>
<TOKEN end_char="6200" id="token-49-11" morph="none" pos="word" start_char="6194">outside</TOKEN>
<TOKEN end_char="6203" id="token-49-12" morph="none" pos="word" start_char="6202">of</TOKEN>
<TOKEN end_char="6207" id="token-49-13" morph="none" pos="word" start_char="6205">the</TOKEN>
<TOKEN end_char="6215" id="token-49-14" morph="none" pos="word" start_char="6209">country</TOKEN>
<TOKEN end_char="6216" id="token-49-15" morph="none" pos="punct" start_char="6216">,</TOKEN>
<TOKEN end_char="6222" id="token-49-16" morph="none" pos="word" start_char="6218">their</TOKEN>
<TOKEN end_char="6230" id="token-49-17" morph="none" pos="word" start_char="6224">initial</TOKEN>
<TOKEN end_char="6239" id="token-49-18" morph="none" pos="word" start_char="6232">searches</TOKEN>
<TOKEN end_char="6243" id="token-49-19" morph="none" pos="word" start_char="6241">are</TOKEN>
<TOKEN end_char="6247" id="token-49-20" morph="none" pos="word" start_char="6245">all</TOKEN>
<TOKEN end_char="6255" id="token-49-21" morph="none" pos="word" start_char="6249">focused</TOKEN>
<TOKEN end_char="6262" id="token-49-22" morph="none" pos="word" start_char="6257">within</TOKEN>
<TOKEN end_char="6270" id="token-49-23" morph="none" pos="word" start_char="6264">China's</TOKEN>
<TOKEN end_char="6278" id="token-49-24" morph="none" pos="word" start_char="6272">borders</TOKEN>
<TOKEN end_char="6279" id="token-49-25" morph="none" pos="punct" start_char="6279">.</TOKEN>
</SEG>
<SEG end_char="6438" id="segment-50" start_char="6282">
<ORIGINAL_TEXT>The UN agency has tried to temper expectations ahead of the investigation, warning that tracking any new pathogen is a 'riddle that can take years to solve'.</ORIGINAL_TEXT>
<TOKEN end_char="6284" id="token-50-0" morph="none" pos="word" start_char="6282">The</TOKEN>
<TOKEN end_char="6287" id="token-50-1" morph="none" pos="word" start_char="6286">UN</TOKEN>
<TOKEN end_char="6294" id="token-50-2" morph="none" pos="word" start_char="6289">agency</TOKEN>
<TOKEN end_char="6298" id="token-50-3" morph="none" pos="word" start_char="6296">has</TOKEN>
<TOKEN end_char="6304" id="token-50-4" morph="none" pos="word" start_char="6300">tried</TOKEN>
<TOKEN end_char="6307" id="token-50-5" morph="none" pos="word" start_char="6306">to</TOKEN>
<TOKEN end_char="6314" id="token-50-6" morph="none" pos="word" start_char="6309">temper</TOKEN>
<TOKEN end_char="6327" id="token-50-7" morph="none" pos="word" start_char="6316">expectations</TOKEN>
<TOKEN end_char="6333" id="token-50-8" morph="none" pos="word" start_char="6329">ahead</TOKEN>
<TOKEN end_char="6336" id="token-50-9" morph="none" pos="word" start_char="6335">of</TOKEN>
<TOKEN end_char="6340" id="token-50-10" morph="none" pos="word" start_char="6338">the</TOKEN>
<TOKEN end_char="6354" id="token-50-11" morph="none" pos="word" start_char="6342">investigation</TOKEN>
<TOKEN end_char="6355" id="token-50-12" morph="none" pos="punct" start_char="6355">,</TOKEN>
<TOKEN end_char="6363" id="token-50-13" morph="none" pos="word" start_char="6357">warning</TOKEN>
<TOKEN end_char="6368" id="token-50-14" morph="none" pos="word" start_char="6365">that</TOKEN>
<TOKEN end_char="6377" id="token-50-15" morph="none" pos="word" start_char="6370">tracking</TOKEN>
<TOKEN end_char="6381" id="token-50-16" morph="none" pos="word" start_char="6379">any</TOKEN>
<TOKEN end_char="6385" id="token-50-17" morph="none" pos="word" start_char="6383">new</TOKEN>
<TOKEN end_char="6394" id="token-50-18" morph="none" pos="word" start_char="6387">pathogen</TOKEN>
<TOKEN end_char="6397" id="token-50-19" morph="none" pos="word" start_char="6396">is</TOKEN>
<TOKEN end_char="6399" id="token-50-20" morph="none" pos="word" start_char="6399">a</TOKEN>
<TOKEN end_char="6401" id="token-50-21" morph="none" pos="punct" start_char="6401">'</TOKEN>
<TOKEN end_char="6407" id="token-50-22" morph="none" pos="word" start_char="6402">riddle</TOKEN>
<TOKEN end_char="6412" id="token-50-23" morph="none" pos="word" start_char="6409">that</TOKEN>
<TOKEN end_char="6416" id="token-50-24" morph="none" pos="word" start_char="6414">can</TOKEN>
<TOKEN end_char="6421" id="token-50-25" morph="none" pos="word" start_char="6418">take</TOKEN>
<TOKEN end_char="6427" id="token-50-26" morph="none" pos="word" start_char="6423">years</TOKEN>
<TOKEN end_char="6430" id="token-50-27" morph="none" pos="word" start_char="6429">to</TOKEN>
<TOKEN end_char="6436" id="token-50-28" morph="none" pos="word" start_char="6432">solve</TOKEN>
<TOKEN end_char="6438" id="token-50-29" morph="none" pos="punct" start_char="6437">'.</TOKEN>
</SEG>
<SEG end_char="6638" id="segment-51" start_char="6441">
<ORIGINAL_TEXT>It took more than a year for scientists to prove MERS, another coronavirus, originated in camels in Saudi Arabia, and even longer to trace the original SARS back to bats in a cave in southern China.</ORIGINAL_TEXT>
<TOKEN end_char="6442" id="token-51-0" morph="none" pos="word" start_char="6441">It</TOKEN>
<TOKEN end_char="6447" id="token-51-1" morph="none" pos="word" start_char="6444">took</TOKEN>
<TOKEN end_char="6452" id="token-51-2" morph="none" pos="word" start_char="6449">more</TOKEN>
<TOKEN end_char="6457" id="token-51-3" morph="none" pos="word" start_char="6454">than</TOKEN>
<TOKEN end_char="6459" id="token-51-4" morph="none" pos="word" start_char="6459">a</TOKEN>
<TOKEN end_char="6464" id="token-51-5" morph="none" pos="word" start_char="6461">year</TOKEN>
<TOKEN end_char="6468" id="token-51-6" morph="none" pos="word" start_char="6466">for</TOKEN>
<TOKEN end_char="6479" id="token-51-7" morph="none" pos="word" start_char="6470">scientists</TOKEN>
<TOKEN end_char="6482" id="token-51-8" morph="none" pos="word" start_char="6481">to</TOKEN>
<TOKEN end_char="6488" id="token-51-9" morph="none" pos="word" start_char="6484">prove</TOKEN>
<TOKEN end_char="6493" id="token-51-10" morph="none" pos="word" start_char="6490">MERS</TOKEN>
<TOKEN end_char="6494" id="token-51-11" morph="none" pos="punct" start_char="6494">,</TOKEN>
<TOKEN end_char="6502" id="token-51-12" morph="none" pos="word" start_char="6496">another</TOKEN>
<TOKEN end_char="6514" id="token-51-13" morph="none" pos="word" start_char="6504">coronavirus</TOKEN>
<TOKEN end_char="6515" id="token-51-14" morph="none" pos="punct" start_char="6515">,</TOKEN>
<TOKEN end_char="6526" id="token-51-15" morph="none" pos="word" start_char="6517">originated</TOKEN>
<TOKEN end_char="6529" id="token-51-16" morph="none" pos="word" start_char="6528">in</TOKEN>
<TOKEN end_char="6536" id="token-51-17" morph="none" pos="word" start_char="6531">camels</TOKEN>
<TOKEN end_char="6539" id="token-51-18" morph="none" pos="word" start_char="6538">in</TOKEN>
<TOKEN end_char="6545" id="token-51-19" morph="none" pos="word" start_char="6541">Saudi</TOKEN>
<TOKEN end_char="6552" id="token-51-20" morph="none" pos="word" start_char="6547">Arabia</TOKEN>
<TOKEN end_char="6553" id="token-51-21" morph="none" pos="punct" start_char="6553">,</TOKEN>
<TOKEN end_char="6557" id="token-51-22" morph="none" pos="word" start_char="6555">and</TOKEN>
<TOKEN end_char="6562" id="token-51-23" morph="none" pos="word" start_char="6559">even</TOKEN>
<TOKEN end_char="6569" id="token-51-24" morph="none" pos="word" start_char="6564">longer</TOKEN>
<TOKEN end_char="6572" id="token-51-25" morph="none" pos="word" start_char="6571">to</TOKEN>
<TOKEN end_char="6578" id="token-51-26" morph="none" pos="word" start_char="6574">trace</TOKEN>
<TOKEN end_char="6582" id="token-51-27" morph="none" pos="word" start_char="6580">the</TOKEN>
<TOKEN end_char="6591" id="token-51-28" morph="none" pos="word" start_char="6584">original</TOKEN>
<TOKEN end_char="6596" id="token-51-29" morph="none" pos="word" start_char="6593">SARS</TOKEN>
<TOKEN end_char="6601" id="token-51-30" morph="none" pos="word" start_char="6598">back</TOKEN>
<TOKEN end_char="6604" id="token-51-31" morph="none" pos="word" start_char="6603">to</TOKEN>
<TOKEN end_char="6609" id="token-51-32" morph="none" pos="word" start_char="6606">bats</TOKEN>
<TOKEN end_char="6612" id="token-51-33" morph="none" pos="word" start_char="6611">in</TOKEN>
<TOKEN end_char="6614" id="token-51-34" morph="none" pos="word" start_char="6614">a</TOKEN>
<TOKEN end_char="6619" id="token-51-35" morph="none" pos="word" start_char="6616">cave</TOKEN>
<TOKEN end_char="6622" id="token-51-36" morph="none" pos="word" start_char="6621">in</TOKEN>
<TOKEN end_char="6631" id="token-51-37" morph="none" pos="word" start_char="6624">southern</TOKEN>
<TOKEN end_char="6637" id="token-51-38" morph="none" pos="word" start_char="6633">China</TOKEN>
<TOKEN end_char="6638" id="token-51-39" morph="none" pos="punct" start_char="6638">.</TOKEN>
</SEG>
<SEG end_char="6762" id="segment-52" start_char="6641">
<ORIGINAL_TEXT>The Chinese paper was also published shortly before the WHO released the details of scientists leading the probe in China.</ORIGINAL_TEXT>
<TOKEN end_char="6643" id="token-52-0" morph="none" pos="word" start_char="6641">The</TOKEN>
<TOKEN end_char="6651" id="token-52-1" morph="none" pos="word" start_char="6645">Chinese</TOKEN>
<TOKEN end_char="6657" id="token-52-2" morph="none" pos="word" start_char="6653">paper</TOKEN>
<TOKEN end_char="6661" id="token-52-3" morph="none" pos="word" start_char="6659">was</TOKEN>
<TOKEN end_char="6666" id="token-52-4" morph="none" pos="word" start_char="6663">also</TOKEN>
<TOKEN end_char="6676" id="token-52-5" morph="none" pos="word" start_char="6668">published</TOKEN>
<TOKEN end_char="6684" id="token-52-6" morph="none" pos="word" start_char="6678">shortly</TOKEN>
<TOKEN end_char="6691" id="token-52-7" morph="none" pos="word" start_char="6686">before</TOKEN>
<TOKEN end_char="6695" id="token-52-8" morph="none" pos="word" start_char="6693">the</TOKEN>
<TOKEN end_char="6699" id="token-52-9" morph="none" pos="word" start_char="6697">WHO</TOKEN>
<TOKEN end_char="6708" id="token-52-10" morph="none" pos="word" start_char="6701">released</TOKEN>
<TOKEN end_char="6712" id="token-52-11" morph="none" pos="word" start_char="6710">the</TOKEN>
<TOKEN end_char="6720" id="token-52-12" morph="none" pos="word" start_char="6714">details</TOKEN>
<TOKEN end_char="6723" id="token-52-13" morph="none" pos="word" start_char="6722">of</TOKEN>
<TOKEN end_char="6734" id="token-52-14" morph="none" pos="word" start_char="6725">scientists</TOKEN>
<TOKEN end_char="6742" id="token-52-15" morph="none" pos="word" start_char="6736">leading</TOKEN>
<TOKEN end_char="6746" id="token-52-16" morph="none" pos="word" start_char="6744">the</TOKEN>
<TOKEN end_char="6752" id="token-52-17" morph="none" pos="word" start_char="6748">probe</TOKEN>
<TOKEN end_char="6755" id="token-52-18" morph="none" pos="word" start_char="6754">in</TOKEN>
<TOKEN end_char="6761" id="token-52-19" morph="none" pos="word" start_char="6757">China</TOKEN>
<TOKEN end_char="6762" id="token-52-20" morph="none" pos="punct" start_char="6762">.</TOKEN>
</SEG>
<SEG end_char="6883" id="segment-53" start_char="6765">
<ORIGINAL_TEXT>The great cover-up of China: Beijing punished Covid whistleblower and claimed it came from US - so what CAN we believe?</ORIGINAL_TEXT>
<TOKEN end_char="6767" id="token-53-0" morph="none" pos="word" start_char="6765">The</TOKEN>
<TOKEN end_char="6773" id="token-53-1" morph="none" pos="word" start_char="6769">great</TOKEN>
<TOKEN end_char="6782" id="token-53-2" morph="none" pos="unknown" start_char="6775">cover-up</TOKEN>
<TOKEN end_char="6785" id="token-53-3" morph="none" pos="word" start_char="6784">of</TOKEN>
<TOKEN end_char="6791" id="token-53-4" morph="none" pos="word" start_char="6787">China</TOKEN>
<TOKEN end_char="6792" id="token-53-5" morph="none" pos="punct" start_char="6792">:</TOKEN>
<TOKEN end_char="6800" id="token-53-6" morph="none" pos="word" start_char="6794">Beijing</TOKEN>
<TOKEN end_char="6809" id="token-53-7" morph="none" pos="word" start_char="6802">punished</TOKEN>
<TOKEN end_char="6815" id="token-53-8" morph="none" pos="word" start_char="6811">Covid</TOKEN>
<TOKEN end_char="6829" id="token-53-9" morph="none" pos="word" start_char="6817">whistleblower</TOKEN>
<TOKEN end_char="6833" id="token-53-10" morph="none" pos="word" start_char="6831">and</TOKEN>
<TOKEN end_char="6841" id="token-53-11" morph="none" pos="word" start_char="6835">claimed</TOKEN>
<TOKEN end_char="6844" id="token-53-12" morph="none" pos="word" start_char="6843">it</TOKEN>
<TOKEN end_char="6849" id="token-53-13" morph="none" pos="word" start_char="6846">came</TOKEN>
<TOKEN end_char="6854" id="token-53-14" morph="none" pos="word" start_char="6851">from</TOKEN>
<TOKEN end_char="6857" id="token-53-15" morph="none" pos="word" start_char="6856">US</TOKEN>
<TOKEN end_char="6859" id="token-53-16" morph="none" pos="punct" start_char="6859">-</TOKEN>
<TOKEN end_char="6862" id="token-53-17" morph="none" pos="word" start_char="6861">so</TOKEN>
<TOKEN end_char="6867" id="token-53-18" morph="none" pos="word" start_char="6864">what</TOKEN>
<TOKEN end_char="6871" id="token-53-19" morph="none" pos="word" start_char="6869">CAN</TOKEN>
<TOKEN end_char="6874" id="token-53-20" morph="none" pos="word" start_char="6873">we</TOKEN>
<TOKEN end_char="6882" id="token-53-21" morph="none" pos="word" start_char="6876">believe</TOKEN>
<TOKEN end_char="6883" id="token-53-22" morph="none" pos="punct" start_char="6883">?</TOKEN>
</SEG>
<SEG end_char="6901" id="segment-54" start_char="6886">
<ORIGINAL_TEXT>Initial outbreak</ORIGINAL_TEXT>
<TOKEN end_char="6892" id="token-54-0" morph="none" pos="word" start_char="6886">Initial</TOKEN>
<TOKEN end_char="6901" id="token-54-1" morph="none" pos="word" start_char="6894">outbreak</TOKEN>
</SEG>
<SEG end_char="7066" id="segment-55" start_char="6904">
<ORIGINAL_TEXT>Doctors in China, including Li Wenliang, began reporting the existence of a new type of respiratory infection that was similar to SARS in early December last year.</ORIGINAL_TEXT>
<TOKEN end_char="6910" id="token-55-0" morph="none" pos="word" start_char="6904">Doctors</TOKEN>
<TOKEN end_char="6913" id="token-55-1" morph="none" pos="word" start_char="6912">in</TOKEN>
<TOKEN end_char="6919" id="token-55-2" morph="none" pos="word" start_char="6915">China</TOKEN>
<TOKEN end_char="6920" id="token-55-3" morph="none" pos="punct" start_char="6920">,</TOKEN>
<TOKEN end_char="6930" id="token-55-4" morph="none" pos="word" start_char="6922">including</TOKEN>
<TOKEN end_char="6933" id="token-55-5" morph="none" pos="word" start_char="6932">Li</TOKEN>
<TOKEN end_char="6942" id="token-55-6" morph="none" pos="word" start_char="6935">Wenliang</TOKEN>
<TOKEN end_char="6943" id="token-55-7" morph="none" pos="punct" start_char="6943">,</TOKEN>
<TOKEN end_char="6949" id="token-55-8" morph="none" pos="word" start_char="6945">began</TOKEN>
<TOKEN end_char="6959" id="token-55-9" morph="none" pos="word" start_char="6951">reporting</TOKEN>
<TOKEN end_char="6963" id="token-55-10" morph="none" pos="word" start_char="6961">the</TOKEN>
<TOKEN end_char="6973" id="token-55-11" morph="none" pos="word" start_char="6965">existence</TOKEN>
<TOKEN end_char="6976" id="token-55-12" morph="none" pos="word" start_char="6975">of</TOKEN>
<TOKEN end_char="6978" id="token-55-13" morph="none" pos="word" start_char="6978">a</TOKEN>
<TOKEN end_char="6982" id="token-55-14" morph="none" pos="word" start_char="6980">new</TOKEN>
<TOKEN end_char="6987" id="token-55-15" morph="none" pos="word" start_char="6984">type</TOKEN>
<TOKEN end_char="6990" id="token-55-16" morph="none" pos="word" start_char="6989">of</TOKEN>
<TOKEN end_char="7002" id="token-55-17" morph="none" pos="word" start_char="6992">respiratory</TOKEN>
<TOKEN end_char="7012" id="token-55-18" morph="none" pos="word" start_char="7004">infection</TOKEN>
<TOKEN end_char="7017" id="token-55-19" morph="none" pos="word" start_char="7014">that</TOKEN>
<TOKEN end_char="7021" id="token-55-20" morph="none" pos="word" start_char="7019">was</TOKEN>
<TOKEN end_char="7029" id="token-55-21" morph="none" pos="word" start_char="7023">similar</TOKEN>
<TOKEN end_char="7032" id="token-55-22" morph="none" pos="word" start_char="7031">to</TOKEN>
<TOKEN end_char="7037" id="token-55-23" morph="none" pos="word" start_char="7034">SARS</TOKEN>
<TOKEN end_char="7040" id="token-55-24" morph="none" pos="word" start_char="7039">in</TOKEN>
<TOKEN end_char="7046" id="token-55-25" morph="none" pos="word" start_char="7042">early</TOKEN>
<TOKEN end_char="7055" id="token-55-26" morph="none" pos="word" start_char="7048">December</TOKEN>
<TOKEN end_char="7060" id="token-55-27" morph="none" pos="word" start_char="7057">last</TOKEN>
<TOKEN end_char="7065" id="token-55-28" morph="none" pos="word" start_char="7062">year</TOKEN>
<TOKEN end_char="7066" id="token-55-29" morph="none" pos="punct" start_char="7066">.</TOKEN>
</SEG>
<SEG end_char="7249" id="segment-56" start_char="7069">
<ORIGINAL_TEXT>But rather than publicise the reports and warn the public, Chinese police hauled Wenliang and eight of his colleagues who had been posting about the virus online in for questioning.</ORIGINAL_TEXT>
<TOKEN end_char="7071" id="token-56-0" morph="none" pos="word" start_char="7069">But</TOKEN>
<TOKEN end_char="7078" id="token-56-1" morph="none" pos="word" start_char="7073">rather</TOKEN>
<TOKEN end_char="7083" id="token-56-2" morph="none" pos="word" start_char="7080">than</TOKEN>
<TOKEN end_char="7093" id="token-56-3" morph="none" pos="word" start_char="7085">publicise</TOKEN>
<TOKEN end_char="7097" id="token-56-4" morph="none" pos="word" start_char="7095">the</TOKEN>
<TOKEN end_char="7105" id="token-56-5" morph="none" pos="word" start_char="7099">reports</TOKEN>
<TOKEN end_char="7109" id="token-56-6" morph="none" pos="word" start_char="7107">and</TOKEN>
<TOKEN end_char="7114" id="token-56-7" morph="none" pos="word" start_char="7111">warn</TOKEN>
<TOKEN end_char="7118" id="token-56-8" morph="none" pos="word" start_char="7116">the</TOKEN>
<TOKEN end_char="7125" id="token-56-9" morph="none" pos="word" start_char="7120">public</TOKEN>
<TOKEN end_char="7126" id="token-56-10" morph="none" pos="punct" start_char="7126">,</TOKEN>
<TOKEN end_char="7134" id="token-56-11" morph="none" pos="word" start_char="7128">Chinese</TOKEN>
<TOKEN end_char="7141" id="token-56-12" morph="none" pos="word" start_char="7136">police</TOKEN>
<TOKEN end_char="7148" id="token-56-13" morph="none" pos="word" start_char="7143">hauled</TOKEN>
<TOKEN end_char="7157" id="token-56-14" morph="none" pos="word" start_char="7150">Wenliang</TOKEN>
<TOKEN end_char="7161" id="token-56-15" morph="none" pos="word" start_char="7159">and</TOKEN>
<TOKEN end_char="7167" id="token-56-16" morph="none" pos="word" start_char="7163">eight</TOKEN>
<TOKEN end_char="7170" id="token-56-17" morph="none" pos="word" start_char="7169">of</TOKEN>
<TOKEN end_char="7174" id="token-56-18" morph="none" pos="word" start_char="7172">his</TOKEN>
<TOKEN end_char="7185" id="token-56-19" morph="none" pos="word" start_char="7176">colleagues</TOKEN>
<TOKEN end_char="7189" id="token-56-20" morph="none" pos="word" start_char="7187">who</TOKEN>
<TOKEN end_char="7193" id="token-56-21" morph="none" pos="word" start_char="7191">had</TOKEN>
<TOKEN end_char="7198" id="token-56-22" morph="none" pos="word" start_char="7195">been</TOKEN>
<TOKEN end_char="7206" id="token-56-23" morph="none" pos="word" start_char="7200">posting</TOKEN>
<TOKEN end_char="7212" id="token-56-24" morph="none" pos="word" start_char="7208">about</TOKEN>
<TOKEN end_char="7216" id="token-56-25" morph="none" pos="word" start_char="7214">the</TOKEN>
<TOKEN end_char="7222" id="token-56-26" morph="none" pos="word" start_char="7218">virus</TOKEN>
<TOKEN end_char="7229" id="token-56-27" morph="none" pos="word" start_char="7224">online</TOKEN>
<TOKEN end_char="7232" id="token-56-28" morph="none" pos="word" start_char="7231">in</TOKEN>
<TOKEN end_char="7236" id="token-56-29" morph="none" pos="word" start_char="7234">for</TOKEN>
<TOKEN end_char="7248" id="token-56-30" morph="none" pos="word" start_char="7238">questioning</TOKEN>
<TOKEN end_char="7249" id="token-56-31" morph="none" pos="punct" start_char="7249">.</TOKEN>
</SEG>
<SEG end_char="7376" id="segment-57" start_char="7252">
<ORIGINAL_TEXT>Wenliang, who would later die from the virus, was forced to sign a document admitting the information he published was false.</ORIGINAL_TEXT>
<TOKEN end_char="7259" id="token-57-0" morph="none" pos="word" start_char="7252">Wenliang</TOKEN>
<TOKEN end_char="7260" id="token-57-1" morph="none" pos="punct" start_char="7260">,</TOKEN>
<TOKEN end_char="7264" id="token-57-2" morph="none" pos="word" start_char="7262">who</TOKEN>
<TOKEN end_char="7270" id="token-57-3" morph="none" pos="word" start_char="7266">would</TOKEN>
<TOKEN end_char="7276" id="token-57-4" morph="none" pos="word" start_char="7272">later</TOKEN>
<TOKEN end_char="7280" id="token-57-5" morph="none" pos="word" start_char="7278">die</TOKEN>
<TOKEN end_char="7285" id="token-57-6" morph="none" pos="word" start_char="7282">from</TOKEN>
<TOKEN end_char="7289" id="token-57-7" morph="none" pos="word" start_char="7287">the</TOKEN>
<TOKEN end_char="7295" id="token-57-8" morph="none" pos="word" start_char="7291">virus</TOKEN>
<TOKEN end_char="7296" id="token-57-9" morph="none" pos="punct" start_char="7296">,</TOKEN>
<TOKEN end_char="7300" id="token-57-10" morph="none" pos="word" start_char="7298">was</TOKEN>
<TOKEN end_char="7307" id="token-57-11" morph="none" pos="word" start_char="7302">forced</TOKEN>
<TOKEN end_char="7310" id="token-57-12" morph="none" pos="word" start_char="7309">to</TOKEN>
<TOKEN end_char="7315" id="token-57-13" morph="none" pos="word" start_char="7312">sign</TOKEN>
<TOKEN end_char="7317" id="token-57-14" morph="none" pos="word" start_char="7317">a</TOKEN>
<TOKEN end_char="7326" id="token-57-15" morph="none" pos="word" start_char="7319">document</TOKEN>
<TOKEN end_char="7336" id="token-57-16" morph="none" pos="word" start_char="7328">admitting</TOKEN>
<TOKEN end_char="7340" id="token-57-17" morph="none" pos="word" start_char="7338">the</TOKEN>
<TOKEN end_char="7352" id="token-57-18" morph="none" pos="word" start_char="7342">information</TOKEN>
<TOKEN end_char="7355" id="token-57-19" morph="none" pos="word" start_char="7354">he</TOKEN>
<TOKEN end_char="7365" id="token-57-20" morph="none" pos="word" start_char="7357">published</TOKEN>
<TOKEN end_char="7369" id="token-57-21" morph="none" pos="word" start_char="7367">was</TOKEN>
<TOKEN end_char="7375" id="token-57-22" morph="none" pos="word" start_char="7371">false</TOKEN>
<TOKEN end_char="7376" id="token-57-23" morph="none" pos="punct" start_char="7376">.</TOKEN>
</SEG>
<SEG end_char="7568" id="segment-58" start_char="7379">
<ORIGINAL_TEXT>While China has been widely-praised for a draconian lockdown that helped slow the spread of the virus, evidence suggests that the country could have acted much quicker to prevent the spread.</ORIGINAL_TEXT>
<TOKEN end_char="7383" id="token-58-0" morph="none" pos="word" start_char="7379">While</TOKEN>
<TOKEN end_char="7389" id="token-58-1" morph="none" pos="word" start_char="7385">China</TOKEN>
<TOKEN end_char="7393" id="token-58-2" morph="none" pos="word" start_char="7391">has</TOKEN>
<TOKEN end_char="7398" id="token-58-3" morph="none" pos="word" start_char="7395">been</TOKEN>
<TOKEN end_char="7413" id="token-58-4" morph="none" pos="unknown" start_char="7400">widely-praised</TOKEN>
<TOKEN end_char="7417" id="token-58-5" morph="none" pos="word" start_char="7415">for</TOKEN>
<TOKEN end_char="7419" id="token-58-6" morph="none" pos="word" start_char="7419">a</TOKEN>
<TOKEN end_char="7429" id="token-58-7" morph="none" pos="word" start_char="7421">draconian</TOKEN>
<TOKEN end_char="7438" id="token-58-8" morph="none" pos="word" start_char="7431">lockdown</TOKEN>
<TOKEN end_char="7443" id="token-58-9" morph="none" pos="word" start_char="7440">that</TOKEN>
<TOKEN end_char="7450" id="token-58-10" morph="none" pos="word" start_char="7445">helped</TOKEN>
<TOKEN end_char="7455" id="token-58-11" morph="none" pos="word" start_char="7452">slow</TOKEN>
<TOKEN end_char="7459" id="token-58-12" morph="none" pos="word" start_char="7457">the</TOKEN>
<TOKEN end_char="7466" id="token-58-13" morph="none" pos="word" start_char="7461">spread</TOKEN>
<TOKEN end_char="7469" id="token-58-14" morph="none" pos="word" start_char="7468">of</TOKEN>
<TOKEN end_char="7473" id="token-58-15" morph="none" pos="word" start_char="7471">the</TOKEN>
<TOKEN end_char="7479" id="token-58-16" morph="none" pos="word" start_char="7475">virus</TOKEN>
<TOKEN end_char="7480" id="token-58-17" morph="none" pos="punct" start_char="7480">,</TOKEN>
<TOKEN end_char="7489" id="token-58-18" morph="none" pos="word" start_char="7482">evidence</TOKEN>
<TOKEN end_char="7498" id="token-58-19" morph="none" pos="word" start_char="7491">suggests</TOKEN>
<TOKEN end_char="7503" id="token-58-20" morph="none" pos="word" start_char="7500">that</TOKEN>
<TOKEN end_char="7507" id="token-58-21" morph="none" pos="word" start_char="7505">the</TOKEN>
<TOKEN end_char="7515" id="token-58-22" morph="none" pos="word" start_char="7509">country</TOKEN>
<TOKEN end_char="7521" id="token-58-23" morph="none" pos="word" start_char="7517">could</TOKEN>
<TOKEN end_char="7526" id="token-58-24" morph="none" pos="word" start_char="7523">have</TOKEN>
<TOKEN end_char="7532" id="token-58-25" morph="none" pos="word" start_char="7528">acted</TOKEN>
<TOKEN end_char="7537" id="token-58-26" morph="none" pos="word" start_char="7534">much</TOKEN>
<TOKEN end_char="7545" id="token-58-27" morph="none" pos="word" start_char="7539">quicker</TOKEN>
<TOKEN end_char="7548" id="token-58-28" morph="none" pos="word" start_char="7547">to</TOKEN>
<TOKEN end_char="7556" id="token-58-29" morph="none" pos="word" start_char="7550">prevent</TOKEN>
<TOKEN end_char="7560" id="token-58-30" morph="none" pos="word" start_char="7558">the</TOKEN>
<TOKEN end_char="7567" id="token-58-31" morph="none" pos="word" start_char="7562">spread</TOKEN>
<TOKEN end_char="7568" id="token-58-32" morph="none" pos="punct" start_char="7568">.</TOKEN>
</SEG>
<SEG end_char="7724" id="segment-59" start_char="7573">
<ORIGINAL_TEXT>Dr Li Wenliang, one of the first Chinese medics to report the existence of the new coronavirus, was forced by police to confess to spreading false data.</ORIGINAL_TEXT>
<TOKEN end_char="7574" id="token-59-0" morph="none" pos="word" start_char="7573">Dr</TOKEN>
<TOKEN end_char="7577" id="token-59-1" morph="none" pos="word" start_char="7576">Li</TOKEN>
<TOKEN end_char="7586" id="token-59-2" morph="none" pos="word" start_char="7579">Wenliang</TOKEN>
<TOKEN end_char="7587" id="token-59-3" morph="none" pos="punct" start_char="7587">,</TOKEN>
<TOKEN end_char="7591" id="token-59-4" morph="none" pos="word" start_char="7589">one</TOKEN>
<TOKEN end_char="7594" id="token-59-5" morph="none" pos="word" start_char="7593">of</TOKEN>
<TOKEN end_char="7598" id="token-59-6" morph="none" pos="word" start_char="7596">the</TOKEN>
<TOKEN end_char="7604" id="token-59-7" morph="none" pos="word" start_char="7600">first</TOKEN>
<TOKEN end_char="7612" id="token-59-8" morph="none" pos="word" start_char="7606">Chinese</TOKEN>
<TOKEN end_char="7619" id="token-59-9" morph="none" pos="word" start_char="7614">medics</TOKEN>
<TOKEN end_char="7622" id="token-59-10" morph="none" pos="word" start_char="7621">to</TOKEN>
<TOKEN end_char="7629" id="token-59-11" morph="none" pos="word" start_char="7624">report</TOKEN>
<TOKEN end_char="7633" id="token-59-12" morph="none" pos="word" start_char="7631">the</TOKEN>
<TOKEN end_char="7643" id="token-59-13" morph="none" pos="word" start_char="7635">existence</TOKEN>
<TOKEN end_char="7646" id="token-59-14" morph="none" pos="word" start_char="7645">of</TOKEN>
<TOKEN end_char="7650" id="token-59-15" morph="none" pos="word" start_char="7648">the</TOKEN>
<TOKEN end_char="7654" id="token-59-16" morph="none" pos="word" start_char="7652">new</TOKEN>
<TOKEN end_char="7666" id="token-59-17" morph="none" pos="word" start_char="7656">coronavirus</TOKEN>
<TOKEN end_char="7667" id="token-59-18" morph="none" pos="punct" start_char="7667">,</TOKEN>
<TOKEN end_char="7671" id="token-59-19" morph="none" pos="word" start_char="7669">was</TOKEN>
<TOKEN end_char="7678" id="token-59-20" morph="none" pos="word" start_char="7673">forced</TOKEN>
<TOKEN end_char="7681" id="token-59-21" morph="none" pos="word" start_char="7680">by</TOKEN>
<TOKEN end_char="7688" id="token-59-22" morph="none" pos="word" start_char="7683">police</TOKEN>
<TOKEN end_char="7691" id="token-59-23" morph="none" pos="word" start_char="7690">to</TOKEN>
<TOKEN end_char="7699" id="token-59-24" morph="none" pos="word" start_char="7693">confess</TOKEN>
<TOKEN end_char="7702" id="token-59-25" morph="none" pos="word" start_char="7701">to</TOKEN>
<TOKEN end_char="7712" id="token-59-26" morph="none" pos="word" start_char="7704">spreading</TOKEN>
<TOKEN end_char="7718" id="token-59-27" morph="none" pos="word" start_char="7714">false</TOKEN>
<TOKEN end_char="7723" id="token-59-28" morph="none" pos="word" start_char="7720">data</TOKEN>
<TOKEN end_char="7724" id="token-59-29" morph="none" pos="punct" start_char="7724">.</TOKEN>
</SEG>
<SEG end_char="7753" id="segment-60" start_char="7726">
<ORIGINAL_TEXT>He later died from the virus</ORIGINAL_TEXT>
<TOKEN end_char="7727" id="token-60-0" morph="none" pos="word" start_char="7726">He</TOKEN>
<TOKEN end_char="7733" id="token-60-1" morph="none" pos="word" start_char="7729">later</TOKEN>
<TOKEN end_char="7738" id="token-60-2" morph="none" pos="word" start_char="7735">died</TOKEN>
<TOKEN end_char="7743" id="token-60-3" morph="none" pos="word" start_char="7740">from</TOKEN>
<TOKEN end_char="7747" id="token-60-4" morph="none" pos="word" start_char="7745">the</TOKEN>
<TOKEN end_char="7753" id="token-60-5" morph="none" pos="word" start_char="7749">virus</TOKEN>
</SEG>
<SEG end_char="7942" id="segment-61" start_char="7756">
<ORIGINAL_TEXT>Samples analysed as early as December 26 suggested a new type of SARS was circulating, the Washington Post reported, but Wuhan was not locked down until January 22 - almost a month later.</ORIGINAL_TEXT>
<TOKEN end_char="7762" id="token-61-0" morph="none" pos="word" start_char="7756">Samples</TOKEN>
<TOKEN end_char="7771" id="token-61-1" morph="none" pos="word" start_char="7764">analysed</TOKEN>
<TOKEN end_char="7774" id="token-61-2" morph="none" pos="word" start_char="7773">as</TOKEN>
<TOKEN end_char="7780" id="token-61-3" morph="none" pos="word" start_char="7776">early</TOKEN>
<TOKEN end_char="7783" id="token-61-4" morph="none" pos="word" start_char="7782">as</TOKEN>
<TOKEN end_char="7792" id="token-61-5" morph="none" pos="word" start_char="7785">December</TOKEN>
<TOKEN end_char="7795" id="token-61-6" morph="none" pos="word" start_char="7794">26</TOKEN>
<TOKEN end_char="7805" id="token-61-7" morph="none" pos="word" start_char="7797">suggested</TOKEN>
<TOKEN end_char="7807" id="token-61-8" morph="none" pos="word" start_char="7807">a</TOKEN>
<TOKEN end_char="7811" id="token-61-9" morph="none" pos="word" start_char="7809">new</TOKEN>
<TOKEN end_char="7816" id="token-61-10" morph="none" pos="word" start_char="7813">type</TOKEN>
<TOKEN end_char="7819" id="token-61-11" morph="none" pos="word" start_char="7818">of</TOKEN>
<TOKEN end_char="7824" id="token-61-12" morph="none" pos="word" start_char="7821">SARS</TOKEN>
<TOKEN end_char="7828" id="token-61-13" morph="none" pos="word" start_char="7826">was</TOKEN>
<TOKEN end_char="7840" id="token-61-14" morph="none" pos="word" start_char="7830">circulating</TOKEN>
<TOKEN end_char="7841" id="token-61-15" morph="none" pos="punct" start_char="7841">,</TOKEN>
<TOKEN end_char="7845" id="token-61-16" morph="none" pos="word" start_char="7843">the</TOKEN>
<TOKEN end_char="7856" id="token-61-17" morph="none" pos="word" start_char="7847">Washington</TOKEN>
<TOKEN end_char="7861" id="token-61-18" morph="none" pos="word" start_char="7858">Post</TOKEN>
<TOKEN end_char="7870" id="token-61-19" morph="none" pos="word" start_char="7863">reported</TOKEN>
<TOKEN end_char="7871" id="token-61-20" morph="none" pos="punct" start_char="7871">,</TOKEN>
<TOKEN end_char="7875" id="token-61-21" morph="none" pos="word" start_char="7873">but</TOKEN>
<TOKEN end_char="7881" id="token-61-22" morph="none" pos="word" start_char="7877">Wuhan</TOKEN>
<TOKEN end_char="7885" id="token-61-23" morph="none" pos="word" start_char="7883">was</TOKEN>
<TOKEN end_char="7889" id="token-61-24" morph="none" pos="word" start_char="7887">not</TOKEN>
<TOKEN end_char="7896" id="token-61-25" morph="none" pos="word" start_char="7891">locked</TOKEN>
<TOKEN end_char="7901" id="token-61-26" morph="none" pos="word" start_char="7898">down</TOKEN>
<TOKEN end_char="7907" id="token-61-27" morph="none" pos="word" start_char="7903">until</TOKEN>
<TOKEN end_char="7915" id="token-61-28" morph="none" pos="word" start_char="7909">January</TOKEN>
<TOKEN end_char="7918" id="token-61-29" morph="none" pos="word" start_char="7917">22</TOKEN>
<TOKEN end_char="7920" id="token-61-30" morph="none" pos="punct" start_char="7920">-</TOKEN>
<TOKEN end_char="7927" id="token-61-31" morph="none" pos="word" start_char="7922">almost</TOKEN>
<TOKEN end_char="7929" id="token-61-32" morph="none" pos="word" start_char="7929">a</TOKEN>
<TOKEN end_char="7935" id="token-61-33" morph="none" pos="word" start_char="7931">month</TOKEN>
<TOKEN end_char="7941" id="token-61-34" morph="none" pos="word" start_char="7937">later</TOKEN>
<TOKEN end_char="7942" id="token-61-35" morph="none" pos="punct" start_char="7942">.</TOKEN>
</SEG>
<SEG end_char="8142" id="segment-62" start_char="7945">
<ORIGINAL_TEXT>Wuhan's mayor also admitted an error that allowed 5million people to travel out of the city before the lockdown came into place without being checked for the virus, potentially helping it to spread.</ORIGINAL_TEXT>
<TOKEN end_char="7951" id="token-62-0" morph="none" pos="word" start_char="7945">Wuhan's</TOKEN>
<TOKEN end_char="7957" id="token-62-1" morph="none" pos="word" start_char="7953">mayor</TOKEN>
<TOKEN end_char="7962" id="token-62-2" morph="none" pos="word" start_char="7959">also</TOKEN>
<TOKEN end_char="7971" id="token-62-3" morph="none" pos="word" start_char="7964">admitted</TOKEN>
<TOKEN end_char="7974" id="token-62-4" morph="none" pos="word" start_char="7973">an</TOKEN>
<TOKEN end_char="7980" id="token-62-5" morph="none" pos="word" start_char="7976">error</TOKEN>
<TOKEN end_char="7985" id="token-62-6" morph="none" pos="word" start_char="7982">that</TOKEN>
<TOKEN end_char="7993" id="token-62-7" morph="none" pos="word" start_char="7987">allowed</TOKEN>
<TOKEN end_char="8002" id="token-62-8" morph="none" pos="word" start_char="7995">5million</TOKEN>
<TOKEN end_char="8009" id="token-62-9" morph="none" pos="word" start_char="8004">people</TOKEN>
<TOKEN end_char="8012" id="token-62-10" morph="none" pos="word" start_char="8011">to</TOKEN>
<TOKEN end_char="8019" id="token-62-11" morph="none" pos="word" start_char="8014">travel</TOKEN>
<TOKEN end_char="8023" id="token-62-12" morph="none" pos="word" start_char="8021">out</TOKEN>
<TOKEN end_char="8026" id="token-62-13" morph="none" pos="word" start_char="8025">of</TOKEN>
<TOKEN end_char="8030" id="token-62-14" morph="none" pos="word" start_char="8028">the</TOKEN>
<TOKEN end_char="8035" id="token-62-15" morph="none" pos="word" start_char="8032">city</TOKEN>
<TOKEN end_char="8042" id="token-62-16" morph="none" pos="word" start_char="8037">before</TOKEN>
<TOKEN end_char="8046" id="token-62-17" morph="none" pos="word" start_char="8044">the</TOKEN>
<TOKEN end_char="8055" id="token-62-18" morph="none" pos="word" start_char="8048">lockdown</TOKEN>
<TOKEN end_char="8060" id="token-62-19" morph="none" pos="word" start_char="8057">came</TOKEN>
<TOKEN end_char="8065" id="token-62-20" morph="none" pos="word" start_char="8062">into</TOKEN>
<TOKEN end_char="8071" id="token-62-21" morph="none" pos="word" start_char="8067">place</TOKEN>
<TOKEN end_char="8079" id="token-62-22" morph="none" pos="word" start_char="8073">without</TOKEN>
<TOKEN end_char="8085" id="token-62-23" morph="none" pos="word" start_char="8081">being</TOKEN>
<TOKEN end_char="8093" id="token-62-24" morph="none" pos="word" start_char="8087">checked</TOKEN>
<TOKEN end_char="8097" id="token-62-25" morph="none" pos="word" start_char="8095">for</TOKEN>
<TOKEN end_char="8101" id="token-62-26" morph="none" pos="word" start_char="8099">the</TOKEN>
<TOKEN end_char="8107" id="token-62-27" morph="none" pos="word" start_char="8103">virus</TOKEN>
<TOKEN end_char="8108" id="token-62-28" morph="none" pos="punct" start_char="8108">,</TOKEN>
<TOKEN end_char="8120" id="token-62-29" morph="none" pos="word" start_char="8110">potentially</TOKEN>
<TOKEN end_char="8128" id="token-62-30" morph="none" pos="word" start_char="8122">helping</TOKEN>
<TOKEN end_char="8131" id="token-62-31" morph="none" pos="word" start_char="8130">it</TOKEN>
<TOKEN end_char="8134" id="token-62-32" morph="none" pos="word" start_char="8133">to</TOKEN>
<TOKEN end_char="8141" id="token-62-33" morph="none" pos="word" start_char="8136">spread</TOKEN>
<TOKEN end_char="8142" id="token-62-34" morph="none" pos="punct" start_char="8142">.</TOKEN>
</SEG>
<SEG end_char="8302" id="segment-63" start_char="8145">
<ORIGINAL_TEXT>Chinese authorities have also been reluctant to had over information on the country's 'patient zero' - or the first person known to have contracted the virus.</ORIGINAL_TEXT>
<TOKEN end_char="8151" id="token-63-0" morph="none" pos="word" start_char="8145">Chinese</TOKEN>
<TOKEN end_char="8163" id="token-63-1" morph="none" pos="word" start_char="8153">authorities</TOKEN>
<TOKEN end_char="8168" id="token-63-2" morph="none" pos="word" start_char="8165">have</TOKEN>
<TOKEN end_char="8173" id="token-63-3" morph="none" pos="word" start_char="8170">also</TOKEN>
<TOKEN end_char="8178" id="token-63-4" morph="none" pos="word" start_char="8175">been</TOKEN>
<TOKEN end_char="8188" id="token-63-5" morph="none" pos="word" start_char="8180">reluctant</TOKEN>
<TOKEN end_char="8191" id="token-63-6" morph="none" pos="word" start_char="8190">to</TOKEN>
<TOKEN end_char="8195" id="token-63-7" morph="none" pos="word" start_char="8193">had</TOKEN>
<TOKEN end_char="8200" id="token-63-8" morph="none" pos="word" start_char="8197">over</TOKEN>
<TOKEN end_char="8212" id="token-63-9" morph="none" pos="word" start_char="8202">information</TOKEN>
<TOKEN end_char="8215" id="token-63-10" morph="none" pos="word" start_char="8214">on</TOKEN>
<TOKEN end_char="8219" id="token-63-11" morph="none" pos="word" start_char="8217">the</TOKEN>
<TOKEN end_char="8229" id="token-63-12" morph="none" pos="word" start_char="8221">country's</TOKEN>
<TOKEN end_char="8231" id="token-63-13" morph="none" pos="punct" start_char="8231">'</TOKEN>
<TOKEN end_char="8238" id="token-63-14" morph="none" pos="word" start_char="8232">patient</TOKEN>
<TOKEN end_char="8243" id="token-63-15" morph="none" pos="word" start_char="8240">zero</TOKEN>
<TOKEN end_char="8244" id="token-63-16" morph="none" pos="punct" start_char="8244">'</TOKEN>
<TOKEN end_char="8246" id="token-63-17" morph="none" pos="punct" start_char="8246">-</TOKEN>
<TOKEN end_char="8249" id="token-63-18" morph="none" pos="word" start_char="8248">or</TOKEN>
<TOKEN end_char="8253" id="token-63-19" morph="none" pos="word" start_char="8251">the</TOKEN>
<TOKEN end_char="8259" id="token-63-20" morph="none" pos="word" start_char="8255">first</TOKEN>
<TOKEN end_char="8266" id="token-63-21" morph="none" pos="word" start_char="8261">person</TOKEN>
<TOKEN end_char="8272" id="token-63-22" morph="none" pos="word" start_char="8268">known</TOKEN>
<TOKEN end_char="8275" id="token-63-23" morph="none" pos="word" start_char="8274">to</TOKEN>
<TOKEN end_char="8280" id="token-63-24" morph="none" pos="word" start_char="8277">have</TOKEN>
<TOKEN end_char="8291" id="token-63-25" morph="none" pos="word" start_char="8282">contracted</TOKEN>
<TOKEN end_char="8295" id="token-63-26" morph="none" pos="word" start_char="8293">the</TOKEN>
<TOKEN end_char="8301" id="token-63-27" morph="none" pos="word" start_char="8297">virus</TOKEN>
<TOKEN end_char="8302" id="token-63-28" morph="none" pos="punct" start_char="8302">.</TOKEN>
</SEG>
<SEG end_char="8494" id="segment-64" start_char="8305">
<ORIGINAL_TEXT>While Beijing claims the first infection took place on December 8, researchers have traced the virus back to at least December 1 and anecdotal evidence suggests it was spreading in November.</ORIGINAL_TEXT>
<TOKEN end_char="8309" id="token-64-0" morph="none" pos="word" start_char="8305">While</TOKEN>
<TOKEN end_char="8317" id="token-64-1" morph="none" pos="word" start_char="8311">Beijing</TOKEN>
<TOKEN end_char="8324" id="token-64-2" morph="none" pos="word" start_char="8319">claims</TOKEN>
<TOKEN end_char="8328" id="token-64-3" morph="none" pos="word" start_char="8326">the</TOKEN>
<TOKEN end_char="8334" id="token-64-4" morph="none" pos="word" start_char="8330">first</TOKEN>
<TOKEN end_char="8344" id="token-64-5" morph="none" pos="word" start_char="8336">infection</TOKEN>
<TOKEN end_char="8349" id="token-64-6" morph="none" pos="word" start_char="8346">took</TOKEN>
<TOKEN end_char="8355" id="token-64-7" morph="none" pos="word" start_char="8351">place</TOKEN>
<TOKEN end_char="8358" id="token-64-8" morph="none" pos="word" start_char="8357">on</TOKEN>
<TOKEN end_char="8367" id="token-64-9" morph="none" pos="word" start_char="8360">December</TOKEN>
<TOKEN end_char="8369" id="token-64-10" morph="none" pos="word" start_char="8369">8</TOKEN>
<TOKEN end_char="8370" id="token-64-11" morph="none" pos="punct" start_char="8370">,</TOKEN>
<TOKEN end_char="8382" id="token-64-12" morph="none" pos="word" start_char="8372">researchers</TOKEN>
<TOKEN end_char="8387" id="token-64-13" morph="none" pos="word" start_char="8384">have</TOKEN>
<TOKEN end_char="8394" id="token-64-14" morph="none" pos="word" start_char="8389">traced</TOKEN>
<TOKEN end_char="8398" id="token-64-15" morph="none" pos="word" start_char="8396">the</TOKEN>
<TOKEN end_char="8404" id="token-64-16" morph="none" pos="word" start_char="8400">virus</TOKEN>
<TOKEN end_char="8409" id="token-64-17" morph="none" pos="word" start_char="8406">back</TOKEN>
<TOKEN end_char="8412" id="token-64-18" morph="none" pos="word" start_char="8411">to</TOKEN>
<TOKEN end_char="8415" id="token-64-19" morph="none" pos="word" start_char="8414">at</TOKEN>
<TOKEN end_char="8421" id="token-64-20" morph="none" pos="word" start_char="8417">least</TOKEN>
<TOKEN end_char="8430" id="token-64-21" morph="none" pos="word" start_char="8423">December</TOKEN>
<TOKEN end_char="8432" id="token-64-22" morph="none" pos="word" start_char="8432">1</TOKEN>
<TOKEN end_char="8436" id="token-64-23" morph="none" pos="word" start_char="8434">and</TOKEN>
<TOKEN end_char="8446" id="token-64-24" morph="none" pos="word" start_char="8438">anecdotal</TOKEN>
<TOKEN end_char="8455" id="token-64-25" morph="none" pos="word" start_char="8448">evidence</TOKEN>
<TOKEN end_char="8464" id="token-64-26" morph="none" pos="word" start_char="8457">suggests</TOKEN>
<TOKEN end_char="8467" id="token-64-27" morph="none" pos="word" start_char="8466">it</TOKEN>
<TOKEN end_char="8471" id="token-64-28" morph="none" pos="word" start_char="8469">was</TOKEN>
<TOKEN end_char="8481" id="token-64-29" morph="none" pos="word" start_char="8473">spreading</TOKEN>
<TOKEN end_char="8484" id="token-64-30" morph="none" pos="word" start_char="8483">in</TOKEN>
<TOKEN end_char="8493" id="token-64-31" morph="none" pos="word" start_char="8486">November</TOKEN>
<TOKEN end_char="8494" id="token-64-32" morph="none" pos="punct" start_char="8494">.</TOKEN>
</SEG>
<SEG end_char="8636" id="segment-65" start_char="8497">
<ORIGINAL_TEXT>A lack of information about the first patient has meant scientists are still unclear how the disease made the leap from animals into humans.</ORIGINAL_TEXT>
<TOKEN end_char="8497" id="token-65-0" morph="none" pos="word" start_char="8497">A</TOKEN>
<TOKEN end_char="8502" id="token-65-1" morph="none" pos="word" start_char="8499">lack</TOKEN>
<TOKEN end_char="8505" id="token-65-2" morph="none" pos="word" start_char="8504">of</TOKEN>
<TOKEN end_char="8517" id="token-65-3" morph="none" pos="word" start_char="8507">information</TOKEN>
<TOKEN end_char="8523" id="token-65-4" morph="none" pos="word" start_char="8519">about</TOKEN>
<TOKEN end_char="8527" id="token-65-5" morph="none" pos="word" start_char="8525">the</TOKEN>
<TOKEN end_char="8533" id="token-65-6" morph="none" pos="word" start_char="8529">first</TOKEN>
<TOKEN end_char="8541" id="token-65-7" morph="none" pos="word" start_char="8535">patient</TOKEN>
<TOKEN end_char="8545" id="token-65-8" morph="none" pos="word" start_char="8543">has</TOKEN>
<TOKEN end_char="8551" id="token-65-9" morph="none" pos="word" start_char="8547">meant</TOKEN>
<TOKEN end_char="8562" id="token-65-10" morph="none" pos="word" start_char="8553">scientists</TOKEN>
<TOKEN end_char="8566" id="token-65-11" morph="none" pos="word" start_char="8564">are</TOKEN>
<TOKEN end_char="8572" id="token-65-12" morph="none" pos="word" start_char="8568">still</TOKEN>
<TOKEN end_char="8580" id="token-65-13" morph="none" pos="word" start_char="8574">unclear</TOKEN>
<TOKEN end_char="8584" id="token-65-14" morph="none" pos="word" start_char="8582">how</TOKEN>
<TOKEN end_char="8588" id="token-65-15" morph="none" pos="word" start_char="8586">the</TOKEN>
<TOKEN end_char="8596" id="token-65-16" morph="none" pos="word" start_char="8590">disease</TOKEN>
<TOKEN end_char="8601" id="token-65-17" morph="none" pos="word" start_char="8598">made</TOKEN>
<TOKEN end_char="8605" id="token-65-18" morph="none" pos="word" start_char="8603">the</TOKEN>
<TOKEN end_char="8610" id="token-65-19" morph="none" pos="word" start_char="8607">leap</TOKEN>
<TOKEN end_char="8615" id="token-65-20" morph="none" pos="word" start_char="8612">from</TOKEN>
<TOKEN end_char="8623" id="token-65-21" morph="none" pos="word" start_char="8617">animals</TOKEN>
<TOKEN end_char="8628" id="token-65-22" morph="none" pos="word" start_char="8625">into</TOKEN>
<TOKEN end_char="8635" id="token-65-23" morph="none" pos="word" start_char="8630">humans</TOKEN>
<TOKEN end_char="8636" id="token-65-24" morph="none" pos="punct" start_char="8636">.</TOKEN>
</SEG>
<SEG end_char="8802" id="segment-66" start_char="8639">
<ORIGINAL_TEXT>Theories include that it could have been carried by a bat or pangolin that was sold at a market in Wuhan and then eaten by someone, but this has not been confirmed.</ORIGINAL_TEXT>
<TOKEN end_char="8646" id="token-66-0" morph="none" pos="word" start_char="8639">Theories</TOKEN>
<TOKEN end_char="8654" id="token-66-1" morph="none" pos="word" start_char="8648">include</TOKEN>
<TOKEN end_char="8659" id="token-66-2" morph="none" pos="word" start_char="8656">that</TOKEN>
<TOKEN end_char="8662" id="token-66-3" morph="none" pos="word" start_char="8661">it</TOKEN>
<TOKEN end_char="8668" id="token-66-4" morph="none" pos="word" start_char="8664">could</TOKEN>
<TOKEN end_char="8673" id="token-66-5" morph="none" pos="word" start_char="8670">have</TOKEN>
<TOKEN end_char="8678" id="token-66-6" morph="none" pos="word" start_char="8675">been</TOKEN>
<TOKEN end_char="8686" id="token-66-7" morph="none" pos="word" start_char="8680">carried</TOKEN>
<TOKEN end_char="8689" id="token-66-8" morph="none" pos="word" start_char="8688">by</TOKEN>
<TOKEN end_char="8691" id="token-66-9" morph="none" pos="word" start_char="8691">a</TOKEN>
<TOKEN end_char="8695" id="token-66-10" morph="none" pos="word" start_char="8693">bat</TOKEN>
<TOKEN end_char="8698" id="token-66-11" morph="none" pos="word" start_char="8697">or</TOKEN>
<TOKEN end_char="8707" id="token-66-12" morph="none" pos="word" start_char="8700">pangolin</TOKEN>
<TOKEN end_char="8712" id="token-66-13" morph="none" pos="word" start_char="8709">that</TOKEN>
<TOKEN end_char="8716" id="token-66-14" morph="none" pos="word" start_char="8714">was</TOKEN>
<TOKEN end_char="8721" id="token-66-15" morph="none" pos="word" start_char="8718">sold</TOKEN>
<TOKEN end_char="8724" id="token-66-16" morph="none" pos="word" start_char="8723">at</TOKEN>
<TOKEN end_char="8726" id="token-66-17" morph="none" pos="word" start_char="8726">a</TOKEN>
<TOKEN end_char="8733" id="token-66-18" morph="none" pos="word" start_char="8728">market</TOKEN>
<TOKEN end_char="8736" id="token-66-19" morph="none" pos="word" start_char="8735">in</TOKEN>
<TOKEN end_char="8742" id="token-66-20" morph="none" pos="word" start_char="8738">Wuhan</TOKEN>
<TOKEN end_char="8746" id="token-66-21" morph="none" pos="word" start_char="8744">and</TOKEN>
<TOKEN end_char="8751" id="token-66-22" morph="none" pos="word" start_char="8748">then</TOKEN>
<TOKEN end_char="8757" id="token-66-23" morph="none" pos="word" start_char="8753">eaten</TOKEN>
<TOKEN end_char="8760" id="token-66-24" morph="none" pos="word" start_char="8759">by</TOKEN>
<TOKEN end_char="8768" id="token-66-25" morph="none" pos="word" start_char="8762">someone</TOKEN>
<TOKEN end_char="8769" id="token-66-26" morph="none" pos="punct" start_char="8769">,</TOKEN>
<TOKEN end_char="8773" id="token-66-27" morph="none" pos="word" start_char="8771">but</TOKEN>
<TOKEN end_char="8778" id="token-66-28" morph="none" pos="word" start_char="8775">this</TOKEN>
<TOKEN end_char="8782" id="token-66-29" morph="none" pos="word" start_char="8780">has</TOKEN>
<TOKEN end_char="8786" id="token-66-30" morph="none" pos="word" start_char="8784">not</TOKEN>
<TOKEN end_char="8791" id="token-66-31" morph="none" pos="word" start_char="8788">been</TOKEN>
<TOKEN end_char="8801" id="token-66-32" morph="none" pos="word" start_char="8793">confirmed</TOKEN>
<TOKEN end_char="8802" id="token-66-33" morph="none" pos="punct" start_char="8802">.</TOKEN>
</SEG>
<SEG end_char="8817" id="segment-67" start_char="8805">
<ORIGINAL_TEXT>Early reports</ORIGINAL_TEXT>
<TOKEN end_char="8809" id="token-67-0" morph="none" pos="word" start_char="8805">Early</TOKEN>
<TOKEN end_char="8817" id="token-67-1" morph="none" pos="word" start_char="8811">reports</TOKEN>
</SEG>
<SEG end_char="9026" id="segment-68" start_char="8820">
<ORIGINAL_TEXT>Chinese authorities initially reported that the virus could not spread person-to-person, despite evidence that it was spreading rapidly through the city of Wuhan including doctors being infected by patients.</ORIGINAL_TEXT>
<TOKEN end_char="8826" id="token-68-0" morph="none" pos="word" start_char="8820">Chinese</TOKEN>
<TOKEN end_char="8838" id="token-68-1" morph="none" pos="word" start_char="8828">authorities</TOKEN>
<TOKEN end_char="8848" id="token-68-2" morph="none" pos="word" start_char="8840">initially</TOKEN>
<TOKEN end_char="8857" id="token-68-3" morph="none" pos="word" start_char="8850">reported</TOKEN>
<TOKEN end_char="8862" id="token-68-4" morph="none" pos="word" start_char="8859">that</TOKEN>
<TOKEN end_char="8866" id="token-68-5" morph="none" pos="word" start_char="8864">the</TOKEN>
<TOKEN end_char="8872" id="token-68-6" morph="none" pos="word" start_char="8868">virus</TOKEN>
<TOKEN end_char="8878" id="token-68-7" morph="none" pos="word" start_char="8874">could</TOKEN>
<TOKEN end_char="8882" id="token-68-8" morph="none" pos="word" start_char="8880">not</TOKEN>
<TOKEN end_char="8889" id="token-68-9" morph="none" pos="word" start_char="8884">spread</TOKEN>
<TOKEN end_char="8906" id="token-68-10" morph="none" pos="unknown" start_char="8891">person-to-person</TOKEN>
<TOKEN end_char="8907" id="token-68-11" morph="none" pos="punct" start_char="8907">,</TOKEN>
<TOKEN end_char="8915" id="token-68-12" morph="none" pos="word" start_char="8909">despite</TOKEN>
<TOKEN end_char="8924" id="token-68-13" morph="none" pos="word" start_char="8917">evidence</TOKEN>
<TOKEN end_char="8929" id="token-68-14" morph="none" pos="word" start_char="8926">that</TOKEN>
<TOKEN end_char="8932" id="token-68-15" morph="none" pos="word" start_char="8931">it</TOKEN>
<TOKEN end_char="8936" id="token-68-16" morph="none" pos="word" start_char="8934">was</TOKEN>
<TOKEN end_char="8946" id="token-68-17" morph="none" pos="word" start_char="8938">spreading</TOKEN>
<TOKEN end_char="8954" id="token-68-18" morph="none" pos="word" start_char="8948">rapidly</TOKEN>
<TOKEN end_char="8962" id="token-68-19" morph="none" pos="word" start_char="8956">through</TOKEN>
<TOKEN end_char="8966" id="token-68-20" morph="none" pos="word" start_char="8964">the</TOKEN>
<TOKEN end_char="8971" id="token-68-21" morph="none" pos="word" start_char="8968">city</TOKEN>
<TOKEN end_char="8974" id="token-68-22" morph="none" pos="word" start_char="8973">of</TOKEN>
<TOKEN end_char="8980" id="token-68-23" morph="none" pos="word" start_char="8976">Wuhan</TOKEN>
<TOKEN end_char="8990" id="token-68-24" morph="none" pos="word" start_char="8982">including</TOKEN>
<TOKEN end_char="8998" id="token-68-25" morph="none" pos="word" start_char="8992">doctors</TOKEN>
<TOKEN end_char="9004" id="token-68-26" morph="none" pos="word" start_char="9000">being</TOKEN>
<TOKEN end_char="9013" id="token-68-27" morph="none" pos="word" start_char="9006">infected</TOKEN>
<TOKEN end_char="9016" id="token-68-28" morph="none" pos="word" start_char="9015">by</TOKEN>
<TOKEN end_char="9025" id="token-68-29" morph="none" pos="word" start_char="9018">patients</TOKEN>
<TOKEN end_char="9026" id="token-68-30" morph="none" pos="punct" start_char="9026">.</TOKEN>
</SEG>
<SEG end_char="9237" id="segment-69" start_char="9029">
<ORIGINAL_TEXT>This was used as justification for keeping the city of Wuhan operating as normal through a major CCP conference that was held between January 11 and 17, with authorities claiming zero new cases in this period.</ORIGINAL_TEXT>
<TOKEN end_char="9032" id="token-69-0" morph="none" pos="word" start_char="9029">This</TOKEN>
<TOKEN end_char="9036" id="token-69-1" morph="none" pos="word" start_char="9034">was</TOKEN>
<TOKEN end_char="9041" id="token-69-2" morph="none" pos="word" start_char="9038">used</TOKEN>
<TOKEN end_char="9044" id="token-69-3" morph="none" pos="word" start_char="9043">as</TOKEN>
<TOKEN end_char="9058" id="token-69-4" morph="none" pos="word" start_char="9046">justification</TOKEN>
<TOKEN end_char="9062" id="token-69-5" morph="none" pos="word" start_char="9060">for</TOKEN>
<TOKEN end_char="9070" id="token-69-6" morph="none" pos="word" start_char="9064">keeping</TOKEN>
<TOKEN end_char="9074" id="token-69-7" morph="none" pos="word" start_char="9072">the</TOKEN>
<TOKEN end_char="9079" id="token-69-8" morph="none" pos="word" start_char="9076">city</TOKEN>
<TOKEN end_char="9082" id="token-69-9" morph="none" pos="word" start_char="9081">of</TOKEN>
<TOKEN end_char="9088" id="token-69-10" morph="none" pos="word" start_char="9084">Wuhan</TOKEN>
<TOKEN end_char="9098" id="token-69-11" morph="none" pos="word" start_char="9090">operating</TOKEN>
<TOKEN end_char="9101" id="token-69-12" morph="none" pos="word" start_char="9100">as</TOKEN>
<TOKEN end_char="9108" id="token-69-13" morph="none" pos="word" start_char="9103">normal</TOKEN>
<TOKEN end_char="9116" id="token-69-14" morph="none" pos="word" start_char="9110">through</TOKEN>
<TOKEN end_char="9118" id="token-69-15" morph="none" pos="word" start_char="9118">a</TOKEN>
<TOKEN end_char="9124" id="token-69-16" morph="none" pos="word" start_char="9120">major</TOKEN>
<TOKEN end_char="9128" id="token-69-17" morph="none" pos="word" start_char="9126">CCP</TOKEN>
<TOKEN end_char="9139" id="token-69-18" morph="none" pos="word" start_char="9130">conference</TOKEN>
<TOKEN end_char="9144" id="token-69-19" morph="none" pos="word" start_char="9141">that</TOKEN>
<TOKEN end_char="9148" id="token-69-20" morph="none" pos="word" start_char="9146">was</TOKEN>
<TOKEN end_char="9153" id="token-69-21" morph="none" pos="word" start_char="9150">held</TOKEN>
<TOKEN end_char="9161" id="token-69-22" morph="none" pos="word" start_char="9155">between</TOKEN>
<TOKEN end_char="9169" id="token-69-23" morph="none" pos="word" start_char="9163">January</TOKEN>
<TOKEN end_char="9172" id="token-69-24" morph="none" pos="word" start_char="9171">11</TOKEN>
<TOKEN end_char="9176" id="token-69-25" morph="none" pos="word" start_char="9174">and</TOKEN>
<TOKEN end_char="9179" id="token-69-26" morph="none" pos="word" start_char="9178">17</TOKEN>
<TOKEN end_char="9180" id="token-69-27" morph="none" pos="punct" start_char="9180">,</TOKEN>
<TOKEN end_char="9185" id="token-69-28" morph="none" pos="word" start_char="9182">with</TOKEN>
<TOKEN end_char="9197" id="token-69-29" morph="none" pos="word" start_char="9187">authorities</TOKEN>
<TOKEN end_char="9206" id="token-69-30" morph="none" pos="word" start_char="9199">claiming</TOKEN>
<TOKEN end_char="9211" id="token-69-31" morph="none" pos="word" start_char="9208">zero</TOKEN>
<TOKEN end_char="9215" id="token-69-32" morph="none" pos="word" start_char="9213">new</TOKEN>
<TOKEN end_char="9221" id="token-69-33" morph="none" pos="word" start_char="9217">cases</TOKEN>
<TOKEN end_char="9224" id="token-69-34" morph="none" pos="word" start_char="9223">in</TOKEN>
<TOKEN end_char="9229" id="token-69-35" morph="none" pos="word" start_char="9226">this</TOKEN>
<TOKEN end_char="9236" id="token-69-36" morph="none" pos="word" start_char="9231">period</TOKEN>
<TOKEN end_char="9237" id="token-69-37" morph="none" pos="punct" start_char="9237">.</TOKEN>
</SEG>
<SEG end_char="9396" id="segment-70" start_char="9240">
<ORIGINAL_TEXT>China did not confirm human-to-human transmission of the virus until late January, when large parts of Hubei province including Wuhan were put into lockdown.</ORIGINAL_TEXT>
<TOKEN end_char="9244" id="token-70-0" morph="none" pos="word" start_char="9240">China</TOKEN>
<TOKEN end_char="9248" id="token-70-1" morph="none" pos="word" start_char="9246">did</TOKEN>
<TOKEN end_char="9252" id="token-70-2" morph="none" pos="word" start_char="9250">not</TOKEN>
<TOKEN end_char="9260" id="token-70-3" morph="none" pos="word" start_char="9254">confirm</TOKEN>
<TOKEN end_char="9275" id="token-70-4" morph="none" pos="unknown" start_char="9262">human-to-human</TOKEN>
<TOKEN end_char="9288" id="token-70-5" morph="none" pos="word" start_char="9277">transmission</TOKEN>
<TOKEN end_char="9291" id="token-70-6" morph="none" pos="word" start_char="9290">of</TOKEN>
<TOKEN end_char="9295" id="token-70-7" morph="none" pos="word" start_char="9293">the</TOKEN>
<TOKEN end_char="9301" id="token-70-8" morph="none" pos="word" start_char="9297">virus</TOKEN>
<TOKEN end_char="9307" id="token-70-9" morph="none" pos="word" start_char="9303">until</TOKEN>
<TOKEN end_char="9312" id="token-70-10" morph="none" pos="word" start_char="9309">late</TOKEN>
<TOKEN end_char="9320" id="token-70-11" morph="none" pos="word" start_char="9314">January</TOKEN>
<TOKEN end_char="9321" id="token-70-12" morph="none" pos="punct" start_char="9321">,</TOKEN>
<TOKEN end_char="9326" id="token-70-13" morph="none" pos="word" start_char="9323">when</TOKEN>
<TOKEN end_char="9332" id="token-70-14" morph="none" pos="word" start_char="9328">large</TOKEN>
<TOKEN end_char="9338" id="token-70-15" morph="none" pos="word" start_char="9334">parts</TOKEN>
<TOKEN end_char="9341" id="token-70-16" morph="none" pos="word" start_char="9340">of</TOKEN>
<TOKEN end_char="9347" id="token-70-17" morph="none" pos="word" start_char="9343">Hubei</TOKEN>
<TOKEN end_char="9356" id="token-70-18" morph="none" pos="word" start_char="9349">province</TOKEN>
<TOKEN end_char="9366" id="token-70-19" morph="none" pos="word" start_char="9358">including</TOKEN>
<TOKEN end_char="9372" id="token-70-20" morph="none" pos="word" start_char="9368">Wuhan</TOKEN>
<TOKEN end_char="9377" id="token-70-21" morph="none" pos="word" start_char="9374">were</TOKEN>
<TOKEN end_char="9381" id="token-70-22" morph="none" pos="word" start_char="9379">put</TOKEN>
<TOKEN end_char="9386" id="token-70-23" morph="none" pos="word" start_char="9383">into</TOKEN>
<TOKEN end_char="9395" id="token-70-24" morph="none" pos="word" start_char="9388">lockdown</TOKEN>
<TOKEN end_char="9396" id="token-70-25" morph="none" pos="punct" start_char="9396">.</TOKEN>
</SEG>
<SEG end_char="9600" id="segment-71" start_char="9400">
<ORIGINAL_TEXT>Despite reporting the existence of a 'novel type of pneumonia' to the World Health Organisation on December 31, Wuhan's largest newspaper also made no mention of the virus until the week of January 20.</ORIGINAL_TEXT>
<TOKEN end_char="9406" id="token-71-0" morph="none" pos="word" start_char="9400">Despite</TOKEN>
<TOKEN end_char="9416" id="token-71-1" morph="none" pos="word" start_char="9408">reporting</TOKEN>
<TOKEN end_char="9420" id="token-71-2" morph="none" pos="word" start_char="9418">the</TOKEN>
<TOKEN end_char="9430" id="token-71-3" morph="none" pos="word" start_char="9422">existence</TOKEN>
<TOKEN end_char="9433" id="token-71-4" morph="none" pos="word" start_char="9432">of</TOKEN>
<TOKEN end_char="9435" id="token-71-5" morph="none" pos="word" start_char="9435">a</TOKEN>
<TOKEN end_char="9437" id="token-71-6" morph="none" pos="punct" start_char="9437">'</TOKEN>
<TOKEN end_char="9442" id="token-71-7" morph="none" pos="word" start_char="9438">novel</TOKEN>
<TOKEN end_char="9447" id="token-71-8" morph="none" pos="word" start_char="9444">type</TOKEN>
<TOKEN end_char="9450" id="token-71-9" morph="none" pos="word" start_char="9449">of</TOKEN>
<TOKEN end_char="9460" id="token-71-10" morph="none" pos="word" start_char="9452">pneumonia</TOKEN>
<TOKEN end_char="9461" id="token-71-11" morph="none" pos="punct" start_char="9461">'</TOKEN>
<TOKEN end_char="9464" id="token-71-12" morph="none" pos="word" start_char="9463">to</TOKEN>
<TOKEN end_char="9468" id="token-71-13" morph="none" pos="word" start_char="9466">the</TOKEN>
<TOKEN end_char="9474" id="token-71-14" morph="none" pos="word" start_char="9470">World</TOKEN>
<TOKEN end_char="9481" id="token-71-15" morph="none" pos="word" start_char="9476">Health</TOKEN>
<TOKEN end_char="9494" id="token-71-16" morph="none" pos="word" start_char="9483">Organisation</TOKEN>
<TOKEN end_char="9497" id="token-71-17" morph="none" pos="word" start_char="9496">on</TOKEN>
<TOKEN end_char="9506" id="token-71-18" morph="none" pos="word" start_char="9499">December</TOKEN>
<TOKEN end_char="9509" id="token-71-19" morph="none" pos="word" start_char="9508">31</TOKEN>
<TOKEN end_char="9510" id="token-71-20" morph="none" pos="punct" start_char="9510">,</TOKEN>
<TOKEN end_char="9518" id="token-71-21" morph="none" pos="word" start_char="9512">Wuhan's</TOKEN>
<TOKEN end_char="9526" id="token-71-22" morph="none" pos="word" start_char="9520">largest</TOKEN>
<TOKEN end_char="9536" id="token-71-23" morph="none" pos="word" start_char="9528">newspaper</TOKEN>
<TOKEN end_char="9541" id="token-71-24" morph="none" pos="word" start_char="9538">also</TOKEN>
<TOKEN end_char="9546" id="token-71-25" morph="none" pos="word" start_char="9543">made</TOKEN>
<TOKEN end_char="9549" id="token-71-26" morph="none" pos="word" start_char="9548">no</TOKEN>
<TOKEN end_char="9557" id="token-71-27" morph="none" pos="word" start_char="9551">mention</TOKEN>
<TOKEN end_char="9560" id="token-71-28" morph="none" pos="word" start_char="9559">of</TOKEN>
<TOKEN end_char="9564" id="token-71-29" morph="none" pos="word" start_char="9562">the</TOKEN>
<TOKEN end_char="9570" id="token-71-30" morph="none" pos="word" start_char="9566">virus</TOKEN>
<TOKEN end_char="9576" id="token-71-31" morph="none" pos="word" start_char="9572">until</TOKEN>
<TOKEN end_char="9580" id="token-71-32" morph="none" pos="word" start_char="9578">the</TOKEN>
<TOKEN end_char="9585" id="token-71-33" morph="none" pos="word" start_char="9582">week</TOKEN>
<TOKEN end_char="9588" id="token-71-34" morph="none" pos="word" start_char="9587">of</TOKEN>
<TOKEN end_char="9596" id="token-71-35" morph="none" pos="word" start_char="9590">January</TOKEN>
<TOKEN end_char="9599" id="token-71-36" morph="none" pos="word" start_char="9598">20</TOKEN>
<TOKEN end_char="9600" id="token-71-37" morph="none" pos="punct" start_char="9600">.</TOKEN>
</SEG>
<SEG end_char="9707" id="segment-72" start_char="9603">
<ORIGINAL_TEXT>That meant people in the city were not taking precautions such as social distancing to stop it spreading.</ORIGINAL_TEXT>
<TOKEN end_char="9606" id="token-72-0" morph="none" pos="word" start_char="9603">That</TOKEN>
<TOKEN end_char="9612" id="token-72-1" morph="none" pos="word" start_char="9608">meant</TOKEN>
<TOKEN end_char="9619" id="token-72-2" morph="none" pos="word" start_char="9614">people</TOKEN>
<TOKEN end_char="9622" id="token-72-3" morph="none" pos="word" start_char="9621">in</TOKEN>
<TOKEN end_char="9626" id="token-72-4" morph="none" pos="word" start_char="9624">the</TOKEN>
<TOKEN end_char="9631" id="token-72-5" morph="none" pos="word" start_char="9628">city</TOKEN>
<TOKEN end_char="9636" id="token-72-6" morph="none" pos="word" start_char="9633">were</TOKEN>
<TOKEN end_char="9640" id="token-72-7" morph="none" pos="word" start_char="9638">not</TOKEN>
<TOKEN end_char="9647" id="token-72-8" morph="none" pos="word" start_char="9642">taking</TOKEN>
<TOKEN end_char="9659" id="token-72-9" morph="none" pos="word" start_char="9649">precautions</TOKEN>
<TOKEN end_char="9664" id="token-72-10" morph="none" pos="word" start_char="9661">such</TOKEN>
<TOKEN end_char="9667" id="token-72-11" morph="none" pos="word" start_char="9666">as</TOKEN>
<TOKEN end_char="9674" id="token-72-12" morph="none" pos="word" start_char="9669">social</TOKEN>
<TOKEN end_char="9685" id="token-72-13" morph="none" pos="word" start_char="9676">distancing</TOKEN>
<TOKEN end_char="9688" id="token-72-14" morph="none" pos="word" start_char="9687">to</TOKEN>
<TOKEN end_char="9693" id="token-72-15" morph="none" pos="word" start_char="9690">stop</TOKEN>
<TOKEN end_char="9696" id="token-72-16" morph="none" pos="word" start_char="9695">it</TOKEN>
<TOKEN end_char="9706" id="token-72-17" morph="none" pos="word" start_char="9698">spreading</TOKEN>
<TOKEN end_char="9707" id="token-72-18" morph="none" pos="punct" start_char="9707">.</TOKEN>
</SEG>
<SEG end_char="9898" id="segment-73" start_char="9710">
<ORIGINAL_TEXT>It also meant that people had begun travelling for the Lunar New Year holiday, which was due to start on January 24 and sees millions of people visit relatives, spreading the virus further.</ORIGINAL_TEXT>
<TOKEN end_char="9711" id="token-73-0" morph="none" pos="word" start_char="9710">It</TOKEN>
<TOKEN end_char="9716" id="token-73-1" morph="none" pos="word" start_char="9713">also</TOKEN>
<TOKEN end_char="9722" id="token-73-2" morph="none" pos="word" start_char="9718">meant</TOKEN>
<TOKEN end_char="9727" id="token-73-3" morph="none" pos="word" start_char="9724">that</TOKEN>
<TOKEN end_char="9734" id="token-73-4" morph="none" pos="word" start_char="9729">people</TOKEN>
<TOKEN end_char="9738" id="token-73-5" morph="none" pos="word" start_char="9736">had</TOKEN>
<TOKEN end_char="9744" id="token-73-6" morph="none" pos="word" start_char="9740">begun</TOKEN>
<TOKEN end_char="9755" id="token-73-7" morph="none" pos="word" start_char="9746">travelling</TOKEN>
<TOKEN end_char="9759" id="token-73-8" morph="none" pos="word" start_char="9757">for</TOKEN>
<TOKEN end_char="9763" id="token-73-9" morph="none" pos="word" start_char="9761">the</TOKEN>
<TOKEN end_char="9769" id="token-73-10" morph="none" pos="word" start_char="9765">Lunar</TOKEN>
<TOKEN end_char="9773" id="token-73-11" morph="none" pos="word" start_char="9771">New</TOKEN>
<TOKEN end_char="9778" id="token-73-12" morph="none" pos="word" start_char="9775">Year</TOKEN>
<TOKEN end_char="9786" id="token-73-13" morph="none" pos="word" start_char="9780">holiday</TOKEN>
<TOKEN end_char="9787" id="token-73-14" morph="none" pos="punct" start_char="9787">,</TOKEN>
<TOKEN end_char="9793" id="token-73-15" morph="none" pos="word" start_char="9789">which</TOKEN>
<TOKEN end_char="9797" id="token-73-16" morph="none" pos="word" start_char="9795">was</TOKEN>
<TOKEN end_char="9801" id="token-73-17" morph="none" pos="word" start_char="9799">due</TOKEN>
<TOKEN end_char="9804" id="token-73-18" morph="none" pos="word" start_char="9803">to</TOKEN>
<TOKEN end_char="9810" id="token-73-19" morph="none" pos="word" start_char="9806">start</TOKEN>
<TOKEN end_char="9813" id="token-73-20" morph="none" pos="word" start_char="9812">on</TOKEN>
<TOKEN end_char="9821" id="token-73-21" morph="none" pos="word" start_char="9815">January</TOKEN>
<TOKEN end_char="9824" id="token-73-22" morph="none" pos="word" start_char="9823">24</TOKEN>
<TOKEN end_char="9828" id="token-73-23" morph="none" pos="word" start_char="9826">and</TOKEN>
<TOKEN end_char="9833" id="token-73-24" morph="none" pos="word" start_char="9830">sees</TOKEN>
<TOKEN end_char="9842" id="token-73-25" morph="none" pos="word" start_char="9835">millions</TOKEN>
<TOKEN end_char="9845" id="token-73-26" morph="none" pos="word" start_char="9844">of</TOKEN>
<TOKEN end_char="9852" id="token-73-27" morph="none" pos="word" start_char="9847">people</TOKEN>
<TOKEN end_char="9858" id="token-73-28" morph="none" pos="word" start_char="9854">visit</TOKEN>
<TOKEN end_char="9868" id="token-73-29" morph="none" pos="word" start_char="9860">relatives</TOKEN>
<TOKEN end_char="9869" id="token-73-30" morph="none" pos="punct" start_char="9869">,</TOKEN>
<TOKEN end_char="9879" id="token-73-31" morph="none" pos="word" start_char="9871">spreading</TOKEN>
<TOKEN end_char="9883" id="token-73-32" morph="none" pos="word" start_char="9881">the</TOKEN>
<TOKEN end_char="9889" id="token-73-33" morph="none" pos="word" start_char="9885">virus</TOKEN>
<TOKEN end_char="9897" id="token-73-34" morph="none" pos="word" start_char="9891">further</TOKEN>
<TOKEN end_char="9898" id="token-73-35" morph="none" pos="punct" start_char="9898">.</TOKEN>
</SEG>
<SEG end_char="10128" id="segment-74" start_char="9901">
<ORIGINAL_TEXT>Furthermore, China delayed reports suggesting that some 14 per cent of patients who initially tested negative for the virus or who appeared to have recovered tested positive a second time, only confirming such cases in February.</ORIGINAL_TEXT>
<TOKEN end_char="9911" id="token-74-0" morph="none" pos="word" start_char="9901">Furthermore</TOKEN>
<TOKEN end_char="9912" id="token-74-1" morph="none" pos="punct" start_char="9912">,</TOKEN>
<TOKEN end_char="9918" id="token-74-2" morph="none" pos="word" start_char="9914">China</TOKEN>
<TOKEN end_char="9926" id="token-74-3" morph="none" pos="word" start_char="9920">delayed</TOKEN>
<TOKEN end_char="9934" id="token-74-4" morph="none" pos="word" start_char="9928">reports</TOKEN>
<TOKEN end_char="9945" id="token-74-5" morph="none" pos="word" start_char="9936">suggesting</TOKEN>
<TOKEN end_char="9950" id="token-74-6" morph="none" pos="word" start_char="9947">that</TOKEN>
<TOKEN end_char="9955" id="token-74-7" morph="none" pos="word" start_char="9952">some</TOKEN>
<TOKEN end_char="9958" id="token-74-8" morph="none" pos="word" start_char="9957">14</TOKEN>
<TOKEN end_char="9962" id="token-74-9" morph="none" pos="word" start_char="9960">per</TOKEN>
<TOKEN end_char="9967" id="token-74-10" morph="none" pos="word" start_char="9964">cent</TOKEN>
<TOKEN end_char="9970" id="token-74-11" morph="none" pos="word" start_char="9969">of</TOKEN>
<TOKEN end_char="9979" id="token-74-12" morph="none" pos="word" start_char="9972">patients</TOKEN>
<TOKEN end_char="9983" id="token-74-13" morph="none" pos="word" start_char="9981">who</TOKEN>
<TOKEN end_char="9993" id="token-74-14" morph="none" pos="word" start_char="9985">initially</TOKEN>
<TOKEN end_char="10000" id="token-74-15" morph="none" pos="word" start_char="9995">tested</TOKEN>
<TOKEN end_char="10009" id="token-74-16" morph="none" pos="word" start_char="10002">negative</TOKEN>
<TOKEN end_char="10013" id="token-74-17" morph="none" pos="word" start_char="10011">for</TOKEN>
<TOKEN end_char="10017" id="token-74-18" morph="none" pos="word" start_char="10015">the</TOKEN>
<TOKEN end_char="10023" id="token-74-19" morph="none" pos="word" start_char="10019">virus</TOKEN>
<TOKEN end_char="10026" id="token-74-20" morph="none" pos="word" start_char="10025">or</TOKEN>
<TOKEN end_char="10030" id="token-74-21" morph="none" pos="word" start_char="10028">who</TOKEN>
<TOKEN end_char="10039" id="token-74-22" morph="none" pos="word" start_char="10032">appeared</TOKEN>
<TOKEN end_char="10042" id="token-74-23" morph="none" pos="word" start_char="10041">to</TOKEN>
<TOKEN end_char="10047" id="token-74-24" morph="none" pos="word" start_char="10044">have</TOKEN>
<TOKEN end_char="10057" id="token-74-25" morph="none" pos="word" start_char="10049">recovered</TOKEN>
<TOKEN end_char="10064" id="token-74-26" morph="none" pos="word" start_char="10059">tested</TOKEN>
<TOKEN end_char="10073" id="token-74-27" morph="none" pos="word" start_char="10066">positive</TOKEN>
<TOKEN end_char="10075" id="token-74-28" morph="none" pos="word" start_char="10075">a</TOKEN>
<TOKEN end_char="10082" id="token-74-29" morph="none" pos="word" start_char="10077">second</TOKEN>
<TOKEN end_char="10087" id="token-74-30" morph="none" pos="word" start_char="10084">time</TOKEN>
<TOKEN end_char="10088" id="token-74-31" morph="none" pos="punct" start_char="10088">,</TOKEN>
<TOKEN end_char="10093" id="token-74-32" morph="none" pos="word" start_char="10090">only</TOKEN>
<TOKEN end_char="10104" id="token-74-33" morph="none" pos="word" start_char="10095">confirming</TOKEN>
<TOKEN end_char="10109" id="token-74-34" morph="none" pos="word" start_char="10106">such</TOKEN>
<TOKEN end_char="10115" id="token-74-35" morph="none" pos="word" start_char="10111">cases</TOKEN>
<TOKEN end_char="10118" id="token-74-36" morph="none" pos="word" start_char="10117">in</TOKEN>
<TOKEN end_char="10127" id="token-74-37" morph="none" pos="word" start_char="10120">February</TOKEN>
<TOKEN end_char="10128" id="token-74-38" morph="none" pos="punct" start_char="10128">.</TOKEN>
</SEG>
<SEG end_char="10348" id="segment-75" start_char="10131">
<ORIGINAL_TEXT>That further hampered efforts at early containment of the virus in places such as Japan, where patients who tested negative on board the Diamond Princess cruise ship were allowed to leave - only to test positive later.</ORIGINAL_TEXT>
<TOKEN end_char="10134" id="token-75-0" morph="none" pos="word" start_char="10131">That</TOKEN>
<TOKEN end_char="10142" id="token-75-1" morph="none" pos="word" start_char="10136">further</TOKEN>
<TOKEN end_char="10151" id="token-75-2" morph="none" pos="word" start_char="10144">hampered</TOKEN>
<TOKEN end_char="10159" id="token-75-3" morph="none" pos="word" start_char="10153">efforts</TOKEN>
<TOKEN end_char="10162" id="token-75-4" morph="none" pos="word" start_char="10161">at</TOKEN>
<TOKEN end_char="10168" id="token-75-5" morph="none" pos="word" start_char="10164">early</TOKEN>
<TOKEN end_char="10180" id="token-75-6" morph="none" pos="word" start_char="10170">containment</TOKEN>
<TOKEN end_char="10183" id="token-75-7" morph="none" pos="word" start_char="10182">of</TOKEN>
<TOKEN end_char="10187" id="token-75-8" morph="none" pos="word" start_char="10185">the</TOKEN>
<TOKEN end_char="10193" id="token-75-9" morph="none" pos="word" start_char="10189">virus</TOKEN>
<TOKEN end_char="10196" id="token-75-10" morph="none" pos="word" start_char="10195">in</TOKEN>
<TOKEN end_char="10203" id="token-75-11" morph="none" pos="word" start_char="10198">places</TOKEN>
<TOKEN end_char="10208" id="token-75-12" morph="none" pos="word" start_char="10205">such</TOKEN>
<TOKEN end_char="10211" id="token-75-13" morph="none" pos="word" start_char="10210">as</TOKEN>
<TOKEN end_char="10217" id="token-75-14" morph="none" pos="word" start_char="10213">Japan</TOKEN>
<TOKEN end_char="10218" id="token-75-15" morph="none" pos="punct" start_char="10218">,</TOKEN>
<TOKEN end_char="10224" id="token-75-16" morph="none" pos="word" start_char="10220">where</TOKEN>
<TOKEN end_char="10233" id="token-75-17" morph="none" pos="word" start_char="10226">patients</TOKEN>
<TOKEN end_char="10237" id="token-75-18" morph="none" pos="word" start_char="10235">who</TOKEN>
<TOKEN end_char="10244" id="token-75-19" morph="none" pos="word" start_char="10239">tested</TOKEN>
<TOKEN end_char="10253" id="token-75-20" morph="none" pos="word" start_char="10246">negative</TOKEN>
<TOKEN end_char="10256" id="token-75-21" morph="none" pos="word" start_char="10255">on</TOKEN>
<TOKEN end_char="10262" id="token-75-22" morph="none" pos="word" start_char="10258">board</TOKEN>
<TOKEN end_char="10266" id="token-75-23" morph="none" pos="word" start_char="10264">the</TOKEN>
<TOKEN end_char="10274" id="token-75-24" morph="none" pos="word" start_char="10268">Diamond</TOKEN>
<TOKEN end_char="10283" id="token-75-25" morph="none" pos="word" start_char="10276">Princess</TOKEN>
<TOKEN end_char="10290" id="token-75-26" morph="none" pos="word" start_char="10285">cruise</TOKEN>
<TOKEN end_char="10295" id="token-75-27" morph="none" pos="word" start_char="10292">ship</TOKEN>
<TOKEN end_char="10300" id="token-75-28" morph="none" pos="word" start_char="10297">were</TOKEN>
<TOKEN end_char="10308" id="token-75-29" morph="none" pos="word" start_char="10302">allowed</TOKEN>
<TOKEN end_char="10311" id="token-75-30" morph="none" pos="word" start_char="10310">to</TOKEN>
<TOKEN end_char="10317" id="token-75-31" morph="none" pos="word" start_char="10313">leave</TOKEN>
<TOKEN end_char="10319" id="token-75-32" morph="none" pos="punct" start_char="10319">-</TOKEN>
<TOKEN end_char="10324" id="token-75-33" morph="none" pos="word" start_char="10321">only</TOKEN>
<TOKEN end_char="10327" id="token-75-34" morph="none" pos="word" start_char="10326">to</TOKEN>
<TOKEN end_char="10332" id="token-75-35" morph="none" pos="word" start_char="10329">test</TOKEN>
<TOKEN end_char="10341" id="token-75-36" morph="none" pos="word" start_char="10334">positive</TOKEN>
<TOKEN end_char="10347" id="token-75-37" morph="none" pos="word" start_char="10343">later</TOKEN>
<TOKEN end_char="10348" id="token-75-38" morph="none" pos="punct" start_char="10348">.</TOKEN>
</SEG>
<SEG end_char="10551" id="segment-76" start_char="10351">
<ORIGINAL_TEXT>Authorities in Beijing were also slow to report the deaths of two doctors from the virus, including one who was killed on January 25 but whose death was not reported by state media until a month later.</ORIGINAL_TEXT>
<TOKEN end_char="10361" id="token-76-0" morph="none" pos="word" start_char="10351">Authorities</TOKEN>
<TOKEN end_char="10364" id="token-76-1" morph="none" pos="word" start_char="10363">in</TOKEN>
<TOKEN end_char="10372" id="token-76-2" morph="none" pos="word" start_char="10366">Beijing</TOKEN>
<TOKEN end_char="10377" id="token-76-3" morph="none" pos="word" start_char="10374">were</TOKEN>
<TOKEN end_char="10382" id="token-76-4" morph="none" pos="word" start_char="10379">also</TOKEN>
<TOKEN end_char="10387" id="token-76-5" morph="none" pos="word" start_char="10384">slow</TOKEN>
<TOKEN end_char="10390" id="token-76-6" morph="none" pos="word" start_char="10389">to</TOKEN>
<TOKEN end_char="10397" id="token-76-7" morph="none" pos="word" start_char="10392">report</TOKEN>
<TOKEN end_char="10401" id="token-76-8" morph="none" pos="word" start_char="10399">the</TOKEN>
<TOKEN end_char="10408" id="token-76-9" morph="none" pos="word" start_char="10403">deaths</TOKEN>
<TOKEN end_char="10411" id="token-76-10" morph="none" pos="word" start_char="10410">of</TOKEN>
<TOKEN end_char="10415" id="token-76-11" morph="none" pos="word" start_char="10413">two</TOKEN>
<TOKEN end_char="10423" id="token-76-12" morph="none" pos="word" start_char="10417">doctors</TOKEN>
<TOKEN end_char="10428" id="token-76-13" morph="none" pos="word" start_char="10425">from</TOKEN>
<TOKEN end_char="10432" id="token-76-14" morph="none" pos="word" start_char="10430">the</TOKEN>
<TOKEN end_char="10438" id="token-76-15" morph="none" pos="word" start_char="10434">virus</TOKEN>
<TOKEN end_char="10439" id="token-76-16" morph="none" pos="punct" start_char="10439">,</TOKEN>
<TOKEN end_char="10449" id="token-76-17" morph="none" pos="word" start_char="10441">including</TOKEN>
<TOKEN end_char="10453" id="token-76-18" morph="none" pos="word" start_char="10451">one</TOKEN>
<TOKEN end_char="10457" id="token-76-19" morph="none" pos="word" start_char="10455">who</TOKEN>
<TOKEN end_char="10461" id="token-76-20" morph="none" pos="word" start_char="10459">was</TOKEN>
<TOKEN end_char="10468" id="token-76-21" morph="none" pos="word" start_char="10463">killed</TOKEN>
<TOKEN end_char="10471" id="token-76-22" morph="none" pos="word" start_char="10470">on</TOKEN>
<TOKEN end_char="10479" id="token-76-23" morph="none" pos="word" start_char="10473">January</TOKEN>
<TOKEN end_char="10482" id="token-76-24" morph="none" pos="word" start_char="10481">25</TOKEN>
<TOKEN end_char="10486" id="token-76-25" morph="none" pos="word" start_char="10484">but</TOKEN>
<TOKEN end_char="10492" id="token-76-26" morph="none" pos="word" start_char="10488">whose</TOKEN>
<TOKEN end_char="10498" id="token-76-27" morph="none" pos="word" start_char="10494">death</TOKEN>
<TOKEN end_char="10502" id="token-76-28" morph="none" pos="word" start_char="10500">was</TOKEN>
<TOKEN end_char="10506" id="token-76-29" morph="none" pos="word" start_char="10504">not</TOKEN>
<TOKEN end_char="10515" id="token-76-30" morph="none" pos="word" start_char="10508">reported</TOKEN>
<TOKEN end_char="10518" id="token-76-31" morph="none" pos="word" start_char="10517">by</TOKEN>
<TOKEN end_char="10524" id="token-76-32" morph="none" pos="word" start_char="10520">state</TOKEN>
<TOKEN end_char="10530" id="token-76-33" morph="none" pos="word" start_char="10526">media</TOKEN>
<TOKEN end_char="10536" id="token-76-34" morph="none" pos="word" start_char="10532">until</TOKEN>
<TOKEN end_char="10538" id="token-76-35" morph="none" pos="word" start_char="10538">a</TOKEN>
<TOKEN end_char="10544" id="token-76-36" morph="none" pos="word" start_char="10540">month</TOKEN>
<TOKEN end_char="10550" id="token-76-37" morph="none" pos="word" start_char="10546">later</TOKEN>
<TOKEN end_char="10551" id="token-76-38" morph="none" pos="punct" start_char="10551">.</TOKEN>
</SEG>
<SEG end_char="10573" id="segment-77" start_char="10555">
<ORIGINAL_TEXT>Origin of the virus</ORIGINAL_TEXT>
<TOKEN end_char="10560" id="token-77-0" morph="none" pos="word" start_char="10555">Origin</TOKEN>
<TOKEN end_char="10563" id="token-77-1" morph="none" pos="word" start_char="10562">of</TOKEN>
<TOKEN end_char="10567" id="token-77-2" morph="none" pos="word" start_char="10565">the</TOKEN>
<TOKEN end_char="10573" id="token-77-3" morph="none" pos="word" start_char="10569">virus</TOKEN>
</SEG>
<SEG end_char="10777" id="segment-78" start_char="10576">
<ORIGINAL_TEXT>Despite early admissions that the virus began in the city of Wuhan, China later back-tracked - even going so far as to suggest American troops had brought the infection over after visiting the province.</ORIGINAL_TEXT>
<TOKEN end_char="10582" id="token-78-0" morph="none" pos="word" start_char="10576">Despite</TOKEN>
<TOKEN end_char="10588" id="token-78-1" morph="none" pos="word" start_char="10584">early</TOKEN>
<TOKEN end_char="10599" id="token-78-2" morph="none" pos="word" start_char="10590">admissions</TOKEN>
<TOKEN end_char="10604" id="token-78-3" morph="none" pos="word" start_char="10601">that</TOKEN>
<TOKEN end_char="10608" id="token-78-4" morph="none" pos="word" start_char="10606">the</TOKEN>
<TOKEN end_char="10614" id="token-78-5" morph="none" pos="word" start_char="10610">virus</TOKEN>
<TOKEN end_char="10620" id="token-78-6" morph="none" pos="word" start_char="10616">began</TOKEN>
<TOKEN end_char="10623" id="token-78-7" morph="none" pos="word" start_char="10622">in</TOKEN>
<TOKEN end_char="10627" id="token-78-8" morph="none" pos="word" start_char="10625">the</TOKEN>
<TOKEN end_char="10632" id="token-78-9" morph="none" pos="word" start_char="10629">city</TOKEN>
<TOKEN end_char="10635" id="token-78-10" morph="none" pos="word" start_char="10634">of</TOKEN>
<TOKEN end_char="10641" id="token-78-11" morph="none" pos="word" start_char="10637">Wuhan</TOKEN>
<TOKEN end_char="10642" id="token-78-12" morph="none" pos="punct" start_char="10642">,</TOKEN>
<TOKEN end_char="10648" id="token-78-13" morph="none" pos="word" start_char="10644">China</TOKEN>
<TOKEN end_char="10654" id="token-78-14" morph="none" pos="word" start_char="10650">later</TOKEN>
<TOKEN end_char="10667" id="token-78-15" morph="none" pos="unknown" start_char="10656">back-tracked</TOKEN>
<TOKEN end_char="10669" id="token-78-16" morph="none" pos="punct" start_char="10669">-</TOKEN>
<TOKEN end_char="10674" id="token-78-17" morph="none" pos="word" start_char="10671">even</TOKEN>
<TOKEN end_char="10680" id="token-78-18" morph="none" pos="word" start_char="10676">going</TOKEN>
<TOKEN end_char="10683" id="token-78-19" morph="none" pos="word" start_char="10682">so</TOKEN>
<TOKEN end_char="10687" id="token-78-20" morph="none" pos="word" start_char="10685">far</TOKEN>
<TOKEN end_char="10690" id="token-78-21" morph="none" pos="word" start_char="10689">as</TOKEN>
<TOKEN end_char="10693" id="token-78-22" morph="none" pos="word" start_char="10692">to</TOKEN>
<TOKEN end_char="10701" id="token-78-23" morph="none" pos="word" start_char="10695">suggest</TOKEN>
<TOKEN end_char="10710" id="token-78-24" morph="none" pos="word" start_char="10703">American</TOKEN>
<TOKEN end_char="10717" id="token-78-25" morph="none" pos="word" start_char="10712">troops</TOKEN>
<TOKEN end_char="10721" id="token-78-26" morph="none" pos="word" start_char="10719">had</TOKEN>
<TOKEN end_char="10729" id="token-78-27" morph="none" pos="word" start_char="10723">brought</TOKEN>
<TOKEN end_char="10733" id="token-78-28" morph="none" pos="word" start_char="10731">the</TOKEN>
<TOKEN end_char="10743" id="token-78-29" morph="none" pos="word" start_char="10735">infection</TOKEN>
<TOKEN end_char="10748" id="token-78-30" morph="none" pos="word" start_char="10745">over</TOKEN>
<TOKEN end_char="10754" id="token-78-31" morph="none" pos="word" start_char="10750">after</TOKEN>
<TOKEN end_char="10763" id="token-78-32" morph="none" pos="word" start_char="10756">visiting</TOKEN>
<TOKEN end_char="10767" id="token-78-33" morph="none" pos="word" start_char="10765">the</TOKEN>
<TOKEN end_char="10776" id="token-78-34" morph="none" pos="word" start_char="10769">province</TOKEN>
<TOKEN end_char="10777" id="token-78-35" morph="none" pos="punct" start_char="10777">.</TOKEN>
</SEG>
<SEG end_char="10931" id="segment-79" start_char="10780">
<ORIGINAL_TEXT>Lijian Zhao, a prominent official within the Chinese Foreign Ministry, tweeted out the claim on March 12 while providing no evidence to substantiate it.</ORIGINAL_TEXT>
<TOKEN end_char="10785" id="token-79-0" morph="none" pos="word" start_char="10780">Lijian</TOKEN>
<TOKEN end_char="10790" id="token-79-1" morph="none" pos="word" start_char="10787">Zhao</TOKEN>
<TOKEN end_char="10791" id="token-79-2" morph="none" pos="punct" start_char="10791">,</TOKEN>
<TOKEN end_char="10793" id="token-79-3" morph="none" pos="word" start_char="10793">a</TOKEN>
<TOKEN end_char="10803" id="token-79-4" morph="none" pos="word" start_char="10795">prominent</TOKEN>
<TOKEN end_char="10812" id="token-79-5" morph="none" pos="word" start_char="10805">official</TOKEN>
<TOKEN end_char="10819" id="token-79-6" morph="none" pos="word" start_char="10814">within</TOKEN>
<TOKEN end_char="10823" id="token-79-7" morph="none" pos="word" start_char="10821">the</TOKEN>
<TOKEN end_char="10831" id="token-79-8" morph="none" pos="word" start_char="10825">Chinese</TOKEN>
<TOKEN end_char="10839" id="token-79-9" morph="none" pos="word" start_char="10833">Foreign</TOKEN>
<TOKEN end_char="10848" id="token-79-10" morph="none" pos="word" start_char="10841">Ministry</TOKEN>
<TOKEN end_char="10849" id="token-79-11" morph="none" pos="punct" start_char="10849">,</TOKEN>
<TOKEN end_char="10857" id="token-79-12" morph="none" pos="word" start_char="10851">tweeted</TOKEN>
<TOKEN end_char="10861" id="token-79-13" morph="none" pos="word" start_char="10859">out</TOKEN>
<TOKEN end_char="10865" id="token-79-14" morph="none" pos="word" start_char="10863">the</TOKEN>
<TOKEN end_char="10871" id="token-79-15" morph="none" pos="word" start_char="10867">claim</TOKEN>
<TOKEN end_char="10874" id="token-79-16" morph="none" pos="word" start_char="10873">on</TOKEN>
<TOKEN end_char="10880" id="token-79-17" morph="none" pos="word" start_char="10876">March</TOKEN>
<TOKEN end_char="10883" id="token-79-18" morph="none" pos="word" start_char="10882">12</TOKEN>
<TOKEN end_char="10889" id="token-79-19" morph="none" pos="word" start_char="10885">while</TOKEN>
<TOKEN end_char="10899" id="token-79-20" morph="none" pos="word" start_char="10891">providing</TOKEN>
<TOKEN end_char="10902" id="token-79-21" morph="none" pos="word" start_char="10901">no</TOKEN>
<TOKEN end_char="10911" id="token-79-22" morph="none" pos="word" start_char="10904">evidence</TOKEN>
<TOKEN end_char="10914" id="token-79-23" morph="none" pos="word" start_char="10913">to</TOKEN>
<TOKEN end_char="10927" id="token-79-24" morph="none" pos="word" start_char="10916">substantiate</TOKEN>
<TOKEN end_char="10930" id="token-79-25" morph="none" pos="word" start_char="10929">it</TOKEN>
<TOKEN end_char="10931" id="token-79-26" morph="none" pos="punct" start_char="10931">.</TOKEN>
</SEG>
<SEG end_char="10968" id="segment-80" start_char="10934">
<ORIGINAL_TEXT>'When did patient zero begin in US?</ORIGINAL_TEXT>
<TOKEN end_char="10934" id="token-80-0" morph="none" pos="punct" start_char="10934">'</TOKEN>
<TOKEN end_char="10938" id="token-80-1" morph="none" pos="word" start_char="10935">When</TOKEN>
<TOKEN end_char="10942" id="token-80-2" morph="none" pos="word" start_char="10940">did</TOKEN>
<TOKEN end_char="10950" id="token-80-3" morph="none" pos="word" start_char="10944">patient</TOKEN>
<TOKEN end_char="10955" id="token-80-4" morph="none" pos="word" start_char="10952">zero</TOKEN>
<TOKEN end_char="10961" id="token-80-5" morph="none" pos="word" start_char="10957">begin</TOKEN>
<TOKEN end_char="10964" id="token-80-6" morph="none" pos="word" start_char="10963">in</TOKEN>
<TOKEN end_char="10967" id="token-80-7" morph="none" pos="word" start_char="10966">US</TOKEN>
<TOKEN end_char="10968" id="token-80-8" morph="none" pos="punct" start_char="10968">?</TOKEN>
<TRANSLATED_TEXT>'When did patient zero begin in the US?</TRANSLATED_TEXT><DETECTED_LANGUAGE>nl</DETECTED_LANGUAGE></SEG>
<SEG end_char="10998" id="segment-81" start_char="10970">
<ORIGINAL_TEXT>How many people are infected?</ORIGINAL_TEXT>
<TOKEN end_char="10972" id="token-81-0" morph="none" pos="word" start_char="10970">How</TOKEN>
<TOKEN end_char="10977" id="token-81-1" morph="none" pos="word" start_char="10974">many</TOKEN>
<TOKEN end_char="10984" id="token-81-2" morph="none" pos="word" start_char="10979">people</TOKEN>
<TOKEN end_char="10988" id="token-81-3" morph="none" pos="word" start_char="10986">are</TOKEN>
<TOKEN end_char="10997" id="token-81-4" morph="none" pos="word" start_char="10990">infected</TOKEN>
<TOKEN end_char="10998" id="token-81-5" morph="none" pos="punct" start_char="10998">?</TOKEN>
</SEG>
<SEG end_char="11046" id="segment-82" start_char="11000">
<ORIGINAL_TEXT>What are the names of the hospitals,' he wrote.</ORIGINAL_TEXT>
<TOKEN end_char="11003" id="token-82-0" morph="none" pos="word" start_char="11000">What</TOKEN>
<TOKEN end_char="11007" id="token-82-1" morph="none" pos="word" start_char="11005">are</TOKEN>
<TOKEN end_char="11011" id="token-82-2" morph="none" pos="word" start_char="11009">the</TOKEN>
<TOKEN end_char="11017" id="token-82-3" morph="none" pos="word" start_char="11013">names</TOKEN>
<TOKEN end_char="11020" id="token-82-4" morph="none" pos="word" start_char="11019">of</TOKEN>
<TOKEN end_char="11024" id="token-82-5" morph="none" pos="word" start_char="11022">the</TOKEN>
<TOKEN end_char="11034" id="token-82-6" morph="none" pos="word" start_char="11026">hospitals</TOKEN>
<TOKEN end_char="11036" id="token-82-7" morph="none" pos="punct" start_char="11035">,'</TOKEN>
<TOKEN end_char="11039" id="token-82-8" morph="none" pos="word" start_char="11038">he</TOKEN>
<TOKEN end_char="11045" id="token-82-9" morph="none" pos="word" start_char="11041">wrote</TOKEN>
<TOKEN end_char="11046" id="token-82-10" morph="none" pos="punct" start_char="11046">.</TOKEN>
</SEG>
<SEG end_char="11205" id="segment-83" start_char="11050">
<ORIGINAL_TEXT>Referencing a military athletics tournament in Wuhan in October, which US troops attended, he wrote: 'It might be US army who brought the epidemic to Wuhan.</ORIGINAL_TEXT>
<TOKEN end_char="11060" id="token-83-0" morph="none" pos="word" start_char="11050">Referencing</TOKEN>
<TOKEN end_char="11062" id="token-83-1" morph="none" pos="word" start_char="11062">a</TOKEN>
<TOKEN end_char="11071" id="token-83-2" morph="none" pos="word" start_char="11064">military</TOKEN>
<TOKEN end_char="11081" id="token-83-3" morph="none" pos="word" start_char="11073">athletics</TOKEN>
<TOKEN end_char="11092" id="token-83-4" morph="none" pos="word" start_char="11083">tournament</TOKEN>
<TOKEN end_char="11095" id="token-83-5" morph="none" pos="word" start_char="11094">in</TOKEN>
<TOKEN end_char="11101" id="token-83-6" morph="none" pos="word" start_char="11097">Wuhan</TOKEN>
<TOKEN end_char="11104" id="token-83-7" morph="none" pos="word" start_char="11103">in</TOKEN>
<TOKEN end_char="11112" id="token-83-8" morph="none" pos="word" start_char="11106">October</TOKEN>
<TOKEN end_char="11113" id="token-83-9" morph="none" pos="punct" start_char="11113">,</TOKEN>
<TOKEN end_char="11119" id="token-83-10" morph="none" pos="word" start_char="11115">which</TOKEN>
<TOKEN end_char="11122" id="token-83-11" morph="none" pos="word" start_char="11121">US</TOKEN>
<TOKEN end_char="11129" id="token-83-12" morph="none" pos="word" start_char="11124">troops</TOKEN>
<TOKEN end_char="11138" id="token-83-13" morph="none" pos="word" start_char="11131">attended</TOKEN>
<TOKEN end_char="11139" id="token-83-14" morph="none" pos="punct" start_char="11139">,</TOKEN>
<TOKEN end_char="11142" id="token-83-15" morph="none" pos="word" start_char="11141">he</TOKEN>
<TOKEN end_char="11148" id="token-83-16" morph="none" pos="word" start_char="11144">wrote</TOKEN>
<TOKEN end_char="11149" id="token-83-17" morph="none" pos="punct" start_char="11149">:</TOKEN>
<TOKEN end_char="11151" id="token-83-18" morph="none" pos="punct" start_char="11151">'</TOKEN>
<TOKEN end_char="11153" id="token-83-19" morph="none" pos="word" start_char="11152">It</TOKEN>
<TOKEN end_char="11159" id="token-83-20" morph="none" pos="word" start_char="11155">might</TOKEN>
<TOKEN end_char="11162" id="token-83-21" morph="none" pos="word" start_char="11161">be</TOKEN>
<TOKEN end_char="11165" id="token-83-22" morph="none" pos="word" start_char="11164">US</TOKEN>
<TOKEN end_char="11170" id="token-83-23" morph="none" pos="word" start_char="11167">army</TOKEN>
<TOKEN end_char="11174" id="token-83-24" morph="none" pos="word" start_char="11172">who</TOKEN>
<TOKEN end_char="11182" id="token-83-25" morph="none" pos="word" start_char="11176">brought</TOKEN>
<TOKEN end_char="11186" id="token-83-26" morph="none" pos="word" start_char="11184">the</TOKEN>
<TOKEN end_char="11195" id="token-83-27" morph="none" pos="word" start_char="11188">epidemic</TOKEN>
<TOKEN end_char="11198" id="token-83-28" morph="none" pos="word" start_char="11197">to</TOKEN>
<TOKEN end_char="11204" id="token-83-29" morph="none" pos="word" start_char="11200">Wuhan</TOKEN>
<TOKEN end_char="11205" id="token-83-30" morph="none" pos="punct" start_char="11205">.</TOKEN>
</SEG>
<SEG end_char="11223" id="segment-84" start_char="11208">
<ORIGINAL_TEXT>'Be transparent!</ORIGINAL_TEXT>
<TOKEN end_char="11208" id="token-84-0" morph="none" pos="punct" start_char="11208">'</TOKEN>
<TOKEN end_char="11210" id="token-84-1" morph="none" pos="word" start_char="11209">Be</TOKEN>
<TOKEN end_char="11222" id="token-84-2" morph="none" pos="word" start_char="11212">transparent</TOKEN>
<TOKEN end_char="11223" id="token-84-3" morph="none" pos="punct" start_char="11223">!</TOKEN>
<TRANSLATED_TEXT>Be transparent!</TRANSLATED_TEXT><DETECTED_LANGUAGE>fr</DETECTED_LANGUAGE></SEG>
<SEG end_char="11246" id="segment-85" start_char="11225">
<ORIGINAL_TEXT>Make public your data!</ORIGINAL_TEXT>
<TOKEN end_char="11228" id="token-85-0" morph="none" pos="word" start_char="11225">Make</TOKEN>
<TOKEN end_char="11235" id="token-85-1" morph="none" pos="word" start_char="11230">public</TOKEN>
<TOKEN end_char="11240" id="token-85-2" morph="none" pos="word" start_char="11237">your</TOKEN>
<TOKEN end_char="11245" id="token-85-3" morph="none" pos="word" start_char="11242">data</TOKEN>
<TOKEN end_char="11246" id="token-85-4" morph="none" pos="punct" start_char="11246">!</TOKEN>
<TRANSLATED_TEXT>Publicare i dati</TRANSLATED_TEXT><DETECTED_LANGUAGE>id</DETECTED_LANGUAGE></SEG>
<SEG end_char="11273" id="segment-86" start_char="11248">
<ORIGINAL_TEXT>US owe us an explanation!'</ORIGINAL_TEXT>
<TOKEN end_char="11249" id="token-86-0" morph="none" pos="word" start_char="11248">US</TOKEN>
<TOKEN end_char="11253" id="token-86-1" morph="none" pos="word" start_char="11251">owe</TOKEN>
<TOKEN end_char="11256" id="token-86-2" morph="none" pos="word" start_char="11255">us</TOKEN>
<TOKEN end_char="11259" id="token-86-3" morph="none" pos="word" start_char="11258">an</TOKEN>
<TOKEN end_char="11271" id="token-86-4" morph="none" pos="word" start_char="11261">explanation</TOKEN>
<TOKEN end_char="11273" id="token-86-5" morph="none" pos="punct" start_char="11272">!'</TOKEN>
</SEG>
<SEG end_char="11378" id="segment-87" start_char="11276">
<ORIGINAL_TEXT>In fact, America's 'patient zero' was a man who travelled from China to Washington State on January 15.</ORIGINAL_TEXT>
<TOKEN end_char="11277" id="token-87-0" morph="none" pos="word" start_char="11276">In</TOKEN>
<TOKEN end_char="11282" id="token-87-1" morph="none" pos="word" start_char="11279">fact</TOKEN>
<TOKEN end_char="11283" id="token-87-2" morph="none" pos="punct" start_char="11283">,</TOKEN>
<TOKEN end_char="11293" id="token-87-3" morph="none" pos="word" start_char="11285">America's</TOKEN>
<TOKEN end_char="11295" id="token-87-4" morph="none" pos="punct" start_char="11295">'</TOKEN>
<TOKEN end_char="11302" id="token-87-5" morph="none" pos="word" start_char="11296">patient</TOKEN>
<TOKEN end_char="11307" id="token-87-6" morph="none" pos="word" start_char="11304">zero</TOKEN>
<TOKEN end_char="11308" id="token-87-7" morph="none" pos="punct" start_char="11308">'</TOKEN>
<TOKEN end_char="11312" id="token-87-8" morph="none" pos="word" start_char="11310">was</TOKEN>
<TOKEN end_char="11314" id="token-87-9" morph="none" pos="word" start_char="11314">a</TOKEN>
<TOKEN end_char="11318" id="token-87-10" morph="none" pos="word" start_char="11316">man</TOKEN>
<TOKEN end_char="11322" id="token-87-11" morph="none" pos="word" start_char="11320">who</TOKEN>
<TOKEN end_char="11332" id="token-87-12" morph="none" pos="word" start_char="11324">travelled</TOKEN>
<TOKEN end_char="11337" id="token-87-13" morph="none" pos="word" start_char="11334">from</TOKEN>
<TOKEN end_char="11343" id="token-87-14" morph="none" pos="word" start_char="11339">China</TOKEN>
<TOKEN end_char="11346" id="token-87-15" morph="none" pos="word" start_char="11345">to</TOKEN>
<TOKEN end_char="11357" id="token-87-16" morph="none" pos="word" start_char="11348">Washington</TOKEN>
<TOKEN end_char="11363" id="token-87-17" morph="none" pos="word" start_char="11359">State</TOKEN>
<TOKEN end_char="11366" id="token-87-18" morph="none" pos="word" start_char="11365">on</TOKEN>
<TOKEN end_char="11374" id="token-87-19" morph="none" pos="word" start_char="11368">January</TOKEN>
<TOKEN end_char="11377" id="token-87-20" morph="none" pos="word" start_char="11376">15</TOKEN>
<TOKEN end_char="11378" id="token-87-21" morph="none" pos="punct" start_char="11378">.</TOKEN>
</SEG>
<SEG end_char="11428" id="segment-88" start_char="11380">
<ORIGINAL_TEXT>The case was confirmed by the CDC six days later.</ORIGINAL_TEXT>
<TOKEN end_char="11382" id="token-88-0" morph="none" pos="word" start_char="11380">The</TOKEN>
<TOKEN end_char="11387" id="token-88-1" morph="none" pos="word" start_char="11384">case</TOKEN>
<TOKEN end_char="11391" id="token-88-2" morph="none" pos="word" start_char="11389">was</TOKEN>
<TOKEN end_char="11401" id="token-88-3" morph="none" pos="word" start_char="11393">confirmed</TOKEN>
<TOKEN end_char="11404" id="token-88-4" morph="none" pos="word" start_char="11403">by</TOKEN>
<TOKEN end_char="11408" id="token-88-5" morph="none" pos="word" start_char="11406">the</TOKEN>
<TOKEN end_char="11412" id="token-88-6" morph="none" pos="word" start_char="11410">CDC</TOKEN>
<TOKEN end_char="11416" id="token-88-7" morph="none" pos="word" start_char="11414">six</TOKEN>
<TOKEN end_char="11421" id="token-88-8" morph="none" pos="word" start_char="11418">days</TOKEN>
<TOKEN end_char="11427" id="token-88-9" morph="none" pos="word" start_char="11423">later</TOKEN>
<TOKEN end_char="11428" id="token-88-10" morph="none" pos="punct" start_char="11428">.</TOKEN>
</SEG>
<SEG end_char="11673" id="segment-89" start_char="11431">
<ORIGINAL_TEXT>Chinese has also tried to push the theory that the virus originated in Italy, the country with the most deaths, by distorting a quote from an Italian doctor who suggested the country's first cases could have occurred much earlier than thought.</ORIGINAL_TEXT>
<TOKEN end_char="11437" id="token-89-0" morph="none" pos="word" start_char="11431">Chinese</TOKEN>
<TOKEN end_char="11441" id="token-89-1" morph="none" pos="word" start_char="11439">has</TOKEN>
<TOKEN end_char="11446" id="token-89-2" morph="none" pos="word" start_char="11443">also</TOKEN>
<TOKEN end_char="11452" id="token-89-3" morph="none" pos="word" start_char="11448">tried</TOKEN>
<TOKEN end_char="11455" id="token-89-4" morph="none" pos="word" start_char="11454">to</TOKEN>
<TOKEN end_char="11460" id="token-89-5" morph="none" pos="word" start_char="11457">push</TOKEN>
<TOKEN end_char="11464" id="token-89-6" morph="none" pos="word" start_char="11462">the</TOKEN>
<TOKEN end_char="11471" id="token-89-7" morph="none" pos="word" start_char="11466">theory</TOKEN>
<TOKEN end_char="11476" id="token-89-8" morph="none" pos="word" start_char="11473">that</TOKEN>
<TOKEN end_char="11480" id="token-89-9" morph="none" pos="word" start_char="11478">the</TOKEN>
<TOKEN end_char="11486" id="token-89-10" morph="none" pos="word" start_char="11482">virus</TOKEN>
<TOKEN end_char="11497" id="token-89-11" morph="none" pos="word" start_char="11488">originated</TOKEN>
<TOKEN end_char="11500" id="token-89-12" morph="none" pos="word" start_char="11499">in</TOKEN>
<TOKEN end_char="11506" id="token-89-13" morph="none" pos="word" start_char="11502">Italy</TOKEN>
<TOKEN end_char="11507" id="token-89-14" morph="none" pos="punct" start_char="11507">,</TOKEN>
<TOKEN end_char="11511" id="token-89-15" morph="none" pos="word" start_char="11509">the</TOKEN>
<TOKEN end_char="11519" id="token-89-16" morph="none" pos="word" start_char="11513">country</TOKEN>
<TOKEN end_char="11524" id="token-89-17" morph="none" pos="word" start_char="11521">with</TOKEN>
<TOKEN end_char="11528" id="token-89-18" morph="none" pos="word" start_char="11526">the</TOKEN>
<TOKEN end_char="11533" id="token-89-19" morph="none" pos="word" start_char="11530">most</TOKEN>
<TOKEN end_char="11540" id="token-89-20" morph="none" pos="word" start_char="11535">deaths</TOKEN>
<TOKEN end_char="11541" id="token-89-21" morph="none" pos="punct" start_char="11541">,</TOKEN>
<TOKEN end_char="11544" id="token-89-22" morph="none" pos="word" start_char="11543">by</TOKEN>
<TOKEN end_char="11555" id="token-89-23" morph="none" pos="word" start_char="11546">distorting</TOKEN>
<TOKEN end_char="11557" id="token-89-24" morph="none" pos="word" start_char="11557">a</TOKEN>
<TOKEN end_char="11563" id="token-89-25" morph="none" pos="word" start_char="11559">quote</TOKEN>
<TOKEN end_char="11568" id="token-89-26" morph="none" pos="word" start_char="11565">from</TOKEN>
<TOKEN end_char="11571" id="token-89-27" morph="none" pos="word" start_char="11570">an</TOKEN>
<TOKEN end_char="11579" id="token-89-28" morph="none" pos="word" start_char="11573">Italian</TOKEN>
<TOKEN end_char="11586" id="token-89-29" morph="none" pos="word" start_char="11581">doctor</TOKEN>
<TOKEN end_char="11590" id="token-89-30" morph="none" pos="word" start_char="11588">who</TOKEN>
<TOKEN end_char="11600" id="token-89-31" morph="none" pos="word" start_char="11592">suggested</TOKEN>
<TOKEN end_char="11604" id="token-89-32" morph="none" pos="word" start_char="11602">the</TOKEN>
<TOKEN end_char="11614" id="token-89-33" morph="none" pos="word" start_char="11606">country's</TOKEN>
<TOKEN end_char="11620" id="token-89-34" morph="none" pos="word" start_char="11616">first</TOKEN>
<TOKEN end_char="11626" id="token-89-35" morph="none" pos="word" start_char="11622">cases</TOKEN>
<TOKEN end_char="11632" id="token-89-36" morph="none" pos="word" start_char="11628">could</TOKEN>
<TOKEN end_char="11637" id="token-89-37" morph="none" pos="word" start_char="11634">have</TOKEN>
<TOKEN end_char="11646" id="token-89-38" morph="none" pos="word" start_char="11639">occurred</TOKEN>
<TOKEN end_char="11651" id="token-89-39" morph="none" pos="word" start_char="11648">much</TOKEN>
<TOKEN end_char="11659" id="token-89-40" morph="none" pos="word" start_char="11653">earlier</TOKEN>
<TOKEN end_char="11664" id="token-89-41" morph="none" pos="word" start_char="11661">than</TOKEN>
<TOKEN end_char="11672" id="token-89-42" morph="none" pos="word" start_char="11666">thought</TOKEN>
<TOKEN end_char="11673" id="token-89-43" morph="none" pos="punct" start_char="11673">.</TOKEN>
</SEG>
<SEG end_char="11832" id="segment-90" start_char="11677">
<ORIGINAL_TEXT>Giuseppe Remuzzi said he is investigating strange cases of pneumonia as far back as December and November, months before the virus was known to have spread.</ORIGINAL_TEXT>
<TOKEN end_char="11684" id="token-90-0" morph="none" pos="word" start_char="11677">Giuseppe</TOKEN>
<TOKEN end_char="11692" id="token-90-1" morph="none" pos="word" start_char="11686">Remuzzi</TOKEN>
<TOKEN end_char="11697" id="token-90-2" morph="none" pos="word" start_char="11694">said</TOKEN>
<TOKEN end_char="11700" id="token-90-3" morph="none" pos="word" start_char="11699">he</TOKEN>
<TOKEN end_char="11703" id="token-90-4" morph="none" pos="word" start_char="11702">is</TOKEN>
<TOKEN end_char="11717" id="token-90-5" morph="none" pos="word" start_char="11705">investigating</TOKEN>
<TOKEN end_char="11725" id="token-90-6" morph="none" pos="word" start_char="11719">strange</TOKEN>
<TOKEN end_char="11731" id="token-90-7" morph="none" pos="word" start_char="11727">cases</TOKEN>
<TOKEN end_char="11734" id="token-90-8" morph="none" pos="word" start_char="11733">of</TOKEN>
<TOKEN end_char="11744" id="token-90-9" morph="none" pos="word" start_char="11736">pneumonia</TOKEN>
<TOKEN end_char="11747" id="token-90-10" morph="none" pos="word" start_char="11746">as</TOKEN>
<TOKEN end_char="11751" id="token-90-11" morph="none" pos="word" start_char="11749">far</TOKEN>
<TOKEN end_char="11756" id="token-90-12" morph="none" pos="word" start_char="11753">back</TOKEN>
<TOKEN end_char="11759" id="token-90-13" morph="none" pos="word" start_char="11758">as</TOKEN>
<TOKEN end_char="11768" id="token-90-14" morph="none" pos="word" start_char="11761">December</TOKEN>
<TOKEN end_char="11772" id="token-90-15" morph="none" pos="word" start_char="11770">and</TOKEN>
<TOKEN end_char="11781" id="token-90-16" morph="none" pos="word" start_char="11774">November</TOKEN>
<TOKEN end_char="11782" id="token-90-17" morph="none" pos="punct" start_char="11782">,</TOKEN>
<TOKEN end_char="11789" id="token-90-18" morph="none" pos="word" start_char="11784">months</TOKEN>
<TOKEN end_char="11796" id="token-90-19" morph="none" pos="word" start_char="11791">before</TOKEN>
<TOKEN end_char="11800" id="token-90-20" morph="none" pos="word" start_char="11798">the</TOKEN>
<TOKEN end_char="11806" id="token-90-21" morph="none" pos="word" start_char="11802">virus</TOKEN>
<TOKEN end_char="11810" id="token-90-22" morph="none" pos="word" start_char="11808">was</TOKEN>
<TOKEN end_char="11816" id="token-90-23" morph="none" pos="word" start_char="11812">known</TOKEN>
<TOKEN end_char="11819" id="token-90-24" morph="none" pos="word" start_char="11818">to</TOKEN>
<TOKEN end_char="11824" id="token-90-25" morph="none" pos="word" start_char="11821">have</TOKEN>
<TOKEN end_char="11831" id="token-90-26" morph="none" pos="word" start_char="11826">spread</TOKEN>
<TOKEN end_char="11832" id="token-90-27" morph="none" pos="punct" start_char="11832">.</TOKEN>
</SEG>
<SEG end_char="11951" id="segment-91" start_char="11835">
<ORIGINAL_TEXT>Chinese state media widely reported his comments while also suggesting that the virus could have originated in Italy.</ORIGINAL_TEXT>
<TOKEN end_char="11841" id="token-91-0" morph="none" pos="word" start_char="11835">Chinese</TOKEN>
<TOKEN end_char="11847" id="token-91-1" morph="none" pos="word" start_char="11843">state</TOKEN>
<TOKEN end_char="11853" id="token-91-2" morph="none" pos="word" start_char="11849">media</TOKEN>
<TOKEN end_char="11860" id="token-91-3" morph="none" pos="word" start_char="11855">widely</TOKEN>
<TOKEN end_char="11869" id="token-91-4" morph="none" pos="word" start_char="11862">reported</TOKEN>
<TOKEN end_char="11873" id="token-91-5" morph="none" pos="word" start_char="11871">his</TOKEN>
<TOKEN end_char="11882" id="token-91-6" morph="none" pos="word" start_char="11875">comments</TOKEN>
<TOKEN end_char="11888" id="token-91-7" morph="none" pos="word" start_char="11884">while</TOKEN>
<TOKEN end_char="11893" id="token-91-8" morph="none" pos="word" start_char="11890">also</TOKEN>
<TOKEN end_char="11904" id="token-91-9" morph="none" pos="word" start_char="11895">suggesting</TOKEN>
<TOKEN end_char="11909" id="token-91-10" morph="none" pos="word" start_char="11906">that</TOKEN>
<TOKEN end_char="11913" id="token-91-11" morph="none" pos="word" start_char="11911">the</TOKEN>
<TOKEN end_char="11919" id="token-91-12" morph="none" pos="word" start_char="11915">virus</TOKEN>
<TOKEN end_char="11925" id="token-91-13" morph="none" pos="word" start_char="11921">could</TOKEN>
<TOKEN end_char="11930" id="token-91-14" morph="none" pos="word" start_char="11927">have</TOKEN>
<TOKEN end_char="11941" id="token-91-15" morph="none" pos="word" start_char="11932">originated</TOKEN>
<TOKEN end_char="11944" id="token-91-16" morph="none" pos="word" start_char="11943">in</TOKEN>
<TOKEN end_char="11950" id="token-91-17" morph="none" pos="word" start_char="11946">Italy</TOKEN>
<TOKEN end_char="11951" id="token-91-18" morph="none" pos="punct" start_char="11951">.</TOKEN>
</SEG>
<SEG end_char="12102" id="segment-92" start_char="11954">
<ORIGINAL_TEXT>In fact, Remuzzi says, there can be no doubt it started in Wuhan - but may have spread out of the province and across the world earlier than thought.</ORIGINAL_TEXT>
<TOKEN end_char="11955" id="token-92-0" morph="none" pos="word" start_char="11954">In</TOKEN>
<TOKEN end_char="11960" id="token-92-1" morph="none" pos="word" start_char="11957">fact</TOKEN>
<TOKEN end_char="11961" id="token-92-2" morph="none" pos="punct" start_char="11961">,</TOKEN>
<TOKEN end_char="11969" id="token-92-3" morph="none" pos="word" start_char="11963">Remuzzi</TOKEN>
<TOKEN end_char="11974" id="token-92-4" morph="none" pos="word" start_char="11971">says</TOKEN>
<TOKEN end_char="11975" id="token-92-5" morph="none" pos="punct" start_char="11975">,</TOKEN>
<TOKEN end_char="11981" id="token-92-6" morph="none" pos="word" start_char="11977">there</TOKEN>
<TOKEN end_char="11985" id="token-92-7" morph="none" pos="word" start_char="11983">can</TOKEN>
<TOKEN end_char="11988" id="token-92-8" morph="none" pos="word" start_char="11987">be</TOKEN>
<TOKEN end_char="11991" id="token-92-9" morph="none" pos="word" start_char="11990">no</TOKEN>
<TOKEN end_char="11997" id="token-92-10" morph="none" pos="word" start_char="11993">doubt</TOKEN>
<TOKEN end_char="12000" id="token-92-11" morph="none" pos="word" start_char="11999">it</TOKEN>
<TOKEN end_char="12008" id="token-92-12" morph="none" pos="word" start_char="12002">started</TOKEN>
<TOKEN end_char="12011" id="token-92-13" morph="none" pos="word" start_char="12010">in</TOKEN>
<TOKEN end_char="12017" id="token-92-14" morph="none" pos="word" start_char="12013">Wuhan</TOKEN>
<TOKEN end_char="12019" id="token-92-15" morph="none" pos="punct" start_char="12019">-</TOKEN>
<TOKEN end_char="12023" id="token-92-16" morph="none" pos="word" start_char="12021">but</TOKEN>
<TOKEN end_char="12027" id="token-92-17" morph="none" pos="word" start_char="12025">may</TOKEN>
<TOKEN end_char="12032" id="token-92-18" morph="none" pos="word" start_char="12029">have</TOKEN>
<TOKEN end_char="12039" id="token-92-19" morph="none" pos="word" start_char="12034">spread</TOKEN>
<TOKEN end_char="12043" id="token-92-20" morph="none" pos="word" start_char="12041">out</TOKEN>
<TOKEN end_char="12046" id="token-92-21" morph="none" pos="word" start_char="12045">of</TOKEN>
<TOKEN end_char="12050" id="token-92-22" morph="none" pos="word" start_char="12048">the</TOKEN>
<TOKEN end_char="12059" id="token-92-23" morph="none" pos="word" start_char="12052">province</TOKEN>
<TOKEN end_char="12063" id="token-92-24" morph="none" pos="word" start_char="12061">and</TOKEN>
<TOKEN end_char="12070" id="token-92-25" morph="none" pos="word" start_char="12065">across</TOKEN>
<TOKEN end_char="12074" id="token-92-26" morph="none" pos="word" start_char="12072">the</TOKEN>
<TOKEN end_char="12080" id="token-92-27" morph="none" pos="word" start_char="12076">world</TOKEN>
<TOKEN end_char="12088" id="token-92-28" morph="none" pos="word" start_char="12082">earlier</TOKEN>
<TOKEN end_char="12093" id="token-92-29" morph="none" pos="word" start_char="12090">than</TOKEN>
<TOKEN end_char="12101" id="token-92-30" morph="none" pos="word" start_char="12095">thought</TOKEN>
<TOKEN end_char="12102" id="token-92-31" morph="none" pos="punct" start_char="12102">.</TOKEN>
</SEG>
<SEG end_char="12119" id="segment-93" start_char="12105">
<ORIGINAL_TEXT>Infection total</ORIGINAL_TEXT>
<TOKEN end_char="12113" id="token-93-0" morph="none" pos="word" start_char="12105">Infection</TOKEN>
<TOKEN end_char="12119" id="token-93-1" morph="none" pos="word" start_char="12115">total</TOKEN>
</SEG>
<SEG end_char="12332" id="segment-94" start_char="12122">
<ORIGINAL_TEXT>China has reported a total of some 82,000 infections from coronavirus, claiming a domestic infection rate of zero for several days in a row recently - even as it eased lockdown restrictions in placed like Hubei.</ORIGINAL_TEXT>
<TOKEN end_char="12126" id="token-94-0" morph="none" pos="word" start_char="12122">China</TOKEN>
<TOKEN end_char="12130" id="token-94-1" morph="none" pos="word" start_char="12128">has</TOKEN>
<TOKEN end_char="12139" id="token-94-2" morph="none" pos="word" start_char="12132">reported</TOKEN>
<TOKEN end_char="12141" id="token-94-3" morph="none" pos="word" start_char="12141">a</TOKEN>
<TOKEN end_char="12147" id="token-94-4" morph="none" pos="word" start_char="12143">total</TOKEN>
<TOKEN end_char="12150" id="token-94-5" morph="none" pos="word" start_char="12149">of</TOKEN>
<TOKEN end_char="12155" id="token-94-6" morph="none" pos="word" start_char="12152">some</TOKEN>
<TOKEN end_char="12162" id="token-94-7" morph="none" pos="unknown" start_char="12157">82,000</TOKEN>
<TOKEN end_char="12173" id="token-94-8" morph="none" pos="word" start_char="12164">infections</TOKEN>
<TOKEN end_char="12178" id="token-94-9" morph="none" pos="word" start_char="12175">from</TOKEN>
<TOKEN end_char="12190" id="token-94-10" morph="none" pos="word" start_char="12180">coronavirus</TOKEN>
<TOKEN end_char="12191" id="token-94-11" morph="none" pos="punct" start_char="12191">,</TOKEN>
<TOKEN end_char="12200" id="token-94-12" morph="none" pos="word" start_char="12193">claiming</TOKEN>
<TOKEN end_char="12202" id="token-94-13" morph="none" pos="word" start_char="12202">a</TOKEN>
<TOKEN end_char="12211" id="token-94-14" morph="none" pos="word" start_char="12204">domestic</TOKEN>
<TOKEN end_char="12221" id="token-94-15" morph="none" pos="word" start_char="12213">infection</TOKEN>
<TOKEN end_char="12226" id="token-94-16" morph="none" pos="word" start_char="12223">rate</TOKEN>
<TOKEN end_char="12229" id="token-94-17" morph="none" pos="word" start_char="12228">of</TOKEN>
<TOKEN end_char="12234" id="token-94-18" morph="none" pos="word" start_char="12231">zero</TOKEN>
<TOKEN end_char="12238" id="token-94-19" morph="none" pos="word" start_char="12236">for</TOKEN>
<TOKEN end_char="12246" id="token-94-20" morph="none" pos="word" start_char="12240">several</TOKEN>
<TOKEN end_char="12251" id="token-94-21" morph="none" pos="word" start_char="12248">days</TOKEN>
<TOKEN end_char="12254" id="token-94-22" morph="none" pos="word" start_char="12253">in</TOKEN>
<TOKEN end_char="12256" id="token-94-23" morph="none" pos="word" start_char="12256">a</TOKEN>
<TOKEN end_char="12260" id="token-94-24" morph="none" pos="word" start_char="12258">row</TOKEN>
<TOKEN end_char="12269" id="token-94-25" morph="none" pos="word" start_char="12262">recently</TOKEN>
<TOKEN end_char="12271" id="token-94-26" morph="none" pos="punct" start_char="12271">-</TOKEN>
<TOKEN end_char="12276" id="token-94-27" morph="none" pos="word" start_char="12273">even</TOKEN>
<TOKEN end_char="12279" id="token-94-28" morph="none" pos="word" start_char="12278">as</TOKEN>
<TOKEN end_char="12282" id="token-94-29" morph="none" pos="word" start_char="12281">it</TOKEN>
<TOKEN end_char="12288" id="token-94-30" morph="none" pos="word" start_char="12284">eased</TOKEN>
<TOKEN end_char="12297" id="token-94-31" morph="none" pos="word" start_char="12290">lockdown</TOKEN>
<TOKEN end_char="12310" id="token-94-32" morph="none" pos="word" start_char="12299">restrictions</TOKEN>
<TOKEN end_char="12313" id="token-94-33" morph="none" pos="word" start_char="12312">in</TOKEN>
<TOKEN end_char="12320" id="token-94-34" morph="none" pos="word" start_char="12315">placed</TOKEN>
<TOKEN end_char="12325" id="token-94-35" morph="none" pos="word" start_char="12322">like</TOKEN>
<TOKEN end_char="12331" id="token-94-36" morph="none" pos="word" start_char="12327">Hubei</TOKEN>
<TOKEN end_char="12332" id="token-94-37" morph="none" pos="punct" start_char="12332">.</TOKEN>
</SEG>
<SEG end_char="12448" id="segment-95" start_char="12335">
<ORIGINAL_TEXT>But, by the country's own admission, the virus is likely still spreading - via people who have few or no symptoms.</ORIGINAL_TEXT>
<TOKEN end_char="12337" id="token-95-0" morph="none" pos="word" start_char="12335">But</TOKEN>
<TOKEN end_char="12338" id="token-95-1" morph="none" pos="punct" start_char="12338">,</TOKEN>
<TOKEN end_char="12341" id="token-95-2" morph="none" pos="word" start_char="12340">by</TOKEN>
<TOKEN end_char="12345" id="token-95-3" morph="none" pos="word" start_char="12343">the</TOKEN>
<TOKEN end_char="12355" id="token-95-4" morph="none" pos="word" start_char="12347">country's</TOKEN>
<TOKEN end_char="12359" id="token-95-5" morph="none" pos="word" start_char="12357">own</TOKEN>
<TOKEN end_char="12369" id="token-95-6" morph="none" pos="word" start_char="12361">admission</TOKEN>
<TOKEN end_char="12370" id="token-95-7" morph="none" pos="punct" start_char="12370">,</TOKEN>
<TOKEN end_char="12374" id="token-95-8" morph="none" pos="word" start_char="12372">the</TOKEN>
<TOKEN end_char="12380" id="token-95-9" morph="none" pos="word" start_char="12376">virus</TOKEN>
<TOKEN end_char="12383" id="token-95-10" morph="none" pos="word" start_char="12382">is</TOKEN>
<TOKEN end_char="12390" id="token-95-11" morph="none" pos="word" start_char="12385">likely</TOKEN>
<TOKEN end_char="12396" id="token-95-12" morph="none" pos="word" start_char="12392">still</TOKEN>
<TOKEN end_char="12406" id="token-95-13" morph="none" pos="word" start_char="12398">spreading</TOKEN>
<TOKEN end_char="12408" id="token-95-14" morph="none" pos="punct" start_char="12408">-</TOKEN>
<TOKEN end_char="12412" id="token-95-15" morph="none" pos="word" start_char="12410">via</TOKEN>
<TOKEN end_char="12419" id="token-95-16" morph="none" pos="word" start_char="12414">people</TOKEN>
<TOKEN end_char="12423" id="token-95-17" morph="none" pos="word" start_char="12421">who</TOKEN>
<TOKEN end_char="12428" id="token-95-18" morph="none" pos="word" start_char="12425">have</TOKEN>
<TOKEN end_char="12432" id="token-95-19" morph="none" pos="word" start_char="12430">few</TOKEN>
<TOKEN end_char="12435" id="token-95-20" morph="none" pos="word" start_char="12434">or</TOKEN>
<TOKEN end_char="12438" id="token-95-21" morph="none" pos="word" start_char="12437">no</TOKEN>
<TOKEN end_char="12447" id="token-95-22" morph="none" pos="word" start_char="12440">symptoms</TOKEN>
<TOKEN end_char="12448" id="token-95-23" morph="none" pos="punct" start_char="12448">.</TOKEN>
</SEG>
<SEG end_char="12633" id="segment-96" start_char="12451">
<ORIGINAL_TEXT>Beijing-based outlet Caixin reported that 'a couple to over 10 cases of covert infections of the virus are being detected' in China every day, despite not showing up in official data.</ORIGINAL_TEXT>
<TOKEN end_char="12463" id="token-96-0" morph="none" pos="unknown" start_char="12451">Beijing-based</TOKEN>
<TOKEN end_char="12470" id="token-96-1" morph="none" pos="word" start_char="12465">outlet</TOKEN>
<TOKEN end_char="12477" id="token-96-2" morph="none" pos="word" start_char="12472">Caixin</TOKEN>
<TOKEN end_char="12486" id="token-96-3" morph="none" pos="word" start_char="12479">reported</TOKEN>
<TOKEN end_char="12491" id="token-96-4" morph="none" pos="word" start_char="12488">that</TOKEN>
<TOKEN end_char="12493" id="token-96-5" morph="none" pos="punct" start_char="12493">'</TOKEN>
<TOKEN end_char="12494" id="token-96-6" morph="none" pos="word" start_char="12494">a</TOKEN>
<TOKEN end_char="12501" id="token-96-7" morph="none" pos="word" start_char="12496">couple</TOKEN>
<TOKEN end_char="12504" id="token-96-8" morph="none" pos="word" start_char="12503">to</TOKEN>
<TOKEN end_char="12509" id="token-96-9" morph="none" pos="word" start_char="12506">over</TOKEN>
<TOKEN end_char="12512" id="token-96-10" morph="none" pos="word" start_char="12511">10</TOKEN>
<TOKEN end_char="12518" id="token-96-11" morph="none" pos="word" start_char="12514">cases</TOKEN>
<TOKEN end_char="12521" id="token-96-12" morph="none" pos="word" start_char="12520">of</TOKEN>
<TOKEN end_char="12528" id="token-96-13" morph="none" pos="word" start_char="12523">covert</TOKEN>
<TOKEN end_char="12539" id="token-96-14" morph="none" pos="word" start_char="12530">infections</TOKEN>
<TOKEN end_char="12542" id="token-96-15" morph="none" pos="word" start_char="12541">of</TOKEN>
<TOKEN end_char="12546" id="token-96-16" morph="none" pos="word" start_char="12544">the</TOKEN>
<TOKEN end_char="12552" id="token-96-17" morph="none" pos="word" start_char="12548">virus</TOKEN>
<TOKEN end_char="12556" id="token-96-18" morph="none" pos="word" start_char="12554">are</TOKEN>
<TOKEN end_char="12562" id="token-96-19" morph="none" pos="word" start_char="12558">being</TOKEN>
<TOKEN end_char="12571" id="token-96-20" morph="none" pos="word" start_char="12564">detected</TOKEN>
<TOKEN end_char="12572" id="token-96-21" morph="none" pos="punct" start_char="12572">'</TOKEN>
<TOKEN end_char="12575" id="token-96-22" morph="none" pos="word" start_char="12574">in</TOKEN>
<TOKEN end_char="12581" id="token-96-23" morph="none" pos="word" start_char="12577">China</TOKEN>
<TOKEN end_char="12587" id="token-96-24" morph="none" pos="word" start_char="12583">every</TOKEN>
<TOKEN end_char="12591" id="token-96-25" morph="none" pos="word" start_char="12589">day</TOKEN>
<TOKEN end_char="12592" id="token-96-26" morph="none" pos="punct" start_char="12592">,</TOKEN>
<TOKEN end_char="12600" id="token-96-27" morph="none" pos="word" start_char="12594">despite</TOKEN>
<TOKEN end_char="12604" id="token-96-28" morph="none" pos="word" start_char="12602">not</TOKEN>
<TOKEN end_char="12612" id="token-96-29" morph="none" pos="word" start_char="12606">showing</TOKEN>
<TOKEN end_char="12615" id="token-96-30" morph="none" pos="word" start_char="12614">up</TOKEN>
<TOKEN end_char="12618" id="token-96-31" morph="none" pos="word" start_char="12617">in</TOKEN>
<TOKEN end_char="12627" id="token-96-32" morph="none" pos="word" start_char="12620">official</TOKEN>
<TOKEN end_char="12632" id="token-96-33" morph="none" pos="word" start_char="12629">data</TOKEN>
<TOKEN end_char="12633" id="token-96-34" morph="none" pos="punct" start_char="12633">.</TOKEN>
</SEG>
<SEG end_char="12732" id="segment-97" start_char="12636">
<ORIGINAL_TEXT>Meanwhile foreign governments have heaped scorn on China's infection reporting cannot be trusted.</ORIGINAL_TEXT>
<TOKEN end_char="12644" id="token-97-0" morph="none" pos="word" start_char="12636">Meanwhile</TOKEN>
<TOKEN end_char="12652" id="token-97-1" morph="none" pos="word" start_char="12646">foreign</TOKEN>
<TOKEN end_char="12664" id="token-97-2" morph="none" pos="word" start_char="12654">governments</TOKEN>
<TOKEN end_char="12669" id="token-97-3" morph="none" pos="word" start_char="12666">have</TOKEN>
<TOKEN end_char="12676" id="token-97-4" morph="none" pos="word" start_char="12671">heaped</TOKEN>
<TOKEN end_char="12682" id="token-97-5" morph="none" pos="word" start_char="12678">scorn</TOKEN>
<TOKEN end_char="12685" id="token-97-6" morph="none" pos="word" start_char="12684">on</TOKEN>
<TOKEN end_char="12693" id="token-97-7" morph="none" pos="word" start_char="12687">China's</TOKEN>
<TOKEN end_char="12703" id="token-97-8" morph="none" pos="word" start_char="12695">infection</TOKEN>
<TOKEN end_char="12713" id="token-97-9" morph="none" pos="word" start_char="12705">reporting</TOKEN>
<TOKEN end_char="12720" id="token-97-10" morph="none" pos="word" start_char="12715">cannot</TOKEN>
<TOKEN end_char="12723" id="token-97-11" morph="none" pos="word" start_char="12722">be</TOKEN>
<TOKEN end_char="12731" id="token-97-12" morph="none" pos="word" start_char="12725">trusted</TOKEN>
<TOKEN end_char="12732" id="token-97-13" morph="none" pos="punct" start_char="12732">.</TOKEN>
</SEG>
<SEG end_char="12950" id="segment-98" start_char="12735">
<ORIGINAL_TEXT>Marco Rubio, a prominent Republican senator and former presidential candidate from the US, tweeted that 'we have NO IDEA how many cases China really has' after the US infection total passed Beijing's official figure.</ORIGINAL_TEXT>
<TOKEN end_char="12739" id="token-98-0" morph="none" pos="word" start_char="12735">Marco</TOKEN>
<TOKEN end_char="12745" id="token-98-1" morph="none" pos="word" start_char="12741">Rubio</TOKEN>
<TOKEN end_char="12746" id="token-98-2" morph="none" pos="punct" start_char="12746">,</TOKEN>
<TOKEN end_char="12748" id="token-98-3" morph="none" pos="word" start_char="12748">a</TOKEN>
<TOKEN end_char="12758" id="token-98-4" morph="none" pos="word" start_char="12750">prominent</TOKEN>
<TOKEN end_char="12769" id="token-98-5" morph="none" pos="word" start_char="12760">Republican</TOKEN>
<TOKEN end_char="12777" id="token-98-6" morph="none" pos="word" start_char="12771">senator</TOKEN>
<TOKEN end_char="12781" id="token-98-7" morph="none" pos="word" start_char="12779">and</TOKEN>
<TOKEN end_char="12788" id="token-98-8" morph="none" pos="word" start_char="12783">former</TOKEN>
<TOKEN end_char="12801" id="token-98-9" morph="none" pos="word" start_char="12790">presidential</TOKEN>
<TOKEN end_char="12811" id="token-98-10" morph="none" pos="word" start_char="12803">candidate</TOKEN>
<TOKEN end_char="12816" id="token-98-11" morph="none" pos="word" start_char="12813">from</TOKEN>
<TOKEN end_char="12820" id="token-98-12" morph="none" pos="word" start_char="12818">the</TOKEN>
<TOKEN end_char="12823" id="token-98-13" morph="none" pos="word" start_char="12822">US</TOKEN>
<TOKEN end_char="12824" id="token-98-14" morph="none" pos="punct" start_char="12824">,</TOKEN>
<TOKEN end_char="12832" id="token-98-15" morph="none" pos="word" start_char="12826">tweeted</TOKEN>
<TOKEN end_char="12837" id="token-98-16" morph="none" pos="word" start_char="12834">that</TOKEN>
<TOKEN end_char="12839" id="token-98-17" morph="none" pos="punct" start_char="12839">'</TOKEN>
<TOKEN end_char="12841" id="token-98-18" morph="none" pos="word" start_char="12840">we</TOKEN>
<TOKEN end_char="12846" id="token-98-19" morph="none" pos="word" start_char="12843">have</TOKEN>
<TOKEN end_char="12849" id="token-98-20" morph="none" pos="word" start_char="12848">NO</TOKEN>
<TOKEN end_char="12854" id="token-98-21" morph="none" pos="word" start_char="12851">IDEA</TOKEN>
<TOKEN end_char="12858" id="token-98-22" morph="none" pos="word" start_char="12856">how</TOKEN>
<TOKEN end_char="12863" id="token-98-23" morph="none" pos="word" start_char="12860">many</TOKEN>
<TOKEN end_char="12869" id="token-98-24" morph="none" pos="word" start_char="12865">cases</TOKEN>
<TOKEN end_char="12875" id="token-98-25" morph="none" pos="word" start_char="12871">China</TOKEN>
<TOKEN end_char="12882" id="token-98-26" morph="none" pos="word" start_char="12877">really</TOKEN>
<TOKEN end_char="12886" id="token-98-27" morph="none" pos="word" start_char="12884">has</TOKEN>
<TOKEN end_char="12887" id="token-98-28" morph="none" pos="punct" start_char="12887">'</TOKEN>
<TOKEN end_char="12893" id="token-98-29" morph="none" pos="word" start_char="12889">after</TOKEN>
<TOKEN end_char="12897" id="token-98-30" morph="none" pos="word" start_char="12895">the</TOKEN>
<TOKEN end_char="12900" id="token-98-31" morph="none" pos="word" start_char="12899">US</TOKEN>
<TOKEN end_char="12910" id="token-98-32" morph="none" pos="word" start_char="12902">infection</TOKEN>
<TOKEN end_char="12916" id="token-98-33" morph="none" pos="word" start_char="12912">total</TOKEN>
<TOKEN end_char="12923" id="token-98-34" morph="none" pos="word" start_char="12918">passed</TOKEN>
<TOKEN end_char="12933" id="token-98-35" morph="none" pos="word" start_char="12925">Beijing's</TOKEN>
<TOKEN end_char="12942" id="token-98-36" morph="none" pos="word" start_char="12935">official</TOKEN>
<TOKEN end_char="12949" id="token-98-37" morph="none" pos="word" start_char="12944">figure</TOKEN>
<TOKEN end_char="12950" id="token-98-38" morph="none" pos="punct" start_char="12950">.</TOKEN>
</SEG>
<SEG end_char="13030" id="segment-99" start_char="12953">
<ORIGINAL_TEXT>'Without any doubt it's significantly more than what they admit to,' he added.</ORIGINAL_TEXT>
<TOKEN end_char="12953" id="token-99-0" morph="none" pos="punct" start_char="12953">'</TOKEN>
<TOKEN end_char="12960" id="token-99-1" morph="none" pos="word" start_char="12954">Without</TOKEN>
<TOKEN end_char="12964" id="token-99-2" morph="none" pos="word" start_char="12962">any</TOKEN>
<TOKEN end_char="12970" id="token-99-3" morph="none" pos="word" start_char="12966">doubt</TOKEN>
<TOKEN end_char="12975" id="token-99-4" morph="none" pos="word" start_char="12972">it's</TOKEN>
<TOKEN end_char="12989" id="token-99-5" morph="none" pos="word" start_char="12977">significantly</TOKEN>
<TOKEN end_char="12994" id="token-99-6" morph="none" pos="word" start_char="12991">more</TOKEN>
<TOKEN end_char="12999" id="token-99-7" morph="none" pos="word" start_char="12996">than</TOKEN>
<TOKEN end_char="13004" id="token-99-8" morph="none" pos="word" start_char="13001">what</TOKEN>
<TOKEN end_char="13009" id="token-99-9" morph="none" pos="word" start_char="13006">they</TOKEN>
<TOKEN end_char="13015" id="token-99-10" morph="none" pos="word" start_char="13011">admit</TOKEN>
<TOKEN end_char="13018" id="token-99-11" morph="none" pos="word" start_char="13017">to</TOKEN>
<TOKEN end_char="13020" id="token-99-12" morph="none" pos="punct" start_char="13019">,'</TOKEN>
<TOKEN end_char="13023" id="token-99-13" morph="none" pos="word" start_char="13022">he</TOKEN>
<TOKEN end_char="13029" id="token-99-14" morph="none" pos="word" start_char="13025">added</TOKEN>
<TOKEN end_char="13030" id="token-99-15" morph="none" pos="punct" start_char="13030">.</TOKEN>
</SEG>
<SEG end_char="13231" id="segment-100" start_char="13033">
<ORIGINAL_TEXT>Meanwhile the UK government has also cast doubt on China's reporting, with Conservative minister and former Prime Ministerial candidate Michael Gove claiming the Communist Party could not be trusted.</ORIGINAL_TEXT>
<TOKEN end_char="13041" id="token-100-0" morph="none" pos="word" start_char="13033">Meanwhile</TOKEN>
<TOKEN end_char="13045" id="token-100-1" morph="none" pos="word" start_char="13043">the</TOKEN>
<TOKEN end_char="13048" id="token-100-2" morph="none" pos="word" start_char="13047">UK</TOKEN>
<TOKEN end_char="13059" id="token-100-3" morph="none" pos="word" start_char="13050">government</TOKEN>
<TOKEN end_char="13063" id="token-100-4" morph="none" pos="word" start_char="13061">has</TOKEN>
<TOKEN end_char="13068" id="token-100-5" morph="none" pos="word" start_char="13065">also</TOKEN>
<TOKEN end_char="13073" id="token-100-6" morph="none" pos="word" start_char="13070">cast</TOKEN>
<TOKEN end_char="13079" id="token-100-7" morph="none" pos="word" start_char="13075">doubt</TOKEN>
<TOKEN end_char="13082" id="token-100-8" morph="none" pos="word" start_char="13081">on</TOKEN>
<TOKEN end_char="13090" id="token-100-9" morph="none" pos="word" start_char="13084">China's</TOKEN>
<TOKEN end_char="13100" id="token-100-10" morph="none" pos="word" start_char="13092">reporting</TOKEN>
<TOKEN end_char="13101" id="token-100-11" morph="none" pos="punct" start_char="13101">,</TOKEN>
<TOKEN end_char="13106" id="token-100-12" morph="none" pos="word" start_char="13103">with</TOKEN>
<TOKEN end_char="13119" id="token-100-13" morph="none" pos="word" start_char="13108">Conservative</TOKEN>
<TOKEN end_char="13128" id="token-100-14" morph="none" pos="word" start_char="13121">minister</TOKEN>
<TOKEN end_char="13132" id="token-100-15" morph="none" pos="word" start_char="13130">and</TOKEN>
<TOKEN end_char="13139" id="token-100-16" morph="none" pos="word" start_char="13134">former</TOKEN>
<TOKEN end_char="13145" id="token-100-17" morph="none" pos="word" start_char="13141">Prime</TOKEN>
<TOKEN end_char="13157" id="token-100-18" morph="none" pos="word" start_char="13147">Ministerial</TOKEN>
<TOKEN end_char="13167" id="token-100-19" morph="none" pos="word" start_char="13159">candidate</TOKEN>
<TOKEN end_char="13175" id="token-100-20" morph="none" pos="word" start_char="13169">Michael</TOKEN>
<TOKEN end_char="13180" id="token-100-21" morph="none" pos="word" start_char="13177">Gove</TOKEN>
<TOKEN end_char="13189" id="token-100-22" morph="none" pos="word" start_char="13182">claiming</TOKEN>
<TOKEN end_char="13193" id="token-100-23" morph="none" pos="word" start_char="13191">the</TOKEN>
<TOKEN end_char="13203" id="token-100-24" morph="none" pos="word" start_char="13195">Communist</TOKEN>
<TOKEN end_char="13209" id="token-100-25" morph="none" pos="word" start_char="13205">Party</TOKEN>
<TOKEN end_char="13215" id="token-100-26" morph="none" pos="word" start_char="13211">could</TOKEN>
<TOKEN end_char="13219" id="token-100-27" morph="none" pos="word" start_char="13217">not</TOKEN>
<TOKEN end_char="13222" id="token-100-28" morph="none" pos="word" start_char="13221">be</TOKEN>
<TOKEN end_char="13230" id="token-100-29" morph="none" pos="word" start_char="13224">trusted</TOKEN>
<TOKEN end_char="13231" id="token-100-30" morph="none" pos="punct" start_char="13231">.</TOKEN>
</SEG>
<SEG end_char="13363" id="segment-101" start_char="13234">
<ORIGINAL_TEXT>'Some of the reporting from China was not clear about the scale, the nature, the infectiousness of this [virus],' he told the BBC.</ORIGINAL_TEXT>
<TOKEN end_char="13234" id="token-101-0" morph="none" pos="punct" start_char="13234">'</TOKEN>
<TOKEN end_char="13238" id="token-101-1" morph="none" pos="word" start_char="13235">Some</TOKEN>
<TOKEN end_char="13241" id="token-101-2" morph="none" pos="word" start_char="13240">of</TOKEN>
<TOKEN end_char="13245" id="token-101-3" morph="none" pos="word" start_char="13243">the</TOKEN>
<TOKEN end_char="13255" id="token-101-4" morph="none" pos="word" start_char="13247">reporting</TOKEN>
<TOKEN end_char="13260" id="token-101-5" morph="none" pos="word" start_char="13257">from</TOKEN>
<TOKEN end_char="13266" id="token-101-6" morph="none" pos="word" start_char="13262">China</TOKEN>
<TOKEN end_char="13270" id="token-101-7" morph="none" pos="word" start_char="13268">was</TOKEN>
<TOKEN end_char="13274" id="token-101-8" morph="none" pos="word" start_char="13272">not</TOKEN>
<TOKEN end_char="13280" id="token-101-9" morph="none" pos="word" start_char="13276">clear</TOKEN>
<TOKEN end_char="13286" id="token-101-10" morph="none" pos="word" start_char="13282">about</TOKEN>
<TOKEN end_char="13290" id="token-101-11" morph="none" pos="word" start_char="13288">the</TOKEN>
<TOKEN end_char="13296" id="token-101-12" morph="none" pos="word" start_char="13292">scale</TOKEN>
<TOKEN end_char="13297" id="token-101-13" morph="none" pos="punct" start_char="13297">,</TOKEN>
<TOKEN end_char="13301" id="token-101-14" morph="none" pos="word" start_char="13299">the</TOKEN>
<TOKEN end_char="13308" id="token-101-15" morph="none" pos="word" start_char="13303">nature</TOKEN>
<TOKEN end_char="13309" id="token-101-16" morph="none" pos="punct" start_char="13309">,</TOKEN>
<TOKEN end_char="13313" id="token-101-17" morph="none" pos="word" start_char="13311">the</TOKEN>
<TOKEN end_char="13328" id="token-101-18" morph="none" pos="word" start_char="13315">infectiousness</TOKEN>
<TOKEN end_char="13331" id="token-101-19" morph="none" pos="word" start_char="13330">of</TOKEN>
<TOKEN end_char="13336" id="token-101-20" morph="none" pos="word" start_char="13333">this</TOKEN>
<TOKEN end_char="13338" id="token-101-21" morph="none" pos="punct" start_char="13338">[</TOKEN>
<TOKEN end_char="13343" id="token-101-22" morph="none" pos="word" start_char="13339">virus</TOKEN>
<TOKEN end_char="13346" id="token-101-23" morph="none" pos="punct" start_char="13344">],'</TOKEN>
<TOKEN end_char="13349" id="token-101-24" morph="none" pos="word" start_char="13348">he</TOKEN>
<TOKEN end_char="13354" id="token-101-25" morph="none" pos="word" start_char="13351">told</TOKEN>
<TOKEN end_char="13358" id="token-101-26" morph="none" pos="word" start_char="13356">the</TOKEN>
<TOKEN end_char="13362" id="token-101-27" morph="none" pos="word" start_char="13360">BBC</TOKEN>
<TOKEN end_char="13363" id="token-101-28" morph="none" pos="punct" start_char="13363">.</TOKEN>
</SEG>
<SEG end_char="13497" id="segment-102" start_char="13366">
<ORIGINAL_TEXT>Meanwhile sources told the Mail that China's true infection total could be anything up to 40 times as high as reports had suggested.</ORIGINAL_TEXT>
<TOKEN end_char="13374" id="token-102-0" morph="none" pos="word" start_char="13366">Meanwhile</TOKEN>
<TOKEN end_char="13382" id="token-102-1" morph="none" pos="word" start_char="13376">sources</TOKEN>
<TOKEN end_char="13387" id="token-102-2" morph="none" pos="word" start_char="13384">told</TOKEN>
<TOKEN end_char="13391" id="token-102-3" morph="none" pos="word" start_char="13389">the</TOKEN>
<TOKEN end_char="13396" id="token-102-4" morph="none" pos="word" start_char="13393">Mail</TOKEN>
<TOKEN end_char="13401" id="token-102-5" morph="none" pos="word" start_char="13398">that</TOKEN>
<TOKEN end_char="13409" id="token-102-6" morph="none" pos="word" start_char="13403">China's</TOKEN>
<TOKEN end_char="13414" id="token-102-7" morph="none" pos="word" start_char="13411">true</TOKEN>
<TOKEN end_char="13424" id="token-102-8" morph="none" pos="word" start_char="13416">infection</TOKEN>
<TOKEN end_char="13430" id="token-102-9" morph="none" pos="word" start_char="13426">total</TOKEN>
<TOKEN end_char="13436" id="token-102-10" morph="none" pos="word" start_char="13432">could</TOKEN>
<TOKEN end_char="13439" id="token-102-11" morph="none" pos="word" start_char="13438">be</TOKEN>
<TOKEN end_char="13448" id="token-102-12" morph="none" pos="word" start_char="13441">anything</TOKEN>
<TOKEN end_char="13451" id="token-102-13" morph="none" pos="word" start_char="13450">up</TOKEN>
<TOKEN end_char="13454" id="token-102-14" morph="none" pos="word" start_char="13453">to</TOKEN>
<TOKEN end_char="13457" id="token-102-15" morph="none" pos="word" start_char="13456">40</TOKEN>
<TOKEN end_char="13463" id="token-102-16" morph="none" pos="word" start_char="13459">times</TOKEN>
<TOKEN end_char="13466" id="token-102-17" morph="none" pos="word" start_char="13465">as</TOKEN>
<TOKEN end_char="13471" id="token-102-18" morph="none" pos="word" start_char="13468">high</TOKEN>
<TOKEN end_char="13474" id="token-102-19" morph="none" pos="word" start_char="13473">as</TOKEN>
<TOKEN end_char="13482" id="token-102-20" morph="none" pos="word" start_char="13476">reports</TOKEN>
<TOKEN end_char="13486" id="token-102-21" morph="none" pos="word" start_char="13484">had</TOKEN>
<TOKEN end_char="13496" id="token-102-22" morph="none" pos="word" start_char="13488">suggested</TOKEN>
<TOKEN end_char="13497" id="token-102-23" morph="none" pos="punct" start_char="13497">.</TOKEN>
</SEG>
<SEG end_char="13632" id="segment-103" start_char="13501">
<ORIGINAL_TEXT>Marco Rubio, a prominent Republican senator, has said that China's figures cannot be trusted and a far higher than has been reported</ORIGINAL_TEXT>
<TOKEN end_char="13505" id="token-103-0" morph="none" pos="word" start_char="13501">Marco</TOKEN>
<TOKEN end_char="13511" id="token-103-1" morph="none" pos="word" start_char="13507">Rubio</TOKEN>
<TOKEN end_char="13512" id="token-103-2" morph="none" pos="punct" start_char="13512">,</TOKEN>
<TOKEN end_char="13514" id="token-103-3" morph="none" pos="word" start_char="13514">a</TOKEN>
<TOKEN end_char="13524" id="token-103-4" morph="none" pos="word" start_char="13516">prominent</TOKEN>
<TOKEN end_char="13535" id="token-103-5" morph="none" pos="word" start_char="13526">Republican</TOKEN>
<TOKEN end_char="13543" id="token-103-6" morph="none" pos="word" start_char="13537">senator</TOKEN>
<TOKEN end_char="13544" id="token-103-7" morph="none" pos="punct" start_char="13544">,</TOKEN>
<TOKEN end_char="13548" id="token-103-8" morph="none" pos="word" start_char="13546">has</TOKEN>
<TOKEN end_char="13553" id="token-103-9" morph="none" pos="word" start_char="13550">said</TOKEN>
<TOKEN end_char="13558" id="token-103-10" morph="none" pos="word" start_char="13555">that</TOKEN>
<TOKEN end_char="13566" id="token-103-11" morph="none" pos="word" start_char="13560">China's</TOKEN>
<TOKEN end_char="13574" id="token-103-12" morph="none" pos="word" start_char="13568">figures</TOKEN>
<TOKEN end_char="13581" id="token-103-13" morph="none" pos="word" start_char="13576">cannot</TOKEN>
<TOKEN end_char="13584" id="token-103-14" morph="none" pos="word" start_char="13583">be</TOKEN>
<TOKEN end_char="13592" id="token-103-15" morph="none" pos="word" start_char="13586">trusted</TOKEN>
<TOKEN end_char="13596" id="token-103-16" morph="none" pos="word" start_char="13594">and</TOKEN>
<TOKEN end_char="13598" id="token-103-17" morph="none" pos="word" start_char="13598">a</TOKEN>
<TOKEN end_char="13602" id="token-103-18" morph="none" pos="word" start_char="13600">far</TOKEN>
<TOKEN end_char="13609" id="token-103-19" morph="none" pos="word" start_char="13604">higher</TOKEN>
<TOKEN end_char="13614" id="token-103-20" morph="none" pos="word" start_char="13611">than</TOKEN>
<TOKEN end_char="13618" id="token-103-21" morph="none" pos="word" start_char="13616">has</TOKEN>
<TOKEN end_char="13623" id="token-103-22" morph="none" pos="word" start_char="13620">been</TOKEN>
<TOKEN end_char="13632" id="token-103-23" morph="none" pos="word" start_char="13625">reported</TOKEN>
</SEG>
<SEG end_char="13645" id="segment-104" start_char="13635">
<ORIGINAL_TEXT>Death total</ORIGINAL_TEXT>
<TOKEN end_char="13639" id="token-104-0" morph="none" pos="word" start_char="13635">Death</TOKEN>
<TOKEN end_char="13645" id="token-104-1" morph="none" pos="word" start_char="13641">total</TOKEN>
</SEG>
<SEG end_char="13758" id="segment-105" start_char="13648">
<ORIGINAL_TEXT>Doubt has also been cast on China's reported death toll from the virus, which currently stands at around 3,300.</ORIGINAL_TEXT>
<TOKEN end_char="13652" id="token-105-0" morph="none" pos="word" start_char="13648">Doubt</TOKEN>
<TOKEN end_char="13656" id="token-105-1" morph="none" pos="word" start_char="13654">has</TOKEN>
<TOKEN end_char="13661" id="token-105-2" morph="none" pos="word" start_char="13658">also</TOKEN>
<TOKEN end_char="13666" id="token-105-3" morph="none" pos="word" start_char="13663">been</TOKEN>
<TOKEN end_char="13671" id="token-105-4" morph="none" pos="word" start_char="13668">cast</TOKEN>
<TOKEN end_char="13674" id="token-105-5" morph="none" pos="word" start_char="13673">on</TOKEN>
<TOKEN end_char="13682" id="token-105-6" morph="none" pos="word" start_char="13676">China's</TOKEN>
<TOKEN end_char="13691" id="token-105-7" morph="none" pos="word" start_char="13684">reported</TOKEN>
<TOKEN end_char="13697" id="token-105-8" morph="none" pos="word" start_char="13693">death</TOKEN>
<TOKEN end_char="13702" id="token-105-9" morph="none" pos="word" start_char="13699">toll</TOKEN>
<TOKEN end_char="13707" id="token-105-10" morph="none" pos="word" start_char="13704">from</TOKEN>
<TOKEN end_char="13711" id="token-105-11" morph="none" pos="word" start_char="13709">the</TOKEN>
<TOKEN end_char="13717" id="token-105-12" morph="none" pos="word" start_char="13713">virus</TOKEN>
<TOKEN end_char="13718" id="token-105-13" morph="none" pos="punct" start_char="13718">,</TOKEN>
<TOKEN end_char="13724" id="token-105-14" morph="none" pos="word" start_char="13720">which</TOKEN>
<TOKEN end_char="13734" id="token-105-15" morph="none" pos="word" start_char="13726">currently</TOKEN>
<TOKEN end_char="13741" id="token-105-16" morph="none" pos="word" start_char="13736">stands</TOKEN>
<TOKEN end_char="13744" id="token-105-17" morph="none" pos="word" start_char="13743">at</TOKEN>
<TOKEN end_char="13751" id="token-105-18" morph="none" pos="word" start_char="13746">around</TOKEN>
<TOKEN end_char="13757" id="token-105-19" morph="none" pos="unknown" start_char="13753">3,300</TOKEN>
<TOKEN end_char="13758" id="token-105-20" morph="none" pos="punct" start_char="13758">.</TOKEN>
</SEG>
<SEG end_char="13953" id="segment-106" start_char="13761">
<ORIGINAL_TEXT>Locals in epicenter city Wuhan have been keeping an eye on funeral homes since lockdown restrictions were partly lifted, claiming they have been 'working around the clock' to dispose of bodies.</ORIGINAL_TEXT>
<TOKEN end_char="13766" id="token-106-0" morph="none" pos="word" start_char="13761">Locals</TOKEN>
<TOKEN end_char="13769" id="token-106-1" morph="none" pos="word" start_char="13768">in</TOKEN>
<TOKEN end_char="13779" id="token-106-2" morph="none" pos="word" start_char="13771">epicenter</TOKEN>
<TOKEN end_char="13784" id="token-106-3" morph="none" pos="word" start_char="13781">city</TOKEN>
<TOKEN end_char="13790" id="token-106-4" morph="none" pos="word" start_char="13786">Wuhan</TOKEN>
<TOKEN end_char="13795" id="token-106-5" morph="none" pos="word" start_char="13792">have</TOKEN>
<TOKEN end_char="13800" id="token-106-6" morph="none" pos="word" start_char="13797">been</TOKEN>
<TOKEN end_char="13808" id="token-106-7" morph="none" pos="word" start_char="13802">keeping</TOKEN>
<TOKEN end_char="13811" id="token-106-8" morph="none" pos="word" start_char="13810">an</TOKEN>
<TOKEN end_char="13815" id="token-106-9" morph="none" pos="word" start_char="13813">eye</TOKEN>
<TOKEN end_char="13818" id="token-106-10" morph="none" pos="word" start_char="13817">on</TOKEN>
<TOKEN end_char="13826" id="token-106-11" morph="none" pos="word" start_char="13820">funeral</TOKEN>
<TOKEN end_char="13832" id="token-106-12" morph="none" pos="word" start_char="13828">homes</TOKEN>
<TOKEN end_char="13838" id="token-106-13" morph="none" pos="word" start_char="13834">since</TOKEN>
<TOKEN end_char="13847" id="token-106-14" morph="none" pos="word" start_char="13840">lockdown</TOKEN>
<TOKEN end_char="13860" id="token-106-15" morph="none" pos="word" start_char="13849">restrictions</TOKEN>
<TOKEN end_char="13865" id="token-106-16" morph="none" pos="word" start_char="13862">were</TOKEN>
<TOKEN end_char="13872" id="token-106-17" morph="none" pos="word" start_char="13867">partly</TOKEN>
<TOKEN end_char="13879" id="token-106-18" morph="none" pos="word" start_char="13874">lifted</TOKEN>
<TOKEN end_char="13880" id="token-106-19" morph="none" pos="punct" start_char="13880">,</TOKEN>
<TOKEN end_char="13889" id="token-106-20" morph="none" pos="word" start_char="13882">claiming</TOKEN>
<TOKEN end_char="13894" id="token-106-21" morph="none" pos="word" start_char="13891">they</TOKEN>
<TOKEN end_char="13899" id="token-106-22" morph="none" pos="word" start_char="13896">have</TOKEN>
<TOKEN end_char="13904" id="token-106-23" morph="none" pos="word" start_char="13901">been</TOKEN>
<TOKEN end_char="13906" id="token-106-24" morph="none" pos="punct" start_char="13906">'</TOKEN>
<TOKEN end_char="13913" id="token-106-25" morph="none" pos="word" start_char="13907">working</TOKEN>
<TOKEN end_char="13920" id="token-106-26" morph="none" pos="word" start_char="13915">around</TOKEN>
<TOKEN end_char="13924" id="token-106-27" morph="none" pos="word" start_char="13922">the</TOKEN>
<TOKEN end_char="13930" id="token-106-28" morph="none" pos="word" start_char="13926">clock</TOKEN>
<TOKEN end_char="13931" id="token-106-29" morph="none" pos="punct" start_char="13931">'</TOKEN>
<TOKEN end_char="13934" id="token-106-30" morph="none" pos="word" start_char="13933">to</TOKEN>
<TOKEN end_char="13942" id="token-106-31" morph="none" pos="word" start_char="13936">dispose</TOKEN>
<TOKEN end_char="13945" id="token-106-32" morph="none" pos="word" start_char="13944">of</TOKEN>
<TOKEN end_char="13952" id="token-106-33" morph="none" pos="word" start_char="13947">bodies</TOKEN>
<TOKEN end_char="13953" id="token-106-34" morph="none" pos="punct" start_char="13953">.</TOKEN>
</SEG>
<SEG end_char="14133" id="segment-107" start_char="13957">
<ORIGINAL_TEXT>Social media posts estimate that 3,500 urns are being handed out by crematoriums each day, while Caixin reports that one funeral home in the city placed an order for 5,000 urns.</ORIGINAL_TEXT>
<TOKEN end_char="13962" id="token-107-0" morph="none" pos="word" start_char="13957">Social</TOKEN>
<TOKEN end_char="13968" id="token-107-1" morph="none" pos="word" start_char="13964">media</TOKEN>
<TOKEN end_char="13974" id="token-107-2" morph="none" pos="word" start_char="13970">posts</TOKEN>
<TOKEN end_char="13983" id="token-107-3" morph="none" pos="word" start_char="13976">estimate</TOKEN>
<TOKEN end_char="13988" id="token-107-4" morph="none" pos="word" start_char="13985">that</TOKEN>
<TOKEN end_char="13994" id="token-107-5" morph="none" pos="unknown" start_char="13990">3,500</TOKEN>
<TOKEN end_char="13999" id="token-107-6" morph="none" pos="word" start_char="13996">urns</TOKEN>
<TOKEN end_char="14003" id="token-107-7" morph="none" pos="word" start_char="14001">are</TOKEN>
<TOKEN end_char="14009" id="token-107-8" morph="none" pos="word" start_char="14005">being</TOKEN>
<TOKEN end_char="14016" id="token-107-9" morph="none" pos="word" start_char="14011">handed</TOKEN>
<TOKEN end_char="14020" id="token-107-10" morph="none" pos="word" start_char="14018">out</TOKEN>
<TOKEN end_char="14023" id="token-107-11" morph="none" pos="word" start_char="14022">by</TOKEN>
<TOKEN end_char="14036" id="token-107-12" morph="none" pos="word" start_char="14025">crematoriums</TOKEN>
<TOKEN end_char="14041" id="token-107-13" morph="none" pos="word" start_char="14038">each</TOKEN>
<TOKEN end_char="14045" id="token-107-14" morph="none" pos="word" start_char="14043">day</TOKEN>
<TOKEN end_char="14046" id="token-107-15" morph="none" pos="punct" start_char="14046">,</TOKEN>
<TOKEN end_char="14052" id="token-107-16" morph="none" pos="word" start_char="14048">while</TOKEN>
<TOKEN end_char="14059" id="token-107-17" morph="none" pos="word" start_char="14054">Caixin</TOKEN>
<TOKEN end_char="14067" id="token-107-18" morph="none" pos="word" start_char="14061">reports</TOKEN>
<TOKEN end_char="14072" id="token-107-19" morph="none" pos="word" start_char="14069">that</TOKEN>
<TOKEN end_char="14076" id="token-107-20" morph="none" pos="word" start_char="14074">one</TOKEN>
<TOKEN end_char="14084" id="token-107-21" morph="none" pos="word" start_char="14078">funeral</TOKEN>
<TOKEN end_char="14089" id="token-107-22" morph="none" pos="word" start_char="14086">home</TOKEN>
<TOKEN end_char="14092" id="token-107-23" morph="none" pos="word" start_char="14091">in</TOKEN>
<TOKEN end_char="14096" id="token-107-24" morph="none" pos="word" start_char="14094">the</TOKEN>
<TOKEN end_char="14101" id="token-107-25" morph="none" pos="word" start_char="14098">city</TOKEN>
<TOKEN end_char="14108" id="token-107-26" morph="none" pos="word" start_char="14103">placed</TOKEN>
<TOKEN end_char="14111" id="token-107-27" morph="none" pos="word" start_char="14110">an</TOKEN>
<TOKEN end_char="14117" id="token-107-28" morph="none" pos="word" start_char="14113">order</TOKEN>
<TOKEN end_char="14121" id="token-107-29" morph="none" pos="word" start_char="14119">for</TOKEN>
<TOKEN end_char="14127" id="token-107-30" morph="none" pos="unknown" start_char="14123">5,000</TOKEN>
<TOKEN end_char="14132" id="token-107-31" morph="none" pos="word" start_char="14129">urns</TOKEN>
<TOKEN end_char="14133" id="token-107-32" morph="none" pos="punct" start_char="14133">.</TOKEN>
</SEG>
<SEG end_char="14276" id="segment-108" start_char="14136">
<ORIGINAL_TEXT>Locals believe that efforts to dispose of the bodies began March 23 and city authorities have said the process will end on or around April 5.</ORIGINAL_TEXT>
<TOKEN end_char="14141" id="token-108-0" morph="none" pos="word" start_char="14136">Locals</TOKEN>
<TOKEN end_char="14149" id="token-108-1" morph="none" pos="word" start_char="14143">believe</TOKEN>
<TOKEN end_char="14154" id="token-108-2" morph="none" pos="word" start_char="14151">that</TOKEN>
<TOKEN end_char="14162" id="token-108-3" morph="none" pos="word" start_char="14156">efforts</TOKEN>
<TOKEN end_char="14165" id="token-108-4" morph="none" pos="word" start_char="14164">to</TOKEN>
<TOKEN end_char="14173" id="token-108-5" morph="none" pos="word" start_char="14167">dispose</TOKEN>
<TOKEN end_char="14176" id="token-108-6" morph="none" pos="word" start_char="14175">of</TOKEN>
<TOKEN end_char="14180" id="token-108-7" morph="none" pos="word" start_char="14178">the</TOKEN>
<TOKEN end_char="14187" id="token-108-8" morph="none" pos="word" start_char="14182">bodies</TOKEN>
<TOKEN end_char="14193" id="token-108-9" morph="none" pos="word" start_char="14189">began</TOKEN>
<TOKEN end_char="14199" id="token-108-10" morph="none" pos="word" start_char="14195">March</TOKEN>
<TOKEN end_char="14202" id="token-108-11" morph="none" pos="word" start_char="14201">23</TOKEN>
<TOKEN end_char="14206" id="token-108-12" morph="none" pos="word" start_char="14204">and</TOKEN>
<TOKEN end_char="14211" id="token-108-13" morph="none" pos="word" start_char="14208">city</TOKEN>
<TOKEN end_char="14223" id="token-108-14" morph="none" pos="word" start_char="14213">authorities</TOKEN>
<TOKEN end_char="14228" id="token-108-15" morph="none" pos="word" start_char="14225">have</TOKEN>
<TOKEN end_char="14233" id="token-108-16" morph="none" pos="word" start_char="14230">said</TOKEN>
<TOKEN end_char="14237" id="token-108-17" morph="none" pos="word" start_char="14235">the</TOKEN>
<TOKEN end_char="14245" id="token-108-18" morph="none" pos="word" start_char="14239">process</TOKEN>
<TOKEN end_char="14250" id="token-108-19" morph="none" pos="word" start_char="14247">will</TOKEN>
<TOKEN end_char="14254" id="token-108-20" morph="none" pos="word" start_char="14252">end</TOKEN>
<TOKEN end_char="14257" id="token-108-21" morph="none" pos="word" start_char="14256">on</TOKEN>
<TOKEN end_char="14260" id="token-108-22" morph="none" pos="word" start_char="14259">or</TOKEN>
<TOKEN end_char="14267" id="token-108-23" morph="none" pos="word" start_char="14262">around</TOKEN>
<TOKEN end_char="14273" id="token-108-24" morph="none" pos="word" start_char="14269">April</TOKEN>
<TOKEN end_char="14275" id="token-108-25" morph="none" pos="word" start_char="14275">5</TOKEN>
<TOKEN end_char="14276" id="token-108-26" morph="none" pos="punct" start_char="14276">.</TOKEN>
</SEG>
<SEG end_char="14375" id="segment-109" start_char="14279">
<ORIGINAL_TEXT>That would mean roughly 42,000 urns handed out in that time frame, ten times the reported figure.</ORIGINAL_TEXT>
<TOKEN end_char="14282" id="token-109-0" morph="none" pos="word" start_char="14279">That</TOKEN>
<TOKEN end_char="14288" id="token-109-1" morph="none" pos="word" start_char="14284">would</TOKEN>
<TOKEN end_char="14293" id="token-109-2" morph="none" pos="word" start_char="14290">mean</TOKEN>
<TOKEN end_char="14301" id="token-109-3" morph="none" pos="word" start_char="14295">roughly</TOKEN>
<TOKEN end_char="14308" id="token-109-4" morph="none" pos="unknown" start_char="14303">42,000</TOKEN>
<TOKEN end_char="14313" id="token-109-5" morph="none" pos="word" start_char="14310">urns</TOKEN>
<TOKEN end_char="14320" id="token-109-6" morph="none" pos="word" start_char="14315">handed</TOKEN>
<TOKEN end_char="14324" id="token-109-7" morph="none" pos="word" start_char="14322">out</TOKEN>
<TOKEN end_char="14327" id="token-109-8" morph="none" pos="word" start_char="14326">in</TOKEN>
<TOKEN end_char="14332" id="token-109-9" morph="none" pos="word" start_char="14329">that</TOKEN>
<TOKEN end_char="14337" id="token-109-10" morph="none" pos="word" start_char="14334">time</TOKEN>
<TOKEN end_char="14343" id="token-109-11" morph="none" pos="word" start_char="14339">frame</TOKEN>
<TOKEN end_char="14344" id="token-109-12" morph="none" pos="punct" start_char="14344">,</TOKEN>
<TOKEN end_char="14348" id="token-109-13" morph="none" pos="word" start_char="14346">ten</TOKEN>
<TOKEN end_char="14354" id="token-109-14" morph="none" pos="word" start_char="14350">times</TOKEN>
<TOKEN end_char="14358" id="token-109-15" morph="none" pos="word" start_char="14356">the</TOKEN>
<TOKEN end_char="14367" id="token-109-16" morph="none" pos="word" start_char="14360">reported</TOKEN>
<TOKEN end_char="14374" id="token-109-17" morph="none" pos="word" start_char="14369">figure</TOKEN>
<TOKEN end_char="14375" id="token-109-18" morph="none" pos="punct" start_char="14375">.</TOKEN>
</SEG>
<SEG end_char="14397" id="segment-110" start_char="14378">
<ORIGINAL_TEXT>Chinese aid packages</ORIGINAL_TEXT>
<TOKEN end_char="14384" id="token-110-0" morph="none" pos="word" start_char="14378">Chinese</TOKEN>
<TOKEN end_char="14388" id="token-110-1" morph="none" pos="word" start_char="14386">aid</TOKEN>
<TOKEN end_char="14397" id="token-110-2" morph="none" pos="word" start_char="14390">packages</TOKEN>
</SEG>
<SEG end_char="14637" id="segment-111" start_char="14400">
<ORIGINAL_TEXT>As it brought its own coronavirus epidemic under control and as the disease spread across the rest of the world, China attempted to paint itself as a helpful neighbour by sending aid and supplies to countries most in need - such as Italy.</ORIGINAL_TEXT>
<TOKEN end_char="14401" id="token-111-0" morph="none" pos="word" start_char="14400">As</TOKEN>
<TOKEN end_char="14404" id="token-111-1" morph="none" pos="word" start_char="14403">it</TOKEN>
<TOKEN end_char="14412" id="token-111-2" morph="none" pos="word" start_char="14406">brought</TOKEN>
<TOKEN end_char="14416" id="token-111-3" morph="none" pos="word" start_char="14414">its</TOKEN>
<TOKEN end_char="14420" id="token-111-4" morph="none" pos="word" start_char="14418">own</TOKEN>
<TOKEN end_char="14432" id="token-111-5" morph="none" pos="word" start_char="14422">coronavirus</TOKEN>
<TOKEN end_char="14441" id="token-111-6" morph="none" pos="word" start_char="14434">epidemic</TOKEN>
<TOKEN end_char="14447" id="token-111-7" morph="none" pos="word" start_char="14443">under</TOKEN>
<TOKEN end_char="14455" id="token-111-8" morph="none" pos="word" start_char="14449">control</TOKEN>
<TOKEN end_char="14459" id="token-111-9" morph="none" pos="word" start_char="14457">and</TOKEN>
<TOKEN end_char="14462" id="token-111-10" morph="none" pos="word" start_char="14461">as</TOKEN>
<TOKEN end_char="14466" id="token-111-11" morph="none" pos="word" start_char="14464">the</TOKEN>
<TOKEN end_char="14474" id="token-111-12" morph="none" pos="word" start_char="14468">disease</TOKEN>
<TOKEN end_char="14481" id="token-111-13" morph="none" pos="word" start_char="14476">spread</TOKEN>
<TOKEN end_char="14488" id="token-111-14" morph="none" pos="word" start_char="14483">across</TOKEN>
<TOKEN end_char="14492" id="token-111-15" morph="none" pos="word" start_char="14490">the</TOKEN>
<TOKEN end_char="14497" id="token-111-16" morph="none" pos="word" start_char="14494">rest</TOKEN>
<TOKEN end_char="14500" id="token-111-17" morph="none" pos="word" start_char="14499">of</TOKEN>
<TOKEN end_char="14504" id="token-111-18" morph="none" pos="word" start_char="14502">the</TOKEN>
<TOKEN end_char="14510" id="token-111-19" morph="none" pos="word" start_char="14506">world</TOKEN>
<TOKEN end_char="14511" id="token-111-20" morph="none" pos="punct" start_char="14511">,</TOKEN>
<TOKEN end_char="14517" id="token-111-21" morph="none" pos="word" start_char="14513">China</TOKEN>
<TOKEN end_char="14527" id="token-111-22" morph="none" pos="word" start_char="14519">attempted</TOKEN>
<TOKEN end_char="14530" id="token-111-23" morph="none" pos="word" start_char="14529">to</TOKEN>
<TOKEN end_char="14536" id="token-111-24" morph="none" pos="word" start_char="14532">paint</TOKEN>
<TOKEN end_char="14543" id="token-111-25" morph="none" pos="word" start_char="14538">itself</TOKEN>
<TOKEN end_char="14546" id="token-111-26" morph="none" pos="word" start_char="14545">as</TOKEN>
<TOKEN end_char="14548" id="token-111-27" morph="none" pos="word" start_char="14548">a</TOKEN>
<TOKEN end_char="14556" id="token-111-28" morph="none" pos="word" start_char="14550">helpful</TOKEN>
<TOKEN end_char="14566" id="token-111-29" morph="none" pos="word" start_char="14558">neighbour</TOKEN>
<TOKEN end_char="14569" id="token-111-30" morph="none" pos="word" start_char="14568">by</TOKEN>
<TOKEN end_char="14577" id="token-111-31" morph="none" pos="word" start_char="14571">sending</TOKEN>
<TOKEN end_char="14581" id="token-111-32" morph="none" pos="word" start_char="14579">aid</TOKEN>
<TOKEN end_char="14585" id="token-111-33" morph="none" pos="word" start_char="14583">and</TOKEN>
<TOKEN end_char="14594" id="token-111-34" morph="none" pos="word" start_char="14587">supplies</TOKEN>
<TOKEN end_char="14597" id="token-111-35" morph="none" pos="word" start_char="14596">to</TOKEN>
<TOKEN end_char="14607" id="token-111-36" morph="none" pos="word" start_char="14599">countries</TOKEN>
<TOKEN end_char="14612" id="token-111-37" morph="none" pos="word" start_char="14609">most</TOKEN>
<TOKEN end_char="14615" id="token-111-38" morph="none" pos="word" start_char="14614">in</TOKEN>
<TOKEN end_char="14620" id="token-111-39" morph="none" pos="word" start_char="14617">need</TOKEN>
<TOKEN end_char="14622" id="token-111-40" morph="none" pos="punct" start_char="14622">-</TOKEN>
<TOKEN end_char="14627" id="token-111-41" morph="none" pos="word" start_char="14624">such</TOKEN>
<TOKEN end_char="14630" id="token-111-42" morph="none" pos="word" start_char="14629">as</TOKEN>
<TOKEN end_char="14636" id="token-111-43" morph="none" pos="word" start_char="14632">Italy</TOKEN>
<TOKEN end_char="14637" id="token-111-44" morph="none" pos="punct" start_char="14637">.</TOKEN>
</SEG>
<SEG end_char="14779" id="segment-112" start_char="14640">
<ORIGINAL_TEXT>In fact, while the Chinese Red Cross supplied some free equipment to the Italians, the country purchased a large amount of what it received.</ORIGINAL_TEXT>
<TOKEN end_char="14641" id="token-112-0" morph="none" pos="word" start_char="14640">In</TOKEN>
<TOKEN end_char="14646" id="token-112-1" morph="none" pos="word" start_char="14643">fact</TOKEN>
<TOKEN end_char="14647" id="token-112-2" morph="none" pos="punct" start_char="14647">,</TOKEN>
<TOKEN end_char="14653" id="token-112-3" morph="none" pos="word" start_char="14649">while</TOKEN>
<TOKEN end_char="14657" id="token-112-4" morph="none" pos="word" start_char="14655">the</TOKEN>
<TOKEN end_char="14665" id="token-112-5" morph="none" pos="word" start_char="14659">Chinese</TOKEN>
<TOKEN end_char="14669" id="token-112-6" morph="none" pos="word" start_char="14667">Red</TOKEN>
<TOKEN end_char="14675" id="token-112-7" morph="none" pos="word" start_char="14671">Cross</TOKEN>
<TOKEN end_char="14684" id="token-112-8" morph="none" pos="word" start_char="14677">supplied</TOKEN>
<TOKEN end_char="14689" id="token-112-9" morph="none" pos="word" start_char="14686">some</TOKEN>
<TOKEN end_char="14694" id="token-112-10" morph="none" pos="word" start_char="14691">free</TOKEN>
<TOKEN end_char="14704" id="token-112-11" morph="none" pos="word" start_char="14696">equipment</TOKEN>
<TOKEN end_char="14707" id="token-112-12" morph="none" pos="word" start_char="14706">to</TOKEN>
<TOKEN end_char="14711" id="token-112-13" morph="none" pos="word" start_char="14709">the</TOKEN>
<TOKEN end_char="14720" id="token-112-14" morph="none" pos="word" start_char="14713">Italians</TOKEN>
<TOKEN end_char="14721" id="token-112-15" morph="none" pos="punct" start_char="14721">,</TOKEN>
<TOKEN end_char="14725" id="token-112-16" morph="none" pos="word" start_char="14723">the</TOKEN>
<TOKEN end_char="14733" id="token-112-17" morph="none" pos="word" start_char="14727">country</TOKEN>
<TOKEN end_char="14743" id="token-112-18" morph="none" pos="word" start_char="14735">purchased</TOKEN>
<TOKEN end_char="14745" id="token-112-19" morph="none" pos="word" start_char="14745">a</TOKEN>
<TOKEN end_char="14751" id="token-112-20" morph="none" pos="word" start_char="14747">large</TOKEN>
<TOKEN end_char="14758" id="token-112-21" morph="none" pos="word" start_char="14753">amount</TOKEN>
<TOKEN end_char="14761" id="token-112-22" morph="none" pos="word" start_char="14760">of</TOKEN>
<TOKEN end_char="14766" id="token-112-23" morph="none" pos="word" start_char="14763">what</TOKEN>
<TOKEN end_char="14769" id="token-112-24" morph="none" pos="word" start_char="14768">it</TOKEN>
<TOKEN end_char="14778" id="token-112-25" morph="none" pos="word" start_char="14771">received</TOKEN>
<TOKEN end_char="14779" id="token-112-26" morph="none" pos="punct" start_char="14779">.</TOKEN>
</SEG>
<SEG end_char="14951" id="segment-113" start_char="14782">
<ORIGINAL_TEXT>Meanwhile officials in Spain said that a batch of coronavirus testing kits bought from China had just 30 per cent reliability - unlike the 80 per cent they were promised.</ORIGINAL_TEXT>
<TOKEN end_char="14790" id="token-113-0" morph="none" pos="word" start_char="14782">Meanwhile</TOKEN>
<TOKEN end_char="14800" id="token-113-1" morph="none" pos="word" start_char="14792">officials</TOKEN>
<TOKEN end_char="14803" id="token-113-2" morph="none" pos="word" start_char="14802">in</TOKEN>
<TOKEN end_char="14809" id="token-113-3" morph="none" pos="word" start_char="14805">Spain</TOKEN>
<TOKEN end_char="14814" id="token-113-4" morph="none" pos="word" start_char="14811">said</TOKEN>
<TOKEN end_char="14819" id="token-113-5" morph="none" pos="word" start_char="14816">that</TOKEN>
<TOKEN end_char="14821" id="token-113-6" morph="none" pos="word" start_char="14821">a</TOKEN>
<TOKEN end_char="14827" id="token-113-7" morph="none" pos="word" start_char="14823">batch</TOKEN>
<TOKEN end_char="14830" id="token-113-8" morph="none" pos="word" start_char="14829">of</TOKEN>
<TOKEN end_char="14842" id="token-113-9" morph="none" pos="word" start_char="14832">coronavirus</TOKEN>
<TOKEN end_char="14850" id="token-113-10" morph="none" pos="word" start_char="14844">testing</TOKEN>
<TOKEN end_char="14855" id="token-113-11" morph="none" pos="word" start_char="14852">kits</TOKEN>
<TOKEN end_char="14862" id="token-113-12" morph="none" pos="word" start_char="14857">bought</TOKEN>
<TOKEN end_char="14867" id="token-113-13" morph="none" pos="word" start_char="14864">from</TOKEN>
<TOKEN end_char="14873" id="token-113-14" morph="none" pos="word" start_char="14869">China</TOKEN>
<TOKEN end_char="14877" id="token-113-15" morph="none" pos="word" start_char="14875">had</TOKEN>
<TOKEN end_char="14882" id="token-113-16" morph="none" pos="word" start_char="14879">just</TOKEN>
<TOKEN end_char="14885" id="token-113-17" morph="none" pos="word" start_char="14884">30</TOKEN>
<TOKEN end_char="14889" id="token-113-18" morph="none" pos="word" start_char="14887">per</TOKEN>
<TOKEN end_char="14894" id="token-113-19" morph="none" pos="word" start_char="14891">cent</TOKEN>
<TOKEN end_char="14906" id="token-113-20" morph="none" pos="word" start_char="14896">reliability</TOKEN>
<TOKEN end_char="14908" id="token-113-21" morph="none" pos="punct" start_char="14908">-</TOKEN>
<TOKEN end_char="14915" id="token-113-22" morph="none" pos="word" start_char="14910">unlike</TOKEN>
<TOKEN end_char="14919" id="token-113-23" morph="none" pos="word" start_char="14917">the</TOKEN>
<TOKEN end_char="14922" id="token-113-24" morph="none" pos="word" start_char="14921">80</TOKEN>
<TOKEN end_char="14926" id="token-113-25" morph="none" pos="word" start_char="14924">per</TOKEN>
<TOKEN end_char="14931" id="token-113-26" morph="none" pos="word" start_char="14928">cent</TOKEN>
<TOKEN end_char="14936" id="token-113-27" morph="none" pos="word" start_char="14933">they</TOKEN>
<TOKEN end_char="14941" id="token-113-28" morph="none" pos="word" start_char="14938">were</TOKEN>
<TOKEN end_char="14950" id="token-113-29" morph="none" pos="word" start_char="14943">promised</TOKEN>
<TOKEN end_char="14951" id="token-113-30" morph="none" pos="punct" start_char="14951">.</TOKEN>
</SEG>
<SEG end_char="15106" id="segment-114" start_char="14955">
<ORIGINAL_TEXT>China is also the world's largest manufacturer of disposable masks of the kind being worn to slow the spread of the virus by people while out in public.</ORIGINAL_TEXT>
<TOKEN end_char="14959" id="token-114-0" morph="none" pos="word" start_char="14955">China</TOKEN>
<TOKEN end_char="14962" id="token-114-1" morph="none" pos="word" start_char="14961">is</TOKEN>
<TOKEN end_char="14967" id="token-114-2" morph="none" pos="word" start_char="14964">also</TOKEN>
<TOKEN end_char="14971" id="token-114-3" morph="none" pos="word" start_char="14969">the</TOKEN>
<TOKEN end_char="14979" id="token-114-4" morph="none" pos="word" start_char="14973">world's</TOKEN>
<TOKEN end_char="14987" id="token-114-5" morph="none" pos="word" start_char="14981">largest</TOKEN>
<TOKEN end_char="15000" id="token-114-6" morph="none" pos="word" start_char="14989">manufacturer</TOKEN>
<TOKEN end_char="15003" id="token-114-7" morph="none" pos="word" start_char="15002">of</TOKEN>
<TOKEN end_char="15014" id="token-114-8" morph="none" pos="word" start_char="15005">disposable</TOKEN>
<TOKEN end_char="15020" id="token-114-9" morph="none" pos="word" start_char="15016">masks</TOKEN>
<TOKEN end_char="15023" id="token-114-10" morph="none" pos="word" start_char="15022">of</TOKEN>
<TOKEN end_char="15027" id="token-114-11" morph="none" pos="word" start_char="15025">the</TOKEN>
<TOKEN end_char="15032" id="token-114-12" morph="none" pos="word" start_char="15029">kind</TOKEN>
<TOKEN end_char="15038" id="token-114-13" morph="none" pos="word" start_char="15034">being</TOKEN>
<TOKEN end_char="15043" id="token-114-14" morph="none" pos="word" start_char="15040">worn</TOKEN>
<TOKEN end_char="15046" id="token-114-15" morph="none" pos="word" start_char="15045">to</TOKEN>
<TOKEN end_char="15051" id="token-114-16" morph="none" pos="word" start_char="15048">slow</TOKEN>
<TOKEN end_char="15055" id="token-114-17" morph="none" pos="word" start_char="15053">the</TOKEN>
<TOKEN end_char="15062" id="token-114-18" morph="none" pos="word" start_char="15057">spread</TOKEN>
<TOKEN end_char="15065" id="token-114-19" morph="none" pos="word" start_char="15064">of</TOKEN>
<TOKEN end_char="15069" id="token-114-20" morph="none" pos="word" start_char="15067">the</TOKEN>
<TOKEN end_char="15075" id="token-114-21" morph="none" pos="word" start_char="15071">virus</TOKEN>
<TOKEN end_char="15078" id="token-114-22" morph="none" pos="word" start_char="15077">by</TOKEN>
<TOKEN end_char="15085" id="token-114-23" morph="none" pos="word" start_char="15080">people</TOKEN>
<TOKEN end_char="15091" id="token-114-24" morph="none" pos="word" start_char="15087">while</TOKEN>
<TOKEN end_char="15095" id="token-114-25" morph="none" pos="word" start_char="15093">out</TOKEN>
<TOKEN end_char="15098" id="token-114-26" morph="none" pos="word" start_char="15097">in</TOKEN>
<TOKEN end_char="15105" id="token-114-27" morph="none" pos="word" start_char="15100">public</TOKEN>
<TOKEN end_char="15106" id="token-114-28" morph="none" pos="punct" start_char="15106">.</TOKEN>
</SEG>
<SEG end_char="15298" id="segment-115" start_char="15109">
<ORIGINAL_TEXT>But as the disease began gathering speed in the country in January, China began limiting exports of the masks while also buying up supplies from other countries, the New York Times reported.</ORIGINAL_TEXT>
<TOKEN end_char="15111" id="token-115-0" morph="none" pos="word" start_char="15109">But</TOKEN>
<TOKEN end_char="15114" id="token-115-1" morph="none" pos="word" start_char="15113">as</TOKEN>
<TOKEN end_char="15118" id="token-115-2" morph="none" pos="word" start_char="15116">the</TOKEN>
<TOKEN end_char="15126" id="token-115-3" morph="none" pos="word" start_char="15120">disease</TOKEN>
<TOKEN end_char="15132" id="token-115-4" morph="none" pos="word" start_char="15128">began</TOKEN>
<TOKEN end_char="15142" id="token-115-5" morph="none" pos="word" start_char="15134">gathering</TOKEN>
<TOKEN end_char="15148" id="token-115-6" morph="none" pos="word" start_char="15144">speed</TOKEN>
<TOKEN end_char="15151" id="token-115-7" morph="none" pos="word" start_char="15150">in</TOKEN>
<TOKEN end_char="15155" id="token-115-8" morph="none" pos="word" start_char="15153">the</TOKEN>
<TOKEN end_char="15163" id="token-115-9" morph="none" pos="word" start_char="15157">country</TOKEN>
<TOKEN end_char="15166" id="token-115-10" morph="none" pos="word" start_char="15165">in</TOKEN>
<TOKEN end_char="15174" id="token-115-11" morph="none" pos="word" start_char="15168">January</TOKEN>
<TOKEN end_char="15175" id="token-115-12" morph="none" pos="punct" start_char="15175">,</TOKEN>
<TOKEN end_char="15181" id="token-115-13" morph="none" pos="word" start_char="15177">China</TOKEN>
<TOKEN end_char="15187" id="token-115-14" morph="none" pos="word" start_char="15183">began</TOKEN>
<TOKEN end_char="15196" id="token-115-15" morph="none" pos="word" start_char="15189">limiting</TOKEN>
<TOKEN end_char="15204" id="token-115-16" morph="none" pos="word" start_char="15198">exports</TOKEN>
<TOKEN end_char="15207" id="token-115-17" morph="none" pos="word" start_char="15206">of</TOKEN>
<TOKEN end_char="15211" id="token-115-18" morph="none" pos="word" start_char="15209">the</TOKEN>
<TOKEN end_char="15217" id="token-115-19" morph="none" pos="word" start_char="15213">masks</TOKEN>
<TOKEN end_char="15223" id="token-115-20" morph="none" pos="word" start_char="15219">while</TOKEN>
<TOKEN end_char="15228" id="token-115-21" morph="none" pos="word" start_char="15225">also</TOKEN>
<TOKEN end_char="15235" id="token-115-22" morph="none" pos="word" start_char="15230">buying</TOKEN>
<TOKEN end_char="15238" id="token-115-23" morph="none" pos="word" start_char="15237">up</TOKEN>
<TOKEN end_char="15247" id="token-115-24" morph="none" pos="word" start_char="15240">supplies</TOKEN>
<TOKEN end_char="15252" id="token-115-25" morph="none" pos="word" start_char="15249">from</TOKEN>
<TOKEN end_char="15258" id="token-115-26" morph="none" pos="word" start_char="15254">other</TOKEN>
<TOKEN end_char="15268" id="token-115-27" morph="none" pos="word" start_char="15260">countries</TOKEN>
<TOKEN end_char="15269" id="token-115-28" morph="none" pos="punct" start_char="15269">,</TOKEN>
<TOKEN end_char="15273" id="token-115-29" morph="none" pos="word" start_char="15271">the</TOKEN>
<TOKEN end_char="15277" id="token-115-30" morph="none" pos="word" start_char="15275">New</TOKEN>
<TOKEN end_char="15282" id="token-115-31" morph="none" pos="word" start_char="15279">York</TOKEN>
<TOKEN end_char="15288" id="token-115-32" morph="none" pos="word" start_char="15284">Times</TOKEN>
<TOKEN end_char="15297" id="token-115-33" morph="none" pos="word" start_char="15290">reported</TOKEN>
<TOKEN end_char="15298" id="token-115-34" morph="none" pos="punct" start_char="15298">.</TOKEN>
</SEG>
<SEG end_char="15468" id="segment-116" start_char="15301">
<ORIGINAL_TEXT>As well as halting virtually all exports of masks, China also bought up some 56million masks and respirators from overseas while fears of a pandemic were still far off.</ORIGINAL_TEXT>
<TOKEN end_char="15302" id="token-116-0" morph="none" pos="word" start_char="15301">As</TOKEN>
<TOKEN end_char="15307" id="token-116-1" morph="none" pos="word" start_char="15304">well</TOKEN>
<TOKEN end_char="15310" id="token-116-2" morph="none" pos="word" start_char="15309">as</TOKEN>
<TOKEN end_char="15318" id="token-116-3" morph="none" pos="word" start_char="15312">halting</TOKEN>
<TOKEN end_char="15328" id="token-116-4" morph="none" pos="word" start_char="15320">virtually</TOKEN>
<TOKEN end_char="15332" id="token-116-5" morph="none" pos="word" start_char="15330">all</TOKEN>
<TOKEN end_char="15340" id="token-116-6" morph="none" pos="word" start_char="15334">exports</TOKEN>
<TOKEN end_char="15343" id="token-116-7" morph="none" pos="word" start_char="15342">of</TOKEN>
<TOKEN end_char="15349" id="token-116-8" morph="none" pos="word" start_char="15345">masks</TOKEN>
<TOKEN end_char="15350" id="token-116-9" morph="none" pos="punct" start_char="15350">,</TOKEN>
<TOKEN end_char="15356" id="token-116-10" morph="none" pos="word" start_char="15352">China</TOKEN>
<TOKEN end_char="15361" id="token-116-11" morph="none" pos="word" start_char="15358">also</TOKEN>
<TOKEN end_char="15368" id="token-116-12" morph="none" pos="word" start_char="15363">bought</TOKEN>
<TOKEN end_char="15371" id="token-116-13" morph="none" pos="word" start_char="15370">up</TOKEN>
<TOKEN end_char="15376" id="token-116-14" morph="none" pos="word" start_char="15373">some</TOKEN>
<TOKEN end_char="15386" id="token-116-15" morph="none" pos="word" start_char="15378">56million</TOKEN>
<TOKEN end_char="15392" id="token-116-16" morph="none" pos="word" start_char="15388">masks</TOKEN>
<TOKEN end_char="15396" id="token-116-17" morph="none" pos="word" start_char="15394">and</TOKEN>
<TOKEN end_char="15408" id="token-116-18" morph="none" pos="word" start_char="15398">respirators</TOKEN>
<TOKEN end_char="15413" id="token-116-19" morph="none" pos="word" start_char="15410">from</TOKEN>
<TOKEN end_char="15422" id="token-116-20" morph="none" pos="word" start_char="15415">overseas</TOKEN>
<TOKEN end_char="15428" id="token-116-21" morph="none" pos="word" start_char="15424">while</TOKEN>
<TOKEN end_char="15434" id="token-116-22" morph="none" pos="word" start_char="15430">fears</TOKEN>
<TOKEN end_char="15437" id="token-116-23" morph="none" pos="word" start_char="15436">of</TOKEN>
<TOKEN end_char="15439" id="token-116-24" morph="none" pos="word" start_char="15439">a</TOKEN>
<TOKEN end_char="15448" id="token-116-25" morph="none" pos="word" start_char="15441">pandemic</TOKEN>
<TOKEN end_char="15453" id="token-116-26" morph="none" pos="word" start_char="15450">were</TOKEN>
<TOKEN end_char="15459" id="token-116-27" morph="none" pos="word" start_char="15455">still</TOKEN>
<TOKEN end_char="15463" id="token-116-28" morph="none" pos="word" start_char="15461">far</TOKEN>
<TOKEN end_char="15467" id="token-116-29" morph="none" pos="word" start_char="15465">off</TOKEN>
<TOKEN end_char="15468" id="token-116-30" morph="none" pos="punct" start_char="15468">.</TOKEN>
</SEG>
<SEG end_char="15697" id="segment-117" start_char="15471">
<ORIGINAL_TEXT>Despite reports from US mask manufacturers of factories in Shanghai being effectively nationalised, China denies it has any such policy in place and has said it is 'willing to strengthen international cooperation' on the issue.</ORIGINAL_TEXT>
<TOKEN end_char="15477" id="token-117-0" morph="none" pos="word" start_char="15471">Despite</TOKEN>
<TOKEN end_char="15485" id="token-117-1" morph="none" pos="word" start_char="15479">reports</TOKEN>
<TOKEN end_char="15490" id="token-117-2" morph="none" pos="word" start_char="15487">from</TOKEN>
<TOKEN end_char="15493" id="token-117-3" morph="none" pos="word" start_char="15492">US</TOKEN>
<TOKEN end_char="15498" id="token-117-4" morph="none" pos="word" start_char="15495">mask</TOKEN>
<TOKEN end_char="15512" id="token-117-5" morph="none" pos="word" start_char="15500">manufacturers</TOKEN>
<TOKEN end_char="15515" id="token-117-6" morph="none" pos="word" start_char="15514">of</TOKEN>
<TOKEN end_char="15525" id="token-117-7" morph="none" pos="word" start_char="15517">factories</TOKEN>
<TOKEN end_char="15528" id="token-117-8" morph="none" pos="word" start_char="15527">in</TOKEN>
<TOKEN end_char="15537" id="token-117-9" morph="none" pos="word" start_char="15530">Shanghai</TOKEN>
<TOKEN end_char="15543" id="token-117-10" morph="none" pos="word" start_char="15539">being</TOKEN>
<TOKEN end_char="15555" id="token-117-11" morph="none" pos="word" start_char="15545">effectively</TOKEN>
<TOKEN end_char="15568" id="token-117-12" morph="none" pos="word" start_char="15557">nationalised</TOKEN>
<TOKEN end_char="15569" id="token-117-13" morph="none" pos="punct" start_char="15569">,</TOKEN>
<TOKEN end_char="15575" id="token-117-14" morph="none" pos="word" start_char="15571">China</TOKEN>
<TOKEN end_char="15582" id="token-117-15" morph="none" pos="word" start_char="15577">denies</TOKEN>
<TOKEN end_char="15585" id="token-117-16" morph="none" pos="word" start_char="15584">it</TOKEN>
<TOKEN end_char="15589" id="token-117-17" morph="none" pos="word" start_char="15587">has</TOKEN>
<TOKEN end_char="15593" id="token-117-18" morph="none" pos="word" start_char="15591">any</TOKEN>
<TOKEN end_char="15598" id="token-117-19" morph="none" pos="word" start_char="15595">such</TOKEN>
<TOKEN end_char="15605" id="token-117-20" morph="none" pos="word" start_char="15600">policy</TOKEN>
<TOKEN end_char="15608" id="token-117-21" morph="none" pos="word" start_char="15607">in</TOKEN>
<TOKEN end_char="15614" id="token-117-22" morph="none" pos="word" start_char="15610">place</TOKEN>
<TOKEN end_char="15618" id="token-117-23" morph="none" pos="word" start_char="15616">and</TOKEN>
<TOKEN end_char="15622" id="token-117-24" morph="none" pos="word" start_char="15620">has</TOKEN>
<TOKEN end_char="15627" id="token-117-25" morph="none" pos="word" start_char="15624">said</TOKEN>
<TOKEN end_char="15630" id="token-117-26" morph="none" pos="word" start_char="15629">it</TOKEN>
<TOKEN end_char="15633" id="token-117-27" morph="none" pos="word" start_char="15632">is</TOKEN>
<TOKEN end_char="15635" id="token-117-28" morph="none" pos="punct" start_char="15635">'</TOKEN>
<TOKEN end_char="15642" id="token-117-29" morph="none" pos="word" start_char="15636">willing</TOKEN>
<TOKEN end_char="15645" id="token-117-30" morph="none" pos="word" start_char="15644">to</TOKEN>
<TOKEN end_char="15656" id="token-117-31" morph="none" pos="word" start_char="15647">strengthen</TOKEN>
<TOKEN end_char="15670" id="token-117-32" morph="none" pos="word" start_char="15658">international</TOKEN>
<TOKEN end_char="15682" id="token-117-33" morph="none" pos="word" start_char="15672">cooperation</TOKEN>
<TOKEN end_char="15683" id="token-117-34" morph="none" pos="punct" start_char="15683">'</TOKEN>
<TOKEN end_char="15686" id="token-117-35" morph="none" pos="word" start_char="15685">on</TOKEN>
<TOKEN end_char="15690" id="token-117-36" morph="none" pos="word" start_char="15688">the</TOKEN>
<TOKEN end_char="15696" id="token-117-37" morph="none" pos="word" start_char="15692">issue</TOKEN>
<TOKEN end_char="15697" id="token-117-38" morph="none" pos="punct" start_char="15697">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>